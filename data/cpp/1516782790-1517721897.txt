That's not what he is asking. He's asking if he can have `make_unique` and `string_view` backported, not to have the full set of features from C++17 somehow retrofitted in C++11. And I don't see why someone wouldn't implement those functions for C++11. The only thing that's not going to happen is officially adding them to the standard. As for the OP, and his arrogant assertion that the community is in bad shape: if it is so easy to see the future, maybe he can save us all a lot of trouble and provide us with a list of C++26 features? 
My bad I didn't saw it was platform specific, thanks ! 
Interesting concepts, thanks :) 
Well, I don't know where you leave, but in my country (France), I can vote for people that I think represent my ideas well. Of course, they might not be elected, but I did my citizen duty, and I expressed my opinion :) But sure, a good dictatorship will solve all our problems.
Thrift Enums are limited to 32 bits. Their encoded size depends on the protocol: [binary protocol](https://github.com/apache/thrift/blob/master/doc/specs/thrift-binary-protocol.md) uses 4 bytes; [compact protocol](https://github.com/apache/thrift/blob/master/doc/specs/thrift-compact-protocol.md) uses between 1 and 5 bytes.
+1, but mainly for the links to competing products.
A standard is final. It can only be changed by defining a new standard. You are talking crap.
What about static constexpr globals? They have scope but no linkage. It’s more of a grey area than you’re making it out to be.
Try upgrade to 15.5 before filing the bug. It might be fixed. I had nothing but problems with my code base moving from 15.3 to 15.4. Moving to 15.5 made them magically go away. 
[Here is info](https://reviews.llvm.org/D41723) on llvm's `-mretpoline` flag. The mitigation on x86 (32-bit) is more complex: https://godbolt.org/g/vyftJW
!remove
OP, A human moderator (u/blelbach) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7sjjvs/visual_studio_2017_154_compiler_bug/dt5udun/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7sleyl/what_is_the_enum_size_in_apache_thrift/dt5ue93/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Wow, it looks so ugly, and I can't imagine it performs well either. Interesting comparison. Thanks.
So, Moore's Law failed years ago and nobody noticed?!
Thank you for simplify the problem even more and even finding a work around. I'll give the work around a shot and use the simpler code to file a report.
Yes. It's pretty easy to make changes that break source, but not binary compatibility. It's also easy to make changes that break binary, but not source compatibility.
&gt; I feel like in a complex app with a fair number of virtual calls in hot loops, that's going to be a big issue. Like virtual calls in hot loops weren't a problem before.
That makes sense. Are there better solutions? Or is it a fundamental limitation of prefetch style CPU?
There are reasonable solutions that don't cost to much performance or die space. Intel newer CPUs already has some fine grained process-ID system for cache lines. That could be optimized to allow prediction but prevent "outside" process-IDs from getting better cache timings. The questions is how long until new CPUs will include it. Because x86 CPUs have a very long development cycle.
Looks like there is a need for shim libraries. Normal thing in other languages.
auto* new_future = new future;
This is related to Sean Parents Concurrency library.
This is awesome. But is QBS really such a great build system? ;)
And even if they include it, the next worry would be that not a lot of people will have the new instructions so companies can't just turn on support and have it work because of backwards compatibility issues. x86, x86-64 and ARM-Ax architecture based Software could be dealing with this problem for the next few decades in some form. A lot of programs are still x86 32 bit stuff compiled to the lowest common denominator level of available instruction sets because devs or owners won't take the chance their program will fail on some unknown platform. The mobile guys with their 2-3 year cycle will be rid of the problem sooner at least.
I use it at work and transition from qmake was both painless and straightforward. What is nice about it is that writing custom functionalities is really easy. Probing system for dependencies, nonstandard deploy features or some really outlandish file preparsing is just few keystrokes away x] Human readable file structure helps it a lot. What I don't particularly like is this weird 'profiles' stuff when you are working with Qt SDK.
It only loks more complex because it creates retpolines for all the calling conventions. Most of the output is 'shared' (once per compile) code that handles all the cases of STDCALL/WINAPI/etc.
Moore's Law isn't about performance. It's about the number of transistors.
I don't think they've ever actually changed the signature of a function between versions, just internal semantics. At the end of the day, it's a c standard library, your call to realloc or memcpy is probably fine no matter what version you use, since there's not all that much room for change. Think stuff like minor differences in what happens if you pass a function a null pointer. If you use it during development, you'll be fine, since you'll have the same behaviour as when it's deployed.
It's also not a "law" but rather an observation.
I can't compare to build2 or meson as I haven't used them, but compared to CMake and QMake it is much easier to understand and extend. The only downside is that it is less popular, which means you want get modules shipped for it by library vendors like you do with CMake.
&gt; 10. const-signal-or-slot &gt; Warns when a signal or non-void slot is const. &gt; &gt; This aims to prevent unintentionally marking a getter as slot, or connecting to the wrong method. **For signals, it’s just pointless to mark them as const**. I don't think that's true. If I have a non-const signal, I cannot emit it through a const object: class Foo : public QObject { Q_OBJECT public: void sayHello() const { emit hello(); } signals: void hello(); }; ... const Foo foo; foo.emitSignal(); This will fail to compile with *‘const class Foo’ has no member named ‘emitSignal’*. However, it will work correctly if I mark the signal const.
It was just an example (which I've unfortunately seen more than once in the wild). You're right though, ctrl+f would work similarly.
I'm not saying that I ever needed this, but the statement that "it’s just pointless to mark them as const" is not true. (PS: yes, thanks)
The idea that destructors shouldn't be marked `override` is new to me. Does anyone have a link to a justification of why?
The part I don't understand is line 4: the jump to the very next instruction. Why is that there?
you know, for whatever reason, I always end up going back to vim. I own a current license of CLion, and it's perfectly usable but I just always find myself preferring vim. Which probably says more about me than CLion. I do use their other products though, most notably Rider and DataGrip.
PAUSE + LFENCE is the generic retpoline sequence that works on Intel and AMD CPUs. 
What's non-traditional about it
Why not this? call meow ud2 meow: mov [rsp], r11 ret The looping retpoline seems like a waste of processor resources to me. IIRC, speculative execution doesn't continue when an always-faulting instructions, like `ud2`, is reached.
&gt; it may have performance impact and right you are: https://spectreattack.com/spectre.pdf
Looks more like a stress/security test than code review.
This is less relevant today now that C++ officially has threads, but it still remains a very convenient way to add parallelism with a few words.
You missed the point of what he was saying. He was saying that everyone looks down on everyone else, and it really doesn't matter.
**Company:** [The STE||AR Group](http://stellar-group.org/) at [Louisiana State University](www.lsu.edu) **Type:** Full time Postdoctoral Researcher **Description:** The STE||AR Group at Louisiana State University is searching for a qualified postdoctoral researcher with strong C++ development skills. Preferred candidates are interested in research relating to distributed runtime systems, parallelism in C++, and heterogeneous computing. The candidate would be responsible for supporting the STE||AR Group and its associated projects by: developing and maintaining the [HPX](https://github.com/STEllAR-GROUP/hpx) codebase, developing and maintaining application frameworks which support various application domains, mentoring and supervising staff and students as directed, writing and dissemination of research results, and writing and preparing research proposals for the solicitation of funding. **Location:** Baton Rouge, Louisiana, USA **Remote:** No **Visa Sponsorship:** Yes **Technologies:** Our team heavily relies on the C++11/14/17 standard features targeting different architectures and platforms and works closely with several standards committees. **Contact:** Interested applicants can apply [here] (https://lsu.wd1.myworkdayjobs.com/LSU/job/LSU---Baton-Rouge/Postdoctoral-Researcher_R00019614-1) or contact us at contact@stellar-group.org 
*I would like to see string_view and make_unique back-ported to C++ 11 compilers.* Those already exist. You just take a C++ 17 compliant compiler, and don't use anything from after C++11 except string_view and make_unique. Boom; it's compiling C++11, with string_view and make_unique.
1. Results of security audits are not usually made public, and 2. open source libraries usually do not get security reviews.
Code was manually inspected. And also the tests you mentioned were run.
This is nice, thanks for sharing. A little OT: beast depends on asio, which is great for many uses, However I’ve recently been investigating c++ http server libraries. I recently tried getting cppcms to run on lwip/freertos but got nowhere. Does anyone know if boost is supported on any lightweight RTOS?
&gt; Australian permanent resident or citizen Anyway possibility for a US Citizen to apply?
I set this up at my work for some of our apps. The shared c++ code originated from windows mfc. Then win forms (c++/Cli). Now pure std c++ It has worked pretty good so far (android and iOS) We target windows/mac as well but that is more about testing the code. We don’t have the resources for a full blown redo of the windows ui right now unfortunately. I found iOS was easier than android since you can do straight objective c++. Doesn’t work well with swift unfortunately. Android was a pain in the ass. We initially used ‘jnipp’ to help with interop. But it is so full of bugs/leaks we rolled our own in the end. Native threads need to be hooked into the java VM in order to call methods on java classses. Figure out how to hook all the threads you create now. I was using a method of hooking only when I needed to, but almost all threads ended up hooked in the end anyways, and Radom crashes were triggered when java references were stored in shared objects with indeterminate lifetimes. Still undecided what to do on mac/windows. Qt quick looks viable. Wish I could target win 10 only and use ‘native’ UI for each. If you have any specific questions feel free to ask!
They released the WSL integration without debugging support? That's annoying. I'll probably hold off on using it until I can debug my code
How do you define the build logic in iOS and Android? Do you have an xcode project and a gradle definition which duplicates the list of .cpp and .h files?
I’m on mobile, I’ll do my best to explain. Android studio + gradle can call out to cmake. So we have something like this: /app/Android/app_ui -&gt; main project, which depends on /app/Android/lib_wrapper -&gt; gradle project which includes c++ lib, java wrappers / helpers Somewhere in lib wrapper there is a android specific cmake file that includes the c++ wrappers and then links them with the cmake file that builds our shared lib. On iOS we checkout the library, then use a script to kick off cmake to generate an Xcode project that statically compiles our library. The main UI project is loaded up with a workspace and the c++ library as child project (reference). Way back when I tried to use vs 2015 to manage everything but I ended up abandoning their cross platform / cross compilation support in cavort of cmake and native ide.
Now do one for [MMIX](https://en.m.wikipedia.org/wiki/MMIX)!
I've used boost on QNX in the past. QNX isn't free, but it is a micro-kernel, you can make it about as lightweight as anything. All the kernel does is message passing, everything else is outside the kernel and optional.
I’ve used QNX in the past as well on imx 35 and 53. Their tools are great! Unfortunately I’m currently targeting MCU with cortex M0/M3/M4 like the NXP kinetis series. Can’t run qnx on that.
Well it's not like you have to use this, there are many ways to handle virtualization in some form.
String_view is implemented as a pointer and a length. It could have been implemented in the earliest versions of C++. 
Also Moore's law has nothing to do with this.
I've had good experiences with Qt Creator. It can start and debug the project directly in Android and iOS (hardware or emulator.) You can use it for non-Qt projects, but if you need to support iOS and Android along with desktops from the same code base, then you might want to use Qt to begin with.
Nothing requires virtual dispatch. It is used in C++ as a form of both generic data size and data type put together.
you can tell you only play with toy projects when you can use vim without issues i would kill myself if i had to use vim... great editor but the whole fucking point of these IDEs is to do insane shit that vim just cant
DUDE easy and multithreading do NOT belong together
I'm not sure about `ud2` specifically but speculation does continue after a fault; it would be pretty useless if it couldn't, for example, dereference a null pointer along a speculative path. This is one of the key factors enabling the Meltdown/Spectre exploits. If always-faulting instructions (as opposed to potentially-faulting ones) *are* special-cased, it's also possible that they're treated by the speculator similarly to the way C/C++ compilers treat UB, i.e. (correctly, in this case) assuming they're unreachable.
Does anyone nowadays... not... unit test? This would shock me if you care about delivering good software.
Thanks for the idea to write a version of make_unique. That would probably work. I have the same problem with boost's string_view as abseil's. Maybe some would agree that ideally C++ 11 would have string_view? 
Not 9, just 5. Worse than 2 still. On the other branch though ... just a dead end.
all or nothing. you don't get to say "this function is safe, really, trust me". Though, I can imagine at some point in the future some compilers to add special function-only flags/attributes that could say: don't retpoline this.
Fair enough, but they will still use up space in the icache.
It will. Still, this is the fastest workaround around. It boggles the mind the fucking mess we're in. 
Nice article, thanks!
I suppose that all destructors override so there's no information added by saying it explicitly.
another option: template &lt;typename... T&gt; auto split(string_view s, char sep) -&gt; std::optional&lt;std::tuple&lt;T...&gt;&gt;; if (auto tokens = split&lt;int, int&gt;(s, '|')) { auto &amp;[a, b] = *tokens; // ... }
It depends on the properties of the class. That will work if: 1. The class does not have a [virtual table.](http://www.learncpp.com/cpp-tutorial/125-the-virtual-table/) 2. All Member variables of the class are [POD.](http://en.cppreference.com/w/cpp/concept/PODType)
&gt; Now, it might look like I am questioning the C++ Core Guideline ES.20 (Always initialize an object). But the real essence of the guideline is, “assign initial value upon declaration provided that you know this value”. Actually, there was a discussion on GitHub about that, where people argued that blindly initializing variables, even if you don't have anything useful to initialize then with impedes diagnostic capabilities of the compiler. IIRC, the maintainers where quite adamant that variables should be initialized on construction, no matter what.
I hate output parameters - unfortunately, it turns out that they sometimes lead to much more readable and efficient code, than the alternative. In my personal opinion, this is one of those cases.
It annoys me how Digia still don't provide Qt in MinGW x64 in 2018!
An iterator is an output (or input/output) parameter and I really don't see, how passing iterators instead of the object we actually want to modify improves anything. I yearn for the day, when I can finally use ranges-v3 on msvc.
Does the bazel plugin work yet?
readable is subjective no doubt. but my function is no less efficient than using out-params: https://godbolt.org/g/NctWi4 of course, parsing an expensive-to-construct object inside a hot loop is another matter (but yeah).
what i like about this solution is that the out params are not available in any scope except the scope where they are guranteed to exist.
Yeah there are a few options but nothing from Qt proper. They only provide an old MinGW toolchain and Qt build whereas MSVC has x64 builds. 
Also you needn't use a structured binding to retrieve individual results: `std::get` works equally well and is just as clear. In fact, I prefer it, but maybe just because I haven't yet really embraced structured bindings. What I like about this is: * The expected parameter types are clearly shown in the call to `split`. * There is no need to define uninitialized variables prior to the call. * The results only exist within the scope which handles them, and are guaranteed to be valid.
The class should decide how to handle it. The class knows whether it's pointing to one thing, multiple things, what kind of things, or even whether it should be saved at all. If it's an owning pointer, then likely anything it points to should be serialized as well. If not, then maybe it should store an ID or something instead so it can hook the pointer back up to the object with that ID when deserialized.
Not an ebook, but there are some high ratted udemy courses on game dev in c++. Fair warning though, making a game can be a pretty big task, and you're probably going to have to start with something simpler to learn programming concepts before you can make a game. It's like asking for a book on carpentry because you want to build a house. You're gonna have to learn what a hammer and nails are first.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7sukg0/the_correct_way_to_store_object_in_a_file/dt7nl3a/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
So, because of Spectre and Meltdown, the correct way to implement a call is with the `ret` instruction. This is horrifying.
I got the following ones so far: - C++ For Dummies 7th Edition Book - C++ in 24 Hours Sams Teach Yourself, 5th Edition - Jumping Into C++ I guess the second one is the best one to start with?
https://bugreports.qt.io/browse/QTBUG-35288 Planned for 5.11 ^
If you recommend using Msys2 toolchain, why wouldn't I just install Qt package from Msys2? 
This means that also his header only c++fied zlib code has been audited. Noice! I think that code should be used by other parts of boost that use zlib compression. 
It usually also takes them ages until the latest MSVC version is offered as binaries :-(
Any link to that discussion? &gt; IIRC, the maintainers where quite adamant that variables should be initialized on construction, no matter what. I wanna see their arguments because I'm not convinced.
Destructors only override (in the new C++11 sense of the word) if a base class has a virtual destructor. Personally, I've been marking all destructors as `override` where applicable as a way of saying "This class was written with the assumption that the base class has a virtual destructor."
Link? Usually such situations can be avoided with immediately evaluated lambdas, unless you do indeed have out parameters. 
or I'm better with vim than you are.
they do the assessment for free?
I'm on my mobile, but if you search for the rule number that talks about initialization in the GitHub issues (probably closed by now) you should find it.
It was not free
I haven't announced it officially because we still have a couple of things to sort out
hi, I'm also a vim user. It compiles and shows errors nicely using clang, but renaming is rarely working (rtags). Do you know of a way to rename a thing in c++ code reliably?
I've been waiting for a walk integration in msvc since wsl shipped - maybe I should give clion chance.
perhaps any project is free to enforce a subset , via clang based tools that verify stuff on checkin / in build-scripts etc. The problem is who can agree on the particular subset. At least major projects could establish some preferences. I find there's big divergence between individuals on what features they want to keep. I made this https://github.com/dobkeratops/compiler , which satisfies my own tastes. I recently discovered this http://ziglang.org which superficially looks very similar, but instantly diverges on some ideas... and of course neither of us agreed with Rusts choices across the board (which is why we haven't happily migrated to that already)
What is usually the best approach in C++ to decouple your classes and implement a Clean Architecture which respects the SOLID principles? I can use something else than DI if needed.
DI can be used for a few things, I've used it for creating a sort of modular functionality framework. Plainly on Linux [dlopen](http://man7.org/linux/man-pages/man3/dlopen.3.html) is what you want. Here's a cross platform way of doing it. [linux example](https://github.com/mkn/mkn.kul/blob/master/os/nixish/inc/kul/sys.hpp) [windows example](https://github.com/mkn/mkn.kul/blob/master/os/win/inc/kul/sys.hpp) Which is used [here](https://github.com/Dekken/maiken/blob/master/inc/maiken/module.hpp)
Obligatory mention of proposed Boost.DI http://boost-experimental.github.io/di/, which sadly has not found a willing review manager to date :(
&gt; How do you define the build logic in iOS and Android? https://github.com/cristeab/ios-cmake https://developer.android.com/ndk/guides/cmake.html just use cmake and you can build for every platform. Also Qt supports android, ios, windows, mac, whatever you throw at it
If you're curious read about C++ Alliance here: https://cppalliance.github.io/
Boost.DI is a fantastic library, but unfortunately it still has a couple of unresolved bugs for some fairly common use cases e.g. handling dependency injection of singletons to factories. I wouldn't recommend using it in production code just yet.
Unfortunately my compiler is only C++11 at the moment for the framework I'm developing for :(
Thanks, yeah I'll continue my research. I also went to ETS ;)
Also, I'll give your lib a try!
Every place I've ever worked failed to leverage unit tests. There was some half-hearted statements about yeah we should, but no motion on it and in fact a rather hostile reaction to all steps toward that possibility. What I find really shocking is how few developers actually know what unit tests even are. There's quite a number of things call "unit tests" that just are not. For example: #ifdef UNIT_TEST int main() { printf("%d", some_call()); } #endif That place told me they do unit testing during my job interview. I was pretty upset to find that crap after being all excited I might learn some good skills.
C++ 11 is very limiting for library writers due to all the bugs and limitations. Hence few new C++ 11 libraries are around compared to new C++ 14 libraries, if a library such as DI started off in C++ 11 originally, it very quickly adopted C++ 14. C++ 14 is the bug fixed edition of C++ 11, as indeed is C++ 17. If your framework is properly on C++ 11, it should work just fine on the 14 and 17 point releases. Just flip the flags in your compiler, or if facing an ancient compiler, compile clang trunk and point it at an ancient runtime. For example, in my current contract it's a CentOS 6 with GCC 4.4 environment with an early 1990s codebase (pre C++ 98) of about 2M lines. Yet, with not much work invested, I have it compiling with clang 7.0 trunk still targeting a GCC 4.4 runtime and CentOS 6. And yes, all the sanitisers and new tooling work as expected. In some ways of course, this use case is unusual because an early 1990s era C++ codebase doesn't use much STL by definition, so libstdc++ 4.4 is not proving to be problematic for clang trunk. But also, much remedial work to support parsing old C++ has been added to recent clangs. So you may well be surprised.
There was a freestanding standard library proposal before SG14 recently. https://github.com/ben-craig/freestanding_proposal/blob/eef741b6b1b8960e9e2e53d59df90e94872f7fb0/freestanding.pdf. But I am unaware of an implementation. You are right to say that implementing the above freestanding standard library proposal ought to be straightforward given how much of it can be written with compiler intrinsics and the C library. But the closest that I know of - and it's quite far away from a proper freestanding standard library - is uSTL https://msharov.github.io/ustl/
Good talk, walks you through implementing std::function, which is a good way to learn how to type erase. I didn't see this: template&lt;class Sig&gt; struct function_view; template&lt;class R, class...Args&gt; struct function_view { R operator()(Args...args)const { return f(ptr, std::forward&lt;Args&gt;(args)...); } explicit operator bool() const { return f; } template&lt;class T&gt; function_view( T* t ): ptr((void*)t), f([](void* ptr, Args&amp;&amp;...args)-&gt;R{ return (*static_cast&lt;T*&gt;(ptr))(std::forward&lt;Args&gt;(args)...); }) {} template&lt;class T, std::enable_if_t&lt; !std::is_same&lt; std::decay_t&lt;T&gt;, function_view &gt;{}, bool&gt; = true &gt; function_view( T&amp;&amp; t ): function_view( std::addressof(t) ) {} private: void* ptr = 0; R(*f)(void*, Args&amp;&amp;...) = 0; }; no heap allocation. Needs some SFINAE checks that we can invoke the passed object with `Args&amp;&amp;...` and get `R`, and handling the discard-return `R`=`void` case we want. It costs some performance due to difficulty inlining and indirection, but no allocation. 
On paper, I believe there is nothing enforcing that this be the case, so a specific implementation might have hidden dependencies in the implementation details. However, I can't think of anything in the library that would warrant that at the top of my head. In conclusion: I wouldn't try to write portable code based on that assumption, but if it happened to work in my environments, I wouldn't hesitate to use it.
You might consider using an older edition of Boost.DI, one which worked on C++ 11. And then upgrade when your new toolchain lands. Ultimately it's a cost benefit thing for you to decide upon. A lot of people lament the lack of DI in C++, but in truth it's because historically people just went ahead and rolled their own DI in C++ and just never called it DI. Artifact of such a mature ecosystem. My point is, you can roll enough DI into your design that it all works lovely. Traditionally DI was done via the usual runtime virtual function technique, but in C++ 11 as you mention it can now be done statically as well via CRTP. It'll depend on your requirements, virtual dispatch is easier and with C++ 11 `final` not expensive, but statically does produce tighter binaries, but is harder. Depends on use case.
Qt would be a good pick IMHO. Following some tutorials sets you up with a basic GUI quickly. It should also be quite straightforward to set up a GUI with a unique look, ie non-native controls, a bit like the web. 
As I said, I'd rather not reimplement everything myself. That means more to maintain, more to do, and more coercing of C++'s absurdly complicated type and memory model to make it do what I want. I've looked at the GNU stdcpp implementation: I don't want to be writing that out myself. I'd also prefer to keep things compiler-independent. Given this, is it a good idea to use something like ustl as a drop-in replacement for those features I'm missing?
Company: [MXX Music](https://www.mxxmusic.com) Type: [Full time](https://www.mxxmusic.com/2018/01/25/new-job-listings-announced/) Description: MXX Music builds smart music editing software. We apply state-of-the-art music and AI technologies to the professional market. Location: London Remote: Occasional. Visa Sponsorship: No. Technologies: C++11/14, optional: MIR / Machine Learning frameworks Contact: join@mxxmusic.com
Does it have to be CPP? This actually seems like a good usecase for React or something.
No not necessarily. Open to any recommendations. I've been kinda scared to learn react after trying to learn it in a couple hours from scratch at a hackathon but I should give it another shot.
Awesome. Ill look into it. Thanks!
It really sounds like what you want is just a Website running in Full Screen Mode on a laptop.
Are you aware of any boilerplate / example project that sets up multiple platforms, or maybe just a small open-source cross-platform library that I could get inspired from. Never worked with CMAKE, but this looks like a lot of ducks to get in a row, so having a source of inspiration would help.
Thank you for considering my library! Sadly, I see you only have gcc 4.9. The minimum supported for all features is gcc 5.4 (Didn't took the time to setup CI for 5.1) I don't plan on supporting 4.9 since it would require disabling some features. With some patching, basic stuff may work. If you're decide to give it a try, don't hesitate to contact me if you have questions/problems!
Maybe my perception is wrong, but I thought Qt is a monstrous dinosaur (with huge disk / runtime costs) as well as pollutant of codebases with MFC-style anachronisms and other "not really C++" stuff. Since I want to create a small cross-platform lightweight C++ library (with no UI components), Qt isn't really on my radar.
We're using v124 with Boost 1.65.0 at my work. Are the fixes for these issues in that version? If not will they be backported and released as v125? We're not ready to move to Boost 1.66.0 yet
Use less buzzwords and get to the programming part.
In c++ I usually refer to component based design (or composition). Try to design your objects in such a way that you construct them with necessary state and pass these dependency objects to the objects that need them, usually also via the constructor. RAII is another common idiom for c++ programming and can be used pretty well with component based designs. C++ is about thinking your architecture through from the beginning, building objects that only accept known types, essentially defining all of the objects dependencies up front. 
On paper, if your implementation does not provide the &lt;type_traits&gt; header, it is not a C++ implementation. A freestanding implementation (as opposed to a hosted implementation) is supposed to provide the &lt;type_traits&gt; header. http://eel.is/c++draft/compliance#:%3ccstdlib%3e RTTI isn't in &lt;type_traits&gt;, it's in &lt;typeinfo&gt;. However, &lt;typeinfo&gt; is also required to be provided by freestanding implementations, but in practice, usually won't work. So on paper, you are in the clear, go for it. When operating from first principles, you are also fine, as type_traits is all compile time stuff. In practice, it depends entirely on what your toolchain vendor does. STL headers are allowed to include any other header they wish. If your vendor decided to include &lt;iostreams&gt; from the &lt;type_traits&gt; header, then you may have difficulty getting it to work. As mentioned, above, there is a paper going around that will revamp the definition of freestanding. I am the author of that paper. The current version is [here](https://github.com/ben-craig/freestanding_proposal/blob/eef741b6b1b8960e9e2e53d59df90e94872f7fb0/freestanding.pdf). &lt;type_traits&gt; will still be present in freestanding assuming my paper is adopted (don't make that assumption yet).
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7swj4w/c11_dependency_injection_best_practices/dt8avxt/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
!removehelp
Well I already got my answers so too bad 😤
I really wish polling the audience wasn't such a popular technique in tech talks. The answer to the speaker's question is interesting -- what the audience thinks the answer to the speaker's question is is totally irrelevant and just wastes time because they never want to answer.
&gt;I'm not sure about `ud2` specifically but speculation does continue after a fault; it would be pretty useless if it couldn't, for example, dereference a null pointer along a speculative path. Why do you assume that a null pointer dereference is going to generate a fault? 0 is a perfectly valid memory address. &gt;This is one of the key factors enabling the Meltdown/Spectre exploits. Um... no, not really? &gt;If always-faulting instructions (as opposed to potentially-faulting ones) *are* special-cased, it's also possible that they're treated by the speculator similarly to the way C/C++ compilers treat UB, i.e. (correctly, in this case) assuming they're unreachable. You don't actually understand this stuff, don't you? You're just wildly speculating. It's either that or I'm having a stroke 🤔
The compiler may not know log's implementation until it's linked. That's possibly why it's not optimized here. Until then it will be used 1:1.
Only the kernel/hypervisor has to be built with retpoline. Normal apps which don't share any memory with untrusted 3rd party code (or don't handle any sensitive data) aren't vulnerable. 
Because no -ffast-math: https://godbolt.org/g/SuAypq
I'm pretty sure the lambda implementation in this is dangerous. If you std::function a lambda, it will make a copy of that lambda which means anything you capture by value will be held with that copy of the lambda. This implementation only copies a pointer to an instance of the lambda, so if it goes out of scope you're kinda screwed.
but why then would cos be optimized ? That seems strange..
On the contrary. I think it is a good way to engage the audience. Conference talks are more than just talking to the camera. As far as people not wanting to answer, maybe they are afraid of sounding dumb. Perhaps gearing the questions to mitigate that would enhance the technique.
Probably because `cos` has no side effects, while `log` may set `errno` in case of domain/other errors or throw exceptions.
Its okay, but the speaker kind of has to report the result. Also in this case, I wish he started the long benchmarks while doing the polling. But its also the first time he presents at a big conference...
!removehelp
There shouldn't be a space in `-std=c++11`.
If it's actually persisted as a function pointer rather than a function object, you're right that there's no problems; but if it's persisted as a function object then it's UB if the lambda goes out of scope (but will likely work in practice).
So copying and then immediately casting to a function pointer (only if it's sfinae'd to do so) is safe, sweet.
It faults in user mode, but not in kernel mode, which is why the exploits allow for reading from kernel/arbitrary memory. &gt;You don't actually understand this stuff, do you? You're just wildly speculating. I'm not, nor did I say I was, an expert on modern CPU design. You aren't either. Your own post was itself "wild speculation." Since we're both of us here spitballing on Reddit, no CPU experts in sight, I felt my 2¢ might add to what I over-optimistically assumed would be a friendly conversation. &gt;It's either that or I'm having a stroke [Apparently so!](https://www.aan.com/PressRoom/Home/PressRelease/87)
I user CMake for my multi-platform projects, but there are a few problems: What kind of project to use for Android? CMake can compile C++ code for Android using Ninja generator quite well, but if you also need Java, and has a goal of building an APK, you probably need one of: * NVidia Tegra NSight plugin for Visual Studio: allows you to create a VS project that compiles C++ and Java into APK. Only VS2015 is supported (VS2017 is not). * Microsoft's fork of CMake that can generate VS projects for VS2017. Abandoned and based on CMake 3.4, which lacks some useful features, but still might work for you. * Android Studio/Gradle CMake integration - this one is a bit more tricky: CMake can't generate Gradle projects, but Android Studio can call CMake to compile C++ part. But you'll have to write Gradle/Java part by hand (very frustrating). Also, AS only supports its own fork of CMake 3.6. If you want to sue later version, you'll have to hack Gradle plugin, or wait until they fix it. This makes it kind of hard to recommend a CMake template. But if we leave Java part aside, then you might actually don't *need* much boilerplate: just a few IF's to include platform-specific files, depending on how complex and platform-dependent your code is. iOS is both better and worse. CMake has no official support for iOS, but iOS projects are just Mac projects with a few paths/settings changed. The most popular toolchain to compile iOS projects is probably the one from [Polly](https://github.com/ruslo/polly) collection. Now, this all might seem like too much pain, and you'd be right to say that. CMake, for all its convenience, isn't very good with mobile platforms yet (though things are getting better, especially in Android department, but slowly). As the other commenter suggested, you can try using Qt Creator (without Qt) or even just QMake. I don't have much experience with it, but one my colleague loved it more than CMake, and thought it best suited for simple multi-platform projects. Qt Creator supports compiling for Android and iOS, so you can have all your projects in one IDE, which is good. Lastly, there is [Qbs](http://doc.qt.io/qbs/) - I haven't tried it, but someone mentioned it on this very subreddit today, and its page states that *"Qbs is a tool that helps simplify the build process for developing projects across multiple platforms. Qbs can be used for any software project, regardless of programming language, toolkit, or libraries used."*, so maybe it worth a try?
you may be 10000x better than vim, oossibly 1000000x, but it doesn't make of the crap you said correct
cos() can set errno on domain errors.
I think your problem is believing there's a correct text editor or IDE. In fact, I'm going to drop out of this conversation, anyone with such an attitude isn't worth my time.
use a combination of grep and bufdo or argdo. People who rely on a monolithic IDE to be productive imagine there aren't tools to do many of these things, but something as simple as renaming is a complete non-issue. If you want to really talk about where an IDE is better, talk about integrated debuggers, not something like renaming. Each environment has it's pros and cons, but CLion has yet to become good enough for its pros to outweigh vim's. Maybe one of these days, but not yet.
Why dont they just use clang instead of maintaining their own parser for syntax highlighting? Seems like a weird decision
as outlined on [SO]( https://stackoverflow.com/questions/7420665/what-does-gccs-ffast-math-actually-do) this might lead to many numerical issues... 
ok. a lot of false positives here, especially if you have common word as a name. refactoring specific member is especially painful this way. it depends on the code base and work style. I like to change names very often.
Your comment has been automatically removed because it appears to contain profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7solxu/first_first_clion_eap_of_2018_starts_with_wsl/dt8zj6h/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
That doesn't work with stateful functors.
I actually really like Qbs. It's just in a chicken-and-egg state right now where nobody uses it, so there's not a lot of support for it, so nobody uses it, etc. I have only made little toy things with it, but it seemed to make more sense to me than Cmake.
Your comment has been automatically removed because it appears to contain profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7solxu/first_first_clion_eap_of_2018_starts_with_wsl/dt94zhd/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It's on by default on Intel's compilers.
If the goal is a real time program that's fine. Unless you need deterministic accurate floating point numbers (like for science or math or keeping people alive) you're fine
It works with stateful functors, but it does not *store* them. It is a view, not a value. For 8/10 uses of std function, that is enough. 
Storing functions for later exrcution lets you do fancy things like threads, coroutines, or other async operations.
Although my top use case for std::function is to store callbacks, where function_view is not such a great idea because of risk of dangles, function_view does have a super killer use case: it's compatible with other forms of runtime polymorphism, unlike templates. In particular, if you have an polymorphic interface that you want to accept a function object, you can't template it of course, but std::function is overkill since you don't need to take ownership (or heap allocate). function_view is a perfect fit for that use case.
Qt has been a godsend for my dev team. I am more at arm’s length from the code now, so I am sure they have headaches I just don’t hear about. But relative to what I was braced for when I told industry colleagues we were investing in Qt, I’ve been pleasantly surprised. Their standard support for commercial licenses is ok...just ok. I haven’t been wowed, so be prepared to wait if you need them, but in the end we got what we needed.
sin and cos map directly to assembly, where as log and exp do not.
Please stop posting this - you appear to be collecting top-voted subreddit links, which makes this especially useless.
For me it's more like 2/10 but ok ;)
I'm sorry, but on what basis exactly are you claiming greater efficiency? Are you just counting instructions and assuming that fewer means faster? Because that hasn't been true ever since we had pipelined processors (and was dubious even before that). Not to mention the fact that the function under investigation, split, isn't even part of the assembly! 
I find that DI is frequently indicated during TDD. If I find that I am writing essentially the same tests for an object as for one of its members, I instead inject the member and rewrite the tests in terms of interactions with the member.
Yes, and has since C++03.
Interestingly, not only can compilers _remove_ memset calls in some circumstances, it can also _add_ them. Something like `int foo[500] = {};` may well compile to include a memset call. Note this line in the [GCC documentation](https://gcc.gnu.org/onlinedocs/gcc/Standards.html): &gt; Most of the compiler support routines used by GCC are present in libgcc, but there are a few exceptions. GCC requires the freestanding environment provide memcpy, memmove, memset and memcmp The reason that the "freestanding" (no standard library) environment has to provide these functions is because the compiler may generate calls to them even when there is no call in the source.
It also does in C, although C requires you to provide at least the first element.
&gt; Here only the first element of the array is set to null, and one byte in the second element. Since the array contains 64-bit long integers, not even the first element is set to null. Or am I wrong?
Yeah sorry if this sounds funny to you but this is pretty basic in terms of software architecture... I'm doing software engineering, not tinkering. I have worked on massive projects in other languages that would not follow those principle and when they were handed to our team, were a big unmaintainable mess. I'm just trying to avoid this from the start.
I think you are referring to defect reports, where the standardization committee realizes they messed up and issue a fix. And yeah, there have been quite a few defect reports issued for C++11/14/17, so those could be considered a "backport" in that they change the behavior of an already-released standard. However, it doesn't really solve the problem of the OP, which is that he seems to want new library features to be available in old standards. Presumably, this is so his library can be used by a wider range of people. The issue is that even if you add new features (or fixes) to old standards, people still need to upgrade their compiler to have access to them.
just playing devils advocate here, but isnt memcpy less ambiguous in this case. What if I change my compiler options / version for some other reason, and then find our that my elements aren't initialized to 0? I think one complier I had didn't even bother to 0 initialize statics.
There is no difference between this and using a framework that does it for you.
Qt has a huge focus on embedded ; you can get complete 3d rendering on raspberry pi-level hardware at 1080p with it. [Try doing this with other toolkits :p](https://www.youtube.com/watch?v=HoHE7tbsUMw) I ship windows / mac / linux qt software and the overall archive size is 25 - 50 megs, considering that I use the QML script engine and traditional widgets, websockets support, the whole of FFMPEG, and a few other extensions. Of course if you don't need UI there's little point in using it. However the IDE is also very nice in terms of cross-platform support (and does not need you to use Qt at all, it supports plain C++ projects).
Without inlining, C++ optimizers are surprisingly helpless to do many things. In this situation, even when both arguments are verifiably the same and passed by value, the function could still be affected by state, either from a global variable, or a static local. That value could be mutated during the first call, giving a different result on the second. Without inlining a compiler can't generally verify that a function only depends on its inputs. 
The = {} is initialization code to default initialize all values in the array. The default initialization value of an int is 0. 
Honestly... The takeaway really is that C++ programmers can't do **anything** right. I mean... Googlers can't get `memset` calls right? **In God damn Chrome code!?** We need nice tools like PVS studio, sanitizers, fuzzers etc. Just... use them goddamn...
I tried using alloca inside a constructor to once to create a dynamically sized vector on the stack (as an experiment!). MSVC actually would act differently based on an inline hint to the constructor and destructor, though it wasn't consistent. 
The new gcc 7.3 can produce the same thing: [godbolt](https://godbolt.org/g/zofp9L).
CMakeLists.txt: project(my_lib) cmake_minimum_required (VERSION 3.10) # adjust according to what you have add_library(my_lib STATIC src/foo.cpp src/bar.cpp) target_include_directories(my_lib PRIVATE include/) For iOS : cmake -GXcode -DCMAKE_TOOLCHAIN_FILE=path/to/iOS.cmake -DIOS_PLATFORM=SIMULATOR For android just open the CMakeLists in android studio
I thought gcc wouldn't make X.0 releases anymore and that releases are now year-based.
&gt;GCC 7.3 is a bug-fix release from the GCC 7 branch containing important fixes for regressions and serious bugs in GCC 7.2 with more than 99 bugs fixed since the previous release &gt;This release includes code generation options to mitigate Spectre Variant 2 (CVE 2017-5715) for the x86 and powerpc targets.
And even __force_inline and friends is just a hint. Because sometimes it’s *technically* not possible or insanely hurtful for performance to inline a function.
go find a project you like on github and look through the issues to see if you can fix some
X.0 is for dev snapshots, X.1 is official release, X.N, n&gt;1 are subsequent patches to that release. There is roughly one new major release per year and server patch releases for relevant versions.
that's not what inline does. inline means that a function implementation may appear more than once (in different compilation units) during linkage (you need to mark functions as inline when you implement them in header files). You can't directly control/hint the compiler's ability to inline functions automatically. 
I wish to unsubscribe from this comment chain.
&gt; I mean... Googlers can't get memset calls right? That's why Pike gave them Go. 
Those are n00bs mistakes that don't read the documentation because they don't give a shit, it has nothing to do with the memset. 
Case in point.
&gt; Googlers can't get memset calls right? rule 1 of programming is that you can't get *anything* right. Unless your code is tested from top to bottom, or formally checked, it must be assumed to not work, and this in every programming language. Even one line bash scripts or 6 character sed commands can be wrong.
&gt; You can't directly control/hint the compiler's ability to inline functions automatically. the article explicitely shows that you actually can by showing the literal code that performs this in gcc &amp; clang's source code
I've never seen a definition for a Unit Test that required the runner be automated. Perhaps you can link me to one?
But that is not what `inline` does. The particular effect `inline` leads to the compiler inlining the function, but it might as well not have done so. These particular versions of gcc and clang just happens to do so.
No way. The JVM's startup time is horrendous.
&gt; But that is not what inline does. what `inline` does exactly is implementation defined so "These particular versions of gcc and clang just happens to do so." is exactly what's relevant : A function declaration (11.3.5, 12.2.1, 14.3) with an inline specifier declares an inline function. The inline specifier indicates to the implementation that inline substitution of the function body at the point of call is to be preferred to the usual function call mechanism. An implementation is not required to perform this inline substitution at the point of call; however, even if this inline substitution is omitted, the other rules for inline functions specified in this section shall still be respected. 
Several larger projects will even have a "good for beginners" or similar tag, and often have people willing to help mentor you on the project and how to contribute.
The standard doesn't define the behavior of non-standard libraries. If it is possible to write code with a particular behavior, it is possible that behavior could be found in a library since anyone can create one.
**Company:** [Dynon Avionics, Inc.](https://www.dynonavionics.com) **Type:** Full time or Internship or Contract **Description:** As a Software Engineer at Dynon Avionics, you will rapidly become a key member of a collaborative team of developers focused on creating the best avionics and aircraft systems for light aircraft. Candidates will act both as an expert in their contexts of greatest experience and as a generalist contributing to a broad spectrum of solutions developed by a cross-functional and self-managing team. We are accepting applications for Internships / Entry-Level positions as well as Senior-Level experienced professionals. You're a good candidate if: * You care about: * Delivering a job well done to make a difference in the real world * Building cool new stuff into a product that you can touch and feel * Developing elegant interfaces that make our products easy to understand and use * Fixing hard problems in order to make both your world and your users’ world better * Growing as a complete person and honing your craftsmanship as a way of life * Working closely with other developers who also care about all of the above * You are learning how to: * Iteratively design &amp; develop modern C++ with pragmatic application of industry best practices * Apply the agile software development practices of test-driven development and refactoring in the real world * Understand a problem at a high level and drill into the depth and breadth of complexity beneath it * Evaluate and make pragmatic trade-offs between cost, schedule, and functionality **Location:** Woodinville, WA and Canby, OR **Remote:** Part-time remote work is supported, but frequent in-office presence is required. **Visa Sponsorship:** Sorry, not yet. But if you're really interested, you could be the first! **Technologies:** Production: C++98/03, C++11, C++14, Linux, OpenGL Infrastructure: Jenkins CI, SVN, Git, GCC, Make, Python **Contact:** See [online listing](https://dynonavionics.bamboohr.com/jobs/view.php?id=12) for more details and to apply.
oh god, it's even worse than that!?! Your printf statement doesn't have a newline, so what if the next line calls a function that returns 43!?!? **OH MY GOD, HOW DO WE KNOW IF IT PASSED OR NOT WHEN BOTH CALLS OUTPUT TO THE SAME LINE?!?!?!** In reality, what you're talking about is a manual runner that calls the tests directly. The probably return a 0 or a 1, or true/false, or some other such thing. Which then gets piped out to a file and a simple grep pulls out the ones that failed, including the surrounding lines. It's perfectly workable, you're missing the forest for the trees here. These are unit tests, they're just not automated. While you may argue that they SHOULD be automated, they're still unit tests and it is **completely unreasonable** for you to claim that someone who has done this doesn't know what a unit test is. And it should be noted that process CAN be automated, what isn't automated is the generation of the tests. And if you're working in something like C or C++, that's a completely rational approach. There is a **clear** difference between the automated **running** of unit tests, and the automated **generation** of the tests for the runner. I was referring to the latter, you are trying to argue the former. And you're wrong about the burden of proof. You've made the claim that these aren't unit tests, it's on you to justify that claim. 
 void AsyncSocksProxySocket::SendAuth() { .... char * sensitive = new char[len]; pass_.CopyTo(sensitive, true); request.WriteString(sensitive); // Password memset(sensitive, 0, len); delete [] sensitive; DirectSend(request.Data(), request.Length()); state_ = SS_AUTH; } On a side note, I've never understood this desire to use `new[]` and `delete[]` in C++, instead of `std::vector&lt;T&gt;` (and in *rare* cases, `std::unique_ptr&lt;T[]&gt;`).
You should consider adding your library to currently fighting c++ package managers like buckaroo, cget, conan, conda, cpm, cppan, hunter, vcpkg and so on :P
I just think you're not very good with a little bullheadedness thrown in. If you're renaming early on in the development you're probably hitting a few files at most. This idea that naming something generic is a productivity hit here is outlandish, in vim you just add the i flag for interactive and then hit y or n for yes replace and no don't replace. There's no way this takes a significant amount of time. By the time that name starts getting used in a significant number of files, the name should already have been set to something that isn't likely to change without other major refactorings. There are so many other things that could potentially be productivity blockers that I just cannot take anyone seriously when they argue this is a problem. Yes it's slightly slower than an IDE, no I don't care, the benefits of using vim far outweight this **occasional** lack of productivity. It astounds me that anyone would cite refactoring names as opposed to things that actually are problematic, such as lack of an integrated debugger.
It could return a pointer to something that isn't an object yet isn't nullptr. Invalid pointers are not UB. Now, using invalid pointers in nearly every situation is UB.
&gt; The probably return a 0 or a 1, or true/false, or some other such thing. It returned a pipe delimited string filled with record data that had to be manually reviewed. You can get bent now.
I think no one pays attention to you because of your attitude and it pisses you off so you feel the need to misrepresent things on the internet. And when you get called out for it you get even angrier. It's **extremely** rare for me to do this, but I reported you for your random aggression. Hopefully you'll learn from the experience, but regardless, nothing you've stated here has shown that the folks you're working with don't understand what Unit Tests are. It appears to me that you disagree with the process they use surrounding Unit Tests. Which is absolutely reasonable, but what isn't reasonable is your insistence that they aren't Unit Tests and your strange aggression surrounding it. I'm going to end this by suggesting you find another job, it's obvious you have a lot of anger surrounding it and that can lead nowhere good. If you're really that pissed off about the way they do things, just leave.
So... [They are all beginners](https://www.viva64.com/en/examples/v512/)... Wolfenstein 3D, Qt, Apache HTTP Server, Doom 3, Open CV, .NET CoreCLR, FreeBSD, Tizen, ....
I would guess this point of view is shared by a majority of C++ devs. CMake (with the ccache option) is a solid choice; the good old way that's hard to beat...
&gt; It's extremely rare for me to do this, but I reported you for your random aggression. LOL. You got some serious issues dude.
I want to add VexCL to the list of math libraries mentioned here: https://github.com/ddemidov/vexcl Eigen has been mentioned and it's my go-to library for math in C++, but VexCL is a little more abstract and closer to Python's way of doing math operations on vectors etc. I believe you could also create e.g. a vexcl::vector&lt;Eigen::Vector3d&gt; and do parallelized operations on vectorfields or in numpy terms arrays of shape (N,3).
[http://clangpowertools.com](http://clangpowertools.com) 
[https://github.com/Caphyon/clang-power-tools](https://github.com/Caphyon/clang-power-tools) 
[Visual Studio Marketplace](https://marketplace.visualstudio.com/items?itemName=vs-publisher-690586.ClangPowerTools) 
Actually, I got more to say on this one. I don't know who the hell you are but you really got no place. Being dismissive of something stupid is not being aggressive and your little tattle nonsense is beneath the pale...especially with all your shouting. Take a look in the mirror. You don't know what code I was talking about or where it came from. I purposefully obfuscated and genericized it. Your statement that printf statements are no different from using a framework is really...I don't know where that could possibly come from but inexperience with unit testing frameworks. As to your reaching with whatever...I never mentioned anything about automating at one time vs. another. You really need to learn the difference between being blown off because you said something stupid, and being threatened or whatever it is you think I've done. You have clearly been the aggressor in this conversation, so just go watch your own self and your own problems before you go telling someone else to quit...or go running to mommy in order to teach me something about myself. I guarantee I have a much deeper understanding of my own issues than you ever will. For shame, tattle tale.
And you trust a compiler that violates such basic aspects of the c++ standard to compile the rest of your program as expected? If your goal is to initialize your variable, what could be less ambiguous than using an initialization expression?
The fact that this is a wishy accepted and often correct view says more about the state of the programming trade than a couple of wrong memsets.
The only place where it is technically not possible is with recursion. Proof: in every case where recursion is not involved you can inline by effectively replacing the function call with a copy of the called function with appropriate binding of parameters and variable renaming.
You also cannot inline `main`, nor virtual functions (if the exact type is not known at compile time and speculative devirtualization is not used), nor functions from separate translation units, etc. 
Right, this only works when the function being called is known. As long as the definition of the function being called is available to the compiler, there is no technical reason it could not inline it.
I don't get your two examples at the end. Why would something be wrong if you remove a space? Compilers don't look for spaces, but for tokens.
I fixed the typo. I believe in Python you would have y = x[:5] # the first 5 elements of x therefore removing the space would change the meaning of the statement. So the problem is that compilers would not be allowed to ignore the spaces in this kind of statement.
Why add a language feature when a library feature will do? I don't find your 5:10 syntax any easier to read than range(5, 10).
I would very oppose to make the syntax "space-sensitive". One of C++'s advantages compared to say Python is that you can remove and add whitespace as you please without changing the meaning of your code (of course the only exception is to separate different identifiers).
Probably that would just take getting used to. The kind of syntax using `range(...)` or even `{...}` becomes cumbersome when one increases the complexity of what one tries to achieve, especially if working on multidimensional arrays. I also believe the fact that it is an incredibly commonly-used feature in Python speaks for itself.
Ok. I think you misunderstood what I pointed out. What's the difference between these two lines? for (auto x : 0:5) {} for (auto x:0:5) {} Making one ill formed would make many problems. Operators and the separation of expressions, and the meaning of those would change because of spaces. Making things absolutely require spaces around some kind of symbols is reminding me of the `&gt; &gt;` when closing templates.
Thanks! Though I saw his cppcon talk, I had not read this. His syntax is quite concise already and using `{...}` as a shorthand for `range(...)` is already quite nice, but in my opinion a new language feature might make such array operations a lot easier to read and write.
The examples you showed have a very clear mapping to a library function call. You didn't show how this feature is different than just a simple function call, which is just adding syntax to the language for little benefit. It becomes yet another thing one has to learn to understand C++, whereas a library function can be searched and documentation can be found easier.
I've seen people get caught debugging the difference between `a/*p` and `a/ *p`. They meant the latter.
Instead of the weird whitespace sensitive corner cases, why wouldn't you just pick a different syntax for ranges that doesn't have this problem, like `5..10`?
I guess what I'm trying to get at is that C++ is a different language from Python. Different languages have different philosophies. I don't think it's fruitful to try to force idioms from one language into another. I absolutely agree that slicing works well in Python, which is because it's a well established idiom/syntax. I don't see how adding it to C++ is helpful when you could just write stuff like `vec.slice(2, 3, 2)` instead of `vec[2:3:2]`. It's fewer characters to type, but that alone is not enough reason for me to agree to adding this to the language.
There's also issues with ternaries. auto x=b?5:11:5:10:2; What the heck is x?
I dont quite get your example. I don't see how `vec[2:3:2]` is any more clear than `vec.slice(2, 3, 2)`; they both say exactly the same thing, but with different syntax. 
&gt; You didn't show how this feature is different than just a simple function call, which is just adding syntax to the language for little benefit It is indeed intended only as syntactic sugar. As an example of syntactic sugar recently added to C++ I would refer to nested namespaces in C++17: http://en.cppreference.com/w/cpp/language/namespace. Also, my experience with Python tells me it would have significant benefit, especially for mathematical and scientific programming. &gt; It becomes yet another thing one has to learn to understand C++, whereas a library function can be searched and documentation can be found easier. How are language features harder to find than libraries etc.? In my opinion it would be a simple, easy to learn addition.
As others pointed out, it would be best to forbid the whitespace-sensitive cases and only allow cases where it wouldn't matter, for example when passing a range to a function or operator.
This is a good point, I had not thought of ternaries... Currently I cannot think of a way to circumvent this case.
yes, doing C most of the time, when I do C++ I am tempted to initialize objects with memset. oops.
I think the namespaces syntactic sugar is a wonderful addition to the language, because it's a completely natural thing for one to attempt. People learning C++ have tried creating nested namespaces with `namespace foo::bar` and it falls out of consistency with accessing members of a namespace. It also has some very clear benefits for code readability, such as consistency in syntax, and especially reduced indentation in many cases. On the other hand, I don't see any benefit of Python style slicing / ranges as you are suggesting, other than that it is fewer characters to type. What is this "significant benefit ... for mathematical and scientific computing"? Is it that short syntax is highly appealing to those communities? Just a quick note on what I mean by searchability: I can easily Google "std::vector slice" and find the function. But how do I Google "std::vector bracket colon thing"? That's unlikely to turn up good results.
Here's a thought: you could require that the range syntax always be in `[]`s, so you could write `vec[1:3]`, but not `auto foo = 1:2`, instead you'd need `auto foo = [1:2]`. But IMO, this is just bikeshedding on syntax. If this feature is desired enough, we'll be able to find an appropriate syntax for all the quirks.
&gt; You have clearly been the aggressor in this conversation I'm going to give you the benefit of the doubt and assume you're just not realizing how aggressive you are. So I'm going to point it out directly. Your very first response to me (with context): &gt; What I find really shocking is how few developers actually know what unit tests even are. followed by &gt; Case in point. :\ Not only is this insulting, it's extremely dismissive, something you're now accusing me of? In your second response to me, emphasis mine: &gt; The idea that printf and a unit testing framework are the same is...**quite daft**. In your third response to me: &gt; You can get bent now. ---- I promise you, no reasonable person is going to look at this conversation and conclude that I've been the aggressor, or that I've even been particularly aggressive. You're free to make any claim you want, but you'll be alone in that. &gt; You don't know what code I was talking about or where it came from. I purposefully obfuscated and genericized it. Your statement that printf statements are no different from using a framework is really...I don't know where that could possibly come from but inexperience with unit testing frameworks. Of course you obfuscated it, that's what I was making fun of. You were attempting to make an argument based upon your example (that it just blindly output numbers?) and I was making fun of that by pointing out your example would print all returns on a single line with no spaces, making it completely useless. It's obvious to anyone with a modicum of critical thinking that the output contained more information than that. The bigger problem here is that you're missing the forest for the trees. They're testing the software. It doesn't matter what you call the tests. Unit Tests, Integration Tests, ad nauseum, it doesn't matter. They're testing the software. Maybe they are reviewing it manually, and maybe that's suboptimal, but the important point is **that the software gets tested**. The rest are things that may be improved, or they may be doing it manually for a valid reason. I don't know, but you act as if there's some egregious problem with them testing the software because they chose to maintain the runner manually. That's an issue with your perspective, and it goes right along with the horrific attitude you've displayed. And whether you realize it or not, I've given you the benefit of the doubt by assumine you're just frustrated with your job and are not just a huge fucking asshole. Maybe I'm wrong on that score, but if you really are that frustrated you need to find another job. If you are just a huge fucking asshole, well... either you'll figure it out or you won't, I honestly don't care. I've done you niceness by pointing it out, it's up to you whether or not you want to hear what I'm saying.
Your comment has been automatically removed because it appears to contain profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7smpgg/benefits_of_unit_testing_and_test_driven/dtamv7j/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
How would forbidding arbitrary cases because of a conflicting syntax and resulting in a mess of a feature be better than just picking a different, non conflicting syntax that works everywhere you'd expect it to?
And for the sake of being a tiny bit more complete, Microsoft's compiler has a flag (-Ob1), which is documented as: "Allows expansion only of functions marked inline, __inline, or __forceinline, or in a C++ member function defined in a class declaration." Reference: https://docs.microsoft.com/en-us/cpp/build/reference/ob-inline-function-expansion
Indeed, that would be the case in 1D arrays. But in 2D, `vec.slice(2, 3, 2)` is no longer unique, it could mean any of the following: vec[2:3:2] vec[2:3,2] vec[2,3:2] It is not clearly defined in which dimension you are slicing and thereby what each of the numbers mean. There are ways around that, the most obvious being that this slice should always be 1D, but in my opinion this creates increasingly cumbersome syntax, such as `vec.slice(2,3,2).slice(4,5,4)` (especially for compile-time, i.e. fixed-size slices as in Eigen: `vec.block&lt;2,3,2&gt;(index1).block&lt;4,5,4&gt;(index2)`).
&gt; You have clearly been the aggressor in this conversation I'm going to give you the benefit of the doubt and assume you're just not realizing how aggressive you are. So I'm going to point it out directly. Your very first response to me (with context): &gt; What I find really shocking is how few developers actually know what unit tests even are. followed by &gt; Case in point. :\ Not only is this insulting, it's extremely dismissive, something you're now accusing me of? In your second response to me, emphasis mine: &gt; The idea that printf and a unit testing framework are the same is...**quite daft**. In your third response to me: &gt; You can get bent now. ---- I promise you, no reasonable person is going to look at this conversation and conclude that I've been the aggressor, or that I've even been particularly aggressive. You're free to make any claim you want, but you'll be alone in that. &gt; You don't know what code I was talking about or where it came from. I purposefully obfuscated and genericized it. Your statement that printf statements are no different from using a framework is really...I don't know where that could possibly come from but inexperience with unit testing frameworks. Of course you obfuscated it, that's what I was making fun of. You were attempting to make an argument based upon your example (that it just blindly output numbers?) and I was making fun of that by pointing out your example would print all returns on a single line with no spaces, making it completely useless. It's obvious to anyone with a modicum of critical thinking that the output contained more information than that, something you later admitted. The bigger problem here is that you're missing the forest for the trees. They're testing the software. It doesn't matter what you call the tests. Unit Tests, Integration Tests, ad nauseum, it doesn't matter. They're testing the software. Maybe they are reviewing it manually, and maybe that's suboptimal, but the important point is **that the software gets tested**. The rest are things that may be improved, or they may be doing it manually for a valid reason. I don't know, but you act as if there's some egregious problem with them testing the software because they chose to maintain the runner manually. That's an issue with your perspective, and it goes right along with the horrific attitude you've displayed. And whether you realize it or not, I've given you the benefit of the doubt by assuming you're just frustrated with your job and are not just someone with an extremely bad attitude problem. Maybe I'm wrong on that score, but if you really are that frustrated you need to find another job. If you are just someone with an extremely bad attitude problem, well... either you'll figure it out or you won't, I honestly don't care. I've done you niceness by pointing it out, it's up to you whether or not you want to hear what I'm saying.
https://www.youtube.com/watch?v=Jne9t8sHpUc ;)
OK I see what you mean. Those are indeed valid points. Complicated indexing (and more so slicing) of multidimensional arrays, e.g. for numerical calculations, is quite cumbersome in C++ when compared to Python. Code readability can suffer quite a lot from this. By now, a few libraries have managed to make maths in C++ a lot nicer (see e.g. https://github.com/ddemidov/vexcl), but I still feel a lack for proper (concise) slicing.
(you have your Twitter secrets committed to a public repo, might want to fix that)
Why would you reply how to unsubscribe to that announcement... lol.
Went into Linux directory. First line in main: #ifdef _WIN32 wut?
well I tried, good luck.
Yes, x86 includes x86 and x86_64
If you want to have an array of bool addressable by pointer arithmetic, you can't use std::vector, because of its specialization for bool. I was bitten by that more than one time, but I think I used unique_ptr in the end.
FWIW MSVC's inlining heuristic also looks at the inline keyword, but it has a much smaller effect than most people assume. So much so that if I had to choose between saying it has no impact versus we take it Very Seriously, I would just round down to zero and say it has no impact. But that's not literally true. In contrast we take __forceinline Very Seriously.
FWIW MSVC's inlining heuristic also looks at the inline keyword, but it has a much smaller effect than most people assume. So much so that if I had to choose between saying it has no impact versus we take it Very Seriously, I would just round down to zero and say it has no impact. But that's not literally true. In contrast we take __forceinline Very Seriously.
I've used gradle for C++ projects both professionally and as a hobbyist. It's awesome for Java, so much better than everything that came before it, so I was pretty hopeful when using it for C++, but it fell short of expectations. It maybe makes sense to use if you're doing JNI (calling native code from Java), no one wants multiple build systems for the same project. I want it to be good enough for standalone C++ projects, but CMake really is superior. If you run into a problem, or are trying to do something non-standard, it is extraordinarily difficult to figure out how to do it in gradle. The error messages are useless, and the documentation is insufficient. Examples online are all trivial toy ones that add very little, and there's barely any SO coverage for their native stuff. With cmake, someone else somewhere on the internet has run into your exact problem and the answer is findable. Another aspect that is hard for them to address is that if you want to embed third party libraries, CMake is by far the easiest option, as most (recent) C++ projects out there use it. Assuming they've set theirs up correctly (which is usually a good bet if it's a large project, someone will have complained if it's not), it's trivial to embed their library in your project. I do hope gradle continues to improve their C++ support. Competition is good, and CMake is far from ideal. Maybe someday it will make sense to use it.
I'm writing a minesweeper program. Write tetris, chess, hangman, anything. Put the code on github. Share the program on Facebook with your friends. Put some fun things in there. Make sure your name gets connected to the code. That way when you apply for a job and people Google your name, they will find your code and can see the concepts you're familiar with.
Functions from separate TUs can absolutely be inlined by LTCG.
For that matter, don't feel bad about following tutorials. After you're done put your own spin on the creation. Maybe you followed the Weekend Ray Tracer book, but you thought maybe it should read in scenes from a text file, etc.
Inline generally has more critical language meaning based on how it interacts with the one definition rule. While compilers are basically allowed to ignore it for actual code generation purposes, the ODR implications are required. More details at http://en.cppreference.com/w/cpp/language/definition
I use CMake, generally. It's a very portable solution to building your projects, and knowing it will serve you well. But seriously: I've interviewed plenty of people at all levels of experience. Your portfolio is only a small piece of the puzzle. As others have said: go solve real problems on a project with which you share interests. Actual contributions to a project will be much more valuable, since they require the same skills that you'll be using day-to-day in the office.
can you recommend/find one for me - i swear i've never seen one like it. Thanks :) 
[This repo](https://github.com/MunGell/awesome-for-beginners/blob/master/README.md) appears to catalog beginner friendly open source projects, and should be a good starting point! It has projects from a variety of languages too.
You're welcome, and good luck!
I can second CMake. I personally despise having to use it and yearn for a real package system for C++, but it's used in a number of large codebases, and my first job (the one I have right now) uses CMake.
No need to replace, just use std::fill() and non-member begin/end(): int indices[500]; std::fill(std::begin(buf), std::end(buf), -1); 
Anything in libstdc++?
like any very useful idiom, it can be abused. news at 11.
Programming is, at its heart, trying to get a very complicated boolean logic system to produce the correct boolean values. We pile abstraction on top of abstraction to try and make sense of it all, and often we try to forego abstractions when we use things like memset, but it's almost impossible to know exactly what you're doing. No human being, let alone a single programmer, would be able to keep all those details in their head. The only way to be safe is to keep them managed by some easier to handle abstraction. Otherwise we'd all still be writing hand-written machine code for each individual machine.
I had to wrap up all mutexes in Pimpl types to get around c++/CLI compilation units being unable to include mutex. :( As those units go away, I un-pimpl them. It’s a hard-knock life, for us.
That's intentional. Its a free to use account.
True, but it's pretty easy to write a small wrapper to do fills function style, i.e. fill(container, -1). Similar syntax and consistent type-safe filling for all your contiguous buffers whether they're arrays or objects, and especially ones you don't have control over the definition for. 
Maybe the author wanted to reduce build times, rather than inflate them?
Some people are clever enough to subscribe to a gcc announcements list but nothing besides that. I question how they can even use gcc? Maybe they thought that gcc stood for “goddamn communist catchers”. That seems more en vogue recently. 
If you have an idea of what you wish was in your profile, learn those missing skills by trying to implement it.
Surely pimpl is just an implementation detail. You should be able to un-pimpl something but still keep the same API. 
No. However assumption that you are immune to such kind of bugs *is* a beginner mistake. 
&gt; Invalid pointers are not UB. You should still be careful with that. From the standard: "Indirection through an invalid pointer value and passing an invalid pointer value to a deallocation function have undefined behavior. Any other use of an invalid pointer value has implementation-defined behavior." This is followed by a footnote that says: "Some implementations might define that copying an invalid pointer value causes a system-generated runtime fault." I'll readily admit that I haven't encountered such a system yet, and if it should ever happen, I'll be happy to tell the owner of said system to go buy a proper computer... 
As it turns out pimpl can help with Spectre and Meltdown mitigation. This is what Webkit developers are [reporting](https://webkit.org/blog/8048/what-spectre-and-meltdown-mean-for-webkit/). Poisoned pimpls. Oh my!
That's what syntax highlighting is for.
Have you considered a user-defined literal? Something like this: "5:10"_r // translates into std::range(5,10) As a side note, I think a method to construct a user-defined literal from multiple components would be much more widely useful than a slicing function. You could in fact use it to construct a slicing function, but also many other things, including complex numbers (with both components!), vectors, matrices, etc. 
Why don't you allocate things with `...={0}`? It's impossible to get wrong, yet every piece of C code I look at invariably does `struct X x; memset (&amp;x, sizeof x, 0);`...
No argument there, but that doesn't mean we should just accept that software has errors and treat that as some kind of fundamental law of nature.
There's a few changes. They're listed here: https://gcc.gnu.org/gcc-7/changes.html (Search for "libstdc++".)
Note that it should be `={}`. Otherwise you have to initialize every member to avoid compiler warnings.
It does. Would be nice if we could write this though: int A[100] = {-1 ...}; And have everything initialized to a specific value.
My question was about why it isn't used more commonly in C, which doesn't allow `={};`. Are there actually even compilers that warn on this? I've been using it for years and years and would consider it idiomatic myself (even though I know lots of people use memset instead)... 
Hammers have a philosophy: it is for hiting things. So when you think "Maybe I should add a screwdriver to the handle", you consider if that matches what hammers are for. Adding a nail-remover, it enhances hitting things (oops, nail you just hit needs removing). This isn't the *end* of the consideration, but a short cut smell test that saves cognitive load and wasting time on prototyping junk.
Friends don't let friends do PIMPL.
&gt; I had to wrap up all mutexes in Pimpl types to get around c++/CLI compilation units being unable to include mutex. And why would that be?! If your code is unable to include standard headers without a compilation error, then that's the issue, not `&lt;mutex&gt;`.
&gt; After 4 hours of trying to make one of them a template class I gave up and worked around the issue I was trying to fix It's perfectly possible to do that - either by making the implementation another .h file you include where needed, or using [explicit template instantiation](https://stackoverflow.com/questions/2351148/explicit-instantiation-when-is-it-used) in the implementation file.
I was actually worried about running into UB accidentally. Pretty sure that if doing this had been UB, there would have been a way to make it well-defined (E.g. via something similar to launder()?) instead of having to blanket ban external libraries. (C++ can't have achieved such a large userbase if its FFI introduced UB so easily!)
Inlining behaviour is documented (somewhere) in the gcc manuals. I don't have a reference for you but I'm sure you can find it. From my recollection, the inline keyword (for gcc) simply increases the threshold of the number of instructions an inline call would produce before it is no longer considered for inlining. I don't know if I recall these numbers correctly, but I think the magic numbers were 100 instructions normally, and 500 when manually inlined. So for a call to a function that isn't marked as inline, the compiler will inline the call if the function itself produces no more than 100 instructions. If it is more than that then it will not inline it. If the function is marked as inline then that threshold is increased to 500. My approach is to never mark functions as inline. Never. The compiler is much smarter than me and until I have identified a performance bottleneck and profiled it there's no reason to believe I can arbitrarily mark things as inline on a hunch and do a better job than the compiler. When I have had performance bottlenecks I've never yet found an example (personally) where manually requesting inlining has been the solution. I expect most people who are fiddling with such manual optimisations would be better playing with other compiler options, such as optimisation levels, -fwhole-program-optimisation (?) and addressing design issues that are inherent to their performance woes.
Seriously? Ok, can I make a suggestion? Stop reading the standard. It's just making you unhappy, and you're not learning anything useful from it. Instead get a good book (perhaps "The C++ Programming Language"), and learn from that. And do NOT worry about something that would break _every single C++ application on the planet_ if it were to magically stop working. 
You just look for `std::vector slicing` and you'll get an SO answer or std::vector and you'll get a page that lists all member functions and operators don't pretend this is harder than it is. Regarding the advantages of a more concise indexing syntax (although people forget we then also need a syntax to accept such a range as a function parameter): I don't understand why parts of the the c++ community have be such an aversion against making simple things simple. C++ is far too verbose anyway and I welcome every suggestion, that makes code more concise and readable.
You just look for `std::vector slicing` and you'll get an SO answer or std::vector and you'll get a page that lists all member functions and operators don't pretend this is harder than it is. Regarding the advantages of a more concise indexing syntax (although people forget we then also need a syntax to accept such a range as a function parameter): I don't understand why parts of the the c++ community have be such an aversion against making simple things simple. C++ is far too verbose anyway and I welcome every suggestion, that makes code more concise and readable.
What's wrong with "[Gentlemen](https://en.wiktionary.org/wiki/gentlemen)"? I wrote this just to attract attention.
Ah, that makes sense, so it's an extension Clang &amp; GCC allow? Or are compilers not required to generated errors in this case?
Are you familiar with the pimpl idiom? One of the main points is to avoid the inclusion of headers, as definitions don't need to be known (everything is handled via pointers) . Removing the pimpl idiom invalidates this.
API maybe, but not ABI.
I think pimpl on every class would be overkill for that. If you are going to have one pointer indirection on any class anyway you might as well just make your data members pointers and forward declare their classes instead.
Does anyone actually use LTCG? I know we don't because it's way too slow on big projects. 
When I run into stuff like that, I wonder how much of it is cargo cult programming. I'll stumble into some piece of code with Hungarian notation everywhere, no clear lines of inheritance and no objects taking responsibility for actually doing anything, and it feels like the guy was programming directly from one chapter of a "C++ For Dummies" book. I've seen programmers where you could tell which chapter of "C++ for Dummies" they were in for any particular file you were looking at. It's like this one Java programmer, who arguably was the worst programmer I've ever met, every single one of his classes was a singleton. Seems like he was just reading through the design patterns book and seized on that as the only thing he could even remotely grasp, and then just did that everywhere. He eventually left and rumor has it started a liquor store. Management didn't want to hear that we had to rewrite all his code, but trying to make use of anything he wrote would have been much more costly. There is such a thing as starting with worse than nothing.
Mmm, I'm not a huge fan of pimpl either tbh. I quite like the C way of encapsulating away stuff from clients, and the only other thing pimpl does really is fixing C++'s bad compile times. My comment was uncharacteristically snarky (for me) but it wasn't clear **why** OP wanted to replace everything with templates.
I over simplified - the legality checks are complicated. The actual restriction involves asm with flow (and a few other cases). We can inline some trivial inline asm cases. We also avoid inlining alloca cases (as someone pointed out below) - but I think this is less about legality and more a heuristic thing trying to avoid introducing alloca in functions that don't currently have it.
&gt; it's an extension Clang &amp; GCC allow? I'm not sure they do allow it in the general case but they probably do. My understanding is that this rule is to allow an implementation to do things like insert the code to run dynamic initializers for the program at the beginning of main. As far as I know MSVC++ allows this because we have an actual entry point not named `main` in which we put runtime init code and similar, which calls `main`. &gt; Or are compilers not required to generated errors in this case? Compilers aren't required to warn for UB :)
My company’s codebase uses the same libraries for native C++ and mixed managed code projects. The MSVC C++/CLI mixed mode compiler cannot make certain types in std within managed memory (e.g. std::thread, std::mutex). It must be done by pointer, if at all. The ultimate solution would be to ban these project types from using those libraries, but I’ve not acquired that kind of power yet.
You need to give people more credit instead of insulting their intelligence.
LTO?
Thin-LTO
It’s 2018. it’s a shame we have have to use stuff like PIMPL with terrible runtime efficiency to improve compile times...
Is it possible to get a visa sponsorship for AN internship position on NVIDIA? 
I compile a good 95% of the operating system I run with -O3 -march=native -flto. It hurts compile time a bit, but I spend most of my time compiling in debug mode anyways... Release mode only occurs on Travis CI and appveyor servers :p 
Why don't you read the OP's reply, just above yours.
&gt; No argument there, but that doesn't mean we should just accept that software has errors well, what can we do instead ? any random guy who started programming two months ago can publish code on github and have its programs used by thousands of people. No one expects bridge engineers to build and ship bridges on their own two months after the beginning of their studies ; the difference is that shipping virtual bridges has almost no cost in comparison.
That's extremely rude.
Unfortunately, at least on Unix-like systems, almost every app is going to share memory with arbitrary 3rd-party code in standard system libraries like libc and libstdc++. I would suspect that an attacker would quite easily be able to find data from those libraries that the victim app never touches and therefore won't be in the cache naturally.
&gt; Are there actually even compilers that warn on this? Ran into myself last night, in fact. I added `= {0}` to a struct and then bam, warnings, warnings everywhere. Also got to find out that `resize`
Yes. In fact I once had to spend hours debugging the Qt build system until I realized that there was this wee qmake option for qtwebkit (or qtwebengine, I forget) called `no_ltcg`. Without forcing that option (it was off by default) my linker would literally segfault trying to build the module.
PIMPL isn't *horrible* for runtime (though mitigations related to Spectre may change that), but it's not merely done to improve compile times. Qt and KDE both use the technique heavily, but that's to improve ABI stability.
Well if the PIMPL data is heap-allocated that means dereferencing a pointer and potentially causing cache miss(es) every time you access it.
I hate to be a curmudgeon, but this subject has really been beaten to death already. Did we need another blog post about it?
Dereferencing a pointer is what the branch target predictor in CPUs is for, and they do a very good job at that. Likewise, if the code being pointed to is "hot" then it will already be in the cache, just like with non-PIMPL code. There's even scenarios where PIMPL would *improve* cache performance if the code segments being pointed to were all nearby in the same few cache lines. Optimization is a complex subject, you can't just always look at code and know what outcome you're going to get. Profiling is key.
The biggest problem I see in the examples is that there is more C than C++. No `std::array`?
&gt;Compilers aren't required to warn for UB :) Oh, silly me, I knew that! Thank you for the extra info and answering my questions. 👍
Yes, until fixed? Simple as that. 
Yes, in a `ref class`, native types must be pointers. But that does not prevent you from including headers (albeit, why would you? a forward reference is enough). There's a way to have native types as members in managed ones and vice-versa, that's the bread-and-butter of C++/CLI. It rather looks like this codebase took a wrong turn somewhere.. 
Just like the comment below, but to specify why pimpl fixes it. You can include the wrapper in your CLI classes and compile with the C++/CLI compiler which will be fine, because you've not included the bad files. You bury those in the impl definition file and then you compile that with the standard MSVC, which allows for mutex. It's a naughty trick, but it works. 
&gt; It's like this one Java programmer, who arguably was the worst programmer I've ever met, every single one of his classes was a singleton. Maybe he was a Fortran 90 programmer. 
Invalid pointer isn't, but it's as good as. Nothing reasonable can't be done with it, so there's no point in having one. I think you wanted to say "a C library can be used to provide memory for type X", with the idea that the same library can be used to construct said type instance? I guess so, but you have an obtuse way... 😁
From MSDN at [mutex at msdn](https://msdn.microsoft.com/en-us/library/hh921467.aspx) : “In code that is compiled by using /clr or /clr:pure, this header is blocked.”
Well, I was talking about professional software development (although that is admittedly a wide field), but I e.g. hope that no Programmer with only 2 months experience can contribute code to chromium without a proper review of the code. In any case, it's not that I have a solution to it or that I can't see the reason behind it. It was mainly an observation that the amount of errors commonly accepted in software engineering is astonishing compared to most other trades and it is not a good sign that this is considered normal.
But that's an ABI thing rather than A**P**I. Extra headers don't necessarily result in any API change.
&gt; But that does not prevent you from including headers It does, they have a hard-coded #error if they're included in a CLI/CLR compilation unit. CLR threads have a M:N mapping to system threads so I can imagine what havoc direct usage of native threads from CLR code could wreak upon the whole runtime. I guess it was too complicated to implement this restriction on a per-class basis in the compiler.
PIMPL is not just about code; the data is always heap allocated. You generally lose cache locality.
I am aware what pimpl is thank you. You're missing the point. What I'm saying is that you don't need to break the **API** if you un-pimpl. We're talking about removing pimpl here. Of course you will lose the benefits.
Why do you have a `HIKE_ASSERT` macro? You just could have called `assert` instead, I don't really see the point of having such a macro.
I hate this stuff so much. Give me native C++ or even C# with pinvoke from a native DLL using C++.
If you want to replace the asserts with exceptions or whatever, you can do it changing the macro content instead of all assert ocurrences.
Sure, but this really seems like a case of YAGNI in my opinion.
I'm sorry, I was having a bad day and got a bit too carried away. &gt;It faults in user mode, but not in kernel mode, which is why the exploits allow for reading from kernel/arbitrary memory. I feel like we're talking past each other. Meltdown: user-mode code reading L1-resident kernel-mode memory. Spectre v1: user-mode code tricking user-mode code into leaking user-mode memory. Spectre v2: user-mode code tricking kernel-mode code into leaking kernel-mode memory. 
I don’t care who started it, but you and /u/philocto need to stop.
I would be interested in this project. I'm currently designing a GRASP heuristic which uses local search; I use best improving local search procedure. Is it possible to add a feasibility check to this library? I guess you could run your feasibility function in the loss function and give infeasible solutions +-Inf score.
You are confused; the branch target buffer is for... branches! Back to the pimpl subject: pimpl is great for ABI stability but I doubt it is typically needed for *every* classes: an interface is typically on *some* classes, then you have internal ones (and also interface but small ones with a more by value semantics, e.g. point with x, y members), and gratuitously pimplifying all classes is not gonna add any advantage. Pimplifying the good ones (and only these ones) will have tremendous advantages. As for cache locality, this must be studied on a case by case basis and there is no general rule that says that not-pimpl is better; pimpl could obviously be better for not very often use stuff if the other members of a embedding class are used way more often.
Some code so we know what you're talking about would be nice.
One interesting idea, which I got from this talk is, to use views as keys into the value types in maps. Thats a neat idea.
Yeah, if for any reason a solution is invalid (e.g. its parameters are out of bounds) the loss function should return +inf to prevent this solution being chosen as a valid candidate.
While this works, it is a lot more finicky, than I would like. I guess, if you are using uint8_t you don't run into aliasing issues (as it should be a char), if you treat it as a bool*. And if you don't return the reference/pointer as bool&amp;/*, you may get a lot of compiler warnings about the runtime behaviour or you could affect overload resolution, etc in ways, you don't want. I think unique_ptr&lt;bool&gt; would still be my preferred solution.
Day to day, no, but for test builds and for releases, yes. We want all the perf we can get. 
Afraid not, no.
How does this compare to BUCK?
I wish these attributes were allowed like vendor pragmas in C++14. I have older OSes where it isn't trivial to get a C++17 compiler going, but have no problem adding [[fallthrough]] so it's there when I'm able to upgrade. 
It is possible to implement a "local" PIMPL, though. https://github.com/sqjk/pimpl_ptr
Yeah, that is cool. I would have used boost::multi_index_container, with a string_view extractor. A std alternative is nice.
Thank you.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7ti4o8/whoever_said_i_will_easily_learn_c_because_i_know/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
My msys2-mingw install now have experimental\filesystem
&gt; You are confused; the branch target buffer is for... branches Fair enough, though the point remains: hardware tends to work to optimize code in use, and since pimpls are just pointers, which are used everywhere, CPU support tends to follow. &gt; gratuitously pimplifying all classes is not gonna add any advantage Sure, but no one is claiming otherwise. Even the projects I gave as examples (Qt and KDE) both will avoid pimpl on classes where the technique is unsuited. All the same, it's much easier from an ABI perspective to do it and not need it than it is to avoid it but need it later. If the interface is stable enough that pimpl wasn't needed after all then you can always de-pimpl it later into an improved version and maintain ABI compat where you want, having to do the opposite is vastly more annoying.
You can! I had the same issue as you and was pleasantly surprised to learn that (at least in GCC) [you can use a fallthrough comment](https://stackoverflow.com/a/45137452). For example GCC 7 will warn about case 2 falling through. However, it recognizes the fallthrough comment after case 1 and won't issue a warning. case 1: // fallthrough case 2: case 3: break;
Very obviously, it is sexist. 
You said it yourself, it’s just a lot easier to simply include a header in your build than it is to worry about compiling and linking against whatever libraries on every platform you intend to support.
I get that header-only is super convenient. But personally, I’d really prefer one primary header and one cpp file for a project rather than 100% .h files. Sometimes it feels like header-only is more popular than that setup only because there is a popular name for it...
Because dependency management in C++ is cancer. 
I like how the [stb libraries](https://github.com/nothings/stb) do it. One file, but with a preprocessor switch to select whether it should be only a header with declarations, or the full source with definitions as well. 
Sometimes, the library in question consists of templates almost exclusively. Some of our libraries fall into this category, the few percent of non-template code doesn't justify all the complexity both for us and our users to create a "real" library, header-only is the canonical way for us.
I think you may have mis-read what I wrote. It is very much a complement, and certainly not an insult. 
&gt; C++17 adds `std::add_const()` Minor typo. It should be `std::as_const()`.
Isn't \r\n is required by http?
Apparently, as a non-native-speaker I am misreading it. Would you mind to explain to me how to read it correctly? Why do I, as an author of a header-only library, give a crap about other programmers? And why would this be a good thing? I am clearly missing something...
Ah! I only knew the expression "doesn't give a crap" and I haven't realized that the opposite "does give a crap" can also be used to express something positive even with such a basically negative word as "crap". I mistook "people who give a crap about me as a programmer" as a short form for "people who do not give a crap about me as a programmer". Thanks!
I am also a non native speaker, and that confused me too since a literal translation to Spanish means exactly the opposite. I had seen "&lt;_subject_&gt; don't/doesn't give a crap" but not "&lt;_subject_&gt; do/does give a cheap" before.
No problem! Second languages are tough!
CVE-2002-0059 way back in 2002. zlib had a double-free that would run arbitrary code, allowing an attacker to take control of your process. Worse, it could be exploited in many hundreds of applications with compressed data such as a PNG file. But people were just copy/pasting zlib code into their applications, so you couldn't tell which apps were vulnerable by looking for a zlib DLL. It was so bad that Microsoft and others released zlib scanners to identify vulnerable executables by checking for the specific assembly instructions.
But that had nothing to do with header-only libraries. Or C++ for that matter.
For the same reason Rust and Haskell statically link everything: it's much easier. You don't have to worry about maintaining ABI stability.
There are several traps with negatives in English. One that I remember tripping up my Chinese roommate at uni was negative questions, e.g.: "So you don't want to go?" - a "no" reply here would mean "don't want to go", i.e. agreement!
because build systems are imperfect and also the modules spec is coming slowly.
The thing is: If I link against the library dynamically, you can fix many bugs and vulnerabilities in an abi compatible manner. That means, all I have to do is to replace the systemwide used all/so and the vulnerability is fixed in all applications. With a header only library I'd have to wait for each program to be updated individually (particularly problematic with closed source programs)
Header only libraries don't really solve that problem though. You still need to make sure you have all the dependencies
&gt; Yet header-only libraries are popular. Why? Because MS Windows does not offer pgk-config by default.
Header-onlyness has nothing to do with this kind of security problem. You can get code which won't update into your project by using static libraries and bundled shared libraries as well. The real evil is bundling (even header only library can and should be used as an external dependency). And proper package management tools are needed which will rebuild/update the package when its dependencies are updated.
Time-waste alert.
Was it recorded by a feature phone camera from 90s?
One thing that hasn't been mentioned yet is if a library is a template library. In that case, there is no other option.
Templates.
Other than Boost, what other header-only libraries are popular? I'm used to working with the STL, Qt and Boost and that usually suffices but I'd like to extend my knowledge.
The point about tests seems a bit a stretch. Many non header-only libraries also lack tests and even if they do have it, but most people won't be running them either when building the library. So in the end that's potentially an issue for all libraries. The bigger one probably being even if you run the tests and they fail, how many will actually take the time to report it?
Slightly curious what module-only libraries would mean. Won't like everything naturally be put in modules anyway, as opposed to headers? I guess I'm missing something.
Module-only library (or, more precisely *module interface*-only) would be a library that consists of just the module interface units with all the implementation crammed into them (as opposed to module implementation units). And module interfaces (unlike headers) can contain non-inline/template function and variable definitions. Recent discussions showed a lot of people can't wait to take advantage of this.
fmtlib, brigand, GSL, rapidjson, websocketpp, etc etc. Also there's a lot of individual generic data structures out there, which are always templated for obvious reasons hence header only.
&gt; With a header only library I'd have to wait for each program to be updated individually (particularly problematic with closed source programs) and as a dev building stuff on linux, too many times I have seen "innocuous" patch releases which entirely broke my stuff. The only way to stay sane as a dev is to ship with exactly all the dependencies that you ran QA with. 
However you don't have to compile them for every target platform, twice if you want a debug version, trice if you note that the debug version is too slow and you need release with debug info instead. 
Slide recording didn't work, and I'm working on upgrading the cameras for this room in this year.
&gt; Compilers have gotten really fast so unless you include them everywhere and use an obscene number of them they don't do much to your compile. I wonder what kind your projects are? Our work project has a few 10k lines of code and often takes 5+ minutes for an incremental build due to borked internal dependencies. Some external dependencies take 30 minutes to compile. I don't see how throwing in a few 10k+ line header only libraries will help me here. &gt; * This entirely eliminates ./configure make make test and make install lunacy. &gt; * You keep your library with your code &gt; * If there are any porting issues they are usually more easily resolved All this can be done with a "regular" library as well. Partly even better so: Having header-only does not magically eliminate the occasional need to configure things. Header-only means you have to apply the configuration at every use. Compiled library means you only apply configuration to the .cpp implementation file that needs it, inside the library, without affecting users. And solving porting issues doesn't magically get easier if you have to wade through tons of ifdefs in each header-only library that brings their own header-only porting layer.
As if this problem was Windows-only. Come on. How about people being stuck on ancient Ubuntu LTS versions (14.04), and even the latest one (16.04) has ancient versions of many packages. Distros like arch are the exceptions but most users are on Ubuntu and stuck with ancient packages in the package manager.
You should consider adding your library to currently fighting c++ package managers like buckaroo, cget, conan, conda, cpm, cppan, hunter, vcpkg and so on :P
Visual Studio tries to be semantic while doing completions or helps with refactoring but if for some reason (your include paths and/or compilation flags are misconfigured) it fails then it falls back to some simple heuristics. From what you described I gather that your project is not configured properly.
Why would you run the tests for a third party library during a build of your own product? There's no need unless you're changing the library code, at which point it becomes part of your project. I've never seen anyone do this, thankfully. 
&gt; Recent discussions showed a lot of people can't wait to take "advantage" of this. I'm curious as to your use of "scare quotes" here, as it reads as if you think this is a bad idea. In a module-enabled world, what would be the disadvantage of putting (non-inline) implementation code in the same file as the interface? Why would an interface/implementation split (as we have now with headers) remain desirable? 
So many competing package managers. Someone should create a single one that meets everyone's use cases.
With a traditional library, I need to see what build system is being used, whether it is composable with my build system, either call their build system or recreate their build in my build system if not, including figuring out which source files are compiled on every platform I care about and whether there are any special preprocessor macros that need to be defined for each. Then I need to repeat the process every time a new version comes out. With a header only library, I can try it out by downloading the library and adding a new include directive. 
lol
I might be mistaking but I think the only processor that can speculate on data pointers is the Alpha. The others can not do it because of their memory model (they could do it, but they would have to *reload* the target -- or at least ensure it has not been modified -- after the pointer has been loaded and checked, rendering any gain too small or even completely eliminating them). And given the C++ memory model is now what everybody has in mind, and that it seems hard to specify a useful data dependency model in high level languages (see the consume fiasco), I predict that no new CPU will speculate on data pointer (except maybe in very special purpose and niche markets)
You should totally try [zapcc](https://www.zapcc.com). IME it can help long build times quite a bit.
https://github.com/nothings/single_file_libs
For me cmake has fixed the build toolchain. It's pretty easy to use cmake projects from github as packages in your c++ projects. It requires a little more work than say npm or nuget but it gets the job done. 
Security is the wrong answer. Convenience is probably the right one, but it's mostly an illusion. At some point any non-trivial c++ project will have to deal with dependencies one way or another, and from that point header only is a liability for anyone valuing productivity and fast build times. I keep reading how c++ compilers got faster, but even if that's true, it doesn't really seem to translate to real world experience. Is it really necessary to compile that 17000 json parser header over and over in all of my modules that touch json? I also keep reading how authors of header only libraries value my time, but I only need to set dependencies once, but I'm doing rebuilds over and over again. I'm really wondering what kind of project people advocating header-only work on. Even for smallish (~100000 loc) project keeping headers reasonably minimal can make significant difference. Big project like chromium and webkit are frugal about what goes into headers and also use templates sparsely and pragmatically, whereas most header only seem to use templates for pretty much everything. I guess when you have a hammer...
I have never heard anyone complaining about including sqlite in a project. Instead of adding one header file, you add one header file and one source file. Is it really that much more inconvenient? (granted, most c++ dependencies don't come amalgamated, but that was not my point)
Abi compatibility in c++ is extremely tricky beast and requires lot of discipline. And deploying c++ project that depends on c++ libraries built on someone else, well, I personally would stay as far from that as possible, especially if I had to support that.
Header only libraries with git dependencies and CMake makefiles solve the problem for me.
Use [`std::unique_ptr`](http://en.cppreference.com/w/cpp/memory/unique_ptr) instead of raw owning pointers and [`std::make_unique`](http://en.cppreference.com/w/cpp/memory/unique_ptr/make_unique) instead of `new`. That change alone will already substantially increase the quality and correctness of your code.
Oh man, the list keeps growing. 
Yes I agree. When it's just a few source files anyway, what practical advantages does header only libraries really provide?
/r/cpp_questions
&gt; they could do it, but they would have to reload the target -- or at least ensure it has not been modified -- after the pointer has been loaded and checked, rendering any gain too small or even completely eliminating them It's precisely because of the checks required that a CPU would want to issue the load once the address is known, and then spend a wee bit of time (in CPU terms) validating that the address had not changed in the meantime once the load has finally completed. The speed differences between CPU ops and memory ops are so stark that it's much more efficient to issue memory requests as soon as they can reasonably be issued and accept some added work on the CPU end. &gt; note that you don't have this problem on code, because on modern processors the code is not supposed to change dynamically without taking special purpose precautions and explicit soft/hard synchro The data *is* supposed to change dynamically though, which CPUs support as a result. The encoding and special precautions needed to access changing data are inherent in the ISA design. With pImpl there are not changes happening all the time anyways, so even though there is an indirection, it's a predictable one. &gt; Edit: also now that we are in a post Meltdown/Spectre world, implementing speculation on data pointer would have to be done without opening blatant new security holes everywhere, so that's one more reason I think this will not happen. Now this is a very fair point! ;) I think we're in wide agreement at least; the way I'd phrase it is that this is one more reason why I think we'll *reduce* performing speculative indirect loads as often as we already do. It's not just Alpha, it's one of the ways a Spectre variant managed to leak data. E.g. [see this page](https://github.com/marcan/speculation-bugs/blob/master/README.md#common-attack-characteristics) and search for 'indirect load'. This [book on superscalar architectures](https://books.google.com/books?id=EgMZEqnvLzsC&amp;lpg=PA364&amp;ots=HFYA5Iwj3A&amp;dq=cpu%20architecture%20speculative%20indirect%20load&amp;pg=PA108#v=onepage&amp;q=cpu%20architecture%20speculative%20indirect%20load&amp;f=false) also indicates that load speculation (including load speculation) is not limited to Alpha. But I don't think we'll get rid of the optimization. It's a huge performance hit for structured software (e.g. all the C code that masks generic code through `void*` pointers) so I don't think we'll eliminate optimization for indirect loads, but rather find ways to have the user code request safer loads in situations where an attacker could influence the result in a way that would result in a Spectre vulnerability.
You still have to design your library to be amalgamated. The post above yours mentions all the things you have to do in order to incorporate a foreign library into your project, where it wasn't designed to be distributed this way. Many projects selectively compile files based on the platform, or generate a config header for the platform. These things prevent easy drop-in deployment. So I personally think the sqlite approach is fine, but I haven't really seen other C++ libraries designed to be distributed this way. 
&gt; Why would you run the tests for a third party library during a build of your own product? Because you want to make sure the library you are depending on is functioning correctly in the exact same build configuration as what you are using for your project.
You're making a very odd claim here: that you're more secure if you use a header-only library. Many people also link against things statically because it's simply easier than having to distribute 35 dlls or shared libraries, or there are compatibility issues, etc etc. So you're using a logical fallacy to say that header-only libraries lead to security issues because they'll never be updated when the same would also be true for projects that link against static libraries. And having distributed multiple projects, I can tell you in the case of many programs it's much easier to do so. The same would be true for projects that just fold in an entire project and include multiple source files, that still wouldn't be updated as easily. The bonus here to header-only libraries is that you don't have to replace large projects and their build systems, you just replace the headers when updates come out. Working from your claims, this would mean that header-only libraries are more likely to be updated as you only have to drop in a single header to update and make sure that it works. There is no security issue here. The issue with zlib is people copypasting code, and has nothing to do with the build system, libraries or methods people use to include this into their projects.
I think this is as close to dependency management as we will get. I love the concept of just adding a cmake project to my git project as a submodule, then just including a line that lets the project's cmake do whatever the hell it wants to as long as in the end it spits out the .lib that I want and care about. It's beautiful and also allows me to lock a specific branch or just keep updated as the external projects update.
&gt; If I link against the library dynamically, you can fix many bugs and vulnerabilities in an abi compatible manner. It's actually not straightforward to do this in C++ in an [ABI-compatible way](https://community.kde.org/Policies/Binary_Compatibility_Issues_With_C%2B%2B).
You also have to design your library to be header only. I don't quite see how having to design library to be header only differs from designing library to be amalgamated.
&gt; Is it really that much more inconvenient? yes
I cant help being curious - what kind of projects are you working on where not having to add one file to build is considered advantage.
You're hiding your root pointer. When inserting into an empty tree, you're creating a different pointer named root, and setting it up. You're not actually setting the Tree.root pointer. Just remove "Node *" from the line after the comment to fix that bug.
Really? Can you be more specific? What kind of build system are you using? Short of the project being one c++ file compiled by hand I'm having rather hard time imagine how adding one extra source file can be that much more inconvenient?
I use CMake and as far as possible I only look for libraries that I can clone as git submodules and add to my include path ; ideally I'd just clone them (and a good three times out of five, if the git repo has a standard structure with an `include/` folder, this is possible).
Unpopular opinion ahead: I never understood why dependency/package management has anything to do with this or that language. Virtually everything linux distribution has solved this in a language-agnostic way. In my workflow I use pacman (either on linux, or msys2) for pretty much everything. The rare cases where a dependency is not available on upstream, cmake `ExternaProject_add` goes a long way, especially if the package I want to import is kind enough to be cmake-compatible. OTOH, every language with a builtin package manager (perl, python, etc.) ends up messing badly with the system package manager, causing endless headache - not to mention the security issues about importing random non-signed stuff from the internet.
Still waiting for structured bindings
You mention one of the best package managers, which mostly rolling-release distros use. Talk about Ubuntu package manager now, which contains ancient packages, particularly on LTS versions like 16.04 or 14.04, which unfortunately many people have to make their software work on. Even if you can drop 14.04, packages on 16.04 are still ancient. So the package manager there doesn't help and is bullshit.
I’ll tell you that much more security issues come from the dependency lock in that happens at the distro later. You end up using ancient versions of software with bugs and security issues, since you have thousands of packages that have to be forward upgraded incrementally. So many serious bugs end up being back ported in shoddy patches by people unfamiliar with the code base or unfamiliar with programming all together. Sounds like a recipe for failure, yea? Since we are buying m2s and SSDs with terabytes of storage I think the days of distros creating their own busy work needs to end. Static self contained binaries built from the source repositories, distros should work with the engineers writing the software for stable builds on their platform with all dependencies locked in. Now that you decoupled everything you have the ability for the lastest software and bug fixes for every package and removed shoddy back porting. The only thing downside is when a top level member of the dependency graph gets a CVE you can’t fix it and get every single package updated for free. But this would happen much less in practice since many cve are locked into version ranges, usually old. So all software bundles on the system won’t always be affected, but static code analysis can help determine when they are. I have more thorough posts on this, but really I find your thoughts here far from reality.
Just for my understanding, are the following statements correct? 1. When you pass a memory barrier, _all_ writes before the barrier are committed - not only those that are marked 'atomic'. 2. Passing a memory barrier potentially requires synchronisation of different CPU caches, and is therefore potentially extremely expensive. 3. x86 is not one of those architectures, since it synchronises caches on the fly. 
Because if it is in a header you don’t have to worry about code coverage testing. 
Thanks for the explanation. But you're using cmake, so you have a build system in place, and thus I'm still very hazy on what exactly is the big deal when adding ../my-dependencies/some-library/amalgamated.cpp line in your project's add_executable statement (for example). It's one line and it will build the file with same compiler flags as the rest of your project. What's so much more inconvenient here?
&gt; What's so much more inconvenient here? I get paid in mental sanity for every character that I can spare to type
please, the same gradle which there is no way to force it to only use a locally installed version instead of downloading another version from the internet and says this is a "feature"? No thank you, no way I am touching something like this. Look, not all people are always on WiFi. I am sometimes connected via my phone and it is capped connection. So I am literally paying $5 when gradle downloads 50 MB. And the thing is there is no way to tell your tool "don't do that" Remember tools should be designed for people. My answer: No thank you. I've had enough gradle when I was doing android-&gt;jni-&gt;ndk development. I am not touching it in any circumstance.
Often I see other developers saying it is because you don't have to build them. I work on multiple platform projects which use IDEs and command line building. The libraries should support XCode, Visual Studio, cmake, make, ndk and others. It is super-rare that all of our requirements are met anyway so what we do is integrate the libraries into our builds and tool-chains we use. It is extra work, sure, but if the library saves us hunders of hours of development a few hours making everything "just perfect" is easily worth the hassle. The downside is upgrades; if you submodule you have to be ready to step in and fix breakage at any moment or do manual upgrades with testing and merging. Either way it's extra work. The easiest path is to submodule and somehow magically integrate every library's build system into your build scripts. That's great when you can do it. The single-header libraries sidestep this problem completely because they don't have any of that. :) From the point of view I described above it is non-issue. This is why the preference is to libraries that do one thing really well and have finite scope of how many things they try to solve simultaneously. It's the framework these libraries are "external / third-party" for that is the one that would be unacceptable as external library itself - the library / framework _we_ use internally (The Uber Library That Does Everything We Ever Wanted And Builds Everywhere). (I love the Uber Library, of course. ;) 
If adding one source file to your build impacts your mental sanity then c++ does seem like an odd choice of language.
Can't access the article (403).
Traditional libraries are a lot more palatable when they're written in Standard C or Standard C++ and you can just add the source files to your project with no palaver. 
This is a composite key, not two different keys.
&gt; don't really solve that problem though. They actually do for simple programs when the only dependency you need is the specific version of the header. You add it to your project and get on with life.
&gt; Is it really necessary to compile that 17000 json parser header over and over in all of my modules that touch json? Precompiled headers. 
xor as a hash combination function is very poor: * `hash({a, b}) == hash({b, a})` * `hash({a, a}) == hash({b, b}) == 0` You need to shift/rotate one of the hashes before xoring. See [this StackOverflow answer](https://stackoverflow.com/a/27952689)
&gt; 1. Define specialization for std::hash struct pair_hash Uh...
&gt; 1. Define specialization for std::hash &gt; &gt; struct pair_hash Um...
Yes. And you could ask the same question for static asserts or templates. But, how do you cross compile? 
Simple answer: yes, they are evaluated as if on the target.
Guaranteed by what? The standard doesn't mention anything about cross-compilation. sizeof(int) is always constexpr, even used in a non constexpr function. The compiler knows what target you're compiling for, so sizeof(int) will be the int size on the target.
My advice is to do two of these things: 1) Stop reading Prata's 'C++ Primer Plus'; it's widely acknowledged to be a terrible book. Instead, acquire and read 'C++ Primer' by Lippman, Lajoie and Moo -- a much, much better learning resource. 2) Stop learning C and focus on modern C++. You don't need C anymore today, even for embedded programming. (https://youtu.be/D7Sd8A6_fYU)
Well, sure, question is, how many of those template heave header-only libraries actually have to be template heavy. A math library? Sure. Container or algorithm library? Sure. But asynchronous networking? Why? Does socket really has to be a template class? Does overhead of a virtual method call really warrant near impossible to debug template code with long compiling times and incomprehensible error messages just so that we can say it's "modern c++" code with abstractions resolved at compile time? I think this is pushing it way further than the language is prepared to comfortably handle, and anyone who ever tried and failed miserably debugging heavily templated code will probably agree. And I'm fine with this for code that absolutely has to be generic, or is extremely performance sensitive, but say networking abstraction is hardly any of those.
sizeof(int) is chosen by the compiler, not the machine the code is running on. But the compiler chooses sizeof(int) based on the platform it's compiling code for. So yes, the compiler guarantees that it will use the same sizeof(int) for both runtime and compile time expressions
Also the fact that in any class ive ever written, there ends up being some code written inline in the class, whether because it's a one-line getter/setter, or because it's a template function etc. Having your actual code (and not just interface vs implementation) split between 2 places really sucks.
Networking code is frequently critical to performance. Any overhead a library imposes is lost work. 
I just do it once, because as I said, you won't alter the library. This happens outside the main build process because trying to integrate disparate build systems supplied by the libraries would be a nightmare, or mean writing my own cmake build for those projects (in some cases). If a build system runs the libraries' tests every time you build, I think there's a problem there. 
Ah, the old "I know your code better than you do" reply. Trust me, I want as little overhead from network code as possible. It's never going to be zero. The comparison you're making between templates and virtual functions is a false dichotomy. I use both in different situations, despite choosing each for performance reasons. 
Expressions like `sizeof(int)` are evaluated during compiletime anyway and would pretty useless if the compiler wouldn't return the correct answer for the target platform. What I'm not 100% sure of is if computations are guaranteed to behave the same. E.g., can you add two `INT_MAX` if the target platform has 16bit ints and the host 32bit. For floating point computations the standard IIRC makes explicit allowances for differences between compile and runtime (Irrespective of cross- or normal compilation).
I never claimed to know your code. My claim was about system network stacks, asynchronous IO and syscalls in general introducing enough overhead to render few indirect method calls in network abstraction (i.e. asio) highly irrelevant. And what false dichotomy? One of the excuse for template heavy header only frameworks such as asio commonly given is that with templates some of the abstractions get resolved at compile time reducing the need for virtual calls. And that's a valid point of course - my concern is whether the performance improvements (possibly negligible concerning the overhead of the rest of network stack) outweigh the lost of productivity (i.e. much longer build times, impaired debugging, etc). For my use cases, they don't. Apparently not everyone has same use cases as me. Fair enough.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7tkt4m/implementing_a_bst_with_c/dtdtnhh/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It's a false dichotomy because it's not as simple as a design choosing between a template and a virtual function. They are not just different approaches to doing the same thing. As such, "because virtual functions have overhead" is never the only reason for any given design. Any real world piece of code of significant complexity is likely to use both techniques. Then, whether the library is header only is a choice made for other reasons. 
&gt; can you add two INT_MAX if the target platform has 16bit ints and the host 32bit. For integers, the host platform is irrelevant, just like for ordinary code. Only the target platform matters. For floating-point, see [N4713](https://wg21.link/n4713) 8.6 [expr.const]/7 and footnote 89. 
I really don't feel like I want to get dragged into discussion about compile time/static polymorphism vs runtime polymorphism. Of course they are not the same. Of course they are not interchangeable. But the preference of one or the other can clearly be seen in design decision made when building a framework. As is quite obvious in asio. And my concern is that C++ is lately pushed quite heavily towards compile time polymorphism, at the sacrifice of productivity. And to be honest, when looking some of the heavy templated header only libraries the other reason other than performance excuse I can think of is that when having a hammer, everything looks like a nail.
What you call a preference is less likely to be a bias, more likely to be a genuine good reason which you just don't know or can't see. To go back to the original point, whether a particular function or class in a asio "needs" to be a template is a question with a real answer - not one which just because you don't have the answer means that it is a bad choice, regardless of the perceived trade offs. 
But the perceived tradeoffs are real. The compilation times are real. Not being able to debug the code is real. Incomprehensible error messages are real. I have friends working for software companies that either have ban on using pretty much anything boost related for new projects or just simply refrain from doing so based on past experiences. All the drawbacks I mentioned are real and tangible. I can measure compile times, I can see breakpoints not working, I can see not being able to step over a function, etc. What exactly are benefits then?
To use a library you have to include a header anyway. A header only library eliminates steps. Those steps all have classes of errors that can be associated with them. They are just simpler to use.
If people use those old versions they mostly do so to avoid most of the new packages. While I use Arch with pacman on my main-machine, I have Debian (!) Stable (!!) on another laptop and the story is pretty much the same there: Make sure that you are not using overly obscure packages and you can develop very easily.
I see where you're coming from, but literally every other mainstream language I can think of (other than C) has interface declarations and definitions together in the same file and people cope with it just fine. I don't see why module-enabled C++ would be any different in this regard?
&gt; Plus there is devirtualization A lot of people throw that around, without realizing how incredibly limited devirtualization actually is in practice. You're not very likely to actually see it unless either `final` is involved (which it's not here; the library is defining an interface so that things can be overriden and final would defeat the whole purpose), or all of the library code between the creation of the derived object (in user code) and calls to the interface (in library code) get inlined (unlikely as this is usually a lot of code). Also, the big cost is not usually direct vs indirect. The big costs are usually a) when you can't inline a small function because it's virtual, you lose many optimizations that don't really work well across function boundaries: const propagation, common subexpression elimination, etc. And b) having to store something by pointer as opposed to inline. What makes things hard for library writers is that what you are saying is totally reasonable, and probably applies to most would be end users. But there are probably some for whom it doesn't apply. Some libraries may choose a narrower scope, but all other things being equal a higher quality library will try to target the broadest possible set of use cases. Also, keep in mind: code built with compile time polymoprhism can always back to runtime, but not vice versa. It involves some boilerplate but with extern template and a wrapper class you can basically recover most of the downsides you're discussing. The reverse is impossible: if the library uses runtime polymoprhism you can never recover the advantages of compile time polymoprhism.
found a YOLO programmer who doesn't do software dev for a living
I feel like this could be fixed by tooling/IDEs. I think it would be relatively easy to make an "interface view" of a module interface, that simply hide implementation. I bit like the ability of hiding scope, but enabled by default for function implementation. Heck, this could even by as simple as an option "folding implementation scopes by default" or even "folding implementation scope by default for external code".
For most libraries that you'll ever link to, even a 5 year old version should be plenty new enough.
&gt;Talk about Ubuntu package manager now, which contains ancient packages, The freshness of the packages in the repo have very little to do with the manager itself... You can use dpkg and apt to build something entirely unrelated to Debian/Ubuntu. 
Well at least you don't have all your classes with dedicated pure virtual base classes because reasons...
visa sponsership ?
Oh, OK. So why not just use an appended string, which will turn out to be exactly the same thing as your composite key example. But no, go ahead down vote me for asking why something is made more complex than it needs to be. Your blog post doesn't give an example for why you would want to use pair&lt;&gt; as a key for unordered_map, it just shows how you might do it, in STL and Boost.
An appended string is different from a composite key. Consider {“hello”, “world”} and {“h”, “elloworld”}. Or types which cannot be converted to string.
Yeah you'd normally elaborate slightly when answering, e.g. "no I don't". You're still "agreeing" with a "no", but it's now clear. You can also disagree with "no" as normal - "no, I _do_ want to go" - but that takes emphasis to make it fully understood.
I disagree, networking is more often than not I/O-bound. Any overhead a library imposes is hardly significant.
Obvious? Sure, for say generic container the benefits of templates are obvious and greatly outweigh the tradeoffs. Same goes for generic algorithms, SSE/AVX abstractions, chainable promises, smart pointers, and so on. But for socket abstraction? Well, I don't quite see it, and you avoiding answering my question sort of confirms it.
'cause ain't nobody got time for linkin' stinkin' problems
Devirtualization was hardly the crux of my comment :) Although with LTO and whole program devirtualization I'd expect devirtualization to become more common even for non final virtual method. I agree with most of your comment, I just don't see how it applies to socket abstraction (which my original comment was about). Do you really need your socket read to be inlined? What difference does it make compared to the rest of network stack machinery?
Thanks for the tip, will check it out.
&gt; I personally strive to keep my interfaces as concise and readable as possible since they are the ultimate documentation. Having interface declarations intermixed with implementation details will certainly subtract from readability. I really don't see the problem in this. For instance every C# IDE is able to show only the interface of a class or module for a quick skim. Why do manually what a computer can do for us ? 
&gt; I wonder what kind your projects are? Our work project has a few 10k lines of code and often takes 5+ minutes for an incremental build due to borked internal dependencies. wow, yuck. A project I work on is currently sitting at 292kloc with many of it being templates and header only (+ heaaavy usage of boost), but an incremental rebuild that modifies a single file is less than a few seconds ; the whole project builds from scratch in less than ten minutes.
A good system should only runs the tests for code that was updated (directly or through compiler / option changes). So it's irrelevant to consider whether you should run the 3rd party library's tests as they would be rerun automatically whenever it should do so.
I don't know about anyone's else's experience, but I work at a large company that ships a number of programming environments and SDKs, and we most certainly test important 3rd party software that uses our products to make sure we don't break stuff.
&gt; Well, sure, question is, how many of those template heave header-only libraries actually have to be template heavy. They have to be template-heavy if this leads to a better design.
That’s a really awesome write up. I want to make a package for teapot so that coverage is generated automatically.
**Company:** [The Document Foundation](http://documentfoundation.org/) **Type:** Full or part time and a one-off gig **Description:** The Document Foundation is the custodian for LibreOffice, the cross-platform FOSS office suite. TDF is currently looking for [a development mentor or several](https://blog.documentfoundation.org/blog/2018/01/25/extended-job-search-development-mentor-201711-01/) for a long term contract and someone [to provide consultancy on implementing features in LibreOffice](https://blog.documentfoundation.org/blog/2018/01/16/tender-consultancy-libreoffice-feature-implementation-incl-site-development-training-201801-01/) during a hackfest in Hamburg (April 7-8, 2018). The deadline of applications for the dev mentor position is February 16, 2018. For the consultancy gig the deadline is February 5, 2018. **Location:** Remote with occasional conference/hackfest travel **Technologies:** C++11 is used. Use of C++14 is limited by [the current baseline](https://cgit.freedesktop.org/libreoffice/core/tree/README.md#n30). Code is being updated to conform with C++17 removals and deprecations. Other languages include Python and, in the build system, bash &amp; Perl scripts. **Contact:** floeff@documentfoundation.org
&gt; can you add two INT_MAX if the target platform has 16bit ints and the host 32bit. `INT_MAX` would also be constexpr for the tagret platform
The more interesting question is how compile-time code execution works when cross-compiling. Things like `sizeof(type)` were compile-time expressions even before `constexpr` existed. But now, this allows code execution at compilation time. How do things like differences in endianness and word size affect cross compilation?
Well, end-users aren't really the problem here. As I see it, developers on every other system can just compile and "make install" the needed dependencies if need be. Then I get on with my life and can keep coding. Except on Windows.
Anyone have a way to get coverage metrics for templated code?
I always have mixed feeling when I'm reminded how one of the things that made C++ so successful (C compatibility) is also one of the things that hold it back from being a better language.
How does this play with libraries that may also be present on the system? I use a couple of header-only libraries, but I also use Ceres and ITK. I'd like to give the user the option of using an existing compiled/installed version if present on their system (and it reaches a minimum required version).
Yes, but my question was in regard to the fact that there must not be signed integer overflow (aka UB) in constexpr expressions. If the compiler uses 32 bit for integer, then adding two (16bit) INT_MAX would not be an overflow. But yeah, that wouldn't make really sense - as confirmed by STL.
&gt; If the compiler uses 32 bit for integer, then adding two (16bit) INT_MAX would not be an overflow The compiler must use the same width integers for any same type for the given platform. So using 32 bit ints to add 2 16 bit `INT_MAX` should never happen
This would be a solution if they could manage multiple versions of a single package and function without admin permissions. Unfortunately apt does neither (which I use at home), and the package manager for RHEL (which all my shared computing resources use) is so laughably behind that it's not useful. I recently wanted to get a package that requires libclang. RHEL does not have clang.
I just started a compiler design course, so I'll definitely watch this. One comment based on the first few minutes: wouldn't it be easier to just write an assembler for your target architecture taking GCC or LLVM's IR code as input, rather than write a whole compiler?
As far as I know, neither GCC's nor LLVM's IR is well adaptable to 16-bit or 8-bit platforms, except through simulating 32-bit operations through a heap of 8-bit operations. Also that would kind of defy the point of the exercise wouldn’t it.
I've never personally used it in combination with find_package (or something like that). You might run stage issues. Worth trying out though.
Thanks for the comment, I'm still in the process of learning all this architecture stuff. &gt; Also that would kind of defy the point of the exercise wouldn’t it. I didn't mean to imply that doing something the hard way was a bad idea! Doing things the hard way can be a great learning experience, which is why I am taking a compiler design course even though there are already compilers for the language we will be building for.
I have no opinion on if C libraries can be used to construct or provide memory for a type X. That looks like something writers of a particular compiler and C/C++ library interface would have to speak on, either by documenting it or by practice. 
So, the OP can be learning something useful from it. Namely, that when objects come into being is extremely fraught in C++. There are certain things you *can* do in a C++ program to make your objects come into being correctly. There are many ways that many C++ programs assume you can bring objects into being. And there are many ways that almost every C++ program on the planet relies on bringing objects into being that the C++ standard does not mandate actually brings an object into being. When writing your own code that is doing something fancier than `new T` or creates an automatic/local/member instance of `T`, you should be aware of this problem. And unless you *think* about this problem and the degree to which it interacts with the assumptions most programs have about object lifetime, you won't understand exactly how dangerous this problem is. While interacting with C libraries is common, many of the other ways to presume an object exists without brining it into existence are relatively rare. So while we shouldn't expect future compilers to break just because you invoked a C library that created an object in the C style, assuming the same for some niche C++ code you just wrote is not a good plan. Questions like this is how you can learn the difference between "yes, the standard under specifies this, but you have to do it" and "the standard under specifies this, stay far away from it, there are alternatives". If you just blindly do what works, you'll end up with code that (usually) works now; but it might not work in 5, 10 or 15 years. Understanding what the standard says *and* understanding common practice *both* is required in order to both hedge against increasing standard compliance in compilers, and changing of the standard to permit standard practice. 
Is there a non-video version?
you can get the audio only version with youtube-dl! ;-) To this point, there is no written format release. If you want to check up new releases or send question, you can contact the author via his [web site](https://bisqwit.iki.fi/) or here on [reddit](https://www.reddit.com/user/Bisqwit) 
Haven't finished reading yet but this blog post is fun to read and has so much information in there! Really nice. My favorite sentence so far: &gt; Maybe life would have been different if we could virtualize OSX. It's really incredible how Apple can still get away with this. And it's really a shame the latest Xcode/AppleClang (and macOS's C++ standard library) always lag so much behind in terms of C++14/17 support :-( The latest Xcode still does not have a conforming `&lt;optional&gt;`, and no `&lt;variant&gt;` :-(
The article you linked says this under the "The Do's and Don'ts" section: &gt;You can... &gt; &gt;append new enumerators to an existing enum. &gt; &gt;* Exception: if that leads to the compiler choosing a larger underlying type for the enum, that makes the change binary-incompatible. Unfortunately, compilers have some leeway to choose the underlying type, **so from an API-design perspective it's recommended to add a Max.... enumerator with an explicit large value (=255, =1&lt;&lt;15, etc)** to create an interval of numeric enumerator values that is guaranteed to fit into the chosen underlying type, whatever that may be. What does that mean? How would one do that? Could this be prevented from explicitly stating the type of the enum? For example: // enum that takes 16 bits: enum smallenum: int16_t { a, b, c };
The source code is in the git repository, linked in the video description. The video is also subtitled and you can read the transcript without playing the video.
I believe that that sentence means that the programmer should do something like this: enum e { a, b, c, E_MAX = a &lt;&lt; 15 }; I think explicitly specifying the type of the enum would eliminate the need for that, but that was added in C++11, so it may not be possible for the maintainers to use that (yet).
So... English has three versions: a) To not give a crap about something -&gt; Don't care about something, negative b) To give a crap about something -&gt; To care about something, positive c) To give crap to someone -&gt; Yell at someone, negative And in my native language we do not say a), we say b) to mean a). No wonder I find this confusing, but having some experience with OpenSSL: It's still less confusing than OpenSSL. :)
not really - some of those are already dead
How to defeat the purpose of: Two factor authentication.
Who said that you should use this for security heavy environments like a work environment? I'm saying that this a c++ exercise implementing an interesting not do difficult RFC for the purpose of learning. :-) How you use it is up to you. 
I was about to ask the same question. How to test the coverage of the multiple paths of `enable_if`s there can be in a heavily templated library? 
!remove
OP, A human moderator (u/STL) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7ttyxw/a_totp_token_generator_cli_tool/dtfappx/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Care to explain why? 
I've been trying your VNS implementation to train a neural network. It was easy to do, because I also implemented ANN-training using a GA (I also implemented Levenberg-Marquardt), applying Gaussian noise to the weights vector. The GA gets stuck at an average solution (the biggest problem with the GA approach), the VNS seems to be able to leap out of local minima (of which there are many). Just to be clear, I only used your public interfaces, and obviously un-modified... What I observe is that the loss function at some point stops going down, and jumps back up to a higher value. At this point (after the loss jumped back up), the algo seems to alternate between a few states only. This seems to be a bug. The good: gets out of local minima. The bad: slow, and then the above problem (loss jumping back up). I'm still very interested in looking further into this, because combining the two methods might be a winner. A rough approach with GA, and then vns, to try and overcome local minima! The problem with your example is that it doesn't have many (if any) local minima, so it doesn't test what's important...
1. Depends on the barrier. A release barrier means "before means before", so things, ie writes, that are before the barrier, will actually happen before the barrier. (An acquire barrier means "after means after"). Reads and writes can float into a critical section from above or below, but they can't escape. 2. Caches should never be mentioned. It is the order of memory operations, not caching. You can think of caching as being part of the problem, but most architectures (not just x86) have cache coherency. You could still need barriers on systems without caches. 3. x86 has cache coherency, but it might reorder things in its read/write buffers (before the cache) or look into its write buffer in order to do a read (bypass cache and memory) or do many other things. But yes, for the most part, x86 is one of the more "forgiving" systems, where most operations are stronger than necessary. Which is why double-checked locking wasn't noticed as broken for so long.
i agree 100%
&gt; What does that mean? How would one do that? By doing something like enum Foo { Bar = 0, Baz = 1, // ... MAX_VAL = 65535 }; In this fashion you will force `Foo` to have at least 2 bytes of storage. For future expansion you would add new values in between whatever the last used value was, and `MAX_VAL`. &gt; Could this problem be prevented by explicitly stating the type of the enum? Yes, though I am uncertain if every compiler supported by KDE has that bit of C++11 support yet (believe it or not we don't yet require that across the board!). There are other bits of advice that are ancient though so it may just be that we need to update the Wiki to be more current.
&gt; BaseArray(CountType size); explicit. It may be slightly more efficient to place m_Data first, as our std::vector implementation does. (That pointer is accessed more often than the size and capacity; I believe that the generated assembly is more efficient when you don't need to add an offset to access a data member.) &gt; Here’s an example of what a vanilla version of Reallocate() would look like: This doesn't contain geometric reallocation logic, so it expects all callers to perform that work, or you'll get quadratic complexity. (In the STL, only vector::reserve() works like this; every other reallocation codepath is geometric.) Your placement news don't tolerate overloaded operator&amp;(), nor do they tolerate overloaded operator new. The syntax `::new (void_ptr) Type(args)` must be used (with a `void *`) to select True Placement New, otherwise you can be hijacked by an overloaded operator new at global scope (taking some `T *`) or a class-specific operator new. &gt; We can use SFINAE Tag dispatch is somewhat nicer than two-way SFINAE for internal helpers like this (because tag dispatch doesn't need to repeat the condition in a negated form). C++17 `if constexpr` is ideal (especially for throughput). `is_pod` is deprecated. There's an STL algorithm that already does this for you (`uninitialized_move`), since you aren't going through STL allocator construct(). &gt; Your compiler will complain that you can’t actually create copies of unique_ptr. That shouldn't happen (especially without the STL's move_if_noexcept logic). In ordinary terminology, member functions of a class template have their declarations instantiated immediately (when the class template is instantiated), but their definitions are instantiated only when they're called. The best example is `list&lt;T&gt;::sort()`, where `list&lt;T&gt;` doesn't require T to be comparable via `operator&lt;()` unless and until `list&lt;T&gt;::sort()` is actually called. Something in your code must be aggressively trying to copy elements, if you're seeing such behavior. I can't say for certain without seeing a repro. (vector itself doesn't have constrained copy/move constructors due to a nightmare in the Standard involving incomplete element types.) &gt; An advantage to this approach is that InplaceArray is an Array, which means we can pass it to any method that expects a parameter of type Array transparently. This seems like it risks slicing, and in particular creating a lifetime problem as m_FixedBuffer is a data member of the derived class. Can't say for sure without seeing all the code (I would particularly suspect move construction; you can transfer pointers for dynamically allocated memory, but not for a local buffer like this).
What to use instead of is_pod?
If templates need to be instantiated then it has to be header only anyhow (barring rare cases where you can write out all the instantiations yourself). In most real life code (which doesn't have ultra granular headers), the vast majority of code in headers isn't actually used by a particular TU. So even though it sounds like instantiating templates and generating assembly is more time consuming than parsing (which it may well be), parsing actually takes a huge amount of the time. Certainly in debug builds, I'm pretty confident that the vast majority of the time is actually spent parsing. YouCompleteMe actually creates a pch on the fly of all of your headers to speed up auto completion and error checking. Some of my terminal project files (i.e. files with main that include a lot of stuff) are 300K lines after preprocessing. They take 10-20 seconds to run through the frontend. Responsiveness of YCM after creating a pch? It's able to reparse my code in &lt; 1 second.
At first, I was doubting, I saw countless video or articles on building compilers that was just about importing some modules in python, then I saw it was from u/Bisqwit. Oh dear, never I had clicked so fast ! After a first look, it is indeed a great video, well explained, not to much that you would be overwelmed with infos, but enough so that you understand what's going on behind the scene ! Great "tutorial", I recommend it to anyone wishing to start building a prog. lang. of some sort ! :D
Theory is the same since a while though isn't it?
&gt;explicit. Yep definitely (it is in the github source, but somewhere being translated twice it got lost in the post itself). &gt;It may be slightly more efficient to place m_Data first, as our std::vector implementation does. (That pointer is accessed more often than the size and capacity; I believe that the generated assembly is more efficient when you don't need to add an offset to access a data member.) Yep it's placed first in the actual code (again the rewrite for formatting) &gt;This doesn't contain geometric reallocation logic, so it expects all callers to perform that work, or you'll get quadratic complexity. (In the STL, only vector::reserve() works like this; every other reallocation codepath is geometric.) Yeah there's explicitly no geometric allocation logic! It's actually one of the downsides to the standard library I feel. It's definitely the best general case solution but in situations where memory is at a premium it may be quite undesirable. This example is a proof of concept but in this case I think it's fairly common for custom array implementations to avoid allocation heuristics entirely. &gt;Your placement news don't tolerate overloaded operator&amp;(), nor do they tolerate overloaded operator new. The syntax ::new (void_ptr) Type(args) must be used (with a void *) to select True Placement New, otherwise you can be hijacked by an overloaded operator new at global scope (taking some T *) or a class-specific operator new. Yes definitely correct worth updating on both counts (addressof &amp; void* cast). &gt;is_pod is deprecated. Well not yet in practice but you're right it's probably not a great idea to use at all. &gt;There's an STL algorithm that already does this for you (uninitialized_move), since you aren't going through STL allocator construct(). I didn't know about it, are there any advantages to it besides handling potential boilerplate mistakes? &gt; That shouldn't happen (especially without the STL's move_if_noexcept logic). You're right it doesn't. I'm unsure where I first encountered the problem now (it was actually a couple of years back now and never actually tested it since!). I do know that other compilers seem to be more aggressive in instantiating template members than MSVC though I don't know the exact rules for it. For example a static_assert(false, "") in a non-invoked template class member. You can see a really trivial example of what I'm talking about here: https://godbolt.org/g/3wz5z9 (compiles in MSVC but not GCC or clang). &gt; This seems like it risks slicing, and in particular creating a lifetime problem as m_FixedBuffer is a data member of the derived class. Can't say for sure without seeing all the code (I would particularly suspect move construction; you can transfer pointers for dynamically allocated memory, but not for a local buffer like this). I think I know what you mean. You definitely can't move the pointer in that case no. The move constructor for BaseArray basically has a check which performs a per element move for each item in the case where the source does not own its own buffer (i.e. we cannot take ownership of it). Thanks for taking the time on the feedback, appreciated
I know virtualizing is illegal, but is it also physically impossible? People manage to run OSX on custom computers after all.
cool
This looked really interesting until I heard this guy unintelligibly narrate the video. It's borderline comical, how can anyone get anything from this
I think the biggest issue is you came into a conversation about header-only vs more normal projects, and were like "But what about amalgamated projects though?" I'll take the middle ground of, yeah, they're cool too. This after I spent hours the other night integrating assimp and bullet into my cmake project using add_subdirectory.
Why would you depend on Qt for `QDateTime` when [Boost.Date_Time](http://www.boost.org/doc/libs/1_66_0/doc/html/date_time.html) exists and has the great advantage of not being Qt.
Because I would depend on Boost now.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7txx35/which_version_of_beginning_c_through_game/dtgb0k7/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; in situations where memory is at a premium it may be quite undesirable. In practice, the overhead is minimal. Consider MSVC's 1.5x policy. If vector sizes are random (and you don't have vectors that have undergone significant erasures), then on average a vector will be in the middle of the 1 to 1.5 range. 1.5/1.25 = 20% additional overhead. And that's the worst case. Many vectors are exactly-sized (e.g. after range-construction, or a range-insertion that triggers reallocation once). &gt; are there any advantages to it besides handling potential boilerplate mistakes? It avoids leaking if any of the constructions throw. It also does the memmove dispatch. &gt; For example a static_assert(false, "") That's a separate rule (compilers are permitted to check the definitions early, and emit an error if they can't possibly compile).
Looks nice. Curious if you are familiar with https://github.com/HowardHinnant/date? How might you handle TZ and DST support? I've seen some interfaces accepting an offset in all the methods.
One test a conclusion doth not make.
Ok, thanks. Why should caches not be mentioned? If there is a serious performance impact of doing (for example) fine-grained locking on some architectures, surely that is something we should take into account? 
**Company:** [ORDIS Co., Ltd.](https://www.ordis.co.th) **Type:** Full time **Description:** As a successful C++ Software Developer you will be involved in implementing features according to customers requirements. You will be joining a small team of expert C++ Programmers, utilising the latest compiler toolsets and will have the opportunity to expand your development skills in a small but future-oriented company. The successful candidate will have professional experience of programming with C++. Knowledge of Boost and STL are required while knowledge of Wt or Qt are highly desirable. **Required skills** * Excellent C++ skills (preferable with C++11 experience) * Experience with STL and the Boost libraries * Knowledge of Microsoft Visual Studio * Strong analytical skills * Good communication skills (English) **Nice to have skills** * Experience with Wt or Qt libraries * Experience with GIT or SVN **Benefits** * 24 days annual leave * Flexible working hours * Five working days per week * Free beverages * Bonus at the end of the year * Visa and work permit sponsorship for non-Thai nationals Office location is 20 meters from BTS Phayathai station. **Location:** Bangkok, Thailand **Remote:** No **Visa Sponsorship:** Yes **Technologies:** **Contact:** Interested applicants can apply [here](https://th.jobsdb.com/th/en/job/cplusplus-software-developer-%e0%b9%82%e0%b8%9b%e0%b8%a3%e0%b9%81%e0%b8%81%e0%b8%a3%e0%b8%a1%e0%b9%80%e0%b8%a1%e0%b8%ad%e0%b8%a3%e0%b9%8c-cplusplus-300003001565576) or contact us at info@ordis.co.th 
I am not using a lexing or parsing _library._ I am using a code generator. Those are entirely two different things. The purpose is to reduce work. I do explain in the first episode how exactly both work, including show line-by-line what kind of code the lexer generator (re2c) makes for my code, and show that even if you wrote it by hand from scratch, it would be pretty much identical in appearance, if not perhaps worse-performing.
 static constexpr uint64_t SECONDS_IN_YEAR = SECONDS_IN_DAY * 365; Except in leap years, when it is 366. Also, `uint64_t` is far larger than this constant needs to be. And that `static` is implied. inline static asap::years operator"" _years(long double v) { return asap::years(static_cast&lt;double&gt;(v)); } inline static asap::year operator"" _year(long double v) { return asap::year(static_cast&lt;double&gt;(v)); } inline static asap::years operator"" _yrs(long double v) { return asap::years(static_cast&lt;double&gt;(v)); } inline static asap::years operator"" _Y(long double v) { return asap::years(static_cast&lt;double&gt;(v)); } inline static asap::years operator"" _years(unsigned long long v) { return asap::years(static_cast&lt;double&gt;(v)); } inline static asap::year operator"" _year(unsigned long long v) { return asap::year(static_cast&lt;double&gt;(v)); } inline static asap::years operator"" _yrs(unsigned long long v) { return asap::years(static_cast&lt;double&gt;(v)); } inline static asap::years operator"" _Y(unsigned long long v) { return asap::years(static_cast&lt;double&gt;(v)); } Why do you have two identical types for years (`year` and `years`), and why do you have no less than 4 user-defined literals to generate them? Why do some result in a `year` and others in a `years`? Why is one spelled with a capital and the rest not? static std::array&lt;std::string, 7&gt; fmts = ... Missing a `constexpr`. 
&gt; I am not using a lexing or parsing library. I am using a code generator. That's basically saying the same thing. You seem to have missed the point of my comment - I am looking for resources that build it all up from scratch, not one that uses code generators. That is not a slight on your particular video. I also explained my rationale - learning two very important skills. Also, like I mentioned, a lot of commercially used compilers are indeed handcoded throughout - that is a vital skill to learn. One could start with a very simple language specification, handcode all the stages, and that would set them up for the future - whether they use code generators or prefer to handcode their custom compilers.
cppref seems to suggest to use ˋis_trivial` + ˋis_standard_layout`.
Why are you guys not even trying D? I can build my projects in 1 min and that's the optimized LLVM5 build. And dependency management is solved. And I debug from Visual Studio.
visa sponsership for the full time position ?
&gt; In x64 size_t is 64bits which is rather wasteful. Your container should ideally be as compact as possible. This only really matters if you have a whole bunch of vectors themselves stored in a container. But if you have a vector of vectors for example, you can usually find a more efficient scheme. I've never really seen a situation where having vector be two words instead of 3 would have helped. I guess YMMV. To top it all off, a vector can never be less than two words due to alignment issues. But if you have a collection of arrays, you can do better than this by storing one array of unique_ptr, and storing the sizes and capacities seprately. And, it rather contradicts your other con: if you want stack allocation, you anyway need some room on the stack to put things. This directly contradicts keeping the vector as small as possible. &gt; 2^64 (18,446,744,073,709,551,616) elements is a few too many. (If you hit this boundary you may have other problems to consider) This number is totally irrelevant; when you step down from 64 bits, to gain anything you have to go down to 32 bits. 2^32 is 4 billion. Bigger than you need usually, but not always. &gt; Not platform agnostic. In x86 size_t is 32bits. This causes all kinds of problems with attempting any kind of communication across platform boundaries (network messages, serialized data etc.). You can't serialize a vector naively anyhow... You'll need to use some kind of framework or hammer out some code that serializes the vector. When you do that, you can pick a fixed width integer for your serialization struct. Fixing the width of the vector buys you essentially nothing in solving this problem. All this, and you missed the worst thing about size_t: it's unsigned! &gt; We can use SFINAE to specialize this method on a type trait of T This is totally unnecessary. You are repeating most of Reallocate to no purpose. You can just do this: void Reallocate(CountType newCapacity) { if (newCapacity &lt;= m_Capacity) return; auto newData = Allocator::Allocate(newCapacity); if (m_Data != nullptr) { if (std::is_trivially_copyable&lt;ObjectType&gt;::value) { memcpy(newData, m_Data, m_Size * sizeof(ObjectType)); } else { // move all existing items to the new array for (CountType i = 0; i &lt; m_Size; ++i) { new (&amp;newData[i]) ObjectType(std::move(m_Data[i])); } } if (!std::is_trivially_destructible&lt;ObjectType&gt;::value) { // call all our destructors in the original array and clean up for (CountType i = 0; i &lt; m_Size; ++i) { m_Data[i].~ObjectType(); } } Allocator::Free(m_Data); } m_Data = newData; m_Capacity = newCapacity; } You don't need if constexpr for this; this is a branch on a compile time value which is trivial for the compiler to eliminate. &gt; Your compiler will complain that you can’t actually create copies of unique_ptr. Just plain wrong; compilers are required not instantiate members of template classes that are not used. &gt; We’re basically at parity with std::vector at this point barring some additional operators and methods, exposing iterators etc. Nope. Your implementation isn't even close to being an allocator aware container. You need to propagate the allocator correctly in copy/move constructor/assignment. Need to call allocator construct/destruct instead of placement new/destructor. Need to use the allocator through allocator traits. Need to support stateful allocators (you don't even store an instance of the allocator). &gt; The concept of m_OwnsData means we can initialize our arrays with data that it doesn’t own. this is something you can do, if you're really desperate. E.g. I considered this once because we wanted to have a map of strings, that we could look up into with const char*. So I thought about some kind of optionally owning string that const char* could cheaply implicitly convert to, since standard containers do not support heterogeneous lookup. That said, C++ ownership can be tricky enough even when statically you understand which things do and don't own. Something that is optionally owning IMHO going to be really, really error prone. I don't think this is a good idea for a general purpose data structure. In 99% of cases you can find a better solution, in the remaining cases I would write something ultra custom or just not write a data structure at all and encapsulate the logic in the higher level class. Sorry but this article did not impress me from several aspects and I would definitely not consider this container to replace vector; it seems like a half measure. I'd rather either use a proper generic container with clearer ownership semantics and proper allocator support, or come up with something bespoke for a specific performance critical problem.
What was wrong with hh? 
I posted [this](https://github.com/martinrotter/qt5-minimalistic-builds) some days ago. I let you know that I also compiled Qt 5.10 with custom minimalistic settings - MSVC2017 in static and shared configuration. Static version is LTCG enabled and thus allows for more resultant executable file size optimizations.
**Defaulted to one day.** I will be messaging you on [**2018-01-31 10:46:40 UTC**](http://www.wolframalpha.com/input/?i=2018-01-31 10:46:40 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/cpp/comments/7ts2bn/parser_and_lexer_how_to_create_a_compiler_part_15/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/cpp/comments/7ts2bn/parser_and_lexer_how_to_create_a_compiler_part_15/]%0A%0ARemindMe! somewhere in the future) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Yes. there's no good reason not to use it with MSVC.
and every build configuration permutation. debug/release, sanitizers, LTO, etc. With a header-only lib, it gets built with whatever your project is built with.
Your actual question is more about static vs dynamic linking, not header-only libs. If you static link a non-header-only lib, you'll have the same problem.
Looks likes you're trying to pass a null pointer to fileIn.read. The read function won't allocate the memory for you, so it will crash if it attempts to write to an null address. You either need to: A. Instantiate the object with the new operator before you use it, then clean up with delete later. B. Allocate it on the stack instead (not a pointer) inside the function then return a copy or pray for RVO. C. Allocate on the stack outside the function then pass in by reference so the file can write to it safely and avoid making any copies. D. Use shared/unique pointers instead of raw pointers if you're concerned about your ability to manage the memory manually.
If I'm not clear, the null pointer I'm referring to is: student* object = nullptr;
Without LTCG, our code build is about 1 hour on a quad core machine. With LTCG, it's about four hours, so that's a pretty good reason not to use it in my book. 
Well, the first time you access it. But, regardless yes, because the access functions can't be inlined, there will always be a cost to using pimpl. Maybe LTCG can help, but I know we don't use LTCG because its way too slow. the. For me, a better solution to solve a lot of the same problems as pimpl is to use factory functions and push reference semantics out to the user. This removes the level of indirection caused by the pimpl, at the cost of forcing users to use pointers. 
Regarding LTO and compile times: Clang ThinLTO offers a good tradeoff between compile time and LTO performance: &gt; In ThinLTO mode, as with regular LTO, clang emits LLVM bitcode after the compile phase. The ThinLTO bitcode is augmented with a compact summary of the module. During the link step, only the summaries are read and merged into a combined summary index, which includes an index of function locations for later cross-module function importing. Fast and efficient whole-program analysis is then performed on the combined summary index. Also, you don’t compile every debug build with LTO. You just need that for release builds. Regarding the factory design: So how do you cope with platform abstraction? Say like a Mutex on Windows and Linux. Does your mutex factory spit out some IMutex? (Which would be worse than PIMPL). 
Got it, thanks
&gt; Except in leap years, when it is 366. You are absolutely right about leap years, but I mostly use these constants for duration which are oblivious about leap years since they have no reference date. &gt; Also, uint64_t is far larger than this constant needs to be. True. I had a good reason for it but now I forgot :) &gt; And that static is implied. I did not know that, thanks. &gt; Why do you have two identical types for years (year and years) Its just because 3_days/asap::days(3) reads better than 3_day or asap::day(3). I was in doubt if I should had them or not, I put it in anyways. &gt; and why do you have no less than 4 user-defined literals to generate them just for good looks when writing, you may want to write 10_yrs. for the double/long it was to keep the compiler happy, I had only the long double version. &gt; Missing a constexpr. Thanks.
If you can't respect someone's effort and dedication why do you even bother to comment. How many foreign languages do you speak Mr Wise guy? Like many, I watch his videos without any issue and I know myself how hard it is to speak multiple languages. You can still browse the repo (source and slides) and keep your lame comment to yourself 
&gt; Also, you don’t compile every debug build with LTO. You just need that for release builds. Of course you should evaluate if inlining is worth the cost of pulling in LTO at all. Yes, but then we're shipping a build that's possibly not as well tested. We want people to generally be running what we're shipping, so if LTO is really out of touch with build times, which we currently find, then we can't do it. But, I do get what you're saying. &gt; &gt; Regarding the factory design: So how do you cope with platform abstraction? Say like a Mutex on Windows and Linux. Does your mutex factory spit out some IMutex? (Which would be worse than PIMPL). Easy. // In Mutex.h class Mutex { public: void Lock(); void Unlock(); private: Mutex(); Mutex(Mutex const&amp;); }; std::unique_ptr&lt;Mutex&gt; CreateMutex(); // In Mutex_Windows.cpp class MutexImpl : public Mutex { public: Lock() { ... } Unlock() { ... } private: CRITICAL_SECTION mutex_; }; Mutex::Lock() { static_cast&lt;MutexImpl*&gt;(this)-&gt;Lock(); }; Mutex::Unlock() { static_cast&lt;MutexImpl*&gt;(this)-&gt;Unlock(); }; std::unique_ptr&lt;Mutex&gt; CreateMutex() { return std::make_unique&lt;MutexImpl&gt;(); } // In Mutex_Linux.cpp class MutexImpl : public Mutex { public: Lock() { ... } Unlock() { ... } private: pthread_mutex_t* mutex_; }; Mutex::Lock() { static_cast&lt;MutexImpl*&gt;(this)-&gt;Lock(); }; Mutex::Unlock() { static_cast&lt;MutexImpl*&gt;(this)-&gt;Unlock(); }; std::unique_ptr&lt;Mutex&gt; CreateMutex() { return std::make_unique&lt;MutexImpl&gt;(); } Then the build system only compiles in the specific files for each platform. One can even take the common bits and move them to a .inl file that gets included at the end of the platform specific .cpp file. // In Mutex_Linux.cpp class MutexImpl : public Mutex { public: Lock() { ... } Unlock() { ... } private: pthread_mutex_t* mutex_; }; #include "MutexImpl.inl" 
You could implement that using CRTP. Instead of implementing Mutex::Lock in very Mutex_Impl.cpp. Nice approach!
One might be able to do something with CRTP, but I'm not really sure there's much point when just #including a .inl file will work; no templates needed. 
a few non-Bisqwit links that might be of interest, there are plenty more available on **youtube**. series of 20 videos (with parse tree) [Compiler design](https://www.youtube.com/watch?v=Qkwj65l_96I&amp;list=PLEbnTDJUr_IcPtUXFy2b1sGRPsLFMghhS) [parser in c](https://www.youtube.com/watch?v=N55XNj8KjC4) [Trees 3 | parse code 1](https://www.youtube.com/watch?v=TastAWp8eIE) [Parse Trees - Programming Languages](https://www.youtube.com/watch?v=9H0-YodumKQ) [DERIVATION TREE OR PARSE TREE IN TOC](https://www.youtube.com/watch?v=42nqWoHacxg) 
You should consider adding your library to currently fighting c++ package managers like buckaroo, cget, conan, conda, cpm, cppan, hunter, vcpkg and so on :P
Thanks for the effort! I have seen some of the resources before, and at the risk of sounding ungrateful, I'd like to annotate my comments on them (in case others looking around like myself chance upon this thread): &gt;series of 20 videos (with parse tree) Compiler design Seen this before - this is pure theory. Good for a quick refresher, but no code. &gt;parser in c This is more like it. I had seen this a few months back, and it was almost exactly what I was looking for. Unfortunately, it has only two parts and comes to an abrupt end after that! :( &gt;Trees 3 | parse code 1 This looks very promising. Thanks for sharing this link! Again, it appears to be only in a couple of parts, but that's still something. &gt;Parse Trees - Programming Languages Too short and limited in scope to be useful. &gt;DERIVATION TREE OR PARSE TREE IN TOC Pure theory again. In terms of theory, Professor Aiken's course on Coursera/Stanford Lagunita is a most recommended course (especially for those who last took Compilers way back in college). However, the quest for the programming guide that starts from basics all the way to a working compiler, handcoding everything from scratch still remains. In any case, thank you for sharing the links - a couple of them (as noted) are very useful , and looks about the best available option right now.
In the case of 32-bit size/capacity and a 64-bit pointer. The objective of the 32-bit size/capacity is to have many of them (I presume), possibly in a vector/array. Adding 'm_OwnsData' is a therefor a bad idea as it affects alignment, nastily. A better approach would be to "tag" the data pointer in case of non-ownership.
 PS: I'm just here trying to provide extra help, I have/receive no benefits from posting these links. I like the content that Bisqwit produces and wanted to help him reach a bigger audience. PS #2, feel free to annotate the content, I didn't sit down and watches everything in the links, I just made sure they were in english (which is also not my native language). I found a free course (which I have not taken) that might be of interest: [compilers-theory-and-practice--ud168](https://www.udacity.com/course/compilers-theory-and-practice--ud168) ** Description of the course ** **Front End** * Compiler Phases * Scanners &amp; Parsers * Semantic Analysis **Middle End** * Syntax Directed Translation * Control Structures and Back-patching * Function and Procedure Calls &amp; Runtime Organization **Back-end** * Register Allocation &amp; Instruction Selection * Code layout and Code Generation * Brief Introduction to Code Optimization Cheers!
This is great!
Well, you're right. Some poisons are easier to take than anothers, though, I intended ASAP to be one of the easiest.
Haha, good idea.
nothing wrong with it per se, it's a great library, but I wanted something that felt more like MomentJS, with a simpler API, (albeit letting you declare dates using something very similar to what you'd write on paper). Also, I specifically needed/wanted to iterate between dates using a range-based for. I might have overlooked it entirely but I couldn't find how to do it. Oviously his library is a lot more mature than mine and feels a lot more like a standard library than mine does, I just feel that my API is more approachable than his. It's just my opinion though, of course its very biased. :)
Thanks. I'll actually find the time to write a proper comparison.
I don't handle TZ and DST explicitly, I rely totally in the system on this point, which usually picks the right tz and DST when creating dates, but I recognize it is an improvement that needs to be made. Not sure about the API to that, though, an offset seems reasonable. Have any other ideas?
How's the pay?
That is one of the problems with dates. You cannot translate a period of 1 year to a number of seconds. Depending on context, it can be 366 days, 365 days, 365.25 days, and in some situations even stranger values. 1 year after Feb 12 at 9 am is Feb 12 at 9 am the next year. It isn't Feb 13 at 9 am, Feb 11 at 9 am, or Feb 12 at 3 pm, all of which are possible if you pick a number of seconds for 1 year and add it to Feb 12 at 9 am. Now, does this make things insanely complicated? Why yes, it does! Which is why writing a time and date library is [b]hard[/b], and using it equally challenging. 
There must be a way to share video augmented content without requiring anyone to sit through the video to consume it. Some way to have the slides and video be in a parallel stream and maybe a transcript in another stream, so you can scrub through the slides / transcript, find the bit of video that is of interest, and watch that part. Because I love videos, yet hate not being able to skim them to find out if they contain something interesting. 
I watch all videos at 2x speed; maybe that could work for you. There are browser extensions to go faster if you need it faster. Usually I just go 2x and skip forward with the right keyboard arrow when I want to "skim" a video
Well, for competitive programming, I have no problem with using namespace std. It's write-once read-never code anyway. Unless I misunderstand what competitive programming is...
Where does it depend on this?
thanks for the feedback konanTheBarbar. i really appreciate. 1. i completely agree, i do have a lot to learn. i only starting competitively programming less than 1 year ago. hopefully in a year or 2 my tutorials / solutions will be that much better. 2. the github idea is a great idea. i will definitely do that 3. macro usage &amp; using namespace std is for speed. I agree though, and will drop the macros, as i didn't think about the readability. but for namespace std, i know in a codebase you shouldnt do it, but for competitive programming i havent seen any code that doesnt 4. as for your STL algorithm solution, it is very neat, but 2 nested for loops for beginners is easier to understand. i will definitely be covering lambdas and STL algorithms in the future, but i probably won't use them unless is reduces the code/simplicity of the solution a lot. however, i do like the idea of showing an "alternative" STL algorithm like yours, just to expose ppl to STL they might not have seen. once again, thanks for the feedback!
&gt; In practice, the overhead is minimal. Consider MSVC's 1.5x policy. If vector sizes are random (and you don't have vectors that have undergone significant erasures), then on average a vector will be in the middle of the 1 to 1.5 range. 1.5/1.25 = 20% additional overhead. And that's the worst case. Many vectors are exactly-sized (e.g. after range-construction, or a range-insertion that triggers reallocation once). You have good points the more I think about it the more I'm inclined to agree with you honestly but it's more of a subjective thing that could or could not be included in the implementation. The proof of concept here was to illustrate how one could use newer language features to build a trait-aware container with a couple of other ideas (variable count size, stack allocated buffer). If you had some kind of allocation heuristic it would probably be better to have some kind of policy class for it. &gt; That's a separate rule (compilers are permitted to check the definitions early, and emit an error if they can't possibly compile). OK I cheated on that one! I've been trying to remember the motivation for this and I think I've found where the problem is. https://godbolt.org/g/Qg98xt
&gt; Aren't there better methods for (more) linear problems? Levenberg-Marquardt should fill that role. In the past, VNS has been more reliable for me, but when Levenberg-Marquardt works it is usually faster. Optimization algorithms (VNS and local searches) can now receive an improved solution callback as parameter.
This provides a thorough and clear explanation along with great concrete demonstrations — makes sense coming from the creator of compiler explorer. Thanks!
I appreciate your effort but, frankly, I don't agree on point 4. If your channel is about C**++** Competitive Programming then you have to exploit the full power of C++ as much as you can. C++ is empowered, among the other things, by the standard library. If you won't show and explain how to wisely use the standard library to solve the challenges then you will end up having the nth channel on Competitive Programming where C++ is there just because the usage of *some* containers and a few utilities. You have the opportunity to be different from the others. But you really need to show useful **C++** snippets. For an example, have a look at my ongoing series on "C++ in Competitive Programming" [here](https://marcoarena.wordpress.com/category/competitive-programming/). Honestly, I don't agree on point 4. If your channel is about C**++** Competitive Programming then you have to exploit the full power of the standard library as much as you can, otherwise you will end up having the nth channel on Competitive Programming where C++ is there just because they use *some* containers and a few utilities. You have the opportunity to be different from the other channels around and I think people would love watching such videos. But you really need to show useful and modern **C++** snippets.
It might work, but it don’t think the standard guarantees any of that. What if some other allocation took the place of the old control clock and data? You should use expire() to check if the weak_ptr is still valid and lock() again.
Why are you guys not even trying Turbo Pascal? I could build 100k+ lines in a minute *20 years ago, on a 200 MHz machine*, with solved dependency management, and a cool debugger. This isn't more or less absurd than switching to D. It's not just my team's few 10k lines, but also 20 other teams. And it's embedded, where even C++ is already a restriction in choosing your silicon. But with decent dependencies, I can also build 100k+ lines of C++ in a minute.
b still has a reference to the original data of a. It doesn't get deleted until b goes out of scope. Making a own a new, different pointer doesn't change what b holds. 
http://en.cppreference.com/w/cpp/memory/weak_ptr/lock &gt; A shared_ptr which shares ownership of the owned object if std::weak_ptr::expired returns false. Else returns default-constructed shared_ptr of type T. So it depends on expire(). Not sure how expire() copes with *different* or already freed data and control block. Probably an implementation detail. But the standard can certainly not guarantee that control block and data are allocated on the same address than before. What if another allocation happened in the meantime?
I did? 
C++17 support?
Oh ok, that explanation is better still. Thanks for clarifying.
The standard doesn't mention control blocks. It defines the semantics of `shared_ptr` and `weak_ptr` only in terms of `use_count`.
I have an issue with the claim that the better solution for the "Jewels and stones" is linear. Constructing a hash_set from a range may be linear in the average case but it in the worst case, it is [quadratic](http://en.cppreference.com/w/cpp/container/unordered_set/unordered_set). I suppose my question is how are solutions judged?
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7u07np/problem_with_reading_object_data_from_file/dth7zv4/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
yes
Control blocks control the semantics of shared_ptr like red-black trees control the semantics of map. If the Standard doesn't fully describe how a control block implementation behaves, that's a defect in the Standard.
The standard rarely mentions implementation details. In practice, since there are no standard library implementations built around a garbage collecting allocator, you're probably not going to find an implementation that doesn't use a pair of reference counters. And if you do, it's not going to have a weak pointer that thinks an expired shared pointer is still valid.
What I am interested in: there should be theoretically huge attack wave on unpatched systems which I don't see. It's like every site on the net explained how to do the attack. What is happening?
Now, what day is 1 year after Feb 29? 1 month and 1 year after Jan 29 on a leap year? On a non-leap year? Is it different if it is 1 year and 1 month than 1 month and 1 year? If you break the math down into steps, does it act differently? And does it make sense to have a time library that isn't, say, tied to a calendar app? In which case, generic "duration" and "time difference" should rather be "event duration" and "delta between repeated events", which are quite distinct things.
Basicly implementation is that there is some kind of control block: SharedPtrControlBlock: sharedCount weakCount pointerToData If the shared pointer is allocated using std::make_shared, storage for the object itself is part of the control block SharedPtrControlBlock: sharedCount weakCount pointerToData, points to data data[obectSize] So there is 2 counters. Shared pointer increases both shared and weak count, weak pointer touches only the weak count. When shared count reaches zero, object's dtor is run. If the shared pointer was not allocated using make_shared, storage for the object is freed. Control block itself will be kept alive, until weakCount also reaches zero. Note that when using make_shared, storage for the object is not freed (only dtor is run), until weak count reaches zero. Thus make_shared is both advantage (single allocation), but also disadvantage (memory footprint when you keep lots of weak pointers around).
Be a rebel. Use AVL trees instead.
There are a few things that keep these exploits from completely breaking everything. For starters, they're pretty slow. Especially in Spectre's case, reading privileged memory requires a large number of CPU cycles to make sure the branch predictor is successfully fooled, and if the branch predictor isn't sufficiently convinced that the out-of-bounds read can be speculatively executed, the attack is even slower, because you have to execute even more dummy reads to fool the predictor. On top of that, you need to already have a pretty good idea of where the memory in question is before you can make something meaningful happen due to your attack. In Meltdown's case, the behavior depends on the application making use of the exploit already knowing where in the process memory the kernel memory is located. And for Spectre, you'd need to know where the other cross-process memory is located. In either case, any attack would need to be tailor-made for a specific machine + OS + configuration, making any kind of general purpose attack extremely difficult to write. Also, patches have been introduced to the following (not exhaustive) parts: * Operating Systems * Browsers * CPU Microcodes * Compilers * Anti-Virus Softwares Which means that even if you write an attack for a given machine, you need to depend on none of those patches being applied. I tried compiling a sample version of the Spectre exploit on a few computers, and the AV software caught and deleted the executable program on every computer. I hesitate to say that any kind of general purpose virus/worm/whatever is *impossible*, simply because these are pretty robust exploits, but there's a lot of good reasons that no such attack has been successfully launched.
**Company:** Roku **Type:** Full-Time **Description:** We are looking for a Senior Software Engineer to focus on developing core Roku platform (firmware) features. This engineer will be contributing extensively to both firmware development and as well as Brightscript/Roku Scene Graph (Roku’s proprietary scripting and markup language) based front-end application development. Extensive experience with embedded Linux, C++ libraries/frameworks, development of tools, scripting languages as well as the integration of third-party code is a must. A proven track record of shipping high-quality software on embedded platform is essential. This is a great role for a senior professional who enjoys a high level of visibility and thrives on great business impact. Work closely Product Development, platform services, and release management teams to contribute to our firmware development. Integrate third party C++ libraries. Investigate, diagnose and resolve issues within the Roku Platform **Location:** Headquarters in Los Gatos Ca. With L.A. , Austin Texas and New York offices and option as well **Remote:** Currently not for this position though other roles may **Visa Sponsorship:** Can be discussed **Technologies:** Extensive programming experience with C++ and Embedded Linux. Ability to work in both user and kernel space. In-depth understanding of Linux, tools, libraries and open source development. Understanding of API design considerations and tradeoffs. Familiarity with tools and libraries such as Boost, PlayReady, ALSA, DIAL a plus. Experience with memory management and multi-threaded development. Media / Video knowledge such as codecs, media streaming, etc. would also be a plus. Application development experience utilizing JavaScript, Python and/or similar languages would be a strong plus. Ideally, embedded and/or consumer electronics experience. **Contact:** Please email me directly at dhamm@roku.com
**Company:** New York Stock Exchange (Intercontinental Exchange) **Type:** Full time **Description:** ICE/NYSE is hiring a C++ developer for the Systems Engineering department at the Atlanta headquarters. You will be working on the configuration and deployment platforms for the NYSE trading and matching engines as well as code supporting the ICE infrastructure as a whole. Being in the Systems Engineering department, our job is twofold - development as well as hands on support of our applications (as opposed to write-and-forget type programming) and the trading engine. **Location:** ICE headquarters are in Atlanta, GA. Travel to Wall Street location occasionally. **Remote:** No **Visa Sponsorship:** Up for discussion **Technologies:** - C++ 11/14/17 - Boost - gcc, gdb, etc - Python - Linux (RHEL/fedora) - Oracle and MySql **Contact:** You can PM me here, and we can exchange e-mails
There was [discussion about this](https://www.reddit.com/r/cpp/comments/613z6g/override_and_final_on_virtual_destructors_yay_or/dfbivxo/) several months ago. My take is that one guy strong-armed his personal preference into the guidelines. I agree with you, explicit `override` on destructor is preferred to establish the expectation that the base class destructor is virtual, and it is unfortunate that the guidelines disagree here. I hope Microsoft allows for differences of opinions here and adds an optional warning for missing `override` keywords on destructors. 
 auto void_continuable = cti::make_continuable&lt;void&gt;([](auto&amp;&amp; promise) { promise.set_value(); }); 1. Is the promise set on a background thread or on the same thread. 2. When .then() is called on the continuable, the body of the passed in lambda by default runs on a background thread or on the same thread that created the continuable? 
I found [DashGL](https://dashgl.com/) to be nice. It uses OpenGL &amp; the GTK library to create a few video games. They're simple examples but after you learn them you'd be able to apply the same techniques to what you'd like to do!
I think using anything except auto when using make_x is just needlessly repeating yourself and sets you up for problems in the future.
1. &gt; Is the promise set on a background thread or on the same thread the continuable lives. The promise is set on the thread the lambda is executed in. Continuables are executed on request and thus the lambda thread isn't neccessarily the same the continuable was created in. By default the library doesn't provide it's own thread pool, however it is designed to work with one, see below. 2. &gt; When .then() is called on the continuable, the body of the passed in lambda by default runs on a background thread or on the same thread that created the continuable? By default the handler inside then works on the thread the promise was resolved. This may be changed through the second parameter in `then`, which accepts a callable that forwards work to a specifc executor or thread pool of your choice such as `boost::asio` or `libuv`: ```cpp auto dispatcher = [](auto&amp;&amp; work) { // Dispatch the work here, store it for later invocation or move it to another thread. std::forward&lt;decltype(work)&gt;(work)(); }; read_file("entries.csv") .then([](Buffer buffer) { // ... }, dispatcher); // ^^^^^^^^ Dispatch the handler through the given dispatcher callable ``` 3. &gt; I do not think its wise to use auto in examples because some people may want to know variable types. You may still use a specific type as the promise type, in this particular example it would be `cti::promise&lt;&gt;`. However this way burdens the performance overhead through an applied **type erasure**, since an unknown type has to be converted to a specific type. Overall the library is designed to avoid type erasure and thus it's higly recommended to use auto. 
One of the best ways I learned was finding projects like what I wanted to acheive or write on Github - usually a few is ideal. Then synthesizing what I thought was the best of the respective codebases and re-writing things in my own words helped tons. Gets you to build conceptual understanding of how to utilize the language, and is also really helpful at getting you to see different features of the language and a variety of coding styles and design decisions. I'm always cautious with written text tutorials, because I find many of them use really outdated C++ idioms. So keep an eye out for that. Don't fear the standard library's most luxurious and advanced features as a beginner, embrace them
&gt; The promise is set on the thread the lambda is executed in Yes, this part i understand, my question was that is the lambda executed in: 1. The original thread. 2. In another thread. 3. Arbitrarily 1 or 2 above. 
Actually, my We Know Where You Live optimization means that the make_shared control block doesn't need to store a pointer to the data. (I "contributed" this to the other implementations by describing it in a talk without code; apparently it was original to my rewrite of MSVC's control block.) Also, there's a basic optimization where shared_ptr doesn't increment both refcounts. If you represent the weak count as "1 if any shared_ptrs are alive, plus the number of weak_ptrs", then the shared_ptrs never increment that, and decrement it exactly once.
Or snug up to Judy.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7u4xv7/looking_for_simple_game_tutorial/dthqkn8/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Thanks!
source code viewer now support shooed encoding ？
Turbo Pascal has been discontinued so your analogy isn't matching.
this is beautiful. The fact that it's executor agnostic is its most useful feature.
I think Spectre would be most powerful in embedded/IoT systems that often get no patching and often don't use best security practices. Not address space randomization for example makes the exploit much easier to use, as memory mapping can be almost perfectly predicted.
If you're not already, join the C++ slack. You can promote your lib there as well as assuage any potential concerns for interested devs.
Interesting; What is your native language? 
I thought it was suitably interesting so watched it. Maybe this is a better summary for you: https://godbolt.org/g/4Ckh7z
It's a transparent organization with a transparent funding, so they should state the amount publicly - otherwise, it is just a negotiation gambling, which is not fair.
&gt; If the Standard doesn't fully describe how a control block implementation behaves, that's a defect in the Standard. No, the standard doesn't mention control blocks at all. This is what the draft says about effects of the destructors: Effects: — If *this is empty or shares ownership with another shared_ptr instance (use_count() &gt; 1), there are no side effects. — Otherwise, if *this owns an object p and a deleter d, d(p) is called. — Otherwise, *this owns a pointer p, and delete p is called. 2 [ Note: Since the destruction of *this decreases the number of instances that share ownership with *this by one, after *this has been destroyed all shared_ptr instances that shared ownership with *this will report a use_count() that is one less than its previous value. —end note ]
German.
yes, it supports changing the text encoding that is used to display the source code.
&gt; If a header-only library you include has a security problem, even your most inquisitive users won't notice the problem and tell you about it What does it have to do with headers? The same thing is valid for .cpp files as well. Not to mention already compiled code which makes it impossible to check it out for security issues.
&gt; But I can kinda understand why people would want to break away from the interface/implementation separation. Headers are not an interface/implementation separation, it is an ancient mechanism of providing information to the compiler. 
It's a shame the STL does not provide a hash function for all the data structures it provides. It's a very common problem, and one of the main reasons boost is so popular.
That is indeed true, but it also functions as a separation mechanism (although not a very optimal one), which is why I brought it up in the context of modules.
Just deprecate it and introduce a template memset function. Also, compilers removing code with side effects is plainly wrong and should be banned. 
Looking for a passionate developer **Company:** linkbit GmbH **Type:** Full time **Description:** We are a young, innovative company developing new solutions for voice, video and real-time communication and desktop sharing. In order to reinforce our development team we are looking for a passionate C++ Developer hooked with modern technology. You working place will be equipped with latest hardware and tools, and you will be able to work with latest technologies like Modern C++, Docker, Kubernetes, .NET Core and high-scalable microservice architecture. Knowledge, experience and skills - 3-5 years of experience in writing applications in C++ - Experience in working on a large codebase - High-performance multithreading and high-scalable Network I/O - German language (or willing to learn) - Ability to to work in a small self-organized team Optional - Experience with C# and .NET Core - Knowledge of voice and video codecs **Location:** Vienna, Austria **Remote:** No **Visa Sponsorshit:** Up for discussion **Technologies:** - C++ 11/14/17, C# .NET Core - Windows, Linux - Docker, Kubernetes - CMake **Contact:** Reddit PM or email to office@linkbit.io 
good point. Often when cross compiling for embedded devices there are trade-offs to be made. I'm going to start using = {0}; in initializers. I'll post an update if anything bad happens. 
To be fair - I've heard rumors about embedded compilers that still don't implement C99/ c++03 let alone c++11/C11 and function calls might be implemented more reliable than more subtl aspects of the language. But it's you have to use one of those, you are in a very special situation anyway. However, one thing where I have to admit that I'm weary myself are unknown c-structs (structs that are defined in a c library header and whose exact definition is not specified - sockaddr_... anyone?). I'm never sure how much them playing around with unions, padding and alignment interferes with initialization. So far I never had a problem, but I don't care to recommend it in reviews either.
Discussion on HN: https://news.ycombinator.com/item?id=16270755
I think i'm in complete disagreement; Yes, C++ is complex; Yes some parts of it are old and some parts of it are broken. Now, ask yourself how many hours you spent convincing your clients/users/bosses to maybe move to C++11/14/17. And how many years it takes for some people to move to the new practice ( just adding a -std11 flag does a idiomatic c++11 program make) Now imagine what breaking changes would entail. There are maybe more critical systems in C++ or C than in any other language. You just can not break that. A breaking change in C++ may well be 10, 100 times as bad as the Python 2 -&gt; Python 3 story. People use C++ with the expectation of decades long support. Otherwise they don't use c++. I think there was a bunch of pretty big mess up in C++11 including the whole uniform initialization / initializer list mess. But it's done, it's too late. Now we can only live with it and try to do better in future versions. That's for the "c++ has cruft" part. Now, on the complexity part, C++ is complex because it's designed to solve complex problems. If you problem is not complex, either use the simple parts of C++ or don't use C++. If you need a web server, use go. if you need a mars rover, maybe don't use Go, maybe use C++. Watch the excellent talk from Kate Gregory "It's complicated".
Is this based on past experience? They posted this 2 days before you said 'they do not reply'
Yes, past experience. They have post on another website as well.
&gt; just adding a -std11 flag does a idiomatic c++11 program make *does not*?
&gt; on the complexity part, C++ is complex because it's designed to solve complex problems. I agree with pretty much everything you said, except this. This correlation is absolutely false. Language complexity has nothing to do with the problems they aim to solve; language complexity is a language design issue. C was designed to solve complex problems, and it's very simple. If language and problem are complex, you have 2 levels of complexity to deal with. That's twice as bad.
I can't fix the source of where I read that but the overall cognitive load of any given programming project tends to be about the same. Either the complexity is in the language or it's in your code; If you take something universal like memory management, either you have the C approach where you have to know every places a `free()` called is made on a given object, either you have the c++ approach where you need to know how RAII, smart pointers, etc work. And if you have a gc collected language, either you don't care about memory, or you need to have intimate knowledge of how and when the GC will kick in. 
Hrm, the difference is that C++ is designed to be able to extend the language through libraries, with the intent being to reduce complexity at the call sight. This certainly makes the language more complex. The implementation of such libraries is probably more complex than necessary because that part of the language is a bit....unruly....but it allows reducing consumer complexity in a way that's just not possible most other languages. 
Is this the same as his cppcon talk?
Yes ! Also, could you elaborate on this ? &gt; I think there was a bunch of pretty big mess up in C++11 including the whole uniform initialization / initializer list mess. I don't see where the problem is :) Maybe you have a link to a blog post or something ?
You should consider adding your library to currently fighting c++ package managers like buckaroo, cget, conan, conda, cpm, cppan, hunter, vcpkg and so on :P
Run the 'install.sh' script in the download package, then Sourcetrail will be available in the terminal and in the application launcher of your Linux distribution. Alternatively run 'sourcetrail.sh' without installation. 
*exact same address* a weak_ptr isn't magically watching an address.
it's already on github, the best 'package manager' of all
&gt; C++ is complex because it's designed to solve complex problems No it isn't.
In general, a weak ptr keeps the *control block* of a shared pointer around. When you call `make_shared`, the control block and the memory where the object resides is one chunk. When the last shared ptr goes away, the object is destroyed but the memory for the object is not recycled. In your specific case, it is not possible for the second make shared to allocate an object at the same spot, because that memory is still in use. If you didn't use make shared, then the new object could be at the same spot, but the control block could not be. And weak ptr cares about the control block. 
Is Bloomberg where old C++ devs go to die? They're constantly hiring in London, must have a retention issue.
C was not really designed to solve complex problems. It lacks fundamental features that make error handling and resource management extremely difficult in a large program, like RAII and exceptions. In C++ I can use the standard library and write simple programs that can survive running out of memory and std::bad_alloc being thrown. How many large C programs have you seen that can handle malloc returning nullptr?
&gt; C was not really designed to solve complex problems. C was designed for the Unix development. If you think Unix development not complex, I can't wait to see the operational system you wrote. &gt; It lacks fundamental features that make error handling and resource management extremely difficult in a large program, like RAII and exceptions. C simplified error handling and resource management from Assembly. Exception handling was introduced with Lisp, but it had a very high cost back in the early 70's. &gt; In C++ I can use the standard library and write simple programs that can survive running out of memory and std::bad_alloc being thrown. And what do you do after this happens?
&gt; If you think Unix development not complex, I can't wait to see the operational system you wrote. On the contrary, I think it's very complex, and it would be significantly less complex if C were not so impoverished.
I hadnt heard of Nicholas before I saw this presentation. But he is an excellent public speaker!
I agree. But at the time, what choices did they have?
&gt; C was designed for the Unix development. If you think Unix development not complex, I can't wait to see the operational system you wrote. Unix in the 1970's, so about 100k LOC. There is no reason to technical use C over C++ for anything any more, including OS and embedded systems (except maybe if there's no C++ compiler available). Even if you only use a limited subset of the language/libraries, C++ is strictly an improvement. I had to look at some C code recently, and while it was a mildly nostalgic experience, it was otherwise pretty horrifying - the amount of boilerplate just to move data and check error codes, the frequent opportunities for buffer overruns, the pointer arithmetic, the general unreadability, the "fprintf(stderr, ...); return -1;" as error handling, some sort of home-made linked list data structure, malloc(), etc. It makes me itch just thinking about it.
They didn't have a choice but that isn't his point
So C++11 introduced uniform initialization syntax, i.e. using {} braces to initialize stuff instead of () parentheses. This solves the "most vexing parse" problem, and disallows narrowing conversions, among other benefits. But C++11 also introduced list initialization which also uses {} braces. So, while C++11 tried to make uniform initialization syntax the new preferred idiomatic way of initializing stuff, list initialization also made some constructors impossible to call when using braces. Example: std::vector&lt;int&gt; v{10, 2}; // is a vector of 2 elements: 10 and 2 sts::vector&lt;int&gt; w(10, 2); // is a vector of 10 elements with the value 2 So in this case, if you want a vector with 10 elements with value 2, you *can not use* {} brace syntax, you have to use (). So in this case it's impossible to change from () to {} for initialization. This is a nuisance in generic code: template &lt;typename T&gt; T create_sized(std::size_t size) { return T{size}; } create_sized&lt;std::vector&lt;int&gt;&gt;(10); // a vector with one element of value 10 create_sized&lt;CustomVector&lt;int&gt;&gt;(10); // a vector with 10 elements? Or a vector with one element of value 10? The result of line 2 depends on whether `CustomVector` has a constructor that takes a `std::initializer_list&lt;T&gt;`. Fun times.
Ok. I was just explaining how a basic implementation looks like. There is always room for optimizations and it is good to know there are some for in MSVC's STL.
how does it compare to the implementations here ? https://github.com/NoAvailableAlias/signal-slot-benchmarks
great presentation, didn't know those and they are indeed fantastic
&gt; And what do you do after a bad_alloc is thrown? [See here.](https://www.youtube.com/watch?v=QIiFsqsb9HM)
I don’t see how my bachelors assignments were as complex as the Linux kernel, or am I misunderstanding your point?
&gt; C was designed to solve complex problems, and it's very simple. On the topic of correlation issues... a simple language is not necessarily simple to use. I would call C *simplistic* rather than simple, or *bare-bones*. This is a conscious trade-off, but it does impact the maintainability of medium-to-large projects.
I'm assuming you mean performance wise, as you linked a benchmark... I haven't really tested the performance of my implementation, but I can imagine it won't come up on top performance wise, as it uses std::function and dynamically allocates for std::vectors. I have contacted the author of the benchmarks you linked, to see if they can help me run it for my lib. Until I can run a real benchmark, it's really just guesswork. As for the interface and functionality, I think my C++ Observe does pretty well as a flexible and generic observer implementation. I honestly didn't know of the term "signal slot" until now, so it didn't really cross my mind to search for it...
&gt; C++ is complex because it's designed to solve complex problems It's complex because it's badly designed. I'd point at something but the problem is *everything*. `&lt;random&gt;`, `&lt;algorithm&gt;`, move and copy semantics, references, standard container types... there are roughly 10 ways to parse an integer in C++ and it took until C++17 to get one that wasn't atrocious (and even that is inconsistently designed).
&gt; 2) Allow string to be written as a library type instead of a language type 3) Allow tuple to be written as a library type instead of a language type. The fact that you can write string and tuple as a library type might be seen as a feature. The fact that standard string and tuple ARE library types without any special language support is just gruesome.
Seems it doesn't cover such typical real-life cases as remove_observer called or the source is deleted from observer handler. This way it's very limited and you better to list observer handler requirements. Or you may fix it e.g. by https://chromium.googlesource.com/chromium/src.git/+/master/base/observer_list.h . But the downside is this way simplicity will be affected.
Wow, I've always used boost::signals2 in my applications and according to that benchmarks I fucked up :/
Alright. I personally like my own API and design more than any other I've looked at (took a quick look at a couple from your link, but not all). But I think you have to judge for yourself if you like it or not! Also, as you can see in the todo-list, some improvements are on their way. The most important one imo being the separate interface for add/remove as that will make encapsulation/API for the classes holding a subject very smooth. PS: Thanks for the terminology lesson! Have never used Qt, but I've understood that it's pretty powerful.
Observers are not easy, particularly if/when you allow them to be added/removed while notifying. https://www.youtube.com/watch?v=RVvVQpIy6zc Although the title say "Thread-safe ..." most of it applies as well to single threaded.
I don't see anywhere on their page that it's free for OSS contributors and how they define them.
More details here: https://www.cppdepend.com/CppDependForOSS
This kind of violates expectations. If we want a function to take ownership of our type, we `move` our type into that function: f(move(x)); If we don't want a function to take ownership of our type, we don't move it: f(x); Replace `f` with `std::get` and have `x` be of type `std::tuple&lt;int&amp;&amp;&gt;` and the principle still holds. `get&lt;0&gt;(x)` should be an `int&amp;`, since we're not giving up ownership. If we want an rvalue reference, we have to be explicit - `get&lt;0&gt;(move(x))`.
The solution is to perfectly forward the tuple, which will cause `std::get` to return the correct value category. The reason why `std::get&lt;0&gt;(lvalue_tuple)` returns `int&amp;` for a `tuple&lt;int&amp;&amp;&gt;` is because the `lvalue_tuple` has a name and can be mentioned repeatedly; the lvalueness is "infectious". This mirrors the Core Language's rules (see N4713 8.5.1.5 [expr.ref]/4; tuple is actually a little better than the Core Language here, because the Core Language says that E1.E2 where E1 is an rvalue and E2 is an rvalue reference data member, is an lvalue, not an rvalue).
Nice point about the ownership. If this was the case "to maintain ownership safety" why does it return rvalue if the container is also an rvalue? (maybe because lvalue to temporary rvalue is dangerous?). I think that having a explicit function that ignores the "ownership safety" and returns the original value+type as it is can be a nice thing
Point in case: I wanted to use boost geometry and had to install dozens of other libraries. Boost dep tells me that boost geom directly depends on `algorithm array assert concept_check config container core function_types fusion integer iterator lexical_cast math move mpl multiprecision numeric conversion polygon qvm range rational serialization smart_ptr static_assert throw_exception tokenizer tuple type_traits utility variant`. A large portion of those could easily be replaced by std types. 
Even as of V6, UNIX was closer to 10K LOC than 100K.
in short terms: if the tuple is lvalue, it means that it can be used in other parts of the code. That's why `get` always returns lvalue, to be safe about it's values ownership. In case tuple is rvalue, returning an lvalue from `get` is dangerous (reference to temporary), that's why also returns rvalue. Forwarding the tuple doesn't help on cases when internal types are mixed (`tuple&lt;int, int&amp;&amp;&gt;`) Did I understand correctly?
Why? It's great that you don't have to wait for the language to come around every few years just to get new features. Being able to implement things in a library without having to wait for the language is great. Remember `shared_ptr`. Imagine how much pain we'd still be in if we waited for the committee to figure out garbage collection. Instead, some clever people figured out how to use existing language features and made the language more capable right away.
Perhaps there used to be a culture of complexity. I don't think there is one today. At this point, most c++ programmers have embodied the various gotws, core guidelines and idioms that make writing clear and simple c++ code a breeze. I do admit that sometimes writing c++ classes, compared to other languages, is akin to an exercise of abstract algebra, when deciding what fundamental attributes (copy, move, assign, etc) the class should have. But that's the price you pay for *zero cost abstractions*. Even in rust, do programmers have to think carefully about class attributes.
That's a very black and white look at things. As I saw someone else explain, you can introduce breakchanges as long as you release a converter. That's how they supposedly "break" things in Go. So old code doesnt compile, but it's trivial to upgrade. This would put a little pressure on people to upgrade their code BC old code won't "just work" with newer compilers versions
Again, the fact that you CAN create very powerful types is a nice feature (although it wouldn't be so crucial if the development would move at such glacial speeds, but that is a different topic). The fact that FUNDAMENTAL types, like strings, tuples and arrays are implemented as library types instead of them being baked into the language is sad and makes them more clumsy to use and less efficient than they could be. The latest example is `std::variant`: in theory this is a very powerful type for functional style programming, but if you have ever seen what you can do with variants in other languages, you'll see how pitiful the library solution in c++ is.
&gt; In case tuple is rvalue, returning an lvalue from get is dangerous (reference to temporary), that's why also returns rvalue. Slightly incorrect. Given an rvalue tuple and an object or rvalue reference element, get() indeed returns an rvalue reference. However, given an lvalue reference element, get() returns an lvalue reference (lvalueness is infectious). Although the tuple is a temporary, its element is an lvalue reference to some persistent thing, and automatically moving from it would be dangerous. &gt; Forwarding the tuple doesn't help on cases when internal types are mixed (tuple&lt;int, int&amp;&amp;&gt;) Incorrect. get() works per-element. Here is a fully worked example: C:\Temp&gt;type tuple.cpp #include &lt;stddef.h&gt; #include &lt;iostream&gt; #include &lt;tuple&gt; #include &lt;utility&gt; using namespace std; void meow(int&amp;) { cout &lt;&lt; "int&amp;" &lt;&lt; endl; } void meow(int&amp;&amp;) { cout &lt;&lt; "int&amp;&amp;" &lt;&lt; endl; } template &lt;size_t I, typename Tuple&gt; void kitty(Tuple&amp;&amp; t) { cout &lt;&lt; I &lt;&lt; ": "; meow(get&lt;I&gt;(forward&lt;Tuple&gt;(t))); } template &lt;typename Tuple&gt; void purr(Tuple&amp;&amp; t) { kitty&lt;0&gt;(forward&lt;Tuple&gt;(t)); kitty&lt;1&gt;(forward&lt;Tuple&gt;(t)); kitty&lt;2&gt;(forward&lt;Tuple&gt;(t)); } int main() { int x = 1729; using T3 = tuple&lt;int, int&amp;, int&amp;&amp;&gt;; T3 tup(x, x, move(x)); cout &lt;&lt; "lvalue" &lt;&lt; endl; purr(tup); cout &lt;&lt; endl &lt;&lt; "rvalue" &lt;&lt; endl; purr(T3{x, x, move(x)}); } C:\Temp&gt;cl /EHsc /nologo /W4 /MTd tuple.cpp &amp;&amp; tuple tuple.cpp lvalue 0: int&amp; 1: int&amp; 2: int&amp; rvalue 0: int&amp;&amp; 1: int&amp; 2: int&amp;&amp; For most types, repeatedly saying forward&lt;T&gt;(t) is dangerous (it will move from rvalues on the first occurrence). For pairs and tuples, forwarding to get() is safe, assuming that you access each element once.
This is very small and straightforward implementation. It's good for reference. Please share here after you implement "Add DestroyObservable, CopyObservable and MoveObservable concepts". 
I would argue that we are toeing the line with tuple not being a language type since the structured bindings make it explicitly more powerful than a standard type.
Regardless of how it is implemented, the use count must be available for the lifetime of all shared and weak pointers. Once there are no shared pointers, the object can be deallocated, but the use count must still return `0` while there is a valid weak pointer available. You are conflating the destruction of the managed object with the destruction of the reference counting machinery. The managed object lives only as long as the shared pointer, but the reference counting machinery (normally a control block) must be valid for the lifetime of all shared *and* weak pointers.
I understand it can, but do you have any example where it is useful? 
I think that this is a very interesting proposal. However, I also fail to see other applications of this. In my experience, many of the uses of chained operators are better expressed with variadic template functions anyway. The biggest example is ostream operator&lt;&lt;. I think the way modern format libraries do this with format("Hello {}", name) is better than using &lt;&lt;. I also think concatenate(s1,s2,s3,s4) is clearer than s1 + s2 + s2 + s3 +s4. In addition, it does not help with maybe one of the biggest use cases of expression templates which is using different operators in sequence. An example is fused multiply-add. You would want to do a+b*c as a single fused multiply add. These are my initial thoughts and I know it is much much easier to criticize a proposal than to actually write one. Thanks for taking the time to write this and to post it.
Structured bindings work with any type that specializes `std::tuple_size` et al; `std::tuple` isn't special in this regard.
Say a user defined class of "points" represented as x and y coordinates. Then we can overload + to add p1 + p2 +p3, where p1, p2 and p3 are of type points.
But in this case, you're not going to do it any faster since you still need to add them point per point. There might be some specific optimizations you could do, but compilers will already inline and reorder the additions. It might make sense with matrices, but in this case it would come from parallelism if you have at least 4 elements (add M1 and M2 together and at the same time add M3 and M4), but something like this would be better solved by adding properties like commutativity/associativity to user-defined operators.
A very nicely written article by a man very experienced and learned in C++. And he's right. C++ programs are generally too complex. But you know what - almost all non-trivial programs in any language are to complex. This is because that programmers write them this way. a) They make prototype - looks good b) They start adding to it to make it more complete. c) As it starts to become more complex, the address this by just adding more code. What they should do is say - "Whoa - only now to I understand the real problem, I should redesign this piece of code. But it's too late, it's already shipped, it seems easier to just fix up the original, so the put in a patch and the problem grows by that much. d) Finally there is a real problem in C++ in that nothing is ever removed. So now there are 10 ways to do anything - and no one can know them all. Simple/demo programs are simple in any language - real world programs deal with complicated problems. There are remedies for some of the above: c) Admit upfront that your code is going to be refactored as it evolves. As long as the code is being used, it's not "done". Accept this as a fact of life and be prepared to invest continuing effort to make your code ever better. d) For C++ use the subset which is appropriate to your environment. In practice this means that the organization should adopt some well considered coding standards - there are several worthwhile models available. Also consider making an investment in study of the C++ Guidelines and associated library. This is basically a subset of C++ with which you can do almost anything. If you stick to this you'll have a code base which has less "surface area" and is easier for anyone in the organization to understand and maintain. Finally, value elegance of code in your organization. It's it's not obvious what it does and how it works, it's not really useful. 
&gt; the most progressive You probably don't realize that making a bold clime like this with any substantiation (and in the face of alternatives like [ODB]( https://codesynthesis.com/products/odb/) is actually having the opposite effect -- people will just filter the weasle words out and make a mental note that this is probably a joke. 
Neat idea, but I'm also struggling to think of more situations where this would be genuinely useful than building a string (for which I'd probably prefer interpolated string literals for short arguments and a `format` call for long ones). This could probably be abused even worse than normal operator overloading, but I see that as a problem with the author rather than the language. One thing: In your example, `(rest.size() + ...)` won't compile if the variadic list is empty. Of course, for `std::string`, this won't be an issue (barring some `stdN` implementation that uses only the variadic version instead of also a two-operand version). For the sake of being an example implementation, though, something like `(rest.size() + ... + std::string::size_type{0})` would be more appropriate.
How about adding a 'to_string' function that accepts multiple parameters? Using the operator + for string concatenation is not very good anyway.
Except because of the preprocessor there isn't any reliable way to offer such tool. Being tool-able is a design goal of go, but not of c++, unfortunately.
I see what you mean. That's a real shame
Interesting, I was missing the fact that `get&lt;0&gt;(tuple)` with `tuple&lt;int&amp;&gt;&amp;&amp;` returns an `lvalue`, not `rvalue`. I was expecting your example to print: rvalue 0: int&amp;&amp; 1: int&amp;&amp; 2: int&amp;&amp; Thanks a lot for the clarification
It makes a difference if creating the return value is expensive (e.g., because of memory allocation). With a chain of binary operators, you need to create a new return value for each call of the binary operator. With a variadic implementation, you can create a single return value and accumulate the result there directly. For binary operators, you can somewhat mitigate the issue by having overloads that accept rvalue references as input, so that you can re-use the memory allocated by incoming temporary arguments. However, this is not optimal as you still have to perform some move operations.
It's true that expression templates are more powerful and general than this proposal, but on the other hand they are at odds with generic programming, and increasingly so in C++11 and later. `decltype()`, `auto` and template argument type deduction are all more or less "broken" in the presence of expression templates. It would be fantastic to see a proposal that makes expression templates play better with modern/generic C++, but it looks like a really hard problem to tackle.
Cool idea. But I'm always hesitant to add or modify lookup systems in C++.
(Off topic) I can't change the size on that site. Ctrl+Wheel scrolls the page. It seems to hijack my mouse wheel.
Agreed. The page design makes it rather off-putting.
The complexity mainly because of c++ has no package manager like pip. 
Thank you, it clarifies the mess :)
It worked with my own projects too but seg faults on its own trunk.
**Company:** [ObjectBox](http://objectbox.io) - the fastest mobile database **Type:** Full time **Description:** ObjectBox (Techstars ’17) is a well funded startup that helps app/IoT developers develop faster apps faster by ensuring data is where it is needed when it is needed. The core of this solution is our embedded mobile database which is 10x faster than SQLite. On top of the database, we’re building a data synchronization solution. We are also the team behind the open source projects, which are used by 30% of the top-500 apps on Google Play. Using C++11, you will work on exciting new features for the core ObjectBox database and on scalable data synchronization using the most efficient technologies available. **Location:** Munich, Germany **Remote:** Yes **Visa Sponsorship:** Maybe **Technologies:** C++11, C++14, multi platform Android/iOS/Linux/Mac/Windows, **Contact:** Full info on the [web site](http://objectbox.io/jobs/objectbox-senior-c-plusplus-developer/), or send your CV to join [at] objectbox [dot] io. PM me if you have questions.
I don't think that proposal is comprehensive enough, as it solves only the `auto x = ...` pattern. What about `decltype(a + b)`, for instance?
I (eventually) got it to build in Debug after cleaning up the VS projects a little bit. What command line args did you give it, I want to try?
I haven't actually tried it but looked at the code to get an overview of its inner workings... I'm not sure I like it. Every single analysis it performs seems to be attempting to parse the token list again and again to detect something. Who even needs AST in a static analyzer? Hardcoded manually parsed very fixed syntactic constructions are not well fit for complex programs.
Or, you know, use C++ and operator new, which throws std::bad_alloc...
Built with C++, but not for C++. I get it
You can't at the same time promote a product and discourage us from using it. 
I haven't really looked into it, but I'm highly suspicious just based on the description: &gt; A fast and accurate static analysis solution for C/C++, C#, Lua codes C/C++ is undefined behavior. And how could someone realistically support these 4 very different languages in a static analyzer, which is difficult enough for 1 language? Too ambitious. Does anyone say "codes" in a serious context?
Doing a + b + c where a,b,c are arbitrary precision numbers.
They have a value-flow framework without any control flow sensitive engine. Joins of branches just overwrite the value of whichever line came first with the one that came in last.
No thanks, that is just empty-calories syntax-candy. 
matrices?
&gt; "on our platforms, malloc doesn't return null" No.
&gt; The C++ programmer has to spend a considerable amount of effort to no other end than to make the language work. Bullshit, next time don't hire guys who barely know about the language. &gt; The evolution of C++ is to a noticeable extent driven by the need to deal with the consequences of the incompatibilities and incongruities at the core of the language. Bullshit. 
Care to elaborate on that response?
There is **no way** this function can't leak memory itself...
"If you want to really talk about where an IDE is better, talk about integrated debuggers, not something like renaming.". Wow... Pand9 wasn't even talking about Pros and Cons of IDEs but just had a simple question about vim.
&gt; Does anyone say "codes" in a serious context? May well be a non-native English speaker. GitHub user is from China
&gt; On a typical Linux system, the OOMKiller will get invoked, so your choices are that either your process will be summarily killed, or else something else will be killed to free up memory so your process' allocation can succeed and receive a non-null pointer. And that something else is usually the X server, which pretty much takes down every app you're running interactively.
Having browsed the source a bit, I still have no idea about C# and Lua, I only saw hardcoded token strings and standard library function names of C/C++. [My other comment](https://www.reddit.com/r/cpp/comments/7uia8u/tscancode_static_code_analyser_by_tencent/dtkqcc8/) makes me think this is a joke in terms of static analysis.
I've been just learning about basic data-flow analysis principles and stuff. I was looking for something along the lines also here maybe but instead found all of this crap: https://www.reddit.com/r/cpp/comments/7uia8u/tscancode_static_code_analyser_by_tencent/dtkqcc8/
I can see a use for matrix multiplication, where you might want to multiply them out of order (via associativity) to reduce the total number of scalar multiplications.
On 32 bit windows you can get a null from malloc or nothrow new. Simply allocate more than 3 gigabytes in one go. Or, fragment memory, and request a bigger chunk than your system has contiguous virtual memory. These are ... harder ... on 64 bit systems.
I'm not going to respond to this, it's obvious your problem is not being that familiar with vim. the only bullet point you listed that's actually true is the one about debugging, the rest are flat out wrong. Not wrong as in "that's your opinion and I disagree with it", but wrong as in "you're claiming the clang compiler has difficulty figuring out what symbols exist in the code". 
`malloc(-1)` will return null even on Linux with full overcommit enabled (which isn't the default)
It's an evolutionary algorithm the places and removes random free() in the application and measures the improvement in max runtime before the application crashes! 
It would, however, be nice to be able to write expression templates without having to do a whole pile of obtuse gymnastics. In effect what we want is the ability to be handed a full parse tree of an expression and describe the result at compile time. Imagine if you where handed `A + B * C` somehow, and asked "do you want to rewrite this". If you do so, then C++ uses your code in its place. If you don't, it breaks it down and asks again, except never on a 2 argument case. But where would that code go? Well, the compiler might determine the naive output type of the expression, then ask if there is a faster way to do the expression. Here is a crappy example. Imagine if there are `std::token_t&lt;char&gt;` types for each of the types and a type tag. We attempt to look up `operator expression( tag&lt;result_type&gt;, A&amp;&amp; a, std::token_t&lt;'+'&gt;, B&amp;&amp; b, std::token_t&lt;'*'&gt;, C&amp;&amp; c )`. If it is found then the entire naive `a+b*c` expression is replaced with the code for `operator expression`. This is horrible because there must be a better way to represent the expression tree than a sequence of tokens. A side effect of this is thta `auto r = a+b*c;` is efficient, `decltype(a+b*c)` is correct, `auto s = s1+s2+s3+s4;` can be efficient, etc. It remains backwards compatible (because existing types don't have an `operator expression`, and existing expression templates can be rewritten to use it. 
The point of abstractions is, that you don't have to know how they work. RAII is something you with a lot more cognitive overhead, if you are implementing it yourself, but if you use std containers, you don't have to think about how they work behind the scene. For the most part you can treat them as value types, which simplifies handling a lot (as passing an int or a vector is almost the same). With manual memory allocation, you have to do the work yourself. This in turn means, you have to think about it and make sure to never forget to call free yourself as well as more explicitly track ownership. In languages with garbage collection you very rarely have to care about the GC itself. Most of the time it works okay, only in maybe 10% of all projects you have to tune your allocations and the GC to increase performance or lower memory usage. I don't see, why the cognitive overhead would be the same, if you have to do a lot less caring about the details in the other two cases. Maybe the overhead is about the same, because there are areas beside the memory management in languages other than C, that are worse and in turn balance the overhead? Also is the cognitive overhead in relation to lines of code, time spent or functionality implemented?
Don't argue about something you're not familiar with and you won't be dismissed out of hand. I know you think that just because you have an opinion that it needs to be taken seriously by others, but I don't operate under those ideas. There are **plenty** of things you can criticize vim for, but you listed things that are **factually incorrect**. It is not my responsibility to deal with your ignorance. 
That was the first time I've posted in this thread; assuming I'm ignorant regarding vim is, in fact, terribly ignorant.
Am I reading it wrong or does every call to that function copy the entire std::list&lt;const Token*&gt; "callstack"?
right, it only took a single post before it became obvious.
That's just the very tip of the iceberg.
I'd have liked to see a brief discussion of assignment operators that return something other than reference to "this". Such as those found in std::atomic&lt;&gt; http://en.cppreference.com/w/cpp/atomic/atomic/operator%3D
P.S. Chromium code dosn't contain malloc functions. They are in libraries. I want to note that this is **unacceptable for libraries**. The library does not know where and how it will be used.
To anyone who has used this, do you find that the extra technical debt features are useful? How does its static analysis completeness and detection compare to other FOSS-friendly ones like PVS-Studio or CppCheck (and others, but I can't think of them right now)?
Unless you are writing very specialized applications, you should just crash on OOM. Makes your program much more robust if you can stop worrying about bad_allocs everywhere.
Using malloc in general in libraries is unacceptable or using malloc without checking its return value?
It seems that they have resolved the problem, It works for me :)
It isn't completely uncommon and actually may be proper English. The way we communicate about computer systems changes rapidly, I could use references common when I was in college and have people literally ask me what I'm talking about. It isn't so much a generational thing as rather the field advances very rapidly. It is not unlike suggesting that my first comp-sci classes used Modula 2 and having people ask what is that. Back in the day Object Oriented programming was just coming into the mainstream, today it is often supplemented with tech that frankly I'm not even familiar with.
I'd certainly be interested in giving it a go!
hell yes!
Say I have three matrices, A, B, and C, of floats. `A * (B * C)` may require fewer float multiplications than `(A * B) * C`, even though they give the same result. A variadic `operator *` for a matrix class may be able to do bracket shuffling, since it sees the entire expression, and thus reduce the number of floating point operations.
Ah good point, I forgot that matrices aren't always square.
This sounds extremely useful, even without the git support or anything.
Sure, mate. That could be really useful. 
#For sure
https://www.rust-lang.org/en-US/ /thread
Yeah Rust is a thing
But unique and shared are standard tools already. Would be nice to have their usage simplified as they are the safer technique. Raw pointer should be raw_pointer&lt;&gt; or some such thing.
I was always a big fan of the D `pure` funcitons.
Changing the syntax of `*p` is quite a different proposition than removing it.
These days there no point in trying to figure out whether it's worth it. Just put it up on github. It's much easier to talk about if theres code to look at.
Yes and it was basically created with the intent to be "C++ remastered". You asked a "what if", but it's already been done and has been well received. 
Yeah, I'd rather just remove redundancies and tidy things up than change things. And meneldal is right, at some point it becomes another language, which is not my point. Theoretically you could build a c++::redux by slightly modifying an existing compiler.
Tencent... I've worked with them.. Their code- and really their entire process- is horrible.. So honestly it's not surprising that this analyzer is super sketch We still have a contract with them on another project... I REALLY hope they don't try to slip this thing into future contract negotiations ~Luckily it's not my project :D~
I think this is also a big reason why people want to use Rust. The borrow checker is great, but the package manager makes a huge difference in barrier to entry.
Glad to see there is progress on modules after a couple of quiet months. BTW, on the implementation side, Nathan Sidwell is making steady progress in GCC (see [ChangeLog](https://gcc.gnu.org/viewcvs/gcc/branches/c%2B%2B-modules/ChangeLog.modules?view=log)) and I believe the upcoming VC 15.6 will have many module-related improvements. Sadly, I don't see much progress in Clang (but do correct me if I am wrong on this).
1. how does the compiler know where to find the module? I assume a module file will have to have the same name as the module name. 2. Can the module files get compiled into a special distributable form that is in a standard format that can be used across different compilers and processors? To simplify distribution. 
Interesting. Thank you.
After skimming over the new draft, it seems the major change is the notion of *Reachability* (see 10.7.6). To my understanding this makes sure that when we export a declaration, we don't need to painstakingly (re-)export everything that it mentions. For example: export module M; class base {...}; export class derived: base {...}; void f (base = 123); // Another translation unit: import M; derived d; // Ok, even thought base is not exported. f (); // Ok, even though the argument type is not exported. base b; // Error. I see there is also words/examples about exported using declarations: void f (); export module M; export using ::f; What's not clear is whether this (or another) mechanism can be used to re-export specific declaration: export module M; import M1; // Exports f(). export using ::f; 
1. This is compiler/build-system specific. See this [writeup](https://build2.org/article/cxx-modules-misconceptions.xhtml#build) for details. 2. No, *binary module interfaces* (which is what *module interface units* get compiled to) are compiler specific. In fact, the closer they are to object files, the more performance benefit one would expect, so there contradicting forces here (performance vs portability).
&gt; 1. how does the compiler know where to find the module? I assume a module file will have to have the same name as the module name. A compiler could map module name with filesystem structure, but I wouldn't rely on that. Instead, I'd expect the build system to provide a mapping between module name and BMI files. Also, if you look at GCC's implementation, you'll see that you can provide a wrapper script that will search for BMI on demand. &gt;2. Can the module files get compiled into a special distributable form that is in a standard format that can be used across different compilers and processors? To simplify distribution. No. BMI are not distributable, simply because there are implementations that could not even use BMIs, imagine a compiler server that keeps compilations in memory to cache modules interfaces. No BMI to distribute. Expect compilers to create their own optimized format. However, don't get all your hope lost. There are efforts done to create a generic binary format called IPR, that would allow us to share compiled module interfaces. This format aim to be translatable from and to any specific format. It would serves as an intermediary between specific implementations. I've heard Microsoft is willing to help the open-source community to speed up it's adoption.
&gt; using malloc without checking its return value This. Imagine if you are on a plane that doesn't have malloc null checks.
Imagine being on a plane with a controller that runs out of memory 
For the build / packaging system, we could just declare CMake and pkg-config the standard, since this is already the case on *nix.
&gt; make a standard build/packaging system I don't believe a standardise is required for that. I believe however we are in great need of such wildly used tool. &gt; move allocators out of containers, use a context system? You should look at `pmr` containers. Also, an allocator a template argument make sense (mauve I'm wrong here?), so I don't believe they should be thrown away, but making/using allocators is quite messy indeed. I have no idea what is this context thing. &gt; merge const/constexpr all into one mechanism You know, you should merge your car and your carpet together into one thing since they have similar names. Oh? You tell me constexpr variables are const? Yeah, I got a carpet in my car, so what? The twos are not the same thing, serves different purposes and are used in different context. Just get over the similar names. &gt; unify initialisation syntax Yeah, we got `{}` but the old didn't went away. &gt; remove (most of?) preprocessor That sentence don't need the "most of" ;) &gt; make string/string_view core language feature (somehow) I don't know how that is useful. C++ is powerful enough to implement things that other languages need to make built in. It doesn't mean we should do that too. Well, I could imagine `std::string_view` to be the native type, if I got to pick one, since it's `constexr` and mostly without overhead. But it remains that we don't need it to be native. `"look at that string view."sv` does it look native enough for you? &gt; no implicit type conversions What about implicit constructors? I mean, they are useful sometime. Don't you like to send `foo("potatoes")` to a function that accept a string? And directly send lambda expression in functions that receives a `std::function` &gt; add statement expressions No idea what it is. &gt; add reflection/metaprogramming We got the second, and part of the first. C++ has reflection abilities, like checking for a member, or checking if a type has a specific function, or even validate expression for a particular type. The only thing we miss is listing stuff by querying, like listing members, listing member types, types in a namespace. And we need a way to obtain names from entities, Wich is quite hard to do today. Note that we can already make a list of only one thing, and it's of parameters a function takes. You can extract then by taking a pointer and a the type, for example to iterate on the parameters or doing stuff with the return type. You can even do that on function templates. &gt; make &lt;cstdint&gt; primitive types Agreed. &gt; remove typedef, add strong aliases I hope you're not talking about removing type aliases altogether, because then I will be sad and a large portion of my codebase is doomed. I find type aliases (and alias templates) quite useful. --- Too lazy for the other bullets. I wrote enough. 
Yes. He said "when I fed itself" in the OP. It segfaults for me as well on lib/checktscnullpointer2.cpp, at least.
I am promoting discouragement!
 --enable=all --quiet
Noooooooo! ... I mean: **Yes!**
Software on the plane should not use dynamic memory at all.
It's great to get rid of these include files, but there's still no standard way to tell the compiler the mapping between modules and libraries to link with. So in the end we are still stuck with builds systems that will require manual description of the dependencies (which could be considered as implicit by the module import), or that will more or less precisely parse the source, to detect which modules are required... what a shame when you see how easy it can be to manage dependencies with other programming languages. At least, Clang old implementation was offering a way to add custom compile-time flags (such as -l&lt;library&gt;) for a given module... 
UB detected in line `1`: `Noooooooo!` Did you mean `Yes!`?
Delicious syntax sugar.
I just checked, this trivial program reliably produces `terminate called after throwing an instance of 'std::bad_alloc'`: #include &lt;vector&gt; int main() { std::vector&lt;int&gt; v; while (true) { v.push_back(42); } } 
&gt; but it should still be C++ Let's name it ++C. &gt; remove typedef, add strong aliases `alias` keyword pls &gt; unify references/pointers/etc (optional ref?) I don't think so. Both have their place. What I would do instead is to **get rid of C declaration** syntax. So `int* p1, p2` truly works and the fight with C right-side asterisks like in `const char *c` will be over.
But by using modules people would not break away from the interface/implementation separation. An interface should be automatically created by the compiler. 
Ok, so it's the only way. There is no specific operator to do this?
You missed the most important one: concepts. Besides auto type deduction, C++ has been crying out for concepts from the beginning. Other than that, metaclasses. Reflection and metaprogramming doesn't quite cut it when it comes to generating programming structure.
I actually think it's good that smart pointers are not so easy to use as managed languages. They're not merely memory management: they say a lot about the design of a programming because they imply an ownership pattern. Declaring variables on the stack should be the reasonable default, not smart pointers.
Not that I know of. What could you do with that that you can't do with a scope or a heap variable?
&gt; have an `import` resolved all the way to a package that is automatically downloaded and built by the package manager I think Go demonstrates quite nicely why this is only a good idea in theory. Namely the inability to reference a specific version of a package. And if special syntax is introduced (i.e. `import libfoo( &gt;1.2.3 );`) then that's just moving information out of some `package.json` file, or what have you, into the code which means you now have to parse all of the source files just to find the dependencies.
Is this the current full specification for modules?
What does it mean to delete a stack variable? Stack is a memory location assigned by your OS that grows down. Your compiler is responsible of growing *stack pointer* down every time you enter a new scope, and grow it up once you exit that scope. Nothing on stack is ever deleted (except by your OS for security reasons, it zeroes it out once your process is killed). If you wanna move your stack pointer up you can either exit that scope (using braces) or use inline assembly or something. Also, C and C++ standards do not talk about "stack" so your compiler can do literally whatever it wants when it comes to "stack". Stack is more of a systems/OS concept than C++ concept.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7uq64g/can_you_delete_stack_variable/dtmatap/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
the standard would have to be as cross platform as c++ itself.
These are the latest proposed changes to the C++ standard, so if you can infer the semantics, intended use, etc., from that, then it's all you should need. For the rest of us there is "A Module System for C++" ([P0142R0](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0142r0.pdf)) which is the design document. Note, however, some of it is outdated compared to the latest proposal. CppCon 2017 had two talks ([one](https://youtu.be/E8EbDcLQAoc) my myself, the [second](https://youtu.be/E8EbDcLQAoc) by Nathan Sidwell) on modules which could be good introduction. Most of the things covered in my talk are also available in [Modules Introdution](https://build2.org/build2/doc/build2-build-system-manual.xhtml#cxx-modules-intro) which is part of the `build2` documentation.
Turn the scope resolution `::` and arrow `-&gt;` operators into `.`
That looks amazing!
Like reflection and concepts this is 10 years away.
wstring support anytime soon?
What does `std::unique_ptr&lt;Foo&gt;{}.get()` do? Does it call `std::unique_ptr&lt;Foo&gt;::get()` or `Foo::get()`?
An proper ABI please.
Well, IMHO packaging management is another story and can be solved externally. Header files or module files are for example expected to be found in a unspecified manner, but they are looked up by name by the compiler. Toolchains usually rely on search paths and standard installation locations for this, and the build system doesn't need to actually know which header is included by the translation unit (it only needs it to figure out what needs to be recompiled and what isn't whenever a file changes but that's an optimization). As long as everything is in the expected location (default and implicit search paths, etc...) you can compile a single translation unit to an object without any additional flag. If you want to use prebuilt modules however, it will not work unless you pass the required library to link with to the compiler command-line, in a non-portable way. This is IMHO a big flaw and should work the same way as header files: look up the module by name and find in some unspecified way the the function definitions to import in the produced binary. Then, like for header files, compiler vendors would be free to allow control over these mechanisms but it would also allow to compile complete C++ programs with prebuilt modules and library without any additional setup as long as everything is available in the default locations. The only solution right now to achieve this is to use header-only libraries everywhere...
- All UDTs and arrays borrow a view on entry into a call chain by default, and move when returned by a call chain by default. Only integral types copy by default. Copying is always explicit for UDTs and arrays. - The `template` keyword is banned from the language as one of the worst design decisions (in hindsight) in C++. - constexpr should be default on for everything it's possible for (still not sure why it isn't anyway actually). - https://github.com/ldionne/dyno but implemented into the language, not via a library. - Ranges, rather than iterators. - I'd even entertain some borrow checking, though I find Rust's too severe, it makes refactoring a large codebase unnecessarily hard. - Lambdas and inline functions should be coroutines by default. Otherwise I'm in fair agreement with your list above, though for me retaining perfect compatibility with C17 and "C++ 1.0" is a red line item. Any "C++ 2.0" is perfectly doable with source compatibility with both, just tag a namespace with what variant of C++ it is. 
&gt; Yeah, we got {} but the old didn't went away. Except, {} is not a uniform initialization mechanism because of the broken clusterfuck that is `std::initializer_list`. In generic code, you're better off using good ol' () for initializing objects. It's actually ridiculous how poorly thought-out `std::initializer_list` is. Not only does it completely foil the purpose of uniform initialization for generic types, it's not even viable in its intended use case that is initializing container types, because it doesn't allow you to move elements out of it. This makes it impossible to use for move-only types and entails subpar performance for copyable types, as [every single element is unnecessarily copied](http://coliru.stacked-crooked.com/a/1d4fd3025a899d13). If you're writing a container type, don't touch `std::initializer_list` with a 10 foot pole but instead use variadic templates and forwarding references.
&gt; The template keyword is banned from the language as one of the worst design decisions (in hindsight) in C++. How do you implement `std::array` without `template`?
Code posted at my gh profile here: https://github.com/rasjani/processcdb - its not clean and beautiful but once up and running - works like a charm :D 
There are lots of ways of implementing genericity which don't involve `template&lt;class X&gt; ...`. D has plenty of good ideas, as does Rust. Off the top of my head, for `std::array` a simple `struct array&lt;auto T&gt; { ... };` would do nicely (and is proposed for an upcoming C++ standard).
https://cppdepend.com/blog/
You are describing how things could work for a simple case which doesn't scale to any even remotely real-world projects. Take this gem for example: &gt; the build system doesn't need to actually know which header is included by the translation unit (it only needs it to figure out what needs to be recompiled and what isn't whenever a file changes but that's an optimization). 
My bad for not reading correctly. Thanks. 
And all for a feature that isn't really used outside of trivial or academic code. Most real systems get their data externally so they don't initialize containers like that. Occasionally yes, but we already have arrays for that if we need. std::array&lt;int, 5&gt; ints = {1,2,3,3,4}; std::vector&lt;int&gt; vints(ints.begin(), ints.end()); This has one extra line over initializer list. Ya, it's not ideal, but damn, initializer list is so bad I almost feel like it should be removed. 
Except for the recompilation optimization, I'm pretty sure that what I describe scales very well to a class of real world projects. Generated sources are useful sometimes but you can very well live without it in many cases, even for "large scale projects". OTOH, it is true that generated configuration headers are very common, but it's another issue that C++ needs to address in order to be a standalone programming language. And it is being addressed with the introduction of __has_include, feature test macros, etc. Going back to the recompilation optimization, (almost?) every compiler has included a way to extract the list of header files being included in order to help build systems to track dependencies. I hope there will be the same kind of thing for modules, but in the end if every one implements it maybe this means it should be part of the language / specification somehow.
The only json lib I've used and will use. It's just absolutely the best. So thank you for making it, dude. 
&gt; Lambdas and inline functions should be coroutines by default. Just because something is a lambda or an inline function doesn't mean I want it to run asynchronously.
No please
I think the only reason it isn't is that references didn't exist in c++ when `this` was added.
Can't stop looking at if ( action == 2 ) break; :)
The news here is that WG21 approved the Module TS, and directed the Convener to transmit the document to ISO for publication. This draft is an identical copy of that document to be published by ISO.
What's the full rebuild performance like? Are Windows and OpenGL imported as modules? Can you get clang to give a report on parsing and template instantiation timings?
And why did you post a screenshot of your code, which btw is all but C++17?
The `::` in `::f` always designates the global scope. There is no provision to quality a name by a module name.
&gt; Yes and it was basically created with the intent to be "C++ remastered" No. That was D. Rust didn't "remaster" anything. It had a few innovative ideas and did it's own thing keeping C-style syntax (i.e. `{}`).
This is black magic!
Oh that's really great news! Thanks for reporting that!
Rebuild performance has improved, I'll put timings up on a blog post about it later this week.
One of the NB comments (GB 076) asked to relax the restriction on exported declarations mentioning non-exported entities. I consider that a simplification of the original spec. However, accepting that comment turned out to be "fun" -- the main reason for the "quiet month". One needs to ensure that the vision of the module interface is coherent and logically consistent. That is when the "attendant entities" come in. Exported using-declarations were expected to work out of the box, but it turns out that the original spec used the word "entities" as opposed to "declarations" so it accidentally/erroneously restricted the applicability. There was also a disagreement in interpretation of how linkage works for using-declaration, so we decided to explicitly spell that out to avoid conflicting interpretation. That is what you see in the new wording. Not a design change. &gt;What's not clear is whether this (or another) mechanism can be used to re-export specific declaration: Yes, the existing exported using-declaration works for that; no new mechanism is needed. All of this follows from the base document (C++17) semantics. &gt;And, BTW, is `::` qualification really necessary? Yes, the existing base document (C++17) requires a qualified name in using-declaration. There is a module issue for looking at whether to relax that requirement.
The codes hardly the point, I'm not sure if you can tell but not much is happening in that picture other than a simple loop... Oh and importing of modules...
In non-module C or C++ world, there is no such mapping either... However, I am not stopping there. I believe it is an issue that is best dealt with outside the language itself. However, I am of the opinion that there ought to be some form of standard notation to handle that; that is why I would like to see the newly created Tooling Study Group to look into that. That is a forum where I expect tool builders to come together to chart a common standard practice.
Great lib, I use it all the time. I have one ask though: Next time you do a breaking version upgrade could you make sure it..erm..breaks code ;) I forget what it was now, but you changed something in 3.0 that would still compile but worked differently. Can go back and look through my commit logs if helpful.
Specialization of basic_json doesn't work?
These are all excellent points. They underscore why handling the issue should be outside the language itself, but we should chart guidance for standard common practice. I am placing my hope on the new Tooling SG to help here.
Well apart from: - raw new/delete - global pointer referring to a singleton? Wtf? - return 1 ...? Why? - ...
Yes, this document is an identical copy of the Module TS as sent to ISO for publication. I am working on a couple of documents, tutorial and updated design documentation. Time is the critical resource here :-/
Building with just a single changed file would be good to know too. If only I knew where to find this blog.
Use what you want, but I fail to see how this screenshot is contributing to this post in a meaningful way. It’s literally just „Hey, I used modules“. Not trying to be an asshole or something. Also: the imgur screenshot is not readable.
Been using this awhile. What a nice library. Thanks for keeping it up.
This is known as the injected-class-name. It's mostly used in template classes so that you don't have to repeat the template parameter list every time. Also, if you have another entity with the same name as the class, without the injected class name you would refer to that entity, and not the class.
Thanks! Once one knows the name of it, it's easy to find a tonne of answers. Interestingly the [first StackOverflow result](https://stackoverflow.com/questions/25549652/why-is-there-an-injected-class-name) for "injected class name" was last edited by you!
I remember I read this in the release. It was warned that it threw its own exceptions if I recall correctly.
You failed
Haha ya, just built a new PC and haven't activated yet.
Great, thanks for clarifying this.
Nice to hear that there is a at least an improvement feeling, I am waiting your blog post!
A great library I loved to use in production code - and I've seen a lot of really bad JSON libraries.
I remember that in 2016 there was a presentation about having modules with legacy support for macros, e.g. making it easier for the industry to move into the module world: https://www.youtube.com/watch?time_continue=2264&amp;v=h1E-XyxqJRE I don't see any of that in the TS. Also I have never seen Gabi to address this work on stage as far as I can remember. I know its not the pure concept how MS planned modules should work. So has this been addressed and resolved with Richard Smith and clang? Or are we again all over stuck in a situation like concepts, where at the end the committee blocking the adoption because of unresolved or unaddressed issues?
I am sure Gabi himself will address this, but FWIW, I've written an article called "Common C++ Modules TS Misconceptions" and one of the items there is [*I cannot export macros from modules*](https://build2.org/article/cxx-modules-misconceptions.xhtml#macros). Maybe it will answer your question.
Yes, I think simplicity and ease of use are lacking in a lot of C++ libraries. We need more like this.
Here is a small video showing some edits in a few modules. https://youtu.be/dcJ8rOOX2Wg
You really should abandon new and use `make_unique` and `unique_ptr`... there's precisely zero overhead compared to new but you never get a double-free, use-after-free, or missed delete again!
I don't use new, I have my own resource manager that uses unique_ptrs. The new = window you see in the pic is old code that I forgot to move over, I don't touch the loop script very often. The new wchar is just something I grabbed from the gfe sdk example, so I could test it.
I wasn't going to comment on the char/string stuff because it looked like interfacing with an external api, which is always horrid...
Please **No**. The problem of all Make/CMake/... is that in order to capture market shares, they attempt to cater to every single usecase. It's a rather obvious strategy, people are more likely to adopt a tool if they can just use it on their current repository of code without any other change. It's a disaster. Have you ever used Maven? I really don't like the tool itself, or the XML files, but it did get something right: **convention over configuration**. So, for example, in C++ this would result in: lib/ foo/ include/ foo/ sub_0/ public_sub_header_0.hpp public_header_0.hpp public_header_1.hpp src/ sub_0/ private_sub_header_0.hpp src_sub_0.cpp private_header_0.hpp private_header_1.hpp src_0.cpp src_1.cpp test/ unittest/ ... And then I'd say: `LIBRARY(foo)`, and the build system would know: - that `lib/foo/include/` need be packaged when delivering the library, it's got the API! - that headers in `lib/foo/src/` are NOT to be packaged, they are private. - that there is one object file to be built for each `.cpp` file in `lib/foo/src/`. - that all the objects files from `lib/foo/src/` need be built in a `libfoo.&lt;version&gt;.a` (or a `libfoo.&lt;version&gt;.so` if dynamic linking is asked for). - that a separate test binary need be prepared for each directory in `lib/foo/test/`, and that they will need to link against `libfoo` (and its dependencies). **Magic!** --- There is *no need* to support: - arbitrary directory layout, - arbitrary cherry-picking of source files to be built into a library/binary, - arbitrary cherry-picking of include paths, - ... However, today's tools go out of their way to support this to gain traction, and the result is horrifying :( --- Not trusting me yet? Read [this "makefile"](https://github.com/rust-lang/regex/blob/master/Cargo.toml), and imagine how complicated the equivalent CMakeLists.txt would end up being. 
No it does not address it. Some very smart people deemed it important enough to present such a thing at CppCon in 2016. Back then it looked like a very good solution, based on a actual existing modules implementation. And it seemed to be tailored towards the work in Modules Gaby has done. So I'd like to know, if this has been addressed in the committee, or just rejected.
Also the "Hey, I used modules" is the exact thing I'm doing here, it's really the whole point of this post. I think it's a pretty big deal, as I know of no other game engine or project of this size that uses modules. I know it's experimental, but so is my engine.
To be fair a lot of this simplicity is often a direct biproduct of the language evolving. Don't want to blame older libraries for being old ;)
Really enjoy working with this library ;) 
That can easily be replaced with auto pathName = std::wstring(reinterpret_cast&lt;wchar_t*&gt;(argv[0]);
Support for exporting macros has never been part of the scope of this TS, and we have been clear and upfront about that. EWG took several polls on that, including during NB comments resolution. What we did say is that we will be working on finding a resolution (and we have been!) to the macro question, partly based on the experience in the field with the Module TS. It will take some time, and work, before we reach a full resolution. It should also be noted that as more and more people become familiar with the design, the specification, and the various ideas around migration paths, people’s understanding and positions have also evolve. And that is a good thing in general for the C++ community. It is really super helpful that people are updating their understand and views. Also, there is nothing “pure” about the design I’m suggesting — this is C++ we are dealing; we just want to ensure that we don’t shoot ourselves in the foot big time in the precipitation of addressing macro-ladden code. Finally, this effort isn’t “Microsoft modules”. I would have made the same suggestions had my employer been Google, Facebook, Red Hat, Apple, you name it. I am sure you heard me say that before. This is an effort for the C++ community. 
yeah it was mentioned in the release notes.
wstring/wchar_t is an unportable piece of shit. A big fail.
I totally agree, there is allot about Windows programming that I don't like haha.
Regardless of the points you're trying to make, please don't use slurs.
So you say that this will be addressed after the TS? I just try do figure out if we head towards Modules being for C++20 what concept ended up being for C++17... ... which would be really bad.
&gt; So you say that this will be addressed after the TS? Yes, as I said earlier, this (and other issues) will be addressed one way or the other. There are a few ideas; I know of at least one person writing a paper for the Jacksonville meeting. &gt; ...concept ended up being for C++17... I worked on concepts from start to finish (for the last two decades) and I don't recognize what is usually portrayed on The Internet. It is hard to know exactly what specific event you are referring to.
I refer to the committee in Jacksonville choosing to reject concepts for C++17. While for some people this seemed to come out of the blue, I hear others saying you could see that coming from miles away. 
If you used CMake you can create a compile_commands.json and feed that into cppcheck to easily create an analysis target
abs_time is an absolute point in time. Why would you want to adjust it?
You're right. I misread the code. For some reason I thought it was relative.
Didn't C++ break backwards compatibility with C?
How does this compare to RapidJson speed wise?
Thanks, really useful talk! I'll definitely change some things to make it safer for more scenarios. So if I don't care too much about thread safety and don't want to have to use multiple threads, would you say that something similar to FooC (the last example before you started talking about threads) is good enough? You mentioned something about it not working recursively, did you mean if notify is called recursively from the observers?
How are you using standard library modules with Clang?
I just include the stl headers I want in the std.core module and then I import that module when needed.
All of what you criticize is necessary for more complicated projects with multiple libraries and executables. And they really don't make CMake files that complicated if you are building a single executable / library project.
What would I do if I wanted f to be only visible inside the module?
string_view doesn't have lifetime extension, so it's a lot more dangerous than references (same is true for all view classes). There's a lot of things that are unique about strings that make it non-trivial to say "C++ can support that as a library" and call it a day. We're desperately in need of compile time strings (necessary for reflection as well); the ideal implementation of this is probably allowing templating by value for a string-like type. Templating on a value is only allowed for built ins (integer like types, and pointers).
I'd say we need constexpr function parameter, that would (implicitly) translate into some kind of template parameter, but taking its value from the value sent in the function arguments. Imagine that: void foo(constexpr std::size_t s) { std::array&lt;int, s&gt; a; // ok, s is a compile time constant } int main() { foo(6); // yay! Works. int n{}; foo(n); // error, n is not a compile time constant } That + extending what type a template parameter can be would be awesome. For the lifetime extension: there should be a mechanism to deal with lifetime extension, whether a explicit or implicit one. That would be really great.
Can you give an example of something that could not easily be done by reflection + CRTP? I've seen very few such examples. There are some that perhaps involve being able to overload operator `.`, which was on the table at some point, and I'd much prefer to see added to the standard. I think metaclasses is a really huge amount of complexity for minor benefit.
I mean, `constexpr` is very deliberately chosen not to behave that way, it's supposed to be usable with runtime values. But ultimately what you're suggesting is exactly equivalent to template parameters by value on UDTs. Which is one way to go, yes. But it's a very big change, and I honestly can't really ever remember people demanding this. Whereas the compile time string is a really huge problem, it's not solved, and it has to be solved in order to get good reflection.
Could you plese provide some resources or books for the topics you mentioned above. I would like to learn more about all this... &gt;Will understanding shared memory, native threading, memory ordering, optimizing, working with "fundamental" algorithms (e.g. stuff like partition and sort rather than stuff like map, filter, reduce), zero-cost abstraction, handling computations using simd... etc, help you in most projects ? No, not even in most C++ projects. 
https://github.com/miloyip/nativejson-benchmark/blob/master/README.md
To be fair, you have to have a very high IQ to understand UTF-8 Everywhere Manifesto. The humour is extremely subtle, and without a solid grasp of theoretical physics most of the jokes will go over a typical reader’s head. There’s also UCS-2’s nihilistic outlook, which is deftly woven into his characterisation- his personal philosophy draws heavily from Narodnaya Volya literature, for instance. The fans understand this stuff; they have the intellectual capacity to truly appreciate the depths of these jokes, to realise that they’re not just funny- they say something deep about LIFE. As a consequence people who dislike UTF-8 Everywhere Manifesto truly ARE idiots- of course they wouldn’t appreciate, for instance, the humour in UTF-8’s existential catchphrase *“std::string and char* variables are considered UTF-8, anywhere in the program.,”* which itself is a cryptic reference to Turgenev’s Russian epic Fathers and Sons. I’m smirking right now just imagining one of those addlepated simpletons scratching their heads in confusion as Dan Harmon’s genius wit unfolds itself on their television screens. What fools.. how I pity them. 😂 And yes, by the way, i DO have a UTF-8 Everywhere tattoo. And no, you cannot see it. It’s for the ladies’ eyes only- and even then they have to demonstrate that they’re within 5 IQ points of my own (preferably lower) beforehand. Nothin personnel kid 😎
"This video is unavailable" in WinXP &amp; Linux Firefox.
Part of my work actually borrows from that project and it was main influence for what I needed when writing this. At the time codechecker didn’t work for us and this was written to fill the gap.
Oh! Thank you! It turns out I already compared these! I'm currently using rj for stop-the-world quicksaves/quickloads in a game so performance is important.
Hm that's wierd, works on two different devices for me, I have it is unlisted but not private... I'll put it on Vimeo and update the link.
One little change I'd like to make is rename `unsigned` and `signed` to `logical` and `arithmetic`, on that note I'd make `size_t` an `arithmetic long`
It's pretty much the standard for high quality/performance AAA titles. /r/gamedev and google should be able to tell you more. ^_^
A great suggestion
Would you restrict arithemetic ops on logical types?
Delete this and spend five minutes on Google please.
It's tempting, but ultimately no, this change would be completely cosmetic. My rational is that when programmers want their interface to say something cannot be negative, they put `unsigned` on the value, but this often leads to other subtle bugs. It also makes it difficult to test that negative values aren't returned, as if it does somehow return a negative value, it will be converted to a very large unsigned value.
No.
That may be an issue for embedded programmers though. C++ is not and should not be just a higher level x86 language.
docker *for the rescue*
Yeah docker is amazing, but my response was to the suggestion that distro package mangers obviate the need for another solution.
That's what stuff like [this](http://preshing.com/20180116/a-primitive-reflection-system-in-cpp-part-1/) is for. Metaclasses will be nice.
Since you already have experience with Java, most concepts (classes, generics, etc.)t ranslate to C++, with a few exceptions: - Value-based semantics is used much more heavily in C++. In Java, when you have a `class` type, you must `new` it to instantiate it. Not so in C++ - Consequently, focus on RAII. (Destructors correspond to Java's try-with-resources, *except* that they run on scope exit.) - For dynamic allocation, learn about ownership models (`unique_ptr`, `shared_ptr`) - Learn about the ideas in STL (containers, algorithms, iterators) - C++ templates are at the same time both more powerful than Java generics, and less powerful (you cannot constrain them) 
Unless you plan on working on AAA games from the start, it's better to build up a skill in Unity and C#, as that is the de facto standard for small to medium games right now. Cpp is used almost exclusively by large companies for in-house engines or things like Unreal and CryEngine.
Some things, like zero cost abstractions, are more of a "concept" rather than a "thing" you can learn, others are very in depth topics which would be hard to cover in a single talk/book. * For understanding some fundamentals about CPU/memory I recommend: a book called "What every programmer should know about memory": https://people.freebsd.org/~lstewart/articles/cpumemory.pdf For a more software centered look at multi threading (e.g. how memory ordering works and what are the threading fundamentals on a POSIX system), I recommend the book called "C++ Concurrency in Action" (https://www.manning.com/books/c-plus-plus-concurrency-in-action-second-edition). * If you can get the second edition do so, otherwise the first should do. Whilst it's C++ focused, I find it to be very language neutral, since it deals with rather "low level" concepts, so the knowledge inside can be applied to any programming language if you want to optimize your parallel and/or concurrent software. * For learning more about algorithms in general, some chapters of TAOCP may do, there's so many books dealing with data structures and algorithm and I never had a favorite one, so, pick and chose. Maybe look at some implementations of basic algorithms or data structures in Rust/C Stuff like * Zero cost abstractions and single instruction multiple data are more language/API specific tools rather than concepts you can learn. Here's a good example of a SIMD library you can play around with and is very easy to use: https://github.com/AdamNiederer/faster (Note, this is a CPU library, once you get to GPUs things get even crazier and you may want to look into a book about physics engine design or math library design). Zero cost abstractions are the idea of having an abstraction that resolves at compile time (and is checked at compile time) in order for the code to be safer and faster. Depending on the language you know or wish to learn, C++'s metaprograming and Haskell's Type Deduction system are two good examples of zero cost abstractions that can accomplish crazy thing, but there's hundreds of good examples here. But those are just recommendations, I work as a data scientist, not as a low level systems programmer, so my knowledge of most of those subjects is shallow.
Here's a quick talk on "C++ for Java Developers". I normally wouldn't recommend a talk for a crash course, but this is actually quite useful. https://www.youtube.com/watch?v=i9TWNlj0I6A
I, for one, applaud the existence of the Tooling Study Group, and in particular its goal of "Commonly agreed up way to describe C++ components for build systems". Presumably what you meant with this is a meta-language that build systems can draw on to automatically download, update, build, and inject (into projects) external libraries? Because that appears to be the major missing link in C++ development these days... 
&gt; Also, an allocator a template argument make sense (mauve I'm wrong here?) The `pmr` approach is the right one IMO, and container allocators will still be a little bit fucked in C++ for a long time because `pmr` is not the default. People will use `std::vector` instead of `std::pmr::vector` by default and write a bunch of code, and then when they go to customize allocators, now a bunch of declarations have to change. Or they have to convert a bunch of functions into function templates so they can take either flavor. What's a real-world use case for allocators as a template parameter? &gt; I have no idea what is this context thing. The context thing is where the default global allocator is a context that you can change within a lexical scope. Like memory arenas, but it's a context and therefore implicit so you don't have to pass the arena around reference around to every little function that might allocate. The context is typically threadlocal. Containers save a reference to the allocator in the context they were created in so destruction works correctly. A good demonstration of usefulness is to push a linear allocator to the context, run a bunch of high level functional code featuring plenty of type erasure and container resizes, popping the allocator context and freeing all that scratch memory in one go. &gt; The only thing we miss is listing stuff by querying, like listing members, listing member types, types in a namespace. And we need a way to obtain names from entities, Wich is quite hard to do today. That's the biggest thing IMO. Way bigger than the metaprogramming with type_traits that C++ currently supports. Having this would make tens of thousands of lines of code redundant at work at a minimum :'( &gt; What about implicit constructors? I mean, they are useful sometime. Don't you like to send foo("potatoes") to a function that accept a string? And directly send lambda expression in functions that receives a std::function I agree, but explicit should be the default, right? C# does it this way and it works pretty well. The current situation in C++ conflates construction and implicit conversion. &gt; I hope you're not talking about removing type aliases altogether, because then I will be sad and a large portion of my codebase is doomed. I find type aliases (and alias templates) quite useful. What do you use them primarily for? Naming types without mentioning their template parameters?
Thanks for your response :) I’ll consider this
Thanks! Ok!
You can constrain the templates, it's just rather ugly, especially without any sort of concepts library. That said, more proper constraining is part of the C++20 WD.
&gt; get rid of C declaration syntax If it's not C compatible, then it's really not C++, it's just a different language.
The annoying bit is the missing intellisense support
Well, your headline also says your engine uses c++17. No wonder people looking for 17 features in the code you post (I'm aware this code is not part of your engine still...)
Sure, I'd also be interested in that. When I first saw the talk, I took the adoption of the paper more or less for granted and was pleasantly surprised when it wasn't. I've no doubt, that they talk to each other, but it would be interesting, what the committees response to those proposals was.
Did you even read the post? He said "without worrying about backwards compatibility".
I assumed he meant C++ backwards compatibility. C backwards compatibility is a core tenet of C++. 
We used semantic version from the start to whether a new version is backward-compatible, and the release notes (https://github.com/nlohmann/json/releases/tag/v3.0.0) for 3.0.0 were quite explicit: &gt; As we adhere to semantic versioning, this means the release includes some breaking changes, so please read the next section carefully before you update.
Am I reading the part about attendant entities right, that if I'm exporting a class A that has a data member of type B, I'm also exporting class B, even if it is private?
I'm stupid. Why is the preprocessor bad? Can't you use it to add code that exists to do slower but more rigorous checks in debug builds, but doesn't exist in release builds? I know you can do funky weird stuff with it too but I often miss it in other languages. I'm conscious that all my checking will still be there in release builds, when the code should theoretically have been tested enough to not fall over in 99.9% of those places anyway.
*a lot
What's "concepts"? Googling "programming concepts" doesn't help.
&gt; The second (induce by the first) is that the my_string_view 'path' is converted to 'std::string' without begin construct beforehand 1. `my_string_view` is being constructed in `to_my_string_view` 2. it's never cast back to `std::string`
This code shouldn't compile under any compliant compiler. You're using `size_t`, `printf`, `std::string`, yet you've yet to include/define any of those. It could be assumed for the first two, that you meant to use `std::size_t` and `std::printf`.
I'll assume you are good at Java. Like, you hack bytecode sometimes. Jsva/C++ diff: * C++ adores actual values. `std::function` is a polymorphic non-inheritance based value type and in modern C++ is a fundamental piece of vocabulary. Few languages have anything similar. Used properly you get a 2 to 5x speedup and entire classes of problems evaporate. * C++ templates generate new, unrelated types and functions. Generics look similar to templates, and can solve some similar problems, but the details of how they work is vastly different. * C++ requires that you treat memory and all object lifetime like resources. In Java you might have to jump through hoops to carefully control and not lose track of the lifetime of an open file. In C++ this is true of every object and memory allocation. However,mthis means destructors are deterministic, which gives us RAII. And value types (see above) make reasoning about object resource lifetime easy. * ADL/Kornig lookup allows powerful compile time dispatch and customization. * C++ mixes procedural, OO, functional, structured and many other language types. There are people who program C++ in alien ways to each other. As a Java programmer you'll have a bias toward OO; realize it and correct for it. * As a C++ programmer, I take inspiration from python procedural code to think about how I can make C++ procedural code more elegant. With a bit of elbow grease I can often take a slick python style comprehension or the like and translate it to C++: I am usually forced to write the "background" machinery that python provides. But as a bonus, if I write it right, I can strip out abstraction overhead. * C++ compilers, when not blocked by hard interfaces, can do crazy magic optimizations. This takes compile time and can couple code in awkward ways, so consider where to put interfaces from an optimization standpoint. Both inserting an interface and removing it can help. * C++ sometimes feels like you are interacting with raw hardware; this is a useful lie. C++ is specified in terms of an abstract machine; when violating its type system you must be aware of that abstract machine and nit just "what works in practice" or things can non-deterministically explode. On the other hand, thinking about the raw hardware is illuminating when thinking about how to improve your C++. * modern C++ (post C++11) is a different, yet reverse compatibble, language to classic C++. If you see `new` (without a scope operator, ie `::new`) in some code it is classic C++, even if it uses some C++11. Learn the rule of 3/5/0. Learn what it means to move and forward. Learn unique ptr. Be wary of shared ptr; it may feel familiar and cozy like Java gc, but it is not: it is shared ownership, a complex kind of lifetime management made verly slightly safer by a helper type. You should rarely use it, because it *seems* to work, but makes understanding lifetimes globally harder, and does not solve the hard problems that eventually result. 
It's more of a bug in the standard. See [CWG 2220](http://wg21.link/CWG2220). Though you should see warnings if you use the `/W4` compiler option.
If I understand you, it means that my "printf" should never be called. And it is called. That's why I suppose it's a bug.
ok, thanks !
try "C++ concepts"
you don’t export it.
Yes, that is among the things I would love the new SG to look into, to help the C++ community.
Yes, the Tooling SG was created after the last meeting (Albuquerque, November 2017), and slightly before the Xmas break. It hasn’t had its first face-to-face meeting yet.
I was talking about the first example by berium, where f is not exported but can still be used in the other module.
Thanks for the explanation!
C++ is not backward compatible with C as it is possible to exists valid C code that cannot be compiled by C++ compiler.
While that's true, it's still compatible with nearly all C code and that's a major benefit of the language and something it was designed around.
That's why I already said: &gt; Sure there are a few things here and there, but massively breaking C compatibility is a no-go for C++. 
[do you know the internet exists?](http://lmgtfy.com/?q=sigsegv)
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7uwzy7/what_is_the_best_resource_free_and_paid_to_get_a/dto6kvm/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7uyifi/visual_studio_2015_compiler_bug_how_do_i_know_if/dto6l4w/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Ah, I think that example has a typo: the `f` must have been exported.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7uyryn/what_is_sigsegv_error_in_c/dto6lfe/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Yes, corrected.
Hopefully all uses of preprocessor will be replaced by specific mechanisms (modules, inline functions, constexpr if, etc.)
Compilation times, single header was turn off, now things getting interesting. I'll make a switch 
To be fair, there are plenty of indie games made with C++ as well. You can make your own engine pretty quickly using a base opengl framework like SFML and the like.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7v024b/need_help_working_through_a_problem/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
100%, Hopefully Visual studio can get that in there this year, it seems almost every minor release has some modules progress and they've mentioned they would work on the intellisense(ide features) next I believe.
Wow. Thanks a lot for this detailed reply. Will bookmark and go through all this books, references and links. Eventhough i work for 5+ years now in system programming i think there a ocean (sea) of information to grasp and understand.... Thanks.... 
Got a better suggestion?
How would you write this: template &lt;typename&gt; struct Foo {}; template &lt;typename R, typename... Args&gt; struct Foo&lt;R(Args...)&gt; {};
It prevents you organizing your libraries and executables into a structure, or using the same files in multiple products. And you can always write a CMake file that uses the directory structure to define the outputs and use itfor your projects. When you said you want recursive dependencies (by which I assume you mean transitive dependencies) you're implying the build system should automatically download and build these. I vehemently disagree with that, the user should be told of the dependencies, and decide whether to install them. This makes using lots of small dependencies hard, but I consider that a good thigh, putting the onus on the developer to ship these dependencies with their source, and keep them up to date. Otherwise you end up with half the ecosystem relying on some old unmaintained package.
&gt; When you said you want recursive dependencies (by which I assume you mean transitive dependencies) Oops! Fixed! &gt; you're implying the build system should automatically download and build these. I vehemently disagree with that, the user should be told of the dependencies, and decide whether to install them. This makes using lots of small dependencies hard, but I consider that a good thigh, putting the onus on the developer to ship these dependencies with their source, and keep them up to date. Otherwise you end up with half the ecosystem relying on some old unmaintained package. I'm not trying to imply anything about automatically downloading or building. I do not even care whether it takes two tools (package manager and build) or one (a mix of both). What I wish for is a **simple, non-macro'ed** single file detailing dependencies and artifacts. One of my main gripe with CMake is that all those layers of functions upon functions completely obscure the meaning; I understand they are somewhat necessary to achieve the humongous task set forth... and this is exactly why I say that we must simply pare down the complexity to obtain a simpler description. &gt; It prevents you organizing your libraries and executables into a structure. No, it doesn't. It simply imposes the structure to be used. &gt; or using the same files in multiple products. No, it doesn't: - any source file can be shared through a library, the unit of sharing, - any resource file can be shared through a library, the unit of sharing, by bundling a resource folder. If you wish to share a single file, you can have a library off a single file, and that's perfectly fine.
It forces a specific one-size-fits-all structure, which may not fit your need. E.g. for an office suite where you want to keep the word processor and its libraries in one directory and the spreadsheet and its libraries in another, but also have libraries shared by both.
Not having macros leaking all over your code base is a huge benefit of the modules proposal, and I would hate to see them brought back. People who really want macros can still use #include. That should be more than enough. 
Ah! I see the misunderstanding. Think of what I presented as a "crate", or unit of "shipping". In your example you would have: - a core crate, with how many libraries (and tests!) as required, - a word-processor crate, depending on the core crate (and possibly others), - a spreadsheet crate, depending on the core crate (and possibly others). A crate itself, however, can internally be split into multiple libraries. It helps with building, and provides interior organization. 
That's cool, but I would really like to invest my time in something with more trendy buzzwords. 
You mean a package. I'll let the operating system handle that, thank you very much. If you want the Rust ecosystem, just use Rust. The problem is things like this make Rust a platform in itself, so it's not really flexible enough for my taste. 
&gt; I'll let the operating system handle that, thank you very much. We really seem to have complete opposite preferences :)
Why would you worry about `std::bad_alloc` "everywhere?" The point of exceptions is that you don't do that you just let them pass through. 
Build something cross platform - get to grips with all compilers and nuances 
The http://www.gotw.ca/gotw/ series has some short but very in-depth articles on c++.
How does it compare to wigwag (which I really like)? (and thanks for your contribution!) https://github.com/koplyarov/wigwag
It seems like wigwag is mainly designed for thread-safety, which this library unfortunately doesn't support yet. Definitely possible that I will make it thread-safe in the future though.
I did some early test and I didn't see any significative performance gains in respect to a properly configured precompiled headers (msvc). hope to see a change in that! I dream of the days when we will get c# like performance, at least for non-templated classes... 😁
Yes, it is currently a bit limited and unsafe for some situations, but I'm working on it! What do you mean by "source is deleted from observer handler"? By source, do you mean the observer, subject or something else?
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7v1nrz/i_know_a_fair_bit_of_programming_and_i_wanna/dtowfzs/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
ok got it. sorry
I specifically mean either |subject::observers_| can be deleted, or it can be an object owning the subject. Like if you delete |subject| from |observer_1|'s handler in https://github.com/Ansoulom/cpp-observe#example-1-basic-usage. I.e. can be two different problems: 1) an iterator corruption because of deletion, or 2) destruction of the container. If you can fix it and keep it simple, it can be a gem. Otherwise, there are already boost::signals2. Ideally, I think it better to be statically configurable: e.g. you can keep the code simple as it is if observers are not supposed to access the source from within its' handler. It's a valid case when handler always performs post to another thread or executor. This way you don't want to pay for the additional checks.
!removehelp
&gt;What I am interested in: theoretically there should be a huge attack wave on unpatched systems. Attacking unpatched systems for the lulz does no harm. So... &gt;It's like every site on the net have explained in details how to do the attack. ...did they also explain how to use the attack to make money? &gt;But I don't see anything of the sort, what's happening? An attacker needs the ability to execute code on the victim's system for a long enough time for the attack to succeed. An attacker who can execute... * ...arbitrary code with user privileges can encrypt your personal files and ask you to pay for the decryption key. * ...arbitrary code with root privileges can encrypt your personal files and ask you to pay for the decryption key. * ...Javascript in your browser can mine some coins.
P.S : I've been working for years in the gaming industry as a Technical artist &amp; Project manager.
Would be nice for everyone to know a little more about what you're interested in doing rather just "PM me".
Can you elaborate? C++ isn't fully compatible with C anyway.
**Company:** [Insomniac Games](https://insomniac.games/) **Type:** Full time **Description:** We work on the custom in-house tools and game-engine that underpins Insomniac’s AAA console and VR/AR games. Our technology empowers designers, artists, animators, gameplay programmers and sound designers to realize their creative vision. Our publicly announced titles in development include Spider-Man for Playstation 4 and The Unspoken for Oculus VR. **Location:** We have studios in Burbank, CA and Durham, NC. **Remote:** No. **Visa Sponsorship:** Up for discussion. **Technologies:** - required: C/C++ - Development is on Windows using Visual Studio 2015. - optional: x64 architecture experience, console experience, code performance optimization, real-time rendering (DirectX, OpenGL, Vulkan, console and VR/AR rendering APIs), Qt, SIMD, physics system middleware, audio system middleware. **Contact:** Apply directly [here](https://insomniac.games/careers/). Feel free to send a Reddit PM for any additional questions.
It actually has two variants. One that is and another that isn't. You can see the two variants listed in the benchmark link I posted. But sure the creator of wigwag mentions this as a major reason. I will keep an eye on this implementation and see where it goes. 
I've thought about this a bit, and these sorts of problems can be solved via trailing syntax struct Foo&lt;typename R, typename... Args&gt; -&gt; struct Foo&lt;R(Args)&gt; {};
Interested to see the FreeRTOS implementation as I also recently implemented it for FreeRTOS (along with the bulk of the rest of the `std::thread` suit, which actually I'd like to see that too in FreeRTOS as my implementation felt gross [though it ended up being similarish to the libstdc++ implementation]).
It’s quite important for the c++ compiler to be able to ingest c header files. That’s how a large number of projects are used from C and one of the major selling points of the language. 
0 points but 68 comments. What does this mean?
Fair enough, but there's still only a subset of C that C++ compilers can read.
Don't worry, we're on the same page here. I just wanted to point out that if you're running a distro which doesn't allow you to install packages you'd like to use for development, a container is your friend. (Especially powerful when coupled with a Gentoo image - the best distro for C/C++ development I can imagine :-))
It's a very good list of conventions, but please let's have a separate directory for built artifacts, to allow for a per-build-configuration output directory (think arch i686/x64, DEBUG vs. \_NDEBUG).