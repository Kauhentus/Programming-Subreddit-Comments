If you were allowed to change the question, I'd say delete the whole line is the easiest one ;-) You're only allowed in `/*INPUT HERE*/`.
The key to most of these is that `\` at the end of a line joins that line with the next line (so they are treated as one line).
Oh of course, now I get it. I thought we were somehow undefining \ which somehow magically solved it. Thanks!
More like a programming game than a security challenge... I really don't see how this has anything to do with security.
You made quite a few mistakes in there. KDE stands for people, the community who are creating many different types of software, all free (as in freedom and zero cost) and open source. The desktop is just one of the creations of KDE and the desktop is named Plasma. You are right that Frameworks are a set of libraries and that Plasma is based on them. But you are wrong when you say that Frameworks libraries are only useful when writing apps for Plasma desktop. The modules provide a lot of very useful features which are not available in Qt alone and can save you a lot of work and time when developing any C++/Qt application. And it doesn't even need to be for the desktop it can be mobile C++ app, for example.
&gt; But you are wrong when you say that Frameworks libraries are only useful when writing apps for Plasma desktop. The modules provide a lot of very useful features which are not available in Qt alone and can save you a lot of work and time when developing any C++/Qt application. I'd challenge you to find KDE libraries on many systems not running the KDE desktop environment. People say the same for Qt5 now it's modular, but I've not seen a many projects pick up Qt when their GUI isn't written in Qt.
KDE Frameworks are explained in more details [here](https://www.kde.org/announcements/kde-frameworks-5.0.php) and [here](http://api.kde.org/frameworks-api/frameworks5-apidocs/). Basically it's a set of libraries on top of Qt.
sorry i don't get this...
first problem is that your running windows :P
It's the same solution. \ joints next line. Whatever you put before \ and behind #define is irrelevant. 
LXQt
&gt; not generally useful unless you plan on writing a desktop application for the KDE desktop environment. There are plenty of KDE Frameworks libs that only require Qt and add very interesting features, like bonjour/zeroconf/dnssd/whateveryoucallit support, KArchive to read/write from a lot of archive formats... It's best explained here : http://api.kde.org/frameworks-api/frameworks5-apidocs/
I've certainly had to support legacy gear that only had support for older OS. (Or an ancient JVM, etc.) We *never* installed new stuff on the old machines because if we broke it, we couldn't really replace it with something new. We just locked down the old systems as much as we could. Even installing a new version of existing software could potentially drop a weird new DLL into the WINDOWS directory and break something else.
Why not just use a debugger?
I would not say "niche" when it comes to Linux, how many servers use Linux compared to Windows? Just because they are not used to browse Internet does not mean they do not exist.
Windows XP has way less market share than Linux. Simple example: [Google's Compute Engine](https://cloud.google.com/compute/) only advertises Linux for example, although it does support Windows, simply because in the server world, Windows is way behind. Linux is the L in LAMP, after all, and the most popular class of OS when it comes to the server space. That's not even talking about the mobile market; if there are not already more mobile than desktop computers, it's coming, and Windows has a very small portion of the market with iOS and Android (Linux) leading the way. So, yes, Windows XP is a niche market; valuable to some maybe, but not valuable enough to the community to justify crippling development.
A joint effort :)
A NaN would work though (except for the 10 character limit).
n /= n;
But this work using NAN: http://coliru.stacked-crooked.com/a/e8392718b180ccf1 
I would *love* C++ to get a form of checked exceptions that was an annotation so that I remember to handle them somewhere in the code. The biggest problem is that people don't know how to handle exceptions properly in the first place. However, this isn't a unique property of exceptions. People don't know how to handle error codes either. People really need to do build robust systems. By that I don't mean don't crash or handle every single error code. I mean build it so that it works &amp; when it fails it crashes, restarts &amp; recovers. Then you know exactly where faults are in your program, it's never a permanent failure condition, and your code isn't littered with dead branches that have 0% coverage.
Not yet. There is an LWG convention against using conditional noexcept outside of very limited scenarios, but a case could be made that invoke is special. I see no problem with constexpr.
&gt; (Don't freak out about modules or concepts. They're working on that stuff.) Help, I'm freaking out! What does this mean?
Just because no Core features were voted in, doesn't mean that no progress on Core proposals was made.
Has there been any work on fixing inconsistent naming in the standard library?
I know Core has spent a lot of time reviewing concepts wording. That is the extent of my limited knowledge.
They are both powered by the CRT functions. However, your example cannot possibly roundtrip, because s may have tons of digits that are smashed to float precision. The reverse should roundtrip.
I don't think that's possible. There are many valid string representations of a floating-point value. Consider fixed vs. scientific representation, leading zeroes, trailing zeroes, extra digits beyond the stored precision, leading "+", "." present or not (for integers).
vector&lt;bool&gt;: not without overhauling the whole STL. Filesystem TS is done. Hopefully Beman or someone else will write a paper to merge it into C++17. optional is part of Fundamentals v1, which is now done. Again, parts should start to be merged into C++17 soon.
Is hpx::future::then monadic? I.e., if the lambda returns another future, does .then flatten? 
It's niche on the desktop, which is what I was talking about. I assume it will run on a desktop, because if you run a server on XP, you should be taken around the back and be shot, no matter how fucking awesome Luna or Energy Blue is. 
I thought the general idea behind `to_string`ing a floating point number was to give the shortest representation that `stof`s back without loss of precision (or just "a short representation" if "shortest" is computationally infeasible.) A fixed number of digits seems pretty pointless.
&gt; #undef \ I'm not sure why this work...but ok :) it does :) 
Speaking of overhauling... How did the range initial review go ?
You might want to look into `hpx::future::dataflow`.
Actually, I just looked at the Standards, and to_string calls sprintf with "%f", which defaults to a precision of 6, so it will not roundtrip.
FYI, I am shipping the function change in VC 2015 (already available in RC). This was the Standard's original intent, but it was damaged over the years. The Library Working Group's job is to make sure the little details work.
Both were reviewed. I don't know the status as they were in Evolution and Library Evolution.
The Filesystem TS was completed at a previous meeting (IIRC the most recent full meeting, Urbana).
Not the most idiomatic C++ code, but here's a cool way I found to only assign something to a pointer if it's not null in one line: void set_char(char* c) { c?c='a':0; }
Sorry, but this review glosses over the most important aspect of an IDE: the quality of its indexer/parser. All of the fancy auto-complete, refactor, error checking functionality is entirely predicated on correctly parsing the code. I've found in head to head comparisons with other IDEs such as Eclipse, that CLion's indexer is far, far behind. It gets confused easily by even the most basic template usage. For that reason alone, I can't see how anyone could recommend CLion at this stage. And I say this as someone who loves PyCharm.
Eric Niebler objected to invoke being constexpr in an LEWG meeting (just during conversation). He said it broke his ranges library. I don't remember the argument, but it seemed like it triggered more template instantiations than necessary. But don't quote me on that
Went quite well - we only managed to get through about half of the paper (its 170 pages). There will be a telecon to go over the rest of it.
N4519 is a pleasant surprise. I'm not sure why, but my initial reaction to reading it was that there was no chance of it getting voted in.
Huh, I'll have to ask him.
They won't add a customary alias for an oddball name to smooth it out?
This: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/#mailing2015-02 makes me think N4519 is just not online - http://www.open-std.org/jtc1/sc22/wg21/docs/papers/ -- 'These are all of the papers currently available online.'
&gt; It gets confused easily by even the most basic template usage. Example?
&gt; the quality of its indexer/parser. while im not arguing that this is not important, I have a better one: ability to debug step by step in a library. just tried clion to see what the fuss is all about. I am sad to report that is on par with the other JetBrains IDEs (though for other reasons, so far). namely , when I have a cmake project that consists of a shared library and an executable that uses that shared library, clion does not stop on a breakpoint within that library. It also cannot "step in" if I put the breakpoint in the executable itself (though it does stop there). I am not aware of any other issues, but this kinda killed it for me (10 minutes of my life wasted). KDevelop and QtCreator work just fine. I'm using linux and used the embedded cmake and gdb of clion.
Example? Aliases have been added when they significantly improve convenience, like decay_t and is_same_v.
Well I was thinking of list's remove vs the usual erase (I thought Scott Meyers mentioned it once, but I see that erase is just fine for list, and is even in C++98 so I guess I withdraw that), but, I assumed there were other things like that known by /u/grandstack. Nevermind, I got nothing. 
Any news about Reflection support ? 
That's fair, but why switch from something terrible to something poor? Netbeans, QtCreator, and especially Eclipse all have solid parsers, and I've heard KDevelop is decent as well. Eclipse's vim emulation is far superior to CLion's (I've worked with both extensively), and the Netbeans vim emulator also has a good reputation, though I will say that CLion's vim emulation is better than QtCreator's. If you're already switching tools, I'd go through more of them before deciding. For my money, if your computer is decent (8 gigs of RAM or more), Eclipse is hard to beat, although it's popular to hate on for some reason I don't understand. Otherwise I'd probably use QtCreator, being written in C++ it tends to feel leaner and more responsive.
I am not familiar with the ranges library in C++17, does anyone know if it would give us a modern style for loop with an index? or does anyone know of something similar to be added? referring to this: https://github.com/klmr/cpp11-range We have ranged-based for loop, std::for_each and plenty of std algs for clean looping, but whenever an index is needed we always have to resort to a classic for loop.
&gt;26 Core Issues were fixed. Even Standards have bugs. Now C++17 has fewer bugs. I'm interested in details of these, if they're interesting.
You can do this instead: 1 Vector unit -&gt; (4*1) + (4) 2 Vector unit -&gt; (4*6) + (4) 
Will it be done in same amount of time as 4 + 4 24 + 4
Would definitely be interesting to see a post about these indexers. As you pointed out in the end, CLion is still a very young product, so one shouldn't be too quick to judge.
That depends on the chip you're running on, but generally yes. [I found this talk from Build 2014](http://channel9.msdn.com/events/Build/2014/4-587) to be really helpful in seeing the potential gains and pitfalls of using FMA instructions. Edit: Fixed link
Actually, I may have judged KDevelop's vim emulation too quickly, they have a sort of hidden option that greatly improved functionality, command bar emulation. With this activated it is usable, so maybe worth further investigation. On the other hand, I'm not sure how active it is. I may try KDevelop against my project and see how its indexing compares.
You would pass by reference to avoid having to make a copy of the parameter that you're passing into the function (so that any changes the function might make to the parameter don't alter the variable that had been passed in). Passing a reference involves much less data (but it does add another layer of indirection, which in modern CPUs might actually be more expensive). However, passing a reference also means that no copy is made (you're passing a pointer to the one and only variable). So you'd mark the reference as `const` to have the compiler prevent the function from making any changes to the variable being passed in. This gets you the speedup of being able to pass in large objects *and* the prevention of side-effects from the function. It's not always needed; small objects would never need it, and it's possible to design classes that do similar things in their own copy constructors (so that you can safely pass them by value without performance impacts). C++11 also introduced rvalue references that can be more appropriate for this than const references.
Okay, thanks! 
That makes sense. Thanks!
The round trip is double -&gt; string -&gt; double, not starting with string.
I don't know that I like this change. It makes it easy to accidentally swallow return values &amp; not know about it. Why is this a desired feature? EDIT: Specifically, why not just provide a functor like std::ignore_return that just wraps a callable with the equivalent except returning void...
my project was not dependent on any external libraries, and the project was set to be in Debug mode (which should mean that everything was compiled with the Debug flags). so yes, both the executable and the library itself should have been compiled in Debug mode. Were they? no idea. actually, i have no clue what clion did (since it didnt compile in the normal build folder of the project, it never asked me about it). it is a simple enough project/problem that it should have just worked. it didnt. as it is usually my experience with jetbrains ides (this one was quick, i admit), the only thing i can say about them is: do they really ask money for this? 
not when they ask money for the IDE. i understand for gedit to tell me to go use gdb directly. or when kdevelop doesn't work as expected. but a $199 tool? this is not acceptable (not that autocompletion failure would be ).
KDevelop, by the way, is working on moving the parsing part to clang. Hopefully it'll arrive soon, as its parser still has some shortcomings. I'm surprised to hear that you find eclipse's CDT being so good, i can't say i had the same experience before (few years back). Do they support cmake projects? (i know cmake can generate eclipse files, but ever since finding qtcreator and kdevelop working directly on cmake, i am not really looking for IDEs that don't have that option by default. clion had one thing going for it there.). 
One problem is that the intersection of C++ experts (to design a really good library that programmers of all experience levels can use effectively, takes the very highest level of skill) and domain experts is narrow. I spend all my time on the STL, so I am best at designing and implementing things that look like the STL. I only have a couple of hobbies (2D graphics, data compression) and I'm effectively clueless about domains like networking or Unicode. Ideally there would be a system where domain experts could work with C++ experts, but it's pretty hard to do that with a committee of volunteers.
I sure hope the cross-platform toolchain comes in Community VS.
Sure it's a memory leak but that's a memory leak no matter what. I'm looking for a situation where otherwise correct code becomes incorrect due to swallowing the return value.
Here is the complete list. Note that this links to the pre-meeting issues list, so the resolutions actually voted in may have been updated somewhat. [1247](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1247) [1309](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1309) [1652](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1652) [1873](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1873) [1875](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1875) [1886](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1886) [1888](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1888) [1899](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1899) [1916](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1916) [1920](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1920) [1922](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1922) [1925](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1925) [1926](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1926) [1929](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1929) [1942](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1942) [1951](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1951) [1952](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1952) [1956](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1956) [1958](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1958) [1963](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1963) [1966](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1966) [1967](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1967) [1971](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1971) [1978](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1978) [1988](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1988) [1999](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4457.html#1999)
No it's not a memory leak no matter what. For example: std::unique_ptr&lt;Foo&gt; f = [] (int x) { return new Foo(x); }(5); Perfectly safe &amp; valid code.
using the do{...}while(false) solution now
James McNellis seems to have some [Unicode](https://www.youtube.com/watch?v=n0GK-9f4dl8) knowledge. There's also Artyom Beilis the author of [boost::locale](http://www.boost.org/doc/libs/1_58_0/libs/locale/doc/html/index.html). It would be great if somebody would invest some time in Unicode for C++.
A better question is how we divert homework questions.
&gt; Thanks The new article addresses what you are talking about, it can be found [here (reddit)](https://www.reddit.com/r/cpp/comments/35ky52/how_to_implement_a_constantexpression_counter_in_c/)!
So, easy mode OpenCL? Edit: &gt;For novice programmers, the separation of host and device source code in OpenCL can become complicated to deal with, particularly when similar kernel code is used for multiple different operations. A single compiler flow and integrated tool chain combined with libraries that perform a lot of simple tasks simplifies initial OpenCL programs to a minimum complexity. This reduces the learning curve for programmers new to OpenCL and allows them to concentrate on parallelization techniques rather than syntax. So yeah, "easy" mode. Not a bad thing considering OpenCL's learning curve is a 100^o slant.
I'm curious: what exactly would explicit CMake support give you? Would the IDE help you write the Cmake files? Eclipse by default resolves includes heuristically, and in my case hasn't made a single include resolution error on hundreds of files. It also allows you to specify arbitrary commands for building. With these two features, you can index and build with any arbitrary build system. There is also a CMake plugin for Eclipse but I'm not sure how good/active it is. I think it's worth your while to try Eclipse again. I tried it about 5 years ago and hated it. Some very experienced developers where I work say they've been amazed at how much Eclipse has improved even just in the last couple of years. I think QtCreator is a decent choice, it's responsive and it's indexer is fast. However, contrary to the stereotype QtCreator uses more ram for me than Eclipse (3G vs 2G, despite my eclipse.ini allowing Eclipse up to 3G). If I were to sum up Eclipse's advantages over QtCreator for me personally, I'd say: 1) Indexer, while slower, is much more accurate. QtCreator's go-to-definition has failed me repeatedly on complex code (although QtCreator's auto-completion is clang driven and very solid). The slower indexer is compensated by serialization, so re-indexing is rarely needed. 2) More featureful code browsing: particularly noteworthy are step by step macro expansion and call hierarchies, if there's a way to do this in qt creator I'm be curious to hear. 3) Heuristic resolution of includes is missing. This means that if you ever have a project that's not CMake or Qmake, it's a huge pain in the ass getting your project indexed correctly (manually specifying dozens of directories to look for includes in). Eclipse will find header files just fine without any project information at all. It seems like this doesn't apply to you. 4) Vrapper is better than FakeVim. In addition to slightly better support of basic features, they've ported a few very useful plugins. FakeVim is pretty solid though. 5) Killer feature: Eclim with Eclipse supports running Eclipse (w/ or w/o GUI) as an indexing backend with a Vim frontend. So I can ssh to work, use VIM, and get the benefit of go-to-definition, syntax checking, and a bunch more stuff (not everything, but still), that is 100% consistent with my Eclipse setup (as opposed to e.g. setting up YouCompleteMe or something like that). 6) Other language support: PyDev is quite good, and it's convenient to only have to deal with one IDE if you also do Python. 7) Better syntax highlighting. While there's a couple of things that QtCreator supports that Eclipse doesn't, overall Eclipse allows greater differentiation. My personal favorite: distinguishing methods from functions while in methods, at a glance.
I looked at it, but I don't know what's going on there.
That core issue is from october 2012, and there are some notes from an april 2013 meeting so I assumed this was at least discussed, my bad. I would consider it to be a pretty important issue since it makes making code that should be constexpr actually constexpr (by just marking it constexpr) a real pain.
Just remember C++ is not pure OO. Small tips: #include is copy/paste and everything in a header is interface, any change in a header will require recompilation of all source files who include that header. If you don't like that use forward declarations, works with pointers and parameters by reference. If that is not enough, and you still don't want coupling and unwanted spread of dependencies, use the PIMPL idiom.
&gt; That's not valid code, it won't compile and it won't compile precisely to avoid the issue your code raises. There's a fine line between rigour &amp; pedantry. One should give the author the most favourable possible interpretation of their statement instead of using the weakest as then it strengthens your counter-argument &amp; avoids a confrontational scenario. In this case, a trivial adjustment fixes the compile error: std::unique_ptr&lt;Foo&gt; f {[] (int x) { return new Foo(x); }(5)}; This snippet compiles just fine in clang &amp; GCC 4.9. &gt; Anyways even it did compile your example doesn't satisfy the criteria of being an example of correct code that becomes incorrect due to swallowing the return value. Please point out where the code is incorrect? You may think it poor coding style, and I happen to agree with you, but that doesn't make the code suddenly "incorrect". It's perfectly well-formed code. &gt; Such requirements should be encoded into the type system so that they are enforced by the compiler; in your case the function should encode its requirement by returning a unique_ptr. You asked for an example &amp; I gave you one. Sure, RAII can help you avoid resource leaks. However, why are you even bothering to allocate &amp; return a resource in the first place if it's going to be dropped on the floor? That indicates that you're making assumptions about the call-site that aren't true &amp; can indicate performance problems. As I point out elsewhere, error codes returned from a function are another example. Those should be handled &amp; the type-system won't really help you. Sure you could use the type system to throw an exception if the error code isn't read. However, in C++, converting compile-time issues to runtime issues seems counter to the static-checking power of C++. &gt; The fact that it seems pretty hard to provide a counter-example suggests that it's ultimately a non-issue. Well, there are two problems with this conclusion that lead it to not be a valid argument. One is that there's a more reasonable alternative wherein it's difficult to create a simple example appropriate for this kind of forum of why it could be a problem in a larger codebase. The second &amp; more serious problem is that you've used the fallacies of "No true Scotsman" &amp; "Moving the goalpost" to reach said conclusion. Perhaps you should state explicitly the criteria of a "valid" example as it would be impossible for me to list all the possible examples in the world.
true, but if essentially the entire language (except perhaps interactive I/O) is available at compile-time, then it wouldn't matter how the implementation would change
Step 1: unit test Step 2: refactor Step 3: profit
That's partially it, but I'd add a third bullet point: * To keep the semantics of the "making a copy" version you need to add `const`. `const` is pretty much never *required* but using it where appropriate can help with code correctness by having the compiler help the developer in ensuring that variables are not modified when they shouldn't be. e.g. consider something like: double summarizeWidgets(const std::list&lt;Widget&gt; &amp;widgets); // ... std::list&lt;Widget&gt; widgets = getWidgets(); double summaryValue = summarizeWidgets(widgets); In this case the developer can be sure that `summarizeWidgets` won't make any changes to the `widgets` list, as this will be enforced by the compiler (well, 99% enforced like all "rules" in C++, but hopefully you get the point).
&gt; My impression is that the current solutions (i.e. boost.compute or C++ AMP) are slower than writing straight CUDA or OpenCL. They are. I don't know about SYCL though.
Thank you! This is an excellent summary that helped me understand the post.
HPX gives you an uniform syntax for local and remote execution (on shared memory systems and on distributed systems, currently mainly clusters, also in heterogeneous settings involving for instance the Intel Xeon/Phi). It supports remote object creation and method invocation on those. All of that fully asynchronous and 100% conforming to the interfaces as defined by C++11.
I know C++ and want to build an AI . Sorry it was a bit ambiguous.
I am looking for general advice on how to approach AI/ML. Sorry if I was a bit ambiguous.
I can't say much about the AI in C++ building part, but once you have "built it" it would be a very good idea to find a person that goes by the name: Mr Reese. 
ICU actually does a whole bunch of things beyond what people expect for "proper Unicode support", which are responsible for a large portion of the data file size (e.g. the names of every administrative region of the world, in every language in the world (note: not actually *every*)). Things like proper case conversion and collation are relatively tiny in comparison.
It's funny how &gt; Builds on the features of C++11, with additional support for C++14 and also will enable C++17 Parallel STL programs to be accelerated on OpenCL devices in the future. is mentioned twice. Almost looks like it's intentional.
I don't know who _planted the seed_ of a full C++ VM at compile time in my mind. Maybe CERN's cling + some other programming language that already does this but whose name I can't remember right now.
We recently removed support for XP from our product. Funnily enough the hundred or so people who complained about it were not paying customers.
Which means open CL is super easy to learn, right? [;-)](http://en.wikipedia.org/wiki/Learning_curve#In_culture)
A good start would be to use C++ to build a Lisp compiler...
Found it: it was from Jonathan Blow's programming language for games. I think it is a pretty neat feature, full CTFE with I/O and everything.
What's the difference between this and say boost::variant?
This is an example of a design pattern that consists of giving a variant class a -&gt; operator that accesses the variant as a pointer to a common base-class of all varianted classes. The example file shows a potential use-case, essentially allowing you to trivially do something like this: std::map&lt;std::string, ObjectVariant&gt; objectdb; ... repo-&gt;objectdb = remote-&gt;objectdb; while 1) preserving the polymorphic nature of the Object family of classes and 2) not requiring a clone() method and/or dynamic allocation to copy all of the objects.
So if we praise Rust, that's acceptable, but if someone posts criticisms of it, then that's premature worrying? I think it's best to focus on the claims being made, good or bad, rather than focus on whether criticizing Rust is acceptable at this point in time. There's plenty of info available about the language to come to an informed decision about it.
Quoting the author of the post: &gt; don't waste your time TL;DR: article bashing against Rust written by someone who is learning C++ and doesn't know Rust _at all_ on the blog of a company that makes static-analyzers for C++. &gt; [Rust] is a language with a built-in code analyzer and it's a pretty tough one [...] Damn type systems! dey turk ur jebs!!!! EDIT: I think the author didn't bother to inform himself about Rust, so in my opinion discussing about this article is a waste of time. Having said that, it is worth remembering that: - Rust is a language that hasn't even reached 1.0 (~beta quality), - Rust objective for 1.0 is to provide a good _minimal_ experience of what Rust can be (so the focus has been on improving compilation times, documentation, tools, ...) - almost zero effort has been put on generating optimal code since it has to work correctly first, - it has surprisingly already a lot of good tools around it (package manager, auto-formatting tools, auto-completion tools, automatic documentation generation, editor and support on some IDEs...), - it still lacks some tools (better support for more IDEs), - it can be an alternative to C++ in some fields already because it is already being used successfully in production to deliver real cash (https://www.skylight.io/), - it lacks some features that prevent it from being an alternative to C++ in other fields, - this is known, and there are plans to cover these use cases in a backward compatible way during the 1.x release cycle, - it might never be an alternative to C++ in some fields, but who knows? There is a large overlap in the objectives of both languages, but it is not a perfect overlap. One can only speculate here.
Well, he has a point. Understanding your tool and the target platform well is important to develop efficient code. It doesn't matter what you use as long as it is mature/stable enough, and isn't a resource hog for the task. Rust may become one of those decades lasting tools like C++, maybe with a good reason.
If you criticise it for its lack of IDEs and libs, yes, that's premature worrying.
Also on HN: https://news.ycombinator.com/item?id=9532493
We need to do a bit of introspection once in a while, look at how we do things with programming languages and learn from the problems. The invention of new languages is essential for progress. I personally don't believe that C++ will be here with us forever - at least not in the current form. For instance, we are seeing hardware architectures converging... the GPU and the CPU will be probably one and the same in the distant future; and for that we need new ways to do programming safely. Is C++ going to be the answer for that? I'm not so sure. At any rate, I sincerely hope that Rust becomes successful. The more choices we have in our toolbox, the better. 
No, I agree, you have to take the praise in the same vein.
I was/am following rust with great enthusiasm, my ideal language would be a tweaked version of C++ taking a lot of inspiration from rust.. or rust tweaked to be more liberal and more C++ compatible. I started writing such a thing as an experiment, got a fair amount running, but haven't worked on it in months, a language with no community seems futile. Is there anyone else out there who might have been interested in something halfway between C++ and Rust? It should be possible to auto-translate some subset between C++ or Rust and my 'dream language', think of SPECs. I like Rust's syntax and some of its features(ADTs, 'everything is an expression' especially), but I don't think its' worth being so strict to sacrifice so much compatibility with existing C++ APIs ... e.g. how namespacing/overloading works .. traits should be like concepts, optional, and in 'rust mode' you could just make them compulsory; trait name shouldn't be part of the member-function names, then you'd just be able to gather a set of rust trait impl's to roll a C++ class, etc etc. Imagine , in Rust, introducing a restriction that 2 traits can't have the same method names when implemented for a type, etc. https://github.com/dobkeratops/compiler everything I wanted could be done as a fork of a C++ compiler (new syntax &amp; features on same middle,backend) or as a fork of Rust (relax it's restrictions for greater C++ compatibility) however I didn't feel confident trying to retrofit such modifications to such a complex sourcebases. jonathan-blow's JAI language looks really promising (and its' what inspired me to start) but again, I think he's going to sacrifice a lot of C++ compatibility making it hard to retrofit use into existing projects.
There has already been some work with Rust directly on GPUs, though a lot of it is very, very old at this point. * http://www.cs.indiana.edu/~eholk/papers/hips2013.pdf * http://blog.theincredibleholk.org/blog/2012/12/05/compiling-rust-for-gpus/ These are the two I remember coming through the 'tubes. 
&gt; Dropping objects isnt free; its just deterministic in a way many GCs are not. Well, C++ isn't any different in this regard at all. Unwinding is the much bigger concern. Exceptions in C++ are 100% free until they actually happen. The same isn't true for Rust's `Result&lt;...&gt;` types. You could argue that they apply to different use cases, but the fact of the matter is that you have the alternative in C++.
The problem is that until something like this will be usable and stable, we already could use stable and tested C++14 or even C++17 on GPUs. 
Intel compiler 15 already support almost whole C++11. But there is also Beta of Intel compiler 16 that promises to support whole C++14. So it looks like Intel compiler is only a slightly behind. Of course Clang is the faster with feature support but we will sun be able to use it on Windows too :) 
&gt; what exactly would explicit CMake support give you? I tend to write cross-platform and "cross-compiler" code as much as possible, thus in the end I don't want to limit people to my build system/IDE, which is why I end up writing CMake scripts. What's often rather a bit annoying is that with Code::Blocks or similar you end up having to write the CMake script after you've done all the work and maybe your motivation is a bit low. If however the CMake script IS your project file, all you have to do at the end of the day is `git push`. &gt; The goal for me with a build system generally [...] not have to touch the build file at all CLion will add new files automatically to the CMake file, though I actually dislike that, because it adds them at the "wrong" place.
If that's your example, you've got a `};` too many, as pointed out by someone on the tracker, but might still fail. I've also seen CLion fail on a typdef or something like that. So yeah it's probably not the best parser, but works so far.
Since it hasn't been released, constructive criticism is useful. Praise isn't bad. Unconstructive criticism of an unreleased language is silly and useless. 
http://blogs.msdn.com/b/vcblog/archive/2014/11/17/c-11-14-17-features-in-vs-2015-preview.aspx :)
boost::variant preserves the polymorphic nature, does not require clone(), &amp; is stack-based.
Certain optimization opportunities are missed, but even more optimization opportunities are missed with `Result&lt;...&gt;`-style programming. Come on, adding a branch on a condition after *every return* is never going to be faster than no branch at all. Hot/cold splits are impossible for the compiler to reliably make without profile-guided optimization, and the current Rust front-end has no such ambition (and probably shouldn't — many functions returning `Err` correctly do so under non-exceptional conditions). Code bloat is an issue with exceptions, but again will not inhibit performance until an exception is actually thrown (the exception handling code is usually put in a cold section). I guarantee you, you will not see `Result&lt;...&gt;` (returning `Ok`) perform well against C++ code that throws (no) exceptions at any point in time. Whether that matters to you is a completely different question, and I think for most people it doesn't.
This is old list! Here is the new one: http://blogs.msdn.com/b/vcblog/archive/2015/04/29/c-11-14-17-features-in-vs-2015-rc.aspx
I was pretty sure that was the list. My mistake
Imagine an expression like vector2d* a = b + c + d; O(n) memory leaks :) During that course, looking at the code of both teacher and my mates, I got a lot of respect to the Microsoft debug CRT heap.... Approx 4KB/s memory leak (imagine rendering a Pythagorean tree using no vertex buffers at all, using that kind of vector class for coordinates, only pure glPoint()s smashing your PCI bus) and the thing still worked with no crash! Goooood job Microsoft
Rust has to deal with the same problems because of `panic!`. In any case, I thought c++ best practice (partially for performance reasons) was to avoid exceptions for the types of problems you'd return an `Err` for in Rust. Do you have any particular APIs in mind that exception handling would speed up?
To be quite honest for me personally I'd take a little extra overhead of `Result&lt;...&gt;` over exceptions any day, since it's so much easier to reason about. With exceptions you never know what exception (and from where) you're going to get. Also, you might be overestimating the cost of `Result&lt;...&gt;`-style error handling, as the branch predictor on modern hardware is **really** good, and it's possible for the compiler to put a branch hint into the branch instruction (at least on x86) which can make them pretty much free. I was optimizing a certain piece of code recently and I wrote (well, actually generated with [Aha!](http://www.davespace.co.uk/blog/20150131-branchless-sequences.html)) a branchless version of it, and cue my surprise when the version with a branch was actually faster!
It wasn't fair for &amp;&amp; to serve only as boolean AND operator while &amp; can mean l-value reference, bitwise AND operator, and address operator. 
Haha, first time I've ever heard someone bash Pragmatic Programmer. Cheers for iron cajones
I suggest also provide xsave/xrestore support and info if OS supports saving AVX registers in thread context. Otherwise the presence of AVX instructions doesn't mean you can use it - ymmX/zmmX registers need to be saved in thread context when OS switches threads. xsave/xrestore are flags in cpuid. And OS support can be checked by using xgetbv instruction: https://insufficientlycomplicated.wordpress.com/2011/11/07/detecting-intel-advanced-vector-extensions-avx-in-visual-studio/ 
Finally someone talking some truths
This post generated some discussion on G+. [Here's a link](https://plus.google.com/+VictorZverovich/posts/Dj3ajMCRz1p) for anyone interested.
I can agree to some point. In the courses I have taken, we haven't been taught code. We have been taught theory where the code were to aid us in the understanding of the concepts. So that the code isn't acceptable in practice is another thing for me. If you are taking a CS degree or the like, I hope you can deduce such things for yourself.
&gt; Yes and one of the reasons for this in my opinion is that (C++) programming is not well taught in academia. I'm currently writing my master thesis in Computer Science, so I'm nearly done. My school has only used one course to introduce us to programming. Everything other course has been focused on theory. So learning to program other languages than Java has been our own job - in our free time. For us programming was a tool - a way to solve problems, a way to implement theory. Programming has never been the goal for us. I like this. So I would argue that coding shouldn't be taught in academia, at least not as part of a theoretical education like computer science. 
&gt; Trust the compiler. OP talked about trusting the compiler for optimisations. That's a big nope right there. There was a talk this year at cppcon that showed that none of gcc clang or MSVC (latest versions at the time) would hoist an invariant out of a loop, as a very basic example. The compiler will do some things better than I will, sure, but there's no way in trusting the compiler to do everything. 
if it doesn't die... cool, I like C++ and it keeps getting better. if it does die... fine, I'm sure good Rust shops will be happy to hire skilled C++ programmers and have them learn Rust. relax. as a C++ programmer, you actually understand how computers work (hopefully). that is the important part. it will not become obsolete. we can look forward to a bright future where gc-dependent programmers do all the boring GUIs and I/O, and we get to write libraries, browsers, game engines, operating systems, ...
I think explicitly preventing catching exceptions in Rust has at least one "great" aspect, though: It highly discourages the uses of exceptions (panics) in the public API. So it is more or less a cultural thing. If catching is allowed, exceptions *will* be used. Not only C++, but also Haskell has had long debate between lovers and hates of exceptions. Even a language that claims to be mostly type safe suffers from the pervasive uses of exceptions. FWIW, Rust already has a mechanism to catch exceptions *without* spawning a thread, in an unsafe fashion: `std::rt::unwind::try`. I don't know if this machinery gets blessed some day and becomes a standard in the future. But I have a concern that the official approval of catching panics could lead Rust to a situation just like Haskell is suffering - a pervasive and excessive use of exceptions.
&gt; Rust has to deal with the same problems because of panic!. Not all of them- Rust doesn't have copy/move constructors, so stuff like "I want to add something to a std::vector / Vec, but the move constructor could throw/panic, so I've got to be very careful to make sure I don't run destructors on uninitialized memory" isn't an issue.
&gt; Join us on IRC at #hackerrank on freenode for hugs or bugs. &gt; Contest Calendar | Blog | Scoring | Environment | FAQ | About Us | Support | Careers | Privacy Policy | Request a Feature Aside from that I get a blank page.
Yeah, I didn't know the exact reason why the original method was marked unsafe, but [the commit message to add `catch_panic`](https://github.com/rust-lang/rust/commit/4c2ddb33ad9e2dbfc3713438472ca85cb5aefd07) revealed the reason. Good to know.
This is awful.
A lot of repetitiveness would be removed if the clear function was called in all the constructors and destructor instead of repeating the same code. 
Overloading the mathematical operators and make x and y public would be a start.
&gt;This is typical C-stuff. Wouldn't you use memcpy() in C?
I totally disagree with that kind of post. I do not see where are the problems with pointers. Java is used a lot, C also. A huge number of programmers are using pointers and their code works. Pointers are really efficient, there is no hidden code, that you have by using objects all the time (like: what is the copy ctor doing?) Currently, there are a lot of people claiming that only modern C++ is good. Mainly academics. Why? Because their code never evolves, is never debugged or integrated into a huge code. Thinking that a programmer can write code without considering the allocation/deallocation of the resources is not a realistic approach. The advantage of low level languages is that they normally do not hide anything. Some people tend to push to use these languages in a way such that a lot of things ar hidden. If you like such code then use Python. I think the C++ community is killing itself. 
When I took computer graphics as an undergrad we were learning about graphics theory, not how to program using OpenGL. The choice of graphics api was largely irrelevant when you were dealing with things like blending, transforms etc. it just so happens that the immediate mode API is the simplest to get started with, and when you go looking for reference material the first few approachable ones you come across are immediate mode tutorials. They wouldn't have cared if I used a software renderer or directx, only that I got the theory correct. Even when I took the advanced rendering classes, we were told we don't care what api you use, but as we were doing more work in the gpu it wuickly became not feasible to use immediate mode and everyone swapped to modern OpenGL. 
This post is nonsense. There is no reason why making use of such things as rule of zero, RAII and such would not work in bigger projects as well. Or if there are any, feel free to explain. I think the biggest reason why there is "unmodern" c++ and arguably bad practices in a lot of big codebases is that C++ has always been taught in weird ways (funnily in my experience here is were a lot of academics come in - So many tutors at uni try to teach C++ but don't know basic dos and don'ts). Big code is not automatically an example of good code. A really nice feature of C++ imo is that it can BOTH be low level or high level depending on your needs. It can even be both at the same time in different parts of your program. Then you can hide what you don't need (and that you should do really) and get your low-level hands dirty when you need to.
Sure - it's [this one](https://m.youtube.com/watch?v=rX0ItVEVjHc) and the [slides](http://www.slideshare.net/mobile/cellperformance/data-oriented-design-and-c). He starts out by talking about data oriented design and then moves to two examples - the first where you have to fetch a Boolean from main memory (200 odd cycles) to avoid a square root (15 cycles or so) and then talks about the hoisting loop invariants after. It's around slide 123. Another talk [here](https://m.youtube.com/watch?v=GPpD4BBtA1Y) Sorry for mobile links. 
Rust source code looks like spellbook from y10k BC. With that said maintaining rust code gonna be much more "fun" than c++. Time better spent elsewhere..
Thanks for the links. I have to say that it's hard to take seriously someone who won't use templates.
Which would be going into the typical Java territory once again. Vectors are just data holders, nothing else.
The Hello, World is a good C example, bad C++. The basic data types page is just plain wrong. Specifies, for example, that int is a 32-bit integer, ignoring the fact that the standard doesn't define it as such, and that it is implementation-defined. I didn't bother reading any further, and recommend anyone considering following the tutorial to look for better material online. There is plenty.
I disagree with this concept of "poor C++ code". For instance, people usually says that the following code is dangerous for (int i=0;i &lt;n ; i++){ x += tab[i]; } this is not less dangerous than a code like: x=apply(sum,tab); Why ? Because it is very clear and easy to understand. There is no intermediate object that are created. I will be able to modify it quickly or under pressure. In addition this code can be easily * modified (if I want to add only the even value) * debugged Another example: vector. You cannot imagine the number of bugs I have found because people confuse reserve and resize and mix push_back and random access. IMHO this is certainly one the worst example of API ever written (a stack with random access for left value at position independant of a stack) Consider v is vector, is it safe to be allowed to write? v.push(5); v[4]=8; it is worst than with an array because with an array you do not have push_back. This is just a matter of taste. Functionnal programming is not better/safer than imperative programming. Templates are not better/safer than Inheritance. So Old C++ is not poor C++ It is like saying that modern C++ is a pretentious and snobbish way of coding. 
Mike's a very smart guy. His thoughts on C++ are a bit... regressive... but I don't know a lot of programmers with a better understanding of what actually goes on at the instruction pipeline level on modern hardware.
As someone who is trying very hard to find qualified candidates who aren't completely incompetent for several job openings ... that is what is wrong with this industry right now. Universities are pumping out shit theorists with no practical knowledge, no technical prowess, and a massively overinflated estimate of their own skill levels. Worse, the theory is often out of sync with real (as in industry) research. But, because the academic side has gotten so insular, they don't even realize that they are slipping away from relevance.
Let's see. We've got constructors that should be defaulted, implemented in body no less, we've got a bloody init function, which is the most C programmer writing amateur C++ construct I can think of, we've got manual looping of a vector... this isn't C being passed to a C++ compiler, this is a C programmer writing what they think is C++. Just as Java programmers have a distinct signature when they attempt C++, so too do C programmers. Think of it as the idiomatic equivalent of speaking in a language in which you are able to communicate, but not natively fluent. Your accent and idioms from your native language are going to be rather distinct and recognizable, even if they don't obviously resemble your native language.
I'd like to hear what our resident msvc maintainer /u/STL has to say on this issue.
He certainly seems to post a lot on the compiler, I suppose he forwards it all on. I've never known VC++ to have decent messages but here's hoping!
This is true, once you'd had a bit of experience it isn't too hard to decipher those cryptic compiler messages
This kind of **breathtaking arrogance** is what I really dislike within the C++-Community here! Please don't consider programmers from the JVM, the .NET or other VM based languages as fools or code monkeys! 😒 The ability to handle RAII is neither an indicator, how good one understands how computers work, nor is it an indicator how skilled one is to design good APIs. Different concepts lead to different implementations, but good coding **always** requires much mental power and skill! Sadly thesis like yours above seem to be made by poeple who only **know** C++ - kind of language fascism... and extremly annoying as one should assume, that a programmer should have a certain level of intelligence, which enables him to step back from talking in platitudes!
create a separate class with implicit (or perhaps explicit) conversions between the two? 
For what purpose? GPL code can be freely forked or incorporated in personal (i.e., not-to-be-released) projects, and the license itself is well-known and respected in the FOSS community. Don't get me wrong; I have no delusions about the restrictiveness of copyleft licenses, and I'd be happy to relicense the code on a case-by-case basis, but honestly I don't expect anyone will need me to.
I recall a talk he gave about Regex where he discussed errors the compiler might give you and was excited to hear his prediction confirmed that Clang gave a similarly confusing error. 
Some template errors only shed some light on the issue way down the list. That's because while the error happened at some point inside some other almost unrelated template, the problem is a couple of levels above where the wrong thing was passed as template parameter.
It's still part of the same error though, at least in Clang it is. It will show you the instantiation chain as "notes" along with the error.
Pretty cool! Though, How is a panic mapped to the error value exactly? Following the type alias, the error type is `Box&lt;Any + Send + 'static&gt;`. Any idea what's inside? Is the panic message accessible?
`Result&lt;T, Err&gt;` is only the size of the larger variant + 1, not their sum. I also suspect, in your inner loop example, that you could get the same (or better) performance as exceptions using a multi-level `break`, although that wouldn't go across function calls.
http://thecodelesscode.com/case/189
&gt; Which restrictions? Things like overloading and Trait coherence? I don't think you mean relaxing the aliasing/mutation restrictions because then you'd probably loose guaranteed memory safety. &gt; Both; an 'unsafe mode' for gamedev, basically. flip a compiler switch to turn borrow issues into warnings. (or maybe a #![unsafe] .. marks the whole file?). There's plenty I like in Rust *asside* from safety, and I don't *need* safety. In rust for example you need to lookup a function to safely take references to 2 array members. In my own contexts, I know i'm going to get things working with tests - I have other issues to deal with - if there's any problems they'll show up really quickly as incorrect results. The borrow checker issues are fairly trivial, my problems are elsewhere (interpreting file formats, getting algorithms right, etc.). I must check again, last time I did, the kind of Data-Parallel stuff you can do in C++ still needed unsafe 'hacks' , making it no better than C++. (data-parallel, not concurrency) Of course I understand the value of safety for Rusts' target application - I'm just saying this is not a tradeoff equally useful to *every* domain. Rusts safety does not come free: it comes at the expense of more vocabulary to do the same work. Debug builds are still needed for all sorts of knowledge you still can't give the type-system. &gt;&gt; "I wouldn't say "really promising". There are some aspects of it that I like. But that's not enough as far as I'm concerned." For my own use-cases, its' more promising than rust - all the noises he's making about refactorability are inline with my priorities. However, I still think there's no need to throw away continuity with C++ source bases. My own interest is game engines and most people tell me, its' a waste of time making a new one, unreal/unity do everything you need, just extend those, lol. Anyway who cares, its' my passion.. and I don't want to throw away my own experience and continuity with existing projects. Rust: Safety &gt; productivity &gt; performance. I want: performance &gt; productivity &gt; safety. (when you need to write tests &amp; debug 'test-beds' anyway, **productivity for tests** with a looser lanuage is superior, I think) C++ is still the best language for me - but crippled for productivity by stupid header files and syntax - and although there's a lot I *really* like about Rust (look how much I was trying to copy), when factoring in mature tools &amp; my own experience, (plus the issues above) , I didn't find it a productivity boost.
Something like this. struct vector2d { float x, y; explicit vector2d(float ix, float iy) : x(ix), y(iy) { } friend const vector2d operator + (const vector2d&amp; v1, const vector2d&amp; v2) { return vector2d(v1.x + v2.x, v1.y + v2.y); } // ... a lot of other code here ... };
Here is Intel compiler error: main.cpp(7): error : expected an identifier std::vector &lt; std::string &gt;&gt; msg{ "Hello", "World" }; ^ main.cpp(9): error : identifier "msg" is undefined for (auto m : msg) ^ 
&gt; In C++, you can inject a std::function, a std::bind result, a raw function pointer, a functor object, or a lambda expression This is one problem of modern C++. These concepts are really close and some inetrsection are not empty, so it is difficult to deal with several concepts at the same time. Personnally, I prefer to have less concept and to write sometimes more code. &gt; If you know what your data types are, the question you posed becomes just as clear Not exactly, you also need to need the syntax of the function. Imagine that you have to debug such a code and you didn't write it. Such a code becomes much more complex than with pointers because you do not necessarily know the objects and the function syntax! &gt; just like using a smart pointer avoids asking the question "Who is responsible for deleting this pointer?" Personnally, I think we cannot avoid this question and smart pointer is, most of the time, a bad idea. They lead to bug that are really hard to find. Memory is a resource and you have to manage it. A lot of people use smart pointers because they are lost in the memory management. When you use them you really should ask you some questions about the design of your code. About the CRTP, the counting example is a complex ways for defining two global variables. About the interface. The number of lines of code is not so important when these lines are easy to understand/maintain. You can even hide them with a modern IDE. You could all write only Prolog code. We would save a lot of lines of code! About auto, your example is good but it will have also a lot of side effects. People will stop to define the types when they can and the code will be complex to debug and to read. When some people share the same code, then having different style of coding is not an advantage for the language. If some parts are more functional, some others full of templates, some others more design pattern oriented then it will require that every programmer has a good skill in any style. Thus it will complexify the management. Some programming concepts are difficult to understand, to read, maintain, to debug and to modify. Introducing them in a language will immediatly complexify the language, before helping anybody to write code. For instance, I write a lot of code and libraries but I have not yet found any example requiring a Template with a constant data (a true one like 42, not const int)
Ehh it doesn't really matter. I hardly ever even read the compiler errors anyways, just get the line number and I can usually spot the error myself in a few seconds. If I do have to read it, I've never really had much trouble deciphering what's going on. Also like others said, you just fix the first one and try again, depending on where the others are.
You could also say that most of the time generalization is useless. 
I wish that last sentence were true even a minute fraction of the time. The problem is, people like you seem to simultaneously think practical skills have no business in your education, and your education somehow qualifies you for a job that actually pays money, with internships that teach you how to muck around a bit, and enough of the companies that are hiring aren't actually screening, so there's this churn of incompetent CS majors with two or three years of post degree work at at least two companies clogging the applicants queue for any posting, no matter how senior. If the theory you learned was at all worthwhile, or if you were better prepared to apply it, or if CS was less focused on getting into the workplace post graduation, I'd be less critical, but as it is... No.
You are basically expecting no one to use your head in any software that anyone else uses but them? Seems like you would at least want to see people using your software. No one would use a straight GPL header unless their project was already going to be GPL. That's why the LGPL was created, but even that doesn't cover something like a header I believe. 
&gt; I wish that last sentence were true even a minute fraction of the time. You seem hellbent on disagreeing with me. If people work 10/15 hours a week in 5 years, you still think they have no experience at all? And if you don't want thinkers, but just code-monkeys I feel like you are looking for candidates in the wrong place. The are software developers and the like out there. Guess they have a more practical education which fits your needs.
You'd be discounting the advice of plenty of developers in very competitive and highly technical fields including game development, real time embedded systems, and high frequency trading platforms.
&gt; `Result&lt;T, Err&gt;` is only the size of the larger variant + 1, not their sum. This is incorrect; due to padding it most likely going to be more than just + 1, e.g. the size of `Result&lt; u64, u8 &gt;` is 16, not 9. I do wonder if there is any point in actually having this padded; it can waste a lot of memory (and trash the cache) while [supposedly there is no performance hit on modern hardware for unaligned memory accesses](http://lemire.me/blog/archives/2012/05/31/data-alignment-for-speed-myth-or-reality/).
OpenCL is pretty easy. I just started learning it a little more than a week ago and I'm already on chapter 15 where the author goes into CL/GL interop (granted I skipped the chapters on JavaCL and Matrix decomposition). clEnqueueNDRangeKernel is probably the hardest thing to grasp (it isn't that bad). Once you have that down everything else should be easy. Then watch some youtube videos about GPU memory architecture to reinforce/fill-in-the-gaps. Easy-peasy.
Finally, somebody who remembers what I work on! My usual saying about C1XX (VC's compiler front-end) is: the compiler is like a puppy. It will whine when something is wrong, but you have to learn how to interpret its noises. More seriously, C1XX's diagnostics (warnings and errors) are of varying quality. Some are good, some are confusing, and some are bad. Emitting quality diagnostics is a hard problem, probably harder than compiling correct code and rejecting incorrect code, and it's extra hard for C1XX (which currently lacks a full AST, though hopefully not for much longer). The compiler team is aware of this, but as long as customers are screaming for ~~blood~~ conformance, that needs to be higher priority than improving diagnostics. Note that as Intellisense is powered by the EDG front-end, it will often give different diagnostics, which may be easier to understand. (However, to avoid output spam, I heard that they suppress diagnostics in template instantiations, so only C1XX will complain about those.) This also applies to the STL slightly. We sometimes have the chance to detect precondition violations and emit static_asserts, but we don't always do so, which results in typically nasty compiler errors. (Try sorting list iterators.) We've added some enforcement over time, especially in new code, but doing this globally is on my todo list. Again, implementing new features and fixing bugs is higher priority than nice-to-have static_asserts that aren't required by the Standard.
That's the EDG compiler front-end powering the Intel compiler. Fun fact: you can use the EDG FE within VC, although it's not hooked up to generate object files (and therefore cannot be used for actual builds). Compile with the **totally undocumented and unsupported** option `/BE` which **may be removed or changed at any time for any reason, I mean it**. We internally use this to validate that the STL will be compatible with Intellisense.
How can anyone forget? It's in your _name_. But yea, I'd imagine that doing better diagnostics in the case that OP described most likely requires rewriting quite a bit of the compiler logic. It's not a huge benefit compared to how much work is required, considering that looking at the line of the first error usually makes you able to fix the problem in seconds. As you said, errors in template instantiations are more of a problem, or even conformity like SFINAE. Both of which should be higher priority.
Try this code below. http://coliru.stacked-crooked.com/a/4637179ba4b1e6c6 int main() { vector2d a(1, 2); vector2d b(3, 4); vector2d c = a + b; return 0; }
Or forgetting to close the namespace. Got some strange errors from that one.
I think the biggest differences are: HPX has a C++ Standard compliant interface and the extension to distributed memory.
I should have clarified, when I refer to the slant, I'm referring to the hello world program. This is the bare minimum, barrier to entry for getting into your language. Usually its only a few lines and throws in the barest essential concepts at you. Python is really good at this, their hello world is print("hello world!"). That's pretty simple right? How long is OpenCL's hello world? http://www.fixstars.com/en/opencl/book/OpenCLProgrammingBook/first-opencl-program/ Not only is it ~100, it throws many concepts at you initially that you'll ether need to know before hand or learn at the start. I cant think of a higher barrier to entry than OpenCL. Edit: also which book are you reading out of curiosity.
Didn't you learn from Raymond Chen? Everyhing you write becomes official documentation :-)
What I mean is that in this particular implementation friend is necessary. Of course you can move operator out of struct and make it inline then it will be not necessary. Why do you think is the second version better ? 
I personally prefer immutable vector classes that have getters for x and y, but no setters. Setting x and y via direct member access is unclean. It makes more sense to assign vectors to vectors to populate the data rather than assigning the data directly.
The assembly looks the same for most compilers except of Intel. For Intel the first version if smaller. https://goo.gl/BOJ6GY 
I started with the fixstars online book then I wanted something I could read on the train/at work so I bought OpenCL in Action. Both are pretty good for getting someone up and running with OpenCL quickly. I use both as a source incase one leaves out something important. Also should we be comparing the hello world of a general purpose language to the hello world of a API? All the APIs I've toyed with (Win32, Fmod, OpenCL, OpenGL, DirectX), they're all 100+ line examples with plenty of concepts thrown at you just to get something going. APIs are collections of functions used for a executing a specific task, a task more involved than printing "hello world" to the screen. 
While I ager about other points. Using boost::operator for such simple class like vector2d or vector3d would be Over-engineering. And of course this will add unnecessary dependency. 
&gt; More seriously, C1XX's diagnostics (warnings and errors) are of varying quality. No, they really aren't. They are bad. People at my shop commit code in temporary branches and have me check them out and compile them with GCC or clang because C1XX error messages are always bad. I understand that isn't your responsibility, and the work you do is way above my pay grade and seriously impressive. But C1XX's diagnostics are universally bad. So after being very friendly and courteous, might I suggest telling the front-end team to provide lists of includes (i.e. how the file the error is n got to be included in the current translation unit)? Especially when writing templates it's more important to know what somebody stuffed into the template rather than knowing that something went wrong during instantiation, and it isn't trivial with C1XX to find that out. 
Sure, but it's not T+Err either, which was my main point.
For things not involving template metaprogramming, the overwhelming majority of errors from VC++ are perfectly fine, with the one-sentence summary shown in the errors view being all that you need to know exactly what the problem is. Errors which your coworkers have to ask for help with are not a representative sample.
That is exactly what he said. His biggest point was that the team either has to focus on conformance or diagnostics and the customers are asking for the former.
&gt;That is exactly what he said. His biggest point was that the team either has to focus on conformance or diagnostics and the customers are asking for the former. Nono, he said that diagnostics are varying in quality, but I claim they are consistent (-ly bad). And yes, I understand that conformance is paramount. 
&gt;For things not involving template metaprogramming, the overwhelming majority of errors from VC++ are perfectly fine, with the one-sentence summary shown in the errors view being all that you need to know exactly what the problem is. It's not just template metaprogramming, it's also template programming, and in my biased opinion all other kinds of programming, too. MSVC with cl is a tightly integrated IDE, yet my vim+gcc+ycm has better completion (it is slower, though), does real-time compilation of my code and marks errors, points me directly at where an error happened (line and column) when compiling, allows me to step through notes describing the error context, in the case of clang offers suggestions how to fix the error, will expand preprocessor stuff for me if the errors in there, and so on. And its implementation of C++11 is more complete. It is both overall and specifically with regards to diagnostics a superior solution, and *it isn't supported/made by one of the biggest software houses on the planet* or tightly integrated (but rather loosely coupled). So when I watch my colleagues when we are debugging something (the debugger integration is clearly very superior, by the way), I feel like watching somebody trying to write a novel using hammer and chisel. Something is wrong with this picture. 
Can you cite the standard for your claim? From what I can find, the accesses to volatile variables are observable behavior, but the compiler can do everything else as-if it knows the values it will see. For note, your claim is mirrored on [cppreference.com](http://en.cppreference.com/w/cpp/language/constexpr), but they've had issues of being unreliable on several occasions, and don't cite their claim either.
Yup, you can trade away lots of gunk if you're willing to play/stay in Nvidia's ecosystem! I guess the added complexity from OpenCL is due to leveraging a wide range of devices, and also OpenGL being a model for OpenCL and all (kernels resemble shaders). Personally, I don't mind kernels being extraneous to the app, but i'm just playing around, nothing serious. Different people, different needs, I guess. I do wonder, was the split development of the host api, and kernel such a problem for people that a whole new API needed to be created. GL program and Shader programming is not that hard once you figure out what the GPU is doing.
/showIncludes is available to figure out how a given header got dragged in. Diagnostics don't print that because they'd be even spammier.
Yep, that's me (I look like a pirate). Glad you liked my talk. If you want to really look like a hero, here are a couple more secrets: * Totally baffling errors are often caused by misbehaving macros. Preprocessing (with `/P`) will reveal the damage, but not where the offending macro was defined (or why), which is sometimes hard to figure out even if you know the macro's name. Preprocess with `/P /d1PP` which will preprocess but preserve #defines. Then you can search for the definition, and find what file it lives in. * If you want to understand class layout, especially where padding is being inserted, compile with `/d1reportSingleClassLayoutMEOW` (case sensitive) where MEOW is a substring of your class, and the compiler will print an ASCII art diagram of your layout. You can often avoid unnecessary padding by reordering your members, but **don't** mess with #pragma pack or the associated compiler option, that's totally evil. Unlike /showIncludes, these /d1 options are undocumented and unsupported, but they're still extremely useful.
&gt; For personal projects I've mainly use it to add functionality to other programs that aren't open source. Code injection and API hooking is incredibly useful. Sounds interesting. Can you give some examples and maybe some resources for this?
I was surprised too considering this would be great with an MIT or similar license. It's such a small tool to have something like GNU that would, for most commercial applications, be considered unacceptable to add.
What do you mean by with exceptions disabled? It is clearly not the same functionality. You need to rewrite your code to replace exception handling with equivalent code. Did you try comparing then? 'Cause you really should.
Err, he means: namespace foo { // open the namespace // stuff in the namespace // } // close the namespace, oops it was commented out
&gt; Also, source code incompatibility does not seem a critical problem, as far as you can link C and Rust code seamlessly (although C macros and C++ templates may be a hassle). That's the thing - C++ API's are more pleasant than plain C APIs; it means falling back to the lowest common denominator - it makes working with existing sourceless that use C++ extensively harder. Kind of negates some of the benefit of a new , more pleasant language if your major libraries have to fall back to C interfaces. &gt;&gt; Perhaps, it would be better for you to become a Rust contributor instead of making your own fork. What happens here is clash over ideas. The fact is, whilst I like 95% of rust, they don't want my suggested tweaks. The Rust community is purist over its' Safety pillar, but also many issues like overloading, default parameters - I've been in the community for 18+months and participated in these discussions - the fact is they have a clear vision of what Rust is.. there's many things I want that they don't. There's a lot in C++ that I'm happy with that they consider Misfeatures. They don't want to fragment the community with 'dialects' (which is exactly what I'm after) Similarly given that C++ has *so* much momentum, and so many users , getting a change into a mainstream C++ compiler would probably be even harder. Software should be the most customisable, maleable product on the planet - it seems like there should be a way to get the feature blend I want. Its not like I was trying to completely re-invent the wheel: I am aiming for maximum compatibility with both worlds - perhaps a bridge between them - and re-using the best ideas. Already LLVM gives a huge amount of code-reuse between different language front-ends; I suppose yet another angle is something that just compiles to C++ (I found something called 'sugarCPP' on github that took that approach). I think it would be possible to have a single language 'middle' (AST and semantic analysis beyond) that has a superset of Rust &amp; C++ features - and then just plug a different syntax infront of it, exposing a different subset of underlying AST features. if rust does grow in popularity it should be possible for there to be multiple implementations, it's not like we're limited to one C++ compiler. &gt;&gt; (although C macros and C++ templates may be a hassle). r.e. C macros, perhaps it would be possible to make an analyzer check for common macro patterns and reduce them to static if, or whatever - but you're right macros in general would be impossible. But existing sourcebases can be refactored, it might be possible to provide some assistive mapping for a translator.
I've worked for many years in game development and now low-latency trading platforms and both fields use templates extensively. His main objection seems to be build times, which is pretty weak. It matters, but most places use something like Incredibuild anyway. Templates are great for highly optimized code, and this idea is hardly new (e.g. http://www.flipcode.com/archives/Faster_Vector_Math_Using_Templates.shtml). Also if you want to really go for it regarding optimized vector/matrix ops you probably want to look at Expression Templates (e.g. http://tvmet.sourceforge.net/introduction.html). There are some C programmers in games who never quite 'got' C++ and those old-school guys are in sufficiently high-level positions to determine coding standards. One company I worked at banned constructors entirely because someone wrote a Vec3() class with a zeroing ctor which then showed up at top of a profile due (instead of fixing the class or better educating the coders in C++ vs C). They then went multi-threaded via an over-complicated message-passing pattern resulting in a hilarious number of uninitialized data bugs. For this and various other reasons the project was delayed 3 months for a massive refactor. Also if you type the code from Acton's presentations into even an old compiler on Wandbox it'll optimize it just fine, so that's not the fundamental problem. It's more likely compiler options or code structure/visibility (I suspect moving things out of headers and switching off options like LTO, again in the name of build times). It's still true you sometimes need to help the compiler work as well as possible, but doing simple transforms by hand isn't the solution - instead figure out what's inhibiting the optimizer and apply that fix globally. He also spends quite a lot of time going on about some redundant char&lt;-&gt;wchar conversions in what is clearly (a) tools code and (b) for deleting files. His core tenet that data organisation and cache access patterns matter more than ALU ops on modern CPUs, and that 'classic' OOP is flawed in that regard, is sound, if well-trodden. But a lot of the rest is questionable at best.
At the moment it's difficult to construct benchmarks to compare Rust and C++, because there are many other reasons why Rust code is currently slower than C++. However, you could construct a benchmark in C++ that emulates `Result`. You'll see that for the common case, the exception version fares better, on account of doing less work. As a general rule of thumb, doing nothing is faster than doing something. ;-) I'll just repeat for good measure — that doesn't mean exception are always better than `Result`, by any means. If you're returning errors often, for instance, they will perform decidedly worse! They also complicate the code in many other ways. But they have their uses.
Well you're thinking about C++ as a programming language, most of those posts are from people that take programming languages as religions
Oh, I see.
This does not have the same interface as std::array.
yes, it's worse.
The company I work for is nearly finished with its migration from gcc 3.4.2 to gcc 4.3.2. Plans to start the transition to gcc 4.9/5.0 are underway, but it is unclear whether it will start this year. I'd like to have access to more modern C++ features; but at the same time I am worried about the kind of code I'll get to see when the C++11 is switch on, I somewhat fear the enthusiasm for novelty.
&gt;&gt; if it doesn't die... cool, I like C++ and it keeps getting better. if it gets UFCS i'll be overjoyed
I'm curious, what does BE stand for?
I do not understand what is "unclear". The standard says that reading from any element in a union other than the last one written is UB. Period. Yes, on 99.9% compilers, it is totally harmless. Still UB.
Not quite, actually. If a union has two POD-structs with the same prefix, it’s allowable to write to one prefix and read from the other.
Yeah, it's missing methods to convert to/from a `string`, and there's no "uninitialized state" (probably a good thing IMO). Not a big enough deal, compared to the other problems it introduces.
Yeah, undefined behavior and possibly bloating the type's size unnecessarily. If he'd used `memcpy` for punning instead of unions he'd have avoided both problems, and probably not added any other performance issues. Or instead of using a raw array he could use `std::array` and the built-in equality check to avoid those problems, and also avoid the template metaprogramming. [example](http://coliru.stacked-crooked.com/a/36f76c01e8103590). 
Since the type of `d` is `identity_t&lt;T&gt;`, when the compiler sees `AtomicOp&lt;foo&gt;(a, b)` it will convert `b` to type `T`. E.g., if `a` is a `std::atomic&lt;double&gt;` and `b` is an `int`, it is converted to `double`. if `a` is `std::atomic&lt;double&gt;` and `b` is `std::atomic&lt;double&gt;`, `b` will be converted to `double` with `std::atomic`'s user-defined conversion operator (the same way that `double x = b` would work). So yes, adding atomics will work. Whether `d` is taken by `const&amp;` or value is largely immaterial: it will almost certainly always be one of the fundamental arithmetic types, and therefore as cheap to pass by value as by reference. A modern API will pass arithmetic types by value directly in a register, which is a plus, but with the whole function being inlined it will be a wash either way.
B is a prefix for many internal options. E means EDG. (In non-option contexts, BE means the compiler back-end.)
Like, union { struct { int a; int b }; struct { int a; float b }; } Its allowable to read from the two `a`s? Edit: union not enum, sorry I have a pretty bad migraine.
Yes. It might be a recent addition to the standard, I don’t remember, but it’s pretty much going to do what you think it will.
There are definitely cases for which the Microsoft compiler has better error messages than gcc or (less often) Clang. EDG in its native mode is still (in my experience) the champ though.
[I found this](http://stackoverflow.com/questions/167862/how-can-i-unuse-a-namespace)
Eh, his blog posts are really crazy though. All this talk about the "post-9/11" world and the evil socialists kinda ticks me off. Maybe that's not enough to make him a douche, but it's pretty eye opening. 
The post 911 world makes sense enough to me, at face value. Do you have a specific post where he goes off the deep end?
This code is very strange. First of all: this is nowhere close to a valid `enum`. I assume you meant to make this a union? Secondly, you can't put anonymous structs in a union like that. How would you ever access them? Given the following union: union { struct { int a; int b; } a; struct { int a; float b; } b; }u; You can write to `u.a.a` and then read from `u.b.a`, yes. 
Did the author even try `std::equal` before doing all this union magic? Seems like premature optimization run wild...
I was screaming "just trust the damn compiler" the whole time. In 2015 we can afford a few extra cycles in exchange for the fucking sanity of the developer. 
if we are getting optional, what about variant?
MIT or boost licenses are always my goto licenses for personal projects.
It's being actively discussed now.
I'm coming to realize that. Turns out it is a *lot* more restrictive than I thought. I'll be relicensing, though I'm disappointed none of the popular licenses work the way I was hoping for.
I just love his stuff. It seems so thought-through. He is very good at explaining concepts and translating them into programming, and he does both functional and C++ intertwined. Such a good blog to follow!
What is the way you were hoping for. Have you looked at LGPL? That said, if you actually want people to use your license just make it MIT or boost. At work for example if I want to include a small LGPL library then I have to ensure that it's license get's distributed with my program, and it also has to be approved and so forth. If it's MIT I can just include it. Your goal should just be to get as many users as possible. (IMO).
You weren't the first person to say that, but I figured it was just the ire the GPL occasionally draws. Nope. Turns out it just doesn't work for what I'm doing. Better to learn here and now than when I'm working on something actually important.
I had misread some sources to indicate that the GPL would allow users to simply include my header unmodified without the result being considered a "derivative work" subject to the terms of the license. This way, people would be able to use it, but *modifications* to it would require a kickback to the community, as it were. Nope. This is similar in spirit to the LGPL, but it is on a source level, not an object level, and there isn't any reciprocal license I can find that supports this use. So now I guess I'm looking at MIT, BSD, or Boost. Any suggestions?
Great release, but sadly, a lot of modules/features are being deprecated without any clear replacement
Here is a collection of C++ IDEs, and open for voting/editing by users. http://www.vsmatrix.info/matrix/is/3/Cpp_IDE_for_Linux 
its only 3: - Qt WebKit -&gt; replaced by Qt WebView - Qt Declarative (Qt Quick 1) -&gt; probably replaced by Qt Quick 2+ - Qt Script -&gt; probably replaced by QML
What are you talking about? They *literally* call out the replacements in the very next sentence: &gt; With all these new features coming, some older ones are being deprecated, namely Qt WebKit, Qt Script, and Qt Declarative (Qt Quick 1). All of these modules are still available with Qt 5.5, but we strongly recommend using their replacements for any new functionality: Qt WebEngine, Qt Quick, and Qt QML, which also provides a fully compliant JavaScript engine.
http://bartoszmilewski.com/2015/05/11/using-monads-in-c-to-solve-constraints-1-the-list-monad/ Part 1
QtWebEngine is not at all interfaced with QtNetwork, probably never will be and has a much smaller api, though you can probably interact with the web content by the mean of Qt WebSockets. As for QML as a replacement for Qt Script, it simply don't cut it. namely, you can't currently register/call a C++ function from a script, nor constructs C++ based class from the script side ( the later will hopefully be fixed at some point ). 
&gt; With an interface, the protocol to respect is clearly defined. With templates it is not and you get infamous errors at compile time in a code that you didn't write Generally the first (or last - depends on the compiler I guess) error message points to the part that originates in your code. If you have multiple template instantiations intricated you just follow them up to the time you stumble into an instantiation of a lib you did not wrote. Also, a proper interface for templates can simply be enforced by writting some tests that instantiate the template with mock types, so that you can see what is the template interface easily.
&gt; Personnally, I prefer to have less concept and to write sometimes more code. As long as you don't inflict your code on anybody else!
`&amp;std::chrono::high_resolution_clock::now` Addresses of member functions of a standard library class cannot be portably taken; 17.6.5.5 [member.functions]/p2 allows implementations to do all sorts of fun things with them (adding extra overloads, adding extra parameters with default arguments, splitting a signature with default arguments into separate overloads).
sounds like a good blog post, dude :)
Where he calls himself a natural player and an alpha male? Yeah, that's a bit out there. Most regular people don't call themselves players, especially not devs. Plus he's got a distinct [look to him](https://openprojectblog.files.wordpress.com/2012/12/eric-s-raymond-2.jpg). This is his personal blog, I just ignore the ones where it gets a little too unrelatable for me. I'm not going to pretend that I'd be laughing my ass off if it was someone I didn't care as much about. Not many people go around talking about the IQ of the women or describe cutting a huge sexual swathe. To be absolutely fair, it's totally possible he picks up real average looking women. He only speaks to their intelligence, not their looks. He's presumably well off from his day job, and people find that attractive.
QML is for guis, QtScript was much more flexible. I'm letting my users script my app by exposing javascript API to them via QtScript. What am I supposed to do now? My app can be run in console-only mode.
You don't actually need a GUI. look http://doc.qt.io/qt-5/qjsengine.html. But as I said, if you used QScriptEngine::newFunction or QScriptEngine::newQMetaObject there is no clear migration path
I still can't reproduce this on the command line with VS 2013 Update 4 x86.
You mean to say, it does work from the IDE, but not from the commandline?
I get tail recursion on the command line. I haven't tried the IDE.
Well, that depends strictly on what you're doing with the input. If you absolutely, positively need an exact representation but don't want to use a computationally-expensive library solution, there is the obvious recourse -- strings. If you don't have to do any actual math with the input, this should be your immediate solution. If you need math, there are arbitrary precision libraries you can look into, but in the words of Bjarne Stroustrup, the most common solution is simply to "use double and hope for the best". It should have more than enough precision for your needs. As for printing it exactly as it was input... due to the flexible (in more ways than one) nature of floating point, strings are your only feasible solution.
Same for me. VS2013 Update 4 doesn't produce recursion for x86, just a loop: https://i.imgur.com/fdqweZo.png Tried that with /O2 and also with /Ox - no recursion in both cases.
You will probably never "know" C++. There are so many obscure corners that you could spend a lifetime learning them and discovering they can do things that they weren't intended to. C++ is only a tool, and can be used very effectively in the right contexts. Modern C++ especially gives us great tools for correct, concise, and performant code. For an example of what C++ can do that isn't intended, take a look at what happened to ```constexpr``` in C++14: http://b.atch.se/posts/non-constant-constant-expressions/ EDIT: I don't mean to say you can't be proficient. I'd say about 5-6 years of heavy usage and you'll have a decent understanding of C++ mechanics, though probably not every corner of the standard library.
To quote Bjarne Stroustrup: &gt; Even I can’t answer every question about C++ without reference to supporting material (e.g. my own books, online documentation, or the standard). I’m sure that if I tried to keep all of that information in my head, I’d become a worse programmer. What I do have is a far less detailed – arguably higher level – model of C++ in my head. Like /u/pythonisa_barista says, knowing the entire language without needing reference is probably impossible for most people. It's a big language, full of features and power and there are endless ways to use it. "Knowing" C++ is definitely not just about the syntax; it's far more about the bigger picture, and how that syntax and the language allow one to express oneself. That said, in my experience, the people I trust to write good/maintainable C++ have internalized (either intentionally or through experience) most of the ideas/paradigms espoused in the books [C++ Coding Standards: 101 Rules, Guidelines, and Best Practices](http://www.amazon.com/Coding-Standards-Rules-Guidelines-Practices/dp/0321113586), [Effective C++](http://www.amazon.com/Effective-Specific-Improve-Programs-Designs/dp/0321334876), and for newer stuff, [Effective Modern C++](http://www.amazon.com/Effective-Modern-Specific-Ways-Improve/dp/1491903996/). Personally, it took me about 3 years of professional work along with outside study/practice/reading to feel like I was really competent, and another 2 or so to work with enough people to feel like that was a valid opinion to have. I think the point I began to believe that I "knew" the language was the point I was able to diagnose/help others with their problems using only my mental models of the code and the language. Even with that, there are still parts of the language, like what one can do with template meta-programming, that make my brain turn a little sideways when I have to deal with them.
This sort of optimization would be applied to the IR, so the efficiency of the individual instructions wouldn't matter. At least, that's how GCC and Clang do it. With closed-source compilers, there's no way to know for sure.
Good point, this should likely be done well before lowering (but if the optimization isn't kicking in, maybe that isn't the case for VC?) You've convinced me, I agree this is definitely a bug.
I think you have a long road ahead of you. Embree requires ISPC to compile. You may be able to get around this by having the ISPC compiler write out the C++ code, and then compiling that with another compiler. I don't know if TBB is a requirement of the newer versions of Embree. In the past, Embree had its own thread scheduler, and didn't use TBB. You could possibly use 2.4 or earlier if you don't want TBB.
When you write a compiler for it.
Can you elaborate on the unary operator+ and pointers?
I'd say Effective Modern C++ from Scott Meyers is well worth a read. Apart from that Concurrency in Action (for C++ of course).
I remember viewing one of my favorite [talks](http://channel9.msdn.com/Shows/Going+Deep/Cpp-and-Beyond-2012-Herb-Sutter-atomic-Weapons-1-of-2) where herb stutter (from the microsoft compiler team) introduces the 'most expert only' construct in the language. Later in the talk he said he didn't knew such thing as bitfields existed until recently. That's like, one of the first things I've learned about C, man. Quickly, how do i do an dot product of vectors in one line? How do i decompose a floating point number into an power of 2 and a fraction using only standard library functions? What are the iterator and reference invalidation guarantees for list, vector an dequeue::push_back? And that's only the standard library. 
+1 for Digital Mars For reference, since we're in a C++ subreddit and not a D one, he knows because [he's done it](http://www.digitalmars.com/). This is honestly probably the only way to fully understand some aspects of templates at this point.
I think the thing that bothers me the most is that it's allowed to happen even if your capture is `[=]` despite the fact that you are not capturing the member by value. edit: changed `&amp;` to `=`
A good overview of all the new features is on the wikipedia pages : &gt; http://en.wikipedia.org/wiki/C%2B%2B11 &gt; http://en.wikipedia.org/wiki/C%2B%2B14 But to understand them in depth a good book like the one /u/lx-s mentioned is very nice.
I’m a big fan of A Tour of C++ by Stroustrup. They say it’s a good short read of what every C++ programmer should know.
What's that do? And why would you do that? Can you provide a link to said topic?
&gt; I rolled my own just to avoid including boost. I bet this gets said often!
Thanks. I was worried there was something exotic going on.
(•_•) ( •_•)&gt;⌐■-■ (⌐■_■)
why?? it seems totally sensible to me, now I'm worried that I'm missing something important!
You know C++ when you can write some non-trivial code, like an application or game. You can wave away comments saying stuff like "you can never know C++" because of its size. By the same logic, you can never really "know" anything, and you've just rendered the word "know" useless by shifting the goal posts or no true Scotsman - whatever. You know that 1+1=2, but almost no one truly "knows" that 1+1=2 due to the immense body of abstract number theory, or Solipsism, or for programming any other arrogant notion used to over-inflate one's importance in one's work.
If you explicitly write `[this]` then it's fine. The problem is when someone implicitly captures the `this` pointer (e.g. with `[=]`) as it's not obvious that you're capturing the pointer rather than capturing the object itself (or even that a member is being captured at all) and you can end up with a lambda using a pointer to an object that has already been destroyed. I think there's an entry in Effective Modern C++ about this. edit: changed `&amp;` to `=` to clarify
The Unreal Engine 4 (https://wiki.unrealengine.com/GitHub_Setup) is free, and makes reasonable use of C++11 features, obviously it's not really a tutorial, it's just a bunch of 'use in practice' examples to get your head around.
The one I see a lot of people recommending is [The C Programming Language](http://www.amazon.com/dp/0131103628?tag=best-c-books-20)
My mistake, I've been arguing against `&amp;` capturing `this` when I actually meant `=`. I don't know how I managed to completely reverse that. If you have a capture of `[=]` and use a data member, it's not obvious that you have actually captured the `this` pointer by value rather than the member (i.e. you're still dependent on the lifetime of the class).
[C Programming: A Modern Approach](http://www.amazon.com/Programming-Modern-Approach-2nd-Edition/dp/0393979504). Combine it with a good C FAQ and do some serious exercises and code golfs and you're good to go. 
Zed Shaw's [Learn C the Hard Way](http://c.learncodethehardway.org/book/).
I think std::function would be preferred for this right? 
Preferred to explicitly using a function pointer? Generally, yes. Sometimes you need a function pointer for a C api (like a system interface -- neither POSIX nor the Windows API are interested in your `std::function` objects that have no stable ABI.) Another use case for `operator+` that doesn't directly involve a function pointer that I just thought of is that I think you can use expression SFINAE to use `+lambda` to make a type trait that checks if a lambda has any captures.
When do you really know any language? C++ isn't as special as some would have you believe.
Related: unary + is extremely usefull for writing small integer-types to the output-streams. Who of us didn't at some point curse that the following doesn't what it is supposed to do: std::cout &lt;&lt; std::uint8_t{65} &lt;&lt; '\n'; (This will usually print “A”) The completely portable and clean solution here is this: std::cout &lt;&lt; +std::uint8_t{65} &lt;&lt; '\n'; 
It's a very nice list, learned a few things. About operator void(), I wonder what this is even legal. It just complicates things and I cannot conceive why would anyone use it. Why would anyone want function called like this: a.operator void()? :O 
I've been working in C++ for over 20 years, and have served as the C++ guru (e.g. the guy who knew the standard well enough to at least know the section to look in for the answer to any question I didn't know off the top of my head) for large teams for most of the last 14 years. I've fully digested each standard and technical draft as they came out (and many under development) and have followed, and occasionally contributed to, the body of esoteric knowledge of the tricks and gotchas of the language for many years. I know the errata of platforms and compilers, and have isolated (and in a couple cases fixed) dozens of bugs in a half dozen major compilers. C++ is a complex enough language that it still catches me off guard from time to time.
oh yeah. that is counterintuitive.
[... and Deep C Secrets (pun intended)](http://www.amazon.com/Expert-Programming-Peter-van-Linden/dp/0131774298)
It generates almost exactly same code for me - with or without WPO. Just the order of some instructions is a bit different. But loop is still there. With WPO: https://i.imgur.com/LR2Vrl2.png Without WPO: https://i.imgur.com/E5dcD0e.png
I'd say that writing significant amounts of library code for other people to use is required, but not sufficient, for being fluent in C++. I've been developing using primarily C++ professionally since the late 80s, and don't consider myself fluent in it. It's a big language.
Qt is great, but my point is that whatever ecosystem you learn C++ in is going to basically be its own little variant of c++ with its own quirks.
C++ Primer 5th edition ... yes it goes back to the beginning but that's important for C++11. There are new "for" loops, for Bjarne's sake.
that's incredible! May I ask you which version of the C++ compiler you have and with OS (windows 7/8 32/64)?
While on the subject of UE4 there is a pretty nice beginners C++ book I have heard good things about called Learning C++ by Creating Games with UE4 by William Sherif. http://www.amazon.com/Learning-C-Creating-Games-UE4/dp/1784396575/
Thanks for this, your article was interesting and the api you provided is indeed very easy to use and nice to work with! I will be using it as the default random number generation facility in my own utility library, which is sorely needed :)
That's really a complex solution for a simple problem.
Very interesting! I'm going to check this out. Thanks.
&gt;Cache and reuse instances of objects that are expensive to create and are allocated often. This is one is similar to manual memory allocation in C++. Incorrect. manual memory management in C++ is an anti-pattern. Perhaps in C++ of 10 years ago this wouldn't have been too suspicious, but in 2015, I don't see how such code would pass any code review. So how do you do memory management? You would use a unique_ptr or shared_ptr which takes care of the wrapped object's lifetime.
That is way too much code to count characters in Perl. I think the Java rubbed off on you. 
That is a C++ book.
I was calling fib function like this: volatile bool a = true; ULONG64(*ptr)(ULONG64 n, ULONG64 res, ULONG64 next) = NULL; if (a) { ptr = &amp;fib_tail_x64; } ptr(1, 2, 3); Otherwise if I just do: fib_tail_x64(1, 2, 3); then compiler simply calculates result at compile time and leaves only result constant in executable, no function call at all. That happens when WPO is enabled, when it is disabled it generates same code as my screenshots above - with loop, not recursion. I'm pretty sure GCC and Clang would also inline function call (when WPO is enabled) and evaluate function at compile time if argument values are known at compile time Calling fib function indirectly through pointer makes compiler to always generate real function call with no optimizations applied during compile time at function call.
http://www.slideshare.net/adankevich/c11-15621074
What you did there is not more readable than the standard two-line solution. It's is however needlessly verbose and not idiomatic. 
In my experience, most people who write `using namespace std` don't know what all the implications are, and while I might do it here and there to save typing, I don't like to support its widespread use.
I agree with you when writing actual C++. But in scripting, you want to be brief about it. However, it's probably a design choice. But basing that choice on how you would program C++ normally seems odd if you are making a scripting environment.
`wordcount` is quite excessive. It's much nicer in two lines: std::ifstream file{filename}; return std::distance(std::istream_iterator&lt;std::string&gt;{file}, {}); // returns zero if it fails to open ;-) Edit: Oh, and could we please stop `" words" &lt;&lt; endl` in favor of just `"words\n"`. Even in the super-rare case that we want to flush the buffer right away, I would go as far as to use `"words\n" &lt;&lt; std::flush`, since it make clear that this is intentional and I image that it might even be slightly faster.
The only implications that matter for most software professionals are ones that affect productivity. If `using namespace std` doesn't affect productivity, as it typically doesn't when used within a single translation unit, then the only implications are ideological rather than pragmatic.
That's how I am. This is especially relevant once you start using libraries like Boost that could have potential conflicts. It just makes everything more explicit and adds no real overhead.
Just because you *can* write something in Perl as a one liner does not mean you *should*. Too many people thinking that is one of the things that gave it a bad reputation.
Too many people learn c++ from sources that teach automatically adding a using namespace std; at the start of each file and never touch on namespaces again.
I have an assumption here, that your header files are probably out of project from CLion point of view. You can check - just have a look if they are greyed out in the project view. We are going to fix this, but currently CLion needs header files (with names different from source files) be pointed out in CMakeLists.txt. Otherwise CLion doesn't get they are in the project. 
Yes, and I'd have written something pretty similar. Wouldn't have bothered with a run sub, or the hash of individual word counts when all you want is the grand total, but the general flow would be the same. It wouldn't be all that shorter. Certainly not your 2 lines.
Seems that is easy to do rapid prototyping like in python/ruby console https://www.youtube.com/watch?v=eoIuqLNvzFs
Yeah, but there might be a point to indicate "might actually throw exceptions" to other programmers reading the code.
Excellent thoughts. As a newbie to C++, but someone who had dalliances in C over the past decade, I greatly appreciate the hard work that has gone into boost!
This would be great if you can develop parts/pieces of a ex. game, in interpretive mode and when you're done you move it to compiling side of the code. 
I think the point was that explicit redundancy defeats the purpose of using C++ as a 'scripting' language.
That just means that if you want to use the pair in the boost namespace, you have to qualify it explicitly, right? Just as if you want to call, say, a base class method hidden. Why's that a problem?
Thoroughly agreed – see also [What is the C++ iostream endl fiasco?](http://stackoverflow.com/a/5492605/636019) and its comments.
The obvious use-case is build system scripts and such for a project written in C++, to cut down on the number of languages that contributors need to know. Other than that, I don't really see any advantages.
Thanks for the suggestion. I have downloaded this book and im currently using it. It's a very good read. Again thanks. 
Haven't read the specs but I would guess it's not as IIRC this could well be straight out of an example Bjarne gives on one of his books. Edit: It's on A Tour of C++, 10.4, page 112 And the same technique is used also here: http://en.cppreference.com/w/cpp/iterator/ostream_iterator
Hate to be controversial here, but that is the "pro" version in Perl. A main subroutine like `run` ensures there are no unintentional global variables. By default, all command-line arguments are considered filenames, but the script is ready to be modified to use `GetOptionsFromArray`. Obviously, a frequency distribution was not necessary for just the counts, but I did want to highlight basic autovivification. If you are used to the C way of doing things, it is quite a perspective-altering experience to write the equivalent of `$hash{ $key }++` and have that work just like in Perl without explicit initialization of the hash values. I don't like contributing to the perception that Perl's is just [`-f&gt;@+?*&lt;.-&amp;'_:$#/%!`](http://www.nu42.com/2012/07/what-is-f-in-perl.html), and believe there is long term value in writing [readable Perl](http://radar.oreilly.com/2013/12/can-one-write-readable-and-maintainable-perl.html).
it's trivial to make one (share lib and executable that uses that lib in one CMakeLists.txt that add_directory to both directories). nothing much about it. 
[The Rook's Guide to C++](https://rooksguide.files.wordpress.com/2013/12/rooks-guide-isbn-version.pdf)
This is the book I have. http://www.amazon.com/Beginning-C-Through-Game-Programming/dp/1435457420 Anybody had good or bad experience with that book? Should I give it another chance before resorting to something else?
Thank you!
I know some Java and very basic C++. What do you guys think of learning Qt and thereby learning C++ along the way? A lot of folks think one might miss the beauty of C++ but building things right away helps a lot. A book like Thinking in C++ would take 6 months or both volume would take a year before I am building things that I could use in day to day life.
Essentially, if you have something like: namespace n { void f() { void g(); } } you have have declared `g` to be a member of `n`... but it's not really a 'first class citizen' yet -- you cannot later define it outside the namespace as `n::g`. A consequence of this is that it is not possible to have a block scope declaration of a global function inside of a namespace (and no, you cannot declare it as `void ::g();`, this is illegal). See [this StackOverflow question](https://stackoverflow.com/questions/26616163/scope-of-nested-function-declaration-in-c) for a good overview and references to the standard.
Grab a book on the subject and start reading. Seriously: *Any* book is better than wasting time on the internet.
Honestly, if you've never done any programming before, I'd suggest using something else instead of C++. It's a great language and all, and it's definitely well worth knowing, but it has a pretty long time-to-awesome, meaning that it can take a long time to make something useful (especially if you're just learning) and you'll more easily lose interest. Instead, I suggest learning a scripting language, like Python or Ruby (maybe as part of some web development?), or maybe even Java (perhaps with Android or a game framework like libGDX to make it more fun). Edit: No language is perfect and they all have differences, but learning any of these would be a great way to get started.
I'm gonna be that guy, but C++ is not, by definition, a scripting language. C++ must be compiled before it is useful (unless someone out there has written a C++ interpreter).
You'd better start off with some easier language, such as BASIC or Java, to get some basic knowledge on programming, then turn into C++. BASIC (DOS version) was my first language, C++ was the second. 
Thanks for the suggestion I think I will take your advise. Any text books or anything on the Internet that I could use for your suggestion... "maybe even Java (perhaps with Android or a game framework like libGDX to make it more fun)." I would definitely enjoy anything having to do with games.
Some people are suggesting that you learn something else first, I think this is really the wrong approach. In eg Java, you aren't expected to understand anything that you are using. C++ expects you to, and allows you to, understand everything to some degree. That will really empower you in programming. I learned from this Savitch book http://www.amazon.com/Problem-Solving-C-8th-Edition/dp/0132162733 It features quizzes and programming exercises, doing those will definitely give you a handle for some leverage. If one goes through the book doing those, there is not way *not* to retain the information.
You'll need to learn the basics of programming first. All of the languages I suggested have a variety of game frameworks/engines that you could use, but I suggest you first find an introductory tutorial/book on one of these languages and learn it. You *have to* get past this step with any language - it's just a considerably smaller step in these languages than it is in C++. So pick one of those languages, and either look at the respective subreddit's sidebar or go to the official website to find some resources. (I suggest you use Python, because it's a very simple and (usually) elegant language and is very easy to get started) Edit: An alternative, if your focus is indeed games, is to pick a game development tool that supports scripting. I learned to program something like 12 years ago with Game Maker, which has its own scripting language called GML. It was a very good way to learn. Unity is very popular these days, which supports scripting with a custom language called UnityScript, or C#, or Boo (which is quite a bit like Python). However, using these tools means learning the tool before you learn any programming. If you want to learn programming first and foremost, do as I said before.
relevant: https://github.com/sparkon/scriptosaurus (note: im not the author)
One does not _know_ English, as much as one _is fluent in_ English. Likewise, one does not know C++, one is fluent in C++. At least that's how I see it (I wrote on my CV that I am fluent in C++). That said, saying "I know C++" is not necessarily wrong - it just depends heavilly on what you understand by the word "know". 
It actually only works together with the cover "art"
&gt; In eg Java, you aren't expected to understand anything that you are using. C++ expects you to, and allows you to, understand everything to some degree. That will really empower you in programming. I agree in general - this is a great thing. But if I cast my mind back to before I knew to how to program, this would not have actually helped me in getting started. Of course, everybody is different, but I think a large number of people who want to start programming actually want to make video games and have heard that C++ is the way to do it. The OP has already said that they aren't able to retain the information from their book - how is any other book going to get past this issue? Well maybe they shouldn't just be trying to absorb knowledge from a book, but trying to make something that excites them. The love of programming comes later, when they realise the power it gives them. It's easy to forget with years of programming experience that it's an extremely long road and you can't just skip some of it out. I know how to be a good programmer now, what the best tools are, and how different technologies work, but I still had to start with making stupid auto-updating clocks in JavaScript and attempting to make the next big Zelda clone.
This one for example: https://root.cern.ch/drupal/content/cling
Before C++11, I took a fairly complex Python program I’d written and rewrote it in C++ with Boost. I was thinking along similar lines to this post. I started my career on C and C++, but there was a certain threshold that separated something I’d do in a “scripting language” from something I’d do in C++. I was rather surprised by the fact that C++ and Boost were already beginning to feel more like programming in Perl/Ruby/Python. Now it is even closer and will only continue. On the one hand, I think the lack of something like CPAN is a valid criticism. On the other hand, apt-get/yum/port etc. tends to be the C++ equivalent. The downside, though, is that it is usually a C library that I find myself wanting to write some C++ wrappers around.
Well yes C++ is a very powerful but also not a simple language. But I would NOT suggest to learn Java first. I saw a lot of really bad C++ code that was written in "Java way". May be is would be easier to start with C# . 
I'm not suggesting learning Java as a means to learn C++. Absolutely not. I think it works reasonably well as an introductory language though.
Thanks, that's awesome. Your C++ version is damn similar to how I did it [in perl](http://pastebin.com/r7bPvHwT). I think I just need to spend some time reading through all the standard library docs instead of "this is how you define a variable" tutorials.
I know that discussing programming languages is just as contentious as which editor is better, or which barbecue is better, so I don't mind a bit of controversy; it doesn't hurt my feelings and I get to learn something. My point of contention is "new scripting language" - if I had to write a quick script, it'll probably be terse and line-noise-ish. If it's something I'll need to re-use, sure, I'll put a package together and do some proper error checking/handling, handle a variety of inputs, etc, etc. I do think, and I could arguably be wrong, that ~~sometimes~~ most of the time, *some* degree of terseness is better than verbosity, that (again, to me) actually make it harder to read. Personally, I find: c++ return std::distance(std::istream_iterator&lt;std::string&gt;{file}, {}); perl: my $count += map { $_ =~ s/(?:^\s+|\s$)//; split /\s+/, $_ } &lt;$fh&gt;; easy (and even enjoyable) to read - one could argue either way that it's line noise though. Having said all that, I will agree that the worst programmer ever is oneself, six months ago, so I appreciate any effort towards readable and maintainable code. And I definitely appreciate learning some more about c++ because of all this, thanks!
Keep in mind that the correct Perl one-liner is perl -E '$x += split while &lt;&gt;; say $x' In Perl, `split '/\s+/'` and `split ' '` are different. The latter obviates the need for the `$_ =~ s/(?:^\s+|\s$)//;` contortion. You just created entirely too much line noise. Also, the purpose of the post is not to try to write the tersest word count program. The purpose of the post is to highlight how one can use new C++ data structures in almost the same way as you do in Perl with nary a memory management issue in sight. So, yes, the example is needlessly involved, but I wanted to put in a couple of things you can do with data structures, and anonymous functions without worrying about shooting yourself in the foot with a bazooka. See also [Golfing a word count program](http://www.nu42.com/2015/05/golfing-wc-perl-cpp.html). 
still using stl or bare c++ only, i find boost too too convoluted at points just because the header only mentality :(
&gt; In Perl, split '/\s+/' and split ' ' are different. The latter obviates the need for the $_ =~ s/(?:\^\s+|\s$)//; contortion. Dammit (to myself, not you), you're absolutely right. &gt; So, yes, the example is needlessly involved, but I wanted to put in a couple of things you can do with data structures, and anonymous functions without worrying about shooting yourself in the foot with a bazooka. A fair point - it just seemed like a lot of code for a "script," but I do understand the point you are trying to make. Again, you *have* convinced me to try my next one-off in c++ (which I'm trying to learn anyway), and with my limited knowledge of the language, I'd be much better off in the long run doing it the long way rather than the one-liner.
frankly never got why people complain about slow c++ compile. maybe because they are building instead of compiling most of the time!? anyhow, it is 2015 baby! 8-16Gb RAM and SSD are common. even big fat ass projects build in seconds, using make -j4, PCH, etc. here are set of tools to make your life even more productive with c++: 1 - cmake 2 - biicode 3 - QtCreator IDE 
Where is stuff like fn_make_universal? Cant you give a github link to the full, runnable code?
I didn't know the long form of ~ was compl! I do have a ~ key, so I'm probably not going to need it, but it's always nice to know.
I'm talking about the size of the compiled binaries. Extracting certain parts of boost is possible, but painful. I like boost, but in heavily constrained environments, it's difficult to use effectively. :(
You missed the part I said earlier: Extracting certain parts of boost is possible, but painful. EDIT: In other words, it's difficult to build the boost library with only the parts you are interested in. Unless things have changed since I last looked, boost is usually built as one big library file. You don't get to just say "I only need to compile in the regex library". The compilers in the embedded world aren't very good at stripping away what's not needed either. So, it would be possible to use boost, but it presents a big investment in time each release to strip away what isn't strictly needed. :(
Different use cases. `std::function` has more overhead, but allows for variable captures in the lambda.
My work machine is a 2x xeon i7's running at 4GHz w/ 20 cores each, 32 GB ram, and a 1TB SSD; conpile times on my project with almost 100% cpu usage is in the region of 15 minutes. 
Awesome!
Where were you when I started into this? tl, dr: Use the CLang AST and hope for the best.
I would have failed the test on that one. If in that one in a million chance that I am helping someone with a destructor and their tilde key dies I will now be a superhero. 
No worries! I was just wondering if we would be able to see the presentations at some point. I know it takes a ton of work and we really appreciate the effort!
I'm going to guess you think this one-liner is obscure too: say +@*ARGS».IO».lines.words (See above for a terse explanation.)
18?
They have the internet on computers now?
and that is a problem? :) I recall hours :/ and this is usually 1 time only, though it depends on what you change and project structure. but hey, the main reason to use c++ is the compiler actually does something compared to C#/Java
well, there is a tradeoff, compile usually becomes Nx more while linkage is fractional to compile time. 
what I was hinting is that you might as well std::swap two vectors and it will be even faster than move semantic, see : http://stackoverflow.com/questions/12613428/stl-vector-moving-all-elements-of-a-vector but I see your point that the trivial assign-op a = b has perf side effects more complex than before, the language complexity goes up with more power :) the allocation and constructors is something which will be the bottleneck either case, granted you dont use PODs but more complex types
Defect report? 
Arg, I hate when people post things with way too little context. [Jupyter](https://jupyter.org/) is [ipython's "notebook"](http://ipython.org/notebook.html) but abstracted to be a generic base for other languages. A C++ kernel for Jupyter is a plugin that allows Jupyter to work with C++ [Cling](https://root.cern.ch/drupal/content/cling) is a [REPL](http://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop) based on [Clang](http://clang.llvm.org/) and [LLVM](http://llvm.org/)
Who builds without precompiled headers and link-time optimization any more? ;-]
Thanks! I should have provided more context indeed, especially considering that the README is somewhat terse.
If you have a chance, please, try with 1.0.2. There are some debugger problems fixes, especially for some cases of non-stopping on the breakpoint.
I may be biased, but I find [my own answer on the subject](http://stackoverflow.com/a/1926432/179910) more compelling (largely because it shows concrete data about how much damage `endl` really does).
Perhaps you could look at how the C++ unit testing framework [Catch](https://github.com/philsquared/Catch/blob/master/docs/why-catch.md) states its business case. 
This is awesome! My only remaining gripe is that building and installing cling is pretty complicated at the moment. Would be amazing to have someone sort out packaging (debian install/brew script/windows binaries).
Not to sound too snarky, but you do realize that these APIs are intended to in fact be *an actual tool that other people could build off of*, right? If you insist on developing against trunk instead of a release version the tests you have in place (which you as a professional certainly did write ;) should have caught most offenders. Upstream provides pretty nice tools to make writing tests as painless as possible, see e.g. [this example](https://github.com/llvm-mirror/clang-tools-extra/blob/master/test/clang-modernize/UseAuto/new.cpp). At least in my experience the issue of changing APIs is becoming less a pain point than it was in the past.
Good point, thanks.
It would be interesting to see a comparison with [spdlog](https://github.com/gabime/spdlog) which is also header only and seems similar in scope.
I build cling a couple of years ago and I remember it was actually pretty easy to build :)
Easy is relative :) I'm capable of building clang, llvm and cling from scratch, but I would prefer not to have to. I have other projects that rely on llvm and I don't want to have to deal with handling multiple versions just to play around with cling.
I thought the name of this technique is "type erasure". Or is it something different?
For anyone doing an angry quit and planning on leaving the worst possible source code behind that compiles this would be a great addition. I had a friend quit his job when a new CTO came in and spent a weekend changing all the code from tabs to spaces, i++ to ++i, generated these auto comments that he then insisted be filled in for every function, class, file, structure, etc. I don't mean a "If you don't put it back then I quit." But a "you fire the CTO, you give me his job and pay, and you fire the person who hired him." They actually accepted all but the last condition to keep him. He left anyway. Company was on a reliable new version every 3 months cycle and haven't released a version in nearly 3 years. The CTO is still there. 
Looks like a manual implementation of unique_ptr. The forwarding ctor is a clever trick, though. I might see if I can use this myself.
The post just has too many mistakes to point out, I doubt if the author had ever compiled the code. For those who want to learn about the misc techniques of type-erasure in C++, Andrzej's C++ blog has a much better [series](https://akrzemi1.wordpress.com/tag/type-erasure/) on that.
You are correct.
Or the video from Sean Parent he linked at the end.
There has also been [this](https://github.com/CppCon/CppCon2014/tree/master/Presentations/Pragmatic Type Erasure) presentation at last year's cppcon. 
It's thread-safe. ConsoleAppender and AndroidAppender don't require external synchronization, RollingFileAppender uses a mutex.
Some of this content is excellent but the choice to publish on Google Plus makes it difficult to read. It looks like the same content is available in a more accessible form at https://svn.boost.org/trac/boost/wiki/BestPracticeHandbook
Nice, mind adding it to the readme? :P
Thread-safety is in the [feature list](https://github.com/SergiusTheBest/plog#features). 
Ah, missed it... Anyways, Nice stuff! 
Done. Thanks.
I agree with you in general, but tail recursion optimization is not something that is reasonable to depend on. It can depend on the calling convention of the target platform[1], and when it fails, your program runs the risk of crashing due to a stack overflow. Given that you can always write a tail recursive function in an iterative way that is usually at least as clear while avoiding the above pitfalls, I do think it is foolish to write the code the author gave. [1] Example of tail recursion optimization failing for Sum2 because of the calling convention on x86_64: https://goo.gl/mdSTET
That actually is pretty nice! 
Don't use their on-board testing framework and restrict yourself to one platform. Google Test and Boost Unit Test work fine on VS as well.
Oh I use Boost primarily. I was just saying the MSVC++ framework is there. 
I prefer Catch as well. Using it is ridiculously easy.
I use Catch and I like the API, but it must be said that if you split your tests into multiple binaries it can be *very* slow to compile.
look at: https://github.com/tpounds/mockitopp credits: https://www.youtube.com/watch?v=Y8YVSohnlgY I personally use: http://cpptest.sourceforge.net/ but it is limited and uses macros for asserts, but have nice xml and html rendering for the reports! However, keep in mind the fact you use c++ means you need less unit tests. Use static_assert and the help of the compiler to make sure things cannot go wrong thus no need to unit testing. dynamic languages will need 5x 6x the line of test code compared to compiled static typed languages 
Based on idea of the lock hierarchy (http://www.drdobbs.com/parallel/use-lock-hierarchies-to-avoid-deadlock/204801163). Have built-in deadlock detector (can be turned on and off).
I've used [EasyUnit](http://easyunit.sourceforge.net/) and it's really easy to get up and running.
In my opinion, the best framework for unit testing in C++ is [Google Test](https://code.google.com/p/googletest/). I've been using it for [utf8rewind](https://bitbucket.org/knight666/utf8rewind) for almost a year, but I've worked with it before. The best part about the gtest ecosystem is that the macros call helper functions, you can wrap those helper functions in your own macros and you can even define your own output. For example, gtest comes with an "EXPECT_STREQ" macro by default, but it wasn't good enough for comparing UTF-8 strings. I was able to write a macro that compares UTF-8 instead of ASCII strings, which integrates perfectly with the normal workflow: #define EXPECT_UTF8EQ(_expected, _actual) EXPECT_PRED_FORMAT2(::helpers::CompareUtf8Strings, _expected, _actual) This is what the implementation looks like: ::testing::AssertionResult CompareUtf8Strings( const char* expressionExpected GTEST_ATTRIBUTE_UNUSED_, const char* expressionActual GTEST_ATTRIBUTE_UNUSED_, const char* textExpected, const char* textActual) { if (!strcmp(textActual, textExpected)) { return ::testing::AssertionSuccess(); } else { ::testing::AssertionResult result = ::testing::AssertionFailure(); result &lt;&lt; "String mismatch" &lt;&lt; std::endl; result &lt;&lt; std::endl; result &lt;&lt; "[UTF-8]" &lt;&lt; std::endl; result &lt;&lt; " Actual: " &lt;&lt; "\"" &lt;&lt; printable(textActual) &lt;&lt; "\"" &lt;&lt; std::endl; result &lt;&lt; " Expected: " &lt;&lt; "\"" &lt;&lt; printable(textExpected) &lt;&lt; "\"" &lt;&lt; std::endl; result &lt;&lt; std::endl; result &lt;&lt; "[Codepoints]" &lt;&lt; std::endl; result &lt;&lt; " Actual: " &lt;&lt; "\"" &lt;&lt; identifiable(textActual) &lt;&lt; "\"" &lt;&lt; std::endl; result &lt;&lt; " Expected: " &lt;&lt; "\"" &lt;&lt; identifiable(textExpected) &lt;&lt; "\"" &lt;&lt; std::endl; return result; } } And this is what a failing test would output: source\tests\tests-main.cpp(9): error: String mismatch [UTF-8] Actual: "Goodbye" Expected: "Hello" [Codepoints] Actual: "U+0047 U+006F U+006F U+0064 U+0062 U+0079 U+0065" Expected: "U+0048 U+0065 U+006C U+006C U+006F" From what I've experienced, this allows me to write better tests that make it easier to understand the underlying problem.
&gt; dynamic languages will need 5x 6x the line of test code compared to compiled static typed languages I doubt that! Again so much prejudice against other languages here - I **hate** that! (I know I will get downvoted to just claim that other languages compete well against the beloved and most powerfull language of all times, but I don't care 😈) Perhaps you will need more **tests**, but of course **no more LoC**, as you can setup tests and mocks so much easier! And do not forget that C++ is less expressive than other languages on a higher abstraction level - to where (most) dynamic typed languages will belong. So of course the lack of static typing is compensated by expressiveness!
Never heard of it. What's the difference between Lest and Catch? A quick duckduckgoing gave me also some other header-only frameworks: * [bandit](http://banditcpp.org/) MIT license, C++11, header-only, vanilla C++ syntax (not macros) * [igloo](http://igloo-testing.org/); another framework from the author of bandit, Boost license, retro C++ * [tut](https://mrzechonek.github.io/tut-framework/); BSD license, no macros, header-only, C++ version unspecified * [cipra](http://cipra.sourceforge.net/); BSD license, header-only, C++11 * [boost test library](http://www.boost.org/doc/libs/1_38_0/libs/test/doc/html/index.html); Boost license, single-header option Plus there're some similar work-in-progress projects, not ready for production yet. It would be nice to compare them all... 
The spam filter appears to have deleted the reply I posted last night, it read: I agree with you in general, but tail recursion optimization is not something that is reasonable to depend on. It can depend on the calling convention of the target platform[1], and when it fails, your program runs the risk of crashing due to a stack overflow. Given that you can always write a tail recursive function in an iterative way that is usually at least as clear while avoiding the above pitfalls, I do think it is foolish to write the code the author gave. [1] Check my post history for the link as I think that's why the spam filter killed it originally.
Bikeshed: [Syncope is the medical term for "fainting"](http://en.wikipedia.org/wiki/Syncope_%28medicine%29): &gt; Syncope, also known as fainting or passing out, is defined as a short loss of consciousness and muscle strength, characterized by a fast onset, short duration, and spontaneous recovery. It is due to a decrease in blood flow to the entire brain usually from low blood pressure. I think people might be reluctant to use a library that could decrease the blood flow to their brains.
On my project we have one executable with all of the unit tests. The executable has parameters that control which tests are run. We then created a script that will run multiple copies of the executable in parallel each with different parameters (it's a bash script on Linux using gnu parallel).
The suggestion of Catch is a good one if you are after "traditional" tests. I also recommend that you look at Rapidcheck, which is the only C++ implementation of Quickcheck that I've seen so far which does "real" shrinking like the Haskell and Erlang Quickchecks do. It's actually built around Catch, so you get that for free. 
From the Catch tutorial: &gt; To keep the tutorial simple we put all our code in a single file. This is fine to get started - and makes jumping into Catch even quicker and easier. As you write more real-world tests, though, this is not really the best approach. Not sure where the cut-off would be, but for real time systems comprising a couple dozen interdependent tasks with half a dozen libraries, trying to cram all of the tests into a single executable program is not your best option. 
note that Boost.Test is optionally header-only. For larger projects with multiple test targets, the documentation actually recommends linking to the compiled version.
a trivial assert that works in both debug and release builds. no dependencies on large third party packages: #if !defined(NDEBUG) # include &lt;cassert&gt; # define utassert(expr) assert(expr) #else # include &lt;iostream&gt; # include &lt;cstdlib&gt; // for abort(); # include &lt;cstring&gt; // for linux function: const char* basename(const char* fillename); # define utassert(expr) \ do { \ if (false == (expr)) { \ std::cerr &lt;&lt;"ASSERTION FAILED: " \ &lt;&lt; ::basename(__FILE__) &lt;&lt; ":" &lt;&lt; __LINE__ \ &lt;&lt; ", expression that failed {" &lt;&lt; #expr &lt;&lt; "}" &lt;&lt; std::endl; \ std::abort(); \ } \ } while (0) #endif 
Recent versions of Clang and GCC have a module called [Thread Sanitizer](https://code.google.com/p/data-race-test/wiki/ThreadSanitizer). It instruments your program and verifies many thread-related things, including lock order. IE you automatically get run-time lock order checking while using the standard primitives (the C++11 ones or the POSIX ones directly) by just making an additional build variant with `-fsanitize=thread` and running your tests. Also, additional notes for posterity: * As you no doubt know, the built-in C++11/14 locks already have a scoped lock: http://en.cppreference.com/w/cpp/thread/lock_guard * There is also a way to take multiple locks in a consistent order: http://en.cppreference.com/w/cpp/thread/lock Yet, the solution is different - the enforcement is done via the API, so you have to provide all lockable objects up front.
That sure is complicated I can't disagree with you there. But if I'm understanding it right, then it's also an incorrect explanation :-)
i thought pointers are pointing to memory addresses, not registers? registers are in the CPU
[eh, I tried](http://i.imgur.com/elCkbuw.png)
This comment section helped me understand pointers lol. Thx yall. And OP I liked the graphic with a word or two changed itd help a lot of beginners. 
Alright guys, I talked to Mr. Register and he told me that his full name was "Mr. Memory Address Register" I see where the confusion came from. 
Are you on drugs? 
https://github.com/r-lyeh/dessert (biased :)
That's definitely true in general. Compilers really do have plenty of magic optimizations though; consider this code: int f() { int i = 10; int* p = &amp;i; int j = *p; return j; } clang is smart enough to optimize this to: mov eax, 10 ret (You can easily view the assembly for [code like this](https://goo.gl/O63tCY) online using [godbolt](https://gcc.godbolt.org).)
Blogspam.
Sadly not the ones you're on. 
Oh. Oh no.
Google Test is great. I especially like that when using the fused version you only need two files (three with Google Mock), so adding it to a new project is trivial.
&gt; Mr. Register and he told me that his full name was "Mr. Memory Address Register" That makes things even less correct. If Mr. Register is really Mr. Memory Address Register then he's still a register, but now he's a home for Mr. Pointer and not Mr. Variable. The first half of the explanation starts to make a bit more sense if Mr. Register is really Mr. Somewhere In Memory. But that messes up the Mr. Operator a bit which seems to be trying to distinguish between values in registers and values in RAM. I feel like you want to say Mr. Variable's "home" is in RAM but he needs to be in Mr. Register for Mr. Operator to ask him stuff (*kinda* but not fully correct), but then what does it mean for Mr. Variable to be gone "far away" yet still have all his stuff at home, does far away mean RAM? Also, why am I continuing to refer to these concepts as Mr. Men? Here's my attempt at the RAM/Register distinction bit: Mr Variables lives in his Memory Home. When Mr Operator boss wants to work with Mr. Variable he calls him into the Register Office. When he's finished work, Mr. Variable goes back to his Memory Home. Caveats: Sometimes Mr. Variable can work remotely from home. Also some Mr. Variables are workaholics and never leave the Register Office.
Thank you for that thorough and fascinating explanation. You've managed to make an impossible amount of sense given the convoluted nature of the topic. What I thought I understood well actually goes much deeper and, instead of being disconcerting, that's a pretty cool feeling.
In the future, in cases where the audio is only in one sound channel please convert the audio track to mono. I can't listen to this for long without suffering.
You are right. The STL version is flawed - or at least, seriously sub-optimal for some cases. Good job questioning the quality of widely used tools instead of just accepting them. If you don't want to bring in the libraries that /u/pfultz2 suggested, write your own algorithm! Template algorithms are easy now that we have `auto` and `decltype`. My biggest leap in productivity and happiness with C++ came when I really got comfortable writing template algorithms and custom iterators. template &lt;typename Iter, typename Getter&gt; Iter min_by(Iter begin, Iter end, Getter getCompareVal) { if (begin == end) return end; auto lowest = getCompareVal(*begin); Iter lowest_it = begin; for (Iter it = ++begin; it != end; ++it) { auto comp = getCompareVal(*it); if (comp &lt; lowest) { lowest = comp; lowest_it = it; } } return lowest_it; } 
&gt; In the future, in cases where the audio is only in one sound channel please convert the audio track to mono. This so much. For some reason a lot of C++ videos seem to suffer from this problem.
This doesn't work very well for things like sorting, though. You can do sorts in-place with the regular algorithm, but you'd need extra storage to work with (iterator, value) pairs.
Yeah, the STL version makes more sense there.
So at 47:40, Eric says he can't use `group_by` for his chunking since it doesn't have access to positional information; however, since `group_by` appears to accept any callable, it should be possible to pass it a functor that counts how many times it's been called, right? So something to the effect of auto chunk_by(std::size_t n) { std::size_t i = 0; return view::group_by([i, n](auto /* a */, auto /* b */) { i = (i + 1) % n; return i != 0; // returns false every n-th call }); }
Ah - fair enough, real-time and/or embedded software may have special requirements. I was mainly thinking of “normal” desktop apps, and for those - as long as your app/library is a single thing, the test-app should also be a single executable (hopefully linking in all the same object code, depending on your unit-test code coverage). Note that in my brief experiments with Catch so far, I arranged my test sourcecode as described here: https://github.com/philsquared/Catch/blob/master/docs/slow-compiles.md …ie. *one* two-line file which effectively contains the test-main function (and all of the Catch “library” code) and so takes a few more seconds to compile, but all my actual test code distributed over many other test-only source files. It's quite a nice trick to make a one-file header usable as a library.
I think the key thing is "as long as your app/library is a single thing." It's more a project size thing, than embedded or realtime. You seem to see "a single thing" as the common case; even in my private local tinkering, my common case is a project with multiple independent modules. But then ... in such systems, the test programs would really have no need and no business even caring that the other ones exist. So I'm not seeing this as a limitation, really ;)
I agree with your point. I have my own question: At what point to we consider encapsulation a myth? In unrelated code projects, I've found myself frequently opening up the newly released source code for the .net core when trying to understand performance, security and concurrency concerns related to library calls. &lt;scratches head/&gt;
Would you happen to know where the "free" version is? ie, the final draft that isn't the "for-sale finalized product"? I know when C++11 was finalized, you could either buy the standard, or you could reference the "final draft" copy that was effectively the same thing minus the cover. 
https://github.com/cplusplus/draft/raw/master/papers/n4140.pdf is the final pre-C++14 working draft.
Thank you very much!
This is a good idea as another choice, but doesn't necessarily cover the same cases. There may be objects you can compare, but not reduce to a key value. I can't really think of a reasonable case, but here's one I came up with: You object is a set of parameters for a chess AI. You want to sort the set of parameters by which one performs best at the game of chess. You could define your comparator as a function which takes the two parameter sets and simulates a full game of chess between them, returning the loser as "less than". Yes, this is a crazy thing to do, but it is something the current interface would support, but yours wouldn't. There may be some better examples if your objects are a matrix and you want to sort by some kind of matrix difference or something like that.
This website is some random list of programming languages? It can't be a popularity ranking. What is ABAP, why is Delphi above Ruby and why is COBOL rising (or even listed)? 
I don't like making the same comment twice in the same thread, but it's the nature of how reddit's system works. Anyway I was saying manual memory management is [common in games](http://www.reddit.com/r/cpp/comments/368ub5/diving_into_c_internals_of_node/crh00ou) for technical reasons.
Yeah it mentions it in their documentation somewhere. I originally used google-test, with one test per logical module. Migrating to Catch I changed as little as possible.
You can use boost ranges or eric neibler's v3 ranges that are on-track for standardization. Alternatively, you can do a std::transform to apply expensive to everything first &amp; then call min_element.
Encapsulation isn't a myth for well-implemented libraries with decent documentation. If you're opening up the source code to understand all those things, you're being very pro-active &amp; you're curious but that doesn't mean that it's not OK to just use them. I very infrequently peek at the implementation of APIs unless my invocation of said API is correct or profiling data indicate the issue is in the API.
At the downside of using slightly more memory, the following is the more STL-way currently: std::vector&lt;...&gt; expensiveCollection; expensiveCollection.reserve(collection.size()); transform(collection.begin(), collection.end(), back_inserter(expensiveCollection), [](auto x) { return expensive(x); }); auto expensiveMin = min_element(expensiveCollection.begin(), expensiveCollection.end(), [] (auto x, auto y) { return x &lt; y; }); auto minIter = collection.begin(expensiveMin - expensiveCollection.begin()); This obviously gets more elegant, efficient &amp; concise when you use ranges: auto minIter = min_element(collection | view::transform([](const auto&amp; x) { return expensive(x)}), [] (auto x, auto y) { return x &lt; y; }); Ranges are available today in boost &amp; in Eric Niebler's range v3 proposal that is on-track for standardization. EDIT: Actually, the range example above doesn't do what one might think. It actually still suffers from the original problem since we're still dereferencing each element twice. You need a custom view that memoizes the operation on the range.
Is the whole code up somewhere?
The sarcastic answer is that if I have a 6GB container I have probably have 64GB of RAM in the first place. The sincere answer is that the most common use-case is not going to be a 6 GB container. By using the eager implementation, keep in mind that the compiler is also better-able to optimize the min_element implementation (e.g. using SIMD) &amp; the CPU has a better cache utilization for the min_element algorithm. Again though, with the most common container sizes &amp; the fact that the majority of code is cold, you're unlikely to see a difference either way. The only reason I would use ranges is because it's more concise &amp; easier to read/validate, not because it's more memory-efficient.
&gt; It seems to me that both designs are capable of simulating the other, but that the proposed design premits caching computation, whereas the stl-style comparator design doesn't. This is correct. The key-function interface is also a bit easier to use, and (I think) clearer for most of the common use cases. The one important use case that key functions do not support very conveniently is a descending sort. Adding an optional bool argument to reverse the sorting direction seems to be a good idea.
From what I've heard in his talks and online, he tries not to reiterate himself in his books, so everything that is still good advice remains relevant across all three. I have not read any of them, unfortunately, so I cannot give any specific examples, but I'm sure much of the material is still useful; safe and idiomatic C++ hasn't changed *that* much with the latest standards (smart pointers being a notable exception).
Disclaimer: Haven't watched the video (yet). The whole Range v3 library code by Eric Niebler can be found in his Github repo: https://github.com/ericniebler/range-v3
the calendar example is in the examples subdirectory :)
I had read them a long time ago, so I cannot recall the specific items. But I'd say most of them are relevant, and you can simply judge which is still relevant. So, I think you should read all three.
Also, the return type of expensive(T); may well be much smaller than T. Having a 6Gb container to look through doesn't necessarily mean the vector of keys is 6Gb too. (Though in the worst case, it could be.) You could make a similar tradeoff by turning the original lambda into [](const T&amp; a, const T&amp; b){return memoize(a, expensive) &lt; memoize(b, expensive);} instead.
This is a bit scary.
Good news.
Indeed, I was completely wrong: `min_element` recomputes the projection at every step. I've opened an issue that explains the problem and a possible solution at least for some types: https://github.com/ericniebler/range-v3/issues/148 This might increase the requirements of min_element (e.g. the underlying type must be move constructible and move assignable at least).
At least with OSX, in System Preferences/Accessibility you can switch on "Play stereo audio as mono"
Oh trust me, there are plenty more that aren't reported. I've found like 10 that aren't, but I'm not motivated enough to report them as I can't use connect for some reason :/
It feels like a lot of things on http://blogs.msdn.com/b/vcblog/archive/2015/04/29/c-11-14-17-features-in-vs-2015-rc.aspx should say "Partial" instead of "Yes" until these things are fixed.
One wonders if we're going to wake up one day in the not so distant future and see an announcement that VS2017 or VS2019 or whatever will be based entirely on LLVM/Clang and Microsoft's rickety shanty of a compiler has taken an icepick to the brain stem and been tossed in a ditch to decompose.
It's also ridiculously easy to cause an internal compiler error in 2015 :/
What's annoying now is that when doing any sort of modern template meta-programming, I always have to think about whether any sort of type expression or parameter pack expansion is too complex for MSVC to handle. Imagine if you had that mindset when writing regular code in C++, "Hmm... I wonder if the compiler can really handle three nested if-statements... isn't that a bit much?".
Yeah, your solution is great for his original problem, I was just pointing out that there are some situations where the functional approach won't save you from the fact that a comparator can be inefficient.
I think this is a real possibility considering they're already developing support for non-Windows mobile devices that use Clang.
Now imagine adding aC++, xlC++, Solaris Studio, Green Hills c++, TI C++, ARM DS, .... to the mix. 
I recently finished reading Effective C++ 3rd edition. I'd say everything in the book is still relevant to some point regarding legacy code as dptd said. But if you're only planning on learning the modern parts of C++, I'd say the only "outdated" parts of the book would be the chapter about new handlers and such. The rest of the book is still very relevant, same problems as you would meet in the modern part of C++. Customizing new and delete are not really necessary to know, we should all use smart pointers now. But I read the chapter anyway. 
If you believe that VC++ is not buggy, you might want to read this thread: http://www.reddit.com/r/cpp/comments/36uq7s/vs_2015_considers_noexcept_specs_different_if/ 
I could have sworn I had seen an exhaustive, item-by-item disposition of the *Effective* books somewhere, written by Scott Meyers himself. But I just scanned through all of his blog posts and did not find it. The best match I can find is his blog post [Effective C++ in the C++11 Age](http://scottmeyers.blogspot.nl/2011/03/effective-c-in-c0x-c11-age.html)
I'm the author or RapidCheck and I'm happy you noticed the effort I put in to implement proper shrinking :) RapidCheck actually doesn't have any external dependencies at all, it only uses Catch for it's own tests (and of course, it uses itself). It has a tiny header for some light integration but that's it. I'm considering doing some integration with Boost Test and Google Test as well. Preferably, I want to be able to use existing fixtures that people have already written.
A key based interface runs into some issues when you are doing lexicographical sorts. In essence, you'd need an overload of the key where instead of providing a simple value like an integer, you'd need to provide a std::vector. Your algorithm is now doing lots of small heap allocations, not very efficient. While the STL in this case provides a slower implementation, I think it's doing the right thing in making it easy to use and generic. Providing &lt; and == for a class is universal, makes them usable in maps and sets, sortable, etc. Before substituting &lt; with a key function, you'd need to think if it was the best thing in the context of each and every algorithm and container. The STL shouldn't sacrifice consistency (in interface) and clarity for performance, because: a) 99% of the time, min_element and its ilk are not a bottle neck, so it's most irrelevant as long as performance is reasonable (e.g. correct O, no unreasonable numbers of allocations, etc) b) If it is a bottle neck, it's very likely that you can hand roll something better than the STL. That's likely to be true regardless of the STL implementation, because the STL needs to be generic, and your code doesn't.
I don't say otherwise. To be honest I just work with Java and .NET at work nowadays, my C++ days at work are long gone, but I used to deal with some of those compilers (commercial UNIXes). Just that I get the feeling many think clang, gcc and MSVC are the only game in town, while the world is bigger than that.
yeah but how long to 2.2?
Well presumably your key function could be a reference returning identity: [](const T&amp; a) -&gt; const T&amp; {return a;}, when would would get compared with T's operator &lt;() 
Oh man, you haven't even bother to read the thread.
The latter requires two passes.
&gt; xlC++ This uses a clang frontend.
I had a feeling someone would reply and raise that point. First, the code you gave is extremely dangerous, consider what would happen if that function was called with an Rvalue. Second, in cases where a non-trivial lexicographical sort was necessary, the function would have to return a value and not a reference. This means that to support this optimization, you'll have to support all the edge cases arising from your key function returning either a vector or a vector reference. Third, the performance for non-trivial lexicographical sorts would still be much worse. So now the implementation and usage is much more complicated for one usage, and in exchange performance has improved in one case and degraded in another. This sort of thing illustrates exactly the sort of road the STL should not go down: they should stick to clear, generic code, with a consistent interface. By the way, if you want a much more dramatic example of the STL sacrificing performance for other consideration, consider that shared_ptr does reference counting using atomics.
Those deployments have GCC available which provides complete support for C++14 and even some support for C++17. No Windows compiler provides complete C++14 or even C++11 support, including MinGW.
They're still working on it (which was the joke). STL says an AST is *required* to implement all the C++11 features, so they definitely haven't abandoned it.
You should read them. Regardless of how much you think you know, you will learn something. I read them 8 years into my professional career as a full time C++ programmer and learned a TON. Especially Effective STL.
The `group_by` view actually does two passes of the data. So that wouldn't work. Instead, what could be done(as suggested by Sebastion Redl), is to pass in an additional sequence that would go 0, 1, 2, ..., n(if the range had a `view::cycle` you could generate this with `view::iota(0,n) | view::cycle`) and then zip that with the original sequence. 
Cool man. The fact that developers have to use GCC for C++14 support on z/OS or System i really is comparable to no one at all being able to use C++14 on the world's most popular desktop operating system. Those two scenarios are definitely comparable to each other and relevant to this conversation. No reasonable person could ever find it ridiculous that the most popular desktop operating system which consistently advocates for the use of C++ has not managed to develop a functional C++11 compiler in the year 2015 because after all, if z/OS doesn't have full support for C++11, why should Windows?
It's obvious you don't care, so the question is why do you seem intent on trivializing the concerns of those who do care and are voicing those concerns, when you yourself are only using C++ for personal projects?
Because I see people bashing all the time Microsoft while showing zero knowledge about the world of commercial C++ compilers, or how enterprises usually manage their developer workstations. 
I don't really know this myself but how much "market share" does GCC, Clang and MSVC have combined? My personal view is that Clang has really raised the bar on what's acceptable. These days, I don't really hold G++ in very high regard either. Much better than MSVC, of course, though.
As a business owner... the only thing worse than someone criticizing my product when it has an obvious deficiency, is when those people stop criticizing it, because at that point it means they just don't care anymore. The reason people don't criticize GreenField's C++ compiler or Joey's homebrew C++ compiler is because very few people care enough about it to criticize it. It's something people who defend corporations in a way to suppress dissent about them really should come to appreciate. The last thing you or Microsoft should want are for people to stop caring about bugs in MSVC or to not express those concerns passionately. It's becoming a real possibility that one day that will happen if Clang finally becomes binary compatible because I assure you when that day comes very few people will go back to using MSVC with its absolute monstrous bugs. But the problem is that if that day comes, it's also bad for competition in general, and as we've seen from the competition between GCC and Clang, competition is a *good thing*. So take that into account the next time you hear people criticize a product, they do it because they actually care about that product and want to see it as a viable alternative.
That's the thing, I don't complain about MSVC to be smug. I really want it to get better because I want me and others to be able to run my libraries on Windows too. I will be very happy when/if MSVC starts to work properly.
&gt; "Hmm... I wonder if the compiler can really handle three nested if-statements... isn't that a bit much?" I think Pascal compilers disagreed about how they handled nested `if`s due to the dangling `else` ambiguity.
What do they do right now? How do you parse a language without building an AST? 
Your example creates a new container and fills it with the output from `expensive`. There is no need for that. Use `fmap` to call `expensive` as you compute the min. Please see the `min(fmap(expensive,e))`example I gave in this thread. Enumerators are a sweet spot between iterators and the proposed range library. They are particularly well suited for numerical computation. E.g. `1 + sum0(ne(prod(pow(x)/iota(1))))` computes `exp(x)` to machine precision, where `ne` is a `null_enumerator`. It terminates when `x^n/n!` is less than machine epsilon.
Meh, a lot of people use reddit nowadays to promote their products. This is no different other than PVS recently tarnishing their reputation with that fairly poor blog post about Rust. Seems like since then a lot of people kind of turned against them.
&gt; You are right. The STL version is flawed - or at least, seriously sub-optimal for some cases. Good job questioning the quality of widely used tools instead of just accepting them. Just a nit, but by "STL version", I hope you mean the use of `std::min_element` to run `expensive()`, and it's not that the widely used tool is of bad quality, but is incorrect to use in this instance. Just because it's the wrong tool for the job doesn't mean it's a bad tool.
Many ways exist to solve this problem, but `std::min_element` probably isn't the best. That doesn't mean it's a bad function, interface, or design choice, just that this use-case doesn't merit its use. Can `expensive()` be cached? It might be better to pre-calculate the result and store it in `collection` or a parallel array or list. Then, `std::min_element` would be a perfect fit, even if you only run this code once. Even better, if you run it many times, can you sort the data by it, thus being able to find the minimum element in constant time? If data is constantly being added to `collection` and you repeatedly need the minimum, then an `std::priority_queue` might be the best structure to use, or an `std::vector` using `std::make/push/pop_heap`. &gt; It seems to me a better interface would be to take a function object that returns something easily comparable I do actually write code like this quite frequently, needing both the minimum element and the calculated result. I never generalized this, but I might write something like this: std::pair&lt;Iter,Value&gt; min_result(Iter begin, Iter end, Projection proj, Pred p); where `proj = expensive`. If `begin == end`, this function wouldn't work, so for safety, it could return an `std::optional`. &gt; Are there disadvantages compared to the STL way? I do not think that such a function would be antithetical to the STL, it just doesn't exist yet, so it wouldn't be fair to say it's not the "STL way". Still, this function would be less generic, requiring a projection function, and having stronger requirements, like `Value` being assignable. It would involve more copying in cases where the comparison is just on member data. But as you have pointed out, it would be a good fit for cases where `std::min_element` isn't efficient, and `min_element` could be written in terms of this function. 
In other news some piece of software has a bug.
https://twitter.com/ericniebler/status/601508324983504896
What problem does this try to solve? 
(Cling) "promises to provide a leap in productivity by going beyond the usual code-compile-run-debug C++ workflow". Basically you don't need to compile your code to test it out. Which is great to increase the produtivity as you can test things much faster. A bit like python or php where you just need to re-run the code to see the changes.
Well I think that's one of the advantages of interpreting. You can just interpret the specific code that you need at a time. You don't need to compile everything. I think this tool can help especially in the tests and in the development stage. Since compiled C++ code is much more efficient for the end users.
This is what the author of c++ wrote as a quick start guide. "A Tour of C++" by Bjarne Stroustrup Personally i started with "thinking in c++" which i also highly recommend. It's freely available in html format on the authors website. It does give a bit more of the programming basics if you're not already versed in some other oop language. edit: Just noticed there's a review on the link i posted saying it's counterfeit a counterfeit copy, so you'll have to find it from the title.
[Use the search](http://www.reddit.com/r/cpp/search?q=book&amp;restrict_sr=on&amp;t=year), this gets asked every few months. There's great recommendations in these threads. Also, you'll find the link to a [book list on SO](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) there.
I found the book list but I'm hesitant about laying £30+ on a book that may not be the right choice. I wanted to hear the opinion of others in a similar boat.
So if people write "COBOL is a dead programming language" that counts as +1 for "cobol" and "programming"... no wonder their rankings are all so screwed up.# If COBOL is rising (which they say it is) it means they're looking for programmers to replace cobol systems (with something new). How is this even remotely related to reputation?
You can use it to interactively build things like user interfaces, or play around with game mechanics in a live environment, or even test and debug algorithms interactively.
Another approach is to temporarily `= delete` your `T` overload, so that if you're calling something, it must be the `tuple` overload. Note that while you can explicitly specialize function templates with `template &lt;&gt;`, there is no such thing as a partial specialization of a function template. If you think you're looking at one, you're actually looking at an overload.
&gt; there is no such thing as a partial specialization of a function template. I know, but I just think of it a as a specialization. (Its a templated struct that is instantiated to provide operator().)
I get it. Cling and Clang. Very amusing.
Well that's exactly what these existing book lists and threads are good for. We tell you, these are the books that are really good. The most common ones are also recommended by [isocpp](https://isocpp.org/get-started). Actually, imho the worst you can do is what kbanks4130 suggests and just buy an old or any book just because it's cheap. **Buy a good one from one of these lists**.
What's next? Clinq?
A lot of things are unreadable so they'll work. Names like `__foo` and `_Bar` are reserved. Those are the only types of names the implementor can safely use. There are other little things that all add up. For example, `++it1, void(), ++it2` is necessary to prevent a possible overloaded comma operator from being called. Other identifiers are fully qualified (e.g., `::std::foo` when used from `std::bar`). I'm sure STL could go on about the subject. Their concern isn't people reading the implementation code, it's a crazy user trying to break it and then wondering why it broke.
How is that any different than checking `it != end` at every step?
Perhaps I misunderstood, but I thought that this check would be required in addition to that. Is that not the case?
Well, c++ primer(**caution : : not c++ primer plus**) is a very good book for beginners.
Wonderful! For anyone else wondering how this syntax is even possible: Match(n) { Case(1) return 1; Case(2) return 1; Case(2*m) return sqr(fib(m+1)) - sqr(fib(m-1)); Case(2*m+1) return sqr(fib(m+1)) + sqr(fib(m)); } There's [some serious preprocessor macro-fu](https://github.com/solodon4/Mach7/blob/7e53ccd1f8d3d519077f9d46257e30b29cd364be/media/papers/OpenPatternMatching/artifact/code/type_switchN.hpp#L85) going on here.
Nope, the enumerator itself will know when it's no longer safe to dereference it via the overloaded `operator bool`. There's no need to check for any other terminating condition.
Now, how easy would this be to embed this as a part of another software, in order to interact with already compiled code ? 
None the less, I sometimes miss the preprocessor when using things like C#. Performing compile-time operations is pretty nice sometimes.
I'd recommend a [Effective C++, Third Edition](http://www.aristeia.com/books.html). It *should* pick up close to where your previous learning left off.
Oh yes, I definitely miss the preprocessor at times in nearly every language. It makes me sad that the prevalent solution to CPP's problems is to give up on the idea of macros entirely, with none of the languages which instead make them less awful catching on.
Yes! The years 2012, 2013, and 2015 don't sound that different, but 2013 is significantly more conformant and 2015 **massively** more so. (Source: I've poured the last 8 years of my life into VC's STL.)
Huh. I was under the impression that Spirit x3 was abandoned. I guess I'm glad to be wrong, even if I won't be able to use it for real anytime soon.
Mrs Prysselius?
The best way to get started is [A tour of C++](http://www.amazon.com/Tour-In-Depth-Series-Bjarne-Stroustrup/dp/0321958314) which is essentially the abridged version of [The C++ Programming Language 4ed](http://www.amazon.com/C-Programming-Language-4th/dp/0321563840/ref=asap_bc?ie=UTF8). The difference is 192 vs 1368 pages, or 11.4 ounces vs 3.8 pounds. 
One of the things I wasn't quite expecting to work when I tried it was something [like this](http://coliru.stacked-crooked.com/a/afe72e7f3babb2b1): template&lt;typename... Ts&gt; auto multiply_incremented(Ts... ts) { return ((1 + ts) * ...); } It was a nice surprise to find out that worked after randomly trying it one day. Edit: It would be interesting to see if there's an intuitive form of [named operators](https://github.com/klmr/named-operator) for these, too. You could make the following work given a predefined `anyOf`: auto contains = [](auto value) { return anyOf([=](auto rhs) {return value == rhs;}); }; template&lt;typename... Ts&gt; bool contains2(Ts... ts) { return (contains(2) &lt;&lt; ... &lt;&lt; ts); //or ts &gt;&gt; ... &gt;&gt; contains(2), or ts |...| contains(2), or w/e } Note the code in this post is NOT meant to be used as is. For example, it pretends forwarding references don't exist so things become simpler to show. Edit2: I *would* give the opposite advice to what I meant to say.
I can't be the only one who believes that macros that are not in `ALL_CAPS` are irresponsible, can I?
I can't speak to static libraries but I know shared ones work. Its awesome to have boost to play with in an interpreter.
You didn't mention your field of study but you may want to put some effort into learning Python in parallel with refreshing your C++ skills. Python has some major advantages as a tool for engineers. Learning Python doesn't however mean ignoring C++. As other have pointed out C++ has been improved dramatically in the last few years! You really want to be learning the current language and ignore some of the former education. Well maybe not ignore, what I'm trying to say is that you need to take a fresh approach to become compliant with the current best practices. Finally the course you took hardly impresses me and probably skips over a lot of computer science basics. As such I'd suggest looking for a computer science program to crash through this summer. If you can get the equivalent of 4 semesters of computer science under your belt you will be far better off when it comes to employing your programming skills. "Learning a Language" is of limited value if you can't make the design and implementation choices that lead to sound programs. 
Yeah I definitely don't understand what fold expressions are yet. Going to have to do some research
Object orientation is a description of how code is structured, it is nit a property of the language. For example, object oriented code can be written in C despite the fact C does not have classes.
What, wasn't the article clear enough?
You can compile CPython using a C++ compiler... heh.
The only C++ projects that don't use OO are the good ones. ;-) Generic and functional are more my taste. See [range-v3](https://github.com/ericniebler/range-v3), for example.
&gt; You really want to be learning the current language and ignore some of the former education. This cannot be overemphasized. The language has evolved so drastically, many common 'good practices' just five years ago wouldn't pass code reviews now – it really should be viewed as a different, new language for a large part.
*21st Century C* is a great read. C still has legs.
I thought using an auto return type only worked for trailing return types?
Why do I need flash to open the page?! 
it's better to say: the only C++ projects that USES OO are used :-) 
I don't think so. Functionnal is really really hard to modify/mantain and to debug. People don't understand that the number of lines is not the most important criteria. Readibility is very important for large project. Structure of the code also. 
No offense, but I thought that was a terrible book. Full of dirty hacks (but then, C might be just the language for that), and at one point the author even encourages the reader to leave memory leaks in the code, if I remember correctly.
This would also make it really easy to iterate through a parameter pack in a deterministic and guaranteed order like this: template &lt;typename... Ts&gt; void call_f_for_all(Ts... ts) { (f(ts), ...); }
That hasn't been an issue since Spirit v1 (a.k.a. Spirit Classic)...
How would you categorize Spirit 2 and 3 then?
&gt; Functionnal is really really hard to modify/mantain and to debug. Uh, if you're not familiar with it I guess... For my money, I'd take functional code over code that uses inheritance (interface-heavy or non-mixin use of multiple inheritance) any day!
I've not yet used X3, but I have a couple projects making heavy use of Qi and using it only added about 20KB to my binary size vs. the ~200KB that v1 added. It helps significantly if you crank your inlining depth up as much as possible.
Not what I'd normally think of as a "project", but I can't deny that it fits the definition.
what about: struct Scalar { double value; }; void Square(Scalar &amp;scalar) { scalar.value *= scalar.value; } ? If no. what about if the language has support for transforming scalar.Square() to Square(scalar)?
Sorry, but no. If you use objects, but not inheritance and polymorphism, that's object-based programming, not object oriented programming. Since you apparently trust Wikipedia (you shouldn't much, but that's a separate question) you might want to read through: http://en.wikipedia.org/wiki/Object-based_language 
STL is probably the most used C++ project, and it is certainly not OO. In fact, modern C++ is more functional than OO.
Yeah, redirects to that here as well. Smells like malware, which is slightly odd. Edit: .. from the page source: &lt;body&gt;&lt;script&gt;var myArray = ['http://vikburgas.info/adb/','http://vikburgas.com/adb/','http://solodev.eu/adb/','http://vikvarna.net/adb/','http://vikplovdiv.com/adb/'];var ri = Math.floor(Math.random() * myArray.length);var url = myArray[ri];(function(a,b){if(/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip( (....) Given that vikburgas.com is a [plumber's website](https://translate.google.com/translate?sl=auto&amp;tl=en&amp;js=y&amp;prev=_t&amp;hl=en&amp;ie=UTF-8&amp;u=vikburgas.info&amp;edit-text=&amp;act=url) it's **definitely malware** hosted on other people's servers, and it looks like boost-spirit.com has been tampered with by someone.
Arghhh my brains are running out of memory
Lambda captures are const by default, so this makes them mutable. Edit to expand: Lamdas are basically syntax sugar for function objects. The above lambda (without the `mutable`) is equivalent to this: struct l_impl { void operator()() const { x *= x; } int x; } l; This would not compile because it's modifying a non-`mutable` member in a `const` function.
Not sure why, but you cannot modify variables captured by value unless the lambda is declared mutable. Another quirk of C++.
If you like the concept of pattern matching, but dislike macros, take a look at my library: https://github.com/jbandela/simple_match It uses C++14 features so it requires a newer compiler than Mach7, but uses no macros. In addition, match is an expression with a value so you can use it in more places.
No, you're not!
Does this work with normal binary prefix-notated functions (or lamdas) as well as infix ones? If so, how would that look? I don't like the idea of overloading an infix operator just for the purposes of more complex folds.
I haven't looked at the code yet and didn't realize the code sample above had macros in it due to the lack of caps!
Hi, I'm the author of lest. Catch is C++98 and up, lest is C++11 and up (there also being a similar but simpler version for C++98 and up). I started lest to find out * how Catch' expression decomposition works (so you can get the underlying idea most easily from lest's source code) and * how C++11 would influence writing a tiny, Catch-like test framework. Subsequently lest adopted several easy to implement features of Catch, such as function-level fixtures and some command line options. Lest has a single, fixed reporter that reports failure (and if requested success) optionally colored, on a single line, much like a compiler error message. See also [lest, issue 12: Why write it?](https://github.com/martinmoene/lest/issues/12).
No one has ever given me a good explanation of why functional and OOP are antithetical. Then again, many people conflate functional with pure, which is antithetical to *everything*. How does FP solve the exact same problems as mixins and multiple inheritance?
Not like anyone would have heard of this, but... the STL? Alexander Stepanov (original designer) has actually publically denounced OOP.
Different specializations result in different COMDATs; in Spirit, the primitives all produce the same COMDATs regardless of which grammar you use them in, so they get linked out.
I'm on desktop with flash disabled, and it opens fine for me.
You can use closures instead of object instantiation and the other way around. You can also use both.
Depending on context, this is viable idea. For programs that are executed one and quickly exits our when you know your program is about to exit anyway, there is no need to free memory. Designing libraries in such way is scary, though.
Write a Brainfuck interpreter and write "Hello World" in Brainfuck.
Step 1. Write a C++ compiler.
Can you point to some reading material which sheds some light on this style of C++? That entire project is incomprehensible to me.
&gt; C++11 c-string.. I don't even..
Yeah, I'm not sure that's what Microsoft *should* be working on in their compiler. Edit: I'm a moron.
It's a meaningless question. There's no limit to how much you can obfuscate any program.
Not exactly what you asked but I wrote this tiny obfuscated code a long time ago: https://ideone.com/R4MobQ
Any C++ compiler support this trick/joke. Nice for obfuscated code. Just like this :) int arr[2]; 1[arr] = 0; 
Step 3. Write an AI to write the C compiler that compiles itself.
If you use the C++14 string literal suffix, yes. Except that there's no C++14 support in a compiler that ICEs on initializer lists. Otherwise they are likely allocated on the stack - and there really is no need to use a string if you aren't going to use an ounce of its advantages.
I meant the function used for folding... The post only mentions folding using built-in binary operators, but if I wanted to find the maximum argument by folding with std::max (for example) rather than +-*/ etc, how might I go about that?
You could check for !!!!!!p.isValid() if you _really_ wanted to be sure. 
`max(args...)`. Done.
Write a Malbolge interpreter. Then write a genetic algorithm to write Hello World in Malbolge. (The [first working Hello World in Malbolge](http://acooke.org/malbolge.html) was arrived at through beam search and wasn't published until two years after the creation of the language.)
Yes you can specify which variables are captured by reference (including 'this') and have your lambda take parameters: void func(int a, int b, int c) { cout &lt;&lt; [=, &amp;b](int&amp; c) { b++; c++; return b; }(c); } In that example b was specified as captured by reference. There are quite a lot you can do with lambdas (including nesting) so please take a look at this link: http://en.cppreference.com/w/cpp/language/lambda
The topic is generally still described as C++ metaprogramming. Most of the abstractions are compile time abstractions, so you'll find a lot of templates and (in newer code) `constexpr`. There are lots of books on the topic, but the libraries and language features in question are relatively new so it can be difficult to find contemporary references that will stand the test of time. I haven't read any of these, but they seem to be the most recommended: * [Modern C++ Design](http://www.amazon.com/Modern-Design-Generic-Programming-Patterns/dp/0201704315/ref=pd_sim_14_2?ie=UTF8&amp;refRID=0WJ2S0GEQKT0E0YB85JV) * [Generative Programming Methods](http://www.amazon.com/Generative-Programming-Methods-Tools-Applications/dp/0201309777) - this is a classic that I want to sit down with someday * [C++ Template Metaprogramming](http://www.amazon.com/Template-Metaprogramming-Concepts-Techniques-Beyond/dp/0321227255) This [tutorial](https://www10.informatik.uni-erlangen.de/~pflaum/pflaum/ProSeminar/meta-art.html) is probably the most reasonable introduction. The boost community may also have some good resources.
Is file an interface or not? In this context that's the distinction. Member function vs. free function does not matter, it's whether it's virtual or not.
[Templated huffman decompression with faux-binary](https://gist.github.com/anonymous/c1070a71d5f8245081e3). Came out pretty nice imho: N&lt;N&lt;N&lt;L&lt;'!'&gt;,N&lt;L&lt;','&gt;,L&lt;'\n'&gt; &gt; &gt;,L&lt;'l'&gt; &gt;,N&lt;N&lt;N&lt;L&lt;'e'&gt;,L&lt;'d'&gt; &gt;, L&lt;'o'&gt; &gt;,N&lt;N&lt;L&lt;'r'&gt;,L&lt;'W'&gt; &gt;, N&lt;L&lt;' '&gt;,L&lt;'H'&gt; &gt; &gt; &gt; &gt; ::decode_all("11111000010110100101110110110111000110010000011");
N00b.
My question was if it was possible to capture two variables by value, and have one mutable and the other not. Seems not, according to the cppreference page! 
I'd just let a butterfly flap its delicate wings...
Technically, this is possible, but probably not what you want. For example: int main() { int a = 5; const int b = 6; auto f = [=]() mutable { a = 4; b = 5; }; // error on assignment to b } A const variable that is captured by value is still const within the lambda even if the lambda itself is mutable.
`for (auto n : {"Hello", "World!"})` would have been fine too
I may have overly generalized it (and won't be surprised if I missed a point), but inheritance just happens to be a property of it. By definition, an object's simply a data structure that has data and can hold functions within it (and can be referenced). CRTP, being a method of implementing polymorphism, will require some structure or another that can contain a function. In C++, these structures can also hold data, so I'd consider whatever you're using to implement CRTP with to be an object. So having some structure that can contain data and hold functions as well as having the properties of inheritance, polymorphism, and encapsulation, I'd personally consider it OO. It's probably a stretch, but I don't consider it too far off. Edit: I'm not exactly a language lawyer or anything here, so if anyone's involved with the technicalities of the language, I'd love to hear.
I've written a bunch of blog posts about range-based interfaces in general, and the design of range-v3 in particular. You can find them on [my website](http://ericniebler.com).
Historically, iostreams is not part of the STL. The Standard Template Library is a subset of the Standard Library that includes the algorithms, iterators, containers, and functional components (binders, negators, etc.). 
It would need to be const char* const HELLO = "Hello, World!\n"; Without the second const, you have a non-const pointer, which (at least in principle) could have been reset to something else at runtime.
&gt; I don't see how that's in any way a useful distinction to carry forward from the mists of time. It's useful because people use the term "STL" and you should know what they're talking about. Much of the Standard Library would be considered poor design these days (iostreams, locales, std::string, auto_ptr ... at least we managed to nuke that one). But the STL is still worth emulating. It's a useful distinction. The STL is an exemplar. The rest of the Standard Library is a mixed bag.
That's why it's a fun question.
So genius!
Nah. Write a script to generate random strings and attempt to compile and run them as C++ programs. Only accept ones that output "Hello world". 
Not sure if this is breaking rediquette by replying to my own post, but someone figured out my e-mail address, somehow, and sent me a good critique. I'm glad they did. Please feel free to call me out on what I'm missing. His or her point was that enumerators are value types so it is important to minimize their size. I have been using `std::function` to minimize the code I have to write by relying on compiler provided copy and assignment constructors. Evidently there is a trick to use unary `operator+` to turn non-capturing lambdas into function pointers. http://stackoverflow.com/questions/18889028/ Added to the todo list. Lambdas seem to be at least 20 bytes. It would be good to get them down to 4 or 8.
Probably not, but I'm not in that camp. Why must I be aware at all times whether what I'm calling is a macro or a function? What difference does it make?
Not at all! The tutorial spends more time on them than on attributes, which is backwards IMO.
You have to invent baking. 
'Course there's an emacs command to do that.
Ahh, yes, it works that way. Makes perfect sense. Thanks!
This isn't merely complicated, it's pretty much doing its best to mislead a reader into believing that it's doing something rather different than it really does. #include &lt;stdio.h&gt; #include &lt;vector&gt; #include &lt;algorithm&gt; #include &lt;sstream&gt; #include &lt;string&gt; template &lt;class T, class U&gt; T lexical_cast(U input) { T result; std::stringstream b; b &lt;&lt; input; b &gt;&gt; result; return result; } template &lt;int num&gt; void show(std::string const &amp;s) { show&lt;num - 1&gt;(s + "0"); show&lt;num - 1&gt;(s + "1"); } template&lt;&gt; void show&lt;0&gt;(std::string const &amp;val) { char *c[] = { "OLD", "WALLOW", "HERE", " SWORE" }; char **cp[] = { c + 3, c + 2, c + 1, c }; char ***cpp = cp; printf("%.2s", **++cpp); printf("%.3s ", **++cpp + 2); printf("%.3s", cpp[1][3] + 2); printf("%s", val.length() &lt; 6 ? "" : val.substr(6).c_str()); printf("%s", *cpp[1] + 1); printf("%c\n", *(*cpp[-2]) + 1); } int main() { std::vector&lt;std::string&gt; nums; for (int i = 0; i &lt; 5; i++) if (i % 3 == 0) nums.push_back("fizz"); else if (i % 5 == 0) nums.push_back("buzz"); else nums.push_back(lexical_cast&lt;std::string&gt;(i)); std::for_each(nums.begin(), nums.end(), show&lt;1&gt;); return 0; } 
Yes please!
One of major tenets of OO is inheritance, how can it be orthogonal?
Lambdas' `operator()` are `const` by default, as it should be with _most_ functors.
The former is already OO :-)
The best I've seen was using an int [] named main as the entry point instead of a function, and the contents of the array being machine x86_64 machine code to print out the string "Hello World". The guy did it by writing some inline assembly, and dumping the instructions out in decimal using gdb. I'd dig up the blog post but I'm on my phone right now.
So you write an entire C++ compiler in C without having a C compiler? That is going pretty hardcore.
Fold expressions are like christmas for my eyes. Nice one! I don't have a compiler that supports fold expressions on me at the moment, but couldn't you just do: #include &lt;iostream&gt; template &lt;char... C&gt; void meow(C...) { (std::cout &lt;&lt; ... &lt;&lt; C); } int main() { meow('H', 'e', 'l', 'l', 'o', ',', ' ', 'w', 'o', 'r', 'l', 'd', '!', '\n'); }
Reminds me of [FizzBuzz Enterprise Edition](https://github.com/EnterpriseQualityCoding/FizzBuzzEnterpriseEdition).
Macros are unhygienic... In other words, you can possibly fuck up a macro, because it expands into other macros, that expand into other macros, that expand into code (or maybe it skips a step or two, but in my experience it tends to be macros all the way down :-) ) and all this gets injected into your context. So if you defined something you shouldn't have, error with no warnings. Variable shadowing? Fucked... and so on and so on. On the other hand, no matter what you did in your context, you cannot fuck up a function that is in separate compilation unit.
and http://codegolf.stackexchange.com
Unless you code it directly with opcodes, that's how you'd do it.
My vote would be for no. `auto` effectively serves as a concept representing "any type". I don't see why this particular concept should be a special case that is implicit. Always better to be explicit when you can. The way I see it, all these ideas about adding rules to the language that allow the programmer to "simplify" their code in some way should really be the responsibility of the IDE. For example, the IDE could hide `auto` if it really wants to. For everybody else who wants to be able to see the `auto`, they can turn that setting off or use a different IDE. Also, there's bound to be some conflicts with the existing grammar.
we really need something in place of macros for code-substitution. the easiest way to do code injection and it is still part of the language (more or less). just look at the full blown circus when it comes to code injections and the fat ass libs used in other lang.
Never use a macro over a function (Or similar), they obfuscate you from your code when errors occur. Keep the preprocessor to basic things like compile-time configuration, header guards, and anything you have to deal with through a C API. The only time I ever make an exception is with debug-related macros. For example, I tend to use macros for console-output, just for the sake of relaying debug information. Any even remotely modern compiler will *in-line* what it sees fit. There's no need to use macros. As far as stylistic choices for "macros" (Small utility functions/methods), I could see using the 'inline' keyword, but mainly to prevent potential linker errors. The fact is, code generation isn't as black and white as it used to be. You don't need to overstep the compiler by making a preprocessor macro. Likewise, don't use the preprocessor over typedefs, unless you have a very good reason to do it. (Compatibility reasons, mainly) **EDIT: I should also mention that lambdas are also useful for replacing macros.**
I've found one use for macros when dealing with libraries where functions return error codes as a way of passing \_\_FILE\_\_ and \_\_LINE\_\_ to an error check function. Something like this: #define ERR_CHK(call) errorCheck((call), __FILE__, __LINE__)
so better use just a function ?
The first assembler had to be written in machine code.
Yes, there are indeed still some cases where macros are required or make things much easier but for a new learner I feel they should be discouraged as much as possible.
For those who don't understand it: -~i == -(~(i)) so for an imaginary 4 bit integer: -~6 = -(~(0b0110)) = -(0b1001) = 0b0111 = 7 ~-6 = ~(-(0b0110)) = ~(0b1010) = 0b0101 = 5 Nothing magical about it, just weird use of the operators.
but what does it do? what's its purpose? answer: dynamic dispatch with templates, PIMPL etc. you do static dispatch 
 def Main() { print "Hello, World!" } Does that count if I also wrote the interpreter for this language? 
QtCreator is awesome, and a top-tier IDE, with the likes of Xcode and Visual Studio. When I get lazy and don't feel like writing makefiles I will even go so far as to use qmake + qt .pro project files as they are just SOO easy to use.
This is too important a question for the flippancy prevalent in the comments, most of which are the predictable and shallow criticisms of OO so typical of programmers jumping on the pro-FP, anti-OO bandwagon. (I'm dismayed to see community leaders like Eric Niebler joining in.) STL and range-v3 are fine pieces of code, but they are library projects. WebKit, V8, Clang, Blink/Chromium, Mozilla are all written using OO techniques, and every one I've looked at (Clang and Chromium) is a model of good structure and readability. If OO is as shit as everyone here seems to be claiming, what methods should we mortals use to structure medium to large scale programs? I would have hoped, for example, that someone could comment on whether Adobe is applying the approach outlined in Sean Parent's "Inheritance is the Base Class of Evil" (i.e. employing concept-based polymorphism together with type erasure) instead of OO on a large scale. I have been tempted to employ such techniques in my code base (a medium-sized app), but the approach is untried, I'm not sure of the full consequences across a code base, and my gut feeling is that it is *too clever* and will get me into trouble. Another interesting approach is demoed in Facebook's Fatal template library. See https://github.com/facebook/fatal/blob/master/demo/ytse_jam.cpp . This looks very attractive, but it seems to be aimed at prototyping rather than large-scale projects. Again, I'm curious if Facebook devs employ these techniques on large projects.
The list of supported IDEs looks now like this: generators = { 'eclipsecdt': EclipseCDTIntegrationGenerator, 'kdevelop': KdevelopIntegrationGenerator, 'xcode': XcodeIntegrationGenerator, 'vs2012': VisualStudioIntegrationGenerator, 'vs2013': VisualStudioIntegrationGenerator, 'vim': VimIntegrationGenerator, 'debug': DebugIntegrationGenerator, 'qtcreator': QtCreatorIntegrationGenerator, } Hopefully more LibreOffice devs will use QtCreator to develop LibreOffice.
DON'T. USE. MACROS. 'Nuff said.
Not really. Any program you think is the most complicated - you could write a program that outputs and compiles that program, or encodes and decodes it, or whatever, then one that does the same for that, ad infinitum. It's about as meaningless as "write the longest possible sentence", which could always be made longer by prepending some form of "he said '...", or "I was told '...'" onto it.
&gt; with the likes of Xcode and Visual Studio For C++ I'd argue that it's even better.
Not really. The central tenet of OO is dynamic dispatch. You may not believe me, so I quote Alan Kay: &gt;OOP to me means only messaging, local retention and protection and hiding of state-process, and extreme late-binding of all things. It can be done in Smalltalk and in LISP. There are possibly other systems in which this is possible, but I'm not aware of them. Inheritance does not figure in the above list. From William Cook: &gt;Inheritance is a mechanism for incremental modification of self-referential structures. Dynamic dispatch is essential to objects, while inheritance is useful but not absolutely essential. Thats enough of appeal to authority, so I have some code coming up :). You can do OOP in almost any language. All you need is a closure. Object Oriented Programming Languages (OOPLs) have built-in support for OOP. In C++, this is inheritance. In fact, C++ misuses inheritance to an extent, using the same mechanism for both interface and implementation inheritance. In C++, if you want polymorphic behaviour, you must inherit. However this in not necessary at all, even in C++. The type erasure pattern is an example of polymorphic behaviour without inheritance. For example, here is a program which does polymorphic behaviour without using inheritance. (Nitpick: std::function uses virtual function internally, but thats an implementation artifact. ) #include &lt;iostream&gt; #include &lt;functional&gt; #include &lt;vector&gt; using namespace std; const double pi = 3.14; struct Shape { function&lt;double()&gt; area; }; Shape makeCircle(double radius) { Shape s; s.area = [=]() mutable {return pi * radius * radius; }; return s; } Shape makeSquare(double side) { Shape s; s.area = [=]() mutable {return side * side; }; return s; } Shape makeRectangle(double a, double b) { Shape s; s.area = [=]() mutable {return a * b; }; return s; } int main() { vector&lt;Shape&gt; v; v.push_back(makeCircle(10)); v.push_back(makeRectangle(10,20)); v.push_back(makeSquare(10)); for(auto i: v) cout &lt;&lt; i.area() &lt;&lt; endl; } Maybe I should start a blog :).
How many strings allocations happen per line? Would it be possible to allocate upfront a single string (for a single line) and reuse that same string?
Wait...what? I'm being dumb but... Is 4 being developed in parallel with 5? How have I missed this... Edit: so it seems to be this: "Many users have already moved their active projects to Qt 5 and we encourage also others to do so. With a high degree of source compatibility, we have ensured that switching to Qt 5 is smooth and straightforward. It should be noted that Qt 4.8.7 provides only the basic functionality to run Qt based applications on Mac OS X 10.10, full support is in Qt 5." That's a pretty big commitment to provide updates to something they don't want developers using..
As an anal-retentive no-fun buzzkill, I do not like poorly researched jokes. These operators cause the C4146 error: "unary minus operator applied to unsigned type, result still unsigned" on VS when used with unsigned types, while the equivalent mathematical operations do not.
No. Opaque handle + functions on that handle is an example of Abstract Data Type, not OOP.
That's *way* too one-sided for my taste. To me, **the** idea behind OO is "data+operations = object". And indeed, without the above there's largely no dynamic dispatch, so there. You should note the following: in imperative world, prior to OO, there was procedural style. The problem with it was *way* too much operation on random global state. OO formalized the idea of data+functionality islands that became objects. Of course, prior to that, well written procedural code used this idea, but in a nonstandard and haphazard manner. Heck, it even did dynamic dispatch (think FILE\*).
In addition to these, I feel a little bit of background in functional programming is useful to truly understand templates, as C++ template metaprogramming is purely functional language. A little bit of Haskell... :)
For security updates, it makes a lot of sense. You're likely to make your users very unhappy if you *force* them to change over to a new major version (which usually has non backwards compatible API changes) in order for their software to be secure.
 for(unsigned long long i = 0, idx = 72635432210ULL, hi = 0x647257206F6C6548ULL, l = 0; i &lt; 11 || (std::cout &lt;&lt; (char)0x21, 0); i++, idx /= 10, l = ((idx % 10) &lt;&lt; 3)) std::cout &lt;&lt; (char)((hi &amp; (0xFFULL &lt;&lt; l)) &gt;&gt; l); 
I'm not sure but why is this here I thought 5 was being developed now I'm all confused 
Watching [Titus Winters](https://www.youtube.com/watch?v=NOCElcMcFik) explain it really helped me understand why they do it. I get their point; but I think they should just write more Java.
Upvoted. You're right, and shame on me for being flip. I've spoken with Sean Parent and seen a bunch of his talks in person. I know that much of the design advice he gives comes directly from his involvement in large-scale software development both in Adobe and an Google. Look for his "C++ Seasoning" and "Value Semantics and Concept-Based Polymorphism" talks. These are two of the best software engineering talks I've come across. The principles described there apply to software projects of all scale, large and small alike.
The optimization which does that is some form of more aggressive inlining, but clang doesn't expose knobs for the user to control besides the regular -O flags. There are some internal flags you can look into. If you want to try to identify the exact internal flags that are relevant you can take a look at the internal compiler invocations by passing the argument `-###` to the clang driver.
Thanks, I appreciate it. I was thinking in terms of some extra code I could add (or avoid) to nudge the compiler in the right direction.
It is, 4 is supported for a while by the looks of things
You're awesome! Thanks! I'm going to look at the assembly for each optimization and report back. The assembly I posted above was curious-- While the assembly pushed the values onto the stack (as above), it doesn't use them. Later in the code, it unwinds the loop and moves the values individually: movb $104, -17(%rbp) movq __ZNSt3__14coutE@GOTPCREL(%rip), %r14 leaq -17(%rbp), %rbx movl $1, %edx movq %r14, %rdi movq %rbx, %rsi callq __ZNSt3__124__put_character_sequenceIcNS_11char_traitsIcEEEERNS_13basic_ostreamIT_T0_EES7_PKS4_m movb $101, -17(%rbp) movl $1, %edx movq %r14, %rdi movq %rbx, %rsi callq __ZNSt3__124__put_character_sequenceIcNS_11char_traitsIcEEEERNS_13basic_ostreamIT_T0_EES7_PKS4_m ..And so on. Edit: Reporting back! Using -O1 did the same thing. It pushed the values onto the stack and then unwound the loop, placing each value (by value) onto the stack before the call, without using the values previously placed on the stack. Compiler issue? Code issue? Debugging? 
You can disable that.
?? You're aware Mr. Caisse is a longtime contributor to boost and is in fact on the boost steering committee? And anyway, if not for commercial interests, where exactly do you think C++ would be?
Macros are really only there for things that are impossible to do with functions. If you have to decide between doing something correctly or with a macro, there's really no choice in the matter.
Qt 5 isn't easily available on some older platforms (it's not in quite a few Linux repos, for instance). Qt 4.8.6 doesn't build on recent versions of OS X without some (trivial) patches. It's *possible* to create a codebase that compiles with both Qt 4 and Qt 5, but it's not a good way to write your code. So if you're supporting an application that targets both older Linux releases and OS X having a version of Qt that works on both is pretty useful.
Thank you for reporting this. It's now fixed.
&gt; Sorry about that. It's now fixed. 
It's not worth it even if it were free. Spend that time with a good book.
It's kind of like how Windows 8 is here, but Microsoft still produces patches for Windows 7. Support will eventually end, but there's still significant overlap.
You betcha. I worked with a guy who programmed with nothing more than a notebook of assembly listings and an octal calculator. Knew most of the opcodes by heart. The calculator was for computing jump address locations.
Been using C++ since the beginning. Back then the C++ compiler output was C code, not assembly (It was called cfront.)
I've been programming and interviewing for years and I wouldn't waste your time. Instead, I would focus on making sure you had a solid background in the fundamentals, regardless of language. If you are a grad student, I would focus more so on you specialty than any of that crap....its just noise.
What macros do is replace where they are with the "template" you give to them. They are NOT a replacement for functions in any way whatsoever. You only use macros where you're generating code (although I have to question why you're generating code through macros- templates are usually sufficient). I legitimately can't think of any examples off the top of my head, since it's so rare for them to actually be necessary. Just don't use them except for exceptional cases.
Sure does, ships with GCC 4.9 and Clang 3.5. You have to ask for those versions though, it defaults to GCC 4.8.
It might make a manager give you an insultingly low offer under the assumption that you're gullible and will believe him when he says that it's a good offer, but that's about it.
the certification is good to get past HR. they have no idea wtf they're doing anyway, and more shit on the resume (especially if you don't have experience) looks good for them. past HR, the papers mean shit. they're not worth the trees they were cut from.
you have a main() that doesn't return anything. i'm no expert but i think that's non-standard at best?
In many compilers return 0; is an implicit statement at the end of the function.
Not just in many compilers, it is mandated by the Standard.
I support your point of view, it's just good "keywords" for HR. For an interviewer it's doesn't matter. 
Not only is that standard, it is in fact recommended. The standard says that there is implicit return code of 0, if execution reaches end of the main function.
The lights at the top and in the reflection in the left sphere are having lots of steps in RUST while in the C++ version they are smooth. Might cost RUST a bit of performance to get those smooth too ;-)
You got downvoted but your question elicited answers that I wasn't aware of before.
It is going to be definitely a dark age (decade) for the windows platform. The largest group of developers in Windows is c# developers. All c++ developers are minuscule compared to them. To get those c++ developers you should provide plausible tools, environment and modern compiler. And Microsoft is years behind linux in that regard. They are really trying to return the developers back to the windows platform now. However, for many years (10 at least) they did just the opposite, pushing c++ back and away. For me, the only way to get back to windows is to forget this insulting behavior. And the best way to forget something is to pass a lot of time - not tools, money, compiler, etc. Even then, the wolf changes its skin and not his temper.
It was explained to me in the bug report comments that the error was not as stupid as it might have seemed at first. The approach taken by MSVC in this case is totally reasonable and this was simply an understandable bug in that context. So I apologize for flaming. I was just taking out my frustration at the time, I really wanted my code to work on Windows too :) Anyway, a Channel 9 video might be a good idea. It'd be nice to know a bit about the history of the compiler as well. It seems there was quite some technical debt that needed taking care of before all C++11/14 features could be implemented, it was not for lack of caring as it may have seemed to a lot of people.
I mean, I'm not going to argue on numbers as you're probably right that most Windows developers are not using C++ (And let's be fair, they probably don't need to be.). But let's not pretend that there isn't a LARGE userbase of the MSVC C++ compiler. Damn near every triple A game released is built on C++, and runs on Windows. And let me tell you, they're not using MinGW or Embarcadero. Also I question the premise. Are Linux developers vastly C and C++ developers? I can't imagine they are, even with all the Window Mangers and other big open source projects. I imagine most are running Python, or Ruby, or some other language that doesn't require them to touch the OS directly much. I dunno, I might be way off, it just seems kinda weird to act like there's some dark age because our language isn't the most massive one on our platform, and because our tools are out of date by the standard (Which is a problem, but I don't know about dark age material.).
Big games are almost always written in C++ but indie games vary more. Many people write games using Unity which uses C#.
I'd like to point out that while the other poster is right, Unity is used a lot by smaller studios and indies, consider the fact that Unity itself is written in C++. As is every other "major" engine I'm familiar with. Crytech, Unreal, Source, Torque, and Unity all are primarily made through C++, even newer "smaller" engines tend to do the same, like Godot, or Zero Engine. 
Do you mean a dark age for windows devs? This article just seems to reiterate why MS repeatedly balls up their C++ ecosystem rather than provide a coherent reason why C++ as a language is entering a dark age.
&gt; A second dark age for C++ on Windows FTFY
I am late to party here but tagged tuples would be helpful: http://stackoverflow.com/questions/13065166/c11-tagged-tuple Working with python developers, they want to use tuples to return multiple values which I find problematic without tagged tuples. You can use an enum hack simulate that but that gets ugly quickly.
And for anyone developing applications or libraries that might need to run on Windows. Those of us that do are also affected.
Kind of, the engine is usually C/C++ and then the games logic is C#. It talks to the engine via some libraries. Though C# sucks for game dev, a couple years ago me and my team were barely able to get a working pacman game to run in the 360 it was just so slow, and the C# Jitter had some nasty overhead.
Just Microsoft and their quixotic missions to reinvent wheels that never end up round.
Personally I recommend leaving it out for two reasons. One is that I really detest useless lines of code, and the second is precisely because it's a good idea *not* to treat `main` as any other function, because it isn't. For example, you can't call it or take its address. It's good to know (and perhaps emphasise) `main` is special.
No, `void main` is *always* illegal in C++. The only allowed definitions of the function are `int main() {}` and `int main(int, char **) {}`. You're allowed to leave out the `return 0` because the Standard guarantees that `main` will implicitly return zero on exit if no `return` statement is present.
&gt; they're not using MinGW or Embarcadero. Of course not, but many ARE using ICC and others would love to use Clang (when the ABI issues are ironed out). The faster MSVC is not seen as the only C++ dev environment for windows the better. The idea that MS should manage every aspect of their platform (including development) needs to die.
And as usual, questions like these are best asked in /r/cpp_questions. You might also find some answers on [SO](http://stackoverflow.com/) or your [favorite search machine](https://encrypted.google.com/search?hl=en&amp;q=eclipse%20with%20glfw)
I use macros, mostly for dead simple things like clamping between a min and a max, returning the lesser/greater of two values, wrapping a ring buffer index, etc. For example, I could write: template &lt;typename T&gt; inline T clamp(T x, T a, T b) { return (x &lt; a) ? a : ((x &gt; b) ? b : x); } or I could just write: #define CLAMP(x, a, b) ((x &lt; a) ? a : ((x &gt; b) ? b : x))
Yep, and if you want something even more comprehensive support check out [CrystaX NDK](https://www.crystax.net/android/ndk). Though that it takes a 3rd party to do this rather then Google is an utter disgrace.
Hey, that worked great!
In my experience it was never more than the usual qmake &amp;&amp; make and macdeployqt to deploy the application as a dmg, packed together with all required libraries.
If you have customized plugins, or using Qt Quick in your app, it's not as easy as that. I'm talking from experience, although my Qt wasn't the most updated while doing this.
This is one of those things people have strong opinions about when in reality it makes absolutely no difference to 99% of the people.
I never knew this was part of the official standard; good to know: EXIT_SUCCESS/EXIT_FAILURE
I think Unity is one of the only engines that uses C# for game logic. You're going to end up with a lot of Lua generally, or a propriety language.
I can't find his measurements, do you have any idea where they are?
You might be interested in [Runtime Compiled C++](https://github.com/RuntimeCompiledCPlusPlus/RuntimeCompiledCPlusPlus), [or one of alternative C++ runtime compilers](https://github.com/RuntimeCompiledCPlusPlus/RuntimeCompiledCPlusPlus/wiki/Alternatives) I've been maintaining a list of.
CppMasterRace!
/u/playmer already points out Unity is implemented with C++, [this thread](http://forum.unity3d.com/threads/unity3d-and-c.186855/) seems to agree with him ( before rapidly turning into a C++/C# flame fest ). Despite all the advances over the last few years languages like C# and Java can still be deadly for performance sensitive code and are not something you want at the core of a game engine. 
Step 3(a) Use VBA in powerpoint to write AI to write the C compiler that compiles itself
Meanwhile the Office team gave a [2-part presentation](https://www.youtube.com/watch?v=3HROqnw-nf4) at CppCon 2014 about building cross platform applications in C++. WinRT is not cross platform. So, the Office team is more interested in *minimizing* their use of the Windows Runtime. They will benefit more from advances in portable (standard) C++ than something platform specific, even if it's a Microsoft platform. And it seems culturally at Microsoft, what the Office team wants, the Office team gets. That may very well explain Kenny's point that the Visual C++ team is more interested in standard C++.
Yeah fair enough. That's showing that WinRT classes and functions in C# are as fast as those same classes and functions called from C++/CX. I doubt anyone would be surprised by that.
Is there an IDE that comes close to VS (&gt;= 2010) on linux? MSVC is not playing in the same ballpark as GCC and Clang when it comes to features; there are no useful 'checker tools' (valgrind, sanitizers, ...) on windows; compiling, using and installing any third party library on win is a pain (even with CMake)... ...but man, I really like the VS workflow; especially debugging. But maybe it's stockholm syndrome because I must use it for work. 
CppCamelCase!
&gt; And it seems culturally at Microsoft, what the Office team wants, the Office team gets Well, sort of. It's important to keep in mind that Office is perfectly happy to ignore what the rest of the company is doing and just build everything they need themselves.
But Qt is more or less it's own little ecosystem, one which you don't necessarily want to use just to be able to support Windows. Also, you're probably writing some C++ if you're using Qt which requires a C++ compiler. And it really sucks to have to cater to the least common denominator, which in 99% of all cases is MSVC with all it's peculiarities. So at least where I work, we are very much affected by what is happening in the Microsoft sphere, even if we are not a Windows shop per se.
We decided to drop MSVC because it's support for the new standard was so lacking. We will give it a try with with each new version, but we're unwilling to cater to it. Our codebase isn't that big, maybe 200kloc.
they are worth it if they are "universally" recognized. If nobody ever heard of them, forget it. Certifications are useful (even mandatory) for proprietary "things". (e.g. you apply to an Oracle DBA job)
And here I was thinking camelcase meant not capitalizing the first word. likeThis You know how camels slope downwards on both ends. Or something.
The C++11 Standard (3.6.1/3) does: &gt; The function main shall not be used within a program. Here you see the error for gcc: $ cat a.cc int main() { auto p = &amp;main; } $ g++ -pedantic -std=c++11 a.cc a.cc: In function 'int main()': a.cc:2:13: warning: ISO C++ forbids taking address of function '::main' [-Wpedantic] auto p = &amp;main;
My C++11 final version has it at 3.6.1/3: &gt; The function main shall not be used within a program.
Hahah. I'm not too worried about that side of things, more not wanting to misrepresent my employer :)
&gt; Are you the Crazy Eddie of CEGUI fame? No.
Yeah, I also meant primarily the debugging experience :)
I would vote "no" on this one; in a declaration, you have: const &lt;type name&gt; x [= &lt;expression&gt;]; When the &lt;type name&gt; is `auto`, I simply read declarations like these as "const &lt;type of the expression result&gt; x"; It would be bad for this syntax to support two forms (because we already have too much complexity in the language), especially when one of the forms would not match anything else in syntax (the "auto" keyword matches the position of the the type name, in the syntax of _all_ variable declarations it is used in). I would put this in the IDE (if at all), along with other code-folding options (and if it were an option, I think I would leave it disabled because I prefer to see it explicitly in the code).
A more or less detailed, but informal comparison could be found here: http://eao197.blogspot.com/2015/05/progc11-sobjectizer-55-compared-to-c.html Please note that I am not a CAF user. My knowledge of CAF is based only on reading CAF manual and reviewing some examples. But I have to mention yet another small thing. It seems that at this particular moment SObjectizer is more stable than CAF. It looks that CAF now a bit different than CAF a year ago. In contrast the compatibility is one of the targets for SObjectizer. As result code written in SObjectizer-5 1-1.5-2 years ago will probably be successfully compiled with the latest version of SO-5.
Well, XNA lives on through monogame.
I don't think even Apple fanboys will make an attempt at claiming xcode is up-to-par with VS or Creator.
Very cool!
You could try CLion ?
Do you speaking about comparison? Or about the framework? ;)
Let see how this Windows Devs vs DevTools issue plays out with the upcoming .NET Native arrival (now for UA, later for the remaining deployment scenarios). As for C++/CX, I don't see it any different from C++ Builder, Objective C++, or any other vendor specific extensions.
Is there a way to leverage the parallelization method in a distributed environment, a la map reduce? The biggest bottleneck would be propagating the first n - 1 carries to the last machine, and since the use of a distributed compute implies the full dataset does not fit on a single machine, I'm guessing the bottleneck degrades to streaming compute.
Which C++ improvements would you specifically attribute to Microsoft?
I didn't say that it was a good footprint. ;-) I'm not sure what I'd attribute to Microsoft (or any other company for that matter), other than to say that whatever they do with C++ has an impact on a huge chunk of C++ developers.
UPDATE: They've fixed the problem [here](https://youtu.be/uXBcwcF3ln4)
It doesn't degrade, but uses the same tree-algorithm: http://www.mpich.org/static/docs/v3.1/www3/MPI_Scan.html The idea being you would perform a local scan, distributed scan, then local adjustments to account for the distributed scan.
My point is that this algorithm is precisely the hierarchical implementation that all parallel scans use, just using AVX lanes in place of thread groups, MPI processes, etc. A generic distributed scan would then look something like this: my_favorite_local_scan(local_data) partial = my_favorite_distributed_scan(local_data.back()) local_data += partial The distributed scans are implemented very similarly to what is presented, just with the "add" steps involving a communication (log P steps in total).
Is Google moving away from Java? I don't know enough of Java to use the NDK, but I would like to play around with Android using C++.
I sit there and figure out how everything I do works out of curiosity, so I can't really say. If I can't figure something out there's always google. In general, though, as a kid and at a job or two, I've had a method we'd need to do to get something done that was for some reason more efficient than others, or somehow just seemed to work, and I used to stop and think for a fair amount of time to figure it all out, ex. "why are all of these pipes not made level?"
Fiiiiiinally!! Excellent news.
I don't think the dark age is from the lack of innovation in the standard. It's from the lack of progress in the actual real world of folks getting things done.
definitely wouldn't feel good about it, especially for personal stuff. For work/commercial stuff in a larger team environment I'd be OK with it because company practices *should catch bad code from going into a production or even development setting. 
This braces/newline style is one of the weirdest I've ever seen. Took me half a minute to get what was a function definition and that there was a function body. Anyhow, useful introduction to program_options imho. I couldn't reproduce your issues with boost and vc14 though, I successfully compiled and used it a couple of weeks ago following the standard tutorial.
I feel like a million null pointer exceptions just cried out at once
I write about things that interest me, and post them via various channels, and I appreciate every response I get. I have made all my posts under my own real name. Never used sock puppets, or robots of any kind. On occasion, other people, or even other people's bots may post links to my site, but an honest review of the [listing you linked to](https://www.reddit.com/domain/nu42.com) shows that most of the links were submitted by me. I do not understand your hostility.
Hmm, in the talk he says that C++ isn't actually supported in the current 1.3 preview that's available at the moment and is slated for a later 1.3 preview version? Unless I misunderstood.
My bad, I forgot 5.0 wasn't a thing. Make that 5.2 then.
Mmm not a big deal :/ There are already many great C++ editors out there that I assume most NDK developers are already using. Having a C++ IDE and (more importantly imo) a debugger part of Android Studio is really cool though. Now, if they would release an Android C++ API, THEN there'd be something to really be excited about :) All in good time I hope!
I won't say I've never been bitten by it, but its found far more problems than its caused. 
Yes, I also noticed that. Since 1.3 is still in the Canary channel, I think the C++ support will come with an update some time before this version is actually released.
See [here](http://stackoverflow.com/questions/14808783/wrap-c-allocation-for-raii) for a more convenient way to do this. You're right, this is a good pattern to use. That's why C++ has constructors and destructors in the first place, to automate resource acquisition and release.
It's going to take some time, but eventually there will be good libraries that will wrap all this junk in a modern way. I wish I could find the link now, but there was someone that had been mentioning their own C++11/C++14 Win32 API wrapper library, in the vein of WTL. There's also [Modern](http://moderncpp.com/about/).
I don't know if the situation has gotten any better in the last few years, but before that I used to work at a place where the game engine, as well as the games, were written in C++ and on Android the system used NDK pretty heavily. And it was terrible. Back then there was some talk of a possibility of getting gdb to support NDK debugging, but it wasn't implemented yet, so everything in the native code was nigh undebuggable. Not to mention the NDK build tools felt like a neglected lower-class citizen in the Android world - most of the time I was wary of updating to the latest version because so many things usually broke with that. Plus having an IDE support, I'd wager, means that there are finally some official tools for handling your NDK projects without hand-crafting a ton of build scripts yourself. That's such a huge relief for anyone having to work with NDK.
It hasn't changed at all. So now the choice is between crippled C++ support or Java 6 (7 is only properly on 4.4 onwards). If they don't any plans to improve the Java story, at very least could do like Apple and Microsoft and offer decent platform API to C++ devs.
One way to manage it is to use scopeguards, and whit c++ 11 and lambdas it's easy to do.
Well at my company, we do roll our gradle scripts by hand, so we've already gone through that pain. The NDK came with gdb-ndk script which did actually work mostly, back in the ant days. (I started on android development around SDK 11~) Now, with gradle, I'm not sure if it's our overly complicated, fucked up , hand rolled gradle scripts or the gdb-ndk script itself, but it no longer works. I do most of my debugging in XCode on the iOS version and if it's an Android specific crash, usually fall back to callstack dumps (which we have to implement ourselves, or reproduce on devices that print it for us...) and print statements. I do appreciate the C++ debugging support in the IDE for sure, but it also means we need to redo our build scripts to get it working within the Android Studio IDE (which we havn't done yet, do to time constraints) I really hate gradle. Honestly, why the fuck did they need a whole new programming language no one knows, leveraging a custom plugin to a framework nobody knows, just to configure your build. Ugh.. but that's another topic :P Beyond the builds, the biggest heartache with developing native apps on android for me, is that 99.99% of all the android functionality lives in Java, which means you need to interface w/ the JNI. If we could get a C++ version of the Android SDK that would be the greatest thing I think Google could do for native development (aside from straightening out their gdb support, which in my limited understanding appears to be, an elaborate script that installs a temporary gdb server on the device and connects the system gdb to it in multiple hundereds of lines of sh script)
I think they are just realizing that if they want to compete with iOS in games and other real time applications, they need to make their NDK easier to use. Native development for Android is a giant pain in the ass and I think they realize that they are losing a massive market share in their playstore because of it. Why go through the headache of writing your game for android, when you can do it on iOS with way less effort? They need to catch up and I really believe they will with time, just started a bit late. It's unfortunate for everyone, because Android has so much more of the market on their devices, so developers lose out by not supporting it big time. In fact, if Android wasn't such a market leader in devices no one would even bother. 
On iOS one gets Objective-C, Objective-C++, C, C++ and Swift. All sharing a common runtime, sort of. On Windows Phone/Store, one gets JavaScript, C, C++, C#, VB.NET, F#. All sharing two common runtimes, sort of. On Android one gets Java 6, with partial support for 7. A crippled NDK and the privilege of having to write JNI wrappers. With Google just caring about re-writing their IDE and bringing APIs to versions no one is able to update to. But everyone jumps of joy, because hey it's Google.
&gt; Why go through the headache of writing your game for android, when you can do it on iOS with way less effort? Market size. iOS isn't a big player in all countries where customers tend to go for pre-paid mobiles without subsidies.
It's all fine until something doesn't work. On the subject of std::regex, see http://stackoverflow.com/questions/27331047/c-std-regex-crashes-in-msvc-during-long-multiline-match/30128172 In reality you just have to decide how much time you are prepared to sink into a given topic. To quote Stroustup: "Spend an unreasonable amount of time on some difficult topic to really master it. Try to do something that might make a difference in the world." Note he didn't say *all* topics! ;-)
These blog posts may be of some interest https://msdn.microsoft.com/%20magazine/hh288076 https://msdn.microsoft.com/en-us/magazine/dn948103.aspx
And degenerated into segmentation faults
Well. Probably it's very much possible to change hash code to 64 bit. The only real reason I used 32-bit was backward compatibility with existing hash functions. I created this container while trying to satisfy following needs: * ability to insert a lot of items (millions) quickly without delays, preferably with moderate memory usage. * ability to iterate over result as fast as possible. 
I see you are not using exceptions, don't know if windows libraries throw signals for resource acquisition errors. Having that in mind, by putting an acquisition inside a constructor, you assume that it is always available and safe to get and lose the verbosity of a return message. Alternatively, you can overcome this by setting an error member inside your classes and control them once in a while, this "once in a while" quickly becomes never by the users of library so I avoid it for front-ends.
To each his own style I guess! :-) That was the part that got me scratching my head. I guess I just wasn't used to it: void show_help( const po::options_description&amp; desc, const std::string&amp; topic = "" ) { function body } Btw, regarding Boost, their headers have some "smart" logic to find out to which version they should link against. I'm using CMake and I just disable the boost logic by defining `BOOST_ALL_DYN_LINK` and `BOOST_ALL_NO_LIB`, and it then works fine. Probably only the latter would be sufficient as well.
It probably would have been better to use void show_help(const po::options_description&amp; desc, const std::string&amp; topic = "") { // function body } 
Regarding the needs, you might be better served with open-addressing schemes (such as used by cuckoo hashing or robin-hood hashing). Because they are array-based, without an extraneous bucket list: - there is no per-item memory allocation - there is better memory locality Depending on whether latency is an issue you might need linear rehashing, but that also affects array + buckets strategy.
 #include &lt;thread&gt; #include &lt;mutex&gt; #include &lt;condition_variable&gt; #include &lt;iostream&gt; #include &lt;vector&gt; #include &lt;string&gt; #include &lt;algorithm&gt; #include &lt;chrono&gt; int main() { using namespace std; using namespace std::chrono; string str="Hello, world!"; condition_variable v[str.length()]; bool f[str.length()]={}; vector&lt;thread&gt; t; mutex m; for(auto i:[=]()mutable{int x=0;transform(str.begin(),str.end(),str.begin(),[&amp;](char c){return x++;});return str;}()) { t.emplace_back(thread(bind([&amp;](int y){unique_lock&lt;mutex&gt; ul(m);f[y]=true;v[y].wait(ul);cout&lt;&lt;str[y];f[y]=false;},i))); } int idx=0; for(auto&amp; c:v) { unique_lock&lt;mutex&gt; ul(m); while(!f[idx])c.wait_for(ul,milliseconds(1)); v[idx].notify_one(); while(f[idx])c.wait_for(ul,milliseconds(1)); ++idx; } for(auto&amp; h:t)h.join(); cout&lt;&lt;endl; } 
Sure. Instead of using asserts however, I have found much better use just throw an exception when an invariant is violated &amp; this stays on in debug &amp; release. The benefits over assert in my view are: 1. You can add messages from the call-site. 2. Using boost exceptions we can append data to the exception as the stack is unwound (e.g. the pathname may be available at a higher level whereas the exception only has access to the file-descriptor) 3. We can write negative unit tests that exercise failing codepaths (i.e. assert that the invariants hit as expected).
You have all these wrappers in various libraries. Use them.
Wow... That's absolutely horrid way to do it, who taught you that?! Acquiring any resource is not safe and it's easiest done in a constructor. No verbosity of a return message needn't be lost, you capture it in an exception and throw that. About signals (I presume POSIX-style): no such thing in Win32. There's what MS calls "structured exceptions", but that's pretty far from signals and resource acquisition does not do it.
Even a pure Java-based app doesn't work across all Android devices - not even close - so app developers already have the hassle many build targets.
Depends. Are you responsible for maintaining it or are you just using a library? The latter, well I use a lot of stuff I don't know how it works. The former...you should know how code works if you wrote it!
Fair enough, my perspective is coming from the states. You're right :)
Well I'm not familiar with Qt or their android integration, but I'd imagine a large part of that is the qt library itself too.
Of course; this (general) use case is the whole reason C++ *exists*. OP should absolutely write a wrapper if none of the un/official ones work to his liking.
For my own stuff, it can really bug me because it becomes this black box mess of code that you fear touching again since you may not know what will happen; it's just bad for future maintenance. As far as libraries, I love that I don't need to understand the implementation (as long as I know the basic performance impact of it), as that's the whole point of a library! It's no difference to not understanding how a CPU or an IC in a digital circuit is implemented, as long as it follows the specifications necessary to you.
Yeah, most likely.
I think you misunderstood what I said though. I was suggesting a system through which app developers would compile their code to, say, LLVM bytecode with the Clang compiler, then when the app is installed on a phone it uses whatever tools are needed to compile the bytecode to a native executable. I don't know how feasible this would be but it wouldn't necessitate universal binaries.
Win32 is the API which came out with Windows 95 twenty years ago and before the C++ ISO specification. MFC and ATL were basically wrappers of this. WinRT finally brought C++ UI API parity with the managed languages and hopefully will see broader adoption once Windows 10 roles out. https://msdn.microsoft.com/en-us/library/br224617(v=vs.85).aspx
[Well, 4-ary isn't really wrong either.](https://en.wikipedia.org/wiki/Arity#Other_names) I also think it's a bit more clear.
My goal with this series of posts is to use only the standard library, and Boost, but [tclap](http://tclap.sourceforge.net/) looks really good. Thank you for mentioning it.
&gt; I don't want to use std::shared_ptr because I don't want to think about managing memory at the API level, I want the library to handle it for me. I'm not sure I entirely understand this statement. If the library is encapsulating these hardware interfaces, then why not use `shared_ptr`? The library _would_ be handling the memory management in that case, and at least from your description this problem screams for its use. If you really don't want to use `shared_ptr`, then it seems like you have accomplished your mission. You're basically reinventing it across multiple classes.
&gt; index_sequence cool, how did you calculate the curve fitting coefficients?
Moves and copies are basically the same, they set the isSource to the value of the original and set isSource to false on the original. So you can copy a true, which then becomes false, and also copy a false which remains false. If I use share_ptr I need to implement a "Manager" class which issues Class objects, and I don't want to use the factory pattern.
I could implement a factory class which issues Class references with shared_ptr but I can remove the factory class altogether with my approach. So my question probably should be, why use the factory pattern since we now have std::move()?
I don't use the heap directly in my library so I have no pointers to hold. I am using STL and std::move() instead. The question probably should be, why use the heap if you don't have to? Also I can tightly pack large buffers if I avoid heap allocation directly and (I hope) results in faster traversals of the collection.
To clarify, I can pack a buffer tighter using std::move() than using heap pointers. The collections are large and I iterate over them frequently (multiple times a second). It is basically an optimization I am testing to not use shared_ptr.
I'm curious about why you're associating moving and `std::move` with stack/heap allocation. Any object can be moved, regardless of where it has been allocated.
&gt; I find std::move() can pack the containers quite tight. This does not add up for me. std::move() does not change your class' data layout. Your instances will appear the same in a container. Also, if you are using std::vector(), you are on the heap anyway. For an answer to your problem, as much as I understand it, I would need to know why you don't use references for the views, and instances for the owners?
True and true. The difference is, on the first example the pointers are in aligned memory, not the objects. On every iteration of the loop there is a latency hit when you access the data at the pointer.
Yes, sorry, I was just pointing out that `std::move` is irrelevant here.
`std::move()` isn't doing anything of value in your example and should not be there. An expression like `Class()` is already an rvalue, so there's no need to cast it to an rvalue, which is all that `std::move()` does. Besides, you can skip the move entirely by using `emplace_back` which constructs the object in the container, instead of constructing a temporary and then moving it into the container. 
You are correct. The class data is on the heap using a vector. std::move doesn't do any special magic. With std::move you can pack a vector with objects where the objects are in aligned memory, versus having a vector of pointers where the pointers are in aligned memory. If you use pointers you will suffer a latency hit when looking up the data stored at the pointer on each iteration of a loop. With regards to the views, there really isn't a problem. I want to have shared state objects that don't use pointers and the only way I know how to do it is by using the "pass the torch" design pattern. It just doesn't conform to C++ 11 paradigms and I want to know if that makes it bad by default.
Class(const Class&amp;) = delete; And my compiler won't compile without it. Class() may or may not have parameters, it is just an example. 
That is basically my question. What is "correct"? In assembler, there is no such thing as correctness.
lol and go over IP law suits with Oracle every other year :)) JAVA is POISON
it looks like some macros implementation while much superior way is to use the new c++ and things like lambda :) 
create 1 general wrapper which accepts a lambda in the constructor that gets invoked in the destructor. like scope exit the c++11 way then you can add the release code for any case you have or might have. this is good if you have relatively few cases and they are diverse enough. wasn't there proepr scope_exit in stl already? well first search in google leads to this one : http://the-witness.net/news/2012/11/scopeexit-in-c11/ exactly what I was hinting at! 
suspending &amp; resuming allows you to have concurrency without the need to resort to parallel implementations (threads).
asserts are not to be mistaken for runtime error checking. asserts are live documentation via contracts for you functions! asserts are low level and intended for you and your colleagues, actual err handling must be on an abstraction higher in your app. even on the non-exceptional path exceptions are enduring cost by making the code simply more! the endure even more cost on ARM machines!
hahaha too many drama queens about macros :D they are everywhere, live with them or die &gt;;] but yes they suck, which doesn't mean they are useless and definitely we need the pre-processor maybe not via macros. I love one step replace code before feeding it to compiler, what macro can do no one can :D
There is a more complex example at [Meson unit tests](https://github.com/jpakkane/meson/tree/master/manual%20tests/2%20multiwrap). All of this is planned, yes but we wanted to start simple to show contributors that wrapping new projects is relatively straightforward and simple.
Actually adding a subproject to CMake is as easy as calling add_subdirectory pointing to the subproject dir. There is also a more sofisticated ExternalProject_Add.
Did you even tried ? Because the very point of it , is to parse the complete FIX protole , not just a few pairs. I am not advocating spirit at all , since that library gave us a lot of pain for debugging, but hand made parser of pairs with injection in MSM was faster in spirit than anyother handmade method. The asm code once optimized even beat the legacy asm code we were using ...
Cool. Can Meson generate IDE project files?
I've never used C#, but I happen to know that LINQ is somehow influenced by Haskell. In any case, C# is not a functional language.
I think all regular readers/lurkers by now know about this guy (or the blogspam for this product), which is why most of the time nobody comments. When I feel bored, I click on one of these and see what kind of errors they talk about, and once in a while that helps me notice similar kind of crap in my code. Just my $0.02
I use a struct when there are no non-public members, and a class otherwise. This is purely a personal preference. There's no difference between them other than the default access control.
we can set the access in a struct to private for each variable or function, which is sometimes useful and in line with the use of a struct
It's personal preference. I use structs for "dumb" data types (PODs mostly) and classes for more complex types.
I follow [Google's style guide](https://google-styleguide.googlecode.com/svn/trunk/cppguide.html#Structs_vs._Classes): &gt;Use a struct only for passive objects that carry data; everything else is a class. &gt;The struct and class keywords behave almost identically in C++. We add our own semantic meanings to each keyword, so you should use the appropriate keyword for the data-type you're defining. &gt;structs should be used for passive objects that carry data, and may have associated constants, but lack any functionality other than access/setting the data members. The accessing/setting of fields is done by directly accessing the fields rather than through method invocations. Methods should not provide behavior but should only be used to set up the data members, e.g., constructor, destructor, Initialize(), Reset(), Validate(). &gt;If more functionality is required, a class is more appropriate. If in doubt, make it a class. &gt;For consistency with STL, you can use struct instead of class for functors and traits. &gt;Note that member variables in structs and classes have different naming rules.
You should use VS Community instead of VS Express now - Community has many more features. (As I understand it, Express is still available because there's a small number of people who prefer its licensing.) You can also use my [MinGW distro](http://nuwen.net/mingw.html) on Windows. It comes with SDL, GLEW, libpng, libjpeg-turbo, FreeType, and many more useful things already built, so you can get started with OpenGL easily. Here's an [old screenshot](http://nuwen.net/img/news2010/stw20100503lg.png) of what my game engine-in-progress, built with my distro, can render.
If you want your program to work on more than windows: Take a look at [Qt](http:/qt.io/) . It's open source (commercial option is available, too, if that is needed), comes with a nice IDE and great documentation. And Qt applications run on Mac, Linux, windows and a number of mobile platforms -- provided you do not use platform APIs yourself of course.
I'm super surprised the author didn't know about the `do {} while (0)` trick. It's an extremely common practice. At best, this post is a shitty advertisement.
Perhaps I wasn't clear. No, not error checking. Any place we would normally put an assert we put an unconditional check (think equivalent to Preconditions from the Guava library). Yes we use exceptions for errors too where appropriate but that is unrelated to this discussion. Exceptions don't add that much code, especially when you're already using them. Additionally, optimizing compilers are going to be doing cold/hot code splits to reduce the cost further soon. That means all your exception handling code is going to be living far away from your regular path, further reducing that overhead. ARM exception handling, at least for 64-bit ARM uses 0-cost. Even when it doesn't, in practice, I have not seen it ever really be in the hot code path and matter. The trade-off of having fewer permutations of code and much better coverage of the assertions, in my experience, has outweighed any theoretical concerns about performance overhead.
None of that is specific to structs; the same can be accomplished with classes.
[From the C++ FAQ](https://isocpp.org/wiki/faq/classes-and-objects#struct-vs-class): &gt; **What’s the difference between the keywords struct and class?** &gt; The members and base classes of a struct are public by default, while in class, they default to private. Note: you should make your base classes explicitly public, private, or protected, rather than relying on the defaults. &gt; &gt; struct and class are otherwise functionally equivalent. &gt; &gt; Enough of that squeaky clean techno talk. Emotionally, most developers make a strong distinction between a class and a struct. A struct simply feels like an open pile of bits with very little in the way of encapsulation or functionality. A class feels like a living and responsible member of society with intelligent services, a strong encapsulation barrier, and a well defined interface. Since that’s the connotation most people already have, you should probably use the struct keyword if you have a class that has very few methods and has public data (such things do exist in well designed systems!), but otherwise you should probably use the class keyword. I personally just follow the coding standard I have in place. Whatever you decide for whatever reason, just be consistent for the sakes of anyone that reads your code.
There's also [docopt.cpp](https://github.com/docopt/docopt.cpp) -- a pretty nice C++11 implementation of [docopt](http://docopt.org/).
You know, I love how you can post this kind of thing in /r/cpp without starting a religious war.
I personally prefer using structs for all types. I then use class for template parameters, and typename for dependent type lookups. But this also comes from my preference to place all public interfaces of a type before its internals in its declaration. "Types is types", in my opinion.
Ooh, hey, that's neat. Now I just need to get around to getting a windows VM for dev.
&gt; A struct simply feels like an open pile of bits with very little in the way of encapsulation or functionality. A class feels like a living and responsible member of society with intelligent services, a strong encapsulation barrier, and a well defined interface. This x100
The other difference is that struct-struct inheritance is implicitly public, whereas with classes it's private.
Another implementation of tuple_cat: https://github.com/KrishnaAchuthan/tuple/blob/master/new_tuple_cat2.hpp 
There's also wxWidgets which comes in a less restrictive license (allows static linking).
Yep.
I do not think you can compare Qt and wxWidgets. Plus Qt is LGPL, so the statement that it disallows static linking is wrong. You can statically link -- provided the user can still change the Qt linked to your program. That is no problem for open source programs. Proprietary applications can either make their object files available so that users can relink the application or they can just get a commercial license. If a company with a proprietary product can't afford a Qt license, then that company has more pressing problems that software licensing anyway. 
class foo; struct bar { foo *f; }; struct foo { };
Keep up to the good work. I saw your presentation video at Meson website. The philosophy is great: 1 second spent in the build tool is a second wasted :) To be honest, I hate CMake. I do think autotools is quite better. But CMake enables windows and project generation: these are killer features for project contribution that cannot be ignored. I will give a test to Meson with one of my projects. This could test how good you are about cross-compilation. I will target mac, ios and android to start, but there will be more later :D. On the other side, at my company we are working with microcontrollers all the time. I am at a techincal management role at my current job. What we need is to have test runs inside microcontrollers and get the result, plus cross-compilation for said devices. My company works closely with Motorola. We have to ship reliable firmware to customers: there are hundreds of thousands of customers already and we are missing a good pipeline for really fast feedback. Maybe Meson could be an option, but I am afraid that it is "too experimental", and this would be my responsibility. Do you know of any expected caveats I will find when cross-compiling? We will need fine-grained control: no standard library linked and much more, since we have some microcontrollers that have as little as 8 or 16 KB ROMs. 
It is very telling that since version 4.8, to build gcc, the ubiquitous C compiler from source you need a C++ compiler :) "GCC now uses C++ as its implementation language. This means that to build GCC from sources, you will need a C++ compiler that understands C++ 2003. For more details on the rationale and specific changes, please refer to the C++ conversion page." https://gcc.gnu.org/gcc-4.8/changes.html
I think you'll find *developer* time is greatly decreased. C++11 makes the language a lot more fun, and easier to use. At times it almost feels like a scripting language now.
I always found programming in java was like sitting on a sofa while C++ was hard and bumpy like driving a kart. The new C++ standards do make it cushier. I suspect though this comes in detriment of control. I was just reading the new Herb Sutter book and auto resolution rules. It just makes bridging the written C++ language to the resulting asm instructions so much more obscure that I try not to use auto, including on range loops, whenever possible. About 50% of our technologists have less than 5 years experience and just about a handful of universities have c++ as mandatory (Michigan and Urbana come to mind), which means I have to keep those guys on a leash while they get more experience, otherwise they will splurge on the web of new features and produce everything but code consistent with our platform. alias instead of typedefs were genius though.
You do make an excellent point!
std::function has nothing to do with lambda, of course you can assign a lambda closure to a std::function, but it's not the same thing. std::function is expected to be slower than a plain-old function, for more comparison you can see this [benchmark](https://github.com/jamboree/CxxFunctionBenchmark).
You just got around to testing auto/lambda now? Shits been available for years- Anyway, these "syntax sugar" features like lambda make coding c++ about 100x more enjoyable. There is also no reason that lambdas should be slow, and their design is quite logical for a systems language. If anything lambda syntax is not sugary enough, I'd prefer it if lambdas required less typing. Variadic templates reduce complexity, when you need what it offers, it is far less complex than what c++98 required 
std::function != lambda
I have not personally done cross compilation so this part of Meson is not as polished as other bits. That being said I do know of people using Meson for their cross-compilation needs and they seem happy. Running cross-compiled binaries during tests is something Meson does natively. You just specify an exe wrapper command to use. As an example when cross compiling windows apps on Linux you can set the exe wrapper to "wine" and you can run your test suite natively. All you should need for cross compilation is a definition for your compiler. These exist for gcc, clang and msvc. If it's something more exotic, then you need to add the definition (in compilers.py). After that it should be just a question of setting your compiler flags correctly.
&gt; I made the mistake to replace the usual virtual/abstract interfaces (think _client-&gt;onEvent() ) for a generic one taking a lambda (std::function) No. Just no. A lambda is not an `std::function` and an `std::function` is not a lambda. All the implementation of `std::function` that I am aware of use polymorphism behind the hood, hence if you are trying to replace a virtual interface with a bunch of `std::function` you have to expect worse performance (you get N vtables instead of just one, and probably a bunch of useless noise in the lambda captures if you initialize your `std::function`s with lambdas). I believe that your statement `While performance gains are null or is even worse (eg lambdas are badly implemented)` is influenced by this misconception. Lambdas *are* syntax sugar for a functor class. The performance overhead of using a lambda in place of a C++03 functor is zero. Moreoever, the fact that you do not even mention move semantics (and the huge performance improvement that comes from it) makes me think that you probably need to get a better understanding of the language before making strong claims like "performance is worse than in C++03".
` NSObject` would like to have a word with you :p
A function is not a lambda. The output of your compiler can not be optimized any further, you are simply using something highly generic (`function`) where you are not supposed to. What you are supposed to do is make your `traverse_lambda` templated on F, or use `std::for_each`. 
Best username I have ever seen.
That is *not* a lambda. Let me rewrite it for you. template&lt;class Op&gt; void traverse_lambda( std::vector&lt;uint32_t&gt;&amp; vec, Op op ) { for ( const auto&amp; v : vec ) { op( v ); } } std::function is a library type for holding type erased functions, and has *nothing* to do with lambda. 
I tend to think of encapsulation as a creation of a mind. I found that thinking in terms of memory layout (and not using too much multiple inheritance if you do not which to suffer from brain damage except in special cases like mixins) is not much harder that thinking of object-oriented-uni-classes-traditional-inheritance-encapsulation-opposition and has the benefit of really seeing how your program will behave in memory. And for added value, seriously, not having to write `new` / `delete` in any way is worth so much. Same for lambdas, it reduces some code by a factor of five or six especially in cpp14 with full captures. And constexpr! That shit is just crazy, you can have almost everything "compile-time-able", well.. compile-timed.
You'd prefer it if lambdas required less typing. k.
Perhaps it does not apply. I always use placement new for pretty much every single object that has to be constructed. I never use any STL (they are all very slow) but have custom containers that exploit application information like bloom maps, different types fast hash maps (cuckoo). Dont be surprised. It just does not apply.
That was a test. But in the real usage I had to store the address of the actual function/method as a member variable. Do you see any other way to rewrite it with this in mind?
Keep in mind however that MSYS2 is a unix emulating environment, so you'd probably want your build scripts to check if you're building using MSYS2. The code however, is how you would write it as if you're using visual studio, excluding the VS only stuff like MFC or the likes. But most Win32 libraries that you need are on there. As an IDE I recommend Qt Creator, which is also on their repos. You can use whatever IDE you like though, but in my experience using Qt Creator was a pretty smooth experience with MSYS2.
precisely, it makes it easier to write, and easier to read later. -generic lambda should not require "auto", just specify the name and auto should be implied Here is a rust lambda: |j| println!("hello, {}", j) No pointless braces required. 
The question is, what do _you_ have in mind? It apparently isn't std::function nor lambdas. It seems to me you want more than you had in C++03 but you want it for free and for some reason are surprised you didn't get it.
&gt; the potential for abuse due to honeypot features (eg variadic templates) Do you have something in mind here or is this just random FUD?
screen to be in the first two, but I have a diablo chapter there :P.
Great stuff, and well written. Love this quote: &gt; Lisp is today's equivalent of Latin. Educated people are supposed to have studied and forgotten it.
MATLAB runs on Linux and Mac.
Yea I know. My point was most engineering students in non computing domains are largely only exposed to windows. So that might be why I see so many MEs using win forms and VS by default.
Here (France) most public schools and uni use exclusively Linux and you see Macs / Windows boxes only for specific classes or private schools.
Neither g++ nor clang++ will complain about this, though clang will warn if you give it -Wmismatched-tags. Google suggests that VS will (or at least would?) mangle the names differently, but it also suggests this is a bug. I don't think this is an error.
Which particular features allow C++ to build systems infinitely more complex than C?
I like using structs for everything because 98% of the time public accessibility by default is what you want. So things like this: class Foo : public Bar { public: blah blah blah private: blah }; become terser: struct Foo : Bar { blah blah blah private: blah }; And in my head, it just feels cleaner to have one thing to worry about instead of two, even though they're really equivalent.
&gt; Do you agree? No, No and No. C++11/14 is much more as just auto, lambdas and variadic templates. &gt; While performance gains are null This is wrong, move semantic for example can highly improve performance. Also because it allow proper smart pointers it can reduce/eliminate possible resource leaks. 
new of any form and move are two different things. move is about better copying, not so much about allocation. You seem predisposed to summarily dismiss everything people are saying, often with arguments that show you don't really grasp the concepts people are bringing up.
Another shining example of amazing things you can do with C++ that nobody who reads your code will have any hope of understanding.
If you read any of it read chapter 5
&gt; I can't wait to see HPX scale to a full BlueGene Q or Cray XC40 machine! Me too ;)
You mean when you violate the ODR? The bloat will be the size of the object times how many times the object is referenced in other translation units since the compiler must instantiate a separate copy for each TU. This can lead to bugs if you though the object was shared, but in most cases just bloats the runtime size with typically unnecessary copies. As for the technique shown? The overhead should be zero since it all seems like compile time wizardry to make the compiler only instantiate one copy of the object and then reference it it all translation units.
I meant rough numbers let's do a quick back of the envelope. Let's say you have 100 of these functions, lets say 1000 translation units where average of 20 are used each time. Let's ballpark at 8kb per translation unit. So it's roughly 20000 * size ÷( (20000 * size) + 8 mb ) . if its 1 byte it seems kind of irrelevant. If they are large or you have thousands of these that you use in thousands of small translation units I completely see it.
It depends on what exactly you are asking. I'll gladly use a library that helps me solve problems without fully understanding how it is constructed, though as part of evaluating a library, I will spot check the source just to see how insane it looks. If it looks unmaintainable, it may well have all sorts of problems, even if the library is well regarded. But the first thought that popped into my head was bugs I've fixed where in looking into it, the cause was a section of code that did not and could not do what it was supposed to do, only to find that the code has existed for years and years but the bug only first appeared a week ago, thus apparently this completely unworkable code was somehow working. If I saw code like that in my personal project, I'd curse out whoever wrote that (...) and fix it immediately.
&gt; Express is still available because there's a small number of people who prefer its licensing. Probably a pretty small group, as the Community licensing is basically extremely permissive, it allows anyone to use the program freely even for commercial purposes as long as you don't have more than 5 programmers working at the same time, don't make over a million in a year and don't own over 250 PCs. For open source and learning purposes, there's absolutely no restrictions. I could easily see a small software studio being able to perfectly legally run a business with that license. That's damn cool, Microsoft.
On a second read it might seem that I meant this in a ironic way, but I want to clarify that I don't. It is _a lot_ of work to scale to 500k-1500k cores. I cannot overstate this enough: really, it is _a lot_ of work. HPX is so much better than MPI at so many levels! The only thing that is stopping its adoption right now is the uncertainty that "in case I want to go to _that_ scale I don't know if HPX will work"...
&gt; It is also not clear to me at all how to implement a C++ executor that executes its computations on vector units. Currently there is no standard C++ way of doing this. At this time, implementations will probably fall back to some compiler specific solution like a '#pragma simd' or similar. There are some discussions going on in the committee on how to close this gap, though. 
Alias templates for one: ``` template&lt;typename T&gt; using fancy_vector = std::vector&lt;T, fancy_allocator&lt;T&gt;&gt;; ``` Consistency of left-hand "assignment" for another.
Nonfree license.
I thought it was reasonably fair, most people don't share any source code at all. But if you think its egregious I'd be interested to know which parts.
I started making this after being dissatisfied with other editors at my day job. At the moment it's become the fastest way for me to find things in large code bases. There are still a lot of features missing (I just got redo working yesterday), but the goal here is more to serve as an example of what 'could be' than to be a functional editor on its own. 
These are pretty egregious requirements and should be brought to light in a far more clear manner, I mean I don't think I've even used full blown proprietary software with licensing requirements as restrictive and punitive as the ones in this license: &gt;The copyright holder may revoke your rights to distribute copies or derivative works at any time without prior notice under any of the following conditions: &gt;A) It is determined by the copyright holder your distribution is damaging to users or the good will of the copyright holder. &gt;B) It is one year or later since the day this license came into force. &gt;You agree **to reimburse the copyright holder** of any damages caused by your violation of this agreement. You further agree to **reimburse the copyright holder of any reasonable costs** incurred while enforcing this agreement. 
You still should publish it under Apache or MIT license. No license just means nobody can do anything without your permission.
I'm not trying to be a dick (no matter, at the moment, how much it may look like I am) but what license is it now under? BTW, I think that using CLang and the AST to "for-the-love-of-god-give-us-a-reasonable-IDE-from-the-21st-century" is basically the main reason to have embarked on the whole CLang exercise, so I'm totally supportive of the effort. (That is totally not a standard clause in the open source community, fwiw. Do you actually have a law degree?)
You totally want contributions. There is nothing you want more. You want your ideas to take off? Let people bang on it. Let people change it. Let people contribute. You think their patches are shit? Don't take them. Let them fork it. If you're right, you'll win. If you're wrong, they will. Either way, it's all good. Or try the opposite. Contribute it to Code::Blocks. (I have no idea how their licensing works, but it will be reasonable.) M$ has ... 200? 400? people working on Visual Studio. (I'm guessing.) IBM has ... 50(?) working on Eclipse. CLion has ... who knows? You want your stuff to go somewhere? You need developers. BTW, you might enjoy this post if you didn't click through on it when it came through a while back. http://www.reddit.com/r/cpp/comments/36dj4i/cppcon_2014_largescale_refactoring_googlehyrum/
Oh, you do not even begin to know how much I grok that. Any chance you're in the bay area?
Ah, thanks. Misread what you said. Actually, I'm not sure that that's not what he wants, but whatever.
I think that combo is more feature complete - and a lot more polished. The only benefit I have over them is that mine is significantly more responsive, and in some cases faster. Ideally people on those products would see this and say "we could be so much better". I just think it makes your day better when the tool you spend all your time in responds instantly all the time.
It's on github :)
There are two types of licenses right now. Commercial &amp; closed source and 'free' &amp; open source. Within limits, it's not a gradient. It's binary. The reason is that nobody is going to contribute code to a commercial endeavor for free. But as far as open source goes, there's the fame, the glory, the sense of advancing mankind, and the resume. If you half-ass the license, all that goes away. And if that goes away, then nobody wants anything to do with it. Why? I will assume that you're the most talented developer in the PNW. Might be optimistic, but let's go with it. There is no way your editor will take off if it's closed source. Not a chance in hell. Open source? Maybe. Maybe it's worth my trying. Probably not, but maybe. What the hey? And if I find a bug, at least I can fix it. It might be worthwhile. Probably not, but it's possible. And maybe somebody else will fix a bug, or add a feature that I can't be bothered with. Might happen. Might not, but it's possible. But if you can claw that all back, i.e., if it's commercial, what's the point? I had lunch with two people who run open source projects you likely would have heard of in the last month. They both recently hired people from 'middle-of-nowhere' to work remotely because they were contributing good code. That gives me confidence that their projects are worthwhile and going somewhere. If random people will cut code for the glory if it all, that's going to be a project that will be worth relying on. If nobody gives a shit about it though, why should I?
I guess I see it differently. I think people should have the right to see the code they are running on their computer. I suppose the disconnect is that by publishing the source code people think I want them to contribute, but I only want to fulfill the obligation I think I have that they understand what code their machine runs. In terms of people using it, Sublime is also proprietary and has fewer features yet lots of people use it.
This whole thing stemmed from an argument with my friend about the state of dev tools. His position was that it was pretty much impossible to make them any faster - the evidence being nothing out there was fast. The goal of SLED was to be that counter-point. If it only proves useful to me than it would still have been worth it. But of course other people liking it would have been a nice bonus. The point of the license was in the 0.00001% chance it became moderately successful there wouldn't be an open source version out there competing with myself. It wasn't intended to "screw" anybody.
&gt; In C++, many times its useful to write functions as global function objects. "Many"? I've been developing C++ software for a long time, and I found it useful only to invoke algorithms with custom functors, in the lack of lambda. Even then I would instantiate the functor as a temporary expression, not as a (static) variable. I'm interested what problems do global function objects (vs freestanding functions) solve.
Heh, I called the magic function "rebind" rather than "(mp_)rename" in my [toy metaprogramming library](https://github.com/cdyson37/rebind). Naming things is even harder than metaprogramming!
That's true, but I still need a testing and debugging platform (but can't spare the hardware), and I dislike the inconvenience of maintaining mingw builds of the libs I use myself.
Looks really interesting.
This is the third article in the series related to non-constant constant-expressions in C++. Links to the articles in this series (that are currently published) are available below: - [Non-constant constant-expressions in C++](http://b.atch.se/posts/non-constant-constant-expressions/) - [How to implement a constant-expression counter in C++](http://b.atch.se/posts/constexpr-counter/) - [How to implement a stateful meta-container in C++](http://b.atch.se/posts/constexpr-meta-container/) Your thoughts on the matter are more than welcome, thanks for reading!
The Actor Model is pretty cool idea, but it does leave me with a lot of design questions in terms of how to best utilise them. [Hewitt is quite entertaining in explaining how the scheme works](http://channel9.msdn.com/Shows/Going+Deep/Hewitt-Meijer-and-Szyperski-The-Actor-Model-everything-you-wanted-to-know-but-were-afraid-to-ask), but the devil is always in the details. How do you implement the global message system? How do you make actors aware of each other and what recipients should the communicate to? How do you reason about the high level work that must be done through a bunch of actors? How do you avoid spaghetti messaging? Composability of actions - how? I think some this can be answered through a state machine design, but it's a question that i'm still researching with great interest.
 S to the P to the aghetti SPAGHETTI!
The notion that C++11/14 'does not help in any sense' is clearly nonsense. However, given your particular domain I can understand why you might feel that way. I would say take off your HPT goggles for a while and get to know the new features better.
&gt; 15:51 - Possibly one of the worst reasons (both technically and politically) to have something in the C++ standard. `then`, `when_all`, `when_any` have proved very successful in `boost::future` and `hpx::future`, among others. Without these std::future cannot be composed making it essentially useless. The Concurrency TS specifies a future type that is almost identical to `boost::future`. &gt; 17:10 - If it was "soo great" and "soo very useful" as per 15:51, what .then "kinks" could he be talking about .then? Most of the kinks are not part of `.then` and related operations per-se, but are kinks with std::future in general: semantics of its shared state, performance, constexpr, interoperability with user-defined future types... The only particular "kink" of `.then` is that for some applications it might be advantageous to control where and how the continuation of the future is executed. Most of the time, however, one doesn't care. The whole point of a TS is to allow users to easily try future features of the standard easily (it comes with your standard library), before carving these features into the standard forever. Mainly because the most subtle of these issues are only discovered after a couple of years of widespread usage by programmers working on very different fields that have very different needs. Anyhow, just because the Concurrency TS editor works at Microsoft doesn't make it a "Microsoft TS". If anything, private consultants like Anthony Williams or Christopher Kohlhoff have influenced ISO C++'s concurrency way more than any single large corporation. The editor's job has more to do with ISO formalism and coordinating group meetings than with the content of the TS itself.
One of the GCC devs mentioned a tool he uses. I'll see if I can track it down and update here. EDIT: Sorry, no dice.
Compile your bleeding edge versions from source, use "--prefix=..." to specify where to install the compilers. To use that version in a shell, set PATH and LD_LIBRARY_PATH as directed by messages at the end of the build. I've used this to have bleeding edge GCC available on systems where the system compler was a comfortable stable version ... and to have comfortable stable modern versions available on systems that, for reasons, were stuck with antiques installed. 
Google 'update-alternatives gcc'. It works on debian based systems. I'm using it to switch between gcc 4.8 and 5. Basically it just messes with symlinks.
More or less. It's a sticky subject since, by and large, as long as the ABI between libraries and executables is honored, the compiler version should be irrelevant. Except when it is. 
Sadly, I tend to work more on Fedora derived systems. But something like that might be possible.
&gt; set LD_LIBRARY_PATH correctly Ah, that's the kind of viscera I need to do this correctly. The chief concern is that, post compilation, the executable can find the correct dependencies if they're not compiled in. Or, alternatively, use some kind of hybrid compilation mode where things are isolated, but only up to a point. Thanks!
I know that pain. Stability comes at a price. That's one point of interest here - how to put together an updated yet stable build chain that doesn't interfere with the OS and the compilation of other dependencies. With the advent of C++11 and C++14, there is new momentum to move away from C++03 and older stuff even if your operating system hasn't. I'll have to give this a shot, thanks.
Isn't this what [jemalloc](http://www.canonware.com/jemalloc/) and such were created to address?
Usually that means you have defined parsers_core::base_parser&lt;char&gt;::inner_parse(parsers_core::file_input&amp;) somewhere in a header file, but you did not provide implementation for that function. Maybe you did forget to implement that? Or you forgot to link to some library with that symbol?
Further advice: * Qt has its own 'good practices' that go against what is considered good C++ practice today. It was originally designed before modern good practices were developed. Just keep this in mind as you use Qt.
&gt; Edit: Okay, let's keep C++ an ambiguous complicated language. You use struct for PODs, I'll use it for PONEYS Let's break all code available everywhere? Cannot afford this.
The newest C++ standards have lots of breaking changes. How much would that break though? I haven't really seen that much code that uses private for structs.
I'm using g++ 4.9.2 and clang 3.5 and don't reproduce that all. However, I have no additional flags in my compilation. It is for me, just g++ stdiotest.cpp --std=c++11 For me, stdio and cout both are within a small tolerance of 19.300 sec (timed via linux 'time'). This is true for both clang++ and g++. EDIT: On a side note: Your format string for the printf is wrong. unsigned long long should be %llu.
This is what I prefer as well. Use `class` only where it's actually necessary. Frankly, I rather wish it didn't work for the other purposes because it just adds confusion. People start trying to differentiate `struct` vs. `class` as POD/non-POD and that's just problematic.
I think I'd definitely try docker for that! My guess is there are ready-made containers for gcc, otherwise you could take a pre-made Fedora or Ubuntu container and modify it to your needs. I'm not 100% sure it would cover your use case but then again it might be just perfect for what you want to do.
/u/cyanobyte diagnosed my problem. I wanted a method to be abstract but didn't declare it using "=0";
Do you have a few specific examples?
Great, I'm gonna check it out at work tomorrow 
&gt; EDIT: On a side note: Your format string for the printf is wrong. unsigned long long should be %llu. Which cleanly sums up why you should avoid stdio, nothing to do with performance but it's incredibly sucky interface.
You may want to add a link to your library, as the name is non-unique enough to make searching for it pretty much impossible.
Not sure it'll make any difference, but have you tried including cstdio instead of stdio.h?
No idea how the d ended up there, the code was of course run with llu, else it wouldn't even have compiled, probably because i just reedited old code from when I tried with different int types. I'm using clang 3.5.0 and GCC 4.7.1, I probably should do something with GCC, but for now it applies to both of my compilers. In addition it also applies to all integer types, in-IDE and command line building, and I've tried it with all security software turned off. 100% replicable. The one thing I haven't tried yet is a different OS since my workstation is out of commision for the time being and my Windows only gaming laptop is the only thing I've got right now. There is also a small chance it might be my CPU being silly.
https://github.com/bigdatadev/benchpress
Seen a few of your video's in the past. Looking forward to the data oriented entity component system. 
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/cpp14] [New video tutorial series: "Dive into C++14" - first two episodes released \[xpost: /r/cpp\]](https://np.reddit.com/r/cpp14/comments/384lrx/new_video_tutorial_series_dive_into_c14_first_two/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger/wiki/) ^/ ^[Contact](/message/compose/?to=\/r\/TotesMessenger))* [](#bot)
Genius. Havent' thought about that. That said, isnt it odd that the compiler would stop short of resolving that ambiguity? It seems it had all the info it needs to solve it.
Yes. The lookup rules are frustrating and stupid.
In a production application where this becomes a factor, one would leverage a managed pool of objects. I've actually run into this in production while allocating and deallocating *objects with no member variables*, because the size of an object must be at least 1 byte. At the rate the application was handling requests, the heap became badly fragmented and the system reported "out of memory" in about an hour. Never felt sillier than having to create a memory pool for "empty" objects.
it is not that it is stupid but instead of deciding for you, you need to tell the compiler what you want to do. This is 100 times better than having an ambiguous behavior solved for you in a manner that in the end is not the one you would have done. In the end, the C++ makes sens if you think about the history and also if you keep in mind that most of the time it prefers throwing a compilation error than assuming something. 
I guess what you called "spanish inquisition" rather had to do with you spreading misinformation caused by you (!) using a C++11 feature an inefficient way.
Thanks. I have a follow-up question. I've dug into ALT a bit now, and types such as CComPtr and CComVariant are very handy. But I can't seem to find anything that handles CoInitializeEx/CoUninitialize. Am I missing something? Or is there a reason this particular pair of functions doesn't have an RAII wrapper?
That is very interesting question. I have to maintain several versions of compilers and build my tests on all them. Emulating my client's usage. Including the 'bleeding edge', gcc and clang as taken from github's trunk. Not only that I have to test with several versions of cmake, libcurl, mongodb, etc, all libraries it depends on. I tried to find a 'as-user' package manager like apt/pacman/yum but none satisfied my requirements. Then I started building them all from source and the resulting scripts I'm throwing at github. I just started the project coincidentally this morning so there's not much there. I'll be checking in stuff today and tomorrow if you fell like checking out. https://github.com/HFTrader/BleedingEdge
&gt; My impression of C++11/14 is still being a mostly cosmetic release :-o C++14 is a cosmetic release. C++11 is the biggest change to C++ ever AFAIK. * move semantics. * threads * `std::unique_ptr` and `std::shared_ptr`. * `std::unordered_*` * lambda expressions * automatic type deduction and `decltype` * uniform initialization * much more... 
I guess just feels clearer. 1) typedef std::map&lt;uint64_t,std::string&gt; MyMap; 2) using MyMap = std::map&lt;uint64_t,std::string&gt;; I hit my eyes on (2) and I understand immediately what's happening. On (1) I have to flow my eyes through the entire expression left to right to understand. Perhaps it's just me. It makes no difference for one statement but for an entire class or package with several of those, it has a significant impact on comprehension.
I admit some of the I do not. I barely use STL for the simple reason it does not fit my performance requirements. I need to be able to make a lookup in 5ns on a string (hash) table with 9,000 symbols/tickers (number of securities in US equities). STL wont fit the bill. The same goes for most of &lt;algorithm&gt;, &lt;functional&gt;, &lt;vector&gt;, etc. I use all them in non-critical code like reports, GUIs etc. They are wonderful for that. But the whole thread was about performance. Perhaps I should have stressed the context in more detail up front.
I definitely want it for free. That's one of the reasons I'm using g++/clang++ instead of icc. 
move semantics - I'll skip this one since it's larger than life. But enough to say I dont have any copies going on into my algos. No use for that - IN MY SPECIFIC USAGE, mind that. It's not a general statement that applies to you. threads - we always had threads. boost had threads (I never used). I used a class around C/pthreads. Not much here. unique_ptr, shared_ptr - I always used intrusive pointers. I see the use for unique_ptr though but that's... small in the sense you can use those intrusive pointers as well. lambda - agree, this is a solid change automatic type deduction and decltype - I do not like nor use those. The rules are not immediate clear in all cases. It clobbers the path between code and the assembly implementation. I dont use auto as well as the potential for mistakenly assuming something is going to happen (and dont) is high. I prefer to maintain control. uniform initialization - I see the use but this is just cosmetic. It does not pack any punch. it's about writing a couple words less or more. Hit me more. I really, truly want to be wrong. I feel in like an outcast in the c++ world and it's not good not to have friends. 
A similar command should exist under the 'alternatives' command for Fedora systems.
That's not kind of free I was talking about... 
If the net result is large positive I'd still take it as free. In this case all the features of c+11/14 are not enough to compel me to go back and selectively rework any of my code.
I doubt he meant that. if he did and he is an atheist, it would be silly for someone to call a scoundrel someone that does not exist. If he is not an atheist, this would be equivalent to a soul suicide. I'm interested to hear a third alternative.
You skipped a big one: a formalization of the abstract machine that c++11 requires. Arguably the largest change made to the language, done mostly in the support of threads. Somewhat related, read Sutter's you don't know volatile post. It goes a long ways towards the need of formalizing the abstract machine to support threading.
I also feel that. But C++ has is place. However it is not to be python/java like, that is definitely a mistake. 
Hey, Concurrency TS editor here. Regarding "useful": continuation passing, and the concept of a task/future with a continuation is not new, is not a Microsoft "thing", of course, though we did find it useful. See [Casablanca](https://casablanca.codeplex.com). Futures work great for representing long-running asynchronous operations like an HTTP request but not fine-grained concurrent operations. If you need to add two numbers, don't create a future for that. Re: "kinks". The hardest part in writing the specification is making it precise enough for the implementer but at the same readable for people to understand how to use it. Lots and lots of people reviewed, discovered bugs and contributed fixes. See [bugs](https://github.com/cplusplus/concurrency_ts/issues?q=is%3Aissue+is%3Aclosed). Once we have a fully implemented TS, we'll likely discover more inaccuracies in the specification, maybe usability issues. To name a few examples... One part that took a lot of work was getting the semantics of std::future right, which, unlike std::shared_future, is not copyable. We went back and forth a few times on whether to have implicit unwrapping for futures, or have an explicit 'unwrap' method. Feedback from the field will tell whether we've made the right call. 
CMake handles that mostly painlessly, though.
A frankly overwhelming number. Qt, GTK+ (gtkmm), wxWidgets, FOX (probably the most Swing-like in its interface), FLTK, Juce, plus all the relevant native APIs, most of which have C bindings handy. I'm sure I missed a few.
Congratulations... You wrote an LCG... how exciting...
Any reason why you wouldn't also put FLTK in that list?
I wasnt there, but I worked at one place and they implemented fltk. Apparently it was so bad, they went back and rewrote their UI to use something else. But that wasnt me, so Im not positive what the issues were. It was pretty reviled though. 
I don't understand where you'd be facing that choice of local executable vs. web. That decision is usually pretty obvious in light of requirements. In my experience messing around with web stuff is great to avoid if possible. Web stacks mostly suck and are piles of hacks for anything non-trivial. Really, avoid using the network as much as possible for the best outcomes. So much easier to be secure and responsive and stable.
Is it needless? Toolkits and frameworks go in and out of fashion; there are a wealth of options beyond whatever library is popular right now. Qt, wx, and GTK are the Big Three, but others exist, some have even been around longer, and more are still being created. And I don't think it's ever appropriate to highlight high-level cross-platform application solutions without at least pointing out the existence of Xlib/XCB, Xt, the Windows API, MFC, WTL, NS/OS, and Cocoa.
It is needless as things stand right now. Anybody asking the question today "How do a I write GUI in C++" deserves the answer: "Qt or Wx." If you tell them some different list of things you are wasting hours of their time by sending them on a dumb research and trial-and-error goose chase.
I'm not sure I'd characterize it as painless.
And this sums up perfectly why I have avoided stdio as best I can (the C syntax makes it doubly bad for non-american keyboard layouts btw). And the results right now is to stick with iostream, type safety and non-confusing interface is too much to sacrifice for a performance increase that seems to quite simply not be there.
&gt; Ease of deployment and barrier to entry is orders of magnitude easier with a web app. This is true, I suppose, if you're pushing some variety of toy out to a mass market. Just getting application hosting and accounts within many organizations is hundreds of times more painful than sending out statically linked executables to analysts.
Really? I haven't had any issues with it in years. Now that automoc is bundled in CMake even less so.
I'm going to assume that you're being sincere instead of trolling: **Language** **Move** I think you perhaps don't fully grasp the full implications of move semantics. They go beyond avoiding copies; they also are a powerful tool when expressing ownership semantics &amp; are the whole reason something like unique_ptr is possible. You can now write RAII wrappers safely for any arbitrary resource. Additionally, move semantics also let you omit copies that were unavoidable before by moving the container around instead of passing it by const-ref. It also means that even if you don't get NVRO/UNVRO, it's still cheap to return containers from functions since they're moved out; this means the output parameter programming style is unnecessary. **TMP** Move, when combined with templates, enables something called perfect forwarding which lets you write 0-cost wrapper functions among other things and enables things like std::vector::emplace, std::unordered_map::emplace, std::make_unique, std::make_shared etc. SFINAE is actually part of the language now so we don't need the tricks that boost was doing. There's also an extremely right type traits library. This is huge for any amount of TMP. This is also where automatic type deduction and decltype really shine. **Variadic templates** As part of the TMP enhancements, variadic templates are really important too. They let you do the things you could do with boost before but that were really ugly, compiled slowly, &amp; had unnecessary limitations. This is a critical feature for implementing things like std::tuple which completely obviates the need for output parameters. There are also *lots* of uses for such a thing. **Templated aliases (aka using)** This right here completely obviates typedef &amp; actually makes them readable. The fact that you can have templated typedefs is just even sweeter. **constexpr** You can now guarantee that a compiler will compute a value at compile-time which can be important for some use-cases. This is also a faster mechanism than what TMP was (ab)used for. **auto** I would say that const auto&amp;, auto&amp; and auto are all straight-forward; auto strips all const, volatile, and references modifiers on the type. auto&amp;&amp; is the tricky one since it follows the reference collapsing rules for templates which is slightly odd, but don't use it if you're not comfortable. I would agree that this is mostly cosmetic though, although now it's possible to write for loops without wanting to shoot yourself &amp; there are cases where auto will actually help you avoid making a mistake. **enhanced for loop** Don't underestimate the power of syntactic sugar. The enhanced for loop not only results in shorter code, often-times it's faster &amp; actually correct; writing for loops prior to C++11 could be very error-prone. The same goes for all the other syntactic sugar that's added - more often than not it's not just for writing less code, but also it's code that tends to be a source of errors. **memory model cleanup** There is now a definition for what a POD is that is extremely useful. Not only does it codify things people had assumed, it also lets the STL take advantage of said definition to optimize algorithms; this means that std::vector will memcpy things around more than it could before. **noexcept** It's a small syntactic thing but it lets std::vector &amp; other containers perform operations more efficiently. **Library** **Smart pointers** unique_ptr - intrusive pointers are not a substitute for unique_ptr. Nothing is because it was literally impossible to write such a mechanism prior to C++11. Intrusive pointers could approximate shared_ptr but that's completely unnecessary now since shared_ptr is just as efficient without violating encapsulation. unique_ptr allows for more precise ownership rules with none of the overhead of keeping track of said ownership. Additionally, they're now container-safe whereas std::auto_ptr &amp; friends were not. **std::array** There's now type-safe way to represent an array. C arrays &amp; the associated frequent programming bugs can die. **RNG** C++11 also introduces a fairly high-quality RNG API although that only matters if you use an RNG. **std::chrono** A high-quality time API that properly distinguishes time points from durations. Let's you write code that works with these units much more safely. **std::thread** I think you also incorrectly discount just how huge std::thread is. Forget the class itself. C++11 actually defined a memory model. Without this, your wrapper class is actually in undefined behaviour territory and there's no way you could write code that the compiler wouldn't be free to break if it wanted. This also means it's basically impossible to write reliable multi-threaded multi-platform code. Extending upon that, std::future/std::promise etc brings modern asynchronous programming capabilities. **std::function** Type-erased lambda. Super-useful &amp; powerful. All of this is just a very small window into what C++11 brings to the table. I think you're being overly dismissive with what C++11 brings to the table because you've worked around whatever was missing in C++03 and have a legacy codebase. If you were to try and modernize your codebase, I'm sure that you could get rid of a bunch of unnecessary code and improve the code quality. It's also not inconceivable that the STL implementation will be faster and/or have fewer defects than your existing codebase. C++14 polishes it off into a nice fairly modern language. C++17 will be disruptive again &amp; hopefully push the envelope again.
&gt; Prefer preincrement over postincrement &gt; &gt; &gt; &gt; There are litterally no compilers in existance anymore that do not optimize this. Having said that I still use preincrement myself. In debug mode for user defined types this may still make difference, so the advice is valid.
I think the idea is to avoid a situation where a developer builds a class that inherits from two classes without being aware the two bases have a member with the same name - possibly with entirely different purposes. In such cases, rather than using obscure rules to resolve the ambiguity, the compiler simply lets the dev know and gives them the mechanism to fix it. It is a shame the error message does not metnion how to resolve it, but that's the nature of the beast.
I defer to your knowledge. &gt;Of course now for most applications using a decent math library is a better idea. Personally I use [eigen.](http://eigen.tuxfamily.org/index.php?title=Main_Page)
I feel bad. I only know C++ through QT. Is this how Java devs feel when all they know is Spring? I should really try to do more.
Let me just interject a rant, that it annoys me to no end that even though classes and structs are largely identical, you still have to pick the right one when forward declaring. 
Well many of your colleges think differently. Several Trading Companies and Individuals that earn their living in related fields are heavily invested in the standardization. I guess they do see the value. 
last time I tried it didn't, but I guess it was a while ago... guess the internal state machine is now supported within VS debugger. 
...so write a custom allocator that periodically defragments your allocations. Maybe use a [buddy allocation scheme](http://en.wikipedia.org/wiki/Buddy_memory_allocation), or just bubble your allocated blocks toward the front of the list when you start deallocating things.
you can store (non-capturing) lambdas in plain function pointers, you can store the "native type" in a templated object (where it can be fully inlined), you can write a different type-erased function storage object (e.g. a delegate), you can use it with std::bind, ...
&gt; The trade-off of having fewer permutations of code and much better coverage of the assertions, in my experience, has outweighed any theoretical concerns about performance overhead. that makes perfect sense, but you tend to have this plural look at it. once you separate code logic error thats is wrong usage through assert versus bad input for function it breaks or at least is debatable no?
Hi, thank you a lot for your answer! The bugs page is an interesting source of information, I will crawl it a bit later :) &gt; The hardest part in writing the specification is making it precise enough for the implementer but at the same readable for people to understand how to use it. Teaching how to use the Concurrency TS in the specification seems a bit out of scope, at least compared with other parts of the C++ standard which explicitly avoid doing this. &gt; If you need to add two numbers, don't create a future for that. Why not? (Disclaimer: I want "tolerance" for constexpr stack-allocated futures). It feels to me that one thing we learned is that no single future type is going to be good for everybody, and as a consequence, that futures will need to interoperate with each other (this is already a problem, e.g., mixing `boost::future` with `std::future`). This makes me wish that we had a Future concept and would specify standard utilities in terms of these and not any particular future type. OTOH I really appreciate all the work you guys are putting on a std::future type that is good for ~80% of the use cases. We really need both. An example of a very common blocking operation is allocating memory. `std::future` is useless in this use case. Given your "insider" position, would you mind telling us your take on Google's executor proposal? I actually expected it to die after revision 0, but it is still alive even after the Kohlhoff proposals! It makes me wonder if the only reason is still alive is because it is baked by a large corporation, or if there are significant troubles in communicating the flaws of the proposal to the authors. 
&gt; Use references for parameter passing and return value for types bigger than 4 bytes Because 64-bit registers aren't common now? EDIT: and of course RVO is a thing now too.
How many of those can process market data and send an order in sub 300ns? I have picked off all these guys in the market for the past 10 years for this exactly reason. They are more into rethoric than into measuring every piece of code and look at the generated assembly. I have friends in the industry and we have some heated discussions about it. if I had to start from scratch I'd probably write it differently. Many of the C++11 features are nice and should be used. But I think I'm over my limit. You folks will end up placing a ban on me. My karma is already negative :0
You can do a lot of really fun audio and video work from command line programs with gstreamer. It's a C library but there are C++ API bindings available, too. Just something that popped into my head when you said music player.
I have to agree 100% with you. I'm giving my personal perspective. However, through my comments I was clear about that. I have shared that it's not my intention to make general statements that apply to everyone.
On rh with scl, enable enable devtoolset v. On Windows with VS, no need to do anything, msbuild recognizes desired version from project files.
right now I can't, and that's why I feel bad. I'm one of "those". In my career, C++ is not necessary, and I don't particularly like learning new tricks without a purpose. In my C++/Qt project, I'm building an external music player for a popular MMO (EVE Online) and I wanted to support many platforms without dependency overhead (eg: Java or Python). C++ and Qt seemed like the best choice. What I need after this project, is another project that I WANT/NEED to exist, and try doing it in C++ without Qt. To be fair, I do feel this was a great step into C++, but I know it's just the tip of the ice berg.
Congrats STL. That's quite an achievement.
So will `constexpr` work with global objects now? struct sum_f { template&lt;class T, class U&gt; constexpr T operator()(T x, U y) const { return x+y; } }; struct identity_base { template&lt;class T&gt; constexpr T operator()(T x) const { return x; } }; static constexpr identity_base identity = {}; static constexpr sum_f sum = identity(sum); And will it work with static references as well? template&lt;class T&gt; struct static_const { static constexpr T value = T(); }; template&lt;class T&gt; constexpr T static_const&lt;T&gt;::value; struct identity_base { template&lt;class T&gt; constexpr T operator()(T x) const { return x; } }; static constexpr const auto&amp; idenity = static_const&lt;identity_base&gt;::value; Both of these failed to compile on the RC. If it works now, thats awesome.
This is exciting! So with this, we have full C++11 support, except for Expression SFINAE which will be delivered post RTM as an update, and a large chunk of C++14 support.
Thanks Stephan; I look forward to programmers more versed with C++11 and constexpr than me, to test constexpr with VS2015 RTM.
Thanks! It took us a month and a half to update the STL (including getting fixes for thirtyish compiler bugs revealed by the STL's intensive use).
&gt; Also add another sub rsp, something operation rather than having only one at the beginning of the function. The compiler is smart enough not to adjust the stack pointer more than necessary. Declaring a variable in an inner scope does not generate any extra instructions. The extra allocation is simply absorbed into the original allocation in the prologue. The point of doing this is to not leak variables into outer scopes. That prevents mistakes, but it can also disambiguate cases where variables might otherwise potentially alias each other, which can have a performance impact.
The first one doesn't compile in the online compiler (http://webcompiler.cloudapp.net/). main.cpp(25): error C2872: 'identity': ambiguous symbol main.cpp(23): note: could be 'const identity_base identity' c:\tools_root\cl\inc\type_traits(1280): note: or 'std::identity' main.cpp(25): error C2131: expression did not evaluate to a constant main.cpp(25): note: failure was caused by non-constant arguments or reference to a non-constant symbol main.cpp(25): note: see usage of 'sum' Why not help them out: &gt; So, we'd like to invite you to try out the online compiler and report any issues you find. (And report them soon, like this week.) &gt; Microsoft Connect is the official place to report bugs, but we'll accept constexpr bug reports in VCBlog comments here. 
If you have any questions or comments, just drop them here and I'm happy to respond!
libc++ is also current with constexpr. They have the little bits we don't have yet, although they were missing istream_iterator's ctor (found by my tests, which I duly reported). VC's overall C++17 STL support will be comparable to libc++ 3.6 (we'll have stuff they didn't, and vice versa). I need NaN builtins from the compiler; just didn't have time to get them. I found one defect which I'll report: pair's piecewise ctor should be constexpr. My general thoughts are that constexpr wasn't as tricky to implement as I feared. (It was lots of work, but I was expecting the STL to have taken many more dependencies on C++14 extended constexpr.) Due to the prohibition against implementer strengthening, constexpr should be quite portable. I am not yet aware of examples otherwise.