Yes, hence the mention above the code about it probably not working. :) Looking forward to this merging so I can start using them properly. Great work.
I wonder if I should repeat my argument that Boost isn't a justifiable dependency in a 250 line utility library for those 4 reasons you've listed. Think about the trade-off: Either you spend some extra time to write your code without the utilities in Boost or ALL your users (except the ones that already depend on boost) are exposed to those 4 inconveniences.
Modern C++ was already possible in C++98 and is what I always preached for. For me it means: - Getting rid of C style coding, leave it for C developers or when the compiler needs an helping hand - Prefer the C++ standard library to C style solutions for strings and vectors - Always make use of references instead of pointers for parameters that cannot be NULL - Before *nullptr* existed, use 0 instead of NULL macro - Always use RAII for resource management - templates, const definitions and inline calls instead of pre-processor macros - enumerations instead of #define - make proper use of the type system for imposing correct behaviors, e.g. having a range_integer template class. - ... Just a small set of what Modern C++ means and was already possible with C++98, basically leave basic C with Classes code patterns for C developers.
That doesn't help (or isn't exactly true) if you capture by reference: http://cpp.sh/2u2k This only really concerns me when you'd want to capture by reference, like when you have non-plain-old-data/large objects to capture. Most of the time I don't want to modify them, so I'd like a nice short syntax to capture by const ref.
Sorry; this is a bit off-topic for us. Nice shirts, though.
With the information you gave, the snippet will not compile. I get the feeling that there are other `#defines` that you have to replace as well... `If` for example is not a valid symbol (it shouldn't be capitalized), so there is probably a `#define` for that too. What context are you given this code in?
Any other information then? Otherwise this is just invalid code.
"CLI" normally implies that you provide inputs on program invocation through command line arguments and flags and get the result back in more or less plain text form (maybe with some formatting and coloring). An example of a complex CLI is [git](https://services.github.com/kit/downloads/github-git-cheat-sheet.pdf). I guess this is what the answer about Clang was trying to point out (especially given a typical [number of possible flags](https://gcc.gnu.org/onlinedocs/gcc-6.2.0/gcc/Option-Summary.html#Option-Summary) compilers tend to have).
thanks, didn't notice the spelling mistake
I wrote [Kakoune](http://kakoune.org) which my main code editor nowadays. It was a nice playground to experiment with modern C++ style as well.
I see, I'm happy I learned this distinction. I figured anything terminal based would be considered CLI; maybe I thought so because of "command prompt" and just assumed. You guys have been very helpful, thank you :)
I guess an AMA might be interesting to the community at large. Regarding COM, WinRT and .NET, my Windows knowledge goes back all the way to Windows 3.1. So when .NET was announced, I was a bit disappointed that it wasn't like Delphi and similar languages, e.g. type safe language with AOT compilation to native code. We had NGEN since the early days, but wasn't quite the same. Then I read that paper about the COM Runtime research, and when WinRT and .NET Native came out, I got the feeling you guys decided to bring the project back, but replacing COM type libraries with .NET metadata. As for C++/WinRT it is a nice project from the Visual C++ team and I see it a good approach for those allergic to C++/CX extensions. For me personally, I am pretty comfortable with C++/CLI and C++/CX, and don't mind using them. Actually C++/CX + XAML, was the first time I got the feeling Visual C++ could be as RAD as C++ Builder for GUI development. In any case nice work, I also enjoyed watching the MSFT presentations at CppCon.
Yes but the code is not c++11.
The equivalence of some of these operations can be proved more thoroughly and with less effort by showing that identical assembly is generated. Some of the code is bugged; `std::shared_ptr` is a template and thus `std::shared_ptr p(new ActorIncrement)` will not compile. I do not buy the applicability of a subset of these micro benchmarks to real life code. For instance, copying a raw pointer is a copy of 8 bytes and nothing else. Copying a shared pointer, in addition to requiring more bytes, involves atomic operations which are much harder to optimize around in real life code. You're claiming that copying is 18 vs 19 cycles, which is a tiny difference. This is hard to swallow. Did you ensure that your `TestShared` and `TestShared2` functions weren't inlined? If they were, then no actual copying occurred. Unless you specifically used a compiler pragma to prevent inlining, it's extremely likely that a 3 line function would be inlined at -O3.
I understand your rationale, but it brings about another consideration and kind of touches on the point of what a "CLI" actually is (in the posts below). I believe that TaskWarrior would be a TUI (according to the arguments below), and you're saying that it might be overkill to use a low-level language to produce the output. Does that mean that using a GUI instead of a TUI would be more or less ideal? In this case, /u/paulbeckingham made it for the console - so I don't mean specifically TaskWarrior; but for other instances, is a GUI just better and easier to manage? You said webapp, do you mean html/js/etc based? I ask because I am still trying to understand the *how* part of a TUI. It seems your saying it might be too much, and better outsourced to a higher level langauge.
Sweet mother of Jesus O_O' Ok, please let me ask, how much time did you put into this? Did you build from Vim's source? In terms of style, how did you accomplish output like that (I know you couldn't possibly describe it all, but a reader's digest version would be nice!)? Very impressive, thank you for sharing :)
It wasn't airlifted from Library Fundamentals 2 into the standard, so my guess is that C++20 will have it for sure.
Started working on that in 2011, so more than 5 years now. All written from scratch. Pretty easy to keep working on a software I use 8 hours+ a day ;) I am not sure I get your question "how did you accomplish output like that", do you mean the terminal rendering ?
If this code builds, I think the best explanation for why it builds is *"Because of other code that's not shown here"* I can think of potential explanations, but I can't offer any one with certainty. Your understanding of preprocessor definitions is correct though.
Win32 API is technically there for other platforms, since Windows uses the same core now, so you can certainly do some GetProcAddress and fish out the functions you want, it depends a lot on the build/flavor though
The terminal output goes through ncurses, so thats unix based. There are a few different layers going on: * The highlighting system that builds an array of "display lines", each being an array of "display atoms" that basically are a tuple&lt;text, color, attributes&gt;. * The ncurses ui backend interprets that data and uses ncurses functions to setup terminal display. It also takes care of generating menus/info boxes. * ncurses then sends its internal representation to the terminal, using escape sequences to setup current color, add text, move the cursor around. We use ncurses for that because the actual escape sequences needed to drive a terminal is terminal specific, ncurses takes care of that for us (although we do emit a few hard coded sequences).
I'm always looking for shared_from_raw although I know it won't happen. Don't think it's in boost anymore even. :(
You shouldn't use those functions at all. See here why: https://channel9.msdn.com/Events/GoingNative/2013/rand-Considered-Harmful (not very long, but quite fun and extremely useful to know).
Isn't std::optional&lt;T&amp;&gt; spelled T*? I know this is a snarky comment, but I really don't understand why you would want that.
Absolutely. It could even end up being implemented as a (maybe null) pointer. But [this blog post](http://tristanbrindle.com/posts/optional-references) makes a couple of good cases for it, not least one of consistency with std::variant.
Sadly with T* people eventually go and run delete/new on them. That's why I think observer_ptr&lt;T&gt; and optional&lt;T&amp;&gt; can be useful.
T* gives you a pointer with a value (NULL is a value). `std::optional` does not.
I'm saying it's about picking the right tool for the job. There are tons of tools to help you make a pretty and presentable UI using HTML/JS/CSS. The same cannot be said about using ncurses (or however this tool was made). So there has to be a *really* compelling reason to make a CLI app. The cost associated with maintaining something like this versus a web app is not trivial. I just want to know what that *really* compelling reason is. Again just to clarify: from screenshots, it looks like the application is working well and looking great. I'm talking wholly about the cost of development and not user experience.
&gt;The compiler has found the first argument in the sumf call `sumf_v2(1.5,2)` and deduced its type as `float` (so the template type `T` is set to a `float` type) I believe `T` would be `double`.
&gt; Sadly with T* people eventually go and run delete/new on them. If that's an issue then your problems run much deeper than `optional&lt;T&amp;&gt;` could ever solve.
I write surrealist C++. It looks like it can't possibly work but somehow solves np-hard problems. 
Lies. Did some qt5 distributing myself. It's just more DLLs that were pulled in by qml. Took a bit of head scratching - not a big deal...
&gt; std::string_view ... can make parsing a bajillion times faster. Can anyone give a quick explanation of that statement? I can see how passing around `string_view` objects could be a lot more convenient than passing around a `string` and an iterator/index or two. But why would it be so much faster? (Or is there some other speed-up that I'm missing?)
Thanks so much! I really appreciate it! I think that is a great idea for a video and is extremely important to know for beginners as it makes programming so much easier to know how to manipulate strings! I will definitely make that a video. Thank you for the idea! 
I just learn some aspect of STL which were very obscure for me, doing a lexer that spit tokens, it is not very practical but it worked for me, and saved me a lot of work without using an external library or regex, also helped me to solidify some concepts. typedef pattern&lt;anyOf&lt;'0', '1', '2', '3','4','5','6','7','8','9'&gt; aDigit; typedef pattern&lt;aDigit, Self&gt; aNumber; pattern&lt;many&lt;aNumber&gt;&gt; numbers; .... auto v = numbers(std::stringstream{"123123 123123 12312312 123123"}); // should return a vector with strings with numbers on it. 
std::string_view will not make today's fast parsers faster. Today's fast parsers do not use std::string in the first place.
So maybe it'll enable writing a new parser using std::string/string_view that is _as fast_ as today's fast parsers, but more readable/elegant, with less hacky code and char*'s?
My guess would be 0 copies if done right. 
Maybe you are right, I don't know. I copied the command I posted from a batch file I wrote for myself to compile Boost on Windows and have used it over the last few years. The last version of Boost that I compiled with this command was 1.62 and it compiled and produced usable libraries. Anyway, thanks for the advice. I'll try it next time I want to compile boost.
Many fast parser implementations already use classes that behave just like std::string_view.
What happened to std::location? I've been really looking forward to that!
Yuck
What mental overhead are you paying for complexity that you're not writing or maintaining?
[removed]
My apologies.
Singularity and Midori were two sides of the same coin. Check out Joe Duffy's blog for details. Triton is a well-known codegen technique for Windows Phone 8. There's a video on C9 from Mani Ramaswamy that talks at length about it. Redhawk was a tiny CLR that shipped in Windows 8. So not the same thing. But all these things are connected. It's a big company that does a lot of experimentation and growth. 
http://imgur.com/a/59ju7 I made an automated blackjack table play simulation tracking progress using basic strategy sans doubles and splits based on bankroll cardcounting players-at-table and hours of play desired.
Yes. Lambdas are more likely to be optimized away than functors though. That's all I was saying.
The overhead for the code I'm using. Say I want to do A_Thing. Well, there's Boost::Do_A_Thing. Great! But, when something unexpected happens, how do I diagnose it? I look at Boost::Do_A_Thing::Do() and find that not only is it amazingly complicated, but it delegates a lot of work to Boost::Anything, Boost::Abstract_All_The_Things and Boost::Give_The_Preprocessor_PTSD. Soon, I have 10+ megabytes of code to figure out --much of which is frequently used in compiler stress tests. Or, I could write and maintain a couple hundred lines of my own code. Ex: Boost::Serialization is &gt;750k of code (excluding tests, examples, etc) by itself. Then there are [it's dependencies.](http://www.pdimov.com/tmp/report-6d1f271/serialization.html) My Boost::Serialization clone is 250 lines. It only handles simple types, but that's all I've ever needed.
:-(
&gt; http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0063r2.html &gt; &gt; 18.10p10 effectively says that a signal handler must be written in the common subset of C and C++. But C++ and C11 both have thread-local storage. ... &gt; &gt; **It turns out that there is a technicality/loophole by which this can be dodged. *Because the associated keyword is spelled differently in C and C++*, technically thread-local storage is not actually in the common subset of the two languages** – even though both languages support the feature. Are you serious right now? 
They mention in the CppCon talk that they annotate QueryInterface and similar functions to tell the compiler they are pure even though they are across DLL boundaries. I would like to be able to do this. Looking through base.h on GitHub I'm not seeing any obvious annotation instructing the compiler that it is safe to optimize by assuming anything is a pure function. Anyone see how they do this?
What does this have to do with STL, just curious?
This is off-topic for our subreddit; please try /r/cpp_questions or StackOverflow.
Wtf
Your post has been automatically removed because you are banned from r/cpp. If you think you should not be banned, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Shadowban%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/57jqfq/i_am_an_evil_shadowbanned_user_from_rjava/,%20was%20removed%20because%20I%20am%20shadowbanned.%20I%20do%20not%20think%20I%20should%20be%20shadowbanned%20because...) and we'll discuss it. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
[removed]
[removed]
Your post has been automatically removed because it appears to be spam. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Possible%20Spam%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/57jtl4/check_out_my_dating_site_written_in_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Your post has been automatically removed because it appears to be "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/57ju8n/help_how_do_i_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
[removed]
A human moderator has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and was should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/57jva6/this_is_fine_20/d8skaix,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
[removed]
To aid mobile users, I'll link small subreddits not yet linked in the comments /r/java: News, Technical discussions, research papers and assorted things of interest related to the Java programming language --- ^I ^am ^a ^bot ^| [^Mail ^BotOwner](http://reddit.com/message/compose/?to=DarkMio&amp;subject=SmallSubBot%20Report) ^| ^To ^aid ^mobile ^users, ^I'll ^link ^small ^subreddits ^not ^yet ^linked ^in ^the ^comments ^| ^[Code](https://github.com/DarkMio/Massdrop-Reddit-Bot) ^| [^Ban](https://www.reddit.com/message/compose/?to=SmallSubBot&amp;subject=SmallSubBot%20Report&amp;message=ban%20/r/Subreddit) ^- [^Help](https://www.reddit.com/r/MassdropBot/wiki/index#wiki_banning_a_bot)
[removed]
[removed]
[removed]
[removed]
[removed]
[removed]
[removed]
[removed]
[removed]
[removed]
[removed]
[removed]
[removed]
[removed]
[removed]
No, he's saying you should not be using T*.
[removed]
[removed]
[removed]
A human moderator has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/57k52a/include_test_posth/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
[removed]
[removed]
A human moderator has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/57k61d/include_test_posth/d8sn0ni,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
A human moderator has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/57k61d/include_test_posth/d8sn53u,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
OP, A human moderator (u/blelbach) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/57k76r/include_test_posth/d8snbdy,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
[removed]
I also suggest you benchmark using `T*` vs `std::unique_ptr&lt;T&gt;` as function parameters.
Luckily that's not a goal for me ... hard to debug such programs anyway, I'd rather compile from source, or use technologies such as COM .
Could someone explain what happened to unique_ptr&lt;T[]&gt;?
What about it? It's still there...
Maybe I'm a bit extreme, but I think the practice that consist of being like 'just put `using namespace std, it does stuffs` at the beginning of the file' leads to bad practice. I'm a big proponent of specifying `std::` in front of every call. It also make it clear to the student which methods are part of the STL and which came from our own code.
Couldn't a reference to string already achieve that? 
Note that [template pack folds](http://en.cppreference.com/w/cpp/language/fold) are usually a better option than recursion, if your compiler supports it. While most everything could, in theory, be optimised away, compare the assembly from the following two snippets: [Sample 1:](https://gcc.godbolt.org/#g:!\(\(g:!\(\(g:!\(\(h:codeEditor,i:\(j:1,options:\(colouriseAsm:'0',compileOnChange:'0'\),source:'template+%3Ctypename...+T%3E%0Aauto+sum+\(T...+t\)+%7B+return+\(t+%2B+...\)%3B+%7D%0A%0Aint+main\(\)+%7B%0A%09return+sum\(1,+2,+3,+4,+5,+6,+7,+8,+9,+10,+11,+12,+13,+14,+15,+16,+17,+18,+19,+20\)%3B%0A%7D'\),l:'5',n:'1',o:'C%2B%2B+source+%231',t:'0'\)\),k:50,l:'4',n:'0',o:'',s:0,t:'0'\),\(g:!\(\(h:compiler,i:\(compiler:g62,filters:\(b:'0',commentOnly:'0',directives:'0',intel:'0'\),options:'-std%3Dc%2B%2B1z'\),l:'5',n:'0',o:'%231+with+x86-64+gcc+6.2',t:'0'\)\),k:50,l:'4',n:'0',o:'',s:0,t:'0'\)\),l:'2',n:'0',o:'',t:'0'\)\),version:4) template &lt;typename... T&gt; auto sum (T... t) { return (t + ...); } int main() { return sum(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20); } [Sample 2:](https://gcc.godbolt.org/#g:!\(\(g:!\(\(g:!\(\(h:codeEditor,i:\(j:1,options:\(colouriseAsm:'0',compileOnChange:'0'\),source:'template%3Ctypename+T%3E%0AT+sum\(T+t\)+%7B+return+t%3B+%7D%0A%0Atemplate%3Ctypename+T,+typename...+R%3E%0AT+sum\(T+t,+R...+r\)+%7B+return+t+%2B+sum\(r...\)%3B+%7D%0A%0Aint+main\(\)+%7B%0A%09return+sum\(1,+2,+3,+4,+5,+6,+7,+8,+9,+10,+11,+12,+13,+14,+15,+16,+17,+18,+19,+20\)%3B%0A%7D'\),l:'5',n:'1',o:'C%2B%2B+source+%231',t:'0'\)\),k:50,l:'4',n:'0',o:'',s:0,t:'0'\),\(g:!\(\(h:compiler,i:\(compiler:g62,filters:\(b:'0',commentOnly:'0',directives:'0',intel:'0'\),options:''\),l:'5',n:'0',o:'%231+with+x86-64+gcc+6.2',t:'0'\)\),k:50,l:'4',n:'0',o:'',s:0,t:'0'\)\),l:'2',n:'0',o:'',t:'0'\)\),version:4) template&lt;typename T&gt; T sum(T t) { return t; } template&lt;typename T, typename... R&gt; T sum(T t, R... r) { return t + sum(r...); } int main() { return sum(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20); } In the first case, the compiler inline-expands the t parameter pack using the `+` operator, while in the second case it generates the recursive function calls. Yes, these then could be optimised away, but they still need to be instantiated first (meaning that e.g. summing up many values may lead you to exceed the maximal template instantiation depth or somesuch).
I'd be ok with a shared_from_this that works in the constructor though.
It is still possible, and worthwhile, to avoid recursion even if fold expressions are not available: template&lt;typename T, typename... Ts&gt; auto sum (T t, Ts... ts) { using expand = int[]; expand{0, (t += ts, 0)...}; return t; } [Online Demo](https://godbolt.org/g/mSZE8i)
GCC starting from version 6.1 and Clang 3.6 support it. Intel’s compiler doesn’t like it even in version 17. I don’t know about VS. So yes, your compiler needs to support it, but I would assume that in the far future, most compilers will understand it just fine. Hence while maybe right now it’s not an option, I think it would be a good idea to keep in the back of your head :)
That's the reason I insist on doing it. Teaching something it easier than un-teaching anything. When they get used to a way of doing thing, turning the ship around is almost impossible. Even more if the proper solution is slightly more verbose. Even for an experienced developer, bad habits die hard. I routinely still use 0 instead of nullptr for example. 
Yeah gcc generates much better assembly for first version...
It generates the same thing for me starting with `-O1`. It just calculates the whole sum at runtime! 
I have altest trunk and for 1) it generates one long function where it sums up everything at runtime. for 2) it generates a pile of functions which are called recursively. Neither calculates at compile time though...
&gt; so you're saying that it's OK to call delete on something you don't know if you own or not? Just in case it might leak? I would not agree with this précis. &gt; I'm not saying you leave it alone: it's every programmers job to track down who owns what and when. Oh that is a bit clearer, thank you. That is what we have to do, but hopefully we can make our findings available to those who follow us, either through lengthy comments or by some sort of wrapper. I don't know if `optional&lt;&gt;` is the best job (I am stuck on a C++98 compiler anyway, and boost is not available) but it would be nice to have some unambiguous way to do that.
Strange. Maybe regression? I tried on godbolt and Clang 3.6 (needs O2), gcc 6.1 (needs O1) and up (including svn trunk, don't know how recent though). Here is the link: https://godbolt.org/g/GqT9eQ
i made [this](http://i.imgur.com/0YkrIOO.gifv) in opengl/sfml. 
The point of string_view is to refer to a small piece of a large string being parsed. Just a reference is not enough.
[`source_location`](http://en.cppreference.com/w/cpp/experimental/source_location), probably.
Not exactly. [Singularity](https://www.microsoft.com/en-us/research/project/singularity/) was a research project that eventually became the Midori OS. Bartok was a C# compiler from MSR that was used in the Phoenix framework as well as in Midori for System C#. There are Wikipedia pages about all of these that are pretty on-target. NGen is a tool that precompiles .NET binaries but leaves them dependent on the .NET runtime. Triton used MDIL, a machine-dependent intermediate language, to precompile .NET binaries but allow them to be quickly bound to whatever .NET runtime is on the machine. It's an evolution of NGen that fit the Windows Phone 8 app store scenario. Redhawk was a tiny runtime that shipped in Windows 8 to support low-level OS code. It used MDIL, Bartok, and Phoenix in its toolchain. Code written for Redhawk didn't need a CLR--it just needed the tiny Redhawk runtime. Project N was an effort to "grow" Redhawk and Triton as well as a bunch of .NET Framework work to support Windows Store apps. I'm actually the guy who came up with the name .NET Native. It's the same thing as Project N. Like I said--this stuff is all connected. I'm honored to have worked with many of the same people over and over in the different projects that I've worked on, on the C++, .NET, and Midori projects. They really are some of the smartest people in the industry. 
Many thanks for explaining how all those pieces come together. I am a Java, .NET and former C++ (I still use it occasionally) developer, that is also a systems/languages/type safety geek, and I am always eager to learn about work done at MSR, specially all the endeavours that improve the safety of our computing stack. Because even when we don't use such languages in our daily work, we rely on critical software, like the underlying OS and VMs infrastructure, written in those languages. Congratulations on the work you guys achieved so far and I look forward to what might still be coming on our way. Thanks again for the overview.
Yes this is where MSVC is non-conforming.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/57nqid/should_this_be_considered_a_bug_in_msvc_compiler/d8texfw,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
One thing I never understood is why the standard committee decided not to use nested namespaces to organize the types, values and functions defined in the standard library.
Perhaps not, but it strikes me as an extraordinary design mistake for the addition of a new class constructor to potentially completely change the meaning of existing code. For this reason, I won't touch uniform initialization; it doesn't seem to offer enough obvious benefits to justify its use, given this issue.
True, but the point of the article is not about unicode, that's just an example. It's about IoC on error handling. 
&gt; Interestingly enough, as soon as I try to make make() static or put it in an anonymous namespace it doesn't work anymore... I found that that only applies to gcc with anonymous namespaces, static and anonymous namespaces doesn't phase clang's inliner at all. Interestingly enough, when you add a function that does it the "normal" way, gcc fully optimizes it but only if you have the make method in the translation unit. I believe this is because it realizes it already knows the result, so it just replaces it. Clang on the other hand always inlines it. Edit: Clang seems to fare better with multiple strings then gcc does. It manages to compile three strings into a bunch of moves. However, as soon as you go above the SSO limit, it goes crazy.
He who likes this should also see Alexandrescu's talk "the power of none". I would personally liked much more that the error info contains the invalid code point than all else in the article. Giving good context in your error info is crucial.
Just grab some open source project you are interested in and start digging. Common pages to search for these projects are for example Github and sourceforge. Or just google.
At least GCC does not seem to be accepting • and × as identifier names in a #define, in c++17 mode.
Compile with warnings enabled, and treat warnings as errors (for purposes of releasing at least). Most compilers have a warning for comparing a signed value with an unsigned value.
signed/unsigned-mismatch is not at all a problem if you use all the warnings that you should use: -Wall -Wextra -Wpedantic -Wconversion -Wsign-conversion So the actual solution is this: &gt; Use unsigned if values cannot be negative and enable basic warnings.
Wow there this isn't JavaScript, now...
This was fun! Here is my preliminary analysis... To begin with, I can only get the main version to optimize on the gcc 7 snapshot compiler. Did you manage on other versions too? If so, which flags did you use? The only way I can make this optimize on gcc 7 is by using -std=c++1z that makes the STL code nicer. Changing to -std=c++14 makes this fail to optimize on gcc 7 too https://godbolt.org/g/UqauMG The reason the compiler treat main differently is that it is guaranteed to be called only once, i.e. it is a (very) cold function, so gcc does not really see any reason to inline into it... I'll write up a slightly longer analysis on my blog tomorrow...
Enable warnings yes, use unsigned without a good reason ("can't be negative" is not a good reason - "I need modular arithmetic" or "I use an API which uses unsigned ints and using signed ints would require lots of casts" can be good reasons) no. int main() { unsigned i = 1, j = 2; auto k = i - j; std::cout &lt;&lt; k; if ((i-j) &lt; 4) { std::cout &lt;&lt; "i is at most 3 bigger than j"; } } No conversions, no warnings, not what the user wanted.
I have to laugh every time someone with OCD comments on the use of namespace std; with beginners. There is so much to understand when you are starting to program that the use of global namespace is completely trivial. And people who continue to do this later on "to save space" is more a matter of bad instruction / learning resource as at some point namespaces should be addressed. 
Where did you learn to use 0 instead of NULL? There are some library api that still require NULL / 0 and of course you can't use nullptr w/o a C+11 compliant compiler.
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/57uc41/where_can_one_go_or_what_can_one_do_to_go_from/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
only while under SSO limit though.
You are correct - I only saw the optimization in every case when using gcc7
Thanks.
So, what is it?
My practical experience is that about 2% of variables in a program can potentially and justifiably be negative, unless you're using some kind of API or library that forces negative values on you. Basically, you could safely ban the use of assembly instructions for signed arithmetic, requiring any signed logic to be explicit using unsigned values, and incur minimal performance penalties. Using signed integers everywhere is literally like using pointers instead of references. Mostly, the thing pointed to cannot be null, but because you're not using a reference, it is now unclear whether it can be null or not, and you still have to check it. The use of negative values is generally overloading of meaning, which can be a security issue. MoveForward(-2) should not move backward, it should be illegal, and this needs to be made clear by the parameter being unsigned.
Pretty sure he was advocating UDTs that constrain functionality to what's semantically relevant over built-in integral types, not using floating-point.
There are lots of cases where values can't be negative. If you can't prove unsigned safety, don't use it. It's not the default for a reason.
I would far rather have a compile error than a runtime error. If a negative value is a bug, it shouldn't be possible by the compiler of C++. It's not always 100% the right call, but in general, if your API has a precondition, you can use the type system instead of Assert() or Throw(). Far safer and less buggable.
&gt; Don't mix them on operands I've never found a situation where unsigned integers only ever interact with other unsigned integers and so in my eyes if you follow this then you just never use unsigned integers. The classic case is indices of sequential structures. My experience suggests that indices should be signed so I can do arithmetic on them with negative differences. If indices should be signed, then counting things such as `std::vector::size_type` should be also signed so we can compare indices to sizes without stress. What then is the use of unsigned integers? What sort of thing is best represented with unsigned integers? Best being in a practical sense and following the above rule. &gt; (By the way, I once heard Bjarne Stroustrup say in a video talk that requiring size_t to be unsigned was a mistake)
Do you know if anyone managed to implement this in a compile-time-efficient manner? As far as I can see, the only way to implement this is to create a recursive template type that contains each function object in a recursive instantiation. Then the constructor of each instantiation has to pass all the function objects minus its own down to its bases, which means the overall compile time complexity of instantiating `make_overload` with `n` function objects is `O(n^2)`, which can become significant in generic code handling a lot of variant types. I wish we could simply say: template &lt;class ... Bases&gt; struct S: Bases... { using Bases...::operator(); }; Then we could implement `O(n)` `make_overload`
Yeah I do numerical work which has distributed meshes giving rise to global and local indices. Negative indices make sense there and by association you end up indexing structures with signed integers. You also end up doing a fair bit of arithmetic with them. Embedded would have more use for that extra bit you save as well I suppose. There you go.
The linked page is boring, don't bother. If you want to see something interesting for signed vs unsigned, watch Chandler's talk about undefined behaviour at cppcon: https://www.youtube.com/watch?v=yG1OZ69H_-o The "use unsigned for values that can't be negative" is a dogma. The difference between two numbers that can't be negative can be negative, but the difference between two numbers that are unsigned is unsigned. ("unsigned" as the literal type - the difference between two uint8_ts is actually signed). The product of a number that can be negative with a number that can't be negative **can** be negative, but the type of int times unsigned is unsigned. **C++'s type system is geared towards unsigned for modular arithmethic, and not for unsigned == number can't be negative**. C++'s unsigned should have been called "modular". One matter with unsigned is that, to handle it correctly, you have to sprinkle your code with a ton of casts, and it's easy to do it incorrectly (static_cast&lt;int&gt;(i-j) instead of static_cast&lt;int&gt;(i)-static_cast&lt;int&gt;(j)). These casts are noise, they are only necessary because you used the wrong type, they don't express any useful part of the logic. And your -2147483648 example is a strawman, there are lots of sitations where you *know* that you're not anywhere near the integer boundaries by magnitude.
That's why I have written a [better unsigned](https://github.com/foonathan/type_safe): * No conversions from signed * No mixed operations with signed * No wrapping on over/underflow With it you can safety use it on APIs to enforce that a value isn't negative. This is the main reason you should use unsigned and the built-in type just fails at it big time.
Can we compare oranges with apples? We can't, but somehow C designers could. C++ carries all the baggage of C... To solve this, the standard library should have special types which are not implicitly convertible to each other, and are used through out the library, and the standard shall also define a default header which uses the preprocessor to replace all of C's arithmetic types with those special types. A compiler option shall exist to revert this new behavior to the one we have now. 
Which might not matter at all for many use cases, e.g. plain line of business applications, written in C++ for portability reasons. 
The explanation why `boost::intrusive_ptr` doesn't meet the standard's requirements doesn't explain anything. Fine, the ref count is incremented after construction, but which requirement does this collide with and why?
Make a 2 player game using sfml, it must have a game object class, shooting, frustrate independent movement, shooting, parallax scrolling and everything that a basic game requires :)
Games are great for that. Command line stuff are the simplest. A hangman ? Some kind of text based rpg ? a quiz game ? a 4-in-a-row with an AI ? Graphical stuffs require more setup and may be more complex. Start simple. Depending on his age, I don't see the point on focusing on academics exercises or some technical aspects like template programming or binary tree balancing or what not. The end result should be motivation enough for learning the tools he needs to make it happen. 
Codewars (www.codewars.com) recently added C++ support, you can find many small challenges of intermediate difficulty there
To me a signed integer is for special cases. Most things should never be negative. Yes, unsigned has weird wrapping, but signed integers have exactly the same weird wrapping issue. You don't get to pretend there's no issue either way.
Going by the motivation section: shared_ptr does not work with APIs that maintain their own reference count and it has to be threadsafe, which can be costly. 
Now that the flood of posts is over, can we revert to the status quo ante? The three conspicuous buttons on the sidebar, in particular, are a little distracting.
Code a tic-tac-toe! It is pretty simple, it's visual, but you can work on several programming concepts. A first step would be to play the game on command-line, yet you still have to detect when the game ends, which requires to skim through a table. You have to parse user inputs. When the game is done in command-line, add a GUI (eg. Qt).
Try to implement the things listed in [this comment from an old thread about how to teach C++](https://www.reddit.com/r/cpp/comments/453p8o/how_we_teach_c/czv3krk)
This is types of questions normally belong to /r/cpp_questions, but even there, we are not doing your homework. We are very willing to help, though. Just present your own effort, ask specific questions about concrete problems you have. Also please read the sidebar there, for example about code formatting before you post it.
Hi, I'm the author behind that article. I also think the headers should come with the SDK, but I think they want to keep a separation between the LibreOffice version, and the LibreOffice SDK. The headers are generated from files in the LibreOffice suite. Kent
Hi, I'm the author behind that article. Just yesterday I managed to start LibreOffice Calc from C++, without the world come crashing down. So it is possible! (I've had my doubts for a long time now). I'll publish part 2 later today or tomorrow.
I'd suggest [Project Euler](https://projecteuler.net). It's not specifically aimed at C++ but it does have a lot of good problems that will help improve your coding.
Make a doubly linked list 
 int main() { // TODO: game of life } The hardest part is getting started; hope this helps in getting up to speed.
Write a recursive solution that will solve any size or difficulty Sudoku.
Clang and GCC already have [UBSanitizer](http://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html) for that purpose. In particular, there are checks `-fsanitize=signed-integer-overflow` and `-fsanitize=unsigned-integer-overflow`, and `-fsanitize=integer` group which includes both (and probably some more).
I haven't seen any linear overload implementation that doesn't use recursion. The [overload paper](https://github.com/viboes/tags/blob/master/doc/proposals/overload/P0051R2.md) I linked in my article mentions [Fit](https://github.com/pfultz2/Fit) and [FTL](https://github.com/beark/ftl) - I've briefly looked at their linear overloading implementation and it seems to be recursive as well.
It would be be nice to get a discussion of exactly what the author means by an "intrusive smart pointer", as I didn't fully understand what was going on until I read the proposal link from these comments: https://github.com/slurps-mad-rips/retain-ptr/blob/master/proposal/p0468.rst Overall - a good job on first blush. I'm not entirely convinced that this is of sufficient general utility to make it into the STL, but I am convinced that I might need this functionality one day, and when I do, I'll use this.
&gt; in which case no arithmetic or comparison other than equality comparison makes sense. So your ID cannot be stored in a sorted container or a hash table. 
I believe support for parameter pack folding is fairly poorly implemented at the moment, in gcc at least. (see [here](https://youtu.be/VNrShPCgVjw?t=260)) Once that's flushed out, yes, folding is definitely the way to go. For now the solution seems closer to: template &lt;typename T, typename... Ts&gt; auto add(T&amp;&amp; arg, Ts&amp;&amp;... args) { using swallow = int[]; std::common_type_t&lt;std::decay_t&lt;T&gt;, std::decay_t&lt;Ts&gt;...&gt; ret = std::forward&lt;T&gt;(arg); (void)swallow{ (void(ret += std::forward&lt;Ts&gt;(args)), 0)... }; return ret; } 
Something like `std::vector&lt;std::vector&lt;bool&gt;&gt;` will be useful.
I use clang-tidy all the time and in particular the the 'modernize' transformations on a 100k-500k line code base. I've found them robust and very easy to apply.
Fun fact: I actually have an [implementation of Conway's Game of Life](http://i.imgur.com/CxeQWDl.png) maintained on my computer in C++/OpenGL. I'd be willing to assist you with any of the trouble trying to build it yourself. However, as was mentioned in this thread, /r/cpp isn't the appropriate forum for this. Post your question in /r/cpp_questions or DM me, if you want assistance with this project. And to be clear, you'll be responsible for doing the work yourself. I just have a lot of experience starting the project, maintaining it, and therefore know a lot of common pitfalls and roadblocks.
That does not really solve everything, if you have at least one weak pointer the control block will not be released. Also often thread safety is not required but shared_ptr control block always has atomic counters.
Speaking from experience, a `std::map&lt;std::pair&lt;int64_t, int64_t&gt;, bool&gt;` (or `std::unordered_map`) works a lot better. I've also been known to use `std::map&lt;std::pair&lt;int64_t, int64_t&gt;, uint8_t&gt;` to allow for colorized logic.
Just how big of a world are you making?
I really like [codingame.com](http://www.codingame.com). They have some very fun challenges from novice to very hard, as well as multiplayer AI competitions.
Qt Creator has both CMake and remote Linux support (deploy to remote Linux machines, run/debug there) and great C++ support. For CMake projects the remote Linux support will require a bit of setup to tell Creator which files need to be deployed. For qmake projects no special setup is needed.
The easiest way to use clang-tidy is to get a compile_commands.json for a clang build somewhere (e.g. by using cmake) and use that to tell tidy what flags to apply for each file. I'm not very sure about windows - we have a crossplatform build and I use tidy on linux.
How would pointers work without integers? You need the full range of unsigned and signed logic for pointers to work the way they are used even in modern C++ (a vector is 3 pointers which are compared and subtracted from eachother).
or https://codefights.com 
Each internal_ptr&lt;T&gt; points to a dynamically-allocated T object which could be freed individually. As long as that object is reachable by some path from a root_ptr&lt;Something&gt; via internal_ptr&lt;&gt;s, the object is kept alive. As soon as that T object is no longer accessible via a path from a root_ptr&lt;&gt;, it is deleted (as are all other objects in that group that are unreachable). To do this via the aliasing constructor of shared_ptr requires that you know in advance which set of objects need to be freed together, so you can use the same base pointer for the aliases.
References would be like unsigned types if trying to create a null reference were: - defined, instead of UB - easy, instead of hard - when a null reference were created, it automatically turned into a reference to some random object in your program.
There are lots of situations, even outside of numerical work, where doing subtraction on indices is a common thing to do, like in just about every dynamic programming problem ever. It's very common in DP to subtract some quantity from your current index, and then check if it's in bounds, which almost everyone will do the first time by checking if the result is less than 0 (and then probably be surprised).
If my MinGW compiler is not in PATH (due to having multiple MinGW compilers installed), how do I tell KDevelop/CMake to use that compiler?
http://codeforces.com/
Unfortunately, a lot of low-level code (such as hashing) was written to rely on unsigned using modulo arithmetic so it is not practical to now say "unsigned should not under/overflow".
Unfortunately, substracting one unsigned quantity from another is a valid use case, and it will create an unreasonably large unsigned quantity rather than a negative one.
Your code invokes undefined behavior though while Murillio's did not. Specifically, depending on the implementation, you may get: - a bogus program (optimization having detected the undefined behavior) - a signal (trap on underflow, `-fsanitize=signed-integer-overflow` with gcc/clang) - an exception (VC++ could inject structured exceptions here) - a bogus value (modulo 2 arithmetic, for example) I would argue that activating signed overflow checks in debug mode (at least) should help catch a large portion of issues early. Given that this depends on runtime values I am not sure of the effectiveness of static analyzers here.
We'd like to support macOS, but none of the core developers uses that, or even has a machine capable of running it as far as I'm aware. I personally also have zero experience with Mac -- I can barely open a browser window. Judging from what one hears from people running their self-built versions, kdevelop seems to work ok though; we'd just need somebody to step up and feel responsible for building and maintaining the app bundle.
The third and fourth lines print a floating point constant. The runtime floating point formatter rounds up if necessary. (See my other reply for what's going with the first line.)
Black Magic! Seriously (although this question is a super candidate for /r/cpp_questions): are you able to compile your file on the command line and show the error message? In general if something (strangely) does not work, try to decrease the complexity of the overall system/build process and build from there. 
Indeed there are lots of reasons to use C++ but one of the tenants of the language is zero-overhead abstractions. If the abstractions hurt performance, then they're not likely to be voted into the language. I too would like to see better cross-platform languages with such features but I wouldn't want to change the nature of C++ to get there.
Thanks for all the responses. The hard part is getting the compile_commands.json on windows. We are using make on windows to build our system, so either that or some script to parse the visual studio compile output would be needed. It would be great if i could get it to work with either of those.
Ensure that your teacher is using the latest version of GCC and ensure every computer you're using is using the latest version of GCC too. If your teacher is using MSVC, tell him to use a conforming compiler to test if a code is compiling. This is sadly the truth, as MSVC don't implement two phase name lookup nor expression sfinae, which can f*ck up your templates in some cases, refuse valid C++ code and accept invalid one. It is said that it will support it next year, but it still not there. However, if it's a requirement that your code must compile in MSVC, then listen to your teacher and test it on MSVC. In case of doubt, you can also try to compile your code in another compiler, like clang. It may spot error in your code that GCC did not detect. In some dark corner of the language, you can always discover bugs in compilers, there is no perfect compiler, as there are no perfect code. If you take the time, with not a lot of efforts, you can make your code compile in every major compiler out there (GCC, MSVC, Clang) and make it compile on many platform or computer. With that, your teacher cannot possibly argue that your code is invalid. &gt; same settings/IDE/compiler This is hardly the case. Each computer can have slightly different compiler or standard library version. There is some linux distribution that may have many compiler. Check your makefiles and what compiler those makefile are using. On each computer, there is a high chance that there are some libraries and header that differs. Each differences can make your code not compiling on one computer.
Thank you so much for taking your time to help me! I honestly don't think it's an issue with my code. It's the .project file not wanting to work when thrown onto a different PC. This doesn't make sense to me since I made sure both PCs of mine have everything the same. I set them up at the same time and both are using the same OS. If I copy and paste each individual file's code over to a new project that hasn't been built then it will work fine since it generates a new .project file. So it's clear to me that the code isn't the issue here which frightens me because I struggle enough to pump out decent code each assignment without issues with stuff I haven't even learned about. It is pretty transparent that the issue is with the .project file. So it is more than likely something you mentioned. I just find it odd that just rebuilding the project without the .project file from the original PC works. Now, you probably will be saying "well, then what is the issue here if you can get it working with a work around that simple on a new PC?". My professor has an assistant grade the programs and whoever it is follows a VERY strict guideline. Your .project file must work regardless of what you tell them. I literally told them last time how to get around the issue and I still had the 50% taken off and the professor actually complained when I approached her about the issue. Basically told me to go figure it out myself. :/
Most existing (and by most, I mean everyone but Boost) APIs create their objects with a reference count of 1. Thus, when interacting with these APIs it requires you to construct the object like `boost::intrusive_ptr&lt;type&gt; ptr(input, false);` and you can't just simply construct it with a pointer and then manually force an increment. Every intrusive reference counting pointer out there with the exception of `boost::intrusive_ptr` does the opposite.
There's a notification iframe that's layered on top of buttons, making them unclickable. https://i.imgur.com/Ifv3vce.png EDIT: BTW, the reason I'm finding bugs is because I'm using it and having fun. So thanks for the C++ support. :-)
Interesting, is this CPU or GPU based, what's the performance like ?
So some quick answers: I'm also of the opinion that `unique_ptr::release` should be called `detach`, but I guess that's what `std2::` can be for :P If you need a custom allocator it'll be in the object itself, or you'll have your own memory manager. If retain_traits has to store state, it's not a traits object, and then we don't have an intrusive smart pointer. We have some weird interface otherwise, where not everything is stored inside the object and at that point you might as well use `shared_ptr`. "Furthermore" is definitely a typo. Whoops! `retain_t` was originally called `retainobj_t`. I decided to just make it retain as this is the word used by most interfaces I investigate (addref seems to be unique to COM) People might be creating new intrusive refcounted types if they have been using `boost::intrusive_ptr` and would move to `retain_ptr`. The memory orders are exactly what `boost::intrusive_ref_count` does. I didn't want to rock the boat (I am also not an expert on atomics) `shared_ptr` returns a long for use_count. By using long we get API uniformity. `unique_ptr&lt;T, R&gt;::pointer` is a typo... (and I thought I had fixed it before too!) Your `::pointer` must meet the requirements of the `NullablePointer` concept. That is the correct wording. It's what the standard says (and the constructor doesn't count as having executed because it was interrupted). Having `noexcept(false)` destructors are a possible thing, and some decrement functions could potentially throw if an error occurs (see OpenCL `clRelease*` functions). As long as `traits_type::decrement` is `noexcept`, so too is the destructor. That is also a typo, and was mentioned in one of the GitHub issues.
&gt; Your example also has a bug` I had misread the example code you posted &amp; wasn't familiar with OpenCL; I don't think it materially changes anything I wrote though. &gt; however, it's a lot easier to just rely on the "rule of 0". Now, you don't need to write all this code That argument alone could be used to justify the inclusion of a variety of data structures, algorithms &amp; utilities into the STL. To me it's a necessary but not sufficient argument. &gt; As for exposing shared_ptr's ref/deref, I don't think that's a path at all. Not all types let us get the actual use_count (retain_ptr returns -1 if the traits object doesn't have it) You seem to contradict your own proposal. 1. Why is the lack of real use_count pose a problem for shared_ptr but not retain_ptr? 2. How is -1 a useful result? If it's a problem for shared_ptr I don't see how it's not a problem for retain_ptr. In either case, this argument doesn't seem particularly convincing against std::shared_ptr. &gt; It would add unnecessary complexity, especially in cases like shared_ptr's aliasing constructor, and deleters that are just function pointers. This part isn't clear. Firstly, you just make the claim it's a problem for the aliasing constructor &amp; function pointer deleters without actually explaining why; it's not immediately obvious to me why it's an insurmountable issue. &gt; shared_ptr is thread-safe (as retain_ptr can be used on thread_local objects, or objects that won't be shared between threads and therefore don't need to have atomic operations for increments and decrements). Again, none of this argues that allowing a custom ref/unref implementation to be injected into shared_ptr is a negative. Instead you're actually presenting arguments against your proposal as all of these points against shared_ptr are points against your intrusive ptr implementation too. &gt; Of course if you think it's a good idea, you can write a proposal to challenge mine The biggest issue I have with this proposal is that there isn't actually a clear problem being described and as such it's difficult to write anything on this topic. The paper actually seems to start with the solution &amp; work backwords to find problems that can be hammered in rather than the other way around of identifying various problems and the unifying underlying characteristics that naturally lead the reader to your conclusion. The closest it comes to expressing a motivation is "interacting with C apis", but it doesn't actually explain any challenges nor present any particular reason that would motivate a reader to conclude that the proposal is the right direction. It presents what it sees are defects with the boost implementation but not ComPtr nor WTF::RefPtr (nor again why those solutions are preferred to shared_ptr).
Yep!
Maybe but most of cave story is the art style, story, and levels, which aren't hugely programming related. But writing an engine for a cave story like game would be a good project
Complete shot in the dark: is it possible that that project file happens to contain [absolute paths](https://www.google.com/search?q=absolute+path) which would be specific to the one computer on which you started your work?
Author of that post here. Your best bet right now is [our makefile template](https://blogs.msdn.microsoft.com/vcblog/2016/03/30/visual-c-for-linux-development/#makefile) which lets you invoke whatever build process you like on the remote system. That section of the post also points to some [bash scripts that generate a project from an existing code base](https://github.com/robotdad/vclinux). I'm sure they won't work in every situation, but they should provide a decent starting point. 
Interesting, but my first thought was "why not gperf?"
Yes. Your chanches will drop dramatically. Basically because you will have an experience, but experience without keywords that attract HR managers.
Code that does that triggers UB. You aren't allowed to form an object pointer that points outside of an object. Edit: And if you use `std::array` iterators on MSVC our debugging checks will kill you :)
Probably going to end up being slower due to not treating the 4-character strings as ints.
&gt; Except that signed wrapping occurs far from zero, the most common value in most programs, and unsigned wrapping occurs right beside it. Precisely, which means it is easier to catch bugs with reasonable test data.
Nothing about how to find the constants used in the hash function?
Good point, but for short 4-byte strings there should be very effective algo (but I doubt it would be vectorized though).
Have you ever used gperf? It doesn't do micro optimization or specialization based on things like uniform key length.
No, but I've seen it on TV. What exactly are you asking about? My point is that lookup table will be pretty tiny and switch basically became a single cmp op.
&gt;It's only when I have started implementing programs with template classes that I run into this issue Yeah, sure. But... &gt; Literally just sits there after I hit compile without showing any type of warning/error. The mere fact that their are templates in your code wouldn't make your tools just completely stop working. This smells like the toolchain isn't given anything to do.
It'll probably have two array lookups, possibly a switch too. And a strcmp() to test key equality.
`int main() { return main(); }`
Oh, it's interesting. What does your wordlist contain usually?
Maybe. You can tell I'm not too experienced with this subject so sorry if it seems like I'm doubting you or anyone here. Just trying to get answers by putting more and more information out there. Again, it's only on the last two assignments, which happen to use template classes, that I've ran into this issue. The code works on the PC I actually coded it on and originally compiled it on and it hasn't stopped working. It's when I send it to another location that it starts getting funky. It's the same thing for both my laptop and desktop and it's making me pull my hair out because I do not want to approach this professor again about this issue. 
I have a lot of friends graduating in April with strong graphics and C++ backgrounds. If you guys hire new grads I can pass the job posting along for you.
I mean, I have no idea why this would be an issue with the code at all. If I remove the .project file and simply rebuild on a different PC then it works fine. The issue comes about when I try to download the project folder on a different computer than the original PC and add the project to the workspace of the new computer. I can paste the code behind one of the two problematic programs, but I just don't see a point. If you start a fresh project and just copy and paste the code into their relative header/template files it WILL work, but the outputted .project file will only work on the PC you compiled it on. ^last sentence refers to only my two PCs. Your compiler might produce a proper file unlike mine. I just have no idea where to start looking other than what mother just mentioned, but I'm new in regards to that.
&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;CodeLite_Project Name="Lab6_Dozier" InternalType="Console"&gt; &lt;Description/&gt; &lt;Dependencies/&gt; &lt;Settings Type="Executable"&gt; &lt;GlobalSettings&gt; &lt;Compiler Options="" C_Options="" Assembler=""&gt; &lt;IncludePath Value="."/&gt; &lt;/Compiler&gt; &lt;Linker Options=""&gt; &lt;LibraryPath Value="."/&gt; &lt;/Linker&gt; &lt;ResourceCompiler Options=""/&gt; &lt;/GlobalSettings&gt; &lt;Configuration Name="Debug" CompilerType="MinGW ( MinGW )" DebuggerType="GNU gdb debugger" Type="Executable" BuildCmpWithGlobalSettings="append" BuildLnkWithGlobalSettings="append" BuildResWithGlobalSettings="append"&gt; &lt;Compiler Options="-g;-O0;-Wall" C_Options="-g;-O0;-Wall" Assembler="" Required="yes" PreCompiledHeader="" PCHInCommandLine="no" PCHFlags="" PCHFlagsPolicy="0"&gt; &lt;IncludePath Value="."/&gt; &lt;/Compiler&gt; &lt;Linker Options="" Required="yes"/&gt; &lt;ResourceCompiler Options="" Required="no"/&gt; &lt;General OutputFile="$(IntermediateDirectory)/$(ProjectName)" IntermediateDirectory="./Debug" Command="./$(ProjectName)" CommandArguments="" UseSeparateDebugArgs="no" DebugArguments="" WorkingDirectory="$(IntermediateDirectory)" PauseExecWhenProcTerminates="yes" IsGUIProgram="no" IsEnabled="yes"/&gt; &lt;Environment EnvVarSetName="&amp;lt;Use Defaults&amp;gt;" DbgSetName="&amp;lt;Use Defaults&amp;gt;"&gt; &lt;![CDATA[]]&gt; &lt;/Environment&gt; &lt;Debugger IsRemote="no" RemoteHostName="" RemoteHostPort="" DebuggerPath="" IsExtended="no"&gt; &lt;DebuggerSearchPaths/&gt; &lt;PostConnectCommands/&gt; &lt;StartupCommands/&gt; &lt;/Debugger&gt; &lt;PreBuild/&gt; &lt;PostBuild/&gt; &lt;CustomBuild Enabled="no"&gt; &lt;RebuildCommand/&gt; &lt;CleanCommand/&gt; &lt;BuildCommand/&gt; &lt;PreprocessFileCommand/&gt; &lt;SingleFileCommand/&gt; &lt;MakefileGenerationCommand/&gt; &lt;ThirdPartyToolName&gt;None&lt;/ThirdPartyToolName&gt; &lt;WorkingDirectory/&gt; &lt;/CustomBuild&gt; &lt;AdditionalRules&gt; &lt;CustomPostBuild/&gt; &lt;CustomPreBuild/&gt; &lt;/AdditionalRules&gt; &lt;Completion EnableCpp11="no" EnableCpp14="no"&gt; &lt;ClangCmpFlagsC/&gt; &lt;ClangCmpFlags/&gt; &lt;ClangPP/&gt; &lt;SearchPaths/&gt; &lt;/Completion&gt; &lt;/Configuration&gt; &lt;Configuration Name="Release" CompilerType="MinGW ( MinGW )" DebuggerType="GNU gdb debugger" Type="Executable" BuildCmpWithGlobalSettings="append" BuildLnkWithGlobalSettings="append" BuildResWithGlobalSettings="append"&gt; &lt;Compiler Options="-O2;-Wall" C_Options="-O2;-Wall" Assembler="" Required="yes" PreCompiledHeader="" PCHInCommandLine="no" PCHFlags="" PCHFlagsPolicy="0"&gt; &lt;IncludePath Value="."/&gt; &lt;Preprocessor Value="NDEBUG"/&gt; &lt;/Compiler&gt; &lt;Linker Options="" Required="yes"/&gt; &lt;ResourceCompiler Options="" Required="no"/&gt; &lt;General OutputFile="$(IntermediateDirectory)/$(ProjectName)" IntermediateDirectory="./Release" Command="./$(ProjectName)" CommandArguments="" UseSeparateDebugArgs="no" DebugArguments="" WorkingDirectory="$(IntermediateDirectory)" PauseExecWhenProcTerminates="yes" IsGUIProgram="no" IsEnabled="yes"/&gt; &lt;Environment EnvVarSetName="&amp;lt;Use Defaults&amp;gt;" DbgSetName="&amp;lt;Use Defaults&amp;gt;"&gt; &lt;![CDATA[]]&gt; &lt;/Environment&gt; &lt;Debugger IsRemote="no" RemoteHostName="" RemoteHostPort="" DebuggerPath="" IsExtended="yes"&gt; &lt;DebuggerSearchPaths/&gt; &lt;PostConnectCommands/&gt; &lt;StartupCommands/&gt; &lt;/Debugger&gt; &lt;PreBuild/&gt; &lt;PostBuild/&gt; &lt;CustomBuild Enabled="no"&gt; &lt;RebuildCommand/&gt; &lt;CleanCommand/&gt; &lt;BuildCommand/&gt; &lt;PreprocessFileCommand/&gt; &lt;SingleFileCommand/&gt; &lt;MakefileGenerationCommand/&gt; &lt;ThirdPartyToolName&gt;None&lt;/ThirdPartyToolName&gt; &lt;WorkingDirectory/&gt; &lt;/CustomBuild&gt; &lt;AdditionalRules&gt; &lt;CustomPostBuild/&gt; &lt;CustomPreBuild/&gt; &lt;/AdditionalRules&gt; &lt;Completion EnableCpp11="no" EnableCpp14="no"&gt; &lt;ClangCmpFlagsC/&gt; &lt;ClangCmpFlags/&gt; &lt;ClangPP/&gt; &lt;SearchPaths/&gt; &lt;/Completion&gt; &lt;/Configuration&gt; &lt;/Settings&gt; &lt;VirtualDirectory Name="src"&gt; &lt;File Name="main.cpp"/&gt; &lt;File Name="node2.h"/&gt; &lt;File Name="node2.template"/&gt; &lt;File Name="bag5.h"/&gt; &lt;File Name="bag5.template"/&gt; &lt;/VirtualDirectory&gt; &lt;/CodeLite_Project&gt; 
Not my wordlist.... gperf computes a hash for a user-supplied key, uses it as an index into an array of keywords, and compares that against the user-supplied one to see if it's a match. Out of curiosity, I ran the article's list of words through gperf and get this: http://pastebin.com/hnAzXKmn The assembly, minus the data sections: Perfect_Hash::in_word_set(char const*, unsigned int): .LFB13: pushq %rbx # .seh_pushreg %rbx subq $32, %rsp #, .seh_stackalloc 32 .seh_endprologue xorl %ebx, %ebx # &lt;retval&gt; cmpl $4, %edx #, len jne .L7 #, movzbl 3(%rcx), %eax # MEM[(const char *)str_4(D) + 3B], MEM[(const char *)str_4(D) + 3B] leaq Perfect_Hash::hash(char const*, unsigned int)::asso_values(%rip), %rdx #, tmp106 movzbl 1(%rcx), %r8d # MEM[(const char *)str_4(D) + 1B], MEM[(const char *)str_4(D) + 1B] movzbl (%rdx,%rax), %eax # asso_values, tmp109 movzbl (%rdx,%r8), %edx # asso_values, tmp113 addl %edx, %eax # tmp113, _21 cmpl $30, %eax #, _21 jg .L7 #, leaq Perfect_Hash::in_word_set(char const*, unsigned int)::wordlist(%rip), %rdx #, tmp114 cltq movq (%rdx,%rax,8), %rbx # wordlist, &lt;retval&gt; movzbl (%rbx), %eax # *s_6, tmp123 cmpb %al, (%rcx) # tmp123, *str_4(D) jne .L5 #, addq $1, %rcx #, tmp120 leaq 1(%rbx), %rdx #, tmp119 call strcmp # testl %eax, %eax # _11 movl $0, %eax #, tmp122 cmovne %rax, %rbx # &lt;retval&gt;,, tmp122, &lt;retval&gt; .L7: movq %rbx, %rax # &lt;retval&gt;, addq $32, %rsp #, popq %rbx # ret .p2align 4,,10 .L5: xorl %ebx, %ebx # &lt;retval&gt; movq %rbx, %rax # &lt;retval&gt;, addq $32, %rsp #, popq %rbx # ret .seh_endproc There's an initial check to see if the string length doesn't equal 4, but no special case for the key comparison, just a strcmp call. There's an option to use memcmp instead, but that doesn't get inlined either (And adds a second length check). I'm not going to actually benchmark it, but if this is somewhat comparable in speed to the article's perfect hash version, I'd be extremely surprised. 
I assume that cold functions will be more likely to cache miss, and the cost of the cache miss increases with the function size.
Nah, it's all good. At least it's on here now. Maybe someone who is experienced with both can help out now if they feel like dealing with the mess above.
Nvidia has plenty of jobs focusing specifically on those two specialties.
The bug is easier to catch, because it's buggier on a wider range of data. That's pretty convoluted reasoning. &gt; reasonable test data Either way, both signed and unsigned have to deal with whether they are wide enough. This isn't really any different for the two integer types, barring extremely rare cases where wraparound is not a bug. You still have to test this in both cases. Unsigned just gives you another problem, where you can have bugs even if your integer is wide enough. With signed this is impossible; the *only* way in which signed integers model real integers imperfectly is their finite size.
Will this even compile? EDIT: Turns out, it will. It'll just exit with a segmentation fault on running.
Yeah, infinite recursion will run off the end of the stack.
Hmm, so the proper way to deal with templates is to not have them in a separate file? I'm assuming we are going to get to that, but I guess our coursework is just making it clear to us that they work like classes. Thanks for that input! The problem with that though is the fact that a lot of this code is just reused from other assignments and we have to use them. For example our professor might be like," In assignment 7 you will use the node2.h/node2.cpp files to implement a bag class that *insert functions here* and create a test program (main) to show it works properly. So the node2.template was actually included prior to me starting to work on this project, but the bag5.template was the one I created. So to do what you mentioned would require me to actually change set code that the book/professor provided for the assignment. So I'm just slightly confused as to how changing what you mentioned would fix this when all of the other students are submitting it in the same format. I will try it later, though because I doubt they would take points off for me changing stuff around and it still working. Thank you so much for the help!
assuming the compiler doesn't realize it can TCO the function..... and turn it into an infinite loop.
 }; // NONMEMBER functions for the bag template &lt;class Item&gt; bag&lt;Item&gt; operator +(const bag&lt;Item&gt;&amp; b1, const bag&lt;Item&gt;&amp; b2); // The implementation of a template class must be included in its header file: #include "bag5.template" #endif // BAG5_H There we go. That's the end of the bag5 header file. I believe our goal this time was to implement the functions provided in the bag5.h file, so the comments were provided from the actual author or professor. It does, in fact, seem to say what you mentioned, but the confusing part is the fact node2.h/node2.template are formatted/implemented in the same manner with no comments like that and they were provided.
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/57zd0n/template_class_not_compiling/d8wtm74,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/57yw8q/short_question_about_static_cast/d8wto61,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; I don't think it materially changes anything I wrote though. The reason I pointed out that your code had a bug in it was because just before the code you had written: &gt; For example, the OpenCL example isn't motivating because a simple custom wrapper is really easy to write and **very hard to introduce bugs** into I was kind of using it to prove a point ;P &gt; Why is the lack of real use_count pose a problem for shared_ptr but not retain_ptr? shared_ptr's use count is guaranteed to be accurate in the case of it being 0 or 1. (If it's 1, then its considered safe to modify as it is unique). retain_ptr can't guarantee this. There might be some internal list use by the API you're interacting with or there might be a borrowed reference existing elsewhere (e.g., You've got a reference to a python list. Suddenly a python function you call incremented the list's reference count but no code visibly shows this in your program). retain_ptr can only guarantee that the use_count isn't "stale" if the documentation for a type says so. This is very few APIs, I should note. &gt; How is -1 a useful result? If it's a problem for shared_ptr I don't see how it's not a problem for retain_ptr. It's there because it shows that you can't access the use_count. There are some APIs and libraries that use reference counting, but you're boned if you want to know what the reference count actually is at any given moment. This is the solution for that (and I don't feel comfortable adding exceptions for something that returns an long, unless the user absolutely wants to throw) &gt; it's not immediately obvious to me why it's an insurmountable issue. Well the first biggest issue is the ABI. The second is how do you decide between decrementing and deleting (such as in the case of `atomic_reference_count`) or just calling the deleter? Additionally there is then no way for the user to get the deleter back out. It's a one way street, which I don't care for in shared_ptr's design. And how do you handle cases where one wants to have a delete, an increment, and a decrement and they are all function pointers? Because I have literally no idea. &gt; Again, none of this argues that allowing a custom ref/unref implementation to be injected into shared_ptr is a negative. If I have a shared_ptr&lt;Type&gt; and then another shared_ptr&lt;Type&gt; and one uses atomic operations, and the other doesn't, it'd be a failure at the API level. You literally wouldn't know. With retain_ptr, the traits object would give it away as they would be different. There's also been the desire by several people to have a non-atomic shared_ptr. But we can't make the current shared_ptr actually use non-atomic operations. That'd break the standard. Sure, libstdc++ has an internal policy tag for it's `__shared_ptr`, but that's *not* in the standard and would break ABIs if we suddenly introduced it as a option. &gt; It presents what it sees are defects with the boost implementation but not ComPtr nor WTF::RefPtr (nor again why those solutions are preferred to shared_ptr) As it's said in the proposal, we can't use shared_ptr because shared_ptr has its own reference count. These objects interact with types that were most likely written long before shared_ptr was an idea, and they all have their own. Placing them into a shared_ptr is fairly useless. The issues with RefPtr and ComPtr are that they are implementations separate of intrusive_ptr and they all do more or less the same thing. RefPtr does what retain_ptr does, but relies on ADL. Behavior can't be modified to operate on the same object but to perform different operations (retain_ptr permits this and it is how one could "quickly" implement a shared_ptr and weak_ptr) ComPtr overloads unary `operator &amp;` though and that's just... blech.
It's only called once, on an unconditional path, which should make it a perfect candidate for inlining, surely?
&gt; So to do what you mentioned would require me to actually change set code that the book/professor provided for the assignment. I thought you had come up with that scheme by yourself and figured you might have done something wonky given it is, as I said, *uniquely* unconventional. If that's how it was setup, then you have to roll with it and don't change it otherwise your teacher's head will explode, I can tell from here. I'll just let you in in a little secret. Come closer... Closer.... No, real close... You're listening? Good. NOBODY DOES THAT SHIT IN THE WORKING WORLD! THIS IS LITERALLY THE FIRST TIME IN MY LIFE I SEE A FILE WITH ".TEMPLATE" EXTENSION IN 15 YEARS OF WORKING IN C++! You mentioned earlier using Codelite with TDM-GCC. Is that also mandatory or could you install VisualStudio? It won't be a magic fix but that setup will be also more... conventional and thus easy to get help with.
&gt;very few people are actually using them I come from a different perspective =) https://www.useopus.com/note/xGACxI
make two build directories, build-unix, build-msvc. in each build dir, invoke cmake with two different generators {VS, unix} via -G. open generated .sln file with VS. Dont forget to rerun cmake for unix if you change build files.
But the compiler doesn't know that, does it? At the point where it needs to make the decision about inlining, all the optimization that allows that has yet to happen. (I'm speculating)
Does C/C++ ever do TCO? I don't think so, but it would be nice if it did.
Actually, scrap that. I just realized it's because I had the subreddit style off. Works fine with it. :)
gcc certainly does. http://stackoverflow.com/questions/15897452/tail-recursion-in-gcc-g
Thanks! I tried creating a makefile project and linked my linux machine in the connection manager, then I tried to set up the commands and when launching debugging I received a very informative error message: http://imgur.com/a/MrR98 I probably didn't set the sources for the debugging, but still: it would be nice to let the user know this :P
[removed]
What the..
There is gnu::flatten attribute in gcc for recursive inlining.
You can set those variables from KDevelop's GUI for the cmake cache as well, just look at the project configuration dialog. Setting them from command line has the same effect.
&gt; It would be a nice feature to have in future version of VC I guess it depends how much Microsoft is willing to take away from their partners collaboration.
Short answer yes. Keep coding in C++ in your spare time and keep looking. 
llvm does
That would a great addition. Instead of writing say dot(cross(a, b), c) you could write a `cross` b `dot` c. All implemented outside of your classes so you can have a generic and specialized versions. Right now if you want to use a.cross(b).dot(c) style but still want to have a generic version used by default is quite a pain.
Here is a list of websites that offer programming challenges. Theses are great for prepping for interview or just for learning new stuff. These challenges are designed to increase your understanding of algorithms and Computer Science concepts. Happy coding! https://open.kattis.com/ https://www.hackerrank.com/ https://projecteuler.net/ 
Might be worth looking into some game industry jobs. 
The standard library tends to be a standard deviation of 3 higher in quality than a random boost feature. That doesn't mean boost is low quality, but rather that the standard library tends to be ridiculously solid.
Don't take my comments as any kind of universal truth. I guess it is a matter how long you plan to stay on this job. For example, I work across Java, .NET, Android and some occasional C++ (very little). No way I can fit language + standard library + major third party libraries for all those languages at the same time on my head. So of course, I need to occasionally refresh some stuff. You mentioned PHP, JavaScript, C# and Python as your future languages. So hard core C++ shops might interview you about C++, boost, differences between C++98, C++03, C++11, C++14, what do you like in a specific version, what are the features you are looking forward in upcoming versions. Plus the typical programming exercises. Which means you need a good cover letter explaining how you kept your C++ skills up to date while at the same time working across the languages you referred.
&gt; I was kind of using it to prove a point ;P Eh - a bug in an online post that took 15 seconds to write doesn't necessarily represent real-world code. &gt; retain_ptr can't guarantee this Then why even bother providing a use-count? Why not make it conditionally enabled so that it's a compile-time error to try &amp; use it on an unsupported type? In fact, why could this same principle not be applied to a modified shared_ptr? &gt; Well the first biggest issue is the ABI. You keep saying this but not explaining it. Later you mention ABI breakage so I'm assuming that's what you mean. &gt; That'd break the standard. Sure, libstdc++ has an internal policy tag for it's __shared_ptr, but that's not in the standard and would break ABIs if we suddenly introduced it as a option. If that's the only concern it's questionable because C++ famously, for better or worse, doesn't have an ABI defined in the standard. For example, this wouldn't pose a problem for Visual Studio's rules, at least as far as I understand them. Additionally, all major STL implementations have already adopted namespace versioning which should provide for a solution for an ABI-incompatible version of shared_ptr (or any STL class) that won't break existing code and wouldn't subtly break the ABI. This does not seem like an insurmountable problem. &gt; The second is how do you decide between decrementing and deleting (such as in the case of atomic_reference_count) or just calling the deleter? Is there something wrong with the obvious solution? template &lt;typename T&gt; class default_shared_ptr_ctrl_block { public: default_shared_ptr_policy() : ref_cnt_(1) {} void ref() { ref_cnt_.fetch_add(1); } bool unref() { return ref_cnt_.fetch_sub(1) == 1; } void destroy(T *value) { delete value; } private: std::atomic_long ref_cnt_; }; template &lt;typename T, typename ControlBlock = default_shared_ptr_ctrl_block&gt; class shared_ptr&lt;T, Policy&gt; { ... }; This doesn't seem incompatible from an API level with existing code but it seems like you could provide a shared_ptr implementation that does something different with the use-counts. Again, this is 15 seconds of a reddit post so please argue against the strongest version of my argument you can interpret rather than the weakest interpretation (e.g. I know this doesn't take into account weak_ptr but that's intentional to keep the post small). &gt; Additionally there is then no way for the user to get the deleter back out. A STD proposal is made stronger by listing specific problems not solved by the current available solutions not because there's a disagreement on specific implementation details. &gt; If I have a shared_ptr&lt;Type&gt; and then another shared_ptr&lt;Type&gt; and one uses atomic operations, and the other doesn't, it'd be a failure at the API level. You literally wouldn't know Well, in the design above I show how it is possible to distinguish that case. I don't know if erasure vs not is a problem but both designs have to be explored &amp; that has to lead the reader to a natural conclusion that neither approach is right. You have started with the assumption that existing solutions are insufficient and presented a circular argument in this proposal (i.e. we need an intrusive ptr because there are multiple solutions of intrusive ptr &amp; we need a single intrusive ptr). There is no explanation of why existing solutions are insufficient or could not be adapted to be sufficient (you present unique_ptr for some reason when a reader would more naturally compare it against shared_ptr). I'm not trying to say there's absolutely no need for this. I'm saying the paper doesn't make this a self-evident outcome; if you do this your argument is stronger &amp; the paper more likely to be adopted because all opposition is pre-empted. &gt; The issues with RefPtr and ComPtr are... Great. Why is this explanation only in a reddit post? Put it in the proposal. There's another concern with your proposal regarding detach. The following (which is impossible with shared_ptr), is possible with your proposal: retain_ptr&lt;T&gt; x(...); unique_ptr&lt;T&gt; y(x.detach()); // wrong - y deletes the pointer even though the ref count is non-0. It's almost certainly the reason shared_ptr doesn't have release at the moment; maybe someday it will have a conditional release if you're the only owner. If the rebuttal is that the caller should use `use_count`, that can be very subtly wrong since `use_count` can race with an external thread. You also describe the undesirable parts of ADL, at least as I understood it, that the policy is dictated by the type &amp; can't be customized per instance. It seems like this implementation has the same problem and that's it's a fundamental limit of intrusive pointers: retain_ptr&lt;T, atomic_traits&gt; x(...); retain_ptr&lt;T, nonatomic_traits&gt; y(...); One of the above can't compile because the intrusive ptr is either atomic or it isn't. Or if they do somehow compile, then this becomes wildly but subtly incorrect: retain_ptr&lt;T, atomic_traits&gt; x(...); auto y = x; retain_ptr&lt;T, nonatomic_traits&gt; z(x.detach()); // ref-count is being controlled atomically &amp; non-atomically. retain_ptr&lt;T, nonatomic_traits&gt; z = x; // even more wildly incorrect (if valid) So in fact, it seems like the ADL approach is stronger because with intrusive pointers the reference count policy is really tied to the type T, so any flexibility per-instance is not real. Again, I'm not saying that intrusive pointer by itself is necessarily a bad idea. I'm saying that this paper doesn't actually list the problems that motivate intrusive pointer as a solution by itself (regardless of the other existing implementations - what is the underlying problem that motivates intrusive pointers), it doesn't explore potential modifications to existing classes that could still solve the problem (try to build the strongest alternative solution, not the weakest, and show why it would still fail), and it has some questionable design choices (returning -1 instead of disabling use_count, are different traits for a given type possible &amp; what are the potential problems of that, the ability to accidentally transfer ownership from retain_ptr to unique_ptr, etc).
It's hard to believe that because that kind of code is not something ubiquitous or something which can be done by many. Also it's not of a kind that one might work on it as a side project ... I think it requires a lot of effort and time. However, it's almost impossible to see such job ads.
I wish if it was that easy ... usually there are a lots of individuals from great range of companies contributing to the implementation but it's really hard to spot if such companies ever look for more developers interested in that matter. 
Google &amp; Apple contribute greatly to libc++. Microsoft has their own implementation of STL licensed from Dinkumware developed/maintained by /u/STL (&amp; probably others too I imagine). Apple may be not be investing as much in libc++ now that they're focusing on Swift. /u/HowardHinnant, a prominent libc++ contributor, works at Ripple. Bjarne works at Morgan Stanley so I imagine there's some amount of STL development work going on as well. Bloomberg has their own BSL that complements/supplants STL so I imagine that it's not inconceivable for them to have developers working on an STL implementation. The easiest thing to do would be to simply look at the committer log for libc++ &amp; libstdc++ and see what corporate e-mail addresses are present. Then you'll get a sense of what companies are funding development (look for multiple people or lots of patches from the same company).
Cool! But I think IP won't be 127.0.0.1 as the Linux is on a remote machine?
Downvotes are there likely because you should post on the sticky thread (Q4 2016), not as a new post. (Don't forget to replace the shortened url by their target, as per the rule).
Yes, Microsoft and Bloomberg have a few people working on their implementations. Bjarne doesn't work on a standard library implementation, Morgan Stanley are not in the compiler business.
I guess it's the sort of job/position you cannot apply for, but would rather have to be approached and offered the job - meaning you should be well known. 
I just want to point out that there are other STL-like libraries out there that you may be able to contribute to (or work on full time) besides libc++ and libstdc++. For example: EASTL (a game-engine-focused STL-replacement), boost::algorithm, various "embedded" STLs, and so forth exist. A lot of these are quite serious libraries and do require full-time-developers to maintain. Don't close yourself off to just the standard libraries. 
Yes. Removed.
Here's a script you can run to get an idea of the companies involved at some level with a git repository: git log --format='%aE' | sed 's/[^@]*@//' | sort | uniq -c | sort -nr
Let me know if you have any ideas for new types / other feedback.
My story: I started learning C++ in early 2002 (mostly self-taught, one college class), joined MS in mid-2004 working on Outlook (no STL and no operator overloading at the time, lots of COM; I was unhappy). Was working on a personal library of modern C++ at the time, and posted frequently to our internal mailing list, solving other devs' C++ issues. Caught the attention of the Visual C++ Libraries dev lead, who encouraged me to switch teams. Re-interviewed for VC, switched in early 2007, and I've been an STL maintainer since then. I had limited library dev experience (my relatively small personal library and a handwritten doubly linked list template I added to Outlook) and certainly no STL dev experience. (When I switched to VC, I was an SDE I, which is the most junior title at MS.) However, my personal library was the right kind of experience - mostly pure computation, significant amounts of templates, extreme focus on correctness and performance. My STL usage experience was fairly high, because it was smaller and simpler at the time, and I had read all of Effective STL and similar books.
They don't have the same issues, both types wrap at width dependent limit(s) far from zero, but only one wraps at zero. Your statement is about them being equally intuitive is nonsense, because people use unsigned to model the natural numbers, not to model modular numbers. The behavior of unsigned radically departs from natural numbers, even near zero, unlike signed and the integers. And you can keep repeating that numbers never need to be negative all you like, doesn't change the fact that subtracting indices is not uncommon, and this simply leads to bugs more often when you use unsigned than signed, because the domain is modeled more poorly.
Yes, unfortunately. I much prefer Rust's approach (here again): in Rust such an operation produces *an unspecified value*. This leaves room for many implementations: a trap or panic are part of this unspecified value, as is a bogus value, but the behavior is otherwise defined and therefore does not carry the time travel or other weird effects one might experience with UB. (In practice, in Rust, the default is to panic in Debug and wrap around in Release... the latter because of overhead in the detection)
But isn't sizeof(unsigned int) == sizeof(int)?
Since we're all doing "my story", here's mine: I contributed to Boost for a decade, and some to LLVM, and then when my boss started an "Open Source" group, I convinced him that I should work on Boost and LLVM on company time. I started doing libc++ work, because it was interesting to me and because I had known Howard for about a decade (via Metrowerks and Apple), and when he left his job at Apple and was unable to keep working on libc++, I was chosen to lead the libc++ effort. TLDR: volunteer for a long time, be in the right place at the right time.
Oh, nice, thanks for the info.
Something like Bounded&lt;T, minValue, maxValue&gt;. I guess it is possible to use LessThan&lt;&gt; and MoreThan&lt;&gt; for that, but a convenience class would come handy. Apart from that the Sorted&lt;&gt; with a predicate we talked in the previous version, and also the possibility to add or remove values while list remains sorted.
"patches accepted" Start there. Basically start working on it for free. If your contributions are really valuable, then a value can be placed on guaranteeing your future contributions - ie someone might pay you.
EDIT: was really wrong, I'm sorry. You're probably correct.
[citation-needed] I've seen lots of claims of this with examples from LLVM bytecode, but they've all been from using int as a loop invariant counter over a builtin array, which is already terrible code. The correct type for a loop invariant variable over a builtin array is `size_t`, which avoids that performance problem. At CppCon when Chandler was talking about this his claim was that it affected data structures if you did this, but I don't understand why a compiler wouldn't just load the value into the size_t sized register with the normal int-sized load instruction.
Turns out not opening the file at all is more work for [gcc](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=58770) and pragma once is significantly slower there (still true on 5.4). Also i really hope there is no code in the world where hard/soft linking anything is used in a manner where code depends on it. And if there is, its one more reason to use the pragma.
"Hey, so there is this guy, literally knows nothing about C++, but his first and last names are BOTH "STL", we must hire him for PR reasons"
Thank's for the comment. It worked fine in blogger's preview pane so I did not realize it was broken... :( I have made a stop-gap fix, and it seems to work on my phone now...
I like [this](http://aras-p.info/blog/wp-content/uploads/2009/03/cppaccident.jpg) more
I know, we should have modules by now, but C++11 should really have added `#once` to the standard. The damage done by a potential minor slowdown of the switch by it would clearly have been outweighted by it's MASSIVE advantage over include-guards.
I mostly come from a .net background where DI is the order of the day. I dabble in C++ occasionally but have always wondered - is it just me or is DI just not a common thing in C++ land? Is there a reason for this?
I think DI in C++ is not as popular as, let's say, in C# or javascript, because most C++ applications existed before C++11 and have their own funky structure. It's only recently (2011) that we can make robust tool like so that are fast and somewhat usable. I don't have metric or anything, but this is what I think it's the most probable reason. Another thing is that there might be a lot of people that may fear introducing a library that may change their structure completely, or trying to avoid hard dependencies, or simply just don't need such tool. It's understandable, but I think things are worth trying if you can remove the word "singleton" from your codebase ;) DI is less popular in C++, but still a thing. I know google have their own tool to do this, and boost introduced a DI library for C++14 recently.
Honestly, the issues with pragma once always seem super contrived. I don't think I have ever heard of a case of it breaking in practice.
!remove
OP, A human moderator (u/blelbach) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/58512g/just_finished_chapter_17_of_the_c_programming/d8xsvb4,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Sorry, this is a bit off-topic.
excellent to the whole fleshlight
Just one minor thing: In [this class](https://github.com/I3ck/FlaggedT/blob/master/inc/flaggedT.h#L49), you define `operator T` for both the const-ref and rvalue case. I believe that the class should provide `operator const T&amp; () const &amp;` instead. This way, you can pass a `FlaggedTBase&lt;T&gt;` to a function that expects a `const T&amp;` without having to create a copy, which will be costly for containers and the like.
What you don't symlink your headers across network shares?
&gt; Even with modern code bases, a problem that can realistically happen is using 2 libraries that both include `some_really_cool_header.h` that just has pragma once in it and then you're hit with a multiple definition problem. I don't understand what you mean here. Do you mean each lib would include its own header with the same name (2 separate files)? In that case, doesn't the compiler hash the contents or something to avoid this kind of problem?
To be honest, I prefer include guards because it can let me replace a header in a library without having to hack the library. Most people probably don't have that use case, but I work on weird platforms have to do this fairly frequently. 
Which makes sense. There's only a handful of C++ std libraries. The big ones are the ones part of gcc, clang and msvc. You have a few other ones for more odd platforms (AIX, Solaris, etc.), a handful or two as part of embedded toolchains (Greenhills, IAR, etc.). Basically 10-20 different ones. Each implemenation doesn't require that many paid people to work on fulltime. If we ballpark the amount of people having this as their job at 100-200 people, there is not that many people needing to be replaced per year - you're not likely to see job openings for them - the companies that has a position available would offer such a job to someone that already works on one of the open source implementations, boost, or any other big well known (open source) C++ library/application - or someone else already within the company. 
https://msdn.microsoft.com/en-us/library/4141z1cx.aspx &gt;Also be careful to manage include paths to avoid creating multiple paths to included files, which can defeat the multiple-include optimization for both #include guards and #pragma once.
I'm saying the reason explained isn't a strong argument and isn't materially accurate (all major compilers do actually support it correctly), thereby rendering the advice questionable (have to be careful here with appeal to authority). If you're an author for a widely-used library that gets ported to obscure embedded architectures, sure, this is great advice because those frequently use versions of GCC (&lt;4.0) that have broken #pragma once (&amp; even then only in corner cases). For the majority of people using a decent version of GCC, or any version of clang/MSVC, this isn't an issue to worry about.
If you think you don't need to worry about wrapping far from zero, a generation of security exploits begs to disagree. You're being foolish.
[Wikipedia says](https://en.wikipedia.org/wiki/Pragma_once#Portability) that only one compiler does not support `#pragma once` properly at the moment. I sure there are others not listed, but all main compilers does.
Linux-only, but I've been using this little fragment in my .vimrc recently: command CHeader :read !echo "\#ifndef H_"$(uuidgen -r | sed s/-/_/g) 
From skimming it, this paper seems to be about comparing some kind of weird `std::for_each` style looping with lambdas to some kind of weird imitation of Java iterators. Both of them are incredibly strange and pointless and the cool stuff you can do with lambdas far exceeds overcomplicating some mundane loop. o.o
That is _such_ a weird way to evaluate the usefulness of a language feature! :-o
Pro tip: don't use header guards, use a modern compiler. Then you won't ever have to use this tool.
Lambdas are not a silver bullet, but they make code more readable in many cases. Let's take Java for example and its streams: http://www.drdobbs.com/jvm/lambdas-and-streams-in-java-8-libraries/240166818?pgno=2 Or C# with LINQ, that makes many operations a breeze, http://linq101.nilzorblog.com/linq101-lambda.php
I guess this paper should be called, "An empirical study on the impact of new tools on people who don't invest time trying to learn them right". Srly, I can't live without lambdas, make the generic programming so much easy, clear and readable.
Yeah, the people who wrote this seem to not really "get it." &gt; four data sets were not usable because three of the participants did not follow the experimental protocol Those four programmers were four of the twelve professional programmers (in a sample of 58). They didn't call that out. I wonder why... /s Their experiment seems like it wasn't even suited to people who actually program professionally. Also, void marketBasket::iterateOverItems(function&lt;void(item)&gt; f) { for(vector&lt;item&gt;::size_type i = 0; i &lt; items.size(); i++) { f(items[i]) ; } } Yergh. They're "testing" lambdas, but they don't write the type of code you'd write when *using* lambdas. Which furthers the point, they just don't "get it". std::for_each(item.begin(), item.end(), f); They just want you to write the lambda you'd use in std::for_each, but they phrased it so poorly. Testing time to develop? Code is written ~once and read ~tens of times. They just don't "get" lambdas, the benefits of them, or how to evaluate the utility of them. &gt; one data set was deleted by accident Heh, color me surprised.
From reading the first two examples and the readme, it's hard for me to understand what the point of the library is. I haven't done di before, so I guess that is part of it.
Well... the issue is not strictly a bug. It's just how most C++ build systems (and many others for other languages) and git (and many other version control systems) work
This is terrible... How the hell did it get past the reviewers :(
I'd rather put a header in my include path before the library to override whatever I want in it than using the include guard. You can then add comments and new definitions as necessary.
Probably the worst paper I have ever read. Subpar, suboptimal, non-idiomatic code throughout the article. Hope the authors redo their study and experiments on the subject.
Given that include guards are a standard-compliant mechanism that is usually not slower than the non-standard `#pragma once` alternative, my choice is clear.
Ha, didn't realize you were the author, I mostly wanted to vent about the one in our codebase :) The problem (with ours) is that the refcount starts at 1, and the destructor has a sanity check that the refcount is 0. The only way to achieve this (aside from manually decrementing the refcount, yuck) is to use the associated 'retainer' type which takes the pointer. So, no easy automatic lifetimes for those types, which is not good for developer sanity (or performance). You have a similar issue, since the type starts with refcount 1 and the "adopting" constructor doesn't increment it. However, there's no sanity check in the destructor of the reference count, so the reference count can be safely deleted when it's non-zero (e.g. when stack-allocated). I reread your comment and I'm not sure what the downside of starting with refcount 0 and having the "retaining" constructor by default is? I haven't explored this space myself as I've been simply switching to `shared_ptr` where possible :)
Could not agree more.
Where does one find that GUI for the CMake cache?
It really depends on the compilation complexity and rebuild times. The project that triggered the creation of this tool had the Travis machine spend about 40 seconds in clone (with default depth 10) and then about 25 minutes in C++ build (of about 5500 relatively complex files). Thanks to this tool in 95% of the time, when only a small amount of cpp files have changed, the build time is less than a minute. That's 24 minutes saved for each build. Here are screenshots from the travis log: http://imgur.com/a/QX4LR If your C/C++ build takes up more than a couple of minutes on Travis or AppVeyor or Codeship, and source files rarely change, you will CERTAINLY find this useful to save time.
Fair enough. Although the typical user of Travis-CI does not have persistency of code, you get a new virtual machine (docker I belive) and the code gets built from scratch every time. What setup / Travis-CI configuration do you have?
How do you not get duplicate symbols this way using pragma once? Without include guards, they would be collide. Edit: Got it, works with full replacement of said header. 
I did some experiments on the subject. Alas, expressing non-integer bounds (i.e. double ones like pi/2) is really cumbersome as double values are not valid template parameters. https://gist.github.com/LucHermitte/77f123683dcbb1d9e0b044ff772e25dc Don't hesitate to improve or to find better solutions.
Right-click on your project and select "Open configuration", then under CMake.
&gt; What's your opinion on referring to the static member npos via the string instance instead of the canonical, but longer to type, and IMO visually rather noisy, std::string::npos? As long as this style is consistently used, it'd be fine. Personally, it would trip me up the first time I saw it as I'm used to the longer/verbose form. I've also seen stuff like this done: `size_t END_MARKER = std::string::npos` not a huge fan of this either, but since it was consistent, one can tune it out as boilerplate and focus on what's actually going on. :)
Thanks for the link.
If you look carefully at example1, the way `PathPrinter` is constructed is described in the service definition. That way, you can add, change, and remove dependencies and change the constructor of `PathPrinter` completely without the `main()` function even noticing it. Let's say you're constructing `PathPrinter` at 2500 places in your codebase. If you decide that now it should receive `OstreamProvider` in it's constructor too, you would have to change those 2500 places that call your constructor. With kangaru, you will have to change one thing: the service definition.
To be fair without a proper range api it is not exactly intuitive. OP's code written using stl would be something like this: const char q[] = "foo"; auto it = std::search(s.begin(), s.end(), begin(q), end(q) - 1 ); Which is error prone (notice -1 at the end?), it should be as simple as: auto it = std::search( s, "foo" ); But yes, the part of `std::string` interface that uses indexes is really dumb, I think it is there mostly because it predates the STL.
TCP Partitions? I thought we moved onto TCP/SNG - TCP Systematic Node Generation. 
More like reverse Dunning-Kruger...
Likewise for std::map. Right now, if you don't know that a key exists, you either use exceptions or a double lookup.
This makes a lot of sense to me. I've love to hear counterarguments.
An optional&lt;size_t&gt; would be roughly double the size of size_t, and if you can't inline the call you couldn't just return the value but would have to construct some hidden pointer or return it on the stack. (I think, without actually looking up the ABI rules)
Reverse Dunning-Kruger IS Dunning-Kreuger.
It's just a static member; I don't think "magic values" is a concept that exists. Would it still be a problem if `npos()` was a method?
How about contributing to EASTL? Disclaimer: I'm a biased EA employee :) I did contribute to it a bit when it was closed source..
Also, there's pitfalls with include guards that we just accept. Like name collision and typos: #ifndef MYHEADER_H #define MYHAEDER_H //... #endif 
Maintaining a project with 100 targets written by 25 developers over 15 years and 30+ OSS dependencies has made me come to hate include guards. You'll be lucky to find even a single target's include set with a consistant guard pattern. OH and you can easily screw up include guards. `projectA/include.h` uses guard `COMPANYNAME_INCLUDE_H_` `projectB/include.h` uses guard `COMPANYNAME_INCLUDE_H_` Fine until someone needs both and then they need to be refactored - oh and now you might as well refactor all of the other include guards in that project. So should include guards include their project name, their parent folder name, a UNC path? What happens when companies change hands? (seriously this is also happening to us) This actually just happened to me. We had two files in different subfolders but both subfolders were on the include path - in the reverse alphabetical order. I changed it because it wasn't documented and boom things blow up. Only one of the headers was ever being used because the include guard prevented the other. For the record even after all of this we still use include guards because #pragma once simply isn't supported on all of our target platforms but we would if we could. Developer time is far more valuable than those extra seconds saved in compile time.
Many ABIs allow multi-word return values via registers. On Intel, it's typically 2 words (64bit on x86, 128b on x86-64). So `optional&lt;size_t&gt;` would likely return via registers. (The exception here appears to be [Windows 64b](https://msdn.microsoft.com/en-us/library/7572ztz4.aspx), which only allows one return register.) Larger structures are usually returned by the caller allocating stack space for it and passing a pointer to the callee. The callee making space for it on the stack is awkward at best because you need to remove everything you added to the stack before the `ret` instruction.
This code would break if size_t was signed. Now you may not care since the standard states it is unsigned, but these functions all return npos specifically so it makes more sense to me to compare to that. Your code should really depend on the signedness of size_t :P
Interesting, I didn't know that. Although `optional` seems to be slightly different than just a bool+size_t, preventing g++ from actually doing it: ➜ cat return.cpp #include &lt;experimental/optional&gt; std::experimental::optional&lt;size_t&gt; f() { return 10u; } struct opt { bool b; size_t s; }; opt g() { return opt {true, 10u}; } ➜ g++ -c return.cpp -std=c++14 -O3 ➜ objdump -d return.o return.o: file format elf64-x86-64 Disassembly of section .text: 0000000000000000 &lt;_Z1fv&gt;: 0: 48 89 f8 mov %rdi,%rax 3: 48 c7 07 0a 00 00 00 movq $0xa,(%rdi) a: c6 47 08 01 movb $0x1,0x8(%rdi) e: c3 retq f: 90 nop 0000000000000010 &lt;_Z1gv&gt;: 10: ba 0a 00 00 00 mov $0xa,%edx 15: b8 01 00 00 00 mov $0x1,%eax 1a: c3 retq 
Lambdas for me have been syntactic sugar to replace functor classes, and have definitely increased productivity and readability compared to functors (I use the equivalent of `std::for_each` a lot). So they definitely benefit me as a professional. I was also a TA for C++ courses, and the single most annoying C++ syntax I had to teach was writing a comparison functor for `std::sort`, so I think lambdas would help novices there.
I take it the same functionality can be instituted with Boost's `unique_lock/shared_lock`? Or do the SRW APIs have some advantage?
Best advice is to always "just write something". For example, think about your work with undergraduates and grant writing - can software help you manage this? Something as simple as a personal time tracker with exactly the kind of reporting you want is excellent motivation to get your hands dirty. You are your own customer, enjoy!
Why not simply allow any non-alpha character sequence to become an operator like F# does? E.g., `x &lt;@&gt; y`? This way, if you want to distinguish between vector and scalar multiplication you can just define `*` and `.*` (think MATLAB) respectively.
`unique_lock` (in both std and boost) is just an RAII-style wrapper that makes it pleasant to work with any lock class meets the requirements of the Mutex concept (or SharedMutex in the case of `shared_lock`). So you'd use the SRW APIs to implement a mutex class ([example](https://gist.github.com/markwaterman/1e385dab141e92f5cc121f659af3496e)) and then use boost/std `unique_lock/shared_lock` to manage its lifetime and ownership.
This doesn't work with constructors, but its goals are similar: https://crazycpp.wordpress.com/2011/10/
!remove
OP, A human moderator (u/blelbach) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/58b20i/advice_for_grad_student_trying_to_transition_back/d8z0805,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; you're relying on the fact that npos is the largest possible size_t Not exactly. I'm relying on the fact that `npos` is never less than `size()` -- I don't really care what the actual value is. This is why it is more robust: there is exactly one value that is (possibly) legitimate (`npos`) and then there are billions of other values that definitely are not (anything `&gt;= size()`). My idiom catches them all. If `size()` were signed, I would also have to check for `&gt;=0` (making the idiom much less appealing) but since it isn't, I don't.
&gt; In any case, there's almost never a reason to refer to it directly Here's the actual spec for `find`: &gt; Returns: xpos if the function can determine such a value for xpos. Otherwise, returns npos. Considering the spec of the function says that `npos` is a possible result, it makes a lot of sense to me to compare the result with `npos`. By the way, by "magic value", do you mean sentinel value? If you're against sentinels, then the `optional&lt;size_t&gt;` approach discussed above should be appealing.
&gt; A thread that write-acquires the same SRWL twice will “deadlock” itself. This makes it simple to detect and fix mistakes. Why would it make it simple? I would even argue that if some code deadlocks with a non-recursive mutex, but has no issues with a recursive one, then that code is not necessarily broken. Furthermore, recursive mutexes have very valid use cases. Especially if you are dealing with legacy code with god knows how many threads. The last thing you want is to untangle a mess like that just so you can use a non-recursive mutex. &gt; Mistakenly nested read lock scopes lead to nasty threading bugs when the innermost scope releases the lock too soon. If you are using C++ you can (and should) utilize RAII to release locks based on the lexical scope.
It is a bug. It shouldn't do a fresh clone every time because it's just wasteful (unless they're grabbing from a local mirror they incrementally fetch into). If they insist on doing that, then they should update the build product timestamps in the same way you're doing or force all files to the timestamp of the last commit on checkout. Time-stamp based build systems are so common &amp; you'd think they'd want a free way to reduce the build load on their machines.
Or, you know, there is almost identical assembler code: https://godbolt.org/g/p4Gefs
You might be thinking of one of the online compilers linked from https://isocpp.org/get-started . I am removing your post as basic questions are off-topic for our subreddit.
Self-deadlocking code is simple to detect since it's deterministic and usually happens fast. Single threaded unit tests can catch it, unlike normal deadlocks. Most self-deadlocking code would run perfectly fine had the lock been reentrant, yes. The point is you have failed to establish a clear public boundary if this happens. If you consistently create a clear public boundary your code becomes a lot easier to maintain. I've written plenty of very fine-grained locking code that is subject to very intense parallelization. I can't recall ever seeing a single bug report about a deadlock. If you let lock acquisition order follow ownership and each class has a clear public boundary, you can easily reason about each class in isolation. Reentrant mutexes are useful for legacy codebases, yes. If you plan to maintain and augment the system for a long time, it can make sense to clean it up and define clear boundaries instead of dealing with a never ending stream of elusive deadlocks. I don't want to get into a debate on when you should clean up legacy codebases or continue doing ad-hoc patches to them. In my experience you will often make more changes to legacy systems than you think :) My experience is also that even horrible messes that seem impossible to untangle can incrementally unravel themselves quite fast once you get past a certain threshold. Complete rewrites are obviously more fun and in many cases a better approach too. By "read lock scopes" I mean RAII scopes. I should perhaps have chosen some other wording to make this clear. A self-deadlock usually occurs when an inner function, already wrapped by a public outer function with a lock scope, by mistake calls out to another public outer function. I usually have a naming convention for inner vs outer functions to easily spot these mistakes. Thanks for your feedback.
My comment from blog reproduced (with typo fixed): I don’t think your example is correct; ConstructorKey as written is an aggregate, and it seems like {} initialization directly goes into aggregate initialization, bypassing any access checks. Live example: http://coliru.stacked-crooked.com/a/243d61fc72b38e4b. Changing the defaulted constructor to an empty one counts as a “user-defined constructor”, making ConstructorKey a non-aggregate, making aggregate initialization impossible, making it work.
Implementing a DI container without reflection was quite a challenge that's for sure ;). Indeed, one is not required to use a container to use DI. I think of DI as a way to structure and organize code, and a DI container something that help normalize and automatize the implementation of DI in a project. As you guess, the purpose of that library *is* to provide that magical container that seems to do everything automatically.
Sorry for not checking in earlier after replying. I've seen another report of that, we don't have a repro yet. If you got past that it would be helpful to us to know what options you had to change. 
&gt; Something along the way must make std::experimental::optional too opaque to the optimizer. Does the optimizer even have the right to decide this? I feel like the process of selecting the correct parameter/return value passing convention should be deterministic based on the struct definition to allow linking.
Clang will with -Wheader-guard, but I can't find a GCC or MVCC equivalent.
&gt; A self-deadlock usually occurs when an inner function, already wrapped by a public outer function with a lock scope, by mistake calls out to another public outer function. I usually have a naming convention for inner vs outer functions to easily spot these mistakes. Can you make an RAII wrapper over the lock with a constructor that only tries to lock if the thread doesn't already have the lock, and only unlocks if it locked in the constructor?
I'm not the author, just found it on the internet.
How do you know if the current thread holds the lock? `SRWLOCK` doesn't know; this is part of what makes it fast. There isn't enough space inside to store the owning thread ID.
How about: for(const auto &amp;foo:item){ f(foo); } Though just going , std::for_each(item.begin(), item.end(), [](){//random stuff}); as you said makes a lot more sense.
`ntohl` is a noop on a big-endian machine; why would there be issues?
Thanks! This gives me hope! :)
Yeah, you don't normally use a lambda when you're doing: for (const auto&amp; foo : bar) since the situations where it affords any benefit is minimal. But you often do use lambdas when you're doing std::for_each(bar.begin(), bar.end, ...) So I kept to the latter in my example :)
Indeed, I had it backwards. :-/
I'm surprised he didn't post it here himself. His articles pop up from time to time and they're a pretty good read.
Thank you! I always feel bad when posting my own articles here so I wait around a day or so...
I asked him if Bjarne gave him specific reasons, but he does not know them.
dunno for you, but my IDE already shows me the name of the parameters during autocomplete, so I don't really see the benefit
Uhm, meter and kilogram are physical units not physical quantities. The types should have been called 'length_m' and 'mass_kg' to make it clear.
Something like ocaml's labeled parameters? 
Umm... The problem is not `sizeof`, it's that the class *actually* is not defined. You only declare it. Try this: template&lt;int&gt; class X {}; X&lt;sizeof(SomeType)&gt; _; 
Does it work if you actually define the class, not just declare it exists?
did you review the existing solutions first ? e.g. what's in : https://marcoarena.wordpress.com/2014/12/16/bring-named-parameters-in-modern-cpp/ also a previous reddit discussion : https://www.reddit.com/r/cpp/comments/2jiai2/n4172_named_arguments/
Thank you. I tried to google such words but I hardly find any discussion about it.
How about C++17 auto template parameter? Like: template &lt;auto&gt; class X;
Oh, I see. Nifty. In VS 2015, there's usually no need. You can just hover over sizeof(...), and it shows the value in a tooltip. (Also appropriately reflects changes if you e.g. change build configuration.)
Returning iterator, or more generally: a coordinate, is lighter and cleaner. The current API actually doest almost that, except for not having a robust notion of "last" coordinate, which the npos hack serves for. I would prefer std::string::iterator, but I can get that with the general algorithms. std::optional on the other hand is a bulldozer. In this particular case optional return value is bogus - like you were designing the API, but gave up on some corner cases throwing them into the "nothing" bag. Using std::optional return value here is like birds. What semantics exactly it carries? We just don't know. I presume std::optional it will be as overused as auto or lambda, especially by inexperienced programmers.
I could do with an IDE toggle that showing and hiding the names of the parameters at All/Writing/No times. That I believe would be cool and helpful. However other times I simply don't want to have to deal with the verbosity nor do I want to have to deal with writing it out every single time I want to use the function. So having the IDE deal with showing and hiding it would certainly be useful.
I don't mind any syntax, I would just enjoy having such a thing a C++.
Indeed, that would be one way for IntelliSense to not work. :) I tested this on a huge solution, BTW &amp;ndash; over 100 mostly C++ projects &amp;ndash; and the sizeof tooltip became available as soon as the source files were parsed, which was a reasonable time (e.g. 10s of seconds) given the size of the solution. On a small project, of course, it would be practically immediate. 
Since it already works, I would opt for standardizing something like this: https://ideone.com/dQATaj
We have a [pinned post](https://www.reddit.com/r/cpp/comments/55evue/whos_hiring_c_devs_q4_2016/) for requests like this. Also try posting on r/gamedevclassifieds.
ah thanks
Oh. Why would you do that?
Maybe hovering the mouse over doSomething(10, 5, false, false) could display the names.
You can set a default generator in *Settings -&gt; Configure KDevelop -&gt; CMake*, but it doesn't provide MinGW as one of the options yet. Indeed, that should be fixed. Thanks! Tracked here: https://phabricator.kde.org/T4103
Why not use [BOOST_STRONG_TYPEDEF](http://www.boost.org/doc/libs/1_61_0/libs/serialization/doc/strong_typedef.html)? 
To quickly get the size or alignment of some type without having to open up the header file and look at the definition. And to not have to sum up member sizes and follow inheritance chains manually. SushiAndWow pointed out you can get sizeof from IntelliSense in Visual Studio. Intellisense is unfortunately still unacceptably slow for my use cases. Also, I often code in a text editor and build from commandline and then IntelliSense isn't of much help. This trick is IDE-independent and works across different compilers. I tried to make the post a bit fun but probably failed. Most people didn't get it and many down-voted this post, I presume since the example didn't compile. Fail :)
If it's relevant post away! I was actually hoping for this one after your last post and a similar video I watched on this topic. Thanks :)
Very nice. I would like to see that in Visual Studio. Is this controllable on a granular basis, e.g. at function scope? For example, I might want to enable these checks most everywhere, but disable them in crypto code.
To be fair, C++ is standardized by a committee, not by Bjarne himself. So even if Bjarne doesn't like feature X, it does not mean it can't get into the language. It might be harder to get it in, however, since Bjarne does have a lot of influence.
I was looking through some old committee papers when I came across this wish list from 2005. I figured other people might also be interested in seeing how things have developed in the past 11 years, and what's still outstanding.
[removed]
I think having an ide with a button to convert a one line function call to a multi-line function call with a comment labeling each line/parameter would be a start. There are many things actually that are arguably better suited to be in the realm of a sophisticated ide. An extreme example might even be using straight C and having the ide insert destructors while having '#pragma move' at the end of a return statement line. 
... That's exactly the point.
It's also mentioned in the Effective Modern C++ book.
ah yes, sorry, I thought that it was about the template&lt;auto&gt; feature not compile time sizeof.
Some of these are rather crazy and big moving targets. There's 0 chance that a high-quality, cross-platform graphics library can be introduced in the standard. Just the std::regex that got introduced in c++11 is already much too opinionated to be usable in anything but the simplest circumstances. It's fine to just have data structures and low-level algorithms in the STL imo.
just `#define boost std` and you'll be happy edit: god people can't take a joke...
Break it down into pieces and print the outputs, rather than asking us to do your homework
A 2D standard graphics library is already in the works! It's heavily inspired by cairo, from what I understand.
Interesting, is there already a draft or something? Still, I'm not sure why this has to integrated in the STL, what's wrong with just having a cross-platform standalone library?
Yes, it is. See "Issue Suppression" section in the document linked. You can do it with attributes or in separate exclusions file. About VS, you may check if UBsanitizer is supported in Clang for Windows or Clang/C2.
http://open-std.org/JTC1/SC22/WG21/docs/papers/2016/p0267r0.pdf
&gt; a SI/Units library. ( e = m c2, and end to the mars lander crashes.) :(
Latest from what I found http://open-std.org/JTC1/SC22/WG21/docs/papers/2016/p0267r0.pdf It based on Cairo Implementation: https://github.com/cristianadam/io2d
This is indeed one approach but unfortunately creating a struct for every different prototype isn't realistic if we want to have named argument for all the functions. Also designated aggregate initializers miss 2 points for me (this is an opinion and I really like those initializers): * for the syntax : I'm not a fan of the '{}', '.' and '=' in a function call. Here it is logical but I would prefer a simpler syntax. ( far from something like 'create_window([width=800, height=600](){});' proposed by [p2rkw](https://www.reddit.com/r/cpp/comments/58fknu/c_function_argument_labels/d903g5r) ) * for the semantic : I am strongly interested in decoupling the name given to an argument to its nature in the function. Being able to add additional information here can be very nice. I'm also thinking about having some polymorphisms based on argument labels (with the same prototype).
&gt; I would even argue that if some code deadlocks with a non-recursive mutex, but has no issues with a recursive one, then that code is not necessarily broken. Id argue otherwise. The code is probably broken and rmutex is there to work around bigger issue. Admittedly, those situations happen and its nice to not have to roll your own when it happens but its still broken.
&gt;* Network programming We have a networking TS. We're getting there slowly. &gt;* String formatting [fmtlib](http://fmtlib.net/) (aka cppformat) is being proposed for &gt;* Serialization I think this will have to wail until the dust settles a bit from the work on reflection. That might also be holding up the XML/JSON parser. &gt;* Graphics library There was a working group for this, but I don't know what came of it.
You're absolutely right, it has been so long I didn't use this function declarations I just forgot their existence.
Now that C++17 is including file system navigation, it would be nice to have a function that returns the paths to standard directories such as those used for storing preferences, temporary files, etc.
Some high school algebra: c' = c*b + a / (b-1) c' = c*b + (c / c) * a / (b-1) c' = c*(b + a/((b-1)*c)) so c *= b + a/((b-1)*c) not really more readable than the starting one.
The problem with protobuf is that it's fairly expensive to encode/decode. The modern serializers/deserializers are trying to make it so that serialization/deserialization is in-place (except obviously when a big-endian machine does it) so that there's literally no operation to deserialize (even validating the validity of the format is deferred). Compression is delegated to proper compression algorithms instead. All of them however suffer the need to have a code generator due to the lack of reflection in C++ and the generated code typically makes opinionated performance trade-offs. Hopefully binary serialization will eventually make it into C++ &amp; a solution compatible with other languages will be selected.
Nah. Just hover the mouse above the function name and you get its param names. Similarly, you coyld get it in text mode when cursor is on the function or whatever.
Your compiler needs to support c++17. Here you can find the filesystem docs: http://en.cppreference.com/w/cpp/experimental/fs If you google something you are looking for there are many boost version but they work almost the same as the sdl version.
thank you man. this is corect solution
You mean the platform specific environmental variables? This would be a cross platform wrapper for these, basically. I like the idea.
For starters it doesn't even have level 1 unicode support. And it carries over the usual quirks of PCRE-style regex.
&gt;DLL library Not sure what you mean, but standardizing DLL related stuff, mainly making weak symbols a thing (on Windows), would solve so many complicated problems.
executing c = c*b + a / (b-1); and c *= b; c += a / (b-1) and (c *= b) += a / (b-1); will all produce the same final result. You can try it yourself if you don't believe me: #include &lt;iostream&gt; using namespace std; void print(int a , int b, int c) { cout &lt;&lt; a &lt;&lt; " " &lt;&lt; b &lt;&lt; " " &lt;&lt; c &lt;&lt; endl; } void calc1(int a, int b, int c) { c = c * b + a / (b - 1); cout &lt;&lt; "First: "; print(a, b, c); } void calc2(int a, int b, int c) { c *= b; c += a / (b - 1); cout &lt;&lt; "Second: "; print(a, b, c); } void calc3(int a, int b, int c) { (c *= b) += a / (b - 1); cout &lt;&lt; "Third: "; print(a, b, c); } int main() { int a, b, c; cout &lt;&lt; "Set a, b, and c: "; while (cin &gt;&gt; a &gt;&gt; b &gt;&gt; c) { if (b == 1) { cout &lt;&lt; "Can't divide by 0!"; continue; } calc1(a, b, c); calc2(a, b, c); calc3(a, b, c); cout &lt;&lt; "Set a, b, and c: "; } }
do you mean `c != 0`? :), but yeah, they are not completely equivalent
ohh i see you are corect. thanko you for that explanation 
Actually, C++ (I believe EWG specifically) [has accepted](https://botondballo.wordpress.com/2016/07/06/trip-report-c-standards-meeting-in-oulu-june-2016/) a limited form of designated initializers for C++20. Search for designated initializers to get there quickly. Scroll up a little bit for context.
It's `friend T;`, not `friend class T;`.
Presumably, a standard way to load shared libraries at runtime. Similar to `LoadLibrary`, `GetProcAddress`, etc. It would also be nice if C++ got a standard ABI at some point so you could get classes and mangled functions from DLL's reliably. I don't know how plausible this is... but I think it's about time we don't need to create C wrappers for interop.
&gt;Under this schema, named parameters would work exactly like default arguments. So, in order: No, you're not allowed to do that anymore; no; no; and no. Note that I'm not at all sure this is the best way to do it; just answering your questions wrt. the idea I sketched above.
Holy fuuuuuu- this is so much better than what boost offers. :O
Be passionate about what you love, practice, do personal projects, try new things, improve your skills,... and one day, you'll have the opportunity to get a new job :)
There are two cases: * The compiler has seen the actual declaration for the object and can deduce the real type. Devirtualization can happen here as the compiler knows which version of the function is called (GCC has been doing this for at least 10 years, I thikk it's used, for example to optimize the use of cin/cut which are declared globally so the compiler knows the actual type) * You haven't seen the declaration. Say your entire compilation unit is the declaration of an abstract base class A and a foo(A* a). The parameter can be an A or any of its subclasses whose definition you haven't even seen. They might be different classes on every call, and even if it's always the same, that class might be defined in another file (hell, it might not even have been *written* yet). In this case the compiler has no way to know what to inline and has to do a Vtable lookup every call. Final allows a middle ground. If A is final and you receive an A pointer there's no question what class the object is and you can do a static call or even in line it if you know the definition. Note that java does the same optimization for constructors, private and final functions, even if the language's functions are virtual by default. 
Good point, I thought of this when reading the article, as the next step that the article should have IMHO taken, but then got caught up in pointing out the technical error :-). Though, the technical error that's easy to make, strongly helps make a case for a generic key class.
Thanks for letting me know. Can you please let me know about the Q4 2016 post? I'd like to post our jobs on here if possible. I thought at one point we could post jobs on the cpp thread. Thanks for the help.
What is the status on fmtlib? I saw a thread here with the talk of proposing it and I'd be very happy to have it in standard (with one little nitpick fixed regarding handing of negative hex and such), but is there actually a proposal/is it in the works or it was just some wishful discussion?
You could check out [LtU](http://lambda-the-ultimate.org/) if you're interested in current research in programming languages.
Pinging /u/aearphen for an update...
uhm? theres also getenv() in libc. Or just reading it straight from envp. Or environ. None of these are the C++ standard. I'm not sure if your trolling, but the point is having a standardized, compatible and sane way in the STL to do it. Not having to use 1995 software (Qt) or parse it out.
What if you have var named width/height and want to pass it that way? It'd just reassign it. Creates an ambiguity.
I heard that employers look for candidates who make use of object oriented design, so here is a completely unnecessary object oriented implementation of fizzbuzz! 
Calling Qt 1995 software is like calling C++ a 1983 language.
I wouldn't worry too much about the details of OOP: for starters, make sure you know how to use `std::vector` and work from there. Since you have some experience with programming I think that you should start by reading Stroustrup's "A Tour of C++", which is a nice introduction to the language and what is considered the 'modern' style. The other thing that helped me learn the language when I got started (which was about two years ago) was to go watch all of the talks on YouTube. I recommend watching all of Stroustrup's talks (or at least leaving them on in the background). I also really liked Stepanov's "Programming Conversations". Try to keep in mind that C++ is a large language with very advanced features (like `alignas` and template metaprogramming), but most of the time you don't need this stuff. The three classes I use the most are `std::vector`, `std::string`, and `std::unique_ptr`. If you can do that then you should have a nice start.
What kind of stuff would/do you use it for? Just curious. I'm sure they're useful. 
What about int width = 400, height = 600; create_window(width=height, height=width); cout &lt;&lt; height &lt;&lt; ", " &lt;&lt; width; (the example here is sort of UB, but same question for `foo(bar=baz)` where bar and baz are vars)
Cryptography, encoding strings, or really any situation where memory is less important than worrying about overflowing. The current options are all not great.
!remove
OP, A human moderator (u/blelbach) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/58kawo/object_oriented_fizzbuzz/d917azq/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
This is technically undefined behavior (violates C++'s strict aliasing rules): const char* p; uint32_t v = *(const uint32_t*) p; (Note that, in this case, the C-style cast becomes `reinterpret_cast`) const char* p; uint32_t v = *reinterpret_cast&lt;const uint32_t*&gt;(p); On the other hand, this well-defined: const char* p; uint32_t v; std::copy(p, p + sizeof(uint32), reinterpret_cast&lt;char*&gt;(&amp;v)); // depending on endianness of machine / encoding, may need: // std::reverse(p, p + sizeof(T), reinterpret_cast&lt;char*&gt;(&amp;v)); I like to write a function like this: template &lt;typename T&gt; const char* from_bytes(const char* p, T&amp; v) { std::copy(p, p + sizeof(T), reinterpret_cast&lt;char*&gt;(&amp;v)); return p + sizeof(T); } which allows: const char* p; uint32_t v; p = copy_bytes(p, v);
This seems to be the same approach as was described in N4172, which is already [rejected](http://wg21.link/ewg150).
&gt; There's 0 chance that a high-quality, cross-platform graphics library can be introduced in the standard. From what I understand this is meant as a simple toy library for teaching, instead of a serious production library. A standard graphics library to solve all problems would never work, as things are evolving far too quickly for the standard to keep up and people can't even agree on what is a good abstraction level (see SceneGraph libraries vs OpenGL vs Vulkan, 2D vs 3D, etc.). On the other side when you just want to draw a few lines in 2D it is really useful to just have a library to do that and it can be done in a portable manner rather easily. It might not be the best or the fasted way, but it will get the job done in a lot of simple cases. The difference easy graphics access can make in learning is huge and it's easily the thing I miss most from old QBASIC days. 
It has multiple uses (hah!); see http://en.cppreference.com/w/cpp/keyword/using
&gt;I searched the internet but i couldn't find the exact definition of the keyword "using" in c++. What is that? Is that something like typedef that change the current name with another name? It is somewhat similar to typedef in that it allows you to use shorter names for the same end result. What "using" does is import another namespace into that file. So instead of std::cout you can just type cout If you had previously typed using namespace std; The reason namespaces exist is to reduce name collisions. Say someone else has written a library that has the function "multiply()" in it, perhaps for vectors. But you've written a function "multiply()" that multiplies two numbers (don't do that, but as an example...) So if you just type "multiply(..., ...)", the compiler won't know which one you mean. So you have to specify it vectorlibrary::multiply(..., ...) When you use a namespace with "using" it allows you to omit the namespace name ("vectorlibrary" in the above example). This is primarily helpful when you don't have any functions that are named the same as the functions in the used namespace.
!removehelp
But as it is now assignments are allowed inside of functions calls and such right? If so that would be a breaking change. Not that it couldn't be done, but still, the committee seems to steer away from exactly this sort of thing. 
I wouldn't even touch a library developed by overworked engineers during crunch times... ;)
&gt;From what I understand this is meant as a simple toy library for teaching, instead of a serious production library. That just makes it worse imo. I really don't see the point in spending C++ committee and STL implementors' time on toy libraries, when this can already be handled by external libraries. And it's really not something that most C++ programs would ever use. If one wants easy graphics, there is [imgui](https://github.com/ocornut/imgui) which is very nice to use.
I have no idea how such a proposal would look like and whether a hobby project like this could be qualified. Do you have any pointers on more information?
...this is horrible and that other template should just use a different naming scheme (like, differentiate between an argument that is specified and one that comes from a template argument). I am convinced this can be made to work without being horrible and naming what is essentially an alias in the mangled name. I still consider this to be an absurd nonsense, and I still want to strangle whoever originally made the decision to do it this way. Do you happen to know who that is?
[Here](http://www.boost.org/doc/libs/1_55_0/libs/parameter/doc/html/) ;) 
Finally all talks are published!
Don't miss the exciting errors detailed in part 2 :) https://studiofreya.com/2016/10/19/errors-connecting-to-libreoffice-with-cpp-errors-part-2/
&gt; If you are using C++ you can (and should) utilize RAII to release locks based on the lexical scope. I agree ... but when you have mountains of legacy code, in my view you have to be a bit cautious about saying "in this part of the code we have a completely different way of accessing and releasing a lock to everywhere else". Now when I have a free week I will sit down and refactor the locking system, it is on the list. But today when I am under some pressure to add in a new feature, I will probably continue to use the old style, to avoid introducing confusion for the other maintainers (most of whom are schooled in the C-style of code writing and find RAII unnatural).
The whole point is to not do it manually - not having to go to the header file and find all members or worse have to follow a deep inheritance chain across lots of headers. Should've been more clear about that, I'm a complete blogging n00b. At least I learned one important thing from this post - be extremely specific about what problem is being solved :)
Seems like it is down
Yep, apparently "/r/cpp hug of death" :P edit: after 50 minutes, it works again..
The GitHub page: https://github.com/gentryx/libflatarray
 int width = 42, height = 22; // 1000 lines ... create_window( width = 800, height = 600 ); This compiles in the current standard. It does not do what you expect to do. Your proposed syntax would either break existing code, or if you add some kind of backward-compatibility rule, it would be ambiguous and hard to read. 
I feel like this is the least confident article I've read all week. No numbers, side cases considered the norm (well designed code should not have 100k locks), direct mentions of critical issues with the suggested SRWL. Additionally most cross platform code isn't going to use either CS or SRWL manually but instead wrap them in a 'lock' class which needs to have consistent behavior across Windows and everything else - which really doesn't work when you mix the 'mutex' and 'ReadWrite lock' paradigms especially when most of those mutexes are reentrant. To put it as un-confidently as the article: You ***may*** be right but don't just go and change all of your CriticalSections to SRWL if you are writing cross platform. Write a wrapper for 'Mutex' and a second for 'ReadWrite Lock'. 
At least in my opinion, this should probably be done as a `std::map&lt;std::string, std::string&gt;` that get's automagically initialized from `envp` (or equivalent) at startup. From there, if we need something in the way of string parsing that's not already trivial, we should probably add it as a general string parsing capability, not something specific to environment variables.
You need to link the filesystem library manually with `-lstdc++fs` with g++, presumably because they're not guaranteeing ABI stability yet -- see [this StackOverflow answer](http://stackoverflow.com/a/33159746/2797826) (and related links) from libstdc++ maintainer Jonathan Wakely.
Well I've gotten messed up with namespace collisions when working with the stl, boost, Qt, and CGAL.
It wouldn't be the first case of breaking changes in standard, and I would be OK with breaking code using dumb tricks like this. (Especially since it would be trivial to find using good tooling)
Thanks :P
The reddit subject says (Windows) and the first sentence of the post states that the post is about Win32 application development. I tried to make it obvious that the post is *not* about cross platform developement, but I guess I failed. I'm not suggesting anyone should use the APIs directly all over their code. What gave you that idea? Even if you only target Win32 it's good hygiene to have a wrapper to get a level of indirection and not leak Windows includes. Our wrapper uses a void* to hide the implementation for instance. You almost certainly want reusable RAII lock scopes, so you will need a header anyway. Re: confidence, I'm not trying to sell SRW locks, just to explain pros and cons. Re: numbers. Performance numbers truly would be truly worthless in this article. The main point about performance is that your data layout matters a lot and 40 bytes instead of 8 byts can often ruin it. The speedup will come from your specific data layout, your level of parallelism, your contention, the size of your data sets, etc. I kind of agree that well designed systems shouldn't need 100k locks. We need it to keep backwards compatibility for certain APIs and only in reach those numbers in certain edges. Well designed highly parallel systems will routinely need thousands of locks though. I've seen many cases where sharding up a contended hash table from 64 to 256 shards give measurable speedups on 16 - 32 HW threads. If you need a bunch of such shards you reach the 1000s quickly. 
I did do that, but I got errors for unresolved external symbols related to my program's usage of the filesystem library. At this point in time Linux will not be a target program for my (still unreleased) application. Well, until they implement that.
Why?
He doesn't know. Bjarne didn't tell his reasons for opposing the paper to the author of said paper apparently.
Sure, I agree. We wouldn't have half the standard library if "Qt already does it" were a good argument. But the Qt from the 90's is nothing like modern Qt. The only thing that's from '95 is the name. It is, in all practicality, modern software.
AFAIK Boost.SIMD has no Struct-of-Arrays containers. The expression templates in LibFlatArray have some similarities to Boost.SIMD, although [UMESIMD](https://bitbucket.org/edanor/umesimd) and [Vc](https://github.com/VcDevel/Vc) are much more similar to LibFlatArray's vectorization code. IIRC LibFlatArray is right now the only one to support all ISAs listed in the release, the others are missing at least one. I hope that an upcoming C++ standard will adopt the technical proposal [C++ Needs Language Support For Vectorization ISO/IEC JTC1 SC22 WG21 N3774](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3774.pdf) (background: the proposal is co-authored by Sandro Wenzel, who's IIRC also the main developer of UMESIMD). Once that happens I can get rid of the vectorization code in LibFlatArray and focus on the SoA part. :-)
The committee is practically begging for people to propose libraries like this.
nice, thanks for the precisions
Maybe it died to DDoS like half of the internet today
The demo implementation in “[Sample in place](http://open-std.org/Jtc1/sc22/wg21/docs/papers/2016/p0469r0.html)” is probably wrong or at least bad: * `stable_partition` may allocate memory, thereby it is not inplace * if it doesn't it will run in O(n * log n) which means it is slower than it should be * I am extremely skeptical about a predicate-lambda that changes state, this might in fact be illegal A better implementation would be this: template &lt;class ForwardIterator, class Distance, class UniformRandomBitGenerator&gt; ForwardIterator inplace_sample(ForwardIterator first, ForwardIterator last, Distance n, UniformRandomBitGenerator&amp;&amp; g); { const auto total = std::distance(first, last); assert(n &lt;= total); using dist_t = uniform_int_distribution&lt;Distance&gt;; using param_t = typename dist_t::param_type; dist_t d{}; for (auto i = Distance{}; i &lt; n; ++i) { // edit: fix swap with self: const auto selected = first + d(g, param_t{i, total}); if (i != selected) { iter_swap(first + i, first + selected); } } return first + n; } As much as I like the use of the algorithm-library, you shouldn't use it just because you can. If the code with loops is much simpler (like here) and additionally states the algorithm in clearer terms, use them. And as this already implies, I strongly believe that the algorithm should not be stable.
The proposal is one year old.
“[Bravely Default](http://open-std.org/Jtc1/sc22/wg21/docs/papers/2016/p0481r0.pdf)” looks really nice. It argues that equality-comparission should be provided by default if the copy-ctor is also just a default which seems quite reasonable. The only nitpick I have is with the suggestions about generating `&gt;=` and `&lt;=` only if there is a `&lt;` and a `==`. I think it should be enough to provide `&lt;` even though I see that `!(a &lt; b) and !(b &lt; a)` don't necessarily imply `a == b` for strict weak orders (think about complex numbers ordered by the norm).
Hi, I'm not really sure what really happened, but a reboot of the server seemed to bring it back online. If it was DDoSed to hell and back, it didn't show up in the logs... However, the load average was around 25.0 for now / 5-min avg / 15-min avg.
No. `try_lock` has a `Requires: the current thread does not hold the mutex`.
&gt; `::com::sun::star::beans::PropertyValue` Ah, legacy...
I use this as a simple cross-platform (Mac, Linux, Windows) HTTP client and it works great, especially now that recent versions added proxy support on macOS and Linux. I love that it uses CMake for *nix builds.
That doesn't change it to say it must work, it does the opposite. The issue is that before it was defining what the behavior was. Now if the two arguments refer to the same object it is literally undefined.
Self assignment is legal -- self move assignment isn't.
*`typename iterator_traits&lt;ForwardIterator&gt;::difference_type` Anyway, I think it's too late for that. Just look at the rest of `&lt;algorithm&gt;`.
We can't change the algorithms that are already there. But we can change any new ones. :)
Nope, it's not undefined; it's unspecified per "`rv`'s state is unspecified". And the note edit makes it clear that "`rv` must still meet the requirements of the library component that is using it, whether or not `t` and `rv` refer to the same object". So it can do anything as long as it isn't crazy. So if a library function template requires MoveAssignable, what you pass to it can't crash on self-move-assignment. Clearing out the object is fair game, but `swap` is fine with that. OTOH, you still can't self-move-assign library types because few of them are required to meet MoveAssignable.
Regex. So fucking unhelpful for 90% of the cases.
If you really have this recursive problem, yes. But you should try very very hard to avoid needing the recursive mutex. http://zaval.org/resources/library/butenhof1.html
Forget all this and use PIMPL. You will solve the access problem proposed here and a few other problems with one technique.
Forward iterator has no +, so this won't work.
I found out about this in January this year, tried to compile it on Windows 7 x64 by generating a MinGW Makefile project with CMake but I couldn't get it to link, compiling went fine. Can't remember why the linking failed. Same thing with a generated visual studio project. Maybe the compile / link process is more generalized now, who knows, but I just remember it being a pain as a windows user because I was missing libraries that could quickly be installed on *Nix.
You got an incredibly strong lineup there! Congratulations! That's really amazing. It's easily on par with CppCon actually. Very nice.
And in Abrahams and Gurtovoy's C++ Template Metaprogramming book.
I have actually used this to write a customer app component to interact with the latest Dynamics CRM release. They chose C++ over having to implement it in multiple languages. And one of the old tech foxes simply commented "this doesn't look like C++" when I showed him some code. The language evolution is real.
The Java Way (TM)... in C++.
Is Bjarne using Windows XP o_O? Or is this just an old picture? Anyhow, looks like quite a few very interesting topics.
I tried to use it half year ago. The API is different from old school networking libraries but in the end it looks concise and pretty readable. Asynchronous calls return futures and you can then chain them using .then. Problems came when I tried to use it cross-platform. It turned out windows implementation is calling WinHTTP with some default parameters which means automatic redirects. Android version was built on boost asio so no automatic redirects. I filed a bug because I thought it is a major breakage of any cross-platform scenario when the same code fires different number of http requests depending on target platform. I suggested an option to configure it but they told me it works as expected and suggested some workaround instead. So that didn't really convince me. Either you want to be cross-platform or not but then you should not advertise it. Another issue was the CMakeLists. It looks like different libraries (boost, WinHTTP, PPL, ...) with various configuration macros are coming into play and it's getting little messy. Static linking was not possible as mentioned. I tried to make it work from QtCreator/Android and it gave me a headache back then. But maybe the situation already improved. So in the end I felt like the potential is there but it looked like this library is not robust enough for my usage and so I used something else.
Can you give an example of a library type that is not required to be MoveAssignable?
Random example: `std::function`. I looked at every occurrence of Copy/MoveAssignable in [function.objects]; none of them apply to `std::function`. The standard uses MoveAssignable primarily as a requirement on user-provided types, not as a requirement on library types.
Thanks. 20.14.12.2.1 [func.wrap.func.con] defines a move assignment operator for `std::function` with the semantics described in 17.6.3.2 [swappable.requirements], Table 23 [moveassignable]. This makes `std::function` MoveAssignable. A type does not need to document that it meets the MoveAssignable requirements to be MoveAssignable. It merely has to document (and implement) that it can be move assigned. And that move assignment operation must meet the requirements in Table 23 (i.e. have the expected semantics). If this were not so, then one could not insert a `string` into a `vector&lt;string&gt;`, as `vector&lt;T&gt;::insert` requires `T` to be MoveAssignable, and yet the word "MoveAssignable" appears nowhere in chapter 21. There's a handy type trait that you can use to test if a type is MoveAssignable at compile-time: static_assert(std::is_move_assignable&lt;std::function&lt;void()&gt;&gt;::value, "");
There isn't a straightforward answer here. I usually go with `find_package` that looks in a local "dependency" directory first before looking globally. It's not much modular than what chromium does in your link. If you *really* want to have the python-pip, node-npm style synergy, there's [build2](https://build2.org/) and [cppget](https://cppget.org/). Some have also mentioned [hunter](https://github.com/ruslo/hunter) (CMake-based) and [maiken](https://github.com/Dekken/maiken). Please remember that none of these have widespread adoption (not even all projects use CMake today). I'm afraid that this will remain a problem for a while. However, [Bjarne Stroustrup did acknowledge this in a recent talk](https://youtu.be/_wzc7a3McOs?t=1h46s). Hopefully we'll have a standard package manager in C++20. I'd say it'll be at least another 6-7 years before there's a right answer to your question. I've shown you *some* of the options you have today, choose wisely ;). EDIT: I don't think `find_package` is useless at all. You can write your own CMake modules that define what happen when you use `find_package`. You could, in theory, download on-the-go. EDIT 2: Forgot about [conan](https://www.conan.io/).
I'm just trying to let you know what the intent of these words are. The standard has never been perfect, and never will be. It is a living document that we are always trying to improve. If you would like to help improve it, the committee would be grateful. Here are specific instructions on how to do that: http://cplusplus.github.io/LWG/lwg-active.html#submit_issue
[C++ Archive Network](https://cppan.org/) * C/C++: cppan, cppan.yml But Qt is not there at the moment. I'm planning to add it by the end of the year.
CMake's [ExternalProject](https://cmake.org/cmake/help/v3.7/module/ExternalProject.html) is what you want to pull packages from the internet. For example: ExternalProject_Add( gsl URL https://github.com/Microsoft/GSL/archive/d23f4d931c98c074ebe90bebf609c397589bf7b9.zip URL_HASH MD5=033f3f8b3306f13e848ce25743e7a4d3 CONFIGURE_COMMAND "" BUILD_COMMAND "" INSTALL_COMMAND "" ) Though, dependency managers such as npm are still superior because npm won't just download the library you ask for, it'll also download the dependencies of that library, and the dependencies of those dependencies. Whereas CMake's ExternalProject will download only what you ask for. It's still up to you to find out what the dependencies are and add those individually as additional ExternalProjects. The *technology* for a full featured C++ dependency manager is available, but it's not good enough to just have the technology, we need widespread community adoption. Imagine that I publish a JS library to npm, but my library depends on another library that is *not* in npm. That situation means you can't just npm install my library, you would need to manually fetch the other dependencies that npm doesn't have. That's what we're faced with in C++. Lots of people have made good dependency managers, but if the community doesn't publish their libraries to it... then it just can't work the way a dependency manager is meant to work.
A lot of code in a lot of projects has been written by people who don't understand these concepts though. A tool to find hotspots in existing code could be useful for that.
&gt; many appear to literally just commit the source code of the libraries that they're using into their VCS. This is usually the best solution. Or something very similar, like `git submodule` links to the source code on github. There are *lots* of reasons this is the best answer. Here are my top reasons: 1) cross-platform builds are easier, since you don't have to deal with variances in packaging between platforms (`.deb` vs. `.exe`). Basically you're combining all the different libraries, plus your own application code, into one giant project. This often means you can have similar build automation on all platforms, since literally every build system has a "compile source code" feature (but not necessarily a "find the library" feature). 2) repeatable builds are easier, since you can factor all dependencies into the project and not rely on the system versions installed. Obviously you wind up with some out-of-project links to the compiler's standard library, or to the OpenGL indirection libraries... but these are usually minimal and have stable, well-defined interfaces. 3) you can directly control build options, such as debug level, architectures/instruction sets supported, optimization level, position independence, etc. On Windows mismatching these options results in literally incompatible DLLs. And on Linux, your debug options can bloat a 1MiB library to 50+MiB. With pre-built packages, you either have to accept whatever the package maintainer liked for his build options, or the package maintainer has to offer lots of different builds of the package. 4) if you're clever, and put in the time to craft your own build for child libraries, you can easily produce a single build artifact for the whole project from the individual translation units. This enables the compiler to perform pretty amazing whole-program optimizations.
Yeah...hardly a good idea. But it's not useless like you make it out to be in your post. `find_package` is what it should be. The problem is cmake doesn't help you much to download packages.
Looks interesting, but I need ffmpeg and Qt.
Unfortunately C++ has a lot of catching up to do. First it needs modules (Java have packages and Python have modules, I think Node have modules too). Then C++ needs a better build description, with more metadata (Java has maven/POM.xml and derivatives, Python has pip/distutils and Node has npm) and no CMAKE isn't a solution yet. *Then* we can start thinking about dependencies.
&gt; Using apt and dnf on Linux, brew on macOS, and MSYS2 on Windows You can use [vcpkg](https://github.com/Microsoft/vcpkg) on Windows instead, it has user-wide integration &gt; CMake's find_package, which doesn't pull packages from the internet but instead just looks for them at a specific place on your computer. So you still need to download the correct version of the code yourself and build it yourself. So pretty much useless. You can use CMake as build system and [Conan.io](https://www.conan.io/) or [Hunter](https://github.com/ruslo/hunter) for downloading external dependencies. We use Conan for our projects
You can use `find_package` in CMake to try and find the lib if it's already compiled/pre-installed on the system and if it fails, check out git submodule/download zip with sources and compile them manually. Not the best, but works reliably for a moderate number of dependencies.
These are tools for distributing application bundles for deployment; they aren't for development.
&gt; It turned out windows implementation is calling WinHTTP with some default parameters which means automatic redirects. A I wonder if a wrapper of [libcur](https://curl.haxx.se/libcurl/) on non-Windows platforms would have been a better option.
Not quite. You now have to deal with CMake, plus the build system of the 23 other damn projects. And if you're trying to enforce something like `CMAKE_CXX_FLAGS` across the whole project, it's much cleaner (although more time consuming) to just fold all the code in and write your own CMake code to build them. Believe me... our codebase at work has been through a number of different build modularization schemes. What we've finally settled on is a single project repository, with all modules in their own subdirectories with their own CMakeLists. Code that we're definitely never going to change and that's already built with CMake (e.g. GLFW) gets pulled into the tree with `git submodule`. Code that we're definitely going to modify incompatibly with the upstream version, or which needs to have new build scripts written (lookin' at you `libtiff`), gets copied into the repo. All of it is then tied together with `add_subdirectory`, cascading our complete set of configurations through the whole codebase. It requires work to implement in the first place, but it's beautiful when it runs. A new dev goes from blank SSD to fully repeatable build in about 45 minutes, and most of that is just spent waiting for various things to download. There's only like 5 steps in the whole bootstrap and build process.
`apt-get build-dep &lt;my-package&gt;` And if it needs some non-C++-specific package, it will be installed too.
I like this solution because it requires the least amount of work. I might have to give this a shot.
Well I'm on windows. As you can see my best method of attempting to track it down is by tracking all memory manually. Tooling on Windows is an abhorrent wasteland as far as I'm aware and it's just sorta what I have to deal with if I don't want to work in a Linux VM or otherwise run a second OS. I'd love to learn that Windows has some great free tools to deal with something like false sharing but as far as I am aware of none exist.
yeah, find_package works much better under linux because for popular and large libraries like boost, you can usually get them from the distro-built-in package manager (apt-get, yum, etc), and they install to a standard location /usr/lib, /usr/include. Windows libraries are usually installed manually and to wherever the fuck the user decides, and it's prone to ABI breakage every time theres a new redist (which means switching vc++ redist means rebuilding all library dependencies). Creating something cross platform is easy IF you can guarantee that there are fixed environments, everything will be in a predictable location and everyone is using the operating systems/compilers that you've tested. The real problem is creating something environment agnostic. That's why this is less of an "industry" problem most of the time and more of an open-source problem - because companies can afford to be dictatorial about build environments as long as everything else has got static linkage (except for the vc++ redist). Under windows, I wrap my cmake script in a python script that looks like this which can tell it where my libraries are. If I was doing this in industry, I'd also sub divide my libraries in /usr/lib under the particular vc++ redist they've been linked against. In this case, I'm only using the msvc14 one, so it doesn't matter that much. from subprocess import call project = "Project-Name" generator = "Visual Studio 14 2015 Win64" source_path = "." library_path = "C:/usr/lib/x86_64" include_path = "C:/usr/include" command = "" command += "cmake -Bbuild/{} -H{} ".format(project, source_path) command += "-DCMAKE_INCLUDE_PATH={} -DCMAKE_LIBRARY_PATH={} ".format(include_path, library_path) command += "-G \"{}\"".format(generator) print command call(command)
Well I understand in some cases automatic redirects are easier but in my case it was absolutely unwanted. I needed to process cookies and these are transferred in http headers which I needed to parse. Cookies are sent during redirect response as well so if automatic redirects take place I will not get a chance to parse cookie headers and all subsequent communication with the server is doomed. That's why I suggested a configuration option. libcur for non-windows platform would not help anything in this regard. And finally WinHTTP supports manual redirects it just needs to be configurable through cpprestsd API
The current resolution of LWG 2468 does not leave room for UB or ambiguity regarding self-move-assignment. It clearly defines the value of `t` when `t` and `rv` do not refer to the same object. It also clearly states that `rv` is unspecified after the move assignment, *whether or not `tv` and `rv` refer to the same object.*
Especially if you'll be open sourcing your project, this approach lets other people substitute their own (updated) versions of the libraries in the future easily. If you want to use Visual Studio / MSVC on windows, you can get the same experience as `apt-get` (where you just install your dependencies once and CMake's `find_package` just works) using [vcpkg](https://github.com/Microsoft/vcpkg/). In another comment, you mentioned you needed Qt and FFMPEG -- we don't have those two libraries today, but we'd be happy to accept PR's for them! [disclaimer: developer on vcpkg; I'd be happy to answer any questions you have!]
Hi everyone! I'm one of the maintainers of Cpprestsdk and I'd be happy to answer any questions you have.
Cross-platform?
I've pulled down both boost and qt using CMake ExternalProject. It's not that bad. It only takes a few minutes, and CMake is smart enough to skip it for subsequent incremental builds.
I did it with a script because the current version of cmake doesn't let you set the generator from inside a cmakelists.txt. I figured i might as well put the other environment specific stuff in the same python script
`apply(f, make_tuple(x, y, z))` is `f(x, y, z)`. What you seem to want is `return make_tuple(map_to_gl(shapes)...);`, not `apply`. Then, make your return type `auto`, and drop `R`.
It is bad practice on desktop linux to use bundled versions of other libraries, the way to go is to let the packagers do it. Else yoir software will never be able to get into debian for instance.
Sometimes there's just no way to avoid different threads to accessing shared data. A typical example is a shared multiple producer/multiple consumer queue.
Same here, it works fine.
Have a look to Conan.io and Vcpkg
Very interesting episode! Like the talk on embedded C++. I think there is a lot more of that going on than gets press, so probably a lot of interest.
[According to this article](http://mechanical-sympathy.blogspot.com/2011/07/false-sharing.html) &gt; The most common cache line size is 64 bytes. False sharing is a term which applies when threads unwittingly impact the performance of each other while modifying independent variables sharing the same cache line. So long as you use attribute align to 64 bytes on all elements that the multiple consumers/producers touch then there will be no false sharing as no elements would be on the same cache line.
I know this isn't a homework question, but it's still a question. Sorry, but it gets the automod hammer!
&gt; I'd be happy to answer any questions you have. Here is my question. I downloaded the [zip](https://github.com/Microsoft/cpprestsdk/archive/master.zip) file. I am using Visual Studio Express 2013 for Windows Desktop Version 12.0.31101.00 Update 4. On Win 7. I cannot open any of the projects in the solution. They all fail. e,g. casablanca120.vcxproj : error : Cannot find an instance of the Microsoft.Internal.VisualStudio.Shell.Interop.IVsSharedMSBuildFilesManager service. I don't care much about samples, xp support, winrt. But at least get the basic lib to compile and link. 
Only if people actually give them meaningful names. You could call an operator szwe and who knows what this means?
The pulling is not the problem, it's the fact that you're pulling it into the build directory for your cmake project instead of to a common location. You don't want to be redownloading and building boost for every small library that depends on either of them.
`std::atomic`, `std::mutex` and other related classes.
You can setup external project to grab from a local cache to avoid multiple downloads. Now the sharing build artifacts between libraries is trickier, but is possible by only using external project if you don't find the project locally. 
Thant's actually what I did previously! https://github.com/jimktrains/uil/blob/master/LadderRung.h#L214 In this version, I was trying to keep the checks completely within the type system, not just being done at compile time. The `static_asserts` give better error messages and occur at the location you'd expect the check to occur, making it a better means of generating the error. I should probably mention that in the post. Thanks!
Would this be helpfull in a game for keeping track of objects in the scene?
Not just that, FireMonkey is a framework that only works in C++ builder because it relies on proprietary C++ extensions.
I am the original author of the blog post linked. Some comments: &gt; Build directory can't be separate from the source directory: I find this argument very odd since in my experience this is completely supported by autotools. Autotools does support out-of-source builds but does not mandate them nor does it make it easy to be able to do both from the same project. Many projects can't be built out-of-source because they started by building in-source and have a ton of things that depend on this (for example, that data files for unit tests are in the same directory as the built executables). &gt; Configure step is single-threaded: In my experience, this is also a complete non-issue ... even on slow machines the configure steps rarely take so long that most would care. Maybe I'm wrong and there are situations where this is a real drawback. I don't know any. Configure scripts are hideously slow when compiling on Windows or embedded devices. As an example running the configure script of glib on an embedded board (roughly the same as a raspi) takes 15 minutes. No, I am not kidding. As for Windows, the GStreamer developers ported their Autotools setup to [Meson](http://mesonbuild.com) and the time it took to compile just the base component went from 10 minutes to about 1 minute. More details can be found [in this video](https://gstconf.ubicast.tv/videos/gstreamer-development-on-windows-ans-faster-builds-everywhere-with-meson/) from this year's GStreamer conference. &gt; Oh, and about "doesn't work on Windows": I haven't done any development on or for Windows in almost 15 years, so maybe some of my points are a bit outdated. I have. Autotools do not work with Visual Studio. They assume certain things about a compiler and its command line arguments. VS does not support any of those. There are horrible converter hacks available but they are not supported and don't really work either. If you need to support VS in any way Autotools are a complete no-go.
It's more of an efficiency matter than that it is for ease of use. If you don't hit any performance bottlenecks yet then you shouldn't use this yet. And even if you are performance bound there are probably better methods to improve speed before going this route.
Cool article, but now I really just want that colorscheme with the drop shadows in my vim somehow.
!remove
**Company:** [Uber Advanced Technologies Center](http://uberatc.com/) **Type:** Full time, Internship **Description:** We build and have [**launched Self-Driving Ubers**](https://newsroom.uber.com/pittsburgh-self-driving-uber/) in Pittsburgh, PA, USA. We need junior and senior software engineers for onboard and offboard stacks; both specialists and generalists in simulation and automation. We need developers with experience building large production-quality C++ software systems. &amp;nbsp;In Simulation specifically, we need **game developers** with AI, physics and level designer UI experience - people who currently build interactive simulated 3D worlds for manipulating intelligent agents. Our software includes the simulation of vehicles and people that behave in a realistic manner. It is software that impacts the real world. **Location:** Pittsburgh, PA, USA **Remote:** No **Visa Sponsorship:** Yes **Technologies:** modern C++, Boost, Python, Linux, OpenGL, computer vision, machine learning **Contact:** Game and simulation developers [apply for simulation directly](https://boards.greenhouse.io/uber/jobs/90923) or email me at sgundry@uberatc.com. Automation specialists and C++ generalists check out [all Uber ATC job openings](https://boards.greenhouse.io/uber). Feel free to email any questions. 
Have you tried `g++ -fno-rtti`
What compiler toolchain do you use? GCC supports `-fno-rtti` but should only be used when not using functionality that uses RTTI (`dynamic_cast`, `typeid`, etc). Not sure what parts of OpenCV you are using so you might or might not be able to use this option. MSVC should also support turning off RTTI, and am assuming clang does as well. However, there are no out-of-the-box solutions in the compilers that do this type of symbol obfuscation for you. I believe clang has something in its backlog to do this but can't find that right now. There are many third-party products that do lots of obfuscation far beyond just symbol obfuscation. Google-ing for c++ obfuscator should get you somewhere. If don't want to pay for a product, then you could always roll your own. There are many ways to do it, usually just defining some new symbol that creates a bunch #defines in a pre-processing stage is the easiest way to get it done. Does require source updates though. The ones you pay for usually don't require this and just obfuscate everything.
Oh, I see what you're saying. I guess I was imagining this would happen during the linking step when linking the static libraries - so that the final API remains untouched. However that seems like a difficult place to insert 3rd party software (maybe a proprietary linker or something). That's why I was saying in the other reply - a change to llvm/ld would be the most straightforward in my mind. Alright, I'll look into how to bring together all the dependencies and obfuscate them together. I was hoping to avoid that b/c it seems messier to me, but I get what you're saying - it might be unavoidable.
That's certainly not what happens right now. The problem is that implementing what you say will break existing code. You may be okay with it, but there are reasons other people aren't. Even without considering backwards compatibility it seems like a bad idea to have special rules for what expressions mean that apply only in certain contexts. C++ is complicated enough. We don't need to add more 'gotchas'.
Did you find out which one were doing the right thing?
Also Visual C++ which adds aquire/release semantics to volatile unless disabled with /volatile:iso .
-fvisibility=hidden should hide the RTTI emitted by non-default visibility types. Unless they've changed it since I added that feature to GCC 4.0.
Even is, as in this example, the compiler can prove there is no possible way another thread can observe the atomic? 
Why do this article has so many negative votes? Is this about video format of tutorial?
You didn't use volatile in your code, so I don't see what the assembly is supposed to prove. If you use volatile, you get this: https://godbolt.org/g/pyPl0E, so there is no infinite loop and volatile is respected by GCC. Your point about const volatile is not relevant to this case. const volatile is useful because the memory can be changed by someone else, or because reading from the memory can cause the hardware to perform an action. But a volatile local variable is not useful if you don't give its address to anyone else, because the compiler can place the variable anywhere and nobody else will know where, so it won't be modified. Even if it technically violates the standard to optimize it, it can't really cause a problem.
I think that this has to do with the as if rules. If one puts the struct in the heap with a unique_ptr or just new/delete it no longer optimises it away 
&gt; You didn't use volatile in your code, so I don't see what the assembly is supposed to prove. i clearly showed that the variable won't get optimized away because you pass its address to an extern function (but the optimization does a different approach). it's not because of volatile. &gt; Your point about const volatile is not relevant to this case. it is, because volatile and const are qualifies, and qualifier rules are the same across them. that is, if you put `const` in a data member, you'd not expect to be able to modify it. why is `volatile` not being respected by gcc? if you put `volatile` in a data member, you'd expect it to not get optmized away. &gt; But a volatile local variable is not useful it doesn't matter, `volatile`'s role is clear: do not optimize away. i'm not saying that optimization is bad, or that gcc is generating bad code. i'm rather saying (and this is my point) that the standard says it should not be optimized, and i'd expect it not to be. &gt; the compiler can place the variable anywhere and nobody else will know where it is still a possible side effect. 
You'd be better off reading the side bar and posting in the appropriate place :) &gt; For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow.
Dependency management is what your system package manager does. Your project should just use ```find_package```.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/594un6/i_am_curious_about_this_for_loop/d95ojdb/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
This overhead is negligible since you need only one to handle one buffer (= thousands or millions of pixels). Anything that process the pixel buffer will always take orders of magnitude more time than a refcount. 
&gt; What? Where did you get that impression? I've never known another dev who thought that. Take a look at the book "Effective Modern C++" Item #40. The author also starts with this claim because this is a common misconception. As people already mentioned, Java is certainly one of the reasons people believe that. 
Just because you suck at it doesn't mean it's not useful.
Of course it is useful. Only 10% useful though.
&gt; &gt; Lots of developers believe that it makes the declared variable an atomic variable, but that’s wrong. &gt; What? Where did you get that impression? I've never known another dev who thought that. You hang around with a better class of developer than most of us. :-D Lots of people have that mistaken idea. I'd say that that keyword is poorly understood by people who aren't C++ specialists.
But it leads one to assume the following would work, no? create_window(height=600, width=800) ; 
My point was that the device cannot change the variable if it doesn't know where it is. And it can't know where it is if you didn't pass its address to anything.
As I said to others, the hardware can't change the variable if it isn't provided the variable address somehow.
Looks like [PR47409](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=47409).
&gt; Not really an option. It severely restricts what libraries you can use Does it? We never use RTTI because it has a big impact on both the binary size and the performances. Of course, we don't use exception as well. But that doesn't prevent us from linking to other 3rd party libraries I think...
Not for me, or anyone that knows how the assignment operator works. It's being used for call-site's self documentation and doesn't change rules of argument order in anything. Your example is deceiving, just like an old code comment that doesn't apply anymore because the code has changed, or any miriad forms of misuse of language features and practices, done on purpose or by ignorance.
To be fair, if you're using it to access a hardware register you're going to either have a pointer to a volatile int or a volatile structure mapped to the region. Both of the seem to work as expected. Making a single field volatile shouldn't be as common
I've seen similar behavior in MSVC++ *if* the variable is declared locally (translation unit or scope) and no reference is taken. I wonder if this falls under what-if behavior, i.e. the volatile assignment is observable behavior in the sense of the standard but actually non-observable since it's not reachable from any place the compiler has no control over. (to be clear: This might be the reason behind, I'm not sure if I wanted to make that argument, but I wouldn't necessarily disagree.)
With the proxy iterators for range extensions you could essentially redo Structure of Arrays almost trivially with zip. Which seems pretty cool to me. 
The device memory mapped IO is defined by the hardware, the code sets a pointer to something like 0x0330 and the code knows somehow to set the pointer to that address. 
Ah, I think you were using function templates then. They only worked on one compiler IIRC, can't recall which. class/struct templates has always worked on all three as far as I can remember.
nope, definitely the same struct trick :-) anyway nice trick!
Yeah I noticed belatedly that the temp directory is indeed exposed in std::filesystem so I stand corrected on that.
This should work; I'll try to repro the issue on my side. Could you (in the meantime) try using VS 2015 community/express as well?
Yup. That's the kind of language I might use when talking about C++ assuming I was talking about it at a dive bar with close friends and I was 8 shots in to the night, and even then I'd feel like an idiot the next day. This is not the kind of personality I want representing my industry (... more than it already does), thank you very much.
Nah, volatile is meant to be say "Hey, this place is weird and all stores and loads have to be respected, because it is a window outside of the virtual machine the binary represents." Optimizing it out is verboten.
/u/HowardHinnant/ 31:09, you mention that all times exist in UTC. I don't think that is true due to leap seconds. Am I misunderstanding something? TAI is typically the time used that doesn't skip any times. EDIT: maybe I should watch the entire presentation before asking questions :) Leap seconds (so far) don't follow the same pattern as daylight-savings time. The leap seconds we've had so far add a sixty-first second ( :60 ), that won't cause a skip or repeat. I guess if we ever have a negative leap second then there may be some non-existent times. Or maybe if you consider the lack of :60 on most minutes a non-existent time.
Yes. And you have to declare it volatile in this case, or the compiler doesn't have to assume anyone else will access it. You also have to provide the address to someone, or use a fixed address, of course.
Anyway, something is wrong either with VS "15", or NuGet package. For a upgraded project (from Visual Studio 2015 Update 3), which used NuGet package cpprestsdk.v140.windesktop.msvcstl.dyn.rt-dyn version 2.8.0, the following line no longer compiles: #include &lt;cpprest/http_client.h&gt; It results with a following error: fatal error C1083: Cannot open include file: 'cpprest/http_client.h': No such file or directory So, if you going to release a NuGet package for version 2.9.0, please check that it is compatible with VS "15" 
At that point in the talk I'm discussing adding a duration to `sys_time` (time based on `system_clock`). It turns out that `system_clock` measures Unix Time (https://en.wikipedia.org/wiki/Unix_time) which neglects the existence of leap seconds. Starting at time point 40:00 in the talk, I start discussing how you can use this library to take leap seconds into account, if that is important for your application.
I was able to reproduce your issue, thanks for bringing this up. Unfortunately, VS Express 2013 does not support shared items projects in the IDE. It can still build them just fine from the command line. The two workarounds are either a) install [VS 2015 Community](https://www.visualstudio.com/vs/community/) and build the v120 solution or b) use the [command line build instructions](https://github.com/Microsoft/cpprestsdk/wiki/How-to-build-for-Windows). I've added a note to the wiki page containing this information as well.
Following Jason Turners guideline "less assembly is better", I'm not so sure the current gcc std::variant implementation is staying true to our new ZOA buzzword. Edit: Just noticed that I forgot the return statement in main()
Luckily you don't need to return from main. It's special.
A `const` here and a ~~const~~ reference there got a ~10% reduction. https://godbolt.org/g/5psxYO Also boost variant seems to produce about the same amount of assembly, so maybe it's genuinely hard to implement. https://godbolt.org/g/nrTF3F EDIT: I pulled just `string` out of the variant and the code size dropped considerably. So I'm thinking string, more so than variant, is the biggest culprit. https://godbolt.org/g/MUN99w
I recently dealt with code that messed with hardware registers via ´volatile struct foo *regs´. Doing a write to a member element wrote *the entire structure* not just that one element. Had to switch it to have each element be volatile. 
It's observable, with, say, a debugger.
I think the standard requires std::visit to do table lookup when there is only one variant (or at least that's the intent) by [requiring the invocation to be implemented in constant time independent of the number of alternatives](http://eel.is/c++draft/variant.visit#3).
Boy those number puzzles at the end were tough. I was feeling so optimistic after the first two questions!
Because erased_ctor is only used in the copy ctor and the move ctor of variant. The initialization of std::vector needs to call the copy ctor of variant, while the aggregate initialization of std::array does not. If you attempt to copy the array, all the erased_ctor's will come back.
Good point. Once all the extra symbols are stripped out, it is indeed nearly identical. In fact, the std::variant implementation, while slightly longer, looks like it takes advantage of the fact that the index fits inside a byte. Perhaps because of this, it also uses an aligned store for the double, so it's probably marginally faster.
&gt; A const here and a const there THANK YOU. That was making my OCD act up.
Ok, what exactly does it check, and how, and what does it do when a check fails, does it check at runtime or compile time?
&gt;Seems like exposing code-internals is a no-no in most commercial software Who told you this? E.g. virtually **everything** is completely and utterly visible in Windows, a major COTS product. Same for many others. I even know one major product of one major vendor who ship debug symbols (don't agree with that, but don't care much either). You won't hide the intention of your code by slightly obscuring RTTI, not from someone who knows what they are doing. My guess is that you are a beginner and some coughidiotcough in management filled your head with nonsense. 
Could use much better readme, ie the benchmarks could be already ran and graphed. Also is there a reason why its separate sanitizer instead of being a part of UBSan?
Not really no. Generally that only holds if you are replacing loops with more asembly (or unrolling), but as a rule of thumb, less assembly is executed faster, just because there is less work to do.* \* The usual caveats about different instructions taking different amount of cycles and having different delays obviously apply. Uncached mem load is obviously one of the worst things from perfomance PoV and yet it is a single instruction.
&gt; Now it seems that the committee made a wrong decision requiring `std::visit` to use table lookup.... That's entirely QoI dependent.
What parts are you not comfortable with? If it's the systems side of it, have a look through this book. Windows System Programming, Paperback by Johnson M. Hart Link: http://a.co/1vnxDDc
Your Obsessive `Const` Disorder?
Likewise, I tried implementing `visit` using a switch statement (with the help of Boost.Preprocessor) and again gcc manages to no-op it: https://godbolt.org/g/Jsy0qw Really, this is why we need variadic expansion of switch cases.
Stripping destructors and changing table of lambdas to table of plain function pointers makes at least clang to optimize even table-based variant: https://godbolt.org/g/QydZwh
Exceptions vs iostreams
Horribly pedantic there :)
&gt; I've read through the book 'Programming Windows 95 - Charles Petzoid" in 2016. poor soul.
How to get a paper published on C++: 1. Come up with some nonsense argument about how one specific way of doing something is somehow worse than another specific way of doing something. 1. Find empirical evidence in favor of your nonsense in a contrived test with less than 100 people. 1. Conflate your findings with a more general version of what you meant to test for in the first place. 1. ????? 1. Academia
you forgot the part where you accidentally delete some of your meaningful test results. now that i think of it, maybe the testers wrote that the test was total bullshit... so the 'mistake' happened
Oh wow that is golden
I've a copy of that and agree with the recommendation. Dan - you're not, by any chance, working with a company doing map-based software based in Swindon, UK by any chance. If so, you have my sympathy.
Protobuffers vs. MSPaint.exe
Expression Templates vs Curl vs Lambda vs fork *sorry for the spam :)
Variadics vs ODR
Was an article about another nonsense paper really necessary?
I think the conference is a medium-tier conference (i.e. it's not crap) so people may read it as a genuine peer-reviewed publication. (Correct me if I'm wrong). Therefore it's very important that people in the community point out if it's nonsense, and present the counter-arguments. Otherwise people will believe what's in there. Thank you to the OP for taking this paper apart.
It's the reference that makes the difference, not the const.
ELI5? Is there an issue here? Too much code generated?
a virtual call is also constant time. It's generally bigger and slower than a switch, but still constant time.
"Even though I walk through the darkest valley, I will fear no evil, for you are with me; your rod and your staff, they comfort me." - Psalm 23:4
2.a: make your contrived expected good results look like Java, not C++.
It is Java iterator interface, so...
BURN!!!
Something vs something else!
&gt;However, sometimes managers who do not use C++ regularly stumble upon such articles, and become irrationaly fearful of new language features Managers who dont use C++ regularly don't read such articles. They MAY read ~~reddit~~ HN but the comments already disproved the article. Edit: I don't know how to format a strikeout in my reddit app... Edit2: thanks u/louiswins 
How about exceptions thrown by iostreams?
[A Tour of C++](https://www.amazon.com/Tour-C-Depth/dp/0321958314)!
I don't think this could catch all cases because the example I'm talking about here could occur in separate compilation units and the problem wouldn't be visible until linking happened.
I've put all my dependencies in-tree and build them on demand using shell scripts. I even have to build build dependencies, so I have pkg-config in-tree. It's horrible.
holy shit. not sure what platforms you're targeting, but you can get pkg-config on Windows via MSYS2 and you can get it on macOS via Homebrew (if it's not installed out of the box, I don't remember). and of course it's easy to install on any Linux distro via the official package manager. 
 auto visit_impl = [this]&lt;std::size_t N&gt;( auto f, std::integral_constant&lt;std::size_t, N&gt;, std::size_t v, Visitor&amp; visitor ) -&gt; R { }; Can also be done using standard polymorphic lambdas. auto visit_impl = [this]( auto f, auto integral_c, size_t v, Visitor&amp; visitor ) -&gt; R { constexpr size_t N = integral_c; }; 
I very much agree with the claims/conclusions in this post. However, there is a point made in the paper that I don't think we want to dismiss lightly: that there a gap in the published research about programming. Specifically, very little work has been done on PL design from a human-factors POV. Programming productivity, accuracy, etc., as it relates to PL design, is certainly a major concern. It certainly seems plausible that the human-factors approach may give us useful information on how &amp; why programmers do what they do, and how we can help them be better at it. So, while the critique in the post is both needed and well deserved, let us also turn our attention to more constructive issues: * Is it *possible* to design a human-factors experiment on PL design that would give useful information? * If so, what PL properties would be good to examine? * Design a human-factors experiment that would give useful information on PL design.
I'm not sure what you mean... Can I use C++14? Boost? Range-v3?
Yes and that's perfectly fine. I think you missed the point of my comment.
Or just: constexpr size_t N = integral_c;
I still find it easiest to pull up the built-in terminal and just fire off make/ninja/scons. Same number of key strokes, far less buggy. Colorized build system output doesn't work in the task 'terminal' (or whatever you call that view) for example. &gt; In order to build your C++ code you need to make sure you have C/C++ build tools (compilers, linkers and build systems) installed on your box. I think this is the equivalent of 'have you plugged in your router' applied to build systems... I wonder which manager made Ankit put this in. :)
I could see the stack protection one being a real use case. Does the standard say anything about local variable arrangement on the stack? I would think they would leave it up to the compiler...
&gt; What's the best/quickest foundation basically? Assuming you know the basics of the language, it would be best to sit down and have a chat with the team and let them explain how they use C++ to you. Even an hour or two should help you get a fair overview of how the langauge used in your company, which aspects/idioms/constructs are commonly used and which ones rarely. If you could skim thru the codebase before this meeting, you could even ask specific questions on stuff you've encountered while reading parts of the code. In my (fairly limited) experience, C++ is vast and used in different places and it would be prudent to let some one show you the ropes, if this is possible at all. &gt; What book or books (either on the stack overflow list, or elsewhere), are the best to read to learn C++ core concepts in a short period of time? I transitioned from C to C++ with [Accelerated C++](https://www.amazon.com/Accelerated-C-Practical-Programming-Example/dp/020170353X) and [Effective Modern C++](https://www.amazon.com/gp/product/1491903996). Both are on the SO list, IIRC and are really great books. &gt; What would you suggest for a reference guide as well? Apart from Effective Modern C++, I find the [Core Guidelines](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md) and [cppreference.com](http://en.cppreference.com/w/) very useful. If you'd like to use the latter site offline, take a look at [cppman](https://github.com/aitjcize/cppman).
This looks like a subject of research all on its own. Figuring out how to even control for human factors in PL design seems a feat by itself. I recall seeing a lot of discussion about how no one has ever really done it, multiple times in the last decade and a half.
For some video tutorial ["How Do I?" Videos for Native Coding](http://rutracker.org/forum/viewtopic.php?t=2063862) is quite entertaining (I used a tracker link because it seems videos are no longer available on MS site).
I'm sorry but you completely lost me now. I have no idea what you're arguing for/against.
Listen, if you have a `constexpr` array of function pointers (see: https://www.youtube.com/watch?v=Os5YLB5D2BU, shameless plug), and that includes lambdas since C++17, you can just build a static array that's optimized out. Expansion of cases in switch would be "nice", but it's nowhere near being necessary.
Beware that the term "C++ concepts" is a term in itself in C++: [C++ Concepts] (https://en.wikipedia.org/wiki/Concepts_\(C%2B%2B\))
(Or rather, an array of constexpr pointers is enough - the array itself doesn't even need to be constexpr *or* const, as demonstrated by the beautiful assembly I have somewhere in my slides.)
Obviously that isn't "magic"; that's the table lookup approach. The problem is that gcc doesn't perform that optimization currently.
Ah, good point. And the symbols will be horrible (imagine debugging that call stack in gdb, ugh).
Using an array of function pointers, OTOH, seems to make GCC totally unable to produce the most optimal code. At least that's the conclusion I made after comparing https://godbolt.org/g/XHMLLj and https://godbolt.org/g/L7sv7f.
Yeah that's exactly what I said? &gt; That's entirely QoI dependent. 
I'm not sure how this compares to the various other concurrency efforts in C++. Looking at your example from https://github.com/davidklaftenegger/qd_library #include&lt;iostream&gt; #include&lt;qd.hpp&gt; int main() { int* counter = new int; qdlock lock; std::thread threads[4]; for(auto&amp; t : threads) { t = std::thread( [&amp;lock, counter]() { lock.delegate_n([counter]() { (*counter)++; }); } ); } for(auto&amp; t : threads) { t.join(); } std::cout &lt;&lt; "The counter value is " &lt;&lt; *counter &lt;&lt; std::endl; } If there is some strange reason that counter needs to be on the heap, please use a unique_ptr, otherwise the stack of main should do it. But please don't use raw new in an example anymore.
Thank you for your suggestion, I will try to update the example later today. You are correct that the stack would work too.
There's something weird going on in gcc's optimizer. Look at this: https://godbolt.org/g/shBIf5 If I change the `#if 1` to `#if 0` then gcc optimizes `main` to `mov eax, 42`; likewise if the array elements are changed to local variables. It has some weird hiccup over propagating the values of class/array elements.
Hey, I was just asking. The slides are fine, thanks.
[citation needed] for the first part, please. The current variant is efficiently implementable with current compilers. (Compiles down to call tables if you abstain from using lambdas until your implementation has constexpr lambdas.) Whether it can be folded down at compile time for all constant values is of no consequence to the initial statement of this paragraph. The disappearing act nonsense is really harming people's perception of reality, and that reality is: very often constant folding matters much less than people think these days, because the useful use-cases for language and library features will operate on runtime data, which cannot be constant-folded (for obvious reasons).
This sounds really weird - what use case could there be for telemetry that's delivered at per-frame resolution? It's affected by factors that mean the timing isn't going to be precise, first and foremost - sending packets over the internet; the latency is going to be much more than a single frame and probably vary by a frame or two. Unless the framerate is tightly locked, the send interval is going to vary too. This smells like telemetry isn't the solution for whatever problem is being solved, and I'd be willing to bet that a lower rate, eg 10 sends per second would be more than sufficient for anything a game needs to do.
If I might make a suggestion, for the purpose of learning MFC, the first edition of this book is better. It's titled "Programming Windows 95 with MFC". In my opinion, the second edition ("Programming Windows with MFC") relies a little too much on wizards. It's broadly the same content, but for understanding the first is better. I have a copy of both and I preferred learning MFC from the first. It doesn't use the wizards; every line is explained and hand-coded, like a primordial Handmade Hero. Bonus; the first edition is generally available for a penny plus postage. As I type, there are four copies going for a penny plus postage on Amazon UK. Amazon UK also tells me that I bought my copy for the extortionate cost of FOUR pence plus postage back in 2008 (although postage was five pence cheaper back then). 
never owned the first edition, but yes, he focuses in the 2nd edition also on the tooling which was available back then.
One more problem with output variables is that they cannot be declared `const`. &gt; What are you going to do now?! std::string shift_right(std::istream &amp;in) { std::string res; in &gt;&gt; res; return res; } auto a = shift_right(std::cin); auto b = shift_right(std::cin); and now put `a` and `b` to `struct` if you wish. As a bonus, one might choose a better function name.
I actually prefer the google coding standards solution for output parameters: declare them as pointers and take input objects by const ref. If you adhere to this idiom, it becomes quite clear when something is being modified at the call site.
Yes, operator&gt;&gt; is a bad example, as said But what about: while (something(output))?
&gt; No, I'm implying that you have to use an output parameter there. Why?
Talk to an experienced c++ programmer in your team. Ask about the language standard, internal tooling/infrastructure and coding guide lines that are used. Then focus on learning that first. There are many great books out there, but they may not apply to you when that project still uses c++03.
Yes, but output_parameter is smart: If the deferred_conction has been initialized, it assigns to the result of `value()`, so it works.
Might be a naive question: Why not use 'const' to mark input parameters. If the parameter isn't const I assume it can be modified in the function and thus is part of the output.
This depends entirely on how narrow or wide your contract is and how defensive you want to write the software. With a narrow contract and a non-defensive approach (resulting usually in faster code than wide-contract-defensive but not as robust) it may be completely fine. This is maybe not the best solution when dealing with external data, but there are very valid cases.
I guessed it was probably a Java programmer, just from the abstract. That's the only way I know of that that comparison could make any sense whatsoever.
What's the point of looking at a function call if you don't know its parameter types? (or, more generally, if you don't know what it does). This is a made-up problem.
“Would to Heaven we had never approached them at all, but had run back at top speed... before we had seen what we did see, and before our minds were burned with something which will never let us breathe easily again!” -- H.P. Lovecraft re: Windows 95 in 2016
I fully agree to that. Yet many, very smart people complained about it, so I tried to come up with something that makes it obvious. I personally don't have a problem with it either.
My assumption was that because it was a local variable at function scope and on the stack. No pointer is ever created to it. I would assume that it would be fair game, but that could be my ignorance. I am having trouble seeing when this value could be observed outside this context. The location is not special either, as the linker/compiler chose where to put it. Or is that it. It's the practicality, of how one would ever hit this bug. Or is that not the problem, but the non-conformity.
&gt; But multiple return values are not the only situations where you want to have output parameters. Not the only, but in most cases the best. &gt; As argued in the post, sometimes the return type cannot be changed. In those cases (e.g. your `operator&lt;&lt;`) the argument list cannot be changed to have additional out parameters either.
There are several npos declarations, using std::string means that you then can't import a separate namespace with npos into your code and keep a consistent or logical formatting Best just to fully qualify imo
npos is static constant of `std::string`. That means that even if you do `using std::string`, you will still refer to npos as `string::npos`. So I don't see any problem. Did you think that static constants get pulled into the namespace below?
The problem I have with your article is that it’s your *only* example (your `read_strings` example can easily be implemented using optional return values). As a consequence you haven’t convinced me that out parameters are ever a good idea. In fact, except when required by established APIs such as C++ iostreams, I am convinced that they are terrible and I advocate using parameters for input only, and exclusively use return values for output. One potential exception to this is the `this` pointer, but strictly speaking that’s not an output parameter and at any rate I advocate interface immutability (except where unfeasible due to performance penalties).
I didn't actually want to advocate foror against output parameters. I just wanted to show how you can make output parameters better, if you use them.
Why thank you good sir! It's healthy competition.
&gt; In those cases (e.g. your operator&lt;&lt;) the argument list cannot be changed to have additional out parameters either. "many seems to confuse the examples used to illustrate a point with the point itself." - [Bjarne Stroustrup](https://isocpp.org/blog/2014/12/five-popular-myths-about-c-bjarne-stroustrup) There can be situations where it is reasonable to change a functions arguments but not it's return type, why is that so hard to imagine?
Alright, fair enough. I think the introduction to your article (especially the very first paragraph) threw me off. For what it’s worth the actual interface and implementation of your proposal is good, and definitely superior to either using references or `std::reference_wrapper`, as far as I’m concerned.
Yes, I need to amend that.
Meta: why would you use VS Code for C++ instead of VS 2015?
Aren't they compile time?
This short description reminds me of libdispatch. I see the paper states: &gt; To the best of our knowledge, our libraries^1 are the first to provide portable support for delegation. By portable we mean that they only require the presence of a compiler that adheres to the C11/C++11 standards. I'd be curious to see comparisons with those other libraries, portable or not. 
I'm not sure I'd use this technique for the cases when I need out-parameters, but the blog post was a very good read and getting to know this technique was very useful! Thank you for the post!
They need to be "active" during compilation to insert instrumentation, but they only find bugs at runtime. This is unlike Valgrind, which can run and check any binary (but it is better, if it has debug info), but has significantly larger overhead.
The page you linked does not seem to work with the hover feature. It works fine on their homepage... Also from what I read this seems to be a code base viewer not a pastebin alternative. **EDIT** I figured it out. paste.woboq.org is the correct link for the paste program. Weirdly the logo directs you to code.woboq.org
This tech can however be very easily turned into a pastebin alternative.
I love user-defined literals. I use them for [fixed-point literals](https://github.com/aubreyrjones/julimin/blob/master/nos/math/fixed.h).
Which browser/OS were you using where it did not hover? Just added support for on-Click. Does that work? :) paste.woboq.org is a pastebin that uses the API of code.woboq.org
Either "function name makes it clear" or it doesn't, it is no more or less tricky if not everything is passed by value. In any case if you are actually reading code, the type (and hopefully a brief documentation) is one click/button/hover away. 
&gt;So, is it only possible to get value from the assignment ? Why ? In order to prevent bugs for you accidentally have a precondition for the output parameter but did not intend it. &gt; Also, In the example where you did auto&amp; result = (out = ""); &gt;The user of the ouput_parameter has to know, that they should use deferred_construction before putting their variables in ouput_parameter or they will be twice assigned. They will be assigned twice, yes. But that is no different then using a normal reference, you'd also have to put in a known state before you can use it. 
Yes, the request sounded a bit weird to me at first as well. However, the client has real time stream processing of events that requires data to be sent as it becomes available. Without going into the specifics, firing more frequently can facilitate offloading of complex compute tasks to azure and potentially changing in game behavior as the player is playing (assuming one has duplex communication with game client). The other reason will be to lower the MTTD (Mean Time To Detection) for service level outages. Now, we could have just sent it every X number of miliseconds - but because of some perf considerations, we did not want to fire two events in a single frame neither did we want to miss a beat.
It seems to work now. I even tried multiple times before. But the popup pops up instantly which is quite enoying when you try to hover over a method and are moving your mouse over the other code to get to the function you want to view. Hope that makes sense. Not sure how to explain it. I really like this idea but it needs a few features for me to be able to use it. Are you open for feedback?
They work great for bignum/pair types as well. Can encode 256-bit integer constants for things like cryptography without having to do an array of unintelligible 8-bit/64-bit hex values. Eg for Ed25519: static const uint256_t L = (1_u256 &lt;&lt; 252) + 27742317777372353535851937790883648493_u256; 
`any` is not a substitute for `variant`...
I checked the source briefly and I wonder why is there the "isServer" template parameter everywhere instead of two explicit separate classes (client/server) ?
Union version! Can't do 1-1 because you can't stick a std::string inside a union. So we've already failed there. However if we wanted to remove the std::string and compare here's what we have: design|# lines assembler :--|:-- [std::variant](https://godbolt.org/g/waBYZ7)|118 [union](https://godbolt.org/g/X4REsK)|31 So we can see that the union implementation is massively more efficient (and verbose). That said, it's like...incredibly dangerous code. I had to comment out that exception to keep the code size down, and it's really easy for someone to mistype and break. Personally I wouldn't accept any code with unions instead of variants unless they've profiled and shown me that it's worth it.
You can get the `std::any` version down further (I got it down to 910) with more any_cast's, and not comparing `type_info` explicitly: https://godbolt.org/g/LIQL4Z
updated
&gt; Instead of accessing the attribute of the object, its property, you need to call a function, **which doesn't make sense in OOP**. I don't recall seeing anything in "the OOP spec" that says attributes should not be exposed as functions. Unfortunately ReadOnly seems like a whole lot of boilerplate to avoid getter/setter functions. Edit: not only that, I have to friend as-of-yet unknown classes in the somewhat-generic-ish template class?
I've given this some consideration on the drive home, wouldn't this solution work just as well for exposed read only attributes? class Human { public: Human(); const int&amp; age; const std::string&amp; name; private: int age_; std::string name_; } Human::Human() : age(age_), name(name_) {}
I'm still confused by what you mean here. Are you saying that there are a whole bunch of smart people who refuse to look up the function parameters but at the same time know the rest of the function signature (name &amp; return type)? And these are smart C++ devs? Smart, experienced C++ devs? I must work with dumb c++ devs if this is the case, because if any of my colleagues programmed solely through assumptions of what *should* happen based on the function name, they'd be fired pretty quickly.
Sometimes you want the parameter to be both an input + output parameter. I agree that the problem of "how do I return multiple things" isn't great, but the pitfalls of it are well understood. Generally speaking, you resolve ambiguities with comments or just ensuring that the output param you pass in isn't dirty. Maybe I'm reaching a point in my career where I've ended up in the "get off my lawn!" zone, but this feels like it needlessly adds complexity to a problem that's really not worth that complexity.
One of the core C++ principles is zero overhead abstraction. In my example it should kinda boil down to something like [this](https://godbolt.org/g/QcTxSo). Variant is an abstraction useful for many scenarios, however the current standard implementations do not satisfy the ZOA principle. Our variables and calculations have no observable side effects on the program. So the compiler should be free to optimize everything out. If you think that such example, where we want the compiler to understand, to produce assembly that does not do the task we told it to do, is artificial and not representative for more complex run time problems, then you are partially right. By uncommenting the string addition, you should see that non-trivial types such as std::string, already confuse the compiler enough to miss the lack of side effects. On the other hand, a compiler front end such as clang for [llvm](https://en.wikipedia.org/wiki/LLVM), converts your code into intermediate representation where every instruction is a static single assignment. Imagine: int a = 5; int b = 3; int a += b; turns into: const int a = 5; const int b = 3; const int a2 = a + b; This makes optimization much easier for the compiler. So that optimizations that works for artificial examples, such as the one used in the variant example, could also work for run time data. Artificial examples are more common when looking at compiler output, as they produce less noise and are easier to reason about. --- I was unable to meet ELI5 requirements, without making it so general that the important details would have been lost.
If I had a nickle for every time I see some grand proclamation about how C++ fails OOP rooted in someone understanding neither C++ nor OOP, I'd have... well, like $12.50, but still.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). 
I see, thanks for enlightenment!
I hate to say it, but this is the least compelling argument I've ever heard for using a language feature. I don't want debug builds to be optimized, I want them to be easy to debug. The fact that assembly is disappearing in this case means that stepping through it in a debugger won't show as much detail. Notice that gcc didn't have any assembly associated with the default initializer line, so you can't even step into that line.
Look for **MFC black book**. Everything else is garbage.
Indeed. And there are other differences too. The polymorphic unique_ptr uses push_back rather than direct initialization. None of the other versions had to do that. There are some [tricks](http://stackoverflow.com/questions/8468774/can-i-list-initialize-a-vector-of-move-only-type/8469002#8469002) to work around that, or we could change all the version to use std::array instead. Also the derived is constructed with T by value. It makes an unnecessary copy then moves the copy into its member arg. With std::array and rref constructor: https://godbolt.org/g/8BE0Gz &gt; But the most worrying: version with new and delete instead of unique_ptr gives 485 lines The unique_ptr version is also leak-proof; the naked new/delete version isn't. We make four derived objects in a single expression... what happens if construction of the fourth throws an exception? `arg + arg` doesn't mean you're adding two numbers, sometimes it means concatenating two strings... so what happens if `add()` throws? Make the naked new/delete version leak proof, then we'll count lines again. ;-) EDIT: Also how fucking fun is CompilerExplorer! :-D
&gt; `uint256_t` I need this. Hit me up. 
Light, free, less bloat files, integration with git.
Here you go: http://hastebin.com/raw/oqoteviyac Unlike the other reply, my library scales from 128-bit to 8192-bit reusing the same header (it can go further, but after 1024, you're better off using a bigint library.) It can also utilize native 128-bit types if your compiler has them, which makes the bigger types way faster. And it has some nice additions like an optimized square function (x*x), Barrett reduction for fast modulo by a constant value, functions to turn the values to and from strings and vectors, etc. As with every library like this, division is the operation that is *immensely* painful (slow.) Unlike multiplication, there's no divide-and-conquer approach possible. We have to iterate over every single bit of the input. Warning: there are conditional expressions in there (especially in division, but also in shift+comparisons+not), so it's not safe for use in cryptographic applications as it leaks side-channel information. It's also too slow for that. In my own crypto code, I use 64-bit limbs and optimized functions by DJB that perform modulo over prime fields without division. For the parts where 256-bit and 512-bit values are fed into the crypto functions with these types, I use Barrett reduction that operates in constant time. Also, these large integers are really useful for hash functions (like SHA512) and for encoding large numbers (like signatures, public keys, hashes) into something easy to share online (like Base57.)
not_null&lt;type*&gt;?
That isn't enforced by anything though.
Visual studio has git integration. Definitely not light, but can be free depending on your circumstances and usage. 
&gt; I still find it easiest to pull up the built-in terminal and just fire off make/ninja/scons That's ok for building ... but a completely different story for debugging.
Thank you for the great example
I honestly have no idea how that paper got published. Hey, wait, I'm an academic. I can publish papers too. Vittorio, we should submit a rebuttal paper for ICSE next year.
Not all C habits are bad. And, due to the language constraints, some of the best architectures I've seen where built in C because they could use simple concepts to great benefit. e.g. [This](http://nob.cs.ucdavis.edu/bishop/secprog/robust.html) It's in C so it has all the C idioms, but it's great design, safe and really simple to use. You can do the same in C++ without relying too much in template tricks to avoid that specific corner case that someone who doesn't know your code base wrote because they didn't bother to read the docs before using that function. Gosh, we desperately need some standard docgen syntax in C++ so IDEs can provide documentation on the fly. 
&gt; if it's C++, the whole purpose of using a pointer is that it is ootional That's incorrect, otherwise the standard wouldn't be accepting std::optional&lt;T&gt;! :)
&gt;So, what’s the advantage of a tuple over a struct? &gt;I have no idea! But I guess the answer is “none”. I laughed at this. There is a huge advantage which is completely ignored in this post: I can iterate over tuple elements, but I can not iterate over a struct (b.t.w. the correct word here is "aggregate"), at least until we get reflection (C++20?). Unless that is what you mean by "variadic structs". Another point being made: &gt;you can enforce invariants amongst the data members by making them private and mediating access via member functions. Yes you can, but it would not be an aggregate anymore. You use `tuple` when there is no invariant between the types (definition of aggregate). Anyone who used `Boost.Fusion` or `Boost.Spirit` realizes why tuple are useful at an API level (albeit mostly for metaprogramming). Yes an API that deals with `tuple&lt;string, string, string, string&gt;` is not a sane one (unless there is a very intuitive logical ordering among the strings), but I argue that given the more and more extensive use of the type system in modern C++, the case where you have multiple distinct objects of the same type that you want to return is getting rarer and rarer. For example yesterday I wrote a function that returns a `tuple&lt; position_t, orientation_t, velocity_t, angular_velocity_t&gt;`. Here 3 out of 4 types are in fact just `vec3`, but since I am using a type-safe dimensional analysis library, there is no way that you can confuse one with the other. Even without structured bindings, extracting the right thing out of it is quite intuitive: `get&lt; velocity_t &gt;( ... )`. 
Replacing iteration by value with iteration by const ref [saves about 70 assembly lines](https://godbolt.org/g/K2dvif).
No, the whole point is that a reference is a-ok compared to a naked pointer.
I'm going to be really upset if structured bindings only work via compiler magic against std::tuple. I would like a way to choose between my own structs with named members or this new syntax to expand things. If I can't implement structured bindings without my functions returning tuples (and thus implicitly allowing code to use the older .first, .second syntax), then I most likely won't even bother using them. Language features should not be tied to library components. The entire standard library should be replacable by a user's own implementation without any compiler magic.
I'm up for it!
AFAIK it will be posible to use structured bindings with any agregate, so it will work with own defined structs.
Interesting, thanks. Ideally, It would be great to have a single solution for refactoring, indexing, and possibly static analysis &amp; quick fixes ( "You probably want to add an override there, do you want me to do that for you ?" - "you said 0, did you meant nullptr ?" ) Beside the performance loss of running multiple overlapping tools, It could probably cause all sort of issue because each tool will end-up having outdated cache. As you said, regardless of the size of the project, the rate of local human-made changes is pretty low so there is a huge gain in having the whole project indexed in cache. So for your tool to be quick you probably want to write 90% of an indexer, so, why not provide an indexer to begin with ? Also, wouldn't it be easier to provide a command line interface atop a library/server rather than the other way around ? Also, one of the major issue I have with big refactoring is how platform-specific code is handled. Namely, if I have a class or a file that for some reason is only built on windows and I'm on Linux, if I'm renaming a method project wide, the windows-specific code should be refactored as well. Good luck, sounds like a really nice project - is it baked by Google or is it a personal project ?
Also `&lt;typeinfo&gt;`, most of `&lt;type_traits&gt;`, `exception_ptr`, exceptions thrown by`dynamic_cast&lt;T&amp;&gt;`, exceptions thrown by `new`, and probably more. I don't think this is a bad thing tho.
&gt; So, what’s the advantage of a tuple over a struct? &gt; &gt; I have no idea! At least the author has the grace to admit to his readers that he is unqualified to write an article premised on the use of `std::tuple&lt;&gt;`, even if he has not admitted it to himself.
And any class/struct where you specialize std::get, std::tuple_size, std::tuple_element 
Are you sure? the N-paper doesn't list that as a requirement. It just says from any struct or tuple.
Well, for questions we have this one ;) http://reddit.com/r/cpp_questions
&gt; Ideally, It would be great to have a single solution for refactoring, indexing, and possibly static analysis &amp; quick fixes ( "You probably want to add an override there, do you wan't me to do that for you ?" - "you said 0, did you meant nullptr ?" ) Yep, that's exactly what *clang-refactor* + its infrastructure is meant for. Basically, we would need all of the things you mentioned. The idea is to build a uniform solution for static analysis, refactorings, with focus on editor integration. E.g. static analysis in Clang is currently TU-local, whenever you rename (call *clang-rename*) a class, it's only renamed within a translation unit, which is bad. Whenever you run *clang-tidy*, it only "sees" everything within a single translation unit, which makes *some specific* checks unrealistic (though most of them do not require other translation units within a single run). It should be also extremely efficient. Google has Clang MapReduce for *clang-tidy* parallel runs, **but** that's too *clang-tidy* specific (and it's not open source). There are refactorings, there is static analysis, there is cross-reference index, there are editors, and more, more, more, more... We want all of it. And we want all of it stable, scalable and easy to use. There are tons of challenges. For example * How do we keep a large project's index up-to-date without a huge overhead? * How do we minimize the editor latency for refactorings? * How do we pass information from one translation unit to others? * How do we not parse every translation unit every time (refactorings are called quite often and thus it might make sense to store TUs, but at the same time stornig TUs for any considerably big project is unrealistic - it's just too big)? And more and more. &gt; As you said, regardless of the size of the project, the rate of local human-made changes is pretty low so there is a huge gain in having the whole project indexed in cache. So for your tool to be quick you probably want to write 90% of an indexer, so, why not provide an indexer to begin with ? Yes, Clang-based Server isn't the first step towards a bright *clang-refactor* future. While it is important, many other things (like actual cross-TU stuff and parallelizing module [rename something, static analysis, ...] runs). But Clang-based Server is also very important one. &gt; Also, wouldn't it be easier to provide a command line interface atop a library/server rather than the other way around ? Most Clang-based tools have a nice CLI, having that for *clang-refactor* makes sense, too. &gt; Also, one of the major issue I have with big refactoring is how platform-specific code is handled. Namely, if I have a class or a file that for some reason is only built on windows and I'm on Linux, if I'm renaming a method project wide, the windows-specific code should be refactored as well. Sorry, could you elaborate? By "for some reason is only built on windows" do you mean that it is enclosed into some `#ifdef`s or do you mean that the project itself generally supports Windows? &gt; Good luck, sounds like a really nice project - is it baked by Google or is it a personal project ? Thanks :) As you can see, the project scale is just huge. I started it as an intern this summer, but now I got back to studies and therefore I can't work on that extensively at least until the next summer. However, as far as I understand my former team was interested in the project and there is a decent chance they'll continue my work, I'll be happy if they do. I was an intern in the team working on C++ Tools using Clang, the guys are just amazing. I also wrote a [post](https://omtcyfz.github.io/2016/08/30/Improving-workflow-by-using-Clang-based-tools.html) about some Clang-based tools, but they do many things beyond that - e.g. recently added clang-move, clang-change-namespace.
Eigen supports dynamically sized matrices as well. Check out Eigen::MatrixXd and Eigen::VectorXd.
Maybe it's not natural to group the elements together, so it would be a bit weird having a type (a struct) that contains all of them. You don't want to create a new type just for a return value I think. Of course you could argue now, if the grouping is not natural, then also the function should be split into two (or multiple). But in practice I have found this quite often, you want to return multiple values from a function that are connected (i.e. you don't want to split the function into two because either you can't (because then the calculation would have to be done twice) or you don't want to because you want the caller to have one single function to call, not two), but at the same time you don't have to introduce a new type just for that return value. There is this "trick" with an anonymous struct or something declared inside the function and then returned, but I don't think that this is intuitive either in an API. So the best way to go is kind of a tuple. (and structured bindings hopefully soon). (Or out-parameters (which are also not intuitive).)
thanks ! 
OMFG... Read MSDN, debug throug MFC sources and the code you have. The truth is in the pudding. Or just run, like the other dude said :-)
They are returned together, but may be needed in different places. What matters is that the declaration of the tuple is one line (and sometimes on the same line as the function). You read declarations more often than getters, so there is a speed-up.
&gt; Sorry, could you elaborate? By "for some reason is only built on windows" do you mean that it is enclosed into some #ifdefs or do you mean that the project itself generally supports Windows? Exactly #ifdefs. You shouldn't have to run the tool on each supported platform to rename a method thoroughly for example. There are other issue, for example, the code for other platform may use headers clang don't know about and it shouldn't complaint about that. To rephrase, it's not because the pre-processor disable some codepaths that said codepaths should be ignored by the developer and their tools. I know. it's a hard one. &gt; However, as far as I understand my former team was interested in the project and there is a decent chance they'll continue my work, I'll be happy if they do. Suddenly, I'm less enthusiastic. I've seen so much cool intern projects thrown away for lack of resources. For fun, let me throw some stupid ideas out of my... hat. &gt; How do we keep a large project's index up-to-date without a huge overhead? An editor rarely has that much file open and it's something we can factor in. For out of the blue modifications, running recursively checking modification through fstat is fairly quick, even on thousands of files. Doing that partially every though often should be fast. Look at what git status is doing. It also depends what your targeted use case is. But if you assume a developer working on their machine, quite a bit of assumption can be made. &gt; How do we minimize the editor latency for refactorings? This is a hard one and I would make the assumption that you can't. Because given enough files, you really can't make any guarantees. What you can do is having that run in the background. So it's more about having a proper feedback on the client side. &gt; How do we pass information from one translation unit to others? What do you mean ? &gt; How do we not parse every translation unit every time (refactorings are called quite often and thus it might make sense to store TUs, but at the same time stornig TUs for any considerably big project is unrealistic - it's just too big)? Refactoring are really, really rare compared to lookup &amp; completion. But, maybe you can maintain a table of which symbols are in which files. You know whether the file was modified (because you trust your index/cache) and so you know which TU you need to modify. Ideally, it could be guided by how the code is structured. Some symbols get use way more than other, some files get modified more, etc and the caching could take that into account. I'm sure there are smarter/crazier things doable. Like, running a diff on the file and somehow have incremental parsing - with the granularity of a function for example.
Adjustable layer size? How does that work?
&gt; I can iterate over tuple elements, but I can not iterate over a struct (b.t.w. the correct word here is "aggregate"), at least until we get reflection (C++20?). With the help of structural bindings in C++17, you can convert aggregates to a tuple https://www.reddit.com/r/cpp/comments/4yp7fv/c17_structured_bindings_convert_struct_to_a_tuple/ 
Can we have a sidebar on a pop out window? 
Thanks, I had overlooked that class Dynamic may be passed as template parameter
If you're just going to store the pointer in a data structure that needs to be a pointer so that it can be rebound, passing that pointer "as a reference" over the function boundary just creates more syntax on both sides of the boundary to fight with. Saying `-&gt;` instead of `.` isn't that big a deal. Worse, since dereferencing null and passing it as a "null reference" merely creates UB in the caller which typically results in a null pointer being stored, it doesn't save you from the "now I need to figure out how this null got into the data structure" problem. Even if a parameter is accepted by reference you still should have/read documentation on the callee because the callee may stash that reference around for later, creating lifetime issues, or have other preconditions that are less blatant than "the thing cannot be null". EDIT: To clarify, I like references and think they're great in a lot of domains. I just think an attitude of "it's a pointer parameter so I can pass null here" is wrong, has always been wrong, and will continue to be wrong.
This is looking promising! Just a few questions: * What license will this be under? * Is this a project other developers can contribute to?
Thank you. I haven't decided yet about licensing, nor about going open-source.
A second comment, because I like your comment so much. &gt; I can iterate over tuple elements, but I can not iterate over a struct Well under certain circumstances (§9.2 15?) you can use raw pointer addressing to advance through a struct without accessing its members by name ... believe it or not I found some live production code only the other day that actually does this. I'm still not sure whether to replace it with something that is not completely insane or just pretend I never saw it and leave it alone.
getOrCreate
Why not just use std::unique_ptr&lt;FILE, decltype(&amp;fclose)&gt; ?
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). 
Was trying to make a joke... VS questions are not C++ related. C++17 - https://en.wikipedia.org/wiki/C%2B%2B17
Incredibuild if you can afford to spend money on the licenses 
What's the general landscape for C++ web development? Is there a demand for better web frameworks and tools?
I want external build tools to parallelize. Specifically, everything built with NVCC (Cuda) builds in serial, and takes a hell-of-a-lot of time. IncrediBuild correctly identifies these operations as something that can be ran in parallel. Also Qt Moc.
Two drawbacks of that approach: - Every file pointer is now twice as big because the deleter isn't stateless. - You have to pass fclose to the constructor. The implementation I tested on static_asserts if you forget, but I don't think that is required.
None of this matters if your entire team is not on the same page. It takes one person to disagree with this effort, or to be careless, for this to be futile. You can't be alone on this, and you can't "try" or "ask" people to "cooperate". It has to be a team effort where everyone are all in. It helps if everyone feel the pain of slow builds first, to get context.
This looks great! It seems like double is used as the underlying type. Is it possible to use floats instead?
No.
&gt; Due to incompatibilities with the WINAPI, the literal abbreviation for tesla units are `_Te`, instead of the SI standard `_T`. You can fix this. Instead of `operator"" _T`, which uses a reserved identifier, use `operator""_T` without the space. This technique is also necessary in the standard library to define an `if` suffix - `if` is a keyword, but `5if` is a floating-point imaginary number with the value 5i. I imagine MSVC handles this because to my knowledge, it supports `if` as a suffix, but here's [Clang](http://coliru.stacked-crooked.com/a/4dbc363f468c480d). Edit: Looked at the code and I'm not sure why that wouldn't work as is. Here's [Clang](http://coliru.stacked-crooked.com/a/8509c07d7d4da178) with something more similar to your definition mechanism. I don't know whether you actually ran into trouble with `_T` as a suffix or whether you pre-emptively avoided it due to prior knowledge that the Windows API can be a PITA with macros. Edit: That should also work for a function-like macro `_T` (I forget how it's actually defined in the winapi). If it doesn't on MSVC, however, try `ReturnType (operator""_T)(Parameters) { ... }`: [example](http://coliru.stacked-crooked.com/a/f712172cfabee04e). The example puts a space in the operator name to demonstrate the separate effect, but I would recommend not using one.
I'm slowly pushing back against this. We get reasonable default properties from property sheets. My plan is to eventually write a default pre-build target that validates its own .vcxproj (and possibly .cpp files) and errors out if a project breaks the rules. I have a series of scripts and manual steps to fix most of the dumb issues like no/bad pch settings and #imports outside of the pch, and I've tested it successfully on our large (3MLOC, ~325 projects) codebase, but I haven't pulled the trigger on getting it pushed in because without the verification step it'd probably all be re-broken somehow in about a week :(
I want a hololens compatible circular sidebar that I can use with the Surface Studio Dial! 
I love that this has decibels, I had a hell of a time reasoning how they should operate at my dayjob (using boost::units under the covers). Two thoughts: * How is relative temperature vs absolute temperature handled? * decibel_scale is only valid for power quantities (10\*log(val/ref)), not root power quantities (20\*log(val/ref)) 
&gt; Webbit is based on modern C++ features such as variadic templates to attain high performance and stability required by web and enterprise applications. lol
I largely agree with you, but you're discussing **way** beyond the scope here. TFA was about out parameters, and I reacted in that context. Using a pointer for that, in C++, is dumb for reasons I pointed above. And I forgot one reason. It doesn't work in a situations like these: void f1(other params, type* p_outval) { // workwork *p_outval = outval; } void f2(type* p_val) { // workwork f1(p_val); // OH NOES, I LOST MY AMPERSAND, I DON'T // KNOW MY OUT PARAM ANYMORE! } 
Looks like you put a lot of effort into the documentation, which is cool, but this is - and shall remain - completely and utterly worthless to me without access to the full source code and a GNU/Boost/BSD/MIT/Apache license. Just do it!
Yes, from the page: &gt;Changing the underlying type of unit_t &gt;The default underlying type for all unit containers is double. However, this can be overridden by providing a definition for UNIT_LIB_DEFAULT_TYPE, e.g. &gt;// Use 64-bit integers as the underlying unit type &gt;\#define UNIT_LIB_DEFAULT_TYPE int64_t NOTE: changing the underlying type may result in unexpected behavior. Unit conversion makes heavy use of division, which may make integral types unsuitable except for niche embedded applications. Using excessively large types may increase the number of arithmetic overflow errors. 
Maybe I should elaborate at least about stability. Most bugs encountered by anyone who works in a team developing CRUD/web/business applications are "Null Pointer Exception" based. When that happens in C++ you get a SIGSEGV or undefined behavior which is even worse. Model (entity or whatever you'd call it in another language/framework) is implemented as a variadic template class which checks for "null" fields upon access and throws an exception instead of causing a SIGSEGV. Also it notifies registered event listeners which update data upon field write/modification (e.g., web ajax refresh, database update) or read lazy loaded data upon field read (e.g., database read) to simplify the development process.
Yeaaah, I'm gonna hold out until it's open source... 
Is the size of file pointers something that one would need to worry about? Typically I dont think I have seen more then one alive at a time.
I know this is not r/java, but anyone know of an equivalent style library in Java? Unit-aware math is such a headache for bugs without libraries like this one. 
&gt; much more expensive on Windows than the platforms it was designed for. Using a tool that was designed for a completely different platform and complaining it does not match the design of the platform... well, you could've seen that coming. It works *very* well on the platforms it was designed for, given a competent Makefile input.
Did you also benchmark the time it takes to compile both?
Indeed, variant and any are not here to replace inheritance. I talked about inheritance because to me, it's seems that like ```virtual```, this is a C++ feature getting less and less interest (I removed it to avoid the confusion). On the other side, ```std::variant``` and ```std::any seems``` to solve problems similar than the ones ```virtual``` solves. See for example this thread, comparing ```variant```, ```any``` and ```virtual``` to get polymophism: https://www.reddit.com/r/cpp/comments/59jb4h/alternatives_disappearing_c17_stdvariant_act/ 
&gt; thread, comparing ```variant```, ```any``` and ```virtual``` to get polymophism I understood it as being the other way around, the thread looks at using virtual polymorphism to get ```variant```. 
**Company:** King. Officially, we’re a leading interactive entertainment company for the mobile world. Recently, we were acquired by Activision Blizzard – King operates as an independent unit of Activision Blizzard. Unofficially, we’re a serious business that’s not afraid to have fun. And lots of it. Candy Crush Saga. Pet Rescue Saga. Bubble Witch Saga 2. Paradise Bay. We’re proud of the 200+ titles that carry the King crown. Because our mission has always been, and will always be, to create the games that unlock the player in everyone. No matter where they are, who they are or how much time they have. So if you share our ambition, introduce yourself, as a developer at King your code will be deployed to hundreds of millions of devices... **Type:** Full time **Description:** We are looking for a passionate and talented C++ Developer. Together with your colleagues you will have a part in creating and maintaining our mobile casual games. You will specify, design, build and implement existing and new game features. As part of the development team you will enjoy a creative, challenging and collaborative environment where your ideas will be every bit as valued as your programming expertise. Your responsibilities will include: * Designing, testing and implementing game features * Taking an active part in game creation * Maintaining and optimizing new and existing game features * Contributing high quality and well-structured code to our global code base * Sharing knowledge and helping colleagues **Location:** Stockholm, Sweden (also hiring in Barcelona, Berlin, San Francisco and London) **Remote:** No **Visa Sponsorship:** Yes **Technologies:** C++ developers usually use Windows, Mac or Linux (you choose!). Our target platforms are iOS, Android and the web. Experience on those mobile platforms are a plus, not a must. Experience in working with memory / performance critical applications is a tasty bonus skill. **Contact:** Formally apply on the careers page https://jobs.king.com or for Stockholm https://apply.king.com/vacancy/c-game-developer-candy-crush-stockholm/1604/description/ 
Whose definition? I largely based my work on what I could find of the ISO standards. While yes it is going to be proportional to a power, root-power quantities are explicitly called out. Should the users of the library have to do fancy footwork every time they want to use dBV?
&gt; this is a C++ feature getting less and less interest It's more like it had been used in the past to solve problems that are better solved with other tools. &gt; On the other side, std::variant and std::any seems to solve problems similar than the ones virtual solves Both are only useful in static (okay, maybe half-dynamic for "any") contexts. You will never be able to make a plug-in interface with `variant`. * `variant` is useful if you want to make growing the number of operations easy at the expense of growing the number of types. * `virtual` is useful if you want to make growing the number of types easy at the expense of growing the number of operations. 
Please add to readme basic example that compares implementation with VC and implementation only with SIMD intrinsics.
Indeed, only virtual can implement the plug-in interface since all the types composing a variant have to be known at compile time. Do you mean that if I don't write a plug-in interface, I should never use virtual ? 
it seems that at least one those common problems exists : https://www.reddit.com/r/cpp/comments/59jb4h/alternatives_disappearing_c17_stdvariant_act/ 
Thanks. Is there a channel that I should ping for distribution maintainers to notice my releases?
&gt; &gt; How do we keep a large project's index up-to-date without a huge overhead? &gt; An editor rarely has that much file open and it's something we can factor in. For out of the blue modifications, running recursively checking modification through fstat is fairly quick, even on thousands of files. Doing that partially every though often should be fast. Look at what git status is doing. I've written [cpp-dependencies](https://github.com/tomtom-international/cpp-dependencies) and it parses the full Chromium source tree in 5.5 seconds. I've optimized it on an internal project which it fully analyzes in 2 seconds flat - assuming your disk can keep up. And that's for projects on the size of 50k to 1M files, with each ~1kLOC.
`std::variant` is part of C++17. *checks date, hmm...* Not all problems are solved to perfection *yet*. But this has nothing to do with your initial statement about dynamic polymorphism and `virtual` dying, which is not the case. 
&gt; std::any solves the void* (type elision) problem, useful for heterogeneous containers, for example. Interestingly, I tend to use `variant` more for that purpose. It's quite rare for me to require heterogeneity for arbitrary types. 
`std::variant` and `std::any` solve a *different* problem, not the same problem *differently*.
I tried to do something similar, but I concluded it is difficult (impossible?) to do it correctly while still retaining ease of use. My main setback was that strongly typed units seem to need to live segragated in their own world, or the system is not strongly typed enough to fail at compile-time if units are incorrectly used. I see you had to implement casts to an underlying type, which tells me you encountered the same problem.
&gt; Whose definition? A decibel is a power ratio, that's the definition I'm talking about: Wikipedia references "IEEE Standard 100 Dictionary of IEEE Standards Terms, Seventh Edition, The Institute of Electrical and Electronics Engineering, New York, 2000; ISBN 0-7381-2601-2; page 288" for its definition: &gt; The number of decibels is ten times the logarithm to base 10 of the ratio of two power quantities. It's always power, the suffices on dB simply indicate standard references for the denominator in the ratio. `dBV` is not a voltage, it's simply using one volt as the reference. Of course the library user shouldn't have to do fancy footwork -- that's not what I'm saying. But dBV is a measure of power not voltage and it's units are _still_ decibels. The library user would declare them just like any other decibel unit. Perhaps I'm not understanding your complaint though? &gt; decibel_scale is only valid for power quantities (10*log(val/ref)), not root power quantities (20*log(val/ref)) I'm saying that they are the same scale. A decibel is a decibel. Edit: I'm not entirely sure I see how the library lets one use these standard decibel references anyway, it seems to be missing a key factor in: &gt; &gt; UNIT_ADD_DECIBEL(namespaceName, nameSingular, abbreviation) &gt; &gt; Adds the decibel representation for a previously-defined unit. e.g. &gt; &gt; UNIT_ADD_DECIBEL(power, watt, dBW) Without a factor you couldn't distinguish between, say, different dBm measurements (1 microwatt through a 600 ohm resistor for audio; but to 50 ohms for radio). Perhaps you're making the same observation, but using a different reference, the dBV?
The same page also references ISO 80000-3:2006 &gt; In the International System of Quantities, the decibel is defined as a unit of measurement for quantities of type level or level difference, which are defined as the logarithm of the ratio of power- **or field-type** quantities. Maybe I'm misunderstanding your proposal... how would you go about working with dBV or would you refuse to on principle? I agree they are the same, but certain shortcuts (assuming equal resistance, pulling out the square) have been defined as root power quantity levels.
Java cannot do direct abstraction over fundamental types. If you would do that kind of library, it would classes, method, lots of runtime costs and will uses method to do operations. You will probably need interfaces to do generic programming over this. In other words, no, you can't do such things in java.
Thank you
Xcode is the most popular IDE for Mac (free from Apple). It includes debugger etc.
&gt; Without a factor you couldn't distinguish between, say, different dBm measurements (1 microwatt through a 600 ohm resistor for audio; but to 50 ohms for radio). Perhaps you're making the same observation, but using a different reference, the dBV? Aha, yes! I would use dBV for dBm given known resistance. Edit: I'm also pretty foncused at this point by our overlapping edits and replies
An interesting [infographics about C++](https://blog.jetbrains.com/clion/2015/07/infographics-cpp-facts-before-clion/) came out last year. C++ has evolved as a language making it much more productive and simpler to use and IMHO it would see more presence in the web/enterprise area if more modern web/enterprise frameworks were available, hence the idea to make one.
&gt; Since C++11, I do not remember any C++ talk about virtual classes Part of the reason for this is that runtime polymorphism via virtual functions simply isn't very *interesting*. Conference talks tend to focus on new techniques and new libraries, and virtual functions are so well known (and the mechanisms haven't changed in a couple of decades, other than the addition of the `override` and `final` pseudo-keywords) that even if somebody did propose a talk on them, it's unlikely it would be accepted unless it broke significant new ground. There's also the fact that "modern C++" (however you might define that) tends to focus more on using value semantics, whereas traditional runtime polymorphism tends to require reference semantics. On that subject, Sean Parent gave a fascinating talk a few years ago called ["Inheritance is the base class of evil"](https://channel9.msdn.com/Events/GoingNative/2013/Inheritance-Is-The-Base-Class-of-Evil) where he (very very quickly!) ran through an interesting technique for allowing runtime polymorphism using value types, making use of `virtual` behind the scenes. 
The oft repeated dogma 'prefer composition over inheritance' and a bit of push-back from Java/C++'s over zealous OOP-ALL-THE-THINGS in the late 90's (which resulted in huge unmaintainable class hierarchies), has meant that for some programmers anything involving even the slightest inheritance is now incorrectly labelled a code smell. Which is of course, silly. No one is trying to get rid of polymorphism, inheritance, or virtual functions.
Why replace instead of evolve? From what I understand the design of c++ iostreams is mostly like this, except they call a "stream" the fmt layer, and a "streambuf" what you call a "stream".
Specifically file pointers? Probably not, at least in the type of application I write. But other types of resources, sure! To use the other example from the OP, a webserver using WinHttp could easily keep thousands of HANDLEs around.
I mostly agree with OP. Oh, inheritance and virtual methods aren't going away. But in C++03, we had very few ways to combine components, so virtual methods were used for almost everything. Now we're in modern C++ world, we have much more specific tools - `std::function`, solid generics, and soon `std::variant` and `std::any`. This means we only have to use inheritance for actual "is a" relationships - not for "almost any code reuse". Inheritance stops being a ["golden hammer"](https://en.wikipedia.org/wiki/Law_of_the_instrument) and becomes a very useful tool in your broad toolbox.
I don't remember what talk it was. But I remember some talk saying something along the lines of "Do you know how many copies the standard requires when writing a file? The answer is it has to make a minimum of 2 copies" Which sounds really wasteful... Is there ways to reduce the number of copies floating around when writing files?
as well as `std::function&lt;&gt;` you can use type erasure, (though under the covers that just uses polymorphism, but hides it behind a templated constructor). `std::shared_ptr&lt;&gt;` uses type erasure for its arbitrary deleter interface, for example You can also use what are often called extension points, where the library to be extended invokes template functions that the plugins extend for their own purposes, though that requires static linking, so probably falls outside the definition of plugins.
&gt; On the other side, std::variant and std::any seems to solve problems similar than the ones virtual solves No, polymorphism has been used in the past to solve problems that are *better* solved with `variant` and `any`, now that they are available. 
How does it compare to libsimdpp?
Just wait till you get to use `auto`.
to collect data, you could run a survey on the CppCon17 website
I believe its called the "Universal Model for Asynchronous Operations" and you can read about it here: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3747.pdf
If you have a shape class with a measure virtual function, and you know that box and circle are the only two classes that override shape, if you have a pointer to a shape, you don't know at compile time what function to call is, so you still need the virtual system. 
When I started and released Vc there was neither Boost.SIMD nor libsimdpp, nor Agner Fog's vector classes, etc. We have an unfortunate situation where there are many very similar solutions to the same problem. Anyway, there's a major difference, that may seem subtle at first. Vc, AFAIK, is the only SIMD types library to have a low-level vector type that does not have a user-selectable number of elements. I.e. the low-level vector types abstract the native vector registers of your target system (consider it like `int`, which is the most efficient integer type for a target architecture). So, Vc tries to help you writing more portable and scalable code by only allowing portable and scalable operations and conversion. However, sometimes your problem requires a fixed number of vector elements, though. For this case, there's an abstraction on top of the low-level `Vc::Vector&lt;T&gt;` (called `Vc::SimdArray&lt;T, N&gt;`) allowing you to express data-parallel storage &amp; execution with arbitrary `N`. The focus is an API for users without much C++ background, as many physicists and scientists in other fields have to write massive number crunching applications. So, ease of use and helpful compilation errors on misuse are a major motivation. Last but not least, Vc is the basis for the current SIMD data types proposal progressing the C++ standards committee.
&gt; My main setback was that strongly typed units seem to need to live segragated in their own world, or the system is not strongly typed enough to fail at compile-time if units are incorrectly used. Can you elaborate? In my use of a similar units library, I only cast out of Units types at the boundaries of code (writing to driver).
I remember that. I think it was the undefined behavior talk. In any case, they unfortunately didn’t give details. I think my approach avoids that. You can pass a span to a stream’s write function, and the underlying pointer could then be passed directly to the OS write function. And the put member function takes its parameter by reference and then turns it into a span to pass to write. So no copy there either. If you used my stdio_file_ostream and used setvbuf(stream.file(), nullptr, _IONBF, 0) to turn off buffering, that should do it too.
That's exactly the case better served with a variant and a `measure` visitor.
Cool! I've been thinking about SI types several times when I had to program several science-y apps in C#, and wondering how exactly I would implement them in C++. Will definately give it a try! It also appears to me you've got a typo in "Unit containers" section: auto result = a_m * b_ft; // OK. result is 'meter_t' (left-most unit) . . . auto result = a_m * b_ft; // OK. result is 'square_meter_t' (left-most unit) Did you mean `a_b + b_ft` in the first line?
yeah... years are tricky because there's not a single standard, and the 365 day, julian, or gregorian years (maybe more?) can all be "correct" for certain use cases. I chose 365 because my initial use case was for a geodesy library which had parameters in terms of "milliarcseconds per year" where the year was 365 days. However, I think I'll probably add a patch now to include other definitions, and define them in terms of seconds instead of days.
Note that CLion only works if you use CMake
That's true. And I resisted for exactly that reason. But I finally gave in and just drank the CMake Kool-Aid. It's not so bad, once you choke past the magic.
When you have to modify the compiler switch for the project, what do you change? Use the same process to add /MP as an additional compiler switch. What is the command line specified for custom build tool?
&gt; Which ones do you have that boost doesn't _Any and all_. Feet to meter. Radian to degree. IMO implicit unit conversions should be the norm, because they're easy and cost-free, if you are consistent. That said, I never made it past the learning curve/boost dependency upsides before I rolled my own library, so you're probably more of an expert on boost vs units than me. In fact, if I could convince you to try it out in some hobby or non-production code, I'd be very grateful for your input. I've never even heard from a user of `boost.units` before, and your perspective would be incredibly valuable. 
VecOps would already be better. Still nothing perfect, but better.
We're using a .props and .targets file in the project like this: &lt;ImportGroup Label="ExtensionSettings"&gt; &lt;Import Project="mytool.props" /&gt; &lt;/ImportGroup&gt; &lt;ImportGroup Label="ExtensionTargets"&gt; &lt;Import Project="mytool.targets" /&gt; &lt;/ImportGroup&gt; These files specify specific switches and command-line templates for files with custom file extensions. The project only has files in it with these custom extensions, so the properties of the project only has global overrides for our special switches. There wouldn't be anywhere to specify /MP. Does that make sense?
Why do you think it's dangerous?
Because iostreams does ~~unforgivable~~ unfixable things like make their "block device" layer, streambuf, depend on locales. And modes need to die. The block device abstraction should always be binary mode, and the text abstraction should always be text mode.
open a binary only file? it gets a locale. even better, to get the locale requires a lock to be acquired to get the locale. granted its not *that* expensive but it's definitely sign of a poor design. There's also the little issue that iostreams on the text side not providing any support for different grammars which definitely can affect order arguments may need to be presented.
I didn't know you could link Eigen against MKL. I'm sure that would solve any differences. I don't even use much matrix math in my current work. I've been interested in matrix multiplication as a case study in optimization. Particularly interesting that hardware and memory trump asymptotic complexity in this case (e.g., Strassen and all the follow-ups).
What modern C++ programmer would use an undecorated 0? I'm being a little facetious here, but not entirely. You use (decorated) auto when you're rigorously specifying a (generally complex) type in the rhs expression.
I am just going to leave yet another huge "THANK YOU" here. Awesome work!
This is more general coding career advice, but why not find a project to work on *and finish* in your spare time? Even if it doesn't amount to much, showing that you have the initiative and competency to create something practical with an algorithm is a huge plus. And, at the very least, it gives you something to fall back on, if you flub an interview question related to it.
You seem like a smart and knowledgeable guy. Don't worry, you'll find a good job. Just try. If you don't have any projects you can put on GitHub, and don't have any specific ideas (or time) to start one, practice for the interviews and put up a couple of things like a "modern C++" implementation of a tree, linked list, some search algorithm, or something simple from computer vision. Another alternative is to start contributing to some known open source project. Most of them have a list of things for "beginners" to get started with contributing, like OpenCV, but it can also be a smaller project. Show them your strengths in the interview. Are you passionate? I think the combination of having worked in computer vision, graphics, and compilers, is a very powerful one. Good luck!
I have a new Mac book pro, can I have it on the touch bar?
And states. The mix of concern that sees formatting mixed with streaming is already a poor decision (hindsight and all that), but the fact that some formatting changes affect *all* input means that the stream must carry some state around. Which is painful to debug. And mixing concerns again.
I understand your underlying message, but advancing in anything takes dedicating your personal time to it. Self growth isn't something you can usually get paid for, programmers are just lucky enough to have business growth often make a significant impact on their abilities. Just food for thought, I think it's super fun and healthy to spend a little time solving problems that interest you in new areas to stay sharp.
The problem is that like OP said he was in school that he probably had to pay for and that was probably overwhelming enough by itself to dedicate the time that he was not studying/in-school to do anything but work. Advancing anything takes dedication and personal time, I agree, but it doesn't apply here in OP's case.
Ah. Would eliminating that copy, though, be appropriate for this kind synchronous I/O API? Wouldn’t you want to go to an asynchronous model for that?
Lot of speculations and "probably's" in your post. I apologize if Im inferring too much, but, how many interviews have you actually had since looking for a new job? Let them say no, dont do it for them. 
Auto and expression template are a dangerous combo -- it is really easy to evaluate super complex expresssions multiple times with a seemingly innocuous use of auto.
Does anyone know of standard linear algebra type libraries that would work with a dimensional analysis library, like this? The last time I looked into something like this library, I wasn't able to do, say, matrix vector multiplies because y = A * x expects y and x to be th same type, which isn't true for A with dimensions.
Dude, are you my drunk alt account I forgot about? I did games, graphics and compilers. Currently looking for a job and anxious I fail at being senior at anything (including C++, you have that one on me). I'd say, pick a field, study it until you own it? I guess there's nothing else to do between interviews? I'm trying to do that with graphics, I know the theory but I'm terrible at math.
Is there a comprehensive source for reading about the *uses* for fixed-point literals? Also, does your implementation play nice with SIMD types? (I admit I didn't read the code.)
No, but it sounds like a fun follow on project :) if you want to get in touch on github about what a usable, minimal feature set would look like, I don't think it would be that difficult for me to implement.
I hope to have it in Vc 2.0 (which has no release date currently). It is likely that may have to wait for some 2.x, though. However, at this point I can't guarantee anything because my resources are too limited (I'm giving priority to C++ standardization work).
&gt; That would've been my suggestion, using the SSE dot product instruction I guess that the dot product instruction is simply decoded into the microops for scalar multiplications and additions... &gt; How would the calling code look like, that results in the parallelization and speedup? That's why I am a bit confused, that you give an example showing the speedup but it's not actually showing any advantage because you don't show the calling code? That's the problem of a simple / short / basic example. The API design of Vc is guided by full-application vectorization (i.e. horizontal vectorization) and doesn't care so much about local vectorization (typically vertical vectorization). For a larger example see e.g. https://github.com/VcDevel/Vc/blob/1.3.0/examples/mandelbrot/mandel.cpp#L161. Basically, you need to have a program where you have N inputs that need to be processed (mostly) independently but with the same algorithm. Now, instead of processing one input after the other, you process chunks of 2, 4, 8, 16, ... (i.e. `Vc::Vector&lt;T&gt;::size()` many) inputs in parallel. So, if in such an algorithm you require a scalar product, that's where the example comes in.
The pong one was cool, as someone who doesn't really care for that kind of stuff normally. Now I play with my code on goldbolt just to see the generated ASM.
The extent of the zero-cost abstractions was pretty impressive.
Hmm, the mandelbrot example looks pretty ugly. To be honest, I still don't get it at all. So let's say I have a `std::vector&lt;Vec3f&gt;` and I want each of these elements `e` multiplied with a 3x3 matrix `M`. Does Vc help with that and how would the code look like? Or is that still not the "horizontal" vectorization you're talking about?
Talk link: [Jason Turner “Rich Code for Tiny Computers: A Simple Commodore 64 Game in C++17”](https://www.youtube.com/watch?v=zBkNBP00wJE) 
I would think if they were in school they would have some academic projects, but they did say it was a bad program, so who knows.
If you have SIMD hardware there is usually no reason to use fixed point fraction representations, because the SIMD is certainly going to be floating point... and modern floating point is plenty damn fast. But that chip doesn't even have an FPU. Software-emulated floating point routines were a) dozens of KiB in size, and b) slow as balls (at least relative to real-time audio synthesis). It was fixed point or nothing.
Michael Spencer “My Little Optimizer: Undefined Behavior is Magic" Chandler Carruth “Garbage In, Garbage Out: Arguing about Undefined Behavior..."
The point about not as fast as make_shared is true however I think it is a good thing as that means a weak_ptr will not hold the file handle open longer than needed
Videos in this thread: [Watch Playlist &amp;#9654;](http://subtletv.com/_r5a23n3?feature=playlist) VIDEO|COMMENT -|- [CppCon 2016: Jason Turner “Rich Code for Tiny Computers: A Simple Commodore 64 Game in C++17”](https://youtube.com/watch?v=zBkNBP00wJE)|[8](https://reddit.com/r/cpp/comments/5a23n3/_/d9d6a0a?context=10#d9d6a0a) - Talk link: Jason Turner “Rich Code for Tiny Computers: A Simple Commodore 64 Game in C++17” (1) [CppCon 2016: Kenny Kerr &amp; James McNellis “Embracing Standard C++ for the Windows Runtime"](https://youtube.com/watch?v=lm4IwfiJ3EU) (2) [CppCon 2016: Arthur O'Dwyer “Template Normal Programming (part 1 of 2)”](https://youtube.com/watch?v=vwrXHznaYLA) (3) [CppCon 2016: Arthur O'Dwyer “Template Normal Programming (part 2 of 2)"](https://youtube.com/watch?v=VIz6xBvwYd8) (4) [CppCon 2016: Dan Saks “extern c: Talking to C Programmers about C++”](https://youtube.com/watch?v=D7Sd8A6_fYU) (5) [CppCon 2016: Walter E. Brown “What C++ Programmers Need to Know about Header ＜random＞"](https://youtube.com/watch?v=6DPkyvkMkk8) (6) [CppCon 2016: Howard Hinnant “A ＜chrono＞ Tutorial"](https://youtube.com/watch?v=P32hvk8b13M) (7) [CppCon 2016: Howard Hinnant “Welcome To The Time Zone"](https://youtube.com/watch?v=Vwd3pduVGKY)|[2](https://reddit.com/r/cpp/comments/5a23n3/_/d9ddo90?context=10#d9ddo90) - CppCon 2016: "Embracing Standard C++ for the WinRT" Good to see MS embracing Std C++ for WinRT, instead of C++/CX. Simpler Std C++ code beat crap out of C++/CX and C# in perf. Yea! CppCon 2016: "Template Normal Programming (part 1 of... [CppCon 2016: David Sankel “Building Software Capital: How to write the highest quality code and why"](https://youtube.com/watch?v=ta3S8CRN2TM)|[1](https://reddit.com/r/cpp/comments/5a23n3/_/d9dg4y1?context=10#d9dg4y1) - My favourite is CppCon 2016: David Sankel “Building Software Capital: How to write the highest quality code and why" I'm a bot working hard to help Redditors find related videos to watch. *** [Play All](http://subtletv.com/_r5a23n3?feature=playlist&amp;ftrlnk=1) | [Info](https://np.reddit.com/r/SubtleTV/wiki/mentioned_videos) | Get it on [Chrome](https://chrome.google.com/webstore/detail/mentioned-videos-for-redd/fiimkmdalmgffhibfdjnhljpnigcmohf) / [Firefox](https://addons.mozilla.org/en-US/firefox/addon/mentioned-videos-for-reddit)
Not everything in the industry is state of the art work. But in any case, you *need* to know how to apply basic techniques before you can hope to contribute to solving more interesting problems. Look at this from the perspective of a business. They're looking to hire a candidate that they feel can learn quickly, and integrate with their current team. I'm assuming you're not busting on the social side of the interview (which is a possibility), but if you have a masters degree and still can't adequately describe something like the Houghs transform, you're not exactly instilling them with confidence. They have no idea whether you ever even learned it (and your word isn't really enough in that case). You have to meet them at least half way, here. Pick a couple of concepts at least at the level of the problems you have heard come up in interviews, and just apply the algorithm to something. If you're not inspired, it doesn't even really have to do anything than what it says on the tin. Show your prospective employers "I forgot the Houghs transform because it wasn't practical for what I was doing, but it's easy for me to pick up new concepts *and apply them to a real world problem*. Yes, it sucks that you have to go through that to show employers that you're not useless, but, to be blunt, your one advantage right now over typical candidates is a Master's (which I've seen usually substitutable for ~5 years of specialized work experience) and you're unable to show them that you learned anything. They're just not going to take that risk. TL;DR you're asking employers to take a risk on you for no benefit
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/5a45hk/help_with_importing_text_into_2d_array_with_ints/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Yeah I was so jealous how optimized he was able to make his code. I want to be able to write code that sticks to all the tricks but I know what's going to happen is I think I'll be doing it right but I'll do something that compilers can't optimize and I'll be like "Why does my code suck from a performance perspective really wish my compiler told me the dumb things I was doing" To which the response is along the lines of "Well if the compiler knew about optimizations it would just do the optimizations" I'm like well shoot man I don't know what the compiler wants, the compiler just does what I tell it to do. Then I just end up with the bad performing code again. It's a vicious cycle ):
[Using Types Effectively](http://www.elbeno.com/presentations/using-types-effectively/presentation.html#/slide-orgheadline82)
Programming C++ is hard enough that simply being excellent in C++ should be enough to get you a good job. Seriously. If you find otherwise then either your C++ is not excellent, or you are applying to the wrong places. Most people on the job market don't even have a solid grasp of RAII. Let alone asking them to do some basic task with variadics. Knowing a domain well is helpful but it's really not necessary. I've seen tons of C++ devs move between games, tech, and fintech. The domains often don't overlap, and even when they do the considerations are often so different that only a moderate subset is applicable. Why can they move so easily? Because they're smart guys who understand C++ and know how to use it to write solid code that will work. People who understand something like computer vision or machine learning at a very high level, and also have professional level chops in C++ and software engineering are incredibly rare. I've met many people with one or the other but almost nobody with both. You should not feel bad you are not in this elite company. 
It's a design tradeoff. If you use the identity function for your hash, then you might save a few cycles, but you make it very easy to stumble into worst-case O(n^(2)) behavior. For example, if all your keys are even then you are effectively leaving half of your hash buckets permanently empty. And it just gets worse from there, for example if your keys happen to be multiples of 32 then you might end up with all the values in a single hash bucket if the size of the table is small. The hash table is only going to use the lower bits of the hash value, so you're effectively throwing away all the useful information in the upper bits by using the identity function as your hash function. By having an actual hash function that mixes everything up, the resulting low bits of the hash reflect in some way the entire value of all the bits of the keys. This doesn't guarantee you won't get into a pathological situation, but it makes it a lot less common. 
What is the probability of collision when hashing a integer? Virtually zero?
The chance of collision is always going to be a function of the size of the hash table. If the size is 16, then the best you can ever hope to achieve, using the best hashing function in the world, is one in sixteen. But the point is that if you don't use a hashing function then it becomes much worse than one in sixteen, since you aren't mixing in the contribution of the upper bits, you're only using the lower 4 bits of the key verbatim as they come from the application. And applications don't always use nice uniformly distributed keys. For example on Win32, all kernel handles are multiples of 4, i.e. the lower 2 bits are always zero. If you're using a `std::unordered_map` to map handles to some data structures, then if you didn't use a hash function then you'd be cutting the effectiveness of your hash table by a factor of four. For example if it's currently size 16, it acts for the purposes of collisions as if it's a table of size 4 (i.e. a one in four chance of collision as opposed to one in sixteen.)
It seems that you are right. Identity function is having a worse lookup perf now after I increase the element count from 1 million to 10 million 64 bit Performance impact of VC++ std hash versus no_hash std hash:insertion: 4382ms no hash:insertion: 3660ms std hash:lookup: 605ms no hash:lookup: 1034ms 32 bit Performance impact of VC++ std hash versus no_hash std hash:insertion: 3983ms no hash:insertion: 3404ms std hash:lookup: 506ms no hash:lookup: 854ms
It's impossible to answer a question like that without a testcase. And `&lt;cmath&gt;` does not declare `std::min`, that's `&lt;algorithm&gt;`. There's a chance you were using something non-standard, e.g. the Win32 headers define `min()` as a macro (which is evil and bad and you should define `NOMINMAX` if you have to include any Win32 API headers to prevent that.) All the more reason that a testcase (and a description of the compiler, platform, etc.) is necessary. 
Alright, I'll go back and figure out whats what
Oh ugly
Probably between compilations. /s
Yeah. In the STL, I threw FNV-1a at everything because it's a moderately fast way to jumble up bits real good. People keep asking for identity non-hashes but I am not convinced, for the reasons you mention. We'll probably revisit the hash algorithm in the future, but I don't think we'll choose identity.
I was confused by your naming of "std hash" and "no hash". They're both in std library, but with different implementations, so you should label them i. e. as "vc++ hash" and "gcc hash". 
No hash refers to this identity hasher function used for unordered_map struct NopHasher { size_t operator()(const size_t&amp; k) const { return k; } }; The benchmark source is below. [ShortCircuitUnorderedKey.cpp](https://github.com/shaovoon/almost_painless_tips/blob/master/Projects/ShortCircuitUnorderedKey/ShortCircuitUnorderedKey.cpp)
I've found watching them at 1.5 times speed is perfectly feasible
Tiny quibble - why pass a reference? Sure, there's a decent chance the compiler will optimize it out, but why not just go right to pass by value, since it's a scalar anyway? struct Identity { size_t operator()(size_t k) const { return k; } }; 
Don't know the historical reason. An identity type trait appeared briefly in C++0x (for std::forward) before being removed. VC's STL has a combination functor and type trait, but I'm trying to remove it - the function call operator makes the type trait unusable, and the function call operator's signature isn't transparent.
&gt; It's easier to just provide a different function object that works on actual integers. There's pros and cons to each method I guess. Specializing `std::hash` would make your tagged integer have its own hash with whatever it's used in without your intervention. Might be useful for libraries and such.
Your video offers no practical guidance in terms of how to set up your slides. Regarding presentation of code, specifically, I would suggest the following: * Avoid syntax highlighting because you don't know projector characteristics and some colors will be almost invisible; I've seen it tons of times at people's presentations and it's annoying. The only highlighting I think is OK is when keywords are **bold** and even this I wouldn't necessarily recommend. * Use condensed fonts like [PragmataPro Mono](http://www.fsd.it/shop/fonts/pragmatapro/), TheSansMono Condensed, and similar. Yes, these fonts are commercial and cost $, deal with it. * Think about how harmony between text fonts and code fonts. I know a few pairs (e.g., Myriad+Consolas) which are perfectly harmonious. Disharmony between monospaced and sans fonts is annoying. * PowerPoint isn't great for graying out, and doesn't support kinetic typography. * PowerPoint doesn't support ligatures which I'd encourage everyone to use because they are 100% focused on aiding readability. Some general advice: * Ensure you use adequate font weights; there are plenty of excellent, but unfortunately, very thin, fonts which are not too readable, especially from a distance. * Make slides using sans-serif fonts. I am yet to see one example where serif fonts and look any better than sans serif. Let's just say, even 1080p projectors don't have enough resolution to show pretty serifs. * Ensure that fonts on your slides are AS BIG AS POSSIBLE. It is really easy to put tiny fonts because they look good on your 4K screen and then have viewers squint. * LaTeX formulae look *terrible* with default fonts. If you need to show formulae, consider using *at least* something like Adobe Garamond. If using PP, Equation Editor uses sufficiently thick fonts (also goes well with Chapparal). Regarding kinetic typography: we need some equivalent of [Manim](https://github.com/3b1b/manim) but for code. Preferably not in Python. 
thanks for the critique, but I only had 5 minutes, and wanted to cover the points Scott Meyers highlighted in his keynote in 2016. Probably preparing a longer version for Meeting C++, if I find the time. Also tools used to present are very different, so I did not want to go down this rabbit hole. And yes, stuff like graying out etc. is work in Open Office or Power Point.
While you have some good points, this is not entirely correct. The hash function you pass to the container is not the effective hash function. The effective hash function eff_hash() is: size_t eff_hash(const T&amp; val) { return std::hash&lt;T&gt;()(val) % capacity(); } The last part is important as it selects the bucket the hashed value will be stored in. Traditional hashtables have capacities carefully selected to be prime numbers. In those cases the identity hash function is not so bad because a number mod a prime gives a reasonably uniform distribution of hash values. More modern hash tables use power of 2 capacities. In those cases % capacity() means take the log2(capacity()) least significant digits of the intermediate hash value. For those type of hashtables the identity hash function is indeed a bad choice. Some suggestions below talk about FNV. Don't use FNV. It is too expensive and not so great at scrambling the bits of the input (or more precisely it does not fare well on avalanche tests). Two good alternatives are: Knuth style hashing, which does not fare very well at bit scrambling like FNV but it is super fast (2-3 cycles on modern x86): size_t hash(size_t val) { // You can use any other large odd number. // Some are better than others - see link below. return bswap64(val * 0x7fb5d329728ea185)); } Or murmur3 style hashing, which fares very well at bit scrambling and it is faster than FNV (11-12 cycles on modern x86). The basic version is: size_t hash(size_t val) { val ^= (val &gt;&gt; 33); val *= 0xff51afd7ed558ccd; val ^= (val &gt;&gt; 33); val *= 0xc4ceb9fe1a85ec53; val ^= (val &gt;&gt; 33); return key; } It can be improved a bit by selecting constants as described in this [blogpost](http://zimbry.blogspot.ch/2011/09/better-bit-mixing-improving-on.html).
I'm actually somewhat appalled by libstdc++ for using identity "hashes."
Came here to point this out. Excellent explanation. 
It's possible to implement fnv1a using a constexpr. Does or could the STL take advantage of this when constant expressions are used as keys?
This is why I came here!
Do not bother. It is based on Ubuntu 14.04. Just install Ubuntu 16.04 on your Win10 Hypervisor.
Google fresh-grads jobs ask for too many languages to be seriously interested in any of them: "whatever, java, c#, python, c++.. strong computer science to cut to the cheese".. and yet they really don't care for your C++ skills (basic C++ will get you through all of their interviews, the problem is nailing the questions in a VERY QUICK way.. and I'm not fast enough for that). I could say I'm having problems demonstrating I'm a "smart guy" with few experience if I'm not a topcoder champion.
Thanks, I often think of writing something for others to read and learn (the modern C++ implementations of algorithms could definitely do) but this also falls into the problem I expressed in other posts: I find this rather useless. STL provides us with top-quality algorithms and data structures, reinventing the wheel is depressing. I contributed to some opensource projects but I eventually stop since I feel I might be *stuck in a project/field* while other fields might be more productive. Plus it's also hard to showcase your works in a github-fashion when you're contributing to, say, openCV. It'd be a better world if we had less js frameworks and more openCV contributions, but I'm often afraid to "lose part in the scene" with blog posts and such.
You lack experience; _anything_ didactic is useful _to you_, by definition. TBH you sound like a naive high-school kid &amp;ndash; "Math is so boring! I can't wait to be done with school and have a job as an engineer." ^;-]
No, `c` cannot be 8 bits. The standard mandates minimum widths for built-in types. 
You have a thread full of people telling you that having experience &amp;ndash; and better yet, _proof_ of experience &amp;ndash; will contribute heavily to getting a job. _Experience_, not studying. Literally work on something and it cannot be a waste. Having proof that you have the resolve to see something through to the end, _especially_ when it's boring, it worth a **lot**. On the other hand, having no portfolio because you thought you might get bored will _also_ tell your prospective employer a **lot**. ;-] /u/sumo952's stupidly-downvoted comment is spot on: man up.
8-bit platform
... would still need to have `int`s of at least 16-bits, as mandated by the standard.
My company guideline is to always pass input (POD) parameter by const ref. I have benchmarked passing const integer by reference and passing by value (long time ago using VS2008): There is no difference.
Besides the Charles Petzoid and Jeff Prosise books, read MFC tech notes (https://msdn.microsoft.com/en-us/library/a5skz46c.aspx), particularly 3, 6, 21, 22, 25, 26, 33, 60, 61 and 62. Then step into MFC's source code when debugging its samples (https://www.microsoft.com/en-us/download/details.aspx?id=16351) to see how MFC does everything. This is the way I learned MFC back in the 90s.
Think u just need to call WinHttpSetOption with WINHTTP_DISABLE_REDIRECTS in a windows-only #ifdef
Check this out: [http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) I'm reading [Programming -- Principles and Practice Using C++](http://www.stroustrup.com/programming.html) right now and like it so far. Great book. Create account on [https://www.hackerrank.com](https://www.hackerrank.com). 30 days of coding is a great start to keep you coding. Join #c++ on freenode. People there are super nice and helpful.
I found cprogramming.com and of course cplusplus.com to be excellant resources. And as was stated above, hackerranks 30days of code is excellant for not only learning, but giving you one project a day to conquer. I found when I was starting a lot that slowed me down was lack of ideas of what to code. 
I recommend watching Casey Muratori's intro series of Handmade Hero. He uses a limited subset of C++ rather C-like, but in my experience that's a really good way to learn. C++ just adds a ton of features on top of that which you can dive into once you know the basics. https://hero.handmade.network/episodes
Watch Bjarne Stroustrup's lectures. He made the language.
Can you add following hash function to comparison? #include &lt;x86intrin.h&gt; std::size_t hash(std::size_t val) { #if defined(__x86_64__) return _mm_crc32_u64(0, val); #elif defined(__i386__) return _mm_crc32_u32(0, val); #else #error #endif } It have avalanche effect.
Thanks :-D @OP: We're not talking about a year of studying at all here. A few days, weeks, maybe month (not full-time at all) of **working** on something and having an output (for example on your GitHub) is what I mean.
Implementing a sorting algorithm or binary tree or whatever is far from useless. Yes of course it's there in the STL, and you wouldn't end up using yours in your own project, because the STL one is better. But having knowledge of these core CS principles is just required knowledge for an interview, and in the end it's not wasted time because it'll make you a better programmer and thinker by doing that exercise, for **any** field. I might be a bit naive on this one but having OpenCV contributions is something I think you can showcase in your CV/GitHub. Of course the interviewer will ask you (or if he doesn't, you should tell him) what _exactly_ you contributed, and then you can start talking about something that you're really familiar with and also has practical use. Also it shows that you're showing effort and motivation on your own and are capable of doing something of your own (which you seem to have trouble with, as evident from this thread).
Yes, and they are actively developing it. The best start page for information is probably their repo: https://github.com/Microsoft/BashOnWindows. It links to UserVoice, blogs, etc. Also, if you look through the Issues you'll see that people are actively trying to stretch the limits of what's supported. For example, there's an issue where someone is trying to get 16.10 to run. 
&gt; Waiting a few years is probably better for everyone. Hint : it's only going to be worse. People want their shiny little app to be different from all others, and companies (Apple, Google, MS) want their in-house GUI toolkits the most possible incompatible with other GUI toolkits to enforce vendor lock-in.
You're probably seeing the effects of traditional compiler optimizations in the back-end, instead of constexpr evaluation in the front-end. (As I understand it, the FE doesn't care what optimization level is being used.) I'm not an expert here, though. I wouldn't expect anything to change in the Standard. However, you can force constexpr evaluation by adding a mandatory layer, e.g. going through integral_constant. `meow(args)` is just a function call that might or might not be eagerly evaluated, but `integral_constant&lt;T, meow(args)&gt;::value` is a compile-time constant for sure.
It's coming in C++17, after make_shared and make_unique.
I believe that eventually these platforms will all result in very similar user facing designs (per screen size and input type). Internally yes they'll all have terrible APIs but they'll look an feel mostly the same the way desktops do now simply because the better, easier to use designs will win.
+1 to your post. And the link to the JS blog-post you posted is gold. Absolutly fantastic. At this point I'm so glad I'm programming C++. I thought we had it bad with our build-systems and non-existing package managers :-)
Nice summary. I've become convinced that the std::lib implementor is the wrong place to choose the hash algorithm because there is no one-size-fits-all hash algorithm. And the current `std::hash` infrastructure is insufficient to allow the client to choose a hash algorithm. This talk outlines infrastructure that allows the programmer to choose, and easily switch between arbitrary hash functions: https://www.youtube.com/watch?v=Njjp_MJsgt8
constexpr variables are also supposed to be statically initialized, but I am less clear on the rules there (this is not something that the STL especially cares about).
Love this, as a college senior who's job searching, it's depressing to get asked something so useless and then judged on the given solution instead of the analysis. 
&gt; Waiting a few years is probably better for everyone. This has been the standard reply for around 3 decades now. I beg to differ. I don't think the situation is going to improve until or unless somebody puts effort into improving it (but I'll openly admit that it will be a *huge* effort).
Just because you and I had to start learning C++ with the C++98 standard, doesn't mean beginners today should. What exactly do you mean anyway? Are you saying beginners shouldn't use std::vector? std::map? std::unique_ptr? Should beginners learn to use C arrays instead of std::array? How about using new/delete? malloc?
Link dump: * https://github.com/vhf/free-programming-books/blob/master/free-programming-books.md#c-1 * https://github.com/open-source-society/computer-science (not C++ specific, but valuable) * https://github.com/fffaraz/awesome-cpp#videos * https://github.com/fffaraz/awesome-cpp#websites * https://www.youtube.com/watch?v=Rub-JsjMhWY (I like this guy's tutorials, some people don't) * https://www.sololearn.com/Course/CPlusPlus/ (only learned about this recently and haven't fully tried it, so be skeptical) * https://www.udemy.com/free-learn-c-tutorial-beginners/ (haven't tried this course, but it's got a lot of good reviews and is free) * http://www.learncpp.com/ (this is on [/r/learnprogramming's list of discouraged resources](https://www.reddit.com/r/learnprogramming/wiki/index#wiki_discouraged_resources), but I think certain parts of it are decent) * https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines (guidelines from the ISOCPP group about writing good C++, but this requires knowledge of C++, so save this for later)
Thanks a lot. 
Good to hear! Thanks for your work!
FYI, I got an update, in case you were still curious.
Regarding the stack-based queue. The author states that the complexity - presumably of pop() - is O(n^2). Looking at the code, worst-case it's O(n) on the first pop(), and amortized O(1) over several pop() calls.
It's usually to see how you react. A lot of people will just go up to the whiteboard and start shitting code on it. If I were interviewing someone, I'd view it as perfectly acceptable for a candidate to point out to me that some requirement of my interview question is odd, ambiguous or inefficient. Ready for it, in fact; "Uh yeah... in this version of our compiler, we only have queues *shrug*. You can thank Steve for that." After all, at some point your customer is going to ask you to do something stupid and you can either wander off without comment and build something stupid, or you can work with him to make sure that you build what he really wants. It's ambiguous from the blog what the actual question was. I'd guess the interviewer was trying to see how the guy would handle implementing a LIFO stack if he can only push to the back of a data structure and read from the front. If that's the case, it wouldn't be terribly difficult to write an object that has a queue as storage and have your add recursively pop all the objects off the queue and re-add them in the correct order. Adding an object would be fairly expensive and would risk blowing out your program stack, but pointing that out would actually get you more points with me than writing the code to do it. Also seems to me like the guy in the blog really wanted to shoehorn a ridiculously complex template metaprogramming solution into what should be a fairly simple problem. That would raise huge red flags with me if I'd done the interview. But I suppose that's why I don't interview people...
Sorry, I should have [linked to it](https://www.reddit.com/r/cpp/comments/58gtd5/c0x_standard_library_wishlist_2005/d9em5ji/).
Having learned at a time when it was not available at all... *GOOGLE*!!
Thanks!
Nice! So it's only going to be formatting part of fmtlib? Will the printing part come later? Would be pretty sad, if instead of `std::print("Hello, {}!", "World");` we'd have to do `std::cout &lt;&lt; std::format("Hello, {}!", "World");` with all (though less) the drawbacks of iostreams and also passing std::strings around =(
I'm saying it helps tremendously to learn how stuff works, in general. Implementing one's own vectors and whatnot, to get the hang of how memory is laid out in different data structures, and how it is accessed. What the difference is between new/delete and malloc/free, what is vtable, all the nitty gritty things are pretty important to know so that you know absolutely how your program works. Knowing how C array works helps _understanding_ the abstractions you rely on. It's not about forcing anyone to learn "the hard way" just because people in the past have learned that way, I'm saying that learning how the computer actually works when you're executing your programs, that's more important than any modern abstraction, because that is the true basic fundamental knowledge. Although I agree, if you want to just learn modern C++, there are surely good resources for that, but I got the feeling OP doesn't have the basics mastered yet, and that's what I'm trying to advise on.
Yet, the goal of the question seems simple. It is to determine if you've been asleep in your algorithm and data structure class.
&gt; Waiting a few years is probably better for everyone. Qt6, shh...
People keep getting the wrong idea about what the point of interview questions is... The idea is to try to understand a prospect's ability to think within a set of constraints and code around to a solution. That objective is hampered when the problem is one that the prospect has already done before, so it can actually be quite advantageous to present "stupid" questions, because they are disproportionately unlikely to have been previously solved by the candidate. That said, the question isn't *quite* as absurd as it actually sounds. It's not unusual to have to work from a set of primitives that don't precisely match the problem... if you actually had primitives that matched the problem, there'd not be much software work involved. ;-) Actually, the more I think about it, the more it seems like a pretty good basic question. The solution would be pretty quick to code up; it allows for follow up discussions about recursion, computational complexity, exception safety, memory management, prefect forwarding, and even thread safety; it also opens up discussion about why it is a stupid question.
You say that like it is impossible to provide context during the interview.
I don't think this is the all time best interview question, but it's really not as bad as it's made out to be here. Assuming the candidate hasn't heard it before, it will require: - only basic knowledge of data structures, which is good as this knowledge should be universal amongst programmers - It requires knowing how these things work well - It requires some creativity and thinking outside the box, precisely because this isn't something sensible to do - It requires some knowledge of big O. Notably, the blog poster kind of misses that implementing a queue with two stacks actually has amortized constant operations and scales reasonably well. - there's an interesting fundamental asymmetry in the problem: a good queue in terms of two stacks, is much easier than the reverse. This is because stacks naturally reverse the order of their elements. So two reversals leads to in-order. A good candidate could pick up on this point. These criticisms are always the same, and always have some flavor of: why not ask things that you would do on the job? And of course, you should try to, to some degree. But it's not easy. Most interesting problems I encounter on the job require an enormous amount of background knowledge to frame the problem. This background knowledge is often extremely specific. Good fundamentals, intelligence and creativity are reasonable criteria to filter people on (especially in early rounds), and I think this question does a reasonable, if not amazing job doing that.
How did it go?
Yeah, I'm just a bit confused by the line of reasoning. So what if a particular version of a particular compiler happens to generate X instructions versus Y instructions in debug mode for a trivial test case? This seems like it should be way down the list of priorities when deciding whether/when to use a language feature. Even if debug mode performance was important (and to me it is not), it is hard to extrapolate anything meaningful from measuring the # of instructions for such a simple example.
Proof? I will find that bob!
Ya, I'd try to focus on pumping out at least a couple of implementations of masters-student-level algorithms in the area you want to specialize in. It might be rough, if you have to basically relearn the entire concept, but at least you'll have something to show. It does suck that you have to do more work just to catch up, but it's best to fix it now than to stagnate career-wise.
Honestly I'd ask for clarification if they really meant a queue or if they meant any container. Asking people how to implement a solution to a problem that is easily/most obviously done with recursion, without recursion is common in my experience. Usually if a candidate nails a question with recursion I'll follow up with, "cool, what if your stack space is limited and you can't use recursion, any ideas?" Basically asking to see if they can reproduce recursion using a stack container that stores elements on the heap instead. If they actually wanted you to do recursion using a proper queue (no direct access to the bottom or popping from the bottom) then I'd probably just sigh and ask if pseudo code is ok :p
Queue-from-two-stacks is actually a standard data structure in systems with no mutable state (a stack is easy to implement efficiently without mutation: push() creates a node for the new element with the "next" pointer targeting the old stack, and pop() basically just returns the element and pointer from the first node). I.e., this is the way you would implement a queue in Haskell or Erlang. Neither queue-from-stacks nor stack-from-queues makes a good interview question, especially over the phone, but "good interview question" is, itself, a hard problem.
* API for mouse buttons (2, 3, 4, 5 etc. button mice) * API for keyboard (different layouts, scancode, keycode) * API for output displays (resolution, dpi, colors etc). What if we decide to start using non-rectangular screens in the future? * API for triggering system sounds * API for touch vs press vs future input method * API for images These are just *some* of the things (I just thought of) that *must* be available for use in anything other than toy projects. You can't predict what new GUI technology will become relevant next. The standard would have to change often to account for it. If that is the case, then such an API doesn't belong in the standard. What we all need to do is create a library/framework that takes care of all of the above for you, but only for a few platforms that you generally need GUI applications for. And we should name it Qt.
Thanks JT! A link to part 1: https://www.youtube.com/watch?v=my39Gpt6bvY
As a react and analyze type of interview question, I have no problem getting into discussing the pitfalls etc, it just shouldn't go beyond that.
I was hoping someone would post this -- this is exactly what OP was asking for.
Yeah, I think that after a decade of everyone thinking that anything that wasn't object oriented was just bad, we've finally switched to realizing that it's not without costs (both in readability and performance) and sometimes it's useful but often we can just use functions or generic programming instead. It's become a tool to be used when it's useful rather than the must-use methodology.
if it works well and has a reasonable price, sure
On Intel Xeon CPU E5-650, clang version 4.0.0 (trunk 282683): user@ubuntu:~$ clang++ -std=c++14 -stdlib=libc++ ShortCircuitUnorderedKey.cpp -O3 -m32 -march=native -DNDEBUG=1 -o /tmp/32 user@ubuntu:~$ clang++ -std=c++14 -stdlib=libc++ ShortCircuitUnorderedKey.cpp -O3 -m64 -march=native -DNDEBUG=1 -o /tmp/64 user@ubuntu:~$ /tmp/32 std hash:insertion: 7455ms std hash:lookup: 1328ms no hash:insertion: 9165ms no hash:lookup: 3468ms crc hash:insertion:11664ms crc hash:lookup: 5871ms user@ubuntu:~$ /tmp/64 std hash:insertion:11446ms std hash:lookup: 1459ms no hash:insertion:10317ms no hash:lookup: 3692ms crc hash:insertion:15222ms crc hash:lookup: 6756ms Not too expensive (not orders of magnitude).
Thanks for the video! I've been having trouble understanding what "lea" does and never understood it no matter what. This was by far the best and easiest to understand explanation of my most dreaded instruction.
It doesn't have to be so comprehensive. Trying to do everything but the kitchen sink is not what should be in the standard, and the basis of GUI are already pretty established in the same way that files were when C came around. The standard C and C++ IO APIs don't account for the notion of file access, or directories, or file systems or anything more advanced than opening, reading and moving through a file descriptor. If you need anything more advanced than that (and plenty of applications do) you either go to your Operating System or some external library. And that's fine! Hell, Java did that 15 years ago and even if you won't write a FULL application using Swing, it's nice to at least know you can default to it to simple applications. It sucks, but it's better than nothing. Give me a Graphics Library that can: * handle input from 2 buttons + scroll button. * Draw rectangles, archs and bezier curves of any 32-bit RGB color in a canvas * Load basic bitmaps to the screen * Draw and receive basic input from windows, buttons, canvas, sliders, toggle buttons, text-areas, menus, pop-ups, text selection and rich text display. Hell, we could even add the opengl to the standard as it's widely supported. It may be useless in a system without a graphics card, but it covers 99% of the computer devices in the market today.
Of course, the real question is the complexity of pop() in a stack&lt;T, N&gt;. Without thinking too hard, I guess amortized O(N), or O(1) in terms of stored items?
X's core architecture has no controls per se (Xt is a bonus, not core), and is completely unsuitable for how high-performance graphics are done today. You want "simple" retro controls, use Tk. It's been around for a long time and is the dinosaur you so dearly desire.
I don't desire it. I just think even such dinossaur would be useful in the standard over nothing. Python uses TK and does fine. Nobody writing a serious GUI application in python would use it, but it's there for simple stuff. By the same logic, the standard shouldn't have a standard IO api, because it's completely unsuitable for how IO intensive applications are done today.
&gt; Ubuntu 16.04 (already is in Insider builds) Cool! Thanks for mentioning this!
&gt; I'll use a simple or double linked list. Except that I can construct workloads for which that will very likely perform much worse: for (auto i = 0u; i &lt; 10000000u; ++i) { queue.push(i); } for (auto i = 0u; i &lt; 1000000u; ++i) { queue.pop(i); } for (auto i = 0u; i &lt; 10000000u; ++i) { queue.push(i); } for (auto i = 0u; i &lt; 19000000u; ++i) { queue.pop; } If the stack is implemented on a `std::vector` or `std::deque` I have a hard time imagining that your linked lists are anywhere near as fast.
Most of my projects compile and run on both platforms, but I just use Sublime Text + batch/bash script for compiling. I would suggest you try to compile at least one program/example via the command line, even if you switch to an IDE afterwards. Visual Studio has a lot of features, which is good but might be intimidating at first. If you choose DevC++ you have the same tool as your teacher and it will be easier for them to help you if something doesnt work (if your classmates use DevC++ as well they will be able to help you too). I have't used XCode for C++ so I can't comment on that.
I do all of my coding on Linux, but Mac being UNIX would be a very similar experience. I would either go Mac or Linux in your situation. I would suggest using a plain text editor, such as sublime (I personally prefer Vim, but it takes awhile to get used to) and compiling through the terminal.
&gt; Do you want to learn C++ or an IDE? Not to brush off the suggestion, but this is a bad argument. By that logic, one could also ask "Do you want to learn C++ or the command line [interface of the compiler]?". 
Yes and no. At the initial review (which unfortunately I was not able to attend), the LEWG took the position that giving programmers the ability to supply their own hash algorithm would be reckless. Only the std::lib implementor has such skill. Fortunately that view no longer exists. Geoff Romer proposed http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0029r0.html which takes elements from http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3980.html such as enabling the client to supply a hash algorithm. However imho P0029 makes it overly complex/difficult for a programmer to plug in an existing hash algorithm into the proposed infrastructure. There has not been any movement beyond P0029. I haven't had cycles to put into it. However I would like to write a revision of N3980. I believe N3980 was overly verbose and thus failed to clearly communicate what was being proposed. Additionally the committee expressed the desire to create customization points such as `hash_append` along the lines of Eric Niebler's suggested design: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4381.html
Fair enough, I misunderstood your point then.
&gt; Which is really stupid, because that the only times in your career where you have to come up with solutions like you were defusing a bomb. Actually, some workplaces are like that. You can only expect bad decisions in an scenario like that, but nevermind, you'll have to live with the decisions they made while defusing the bomb, and God forbid you to suggest that the whole thing is a trainwreck, that's just bad attitude.
[Image](http://imgs.xkcd.com/comics/standards.png) [Mobile](https://m.xkcd.com/927/) **Title:** Standards **Title-text:** Fortunately, the charging one has been solved now that we've all standardized on mini\-USB\. Or is it micro\-USB? Shit\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/927#Explanation) **Stats:** This comic has been referenced 3750 times, representing 2.8113% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_d9gzjxc)
[Never ever ever ever ever do time calculations yourself.](https://youtu.be/-5wpm-gesOY)
I would strongly recommend Visual Studio on Windows. VC++ debugger is really really superb and very well integrated into the IDE. And you will *need* the debugger when you are learning C++. You will end up exceeding array bounds, getting off by one errors, etc, etc. The ability to quickly set a breakpoint and single-step through the code is extremely useful to figuring out where your logic went wrong. Now, you can do the above in Linux too, but there is really no need. Learning GDB and the vagaries of Linux command line simultaneously with C++ is an extra burden which can and should be avoided. You are learning C++; you should focus on learning C++. You can always learn how to use GDB later. 
Lol! That was fantastic!
Also: https://www.udemy.com/powerpoint-kinetic-typography/ and https://www.youtube.com/watch?v=9NJEs3Piqjk Maybe not the blending between different letters as demonstrated by 3b1b but still looks intresting.
Imagine if old-school 16 bit style Win API or classic Mac Toolbox API's has been standardized as the official spec for GUI development in C or C++. There was a time when they seemed like stable, mature targets in a world that was no longer changing very much. It would be terrible. We'd still be dragging along that baggage, long after the originating vendors had vastly reworked or abandoned them and everybody had moved on to other, better things. Qt is releasing significant new features with every iteration, and the influence of mobile dev and declarative UI stuff has changed their framework a lot compared to the older Qt 4.x that seemed relatively stable/complete for desktop GUI work. GPU's have changed a lot of the assumptions about optimal ways to do things compared to a few years ago, and OpenGL is being changed to Vulkan as the highest performance cross platform way to access those GPU's. I really disagree with the idea that standardizing GUI stuff would be in any way an improvement, at least for the forseeable future.
Guy I worked with a couple of companies ago told me he almost lost a satellite once because he logged into his account rather than the navigation one, and uplinked some commands with times. He had his account time zone set up for MDT instead of GMT and ended up orienting the satellite such that its solar panels were not oriented correctly with the sun. Said it took three days to sort it out and fix the orientation. There's a whole chain of bad programming and bad process in that story that could have been broken anywhere along the way to prevent the potential loss of a $100 million corporate asset, but no one ever actually bothered to take the steps necessary to do so.
!removehelp
Actually Howard Hinnant's work is extremely amazing, and some of this stuff may very well end up in the ISO C++ standard. He is the guy behind `&lt;chrono&gt;` I believe. 
Well, the beauty of it would be to have a std way to do this across all modern codebases without custom hacks, and hoepfully, with first-class compiler support with faster compile times)
I'm getting a little tired of this being posted every time someone tries to make something new. Especially when people end up missing the tongue-in-cheek nature of the comic. (Why build the Web when we have Gopher? Why use ASCII when we have EBCDIC?)
Thanks! I’ll take a stab at that.
I watched this talk just after I finished writing tz.h. Loved it! I carefully recorded each complication to make sure I had _some_ way of dealing with it. Sometimes that way of dealing with it is to tell the client: "Sorry!" :-) Fwiw, for 2016 Egypt is 2013's Libya. They pulled the same stunt (3 days notice). This lib deals with that by making it easy to upgrade your IANA database as quickly as IANA does (instead of waiting on your OS to upgrade it). For those worried about disk space, the IANA database takes 941,013 bytes on my disk (ymmv).
&gt; Async file i/o is more work than sync file i/o Depends on your platform and how big the I/O is. I have been told^1 that on NT all I/O is asynchronous, and that synchronous I/O is built on top of asynchronous by allocating an event to wait upon associated with the file handle. ^1 : at least, that's my understanding based on https://blogs.msdn.microsoft.com/oldnewthing/20121012-00/?p=6343/
Actually, ASCII predates EBCDIC. OS/360 was originally intended to use ASCII, but they didn't have ASCII-capable hardware (card readers, punches, printers, etc.) available by the release date, so shortly before the release date they invented an extended version of their existing BCD code as a stop-gap (and still haven't quite gotten around to fixing it).