&gt; unordered_meow ?
We never meow in order.
5 days! To say I am somewhat excited is an understatement :)
Hearing from him that there are known flaws in the implementation of C++98 features that they're not actively even planning to address &lt;for VS2015&gt; makes me unhappy though. And I'm not talking about export templates.
Thank you, it works, but I'm afraid my Haskell proficiency is too low to do the required modifications.
Thank you for a great response, and all the hard work. Just curious, in the future when Expression SFINAE is available in the compiler will you be revisiting this with a mind to simplify the implementation where possible, for example with the need for the helper classes mentioned? I can only imagine how nice it must feel to see these workarounds disappearing after having spent so much time with them (remembers _VARIADIC_MAX). Keep up the good work, I'm looking forward to what's coming down the line next.
It should be possible to simplify the logic, although simplifying correct code is lower priority than fixing broken code or implementing features. I'll have to add Expression SFINAE support to std::function's ctors and result_of, so I might have time to redo invoke() then. It shouldn't be very hard, and I have *exhaustive* test coverage written during the overhaul.
`std::function` is so pretty now! If you're looking for human sacrifice, see iostreams in aisle 27.
I've been spamming all subreddits where this has been posted: you don't even need to do the translation by hand. Check out [MetaFun](http://gergo.erdi.hu/projects/metafun/) for a Haskell(-like) to C++ templates compiler.
I agree that it is an important feature, but one should understand that MSVC doesn't have an AST for multiple reasons, including performance and memory consumption. Moving the front-end to be "AST"-based is _a lot of error-prone work_. So while I consider this feature to be very important, I can certainly understand that they prioritize multiple other features that require less work and that might have a larger impact on the users.
As you might have seen I've just ranted about the state of C++ Http request libraries. Your's looks nice though it would be really awesome if response.body was an ostream or similar and the same for request bodys. As I mentioned in my post this seems to be really hard to do the way libcurl works because of it's nature of driving the connection when most Http libraries I like get driven so to speak. To be honest I really love the way things work with Go's http package, though the way it combines async with the model of blocking reads only works with Go's M:N green threads. However seeing as I can easily run thousands of threads on my Linux Laptop without much hassle or slowdown and rusts move to 1:1 threading I would love to see a c++ http library with a synchronous interface, Poco seems close but that thing is huge.
The problem isn't so much with the JSON Parser, rapidjson has a SAX interface too. Also with Jackson JSON in Java there is a really low interface where one uses only the tokenizer which is what I do in Java. The problem is that libcurl drives the blocking reads and then calls back at the code using it with whatever it read. This runs counter to what you need to implement a stream, there one needs to block the current thread when there is no more data thus one needs to be driving the reads. The only way I see to do that with libcurl is using another thread and something like rendezvous where the libcurl thread gets blocked when no one reads the data it has and the reading thread gets blocked when there is no new data.
Someone on here a while back posted a Github link to a C++14 HTTP library that looked promising, if a bit immature. EDIT: [Found it!](https://github.com/whoshuu/cpr)
Thanks yeah I saw that after I posted too. It returns a string as the response's body though again storing it entirely in memory, probably because of the same problem with the libcurl callback I mentioned. I like it more than the other curl wrappers though.
Great post. I agree maybe it would be nice to give intuition for morally equivalent. This is not the most familiar branch of math for me, but it seems like maybe a better way to say it would be: equivalently representable as. In other words, &lt;Unit, T&gt; and &lt;T&gt; can represent the exact same stuff, and each other. This is a bit different then saying they are equivalent. After all, natural languages can generally represent the same thoughts and feelings, but I wouldn't say French and English are "morally equivalent" ;-).
I found [POCO](http://pocoproject.org/) pretty easy to get sockets up and running. It has a JSON parser but I found [minijson](https://github.com/giacomodrago/minijson_reader) easier.
I agree, it's very cool. At first I suspected macro magic, then I saw it was operator precedence magic. It would take me forever to convince myself there weren't any hidden edge cases.
Note: Only works with MSVC
The page says that it supports Ubuntu, OSX, iOS, and Android, and MSVC doesn't run on any of those. I can't test that though. 
If im not mistaken, C++ standard extends object lifetime if it's bound to const ref, even if its temporary.
Curl and C++ HTTP libraries generally suck but this isn't one of the reasons why I think. You can easily wrap this in a boost iostream where the curl thing feeds the sink &amp; the source is your "InputStream" equivalent.
and so what? just a "while" with assignment is Turing complete You know, just need a rubon! I agree with esbio 
I love the list of features in poco, didn't love looking for documentation the last time I tried thou.
Thank you very much for your reply and all the information! Cool!
&gt; I haven't really studied category theory, so at least mentioning isomorphism with a link would have been fine. Me neither, and I agree that mentioning that could be useful. For context the discussion was happening in the boost mailing list [here](https://groups.google.com/forum/#!topic/boost-developers-archive/wmcX6uWoL24) and [here](https://groups.google.com/forum/#!topic/boost-developers-archive/7MTEH4j2N8s) (the thread got split for some reason). &gt; How do we classify "meaningless"? Is that something real in category theory? Do we just arbitrarily say that the we name some arbitrary thing and that is our unit type &amp; everything else has extra type information that makes it not the unit type? That seems confusing. I'll try to explain how I see this but i'm not a professional. First, these rules work "within the type system". The type system does not know about meanings. It lets us create new types that are not equal to other types: e.g. for `struct MouseUp {};` and `struct Unit {};` we have that `std::is_same&lt;MouseUp, Unit&gt; == std::false_type`. We do not classify meaningless, we define it. We can define the meaning of the type `Unit` to be "without meaning", in the same way we can define the meaning of the type `MouseUp` to be "indicates that the mouse is moving up". Once we have a program with these types, we can redefine the meanings to be completely different, and our program still type checks: the type system knows nothing about meanings. Within the type system, these types are isomorphic to each other, because we can write: auto map(Unit) -&gt; MouseUp { return {}; } auto map(MouseUp) -&gt; Unit { return {}; } // add metafunctions here that transform one type into the other It doesn't matter that these functions make no sense, we can still write them down and they do type check. We could also define `MouseUp` to be meaningless and write it as `using MouseUp = Unit` and then `std::is_same&lt;MouseUp, Unit&gt;` returns `std::true_type`. &gt; &amp; everything else has extra type information that makes it not the unit type? Well `using MouseUp = Unit` introduces a new "alias" for `Unit` but not a new type. It makes little sense in a programming language to allow introducing a new distinct type that is equal to another: you could use these types interchangeably and would not be able to tell them apart, so in some sense, this is exactly what `using` does. So we could say that "in some sense" (waves hands) we can use using to "create a new type" that is both isomorphic and equal to another type such that there could be multiple unit types (waves hands very much). &gt; Do we say that all empty types are equivalent so that you cannot distinguish the type of MouseUp, MouseDown &amp; Unit? That doesn't seem right. C++ obviously isn't a functional programming language but it already has two Unit types: std::nullptr_t and std::nullopt_t and a function accepting one cannot accept the other. No, we say that these types are isomorphic because we can write these functions, but as long as `std::is_same` returns false they are not equal within the type system. Note also that these types are not unit, since they do have a meaning: a null pointer is not the same as a null optional, which is why functions accepting one cannot accept the other. Note also that C++ also has `void`, and probably many more. EDIT: a couple of things worth noting: - Nothing forbids you from having different types with the same meaning. They are isomorphic, but within the type system they are not equal because they are not the same type. - An example of using these types is Rust. `Send` and `Sync` are "empty types" that are not equal [*]. They are distinct isomorphic types and one uses them to "encode meaning" into the type system. If a function expects `Send` and your type doesn't provide this, the program does not type check because of a type mismatch. Rust uses this to guarantee data-race freedom _as long as you use these empty types correctly_ (following their meaning). If you use them wrong, your program will still type check, and you will get a data race. [*] This is a bit of a lie. In Rust they are Traits, but in C++ they would be tag types. For the discussion it is enough to consider them as types.
That actually looks quite decent. Can someone explain to me what the advantage of async is when you're chaining them with "then" and waiting for the result? My gut says that actually has more overhead than just sync io with maybe another thread and a single join because those pplx things look like they need to do a lot of synchronization under the hood
I tried looking in the code and docs to find what the format of the response is because they cast out to strung sometimes and how to get a stream but my C++ is a bit rusty and I just couldn't find it, any pointers?
/u/esbio's statement is simply silly. Preprocessor macros are text replacement, template metaprogramming is actual programming. I just took the most concise thing preprocessor macros can't do, but templates can, to illustrate that it is silly. Of all the things I do with templates, maybe 5% could be done with the preprocessor.
The silly thing is comparing templates to preprocessor macros in the first place. They are completely different things, and while in your experience the things done with templates used to be done with preprocessor macros, my experience is the opposite. The things I do with templates now weren't done at all in the past. I work in an old code-base that we are slowly modernising (it's a small shop and we can't just rework everything for 2 years, so instead we rework the stuff that's being updated). I'm the template guy. We usually reduce the amount of code and oblique preprocessor macros by about 50%, and the new code is type-safe, clear (if templates aren't confusing for you in the first place), and better optimised via partial and full specialisations. We still use the preprocessor, I'm not saying it is shit. But both theoretically and from my experience, templates are not comparable at all to preprocessor macros &gt; C++ has become two languages into one, with two different programming paradigms C++ always was a multi-paradigm language, but yes. Templates are a meta-language. &gt; The result is a language so complex that does not blow up the leg. It blows up an entire country. I don't have a problem with the complexity of C++. I prefer it to the joy of debugging reams of void pointers and chasing preprocessor indirection.
You can use void_t to detect the presence of nested types. However, it won't work for arbitrary expressions (including detecting the presence of member functions) in MSVC due to the lack of Expression SFINAE.
I think you’re completely wrong there. &gt; it depends how much implementation salt you are willing to put up with for a very small amount of syntactic sugar This is largely true, but it’s been long established that a superior user experience is worth considerable expenses in the implementation. Furthermore, when it concerns *the core API* (as in this case) the cost–benefit analysis favours a good API overwhelmingly. Simply put, as a user I’d choose a library with a better core API pretty much ten times out of ten, even if that meant accepting a significant reduction in features. And last but not least, the work has been done already (in Catch) and since the license is extremely permissive, the code can easily be reused (with adaptation). It’s very hard to argue that implementing a superior API here is a prohibitively costly issue. &gt; Catch still needs different macros for negation, and different macros to stipulate you expect an exception to be thrown, etc. So it's overall just a small reduction in the number of testing macros you need to know No, that’s not true. Yes, Catch needs more than one assertion macro but it’s an entirely different thing to have a separate macro for things like asserting exceptions thrown than it is to have one separate macro per comparison operator. That’s simply *not* a “small reduction”. It’s an interface that’s an order of magnitude smaller.
Thanks for the comment. I updated the blog post to give a better intuition regarding "morally equivalent", and I added a link to the notion of "isomorphism" for those interested.
It seems there is no "stream" interface, but there is a [callback interface](http://cpp-netlib.org/0.11.1/reference/http_client.html#http-methods): response_ = client_.get(request_, callback) Perform an HTTP GET request, and have the body chunks be handled by the callback parameter. The signature of callback should be the following: void(iterator_range&lt;char const *&gt; const &amp;, boost::system::error_code const &amp;). 
It is awesome. I never had to use a DSL for it so I don't know what OP is referring to. Sometimes I think people don't RTFM. 
IIRC, there is a blocking way to do this blocking without a callback, need to find it though...
I gave some thought to your question, and here's what I would say. In the post, I purposefully do not say "equal". I say "equivalent", which hints at the fact that I'm defining "equivalence" as some custom relation which is not the same as equality. Indeed, the definition of equivalence to which I refer in the post is the notion of isomorphism in category theory. Stripped down to the minimum which is of interest to us in this context, that definition can be written as: &gt; Two types T and U are isomorphic if (and only if) there exists lossless structure-preserving functions from both T to U and U to T. This means that both types contain the same "amount" of information, and they also have the same "organization" of that information. For more information, see my comment on Eric Niebler's blog [here][1], and I'll try to precise here if you have further questions. Note that if you were able to define a category where morphisms take into account the semantic meaning that you want to attach to types like `MouseUp` and `MouseDown`, you might find that `MouseUp` and `MouseDown` are _not_ isomorphic (in that category). I have no idea how you could define such a category, or if this is even possible. So basically, what I'm saying is that we define "equivalence" as being some relation which is useful to help us reason about things, while purposefully throwing away a lot of things that we consider as details. But this is just a definition, and of course `MouseUp` and `MouseDown` are not equivalent in terms of the meaning they convey to a human (english speaking) reader. It's just that we're not interested in that precise meaning when talking about isomorphism in the C++ category (which is equivalent to the category of Sets). [1]: http://ericniebler.com/2015/02/13/iterators-plus-plus-part-2/#comment-112782 
This is probably not what you want to hear right now, but judging from your responses to the other replies it seems like the real problem you are having is that you are desperately trying pretend that C++ is Java. It is a different language and trying to write C++ as though it was Java will be both frustrating and not work very well. I am very familiar with this personally because I did the same thing you seem to be doing when I first started writing Android Apps (I was a much happier person once I started doing Android the Java way). As you can tell by many of the other comments, most of the experienced C++ programmers here don't really understand what you are complaining about. Here are some things that IMO you try to understand about C++: * Modern C++ is NOT an Object Oriented language. The dominant programming paradigm in C++ is called Generic Programming. To you method calls are the norm, but in C++ free functions are preferred. * Boost is essentially part of the standard library. You should assume when starting a C++ project that you will be including Boost. * Compile times in C++ will be long. C++ is capable of doing a lot more at compile time that Java and thus compile times are longer. We all wish it was different, but the reality is that long compile times are part of the cost of doing business in C++. * You don't know what the compiler is going to do. All of this talk of performance and efficiency is premature. * Get comfortable with callback interfaces. They are the norm in C++ because they are more generic than blocking interfaces (you can do blocking and async io with a callback) and C++ programers love generic interfaces. 
&gt; allow a temp object to be assigned to non-const reference? I don't see a disadvantage or danger that isn't outweighed by the benefits C++ is not about writing less code, C++ is all about having a lot of control over the resulting binary by stating your intentions as clear as possible. Ambiguous code is nothing but a can of worms. Using that extension only to write a bit less code is just being lazy. There are extension that allow to write less code but also allow the compiler to know more about our intentions: for (const auto&amp; item : container) Less to type and the compilers knows we want to iterate over the whole container without changing its elements. 
Yes I'm aware of the advantages of select/epoll and friends. But what is happening here, I guess their pplx thing is basically a replacement for green threads?
Hey, we were talking about this last week, CPR is pretty awesome: https://www.reddit.com/r/cpp/comments/3corbu/cpr_c_requests_library_written_in_modern_c/ Paging the dev /u/whoshuu The only reason I'm still using POCO for http is that I don't want to do OAUTH1 signatures myself and POCO takes care of that :)
I used C++ before I started with Java though admittedly that was quite a while ago. The problem isn't about templates I really like them but I do begin to understand why the Go authors are so hesitant to add them. It's the lack of standard ways to do things that sucks. A string could be based on wchar_t or char, you can do basic_string&lt;uint8_t≥ too but sadly that can't be printed with std::stream, you want an equivalent for ByteBuffer? Sure vector&lt;char&gt; works, so does string, or stringbuf. You've got threads in the standard library but not sockets or a proper buffer that knows about byte order and how to write it. You interface with C's fread or iostream but only for files oh you want to mmap well fopen() is too high level for that, how would I wrap a socket to be an iostream? C++ is absolutely awesome for scientific code I've seen beautiful template use to model graphs but when it comes to networking the Go way where its absolutely clear that a Reader reads byte slices and nothing else is just so much better. C++ code is also much more dialect based and everyone of course has their own buffer. You might like boost but a lot of projects advertise not using it and I have C++ using friends that love templates but seem to choke when someone even mentions boost. Also they never use callbacks, but libuv is all about them. However my problem here is much simpler. The json libraries mentioned here and the one I tried reads from stream abstractions (rapidjson has its own streams that are quite simple) and they do because parsing is naturally stream based and because files and pipes are stream based and you want to be able to read json from pipes or stdin. Also note the Microsoft library does use streams.
&gt; If a destructor throws when an exception is already being dealt with, the behavior is undefined No, `std::terminate()` is called.
Not quite as big of a library, but very similar to Qt is Wt. It uses boost for signal/slot handling which is great too. There is a Wt::JSON module available. http://www.webtoolkit.eu/wt/doc/reference/html/modules.html
Hey there. Thanks for thinking it's awesome! Just a small correction here, cpr minimally requires C++11, there's nothing in it that needs a C++14 compatible compiler. I've got my eye on OAUTH1 support for a future release, so stay tuned.
It seems better documented than most C++libraries (which isn't saying much). The presentation slides cover the overview, and you can read the source code too.
This is probably the least significant of the issues mentioned in this post, but I'd still like to personally thank you for dealing with C4503 ("decorated symbol name exceeded"). This warning always looked to me as if the compiler were warning its users about its own defect, so I, for one, will be very glad to never see it again.
I feel for you. Learning a new language is hard when you are a new programmer. What many people fail to realize is that learning a new language when you already know another one can be just as hard and is definitely more frustrating. From a philosophical point of view C++ and Java are basically directly opposed to each other. That is why there is so much hate between the two camps. How many people do you know that like both C++ and Java? Java is: * Protect the programmer * Big library with separate classes for each task. * Small language C++ is: * Here is a gun, try not to shoot yourself * Big language * Small Library with functions that can work on many classes For example my first reactions to your complaints are: * basic_string&lt;uint8_t&gt;? Why on earth would you do that? * string or stringbuf for binary data? That is not a good idea. * converting the byte order of a buffer is a one liner, why would you make a separate class for that? * you have a point on the socket interface, the same could be said for filesystem hopefully in C++17 Getting back to you problem. There are basically two use cases for reading off the network. 1.) You want to control how the data is read off the network. This is what cpp-netlib uses callbacks for (it uses callbacks because these work whether or not the IO is blocking or async). 2.) You don't want to know/care how the data is read off the network. This is what cpp-netlib uses streams for. You are trying to use streams for the first case and that is just not going to work with that library as I understand it. You may be able to find a library that works the way that you want it to, but my point is that to a C++ programmer the way that cpp-netlib does it seem like the logical choice. My advice would be, if you want to do block IO then you need a Json parser that parses in blocks. 
You're welcome! Figuring this one out was extremely tricky, but after I identified the things that were causing mangled name amplification, reworking them as part of the &lt;functional&gt; overhaul was simple.
Ok first the points: * basic_string&lt;uint8_t&gt; was just something I tried because I feel like the bytes coming from the network are unsigned just as the byte type in Go, I tried string because of [this](http://stackoverflow.com/questions/1466756/c-equivalent-of-java-bytebuffer) * stringbuf see above * The byte order of a buffer is not converted, one would have something like "using netbuf = byte_buf&lt;BIG&gt;;" and then could do netbuf.write(some_long) and the long would be written in big endian. I'm not sure about the template usage here but the idea is that a buffer can either writes everything in big or little endian. Again a proper buffer class is IMHO just as basic as string, vector, unordered_map or whatever. * I do like the small library approach, I don't care for GUI libraries or some such. Honestly I find Go really has a perfect balance here because the main point of base libraries is to prevent everyone from writing the same basic stuff over and over again and buffers, sockets, file io and threads are IMHO on the same level * I'm fine with having to do manual memory management and lack of bounds checking I don't need hand holding. It's the incompatibilities in the C++ ecosystem that bug me not the language, apart from lack of modules that is For the second part I don't really care about the fact that it's sync or async. I was referring to libcurl being sync but using a low level callback that means it can't be embedded easily even in simple buffer classes. This is because with libcurl one doesn't call it to receive data but gets called from its .perform() function in a very low level way. Also I probably shouldn't have said streams, I really mean an application driven receive/send. Something like fread() would be absolutely fine and is really easy to integrate with buffers.
Ok looking at libcurl again it seems the multi interface should allow driving the connection and therefor implement streaming. My thinking is one would need to either implement an istream/ostream or abuse something like stringstream http://curl.haxx.se/libcurl/c/libcurl-multi.html this would be similar to http://curl.haxx.se/libcurl/c/fopen.html
There should be pdf documentation on their site.
If you want simple graphics with a bit of C++ it's hard to go wrong with [Lazy Foo](http://lazyfoo.net/SDL_tutorials/) which I'd say is the defacto standard intro tutorial for 2D graphics in C++.
I am not really sure what to tell you then. If I understand correctly, you did not like the way that C++ http client libraries work because you are used to them working like this: while (buf = socket.read()) {do something} but C++ http client libs tend to work like this: socket.perform([] (char *buf) {do something}); I thought that maybe you wanted to know why the second one is preferred in C++ and I explained that it is because you get the same interface wether socket is sync or async. Think: while (socket.perform([](char *buf){do something}); It seems like you still do not like it. There is not much I can do about that.
This looks great! Thanks a lot :)
&gt;You don't get that obvious flag from constructor/destructor/overloaded operators. **You** don't. 
Not in the Concepts TS. the `auto` rules are essentially unchanged. You still need an initializer for the declaration. Although, huh. Deducing across multiple statements would be interesting. Not totally different than what we do for return type deduction in the presence of multiple return statements. 
I may have been mistaken about the stream interface. I went back and looked at my code and all I did was dump it into a stringstream. http::client::response response = client.get(request); std::stringstream resp_stream(body(response)); My payloads were small enough that it didnt matter, but I can understand wanting a stream interface.
I compile, structure the file layout and link all my dependencies manually. However I work on a large long term (Years) project so spending a day doing this once in a while is not a big deal; especially once you get familiar with the dependencies. I've also found that in C++ I tend to include fewer dependencies than I do with other languages. In my main project I add one maybe once a year... However, when I need to do some java work (unfortunately) I find I'm adding them all the time.
First I want to thank Andrzej's for his original proposal. While I came up with this independently, the original thread where he broached this was very useful in me clarifying in my mind strong arguments why it's necessary. While I originally favoured the policy design, David Krauss had a really brilliant suggestion to instead do something like `optional&lt;compressed_scalar&lt;double, nan()&gt;&gt;` &amp; have the policy encoded in the optional type. There is still some trickiness obviously because I would still want `optional&lt;compressed_scalar&lt;double, ...&gt;&gt;` to vend `double` not `compressed_scalar` as values, but I think it's possible. I haven't had time to work on this proposal in a few weeks so I'm hoping Andrzej's on here to answer some questions. 1. Why compact_optional as a separate type? I think it's because you changed the API but I just wanted to double-check. 2. Why change the API? While I can understand the desire to provide a less error-prone API, I worry that subtle differences in the two APIs can lead to bad assumptions. Consistency &amp; ease-of-use of APIs is important I think. compact_optional feels unnecessarily restricted. 3. I love the idea behind tagging the sentinels as different types. I worry that it would get rejected by the standards body as unnecessary complexity. Thoughts? If you think it's a strong addition to the proposal I'll incorporate it. To understand my reasoning, my motivation is as follows: 1. Lots of existing code uses sentinel values all over the place. 2. Sentinel values are dangerous &amp; error-prone. There are no safety checks that you're not accessing a non-sentinel value. 3. They are common in memory-mapped data structures 4. They are common in STL interfaces (std::string::npos) 5. It's not an uncommon concern when replacing legacy code that regression risk be minimized. My most recent thinking on the matter is as follows: 1. `optional&lt;compressed_scalar&lt;double, 0&gt;&gt; y = 5; y = 0; assert(y)` fails - compressed_scalar being assigned the sentinel value is equivalent to being cleared. 1. `optional&lt;compressed_scalar&lt;double, 0&gt;&gt; == 0` returns true - empty state &amp; sentinel representing empty-state is true. This follows from the rule above 1. `optional&lt;compressed_scalar&lt;double, 0&gt;&gt; y = 0; y &lt; -5` returns true - empty state always less (as with regular optional). 1. All relational operators for real &amp; compressed optional work as "expected". The only "caveat" is that sentinel values is treated as empty-state which preserves the principle of least surprise. A more limited API makes transitioning existing code more difficult. I'm also concerned that the sentinel value isn't asserted but that could just be a misreading on my part. Thus I wanted to make sure that I could guarantee it's a complete drop-in replacement that would maintain all existing semantics without any further code-changes (aside from trivial compile-time issues like converting access to dereference). Of course, now that I think about it, Andrzej is probably right about the comparisons; if we follow the definition for std::optional, std::string::npos may have been sorted at the end but if you change it to a compact_optional with relational operators it would be sorted at the beginning. I'm not 100% convinced though that the inconvenience of not having them is better; I think at the very least == &amp; != need to be defined. Thanks for the great write-up Andrezj!
The simplest example is NaN. Floating-point is probably the only known case in existence where there's a value that is never equal to anything, but it's an important type.
The only heavy weight part is the one-time download, using Qt will slightly increase your compile times but it doesn't give a run-time performance drag. Take a look at QCoreApplication, for a console style programs.
Nope it blocks the thread that calls it until the request is done. I want the json parser to process the data in the chunks that are incoming so that I only need memory for the decoded object not the object plus the json data. However all parsers I've seen are designed for reads they drive like with fread or a stream. Here they would need to be able to partially parse a char buffer, then hold that state until the next callback and then continue parsing the next buffer. With reads they drive they don't have to make their parsing state explicit because it's just the local function state.
Since May 2013
I'm glad we agree :-)
Thanks this should work!
&gt; but means we're doing a round trip through the scheduler for every chunk Eh, this is exactly what happens when you use a Java async http library. The inefficiency is baked into their API. And besides, if you're running on a dual-core, curl will download at the same time that your parser consumes. There should be no overhead if you use a lock-free list. The only alternative is to pause downloading until the JSON parser wants more and then do *a round trip through the network* to ask for more. 
I don't think so. 5% is very low. For instance, define a generic file (yes a file) containing the code of a class with T as Template parameter and then define in the intiial source code the value of T and include the file for replacement. In that way, and by playing with #if you may be able to growth to at least 95%. 
Concepts is just a way to define the "protocol" that should follow some classes. In OOP we have the concept thanks to interface or inheritance. So, now we are going, once again, to have another way to express the same thing. That is, the same idea can be expressed by 2 different methods. For me: it is really bad. Thus, some people will be happy because inheritance could be removed in some cases. I don't really understand how concept may solve my simple problem? How can I have the equivalent of static_if in only one line? Anyway, we can simulate huge part of static_if usage with SFINAE and enable_if. So you can do whatever you want: people are going to use the simplest way to do something 
Thanks for the answer STL! I was asking specially because of this issue in libc++. IIRC in that issue the problem was about how libc++ uses invoke internally for things like `result_of`, where SFINAE takes different path at compile time when invoke is constexpr because it is then evaluated in unevaluated contexts. "Maybe" your `&lt;functional&gt;` implementation does not have this problem. That is a long shot, but if you manage to give that a try and run that through your test suite the feedback would be interesting. Trying to debug this issue is very hard tho. 
&gt; Not totally different than what we do for return type deduction in the presence of multiple return statements. Never thought about it this way, but interesting idea.
 &gt;However it looks like the libcurl multi interface will allow me to do a stream abstraction similar to http://curl.haxx.se/libcurl/c/fopen.html Aww, their `write_callback` is more efficient than mine since they use realloc. I really wish C++ vectors did that. 
&gt; But that will have to change soon. Interesting, is that because of new features or could you elaborate on why?
Yes for more complex conditions, a predicate would be needed. However, the `static_if` shown is only limited to one condition and an else(ie there is no `else_if`). Trying to expand it to multiple conditions can get ugly unless you use [dependent typing](http://pfultz2.com/blog/2015/01/24/dependent-typing/) instead. Another approach is not to chain the conditions, but rather pass them into a function which will chain them. This is the approach done with the Fit library. So, the example could be written like this: template&lt;typename T&gt; void decrement_kindof(T&amp; value) { eval(conditional( if_(std::is_same&lt;std::string, T&gt;())([&amp;](auto id){ id(value).pop_back(); }), [&amp;](auto id){ --id(value); } )); } And since the conditions are passed to `fit::conditional`, multiple conditions can be passed to it. For example, an additional check for a stack could be added(assuming there is an `is_stack` trait): template&lt;typename T&gt; void decrement_kindof(T&amp; value) { eval(conditional( if_(is_stack&lt;T&gt;())([&amp;](auto id){ id(value).pop(); }), if_(std::is_same&lt;std::string, T&gt;())([&amp;](auto id){ id(value).pop_back(); }), [&amp;](auto id){ --id(value); } )); } 
&gt; C++ is not about writing less code, C++ is all about having a lot of control over the resulting binary by stating your intentions as clear as possible. In comparison to C, C++ is about stating your intentions clearly *with less code*. If it were not, everything else you said is also true about C; and if you didn't care about platform independence, about assembly. &gt; Ambiguous code is nothing but a can of worms. The MSVC extension is not ambiguous.
&gt; Oops: since c++11, destructors automatically get the same exception specification as the implicitly generated one. Since likely no member variables in your class have throwing destructors, that means your destructor is marked noexcept. Jesus Christ. For all the relative progress, sometimes I really wonder what kind of idiots are designing this language. Jesus F-in Christ, this is incredible: &gt; In C++11, a destructor is implicitly specified as noexcept. Even if you add no exception specification and define your destructor like this: [...] The compiler will still invisibly add specification noexcept to your destructor. And this means that the moment your destructor throws an exception, std::terminate will be called, I mean, seriously. What kind of clowns do you have in the C++ standard committee that design the language like this? A rule like this just isn't tenable in practice. A quick test as to which compilers implement this: - VS2013: all good (but then - it doesn't even support noexcept) - g++ without -std: all good - g++ with -std=gnu++11 or gnu++14: yep, requires noexcept(false) Even with -Wall, GCC doesn't even produce a *warning* for the destructor with an obvious throw. *sigh* Well, thanks for pointing this shit out. Seriously - this kind of out-of-control, intrusive fetishism for personal principles without consideration of impact is why I avoid the C++ standard library. Now, the library writers seem to have taken over the language, and their crap seems to be spreading outside the library. *Gah.*
-std=gnu11 by default! fuck yea!
Hopefully they will have std=c++11 default soon. The above default is for C.
Can you *please* add the ability to see the disassembly? IMO that's one of the biggest features for a web compiler ...
Funny that they're jumping straight from c89 to c11 as the default. Although I just learned a couple days ago about the c99 command and how it's required by the POSIX standard.
Usually I do release with github (or fork/patch/release). But this feature planned anyway: [1](https://github.com/ruslo/hunter/issues/56) and [2](https://github.com/ruslo/hunter/issues/204)
It's not clear to me from the proposal whether this would support conditional member variables or not. Can anyone clarify
&gt; Why? Because it allows making static decisions without having to resort to multiple overloads. Having a static if allows for simple and local code, without having to know the intricacies of overload resolution, partial ordering and SFINAE. Well maybe if you don't know how overload resolution works, you should not write a function template that requires a `static_if`. Honestly I feel that this is just a syntactic sugar, it does not solve any problem, just provide an *arguably* nicer syntax for something that we can already do (and easily extend) via tag dispatching. 
I think it'll probably never get implemented for any platform. With the interface as it stands in the standard, there isn't any real benefit over `pthreads` which sucks. Truly portable threading with C is still painful, at least if you don't limit to atomics. At least C++ is portableish.
It will not.
Overloading is much more verbose and less obvious, because overloading is done for lots of other reasons. static_if gives you a compile time syntax that is easy to understand because it mirrors the plain if syntax. Calling it syntactic sugar is a bit like saying constexpr functions are syntactic sugar.
Yes; also, `std::nested_exception` aggregates in the opposite way than I would like. `std::nested_exception` wraps a secondary exception around the first one, and I would prefer that the other way around. What I would most like to see is for the basic `std::exception` to be aggregatable, to allow any number of secondary exceptions to be added to it. For example, the outside and first exception is `Smtp::TemporaryDeliveryFailure`, which derives by some route from `std::exception`. During stack unwinding, `closesocket` fails, so there's an additional aggregated exception `Socket::Error` &amp;#151; also derived from `std::exception`. The `catch` handler can then process just the outer (first) exception, which works for simple stuff, and provides same behavior as now, if `closesocket` result is ignored. Alternately, the handler can go through the aggregated exceptions and e.g. log the failed `closesocket`, which is something that's rather tricky to do now.
Notwithstanding my dissatisfaction with these design decisions, I want to thank you for your feedback and for raising the noexcept issue. This has caused me to [write this post](https://www.reddit.com/r/cpp/comments/3dlm12/errors_in_destructors_and_the_case_for_aggregate/) proposing a language U-turn on this issue, and to add support for automatically aggregated exceptions. In my opinion, this would be a major improvement on the current treatment; it would make destructors useful for purposes people *want* to use them; and with the extensions I propose, aggregating exceptions in library containers would be straightforward. No doubt, you will disagree with my position. However, it's my opinion that the current single-exception behavior is crap. It renders destructors much more restricted, and much less useful, than they ought to be. I am quite sure that eventually - assuming the language survives long enough, even if in 2040 - aggregated exceptions will be supported.
Removing the object files from the repository would be a start. I would suggest using CMake instead of manually writing your Makefiles, and you should look at well organized projects on GitHub, or read through one of the many threads about this on StackOverflow. Like this one: http://stackoverflow.com/questions/13521618/c-project-organisation-with-gtest-cmake-and-doxygen
As no1msd says, you're probably better using CMake. Otherwise, one simple thing you can do is bundle up the compiler flags as a makefile variable (as in DRY in regular coding).
The facility was quite easy to implement using clang. Here's a test file that compiles (within the relevant branch on github): https://github.com/faisalv/clang/blob/static_if/test/CXX/static_if/cxx1z-static_if.cpp
This is a bad idea. An exception should never be allowed to propagate out of a destructor because a destructor should never fail. What would it mean for a destructor to fail? It would mean that the program can't make forward progress (it threw an exception in the first place) nor backward progress (unwinding also throws). You're left with an object that can't be cleaned up or even referred to, and you cannot avoid leaking memory and other resources. If you think you need this, it means you're doing things in a destructor that don't belong there.
This is probably going to sound newbish, so I'm sorry in advance. What are the basic steps to get this installed on Ubuntu 14.04?
is it possible to get it from not sourceforge?
Yup. Having to roll your own stdint.h and stddef.h gets really old really fast.
"Reporting a problem" is different from "throwing an exception". If you need to report a problem in cleanup, log something. Don't throw an exception. My favorite example of "things that could have an error but you should never care" is `int close(int fd)`. I'd generally consider it an error to even check the return value of `close()` because there's nothing you can do if it fails (other than debug why your fd is a bad fd).
&gt; What exactly are the cleanup operations you describe. That's specific to the destructor. If the destructor calls `closesocket`, say, an exception might convey that `closesocket` returned an error. &gt; I'm curious how something which expects and handles an exception in a destructor can be considered a "good implementation". Loaded question expressing, as we're about to find, ignorance... :-/ &gt; What happens to the memory of that object that failed destruction? The object did not fail destruction. The destructor reported an issue via the exception mechanism. &gt; Do you just mark it as 'do not use'? memset it all to zero? There's nothing wrong with the memory. You do exactly the same thing as if the destructor did not throw. &gt; Destructors commonly free memory dynamically allocated by the object. **No!** No! That's not how destructors work. Destructors do not free object memory. `operator delete`, which is *not* the `delete` keyword, frees memory. If one of the destructors of a heap object throws, `operator delete` is called after the rest of the destructor chain to free the object's memory. A destructor exception does not stop orderly and dependable destruction proceedings. You have major misunderstandings of the language. Destructors have *always* been able to throw. They can throw in C++03. They can throw with `noexcept(false)` in C++11. Memory has *always* been released in this circumstance properly. Base destructors are called properly, and will continue to be. The question is not whether destructors can throw. They can, and can do so safely! The question is: * What happens if there's an in-flight exception already? * What happens if we're destroying a collection of 1,000 objects, and 2 or more throw? My proposal answers questions like these. It *does not invent* support for destructors throwing! &gt; What happens in the case of inheritance and virtual destructors? Same thing that happens already when destructors throw. Everything is destroyed and works properly. C++ wouldn't *allow* destructors to throw if there wasn't existing, and extensive, support for this! Destructor exceptions are discouraged because of problems in *some* circumstances, not in the base usage case. My proposal is to address *those* circumstances, so that support for destructor exceptions can be complete; not that we avoid them, and resort to sweeping them under the rug like with default `noexcept`, because support is 99% only. &gt; Any program that throws an exception in a destructor has been poorly designed, I'm sorry, but &amp;#151; you lack basic awareness of how C++ destructors *currently* work. If you make comments like these &amp;#151; please know the language!
&gt; The only reason we think destructors "cannot fail" is because the language lacks the concepts to handle it. All the language needs is this extension of the exception mechanism, and then destructors can fail just fine. That would not fix the fundamental problem - that the failure of a destructor would leave the program in a state from which it could not recover. &gt; The failing nature of destructors does not change with this proposal. Destructors already fail. Ignoring errors doesn't mean they don't occur. I didn't say that they don't fail, I said that they shouldn't. If a destructor fails, the problem is not that C++ lacks the necessary abstractions to handle that, the problem is that the destructor is doing things that a destructor has no business doing. To believe that a destructor should be allowed to fail the same way that normal methods and functions can fail is to misunderstand the entire nature of a destructor. &gt; Continuing backward progress is trivial. Unwinding continues until a catch handler for the original exception is found, at which point forward progress resumes. That can be done perfectly well without any changes to the exception mechanism. Just put the information you want to throw out of a destructor into a global list and have the "catch" block go through that list and do what it will with the contents. The semantics of an exception are "the thing you asked me to do could not be done - execution cannot continue along the path that would otherwise have been taken". But what you're suggesting should happen when an exception is thrown from a destructor is exactly that execution does continue along the path that would have previously been taken (continue to unwind until catch found). &gt; A destructor throwing doesn't mean that destruction didn't succeed to a standard sufficient for the program to continue. It means that there were issues with cleanup that do not require an abort. Such issues could be ignored, but in good implementations, would not be. That is not something that should be signalled with exceptions. An exception means "what you asked me to do I could not do", not "it basically worked but here are some informational messages". What would a program be expected to do with such cleanup issues anyway? The object they are about is already gone! About all you can do is ignore, abort or log. And you can do any of those things from inside the destructor. &gt; There is currently no language solution for this, and alternatives (a standard logging facility?) would not be as general, or context-aware. I don't understand what this would achieve that a logging mechanism wouldn't. &gt; Adopting this proposal further allows destructors to become first-class methods, rather than second-class citizens that can't use a whole aspect of the language, and literally have to pretend like they're written in C. Not at all - you can do anything inside a destructor that you can do anywhere else inside a C++ program, including throwing exceptions. You just can't let exceptions propagate out of the destructor. If you want to run code that might throw inside a destructor, you have to put a catch block inside the destructor and the possibly-throwing code inside that. Perhaps a good way to think about it is to imagine that, while an exception is in flight and the stack is being unwound, it's almost like your program isn't being run at all but has been replaced with a completely different program (the unwinder) which shares the same memory space but has a different call stack. The unwinder contains no "catch" blocks of its own so if you allow an exception to escape into it, the unwinder is itself completely unwound and terminates with an "uncaught exception". With at least one C++ implementation I'm familiar with, this is essentially what is happening under the hood.
&gt; If you need to report a problem in cleanup, log something. There is no language mechanism for a library to log this information without either (1) inventing a C-style hook mechanism to report such errors, or (2) infringe on the using application. &gt; I'd generally consider it an error to even check the return value of close() because there's nothing you can do if it fails (other than debug why your fd is a bad fd). On the contrary, it is an error not to check. You might be double-closing, which would be a serious error you need to detect. Yet you cannot just abort in this case, because the error might also not be your problem.
&gt; That would not fix the fundamental problem - that the failure of a destructor would leave the program in a state from which it could not recover. But destructors can already throw. They have always been able to throw. They can do so safely. It does not indicate that the program cannot continue, after unwinding to where the exception is caught. &gt; the problem is that the destructor is doing things that a destructor has no business doing I assume you don't suggest that we should ditch the whole Resource Acquisition is Initialization concept. If not, then which is your opinion? * Destructors should not free resources? * Destructors should not check for errors when freeing resources? * Destructors should not report errors detected when freeing resources? &gt; Just put the information you want to throw out of a destructor into a global list and have the "catch" block go through that list and do what it will with the contents. Ah, wonderful. A hack! With a global object, nonetheless. Now, how do you recommend implementing this hack as a standard mechanism for reporting errors detected in library destructors to the application user? Yes - we could have a standard error reporting facility in the STL library. But what would make this facility superior to conveying this same information locally, in a context-aware method, via aggregated exceptions? In a way that the destructor error becomes a first-class exception, rather than a log message, when no existing exception is in flight? &gt; An exception means "what you asked me to do I could not do", not "it basically worked but here are some informational messages". An error in `closesocket` is not an informational message, *it is an actual error*. It's just, possibly, a lower priority error than another exception that occurred before it. An exception aggregation mechanism would allow higher priority errors *and* lower priority errors to *all* be reported, rather than forcing ignoring of lower priority errors. If there is no exception in flight, i.e. there's no higher priority error, the `closesocket` failure would still cause a legitimate, first-class, non-aggregated exception. Better yet, aggregation allows containers to properly handle exceptions in multiple objects, which is currently difficult. &gt; I don't understand what this would achieve that a logging mechanism wouldn't. But the language doesn't *have* a logging mechanism. Logging mechanisms are application-specific and cannot be used by libraries. Special mechanisms have to be designed for libraries to convey such information to using applications. If you always just log this type of error, it means you cannot change program behavior when it occurs. You *want* to change program behavior if something unexpected happens. If `closesocket` fails, and there's no exception in flight, I *want* to throw an exception. However, if there's an exception already in flight, I'm okay piggybacking on it; I don't want to crash the program. Likewise, if I'm destroying a vector of 1,000 objects, and one of the destructors runs into a problem, I *want* it to throw an exception. But currently, I cannot, because what happens if *two* of them throw? With aggregated exceptions, this is not a problem. If 10 or 100 destructors throw, all of them can be aggregated. These aren't errors that we're ignoring because they're not *worth* reporting. We're ignoring them because the language lacks support to handle this stuff. But the additional support required seems minimal. &gt; The unwinder contains no "catch" blocks of its own so if you allow an exception to escape into it, the unwinder is itself completely unwound and terminates with an "uncaught exception". So generate an implicit try/catch around destructors that aren't `noexcept`. If exception is caught, and `uncaught_exception` is true, aggregate the exception with the in-flight one before returning control to unwinder.
&gt; Programs (and yes, even libraries) absolutely should abort if they detect such a condition, Yes, if you know without doubt that you detected a double close. But what if you don't know that information for certain? You know that close failed, but what if it's some kind of network resource, and really only the network connection failed? What if this is Windows Sockets, and you're dealing with an unreliable API where the error could be returned by a crappy third party Layered Service Provider? Do you want to crash because the provider is buggy? In that case you would normally want to throw an exception to stop the current part of the program, but let the rest of the program run because you don't have strong reason to believe that corruption has taken place. And you *would* normally throw an exception, except that the close happens in the damn destructor...
&gt; But destructors can already throw. They have always been able to throw. They can do so safely. It does not indicate that the program cannot continue. This was a misfeature. The situation is improved somewhat in C++11 as destructors are now "noexcept(true)" by default. It would be better still if C++ would detect this situation at compile time, but this is not possible with the C linker model. &gt; I assume you don't suggest that we should ditch the whole Resource Acquisition is Initialization concept. You assume correctly. &gt; If not, then which is your opinion? &gt; Destructors should not free resources? No. &gt; Destructors should not check for errors when freeing resources? &gt; Destructors should not report errors detected when freeing resources? One of these, depending on the situation. Or: report them by a mechanism other than throwing an exception (abort or log). &gt; Ah, wonderful. A hack! You're right, it is a hack. I don't except anybody to actually implement such a thing, because what it does isn't actually useful. As is common in the philosophy of C++, if you really think you need to do such a thing you can go and write it yourself. But there's no point in C++ inventing mechanisms that aren't actually useful. &gt; An error in closesocket is not an informational message, it is an actual error. Once closesocket() returns, either the socket in question is not open (in which case we can proceed as planned) or it is open (in which case there is no way to close it, and the program cannot proceed without leaking it, and should abort). &gt; The language doesn't have a logging mechanism! A standardized logging mechanism (usable by libraries) would be a much more useful addition to C++ than aggregate exceptions. &gt; If you always just log this type of error, it means you cannot change program behavior when it occurs. This may be key. What kind of changed program behavior do you envision? In your example of a vector of 1,000 objects and the destructors for 10 of them fail - what is the rest of the program going to do with that information? You want that information in a structured form (not just a textual log file) in order to be able to do something useful. But you just had a perfectly good structured form (the vector itself). And now it's gone! Better to do the thing you want to do with that information while the objects are still intact, in a dedicated loop over the vector which you explicitly call before you start tearing the objects down. &gt; We're ignoring them because the language does not have the support to handle them. No, we're ignoring them because they are not actionable (or because we have an irrational fear of terminating the program). &gt; So generate an implicit try/catch around destructors that aren't noexcept. If uncaught_exception is true, aggregate caught exception with the in-flight one before returning control to unwinder. Again, you're still left with the non-actionable information.
Except that macro is nowhere to be found in POSIX compliancy documents. 
&gt; You know that close failed, but what if it's some kind of network resource, and really only the network connection failed? You're tearing down the socket - you no longer care if the network connection failed. If it matters, it'll be reported the next time you try do something from with the network in a non-destructor context (which is when you do care). &gt; Do you want to crash because the provider is buggy? I'm not sufficiently familiar with Windows Sockets specifically to say, but either I can no longer trust the integrity of the running process (in which case I want to terminate it ASAP) or I can (in which case I don't care about knowing something went wrong when it is of no consequence).
&gt; This was a misfeature. It was not a misfeature. It was a 99% implemented feature which is now being shoved away behind `noexcept` because people aren't understanding the need to implement the final 1%. Aggregated exceptions are that 1%. With aggregated exceptions, this feature becomes safe, and complete, and worthwhile. &gt; In your example of a vector of 1,000 objects and the destructors for 10 of them fail - what is the rest of the program going to do with that information? In my case, probably log all 10 failures, and continue with the rest of the program after unwinding that part. &gt; Better to do the thing you want to do with that information while the objects are still intact, in a dedicated loop over the vector which you explicitly call before you start tearing the objects down. Well that's just wonderful. If I want to detect errors in resource cleanup, you're having me do resource cleanup twice: - Once for the normal case, when there are no other exceptions, to detect any errors. - Another time in a destructor, in case I'm unwinding an exception. What an amazing language this design of yours is. Instead of doing resource clean-up one time manually, like in C, I get to do it twice! &gt; No, we're ignoring them because they are not actionable Self-checking is an action. There are self-check failures where the appropriate response is to stop the current activity and log an error, but do not warrant termination. You're shoehorning your error handling preferences on me, and not giving me a solution. &gt; (or because we have an irrational fear of terminating the program). If terminating was always appropriate, we would not *need* exceptions.
+1 to CMake, I started learning about it a couple months ago and it's made my life a lot easier.
Seriously, a program is not simply either in a full integrity or no integrity state. The program can have integrity in terms of technical correctness, but can run in some suboptimal way that you will not know about unless you care about these "non-actionable" errors. The overhead I'm proposing is minimal. All it requires is a change of logic so that instead of calling `std::terminate`, you join my exception to the one that's already in-flight. The most overhead this might require for you is an implicit try/catch around `noexcept(false)` destructors, and an extra pointer in `std::exception`. But we can't have that, because the world has to comply with your ideas about non-actionable errors?
&gt; A weakpoint with Make is with respect to managing dependency relationships that are documented in the code, like header files. make handles dependencies just fine. My Makefile has perfect incremental rebuilds, and it takes just a few lines.
&gt; In my case, probably log all 10 failures, and continue with the rest of the program after unwinding that part. In that case why no just do that logging from the destructor? &gt; If I want to detect errors in resource cleanup, you're having me do resource cleanup twice: It's proper division of responsibility. The destructor is responsible for one thing and one thing only (cleanup). Detection of errors is a separate responsibility and you need another pass for it. &gt; If terminating was always appropriate, we would not need exceptions. I didn't say it was always appropriate. I certainly agree that there are exceptional cases that don't indicate errors in the program and don't warrant termination.
If using MSVC, check [this](http://lists.boost.org/boost-users/2015/07/84620.php)
&gt; The program can have integrity in terms of technical correctness, In that case it would be in the "full integrity" state. But you were talking about a double-close, which indicates a serious bug and does compromise integrity. &gt; All it requires is a change of logic so that instead of calling std::terminate, you join my exception to the one that's already in-flight. If you really wanted to, I think you could do that with std::set_terminate. &gt; and an extra pointer in std::exception. Not all exceptions derive from std::exception. &gt; But we can't have that, because the world has to comply with your ideas about non-actionable errors? I am not in charge of C++. But I suspect you'll get similar answers from the committee if you do write this up as a formal proposal.
I just copy-paste a small backtrace function in every project and bind it as a SIGSEGV handler.
I did say that it takes just a few lines. Complaining that make doesn't handle dependencies is like complaining that C++ doesn't handle flexible-length sequences until you include &lt;vector&gt;.
&gt; LLVM also has a re-implementation of the libunwind interface in libc++ Not anymore. They've been properly split up into two separate repositories now.
Wait, when did it become no longer maintained?! Last I saw, they detemplatized a lot of the logic to speed up compile times (and in reality, compile times with templates have been getting better and better, so I'm not sure if that is as bad as it once was).
The simplest counter-example to your argument of "destructors should never fail" is scope guards: http://www.boost.org/doc/libs/1_58_0/libs/scope_exit/doc/html/scope_exit/alternatives.html There's absolutely no way of implementing them without allowing them to throw in a destructor. The C++ standards body only mandates invoking std::terminate when throwing from a destructor while already unwinding because the question becomes which exception gets propogated. That does not necessarily mean that it's a design feature as opposed to a reasonable compromise due to the current implementation nor that it can't be changed; I do not know how the standards body as a whole feels about this topic although I suspect it runs the gamut of opinions.
I seem to be missing something here. Why do you need failing destructors to implement scope guards?
&gt; I'd probably want to guarantee that above all-else, the privacy invariants are enforced which is trickier when the application crashes It seems to me like this is something you'd really want some kind of out-of-band mechanism (OS support or at the very least another process) for so that the privacy invariants are maintained even if your process is aborted without notice through no fault of its own (e.g. OOM killer). &gt; The other common scenario is running commands on scope-exit. The only way to do that is using destructors &amp; it's silly for those not to be able to throw exceptions. I don't think it's silly - they really are destructors and the arguments in my other comments on this page apply. If C++ had a real "try-finally" construct I would expect the finally block to have all the same restrictions that a destructor has. &gt; Ignore the comments that say that destructors shouldn't throw. The standards body disagrees with that assessment at least somewhat; otherwise we wouldn't have std::uncaught_exceptions: uncaught_exceptions() is useful for ScopeGuard in order to reliably determine if the destructor is being run as a result of unwinding (failure case) or as a result of a normal scope exit (success case). Neither involve exceptions propagating out of destructors (though they may involve an exception being thrown during a execution of a destructor and being caught before said destructor exits, which is perfectly fine).
[`stddef.h`](http://port70.net/~nsz/c/c89/c89-draft.html#4.1.5) exists since C89.
&gt; all the secondary process needs to do is to monitor the primary process and, if the primary process disappears for any reason, take responsibility for ensuring the privacy guarantees I'm not sure I understand. How are the secondary process &amp; primary process going to co-ordinate this ballet? The primary process gets restarted automatically if it's in the middle of servicing some kind of request (applying the privacy policy is a periodic external request from the OS). Yes, privacy guarantee is maintained if OOM killed (within reason) or if we crash for any reason. &gt; Then if the process gets terminated there will be no open handles to the file and the OS will clean it up. Though perhaps that's too heavy handed. There's a reason we have a cache. If we didn't the user's cellular bill would be astronomical &amp; our performance would be terrible since we'd have to go out to the network all the time before we could yield results - the cache has to be populated for us to do any kind of work.
Why not just build a malware program that infects the OP's computer?
D is not C++. It is not at all obvious that the design or implementation language features in D translate cleanly or easily to C++. For example, my reading of the current proposal makes this valid: void f() { static_if(false) { extern void g(); } g(); } Should it be? Based on my reading, yes. Does that match the intent of the proposed feature? Probably not. What about this? void f() { static_if(false) { std::vector&lt;int&gt; v; } } Is the default constructor for `vector&lt;int&gt;` instantiated or not? It's certainly well-formed, so it seems like it should it should be instantiated. Said otherwise, is that constructor ODR-used? It's an important question for compilers. And these kinds of questions layer nicely, especially if you have non-dependent lambdas inside static ifs whose definitions instantiate other templates or contain extern declarations. Are these questions about more subtle aspects of the C++ language? Certainly. Are these examples included in Faisal's test suite (comment below)? No. Am I guilty of overlooking similar obscure language interactions for Concepts Lite? Absolutely. Are these kinds of questions related to how useful the feature is? No. My point is that language proposals for C++, even the ones that seem simple because e.g., they appear in other languages, are rarely trivial. There are always subtleties.
It would be the equivalent to writing this: template&lt;class T, typename std::enable_if&lt;( std::is_convertible&lt;T, std::string&gt;() || boost::fusion::traits::is_sequence&lt;T&gt;() || boost::fusion::traits::is_sequence&lt;T&gt;() || is_variant&lt;T&gt;() || is_streamable&lt;T&gt;() )&gt;::type&gt; void print(const T&amp; x) { static_if(std::is_convertible&lt;T, std::string&gt;()) { std::cout &lt;&lt; x &lt;&lt; std::endl; } else static_if(is_range&lt;T&gt;) { for(const auto&amp; e:x) print(e); } else static_if(boost::fusion::traits::is_sequence&lt;T&gt;()) { boost::fusion::for_each(x, [](cosnt auto&amp; e) { print(e); }); } else static_if(is_variant&lt;T&gt;()) { boost::apply_visitor(fit::result&lt;void&gt;([](const auto&amp; e) { print(e); }), x); } else static_if(is_streamable&lt;T&gt;()) { std::cout &lt;&lt; x &lt;&lt; std::endl; } } So those conditions to `static_if` become the union of all the conditions, but being able to do it at function scope its not necessary to repeat the conditions. &gt; Is this declaration legal? It overlaps with the one you gave above. What if it were in a different translation unit? It would be the same as now if you had a function define like this: template&lt;class T, typename std::enable_if&lt;( std::is_convertible&lt;T, std::string&gt;() || boost::fusion::traits::is_sequence&lt;T&gt;() || boost::fusion::traits::is_sequence&lt;T&gt;() || is_variant&lt;T&gt;() || is_streamable&lt;T&gt;() )&gt;::type&gt; void print(const T&amp; x); And another defined like this: template&lt;typename T&gt; typename std::enable_if&lt;boost::fusion::traits::is_sequence&lt;T&gt;(), void&gt;::type print(T const&amp; x); It would be an ambiguous overload resolution failure when called with a fusion sequence. 
Can you go I to more detail?
Why not a reference?
You cannot reasonably claim that the same error is simultaneously: - OK to ignore; - a valid reason for whole program abort. This is what you guys - I'll call you destruction error denialists - are claiming. At the same time, I should be ignoring the error, *and* terminating my entire service over it. Why are you made so uncomfortable by the possibility that a destructor error *could* be a type 2 error, where partial program unwinding is appropriate? You are hand-waving in order to coerce *all possible types* of destructor errors into being either type 1 (whole program abort) or type 3 (OK to ignore), *not because you're actually sure* that this is the case; but just because you don't want to make the minor adjustment of allowing destructor errors to be type 2 errors. You're putting the cart ahead of the horse. *First* you must allow for the possibility that destructor errors can be type 2 errors. *Then* you make a decision whether a particular error is type 1, 2, or 3; when you're no longer being coerced to choose between 1 and 3 only.
&gt; If you really wanted to, I think you could do that with std::set_terminate. These are suggestions for more hacks. While I have no doubt that `std::set_terminate` can be useful, a library certainly cannot call that. You may want to see a [similar reply](https://www.reddit.com/r/cpp/comments/3dlm12/errors_in_destructors_and_the_case_for_aggregate/ct6uiia) I made to /u/foonathan, who makes a similar argument. The reason I'm making this proposal is because I feel coerced - and in fact *am* coerced - to treat *all* destructor errors as either type 1 errors (abort) or type 3 errors (ignore). This bothers me, and I do not wish to be so coerced. I find it presumptuous for you to make blanket statements that all destructor errors are either type 1 or type 3, without having opened your mind to the possibility that type 2 may be useful in reasonable scenarios. You *first* need to allow for the possibility that destructor errors *could* be suitable for partial unwinding via exceptions. *Then* you decide whether a particular error requires treatment of type 1, 2, or 3. If you lack proper support, your choice is biased by that the current support is poor, and that you can't imagine a world where it isn't. You may become convinced there is no need for it, because you've worked around the lack of *possibility*. Then you defend the continuing lack of possibility by that there isn't perceived need. This is *at least partially* circular logic. By this reasoning, we can't have language improvement.
`std::reference_wrapper` is though.
&gt; Yes, privacy guarantee is maintained if OOM killed (within reason) or if we crash for any reason. Okay, in that case never mind - I was trying to solve a problem you don't have. In any case, this particular example seems to not be relevant to the topic of exceptions since it's solved at the system level rather than the process level.
&gt; You cannot reasonably claim that the same error is simultaneously: &gt; &gt; * OK to ignore; &gt; &gt; * a valid reason for whole program abort. I am not saying that. I am saying that *most* kind of errors that can occur in cleanup functions are precondition violations. And precondition violations should mean program abortion. But since those precondition violations can *never* occur if you use proper RAII, the checking *could* be omitted. I am not saying to ignore precondition violations, I am saying that they cannot occurr and thus don't need to be checked. For the other, very small percentage of cleanup errors, like the network down for closesocket(), it *might* be the appropriate way to throw an exception, your error handling type 2. But I personally wouldn't do it, even if I had the language support for it. In addition, it is such a small percentage, a language extension isn't really worth the trouble.
&gt; So far all the ones you have mentioned here really should be type 1 (like double close of socket) or type 3 (like network went away while we were closing socket). The ones you want to handle as type 1 or 3 (abort or report) are the ones I want to handle as type 2 (exception). This is not because I never do aborts, but because I think *in this particular case* it's the wrong option. This is not just about one resource; it is in practice any number of resource types, provided by any number of OS facilities. Some of those facilities are buggy; others are modular, and they allow third party implementations that are buggy. If something goes wrong, related to one of those facilities, I want to know. But I have the following issues: - My software runs outside of my control. If I just log warnings, users will absolutely ignore them. I need the issue to be reported by that one user who experiences the issue, not by someone from the 99 that don't. - I need to change behavior in a way that impacts the user so they will report the issue. Whatever they wanted to do, I can't allow them to finish doing. Otherwise, most of them have no inclination to bother reporting. - But I can't just *crash* my service, because that won't be perceived as something that just happened to go wrong with a particular *task*. It will be perceived (arguably rightly) as an unstable, unreliable service. - Depending on how the circumstances are triggered, crashing the service also creates a denial of service attack. I have to balance all of these considerations, and the way this tends to work out in practice is that type 2 errors are *almost always* what is best for me to do. Destructor errors included. Now *in addition to that*, there's the potential for destructors to be more than just little cleanup fairies. They are in fact powerful tools for scheduling code to execute, except that using them this way is currently considered borderline abuse, because of the known problems with exceptions from destructors. If we solve exceptions from destructors, then this becomes a powerful and fully supported usage case. It would legitimize many existing situations where destructors are currently used this way, such as - but not limited to - various database libraries (which I do not personally use, but I have seen mentioned as examples).
There's nothing wrong with writing Makefiles by hand if your needs are simple but the problem is that pretty soon you start requiring more stuff. - support for multiple compilers - support for build types (debug, optimized etc) - unit tests - support for clang sanitizers, valgrind, cppcheck, other tools - proper dependency tracking - and so on Adding support for any one of these in plain Make is not that difficult. Making more than one work properly together and not break every now and then is *hard*. Any time you spend massaging your makefile is time you are not coding. Not coding means not getting your problem solved. Using a higher level build tool that does all that automatically is usually worth it. I recommend [Meson](http://mesonbuild.com/samples.html) but I'm biased because I wrote it. :)
&gt; You'd actually want to do something other than immediately crash if a double-close is detected? It's like you're ignoring what I wrote about the nature of the various OS facilities. If I'm detecting a cleanup error, I have no way of knowing that the reason for that is in *my* process. And it's not like I'm not doing anything about it. You're ignoring what I wrote about changing behavior so that the user will report the issue. How does the fact that I'm making a proposal about error handling, and discussing this with you *in the first place*, lead you to think that I "don't care" about errors? You're better off and safer using my software than open source alternatives; I can tell you *that* for sure. &gt; It sounds like you're trying to build on something unstable and unreliable, Please don't make these insulting assumptions. I don't even build on the *STL library* because much of it is too unreliable for me. This is not to say my replacements have no bugs, but I can fix bugs that I find in *my* library. We have detected and had to work around even OS bugs, when it comes to some issues. Our software does some really advanced stuff that has to be done 100% right in order to deliver a service that seems trivial to people who observe it. We are highly concerned with doing things right, and this proposal is part of that process. &gt; It'd be like a program that has gotos everywhere. It's a pattern enough people want to use. *My* database doesn't commit transactions via destructor, but some others do. This brings me back to the point of what makes C++ great: for the most part, it doesn't try to foist someone's righteous ideas on you. What you're espousing is this type of righteousness. What you don't recognize is that this righteousness is actually *unwillingness to serve*, and is what makes a language less attractive, and a platform less appealing. Appealing languages and platforms do not shoehorn; they accommodate. &gt; It would be a bigger change than that from C++98 to C++14. It would be fully backward compatible. Behavior of existing programs would not change. No one would be harmed if they followed old ideas about exceptions and destructors, except that such ideas would become unnecessary.
&gt; If I'm detecting a cleanup error, I have no way of knowing that the reason for that is in my process. It sounds like we're talking at cross-purposes here. Are you still talking about double-close, or is there another "cleanup error" that you have in mind now? A double-close would definitely be your process's fault. It's really hard to have a discussion about something if we don't both have the same specific example in mind. &gt; It would be fully backward compatible. Behavior of existing programs would not change. I wasn't talking about change in behaviour of programs, but about change in meaning of C++ constructs.
&gt; Are you still talking about double-close, or is there another "cleanup error" that you have in mind now? I was never talking only about double-close. I was always talking about the general case of calling an OS cleanup function, which happens to return an error. At development-time, I can't, and don't want to, analyze in advance an error code that shouldn't happen. I want to postpone deciding what it is until it happens. If the OS function does not succeed, I don't know what error it might return. I don't know why. I don't know what the proper response should be, because I don't *expect* the error. Given my confidence, and past experience, if I receive an error from the OS, it's *probably* going to be the OS's fault. Therefore, if this happens, I'm not going to assume it's my error, and crash the process. But I *do* want to know about this error, and I *do* want it to be reported to me. Therefore: exception.
And is implemented as a pointer... Edit: downvoters: Here is the libc++ code for reference_wrapper. template &lt;class _Tp&gt; class _LIBCPP_TYPE_VIS_ONLY reference_wrapper : public __weak_result_type&lt;_Tp&gt; { public: // types typedef _Tp type; private: type* __f_; /// &lt;&lt;&lt;&lt;&lt; pointer here public: // construct/copy/destroy _LIBCPP_INLINE_VISIBILITY reference_wrapper(type&amp; __f) _NOEXCEPT : __f_(_VSTD::addressof(__f)) {} #ifndef _LIBCPP_HAS_NO_RVALUE_REFERENCES private: reference_wrapper(type&amp;&amp;); public: // = delete; // do not bind to temps #endif // access _LIBCPP_INLINE_VISIBILITY operator type&amp; () const _NOEXCEPT {return *__f_;} _LIBCPP_INLINE_VISIBILITY type&amp; get() const _NOEXCEPT {return *__f_;} // invoke template &lt;class... _ArgTypes&gt; _LIBCPP_INLINE_VISIBILITY typename __invoke_of&lt;type&amp;, _ArgTypes...&gt;::type operator() (_ArgTypes&amp;&amp;... __args) const { return __invoke(get(), _VSTD::forward&lt;_ArgTypes&gt;(__args)...); } };
How do you mean? There's no magic. My process maintains the privacy. We have a very high priority when we say we're doing work (which includes when we do the cache scrubbing). That means other processes get OOM'ed before us. If we fail to check-in as completed for our privacy check schedule, we'll get relaunched. We don't use much memory for doing this check. Thus: 1. Other processes using memory get killed first 2. If we have a bug where we use a lot of memory (i.e. memory leak), we get killed, relaunched requesting the privacy policy be applied. The problem here is that our application does: 1. Open a transaction (this is a write) 2. Deletes rows from the database handle (this can fail because deletes in SQLite are equivalent to writes). 3. Commits the transaction on success, rollback if #2 throws any kind of exception. If this operation fails for any reason, we just truncate the database safely &amp; move-on. The problem is that #3 can throw an exception for the same reason that #2 did but I have no way to represent this fact; I just have to drop the rollback exception &amp; hope for the best.
&gt; if we were allowed to change the on_success() to on_exit() we'd have two exceptions in flight and it's not obvious which one we'd want to catch. Exactly. There were a few suggestions here on how such a thing would work. I agree that it's a difficult design to figure out how to make work; maybe the answer is that there's no "good" answer &amp; the language stays as-is. Keep in mind however that Java has the same problem &amp; their answer is not "terminate the program". &gt; SushiAndWoW is calling a "type 3" error - one that should lead to instant termination of the program on discovery, but perhaps a more concrete example could change my mind. My understanding is he's saying "type 1" is instant termination &amp; "type 3" is ignore. And he's also saying that he wants a middle-ground. Now I don't know if this necessarily needs a language feature. It can probably done more robustly &amp; correctly as a language feature, but there are ways around it if you are in control of all your exceptions; for example you could make sure all exceptions inherited from something like nested_exception except so that you could attach it to the existing exception instead of having to generate a new exception.
I'm just trying to point out the limitation of the existing policy. I agree with you that there is a problem here. I don't know if it can be addressed by the language or would be. It could be that this is possible to implement at the library level without any language changes. Think something like std::nested_exception except that it would just let you record additional exceptions as the stack unwound. Try floating your idea on the forum: https://groups.google.com/a/isocpp.org/forum/#!forum/std-proposals Make sure you outline specifically what your problem is with compelling examples - file close is not (I've tried) but the transaction case I described may be; I'm sure you must have one that spurred this post. Try to avoid stating any specific solution (&amp; definitely no terminology or keywords); otherwise people will get entrenched debating (or outright rejecting) your proposal instead of discussing the problem you're trying to solve. Only once there's agreement that there's a problem do you want to try brainstorming solutions. Also keep in mind that this has been the behaviour of C++ for a long time so there's quite a burden of proof on your shoulders to demonstrate this is something that needs addressing.
&gt; My process maintains the privacy. But if it can do that even in the face of the process being terminated, it's nothing to do with exceptions. That part of it would work just as well if it were written in C. &gt; The problem is that #3 can throw an exception for the same reason that #2 did but I have no way to represent this fact; I just have to drop the rollback exception &amp; hope for the best. I believe the usual pattern here is to have a flag in the object which is set after commit returns successfully. In the destructor the flag is checked and the transaction rolled back if it wasn't set. The rollback is a "cleanup" action but the commit isn't. Yes, this does mean that you have to write the commit() call explicitly (it doesn't happen automatically at the end of the scope). I'm fine with that. If you're finding that you need to put in multiple commit() calls, one for each early return from a big function, it's a strong signal that this big function should be refactored.
&gt; There's a massive amount of extant C++ code which assumes that destructors provide the nofail guarantee. I have control over my entire code base on purpose. I only need (1) language support so that I can use this, and (2) library support - ... which I only need marginally, since I mostly use my own containers, anyway. It would be nice to see STL-wide support for multi-exceptions. I think having an `std::vector` of 1,000 objects, and allowing any number of them to throw, would be quite marvelous. It would remove a defect from the language: this is that you can make `noexcept(false)` destructors, but you can't safely store objects with them in containers. But I don't *really* need STL support. What I *do* really need is for the language to give me *some* way to aggregate an exception to another that's already in flight. It could even be just by allowing me to access (and manipulate) `std::current_exception` from a destructor if `std::uncaught_exception` returns true. But seeing support for this in the language would be marvelous, and it really wouldn't take much. Yes, it would change some fundamental concepts, but *far* for the better. Have you considered that `noexcept` is a really ugly kludge? That it stratifies code in (1) code that throws, and (2) code that doesn't? That it basically creates two languages in one? Have you considered that all of this is unnecessary complexity, that's *only* necessary as a workaround for the lack of support for multi-exceptions? I wish you could see how ugly this is, and how simply marvelous it would be if we just added proper support for multi-exceptions. It would just work! You would simply never have to worry about destructor interaction with exceptions.
&gt; But if it can do that even in the face of the process being terminated, it's nothing to do with exceptions I'm probably not explaining myself well enough. Yes, the process can guarantee invariants in unclean shutdown scenarios. However, unclean shutdowns are not the expected resolution mechanism. So while crashing is not fatal &amp; a general-purpose recovery mechanism, crashing itself is a deemed a bug too. &gt; I believe the usual pattern here is to have a flag in the object which is set after commit returns successfully. In the destructor the flag is checked and the transaction rolled back if it wasn't set Great. That's how my code works. However, rolling back can fail (&amp; probably will for the exact same reason that the write did). So now in my destructor I am rolling back during stack unwinding &amp; I'm boned. The compromise I made recently was to just ignore rollback failing in the destructor.
Isn't the strawman solution then to just make std::current_exception() return not null or expose a std::unwinding_exception() that would let you get the exception_ptr for the exception currently in-flight?
&gt; That also means that the destructor is extremely complicated with try catches everywhere trying to figure out the cause of the current exception. /u/SushiAndWow seemed to indicate that wouldn't work although I believe I unit tested this behaviour. I'm not sure if I understand exactly what you're describing. Can you explain in more detail? If you're referring to my most recent comment about `current_exception` not being available in destructor during unwinding - what I tested right now is this: #include &lt;exception&gt; #include &lt;iostream&gt; #include &lt;ios&gt; using namespace std; struct A { ~A() { cout &lt;&lt; "~A: " &lt;&lt; endl &lt;&lt; "uncaught_exception: " &lt;&lt; boolalpha &lt;&lt; uncaught_exception() &lt;&lt; endl &lt;&lt; "current_exception: " &lt;&lt; boolalpha &lt;&lt; !!current_exception() &lt;&lt; endl; } }; int main() { try { A a; throw 0; } catch (int) { cout &lt;&lt; "catch handler: " &lt;&lt; endl &lt;&lt; "uncaught_exception: " &lt;&lt; boolalpha &lt;&lt; uncaught_exception() &lt;&lt; endl &lt;&lt; "current_exception: " &lt;&lt; boolalpha &lt;&lt; !!current_exception() &lt;&lt; endl; } } This is what I get with GCC 4.9.2 -std=gnu++11 or 14: ~A: uncaught_exception: true current_exception: false catch handler: uncaught_exception: false current_exception: true Same thing with Visual Studio 2013.
so are references
&gt; I have control over my entire code base on purpose. Good for you. But when considering what features to add to the language, the C++ committee does take into account code that already exists and the needs of template library authors. Rather than continuing to argue about this, I would like to propose a challenge: can you write a version of std::vector which can store DMF objects and maintain the strong exception safety guarantee? In the spirit of C++'s "you don't pay for what you don't use" principle, this container should have no space or time overhead over the existing std::vector in the case where no exception is thrown. &gt; Have you considered that noexcept is a really ugly kludge? Arguably it's not "noexcept" that's infectious but exceptions themselves. We already have those, though.
Well I see no harm in requiring `noexcept(false)`. I'm not sure why you need to resort to macros. The general logic would look like: ~Foo() { try { ... } catch (...) { auto unwinding = std::unwinding_exception(); if (!unwinding) { throw; } auto ex = std::current_exception(); try { std::rethrow_exception(unwinding); } catch (my_exception_base&amp; e) { e.add_suppressed(ex); } } } Which can be abstracted by a helper function so that it's less messy: ~Foo() { suppress_if_unwind([this] { ... }); } where `suppress_if_unwind` does the catch logic: template &lt;typename F&gt; void supress_if_unwind(F&amp;&amp; callback) { try { callback(); } catch (...) { auto unwinding = std::unwinding_exception(); if (!unwinding) { throw; } auto ex = std::current_exception(); try { std::rethrow_exception(unwinding); } catch (my_exception_base&amp; e) { e.add_suppressed(ex); } } }
Yeah. My logic still behaves correctly - all the try/catch stuff in my destructor is just dead code I'll remove shortly.
Would be interesting to see, if using make_shared has any more effect on your code. It would turn 2 allocations into one.
Appeal to authority is by no means a logically invalid argument; it can be a fallacy when done incorrectly but I was very careful on this so I think I'm OK. Certainly if my doctor says one thing &amp; my barber says another I'm going to trust the doctor's opinion. The barber has a higher burden of proof whereas the doctor has a lower burden of proof. Similarly, between someone I don't know on reddit &amp; the EWG chair, I'm going to give more weight to that persons arguments by default; AFAIK attaining Ville's position requires technical merit &amp; the support of your peers. I also stated that his proposal lines up exactly with my experience of writing lots of templates. Ville is presenting "static_if lite" to address the valid technical concerns raised in Andrei's brilliant &amp; ambitious initial proposal. Why are you presuming there are tribes? Bjarne came out very critically of Andrei's proposal but Ville's is much reduced in scope. /u/sbabbi seemed to basically say "if you're not familiar enough with C++ templates to implement this complex piece correctly, then don't do it". He's entitled to his opinion but not only is it not at all the counter-arguments Bjarne &amp; co had made, the logical path for me seems to take Ville's proposal more seriously than a random counter-attack by someone I don't know, especially since it's dangerously close to the no-true Scotsman fallacy.
This : http://goo.gl/vNLCz3
Why not use `unique_ptr` everywhere? Who's sharing?
In your Create-function you should be using make_shared and in the Pimpl-constructor make_unique. In your for-loop you should stop copying shared_ptrs (thereby fiddling with the atomic reference count). Comparing the two memory allocations of the Pimpl case (shared_ptr + unique_ptr) to one memory allocation with the abstract base class (only shared_ptr) is not a fair comparison (especially considering that in this test, as it stands, the time spent on memory allocations will largely outweigh the time spent iterating).
&gt; In your for-loop you should stop copying shared_ptrs I tried to fix that in the Core Language.
From the manpage (http://man7.org/linux/man-pages/man2/close.2.html) Not checking the return value of close() is a common but nevertheless serious programming error, and is the mark of a bad programmer. It is quite possible that errors on a previous write(2) operation are first reported at the final close(). Not checking the return value when closing the file may lead to silent loss of data. This can especially be observed with NFS and with disk quota. Note that the return value should be used only for diagnostics. In particular close() should not be retried after an EINTR since this may cause a reused descriptor from another thread to be closed. A successful close does not guarantee that the data has been successfully saved to disk, as the kernel defers writes. It is not common for a filesystem to flush the buffers when the stream is closed. If you need to be sure that the data is physically stored, use fsync(2). (It will depend on the disk hardware at this point.) It is probably unwise to close file descriptors while they may be in use by system calls in other threads in the same process. Since a file descriptor may be reused, there are some obscure race conditions that may cause unintended side effects. I pray that I'll never have to use a product you developed, or that anyone's life depends on software you create. 
Thanks for the detailed answer! I changed my file structure and makefile. I am reading up on how to use CMake 
At first glance decltype doesn't seem very useful. And in my opinion unless you're using a fair bit of templates it may not be. But if you are using templates it can make things very nice. It allows you to write generic code like the following: auto thing = functionWhichReturnsSomethingTemplatedAndNasty(); MyCoolType&lt;decltype(thing)&gt; newTemplatedType; Which makes it easier to use templated objects, particularly helpful in unit tests with mock objects. 
You use it to figure out the type of an expression or variable. So for example: int main() { int x; decltype(x) y; // declare a variable y with the same type as x } To understand where this would actually be useful you need to already have a pretty firm grasp on the basic style of programming in C++ and be moving on to the more advanced, "Generic programming" facilities. In the above program, the obvious point is "why would I need `decltype(x)` when `x` is right there and I know the type, so I can write `int y;`? In 'Generic' programing you _don't_ necessarily know the types of things and you need to be able to 'compute' types, in the same way that regular programs 'compute' values. `decltype` is just one of the operations that helps make computation with types convenient.
I see two potential problems with this test; A) Using ptr to a pimpl object misses the point. Usually one uses pimpl for value types, not polymorphic types, otherwise we would use the base class interface as in the Abc test. I think it's only fair to compare the respective expected use cases. B) I'm not convinced that the complier didn't devirtualize and inline the functions in ABCTest. I suspect it did and the slow down was caused by the extra 8 bytes of object size for the vtable ptr. I would investigate that. Note: I posted the same comment under r/programming before I saw the post here. 
It deduces the type of a declaration. It's useful when writing generic code, because in such cases you don't always know the types ahead of time. `decltype()` lets you express things such as "this function has the same return type as whatever type `foo.bar()` would return" or "declare a variable that has the same type as this other variable, whatever that is." Maybe you could post whatever example from the book that you're having a hard time understanding and will can answer any questions about it and why it's doing what it's doing. 
The alternative to `static_if` isn't to use SFINAE, it's to use tag dispatching, the very method recommended by your second appeal to authority, Stephan T Lavavej.
This is actually cool information, but crowds are not good at separating substance from presentation and so we end up with ad hominem downvotes. 
I can't figure out what kind of deep game lolzfeminism is playing, but I'm pretty sure they were referencing "Real Men Don't Eat Quiche". I really hope it was meant ironically &lt;shudder&gt;.
You're probably corrupting memory somewhere. With a self-contained example, we could figure out where. But the real problem is that someone is teaching you C++ in the wrong way. You should be using vectors and other STL data structures as a beginner; new/delete and raw pointers (especially pointers to pointers) are an advanced topic. This lesson cost me a year and a half of my life to learn - I give it to you freely.
Nobody is going to be able to tell you anything at all without a testcase, i.e. a complete — but minimal — program. Remove everything extraneous and whittle it down to 20 - 30 lines and post that. Posting snippets of code (that is, portions of the code but not enough of it that we can actually build it ourselves) is completely useless because by definition you don't know where the problem is so you don't know which parts are and are not relevant. Please read [sscce.org](http://sscce.org/). 
Assembly and machine instructions have no notion of pointers. What I was trying to say was that "references are implemented as pointers" makes no sense. What you have shown is that use of pointers/recerences results in same disassembly (no problem there). But, for example, the conceptual intention of your functions is fundamentally different. When you use a pointer, you're saying: here's an *optional* parameter. When you use a reference, optionality is gone. At best, one can say something along the lines "references are like pointers, but constrained in functionality, e.g. so that you can't change the pointee, they can't be null, you can't pointer arithmetic on them...".
[Real Programmers don't use Pascal](http://web.mit.edu/humor/Computers/real.programmers) Check it out, hilarious read. It's a parody of "real programmer" culture and the "real men don't eat quiche" article. Yes, it was tongue in cheek.
Okay, I think I understand your case better now. I'm still surprised that rollback can fail, even due to lack of disk space. The information it needs to be back in the rollback state must be on the disk already, all rollback should be doing is setting a flag. But I get that's out of your control - perhaps it's trying to log that a rollback happened and there's no space to store that log entry or something like that. Has "rollback failed" actually happened in your testing? Is it a sufficiently common situation to be worth expending effort (other than terminating the process) over? It seems you have one of those engineering tradeoffs where none of the solutions is really ideal. Possible solutions that spring to mind: * Ignore errors from rollback (what you said you're doing now) on the grounds that the rollback must have actually succeeded but returned an error code for reasons that you don't care about. * Throw an exception from the destructor only if there's no exception already in flight. In C++17 we'll have uncaught_exceptions() and be able to do this reliably but for now you'd just have to take care that your whole transaction commit/rollback block is not itself called during unwinding (which should not be a big deal). If the commit failed you lose the information that the rollback also failed, so you've got to check for that in the catch block or just assume the database needs to be truncated whenever the commit fails. * Throw the exception from the destructor regardless or otherwise let the process get terminated in the commit+rollback both failed case. I appreciate that you don't want to do this if you completely understand what's going on, and can trust the integrity of your process, and this happens often enough that the terminations would be annoying. * Put the call to truncate the database in the destructor itself. I think this one has some merit, but I can how it might be rejected on division of responsibility concerns. * Set a flag somewhere saying "rollback failed" and remember to check it. That's like going back to the bad old days before exceptions though. * Change the language to have first-class support for exceptions leaving destructors, as SushiAndWoW wants. That has its own (severe) drawbacks as I've gone into elsewhere on this topic. There may be others that I haven't thought of.
If you think of it as an way to help enforce pre and post conditions for every function that takes or returns the nn pointer it makes more sense. 
Although I see what you are trying to do, it would actually be very complex to implement (or maybe even impossible) in a way that is compatible with existing code. If you have some class Derived : Base, and the destructor of Derived throws an exception, what do you do with Base? Do you still run it's destructor too? At the very least, you'd need to have a special syntax for throwing within a destructor while still allowing the base class destructors to run. On top of this, every destructor call (or else function call) is going to have to check for these deferred exceptions, so you're adding a bunch of conditional branch instructions to a lot of code, which seems a bit excessive.
&gt; can you write a version of std::vector which can store DMF objects and maintain the strong exception safety guarantee? Yes, of course. That's... the *core* my proposal. :) The whole reason it doesn't work now is because, even if the container stores an exception from the *first* destructor that throws, and saves it to rethrow after the current container operation is complete; the container has no way to handle *multiple* throwing destructors. With aggregated exceptions, the container saves any and all exceptions encountered during container operations; and then, just rethrows them as a bunch. &gt; In the spirit of C++'s "you don't pay for what you don't use" principle, this container should have no space or time overhead over the existing std::vector in the case where no exception is thrown. Sure! Conditionally omit the exception aggregation if the vector element type has a `noexcept` destructor. &gt; Arguably it's not "noexcept" that's infectious but exceptions themselves. Oh, crikey.
&gt; it would actually be very complex to implement (or maybe even impossible) in a way that is compatible with existing code. Actually, the opposite. My proposal is lightweight and fully backward compatible. You do not seem to be aware that most of this is how destructors in C++ already work. My proposal is not a major departure from existing functionality. It mainly just introduces a new catch handler type that can be called to handle multiple exceptions. &gt; If you have some class Derived : Base, and the destructor of Derived throws an exception, what do you do with Base? This is supported by C++ as-is, and remains unchanged in my proposal. If Derived throws an exception, the Base destructor is still called. If the object is being destroyed via `delete`, then `operator delete` is still called. &gt; At the very least, you'd need to have a special syntax for throwing within a destructor while still allowing the base class destructors to run. This is already fully supported by the language. You can use `noexcept(false)` destructors, and they work perfectly well, you can throw and all is destroyed fine. The problem currently is that destructors can't throw even if they wanted to if an exception is already in flight, and it isn't safe to store such objects in containers. Under the single-exception policy, a container cannot store and forward 2 or more exceptions that happen during e.g. resizing. This is the reason for the push to `noexcept` destructors. These are issues that aggregated exceptions address: providing mechanisms to allow destructors to throw *always*, and allowing such objects to be stored in containers. No more holes to plug with the `noexcept` kludge. &gt; On top of this, every destructor call (or else function call) is going to have to check for these deferred exceptions, so you're adding a bunch of conditional branch instructions to a lot of code, which seems a bit excessive. All of those conditional branches are already there. Currently, they call `std::terminate`. With multi-exceptions, they would call something like `std::aggregate_exceptions`.
I don't understand something. Pimpl is used for hidding code. With abstract class the code is not hidden. The advantage of hidding a code is that the user may continue to use the API without knowing anything about the internal code. So it will not be tempted by using internal features and it is more convenient for the code to evolve.
I agree. I also support this idea which is simple and that will simplify the life of programmers even, espacially when reading a code another person wrote
&gt; What would you envision as the syntax for catching and testing for the existence of these aggegate exceptions? This is the most crucial part to get right. The other answers are pretty straightforward, but this is the main question that hasn't been answered, historically. Based on feedback so far in the C++ standards group, the following is my current proposal: 1. To maintain the meaning of existing programs as much as possible, a traditional catch handler cannot receive an exception-list that contains more than one exception. If an aggregated exception meets a traditional catch handler, then to preserve current behavior, `std::terminate` must be called. This means we need a new catch handler to handle multi-exceptions. 2. Notwithstanding the above, we make an exception for `catch (...)`. This is often used in finalizer-type patterns that catch and rethrow, and do not care what they're rethrowing. This type of catch handler should therefore be able to catch and rethrow exception-lists also. It also provides a method to catch and handle an exception-list as a whole. 3. We introduce the following new catch handler type: catch* (&lt;exception-type&gt;) { We call this a "catch-any" handler. It has the following characteristics: - It matches every occurrence of a matching exception in an exception-list. This means it can be called repeatedly, multiple times per scope, if there are multiple matches. We cannot do multiple calls to traditional handlers, because traditional handlers are not necessarily multi-exception aware, and do not expect to be called multiple times in a row. - All catch-any handlers must appear BEFORE any traditional catch handlers in same scope. This is because the catch-any handlers filter the list of exceptions, and can be executed multiple times and in any order, whereas the traditional catch handler will be the ultimate handler if it matches. (Also, because the traditional handler will `std::terminate` if more than one exception remains in the list.) - If there are multiple catch-any handlers in the same scope, they will be called potentially repeatedly, and in an order that depends on the order of exceptions in the exception-list. - If a catch-any handler throws or re-throws, the new exception is placed back into the list of exceptions currently being processed, at the same position as the exception that triggered the handler. If there remain exceptions in the list, the search of catch-any handlers continues, and the same catch-any handler might again be executed for another exception in the list. - If a catch-any handler exits without exception, the exception that matched the handler is removed from exception-list. If this was the last exception, forward progress resumes outside of catch handlers. If more exceptions are in list, other catch-any handlers at current scope are tested; then any catch handlers at current scope are tested; and if there's no match, unwinding continues at the next scope. 
invoking a constructor?
Ah, you're right, answered too fast
I believe Richard Smith suggested that code within a false branch be considered unevaluated - I don't believe Ville is proposing that - it would complicate things - and if really felt necessary, should be either a separate feature or an addition that is justified with important use cases. Templates seem to be specified by the standard to allow them to be tokenized but not parsed - Richard (I believe) has pointed out the complexities this introduces within the standard (since code within templates is removed from certain semantic checks that we would require on corresponding non-template entities) - which doesn't even clearly say (i believe) if a nested name specifier requires instantiation of template specializations within the nestation. I agree that one could argue that code within Ville's static_if false branch should not be considered odr-used if written within a non-template - but i don;t believe he is asking for that - just that it not be instantiated (and so NOT odr-used within the instantiation) - and I believe that's enough by itself to reasonably uncomplicate our lives. 
Solved!
&gt; Interfaces are great, but they aren't as malleable as pImpls. Could you elaborate? What do pImpls/d pointers allow, what abstract base classes do not? (assume "d pointers" to be just another name for pImpl as [the kde techbase](https://techbase.kde.org/Policies/Binary_Compatibility_Issues_With_C%2B%2B#Using_a_d-Pointer) link provided elsewhere says so)
Technically C++ library is on far more wider scale than anything close to any of others language due to C library inheritance. You just don't see how far and deep C/C++ is used. The dispute on interfaces is somehow a troublesome matter in C++ that lead to C++ extincition since nobody want to agree. filesystem interface is no exception. The main issue is raised by compiler itself. The case is simple : #include &lt;stdio.h&gt; or #include &lt;\\remoteserver\include\stdio.h&gt; or #include &lt;https://webserver/cpp11/include/stdio.h&gt; the filesystem isn't as simple as people might think when you want to bring OS abstraction and architecture abrastion at software level. What would is a lock on samba server differ greatly to windows lock and even worst on http or ftp lock system . Sames goes for network , Java coder is expected to be amateur level of network and should use black block api to use top level of network. error and architecture error would throw at higher level and not handled at sub atomic level. In C++, you don't expect anything at all from the coder, for barebone high performances with subatomic error or casual coding. The standard isn't set and far from been set ever. Nobody want to use black box at professional level , but when you want to prototype or code&amp;forget thing you can always rely on external library. Things you can do on windows, linux, qnx, crayux, bullux or aix are too different to be united into a single abraction layer. Mostly the differences between Bullux/Crayux and linux/windows are just too different. So you are the casual coder that want a simple way to do REST/JSON server and for such a task , the logic advise is , do not code this. Use CMS or POCO or any already done stuff that satisfy your current needs Then again, C++ has weakness and flaws with new standard arising like utf8, utf16 utf32 ... and you need external third party libraries . 
But having the two levels of indirection isn't necessary: I usually pass the PimplClass by value and have a shared_ptr to its ::Impl instead of a unique_ptr. Is this bad for some reason I'm not seeing?
&gt;But what if you don't know that information for certain? But you do know that: errno gives you EINVAL (or some such).
While I think generally abstract base classes are better for most use cases I don't think that Pimpl would be used in the way you've tested it in most implementations that would chose to use Pimpl over ABC (I've not read effective C++ however). I'd expect Pimpl to be used to create either a value object (so `std::vector&lt;PimplClass&gt;` instead of wrapping it in a unique_ptr and implementing move construction in the PimplClass) or a reference object which is created from a factory function (like your ABC test) that allocates the necessary space for the implementation inline to avoid double dereferences. Also your for-each loop copies `shared_ptr` with every iteration, I'd expect the difference between inline and either of the others to be much larger so might try to use `for(auto&amp; pInstance : vInstances)`. I still don't recommend the usage of Pimpl in C++ as ABC has much better language support. I'd only consider it for cases where the virtual call overhead matters but I don't want to/can't inline the function (a much larger performance loss usually), which is very rare.
You might not agree with the purposes for which I want to use destructor exceptions, but the fact is that they are necessary in other cases. Database libraries, for example, must perform rollback if an exception occurs somewhere else. But the rollback can also fail in rare cases, and now you have *two* exceptions. If you're running the transaction via lambda with a try-catch block, you can throw away the original exception, and report the rollback exception as the one that's more serious. But if you're running the transaction via RAII, with an object that performs rollback in destructor, you're screwed. You cannot replace the original exception with the rollback exception, and you now have only ugly solutions available. Support for aggregated exceptions fixes this. I'm sorry, but I'm nearly certain that people like you are in denial. Check out [What's wrong with `noexcept`?](http://denisbider.blogspot.com/2015/07/aggregated-exceptions-proposal-summary.html#noexcept) The language can't handle the 1% case. It would be easy to handle if we plan for it; it doesn't take much to adapt to. But the fact is that it is a 1% case, and people want to pretend that it doesn't exist. It's easier to be in denial.
&gt; A pointer and a variant In principle, yes. But if your implementation of the `variant` type family always includes a state in which a variant object does not store any value then they would share this "nullability" property with pointers. IIRC, std::variant will have an "empty" state that just got renamed to "invalid". Its interface tries hard to avoid this state. You can't construct a variant to be invalid, for example. But it's still possible to get a variant object into such a state. It involves exceptions.
You have commented twice before this. I have responded. You might think you are being original, and I do appreciate feedback, but so far, you present nothing new.
Adding members that are not part of the interface in the pimpl is opaque. Otoh private members are still part of a class, still afect the compile times and the abi
I'd recommend looking up how QT actually does it, they have a couple of macros that they use together with the pImpl pattern to help make the usage of pImpl nice even in the face of inheritance and other concerns. Note that this is mainly for plugin systems, and when you have multiple things linked to each other which are independently versioned. With QT, their usage of D pointers allows them to easily add to classes and still maintain binary compatibility. So you can change the interface, but still just replace the .dll and go. When versioning abstract classes you may run into all sorts of eldritch horrors such as ISomethingV2 or ISomethingYouNeedToCastFor. There are some work arounds for this, but they're also clunky with a lot of boilerplate. QT's pattern might start looking attractive here. Even still, if you're writing actually "plug-in" sort of code, an interface is what you want. If you want to plug in your own Renderer, Sound Engine, etc. The pImpl approach is attractive if very large libraries with code churn where you don't want inversion of control, or possibly for low-level engine code that needs binary compatibility and wants to use C++ over C.
That would mean that copying the copying an instance of the outer class refers to the same implementation and state as the instance copied from. This might be quite non-obvious to client code and might lead to obscure/hard to debug errors. Having a shared_ptr to a abstract base has much cleaner semantics as its more obvious if you want to copy just-another-pointer or if you really want a new cloned instance. Very explicitly documenting this etc. might alleviate the impact somewhat, but why bother when you can have a shared_ptr to an ABC that behaves with fewer surprises overall?
This is a fairly elementary question. Please post it to r/cpp_questions
I'm not sure if Ville has considered the issue. I think if he had, he would have written something in the proposal. I agree with Richard here. That code in a false branch should be unevaluated, since it's not supposed to be compiled anyway. Templates are most definitely parsed after tokenization. There is a minimal degree of checking -- you know only if something is declared as a type, non-type, or template, but nothing more. But even that adds a significant degree of complexity (over just tokenization). But for me, any proposal that drops minimal degree of checking is a non-starter.
The initial proposal of static if for C++, of which Andrei was one of three authors (so don't credit the work as just his -- he isn't even listed as first author), was neither brilliant nor ambitious, nor did it raise or address any serious technical issues related to the integration of the proposed feature with existing language mechanics. It was a straightforward proposal of D's static if to C++ that largely presented motivating examples. However, it was a very well written proposal. 
Well this is the code i have for + operator. Matrix Matrix::operator+ (const Matrix&amp; rhs) { if(rows == rhs.rows &amp;&amp; columns == rhs.columns) { Matrix F(rows, columns); int i, j; for(i = 0; i &lt; rows; i++) { for(j = 0; j &lt; columns; j++) { F.fillMatrixOne(i, j, (data[i][j] + rhs.data[i][j])); } } return F; } else cout &lt;&lt; "these two matrices cannot be added." &lt;&lt; endl; } now cout &lt;&lt; A + B &lt;&lt; endl; complies, but it has no values. if i cout &lt;&lt; A+ B at the end of + operator fuctions before return F, it works fine. How can i fix this now? I think it's because F goes out of scope at end of +function...
Null for pointers is a fundamentally valid state, otherwise owning pointers are not moveable. Null can happen to a pointer through valid actions. There is no valid similar state for variant. It only occurs when you swallow an exception. I still don't see why you thought I wouldn't like variant. 
Based on what you pasted, When you return F you are returning a copy of F not a reference or pointer. I think your copy constructor might be the problem. 
hmm, maybe i misunderstood - I thought you were suggesting that the non-`make_unique()` solution is somehow still exception safe. I was saying that it cannot be because your constructor may throw before ownership has passed to the `unique_ptr`
surely you mean `std::aligned_storage`
&gt; &gt; But the rollback can also fail in rare cases, and now you have two exceptions. &gt; That is if you use the limes of a "transaction scope" object, e.g. If you must rollback due to an error; and then the rollback experiences another error; you have two errors. There is no way to structure the program in this case to avoid, potentially, two errors. The issue is how you deal with them. Your reply circles this issue, and tries to find workarounds for the language not being able to convey two errors. &gt; Basically, I am accusing you of inventing an issue in order to prove a point. That's an interesting choice of words. See &amp;#151; accusations are not *helpful*. I read what you write, and reply, by choice. I would like to benefit from any insights you express; and to the extent that I do not, I'm replying as a courtesy. You make it *less* likely that I will see benefit in your views; and *more* likely that I will no longer see value in courtesy; when you reply out of ego, and out of pride for what seem to me narrow-minded convictions. When I may see things in a way that you do not, that doesn't mean your views are superior because you don't understand mine. *Any* difference in understanding must be approached with respect and caution. Ignorance is a bad thing of which to be proud; and it's easy to confuse ignorance with principles.
&gt; The next question is how do you identify the sequence number of the exceptions? Exceptions are added to the list as they happen. Catch-any handlers in each scope are invoked in the order that exceptions appear in the list. If the catch-any handlers match all possible exceptions, they will be processed in order. If they do not match some, or if they re-throw, those will be matched in-order again at the next scope. This provides freedom for the developer to process exceptions in the order they like, with order-of-occurrence as default. For example, if SpecialError has higher priority than any other exception type, the developer can have an inner try/catch block, with a catch-any handler just for SpecialError. This will look for any instance of SpecialError among the caught exceptions, and process that first. Then processing will continue at the next try-catch block. &gt; Since exceptions are stored on the stack, This may be correct for many implementations. However, the language requires exception objects to be copyable so that there is flexibility in how they are stored. Aggregated exceptions may have to be stored more dynamically. The first exception may or may not be stored on the original stack; subsequent ones also may or may not be. I wrote a summary of the proposal's current state. It has a section to address environments with limited memory: [Aggregated exceptions: Proposal summary &amp;#151; Limited memory environments](http://denisbider.blogspot.com/2015/07/aggregated-exceptions-proposal-summary.html#memory)
std::move isn't for daily use.
&gt; Furthermore, my proposal includes a way to reserve memory in advance for any reasonable number of simultaneous exceptions that a developer believes his application will need. So, the space required is O(1) - the aggregated exceptions either fit into the reserved space, or the program calls std::terminate. Who decides how big the aggregated exception buffer is? It's something every program will have to pay for since there's no way to prove that you don't have any throwing destructors (even if you can prove at static link time that none of the objects have throwing destructors, you might load a dynamic library which has throwing destructors). So you want this buffer to be as small as possible. But make it too small and you'll be plagued with unexpected terminations. Consider the case of the "network is down" closesocket() failure we talked about earlier. That's the kind of situation where it's very likely that you could have a cascading effect of failing destructors, or at least a large number of them. So throwing that failure seems like it would be very likely to lead to program termination. So you still need to decide in advance (i.e. in the destructor rather than the catch handler) which cleanup failures you care about (and should throw or terminate over) and which you want to ignore to avoid cluttering up your buffer.
The reason why this calls move constructor isn't because of `std::move`. RVO is disabled because the types aren't the same, but the value is still cast back to BigObject and then returned. Since it's an xvalue, move constructor will be called. BigObject foo(int n) { BigObject localObj; return std::move(localObj); } This returns a dangling reference. BigObject&amp;&amp; foo(int n) { BigObject localObj; return std::move(localObj); }
&gt; there's no way to prove that you don't have any throwing destructors That's not the case; you can make sure that they're all `noexcept`, if that's what you care for. &gt; (even if you can prove at static link time that none of the objects have throwing destructors, you might load a dynamic library which has throwing destructors) If you're concerned about the DLL you're loading terminating you via exceptions &amp;#151; why aren't you concerned that the DLL will terminate you, period? You're talking about unsandboxed native code. There's an inherent absolute level of trust involved. If you're going to be loading code like that, then yes: you may need to accommodate what it needs. But this is not much different than, if the DLL needs a lot of stack space, you need to provide it, even if your application itself doesn't need it. It doesn't mean you're paying for what you're not using. You're paying for what you *are* using; you're using that DLL. &gt; That's the kind of situation where it's very likely that you could have a cascading effect of failing destructors, or at least a large number of them. I really don't see how that's likely. It could be the case if you're destroying a vector with 1,000 sockets, so if one fails in a strange way, others are also prone to. But if you have one socket, then that *one* socket fails. It doesn't mean your next destructor will now throw when it closes a pipe handle, or releases memory. And if you have 1,000 sockets failing, *that* seems like a situation in which `std::terminate` is appropriate.
&gt; If you're concerned about the DLL you're loading terminating you via exceptions — why aren't you concerned that the DLL will terminate you, period? The DLL in question isn't malicious, it just wants to report errors the best it can. So in a world with aggregrate exceptions we'd have two kinds of DLLs - those that throw from destructors (which can be loaded by programs that are aware of that) and those that don't (which can be used in all the programs that would accept such a thing today). &gt; And if you have 1,000 sockets failing, that seems like a situation in which std::terminate is appropriate. Even if they're failing because the network went down and your program doesn't care because it no longer needs network acccess and was in the process of destroying all the sockets anyway?
I've used pimpls in production code with a team of C++ developers, and as long as the community (you, me, the people in this thread) come to an agreement on the usefulness of this idiom, the next person who wants to modify/update the code will: 1. Be familiar with the idiom so it won't seem foreign and jarring 2. Understand that there's a pattern being used and that it should be stuck to, reinforcing the interface/implementation separation 3. Report back to the community about the production use of said idiom and complete the cycle. Idioms are just that, they're patterns developed over time to solve a specific class of problems. That they may be hard to understand sometimes either means the idiom isn't idiomatic, or the developer hasn't been indoctrinated yet :P.
The first paragraph is poorly worded IMO. C++11 didn't change copy elision. It has been there since day one, and it was and still is optional.
https://youtu.be/2egL4y_VpYg?t=1h1m23s Do you see a std::move on the slide #39? (no, because it doesn't belong to the place where classes are used)
&gt; `BigObject&amp;&amp; foo(int n) {` ` BigObject localObj;` ` return std::move(localObj);` `}` `int main() {` ` foo(1);` `}` &gt;Then we compile and run it, and we will get the output like this: &gt; &gt;constructor. destructor. &gt;Yes! The compiler does RVO! It's also noticeable that RVO calls destructor only once, but std::move calls destructor twice. What?!? No! The compiler did not perform **RVO**, you're returning a reference (to a local object no less). No object is constructed so no copy/move construction nor any RVO are performed. The fact that you now have undefined behaviour is just an added bonus.
It isn't used there because the copy is elided. If you mean moves should only be part of data structures that is also not true, as moves can be used to pass parameters to functions that take an argument by value, changing ownership and sinking the argument without any heap activity.
Okay this is pretty stupid. Foo bar() { Foo x; return std::move(x); } This (usually) disables RVO. Don't do it. ********** Foo bar() { Foo x; return x; } This can perform RVO on x, and, if optimization is disabled, calls the move constructor. That's right...no need to call `std::move` explicitly, it moves for you. ********** EDIT: From the standard, section 12.32 (emphasis mine) &gt; When the criteria for elision of a copy/move operation are met, but not for an exception-declaration , and the object to be copied is designated by an lvalue, or when the expression in a return statement is a (possibly parenthesized) id-expression that names an object with automatic storage duration declared in the body or parameter-declaration-clause of the innermost enclosing function or lambda-expression, **overload resolution to select the constructor for the copy is first performed as if the object were designated by an rvalue**. If the first overload resolution fails or was not performed, or if the type of the first parameter of the selected constructor is not an rvalue reference to the object’s type (possibly cv-qualified), overload resolution is performed again, considering the object as an lvalue 
The right time to call std::move is when you're smarter than the compiler and you know something won't be used again. For example, with this code: void bar(Foo); int main() { Foo x; bar(x) //move won't happen here because... //...x could still be used down here. } However, if you KNOW that x isn't needed any more after the call to `bar` you can tell the compiler to move it. void bar(Foo); int main() { Foo x; bar(std::move(x)) //move happens here //Any use of x down here is possibly invalid, depending on the operation and the state of x when it's moved from. } Basically, anytime copy elision can happen, a move will occur in an unoptimized environment. Otherwise you need to say "move" yourself ********** An important side note to realize is that `std::move` is simply "cast to r-value reference". The above case "moves" because it's being passed by value, so the constructor with an r-value reference parameter (the move constructor) is called. If bar took a const l-value reference, or an r-value reference, then no move would occur when calling the function (which is normal for pass-by-reference parameters).
Yes, that thing is not usable at all and not related to the RVO. Just pass the result to something that takes any reference and have some magic going on: #include &lt;iostream&gt; struct A { A() = default; A(A&amp;&amp; a) = default; int m; }; A&amp;&amp; f() { A a; a.m = 10; return std::move(a); } template&lt;typename T&gt; void g(T&amp;&amp; t) { T u; t.m = 5; std::cout &lt;&lt; u.m &lt;&lt; '\n'; } int main() { g(f()); return 0; } 
&gt; I'd only consider it [Pimpl] for cases where the virtual call overhead matters but I don't want to/can't inline the function (a much larger performance loss usually), which is very rare. But when the virtual call overhead really matters, wouldnt resolving the pImpl pointer to access members matter in much the same way? Otherwise, I completely agree.
&gt; Exceptions are not meant to be used to indicate bugs in programming or design. Bad policy. The alternatives you're pushing are (1) ignore, or (2) abort causing denial of service with lack of cleanup, possibly exposing sensitive information.
You are laboring under the assumption that aborting brings you safety against corruption, but that's only the case when a developer is sitting right in front of the aborting program, ready to debug immediately. In practice, users will keep restarting your program, and keep exposing themselves. You need to change behavior enough for users to report the issue, and then you need to fix it ASAP. But in the meanwhile, the program *must not* denial-of-service itself, otherwise what could be a $10,000 issue (we limp along while the bug is fixed) becomes a $1,000,000 issue (disruption in service + penalties). You're insisting that all $10,000 issues should be blown up to become $1,000,000 issues. This is insane.
&gt; If it throws from its destructor, its existing use in containers under C++03 is unsafe. Yes, and fortunately we are not currently encouraging people to throw from destructors! &gt; Aggregated exceptions, as I propose them, don't break any code that's already correct. That can be true without refuting my point. Not every piece of code in a program is written from scratch for that program - people reuse code. Mixing code with throwing destructors with code that already exists will break a lot of assumptions in that existing code in a lot of subtle ways.
&gt;We don't ignore these errors because we want to. We ignore them because we have to. In this case (and many others), you don't *have* to, see &gt;if you feel you must inform about a failed rollback, move the rollback() call out of the destructor (I say that because transaction::rollback is public).
Original post from /r/programming: [Visual Studio 2015 and .NET 4.6 Available for Download](https://www.reddit.com/r/programming/comments/3dy8g1/visual_studio_2015_and_net_46_available_for/) ^^I ^^am ^^a ^^bot, ^^PM ^^me ^^if ^^you ^^have ^^any ^^questions ^^or ^^suggestions
I thought constexpr was completely broken, but it appears you allow the debugger to step through constexpr functions? If I use static_assert to verify constexpr values, it is working as expected.
First you were saying stealing the contents inside a function, now you are saying talking about move constructors. If you pass by const reference you may hold on to an object longer than you have to if the function can use it and destroy it. In that situation using move to get the object in the function works well because the function can use it and possibly destroy it early. When I say sink, I'm talking about passing by value. funcname(Obj o) You can call that with funcname(move(objInst)); and it will create an rvalue reference that will call the rvalue constructor.
This is outragous! What will happen to r/cpp if the script kiddies no longer can complain of non-existing features in the ms compiler!? /s
C++'s support for efficient argument passing is lacking. For example, you cannot return function arguments and expect RVO to work. This prevents efficient function chaining: t = h(g(f(source()))); C++ should add a method to specify the programmer *intent*, rather than the mechanism of parameter passing, leaving the exact mechanism up to the compiler. Say mark a in parameter with the keyword *in*. T f(in T x); Then the compiler can choose the exact calling convention. If T is an int, passes T by value. If it is a string, maybe pass by const reference or r-value reference, depending on whether the actual parameter is an l-value or r-value. Basically the declaration for f works as an implicit template.
&gt; Yes, and fortunately we are not currently encouraging people to throw from destructors! Yes. Instead of fixing a hole in the road, we put up a big sign saying *"Avoid this hole!"* Instead of fixing the road, so it can be traveled on, we're blocking off a whole lane, and creating a traffic bottleneck. Meanwhile, righteous people like yourself go around scolding people who want to use the blocked lane, proclaiming how unsafe it is. **Yes, it's unsafe, because we don't fix the damn hole!** See: [What's wrong with `noexcept`?](http://denisbider.blogspot.com/2015/07/aggregated-exceptions-proposal-summary.html#noexcept) Also, this conversation seems to have started going around in circles. &gt; Mixing code with throwing destructors with code that already exists will break a lot of assumptions in that existing code in a lot of subtle ways. Just migrating from C++03 to C++11 breaks a lot of assumptions in subtle ways. We try hard to minimize the impact, but there are tradeoffs we need to make if we want *anything* to improve.
We shouldn't have to do that. Exceptions ought to *work*, not require workarounds due to limitations.
Note that RTM's installer contains a significant change: Visual C++ is **not installed** by default. You must explicitly select it if you want it. (For clean installations, at least. I'd have to check how RC-to-RTM upgrades work.)
In my code I wrote a very simple RAII wrapper around sqlite. Instead of forcing error code checks everywhere, it throws an exception. The invariant in the SQLite API is that starting a transaction/savepoint must be terminated by a corresponding end (otherwise your transaction never ends) or program termination (which is undesirable as it indicates programmer error). The problem comes in that, for exception safety, rollback must occur in the destructor; exception may have been thrown for any reason (e.g. something failed to deserialize while being written to the DB) &amp; you don't want to leave your DB in an inconsistent state. Instrumenting rollback everywhere not only defeats the whole purpose of RAII, doing so in an exception-safe manner would require manually instrumenting the code with try/catch (&amp; hoping you did it right too) which gets *really* messy real quick.
&gt; r/cpp .... script kiddies hmmmm 
BUG REPORT: It turns out constexpr is borked in the Community edition (this code works fine in the Professional edition): template&lt;unsigned N&gt; constexpr int count(const char(&amp;str)[N], int i = 0) { return str[i] ? 1 + count(str, i + 1) : 0; } int main() { static_assert(count("Ben Hanson") == 10, "No"); }
It's a shame btw that that they present all the new cool features always with XAML/C#/.NET. And then, if you want to find out if said cool feature also works with native C++ code, it's really, really hard to find information about it on their blog posts. (like for example the "history-debugging", code-lense, or the profiler stuff) **Update**: The new Diagnostic Tools window is really awesome! Thank you so much for this! Now we only need [IntelliTrace](https://visualstudio.uservoice.com/forums/121579-visual-studio/suggestions/2286557-support-debugging-of-c-code-with-intellitrace) :-)
The setup team confirmed that upgrading RC to RTM in place is supported. You don't get side-by-side, since RC's lifespan is expiring.
Cool, that's awesome, thanks! All good then. Can't wait till the setup finishes :-)))
Yeah I am very happy to see a return to the advanced install options. They [over] simplified things in Visual Studio 2012 and 2013 so it is great to see so many options. All I want/need is the VC++ language and tools not all the web and mobile stuff. 
It can be pleasant for the function implementer, but for the client it doesn't look good: you need to write std::move; it always moves even if the parameter isn't used at all; the objInst is in the 'vaguely defined state' after the call - so it's like passing a plain non-const reference.
Uninstalled, rebooted, deleted installer, downloaded installer again, installed, rebooted, still borked: 1&gt;d:\ben\dev\constexpr\main.cpp(64): warning C4425: 'const char (&amp;)[N]' : 'constexpr' was ignored (class literal types are not yet supported) 1&gt;d:\ben\dev\constexpr\main.cpp(70): error C2057: expected constant expression 
That's like saying using `const` or `noexcept`is early optimization. 
VC Dev Mgr here, actually because of the libs (and matching pdbs), VC is very large. We also require the Win32SDK, which some scenarios do not. Improving the acquisition experience for our customers is very important. This adds a step for VC devs but significantly improves things for non-VC devs. Note that you can already not install web dev stuff.
Not really. In the first case you spend 2 moves per function call, just moving data into and out of a function. These can be elided with proper annotation, saving 6 moves across 3 function calls. For the 2nd case, currently we need to write 2 overloads to handle things optimally without extra moves: T f(const T&amp;); T f(T&amp;&amp;); This is prevented with extra annotations. 
Can't you simply limit the scope of x in this example? { Foo x; bar(x) } The compiler now knows x will never get used after bar, and a move is safe.
That method will just invoke a bunch of copy constructors, since now you must convert your input type `T&amp;&amp;` to your output `T`, which copies. I would suggest you test with value parameters. You should only get 3 move constructors with that example
I wonder why icon wasn't changed I was so happy when RC had different icon. Now I will have to suffer a ton of misclicks while using VC2013/2015 simultaneously again.
Implicit moves happen wherever copy elision can happen, which according to 12.31 is return statements, throw expressions, "movement of a temporary object", and the exception declaration of an exception handler. So, no not in this case. I think what the designers were attempting to avoid (if it could move there) was how behavior could then change based on seemingly unrelated code edits. { Foo x; bar(x); //The behavior of this line changes... //500 lines of code later baz(x); //...when this line is added. }
And it remains ugly. :( I loved the icon from VS 2010; I wish they didn't replace it with this... awful... thing. :-/
&gt;I'm not entirely sure when the right time to call std::move is. In my experience, the most common usage of `std::move` is when you have a named rvalue parameter, since the parameter is named it itself is an lvalue (confusing right?) // move constructor Obj(Obj&amp;&amp; other) : member(std::move(other.member)) {} 
The [feature comparison table](https://www.visualstudio.com/products/compare-visual-studio-2015-products-vs) says that CodeLens is present in Professional and Enterprise, but not Community.
How do you respond gracefully to a compound exception?
OK. You're talking about C++14 [class.copy]/32: &gt;When the criteria for elision of a copy/move operation are met [...], and the object to be copied is designated by an lvalue, or when the expression in a return statement is a (possibly parenthesized) *id-expression* that names an object with automatic storage duration declared in the body or *parameter-declaration-clause* of the innermost enclosing function or lambda-expression, overload resolution to select the constructor for the copy is first performed as if the object were designated by an rvalue. So in `return a1;` , `a1` may bind to a move constructor. More importantly though, this can only happen when the code was eligible for copy elision anyway. The article on this thread seems to use your function as an example of when copy elision doesn't happen, but that's just the compiler deciding not to do it in this case for some reason. 
You're probably right.
[**@ericniebler**](https://twitter.com/ericniebler): &gt;[2015-07-20 20:58:40 UTC](https://twitter.com/ericniebler/status/623235598027878400) &gt;The Concepts TS was voted out today! Concepts are \(almost\) an ISO standard. Congrats, A. Sutton. This will change everything. [@isocpp](https://twitter.com/isocpp) [#cpp](https://twitter.com/search?q=%23cpp) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/3dzv6i%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
1. That's why I added to the disadvantages of funcname(move(objInst)): 'always moves even if the parameter isn't used at all'. 2. That's why I wrote 'pleasant for the function implementer' and a disadvantage for caller - 'you (client) need to write std::move' every time. 3. Okay, it is like the good old 'f(&amp;a) vs f(a)' taken to the new level: 'f(std::move(a)) vs f(a)'. Your camp is making progress. Can I give up before more arrive?
You have a lot of studying to do on this stuff, you don't know the difference or reasons for these different features and it looks like this is because you don't understand them on a fundamental level.
[Are you in or out?](https://youtu.be/xY5q01fTceQ?t=24s)
A "TS" is a "Technical Specification". In this case it is an (optional) extension of the ISO C++ Standard (language or library). A TS provides a way for the committee to publish more experimental features in order to gain implementation and user experience before committing to change the C++ Standard. The "Concepts TS" is a set of language features that aims to (dramatically) improve support for generic programming. Writing a tutorial is a bit beyond me right now but this paper is a reasonable introduction to the feature set: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3701.pdf. The introduction needs to brought up to date with the spec. In short, Eric's tweet is right. This will change how C++ is written. TLDR: It's a fundamental, not incremental change to the language. I need to write a paper.
It's only not exception safe when you have multiple calls that can get evaluated in undefined order. If you change your example from one line to three, where you separately create each integer pointer before calling foo/bar, then it will be exception safe. So It's still mostly syntactic sugar.
&gt; A "TS" is a "Technical Specification". In this case it is an (optional) extension of the ISO C++ Standard (language or library). A TS provides a way for the committee to publish more experimental features in order to gain implementation and user experience before committing to change the C++ Standard. Thank you for the explanation, that definitely helps me a lot to understand how this actually fits in with current C++. &gt; The "Concepts TS" is a set of language features that aims to (dramatically) improve support for generic programming. Writing a tutorial is a bit beyond me right now but this paper is a reasonable introduction to the feature set: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3701.pdf[1] . The introduction needs to brought up to date with the spec. I'll have to take a look at the paper to find out more of the details! and after all that initial reaction - holy crap, it seems like the person who actually came up with this idea is explaining it to me!! I'm excited to come up with a project to test these features with, that is, once I can actually compile them :P Any idea when I can expect to see a compiler support concepts? In any case, thanks for your contribution!
I can't claim to have come up with all of it. I just did a lot of the leg work. Most of the proposed features are implemented in the c++-concepts branch of GCC, so you'd have to go build it from source to play with it. I *think* it's going to be merged into trunk in the near future, but I don't have the final say on that.
Imagine you're playing a game of Mad Libs, but when you ask your friends for words, you don't tell them whether to give a noun or an adjective, you just ask for any word. When you go to plug the words into the sentence it doesn't make any sense at all. It just comes out as "cat and he said run as he jumped into happy". Bleh. The Mad Libs creators knew that you needed some sort of structure for the sentences to make sense. That's why there are grammatical restrictions -- you need a noun here, then a verb, then an adverb. You still have the flexibility to choose whatever word you want, as long as it fits within that category. That's how you make meaningful yet funny sentences. Right now C++ templates is basically Mad Libs without any restrictions at all. You can plug any type you like into the template T but when the compiler goes to actually compile your code, the result may not make any sense at all. And the compiler doesn't have enough information to even tell you what went wrong, because it's just stuck with a nonsensical sentence. Concepts are restrictions on templates, like grammar is a restriction on Mad Libs. You can still choose many different types for T, but they all have to be in some general category that at least lets the code make sense. And then the compiler can give a much more useful error when something doesn't fit, like "hey, we were looking for something you can add to another thing, but the type you gave doesn't do that!".
cool, I'll have to give that a try when I get a chance. Only one other question - can you recommend where the best place is to keep up to date on these sort of developments and additions to C++?
I refer to these concepts as "reproducible" and "deterministic". `mt19937` is reproducible, in that its output should be identical across all implementations. The Standard even mandates what its 10,000th value should be for a certain seed. Last I checked, VC agreed with GCC. (Note that in VC 2013, I fixed `mt19937`'s behavior for 0 seeds. I hope you're not using 2012. Now that 2015 has been released, you should upgrade.) However, `uniform_int_distribution` is merely deterministic. Its output can vary according to different implementations or versions. This is because the Standard doesn't specify the exact algorithm needed to implement it. (It's actually really nasty to implement in full generality.) If using `mt19937` **without** `uniform_int_distribution` produces different results between VC 2013+ and GCC, please give me a self-contained repro and I'll investigate.
A pointer to what?
Do you know whether the outputs of `uniform_int_distribution` do **actually** vary between VC and libstdc++? Because it doesn't look to me that there are a lot of ways to implement it, if you don't safe unused data (I checked libstdc++ for that a while ago and you once told that this is also the case for VC)? Alternatively: Is there a simple way to get the sources of VC's stdlib as a Linux-only-user to investigate that myself?
It's actually incredibly easy to make a proper, shared content, copy-on-write pimpl. https://crazycpp.wordpress.com/2014/09/13/pimplcow/ Use polymorphism only when you want polymorphism. There's no reason at all to have abstract base if you are not using polymorphism.
Precondition violation should always mean a call to `std::terminate`. Precondition violation basically means "the program is in a state it is *not* allowed to be in", which means all your other assumptions and invariants may not hold, so, say, logging can trash your operating system on disk, and throwing might crash it in memory. As soon as you detect a precondition violation, you exit. If you expect any errors other than precondition violations in your dtors that are worth reporting, you are probably doing something wrong. Closing a file, or closing a socket, provided they are not in a dirty state (and if they are... you probably violated your preconditions somehow?), may safely fail. Log it, go on. Don't throw from dtors.
&gt; &gt; private: &gt; ~Foo() {} OOPS!!
That's intentional, you can only create an instance with `Foo::createInstance()`
My sarcasm mode is in danger of activating... Bar can't be properly deleted and your code should not compile. The problem is that derived classes do not have access to private members of base classes--that's the purpose of `protected`. Derived has to call base destructor.
The only derived class there is and can ever be is friended, making a second derived class would break things. Foo's destructor is only ever called from Bar, calling it from anywhere else would be incorrect since it's not virtual. (No instance of type Foo ever exists, so calling it's destructor or constructor from anywhere but Bar would be an error)
Write a proposal; the committee will then explain to you why the whole idea is broken, and will do a better job at that than reddit.
Yes, you are asking for that - by trying to force a misfeature you think is a feature onto people who don't want it.
I'd not accept any use of Pimpl without some serious data to back up it's necessity in a code review, so the point is kind of moot. Project requirements are different though so if it's commonly used in a project knock yourself out.
It is an easy thing to say.
Termination or recovering it via some other mechanism. Closing the DB handles &amp; trying *might* be something possible too, although likely you'll get an out-of-disk failure opening the handle since it'll be in the middle of a transaction it's going to try &amp; rollback to resolve the journal.
Depends on the mechanism. For example, I proposed instead of having multiple exceptions in-flight, being able to get a pointer to the current exception that's causing unwinding. This would let me attach the generated exception to it as it keeps propogating. In any case, how it gets to higher levels doesn't really matter. The point is you'd have policy that dictates how to resolve multiple exceptions. For example, if any exception is an out-of-disk error, do XYZ. If there was a deserialization error, record something in statistics. If there was ... etc. Basically you would define policy that operates on multiple errors. It does not absolve you of having a policy that makes sense. I also do not dispute that such a mechanism could potentially be too complicated to actually be useful.
I was like... "NOT AGAIN, AT THIS RATE WE'RE NEVER GONNA GET CONCEPTS UNTIL 2027" phew ;)
The concepts stuff you linked to corresponds to a very old proposal that is off the table. What we will get (first) are "concepts lite", a heavily simplified version.
Shouldn't other still be considered an rvalue because it is an rvalue reference but member is not an rvalue because it's just a field of other. I mean for "member(other)" the move constructor of member would be called without a move, after all other is Obj&amp;&amp; and that's exactly the type the move constructor takes?
I've always wondered why people default to explaining C++ features in the most complicated possible way. That sort of explaining only makes sense if you already know what they're talking about.
I appreciate the reduction in bloat especially seeing as how my SSD needs room to breathe.
Is this something similar to `&lt;T extends MyObject&gt;`, in other words when Concepts become ISO standard will it be possible to set upper bounds for templates?
Why is it called "concepts lite"? What would be the "heavy" version?
Wow this is fascinating and really counter intuitive, thanks for this great example. I tried and find it even more crazy in initialization [here](http://ideone.com/nKAvBg). Note I follow C++ discussions and things like LLVM Weekly but use Java and Go most of the time and it's been a while since I had a C++ project though I want to get into C++ again, so I haven't had too much first hand experience but this really gets documented too little.
The "heavy" version was the one proposed to C++11 that was deemed too complicated and got rejected by the standard. The current version was elaborated afterwards as an alternative which tries to solve the same problems but simpler and shorter.
You will but It's really much more generic than that. Concepts are predicates on types. You can test for whatever you want on the type, not limiting yourself to "inherits from" as in `extends`.
Okay so there's a lot of people asking what concepts are in this thread, so I thought maybe I'd spend a few minutes writing up what I remember of them. Disclaimer: I haven't read the TS, and I'm working off of memory of [last year's CPPcon talk](https://www.youtube.com/watch?v=qwXq5MqY2ZA). Note that this talk is really good, and if you have time you should totally watch it! If I screw something up, please correct me and I'll do my best to fix my post. ********** **Why concepts?** Basically right now when you use a template function (or class), the compiler has to scan the instantiation tree to make sure what you're doing is legal. Look at the following code for example: class Foo { Foo(const Foo &amp; other) = delete; }; template&lt; class T &gt; void f(const T &amp; t) { T copy(t); //Error occurs when instantiating this line } int main() { Foo foo; f(foo); //Error occurs when compiling this line } Now this is fairly straightforward to see...the problem is that we're trying to copy construct Foo, and Foo has a deleted copy constructor. However, I'm sure most people with templates have had weird obscure errors that occur with 3 subtypes and 8 levels deep through a third party library that are an absolute pain to parse why your specific template instantiation failed. Wouldn't it be great to know that as soon as you called the function? This is where concepts can help. ********** **Defining Concepts** Concepts are a new thing to the language. There's lots of ways to define them but the basic idea is we define a certain thing that the class can do. Sort of like an interface class, but for duck typing. A CopyConstructable concept would tentatively look like this. template&lt; class T &gt; concept bool CopyConstructable = requires( T t ) { T(t) -&gt; T } This is saying the following things: * I'm defining a concept named `CopyConstructable` * It takes one template parameter, `T`. * An example of a `T` is named `t` (This is simply to avoid using `std::declval` for clarity purposes.) * If I call `T`'s constructor with a `t`, the result is of type `T`, basically confirming that this is a legal function. Tada! You now have a CopyConstructable concept. Note: I'm a bit fuzzy on the exact syntax to create a concept so if you really understand this, please proof my concept above. Thanks! ********** **Using Concepts** The basic way to use a concept is like this: template&lt; class T &gt; requires CopyConstructable&lt;T&gt; void f(const T &amp; t){ ... } Now, when we call `f` with `Foo` we get an immediate error, since `Foo` is not copy constructable. Nice! ********** **Syntactic Sugar** A few things that are also becoming standard to save on space. If your concept only takes one template parameter, you can simply type this template&lt;CopyConstructable T&gt; void f(const T &amp; t){ ... } And if you don't actually need to know the typename `T` in your function, you can simply write. void f(const CopyConstructable &amp; t){ ... } ********** **Extra** Additionally, the TS provides the auto syntax to functions as well. It's mostly unrelated to using concepts, but you can write this. void f(const auto &amp; t){ ... }
The OP has confirmed that they actually vary. There's a lot of latitude in its implementation, even for stateless distributions. Unless its implementer in libstdc++ thought *exactly* like I do, varying output is basically guaranteed. (I could probably replicate my output from scratch, given my thought process of "map the engine to a bitstream and be on guard for treachery at every point", but I'd say there's a 50% chance I'd choose differently somewhere accidentally.) You would have to install VC in a VM to look at the STL's sources. And remember, you would be bound by VC's EULA.
Caution: you may be tempted to use modulo to get reproducible distribution behavior, but this will introduce bias. You can avoid bias only by replicating the work that goes into implementing `uniform_int_distribution`. (It's somewhat easier if you can assume that the input is `mt19937`'s range.)
This explains so much about c++
&gt; You would have to install VC in a VM to look at the STL's sources. That's why I asked for simple. But when I think about it, it should be possible to get those files from the VC-instalation on my universities pool-computers. What is the include-path there? &gt; And remember, you would be bound by VC's EULA. Only to the extremely limited degree that German law permits. Which is basically „the usual laws for copyrighted work apply“.
Returning a pointer means you have to have the object on the heap, incurring extra overhead and extra indirection. In most cases you should be returning by value and letting rvo handle it. 
Indeed, sometimes I even find it to be euphoric.
Any information about modules? 
Yeah, fortunately, I sold all my stock in SSD manufacturers before the product release. &lt;nota bene to SEC regulators.... THIS IS A JOKE&gt;
https://books.google.com/books?id=w5VQAAAAMAAJ&amp;q=aristotle+inauthor:Grady+inauthor:Booch&amp;dq=aristotle+inauthor:Grady+inauthor:Booch&amp;hl=en&amp;sa=X&amp;ved=0CC4Q6AEwAmoVChMIu_GD6d3sxgIVJnmmCh1pVQex
`C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include`
a macro-less way i like to use is something like this: template &lt;bool T&gt; using requires_t = std::enable_if_t&lt;T, std::size_t&gt;; and can be used like so: template &lt;typename T, requires_t&lt;std::is_copy_constructible&lt;T&gt;{}&gt; = 0&gt; void f(const T &amp;t) { ... }
Plan9 is pretty grand, but that's more design-wise than code-wise.
Wouldn't that be a dangling pointer then?
Oh, you mean you would allocate the object on the heap? But maybe I don't wanna do that? Edit: Also, that's bad design, because the user must somehow know to delete the object.
As mentioned below, you don't really need a macro since `enable_if_t` is a thing. The problem this this strategy is that it's very annoying to write type_traits for member functions and other SFINAE constructs...you need to make a trait for each one (`has_function_one`, `has_function_two`, etc). `void_t` can help fill in the gaps, however both of these should become much less necessary once we get proper concepts.
10 Print "Hello World" 20 Goto 10
A lot of coding principles have a broader applications: * Short, clear code is better than convoluted or hard-to-read code. Usually, the compiler will even make it faster than a "clever" formulation. Outside of programming, this is equally true. * A bug that shows up in one place is often due to a problem further up the call stack. * Free everything you malloc. Always clean up after yourself or stuff will pile up. * Be aware of parallel overhead. Sometimes it takes more time to communicate and get everyone on the same page than it would take to just do the job yourself. * In a similar vein, if you need to communicate something, do it as early as possible. Waiting is pointless and will only be more costly. I'm sure I could come up with a dozen more of these. Maybe I should put silly graphics on each one and publish a stupid "philosophy of programming" book that people will buy for their IT friends and family. Hmm...
Which is 10 cycles more than stack allocation in addition to requiring that you pass around a custom allocator as a parameter to every function, which in turn bloats your API... and your measurement doesn't factor in the cost of indirection and the effect it has on the cache every time you want to access that value.
You're the one who started making it personal by citing how you make a living from c++, thereby trying to lend your opinion extra weight. You didn't give any reason as to what's wrong with rvo. You also kind of insinuated that anyone interested in this discussion of move and rvo is a college kid in love with theory and lacking practical experience. I have news for you: I take great interest in these details, and I make a living from c++ as well. In fact, I'm sure many people here do. In any case, we'll all learn more and have better discussions and have more fun if we stick to technical reasons. 
&gt; personal, revengeful attacks. &gt; When you graduate from college and get a job, you'll look back and rethink all this. &gt; I dont know what these "experts" are doing but I have a hunch they are creating inexistent problems so they can be paid to solve. 
This should be the title of a book.
&gt; As mentioned below, you don't really need a macro since enable_if_t is a thing. You shouldn't use `enable_if_t` as its harder for the compiler to diagnosis the error(see bug for clang [here](https://llvm.org/bugs/show_bug.cgi?id=18792)). However, something like this will still have good diagnostics: template&lt;class T&gt; using CopyConstructible = typename std::enable_if&lt;(std::is_copy_constructible&lt;T&gt;())&gt;::type; template&lt; class T, typename = CopyConstructible&lt;T&gt; &gt; void f(const T &amp; t){ ... } &gt; The problem this this strategy is that it's very annoying to write type_traits for member functions and other SFINAE constructs...you need to make a trait for each one (has_function_one, has_function_two, etc). I am not sure what you are referring to. Definition of type traits work the same way as Concepts Lite does. &gt; void_t can help fill in the gaps `void_t` is way too verbose for defining concepts or type traits.
Not anything specifically. But there's a ton of stuff *around* programming that is nothing but philosophy: * Virtually everything going on over in /r/rust. Ever since the language was started, it's been one long philosophical discussion after another; in a good way. The language's direction has benefited greatly from it. * The D community was like that from 2001-2010 or so. Lots of debate and philosophy in the context of new language development. Great stuff. Especially when people would go head-to-head with Walter Bright or Andrei Alexandrescu. Doubly so when they would argue with each other. Edit: now that I think about it: * SQL won't let you compare values to NULL. So `WHERE column_name = NULL` will never evaluate to true. For that matter, common operations like `count(column_name)` will *only* consider rows where column_name is not NULL. So a SQL NULL is *not* a value, but another state entirely. This is like saying that "nothing" is the total absence of value or state at all, apart from zero. * I always kind of liked how C/C++ use 'void' as meaning 'devoid of any type'. It has a certain finality to it that is apart from any use of NULL or zero. 
Even made it uneven so you get the spiral instead of just a flashing line on the bottom. 
It's interesting how a thread like this attracts comments from people I would call *passionate assholes*. You have found it easy to find motivation to make *four separate comments* in this topic to express anger and resentment. Yet, despite your willingness to make this effort, it is beyond your grasp to look at mine and others' responses to other people who have voiced concerns just like yours, to whom I/we have already replied. Your attitude reflects that you're not interested in *learning* about this topic because your mind is already made up. You are pissed off that someone would propose a change, *to begin with*.
 // why
Oh.. wait. You're relying an implicit conversion. Change the parens to ::value and it's fine. Still, that's a very subtle point on which to claim incompatibility. Perhaps you'd like to explain why your example doesn't work?
&gt; You can absolutely write both of those. Really? Then things have changed quickly. A couple of months ago, you told me it was not possible(only booleans allowed with no implicit conversions). However, if that is possible than that is great to hear, and sorry for spreading misinformation.
compact_optional_base has only one template parameter: it does not depend on the "tag". It contains all operations that do not depend on the tag. This way I prevent the code bloat: otherwise functions like has_value() would have been instantiated for every tag separately.
&gt; Change the parens to ::value and it's fine. Except I never write it like that, neither does Eric Niebler in his ranges-v3 library, nor does Concepts Lite write it using `::value`. &gt; Still, that's a very subtle point on which to claim incompatibility. It still is a problem. I would love to be able to do this: #if HAS_CONCEPTS #define REQUIRES(...) typename=void&gt; requires (__VA_ARGS__) &amp;&amp; Bool&lt;true #else #define REQUIRES(...) typename std::enable_if&lt;(__VA_ARGS__)&gt;::type #endif template&lt; class T, REQUIRES(std::is_copy_constructible&lt;T&gt;()) &gt; void f(const T &amp; t){ ... } So it uses `requires` when available and falls back on `enable_if` when it is not. However, its not interchangeable. I could try to define it like this: #define REQUIRES(...) typename=void&gt; requires Bool&lt;(__VA_ARGS__) But I lose error reporting for constraints. &gt; Perhaps you'd like to explain why your example doesn't work? I'll leave that for Scott Meyers.
Philosophical in that my view of the world has darkened considerably.
All of it. I view software development as an exercise in ontology where I am constantly asking myself what is the essence of such and such feature and then defining it in code. E.g. If you are implementing an email server, eventually you have to ask the highly philosophical question, "what is email-ness?"
Yes, you're right that in some cases it is better to use the heap. But your first comment sounded like you wanted to use your technique *instead* of RVO/std::move. I think both have their use cases. 
&gt; My proposition is that I can write a solution with C++ pre-11 as clear as anyone written with C++ 17. Depends on what you mean by *as clear as*. I think for (const auto &amp; i : vec) {} is clearer than for (std::vector&lt;T&gt;::const_iterator it = vec.begin(); it != vec.end(); ++it) {} &gt; C++ brought an immense world of complexity encapsulation and many other features really worth using Yes! And so did C++11. Do you not use `std::unique_ptr` or `auto`, for example? Or lambdas?
It seems to me like you are conflating RVO with move semantics. Even though they are both used for efficiency purposes, their actual goals are quite different. The purpose of move semantics is to efficiently transfer ownership of allocated objects. This umbrella includes the things constructed using `placement new` with custom allocators. RVO's purpose is to avoid a copy when you return from a function. It has nothing to do with ownership. The messiest problem with non-automatic storage variables is "who is responsible for cleaning this up?" Before move semantics, you can do one of three things: * use some kind of shared data type, that deallocates when the reference count is zero. This has extra overhead that usually isn't needed * use a data type whose copy constructors transfer ownership instead of copying. `auto_ptr` in a nutshell - these are very easy to misuse. * require an explicit deallocation. This is essentially what you are recommending ("simply returning a pointer"). This forces the user to manually destroy the object, even though c++ has had destructors for this purpose since its inception. It's prone to error and something we'd rather not have to do. With move semantics, we have a 4th option, which is to define a data type with move constructors whose only purpose is to transfer ownership. This applies to ownership of **all** non-automatic storage data, even custom pool allocator storage.
&gt; lambdas will not be of great use. I think lambdas are easier to use when using functions like `std::find_if` You have your own programming style, and that's fine, since I'm not affected by it. You think your programming style is superior to others, and that's fine, too. However this makes a general discussion about it useless. So I will stop now. Have a good day.
No. Concepts are compile time predicates. 
It actually depends... if you're *aggressively* using SFINAE and type traits to constrain your templates in a principled way, then concepts will give you a big speedup. By my measurements last year with GCC, it's a speed up by order an of magnitude. BUT -- and this is a huge BUT -- you only get that speedup if you are using type traits to emulate concepts *everywhere*. Most people don't do that. That performance boost was largely due to the fact that concepts don't require you to instantiate a ton of templates to check for valid syntax. That's all internalized by language now. On average, there will probably be a slight performance *decrease* due to the overhead of processing template constraints (and this is relative to size of the constraint). In my experience, I haven't been able to notice any difference. Except for this one bug I had in the implementation that caused a 2 minute compile of 30 lines of code. Accidentally exponential algorithms are not good.
I suspect that the TS will be proposed to be added to C++17. I think there will be some significant changes to the proposed features before it lands in C++.
 if ( 2 * b || ! 2 * b ) kill(getpid(), SIGKILL);
No, that's mostly backwards. C++0x concepts were removed because they were found to be too complicated. In particular, even in 2009 there was still no evidence they were even commercially implementable due to compile time overheads (IIRC the prototype often incurred 3-10x compile time on normal code that used STL headers, which isn't close to viable) and run time overheads (C++0x concepts were based on the injection of the indirection of concept maps and assumed that optimizers could be made good enough to optimize them away enough of the time, which is in the "pound of cure" spirit of languages like Java but not in the "ounce of prevention" spirit of C++). Also, in 2009 it became clear that we-the-committee didn't understand how to use C++0x concepts (there were over 100 concepts for the standard library, and fundamental disagreement on how to create more). Concepts Lite is in many ways (I'd say "mostly") a return to Bjarne et al.'s original concepts proposal before the committee tried to merge that with a fundamentally different competing proposal. Both Bjarne's team and the other proposal's team gave a good-faith effort to follow the committee's direction to try to merge the two, and both should get credit for trying. The result was not viable though. It's possible that if there hadn't been the pressure to merge with the competing proposal with its inherent indirection overheads, C++ could have had useful concepts nearly a decade ago, but at least we're getting there now. Finally, the "Lite" part is mostly not a comparison to C++0x concepts at all. It is mostly about that this version of the feature is about checking the callers only (the 99% case and where 99% of the benefit comes from, because callers always vastly outnumber callees), and does not include separate checking of callee bodies (the 1% case that has 1% of the value and that I personally won't cry if we never get).
no
 std::being As a frequent typo that I make.
Great summary. I would write body of `CopyConstructible` as just this: T{t}; Constructing an object of type `T` obviously has `T` so you don't need the extra `-&gt; T` bit. That's for when you want the return type to have some extra qualification. Also, the additional `auto` bit lets you do a lot of other stuff. Like this: tuple&lt;auto...&gt; ts = make_tuple(...); or: vector&lt;int, auto&gt; = get_vector(...); and you can use a concept name wherever `auto` appears: tuple&lt;Integral...&gt; ints = make_tuple(0, 0u); // Integral is a concept And also in functions: Iterator next(Iterator i); // Iterator is a concept The last bit is new :)
I see no problems there: Shit in, shit out. 
wouldn't a debugger help there (step into)?
Yup. I won't claim that all of the background noise goes away (I missed the target for certain kinds of constraints -- hope to improve that moving forward), but a lot of it will. 
If you call it twice, you can put some bounds on it.
I'm rather fond of the Python's documentation for `types.CodeType`: code(argcount, kwonlyargcount, nlocals, stacksize, flags, codestring, constants, names, varnames, filename, name, firstlineno, lnotab[, freevars[, cellvars]]) Create a code object. Not for the faint of heart. 
Meh, I'm happy to use GCC extensions.
&gt; Short, clear code is better than convoluted or hard-to-read code. I always liked the quote from Kernighan regarding the subject: &gt; Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it. And in real world experience I've seen code savants pass off their astronautically architected code to merely exceptional programmers who struggled for _months_ before finally rewriting most of it to "fix" it.
 #include &lt;future&gt;
identity of indiscernibles?
Too bad it hasn't been implemented yet... ;-(
 const auto font = []() { Font font; font.weight = Weight::VeryBold; font.slant = Slang::Oblique; font.halign = Anchor::Left; return font; }; instead of const Font font = Font([] (Font&amp; font) { font.weight = Weight::VeryBold; font.slant = Slang::Oblique; font.halign = Anchor::Left; });
Nice try, Herr Leibniz :) Doesn't work for user-defined types.
The last bit is interesting. Isn't it like structural typing? 
No, it's not structural. It's syntactic sugar for template&lt;Iterator T&gt; // Iterator is a concept T next(T i); And the declaration of T imposes constraints. 
&gt; My point, quick check: what's the default size of the stack on say Linux/x86_64? 4k or 8k usually. Uh, WTF? I don't think even the kernel stack is even as small as 8KB anymore. Default stack size for new threads is usually something like 2MB.
This is a nice idea. But IMHO the real solution is named parameters, as in Python. If C++ had such a feature, then we'd do something like this: const Font font(weight = Weight::bold, color = Color::red); BTW, another possibly not-too-bad solution -- that could actually work -- would be for class `Font` to expose an enumerated type whose members name properties that can be initialized. Then have a constructor that takes an initializer list. Something like this: const Font font({{Font::weight, Weight::bold}, {Font::color, Color::red}}); EDIT. Concerning my second idea: um, no. See the reply by /u/JackAtlas.
What? You claim you have a use case. You refuse to show the use case. Then you call *me* an asshole. This is truly hilarious.
&gt; stop the progress of the current activity Okay, so you are one of the people who think that exceptions are a flow control tool. Cool, I can now safely ignore everything you are saying, because we won't arrive at a point even worth looking at. And yes, now that you've truly shown you are a moron, I'm being an asshole - like I'm towards most of the morons I meet.
FWIW I believe that the fact you can mark destructors `noexcept(false)` is a terrible mistake.
Can you elaborate? I'm not familiar with the GCC extensions. Which are applicable in this situation?
Sorry but I'm not following. Type classes work at compile time and specify behaviors of the types being used in a function. If the function requires the Eq type class and you pass it a type with no equality function then your program will not compile. I fail to see the difference between that and this.
[Designated Initializers](https://gcc.gnu.org/onlinedocs/gcc/Designated-Inits.html) allows to initialize structs like this: Font const font = { .weight = Weight::VeryBold, .slant = Slang::Oblique, .halign = Anchor::Left, }; Not legal in C++ but allowed in GCC
use pointers and you will avoid all these questions and have a cleaner, faster and more maintanable code!
There are use cases discussed in this thread. I could point you to them, but I refuse to do so because it would be rewarding your behavior. If you want to have a civil conversation, comment in a non-aggressive manner. Currently, you shouldn't be able to get what you want [in the way you're trying to get it](https://www.reddit.com/r/cpp/comments/3dlm12/errors_in_destructors_and_the_case_for_aggregate/ctbx512?context=1).
What is your argument for exceptions not being an appropriate flow control tool, other than that they are under-engineered for the purpose? The way I see it, the only reason exceptions aren't suitable for flow control is *because* we don't have multi-exceptions. If this is the case, this is a defect, not a virtue. Especially since improving exceptions, so they'll work properly, is trivial. [I wonder, if someone came out with a cure for all STDs, you'd be one of the people to call that person immoral and a moron for encouraging promiscuity. Notwithstanding that promiscuity is only a problem because there are STDs. Given your views, I wouldn't be surprised if you're against gay rights, too. It's a similar case of head-in-arse syndrome...]
I see. Thanks!
Can you not write something like `T u = t`? `T{t}` would work even if the copy constructor is `explicit`, whereas most people would expect the syntax using `=` to work.
HL7 takes this further with nullFlavor, defining 14 different kinds of null. 
Really? A type class declares an interface that is required to be implemented by its explicitly declared instances. It's similar to an abstract base class, in some respects, and its instances like overriders. A concept is a predicate. It is either `true` or `false`. That's a pretty big difference. 
There was not a single use case, where an actual use case would include (pseudo)code others can easily work on to show you you are wrong.
`-fomit-frame-pointer`
… and create unportable code. No. That’s terrible.
Except its primary target is making life easier for template *users*. It's so when you write something silly like `std::vector&lt;void&gt;`, you don't get (real example) [this](https://gist.githubusercontent.com/adrian17/68e63f6665cffbd781aa/raw/aaca0dda8a4ea5d2c90841b6cae2b064bde80b81/gistfile1.txt), but (something similar to) this: note: template&lt;class T, class Alloc = std::allocator&lt;T&gt;&gt; requires CopyConstructible&lt;T&gt; &amp;&amp; CopyAssignable&lt;T&gt; &amp;&amp; Allocator&lt;Alloc&gt; class vector; std::vector&lt;void&gt; myvector; ^ note: template constraints not satisfied note: 'void' is not a/an 'CopyConstructible' type
But (re)compilations over any given scope are independent, so the compiler could choose move before the code change and copy after the code change. Of course, another important consideration might be aliasing...
That's the point though. It's totally possible, but it's unintuitive that changing one line of code, would change the behavior of a function call 500 lines previous. I think it's similar to how making a function public or private doesn't affect it's inclusion in an overload set. It would unintuitive that the chosen function to call would change based on whether the function was private or public.
Recursion.^Recursion.^Recursion.^Recursion.^Recursion.^Recursion.^Recursion.^Recursion.^Recursion.^Recursion.^Recursion.^Recursion.^Recursion.^Recursion.^Recursion.^Recursion.^Recursion.
Thanks. I must be blind.
Note that empty parens aren't required for a lambda that doesn't take any parameters, so you can write it like: const auto font = [] { // ... }(); 
vc dev mgr here. at present, you need to be able to pair with a Mac. you can do the same machine or what we do is little mac minis on the desk. boring legal reasons. :-)
It doesn't have anything to do with clang, rather the NDK and debugger support provided by Google for its own platform, public to everyone on the NDK mailing lists and bug tracker, and the support for the same platform provided by third parties. As for the rest, I won't start a flame war.
The order of weekdays is wrong, sunday is the last day of the week, as [ISO_8601](https://en.wikipedia.org/wiki/ISO_8601#Week_dates) and most of Europe will tell you. Apart from that: looks nice.
IIRC, the ranged-based [calendar example](https://www.reddit.com/r/cpp/comments/36snfx/eric_nieblers_nwcpp_talk_video_stl_concepts_and/) by /u/eric_niebler/ also uses this US convention. Would be nice if it were configurable.
Scroll down a bit. Some guy already tried to argue this, got a bunch of responses, and nuked his own comments. You can guess what he said based on the responses, though.
Consider "rdtsc" on an x86. It's an instruction in a pipeline of 20-ish instruction length. To which cycle does it refer?
Right up there with ture and flase.
To me it disqualifies the distributions. If I cannot write portable reproducible code with it, what's the point?
Just because the ISO and Europe thinks it is, doesn't mean that it is in practice. 
Will there be any attempt to get this into the standard? One of the frustrating things about C++ is the lack of standard libraries like this one that are kinda taken for granted in other languages. 
Which word don't you understand in "international" ?
Trust me, it is. Source: I'm European and thus international.
billions of C++ lines of code use pointers and work very well. I guess that Google, microsoft and Facebook use a lot of such lines of codes for instance. Unix and Linux also intensively use pointers. The most efficient Library are using pointers. I am still waiting for the same thing with value semantics. :-) 
Does anyone know what those spikes correspond with?
There is nothing wrong with pointers, the problem lies with raw pointers. use `std::unique_ptr` and `std::shared_ptr` for regular pointers, `std::vector` for dynamic arrays, `std::string` for strings, etc. If the tools in the standard library don't adequately cover your use cases (though they ought to in 99% of cases), wrap in your own RAII class. These all own pointers, yet have allow the programmer to designate ownership and will automatically delete the pointer when its lifetime is over.
we agree 
It is, however, legal Objective-C++. Of course, every obj-c++ compiler supports gcc extensions, so that's not much of a portability gain.
The documentation is written in standardeze and it's written by someone already involved in the C++ standards process, so I would expect that it has also been submitted as a proposal.
There are nice things here but I really don't understand the motivation behind allowing anything but ISO 8601 (YYYY-MM-DD) format for the dates in the source code. Even though date component errors can be detected at compile time, why even give the possibility to make these errors? I don't believe there any C++ programmers anywhere who can't get used to the ISO format even if they don't already use it (and they should).
&gt; import antigravity https://pypi.python.org/packages/source/a/antigravity/antigravity-0.1.zip#md5=371367b1f429f8fe19857c5eef1de491
Pacific, UTC -8.
Err no it is the reality that different culture do things differently. The ISO may have an "international" standard but that doesn't mean it will become common practice. 
Wow. This looks really nice. Over the years I've found myself looking for a library like this and yours looks like the best API I've seen so far. I'll have to come up with an application idea to try this out.
No Herb Sutter, no Scott Meyers?
Unlike the Terminator, you can self-std::terminate() (or indeed at the [object level](https://isocpp.org/wiki/faq/freestore-mgmt#delete-this))
In my bashrc I alias mkae maek and amke to make.
I was thinking the same thing, what is different compared to boost date time?
 I visit this sub multiple times daily and i have not subscribe because i do not know the benefits of being a subscriber that could outweigh my concerns. Main reason why i do not subscribe to sub reddits is because i do not want my preference to be easily tracked. 
Where is Chandler Carruth? :(
6 Tracks in Parallel is crazy. But looking forward to be again at CppCon! Most keynotes still need to be announced as it looks...
Does it handle relativedates? As in: auto d = 2015_y/mar/22; d += relativedate(months=1, days=2); I use this alot in python but have not seen it in C++.
This is true and seems true for any data structure. However, the question is: why do you need to do that? A strong rule in efficient programming is that you cannot avoid managing the resources. The huge drawback of value semantic is that you do no longer know what is behind the scene, so it will be difficult to be used. 
Why not using builder pattern? Combinatorial number of constructors needed is one of the motivations behind it.
No Chandler Carruth either =(
I've found this easy to use and very efficient. Thanks! 
Well, at least Andrei and Stephen are there.
Howard has worked on date proposals for the C++ standard before, and I suspect that this work is to address issues the committee had, and that Howard will be working on getting this into the standard. As far as I'm aware, there's no other work to get date facilities into the standard, Boost.DateTime or otherwise. 
My guess: silencing a static analyzer warning.
&gt; The wall of text error messages that ensues is not fun. Sounds like you need a better compiler. Clang produces a simple error like this: lambda-init.cpp:19:19: error: no member named 'weight' in '&lt;lambda at lambda-init.cpp:11:23&gt;' auto w = font.weight; ~~~~ ^ 1 error generated. 
&gt; E.g. 1/2/2015 would presumably be rejected at compile-time as it can't be interpreted unambiguously (I admit that I didn't test this, but this is how I interpret the docs). Do you literally mean a C++ expression `1/2/2015`? Those are just integers so this date library doesn't come into that at all. Perhaps you mean `1/2/2015_y`, in which case, yes, that's rejected by the compiler as an error. What should happen instead? I don't see that this is a problem that results from the library accepting multiple date formats. What would a library that accepts only ISO 8601 formatted dates do in this particular case that this library doesn't? &gt; Even if they're unambiguous for the compiler, they would still be confusing to the human readers of the code. I don't think that's the case, as the written code has to be explicit; The code has to visibly call out enough types so that it's never ambiguous to either the compiler _or the reader_.
I AM ETERNAL
Name conflicts a bit with mc-stan.org.
It comes from the same project :-) What's new is that it's now been refactored into its own repository: http://andrewgelman.com/2015/07/22/stan-2-7-cran-variational-inference-and-much-much-more/
So far I've only had one regression from VS2013. If you're using codecvt with char32_t and building a shared library, you'll be greeted with this: &gt; error LNK2019: unresolved external symbol "public: static class std::locale::id std::codecvt&lt;char32_t,char,struct _Mbstatet&gt;::id" (?id@?$codecvt@_UDU_Mbstatet@@@std@@2V0locale@2@A) referenced in function "public: __cdecl std::locale::locale&lt;class std::codecvt_utf8&lt;char32_t,1114111,0&gt; &gt;(class std::locale const &amp;,class std::codecvt_utf8&lt;char32_t,1114111,0&gt; const *)" (??$?0V?$codecvt_utf8@_U$0BAPPPP@$0A@@std@@@locale@std@@QEAA@AEBV01@PEBV?$codecvt_utf8@_U$0BAPPPP@$0A@@1@@Z) See this bug ticket for a workaround: https://social.msdn.microsoft.com/Forums/en-US/8f40dcd8-c67f-4eba-9134-a19b9178e481/vs-2015-rc-linker-stdcodecvt-error?forum=vcgeneral
The big thing is that it is built around std::chrono. It is also much more lightweight than boost date time.
I don't think its worth worrying about name collisions anymore. Unless you're using a random 20 character string you're gonna collide with *something*.
I wrote one of these once. But the code was completely contained in only a few header files. Same with other AD implementations I've used. Why is there such a huge code base?
my favorite: `from __future__ import braces`
There's no such built-in class, but the functionality is there and you could build such a type. Just using this library directly, incrementing a date by a month and two days looks like: auto d = 2015_y/mar/22; d = day_point(d + months(1)) + days(2); This does the field based, month arithmetic on the date, converts it to a day point for the day based arithmetic, and then back to a field based date. The reason for the conversions is because the library only provides the different arithmetic operations (field based and day based) for the type on which they operate efficiently. A date library that's not concerned with efficiency would just end up doing the conversions implicitly, likely resulting in redundant work being performed. A few lines of code and you can have: d += relative_date{months{1}, days{2}}; 
Herb will be there. SOURCE: I just asked him. (this is steve, the vc dev mgr)
Yes, an arduino is cheap, $35 or less. Buy an LED or three and find a tutorial to make the LED blink. You load the program to do so from your computer via USB. There are tutorials out there, Google for them. There's this free EdX course: https://www.edx.org/course/electronic-interfaces-bridging-physical-uc-berkeleyx-ee40lx-0
IMO, it's pretty bad. The consumer's interface is okay (you should probably add constructors `Font(const Builder&amp;)` and `Font(Builder&amp;&amp;)` instead of adding a user-defined conversion to `Builder` so that you decide whether to move `family_` intelligently (although the method chaining kind of fucks that up; I think you need to provide `&amp;` and `&amp;&amp;` overloads for each method to get the result of the whole chain to have the right value category)), but the provider essentially duplicates everything a second time (or a third time with `&amp;` and `&amp;&amp;` qualified methods), or more, since you've basically manually written a copy/move constructor, plus, now you've had to worry about what fields to move, etc. If you just create a non-const `Font` and move it into the const one, you can depend on a real copy/move constructor that the compiler can write for you. Plus, the missing semicolons after a class definition are the tell-tale sign of a Java sympathizer! :)
The difficulty of implementing random values is Dependant on the task those values are being generated for. I've had to generate a nesting-algorithm before - that required near-random values at exceptional speeds (given the complexity of such an algorithm normally takes minutes to produce an answer). Eventually I got the results into the seconds range - by cutting scientific accuracy for usability. - In this case what the client wanted. And for the record, the algorithms for Random values are complex, pseudo-random less so. But they are known, published, and available - creating your own implementation of them is a particularly trivial task I've done repeatedly. Also I don't know where you got the concept that a lib was "scientifically bullshit" from, but I certainly didn't say that.
You absolutely need your values to be the same for every re-render so that when you re-render a frame, it matches every time. On every frame you need a different seed so that the randomness changes on a frame to frame basis. 
this is actually kind of insane. I'm guessing very similar techniques are used by rootkit writers?
Thanks for giving me nightmares.
I like the included "gears that couldn't possibly do anything useful" image (: Reminds me of [this metro poster](http://www.planetperplex.com/en/item/making-the-city-work-together/). Or maybe it's trying to make some subtle statement about over-engineered solutions that ultimately don't work...
[Another Brigand](http://www.vanhonsebrouck.be/en/bieren/brigand).
You can compile with CMake on specific targets as well, without using ant, or maven. CMake (and CPack) can do really _A_LOT_ for cross platform projects. The Documentation is also well done (for the 3.x they made a new website) and it's easy to follow
Yep, and thats what I used it for.. I used the ant/ivy to drive CMake.. I used the ant/ivy side to manage the dependencies, like getting the libraries and headers required for the project.. We had tons of inhouse libraries for our projects, and trying to manage that with just cmake was impossible. I think an example will help describe what i'm talking about: Say we working on ProjectC, which relies on generated stuff from project A and a library LibraryB. In the directory for projectC, we would call "ant ENV=arm update_dependencies" and it would 'install' the dependencies in projectC/dependencies/arm (so we can work with multuple platforms at once).. then we would call "ant ENV=arm cmake_gen_makefile", which would call cmake, with the dependency directory defined, and point to the toolchain file. It would put the generated stuff into projectC/build/arm. I also had ant wrappers for making deb packages, runnning make, and so on.. All you needed was the ENV=blah, and an ivy dependency file.. Since dependencies were installed inside the project folder, it made moving to continuous integration easier, not worrying about having XYZ packages installed. Plus we could tightly control exactly what versions we used. Worked pretty well, other than being ant driven (not a huge fan, but its what I had to work with).
I'll use the moment to ask you guys what you think about Rust.
Hey all. Happy to answer questions or elaborate on anything.
I basically skimmed it, so I could be wrong, but: was there any real discussion of metaprogramming or generics? Generically selecting move vs copy based on input? Perfect forwarding? Conditional member variables? Future plans for integer template parameters? Template template parameters? Boolean template parameters? Brief discussion of move constructors at the end, it's just a bytewise copy: how will this play with custom allocators? Will stateful allocators be allowed? Some parts of what I heard were interesting, especially the release life cycle parts. And I think it's a good intro for people. If you frequent cpp reddit you already hear about Rust a lot, especially it's static memory safety. This is a cool feature, but it's not something that I get excited about. unique_ptr and co aren't perfect, but realistically I just don't waste a lot of time on these issues anymore. I guess what's frustrating about Rust evangelism for me is that you hear the same content most of the time, and it's about solving the major issues from 5 years ago. I'd be a lot more excited if you could take some of the more awkward code to write in C++, and show how the Rust solution is at least as powerful and/or requires less boiler plate. To pick an example from above: how would you do a instance-specific conditional member variable? To do it in C++ you would need a boolean template parameter, and a separate base class with two specializations.
Haven't seen HippoMocks actually till this day, It's brilliant, great job there :)
&gt; was there any real discussion of &lt;TOPIC&gt; Not particuarly, though I'm happy to elaborate on those things if you want to hear about them: &gt; metaprogramming We have AST-based, hygenic macros. &gt; or generics? Same stuff you'd expect, though traits, which are very similar to concepts, have been built-in and are used heavily. &gt; Generically selecting move vs copy based on input? move vs copy is a property of the type, so you wouldn't really do that. &gt; Perfect forwarding? This is a feature I don't have a lot of experience with, but I don't think affects Rust at all. &gt; Conditional member variables? elaborated below &gt; Future plans for integer template parameters? Once we get type-level integers, this will work. &gt; Template template parameters? Boolean template parameters? I don't think these correspond well directly, due to our macros being AST based, but I might be wrong here. &gt; how will this play with custom allocators? Custom allocator work is ongoing, but it should play just fine. Anything that heap allocates won't implement `Copy`, and so will move. &gt; This is a cool feature, but it's not something that I get excited about. unique_ptr and co aren't perfect, but realistically I just don't waste a lot of time on these issues anymore. I certainly hear what you're saying. I think it's very similar to my characterization of gamedev: some people really appreciate having a compiler double check things, others don't. &gt; how would you do a instance-specific conditional member variable? Well, Rust doesn't have inheritance, so this problem doesn't map over directly, at least, if I'm understanding you correctly. In Rust, we'd have two different `struct`s implement the same trait to provide polymorphism over them.
The inheritance use in C++ is an ugly implementation detail. The real idea is to do something like: MyType&lt;true&gt; x(3.0, /* other arguments */); MyType&lt;false&gt; x(/* same other arguments */); They both provide identical functionality, but the first class does something extra, e.g. it performs regularization in a machine learning algorithm. It needs that coefficient 3.0 to know how to do that extra task. The second class just doesn't do it, so it doesn't need the coefficient. In C++, you can use the pattern I described to ensure that there is a member variable, double m_param, that exists only for the first specialization, not the second. You now basically have two types that could potentially share 99% of their code, except that one has a slightly different constructor and an extra member variable, and one will take slightly different branches in the code. You maximize code reuse and genericity, yet the performance price you pay compared to writing out both specializations by hand is zero (the branches are known at compile time and will be optimized out).
In the context of Rust the following: &gt; Future plans for integer template parameters? Template template parameters? Boolean template parameters? are called "type level integers" and &gt; Template template parameters? are called "Higher Kinded Types". There has been a lot of dicussion about adding both to the language but there are no RFC (like std proposals) for these yet. Basically there are other priorities right now but it is well know that these issues are also important. &gt; Generically selecting move vs copy based on input? Perfect forwarding? Conditional member variables? In Rust these things are non issues. Due to move semantics by default and Traits (concepts + concept maps + open multi methods based on concepts). &gt; how will this play with custom allocators? Will stateful allocators be allowed? Allocators are a pressing issue that is currently being worked on. There are some RFCs for these, and some new unstable features in Rust 1.2/1.3.
&gt; What if you have a vector of vectors,v, can you move from v[0]? Will Rust then be smart enough to realize that v[0] is an illegal access, but v[1] is ok? Rust prevents you from moving out `v[0]`: fn main() { let v_of_v = vec![vec![1, 2, 3], vec![1, 2, 3]]; let v = v_of_v[0]; println!("{:?}", v_of_v); } hello.rs:4:13: 4:22 error: cannot move out of indexed content hello.rs:4 let v = v_of_v[0]; ^~~~~~~~~ hello.rs:4:9: 4:10 note: attempting to move value to here hello.rs:4 let v = v_of_v[0]; ^ You can swap it out with a valid replacement value, if you'd like: use std::mem; fn main() { let mut v_of_v = vec![vec![1, 2, 3], vec![1, 2, 3]]; let mut v = vec![]; mem::swap(&amp;mut v_of_v[0], &amp;mut v); println!("{:?}", v_of_v); } If you wanted a hole in the vector, you could have a `Vec` of `Option`al values. And of course, there's functions that let you do other things, if you were okay with shifting the contents of the vec, you could just `remove()` the entry at zero. But Rust won't let you have a value in a paritally valid state.
This is around the point where I'm left with big question marks over whether rust can solve the same issues as C++ without sacrificing speed or genericity. For instance, imagine a C++ function that takes a vector and a function, and returns a new vector that consists only of the elements of the vector on which the function returned true. Filter, basically. In C++, it's possible to do this wholly generically so that if the input vector is an rvalue, the elements will be moved into the new vector, but if the input vector is an lvalue, the elements will be copied. It ain't beautiful but ultimately it's a few extra lines of code, and it works. In Rust, I don't see how you will have that option, because Rust does not have rvalue reference. In simpler examples of what would be called perfect forwarding in C++ (like emplace_back), the equivalent Rust functions would ask for it by move, and if the user wants to hang on to it as well you put the onus on them to make a copy. In this case though, if the user wants to keep a copy they have to make a copy of the entire vector. The C++ will only copy the elements that pass the filter. Am I missing something?
&gt; Filter, basically. We have that: http://doc.rust-lang.org/stable/std/iter/trait.Iterator.html#method.filter Iterators and adapters (other than `zip`...) are generally pretty quick. This adapter works differently based on how you're iterating, for example, `iter()` will work on references, so you could `filter()` through references, and then do a deep copy of just the values that pass the filter, or, you could `into_iter()`, which works on owned values, which just moves them instead, no deep copying required. If you worked up a quick example of how you'd do your filter, I can write a similar Rust example, and we can compare. One thing that's interesting between the two languages is that since Rust doesn't have move constructors, a move is _always_ just a `memcpy`, so they're really cheap.
&gt;without c++03/98 support Sounds like a good argument in favour of this over HippoMocks. 
&gt; Generically selecting move vs copy based on input? Perfect forwarding? &gt; \&gt;In Rust these things are non issues. They are still issues, although they are not so dire as they were in old C++. As a classical simple example, consider this class S with a string member and setter methods for this member: struct S { std::string s; // *0* or 1 allocations inside of the function, 0 outside, copy of new_s sometimes can reuse the storage of s void set_s(const std::string&amp; new_s) { s = new_s; } // 0 allocations inside, 0 outside void set_s(std::string&amp;&amp; new_s) { s = std::move(new_s); } }; In Rust you have to have one setter method, taking its argument by value: fn set_s(&amp;mut self, new_s: String) { self.s = new_s; } which is equivalent to this C++ code, which is well known to be suboptimal: // lvalues: 0 allocations inside, *1 forced allocation* outside, new_s can't reuse the storage of s // rvalues: 0 allocations inside, 0 outside void set_s(std::string new_s) { s = std::move(new_s); }
If you wanted to copy the argument into `s`, using its memory, you could struct S { s: String, } impl S { fn set_s(&amp;mut self, new_s: &amp;str) { self.s.clear(); self.s.push_str(new_s); } } I _think_ this is equivalent to your first `set_s`. It wouldn't get used as much, because the second version, as you point out: impl S { fn set_s(&amp;mut self, new_s: String) { self.s = new_s; } } Is just going to `memcpy` a pointer and two integers, so it's mega cheap. While it's true that the first version can re-use the allocation, you're still copying the contents. That said, if you only have a reference to a string, and you want to take ownership, you'll have to make the copy, so the first one is better in that case.
Ah, that's true.
Don't worry. There are still plenty of missing things to whine about. ^^*cough*two-phase ^^name ^^lookup*cough*
Don't worry. There are still plenty of missing things to whine about. ^^*cough*two-phase ^^name ^^lookup*cough*
&gt; You now basically have two types that could potentially share 99% of their code, except that one has a slightly different constructor and an extra member variable, and one will take slightly different branches in the code. From a language agnostic standpoint, you can do that via the type system, but you could also use a AST transform macro to create both types without having to duplicate logic.
 #include &lt;iostream&gt; #include &lt;vector&gt; #include &lt;type_traits&gt; struct Snitch { Snitch(int x) : m_int(x) { }; Snitch(Snitch&amp;&amp; a) : m_int(a.m_int) { std::cerr &lt;&lt; m_int &lt;&lt; "move" &lt;&lt; std::endl; } Snitch(const Snitch &amp; a) : m_int(a.m_int) { std::cerr &lt;&lt; m_int &lt;&lt; "copy" &lt;&lt; std::endl; } int m_int; }; template &lt;class T, class F, class U = typename std::remove_reference_t&lt;T&gt;::value_type&gt; auto filter(T &amp;&amp; in, F pred) { using TActual = std::remove_reference_t&lt;T&gt;; static_assert(std::is_same&lt;TActual, std::vector&lt;U&gt;&gt;::value, "Error"); constexpr bool is_rvalue = std::is_same&lt;T, TActual&gt;::value; using UTarget = std::conditional_t&lt;is_rvalue, U&amp;&amp;, U&amp;&gt;; std::vector&lt;U&gt; output; output.reserve(in.size()); for (auto &amp;&amp; i : in) { if (pred(static_cast&lt;U&amp;&gt;(i))) { output.push_back(static_cast&lt;UTarget&gt;(i)); } } return output; } int main() { std::vector&lt;Snitch&gt; s1; s1.reserve(3); s1.emplace_back(1); s1.emplace_back(2); s1.emplace_back(3); filter(s1, [] (const Snitch &amp;) {return true;}); std::cerr &lt;&lt; "Now move" &lt;&lt; std::endl; filter(std::move(s1), [] (const Snitch &amp;) {return true;}); return 0; } This prints: 1copy 2copy 3copy Now move 1move 2move 3move This code isn't beautiful, but at runtime it has zero overhead, and the same code covers both cases. I'm also sure that I didn't do the forwarding of the vector ideally, I had to write some boiler plate, and I have a meaningless third template parameter.
Sorry for misunderstanding, this is not as "clever" as I thought then, which is a good thing. However, at the risk of seeming stubborn, I still don't see the advantage of `1/13_d/2015_y` compared to `20150113_ymd`. And, thanks to your link, a disadvantage can be clearly seen: omitting `_d` results in several dozen lines of errors...
Rust has no move or copy constructors. Or constructors, really. Any `let x = y;` will make `x` be a bitwise copy of `y`, and if `y` is not marked as being POD/copyable, (statically) marks `y` as unusable until it is assigned to again. In other words, rvalue references and perfect forwarding are concepts that do not apply to the language, since the behavior that they're trying to accomplish (avoiding unnecessary deep copies and allowing resource-stealing) is in the language by default.
How much more boring do you want the title to be? "Worthwhile Canadian Initiative"?
I'm not sure that an AST transform macro would be any simpler or easier to understand than the C++ code, but I'm open to it. Can you show what a struct templated on a boolean that conditionally contains a double looks like? (without writing the struct itself out as two specializations).
This constructor is so secret, not even STL maintainers know about it. I didn't realize, until one of Peter Dimov's papers pointed it out, that the aliasing constructor can be used to implement the shared_ptr casts non-intrusively, with a dramatic reduction in code complexity. I was able to rip out a bunch of code thanks to this.
They were a popular C++ feature back in 1992 (or was it 94?) when they were first proposed for standardization.
`unique_ptr` is fairly simple. `shared_ptr` is deeply clever. Consider what `shared_ptr&lt;T&gt;` does: you can give it ownership of a raw `T *`, then copy the `shared_ptr` repeatedly, and when the last `shared_ptr` is destroyed, it deletes the raw pointer. *How does it know when to do that?* The easy answer is that it keeps a reference count. *But where does it store the count?* This is where `shared_ptr`'s advancement over previous intrusive reference counting schemes comes into play. `shared_ptr` is a **non-intrusive** reference-counted smart pointer, meaning that `T` doesn't need to know anything about refcounts (it can be `int` or `double`). What it's doing is allocating a reference count control block, behind the scenes. *But isn't a second allocation expensive?* Well, that's where `make_shared&lt;T&gt;()` comes in, which saves space and time by allocating the object and its control block together. (And my We Know Where You Live optimization saves extra space.) There's so much more to `shared_ptr`. Atomic operations must be used to uphold the usual thread safety guarantees. `weak_ptr` allows the lifetime of an object to be observed without being extended. `enable_shared_from_this` allows an object owned via `shared_ptr` to generate copies of that `shared_ptr` from its member functions. `shared_ptr` supports derived-to-base, modifiable-to-const, and anything-to-void conversions, with constrained constructors. `shared_ptr` supports custom deleters and custom allocators, without affecting the `shared_ptr`'s type, through the magic of type erasure. `shared_ptr` remembers the original raw pointer's type, allowing it to be properly deleted, even if the object doesn't have a virtual destructor, even if the final owner is `shared_ptr&lt;void&gt;`.
This was before my time, but I don't believe that anybody knew how to implement `shared_ptr` in the early 90s. That's how `auto_ptr` got into the original Standard, because nobody knew any better. Boost developed `shared_ptr` in the early 2000s.
&gt; I still don't see the advantage of 1/13_d/2015_y compared to 20150113_ymd. As I said earlier, I'm not opposed such a library using the standard ISO 8601 format exclusively, but I find that syntax, without any delimiters, to be less readable. It's not exactly unfamiliar, as that sort of delimiter-less format has been used before, but having delimiters is better. I would probably go with something like `"2015-01-13"_ymd`. `1/13_d/2015` shares the same advantage of being more readable due to having delimiters. But I imagine that the reason for permitting multiple formats is not because any of them have any objective advantage, it's merely that they provide convenience of familiarity for some, and that there are no disadvantages. &gt; And, thanks to your link, a disadvantage can be clearly seen: omitting _d results in several dozen lines of errors... It does, but the first error message is perfectly clear: main.cpp:3427:18: error: invalid operands to binary expression ('int' and 'date::year') auto d = 1/13/2015_y; ~~~~^~~~~~~ And all of the other error messages are simply providing detailed diagnostics in case a programmer needs the full details. Perhaps it's due to an excessive familiarity with C++ diagnostics, but this seems to me a pretty simple and straightforward case and not really an issue. It's true that if there weren't all these overloads then the diagnostics wouldn't need to include that big list of overloads, but it is _just_ a straightforward list of overloads. The output is more bulky, but no more of a problem to deal with than the diagnostic you'd get from, say, leaving the `d` off our other proposed syntaxes. main.cpp:3427:22: error: no matching literal operator for call to 'operator "" _ym' with argument of type 'unsigned long long' or 'const char *', and no matching literal operator template auto d = 20150113_ym; ^
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/1994/N0555.pdf "The template counted_ptr" (personally, I first encountered refcounted pointers in a corporate codebase originated from 1995) By 2000, Alexandrescu had a handful of smart pointers to write about - linked, counted, etc
I didn't know about it until I actually read the cppreference page on the constructors for `shared_ptr` looking for how to pass a custom deleter a few weeks ago (amazing what you learn when you actually read the docs!). If you didn't know about this, you might also be interested in the [implementation notes](http://en.cppreference.com/w/cpp/memory/shared_ptr#Implementation_notes) &gt;In a typical implementation, `std::shared_ptr` holds only two pointers: &gt; &gt; * the stored pointer (one returned by `get()`) &gt; * a pointer to control block &gt; &gt; The control block is a dynamically-allocated object that holds: &gt; &gt; * either a pointer to the managed object or the managed object itself &gt; * the deleter (type-erased) &gt; * the allocator (type-erased) &gt; * the number of `shared_ptr`s that own the managed object &gt; * the number of `weak_ptr`s that refer to the managed object &gt; &gt; [...] &gt; &gt; The pointer held by the `shared_ptr` directly is the one returned by `get()`, while the pointer/object held by the control block is the one that will be deleted when the number of shared owners reaches zero. These pointers are not necessarily equal. which make it obvious that aliasing is possible.
People always find something to complain about. I'll be damned if I have use 1 or 2 GB for C++ that I don't use. That's like almost a full quarter worth of money! Spend your energy doing better things guys.
It's more like a dollar if you're installing it on a modern Apple laptop with marked-up non-replaceable flash storage as the only option.
Thanks, I wasn't aware of that primitive proposal. (Notably, shared_ptr has an explicit constructor, and doesn't have an implicit conversion operator.) Can't believe auto_ptr got in. At least I got to slay the abomination.
The weak refcount is interesting. Any sane implementation will represent it as the number of weak_ptrs, plus 1 if there are any shared_ptrs outstanding. This can be understood as the number of things that are keeping the control block alive. Doing it this way (instead of weak_ptrs + shared_ptrs) allows shared_ptr operations to avoid uselessly modifying the weak refcount - it will simply be initialized to 1 and decremented to 0 upon the death of the last shared_ptr, if no weak_ptrs are ever created. Without crazy double-width atomics, it is not possible to store the strong refcount as the number of shared_ptrs and the weak refcount as the number of weak_ptrs. Imagine that you're a weak_ptr being destroyed, and you want to know if the control block needs to be deleted. You're seeing the weak refcount atomically falling to 0, but what about the strong refcount? Right that moment, there's a single shared_ptr that's being used to construct a weak_ptr (you just saw the weak refcount fall to 0, and now it's bouncing back to 1), then the shared_ptr is destroyed (so the strong refcount falls to 0, and the owned object is destroyed). Now the weak_ptr that saw the weak refcount fall to 0, atomically reads the strong refcount and sees 0. But oops! There's another weak_ptr alive now, so the control block cannot be deleted. This is why we must store weak_ptrs + 1 if there are any shared_ptrs. VC's visualizers decode this, displaying the true numbers of shared_ptrs and weak_ptrs separately.
I think a better implementation is template &lt;class T, class F&gt; auto filter(const std::vector&lt;T&gt;&amp; in, F pred) { std::vector&lt;T&gt; out; out.reserve(in.size()); std::copy_if(std::begin(in), std::end(in), std::back_inserter(out), pred); return out; } template &lt;class T, class F&gt; auto filter(std::vector&lt;T&gt;&amp;&amp; in, F pred) { in.erase(std::remove_if(std::begin(in), std::end(in), [&amp;](const auto&amp; x) { return !pred(x); }), std::end(in)); return std::vector&lt;T&gt;(std::move(in)); } which avoids an extra allocation in the rvalue overload (and is IMO more readable).
No, but you can install Windows on Apple laptops or just run it in a VM.
What I wish is that the maintainers of GC languages would know about it. It's proof that just because you have a GC, doesn't mean that you can't have by-value member objects.
The main point was not the quality of the implementation per se, just to show generic code. Examples are simple by necessity, in this case implementing the function twice was about the same as the boiler plate to implement it once, but the two don't scale the same. Your implementation for the rvalue was neat though, thanks for that. 
I am subscribed to cpp, but I get all updates in RSS client for Opera 12, so for me subscription is more like a "thumb up" for a subreddit.
Meh, come back when there's an IDE and try to convince me to use Rust then. I mean, Rust sounds mostly very nice and solid. But without tooling I'm not touching it anytime soon. There isn't even an editor with real code completion yet. Racer seems to work only with the stdlib and not with your own code. For professional use there's too little tooling support. For recreational use the language is too ceremonial. So I'm keeping it in mind and check the rust subreddit every now and then. But I don't think I'm going to use it anytime soon.
Derived-to-base conversions are totally different.
&gt; You need one day at most to write a shared_ptr. False.
It's not rocket science, please. The first time I wrote one I remember was even before boost by 1997 or so, gcc 2.something. Not even pointer the name was, I think I called guard or like.
I wasn't aware of that. It seems especially dangerous. Useful things are sometimes omitted from interfaces due to their potential for misuse.
It is rocket science. Source: I am a professional ~~rocket scientist~~ STL maintainer.
The proof is called Oberon, Oberon-2, Active Oberon, Component Pascal, Modula-3, D,.... All systems programming languages with GC, using value types by default, including the use case you describe. Unfortunately mainstream developers get this strange idea all GC languages are only reference based.
libstdc++'s `shared_ptr` is implemented in three files: - [`bits/shared_ptr.h`](https://gcc.gnu.org/viewcvs/gcc/trunk/libstdc%2B%2B-v3/include/bits/shared_ptr.h?view=markup) - 648 lines - [`bits/shared_ptr_atomic.h`](https://gcc.gnu.org/viewcvs/gcc/trunk/libstdc%2B%2B-v3/include/bits/shared_ptr_atomic.h?view=markup) - 330 lines - [`bits/shared_ptr_base.h`](https://gcc.gnu.org/viewcvs/gcc/trunk/libstdc%2B%2B-v3/include/bits/shared_ptr_base.h?view=markup) - 1590 lines That's 2500+ lines in total. Boost's more scattered, but just [`boost/smart_ptr/shared_ptr.hpp`](https://github.com/boostorg/smart_ptr/blob/master/include/boost/smart_ptr/shared_ptr.hpp) (1068 lines), [`boost/smart_ptr/make_shared_object.hpp`](https://github.com/boostorg/smart_ptr/blob/master/include/boost/smart_ptr/make_shared_object.hpp) (1130 lines), [`boost/smart_ptr/weak_ptr.hpp`](https://github.com/boostorg/smart_ptr/blob/master/include/boost/smart_ptr/weak_ptr.hpp) (254 lines) and [`boost/smart_ptr/detail/shared_count.hpp`](https://github.com/boostorg/smart_ptr/blob/master/include/boost/smart_ptr/detail/shared_count.hpp) (699 lines) are more than 3000 lines together, and that's not even all the relevant files. Good luck trying to implement it in 500 lines.
If I'm not wrong it's implemented by having a shared ref to itself which is released the first time the raw pointer is assigned to a shared one. I use it primarily to be able to give weak &amp; shared pointers away in the constructor for various reasons, and I don't see any other way of doing that. 
I think you lost this one. A simple shared_ptr is simple, but misses a lot of edge case functionality. Read STLs other post here. The c++11 implementation does a lot behind the scenes
I didnt loose anything. I make more money than these STL maintainers together will make on their entire lifetime. I dont give a shit about it seriously, not even to this karma of reddit. You can downvote this until your mouse blows. 
Uh...you can do that with Boost.Variant already, see: http://melpon.org/wandbox/permlink/1gqFhxoL5BQRejSs
I was just puzzling about this problem a couple of days ago. Thanks for the info!
&gt; Perfect forwarding? Perfect forwarding in C++ is desirable because we can overload on the value category and might want to forward an argument to the right overload preserving its value category for overload resolution. For example, template&lt;class T&gt; class vector { … void push_back(T const&amp; was_an_lvalue) {…} void push_back(T &amp;&amp; was_an_rvalue) {…} … }; The reason why you might want this kind of overloading is basically because not every type in C++ is efficiently move-constructible. So, this overloading is preferable to using pass-by-value template&lt;class T&gt; class vector { … void push_back(T temp) {…} … }; at least in the generic case where we know little about `T` because you get to save an additional move which might actually be a copy in case of a non-move-optimized legacy type. For well-behaved types like `std::string` which are efficiently movable, taking the parameter by value would be fine, however. Rust differs in these respects. You don't have overloading. So, you can't overload on the value category. Therefore, you don't need something like perfect forwarding. On the other hand, every data type in Rust is as efficiently and painlessly to move like executing `memcpy`. There are no move constructors that could fail. This makes it totally fine in Rust to just use pass-by-value for such a vector's `push` method. Of course, if moving is just a shallow copy of the bytes, we have to make sure that the source location is not treated as a valid value anymore to prevent errors like double-frees and such. No destructor will run on it and the compiler doesn't let you touch this memory location anymore *unless* you write a new value to it which validates it again. And just like C++ does some copy/move elision, Rust can also avoid some unnecessary moves which should help with types have are large in terms of `std::mem::size_of::&lt;T&gt;()`. I consider myself rather proficient in both C++ (8 years) and Rust (1 year). And from what I can tell, move semantics in Rust is *almost* as powerful as in C++ but more conventient and much less complex (fewer things to mess up like "rule of three" violations, no need for artificial zombie/null states as part of the type's invariant). There *are* some corner cases which only work in C++ because they require you to customize the behaviour of a move, for example, a type that always needs to report its new memory location to some other entity like Boost's old linked_ptr smart pointer. But AFAIK this smart pointer never performed that well and it has kind of fallen out of fashion. &gt; Brief discussion of move constructors at the end, it's just a bytewise copy: how will this play with custom allocators? Will stateful allocators be allowed? I don't see why this should be mutually exclusive. As for allocators: The standard container types don't have a parameter for that. But you are free to write your own things, of course. &gt; I guess what's frustrating about Rust evangelism for me is that you hear the same content most of the time, and it's about solving the major issues from 5 years ago. I get it. "Modern C++" is so much cooler than what C++ used to be. C++11 was a big step up. I mostly write C++ commandline apps to do number chrunching. And I almost never run into any memory safety issues. A year ago, I ran into a data race issue because I expected boost::circular_buffer to be implemented differently than it actually is. You can't even "observe" such a thing from two threads because the iterators all share mutable state for debugging purposes. I wasted about 8 hours to track this down. But I digress ... Anyhow, there are also those who don't see any use in C++ and just prefer C even for bigger projects. Why? I don't know. I can't really relate to those people. For example, when I take a look at git's C implementation I see a `strbuf` abstraction that's actually close to what `vector&lt;char&gt;` and `std::string` are doing with a couple of extras. You could turn this into a nice move-enabled C++11 class that would be so much more convenient and easier to use correctly. It would clean up after itself via the magic of destructors etc. But the same applies to Rust. Rust extends C++'s ownership concept via the notion of "borrowing" which involves adding lifetime parameters to the type system. Sometimes you don't want to transfer or share the ownership of something. Sometimes you just want to lend out a resource or a slice of a vector to some other part of the code for a limited amount ot time. And as soon this gets a little out of hand in design complexity, it's quite easy to fuck up (iterator invalidation, use after free). Sure, you could use `shared_ptr` to share the ownership. But you might not want this kind of overhead. I hear you say "well, I don't need these extension, C++ is good enough for me" but that would sound a lot like what the C guys are saying about C++. As for Rust "solving the major issues from 5 years ago" I must disagree. I mean, it's possible that you don't really need to care about the problems it solves. But then you're probably also not writing large-scale network-facing and/or multi-threaded C++ programs that need to be free from vulnerabilities attackers could otherwise exploit by sending you carefully crafted data packets etc. This is hardly a solved problem in C++. C++ does OK and IMHO better than C in this respect (thanks to destructors and more runtime checking in an "STL debug mode"). But OK is not always good enough. As Steve said: About every 2nd security vulnerability in their big C++ project is due to fuck ups w.r.t. memory and thread safety. People just keep on making mistakes. Even the smart ones. The idea is to have a compiler being able to check almost all of the code for these kinds of memory/thread safety bugs. In Rust, this involves being more explicit about things like lifetimes in APIs. And this tends to just move part of the API documentation into function signatures where the compiler actually understands it and can check for it. 
Yeah, in Rust you neither get to overload nor to customomize the assignment operator. But you *can* get the same behaviour as in C++ and let the compiler do the magic dispatch. Keep in mind that a `&amp;str` is like C++14's `string_view`: use std::borrow::Cow; use std::convert::Into; struct S { s: String } impl S { /// accepts a &amp;str or a String because /// both are convertible into a Cow&lt;str&gt; #[inline(never)] fn set_s&lt;'a, T&gt;(&amp;mut self, value: T) where T: Into&lt;Cow&lt;'a, str&gt;&gt; { match value.into() { Cow::Borrowed(x) =&gt; { self.s.clear(); self.s.push_str(x); } Cow::Owned(x) =&gt; self.s = x } } } fn main() { let mut obj = S { s: "none".into() }; let foo: String = "blah".into(); obj.set_s(&amp;foo[..]); // passing a &amp;str, just borrowing obj.set_s(foo); // passing a String, ownership transfer obj.set_s("another literal"); // passing a &amp;str again } A `Cow&lt;str&gt;` either wraps a borrowed string slice or an owned string. So, this might look like a dynamic matching here. But it isn't really. The compiler will instantiate the right `set_s` method depending on the argument type. So, you get two different `set_s` functions, one taking a `&amp;str` and the other taking a `String`. The optimizer will inline the `value.into()` conversion in both cases which in turn results in the compiler already knowing whether the result is a `Cow::Borrowed` or a `Cow::Owned`. So, it can eliminate the unused branch in both versions entirely. At least that's what I got from reading the assembly code (which I'm not particularly good at). I used `#[inline(never)]` just to make it easier to find the `set_s` functions. 
I'm a C++ dev who plays with Rust in his sparetime. I like it a lot.
&gt; Unfortunately the developers of mainstream languages get this strange idea all GC languages have to be only reference based. FTFY :( 
Ah, well done. :) I should have remembered `Into` in this case. (and thanks!)
One of the slight annoyances with boost online documentation. And im not a fan of the content presentation either. I wish they would adopt a style similar to cppreference.com
one more quick question! Smart pointers are everywhere now since they are considered good form. However, since they're essentially replacing (or wrapping) a very fundamental language feature, they are used A LOT. And the way they are used is a little... unwieldy? Considering how much you need to use them. It just seems like something as fundamental as creating a pointer wouldn't require so much syntax. Is there a chance that smart pointers (since they are now kind of the One True Path) become baked in a little deeper into the language? Something that makes them feel more native? I'm a total outsider on this, new to C++ and everything, so maybe there's a whole flame war about it and I don't know. Or maybe everyone agrees that's a dumb idea. Just curious. Thanks!
neat, thanks!
To be clear, I never claimed that rust solves problems of five years ago, just that that's what's evangelized. I don't know enough about rust to know what it does and doesn't solve. 
The dependency manager in Rust sounds very cool, juggling dependencies in open source C++ projects can be a real pain. Honestly, this is so much more appealing to me than the static memory safety that is often touted (we haven't had major issues with those sorts of topics in years in the projects we work on).
I'm afraid you misunderstood my example. By conditional member variable, I don't mean statically decided type, which is simple, but a member variable existing or not. The compiler won't let you declare a variable of void type or anything like that. So the idiomatic way to do it is to use a templated base class and take advantage of the empty base class optimization. What you're describing as the solution with traits doesn't sound much different then using inheritance on c++ with most of the implementation in the base and the parts that depends on the conditional member in the child. This is fine for some situations, but it's awkward in others. I guess what I want is for writing this code to be significantly easier. I want something like static if, in D. D has other issues no doubt but it certainly took meta programming seriously. My main concern with rust is that it's not going to make that code any easier to write. 
Tooling is not just IDEs. The build system/dependencies manager story is already a lot better with Rust than with C++, for example. The integrated unit tests and benchmarks system is very nice, and very well integrated with the build system. The unit test system even checks the correctness of documentation examples ! The type system already covers a lot of what 3rd party static analyses tools offer for C++, and can be conveniently extended using compiler plugins (remember, they can be added very easily thanks to the aforementioned dependencies manager). Also, the compiler errors are clear and rarely unhelpful. Debuggers and profilers support is certainly not as polished as for C++, but it's there and it works. The API documentation generator is wonderful, and I'm sure I forgot other common tools that already work perfectly in Rust. I am confident that Rust will have a good IDE support in a few years. C++ IDE support will never be super great due to the language's legacy. But for Rust there is no such technical limitation. I think there is an ongoing refactoring effort to allow an IDE to reuse the compiler's frontend code.
What's with the "GNU R" instead of "R"? 
Hana is not really a TMP library. It's more like a 'Haskell' library to make functional programming easier in C++. This requires some TMP in Hana itself, but it's not a TMP library per se. At least, this is how I understand it. 
remove this line from Distance_Sensor #include "robot.h" 
Yeah, that attempted circular inclusion is definitely wrong. Headers have to form a directed *acyclic* graph. However, the compiler error is complaining that it can't hash a basic_string (looks like std::string has been declared but not yet defined), so I don't believe that the circular inclusion is the only problem.
Another potential problem with the code is: *who is responsible for deleting Sensors?* Currently, there is no destructor in Robot, and the map keeps only pointers. If this problem is not handled any other way, you have several options: - write a Robot destructor manually deleting all the sensors - (better) use `unique_ptr` instead of bare pointers, so the sensors get destroyed automatically - (probably even better) store sensors themselves in the map, not the pointers (is there a specific reason you decided to store pointers in the first place?)
One of the best testing frameworks around mainly because of its intelligent use of macros making for a very easy to use interface. Inclusion in your project is dead easy as well. Big thanks to Phil for making this publicly available!
I know why I switched back to GTest. I needed to apply the same tests to multiple classes, and GTest provides test templates. It's also faster to compile since it isn't a template suite.
For me it was the superior API. I use tests extensively but I tend to use only basic features of testing libraries, so I never felt Catch lacking in any regard (in particular, I don’t use mocking in the classical sense). On the flip side, Catch’s API for writing test is so much superior to all others it’s positively embarrassing.
Thanks. Very interesting Survey. Hope we may be confident in the data 
~~facts~~ statistical inferences
I'm rather surprised that CMAKE is so much more popular than autotools. It has always felt to me that autotools is way more popular than CMAKE, judging by random projects I've built from github, sourceforge et al over the years.
I'm extremely surprised they're reporting CMake as the top build tool. It certainly seems to take a backseat to gnumake / autotools in my experience. Not that I'm a big fan of either of them. I wish all build environments didn't suck. 
The lesson *should* be that BigObject foo(int n) { BigObject localObj; return localObj; } without any `&amp;&amp;` and `std::move` is exactly how you are supposed to write it and that a `std::move` here is not only not necessary but detrimental w.r.t. (N)RVO. Don't use `std::move` on expressions that already are rvalues. Don't use write `return std::move(some_local_variable);`. The compiler already takes care of it. Even if it can't apply the NRVO optimization the C++11 standard *requires* the compiler to favor a move ctor over a copy ctor in this case. So, if `BigObject` as a move ctor, the C++11 standard *guarantees* that the function *won't* copy-construct the return value. Of course, this version BigObject&amp;&amp; foo(int n) { BigObject localObj; return std::move(localObj); } just returns a dangling reference. If you feel the need to tack a `&amp;&amp;` on some types hoping that this is the magic that makes things move, your understanding of C++'s move semantics is not as good as you think. What makes things actually move are move constructors.
Anyone who says CMake is nice doesn't have experience with a language like Python or Go (or probably even Java, though I'm less familiar these days).
They also claim that 39% of C++ development is done on Windows (where autotools isn't really supported). Maybe that's part of it? It'd be nice if the language had a standard build system across platforms I think, but I'm not really a fan of cmake. Edit: 39% -- I'm still working on drinking my morning coffee.
CMake is the only language that I've fought with for literally years and made little ground in understanding. There are many functions and variables with names that are incredibly similar, and it's difficult to understand/remember if there is some subtle difference or if they're aliases (PROJECT_SRC_DIR vs CMAKE_SOURCE_DIR). Also, some functions take arguments which are supposed to be the names for the argument that follows them (a sane language might have `func(a=1, b=2)`, but CMake does `func(a 1 b 2)`. Debugging CMake is also a pain and tracking down files where macros are defined can also be frustratingly difficult for complex projects. These are the criticisms I can think of off the top of my head. Given a project with a `src/` dir, figuring out how to get things to drop into the correct destination directories (e.g., `build/bin`, `build/lib`, etc) and not in `build/src` is not easy (particularly when your projects depend on each other and the build system needs to be able to find the right libs/headers). I've also had great pain trying to set up a system that will only rebuild and run the unit tests when the unit under test changes (instead of retesting the whole project) or that will fail the build when a test fails. CTest is utterly useless as far as I could tell. More frustratingly, it seems integrating with other CMake projects depends on the vendored project being set up correctly, otherwise a complex build adapter will need to be written. EDIT: also, CMake has special support for some libraries (Qt) and tool chains (SVN is privileged, C/C++ projects are privileged, etc). I could go on and on, but these are the complaints off the top of my head. Contrast that with, say, Go wherein `go install &lt;pkg&gt;` is sufficient for 95% of use cases. Anyone who says CMake is simple/easy/clean/etc is kidding themselves.
This looks much better than C++. I'm excited to try it.
It looks really good. There one thing you didn't talk about (if you did i missed it): what are the dependencies for users of the programs one is developping? I think it's one of the very few thing that autotools does right (and maybe why just about everything else is so horrible) the users only need a bourne-like shell and make. Basically it's already there on every unix-like system. If i understood well how your build system work, meson is required in order to do the configure step. Is that right?
You completely disregarded that a lot of the development is for in-house use and not distribution. For instance do you think all those finance firms and banks are posting their code on Github?
MinGW is GCC. Why separate it?
I obviously knew about its *existence*, I was just talking about its implications (and exaggerating a little).
It's suspicious that no one reported using the Visual Studio debugger. It still has one, right? Same for MSBuild, surely it should take a sizable fraction of the market.
I just spent three months in a paid contract writing Rust, indeed I blogged a post about my first impressions of Rust in /r/rust about three months ago. My impressions of Rust now are very similar to what they were back then surprisingly enough. I would add the following though: * Error handling is very toy in Rust, and just does not scale to very large code bases. It is far, far, far to easy to unwrap() instead of do-the-right-thing. That equals spattering abort() all over your code a la PHP's die() function. Before Rust people start arguing with me, C++ is shortly gaining itself Option&lt;T&gt; and Result&lt;T&gt; written by my own fair hand for Boost with the intention for standardisation, so in C++ we'll have the *choice* of whichever system to use, including using both systems of error handling (which is actually very powerful indeed). * The standard libraries with Rust have a lot of maturity problems, and that becomes only more evident with usage. The biggest immaturity problems are without doubt in i/o where even simple portable socket multiplexing is impossible and I was never ending having to drill into the Rust library source code to figure out what the hell was going wrong. Very inefficient, it takes forever (for me) to write quality Rust code as a result. * The lifetime stuff is actually a curse, not a feature! Yes, controversial I know ... but the damn thing is *viral* and it infests everything it touches and just keeps on multiplying. You end up having to go back and de-genericise your code just to reduce lifetimes to manageable quantities. Lifetimes are also anti-thetical to things like coroutines, and while I can see how C++ gets extended out with a fully coroutinised runtime with all async i/o and non-blocking through even with legacy C++ codebases which will simply auto-coroutinise, I simply cannot see how existing Rust codebases can be similarly forward extended without very substantial rewriting. As warty as C++ is, the language has been repeatedly proven to be extendable to do new tricks no one guessed decades ago. Same as C actually. That's a serious, and underappreciated, feature. * I still find myself unconvinced over why I would choose Rust over .NET portable. It doesn't add enough value to C++ to really dislodge C++ from its niche, and .NET now it's portable does all the stuff Rust does which you'd prefer C++ didn't. I don't see the value add since Microsoft made .NET portable, especially with the really *excellent* .NET tooling with single click deployment to cloud/mobile/desktop on Android/Windows/iOS. All that said, I don't hate Rust in the slightest. I liked the language, I liked the design, I liked the concept, and I especially liked the attempt - it made me think deeply on what C++ needs to do next. Tooling was of high quality given its age. All this is unusual for me, I don't like most of the programming languages I try, but I think the value add proposition for Rust has slid in the past six months simply because the competition is moving so quickly, not least C++ itself which right now is figuring out what bits of Rust to extend and embrace in order to neuter the threat - same as C++ has always done.
game dev is an incredibly tiny fraction of all of the development. Pretty sure that a single code outsourcing company like Atos, IBM or Sopra spits more code yearly that the whole gaming industry.
This is completely anecdotal, but it feels like a lot of game development outside of the big studios has moved to Unity; which is C#.
They didn't say how they collected the data but if it's self-reported then it wouldn't surprise me if a lot of people incorrectly wrote "mingw" as their compiler instead of GCC.
I'm not surprised. Autotools is horrible to work with and is only portable if your definition of portable is "works on all UNIX systems".
C# works fine on Linux. The only legitimate (i.e. not the bullshit that RMS spews) reason you wouldn't want to use it is that MonoDevelop is shit (but you can still develop in VS and deploy to Linux).
I'm not at all surprised. CMake is the best out of all bad options, and one that's completely cross-platform. It's become very popular for OSS/Github projects. I'm more surprised about all statistics on Windows, e.g. the VC/gcc split. All of the Windows stats look quite fishy.
The environment as a whole provides an excellent IDE, a good compiler, and a second-to-none debugger. I haven't had many issues using VS in a platform-neutral way. I'm not doing deeply complicated stuff, though.
This really needs to work at function or class scope otherwise it's not adding any new things to what we already have. At it is right now pretty much every good compiler is able to optimize out a regular if() when the condition is a compile time constant.
If I had any money, I would gild this. I get so incredibly tired of people wailing about how "horrible" Eclipse CDT is. I have found it to be a fantastic IDE not only for C++, but for Perl, Python, Doxygen, and the occasional bit of FORTRAN I have to fiddle with. That I can have side-by-side tabs of these separate languages open and my "run" button just *Does The Right Thing* depending on what window I have selected is fantastic. It has full integration with Git^1 and it even does syntax highlighting for my Makefiles. Yes, it's learning curve is harder than the travelling salesman problem, but all of those options give you full control over every detail of your IDE. Is it the best option for Windows users? Not really. VS works quite well. Is it the best option for non-Windows users? For me, absolutely. [1] And it's visual diff engine allows extremely easy merge conflict resolution.
To be clear: the performance impact is most likely ninja's work rather than meson's. Meson is not the only build system to support ninja (cmake does). I should say that cmake with export targets looks a lot like meson (except for the missing PCH feature). Also [relevant](https://xkcd.com/927/)
[Image](http://imgs.xkcd.com/comics/standards.png) **Title:** Standards **Title-text:** Fortunately, the charging one has been solved now that we've all standardized on mini-USB. Or is it micro-USB? Shit. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/927#Explanation) **Stats:** This comic has been referenced 1782 times, representing 2.4037% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_ctis1ad)
Was watching your presentation first so I know what your views are. Looks like the intent is at least very close together. One point that I found so far where we differ is cyclic dependencies - while I recommend removing them wherever possible, my solution does not make it impossible but rather a stern warning. Rationale for that is that I developed it on a major source base (few million LOC) that has some known cyclic dependencies, where ignoring this would not make it possible to build at all. So it equally makes it impossible to consider Meson until those cyclic dependencies are removed (which I'm trying to get done, but you know, it's kind of hard to get people to do this rather than add features).
In that case you might want to check out [this build tool](https://github.com/Dekken/maiken). Caveat: I'm the author.
The dependencies are link-time between components, but they are slightly more complicated than this. I have a graph of how it looked a year ago, rendered with Graphviz on a 32k pixel wide PNG that had to downscale by 30% in order to fit. We're currently in a much better shape than that, but we still have about ~80 component that are all tightly coupled together. This kind of build fix works for the easy-to-actually-fix cyclic dependencies, not the 20-year-legacy cyclic dependencies.
There are different kinds of cyclic dependencies. If you have exe A that links into shared libraries B and C and those libraries call functions in the other one it should work in Meson (though it is obviously not good practice). The kind of cyclic dependencies that I talked about are where you need to have a fully built B in order to build C (because, for example, you are using some executable to generate source in C that uses B internally). Those are the nasty ones that are not expressable. Meson also has a way to merge the contents of any libraries (static or shared) into one for these occasions. So if you have libs B and C that are intertwined, you can create a new library called, say, BCtemp that has all the object files of both. Then it will link as usual. Once you have the interlocking solved you can drop that temp library and use the proper ones.
And it's still confusing as hell to figure out how to build either Qt4 or Qt5 projects with CMake... :(
The reason you did not get an error is because you can create your own properties, so you certainly created a CXX_STNADARD property. It's very useful if you want to transmit informations with your targets but sucks for cases like this :p. Maybe the CLion IDE with its cmake integration should warn ?
Exceptions only complicate control flow if you use them for control flow, which you shouldn't anyhow. Otherwise chances are you are doing something **horribly** wrong IMNSHO.
Just Adobe and Microsoft.
Man, I feel like I've been trolled based on how off some of the top rules are.
it's hard to argue with your facts
Really, just DirectX lock-in and some old codebases were keeping native windows-only C++ development. Lots of old codebases were dropped for web or were made cross-platform. All 3D game engines went cross-platform. So, C++ is there now.
This is all IMHO: I understand what you're saying re: old code bases, but there are still a bunch of applications that are still Windows-only (for example, some music-creation DAWs, some commercial CAD programs, etc). My original comment (or thought) was that for CLion to say that only a small percentage of C++ developers on Windows use VS meant that their market research didn't look at corporate environments, but at individual or small groups (which is what CLion is targetting). For any greenfield project, or recent code bases, it's easy to do cross-platform from the start. But that still leaves a ton of "legacy" 1998/2003-era Windows C++ apps that will remain in VS-land forever, or have absolutely no reason or budget to convert to cross-platform. Depending on what the Jetbrains market research team focused on, would explain their findings. Just my $0.02
At least for MSBuild, integration should be possible. But I'm not sure how much of the Visual Studio debugging infrastructure is available separately.
Catch/rethrow a la boost::exception, for purpose of adding contextual info, is good and I would not consider it as control flow usage. But yeah, looks like we agree, which is wtrange, because initially you wrote "I don't use exceptions much though", which I read as "I don't throw them" :-). And if you don't throw, you *do* complicate that flow :-)
"C/C++"? Seriously? No.
tor/i2p middle node
I'm now picturing someone submitting a proposal to add the `download_pornhub_to` function to the standard library
Game developers
They have a free 30 day trial.
I'm really hoping that the talks will be on youtube again...I learned a lot from having those resources available to me last year!
Yeah... Best practices differ between standards revs too: what's best practice in C++03 may be the wrong way to do something in C++11 (NULL vs 0 vs nullptr being one that comes to my head immediately)
Yeah, I throw exceptions mostly as a substitute for the `assert` macro, so that my testsuite can verify that.
Nice idea. Not-so-nice implementation.
It would likely be added to the standard before modules.
Your remark concern only the "Effective Modern C++ rules" because we don't have the right to describe in depth what's explained in the scott meyers book. For example the c++ google rules are very well explained. 
&gt; I can download 15TB a month by leaving my 2nd desktop open 247 Your **residential** ISP might have a problem with that. Selling or otherwise profiting from bandwidth resources sold to you is generally banned under the service agreement you have with said ISP. Now if you have a business connection or some sort of special agreement with your ISP, go ahead...
The C rules are grouped in "NetBSD C Coding Standards" and "Linux Kernel Coding Standards", the other ones like "google style guide" and "jsf air vehicule C++ coding rules" are related to C++. These rules are just what exist in the known best practice guides, it's not our rules :) and the goal of the repository is to vote and comment them to have the most interesting ones.
Why aren't these acknowledged best practices incorporated into the C++ standard? Compiler errors would force all n00bs to follow them. I guess they worry about backwards compatibility and legacy code.
I wish my employer would send me. But they're okay with me watching the Youtube vids of CppCon lectures on their time, so there's that. I learned C++ in the 90s, left it ~7 years ago for various Java and C# projects only to return completely dumbstruck with all of the changes to the C++ landscape (compiler improvements, STL improvements, Boost, TBB, OpenMP, etc). I think I learned more about C++11/14 from CppCon's Youtube channel (especially Herb Sutter and Scott Meyers videos) than I ever could reading about them. I think I only fully grasped perfect forwarding last year, as well as when to rely on move semantics vs return-value optimizations, etc. Something about the videos make the subject matter more approachable and memorable, and in turn make me a better developer. I will be looking forward to the 2015 lectures.
As much as Eric's simple test is great, it shares the same problem as Boost lightweight test - it doesn't record and output test results into an XML format which can be consumed by Jenkins and tracked for stability testing over time. CATCH is the least hassle-for-me solution I've found to lightweight testing AND XML results recording. I do agree the compile times are annoying, but precompiled headers helps a lot there.
**What?!** assert and exceptions are **fundamentally** different! The former is exclusively a debugging aid, the latter is not. How did you come up with that idea?! Student, huh?
[Here's the actual program link.](http://cppcon.org/2015program/)
It's important to be able to *test* your debugging aids. Most (all?) test drivers can't recover from a call to `abort`.
I'd like those links too!
&gt; Yes Niall I think you raise a good point. I basically use it with travis, and travis just records jobs that fail and gives me the console output. No way to track over time which particular test failed when. This sucks. Appveyor has a really neat test results tracking tool, sadly it doesn't accept junit xml :(. I'm hoping it's just a matter of time before Travis gains something similar. Stability testing isn't useful for testing which is always success or fail - conformance testing is the classic example. I'm more worried in AFIO about those 1 out of 1000 test fails which are due to some weird combination of timings. BTW Travis has been *very* useful in finding weird AFIO bugs because it has really unusual timings. &gt; I know you are very busy with AFIO but I think if it would be very easy to set up a good cpp project we would all have more and better libraries. I really miss Rust cargo (and travis-cargo) in C++. Dave attempted a package manager for C++ just before he left C++ for Swift. I think that says everything we need to know about that. There *are* package managers for C++ e.g. biicode. But the problem isn't that of package management, it's that of dependency specification - thanks to header includes as the way of importing a dependency, you have no standardised way of inspecting from the outside what dependencies there are and could be, or how to configure them. I tried proposing Boost.APIBind as the standardised way to encode dependencies and was met with a profound yawn from the Boost community. Nobody cares enough to fix this, certainly not to change their ways - same as when Dave attempted this. So I move on. I'll keep using APIBind myself personally as it gives you Boost libraries which only optionally require Boost, but I'm in a tiny minority who thinks that valuable.
&gt; the fast forward moving C++ standard Heh, go tell this to the JS guys :p
It's great!
11 years, and for the coder there are very very few differences between C++98 and C++03 apart from `std::vector`'s contiguousness requirement I think. So more like a first standard, a small fix, a big standard change in 2011, and various ameliorations in 2014.
*Build Applications with Qt and boost.* and text describing Qt and boost separatly, without actually mentioning anything about building applications with Qt-and-boost. Maybe it's only me, but title suggested something along: setting properly environment, toolchain, cmake/qmake comparison or similar topics.
Its not meant to be a tutorial. Thats why I linked to the Qt Introduction in my blog and the site from Boris Schäling...
By the way, Qt uses JS for GUI in the way that doesn't go out of control as an average 'web project'.
Great. I'm looking forward to the video series! Btw. Grüsse aus Mönchengladbach nach Viersen ;)
&gt;So, yeah. If VS 2015 helpfully tells you that "one or more errors occurred" — try VS 2013. It's good advice, and one I'm going to stick to for another year or so. Seems like it usually takes about a year anyways for many of the issues and bugs to get worked out in a VS release, especially with C++.
Problem is the C++11/14 feature set is just so much longer ahead in 2015 ( although still far from perfect, and I'm still getting ICEs from time to time ).
What do you mean by ICEs ?
Does anyone know if the Intel 2015 suite works with Visual Studio 2015? You would think so, but after some searching, the answer isn't so obvious. Intel Parallel Studio (which contains ICC) came out a few months before Visual Studio 2015.
Those are the two pillars of Microsoft software. 
yeah, gonna be so easy to search for with Modern C++ Design...
Have you been reporting the ICEs?
Well i guess, there would be few persons who would like to *research* topic. And maybe we could convince /u/STL to help write that proposal :\^)
This makes me sad because we put so much work into fixing [tons](http://blogs.msdn.com/b/vcblog/archive/2014/06/06/c-14-stl-features-fixes-and-breaking-changes-in-visual-studio-14-ctp1.aspx) and [tons](http://blogs.msdn.com/b/vcblog/archive/2015/07/14/stl-fixes-in-vs-2015-part-2.aspx) of library [and compiler](http://blogs.msdn.com/b/vcblog/archive/2015/07/01/c-compiler-front-end-fixes-in-vs2015.aspx) bugs. I really think that the toolset (compiler/linker/libraries, separate from the IDE) is vastly higher quality with very few regressions. The IDE diagnostic here is terrible for sure, but I wish people wouldn't react to it by falling back to 2013.
Is it possible to use the 2015 toolset from the 2013 IDE? I'm guessing so, but haven't had chance to install 2015 yet.
When you're in the middle of debugging something else is the *worst* time to discover that your debugging tools have been broken for who-knows-how-long.
I've been very tempted to try myself for those reasons well mostly for the C++14. C++11 in 2013 is mostly there now. But as my code is quite large now and cross-platform I'm being hesitant. Also 2013 will behave much better with plug-ins. 
I get a crash when I'm using a manifest to elevate privs to admin. it asks to restart VS in order to debug an admin build, then some VS .exe crashes upon restarting
If anyone from this project is looking, change your name. The name 'Modern' is pretentious and confusing.
I think it might be a nod to the Microsoft explanation of [Modern C++](https://msdn.microsoft.com/en-GB/library/hh279654.aspx)
2015 should be vastly more friendly to cross-platform code, since it's much closer in conformance to GCC and Clang now. (In a few cases, exceeding them.)
"This is much easier to debug! All I have to do is comment out every line one by one until it compiles!"
Well in case of VS2013 there actually were a lot of issues concerning initializer lists and other stuff in curly brackets before a couple of updates, so waiting for updates sometimes worth it afterall.
Or what should have been done in place of the C++/CX language extensions.
Just wait for two or three service packs. 
Really? I wasn't aware of that, but hoping we might soon(ish) get to a newer version than 2010. Unfortunately, we still need XP support (God damn it). Has that situation changed with 2015?
Its also a nod to Herb Sutter and Bjarne Stroustroup who have described c++11 and up as "modern c++". They describe the use of the new features as modern c++. Bjarne says that's almost a new language... and he created it so... get over it.
They are also not equal, which means they are different.
* The SSL certificate on that Trac site has expired. Is there a non-HTTPS way to access it? * Is it a "List of Best Practices"? Is it a "Links To Examples Of Best Practice For C++ 11/14 Libraries"? Is it a "Best Practice Handbook"? The Trac page name says one thing, the incredibly long page heading says another thing, and you just called it something slightly different here. It read very much like a handbook. It doesn't even read very much like a list of links to examples. * The introduction starts with a list of links to C++11/C++14 only libraries, only to say that they all differ in their practices because of a lack of consensus on best practices in C++ libraries. What is the point of the list? * The list at the top is already outdated, isn't it? I thought Fiber and Hana are accepted into Boost. * There is not a lot of meat, but a lot of noise, in the handbook/guide/list. Why isn't it more concise? Just list the advice, show the examples, state the rationale (plainly, without some story). This reads more like an essay, and not a very coherent/straight-down-to-the-facts one at that. * Should this be on the Boost trac or should it be on the author's personal blog? * Why is "use Boost.ApiBind" on the list at all? "ApiBind" is not even a Boost library; people shouldn't be told it is best practice to use it. * "PORTABILITY: Strongly consider trying your library on Microsoft Visual Studio 2015". This entire section seems worthless. People who care about MSVC compatibility will make their library build with it. People who don't care about it, won't bother to compromise any already standard conforming C++ with MSVC specific workarounds. Also, "VS2015 is a very highly conforming C++ 11/14 compiler. It meets or exceeds clang 3.3 on every C++ 11/14 feature" is meaningless when VS2015 doesn't even support a certain C++98 feature. 
With vc120_xp toolset you can use all of the new C++ features from MSVC2013. If you don't mean Windows XP pre-sp3 support of course (which I believe is very weird thing to try to achieve in the first place)
When you encounter an ICE, you should immediately capture a preprocessed file and verify that it repros the problem: `cl OPTIONS /P meow.cpp` to preprocess, `cl OPTIONS /TP meow.i` to verify. Then you can finish working on the code, and report the ICE later. (I learned this habit after encountering many disappearing ICEs.)
vc dev mgr here. as always, if you are seeing issues with crashes and opaque errors, we would LOVE to fix those for you. ESPECIALLY when it comes to large solutions and projects. please file a connect bug. send me a mail. send-a-frown in the product (or a smile if you are feeling happy!) 
I'll do that next time, thanks!
How come Herb Sutter and Scott Meyers aren't listed anywhere? Their talks were the best ones last year. I'm also not seeing anything by Chandler Carruth although he's the on the speakers list.
I'm not sure about this bug but in our build system we usually do feature detection with test files rather than checking compiler versions. This means that when a slowly developed compiler gets around to supporting new features it will be automatically opted in to them by the build system. If the compiler is compiling stuff but generating bad object code then thats something we can't write generic tests for.
On VCBlog, [they said](http://blogs.msdn.com/b/vcblog/archive/2015/07/22/c-edit-and-continue-in-visual-studio-2015.aspx): "Today we’re pleased to announce that Edit and Continue (EnC) is enabled by default in Visual Studio 2015 RTM." You might have encountered an incremental build or incremental link bug, then. I'm not sure what's enabled when. (I build command line programs directly from the command line, which is why I'm usually clueless about IDE matters.)
If you can send us your solution, I'm sure our IDE devs would love to investigate. Last I checked, DevDiv#553676 "If you want a picture of the future, imagine a conditional operator stamping on a human face - forever." which I filed, is still active in our database, so it's on the compiler team's list of things to fix.
Unfortunately, the solution is not just fairly huge, but contains code that you need to buy from us &amp;#151; as soon as you realize that trying to integrate OpenSSH into Windows is a mistake ;)
Just like how your doctor doesn't care what you look like naked, we don't care what your source code is. It still may be possible for IDE devs to investigate performance in your codebase - e.g. we often have companies visit us, where representatives bring laptops with their source code, and we help them port it to the new release. Source isn't delivered to MS, it remains on their laptops or whatever.
What's wrong is that it's not trivial to implement a workflow that makes it trivial to add external library dependencies. Unless maybe you are working on a single platform with libraries distributed with the OS. biicode etc. just add another centralized distribution that may or may not contain the library you want (I guess it makes it easier to be cross-platform). Even just on Linux, the choice between telling users on another distro to figure out how to install some library themselves and finding a header-only replacement seems fairly obvious.
amazing, really. will actually try out winrt with this.
That's a regression from RC, but not from the 2013 release. (constexpr underwent dramatic churn between RC and RTM, as we were constexprizing the STL and fixing tons of compiler bugs along the way.) You can report bugs through 2015's Send A Smile, which is probably easier to use than Connect. Click the little smiley face in the IDE. They eventually get filed in our internal database and assigned to the right devs.
Honestly, this is the correct answer. @OP: instead of making contortions, help yourself and your users install the library, through documentation, quality scripts etc.
If you can't debug when something goes wrong in production, you're going to have a bad time.
I think 2013 actually can get the newer Windows SDK. But not sure about compiler toolset.
Hi spongo2, Please, consider creating a public roadmap for the VS updates - like general improvements, critical bug fixes, and general release date (something like "after September"). I understand that this will generate quite the noise like "Oh, you *promised* to deliver in September, how could you slip 2 days and ship in on October the 2nd" or "My extra-important bug which noone else care about is not in there, you imbeciles", etc etc. But judging from my experience, such visibility brings quite stability and engagement from the users that *matter*. Things like the recent blog post about ruijit or STL's tables with features actually help us to plan ahead. And, being the singe vendor of developer tools for the platform, it's not like you are loosing competing advantage from loosing this obscurity :)
I had some fun with C++17 fold expressions, and this is what I came up with: template &lt; template &lt;typename...&gt; class Trait, bool b = true, typename... TraitArgs, typename... Args &gt; constexpr void static_assert_each(Args...) { static_assert(((Trait&lt;Args, TraitArgs...&gt;::value == b) &amp;&amp; ...), "Assertion failed!"); } This works with Clang 3.6 right now and, hopefully, soon with GCC!
Very neat !
You could write it like this: template&lt;bool...&gt; struct bool_seq {}; template &lt; template &lt;typename...&gt; class Trait, bool B = true, typename... TraitArgs, typename... Args &gt; void static_assert_each_arg(Args...) { static_assert(std::is_same&lt; bool_seq&lt;Trait&lt;Args, TraitArgs...&gt;::value...&gt;, bool_seq&lt;(Trait&lt;Args, TraitArgs...&gt;::value, B)...&gt;&gt;::value, "Assertion failed"); } However, I think `static_assert_each_arg&lt;std::is_same, false, std::wstring&gt;(1, w, 2.0)` is a little hard to read. 
Sadly I haven't, they usually steam from some error which I track down &amp; fix. I think I did a pretty good job of it in [VS 2013](https://www.google.se/webhp?q=site:connect.microsoft.com+sairon#safe=off&amp;q=site:connect.microsoft.com+sairon) though. I'll keep submitting :)
You just said to build release builds specially, without any of the normal information needed for debuggable builds. That's your problem, not mine. The most I would do is use splitdebug, but that's a post-build (packaging) process, not a build process. 
Thank you. This should be on Github, as donvito already suggested. :-)
I, too, write C++ code for a living. But my experience with Rust is different from yours. I've used Rust in my sparetime projects for the past 15 months, on and off. This includes writing a binding to a C library with a safe Rust interface. &gt; Error handling is very toy in Rust [...] As warty as C++ is, the language has been repeatedly proven to be extendable to do new tricks no one guessed decades ago. Same as C actually. That's a serious, and underappreciated, feature. I don't know ... C++ *is* warty. It's warty enough for a C++ dev like me whishing for a clean-slate replacement. Sure, Rust isn't there yet. But it's looking good, IMHO. Sure, C++ can evolve. I'm eagerly awaiting the long-promised modules and concepts lite. But C++ doesn't have the monopoly on evolution. Swift did it, too. Look at how error handling evolved from Swift 1.x to Swift 2.0. Error handling in Swift 2.0 is basically syntax sugar over what Swift 1.x did / what Rust is doing right now. It looks like exceptions but it's not really, it's a little more explicit. You still have to "unwrap" things with `try`. IMHO this is the best of both worlds. I see the same potential for evolution for Rust. &gt; The standard libraries with Rust have a lot of maturity problems, [...] The biggest immaturity problems are without doubt in i/o [...] You're saying this *now* after Rust 1.0 came out? In a comparison with *C++*? Does C++ come with a non-blocking I/O socket library? No, it doesn't (yet). You probably use Boost.ASIO (which *is* pretty cool with its "strands" etc) or some other 3rd party library. But you could say the same thing about Rust. In Rust you would use [mio](https://crates.io/crates/mio) for these sort of things. &gt; The lifetime stuff is actually a curse, not a feature! I disagree. They're one of the reasons why I like Rust. As a library writer I get to express lifetime constraints as part of types and signatures which makes the code more self-documenting and allows the compiler to mechanically check them at compile-time. For example, the portaudio library contains some documentation about how long a returned `char*` will be valid. In the Rust binding I got to encode exactly this as part of the type system and the function signatures. So, I got away *without* copying the string and the resulting API is still safe. &gt; Lifetimes are also anti-thetical to things like coroutines Are they? &gt; but I think the value add proposition for Rust has slid in the past six months simply because the competition is moving so quickly, not least C++ itself which right now is figuring out what bits of Rust to extend and embrace in order to neuter the threat - same as C++ has always done. Hmm. C++'s evolution didn't strike me as very quick. For how long are modules and concepts in the making? It's improving with all the many smaller working groups. But I don't see C++ adopting lifetimes as part of the type system. And even if it did, you have this backwards compatibility constraint in C++ which would probably make this lifetime thing optional. Who's gonna go fix all the third party C++ libraries to make use of that feature for improved static analysis? "Fixing" might even require a redesign because in it's hard to *really convince* a compiler of things like memory safety and datarace freedom without relying on GC and without restricting the programmer too much.
You can use `self` in other typedefs for brevity.
Stop mixing things up.
I've used http://visualgdb.com/toolchains/embedded
While bad, dude should have looked in the output window afterwards, there should have been more info.
On a separate branch, why the hell not? It's kinda essential to know early where you stand :-)
Wow... XP is out of support! (Hm, except embedded)
Do what Boost does - after all, they are probably the exemplar of header only C++ libraries, and they've figured out the best way of doing it. https://svn.boost.org/trac/boost/wiki/BestPracticeHandbook#a16.BUILD:Considerdefaultingtoheaderonlybutactivelymanagefacilitiesforreducingbuildtimes
I'll be honest I don't know how FCC Brightline Net Neutrality rules V commericialing residential ISP plays out. As far as I'm aware they are no longer allowed to say what you can and can't do with your data so long as it is legal.
Also you can omit template parameters in definition of `self` to make it even more compact :)
&gt; I think it's worth noting that in your example, you are basically subverting the purpose of a lambda: you are not capturing any function from the user, it's hard coded the simulate function, Indeed, that example doesn't need std::function or lambdas at all: he can just use a `calc()` member function that has the same body as the lambda. And even if he were capturing a function from the user he could just store that captured function and still have the memoization functionality be a regular member function. The whole struct is simply a replacement for the original lambda because additional access is needed to the lambda's members to implement the new requirements. So the thing to do is to simply convert the lambda into the corresponding explicit struct. The original code: template &lt;typename R, typename... Args&gt; auto memoize(R (*fn)(Args...)) { return [fn, table](Args... args) mutable -&gt; R { auto argt = std::make_tuple(args...); auto memoized = table.find(argt); if (memoized == table.end()) { auto result = fn(args...); table[argt] = result; return result; } else { return memoized-&gt;second; } }; } becomes the equivalent non-lambda functor: template &lt;typename R, typename... Args&gt; struct Memoization { R (*fn)(Args...); std::map&lt;std::tuple&lt;Args...&gt;, R&gt; table; R operator()(Args... args) { auto argt = std::make_tuple(args...); auto memoized = table.find(argt); if (memoized == table.end()) { auto result = fn(args...); table[argt] = result; return result; } else { return memoized-&gt;second; } } }; template &lt;typename R, typename... Args&gt; auto memoize(R (*fn)(Args...)) { return Memoization&lt;R, Args...&gt;{fn}; } And now the "lambda's" `fn` and `table` members are accessible to code implementing the new requirements. 
I'm certainly experimenting with this as much as I can for VC++. (See for example my upcoming talk at CppCon about what's new *and* future directions). We always have to be careful about things where we are doing platform support (new architectures, new OS features, etc) as these are not my stories to tell. Sometimes we will also hold things back so we can make a somewhat bigger splash when we have something new and big. Certainly for compiler conformance I'm trying to set guidance that I think is useful. (e.g. "next is expression SFINAE, in an update, not sure which because it is hard and we are still designing it.") We're transitioning to doing new libraries work and much our multi-platform story out in the open which you'll see more of in the next year. Examples include our recent open sourced lldb-mi/gdb-mi debuggers. 
No date of publication, but I'm going to go ahead and guess that this came out before 2011 :P That said, this is quite interesting as a case study of what can be done with pure templates in (what looks to be) portable C++98. Thanks for the link!
Thanks, I agree with your points. Nested classes suffers the same problem but I just discussed about lambdas because I think capturing this can be done too lightly rather than passing explicitly a pointer to the parent class. But yes, the problem is the same. Thanks for clarifying that. About my example I probably oversimplified, but one of the requirement was the possibility to change the called function easily. For this reason, "calc" is a lambda, that could be quickly switched to other code. As I wrote, this was just for prototyping! :)
What do you mean "interface"? You mean in the Java sense? That's just a special case of abstract classes; C++ has those.
For example it's not possible to specify static functions "pure virtual" (I read somewhere that it is possible in Java 8). Also when using pure virtual we have the overhead of dynamic dispatch. Basically there is no way to have static dispatch without the usage of templates. (Note: I am not 100% sure of what I am saying so I am sorry if there are wrong facts.)
Does this alternative implementation seem ok? template &lt;typename R, typename... Args&gt; struct Memoization { std::function&lt;R(Args...)&gt; calc; std::shared_ptr&lt;std::map&lt;std::tuple&lt;Args...&gt;, R&gt;&gt; tptr; //= //std::make_shared&lt;std::map&lt;std::tuple&lt;Args...&gt;, R&gt;&gt;(); Memoization(std::function&lt;R(Args...)&gt; fn){ tptr = std::make_shared&lt;std::map&lt;std::tuple&lt;Args...&gt;, R&gt;&gt;(); calc = [tptr = tptr, fn = std::move(fn)](Args... args) mutable -&gt; R { auto argt = std::make_tuple(args...); auto memoized = tptr-&gt;find(argt); if(memoized == tptr-&gt;end()) { auto result = fn(args...); (*tptr)[argt] = result; return result; } else { return memoized-&gt;second; } }; } }; Ofcourse what quicknir said applies here as well. I would probably not use a lambda here myself. I am just trying to think of alternatives to capturing this pointer. My intention is not to help improve your design. In general if I have no control over the lifetime of a lambda, I would not let it capture pointers at all saving me the worry of ensuring the lifetime of the pointed to objects. As I see it your use case demands a shared_ptr, so I set up the table as a shared_ptr.
Final can be used to optimise classes?
That's just one meaning of the word `static` in C++; Java doesn't do the other two (or the other three, or one, depending on who exactly you ask). And it also doesn't do non-dispatched methods, static generics, static polymorphism, const variables, compile-time code generation, static arrays, or stack-allocated objects. Pick a context in which one of "static" or "dynamic" could be applied, and odds are Java does dynamic and doesn't give you a choice in the matter.
Thanks for the effort, it is appreciated!
Is the eye patch permanent? I thought it was temporary to correct vision or something.
Some info [here](http://nuwen.net/stl.html).
I was born with unilateral microphthalmia, i.e. my right eye wasn't fully formed. When I was 6 months old, I started wearing a prosthesis. (Ever been to the dentist where they've used that potato-tasting stuff to take a mold of your teeth for a nightguard? They used the same stuff, or very similar, to take a mold of my right eye.) As I grew up, I had something like 7 progressively larger prostheses made. This gave me a relatively normal appearance, and many people were unaware that I had a birth defect, but it wasn't perfect. The prosthesis itself was exceedingly skillfully painted to match my normal eye, but my eyelids look somewhat different (I had 3 cosmetic surgeries growing up, which attempted to get the right eyelid to match, and not droop over the prosthesis; nothing was wrong with the eyelid itself, but without a fully formed eye underneath, it didn't grow the same). Also, the prosthesis didn't move, so I appeared weird when I looked anywhere other than straight ahead, and talking to people was sometimes weird because they didn't know where I was looking. (Some people thought I had amblyopia, lazy eye.) Most importantly (to me), my prosthesis was effectively the world's biggest, most irritating hard contact lens. Although it was made of polished acrylic, and I was very careful to avoid accumulating scratches, it inevitably irritated the inner eyelid. With antihistamine eye drops (and a silicone tube threaded through my tear duct), I was able to wear it for 8+ hours daily, but not comfortably, and I think it got worse over the years. So in 2011 (I think), I stopped wearing the prosthesis and switched to my eyepatch-glasses. I got the idea from the webcomic Homestuck. (The "eyepatch" is for others' benefit, not mine. Without it, my right eye just appears to be closed, but people think that looks *really* weird.) It's vastly more comfortable, although I still need antihistamine eye drops. While I can no longer pass for normal from a distance, I think my appearance has improved as intended (left eye + solid black looks more symmetrical than mismatched eyes). And people can tell where I'm looking, which is a nice bonus. And that's why I don't work on stereoscopic Direct3D.
Ugh, that horrible outdated embarrassing page that I wrote over a decade ago.
http://nuwen.net/stl.html &gt;My right eye is completely blind - no signal from it has ever reached my brain. As a result, my vision is entirely monocular, with a restricted field of view and no stereoscopic depth perception. However, as I have always lived with this, it is entirely normal for me. My entire visual cortex is dedicated to processing input from my left eye. Therefore, while you can experience a restricted field of view and a lack of stereoscopic depth perception by closing your right eye, your experience will not be the same as mine.
[Inkscape](https://inkscape.org/en/).
And here I was proud of my recursive varadic template to concatermerize parameters into a unique string...
&gt; I can no longer pass for normal from a distance After years of watching your videos, the one thing out of the ordinary I notice most is not your "eyepatch", but the buttoned top button on *all* of your shirts. It's those little details that the Men In Black are trained to look out for :)
Kinda surprising. I thought that the "mm" part means they can't understand C++ and rather stick with C.
That's the `#` stringizing operator. See [N4527](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4527.pdf) 16.3.2 [cpp.stringize]. It's also taking advantage of string literal concatenation, 2.2 [lex.phases]/1/6. During macro expansion, the stringizing operator emits string literals. (You couldn't do this by saying `"src"`, since replacement doesn't happen within string literals.) Then C++ considers adjacent string literals to be fused together; i.e. `"meow" "purr"` is equivalent to `"meowpurr"`. Note that due to how the preprocessor behaves, you need a special dance if you want macros to be expanded before stringizing.
The fact that it's old and outdated is what makes it endearing rather than cringey for me.
Except `final` doesn't mean "not virtual"; it means "not overridden". These are unrelated and orthogonal concepts. C++ allows you to extend a class and override its methods non-virtually; this is not always a good idea, but it's not always a bad idea, either. Bottom line is C++ gives you more control; often it's control you don't need, but it's there. Case in point: C++ *does* give you a way to "dispatch" non-virtual methods using templates, without the overhead of vtables, as long as the entire class hierarchy is known at compile-time.
Thanks. This is my first non school c++ app and coming from garbage collecting languages I am sure I have at least several mem leaks.
herb's working on some stuff for CppCon and we'll feature it after that. so I think I have that one covered. thanks for the feedback.
They are not unrelated or orthogonal concepts, the concept of `final` is stronger than the concept of `virtual` and subsumes it. &gt;C++ allows you to extend a class and override its methods non-virtually; this is not always a good idea, but it's not always a bad idea, either. This is not overriding, what you describe is known as name-masking and it's widely considered a misfeature that modern languages prohibit. Name masking doesn't provide more control, on the contrary the reason for prohibiting name-masking is to prevent ambiguities with function overloading, a problem that doesn't exist when name masking is prohibited. &gt;Case in point: C++ does give you a way to "dispatch" non-virtual methods using templates, without the overhead of vtables, as long as the entire class hierarchy is known at compile-time. You're confusing templates with class hierarchies, if anything is orthogonal and unrelated, it would be templates and inheritance, and yet some how you're mixing the two concepts up.
I actually write quite a bit of Gtk+ apps though my language of choice is Vala. I didn't use Gtk 2 so don't really know how it has changed but writing apps using Vala&amp;Gtk+ is actually quite fun.
There is a lengthy talk about porting [Subsurface from Gtk+ to Qt](https://www.youtube.com/watch?v=ON0A1dsQOV0).
Does this mean that they will add move-constructors for their widgets? To me this seems to be the one fundamental feature that this library lacks. With regards to every other aspect, it is clearly the most modern GUI-library for C++ in existence.
Well, it could only know at link time so would require LTCG. In that case it's possible but LTCG is incredibly slow on large projects so its not used in my experience. 
The definition of a function is not related to what OS you are building on, but rather the version of the windows SDK that you are using and the version of the SDK that you are targetting. See https://msdn.microsoft.com/en-us/library/6sehtctf.aspx for information on setting your target, and make sure you have the latest version of the windows SDK, which you most likely do.
&gt;&gt; is a bar that seems useful and informative. Indeed, building should be good enough, the vast bug tracker on these projects hints that they don't work all the time. Reflecting more, I think there are two tiers of users: those who write software for software and those who write software for users. As a desktop application developer, I have to wait until the libraries are working (or the part I want compiles), which can exceed a year after RTM.
Not to be harsh, but... If you want Haskell's syntax why don't you just use Haskell? 
it is
Are you trying to compile C++ with `emcc`? You should be using `em++`. It's the same distinction as `gcc` vs `g++`. 
Scala uses the JVM. There isn't an equivalent for C++.
Nothing about what scalaz functionality and abstractions is particularly tied to the JVM, it just happens to be implemented on a JVM language.
But that is what ties it to Java.
You can use this instead: bool IsGreaterThanWindows10() { // Exists on all unix systems, even crazy ones like NixOS. return access("/bin/sh", F_OK) == 0; }
I don't really understand. You are saying that Java methods are all virtual and virtual static methods make no sense at all but then why this construct does exist in Java ? Isn't it reasonable to have a construct like this in cpp ? I am aware of abstract classes implemented using polymorphism but in this special case of using a static method in a class. interface TestInterface { static void Create() { System.out.println("Create Interface"); } } class TestImplementation implements TestInterface { static void Create() { System.out.println("Test Impl Create"); } } public class Main { public static void main(String[] args) { TestImplementation.Create(); System.out.println("Hai"); } }
&gt; since Microsoft made .NET portable No, they opened up parts of the source and it's being merged with mono. There is no portable .NET release from Microsoft and it's probably years away still.
No, there would be no way to do that in any OO language that I know of, because that would be completely useless; you'd be left with a function in an interface that was required to be defined in a hypothetical implementing class but which could never be called through the interface unless you already knew the name of the class in question, in which case polymorphism isn't even necessary and your interface is redundant.
It's horrible. CamelCase in 2015 aside, magic numbers all over the place. Basically no implementation comments. Lines like *this*: for (size_t i = 0, j = 0; i &lt; 64; ++i, j = i % 4) w[i/4] = j ? (w[i/4] | (_block[i] &lt;&lt; s[j])) : (_block[i] &lt;&lt; s[j]); Edit: Btw, there is a library called websocket++. This is what you should aim for: https://github.com/zaphoyd/websocketpp/blob/master/websocketpp/roles/server_endpoint.hpp Edit2: Last edit before I rip my hair out. writeThread = new std::thread(std::bind(&amp;AsyncTcpClient::writeThread, this)); Both, std::thread and std::bind have such a huge overhead that using a smart pointer instead of raw does not really matter. Also, are you seriously creating a new thread for every client connection? Not sure, difficult to read. Edit3: "CamelCase in 2015 aside" means that it's the least problem there.
Thanks. I felt like an idiot for a moment. I thought there is something super wrong with it. I don't know why but I really like CamelCase. 
Yeah, I was just reading more about Shaders today and read some about the things you mentioned. Thanks for the additional insight.
&gt; Even though anywhere from 50% to 100% of the objects we store in containers can be moved with memcpy — formally, this is undefined behavior. `is_trivially_copyable` reports whether a type can be bit-blasted, and STL implementations can take advantage of this. (VS 2015's STL bit-blasts only scalars, but using `is_trivially_copyable` is on my todo list. The type trait was unusably damaged in 2013.) &gt; and requires inefficient deep copying when noexcept move construction or destruction aren't available — even though the objects could be moved with a trivial memcpy. If something's bit-blastable, it should absolutely have a noexcept copy/move ctor. &gt; It goes without saying that, if you're not present on at least one of the full WG meetings, your chances of making an impact on the C++ language are slim, at the least. John Maddock and Peter Dimov have gotten major changes voted in without physically attending any meetings. &gt; To allow work to get done, it has to be a leisurely occasion of 5 nights and 6 days. Having attended several WG21 meetings, I can tell you that (1) they are not leisurely and (2) the 6-day length really does allow work to get done.
Of all the things he mentioned, that strikes me as the worst.
thanks!
I'm not sure this is a "fundamental problem" (since it's solvable), but it's a bit frustrating that CMake doesn't do much to help you out. In my experience, the ["superbuild" pattern](https://coderwall.com/p/qk2eog/use-cmake-enabled-libraries-in-your-cmake-project-ii) is usually the cleanest way to solve this: use a super-CMakeLists that uses ExternalProject_Add() on all of your projects (dependencies and your own), which will spawn separate builds for each of them. I usually have them install into a sub-directory of the build directory, so its easy to find the output (and it's easy to clean up). It's far from perfect, though, and there are some annoying drawbacks.
Its an interface to multiple package management systems, and you could write one for your package system of choice, thus nuget. It uses Powershell 3 and .net 4.0 so should work on Vista and up. It is like brew-cask, without the possibility to compile. It can then work with your other package managers, such as bower, npm and anything else that you want to write a provider for. And it is open source. 
Why keep the `true` parameter at the start in `and_all`? Fold is generic for any operation, but `and_all` can only do logical conjunction. There's no point in calling this with `false` ever. `true` is the identity element for logical conjunction, and I don't see why anyone would ever want to use anything else there.
Isn't something like this what CPMCPP does? https://github.com/iauns/cpm
&gt; how to get CMake to build the VS project files `cmake -G "Visual Studio something something" [OpenImageIO folder]` You can get the list of possible "Visual studio something something" by just running "cmake" without arguments (or by using the GUI). It will generate a `.sln`
Sure you can use VS2015 and the v140 toolset on Windows 8.1. That's one of it's major use cases.
Good article. However I disagree with the conclusion. Unsigned are good for: shift operations and overflow. In addition, sizeof returns an unsigned, so it will be difficult to avoid them. But the major issue is the management of structure (or algorithm) like a stack. If you need for any reason to pop a certain number of elements then you may easily introduce nasty bugs in your program and loop that should be simple becomes an headache. Furthermore the loops using decrements are unclear to read and not the opposite of incrementation loop. Thus, I do not recommend unsigned integer and I think that modern language should remove them and propose new shift operators. 
To be more precise. I recommend to use signed integer when there is no overflow issue and when you will not use shift. Use unsigned for bit manipulation and when using values coming from a sizeof call. Manage overflow (because you need to manage them) by casting into unsigned before making the operations.
I use reverse unsigned loops from `N-1` down to `0` like this: `for (unsigned i = N - 1; i &lt; N; --i) { /* use i */ }` because when `0` is decremented, it wraps around to something larger than `N`. This avoids the `-- &gt;`operator `for (unsigned i = N; i-- &gt; 0;) { /* use i */ }`, or off-by-one manipulations `for (unsigned i = N; i &gt; 0; --i) { /* use j = i - 1; */ }`
You should use the appropriate type. If the quantity being represented cannot sensibly take on a negative value (for example: _how many times does the letter 'a' appear in this sentence?_); then indicate that to the future reader with an unsigned. Of course, you don't have to -- just as you can store 'a' in an int -- but you're not making use of the semantics inherent in data typing if you do. There is more to picking a datatype than just the needed width. Then there are the times when width is important. Try doing binary value manipulations with Java and enjoy the fun way you can't deal with a 16-bit unsigned, say, flags, field without scattering casts everywhere.
This is just a Haters Gonna Hate case. Lot's of libraries use CamelCase, nothing wrong with it. The STL uses `lowercase_names_with_underscores` and since every C++ programmer should be comfortable with the STL style to be able to use it, lot of people just prefer that style. Historically speaking, some libraries like Qt that use CamelCase were there before the STL was widely available. For a lot of applications "Qt is the standard library". In any programming language I just do "whatever the standard library does", but C++ grew up without a widely available implementation of the standard library and for this reason there is a lot of software written in both styles. Any serious C++ programmer should be comfortable with both. As long as the style is used consistently there is nothing wrong with any of them. 
Don't install libraries. If you have to use an autotools external, it might be unavoidable, but you can usually use --prefix to install into your build directory, as I have here: https://github.com/shadowmint/sdl2-build/blob/master/sdl.txt You'll regret everything hard, if you depend on the install step, later... ...well, that was my personal experience anyway. Cmake expects you to (typically) use add_subdirectory() for local dependencies.
In [Going Native 2013 - Interactive Panel: Ask Us Anything](https://channel9.msdn.com/Events/GoingNative/2013/Interactive-Panel-Ask-Us-Anything) Bjarne, Herb and Chandler all recommend using signed types over unsigned. Chandler even goes on further to say that twos-complement is a reason to **not** use unsigned types unless you specifically want that behaviour. Appeal to authority maybe, but I'm inclined to believe them.
The first loop is difficult to be read and not natural at all. This is a trick for me. We should avoid trick in the most simplest part of the code. However, this is only a personal comment 
`memcpy()` and `memmove()`. They copy bytes from one location to another, usually implemented with ultrafast assembly.
Ok, thanks. I'd just never heard the term. By the way, I just watched you in the cppcon 2014 grill the committee video. That was a fascinating and inspiring look into the backstage of the language. Thanks for your contributions to the community. It's a truly amazing language.
The standard library widely uses unsigned types where possible. Even something simple as: `for ( int i = 0; i &lt; s.size(); ++i)` triggers a compiler warning due to signed-vs-unsigned comparison. I have to watch the talk in order to understand the context of this recommendation.
I know, in the video Bjarne says he regrets that decision and considers it a mistake.
What happen when you need the difference between occurrence of letter 'a' and 'b'? Do you call max before subtraction?
&gt; Holding face to face meetings is an inefficient and exclusionary process that became unnecessary around the year 2000. Wow, I couldn't disagree more with this. This is just your personal opinion, not a fact. 
Actually, `sizeof` doesn't need to be unsigned as it's unlikely a struct is larger than 2GB, now that `int` is 4 bytes on almost any modern computer. Having `sizeof` be signed can make syscalls like `write` easier to use, as then one doesn't need to cast one of the return type or the struct size in order to compare them without warning. That said, I agree with the article that `unsigned` is preferable, mostly because overflow arithmetic is well-defined.
I've looked at that but it's so insanely over complicated. I think there needs to be a cargo or npm like equivalent to C++, even if it did mean 95% of existing libraries wouldn't work with it. If it's simple enough people will port, if not oh well. My theory at least. No clue if it would ultimately work.
The common advice that non-negative numbers should be unsigned is not good advice. Unsigned does not buy you anything, except an extra bit for storage. If your algorithm accidentally assigns a negative number to unsigned, you don't get an error, it will just wraparound to a huge positive number and you will not even be able to detect it later. The best thing to do when you have a positive quantity is use signed, choose a name that clearly indicates that its a quantity that can't be negative, and use asserts to ensure that it does not become negative at appropriate times. Scott Meyers has a specific item on this in one of his books, he focuses specifically how unsigned in interfaces is terrible IIRC. Chandler Carruth, who may have more experience with stupid bugs than anyone by virtue of applying automated tooling to the world's largest C++ codebase (and has entire talks on the subject of stupid but hard-to-catch bugs), advises against unsigned. In fact, basically the entire who's who of c++ is against unsigned for this (as pointed out by Eoinoc). The only things unsigned is appropriate for are: - Representing your position in a discrete universe with periodic boundary condition i.e. it actually makes sense to do modular arithmetic - bitfields - Situations where you want to apply both bitshifts for some purpose (rare) - Rare situations where you are doing very specific operations that can somehow guarantee validity even if overflow occurs
Could've sworn we Swedes still owned Göteborg :)
Solve for x: uint32_t five = 5, seven = 7; int64_t x = five - seven;
Yeah, I figured you'd need to cast one. Still not that obnoxious. 
&gt; The common advice that non-negative numbers should be unsigned is not good advice. Unsigned does not buy you anything, except an extra bit for storage. If your algorithm accidentally assigns a negative number to unsigned, you don't get an error, it will just wraparound to a huge positive number and you will not even be able to detect it later. I didn't say it would protect you. No data typing actually prevents anything. Data typing is semantic, both for the compiler (which will prevent you from or warn you about operations you don't want to do with unsigned number); and tells the reader about what you intended to be stored in the variable. &gt; The best thing to do when you have a positive quantity is use signed, choose a name that clearly indicates that its a quantity that can't be negative, and use asserts to ensure that it does not become negative at appropriate times. I agree -- names are another important semantic tool we have in high-level languages. None of that is an argument why the variable shouldn't _also_ be declared unsigned. Exactly the same set of arguments applies to `bool` vs `int`, and yet there is no fuss at all about using `bool`. Goodness, on 32-bit systems, you can store addresses in `int`s -- after all it's only a number, why restrict yourself with a type?
sizeof returns an unsigned. If you set all warnings then it is going to complain if you assign it to an int. 
There is another issue which is not mentioned here. Having both types is not so simple. Because it almost imposes to have only unsigned types because the number of elements of an array should be an unsigned, so the loop variable. At the end, in a code, almost only unsigned remain until you need a negative number and then casts are coming ... It is better to have only signed because this scenario does not happens. Of course, we need a special shift operator in this case
Sure there is nothing wrong with it. I just wouldn't use a library that uses manual memory management unless the source is very, very reliable. My point was that he does not gain anything by using new since he is already creating a new thread and calling std::bind which is very slow compared to lambdas and raw function pointers.
We have namespaces to distinguish between types and classes. Functions can be easily identified by the nifty "()" at the end.
I second that. Especially in projects that don't use the STL much or at all (e.g. games, large scale server applications, Qt, etc.) it does not matter at all. However, those projects usually come with a solution for most problems in their domain. I think that small libraries that act as drop-ins should not have a style very distinct from the stdlib since the users of the mentioned large projects already have the functionality he provided. (Qt)
I admit I'm not a developer who works in that field much. However I thought there was now a .NET compiler for clang, and VS2015 claims it has single click targeting for Windows, iOS and Android. Sounds pretty portable to me.
That's because I am using blocking sockets everywhere, so I am handling send/recv in those threads separately. Not a very bright idea, I know. But it worked fine for just a few clients connected, so I didn't really care.
That is actually a very good point.
&gt; There are many ways to inform the reader, this is a very weak argument on it's own. I'm not saying "on it's own". &gt; That's the whole point, the compiler doesn't warn you; it provides nearly zero protection from underflow. And "nearly zero" is larger than "zero"; so why not use it anyway? &gt; Leaving it negative is at least more intuitive and makes it possible to do manual checks. "possible"? Do you think those manual checks are not possible with an unsigned variable? There shouldn't need to be an argument to use unsigned, there should be an argument not to. And "doesn't protect you against every misuse of an integer" doesn't seem like a good argument. I really don't understand what is "more intuitve" about using a signed integer for a variable that represents a quantity that has no logical meaning if it's negative. int mass; int length; int count; int frequency; Are all just plain wrong. In an even more ideal language (and C++ has some help for this) we would make it so it's impossible to assign a length to a mass using data types. &gt; Can your give examples of code snippets that give you good warnings with unsigned? That's ignoring that I'm saying communicating with the reader is more important. It's also not primarily about warnings -- it's about the generated code. There are quite a few security holes that have been found in the wild that were only possible because a value was read from an implicitly unsigned field in a protocol to a signed integer in an application. struct header { enum eType type; int size; char *payload; }; You'd better be very careful reading from your socket (or whatever) into this structure. Whereas: struct header { enum eType type; unsigned int size; char *payload; }; Will, at worst, just generate an out-of-memory when someone sends you `0xffffffff`. While we're at it, we'll have a much easier time if that `char *payload` is unsigned too when it comes to decoding it; sign extension with the bitshift operators can get real bitchy. There is no cost to using the "right" type -- so why not?
&gt; if the function expects unsigned or different size signed number, "different sized" will be prevented by the compiler. &gt; Signed is just more flexible and less error prone, using assert to check for negative is better than debugging weird unsigned overflow bug. You're going to have to give me an example of a bug that happens with "correctly" typed unsigned variable that wouldn't happen with a signed variable. Any protection you add to the `int` version will need an equivalent in the`unsigned` version -- and if the value should have been `unsigned` to start with, you'll also gain an extra bit of width.
&gt; twos-complement is a reason to not use unsigned types unless you specifically want that behaviour I do not understand this argument. Is there an explanation of this in the video?
What is a negative index? what is a negative count? Twos-complement is irrelevant. Who cares how 'signed' integers are stored when they are illogical for the problem at hand. Why would you want that behavior for something you are never going to use? Additionally the storage of signed integers is implementation defined. It is never guaranteed to be two's complement.
I've heard this argument a lot. First of all, it's trivial to change signed behavior to defined wraparound in gcc. The only downside is that you will slow your program down... to the exact same level it would be at with unsigned integers. Also note that by default, in debug mode, -fstrict-overflow is actually off. That means that in debug mode, in practical terms, signed integer overflow is not really UB (at least in gcc, and in clang). Second, this optimization out only happens if you check after the overflow would have occurred; you need to anyway be in the habit of checking before. It's the same with pointers: you have to check against null first, checking null after a dereference will get optimized out. Third, bugs caught by overflow are terrible to catch anyhow. Integer out of bounds behavior can change each run because the content of the memory changes. With integer overflow this is unlikely in the extreme. The practical difference between signed and unsigned overflow even with optimization is present but it's not huge. Fourth, most importantly, using unsigned greatly increases the chance of something wrapping around in the first place. Because they underflow very easily, and they don't mix well with signed, and you will have to use signed at some points in your code anyhow for negative integers. tl;dr: use signed integers, and do your debugging in debug mode to optimize happiness.
You're obviously becoming annoyed, so I think we'll just let this one lie after this: &gt; I've already mentioned the costs several times, and you keep ignoring my arguments. No, I've not ignored them, you've simply stated this, repeatedly: &gt; &gt; void usesMassGiveMePositive(int mass) { &gt; assert(mass &gt;= 0); &gt; // ... &gt; } &gt; The first interface is safer. How is that safer? If `assert` is your chosen weapon: &gt; #include &lt;limits&gt; &gt; &gt; void usesMassGiveMePositive(unsigned int mass) { &gt; assert(mass &gt;= numeric_limits&lt;int&gt;::max()); &gt; // ... &gt; } And has the advantage of documenting the _actual_ condition rather than checking for negative masses -- the reader additionally knows that they can't pass negative values simply from the signature. My point is that the number of checks you need to do doesn't change, it's just some are seen as "correct", for some reason. I've been bitten more in my life by `int`s that should have been `unsigned int`s than overflowing `unsigned int`. &gt; If I accidentally do: If you accidentally get the code wrong, then the code is wrong. That's going to fail on your first test. I'm more concerned with cases like this: unsigned long long c = a &lt;&lt; 32 | b; Does this work? The answer is: you don't know unless I tell you the type of `a` and `b`. The fix is: unsigned long long c = ((unsigned long long)(a) &lt;&lt; 32) | b; i.e. you turn `a` into what it should have been in the first place: an unsigned. So: all the big boys think I'm wrong and you're right. Great. That's not an argument though, that's appeal to authority. My experience (which, I admit, is weighted to embedded where I'm manipulating bits more than doing arithmetic) is that I am bitten more by incorrect use of `signed` than by overflows.
No, that’s wrong. The `vector` iterators are *as efficient* as using indexed access, and, again, using a range-based `for` loop has no overhead over using the iterators directly. The same is true for all other standard containers, and indeed for any well-designed container/range class.
&gt; Also note that by default, in debug mode I discussed that - bugs that disappear in debug mode are very hard to debug - because they disappear in debug mode meaning you have to debug them in optimized mode. &gt; Second, this optimization out only happens if you check after the overflow would have occurred I didn't follow that. Can you explain what you mean? &gt; The practical difference... maybe right now (also - I disagree, but even if I agreed it doesn't matter). You write code now, in 2 years some new optimization comes out that uses this undefined behaviour, suddenly you have a new bug. Suddenly you need to debug 2 year old code. &gt; Fourth (basically, there's no negative in signed). Yes, I know there's no negative in signed... if you need negative numbers, used signed. That's a given. But anywhere you can use both signed or unsigned - use unsigned. Make that the default, and use signed only if you specifically need negative numbers. &gt; tl;dr: use signed integers, and do your debugging in debug mode to optimize happiness. Which will not help you in any way for these type of bugs that only appear in optimize mode. Not that easy to debug in a mode where there is no bug...
I can assure you, with 100% certainty, that your code contained an unrelated problem which caused this performance difference. GCC (unless 4.9.2 contained a weird, specific regression) and any modern C++ compiler in general, produces optimally performing code for `std::vector` iterators in release mode with optimisations enabled (and have, for quite a while; well before GCC 4.9).
~~The *storage* is implementation-defined, but the behaviour isn’t. The standard mandates two’s complement behaviour.~~ See comment below for correction.
On top of that, sometimes is not exactly easy to determine the condition under which a signed integer operation will overflow. If you are doing lot of mathematical computations on integers, it is basically impossible, unless you wrap every addition and multiplication with a runtime check. Of course, the same applies for unsigned integer, but at least I know that if an overflow happens, my program will not crash. This is a huge advantage.
I'm not annoyed at all, since I don't work with you your coding doesn't affect me. People can always call an unsigned interface with a negative number, it will be silently converted to a large positive number. More importantly, you have to restate the equivalent width type to do your assert. Refactoring could easily lead to more bugs. It's also much less clear to a human reader. No idea what you mean by the "actual condition". So wrong is wrong, don't make mistakes? This can be applied everywhere then, just write perfect code and be done with it. Your response to my example concedes the point. Such bit shifts are almost never necessary outside bit fields, the compiler will optimize it anyhow where possible. Yeah yeah, another guy on Reddit who's smarter than all the experts. The point is: they have a ton of knowledge and experience and brains, more than the vast majority of c++ programmers. When there's such an absolute consensus among them, that's a strong data point.
Then any idea why it sets the sdk path to the older version which pops up errors about header files starting with ctype.h , this was tested by creating a win32 project from the default template 
Ah, ok, I see what you mean. The only way the bug could disappear though is if you have code that checks for overflow incorrectly, and then handles it. My point that you can simply disable -fstrict-overflow even when optimizing and still be no worse off than signed still stands. To elaborate on checking for overflow incorrectly, and to respond to your question: suppose you write this code. if (a &gt; 0 &amp;&amp; std::numeric_limits&lt;int&gt;::max - a &lt; b) c = a + b; This will always be ok. The compiler is not allowed to assume that two arbitrary variables, a + b, are not capable of overflowing. It can only assume that if you add them, they didn't overflow. And you only add them, inside a branch. So there's no way it is allowed to elide that branch. If you reverse the order: c = a + b; if (a &gt; 0 &amp;&amp; std::numeric_limits&lt;int&gt;::max - a &lt; b) { // throw or something to detect overflow } The compiler now has enough information to reduce the second if check to just a &gt; 0 (though I'm not sure if it's smart enough to do that). I really, really, really recommend this article: http://blog.llvm.org/2011/05/what-every-c-programmer-should-know.html. They discuss the exact same issue in depth, but with pointers, and with better examples. The same situation exists: dereferencing a null pointer is UB, so the compiler assumes that anything you dereference is not null from there forward. Ultimately, the situation is still better for signed: you can either choose to enable this compiler flag and get better performance, or you can disable it and your debugging ability is in no way compromised. signed integers being represented as 2's compliment is not going away anytime soon, and these modes for gcc which allow you to trivially shut this problem off are not going anywhere for even longer. You can't write code on the assumption of what will be in 10 years. Even if you don't need negative numbers, a mistake in an algorithm with subtraction or decrementing can easily lead to accidentally overflowing. These errors are just easier to reason about and debug if negative values stay negative. There's lots of examples of trivial bugs like this (like a backwards for loop using unsigned). This is also true about interfaces, users can pass negative numbers to unsigned parameters, triggering silent conversion to large numbers. Easier to reason about the code (and assert) if they stay negative.
Have you tried `-fsanitize=undefined`?
That stuff isn't nearly as bad. Still love FMP, hate Akira.
You're talking about how to fix the bug. I'm talking about how to find the bug so I can fix it. Yes, the whole premise is that there is a bug. But if the bug is undefined behavior, then it's harder to find. Knowing how to fix it doesn't help at this stage. Let's just say that I'd rather work with a number type where 'a+(b-c)' is guaranteed to be the same as 'a+b-c'. **EDIT** For example, let's say that: const int b=MAX_INT - 16; // just an example for a const value const int c=b-2000; // just an example as well // a lot of lines later, in a different file entirely for (int i=0;i&lt;100;++i){ int k=i+(b-c); // OK, no problem! int kk=i+b-c; // will cause this loop to become an infinite loop! But only in -O3 // do something with k or kk } Finding the bug if you use the `kk` line will be... challenging. Especially since with `-O2` there will be no bug, looking at the code it "looks right" (unless you happen to know that `b` is so that `b+17` overflows), if you add a `printf` before + after the loop you see the loop becomes an infinite loop, but if you add a `printf('i= %d\n',i)` inside the loop (to see why it doesn't exit) the bug disappears. Go ahead and debug that. And that's an easy case where you know the bug is fairly localized. Had the calculations been somewhat more complicated... it would have been extremely hard to pin-point down. So much so, that a lot of projects just optimize with `-O2` and get it over with.
Can't reproduce your infinite loop: http://coliru.stacked-crooked.com/a/4cc4d00eb1e16d29.
Opinion of people that have used it?
And that's my whole point! It's a sneaky bug, that often doesn't show itself but sometimes does, on specific platforms / compilers only, under specific flags etc. BTW - you had a `printf` (well `cout`) in there that I said will negate the bug. But even without it, depending on the default flags of your compiler / compiler version it won't happen. Here's the logic of why it does happen, on platforms that optimize for these things: we have `i+b` calculation (in the `kk=i+b-c;` line). Since `b` is equal to `MAX_INT-16` and integer overflow is undefined behavior, the optimizer can assume that `i&lt;=16`, right? The exit loop condition is `i&gt;=100` (only then does the loop exit). But we already know that `i&lt;=16` always, right? So we can optimize out the `i&lt;100` test, since it will never happen, right? It will just always be true. So we replace it with an infinite loop. Now here's the insidious part: change a bit what happens inside this loop, and the optimizer might not do this optimization (for its own magic reasons). Remove a couple of unrelated lines, add a debug print, change some line order, or even move this whole code into a new main to test it on its own, and some unknown internal optimizer condition might change making this specific optimization not happen, and the bug disappears. This is exactly what happened [here](http://blog.regehr.org/archives/918), where this exact optimization broke the standard benchmark test for compilers, because the old code used undefined behavior similar to the one here.
Great example! As I've said though, if you don't mind sacrificing those optimizations, you still can quite easily by just turning that particular optimization off. I'd still prefer signed with forced defined wrapping behavior over unsigned due to underflow issues.
At the end of the day, I think CERT's Rules &amp; Recommendations are worth considering -- or at least being familiar with (regardless of whether you're using signed or unsigned integers). Depending on your programming language (although there's a significant overlap as far as fundamental types are concerned): * SEI CERT C++ Coding Standard + [Rule 03. Integers (INT)](https://www.securecoding.cert.org/confluence/pages/viewpage.action?pageId=146440565) + [Recommendation 03. Integers (INT)](https://www.securecoding.cert.org/confluence/pages/viewpage.action?pageId=2284) * SEI CERT C Coding Standard + [Rules 04. Integers (INT)](https://www.securecoding.cert.org/confluence/pages/viewpage.action?pageId=270) + [Recommendations 04. Integers (INT)](https://www.securecoding.cert.org/confluence/pages/viewpage.action?pageId=158237210) For instance (note: `rsize_t` is C11-specific; more on that below): - [INT01-C. Use rsize_t or size_t for all integer values representing the size of an object](https://www.securecoding.cert.org/confluence/display/c/INT01-C.+Use+rsize_t+or+size_t+for+all+integer+values+representing+the+size+of+an+object) - [INT02-C. Understand integer conversion rules ](https://www.securecoding.cert.org/confluence/display/c/INT02-C.+Understand+integer+conversion+rules) BTW, C11 introduced `rsize_t` (and `RSIZE_MAX`) -- http://en.cppreference.com/w/c/error -- which seems interesting in this context: - http://www.viva64.com/en/t/0095/ - http://www.drdobbs.com/cpp/the-new-c-standard-explored/232901670 &gt; The type of the second argument is rsize_t, designating a "restricted size_t" value. The intent is to prevent the common error of inadvertently passing a negative value, which after conversion to an unsigned type, becomes a huge number, and in this case, defeating the purpose of bounds-checking the string written into s. This common error is intended to be caught within tmpnam_s by comparing maxsize against RSIZE_MAX and invoking the runtime-constraint handler if it's larger. (I've said "intended" several times, because Annex K makes it optional whether RSIZE_MAX is any smaller than SIZE_MAX.) This manner of designating bounding values with the type rsize_t is another security best practice promulgated in the Annex K library. 
LTCG is at least 10x slower than regular builds (assuming an 8 core machine) because it's not parallel. In a regular build, I parallel compile the cpps and then link them. In LTCG most of the work is deferred to the link step which runs in one thread. In my world this is important because debug builds are too slow to use daily, so the typical thing to do is to use release builds and #pragma optimize(off) individual cpp files locally as necessary. 
&gt; Of course, the same applies for unsigned integer, but at least I know that if an overflow happens, my program will not crash. This is a huge advantage. That's not true: An unintentional unsigned overflow absolutely can result in a crash when that result is used. Even if you could know that the program wouldn't crash, that's hardly an advantage. The worst thing that could possibly happen is that the program continues operating. Crashing immediately is far more desirable. It's just unfortunate that signed overflows don't guarantee crashing. Fortunately there are tools that will add this desirable, crashing behavior.
You aren't making sense. If debug builds aren't faster, you're doing something wrong. You don't use any of speed helpers that i listed, do you? You have no numbers, on your codebase, to corroborate your claims, don't you?
I too have noticed improvements on my 2d range-based for loops over usual nested loops.
I gave an example exactly like this below, and in our thread above, which you rather neatly ignored. void f(int32_t) { ... }; uint32_t five = 5, seven = 7; f(five - seven); // works as expected Later, refactor f to take an int64_t. Breaks. Would not happen if you use signed types. Should we modify: use unsigned for types that will always be positive, and never need to be subtracted? Or just do the easy thing and use signed?
This debate has been going on for years. There's good arguments for boths sides. Question is, how often do you really encounter errors because of signed/unsigned data types? Not very often. Just use whatever the hell you want really.
The error is that in this case I want to pass the difference between the two variables to f(). In the original code I get that, but a refactoring that would be harmless in almost every case breaks it. If you prefer, forget about f(), just imagine I'm assigning the difference to another variable, which is signed. If that variable is the same width as the unsigned then it works, if I make that variable wider, then it breaks. If five and seven were signed, these issues would not exist. The point is that even though five and seven represent variables that are never negative, when we subtract them, we have to be way more careful with unsigned than with signed. More broadly, the point is that you have to use signed for anything that can be negative, and signed and unsigned interact strangely at times. Since you have to use signed for a lot of arithmetic anyway, it makes much more sense to use signed for all arithmetic, and leave unsigned for bitfields. This is probably the line of reasoning that makes Bjarne say that all of these unsigned integers in e.g. std::vector were a mistake. In your example, the two asserts are obviously different; the same assert can still be written with signed in the signature. In that particular case, there would be very little difference. If you are being passed a parameter that has to be positive but doesn't necessarily have an upper bound (like all your previous examples), it's far more readable and intuitive to assert that it's non-negative, than to seemingly arbitrarily assert against the top half of the range of unsigned.
&gt; Why is wrong code that has undefined behavior worse than wrong code that's technically well defined but which nonetheless does things the developer does not expect because the latter case can be spotted by unit tests and contract checks
Well Herb points out that the only time an unsigned value wouldn't work is when you are on a 32bit, working with an array of chars **and** it has over 2 billion elements. I'd guess he figures the default choice should have been a signed type which is cleaner and works 99.9% (stat plucked out of my arse) of the time. For the rare occasion it doesn't, you could reach for an alternative. But that's just my interpretation of the "why" behind "what" he said. P.S. also STL containers `.size()` isn't guaranteed to be `size_t` anyway. I don't have a reference for that off hand.
I'm talking about runtime performance. Debug builds are too slow regardless of build time so we're forced to use optimized builds most of the time. 
&gt; An unintentional unsigned overflow absolutely can result in a crash when that result is used That depends on the context, the point is that with an unsigned you can check for overflow *after* it happened, while with a signed once you get the overflow you have UB, it is too late to do anything. Beside, after watching the GoingNative talk linked in another comment I might change my mind on the subject. Still it really depends on the context. Beside, at some point you have to check if the user input falls within the allowed range for your computations. Checking if `a+b` with `a` and `b` signed ints will overflow is far more trickier than with unsigned.
&gt; What is a negative index? what is a negative count? The difference between index/count A and index/count B. If you are going to perform arithmetic on your values, signed is generally the way to go. There are cases where unsigned is more appropriate such as when the value is non-mathematical (namely a handle to an object, texture, window, etc.).
&gt; P.S. also STL containers .size() isn't guaranteed to be size_t anyway. I don't have a reference for that off hand. Yes, but I am quite sure that is guaranteed to be an unsigned.
&gt; For the rare occasion it doesn't, you could reach for an alternative. Really? How is that going to work? Let's say `std::vector::size` returns `std::ptrdiff_t` rather than `std::size_t`, how am I going to reach for an alternative when I push the 2147483648th byte into my `std::vector&lt;char&gt;` on a 32 bit system? The value isn't representable by `std::ptrdiff_t` and calling `std::vector::size` results in undefined behaviour.
&gt; That means that in debug mode, in practical terms, signed integer overflow is not really UB So your program runs fine in debugging and then has a security vulnerability when deployed. Great!
I guess none of them ever ran into problems with trying to use more than 2GB of RAM? 
Huh? All representations store non-negative numbers in the same way. 
[Here is a stack overflow question which seems to disagree](http://stackoverflow.com/questions/3952123/representation-of-negative-numbers-in-c/3952262#3952262) directly referencing ISO C (C99), section 6.2.6.2/2. Granted this is C99 and I have no idea if the standard does mandate anywhere the actual behavior implicitly.
In the other comment you told me to stop writing buggy algorithms, so I'm sure none of this is relevant for you anyhow. 
Special casing is possible but obnoxious - we did this back in the 98/03/TR1 era with swap before move semantics. Using moves for the general case is simple and buys most of the perf you'd want. Remember, if you have a vector of vectors, your perf is unlikely to be dominated by the reallocation of the outer vector.
&gt; Wow, I couldn't disagree more with this. This is just your personal opinion, not a fact. If you're not going to *physically touch* the other person, there is nothing you can do in a face to face meeting that you cannot do online. There's literally no reason to meet unless you're going to kiss, or have sex, or give a person a massage. If you believe otherwise, you either have bad communication tools, or you are bad at using those that are available. (And you also might be over 50.)
Wrong, and discriminating against the elderly. If only there were a minus two button. 
I was one of the students attending last year, sadly this year I got a job and cannot attend, but hopefully the talks will be on Youtube soon!
If you are on a 32bit system using byte arrays &gt; 2gb then you are already playing with fire. Sure an unsigned size type would double that limit and give you a bit of a safety net, but I would propose it's still not safe enough and you should really have reached for a more specialist structure at design time.
&gt; safe enough What do you mean "*safe*"?
Yes, downvotes are exactly what makes reddit great. Let's shower each other in our dislike. This is what makes the world constructive. Maybe instead of downvotes, we could have guns, and we could shoot at each other. That would be even better. ;) Or maybe &amp;#8212; we could all have a button, and if we dislike what a person wrote, a boxing glove comes out of their keyboard, and punches them in the face. ;) Seriously, screw this whole downvote thing. Humans have enough hatred and intolerance for each other as it is. I know I do &amp;#8212; and so does anyone who ever downvoted, well, most anything. The last thing we need is easy, trigger-happy ways to express our dislike for each other. And this is what reddit offers. To be a true hypocrite &amp;#8212; I downvoted you too. :) I don't have anything against the elderly. We just all tend to operate with assumptions based on how we grew up. Older people tend to be uncomfortable working with people indirectly. IM or email seems impersonal to them. They want to make phone calls and have face to face meetings, and take for granted that this is how things should be.
I'm just suggesting that if you are within a 1 bit or 2 of the limits of your types or data structures then you are on dangerous ground. Yes unsigned gives you an extra bit and doubles that limit, but if it's a case where that bit actually matters then you're probably still too close to the limit for comfort. But I could easily be totally wrong on that, which is I why I'm happy to defer to the experts until I hear a convincing argument otherwise.
&gt; I'm just suggesting that if you are within a 1 bit or 2 of the limits of your types or data structures then you are on dangerous ground. Exactly, but this is part of my argument for unsigned types, specifically `std::size_t`, as opposed to signed types. Since C++ is (conceptually) portable it's difficult if not impossible to pick a signed type that is sufficiently wide. If you pick a 64 bit signed integer I can build on a 64 bit machine which requires the full 64 bits to address its entire memory space. If you pick a 128 bit signed integer I could concoct a hypothetical 128 bit machine. Sure you could argue it's unlikely that you'll ever need to use a full 64 bits to count the number of elements in a collection, but there was a day when we didn't think we'd need more than 32 bits to address memory either. `std::size_t` is provided by the implementation and is wide enough to hold any number of objects which fit in contiguous memory. Accordingly if I'm on a 32 bit machine it's impossible for `std::vector::size` to be greater than `std::numeric_limits&lt;std::size_t&gt;::max()`. Therefore no matter how many objects I stuff into that `std::vector` it'll never be the case that I can address those objects but not count them. The underlying allocation will fail before this becomes the case.
&gt; That seems like a quintessential appeal to authority. Absolutely, but it's ok. As it stands I just don't have enough information from both sides to make an informed decision, so I'm happy to trust the experts until I have a good reason not to.
I go int unless I really really need that extra space. For instance on the arduino I actually need that space. On the desktop or server where an int is 64 bits and I usually have memory to burn then in most cases I should technically use something smaller but I don't. I will happily count to 10 using a 64bit int. I wouldn't be surprised if the CPU can do math faster with 64 bit variables anyway. My simply theory is that by always using ints I can always expect an int. Plus it is rare that a library will be expecting a uint which would then just mean extra coding for me. Plus think about all those extra 'u's that I would have to type. Blechk. 
Obviously it will work better in some settings than others. I've just found that a lot of valuable information gets communicated in the impromptu conversations that pop up when people are in the same room. When you have to coordinate via skype, people are less likely to e.g. have a quick 10 minute discussion, where some design detail is nailed down before code is written as opposed to in code review, where rewrites may be necessary. I've found that blocking or semi-blocking situations are not uncommon. I respect that your mileage has varied, but a the same time I think that your views are a bit extreme; I wouldn't automatically think less of someone who prefers to tele-commute.
I think this is similar to what I wrote about vectors. It's not nearly as simple as bit blasting, you either need a special case not to call the old destructors, or else blast the old vectors into a valid state. The problem is that C++ isn't easily designed to work this way so it's a pain. This is definitely a case where Rust has one over us.
&gt; The problem is that C++ isn't easily designed to work this way so it's a pain. But &amp;#8212; I don't understand this being the problem that it's purported to be. There are so many libraries that are doing this already. These are cross-platform libraries, compatible with a variety of compilers and toolsets. If doing memcpy on location-agnostic objects really was this insurmountable problem, wouldn't these libraries experience this? Wouldn't at least one compiler, at least one platform, have a problem with this usage? It seems to me that the perceived obstacles are, well... fictional; and that overcoming them would be much less of a problem than some folks seem to perceive.
I only read the vector ones, but if you continue explaining pieces of the the STL in that format, this will be golden for beginners starting up in the language! Good job! One thing that you may want to mention briefly in the vector blog is if you run out of contiguous space. After C++0x, it becomes a guaranteed linear-time copy of the entire vector to another block large enough to fit.
&gt; What's the strawman exactly? That `is_trivially_copyable` is any kind of answer. Most types that own any kind of resource aren't trivially copyable, or trivially anything. But they are relocatable &amp;#8212; or would be if there was this property. &gt; Neither strings or vectors are bit-blastable. Their copy constructors require a deep copy through indirection, and their move constructors require that the original/source object is reassigned. Flat out wrong. Unless the string or vector contains a self-reference, it is relocatable to a new location via memcpy, *as long as* no destructor is called in the old location, and no constructor is called in the new one. &gt; The fact that some subset of an object is bit-blastable does not imply that the object as a whole is bit-blastable. This is practically implemented in many libraries, and whole objects (non-trivial objects!) are being moved via `memcpy` or `realloc` during container resizing with no issue. This works with a variety of compilers and platforms. Of course, this relies on undefined behavior, which is exactly my point: standardize what's being used in practice.
&gt; That is_trivially_copyable is any kind of answer. Most types that own any kind of resource aren't trivially copyable, or trivially anything. But they are relocatable — or would be if there was this property. And types which own a resource can't be bit blasted because doing so would result in two objects owning the same resource. &gt;Flat out wrong. Unless the string or vector contains a self-reference, it is relocatable to a new location via memcpy, as long as no destructor is called in the old location, and no constructor is called in the new one. Right, so long as you violate one of the cornerstones of RAII upon which most existing C++ code relies upon (that destructors get called when an object expires), then you can bit blast your object. &gt;This is practically implemented in many libraries, and whole objects (non-trivial objects!) are being moved via memcpy or realloc during container resizing with no issue. Yes, I'm sure a special purpose library can implement containers with specialized semantics. But the standard library isn't designed nor is it suited to deal with specialized cases. The purpose of the standard library is to deal with the general purpose case, and if you need something specialized then you use one of those specialized libraries you talk about.
Very cool, I enjoyed the Python entry. It would be really interesting to see more entries on the C and C++ underpinnings of higher level technologies like Python and Ruby! (On the site itself, I noticed that some of the links are broken on the Python entry.)
&gt; And types which own a resource can't be bit blasted because doing so would result in two objects owning the same resource. No. "Object" is a concept. In reality there is data. When moving objects by memcpy, the object-concept is moved from one location to another. This is done by copying the data. The bits left behind are no longer part of the object. At no point do there exist two object-concepts. The object-concept is moved. &gt; Right, so long as you violate one of the cornerstones of RAII upon which most existing C++ code relies upon (that destructors get called when an object expires), then you can bit blast your object. No part of RAII is violated. The object does not die when it is moved. The object-concept is simply moved to a new location. RAII is honored and the object is destroyed when it expires, in whatever location that may be. This works if we know which objects don't mind being teleported. The developer marks base non-trivial objects as relocatable. The compiler can then infer for other objects, under same rules as move constructors are inferred. &gt; Yes, I'm sure a special purpose library can implement containers with specialized semantics. No, these include general purpose libraries, like Qt. These general purpose libraries implement this general purpose concept in their general purpose containers. &gt; The purpose of the standard library is to deal with the general purpose case Most objects are relocatable. The standard library could make use of this, if there was a concept of relocatability.
Good stuff, looking forward to see more episodes.
Nice! The main difference I see is that my code works with functions that return something :) That was the main reason I invented the helper. If I don't have a return value, I can just use my timer class inside a scope just for the function call: { Timer timer; func (/*...*/); } It does not work here though: { Timer timer; auto val = func (/*...*/); } // val out of scope now...
Cool! What are you using to draw diagrams?
Shame on me. Will go through the articles once again.Thank you for these corrections. Fixed.
Alternatively you could use a lambda - that way you can have more arbitrary blocks of code, capture local vars, etc. just so long as you return something at the end. E.g.: template&lt;typename F&gt; auto PrePost(F fn) { std::cout &lt;&lt; "pre\n"; auto ret = fn(); std::cout &lt;&lt; "post\n"; return ret; } int foo() { std::cout &lt;&lt; "foo()\n"; return 42; } int main() { auto x = PrePost([]() { return foo(); }); std::cout &lt;&lt; x &lt;&lt; "\n"; } 
Thanks, I'll try to find another words.
I assure you we are not doing it wrong. It is simply the reality of soft real time systems. 
Just Microsoft Visio.
http://stackoverflow.com/questions/21085446/what-is-the-meaning-of-auto-main-int
Very great start! Continue, pls! Subscribed on feedly.
I like the tone of the articles, clearly focused on getting concepts right for beginners. This is something we really need, most serious C++ posts are usually pedant (i.e. written from the language lawyer pov) and/or cover advanced topics. This applies to my own posts as well... Just some tips: The Figures 1 and 2 in part 1. That diagrams show `vector` side by side with program memory. The problem is that vector there is not the actual members of the vector object itself, but the elements of the dynamic array. Then some diagrams use arrows to match the array with the memory, such as Figure 2 which directly states "elem points here". I think you should change this since it may confuse beginners about C++ objects memory layout. The "points here" can easily fall into the wrong assumption that C++ works with references as Java or alike. Specifically, I think Figure 2 should use the same dot style from Figure 1, dots do not imply "points to" but "This goes here" or "picked from here". Also I would be glad if Figure 1 legend includes vector space in addition to free and occupied space. Just some notes from a pedant :) Really good articles. I'm looking forward for the `std::string` entry.
I think the OP was hoping to get away with not using the second bit blast. Imagine: template&lt;class C&gt; struct VeryTrivialVector { int my_size; C* my_data; //... }; To move a VeryTrivialVector, you could memcpy the contents of the struct then simply fail to run the destructor on the source. This would make moving even cheaper, since you can use memcpy(), instead of the move constructor, you don't need to set the source to an empty state and you don't then need to run the destructor which would inevitably check for it being in an empty state. 
&gt; Both face to face contact, and instant messaging, are distractions, and are useful primarily in the situation that you cannot progress on anything without immediate input. Such situations are extraordinary. Possibly for work (though personally I disagree(), but as far as I can tell the committee meeting is pretty much the definition of 6 days where nothing can progress without immediate input. All the pre-input stuff has been done in the form of proposals. Please also be aware that your own way of working is not the same as other people's. I'm one of those people who works better in close proximity to the people I'm working with. Impromptu discussions over a whiteboard can be very, very useful.
I can't tell you about RVO and lambda, but values should at least move construct/assign through lambda return values, so returning should still be "cheap".
I am also vim user, but I really miss autocomplete and docs feature. I remember I tried to install them but with no success. (I don't have superuser permissions, e.g. to update vim version)
Well, you could fix the lambda clutter a bit, using auto x = Run ([&amp;]{ return foo(); }); Still, I don't really like it ;)
AFAIK move is only cheaper for large heap storage. Whatever lives on the stack cannot be moved, so RVO is pretty nice if possible.
You should probably have a blog post or a profile on your background. I wouldn't personally read a blog by somebody on these topics unless I know for certain that they should have the knowledge to be able to discuss it.
I did try it, but it was terrible experience with no success. Btw, it requires many dependencies and newer vim version.
&gt; It's a classic space/time tradeoff. Dinkumware/VC's 1.5x conserves space (slightly), GCC and clang's 2x conserves time (slightly). I've never seen the theoretical concern about a growing vector being able to reuse space actually matter in practice. https://github.com/facebook/folly/blob/master/folly/docs/FBVector.md
Already tried, wasn't useful.
As far as I am aware this is now impossible, see: http://blogs.msdn.com/b/vcblog/archive/2015/03/03/introducing-the-universal-crt.aspx
taglist and :Tlist works great for me..at least on linux. I'm in a crappy embedded environment w/ an old ass vim version too.
How are strings bit-blastable? I believe it is not possible without destructive move concept. Currently, the moved-from objects are required to be in a valid but unspecified state. If a string is bit-blasted, the both new and old one are referring to the same memory. Then we push_back to one of them, it relocates the memory, and --- *boom!* --- now the other one refers to the deallocated memory. This is not a valid state.
And they must use the STL allocator interface, which doesn't permit realloc-in-place. (I've considered special-casing std::allocator, but that would be a lot of code complexity for a questionable reward.)
smoothscroll is horribly on Mac (where everything already scrolling smooth), I can hardly browse the page due to it moving all over the place when I try to just scroll a teeny bit.
Welp.
Not a valid option when you use libraries, since it's most likely to break them. Same applies to making libraries.
Manu, thanks a lot. Appreciate your concern and suggestions. Make sense - I will try to improve those guys. BTW, your articles are really worth to read :) 
Thanks!
If you don't use it, why are you telling people to use it? Be careful to avoid providing improper guidance. (I've made that mistake in the past, telling people to use "unified assignment" before understanding that it's harmful.)
&gt; Currently, the moved-from objects are required to be in a valid but unspecified state That actually is inefficient for quite a few things, sorting or any sort of permutation for example. As long as objects does not contain any self-referential elements, I should be able to shuffle them around using memcpy. I should not have to incur the cost of setting each object to a valid state only to overwrite it later. 
Good point, thanks, let me go through this section and make a stress on this.
Documentation (or the Standard). I need to thoroughly understand a function's preconditions, postconditions, and failure modes, not just its signature.
Would the high resolution clock functions of C++11 work instead of the platform specific functions? 
Lambdas in my experience can get very hard to compile and debug if they are nested, which is a reason I have pulled back on using them as much as I used to.
Most libraries that you have to use in cpp anyway have to be compiled from source, only a few of them don't. It says on the page, that you could include a redist which will install on everything XP SP3+. That may be the best way, have the installer detect if it's installed then proceed.
Not only this, but unsigned ints when compared to a negative number won't return what you would expect - 5u &gt; -1 -&gt; false This can be especially problematic when working with an API that has typedefs to give names to basic types. http://ideone.com/DPr3x3
A side note, and not that I'm complaining, but can someone explain to me why conferences like this have a $1k entry fee?
First off, a destructive move doesn't change the fact that you will be violating RAII in C++, and second destructive moves can not be done in C++ without incurring run time overhead, which is part of the reason why the proposal got rejected. Consider this code snippet: void foo(T&amp; value) { ... } void bar() { T value; if(condition) { foo(value); } // Should `value` have its destructor invoked at the end of `bar` or not? // There is no statically verifiable way to determine this since // it depends on `condition` and depends on the body of `foo`. }
If a library hands you a pointer that you're expected to free and defines symbols which clash with your own symbols (thus preventing you from statically linking the library), then you cannot statically link the C runtime. This would be a very poorly designed library, but such libraries exist.
&gt; provide the object files of the non-LGPL portions of the program so that it can be re-linked This is utter nonsense when talking about C++ libraries.
It's not nonsense. Certainly, it doesn't apply for things like header-only libraries that make heavy use of templates, but those libraries tend not to choose the LGPL for that very reason. C++ libraries can be designed with ABI compatibility in mind, using techniques like the pimpl idiom to create a firewall between user and implementation. And that's not to mention libraries that have a C API, even if they're implemented in C++, or ones that use the [hourglass interface idiom](http://www.slideshare.net/StefanusDuToit/cpp-con-2014-hourglass-interfaces-for-c-apis). I made no statements that this applies universally to every library. I'm countering the nonsense that "the [L]GPL forces you to use DLLs". 
So how do you now do app-local deployment? Previously it was easy - use C - copy msvcrXY.dll, use C++ - additionally copy msvcpXY.dll next to exe. What to do now? Copy all those 10 or something dll's next to exe? Ugly... What if I want to copy only those dll's I use? Then I need to start looking at import tables of my exe and dll files.. Terrible waste of time.
Thanks :-) Please, feel free to report any issues back! Cheers!
Wait. Are you hooking the destructor?
CppCon has a student rate, at least they had last year - it was around $150 or $250 or so.
Yes, I just saw that they do have student ticket for 145$, that could be (a limited contigent) free if they found a sponsor for a full student program.
Destructive move as well as a is_trivially_movable trait would be very useful for implementers of containers like Vectors and B-Trees (and other cache efficient data-structures). In these examples you are working with uninitialized memory and all constructors and destructors are explicit. For example, an std::vector&lt;std::string&gt; cannot of re-allocated with memcpy even there this would be perfectly fine in principle. Instead what happens is that the container must move construct/destruct each element. This is far less efficient. I believe /u/SushiAndWow was making a point that some data-structure implementations do the memcpy anyways (Folly comes to mind), and so there ought to be a standard non-UB way to express this.
These optimizations would be significant in std::vector as well as segmented data-structures such as B-Trees, B+Trees, B-Heaps, std::deque, etc. edit: As long as there was a is_trivially_movable trait, it would be easy for a container to take advantage of memcpy/memmove as containers work with uninitialized memory and explicit construction/destruction.
The golden ratio argument only makes sense if you don't have virtual memory , you want a vector to be able to use all memory available on the system and you don't want to use reserve. In other words it's just a time-space trade-off (a factor of 2 is faster than 1.5).
If you realloc a C-array you don't get that guarantee either. What is your point?
I don't know the exact set of DLLs to copy, I'd have to ask James. If you want a single binary, static linking is available.
I believe the GCC folks only tried out the 1.5 growth factor and found it to be slower than 2.0. This is expected IMO. The other optimizations employed by Folly (integration with jemalloc for tight coupling with it's size classes, in-place reallocation, memcpy/memmove of opt-in types) probably do lead to real performance benefits but would be outside the scope of libsdc++ because these things either rely on jemalloc or are UB.
Yes thanks for clarifying. I am only talking about the 1.5 growth factor. The other optimizations Folly implements do result in performance gains.
Yes, I know about static linking. Static linking won't work for some libraries that calls malloc in one dll and free for that memory in another (or fopen/fclose and similar stuff between dll's) The question is about app-local deployment. How to do it properly for vs2015? 
I think the main issue is that it doesn't stop immediately if you drag after doing a quick flick (I usually do short but quick scrolls), but overall I'd say any scroll modification is just about guaranteed to mess up some platform.
Why with every version of VS everything gets worse? It was nice and simple to copy two dll's before. Now we need install separate SDK (and what's wrong with dll files that gets installed by VS?). And copy so many dll's with application... I am sad :( Note that while MS is discouraging app-local deployment of C runtime for already long time, it is still important feature for many developers when shipping applications. There are bunch of end-users who don't have admin rights, so they can not install redist. And there are bunch of complex 3rd-party libraries that require you to build with shared C/C++ runtime. 
Well of course there also other conferences then CppCon ;) Some of them are heavily sponsored by companies, others like my own need to back the people running the work behind the conference. Also, I must say, a great alternative are User Groups, you'll get a great local network of C++ people and see lots of interesting talks on C++.
very nice example. I agree
Well this is decision I disagree. Nobody compiles application to one executable that must run with "legacy" DLL like kernel32.dll and with new magical API sets on Windows Phone. They compile such executables separately. So nothing prevents one exe to use one-file-CRT like msvcr140.dll and other exe to use new API sets. In such case deployment on "legacy" systems would be same as before. 
Side note, [`#pragma once`](https://en.wikipedia.org/wiki/Pragma_once) is a better alternative to header guards.
`using namespace std;` dumps the entire `std` namespace into the context it's used in; this can result in name collisions if you're not careful and is especially dangerous in header files! `std::cout` is a fully-qualified name; it unambiguously refers to `cout` residing in the `std` namespace without the namespace pollution of the above. `using std::cout;` introduces *only* `cout` into the enclosing namespace, allowing you to refer to it without qualification *and* without dragging the entire rest of the namespace along with it. This is analogous to the `import` statement from Java, Python, etc. and is the method preferred by most C++ programmers when a name is deeply nested and/or referenced repeatedly, to the point where fully-qualifying it would hamper readability or be incredibly annoying.
NB: In Python, the `help()` function works for any module, class, or method which has a `__doc__` string defined, which is where the `"""` comment ends up. Simply put there's no clear analog to Python's `help()` because C++ isn't interactive but is instead compiled. Therefore the "help" you want is the documentation -- or at the worst, the source code of whatever you're working with. Some IDEs have a system to read in the documentation, and I'm not just talking about an autocomplete feature where it can recognize what names are valid and give the signature.
Is not the checks but exceptions overhead. Also, compilers are not that genius
`#pragma once` is non-standard 
That's just adding another dimension to the array. If `Number` can be 0 or 1, then declare a 3D array like `char map[2][10][10];`. 
Most people are going to cry and say you should go to /r/cpp_questions instead.. but.. Can you not just be lazy and use [FILE](http://www.cplusplus.com/reference/cstdio/FILE/)* ? so it'd be something like... string file_name; FILE* file; std::cout &lt;&lt; "Enter a file name please\n"; std::cin &gt;&gt; file_name; file = fopen(file_name.c_str(), "w"); //do some magic with writing to the file fclose(file); Granted that's more C than C++; but at least in that way you can figure out the full size of the file in advance, allocate a buffer, and read in all your data in one go instead of asking the stream to pass you data. 
Whoa, I never knew you could do that. That seems real simple. Thank you very much!! 
Are merge modules not installed with 2015? edit: yeah the are, https://msdn.microsoft.com/en-us/library/ms235290.aspx
There are people who strongly advocate byacc over bison. IIRC, both were originally developed by the same person, and byacc was the later new-and-improved version - AFAICT "improved" doesn't mean more bells-and-whistles. 
I can't say anything about byacc, just "don't use plain yacc, lacks important features such as being reentrant".
Is there any chance vector operations like emplace_back could return a reference to the emplaced object instead of void? I've found that the emplace line could be long and below it operations might be done on the new object. Those operations require the vector name and index when a reference could be used as an elegant shortcut. 
Boost is a large collection of high-quality C++ libraries. Each library is carefully [reviewed](http://www.boost.org/community/reviews.html) before being admitted to Boost. The HTTP library will be reviewed starting this Friday.
URL for that library: http://rrsd.com/blincubator.com/bi_library/http/?gform_post_id=1460 repo: https://github.com/BoostGSoC14/boost.http doc: http://boostgsoc14.github.io/boost.http/
I guess Spirit X3 deserves a mentioning too, it may be easier to use than previous versions.
The library is being reviewed to become part of boost. It is not yet. As of standard, it is not a straightforward way way from boost to the standard: committee decides on a case by case basis. Boost is not any special for the standard committee. Of course, things proven to be widely useful and well-designed have higher chances, and being accepted as a part of boost frequently counts as such. And the committee considers, apart from the quality of the library itself, many more arguments, such as it's universal usefulness (will it benefit everyone or just small niche group of programmers?), implementability on a wide range of platforms, etc. So, in short: there are chances to getting into the standard (even not being part of boost), but there is no guarantee. And definitely not in the short term. (not before 2020).
Depends. According to [this SO answer](http://stackoverflow.com/a/5257950) the order of destruction follows the reverse order of construction, as far as side effects go. My clock code is definitely a visible side effect, as should any measurable operation be. Also, in case of the helper function, the timer is the only local variable for the scope and thus guaranteed to be the last object destroyed :)
Anyone who have played around with this. How does it compare to Casablanca
Are they useful for indentation-based grammar?
&gt; Premake What bothers me is that package managers want to be build tools. I just want the package management part. Like, put everything into vendor/ and let CMake, Make or anything else i'm using use that.
I guess temporarily, it was working earlier. If you are still interested just try again later today. 
std::vector does not have a trivial destructor.
I didn't say reallocation couldn't be made more efficient, I said containers-of-containers that support reallocation aren't going to be crazy efficient generally, because the memory will be highly fragmented. If you want a vector-of-vectors, you can get much better performance rolling your own. I'm saying it will be hard to verify that a user defined type is trivially moveable without changing the core language.
I have not used it, but you can see some comparison by the author [here](https://github.com/vinipsmaker/gsoc2014-boost/blob/master/other_frameworks.md). Unfortunately, without Casablanca.
Correct; we can't update them, e.g. if a critical security bug needs to be patched. There will be no breaking changes.
Thanks
Boost.Spirit is a *horrible* idea. The single file that contains the parser will take longer to compile than the rest of your project together. And that's with lowering the optimizations to -O1, too.
Wow, I didn't think of that, thanx for the hint!
Aha! You fell for one of the classic blunders! In C and Friends, integer division always produces an integer, rounded towards zero. So `9/5` evaluates to `1` and `5/9` evaluates to `0`, which will result in wonky and unexpected results for computations like these. Simple fix: Make them floating-point! `9.0 / 5.0` and `5.0 / 9.0` should do the trick. #Edit: Also, if you're getting compiler errors, it's probably because you aren't `using namespace std` and it doesn't know what `cout` and `cin` are. Also, the two function calls in the middle of your `main` are completely useless; you're not assigning them or outputting them anywhere, you're just calling them and then throwing away the result. You should delete them. Also, your signature for `main` is completely wrong. `main` *always* returns and `int` and *usually* doesn't take any parameters, but when it does take parameters, it takes an `int` and a `char**`. You're not using any arguments, so better to just leave it parameterless.
Okay got it. But the problem actually seems to be in the float main(float){ part. Not sure whats happening there :D 
Edited as I noticed it immediately after posting this. You really should explain what's going on instead of just posting some broken code and saying "Fix this!". Also, you should read compiler error messages, because they're generally pretty good at telling you what you screwed up. When I try to compile this, the very first things I see are "main must return int", "first argument of main must be int", and "main only takes zero or two arguments".
headers
In this case, especially if still learning, go with fstream. That way you're learning c++ not c, and the idiomatic use of the two languages belies the similarity of there syntax. At some point you'll come up against a case where you have to adapt to a c api in c++. Here, the RAII pattern comes into its own. Wrap the resource (a FILE* above) in a class with a destructor that frees the resource. That way you can benefit from destructors properly. Stroustrup's principles and practice book may be good at this point. While aimed at absolute beginners, it does cover all this stuff pretty well, and will help learn idiomatic c++ without getting too bogged down in its idiosyncrasies.
I have some questions that are brought up by the discussion on the explanation of the expansion factor. As I understand it the address you receive in your program is not the true address but a virtual one which is then mapped to the physical address somewhere in RAM, just because two pages are contiguous in the virtual address space doesn't mean they are contiguous in physical address space (which bit of silicon is holding it). This has a significant implication to this. I have physical pages A,B,C,D,E &amp; F and virtual pages 1,2,3,... and the following happens: - I have a `vector` allocated with memory on virtual page 1 which is mapped to A - The vector doubles in size and is now on virtual pages 2 and 3 which are mapped to B &amp; C. - The vector double again, it doesn't have space for 4 pages in D,E,F but couldn't it just put it in virtual pages 4-7 which map to physical locations A,D,E,F? In essence, can you reuse de-allocated memory with new pointers? The OS does do fancy things already by providing you with virtual addresses that [aren't actually assigned to physical addresses](http://stackoverflow.com/a/1941538/1227915) until accessed. I'm not an expert but I'd love to understand this stuff better.
[**@SeanParent**](https://twitter.com/SeanParent/) &gt; [2015-07-31 04:28 UTC](https://twitter.com/SeanParent/status/626972701207302144) &gt; @superfunc I am! They haven't yet posted all the plenaries and keynotes on the program, but I've been assured I will have a slot. ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://www.np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
This happened to me with warning level 4 on intel C++ 2015. I don't know the behavior of other compilers.
Use a VM.
If you are using a desktop, [harddrives](http://www.amazon.com/Blue-Desktop-7200rpm-Internal-Drive/dp/B0088PUEPK/ref=sr_1_1?s=pc&amp;ie=UTF8&amp;qid=1438831600&amp;sr=1-1&amp;keywords=harddrive&amp;refinements=p_n_feature_keywords_six_browse-bin%3A6158683011%2Cp_n_feature_keywords_two_browse-bin%3A6799355011) are pretty cheap, so you could just dual boot to provide total separation. I am currently triple booting. * Windows 10 for gaming * Windows 10 for development * Ubuntu for Linux Development
I would be more than interested in hearing more about clang + c2 integration. Also, is this "just" for Objective-C compilation purposes, or do you have plans for clang as an opt-in replacement frontend for "pure" C++ (c1xx)?
For use with c++, I'd rather use flexc++ and bisonc++ though. Or are there significant advantages to using the original flex and bison? I'm admittedly not sure what the reentrant and pure options do.
with gcc 4.8.3 and -Wall I get: &gt; warning: comparison between signed and unsigned integer expressions with the Visual Studio cl.exe and /Wall I get: &gt; warning C4287: '&lt;': unsigned/negative-Konstantenkonflikt If the Intel compiler has a /Wall flag you should try that, cl.exe does not mention the error on /W4 either. 
what? how can it "go to shit"? What do you do there? what does one have to do with the other? i have 3 os-es installed too on my main machine: win,linux and freebsd. but one win can be used for games and dev, there's no conflict. 
Well, what I mean here is just that C++ is useful to me: many libraries, standard in some industries, and compilable in many different platforms. If you like better your Java, your Python or whatever, I am ok with it. I also use them in the right context. But when it is about long-living portable code that must run everywhere, my choice is going to be C++ almost for sure.
If last year's CppCon is any indication, yes, they will eventually all be on channel9 and youtube.
I'm only familiar with the C++ modes of vanilla flex and bison, but they force an unnatural use of classes and there's no real point since all the flex and bison code is and you can embed your own C++ code in it anyway. Maybe if they were updated to be C++11-compatible, but ...
No, QWidgets are still a very well working and mature solution.
There's also [Copper Spice](http://www.copperspice.com/) the C++11 Qt 4.8 fork :) For the case that widgets get obsolete in Qt. 
What is a "lightweight monadic future"? How is it different in interface to `std::future`?
why on earth did they base it on qt4? qt5 brought a ton of cleanups all over the place, and also c++11 compatibility. and if they want to make sure qwidgets survive, why not just help maintain it in qt proper?
They started hacking on Copper Spice before Qt 5 was released, and I think they didn't want to start over with Qt5. I think the scope of the project is different than having widgets in Qt. They want a modern C++ GUI and Qt won't change overnight. It's easier with a fork. Speaking of forks, there is a Copper Spice [fork](https://github.com/fluxer/copperspice/) which adds CMake support. Yeah!
What kinds of candidates are you looking for, i.e. years of experience, specialties, etc? Is pay commensurate with experience? What kinds of benefits are offered and where in the city is the job? Who exactly is the employer? These are all things a potential candidate would really like to know...
Well, you need several casts in the code plus a naked 'new' to make it work. And then there is a look-and-feel thing...
Well, that is just how Qt is. QML is just hiding that from you. I do write an actual application I need here, so no time to fancy things up with QML. Also where do you see several casts in this code? I only see one static cast, which is due to Qts Model/View system storing fancy pointers (which is IMHO ok btw). When you want to expose data to QML/QtQuick, you're going to use exact the same QModel/View system.
You can start with reading books "Physically-based rendering" and "Computer Graphics: Principle and Practice".
Honestly, I'd start with the [OpenGL 4.0 tutorials at Rastertek](http://www.rastertek.com/tutgl40.html). OpenGL is (IMO) a bit easier than DirectX for a beginner.
he said 3D engine, not game engine
I'd start with this: http://www.rastertek.com/tutdx11.html Skip the setting up VS part: if you install VS2013 or VS2015, it does everything you needed to do manually back in VS2010.
Start with a working vertical slice. A hardcoded, untextured triangle, perhaps. Then add camera controls, then start adding other things from there. Have a milestone scene in mind ( something from http://graphics.cs.williams.edu/data/meshes.xml perhaps ) but whatever you do, do not attempt to write your own importer - you're here to make a 3D engine, not a file parser.
Legacy OpenGL is not a good base for learning. It's completely different from modern OpenGL and will teach you many very bad habits that will be difficult to unlearn when you switch to modern methods (which is unavoidable, because old OpenGL is garbage in terms of capability and performance)
&gt; I do not want to use a library since that would defeat the purpose of learning. You have to decide if you want to write a software renderer or a hardware renderer. The former will let you understand the whole stack all the way down to how polygons are rasterized to pixels, but it will be too inefficient for practical usage. The latter is much easier and faster, but means at some level you're just learning some graphics API. Real-world 3D games today almost invariably do this.
You might want to check out the geometrictools.com website, and [related books](http://www.geometrictools.com/Books/Books.html). The book _Geometric Tools for Computer Graphics_ is very good.
There are two main methods of rendering in 3D: Rasterization and Raycasting. Most modern day renderers are rasterizers. I'd suggest reading up on that if you truly "do not want to use a library". If you go along with someone else's advice, I recommend learning the ins and outs of shaders, as great shaders can truly make your program look fantastic. You can use them to perform custom lighting, reflections, shadows, SSAO, MSAA, HBAO, HDAO, etc. I recommend shadertoy.com for learning to write shaders. 
start with google, tons of tutorials. start with a line. rotate it, stretch it, translate it, turn that line into a square or triangle, do the same. then do it for a simple object like a cube or pyramid. wireframe by the way. yeah, you have done your first 3D. now, find out how to apply texture on a surface. yea!, texture mapping. 
I would strongly suggest watching this video. [The Physics of Light and Rendering | A Talk by John Carmack](https://www.youtube.com/watch?v=MG4QuTe8aUw)
At the beginning
I wrote a software renderer a while back and it was pretty fun and I think a worthwhile little project. It could only draw wireframe but could barf out whatever .obj you fed it. I started here, I think. https://msdn.microsoft.com/en-us/library/windows/desktop/bb206269(v=vs.85).aspx The backend was GDI DIB Sections, writing directly to a texture and BitBlt()'ing to screen. I implemented the matrix / vector stuff myself, and later vectorized it for practice. Here it is before it could even draw lines. 4 corners of a cube. http://i.imgur.com/gV63Rv8.jpg And slightly more evolved. http://i.imgur.com/KeYbin7.png
From https://ned14.github.io/boost.monad/: &gt; What is a "lightweight monadic future"? Predefined basic_monad implementations: * monad&lt;R&gt; Can hold a fixed variant list of empty, a type R, a lightweight std::error_code or a heavier std::exception_ptr at a space cost of max(24, sizeof(R)+8). This corresponds to tribool::unknown, tribool::true_, tribool::false_ and tribool::false_ respectively. * result&lt;R&gt; Can hold a fixed variant list of empty, a type R or a lightweight std::error_code at a space cost of max(24, sizeof(R)+8). This corresponds to tribool::unknown, tribool::true_ and tribool::false_ respectively. This specialisation looks deliberately like Rust's Result&lt;T&gt;. * option&lt;R&gt; Can hold a fixed variant list of empty or a type R at a space cost of sizeof(value_storage&lt;R&gt;) which is usually sizeof(R)+8, but may be smaller if value_storage&lt;R&gt; is specialised e.g. sizeof(option&lt;char&gt;) is just two bytes, and sizeof(option&lt;bool&gt;) is just one byte (see note about option&lt;bool&gt; below). This corresponds to tribool::unknown and tribool::true_ respectively. This specialisation looks deliberately like Rust's Option&lt;T&gt;. By lightweight I mean minimum runtime and build time costs. Nothing fancy is in there, just the minimum. I have a CI counting opcodes generated by the compiler for various common instruction sequences to verify that minimum really is and stays minimum. &gt; How is it different in interface to std::future? tl;dr; It's a drop in for the C++ 1z Concurrency TS and Boost.Thread Futures. Nothing should change except your code goes much faster and you get many fancy new toys. More detail: In exchange for some minor limitations, this lightweight promise-future is 2x-3x faster than std::promise and std::future in the non-blocking case. You also get deep integration with basic_monad and lots of cool functional programming stuff. Unless you use continuations, they allocate no memory whatsoever and entirely rely on your compiler's optimiser to do the right thing. Known deviations from the ISO C++ standard specification: * No memory allocation is done, so if your code overrides the STL allocator for promise-future it will be ignored. * T must implement either or both the copy or move constructor, else it will static_assert. * T cannot be error_type nor exception_type, else it will static_assert. set_value_at_thread_exit() and set_exception_at_thread_exit() are not implemented, nor probably ever will be. * promise's and future's move constructor and move assignment are guaranteed noexcept in the standard. This promise's and future's move constructor and assignment is noexcept only if type T's move constructor is noexcept. * Only the APIs marked "SYNC POINT" in both promise and future synchronise memory. Calling APIs not marked "SYNC POINT" can return stale information, so don't write code which has a problem with that (specifically, do NOT have multiple threads examining a future for state concurrently unless they are exclusively using SYNC POINT APIs to synchronise memory between them). Extensions to the ISO C++ standard specification (and Concurrency TS): * We match the greatly extended API of Boost.Thread's future-promises, this should guarantee very close conformance to future ISO C++ standard enhancements to std::future. Boost.Thread's API extensions are all very useful, and make your life a lot easier. * All our futures inherit from corresponding monads, they are just an asynchronously set monad. * As a result our futures can transport an error_code as well as an exception_ptr. The latter allocates memory and is profoundly slow on some platforms, so avoiding it completely can add 10-15% to some use cases. * You can add as many continuations to future as you like so long as only the first added continuation takes an rvalue reference. Sorry for the perhaps excessive detail. There is far, far more excessive detail at the link above. 
Just a quick caveat: These lightweight monads and future promises pass a conformance test suite but have not yet been battle tested. They should support C++ 1z coroutines and by the time of the Boost peer review, Boost.Fiber coroutines too. I'd be **very** cautious using these in any production code until early 2016, after the Boost peer review.
From Scratch, you want to start here ;) [https://scratch.mit.edu/](https://scratch.mit.edu/)
I am a professional 3D graphics programmer (I write renderers for a living) for a major feature animation studio; I'll try to condense other posts and give you direction. Basically, we need more information. As others have said, like /u/munificent, you need to decide if your engine will be hardware or software based. As /u/evenam said, you need to decide if you're writing a rasterizer or ray tracer. That gives us four main combinations: Hardware rasterizer: This is what most people trying to learn 3D graphics start out with. It implies that you're going to be using OpenGL or Direct3D, which is usually the simplest way to get started. On the bright side, there is a lot of reference on the web for this. This is what game engines are typically written with. Software ray tracer: This is probably the second most common renderer out there. Most college-level graphics course have students implement or modify a simple version of these. These are typically what feature animation is done with these days (path tracing, an extension of ray tracing). The good news is that the basic concepts are quite simple. The bad news is that simple versions are pretty slow to render. Software rasterizer: These are typically very uncommon. Older feature renderers do this (old Pixar Renderman, the DreamWorks renderer). In the professional world, these are becoming obsolete. If you're going to do software rendering these days, it's typically best to stick to ray tracing. Hardware ray tracing: New new horizon. People and companies are having some success in ray tracing on GPUs. There's quite a programming barrier to getting here, though. You have to understand ray tracing and GPU programming -- a tall order for somebody starting out. They're not used much in the feature industry, because for feature scenes we need more memory, and out-of-core rendering is slow (the bus is a limiting factor). /u/nemui_one_zzz recommended *Physically-Based Rendering*. It's the bible of software ray tracing, but it's big and dense. *Computer Graphics: Principle and Practice* is ancient, but it's still my go-to guide when I need transformation refreshers. :) If you want to write a software ray tracer, I recommend *Ray Tracing From the Ground Up* as a gentler introduction.
&gt; Nobody compiles application to one executable that must run with "legacy" DLL like kernel32.dll and with new magical API sets on Windows Phone. Uh, that's *exactly* what people do with the new Universal App model.
yeah but i'm sure he'd like to learn a rendering engine that people actually use, should probably stick to something applicable and relevant to the real world :)
While I'm glad someone is trying to teach people how to do cool apps with C++, I'm really struck by the thought that it's still such a low-level way to do a GUI/Application. I know QT has some nice higher-level features, but honestly, I remember doing a lot of stuff like this in OWL and MFC twenty years ago. It's sort of depressing that C++ tooling is still so far behind i.e., having to discuss static casts, pointers, and memory allocation just to get a UI running. Really, having to deal with any of this at all, some 20 years later. There should be a better way!
Better git integration: - Force push - Squash commits Option to set default file encoding for new files(I want my files encoded in UTF-8 without BOM!!!) Set file encoding for entire project all at once Format all documents all at once
&gt; My fondest wish is for *reasonable user expectations*. Fewer crashes...? Oh, oh, oh! Syntax highlighting for build warnings and errors. With templates, and for a while now, in many cases build output has become completely un-navigable...
How would you implement / refactor Qt today: * use TMP (libsigc?) instead of moc * use std::shared_ptr / std::unique_ptr without calling raw `new` * use namespaces * use standard containers (std::vector, std::map etc) * use std::regex * use std::thread, std::atomic&lt;&gt; * use exceptions But what about tomorrow? * use modules * use reflection instead of moc * use std::filesystem * use std::network I know Qt has to support lots of compilers, but even if you have the compiler support you still need to modernize your code base, which requires lots of engineering time and willpower.
Be able to compile range-v3 :-) But it looks like that's already on the list for Update 1.
both!
Support for [range-v3](https://github.com/ericniebler/range-v3) would be my big one, but I realise that's likely not within the realm of reasonability.
 I also have performance regressions from 2015-&gt;2013
Clang, I guess. There was this whole thing about being able to use clang for mobile on VS, but I still have no idea how to use it on Windows applications, if it's even possible.
Wasn't VS2015 the one with the refactored CRT in C++ with increased performance? This should explain the improvement for atof. Will have to wait for the C++ library to be improved :(
I really wish this project can keep on. I known Gradle started integration for C++ a while back, but I believe they have an another philosophy about using xml.
await
We're very close to being done with C++11. There's Expression SFINAE, which we've promised in an Update (not necessarily Update 1). The others are overhauling the preprocessor and implementing two-phase name lookup. In particular, two-phase will surely break nonconformant code, so it's unclear whether that could be shipped in an Update. The road to C++14 is longer, mostly due to C++14 extended constexpr.
&gt; It's completely different from modern OpenGL No it is not, I wish it was. General concepts like states, blending, depth test, stencil test are the same. Texturing is exactly the same as well if you do not consider GL 4. There are 2 things that are really different: 1) fixed pipeline vs shaders, and 2) immediate mode vs VBO. 1) In my experience most beginners struggle to learn transformation matrices and combination. I believe that the old matrix stack is a good concept to grasp how they work. Also no beginner should write GLSL code *on top* of the usual GL initialization, to setup an HelloTriangle program. Also note that GLSL is available on the legacy API, so you can transition from the fixed pipeline to the modern one gradually. 2) VBO exists even in GL 1 as an extension, and you are going to use that extension quite early in the learning process. I am not saying "you should not learn modern OpenGL". Modern OpenGL is a must and the legacy one sucks anyway. I only believe if your start from zero, it is way easier to start from the legacy API.
What you're seeing is a regression from 2010 to 2012 in iostreams floating-point parsing. I know what's going on, but I'm going to need a major version to fix it (can't mess with this stuff in an Update). This is one of the bugs I feel really bad about. :-/ Can you file bugs with repros for the non-iostreams codegen regressions you're seeing? The back-end devs will investigate, but they need repros.
Would you happen to know whats happening here: https://llvm.org/bugs/show_bug.cgi?id=23327
We're switching databases internally, so Connect may be even more "fun" than usual. Consider using Send A Smile, which should hopefully be easier.
It's on the front-end devs' list of stuff to implement. Oh yeah, and I forgot about C++98/03's dynamic exception specifications. It's not very likely that they'll ever be implemented in C1XX, but fortunately nobody cares, since they were deprecated in C++11 and superseded by noexcept. It's possible that they'll be removed outright in C++17.
I don't know if we've talked about the shipping vehicle yet. I'll let Steve answer this.
&gt; memory allocation when you use Qt, the `new` is pretty much java's new; if your program is well-formed (every QObject-descendant has a parent), you don't need to delete anything, memory is managed by the framework.
One option we have a lot of success with is [IncrediBuild](https://www.incredibuild.com/).
Or turned it into a single line comment
Or turned it into a single line comment
Improve refactoring capabilities further - make it so that when you rename a class, its containing .h and .cpp files are renamed as well
Are VLAs in yet? If not, then VLAs.
Well, Qt is kind of the JDK for C++, its major parts are old, and also Qt Quick is just adding a layer on top of this, once you need to use C++ your code will not look much different... And ofc it would be nice to have a modern C++ UI Framework, an alternative to Qt, wxWidgtes or Gtkmm... But doing crossplatform UI is really hard.
Stability and polish. VS 2015 crashes constantly and it's just not usable with my setup. It literally crashed 6 times the first day I tried using it. I'd also love quick a way to minimize all projects in solution explorer. When you have 140 projects it gets really old re-minimizing all of them after they all expand for whatever reason. I rarely try to find files in the solution explorer, since there are so many, but I do need to adjust project settings, set startup project, build only one project, and so forth. But all the features in the world aren't worth much if the product isn't stable. 
That would be great; then I could run clang-modernize.
Full C++11 support.
Re the two-phase name lookup: what will break exactly? Do we have to insert `.template` and `-&gt;template` etc. in the appropriate places (which I remember from porting VS2010 code to g++ a few years ago), or is it also possible to get *silent* breakage because different functions are found and run?
I want to see it working :) Right now it crashes whenever I create a new project.
&gt; use TMP (libsigc?) instead of moc TMP signals are nice but you should know it's not possible to use them every time. For example when you want to connect to signal from QML component TMP will not work as there is no C++ code to connect from.
I'd suspect something else in your setup. I've been using it continually through various CTP's. While I've had occasional crashes, I could count them on one hand over months.
I would say the core abstraction is the so called "scene graph", see Wikipedia, the easiest is to depend on openGL below. Internally you should benefit from the trick of working in homogeneous coordinates, where you can represent rotations and traslations in R^3 by a single linear operation in R^4. To each node in the graph (tree) you associate a 4x4 matrix and they support the kinematic primitives. In the leaves you have a triangle mesh. You compound (multiply) the matrices from the root down to the leaf with the triangle's vertex coords before rendering to move objects in space (more or less, see [1]). And you import you triangle meshes from a given asset format, easily a wavefront OBJ file. A further homework would be to read the MTL materials sidecar file, get the diffuse maps file names and create the textures in opengl. Depending on your objectives, you could drop classic opengl and go for a shader only, all GPU implementation, that would be harder but valuable. The hot new thing would be khrono's Vulkan. [1] http://gamedev.stackexchange.com/questions/64303/what-are-the-semantics-of-glrotate-and-gltranslates-parameters
Fix [this](http://www.boost.org/development/tests/master/developer/output/teeks99-08l-win2012R2-64on64-boost-bin-v2-libs-multi_index-test-test_key_extractors-test-msvc-14-0-dbg-adrs-mdl-64-thrd-mlt.html). More generally, make Boost test suites part of your regression codebase.
Yes, but I doubt that I can do everything I need to do in QML. Plus that I have to deal with all kind of issues concerning QML/QtQuick instead just C++. I've used widgets for years, its a good and mature solution to build UIs in. I do write an actual application here, I'm much more productive in QWidgets, so its my choice to use it.
You might want to look into LLVM. The are working on a Windows version of Clang which targets the Microsoft ABI.
I'll go against the grain here and ask for some things from the future - support for some C++17 experimental TS features maybe? I'd love to have current_location, string_view, observer_ptr, memory_resource, search/sample, optional, uniform container erasure, etc. etc. Sigh, a man can dream, can't he?
If I had a choice in the compiler that might matter.
I would very much love to have a warning when a method is overridden without having override specified. The C++11 override keyword is great to express the intention to override a method but there is no support for cases where you accidentally override a method especially since you don't need to make it virtual. A warning would catch these cases as well. It's a feature I have been using in Java now for several years and I really miss it in C++. 
First just let me preface this with the fact that I'm pretty biased; I learnt C++ from the appendix of "C++ GUI Programming With Qt4", and most of the c++ code I've written has been using Qt. So feel free to correct me, I pretty recently (well, last 3-4 years) started doing significant things without Qt, but there's still a ton of things I'm ignorant about. &gt; * use TMP (libsigc?) instead of moc &gt; * use reflection instead of moc Well, the maintainer of moc actually wants to drop moc in favour of just standard C++, but apparently that just isn't possible yet (it's a bit over my head, though, I'm a simple soul): http://woboq.com/blog/reflection-in-cpp-and-qt-moc.html &gt; I know Qt has to support lots of compilers, but even if you have the compiler support you still need to modernize your code base, which requires lots of engineering time and willpower. Exactly, that's why it's surprising to me that someone instead of actually helping the other people working on Qt to modernize it, they went with their own fork. As for some of the other points you have, it seems to be a pretty common feeling that the Qt APIs are better than the STL one. A couple of the Qt people literally wrote [one of the most respected books on good API design](http://www4.in.tum.de/~blanchet/api-design.pdf) after all, it is used in various university courses, etc. So I guess removing the "duplicated" libraries/classes are probably a bit hard to do in Qt, apart from the technical and engineering effort reasons. Personally I don't really think that all the Qt APIs are better in every way, but they do usually lend themselves to very readable code (which I think should be one of the highest prioritized issues when writing code in general), even if they sometimes lead to suboptimal performance or just plain bad design. Lastly, Qt does have attempts in some places to integrate with the STL, but it could be much better. So again I wonder why people just didn't work on improving this so people can pick and choose what parts of Qt and the STL they prefer, instead of forking.
Does anybody from Qt (maintainer of moc, or somebody else) actively participate to `SG7, Reflection` making sure that the next C++ standard will actually replace moc? I assume it's not easy to hack gcc or clang to do what you want for a moc replacement. From what I've seen others have tried to implement reflection and the Qt guys are testing to see if it works.
Another reason would be VMs for continuous integration or a nightly build. On such machiens you seldomly need the whole IDE, just the toolchain is enough.
what is the advantage over [`WriteCompilerDetectionHeader`](http://www.cmake.org/cmake/help/v3.2/module/WriteCompilerDetectionHeader.html)? 
The flip side is also true - allow the Visual Studio compiler/linker/debugger to be used from other IDE's. Right now you can use makefiles for build and link but there's no way to access the debugger from the command line.
So, is there any primer somewhere that would explain how to use the feature in order to test it? 