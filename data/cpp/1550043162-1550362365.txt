&gt;or whatever else you can imagine I dunno, I can imagine quite a bit. :) The SaferCPlusPlus library (shameless plug) provides non-owning (smart) reference types (pointers, iterators, string\_views, spans) that work in concert with smart owning pointers, containers and/or transparent object wrappers to prevent this kind of use-after-free via either compile-time restrictions (similar to Rust) or run-time checks. For example, vectors can be ["size locked"](https://github.com/duneroadrunner/SaferCPlusPlus#make_xscope_vector_size_change_lock_guard) while (smart) references to any of their elements are outstanding. But of course your point is valid.
You thought this was an argument? I was just seeing how far you would dig in to a nonsense position.
I don't think the concern is "there is a loop in this code", the concern is that there are unconditional exchanges and thundering herd problems here. Good synchronization primitives like SRWLOCK combine both the optimistic spinning bits and any actually blocking bits into operations on the same machine word.
Forget what I said. I didn't have coffee
This auto-reset Mutex, does not have a thundering heard problem. You really need to study it some more, wow. Btw, where can you find a read write mutex that has no loops in the code? Try to find one. If you cannot find one, I can help you out.
I'm not sure now either... I just don't think that implicit casting is the entire issue. As in, even with it in the language, deduction of return type could still be possible. I lost the train of thought though, so can't argue for it well ATM.
JUCE is great, I'd just point out that I think it is not accessible at all.
Meanwhile I just have a template wrapper struct that implements a begin and end method and takes two iterators as construction params. You can traverse with any iterator pairing you please but, break, continue and don't have to deal with iterator syntax in the loop body. The best of both worlds.
Sure. I didn't mean to say that you can't have safe referential objects in general (weak_ptr being an example from the standard library and the debug implementation of std::vector in msvc also tracked iterators if I remember correctly). Just that almost all types you find in the wild - even in relatively modern c++ codebases - aren't. 
My last benchmarks were under MSVC2015 for it. The `try_realloc` form won handedly.
So true! Using template specializations with dlls are a pain! Clang for example forbids [[gnu::visibility ("default")]] for template specializations, gcc doesn't work with __attribute__ ((visibility ("default"))) if another attribute is used, msvc requires __declspec(dllexport) for specializations while gcc forbids it. I really hope for standard to at least try to solve these problems.
\*\*Company:\*\* [GOG.com](https://www.gog.com/work) (part of CD PROJEKT Group) \*\*Type:\*\* Full time \*\*Description:\*\* [GOG.com](https://GOG.com) is looking for passionate Software Engineer to enhance our extraordinary team, which is working on the GOG Galaxy platform. *Responsibilities:* * Shape and develop ambitious features for GOG Galaxy, combining networking, gameplay and community, experienced by millions of gamers. * Develop and own major features in the GOG Galaxy SDK. * Implement performance measurements, testing strategies and optimizations. * Work with other engineers in SCRUM methodology and mentor team members. * Stay abreast of emerging new technologies, research new tools and implement best practices. *Job requirements:* * Proficiency in C++ with proven years of experience. * Deep knowledge of network protocols and communication (TCP, UDP, HTTP). * Experience with the client-server architecture. * Basic Python knowledge. * Knowledge of software development best practices (version control, testing, deployment etc.). * Knowledge of network and server security issues. * Fluency in spoken and written English. * Passion for gaming, game services, and online communities. More details [here](https://www.gog.com/work/software-development-software-engineer-sdk-c). \*\*Location:\*\* Warsaw, Poland (we provide relocation package) \*\*Remote:\*\* No \*\*Visa Sponsorship:\*\* Yes \*\*Technologies:\*\* C++11 (soon c++14/c++17), boost, google test, multi-threading, networking, multi platform support \*\*Contact:\*\* please apply directly through our [website](https://system.erecruiter.pl/FormTemplates/RecruitmentForm.aspx?WebID=cfb71fa9bf9a4fa6a5fc717ea0c40d7b) or contact kolkowska\[at\][gog.com](https://gog.com) for more questions 
This? https://github.com/vukis/Cpp-Utilities/tree/d9db16f638df24ac37a5997a6628ea8929561308 http://sean-parent.stlab.cc/presentations/2016-11-16-concurrency/2016-11-16-concurrency.pdf
Yep, that's the one. The talk is on YouTube too: [link](https://youtu.be/zULU6Hhp42w)
I vaguely remember Robert that you *did* remove some of the dependencies, or rather, you made them macro-optional but with the default to enabled. Am I wrong on that? Outcome is no different. It is dependent on Boost.System, but only if you use `&lt;boost_result.hpp&gt;`. If you don't use the headers which use Boost, then there is no dependency on those parts of Boost. Thing is, automated scanning tools won't and can't realise this. And to my best knowledge, Boost is vastly more cleanly separated and more modular than it was five years ago.
TransferWise made it cheap, but it was always easy if you were willing to pay. A long time ago I used to use the banks in the Isle of Man. For a monthly fee, they'd set up a US dollar denominated account fully routed into the US. I later found out that the RBS family of banks can "mount" your EU business bank account with numbers on the US ACH system, you just need to go ask and pursue the paperwork. However RBS recently trebled their monthly account maintenance fee, hence me recently moving over to TransferWise and Fire.com, I'm closing my RBS business account, too expensive now. Also, I really like how in TransferWise I don't have to accept their conversion from US dollars, I can use a currency auction house like CurrencyFair which drops the cost significantly. Fintech is really great!
How would that even help with e.g. vector iterators? The objects NEEDS to leave its current place, there's no other way.
It was an intentionally absurd comment. Like you could block any reallocation or moves of items that have iterators to them. But it would be worse than useless
&gt; But that changes a lot in terms of "social insurance" payments, or does it not? I mean things like health insurance, unemployment insurance payments, state pension payments, etc. Lots of this is mandatory by the state in many countries, where the employee pays a couple of percent, and the employer a few percent. The state in which you are employed gets fully paid its taxes in full. Your self incorporation will pay the employer's side of the taxes, and withhold the employee's side of the taxes at source. So the EU country is fully paid, and thus are happy, and you get all your fancy EU social benefits. &gt; Because with the B2B relationship, it's not employment anymore, but contractor work? And on top of that, isn't that also illegal in many EU countries, i.e. if you're contracted by a company 100% effectively you need to prove that you are an independent contractor and are free to work when and as you please and are not essentially an employee of the company, managed by them. There is a "U shape" on this sort of employment relationship in the EU, so basically people at the very bottom and at the very top tend to be employed under B2B contracts. Most of the pressure comes on the exploitation at the bottom, and rightly so. Much less pressure comes on the tax avoidance at the top, partially because there are relatively few people doing this at the top, and a lot of them are celebrities of some form, so it's politically risky. But no, it's not illegal in any EU country. And at the upper pay range, very common. Indeed the EU wouldn't have invented single person incorporation if it were not. You're right that you can't take the p*iss. Doing stuff like working for the same employer, onsite, wearing a uniform supplied by them and working the hours they tell you is obvious disguised employment. But at the upper pay range, most work in the knowledge, entertainment or sports sectors. There are no fixed hours, no uniforms, often where you physically work varies, or you work remotely. You definitely direct your own work, it's why you get paid so much. Most tax authorities look leniently at the latter. It is felt if they clamped down, people would simply move country and the income to the country would be lost, as well as the valuable worker to that country's industry.
Company: [Loki](https://loki.network/) Type: Full Time Description: Loki is an open source, fully funded project aiming to develop a censorship resistant mixnet with an end-to-end encrypted messaging service built on top of a privacy centric cryptocurrency. We are mostly comprised of C/C++ developers who work on the core of our product. We are looking for a Senior C++ developer with experience in project architecture aswell as a strong understanding of Blockchain, a research or Mathematics background is also a plus. The right candidate for this position is experienced, creative, and is passionate about privacy preservation. Particular proficiency in any of the following areas is desirable, but not a requirement: • Strong Mathematical or Computer Science background • Large project experience (especially in architecture) • Experience with Distributed Networks • High level of working C++ experience (5+ years) • Low level understanding of ECC systems, High level understanding of Ring signatures, RingCT, NIZKPs, SIDH • Mixnet development • Open Source Projects/git Location: We have our office in Melbourne, Australia and have a strong preference for relocation of any candidate to our Melbourne office, we also have the ability to sponsor or relocate the right candidate as part of their employment contract. Remote: No Visa Sponsorship: Yes Technologies: We have a wide breadth of technology, mostly we use C++ and work on the Cryptonote code base, projects outside of Cryptonote are still C++ and networking heavy like Lokinet our internet overlay protocol. Contact: PM me on reddit 
Doesn't this prohibit inlining (if you don't use LTO)? I guess for classes like `optional` you really want to inline.
&gt; TransferWise made it cheap, but it was always easy if you were willing to pay. I see! Yes I guess that's kind of what I meant. As a business customer it was perhaps always possible but with ludicrous fees. Now it's also accessible to the lesser mortals. Thank you for the other pointers in your comment! TransferWise uses the mid-market rate for conversions with a very small fee (0.35% or so I believe?) - can you really get better rates with CurrencyFair?
&gt; The state in which you are employed gets fully paid its taxes in full. Your self incorporation will pay the employer's side of the taxes, and withhold the employee's side of the taxes at source. So the EU country is fully paid, and thus are happy, and you get all your fancy EU social benefits. Oh right! I see! Yea that makes complete sense of course. So you just have to charge the abroad company that employs/contracts you a higher salary accordingly (like 10-20% or so), because your one-man-company has to pay those social benefit payments. I see - very nice explanation with the U-shape. I completely get what you're saying and it makes complete sense. Thank you very much for explaining so well and for your insights, it's very much appreciated!
This implementation seems ok to me, and I will probably use it for testing some game dev project I have in mind. However, you are checking loits of times if the component has been constructed or not: void create(const Args&amp;... args) { if(components&lt;T&gt;.constructed(id)) // Constructed Check { components&lt;T&gt;.destruct(id); } else if(components&lt;T&gt;.size() &lt;= id) { components&lt;T&gt;.resize(id+1); } hasMask[id] |= typeBitID&lt;T&gt;; assert(!components&lt;T&gt;.constructed(id)); // Constructed Check components&lt;T&gt;.construct(id, args...); // Constructed Check (inside the function construct) } ... void construct(const size_t i, const Args&amp;... args) { assert(i &lt; m_size); if(constructed(i)) Constructed Check { destruct(i); } new (&amp;m_buffer[i]) T(args...); m_constructed[i] = true; } I do not thing those many checks on creation are needed.
Yes, I'm fairly sure all the talks were filmed and will be on YouTube soon. A couple of talks that stood out to me as really worthwhile: * "Oh, the humanity!" by Kate Gregory * "Writing well-behaved value wrappers" by Simon Brand
What do you - in general - think about the suggestion made by Robert Schumacher at cppcon2018 where he suggests to encapsulate optional functionality into separate libraries instead of configurations via `#ifdefs` and build script options? E.g. in case of Boost.Outcome there would be two logical libraries: Boost.Outcome and Boost.Outcome_with_result, the latter depending on the former and Boost.System (Just using Outcome as an example to demonstrate what I mean - not suggesting you actually do that). I'm not quite sure if that would work out in practice, but it is certainly an interesting Idea. (Ref: https://www.youtube.com/watch?v=sBP17HQAQjk). One thing I would personally whish for boost is that libraries with different versions that are maintained in parallel (e.g. thread and spirit) would split those versions into actually distinct libraries like coroutine and coroutine2 or signals (now removed) and singals2. But I don't claim to know about all the possible welcome and unwelcome side effects this would have. 
I have interesting in the word "decentralized", can you elaborate a little how it works? Or my some specified questions, 1. Is you application working in trusted or untrusted network? If it's trusted, just ignore the second question :-) 2. So if it's untrusted, how each node validates the config file? If it uses digital signature, then all nodes have to know a single public key from a trusted administrator? Then it's centralized. 
Right! I am also looking forward to the talk by Kate Gregory. I think she's a great speaker and the topic also sounds quite interesting.
I'm hope the Low-latency C++ workshops were recorded. 
&gt; I can believe that it'd be common for a heap to maintain some extra space after an allocation we might be able to borrow Personally it seems to me like the "right" way to handle this would be to standardize [`malloc_usable_size`](http://man7.org/linux/man-pages/man3/malloc_usable_size.3.html) or something like it; or even better, have some `spiffy_new` operation that returns pointer and usable size. In theory `try_realloc` could still be helpful in case the whole reserved *block* is smaller than it could be, but I wonder how often that would actually be helpful. Maybe once you pop out of the smaller sizes where typical malloc implementations group allocations of the same equivalence class in terms of size and gets up to `mmap`ping whoe blocks or something? Or for platforms where malloc doesn't do that?
The rpoblem I see with this is: The c and c++ communities (at least the vocal parts of it) have a very low tolerance for runtime overhead, so I don't see this happening in mainstream / standardized cpp. Also, I think if you introduce a new language with dynamic checking you very quickly end up in a situation, where using a GCed language without raw memory access is the more reasonable thing to do in the first place. 
Firstly, I wasn't aware that Transferwise have dropped their fee to 0.3%. That changes things a lot. If you're willing to be patient, and let the conversion happen in dribs and drabs over a week. I've gotten down to 0.15% before on CurrencyFair. But it can take over a week, and that can be irritating. But Transferwise at that low fee rather changes things, unless you're converting 100k or something. And even then, you're only saving €200 to have to wait a week. For smaller amounts I'd say Transferwise is fairly unbeatable right now at that price.
ok thanks
Well, it's more the case that the foreign company pays you what they pay you rather than paying you extra. Sometimes you can persuade them to pay you at their gross cost, but many want to pocket the savings of not paying local social security taxes, health insurance etc. And that's fair enough I think, both parties win something for the cross-border hassle. The biggest gains from self incorporation are mainly income deferment into your own choice of a pension, and avoiding 20-25% sales tax for business expenses. It's worth a nice bump in effective pay over being a conventional employee, but we're talking 10% or so here, not 50% or more like a lot of people assume. In some countries like Ireland, self incorporation is worth vastly more to trade businesses than to service businesses. They get far more tax deductibles. We service businesses, meanwhile, cannot keep any money in the business across a tax year. It all must get paid out. This creates a cash flow crunch every January, which typically is also exactly when annual taxes must be finalised, so every January I must take out a bank loan for two months. But that's business for you. The system is stupid, but it could always be worse.
I agree that ifdefs are brittle. If you can replace them with specific inclusion headers, that's much better. However before C++ 11 the language made that much harder, hence the proliferation of ifdefed support in Boost. In terms of splitting libraries into "core", "boost_fascade", "std_fascade", I would be opposed. The fascade libraries are about twenty lines long. Barely worth calling a library. In terms of making three C++ Modules for one Boost library, that's much more interesting. I already have three single header inclusion editions of Outcome. And each Module would have different dependencies, yet be (hopefully) compatible with one another. I guess I'd need to see it in action first. And without ICEing the compiler, as Outcome currently does in MSVC's case.
Absolutely amazing questions, I would like to Know as well.
The C++ standard does not believe in shared libraries.
I actually did some tests on it, for the most part it vectorises pretty well! I've not used EnTT much, but do really appreciate it and hope to use it more. Thank you for your work! Any plans on adding an execution policy to the each() member functions? I know i can just use for_each with the policy, but the lambda looks and seems to perform better with out the view::get() calls. They seem to make it hard to vectorise. I made an overload for the single component view to accept one and it works great, just can't figure out the multicomponent one just yet.
For those interested, you can still find the slides on GitHub: https://github.com/philsquared/cpponsea-slides
Yeah, I plan to add built-in support for parallelization in future. Btw EnTT is a free time project, so it could take a while.
And here is the source code of the current implementation: [https://github.com/stlab/libraries/blob/develop/stlab/concurrency/default\_executor.hpp](https://github.com/stlab/libraries/blob/develop/stlab/concurrency/default_executor.hpp) Starting line 181. It is the fallback in our library, when the OS does not offer a thread pool.
Sure modules have to support realistic use cases, but it is a fallacy to believe that modules will provide any significant improvement over the current situation if we require them to support all kinds of existing code and project structures without modifications. I'd much more prefer if the modules design was optimized for future usability, efficiency and simplicity than ease of transition, but I know I'm pretty much alone with that opinion.
In principle there's no difference between a static library and a dynamic library that is linked with the exe at link-time. Both provide symbol definitions to the linker. `LoadLibrary`is another can of worms though.
&gt; msvc requires __declspec(dllexport) With MSVC you can use module definition files for export without declspec. Though, you have to list mangled names which makes it a bit cumbersome unless automated. Maybe the same is achievable with linker scripts for gcc/ld.
It wasn't. Source: a colleague that attended it. (Mine wasn't recorded either, so I suspect that is the case for the other two as well. If you want to capital-K-kown I can ask two other colleagues as well.)
For fuck sake 
That keynote was excellent. As was the opening keynote by Kate Gregory. There was definitely a camera set up at the back of the main hall, where Godbolt's talk was held.
I have also experimented with this on my employer's (huge) code base. My experience was in line with what /u/vector-of-bool commented, object size and link times improved, but compile times did not. I think the reason is that even if the compiler sees an `extern template` declaration, it still compiles the whole thing, but does not generate code. How do I know? Create e.g. a class template with a function that uses the default constructor of the template parameter, and mark the instantiation extern with a class that doesn't have a default constructor. The compiler will still complain about the missing default ctor, even though it should not instantiate it. See: [https://godbolt.org/z/\_WgSUn](https://godbolt.org/z/_WgSUn) So if you have an `extern template` that is used in 100 translation units, it will still be parsed, semantically analyzed, etc. a 100 times. This is a goddamn shame, as this would be a huge opportunity to reduce compile times. Does anyone know why it's this way?
capital-K-kown? 
[P0894](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0894r1.md) has an option (inspired by [N2045](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n2045.html)) to do \`expand\_by(preferred\_size, min\_size)\` which should give us the best of both approaches, i.e. deferring reallocation until it is really needed, and geometric growth to ensure amortised O(1) allocations
gah! capital-K-know, not kown... An author uses "capital-D-dragons" is live Q&amp;A sessions to distuingish between the asian cosmic entity type of Dragons and their pale europeon imitations. (The Dresden Files contain both types of dragons.) I felt like writing it like that because, well, capital-R-reasons. Anyway, I'm weird. Have a nice day!
How is that better than Ansible?
Can you please explain, what are the biggest flaws in your opinion?
Are you detecting when a thread pool isn't available? Or is it just hard coded (libstdc++ on Linux doesn't, msvc on windows does, etc)?
While tangential, `shared_ptr` being required to be atomic has always made me sad. It means that you can't reliably implement `release()`, and thus `shared_ptr` is viral (you can never pass ownership elsewhere, like `unique_ptr`). As far as being non-atomic goes, I'm not sure... I'll have to dig up some code we had where used `shared_ptr` to implement a conservatively scoped singleton. IIRC, at some point we realized there was a race condition and had to put a mutex in that code. Wonder if it's at all related...
I take issue with the use of “reliably”. Release will always release. You might not be comfortable doing it due to the semantics and use-case of it. But it is definitely reliable. 
It is hardcoded. Mac, Windows, PNCL and Emscriplten have one. For all the others we use our own implementation. But ours has the limitation, that it does not oversubscription, so if one has 4 cores and 4 tasks wait on a mutex, then the system is in a deadlock. Here is a great talk about all the problem of designing a thread pool: [https://channel9.msdn.com/Shows/Going+Deep/Inside-Windows-8-Pedro-Teixeira-Thread-pool](https://channel9.msdn.com/Shows/Going+Deep/Inside-Windows-8-Pedro-Teixeira-Thread-pool)
Keep in mind this is only about the reference count. Changing the internal state always requires synchronization unless the special "atomic" implementation is used.
This is designed for untrusted environments. Idea behind libdinemic is to adapt X509 to objects in applications code. Also it was a bit inspirated by blockchain, but I think, that X509 and git are much closer technologies. In a nutshell seciruty here is based on public key cryptography, hashes and digital signatures. In a bit more details: In general, each object you create in ORM (for example file or administrator) is getting its own pair of keys - one private and one public. ID of such object is also generated from hash(public key). When you create one object, let's say ConfigFile from above rekonf example, it sends a message with its details over multicast to all neighbors (however it depends on configuration, neighbor could be anywhere in the Internet). One of information in such message are ID and public key. Then everybody know such object with its key and add this information to local databases. Then, any change related to this object's fields creates digitally signed update. Everybody on network could verify them by object's public key. Updates with invalid or no signatures could be rejected. To manage privileges on each mapped by dinemic ORM object, you can add list of other objects which are authorized to make updates and/or encrypt theirs data to protect it. Finally chain of such updates of changes on any object could traverse network any time. If your node is not present, when you create changes in network, it could receive such changes later, as copy from other nodes. Also if such node is not accessible directly from your machine, updates will be copied by other intermediating nodes. Nobody is not able (or shouldn't) to forge such updates unless you will not compromite your private keys related to objects created on your machine. And finally - when you create Node entity on remote machine, you (or somebody else) should add there your Admin's key to authorized keys to be able to modify that node. The same is with configuration files.
Ugh, linux-style loading of .so files is the worst. Who the hell thought that overriding any function in a program by loading dll is a good idea? Now you can't for example statically link python in your application and allow user to provide external python3.so to load because of name collisions.
For ansible you have to get direct connection to node, where you make updates, or that node has to connect some central service. This application is some kind of demo for dinemic framework, which I developed recently. This is rather git with public key cryptography and digital signatures, that applies changes to ORM mapped objects. And from perspective of functionality - this allows to make basic updates, Ansible is Swiss army knife :)
It didn't believe in filesystems and threads but look where we're now. There's always hope)
&gt; encapsulate optional functionality into separate libraries That's exactly the approach that was rejected years ago which I was trying to make happen. It was done for some boost libraries, but it's up to the maintainer to some extent.
Just a random quibble, but does it make sense for a multithreaded queue to have size() and empty() functions? I feel like there is no way a client could use for any real logic without creating a TOCTOU bug. Something about interfaces that are difficult to misuse . . .
&gt; each object you create in ORM (for example file or administrator) is getting its own pair of keys Then a malicious node (if there is any) can create a config file with virus (or just `rm *`, for example) and spread it to the network? Maybe because I'm thinking about blockchain too much so I didn't understand you.
Unit testing has been most useful for me, when trying to design my interfaces. 
“A bit cumbersome” is a rather reserved way of saying it. I’d say that a more open personal attack would be warranted: some people are insufferable, and some of those people happen to be very intelligent and happen to sit on standards committees…
At least to imbue is just English, even if perhaps not very common English. Its use is reasonable. 
If your tests don't cover all valid (alternatively all invalid) scenarios in the problem domain it doesn't ensure much. It might cause you to ponder the problem space a bit more and thus capture a few edge cases that you might not have thought about otherwise, but that's about it. Then it completely depends on what paradigm you're developing; e.g. if you're working with pure functions it's quite handy; but if you're working in a code base where bugs often may result in side effects that extend beyond whatever class you've developed tests for? Not as useful. Or if you're working with a constantly changing code base and someone forgets to update a unit test properly, then it's pretty useless as well. IMO, planning the design thoroughly before implementing it and sticking to good design principles, idiomatic code and mature libraries is time much better spent in most scenarios.
Yes and no :) This update with virus will reside in databases, but won't be applied to local files. Here is how it works: 1. you create admin - and his cryptographic keys 2. you create node - and its cryptographic keys. Then you add admin's ID as trusted object of this node, so any change made by that admin will be accepted 3. you create file - again, you get file keys and add admin + node's ID as authorized objects to modify this node Finally only you as admin can modify this file and assign file to node. Any other admin, unless is not added to node, is not able to modify contents of that file or assign new file to node. Additionally file content's are encrypted, so only admin and node could decrypt it. If anybody wants to put there virus, he should encrypt it with file's key (intermediating common symmetric key, available to decryption only by file object and read authorized objects). Then you should sign this by private key of one of authorized objects - attacker won't have such key unless it is not stolen from admin or node. Above is theory. For implementation you can check it there, in listener: [https://gitlab.cloudover.io/dinemic/rekonf/blob/master/listeners/monitorfilechanges.cpp](https://gitlab.cloudover.io/dinemic/rekonf/blob/master/listeners/monitorfilechanges.cpp) Methods of such classes are called each time any object in DB is updated. Methods on\_update and on\_updated. By throwing exception in on\_update you can cause that update won't be applied to your local DB. Going ahead your question - attacker might make large mess in sending a lot of fake updates with wrong keys or unsigned, but should not be able to modify protected areas.
That's quite clear, thanks for the elaboration.
I think we have a more efficient way to specify capital letters in writing, by the way...
The general rule is that the (final) draft documentation does not differ significantly from the final spec. It's what a draft is for, after all. It'll be fine for whatever you're trying to do with it. I don't know about being able to get the official one for free as a student.
That's what I thought. Thanks for the answer. ;-)
Ok, I see your points. Well, first of all, where did you get feeling that unit testing promise bug-free code? As you state it's might help to capture a few corner cases - it's better than nothing. Now let's look at the talk title: "How to write **mode** reliable code". I think code which is covered with some tests is indeed more reliable than code without them. Comment by /u/Sjeiken states that unit testing is flawed by *design*, as if they are not fulfilling their purpose and he didn't mention what exactly it is. And think it is a debatable topic. &gt; but if you're working in a code base where bugs often may result in side effects that extend beyond whatever class you've developed tests for? Not as useful. To me, it sounds like an architecture problem and as you write later: &gt;IMO, planning the design thoroughly before implementing it and sticking to good design principles, idiomatic code and mature libraries is time much better spent in most scenarios. Unit tests might help to enforce good design. When you writing new code you always (IMO) should ask yourself - is it testable? And if it is not - there is something wrong with your design and you should fix it. If you will write like this you will get a better design of system inevitably due to the side-effects of testability of your code: loose coupling and small clean interfaces. When you will try to write unit tests for your classes (especially if you develop some library code) - you will encounter first with all your design decisions and will suffer from them - that's the signal to fix some mistakes. And I think after some time and experience with this concept of testability in mind - you won't be needing to write tests as much as in the beginning. These questions: "Is it testable? Is this class are doing too much? Should it really depend on this thing?", etc - will help a lot. 
If I wanted efficiency I would have written it in C++, not English :p
The `std::make_shared` optimization (which allows the object being shared and the control block) already makes a hypothetical `release` unimplementable.
Sorry, I totally forgot about that :[ Give me 24 hours and I will post the ticket.
Please format code with 4 leading spaces
&gt;Or if you're working with a constantly changing code base and someone forgets to update a unit test properly, then it's pretty useless as well The problem here is you allow committing of code that doesn't pass unit tests. Why would you do that?
If binary size or compilation time are a concern, then monitor and control those things directly, as many things can contribute to both. A blanket ban on templates (or any other language feature) is never the right approach - it's lazy, wrong-headed, and removes utility, performance and correctness.
It keeps removing the spaces. I edited but it removed the spaced again.
You don't need 3 variants of `make` in your `Maker` - `std::shared_ptr` is constructible from `std::unique_ptr`. And if you absolutely need an owning raw pointer (like in `Maker::make`), you can call `std::unique_ptr::release` (this should be rare).
I think this is strange. The _storage member of struct factory will store instances of your added classes. But those instances are not used when calling the make method. So to me it seems that you are wasting as much memory as you have "stored" classes in factory. In that case, this is smelly code. 
You still need to provide a runsettings-file, but with the minimal runsettings file you will now also get the source file links to the test case. Before you needed to supply a custom discovery algorithm to get the source file links. 
```shared_ptr``` doesn't have a ```release``` method period. You can try to implement your own release functionality with a custom deleter but it's very difficult to do so reliably (although not impossible).
Ah, I see, makes sense. Thanks for the reply.
*cough* global variables always should start with two leading slashes! 1. I'm not sure whats your thought process is behind making it a factory(I read your text i just want you to think about it a bit more)? It looks like you have the information about what text processor at compile time, and not only at runtime. And you're forcing it to occur at runtime if you don't have a certain type which should be a compile error. (Makes refactoring easier and makes you have to run the code instead of just compiling) 2. I'm not sure if you really want std::string as index for the map, more something like view maybe? you're hiding alot of information at compile time and going through a lot of templates which you could just write out. (Could mess with the optimizer) 3. ``` MakerType&amp; get_factory(const std::string&amp; name) { return *this-&gt;_storage[name]; } ``` What do you think this does do? (If the index is not found? 4. Make in TemplateMaker is imo obsolete and a smell since you don't know the ownership. and you can get a raw pointer from unique_ptr (get). Same for std::shared_ptr Overall this looks like bad code tbh. 
/u/philsquared can confirm, but if I recall correctly he said in his closing remarks that videos of the talks would be on-line in due course.
Ha! I'll be darned. I use `unique_ptr` way more often. I stand corrected!
"but if you're working in a code base where bugs often may result in side effects that extend beyond whatever class you've developed tests for " That's why they are called 'unit' and not integration tests. Bugs can exist within classes and between classes. But, you will have a LOT more bugs between classes if the code inside the classes has bugs or isn't correctly implementing the functionality it claims to, or isn't catching invalid inputs. It would be like building a rocket and making absolutely sure every part was in the right place, but never testing the parts to make sure that they meet tolerances or perform their function correctly. Would you want to take that ride? You can also have integration tests that test sub-systems as a hole or in sections and such.
Probably modules. 
2015 still had the bug where no part of push_back was inlinable. It’s possible that your workaround actually just fixed that. Without actually seeing the workaround I don’t know for sure.
I think perhaps `try_realloc` is the wrong approach here. Instead, the allocator could return the truly allocated space at the time of allocation. Then when `vector` asks for `N*2` space but gets room for `N*2+M`, it knows it has that extra capacity immediately, and doesn't need to hit the allocator again until it's really out of available space. While it is possible to construct some scenarios in modern allocators where there might be room to grow but only after initial allocation (e.g., freeing a block right after the containers' block of memory in allocators that can find adjacent blocks efficiently), the circumstances are relatively uncommon; optimizing a standard container for uncommon allocation cases while pessimizing it for the common ones seems like the wrong approach to me.
This mutex wakes up all the threads waiting on the event. They all wake up, then the first one gets 0 in the exchange and gets to proceed, and the other N-1 wake up and then go back to sleep on the event. An efficient mutex would maintain a queue of waiting threads and wake just one of them (like SRWLOCK does). Did I ever make claims about no loops being desirable? I believe I said just the opposite. Good primitives will spin with exponential back off for a while before going to sleep, and this doesn’t. I never said anything about your rwlock; that’s not the code under discussion. SRWLOCK is more efficient even if you never use the shared reader part.
Am I the only one that think that memory bugs on Windows are mainly because their terrible Win32 API instead of C++ itself? I remember looking Microsoft examples and MSDN documentation telling little secrets about buffers and lengths needed in specific functions. Someone knows why Microsoft never released a wrapper for all those tricky API functions with buffer+length (and all those tricks with CHAR, TCHAR, WCHAR, length+1, or -1, or an extra char for the zero, etc.)? &amp;#x200B; The good thing about a Windows Rust API would be that they will need to create that kind of wrapper library for the insecure Win32 API, the bad thing is that we'll never had that wrapper for C++.
How? I have my own class that does a shared atomic pointer with release. It’s not somehow problematic. The release only works when the instance has the last reference on the object, and then atomicity is unnecessary since nobody else has access to the object. For used where a forced release would be useful, I’ve made a weak_shared_ptr: it keeps references alive, so is stronger than a weak_ptr, but can be reset to zero at any time by releasing it. To use it, you do similarly to weak_ptr: you convert it to a strong_shared_ptr that you can then dereference. While any shared pointers exist, `release` will wait, and `try_release` will fail. The object is of course automatically released when the count of strong and weak pointers goes to zero. The control block is released when the count of weakest_shared_ptr goes to zero – those are the equivalents of weak_ptr. 
I'm looking forward to static exceptions from a [distributed systems ](https://github.com/Ebenezer-group/onwards) perspective. I'm kind of interested in contracts.
Yes! The first videos should be appearing today - or tomorrow at the latest. We've just been finalising the templates (no, not \_those\_ templates) and things, and the first batch is being rendered by the video crew. The keynotes should be in the first batch.
Before implementing a factory, do you really need to create one? To sum up, instead of doing vector&lt;string&gt; args; auto processor = global_processor_registry.get_factory("mood_classifier").make(args); can you do vector&lt;string&gt; args; auto processor = MoodClassifierTextProcessor(args); If yes, then don't bother to implement a factory. It's a lot of pain, and add a lot of complexity for nothing. However, if you need to be able to separate the place where you choose your builder, from the place where you get an instance, then using a factory is the right tool. What I generally saw in code using a factory, is that the client code has all the knowledge required to call `MoodClassifierTextProcessor`'s constructor. What makes it really obvious that a factory wasn't needed is that you often find a `dynamic_cast` because to be able to use member function of the derived class.
&gt; there's no difference between a static library and a dynamic library Oh boy! You're in a for a treat. 
LD_PRELOAD is actually really useful. We use it to override the system allocator.
modules. in any form. doesn't matter if they are broken. 
All you have is this non-answer? Fine.
Your Readme file still says `konfigorator`.
That's true, except that there's one thing that is even *more* valued than performance: predictability. ASAN only has a 2x performance overhead and there are people who use it in production, despite its weaknesses.
You can do the same on Windows, it just requires a bit more effort with DLL hooks.
From managed language point of view, modules.
&gt; Add this optimization to Rust! &gt; &gt; Not so fast! Arc actually means Atomic Reference Counted so it would be a plain lie if it hadn’t use atomic operations on the reference count. If you have only one thread, non-atomic operations are atomic. That's the point. "atomic" doesn't mean use certain instructions. "atomic" means indivisible, which, when combined with "as-if" means "can not be shown to be divisible". If you only have one thread, your program cannot detect a "division" or series of steps in the operation, it is as-if one indivisible, atomic, operation. (Similarly, you could implement atomics with a global mutex that stops the world while running a bunch of instructions to do an "atomic" add)
I consider this relevant because this post discusses some issues writing Rust code that Sean identified as also being real concerns with real-world C++ code. This isn't intended as a roast of C++ (which is my day job) -- I hope to spark productive discussion here, since I almost always learn something new from comments on threads like this. :)
Linux is not better, Google has been pushing for the Kernel Self Protection Project for a while now. Solaris on SPARC makes use of hardware memory tagging to keep typical C and C++ exploits at bay. Google is working with ARM to help pushing tagged memory adoption in future ARM SoCs. So no, it isn't a Windows thing.
"There are people...". Sure, but that doesn't mean that the larger c++ community would accept a compiler that can't disable asan - let alone a change to the core language that would require additional overhead. I believe that on average, if the c++ community has the choice between safety and performance, it chooses performance.
Okay I see! :-) I've had a second look at the TransferWise fees, it indeed sounded a bit low. But it does seem like I am quite correct - the fees vary slightly depending on the currencies but it is around 0.3-0.6% plus a flat fee of around €1. Then there's indeed not too many reasons to use another service, but it's good to know things like CurrencyFair exist. In any case Fintech is really great, it really is changing consumer and small business banking for the good, particularly for international transactions.
☝️ this! Exactly what I thought of while reading about ranged for loops being "limited". Combine this with what will come into the standard with ranges and one could even almost write pythonic code
Most important to get into the C++20 standard? Clearly coroutines **and** modules -- there's no more time to waste. Concepts and ranges are already in, and should stay in. Same for contracts. I honestly get scared when I see all kinds of papers \[in the most recent mailing\] trying to deter swift progress. Things can/should be fixed later, if really, really necessary.
Awesome! What channel will they be in?
they should start with slashes? you mean underscores? thanks for the response, yeah it does look strange that's why I thought of asking the question. The reason I'm having this factory is because I'm writing a small web framework and I've got a router to associate routes to a handler that can take an http request and produce a response. Sometimes we take parameters from the URL, like in Django and many other frameworks. For instance **/api/users/5/info** we want to extract 5 or have some validator match it. I'm aware using just regex can solve the problem here but imagine I don't want to just use regex. so you could have **/api/users/&lt;regex:\\d\*&gt;/info** . now I'm thinking my library parses that **regex**, extracts the arg list which is just **\\d\* .** Now I want this to be extendable. I could just write my own matcher and register it in the factory under name **regex**, get the arguments and initialize the instance properly and then be ready to respond to match requests that come my way. Does that make sense? Since I don't have prior knowledge of those classes I can't just write code to instantiate them, I don't know what they are yet. They're coming from the consumer of the library. I can't just store one instance because they're different instances initialized with different parameters so I thought I need to instantiate different instances and a factory might be good for that so I have this factory, store **builders** that can create instances for me since I can't just store a type and dynamically initialize it in C++.
Only because there has *never* been a choice. There are *no* implementations that provide safety and preserve flexibility, while still keeping performance proportional.
&gt; If you only want to operate on part of a container? You have to re-write your loop body. This will become untrue with ranges in the next C++ standard, which should generally allow ranged for to be used in a more functional manner
I guess you could implement vector iterators as a pointer to the vector object and an index. That double indirection guarantees that you will catch invalid accesses.
What do you mean by "managed language point of view"?
Well, you could use virtual memory for that. If every time a vector is reallocated the old memory is unmapped the MMU will catch usage of invalid iterators. This is seems like a good idea for big vectors.
The reason I thought about this factory and again, not sure if that's necessarily enough reason to do so but the initial reasoning in my head was in the comment I made to pushrcx's response. I basically have a router that takes a path and resolves it to a handler instance. So **/path/to/resource/56/** would yield a handler and pass along 56 to it. that handler would then do something to it, that part doesn't matter. Now in order to match these paths, I thought about small grammar like this **/path/to/resource/&lt;some-matcher:param1:param2:...&gt;** Now using that factory, I'd retrieve the factory to create an instance of "some matcher" using the appropriate arguments "param1", "param2", ... and then use the matcher to see if I have a match. Like that matcher would have to implement a match method or something like that. Having a factory would make it easy to extend this and have consumers of the library add custom matchers.
For project folder and file layout see https://github.com/vector-of-bool/pitchfork IMO it is the best reference in this regard, kept very general but it describes very sensible defaults. For Code itself, I would mainly recommend to never write yourself what is available as a library (E.g. logging, unit testing, or any math). Most other things are simply a matter of taste.
We have no history of fixing anything in C++. We sometimes replace things with something else entirely. 
&gt; Things can/should be fixed later C++'s high order bit is "your existing code keeps working", so this kind of stuff can't really be fixed later.
I wish people voting for modules would clarify what they want out of that proposal. I can see clear benefits but not "revolutionize the face of the language" benefits. I am not super plugged-in to what's going on with modules, but folks I've talked to seem to think it would give you "here's a DLL, go ahead and use it" kind of behavior like you get with Java or C#, and that's not what C++ modules do.
I really wish this bit would flip in certain circumstances (cough initializer\_list cough), and given the right tooling to migrate.
I like static exceptions but there's no chance of them being a C++20 feature. Maybe C++23
Please use \*\*two stars\*\* to **bold** the sections of the template for easier scanning.
\`get\` + destruction is not a release, it will delete the pointer and invalidate the address returned by \`get\`
The pages I explained weren't already enough? Now you need silly scenarios you just came up with confronted for no reason? Find me a single piece of mature software that uses two stacks to make a queue like this.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/aq9zyt/how_to_make_a_cstring_print_double_spaced/egeg6fz/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I'll try rerunning it under '17,' '19, GCC, and Clang.
How do you guarantee that between the check for refcount == 1 and the actual release another thread does not create another shared\_ptr and increase the refcount?
There could be a partial specialization of `cache_iterator` to handle references by storing them in a pointer, and then have the standard `operator*` return by value.
vector isn't allowed to implement a small object optimization because swap() needs to be unconditionally non-failing.
&gt; If you have only one thread, non-atomic operations are atomic. That's the point. The issue is with the "you have only one thread" part. libstdc++ makes a specific but easily fallible assumption on that front, and when it's broken so's your software. Unless the system itself provides the atomic you're basically just guessing.
That is the definition of a dirty hack and shouldn't be the default behaviour. 
Well, I've heard some compilers will have support for static exceptions this year. 
Ranges will fix it. I heard.
It's because modules are the one thing listed where everyone has their own fairly sensible idea about how it will work, and everyone is wrong about it. What C++ calls modules and the current debates and discussions on the issue is nothing at all related to what most sensible people expect out of that feature. I'm fairly pessimistic about C++ modules... in my opinion all anyone wants in C++ is a standard uniform way to build and structure projects that works for 99% of use cases and where that structure can be somehow codified into the compiler so the compiler can optimize the build process, perhaps by caching or other mechanisms. What's being debated, however, is nothing of the sort. People can't even agree that C++ source code actually exists in something called a file and that files exist in things called directories... this kind of minutiae because of some very obscure architectures is why 99.9% of C++ developers will not get anything resembling to a sensible, useful, module system.
No, he means slashes, as in, you should comment them out, because you should not use them.
I think, ranges should definitely not be standardized before coroutines, because coroutines can have such a huge impact on how new ranges can be written, and their final design and characteristics could even affect what makes sense for ranges. I'm not really that excited for any of these features. Come get me when reflection is on the poll.
Even if that’s true, it won’t be a feature in the standard.
European dragons have a heritage that [stretches back](https://en.wikipedia.org/wiki/European_dragon#Greek_and_Roman_dragons) to at least the time of the Greek civilisation; calling them "pale imitations" does them a grave disservice. The oldest known sources for dragon myths are from the [Middle East](https://en.wikipedia.org/wiki/Dragon#Middle_East), not the Far East. If you feel like arguing this point, please don't use the Dresden Files. Just stick with [authorative](https://www.amazon.com/Fantastic-Beasts-Where-Find-Them/dp/1338216791/) [sources](https://www.amazon.com/Compilers-Principles-Techniques-Tools-2nd/dp/0321486811/) instead, ok?
Someone that has left C++ for managed languages, but still uses it via JNI, C++/CLI, C++/CX, C++/WinRT, when required to do so.
&gt; Someone correct me if I'm wrong. Sure. You are right in the sense, that release() can't free the memory of the object if it was created usinf make_shared(). But it can destroy the object. The same behavior already exists, when a weak_ptr outlives the object, so not really changes anything. With a custom deleter you should be able to implement a release(). Of course that means you have to control the creation of the initial shared_ptr and can't just use make_shared(). I don't like it though, because it interferes with the semantic of a shared_ptr. Ownership is shared, so it feels wrong if any owner can rip the object asynchronously away from the other owners.
People stopped caring for it, modules will deliver none of the promises and will only be helpful to obfuscate code.
The standard is being help ransom by the module guys. It’s going to cure cancer they say.
Pulling templates into their own TU will indeed block inlining them unless you use LTO. That said, there is basically no case where you shouldn't be using LTO, so this shouldn't be a huge problem.
As with other compiler hint keywords: inline, etc. The default is to omit the use of these keywords because on average, you can expect the compiler's model of how to inline or order branches to be better than yours. You make a good point about PGO. The over-simplified model of what PGO does is that it sets -Os on everything, except what it determines to be worth O2 / O3. One of the ways in which is important is for icache. [\[Build Time Switches, CppCon 2018\]](https://www.youtube.com/watch?v=FsrC6PI2TBg) IMO, likely, unlikely, etc are badly named. They are well-suited for when you want the compiler to optimize / pessimize a particular path at the expense of the average case. Somehow \[\[ unlikely\_but\_treat\_it\_as\_likely \]\] just doesn't fall off the tongue as well. For more details on optimizing for the worst case rather than the average case see [\[Patrice Roy, CppCon 2018\]](https://www.youtube.com/watch?v=pnSvUbE1HHk) &amp;#x200B;
Yes! oh my.
All recent (less than 15 years) linuces can pass a flag to dlopen to resolve symbols insude the library before looking outside
lolz
hahahaha omg. ok :)
Edit: I feel like I didn't word the last sentence strong enough. A release() function would fundamentally break shared_ptr. Holding a shared_ptr to an object is your only insurance that the object is still alive, so it would be very hard indeed to write correct programs that use release(). It would require some side channel of communication between the caller of release() and other co-owners of the object. And if you are ready to put in that effort, you might as well use it to communicate "please drop the shared_ptr" instead of "don't use the shared_ptr anymore, because I am about to rip it from your hands".
thanks, updated :) Probably there are much more old names on documentation, on website - this is almost on top of my todo list to write some more documentation with examples
- eliminate recompilation of headers - per-module language versioning with link compatibility - eliminate macros and #includes from the common case
&gt; eliminate recompilation of headers &gt; [...] &gt; eliminate [...] #includes from the common case That's fair :) &gt; per-module language versioning Don't see how that's part of this proposal. (In fact, inability to expose symbols according to importing language version is a big problem for use in the standard library.) &gt; with link compatibility Also don't see how modules affect this. They don't change separate translation as a model. The linker still runs and there's still an overall symbol namespace post-mangling. &gt; eliminate macros [...] from the common case Don't think modules do that either. Modules certainly make it necessary, but they don't resolve the problems that actually lead people to use macros today.
I've asked you a question. Let me repeat it. &gt;But you really want to go that approach, answer me this: how would you implement a queue in a purely functional language, say Haskell? That's a real task with real restrictions as you've wanted. It might've been solved by the time it's given to you but it wasn't at some point in time.
Is there a tutorial for using qtcreator with cmake? 
The usual people saying the same things with kitchy, non-descriptive clickbait titles is getting a little old.
Compare-and-exchange instruction is atomic, so when the test succeeds the new value, which is incremented, is swapped to replace the old value. Then you have all the time in the world to inspect the new value which is result from atomic operation.
A guy from microsoft says that cross platform C++ is challenging. I wonder what company is the most directly responsible for this scenario.
Uhm it seems you are really doing a lock-free \`release\`...my question is how do you prevent this from happening: &amp;#x200B; thread #1: compare and swap: check that refcount == 1, if yes sets refcount to 0 thread #2: copy-constructs object thread #1: returns "released" pointer &amp;#x200B; What does thread #2 do in that situation?
We are talking about C++ interview questions still right? Also calling anything in Haskell is a bit of stretch. Also can Haskell not create a queue without quadratic insertion? Do you frequently get asked Haskell questions at interviews for jobs that will have you programming in C++? 
&gt; With a normal mutex we would be fine, ... it doesn’t matter if we unlock it on a thread other than the one we locked it from. Really? In most (all?) mutex implementations unlocking from a non-owner thread is either an error or an undefined behavior. After such mistake, it's hard to view the rest of this writeup seriously.
I think you might have misunderstood what capn_bluebear was saying. std::share_ptr&lt;whatever&gt; ptr; &lt;- global. Thread 1: if(ptr.refcount == 1) { Do a thing } Thread 2: ptr.increase_refcount(); It's entirely possible that thread 1 checks to see if the reference count is 1, then gets paused by the OS, thread 2 increases the reference count, and then is paused by the OS, and then thread 1 wakes up and proceeds. Or both threads can be running simultaneously and still do things in that order. It's only possible to reliably determine that the reference count is 1 when dealing with a shared pointer that has it's access serialized somehow This could be via: * only ever used / accessed on a single thread * or there's a mutex that gates all possible accesses * the shared pointer lives it's entire life on the stack of a single function call and you're doing a sanity check at the end of that function call to ensure no one made a copy of it * so on. But the fundamental problem is that by offering ability to query the reference count, unless you've already made sure the access to the ref-count is serialized properly, the information that you query is wrong (potentially) as soon as you get it. So any subsequent actions you take as a result are potentially invalid as well. 
Modules but only if they're going to reduce compile times significantly otherwise ranges.
Static exceptions benefit from contracts.
While nothing you said is wrong, I think you missed the point. Many of the ranges adaptors worth caching perform a lazy computation and will often return values (rather than references) from their dereference operators. The trouble with returning a reference to a value cached on the iterator from the deference operation (as the suggested implementation does) is that the reference goes stale when the iterators lifetime ends. The standard requires that (for a forward iterator or stronger) this not be the case. Consider the example: ```cpp auto r = ranges::view::iota(1) | ranges::view::transform(times2) | ranges::view::cache; auto&amp; reference = *(r.begin()); // reference refers to a valid memory until semicolon // iterator's lifetime has ended. reference is dangling std::cout &lt;&lt; reference &lt;&lt; std::endl; // UB ```
There is no other thread with a copy because the copy you have is the only copy... Because refcount == 1...
You're posting your own content too frequently.
You do it like this: void release() { if(0 == --m_atomicRefCount) { delete m_ptr; } } The trick is that you have to decrement the refcount atomically. If, after atomically decrementing the refcount, you have a refcount of zero, then it's not possible to have another reference. Part of the trick is that you also have to enforce this in the other parts of the smart pointer that can increase the reference count. E.g. void attach() { if(0 == m_atomicRefcount++) { assert("Increasing the reference count for a pointer that has been deleted"); } }
I want to be able to write libraries without using [lex.name]/3, and being able to actually `using` names at a top level, being able to `using namespace`, having private helper functions that are actually private. I'm so ready for these.
the other thread *is making a copy* while the first thread *is releasing*
I'm not sure why modules would be relevant to you exactly - aren't you consuming it mostly/only from already compiled libraries? C++ modules are for speeding up compile times, they're not for interaction with external code
that is wrong. between the time \`if(0 == --m\_atomicRefCount)\` returns true and the time \`delete m\_ptr\` is called *anything* could have happened in a multi-thread application.
If you make sure the rest of your smart pointer's implementation checks the value of m_atomicRefcount prior to doing anything that's potentially destructive, then *anything* turns into *nothing*. Source: Maintainer of smart pointer library at work. Have had hundreds of hours of design meetings with people much much smarter than me.
I couldn't agree more about Fintech. This past two years of challenger PayPals (these are not banks, no deposit guarantee) have been a breath of fresh air to retail banking consumers, not least that PayPal is finally made to look like the fees ripoff which it is. I'm happy to move my business 100% over to fintech payment services, as under Irish law I must empty its accounts every year anyway, so there's little to lose if somebody goes bust. But until they get a deposit guarantee, I must admit I'll be sticking with my crusty old bank for my personal account. I'm fairly sure the government will keep the ATMs working come what may for the major retail banks. 
Absolutely right. At best they might be in an Experimental TS for C++ 23. Not in the standard.
Maybe static exceptions are "the most likely to succeed".
Nice! What about overlapping intervals? &amp;#x200B;
You asked about real task. I've given you one. You've asked about "real restrictions". I've given them to you (even though that's totally unnecessary for sanity-check kind of question like this is). You are still not happy. You still complain and maintain your "nonsense" position. And now you are trying to say that Haskell is not used for real tasks? You question the worst-case quadratic performance of this kind of queue, yet you don't question the same worst-case for the regular queue? Thanks. I see that you are just a regular troll. Good day sir, I see no reason to continue in this vein. You are dedicated to stick to your ways and nothing I say or show would change your mind.
I'm just trying to share what's on my blog and in the process gather greater following. I don't mean to be spamming this forum; I feel like I'm sharing valuable content.
this approach will handle overlapping ranges; it will simply pick first one that's a hit in the sorted range order. &amp;#x200B;
This mutex does NOT wake up all the threads waiting on the auto reset event!!! Study it. Please. You do not know what this algorithm is actually doing. It does not broadcast! Wow. Just calm down, read it carefully and stop making totally false claims. Btw, I want you to show me where this mutex wakes all threads. Please try, lol. 
I bet it was Google. /s
&gt; It does not broadcast! Okay, then there are things that aren't clear in the 20 line code example on the blog. You know what would end this kind of speculation? Any kind of data showing that the thing was actually faster. As I said in my first comment, claims of fast without benchmarks are baseless. &gt; what part of notify_one do you not understand? Only this comment, because "notify_one" does not appear in the blog post under discussion.
&gt; You asked about real task Nope &gt; You've asked about "real restrictions". I've given them to you Nope &gt; And now you are trying to say that Haskell is not used for real tasks? Yep &gt; You question the worst-case quadratic performance of this kind of queue, yet you don't question the same worst-case for the regular queue This is always quadratic, a regular queue is amortized constant time, neither is worst case. &gt; I see that you are just a regular troll That's very good when you don't even understand the basics of what is being talked about, resorted to talking about Haskell in a thread about C++ interview questions, and ignored everything I asked including what mature piece of software does something like this.
You say it like it's a *fait accompli* but personally I think what you're describing is *precisely* what people need: an ability to take a DLL, plug it into their project, have all the bundled metadata read by the IDE and compiler and shown in code completion. Yes, you can bundle an XML with documentation side-by-side, or a PDB, but that's about it. ↑↑↑ **this** is what people actually want. not macro support. seriously, there is no reasonable way to make macros a part of this: there is no palatable set-up unless you decide, for whatever reason, to include macros as part of metadata **as plain text** to be inserted verbatim into the client's sources. which is disgusting and unnecessary, but it will work.
I'll stop.
&gt; You say it like it's a fait accompli but personally I think what you're describing is precisely what people need: an ability to take a DLL, plug it into their project I'm not making a statement as to whether this is feasible or a statement about the merits (although I think making templates work in a completely binary distribution scenario is likely impossible/impractical). I'm only making a statement that C++ modules as currently being discussed are not that, and I think a large number of folks asking for modules think they're getting something they are not.
Unfortunately I don't think coroutines are going to be amazing citizens in ranges world because a coroutine is at best an input range. That's not to say that there aren't useful things you can do with input ranges and views; it's just that most range adapters and similar probably want to pass through the underlying range's power. Luckily, most of the ones folks will come up with already come in the box thanks to Eric and Casey's hard work.
I understand the point that’s being made, but it still feels like bad programming?
That's fair!
I hope there will be challengers soon too for the likes of Stripe and Squarespace. That's a complete rip-off too, for small businesses. With regards to current accounts (business &amp; personal), I think the likes of N26 or Starling all have banking licenses, with the money guarantees that come with it. And they're really refreshing and have nearly zero fees for international transactions, along the lines of TransferWise.
The op is using an auto\_reset event for the m\_waitset. There is no broadcast, and no thundering herd. However, now I want to create a little benchmark. It would be interesting. I hope that std::mutex wins! Seriously, std::mutex better win, damn it.
Can you finally stop Spamming this sub with these CS Interview questions? 
uhm, ok, how do you do \`operator\*\` and \`operator-&gt;\` without leaking memory? Consider \`myPtr-&gt;method()\`: \`operator-&gt;\` will see the object is still alive, increase the refCount, and return the raw pointer to the object. When is the refCount decreased again? If never, the object will never be deleted. If \`operator-&gt;\` decreases the redCount before returning, the object might be freed before \`method()\` is called on it.
It is mostly for in-house libraries, which we also might have to compile. Binary libraries usually can be linked directly from Java/.NET anyway. Also to keep my C++ skills up to date, I tend to occasionally do hobby projects in C++.
I don't think std::mutex will win, but I think SRWLOCK will.
No it's not. You merely place your shared library in front of the system ones so that the OS picks it first when looking for a function.
What does? I'm not sure what you mean.
From the given options: ranges I would however prefer the unlisted underdog-answer: Contracts! Unless we manage to fuck them up again, their impact has the potential to be HUGE! Every programmer would be able to define the precise requirements for all their functions in a formal way that can be checked in debug-builds and exploited for compiler-optimization in release-builds. You would be able to easily fuzz many functions independently simply by throwing in values that satisfy their preconditions and check whether they trigger any pre-condition-violations in the functions they call or violate their post-conditions. Adding pre-conditions to build-in-operations for all UB (has to be done by compiler-vendors, but there really is nothing that stops them, as we talk about UB!) could vastly decrease many subtle bugs. 
Your university library may have subscription to iso standard.
Afaict, std::mutex should be at least as fast as this "fast" mutex. If not, something is wrong. I am not sure if MSVC uses a SRWLOCK for std::mutex. I am going to code up a little test, starting with this "fast" mutex vs std::mutex, then a specific windows version that tests it against SRWLOCK wrt pure write access. Also, I need to port my rwlock algorithm to C++11, then create another benchmark wrt reads and writes. Humm... Thanks. Fwiw, an old crusty x86 POSIX version of my algo can be found here: &amp;#x200B; [https://pastebin.com/raw/f3d6140eb](https://pastebin.com/raw/f3d6140eb)
So you are giving up the managed ownership? What does the standard say? Should it be synchronized? 
Executors, because it is a prerequisite for so much other useful stuff.
It's a managed copy. I'm copy-constructing.
&gt; I am not sure if MSVC uses a SRWLOCK for std::mutex. We use SRWLOCK on Win7 and later, but we don't get most of the benefits because that's hidden behind OS version checks and ConcRT garbage for WinXP support. When we break ABI next (and thus drop XP) std::mutex will become just a pretty face on SRWLOCK and then they should become more or less equivalent.
(If you use std::shared_mutex, that should be more or less equivalent, as that unconditionally uses SRWLOCK)
Hard for me to know for sure, but based on experience, I'd disagree. Having used python extensively side by side with C++, which has support for both of these things, I'd say the vast majority of the time all you really want/need are either lazy input ranges, or actual real containers. The number of times I missed the fact that python's whole concept of ranges (iterators) is "input", was pretty much nil (although better left to right composition would be nice). On the other hand, there are many times where if I couldn't have easily written my own generations, I would have resorted to for loops. In other words, I think you are very much reversing the priorities of these two things: being able to easily write input ranges is much more useful in practice, more often, than being able to work with non-input ranges. To take a very practical example, skimming Eric's 2015 Cppcon talk, with the date ranges example, everything there AFAICS would work perfectly well, strictly with input ranges and nothing else. You can do groupby, you can do chunking, you can do interleaving, no problem. And many of the constructs that Eric has to write on the way to creating this example are so complicated that he admits the presentation will run long if he actually explains them! Here in the background, you can see the implementation of interleave: https://youtu.be/mFUXNMfaciE?t=2840. To say that it's not intuitive for mere mortals, is an understatement. It involves writing two classes and a function, the function uses another function that was complicated (it hurt Eric's head so who knows what it would do to mine), one of the classes has 3-4 non-trivial member functions. Compare this to the python coroutine implementation of the same idea: def roundrobin(*iterables): "roundrobin('ABC', 'D', 'EF') --&gt; A D E B F C" # Recipe credited to George Sakkis pending = len(iterables) nexts = cycle(iter(it).next for it in iterables) while pending: try: for next in nexts: yield next() except StopIteration: pending -= 1 nexts = cycle(islice(nexts, pending)) One function, ~10 lines. If you understand how a coroutine works in python, and how iteration works in python (throwing StopIteration when an iterated is exhausted), you can understand this code in 2 minutes.
&gt; being able to easily write input ranges is much more useful in practice, more often, than being able to work with non-input ranges Most of the "interesting" standard library algorithms like sort or partition don't work with input ranges.
unit tests aren't the be all and end all, but realistically while the type system can help you cover many types of trivial errors, it doesn't cover all of them. Even once my code compiles, it's pretty common for me to have really trivial runtime errors several times, if I don't write unit tests. Before even getting to debugging more subtle things. A big part of unit tests is actually just being the most efficient way to quickly catch trivial errors. This is doubly true in a language with untyped generics; if you don't instantiate your generic code you're not even really exercising the type system meaningfully. And of course, the unit tests stick around so it prevents trivial bugs from creeping back in during changes, where they might get caught later down the pipeline and be much less obvious. There are some domains or pieces of code where unit tests will go far beyond that and really help you verify things very deeply (like writing a container for example), and there are other pieces of code where I admit I've found it difficult to really use unit tests to deeply verify that my code is correct. But even in the latter case, it still does catch simple things. And most important of all, unit tests should really have next to no "extra" cost. You need to make at least some basic attempt that your class/function is sane before its worth trying to integrate it into everything else, unit tests just provide an environment for doing that which should be easier and more frictionless than a throw-away main.
Perfect. Wrt the benchmark, I am thinking of checking how many reads and writes a thread can perform per second. Writes wrt the mutex test, of course. Think of read/writes per-second, per-thread. How many operations can a thread accomplish in a time frame. For instance, in the past I have checked RCU vs many different rwlocks. RCU beat the living crap out of all of them, not even close, really bad. It allowed reader threads to perform \_many\_, orders of magnitude, more reads per-second per reader thread. Also, it beat them on the write side using a simple mutex. I will start coding it up sometime today. When completed, I want you to take a close look at it to make sure it is "Kosher", so to speak. Thanks again. :\^) &amp;#x200B; Fwiw, RCU beats the living shi% out of my rwlock, and it should slaughter SRWLOCK. But, RCU is a different sort of beast...
If the smart pointer that you're using operator-&gt; or operator* on is destructed before the statement containing operator-&gt; or operator* is finished, you've got much bigger issues than atomic variable race conditions.
Ok so how are these operators implemented? Honest question, I'm missing this piece of the puzzle :)
Let's make this really simple and concrete. Let's say that someone needed to do read some data, write and perform some nifty range operations (things that can be made into random access ranges, which I think includes chunking/interleaving, but not sure), neat stuff, and then sort the final results with some comparator. In the ranges + coroutines world, they have two options: 1. They can write the range operations the long way, making sure to perfectly preserve the range category of the input. Note that even Eric didn't do this, he just wrote input versions AFAICS since his classes only have next and done methods. 2. Or, they can just write, at nearly python levels of simplicity, input range only coroutines. Then, in the final stage of their pipeline, they can simply dump the results into a vector and sort the vector in place. Which one are they going to choose? It's pretty obvious that 95% of programmers, are going to choose 2, 95% of the time. Hopefully that makes it clear, what the relative importance of these two things is. 
The thread #2 shouldn't make copies of objects that don't exist and by exist I mean the shared_ptr object not existing, not the object it has ownership of. The same "problem" exists for objects of any type.. to make a copy the source has to exists. That is not a problem the shared_ptr is trying to solve; it just guarantees that the object which the instances of shared_ptr are referring to exists. You can make shared_ptr of shared_ptr, if you wan to guarantee that the shared_ptr exists, as long as you have a valid instance of the shared_object that shares the shared_object. Woo! 
Why should the 'operator -&gt;' increase reference count? xD 
Sure, totally different primitive, that.
I'm referring to std::string in this case. However, can't any vector holding a POD or trivial type use SSO?
No, because swap doesn't invalidate iterators or references.
That's fair!
Alternatively you can also download the version in question from [github](https://github.com/cplusplus/draft/releases) and build it yourself.
Reflection! Come on. How many awful, macro-heavy / generated-code systems have to be written before we can just query a class for its methods, their keywords, etc. Please save the gamedev world from this.
Yeah I agree, the example does not hold up. If you are writing a thread safe resource management system you should really understand your thread ownership model enough to know who can release a lock. However, in general I agree that cpp is perfectly happy to let us shoot ourselves in the foot. 
yep; I'll stop. sorry. just wanted to get some momentum for my blog. hope you understand.
And with cmake you can generate module definition files automatically by setting WINDOWS_EXPORT_ALL_SYMBOLS property. I discovered this while developing an Excel plugin...
Do you have a source from the Standard? I've tried trawling through [https://cppreference.com](https://cppreference.com) to find some supporting information for this (because this would be *really* good to confirm a source of UB, though I can't imagine when I'd need this knowledge right this second), and I could only find the following: At [this page](https://en.cppreference.com/w/cpp/thread/mutex): &gt; `mutex` offers exclusive, non-recursive ownership semantics: &gt; &gt; A calling thread *owns* a `mutex` from the time that it successfully calls either [lock](https://en.cppreference.com/w/cpp/thread/mutex/lock) or [`try_lock`](https://en.cppreference.com/w/cpp/thread/mutex/try_lock) until it calls [`unlock`](https://en.cppreference.com/w/cpp/thread/mutex/unlock). &gt; &gt; When a thread owns a `mutex`, all other threads will block (for calls to [lock](https://en.cppreference.com/w/cpp/thread/mutex/lock)) or receive a `false` return value (for [`try_lock`](https://en.cppreference.com/w/cpp/thread/mutex/try_lock)) if they attempt to claim ownership of the mutex. &gt; &gt; A calling thread must not own the `mutex` prior to calling [`lock`](https://en.cppreference.com/w/cpp/thread/mutex/lock) or [`try_lock`](https://en.cppreference.com/w/cpp/thread/mutex/try_lock). &gt; &gt; The behavior of a program is undefined if a `mutex` is destroyed while still owned by any threads, or a thread terminates while owning a `mutex`. .... &gt; &gt; `std::mutex` is neither copyable nor movable. The latter note on UB is mentioned for most articles on mutexes I saw. At [this page](https://en.cppreference.com/w/cpp/named_req/Mutex): &gt; The expression m.unlock() has the following properties &gt; &gt; .... &gt; &gt; The behavior is undefined if the calling thread does not own the mutex. None of the other named requirements associated with `mutex`es seem to have additional notes on potentially relevant UB.
You won't get more reader through aggressive self-promotion. Besides, I don't think people on this sub enjoy reading interview questions that look like they were extracted from an entry level CS exam.
Lets say you have template&lt;typename TYPE_T&gt; class MySmartPtr { using pointer = TYPE_T*; using reference = TYPE_T&amp;; m_ptr; // points to the object, and if using intrusive reference counting, points to the ref count as well. m_refCtPtr; // If using non-intrusive reference counting, this points to the reference count object. } Then you can define your operator* and operator-&gt; as simply as: pointer operator*() const { return m_ptr; } reference operator-&gt;() const { return *m_ptr; } You might wonder why there's no checks for nullptr. Well, you don't need them. Your programs going to crash regardless. Might as well not generate extra code just to say "I'm about to crash", unless you want to have a debug build that launches your debugger for you when you have a nullptr smart pointer. Notably, you don't need to bother with any checks against the reference count. Just no reason to with *this particular* design. So you then have two functions. acquire() and release() Lets assume you've made an intrusive reference counting pointer, where the thing being pointed to has to have an m_refcount variable. In that case, your acquire function is as simple as void acquire() { if(m_ptr != nullptr) // check for null, obviously. { // depending on how you want to design things, you don't even need to assert that the value is not zero. // Maybe you allocate your object with a refcount of zero, and then the smart pointer's constructor increases the refcount by one. // Or maybe you start it at 1, and the first such smart pointer that points to it doesn't increase it. // it's up to you. m_ptr-&gt;m_refcount.increment(); } } and then release void release() { pointer pTmp = std::exchange(m_ptr, nullptr); // make sure we null the ptr first. if(pTmp != nullptr) // check for null, obviously. { if(pTmp-&gt;m_refcount.decrement()) // decrement returns true if the refcount fell to zero. { delete pTmp; // now delete the previously pointed to object. } } } You call acquire in your constructor, and release in your destructor. In this particular design, which is certainly not the only way to design an intrusive reference counted smart pointer, the way that you protect yourself against another thread swooping in and screwing stuff up is by putting an assert in the m_refcount variable's destructor that the value of the refcount is 0 when m_refcount is destroyed. This doesn't stop it from happening, of course, but it will make your code barf at you when it does, and you can fix your design, since it's not the smart pointer's fault. If you ever have a situation where something has swooped in and made a copy of your smart pointer between when your smart pointer has dropped the reference count to zero, and when it's nulled it's pointer to the referenced object, that means that you're manipulating the smart pointer *itself* (not the thing it points to!) from another thread, and that's a *huge* problem. The key concern here is that the smart pointer itself is *not* thread safe, nor is any aspect of the pointed-to object thread safe, except for the number of references to that object that are held. So it's not valid to have a smart pointer that's conceptually owned by thread1, and then have thread2 make a copy of that smart pointer. It's also not valid to have a smart pointer that's conceptually owned by thread1 just arbitrarily access data from the pointed-to-object without some other access protection (mutexes, atomic variables, or just designing your app so that it's not possible). What is valid is to have a smart pointer that's conceptually owned by thread1, and an unrelated such pointer conceptually owned by thread2, that both point to the same object, where each thread can make arbitrary copies of the smart pointer objects that they conceptually own. You can even go farther with this by having thread1 own a smart pointer, and then put it into a data structure that gets "migrated" to another thread in some fashion, but only so long as you ensure that the smart pointer (not the thing it points to) doesn't get accessed by thread1 after the migration happens. Now, that'a ll being said, you can design a smart pointer class that is, itself, safe to access from other threads. That is not what my psuedocode example here is intended to be. The way you design your smart pointer is going to have positives and negatives, tradeoffs and so on. This is just the way my org designed them *shrug*.
I agree that the specific case that /u/rabidferret writes about in the OP doesn't look like it would have been correct anyway, though I think that the point about concurrency invariants changing out from under other code in the codebase is still a significant reality for C++ codebases. Having written a few async things in both C++ and Rust, the latter's help with initial code and subsequent changes to concurrency-related properties is a breath of fresh air.
You cannot make a copy of object if it doesn't exist. The shared_ptr you are making a copy of, has to exist. You have to make the copy while the object is still valid, if it has been "released", has gone out of scope or has been deleted by other means it is no longer a valid object to make a copy of. That would be a programming error. 
You can continue to post your own content if it's high-quality and prompts valuable discussion (this is more important than reddiquette's 1:10 ratio guideline), it's just that once a day and especially multiple times a day is way too much.
Exactly !
The fundamental problem here is that you have two threads which are referencing the same shared_ptr object. If both threads have their own instance of the smart pointer, this is completely a non-issue. Either make the copy when you create the thread, put it in a channel, or a lambda capture of a work-queue task, future, async, etc. Don't just reference the same global variable or pass a reference. With this assumption, two or more threads have an instance of smart pointer, and as a result the reference count will be greater than one, and the check will fail.
Since this post is about Rust, my guess is that author is using [`parking_lot`](https://github.com/Amanieu/parking_lot) library that does allow this.
No. Inlining (on every implementation I am aware of, ignoring LTO) happens before codegen, while `extern template` is specifically regarding codegen. The definition of the function bodies is visible to the optimizer, and is therefore allowed to inline. The bodies of function templates will be inserted into the codegen for the TU unless they have an `extern template` which tells the compiler to omit the codegen and assume that the definitions will appear in another TU that will later be merged into the program. Incidentally, this is also the reason `extern template` doesn't help much with compile times: The compiler and optimizer still see the entire template specialization.
I think the analogy at the end works better as an argument for better tooling, instead of an argument against needing better programmers. I would argue that if we were to fully switch over to self driving cars we could actually remove seatbelts from cars (not saying we should). On the same line, if we improve our tooling for c++ we don't solve the problem of bad c++ programmers, we would circumvent it. Good static analysis tools allow good programmers to focus on the core problem and lessens the ability for bad programmers to break the world.
Do you know of a good resource that summarizes what the current modules proposal is actually proposing - but written in a way that the average C++ guy can understand it? Most summaries read more like a sales pitch about why I should like it - versus what does it actually do.
https://doc.qt.io/qtcreator/creator-project-cmake.html should help. On that site you can find the documentation for qtcreator.
Um...he makes it explicit that that's part of his point (emphasis mine): &amp;#x200B; \&gt; \*\*We need languages with guard rails to protect against these kinds of errors.\*\* Nobody is arguing that if we just had better drivers on the road we wouldn’t need seatbelts. We should not be making that argument about software developers and programming languages either. &amp;#x200B; So...yes! I think we both agree with you. :)
Fwiw, here is a very crude version that uses std::clock, not too good, however it does show an interesting moment... &amp;#x200B; [https://pastebin.com/raw/UMjtLFgC](https://pastebin.com/raw/UMjtLFgC) &amp;#x200B; The timings I get from MSVC 2017 std::mutex are not good. This "fast" mutex beats it. However, on GCC 7.3.0, the std::mutex wins, great! Here are some of my timings on Windows 10: &amp;#x200B; Fast Mutex MSVC 2017: msec = 19067 std::mutex MSVC 2017: msec = 90442 // WOW! slow.... \------------------------- Fast Mutex GCC 7.3.0 -O3: msec = 18408 std::mutex GCC 7.3.0 -O3: msec = 12234 ... Great! perfect. &amp;#x200B; Imho, a std::mutex should always beat this "fast" mutex. Just from this alone, std::mutex on MSVC is garbage.
Yes please! 
&gt;std::mutex on MSVC is garbage Sadly yes.
If it does anything to make a large project compile significantly faster, they will use it. 
Yeah. I have seen the clarity ranges brings. I'm just not convinced that you move up to amazing levels of abstraction with std::for\_each. \`\`\` std::for\_each(rangedThing, \[\](const auto &amp; thing) { // Am I ugly? }); for( const auto &amp; thing : rangedThing) { // Am I better? } \`\`\`
I just want to not worry about #defines and speed up compile times :3
if only :(
I am wondering if they are still using the following library, iirc, their mutex was absolutely horrific: &amp;#x200B; [https://www.dinkumware.com](https://www.dinkumware.com/) &amp;#x200B; Also, I am wondering if GCC is properly aligning and padding memory on L2 cache lines to avoid false sharing. This "fast" mutex can definitely get more efficient if it did all of that. Might be interesting.
Thank you!! I just assigned it to the right team
You could have them merged into one blog post and post it once, maybe it would have been more well received.
#defines and **warning setup**. There are way too many devs who think it is OK to mess with warning setup in their library headers without restoring original state. I then end up wondering why charPtr1 == charPtr2 is a warning in half of my code but not in the other... all determined by whether #include &lt;FooLib.h&gt; is seen somewhere earlier. MSVC /experimental:external was godsend, but I would love to have this standardized ;)
Honestly this is a shallow way to attract attention for your blog. I don’t mean this as an insult. If you are blogging for yourself, to document your journey, then there’s nothing wrong with that, but it’s not appropriate to post each individual piece here. If you want to attract lasting attention to your blog and build your online prescience, you really need to take a break and decide what it is that 1) the community is interested in and 2) what you want to offer the community. That may require more development on your end and more *interaction* with the community. For example, is there a unique personal perspective you can offer? Educational posts are fine, but they should offer something novel that I couldn’t find by just googling the topic and clicking the first five links. 
Fixed
`shared_ptr` protects against multiple threads manipulating their own instances simultaneously, even if those instances all manage the same shared data. Multiple threads accessing _the same `shared_ptr` instance_ is still a data race (if at least one calls a non-const member function).
MSVC 2017 std::mutex looses badly to this "fast" mutex. However, GCC 7.3.0 on Windows 10 is much better, and beats them both. std::mutex should \_always\_ beat this "fast" mutex. It is basically for a "learning" experience wrt differentiating fast-path's: non-blocking, from slow-path's: blocking...
TIL that warning pragmas are a thing. 
Yes. ABI breaking to fix sadly.
I understand. Again, my apologies. I will participate more in discussions and less in self promotion ;)
&gt; No you didn't. You talked about Haskell and even in Haskell doing this would be idiotic. Do you have anything to back up your claim? I know of a several "legit" packages that use the simple idea of two stacks (lists) to back the queue as their base. Also I can link you a paper covering this topic (though you'll probably find it soon enough if you even attempt to search for how Queues are usually done in functional/pure environments). &gt;Yeah. One or two production programs compared to millions in other languages. Also this is about C++ interview questions. How fucking desperate are you to defend pointless nonsense that would start babbling about something completely different? Again with troll comments. Have you even attempted to look at the job offerings? There are plenty to choose from. Certainly not as much as for "mainstream" languages like Java, C#, C++, JS, but it doesn't make it any less real. &gt; This is always quadratic, a regular queue is amortized constant time, there is no 'worst case' here. The one in the article is. It can be trivially made amortized. If you don't understand that, then congratulations, you've failed a Junior position interview. If you do, then you've just grasping at straws. What next, attempt to appeal to my grammar? &gt;That's pretty bold when you don't even understand the basics of what is being talked about, resorted to talking about Haskell in a thread about C++ interview questions, and ignored everything I asked including what mature piece of software does something like this. Right back at you. You've ignored my answers and asked irrelevant questions and demonstrated a complete lack (or refusal to use them) of any programming skills.
There was recently a bunch of noise about this https://vector-of-bool.github.io/2019/01/27/modules-doa.html article highlighting issues with the current modules proposal.
The paradigm of leasing a thread to do asynchronous work is already moving afield of best practice and for cases where threads really need to be pinned, understanding how to restrict access is just something you need to know. But again, I’m not saying I disagree with the original point. 
I don't think this is true in general; SRWLock and futex don't care if you unlock on a different thread, although the C++ standard might.
https://docs.microsoft.com/en-us/windows/desktop/sync/slim-reader-writer--srw--locks SRWLock doesn't care.
One aside (mostly) unrelated to the factory design is that you are deleting a derived class via a pointer to base class, so you need a virtual destructor in both your `TextProcessor` class and your `Maker` class template.
Don't make it a tragedy, just be more careful when posting series.
Definitely Nvidia. /tangential s
I think ergonomics are a related issue. &amp;#x200B; If it's easier to do the wrong thing than the right thing, what do you expect ill-informed people to do?
Taking this opportunity to remind people it's tricky to do well. [Futexes Are Tricky](http://dept-info.labri.fr/~denis/Enseignement/2008-IR/Articles/01-futex.pdf)
What is your goal? by using Visual studio you are already pulling down a lot more than the bare minimum to build C++.
I think the "Desktop development in C++" is the option you want to select. that's what I'm running on my home laptop.
I want a good IDE to do HW the Course is an introductory class so I doubt will do anything fancy.
FWIW, it made me add your blog to my feed reader. I always like reading about C++ and I like your blogging. 
I think the point he's making is he initially did understand the model, but someone changed the model upstream. In that scenario the rust compiler was able to warn him when the changed happened that what he was doing was no longer valid. The rust type checker is "strong" enough to validate thread actions. It's more accurate here to say "c++ is perfectly happy to let your coworkers shoot you in the foot" :)
Maybe I'm not getting this but, honestly, can't you just create a common struct containing the parsed data that you want to let your user manipulate e provide a __free-function__ that populates the struct by parsing the URL? If the user wants to implement their own matcher they just need to create their own function that creates an object of that struct. If the user wants to implement their own processing stuff they create their own function that does that (I mean, if each "processing" function is different then it's totally possible that the algorithms that operate on your data are different, so chances are they have different names and all) By doing it this way you don't have to deal with a Factory and allocating stuff on the heap (assuming I'm understanding the problem at hand); frankly I can't figure out what your code *really* means, it's too much abstracted
Your match us probably incorrect. Otherwise this belongs to r/cpp_questions
This isn't the right place to ask questions... /r/cpp_questions C++ is not like math, it will evaluate the entire expression to the right side of the = and store the result in the variable on the left side. You never assign anything other than 0 to `u` so it'll always be 0.
Please post a formatted answer to /r/cpp_questions instead. You can format your posts with four leading spaces 
Modules is probably the feature that has taken more committee time. The disproportionate attention to modules caused important language features to be pushed to cpp23.
&gt;Yes. ABI breaking to fix sadly. Damn. For some reason I thought std::mutex would just map to a properly aligned and padded CRITICAL\_SECTION in C++11 on Windows. Iirc, **Dinkumware** did some "strange" things wrt its mutex. Need to step through the MSVC std::mutex code... Okay, so std::mutex on MSVC is pretty slow, while GCC 7.3 beats it and the "fast" mutex. I am wondering about std::shared\_mutex. Currently porting my rwlock over to C++11 so we can see if it does any good against the standard primitives. std::shared\_mutex \_should\_ beat it. If my rwlock wins then there is something wrong with the std::shared\_mutex. Should be done sometime tonight or tomorrow. I am hoping that std::shared\_mutex wins, crossing fingers. Thanks again. &amp;#x200B; Fwiw, I am just going to do a simple port, and not align and pad data-structures. This way, if I do decide to take it that far, we can compare it to the naive version that does not take false sharing into account.
There are `constexpr` functions that aren't `pure`/`const`, and also `pure`/`const` functions that cannot be marked as `constexpr`. Having said that, it is true that, in many cases, the `constexpr` functions people usually write are free of side-effects for all inputs, and therefore could be marked as `pure`/`const`, but not always, and anyway it is not what other developers will understand when they see `constexpr`.
&gt; I am wondering about std::shared_mutex. That should just be SRWLOCK (with ~1 extra function call overhead). So if you use shared_mutex as a plain non-shared mutex it should crush our std::mutex. (But shared_mutex doesn't claim to work on XP or Vista)
AFAIK the only component you need to select when installing VS will be Visual C++.
That's why contracts are the ultimate CYA. It's not your fault if your coworkers broke your function, they didn't follow the contract.
Maybe it is just the first step in the direction. Maybe C++23 or C++26 or so can build on top of that to get even closer to what we need. It is clear to me though, that without containing parser status between libraries, we are not getting anywhere, so even a modest modules proposal is better then nothing.
I don't think the current modules proposal has anything, at all, with a binary distribution scheme.
I know that. I mean that the language itself might have to change first, and that is what modules *is* doing.
You forgot the C++20 part.
I'm not under any illusion that everyone on the internet lives in the U.S., but FYI Amazon could have the book to you by Friday Feb 15. Was that email maybe from the publisher? If I didn't already have the first edition I'd jump on it. Will probably hold off for now...
Yeah, I agree that the root cause was a second change causing a bad merge, but I find it hard to picture a scenario where a merge causes a fundamental change to what type of mutex is being used without some notification. This sounds like poor team communication to me. I agree with his assessment of cpp missing some good static analysis, just think it was a bad example.
This "fast" mutex badly beats both MSVC's std::mutex and std::shared\_mutex wrt writes alone. Beats it very badly. Now, std::mutex on GCC 7.3 on Windows beats this "fast" mutex. So, why does MSVC's std::mutex \_and\_ std::shared\_mutex behave so terribly? Here is a simple test: &amp;#x200B; [https://pastebin.com/raw/WUN3cb3b](https://pastebin.com/raw/WUN3cb3b) &amp;#x200B; The "fast" mutex takes around 18 seconds, while the std::shared\_mutex from MSVC takes around 89 seconds. Try it for yourself on MSVC...
Run-time contracts don’t excite me very much. What I’d _love_ to see is compile-time contracts. Now that would be a game changer.
It can be made to only return a reference when it is given a reference, and to give a plain value otherwise. Example, using `boost::optional` because it handles storing references as pointers: #include &lt;iostream&gt; #include &lt;range/v3/view.hpp&gt; #include &lt;boost/optional.hpp&gt; using namespace std; static int arr[] = { 1, 3, 5, 7 }; template&lt;typename Iter&gt; class cache_iterator { using reference_t = decltype(*declval&lt;Iter&gt;()); Iter it; boost::optional&lt;reference_t&gt; cache; public: cache_iterator(Iter iter) : it { iter } { cache = *it; } cache_iterator&amp; operator++() { ++it; cache = *it; } reference_t operator*() { return *cache; } }; template&lt;typename Iter&gt; cache_iterator&lt;Iter&gt; make_cache(Iter it) { return cache_iterator&lt;Iter&gt;(it); } int main() { auto r = ranges::view::iota(1) | ranges::view::transform([](int x) -&gt; int&amp; { return arr[x]; }); auto cached = make_cache(r.begin()); auto&amp; ref = *cached; cout &lt;&lt; ref &lt;&lt; endl; cout &lt;&lt; &amp;ref &lt;&lt; " " &lt;&lt; arr + 1 &lt;&lt; endl; return 0; } When the transform function returns a reference, that reference is passed as-is. When it returns a value, `*cached` will return a value and line 44 fails.
I'll be honest I struggled with understanding what's going on in this so please correct me if I'm wrong anywhere. I tried to compile this, and after forward declaring Session and adding virtual destructor = default to `TextProcessor` and `factory` I get this compiler error and a "note". factory.cpp:62:82: error: rvalue reference to type 'vector&lt;...&gt;' cannot bind to lvalue of type 'vector&lt;...&gt;' auto processor = global_processor_registry.get_factory("mood_classifier").make(args); ^~~~ factory.cpp:30:35: note: passing argument to parameter 'args' here virtual Base* make(Args &amp;&amp; ...args) = 0; An aside - I don't understand what the "note: passing argument to parameter 'args' here" means, could anyone enlighten me? Perhaps it relates to the next point? I believe the error is due to this line factory&lt;TextProcessor, std::vector&lt;std::string&gt;&gt; global_processor_registry; When we create the mapping from "mood_classifier" in the map using `add` we substitute for `typename ... Args` the template parameter provided: `std::vector&lt;std::string&gt;`. Therefore when we call make on this line auto processor = global_processor_registry.get_factory("mood_classifier").make(args); It expects only a `std::vector&lt;std::string&gt;` rvalue but is being given an lvalue `std::vector&lt;std::string&gt;&amp;` and won't compile. It will compile if for example you change it to `std::move(args)`. How do you get around this problem? (It feels to me like a symptom of a code smell?) I also don't really understand why you want to specify `std::vector&lt;std::string&gt;` at all in the factory template? Is this to force users to add functions adhering to this for their classes that they add (this is unchecked though at the moment). Otherwise it just seems like repeating the constructor arguments (DRY) in two places. Also this function MakerType&amp; get_factory(const std::string&amp; name) returns a `MakerType&amp;` which is `typedef Maker&lt;Base, Args...&gt; MakerType;`. However in this case it is used to actually return a derived instance of `Maker`, namely `TemplateMaker`. Is this ok? Is it just polymorphism in action? Will it still work in it wasn't returning a reference and the type was copyable - reminds me of the slicing problem but is that only for containers?
You're right. I think that mutex that can be released from another thread can't be called "a normal mutex" in principle. Because such mutex won't defend from data races and anyone can write code like that: MyData my_data; Mutex my_data_mutex; ... void thread_one() { my_data_mutex.lock(); while(not_all_data_written()) { my_data.write_some_data(...); } my_data_mutex.unlock(); } ... void thread_two() { while(!my_data_mutex.try_lock()) my_data_mutex.unlock(); // Acquire mutex anyway. my_data.write_some_data(...); // Oops! my_data_mutex.unlock(); }
You think stacks and lists are the same thing?
Those go under the name of "Concepts."
I do love to stir up trouble.
Fwiw, I finally ported my rwlock to C++11. It happens to beat the heck out of std::shared\_mutex on MSVC 2017. My algorithm takes around 34'ish seconds, and std::shared\_mutex takes about 127'ish seconds. Here is my crude little "benchmark" code: &amp;#x200B; [https://pastebin.com/raw/xCBHY9qd](https://pastebin.com/raw/xCBHY9qd) &amp;#x200B; Can anybody else run this and test for themselves? I should probably create a new thread for this. Why is std::mutex and std::shared\_mutex on MSVC 2017 so darn slow? Damn.
Just being able to write a class in one place without having to spread it out (with error-prone duplicated definitions) over 2 files is enough to convince me to start using them. &amp;#x200B; I don't mind if it means the compiler invocation has every cpp file in my project on it. I don't even mind if it doesn't improve compile times. These are just build-system and compiler implementation details at the end of the day. They're important, but they're already not part of the standard, and they're something that could continue to be improved outside of the standard.
Type of post: "I'm sorry for spam but... I will throw more spam here xD".
I don’t _think_ that’s the same thing. What is like to see, for example, is a pre-condition that a Vec3 is normalized. I’d like other functions to have a post-condition that the vector is normalized. Then I’d like compile-time verification that a function which requires a normalized Vec3 is not called with an unnormalized input paean. Another constraint might be that an input float is within [0,1]. Can concepts do that?
 **#define trace(x) { scoped\_lock&lt;mutex&gt; lock(cout\_lock); cout &lt;&lt; x &lt;&lt; endl; }** &amp;#x200B; it's single thread code so why You are using mutex for ostream? and why are You overusing of std::endl?
I just tested it using GCC 7.3 in C++17 mode. My algorithm is beating std::shared\_mutex, big time. Around 30 seconds for mine, and about 112 seconds for std::shared\_mutex. Wow. These results are surprising, and a bit disappointing. Why is std::shared\_mutex so slow on both GCC and MSVC on Windows?
You should create one thread which will process timers from queue not spamming hundreds of new threads. 
`ENOTIN20`
No, but contracts and static analysis can do a pretty good job when combined. (If you want a better job, you may be interested in dependently typed languages or proof assistant languages.) 
Those are runtime conditions? So contracts?
So, story time. Once upon a time, we tried to fix some stuff, and broke the ABI. There was pain and misery across the world, and it significantly slowed C++11's adoption at the time. So let's not do that again.
I'd be happy if all that came out of C++20 modules was the import syntax and the standard library being modularized. That's an MVP, and I feel like anything beyond that people are still actively figuring out and discussing.
Your solution is good. **But be sure that you have a problem first**! Also, if you don't need to be able to extend the types that your factory can create [1], you may consider using and enum instead of strings, and a switch instead of a map for much better performances. [1] If your factory is in a different library than than the code of your matcher, using strings make sense, otherwise you will pay a price for no reason.
Concepts clearly.
Genuine question: given that all major compilers now support specifying the language version which code is compiled with, to what extent does it still make sense to keep backwards compatibility between language versions? I want old code to continue to compile successfully, but I don't need to compile C++98 code as C++23. Language feature deprecations and automatic upgrade tooling help here too.
This is just contracts in constexpr contexts (which you can already do btw)
Of course it is, for no other reason than you usually end up having to use a different compiler for the platform. That usually means different levels of adherence to the standard. That's one of the things I like about Go - one compiler for all supported platforms, that conforms to the language standard.
What Delphi units, D modules, Haskell/OCaml modules do would already be quite good.
I completely agree, at least iterate it's members like a tuple. 
Which isn't always followed upon. Some things in C++ only make sense to me since I use the language on and off since 1993 and try to keep up to date with it. Showing someone a random piece of C++ code and let them guess the mininum ISO version to compile it is already a good quiz question. Then we have stuff like exception specifications, dropped only to eventually be re-introduced with another similar kind of syntax for value exceptions, or how the whole auto vs decltype differences were sorted out across ISO releases. So occasionally the code does stop working.
[Don't get excited about a modular `std` yet](https://imgur.com/a/hnUt9x2)
I wonder if you get TU to compile with different versions, say C++98 and C++23 as per your example, if when everything links with the same stdlibc++, what happens given the semantic differences.
Nothing prevents you from using clang on all platforms
Sure. And all the edge cases and undefined behaviour is also consistent accross all platforms, on clang?
What I want: * Improved compiler throughput. * Not having to artificially split every damn thing I write into a definition and a declaration. Surely the compiler can figure this out on its own. Just let me write it \_once\_ (and I know some smart editors can do it for you, but that still leaves the maintenance and cognitive load on me). * Not having to write towering lists of #include statements everywhere. Just "import this library", without worrying about blowing up compile times. * Not getting bitten by everybody else's macros. * Not seeing all of windows.h in intellisense anymore. This last one I hope to achieve by creating a module "mywindows" which includes windows.h and exports precisely what I need \_and nothing else\_. I'm hoping I can do that, and in doing so eliminate the vast wall of symbols I honestly don't care about, giving more prominence to my own symbols instead. Also, I'm hoping that this will vastly decrease the size of my pch files which currently run up to around 80MB each, as well as my .ipch files which seem to average at about 140MB each. I'm currently looking at 6GB of these files in total - enough that it is a serious drain on disk usage, on memory usage, and on IO. And ideally: * Being freed from having to having to order everything I write manually. This, too, is something the compiler \_can\_ figure out for me - so why do I have to do it? But ok, I'm not holding my breath on this one :-( 
This is basically the right answer. C++ is an extraordinarily powerful and expressive language tied down by an extraordinarily clunky and inefficient dependency management system. While many other features would be *nice* to have, a sane, scalable, 21st-century dependency management system is far more *important* than any amount of syntactic sugar.
Thanks! That was actually a really good talk. I've seen a lot of great talks from cppcon 18, but this one have escaped me.
I would personally prefer concepts. Any compile-time constraint (literal), I am all for it.
&gt; VisualC++ doesn’t have its source code available Huh? 
Thank you! Just what I was looking for. I quite like the idea of having example repos like this where we can collaboratory improve through discussions and PRs. Also, the idea of not reinventing stuff is really important. This have caused many of my earlier toy project to a halt, due to spendng too much time on reimplementing stuff. Though, it's sometimes hard to find and and implement the right library is difficult, and header-only libraries ofcourse makes this a lot easier. I guess modules in C++2x will be a game changer in this regards?
This looks like a standard Java code to me. It's equally hard to read in Java too. Factory pattern is often used when your objects have complex construction. Judging by this code alone, your construction seems rather trivial. Then again, I have never needed factory pattern before, maybe it's just me.
I would say modules but the current modules proposal isn't really all that interesting to me(I'd prefer something like Rust's Cargo). \-ranges: not sure about this, my experience in VS with such constructs has been very negative since the debugging experience is \*terrible\* once you started using nested/chained lambdas.. &amp;#x200B;
There are papers tackling this exact question and the problem is that for the first time C++ won't allow embarrassingly parallel builds. Compute Units can only be build after the modules have been built.
Alas N26, Starling, Revolut etc either charge a monthly fee to incorporations, or won't do business with them (their "business accounts" refer to self employed persons, not incorporations). I'm personally much happier with my retail bank here in Ireland. No monthly fees if you keep the balance above €3k. SEPA forces them to charge low fees for wire transfers, online banking works well, plus has an OTP physical token to prevent compromise. I just wish they paid more than 0.05% interest on deposit, but that's not their fault, it's the ECB's. 
This sounds like you want a dependent type system, like Coq or Idris.
I've read through that too. I imagine there must be a lot of people like me who are stuck trying to infer the basics of the underlying proposal by way of the "sales pitches" and the detailed criticisms. That's not meant as - that's on you - but I just wish there was a way to better come up to speed on what it actually is.
That would mean that you have two threads accessing the same non atomic object (the shared pointer variable) at the same time and one of them modifies it. That is always UB. It's like asking: What is happening if someone copies my shared_ptr while I'm destroying it. That is simply not legal just as for almost any other type in the standard library. 
&gt; I went and wrote a not-quite-philosophically-defensible optimization in vector::insert, where if we’re inserting just a single element in the middle of the vector, and trivial relocation is available, then we use memmove So trivial relocation is an optimization of move constructor immediately followed by destructor (of source). I'm pretty sure doing that for each element, one by one, would be a valid implementation. So I don't see the philosophical problem.
congratulations! i've been looking at this for a while, guess it's time to play around with it. out of curiosity, why does https://www.boost.org/doc/libs/develop/libs/outcome/doc/html/reference/policies/base/ub.html take a template param? we have something similar in our code base, but it doesnt have any args.
&gt; Exceptions are easy to use and fairly easy to reason about. I disagree. In fact, this is the main reason why I don't use exceptions: I just can't write exception safe code reliably. In theory, using RAII everywhere and letting the unwinding code clean everything should make it easy, however in practice there often is some resource that will need special care (I work in graphics, that might be an aggravating factor) meaning that you have to write a lot of exception handling code. And that's a nightmare because or point 2: &gt; The biggest drawback is that handling exceptions is not enforced by the type-system. It's really freaking hard to know what can throw and what won't. I just find using `expected` a lot simpler, especially with `[[nodiscard]]`.
there's a broken link to boost::outcome at the top
Oh dammit. I had high hopes for modules, but as usual @vector-of-bool is right on the ball. I can only hope the committee starts listening ☹️
It is amazing the amount of whining I see about modules. They will give you, as a minimum, better compile times (maybe not amazing since day 1) and great isolation. You all talk about modules as if every problem found was unfixable later and as if having them was going to be a step backward from includes...
It is not just sybtactic sugar. It is way better isolation.
Love Cmake
Reference cycles would like to have a word with you.
&gt;however in practice there often is some resource that will need special care Can you provide some examples?
Prevents immediate instantiation. I vaguely remember that clang-tidy or some other lint tool spews otherwise.
Out of interest, is there a reason that the `_ub` function doesn't use MSVC's `__assume` built-in? AFAICT, in terms of optimizer hints, `__assume(0)` is similar (if not identical) to `__builtin_unreachable()` isn't it? Is the `__declspec(noreturn)` enough of a hint on MSVC?
&gt; It's really freaking hard to know what can throw and what won't Rule of thumb: everything but dtors, move ctors, move assignments, swaps and standard C functions either already throws or will one day.
I'm completely on the other side of the fence, but might be because I'm mostly on windows. I find it to be a crappy markup / script frankenstein mix which requires an awfully lot of typing to accomplish very little, while also being an additional out of version control dependency. Not a big fan of to much "auto-magic", because it's bound to fail and hard to debug. At least in the past it often used to fail to generate a working build for a lot of projects using MSVC, perhaps not entirely the fault of CMake though.
I don't consider myself a dullard, but this seems very difficult to understand. At a minimum, "left" should be renamed error and "right" renamed value. Also, the conditional mapping stuff does not seem easy to reason about. Even the trivial float to string example is a head scratcher. And I expect real functions will become a tangle of nested lamdas.
Objects that require two+ steps initialization which is quite common when you are interfacing with C ish APIs, or anything that embed a state machine (Most IO and graphics systems)
You don't need concepts for this, and probably not even dependent types. Just use the existing type system: Create a strong typedef of Vec3 named Vec3::normalized auto normalize(Vec3 vec) -&gt; Vec3_normalized ; auto functionWhichRequiresNormalizedVector(Vec3_normalized vec) -&gt; result_t; // can only be called with normalized types. For your second example, I'd like to point you to http://doublewise.net/c++/bounded/, except that it only does integers, as you can't have floats as a template parameter.
Sorry, but I'm afraid that without a code snippet (even in pseudo-code) your point it not clear for me. 
To be honest, I hadn't thought to do so until now. Logged to https://github.com/ned14/outcome/issues/172. Thanks for the suggestion!
&gt; everything but dtors, move ctors, move assignments, swaps and standard C functions either already throws or will one day. Sure, but then every time you have any resource that isn't exception safe you have to bulletproof your code to death. That's very hard to do and is a lot of extra code. With an `expected` you don't need this pessimization which saves a lot of headaches. And if you ever miss something `[[nodiscard]]` will catch it for you. 
The hardset part of RAII is wrapping every library you use. Want to call glGenTextures? Nope! You must get that tex id wrapped in a class that calls glDeleteTextures automatically. Making it impossible to write exception unsafe code with the wrapper isn't hard but takes time. I can't think of any paterns that can't be wrapped though.
&gt;there often is some resource that will need special care (I work in graphics, that might be an aggravating factor) meaning that you have to write a lot of exception handling code Doesn't that get handled by destructors? When you throw an exception that leaves a scope the destructors of everything in that scope get called.
If you do add_library(solver::solver ALIAS solver) then later you can use target_link_libraries(... solver::solver) without fear of typos going unnoticed.
Visual Studio do not support intellisense for cmake scripts or features like "add this file to project". If you want write cmake scripts I can recommend CLion (problably IDE with best support for cmake now).
It is acceptable for *simple* projects like library or small app. It is very, very bad for big and complex projects (many build options, many compilers, platforms, etc).
I also work at graphics (in games) and exceptions are flat out banned in our codebase. I've never heard anyone miss them. They also either take the low-level error handling away from where it should be (next to the error, where the situation might be salvageable) and into somewhere else (wherever the exception is caught), or then they're just a fancy if.
I had seen a mention of it on a mailing list (possibly `comp.stdc++`) a while back, but I've been searching today for around 30min, and haven't yet found it. It paralleled the other votes for needing critical sections, and I think the overhead (memory + speed) was the basis for rejecting `shared_ptr::release()`, at least within that discussion. Lemme see if I can dig it up...
Yeah, it's very confusing. I dislike C++ exceptions a lot but if given a choice, I'd still choose them before that sort of a self-made contraption. 
Have you taken a look at [https://zajo.github.io/leaf/#rationale](leaf)? How would you compare it to eithers?
Cool. I wasn't sure. This kind of stuff is at the fringes of my knowledge TBH. Great work on this library and getting it into Boost!
Easily fallible? If it were so easily fallible we'd see race condition bugs in the wild all the time
 add_library(solver SHARED src/solver.cpp) You shouldn't specify SHARED unless your library explicitly depends on being compiled as a shared library. There is a BUILD_SHARED_LIBS option which does this on behalf of the user. This way they can use your library as shared or static. 
&gt; I can't think of any paterns that can't be wrapped though. I am sure everything can be wrapped if you try hard enough. The question is, is spending time wrapping everything worth it?". &gt; Want to call glGenTextures? Nope! You must get that tex id wrapped in a class that calls glDeleteTextures automatically. Of course, but the problem handling complex state machines correctly. It can absolutely be done with exceptions, it's just harder. Imagine: gfxDevice.TransitionResource(image, TextureLayout, RenderTargetLayout); gfxDevice.SetRenderTarget(image); RenderStuff(gfxDevice); gfxDevice.TransitionResource(image, RenderTargetLayout, TextureLayout); If RenderStuff throws and the exception escape, it leaves our `image` in an unexpected state so we have to make sure the second transition is done anyway. We can do this using `try catch` but that sucks so we do: { gfxDevice.TransitionResource(image, TextureLayout, RenderTargetLayout); DEFER(gfxDevice.TransitionResource(image, RenderTargetLayout, TextureLayout)); gfxDevice.SetRenderTarget(image); RenderStuff(gfxDevice); } It works, only now the code isn't sequential which makes it much harder to understand, and to do this **you have to know that `RenderStuff` can throw**. When working on a code base with half a million functions, it's basically impossible. Using `expected` you get an error if you ever forget that `RenderStuff` can fail and the final code looks much nicer: gfxDevice.TransitionResource(image, TextureLayout, RenderTargetLayout); gfxDevice.SetRenderTarget(image); RenderStuff(gfxDevice).IgnoreErr(); // &lt;- we can even see that the error has been considered and how it was handled. gfxDevice.TransitionResource(image, RenderTargetLayout, TextureLayout); *************************** I don't argue that exception are bad or impossible to use. But for what I use C++ for (which probably isn't representative of the average case) I find monads much much nicer/easier to use.
Sometimes destroying everything isn't what you want to do. [See my example in another answer.](https://www.reddit.com/r/cpp/comments/aqir7n/error_handling_in_c_eithers_vs_exceptions_vs/eggfi39/)
[Of course, here is my example from another answer.](https://www.reddit.com/r/cpp/comments/aqir7n/error_handling_in_c_eithers_vs_exceptions_vs/eggfi39/)
So you want "RenderStuff" to run without exceptions. Doesn't that mean that you should identify what inside it can throw an exception and catch/handle it inside that routine?
Let's imagine that with time someone rewrote your code that way: ``` gfxDevice.TransitionResource(image, TextureLayout, RenderTargetLayout); gfxDevice.SetRenderTarget(image); if(ValidCondition()) RenderStuff(gfxDevice); else { ... // A lot of code. if(SomeVeryRareCodition()) return; } gfxDevice.TransitionResource(image, RenderTargetLayout, TextureLayout); ``` I just want to say that approach with DEFER/gsl::finally will work and will save you from stupid errors even without usage of exceptions.
That's what toolchain files are for. 
&gt; So you want "RenderStuff" to run without exceptions. No. In this case I don't care if it fail, which is different. *This is an example*, in a real engine you will actually want to handle failure in a meaningful way. &gt; Doesn't that mean that you should identify what inside it can throw an exception and catch/handle it inside that routine? And do what? The role of `RenderStuff` is to render stuff... There is no correct universal behavior if it fail: what to do depends on what the program is currently doing at a much higher level. On the client you might want to stream more aggressively to free memory which you probably don't want to do on a farm baking light maps. 
#BOOST_FUSION_ADAPT_STRUCT IDE: "Explore macro expansion (5323 steps)"
&gt; can be checked in debug-builds and exploited for compiler-optimization in release-builds aliasing and vectorization awaits
No, no it is not. Toolchain files are for telling CMake about a compiler to use and details about the target platform when it is not the host platform as well. You're thinking cache initialization files (the `-C` flag).
The left / right names refer to the position of the types in the template. Eithers can be used for more than just error-handling, so the names are generic. We put the errors on the left because otherwise errors would be "right", and that would get VERY confusing! &amp;#x200B; In F# there is a \`Result\` type with \`map\` and \`mapError\`, which is a convention you might prefer. You could do the same in a C++ library. 
&gt; often used to fail to generate a working build for a lot of projects using MSVC, perhaps not entirely the fault of CMake though. I haven't heard this. Please file issues when you see them. We can't fix what we don't know about (and we have *many* MSVC-using builds generated by CMake, so it isn't that MSVC is neglected).
&gt;A feature with identical syntax to what they proposed in the paper was once in the language and has been deprecated: Dynamic exception specifications. It fell out of favor, and I really don't know why. But it would be worth finding out why because there could be very good technical reasons why it's not a good idea. Even if this new feature is different, reusing syntax of another feature (even a deprecated one) would be a BAD idea. The problem with dynamic exceptions was that they didn't really limit what could be thrown by the functions you called, so in theory whenever you add or remove an exception type in a function you needed to modify every calling function recursively. In practice the result was that dynamic exception specifications were either wrong (and failed at runtime) or just specified a base class of all exceptions (so didn't really have any purpose beyond nothrow). Specifying exactly one static exception type means that it can be statically checked at compile time, and that whole problem is avoided.
That would be bad indeed. &gt; I just want to say that approach with DEFER/gsl::finally Absolutely. In this case DEFER/gsl::finally is the right solution. But this is orthogonal to my original point, (which is that monad are easier to use correctly that exception in code interfacing with stateful APIs). In your example the bug is entirely within the function. You don't need to know what `RenderStuff` does to find it. Which is really freaking nice.
By build options I mean high level options like what to include/exclude from the build.
What are you talking about? What tried-and-true alternative for large cross-platform projects do we have besides CMake? QMake? Aside from Qt-only stuff, CMake does everything better. Bazel is getting close, but it's still in early stages and attacks the problem from much different angle. You probably have a bad experience with CMake because examples you encountered were written without much though or research put into it. To avoid that, we need to treat CMakeLists.txt as any other code.
It will be here: [https://cpponsea.uk/videos/](https://cpponsea.uk/videos/) Note that it's empty for now, at time of writing this (we had some small issues and are having to re-encode the first batch I was hoping we'd have up by now) - but should start populating later today. That redirects to the YouTube channel at the moment, but I might put an RSS feed there later.
None of the workshops were recorded, which is standard practice.
&gt;But this is orthogonal to my original point No. If you use DEFER/finally approach then an error-reporting strategy doesn't matter. Your code still be correct in presence of exceptions or not. So you can't refer to a complex cleanup as a problem.
Out of curiosity, do you disable exceptions completely (ie `-fno-exceptions`) or do you just not use them?
Depends, for work we typically compile with `-fno-exceptions` (because exceptions are simply forbidden we can gain a littlebit of perf that way). For my own code I tend to not use exceptions but I don't disable them.
Exception specifications of any kind are currently impossible to implement anyway, as far as I know. The only way it could be done in C++ is in code that specifies exceptions everywhere. That is, your code does not call functions which don't specify their exceptions, because otherwise they could throw anything.
Why, because attendees pay an attendance fee?
&gt;IDE/CI/CD =&gt; CMake (calls python/bison/etc) =&gt; Ninja/MSBuidl/NMake/make/etc =&gt; gcc/clang/cl. &gt;Multiply this by several OS and you are in hell. What kind of hell would this be without CMake?
One improvement: cross-platform (or generator-agnostic) way of building is to call 'cmake --build .' instead of make, msbuild etc.
&gt;What are you talking about? What tried-and-true alternative for large cross-platform projects do we have besides CMake? QMake? I know well only about QBS. It is no Qt-only, it is a generic build system (not just C/C++). &gt;You probably have a bad experience with CMake because examples you encountered were written without much though or research put into it That is a very good illustration of one of the problems: there are too many ways to solve even simple problem with CMake. &gt; To avoid that, we need to treat CMakeLists.txt as any other code. Exactly, that is why build system should not use it's own language.
Congrats! Outcome has been quite the journey for you for quite some time!
It is hard with any tool with big enough project, but generators like CMake makes problem more complex comparing to true build tools like QBS. Add to this CMake language and some quirks.
Copy-constructing a null shared pointer is legal, you know :)
Maybe I explained my point wrong. The code without defer works as long as `RenderStuff` can not fail. Now, if one day, `RenderStuff` is modified and can fail, with exception you get no warning that your code is potentially broken, with expected you do, because the signature has to change. Of course if the code was written with defer from the start it would always work. But, I know for a fact that I won't always write code correctly the first time. That's why I prefer to use the more explicit method. If you trust yourself with writing code that is exception safe without knowing what throws what, you should absolutely use exceptions. My personal experience tells me that I can't trust myself with that and rather than pretend that I understand what my code is doing and hope for the best I prefer to use something I know I can manage, even if it's a little bit more verbose. 
Nice! I stand corrected. &amp;#x200B; There's definitely a use case for this sort of thing.
Two thread referencing the same shared pointer is UB, so why are we even having this discussion??
It doesn’t work that way. A smart pointer increments reference count on construction, decrements on destruction or reset: when you have a smart pointer [value] that is not null, it’ll remain not null, and you are guaranteed that the pointer-to object exists. No other shared_ptr methods touch the count – certainly not dereference operators: it’d have atrocious overhead and is unnecessary.
How? They dereference via the control block. Smart pointer points to the control block, control block has a pointer to the object. The dereference operator basically is this: `return this-&gt;control_blk ? control_blk-&gt;obj : nullptr`. That’s the actual code, no atomic ops or anything like that. A smart pointer could also hold two pointers: one to the control block, and another to the object itself, and return the latter directly. Some smart pointers have a single tagged pointer: if the tag is set, they dereference via the control block, otherwise the control block is contiguous with the object as a result of `make_shared` and they dereference it directly. 
Just curious if you have ever had to write and/or maintain a `make` based build system. Because nothing makes me appreciate CMake like maintaining a twisted mess of Makefile. Also, note that just because a project uses a cross-platform build tool does not necessarily mean it is a cross-platform project.
It has often seemed it would never end, yes. And next comes the slew of bugs which I didn't know I wrote, upstreamed from everywhere Boost is used, for many years to come[^1]. It'll be very humbling, and good for me as an engineer. One of the big reasons I invested the effort! [^1]: Did you know Boost ships as an installable package on https://openwrt.org/? A recent version too. So, quite literally, you can program in C++ 17 using Boost on your wireless router. I find that quite stunning that that's just *normal* now.
Updating config files has been shown to be insufficient for managing distributed configuration. There’s more state to control that mere configuration file contents. You need to change this complete state in a controlled fashion, and that’s why Ansible is a “Swiss army knife”: it has no choice – it wouldn’t be functional otherwise. 
&gt;If you trust yourself with writing code that is exception safe without knowing what throws what From my experience there is no need to know what throws what. It's only necessary to understand that almost all can throws (except rare functions/methods with noexcept mark, like swap functions). &gt; My personal experience tells me that I can't trust myself with that and rather than pretend that I understand what my code is doing and hope for the best I prefer to use something I know I can manage, even if it's a little bit more verbose. I do know that I make mistakes in code. Because of that I prefer to write code that will cleanup resources regardless of reasons of scope exit (early return or exception). What I'm missing from C++ is something like noexcept section in code. For example: ``` // v.1.0 void first_very_important_action() noexcept {...} void second_very_important_action() noexcept {...} ... void some_my_application_code() { ... // Ordinary code that can throw. // That fragment must not throw. noexcept { // I assume that code in that fragment doesn't throw. first_very_important_action(); second_very_important_action(); } ... // Ordinary code that can throw. } ``` After some time someone changed signature of first_very_important_action, but all other will be the same: ``` // v.2.0 void first_very_important_action() {...} // NOW IT CAN THROW! void second_very_important_action() noexcept {...} ... void some_my_application_code() { ... // Ordinary code that can throw. // That fragment must not throw. noexcept { // I assume that code in that fragment doesn't throw. first_very_important_action(); // OOPS! second_very_important_action(); } ... // Ordinary code that can throw. } ``` I would to receive a message (or even error) from compiler on attempt to use no-noexpect function inside noexcept-section.
The template metaprogramming parser generators treat the compiler as if it was a good Haskell runtime. It’s not. Running template meaprograms efficiently is still an open research topic, and it’s unlikely that it will ever be solved: there’s zero need given the evolution of the language. And the compile performance of metaprogrammed parsers sucks, and the whole thing is brittle and limited in what it can do. C++20 allows you to do much better than Spirit ever could, so either wait for someone to write an **imperative** parser generator in that, or just use Bison or Antlr or Lemon or whatever: your experience will be miles better. 
This is yet another one of those things in C++ that just kills people who are new to the language. Hey, Google, video games, and other cool companies disable exceptions and you get a very small performance gain at the same time - certainly I shouldn't use exceptions! Then they discover the other side of the argument from equally smart people and the confusion commences. Yes, I am talking about myself - so maybe it is just my own issue, I don't know. As a small independent developer still learning I know I ran into this struggle, and it is silly because it doesn't really even matter to someone like me. One thing I tend to notice in my small programs is that when an error happens I either do not really care at all and a simple log message is good enough, or it's fatal and I just want the program to crash - so essentially I naturally do not use exceptions. I get the sense most people on this subreddit have jobs or work on projects that force them to use one design over the other - or that one is just an obvious choice for their project. As a small guy it shouldn't be difficult to figure out an error handling design to default too.
Usually, you won't need \`FindXXX.cmake\`. For example, \`find\_package(Catch2 2.5.0 REQUIRED)\` works out of the box. You simply have to install catch2 in your prefix path. The prefix path can be in your user directory or inside your project directory.
One thing I've found as useful is not to think of it as a choice of "Exceptions vs Error Codes" (also, wtf, error codes? error objects please!) but rather thinking about disjoint areas of code in which exceptions can propagate and boundaries between them in which exceptions must be caught and coerced into an Error object. To take a trivial example, if you are exposing some code in a shared OS-level library, the public interface of that library is absolutely a boundary that must coerce exceptions into returns (unless you propagate C++ exceptions across library boundaries). Often it's as simple as struct Error { std::string what(); ... }; using TypeOrError = std::expected&lt;T,Error&gt;; [[nodiscard]] TypeOrError PublicFunction(...) { try { InternalFunction(...); } catch (std::exception const &amp; e) { return Unexpected&lt;Error&gt;( e.what(), .... ); // Some places make this a static member of Error instead of a free function, doesn't really matter } Annoying boilerplate, yes, but now your reasoning can be made a lot simpler. You have to reason about exceptions within the boundary of this library/module and only within the types and causes of exceptions that it and its children can call. You can continue this sub-division until you feel you have the appropriate boundaries. To me, this really crystallizes the way I want to think about the problem. Colloquially: exceptions "live" in these areas which are fenced off by these "walls".
Isn't that what I just said? &gt;(many build options, many compilers, platforms, etc).
&gt; From my experience there is no need to know what throws what. It's only necessary to understand that almost all can throws I agree, but as I already wrote in some other comment; writing code that is safe for this pessimization is more work than relying on [[nodiscard]] to tell you what cases you actually need to handle. &gt; Because of that I prefer to write code that will cleanup resources regardless of reasons of scope exit (early return or exception). I prefer too. but that's not enough to do it reliably =/ &gt; What I'm missing from C++ is something like noexcept section in code. For example: That would be awesome. And probably solve my gripe with exceptions. The problem is that `noexcept` means "call `std::terminate` if an exception tries to pass through" not "does not fails (in a recoverable way, ...)" which is what I am interested about. 
Ah, I can see that now. I got stuck on "many build options". Seeing as CMake doesn't support more than one platform or compiler (per language) per build, I probably did some short circuit logic there.
No problem, I was concerned that I've been egregiously misusing CMake this whole time. Apologies if I came off as overly defensive. 
Hmm. Calling `bison` during configure is not something I'd say is "normal". I'd usually embed that into the build graph. But, I don't know your system so I'm not going to guess how much legacy stuff you're trying to work around. The upshot of two-step build tools is that I don't have to keep specifying input parameters to every build invocation (e.g., enable Python or MPI support) and that gets remembered when the build generator tool gets rerun. Yeah, `-include config.mk` can be fine (e.g., Git), but discoverability is usually a problem there. As for complex projects, yes. CMake can be heinous when it grows into that, but I think any build system would when the targets are so diverse. I recently did an uplift of VTK's build to "modern" CMake with target usage requirements and such and being able to rework the build around CMake's new features has, IMO, vastly improved the CMake code.
&gt; writing code that is safe for this pessimization is more work than relying on [[nodiscard]] to tell you what cases you actually need to handle I can't agree. When you believe that code you use doesn't throw you will fall into problems if that code throws (it doesn't matter why: may be someone changed it, may be you have wrong assumptions).
Valid technical concerns aren't "whining".
BTW thanks very much for your work. CMake is fantastic. (We use it under Yocto/BitBake)
Yes, but painting the apocalipsis on top of it all the time about every single concern as unfixable seems disproportionate to me.
IDE/CI/CD =&gt; CMake (calls python/bison/etc) =&gt; Ninja/MSBuidl/NMake/make/etc =&gt; gcc/clang/cl. Why not `cmake --build .` then?
I wasn't talking about exceptions, but about using monads as the only error handling mechanic (for the system you are working on). This way errors are **always** part of the type systems, so you don't have to make assumptions about what can fail and what can't, everything is checked, so if you ever forget to check something you'll `error: ignoring return value of function declared with 'nodiscard' attribute [-Werror,-Wunused-result]`. If `noexcept` actually generated errors when an exception was susceptible to escape instead of calling `std::terminate` I would happily use exceptions. 
I would blatantly reject this code in a code review. There are several issues and I will try to list them here: * There is no virtual destructor. This is the first outright bug in your code and definitely worthy of a rejection. * The variadic template argument is in your class instead of method. I guess you've done that because making a pure virtual template class isn't possible and therefore you put it in the class instead. But here is the thing, type deduction happens on the class level and you can't therefore use SFINAE in your make method. * Why structs and not classes? There is a generally speaking a consent among C++ developers that struct should be mostly data holders. While your code isn't wrong, it's still unusual to use structs for more than data holders. * Using raw pointers instead of smart pointers in 2019 is not good. While raw pointers are ok in some cases, your code is no such case. I believe that your are junior level developer capable of learning new features in a very short amount of time. But, taking constructive criticism which helps you improving your code will benefit you in the long run. The code is definitely over-engineered and overkill for the intended purpose. Also, the service locator pattern should be avoided if possible. I myself use it in tightly coupled legacy code to get rid of said coupling. But the service locator does still couple your code in some sense. Try to use different patterns instead. And as someone has already mentioned, global variables should be avoided at all cost. In your case you have to use one due to the service locator pattern.
No, they are verifiable at compile-time.
That would certainly be a way to do it. But it’s not one that scales.
What specifically from C++20 would make parser better? Concepts?
Never had to maintain a make based build system. We use premake, and while it's certainly not perfect it's flexible, debuggable &amp; easily extendable if one knows lua.
C++ modules do not result in purely binary libraries, so the binary scenario you want is not addressed. Think of them as kind of a super PCH plus name lookup/isolation and composition rules.
I think we are going to have to break ABI again; we need to bundle more than 1 bugfix in this time though.
To my knowledge (which may be outdated because I didn't touch Java in eleven years), Java did not change the widths of integer types and you can't really inspect the bits of a reference to see the difference between a 32 and 64 bit address. W.r.t. JNI, the jni header defines all the necessary data types that are used for the interface. Stick to those and you should be fine. Depending on your platform, the C/C++ type `long` might change from 32 to 64 bit. If you have some piece of code that relies on `long` being exactly a 32bit value, this has to change, obviously. For these situations, we have all the type aliases in `#include &lt;cstdint&gt;`. In general, avoid assumptions about the width of the various integer types on the C/C++ side. The ISO standard only guarantees a minimum range of possible values they can store. For example, `short` must be able to hold values between -32767...32767, possibly -32768 (I'm not sure about whether C++ mandates 2's complement by now, if not, -32768 is not part of that range). Good luck!
Meson is mature enough and better at many areas than CMake. Better documentation as well. 
If you don't use -fno-exception or don't mark all functions in your code as noexcept then you create a false sense of safety: you think that your error handling mechanic is based on monads only, but you can prove it, there is no help from the compiler. Expecially if you use a lot of 3rd-party code, expecially if that code evolves with time and you have to switch to fresh versions. At some moment some of your underlying code throws and... And we don't speak about other corner cases: like struct/classes with complex attributes (and initialization of those attributes can fail) or like operator overloading.
Here is an easier way https://gitlab.com/LIONant/properties 
&gt;you have to assume everything can throw (which is a lot of work) I can't say it is a lot of work. There is necessity of checking functions to be called only when I write noexcept code like destructors, move constructors/operators, swap functions. And noexcept-code is a small fraction of the whole code.
Yah, agreed.
You are right, that's why we use `-fno-exception`. My point of monads being easier to work with because they are more checked absolutely falls apart if you mix them with exceptions, but when I say "I use `expected`" I also mean "I don't use exceptions". &gt; Expecially if you use a lot of 3rd-party code, expecially if that code evolves with time and you have to switch to fresh versions. We typically don't update 3rd-party code in the middle of a project, especially without reviewing the changes carefully. &gt; And we don't speak about other corner cases: like struct/classes with complex attributes (and initialization of those attributes can fail) or like operator overloading. Never actually had problem with any of these. Operators and factories can return `expected` too and it works just fine. (although I would argue that if a function can fail it probably shouldn't be an operator). 
Pretty much - or, more specifically, a large part of the ticket price goes to the workshop instructors themselves. Some might be ok to have it recorded, still - but then you'd have 7.5 hours of video to watch!
Moderately interesting post, but I don't see why it starts with a complaint about floating point math. That has nothing to do with pretty printing.
&gt;that's why we use -fno-exception It means that you can't use a lot from the standard library. You can't also use a lot of 3rd-party libraries. Maybe it is not a problem in your specific conditions but it doesn't lock as a good situations for other C++ developers. &gt; Never actually had problem with any of these. Operators and factories I think it that "no problems" and "factories those returns `expected`" are mutually exclusive :) The necessity of writing a factory is a problem by itself. For example, with the presence of exception I can just write: ``` class my_class { some_complex_class a_; another_complex_class b_; public: my_class(some_environment &amp; env) : a_{env} /* can fail */ , b_{env} /* can fail */ { ... // some code that can fail. } ... }; ``` That is a straightforward code that can be understand even by novices. I suppose that rewriting it in form of a factory that returns `expected` will require some more lines of code (and additional lines for factories for `some_complex_class` and `another_complex_class`).
The binary scenario is already addressed today, my point was about not waiting 30m for something that takes a couple of minutes in Ada.
What about another thread using a weak\_ref and creating a shared\_ptr from it?
but it makes my code ugly and complicated without using exceptions.
Note that this question of handling dependencies is ongoing and so far without resolution. &amp;#x200B; It will never be resolved. The question itself is flawed. &amp;#x200B; Currently a library A is considered dependent on library B if some header file in library A refers to a header file in Library B. Consider an example of the serialization and date time libraries. The boost date time library supports serialization via the boost serialization library. Makes sense. And the automatically generated dependency graphs show this. But those graphs then imply that date time is dependent on all the other libraries that serialization depends upon. But this is only true for application which use serialization of date time. Other applications are not dependent upon serialization. The review of the dependency graph is misleading. The dependency graph fails because that it presumes the existence of a concept named "library dependency". But as the above example demonstrates, such a concept cannot exist independently of the application in question. So a dependency graph is application specific and should be generated as such. Apply the dependency graph tools to the application as the root and you'll get a much smaller list of dependent libraries - and an accurate one. The effort to refactor Boost so that libraries dependencies are minimized is a fools errand and will never be successful. What needs to be done is to improve workflow: Take application -&gt; generate dependencies -&gt; update build file CMake, Boost Build or ... -&gt; download true dependencies -&gt; build application. Until developers adopt this workflow, the will continue to spend man years of effort on trying to solve and insolvable problem.
&gt; You can't also use a lot of 3rd-party libraries. The game industry has a serious case of not invented here culture which make it a non issue. &gt; I suppose that rewriting it in form of a factory that returns expected will require some more lines of code (and additional lines for factories for some_complex_class and another_complex_class). Yes, but I am fine with it. It's a bit longer but it's very straight forward code so it's easy so write and easy to read.
This is an interesting problem, thanks for sharing! I feel like in this particular example, you have not used the type system to describe this problem, and that you could transform this snippet in a way that would be more type heavy and exception-safe (and maybe even not less readable!). (eg. RenderStuff requires that particular image to be in that state, but this is not enforced, the transition source and destinations are not enforced, etc. - I could imagine using something like a scope guard to ensure transition: for example taking a `ImageInLayout&lt;RenderTargetLayout&gt;&amp;` as parameter to `RenderStuff`)
But it's not the de-facto \*standard\* build system \[generator\], as CMake is, and neither is it looking like it will become that. So what's the point? 
I do not love it, but I think "modern" CMake does not deserve all the hate that CMake usually gets. Its syntax isn't great, but it's clean, flexible, and all around good enough. And a \*lot\* of projects support it. In fact, if a project decides to arbitrarily go with an alternative way of generating build files, and not support CMake, I'll probably try and avoid it. Interoperability with CMake is key in today's C++ library ecosystem.
That was what I was hoping for :-)
Just wait a week more for the trip reports. Committee members will probably bee too occupied with paper reviews anyway.
It has a lot to do with pretty printing because the default formatting precision used by `printf` and other methods is what largely leads to misunderstanding and questions like that. With proper default formatting the answer to this SO question becomes obvious: ``` #include &lt;fmt/core.h&gt; int main() { // prints 0.30000000000000004 != 0.3 fmt::print("{} != {}\\n", 0.1 + 0.2, 0.3); } ```
&gt; but I don't see why it starts with a complaint about floating point math Where does it? If you mean the sub title linking to an SO question: that's where we just have to assume most junior devs stand. I once tackled thatproblem, and *had I known it's complicated, I probably would have succeeded*. Approaching it as *"can't be that hard, it's just an `itoa` with embellishments"*, failure within allotted time was preprogrammed. Boy, was I wrong. But at least I learnt one thing: *"Surprisingly complicated"* hits that nail on the head. 
As far as I know the answer is "you can't". In the past, attendees have "live tweeted" during meetings, but AFAIK it was requested that they no longer do so until after the final plenary session.
Nope. That just makes you selfish. Please just leave. 
&gt; If you mean the sub title linking to an SO question That's what I mean. That question is perfectly valid, floating point math is broken, or at least very counterintuitive. But the rendering with junk in the last position is accurate, or at least not wrong. that said, the article as such is interesting and I appreciate that pp'ing a floating point number is not trivial. 
Yup. That's actually what I am trying to do in [my own toy engine](https://github.com/gan74/Yave). It has a serious problem though: it require many many functions and class to be templated. This means that a lot more code has to be in headers which increase compilation times quite substantially. For a 7 digits LoC code base it can be really bad. For comparison: my 18LoC pet project takes about half time to compile than the project I work on at work for single file modifications despite being 3 order of magnitude less code and debug symbols are 7 times more massive relative to the size of the executable.
If the image really must be turned back to TextureLayout, then the 2nd TransitionResource is really a clean-up action. RAII says clean-up should be in a destructor. So another option is to wrap TransitionResource with TempTransitionResource, which would set the layout and return a class which reverts the layout at destruction. "auto" can be used for that returned class to avoid having to worry about its name. The complexity of non-exception code is that longer functions have many places they can error and you have to write the correct clean-up for all cases. That can be done with greatly nested ifs, duplicated cleanup code, and/or gotos. With RAII you just think about the cleanup when the change is made and forget about it for the rest of the function. I mostly only use these wrappers for larger projects, or if they already exist. Smaller code might ditch error handling entirely or just use asserts for sudden death.
As I understand, an entity can only have one of `Mass`, `Position`, etc.? I've been thinking about components for games too and trying to get something nice to work, the biggest problem I can't solve cleanly is giving two "sibling" components the ability to talk to each other.
Yes we know about Eurovision contest. The prices of accommodation went significantly higher... :]
Clang on windows is not exactly a super easy mature solution. Visual Studio's C++ lib still has to be unless you want to build it yourself and not have certain things like std::filesystem. I check every few months for how I can easily have clang on the command line, isolated and separate from visual studio and it is far from easy.
Who would go to that on their own!?
One lucky person! 🍀
It looks like something new, but it's actually a repost from [two years ago](https://hackernoon.com/error-handling-in-c-or-why-you-should-use-eithers-in-favor-of-exceptions-and-error-codes-f0640912eb45).
It's worse than just correctness of handling exceptions, which a hypothetical static analyzer could address. A big part of the problem is that there are data structures which are outright impossible to make exception-safe (with the strong guarantee). The simple `flat_set` for instance, if you have a throwing move operation during an insert, will be unable to ensure its invariant (all elements are contiguous and sorted by key) and unable to recover (the only to recover is to move elements back, which could also throw). The only options are to make `flat_set` ridiculously inefficient (allocate a whole new backing store on every insert) or to make it only provide the basic exception guarantee (e.g. it drops all its contents if a move operation throws). This applies to many variants of faster hash maps, faster trees, and so on - basically anything that relies on multiple move operations to shuffle data around and which has to put itself into a temporarily-invariant-breaking state to do so. The basic exception guarantee in a container means it can only be used as a cache and never as an authoritative data source, or that you have to abort on these exceptions anyway and why are you even using exceptions in the first place instead of just terminating at the point of failure (with _far_ better diagnostics than you can get at the point of an exception catch handler!), as otherwise recovering from the exception is actually worse than crashing (you'll lose a portion of the user's data and effectively have an invalid application state; *especially* bad if this is a document editor or game or something where the user could save that state and end up with a permanently "corrupted" snapshot of their work!). This _mostly_ is only a problem for throwing moves/copies. And those mostly only ever throw because `bad_alloc`. Consider that for whatever it's worth.
yes. what are sibling components? why should they communicate? My understanding is that the Entity/Components just provide the data and the logic happens somewhere else.
&gt; TransitionResource is really a clean-up action. RAII says clean-up should be in a destructor. Agreed, my example is... suboptimal. &gt; The complexity of non-exception code is that longer functions have many places they can error This isn't a problem with non exception code, but with all code that does cleanup outside of dtors. If you hold a resource that manually get cleaned up at the end of the function it will get leaked if your function exits early, be it via return **or throw**. My gripe with exceptions is that they add implicit exit paths to functions. In a code base without exceptions a function with 7 returns has 7 (or 8) exit points (assuming no UB). In a code base with exceptions a function that isn't noexcept can have *any number* of exit points. It gets even worst when you consider that the exception behaviours of the called functions can change and it'll change the number of exit paths of the caller. The real kicker for me is that calling a noexcept(false) function in a noexcept context is not a compile error. This means that changing a noexcept function into a noexcept(false) one will almost never result in a compile error despite potentially breaking many assumptions adding terminating conditions to your program. The only way (that I know of) of working around this is to make sure to RAII absolutely everything. Sometimes it's easy (like in my example), but it is often not (this might be specific to what I do). At some point I had to evaluate if it was easier to use exceptions and box all the hilariously unsafe C style APIs I use in exceptions safe constructs or to ditch exceptions and to use an other error handling mechanic that allowed me to be more explicit about what can fail and how and make stronger assumptions about my functions exit conditions. I (and most of the game industry AFAIK) (and rust) chose the later, even if it is a little more verbose.
I’m pretty happy with CMake, but it has some bizarre deficiencies whose continued existence makes no sense. For example, the GENERATED property (probably all properties) for source files isn’t propagated to all consumers of the file (via target_sources() and the like), so you can get errors from CMake about the file not existing. Of course it doesn’t exist, it’s a generated file!
If you are asking yourself what can throw, you're doing it wrong. No, really. The correct way is: **everything** throws, except a small set of well-known code blocks: pointer and primitive type assignments, swap() functions (a.k.a non-throwing swap), moves, destructors and C calls. That's it. `noexcept` functions don't count (in my book), because deletion of text is **easy**. Once you adopt that mindset, it's freaking *easy*. You use RAII consistently and code in terms of [exception safety guarantees](https://en.m.wikipedia.org/wiki/Exception_safety) (most often, you want strong safety), your code is regular-looking and reads like a book.
Right, but it only finds the first. 
I know that I should consider that everything goes throw. The problem is the consequences. When dealing with some API you just can't make all your code exceptions safe. And since everything can throw, you can chose to either not use exceptions at all (both -fno-exceptions) or deal with exceptions safety issues. 
I hope your software doesn't run on any life-support machines or nuclear power plants!
&gt; At a minimum, "left" should be renamed error and "right" renamed value. That'd be `Result` not `Either`. Same thing, but `Either` is general concept of the variant of two things.
&gt; you just can't Example? I posit it's trivial, let's see it.
For old.reddit.com users: #include &lt;fmt/core.h&gt; int main() { // prints 0.30000000000000004 != 0.3 fmt::print("{} != {}\n", 0.1 + 0.2, 0.3); }
It is just a wrapper around "native" build tool (ninja/msbuild/etc).
&gt; calling a noexcept(false) function in a noexcept context is not a compile error Yes. I don't want a compiler as pedantic about exceptions as Java, but I do want that. It would help with making sure destructors don't throw during unwinding. 
That’s that point I was trying to make.
I have written and used many graphic API wrappers. None claimed to be even remotely exception safe. And despite working with people's that have used even more over the years I have never heard of one. I suspect that the hairy ball theorem applies to graphic APIs, in the sense that no matter how hard you try to wrap them into a nice system, there will always be a spot that is all fucked up and leaky. I would like to be proven wrong. If you wanna try you can take a look [here](https://www.khronos.org/registry/vulkan/specs/1.1-extensions/html/vkspec.html). Good luck. 
I'm just an inexperienced amateur, but the solution I'm considering is to store component instances in "clusters". Say that I have two components A and B. Then I store the B components similar to this (assuming a cluster size of 32 component instances per cluster): vector&lt;b\_data\[32\]&gt; b\_data\_clusters; vector&lt;a\_data\_index&gt; sibling\_a\_cluster\_for\_every\_b\_cluster; Want to work on the data for an entity with component B while simultaneously having access to sibling A data? Access it like this: some\_func(bId) { b\_data&amp; bData = b\_data\_clusters\[bId / 32\]\[bId % 32\]; a\_data&amp; aData = a\_data\_clusters\[sibling\_a\_cluster\_for\_every\_b\_cluster\[bId / 32\]\]\[bId % 32\]; .... } For this to work you need to make sure that when you create a new entity, you put them at the same offset within a cluster for every component. This is easily achievable by segregating component instances by what combination of components the entity has. Want to create a (A, B, C) entity? Don't put it in the same cluster as (A, B, D), (A, B) or (A, B, C, E).
Google doesn't disable exceptions because of performance gain. Their style guide makes it clear that it's for legacy reasons, but that checked error codes are a reasonable substitute and therefore that don't have strong pressure to switch. Most people should be using exceptions but that doesn't necessarily mean using them pervasively, I think different techniques are appropriate depending on the situation.
This is a trivial example so it makes your "sequential" argument look like it actually has some weight. In non-trivial code, you'll quickly have multiple resources that need to be cleaned up, multiple error conditions which results in needing to clean them up, etc. In which case, trying to keep code sequential will have a lot of duplication. There's a reason why every decent C programmer is using `goto cleanup` idiom so often. It's because other than RAII (or similar things, like scopeguard, `with` in python, etc), there is no other option that doesn't suck. And `goto cleanup` suck as well, just less. Good C++ code is just to accept that you either wrap the C library, or use `DEFER` (or `ScopeGuard` as I prefer to call it). Which automatically makes your code weak exception safe. These are idioms that can be applied everywhere and will work correctly, and scale well. Trying to do the error handling the naive way just so that code can "look sequential", just makes your codebase inconsistent, and is just a pointless thing to do. And again, none of this really has to do with exception per se. Using error codes, monadic error handling, etc, will make your mistakes more obvious, yes. But naive resource cleanup is a mistake no matter what your error handling paradigm is.
Thanks for pointing that out, I remade the example code here without compilation and it fell through the cracks. I corrected the code so now you should be able to compile. Problem was what you pointed out, I just corrected the args and now we're good to go. The DRY problem is the biggest problem with this and what sparked me to ask it here. Idea is that this is a general purpose code to create factory instances. Like I could make two factories, one to make instances of class A, and one to make instances of B. Now A needs to have a constructor with whatever parameter set I have in mind which could be different than B. I can still use factory&lt;A, AParams&gt;, factory&lt;B, BParams&gt; without needing to rewrite the factory code. Inspiration for this came out of a stack over flow question but their code was only for one object. This code is my attempt to make it general purpose. I don't like the DRYness either but don't know how to accomplish my goal and not repeat code for the factory.
Thanks for the response and detailed explanation. I don't use raw pointer, I just put it there for the sake of having the option but as someone else pointed out, you can always release the unique\_ptr in rare cases I might need that. Point taken, boom. Point taken on the struct vs class. I'll keep that in mind for other places. I was aware of the convention but didn't pay close attention to it. I'm processing the first two items you mentioned. I'll get back on those :)
&gt; and to do this you have to know that RenderStuff can throw. When working on a code base with half a million functions, it's basically impossible. You don't have to know that. You just have to know the rule that all 'responsibilities' must always be handled by destructors/scope_guards. The instant I saw the code and noted the two `TransitionResource` lines with the reversed arguments I understood that the second one was doing cleanup for the first one, and immediately knew it was 'wrong' in terms of exception safety. You don't ever need to know if any particular thing throws, so you don't need to memorize that knowledge for half a million functions.
might as well default to hex for even better precision #include &lt;stdio.h&gt; int main() { // prints 0x1.3333333333334p-2 != 0x1.3333333333333p-2 printf("%a != %a", 0.1 + 0.2, 0.3); } 
Your first point got me to learn about why we need a virtual destructor and thought me quite a bit. I'll definitely keep that in mind.
Sweet project! I am also writing a Vulkan renderer, so I know it is fun times. My point was then that I feel like this gripe that you have is not with exceptions, but rather with compile times (and honestly, this is a much more commonly held viewpoint). If you are forced to write C-like-C++, that is not because of exceptions, but because we have compilers that force you to make that tradeoff, as the benefits of encapsulating these pre- and postconditions into idiomatic C++ constructs go way beyond exception safety.
 &gt; If you are forced to write C-like-C++ I don't think I am. I think that my code is closer to Rust than C if anything. (Rust use monads for basically everything and it works very well) I have a problem with compile times, but it is not the reason why I don't like exceptions. I use RAII a lot, without exceptions. I don't like exceptions because I feel like they often makes thinking about simple code a lot harder than it should be. I write a lot of very linear code that interact with state machines. Using exceptions means writing everything with RAII, which can be harder than just writing thing the C way. I find that using monads isn't harder than using exception in almost all cases (even it's often a little bit more verbose) (I might be biased, I have a small baggage in language that really heavily on them) and allow me to write code using either RAII or not using RAII when it's clearer not to. 
Meh, you rarely want it down to that precision for human readable formatting. If you _really_ care about the exact value, print the binary representation instead. But as it tends to be stated with these things: If you somehow end up in a position where you care about whether or not two floating point numbers are equal, you should probably take 10 steps back and see where you went wrong.
[Build Tools for Visual Studio](https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2017) lets you install just the C++ compilers and relevant SDKs without any IDE – a minimal installation here is all that's necessary to use Clang on Windows. Not ideal by a long shot, but really not that terrible either.
&gt; floating point math is broken No &gt; very counterintuitive It's slightly counterintuitive, yes, but only in the sense that it doesn't do exact rational arithmetic which many people seem to expect (the problem of course being that you can't actually do that within _finite_ space, let alone _fixed_ space which is what you want for predictable performance)
Perfect, I'm glad I could enlighten you on that one and keep learning because one does never stop learning with C++ :-)
Maybe you are right. But when the clean up code gets complicated I feel like packing it into a scope guards just makes it harder to read, especially when what is required for cleanup after an error change thourough the function. I just find monads a lot harder to get "wrong" and a lot more flexible around code that doesn't RAII out of the box. They are a little bit more verbose than exceptions but they work just as well for what I do so there is no reason to not use them. 
I really like stuff like this. 
Please use the [pinned post](https://www.reddit.com/r/cpp/comments/abh8bm/c_jobs_q1_2019/) for job offers.
Also the second point about SFINAE, I encourage you to look into it (and also RAII). It's such a powerful concept with templates worthy to learn and use to write powerful code.
modules don't give us that language versioning thing, but you can imagine ways that it might in the future. Currently compatibility comes down to ABI. But you could imagine module-level compatibility. ie in theory, you could write &lt;insert-language-here&gt; non C++ code that compiled down to module info (ie a .bmi file). Like languages that aren't java, but target JVM. Modules could be a new target. This is, of course, not at all part of the modules proposal(s), but it could be a future avenue.
&gt; it doesn't do exact rational arithmetic How about the fact that addition is not associative? Everyone accepts the fact that it's inexact, but how about the fact that completely deterministic calculations give different results depending on how many cores you employ? I know that it's not broken: it is the way it is defined, and you can actual axiomatize it, but is decidedly more than "slightly" counterintuitive.
I appreciate what all these newer build systems are trying to achieve but I just can’t get on board with the tooling fragmentation that they introduce. I assume a lot of them have been developed because CMake doesn’t do something *quite* to the authors’ liking. Wouldn’t it be better to contribute fixes and improvements to CMake instead? It has been mentioned elsewhere in the thread; people who use CMake just aren’t going to use a library that can’t be built/configured using CMake. With more build systems present, aren’t projects going to be more siloed?
&gt; cough global variables always should start with two leading slashes! Can I borrow this? Is it yours or where does it come from? Do I reference you as "pushrcx" or something else?
Fwiw, I am using the latest version of MSVC 2017 Community. Wondering if the Professional version does any better.
And to think the presenter had an opportunity to coin a term "postmodern CMake".
It's funny how you make `RenderStuff` to throw, but if it has an error, you ignore it. That tells me you are being dishonest in order to score. If you consider that the error of `RenderStuff` can't be ignored, then the code with error return becomes more unwieldy than that with DEFER. Also, you also have `TransitionResource` and `SetRenderTarget` who have no failure mode. Is this true? In my experience, C APIs that aren't cleanup of some fashion virtually always have a failure mode. Which also looks like you're being dishonest in order to score.
I don't like the following in your argument: * you want to selectively presume what functions do and don't throw ; you don't need that, presume throw, always, use DEFER * even if you *don't* have exceptions, using DEFER is easier because it makes the code safe from a premature return (that might be added later)
&gt; It's funny how you make RenderStuff to throw, but if it has an error, you ignore it. That tells me you are being dishonest in order to score. You are kinda right. The problem is that I wasn't able to find a good example. I was kinda able to explain my point more clearly [here](https://www.reddit.com/r/cpp/comments/aqir7n/error_handling_in_c_eithers_vs_exceptions_vs/egh2hmo/) &gt; Also, you also have TransitionResource and SetRenderTarget who have no failure mode. Is this true? From the standpoint of the API, [Yes](https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/vkCmdPipelineBarrier.html), and [Yes](https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/vkCmdBeginRenderPass.html). of course the engine can have it's own failure conditions. 
I'd argue that you almost always want the default to be correctly rounded round-trip representation. One language that did it right is Python. Hex is good for perf, but hard for human-readabililty and there is no standard way to print as binary without a cast.
Holy moly, why didn't anybody tell me this before?!
&gt; and there is no standard way to print as binary without a cast. Well of course not. The standard doesn't even specify what floating point numbers even are very tightly. Most people assume IEEE 754, but the standard mandates no such thing.
&gt; Visual Studio's C++ lib still has to be unless you want to build it yourself and not have certain things like std::filesystem. https://github.com/mstorsjo/llvm-mingw works fine here, I can build my software that itself uses LLVM and Qt with it - and I get better perf than with MSVC
&gt; all around good enough &gt; if a project decides to ***arbitrarily*** go with an alternative way of generating build files Seems like there's potentially several reasons that aren't so arbitrary. Part of my problem even with more recent additions is that it's hard to know what to use. At least the last time I was really digging into it I found the documentation relatively unhelpful and relied mostly on outdated stack overflow answers to inform me what commands to use over what other commands. Even trying to take a methodical and structured approach to it ended up being a cludegy mess. But maybe that failure is mine, but it was generally a negative experience. I totally get the concept of sticking with standard tools, it's just frustrating when you really aren't fond of the standard tools and there isn't a clear path to something better.
Bazel and Buck are already superior to CMake in terms of scalability, composability, managing complexity and speed. 
The official documentation is just a reference, there aren't really any usage examples. This is a definitive weakness of the documentation, but it isn't a deficiency of the tool itself (although it does make it harder to get started with).
It makes it harder to remember too. I did a lot of reading before I even started trying to use it, but it's been months since I've touched anything CMake. Now I'm far less inclined to use it if I don't have to, simply because I don't want to pay that cost again.
Not only do you not _need_ a `FindXXX.cmake` under most circumstances, I'd be very suspicious of any `FindXXX.cmake` you find in the wild. Most of the time that means that the build hasn't been updated in the past 10 years or so.
Well, I was once thrown into the nightmare of extending poorly written autoconf files, which are basically shell scripts. Those files contained decades of developments and nobody explained to me how it worked. I found whatever shell scripting trick in a random manner the intern students ended up. I even saw machine-specific environment variables hardcoded in those files, because people pushed those lines to the official repo. And people don't want to refactor the scripts since IDEs don't really help you analyze shell scripts... I told them there are better build systems out there and postponing the migration makes things only worse. Nope, through the countless pains of autoconf, many convinced themselves that build systems should be left untouched. But really, the project didn't require anything complex because the source code were straight forward Fortran with standard set of flags, without too much dependency to third party libs... But, damn, I had to add C++ code with some dozen libs and complex combinations of flags. And I was supposed to do that via analyzing shell scripts (m4 macros, to be more precise) some students wrote. Finally, their convention was to deliberately prevent autoconf from inserting comments into the generated shell scripts... One can argue it's not the fault of autoconf and he might be correct, but CMake threw me fewer problems so far. At least I can refactor CMake.
I mean, what else is there. I've been using Visual Studio since before it was Studio (Visual C++ and Visual Basic were separate products). I've dealt with almost every single option in a vcproj property page and solution at some point. And then there's Make. It's not even a build system. It matches rules based on file timestamps. That's literally all it does. Should we use autotools? Have you ever tried? It's pretty disgusting all around. And then there are even more niche tools like SCons. And now for some reason you have python installed. And on top of all of this, you are trying on Windows, which is always treated as a second class citizen by the free software world. So here we are, with CMake, and I am so very thankful we have it. For all of it's quirks, it's infinitely better than the dark ages we were living in before it. 
I just tested my algorithm vs a raw Windows SRW. Mine slaughters it. Here is the code: &amp;#x200B; [https://pastebin.com/raw/HgYzCDSQ](https://pastebin.com/raw/HgYzCDSQ) &amp;#x200B; (test for yourself!) &amp;#x200B; Mine takes around 35 seconds, wile SRW takes 122 seconds ish. Wow. Also, I have some reports of my invention beating std::shared\_mutex in g++ on Linux: &amp;#x200B; [https://groups.google.com/d/msg/comp.lang.c++/g6veUOvOAu0/L7Sjs0xOBAAJ](https://groups.google.com/d/msg/comp.lang.c++/g6veUOvOAu0/L7Sjs0xOBAAJ) &amp;#x200B; [https://groups.google.com/d/msg/comp.lang.c++/g6veUOvOAu0/hMIu5VBSBAAJ](https://groups.google.com/d/msg/comp.lang.c++/g6veUOvOAu0/hMIu5VBSBAAJ) &amp;#x200B; Wow! Why is SRW, and Linux st::shared\_mutex so darn slow? I am going to create a new thread on this.
Not to mention the incredibly fucked up visual studio projects it generates, applying settings to each file individually instead of using property pages. Makes it impossible to work with the solution after it's generated.
Except they will probably not give better compile times. That’s the whole problem with modules - they morphed into something nobody except for big companies with huge legacy systems want. They will not bring all the goodies people think they would. It’s not even a priority. Priority now seems to be able to shove existing headers into module and call it a day. In some sense it will be a step backwards from includes and people are trying to bring that up until it’s not too late
Please let me know where I can download Clang for, say, Analog Devices SHARC dsps.
But modules is not about dependency management. Modules do not cover versioning, repositories, cli tools etc. If you look at their state now, they don’t improve existing workflow much. They are more about code isolation than anything else
His course is very good too. Some things have changed since he made it though, so don't disable IntelliSense any more because it works properly with Unreal now.
Boost is dying confirmed.
Well sorta the point is that your project is in a defined, correct state after generating, you're not supposed to be hand editing after. Kinda defeats the purpose of the CMake script setting up the project, if it's not actually set up. I haven't run into your problem though, the project pages do work correctly for me after generating from CMake.
Well, that's part of the problem. It's just assumed that you are using cmake for your entire pipeline, so who cares if it's garbage? Unfortunately for me, I don't want to use cmake for my projects. I'm perfectly happy with just using visual studio projects, since I do all my development on windows anyway. But when I need to use a 3rd party library, I end up having to choose between generating a project though that 3rd party's cmake script, or just manually constructing a sensible visual studio project for that library from scratch. I realize I'm in a minority, and I'm not using cmake "properly". I just don't like the "We'll design for Linux, then sorta half-ass something for Windows later on" mentality that most open source projects seem to fall victim to.
&gt; I find it to be a crappy markup / script frankenstein mix which requires an awfully lot of typing to accomplish very little You're right about this. But this is also why you're wrong. The scripting language is probably the single worst failure in the history of computing and it has literally zero redeeming qualities. Everything else about it is as good as it comes, though. It's not designed to be a system for writing simple programs. If you're writing simple programs you probably don't need to leave Visual Studio. If you're doing large projects and/or cross platform projects then CMake is a fucking blessing. If I were to give an ELI5 answer why cmake is so good I would say that most build systems scales as O(nlogn) with the size of the project and O(2^(p)) to the number of platforms. CMake scales linearly with both. 
CMake is probably the best tool from its generation, but the next generation of build tools is reaching maturity, and has learned a lot from those that came before. Basically all of the newer tools are significantly nicer to use than CMake.
True. Still seems an odd restriction to me.
I wonder why markdown rendering doesn't use the same code. Here's another one: # exclusive new club
I've seen it scale. Go ahead and prove that negative. ;-]
&gt; I don't need to compile C++98 code as C++23 Need is one thing, but are you sure you don't _want_ to? The introduction of rvalue references and move semantics "automagically" made a _lot_ of code faster...
I think people want to have a different regex library (CTRE) instead of inproving `std::regex`. &gt; for an std::string_view to be passed as the first argument to std::regex_match `std::regex_match` intentionally disallows rvalue `std::string` argument because it can easily result in dangling reference. I'd expect `std::string_view` argument to be disallowed for the same reason. &gt; for std::string_view to be returned from std::sub_match That works if the underlying string is contiguous, but for some reason `std::sub_match 
I do admit that the official documentation serves more of a reference than a tutorial, and might be utterly frustrating when trying to learn the basics of (good) CMake. **But it's also not very difficult to find plenty of resources on the web that \*do\* teach you this.** Books: Professional CMake: A Practical Guide: [https://crascit.com/professional-cmake/](https://crascit.com/professional-cmake/) (Written by a CMake contributor. Costs some money, but likely very worth it.) Blog posts: [https://pabloariasal.github.io/2018/02/19/its-time-to-do-cmake-right/](https://pabloariasal.github.io/2018/02/19/its-time-to-do-cmake-right/) [https://rix0r.nl/blog/2015/08/13/cmake-guide/](https://rix0r.nl/blog/2015/08/13/cmake-guide/) [https://gist.github.com/mbinna/c61dbb39bca0e4fb7d1f73b0d66a4fd1](https://gist.github.com/mbinna/c61dbb39bca0e4fb7d1f73b0d66a4fd1) Videos: C++Now 2017: Daniel Pfeifer "Effective CMake": [https://youtu.be/bsXLMQ6WgIk](https://youtu.be/bsXLMQ6WgIk) CppCon 2017: Mathieu Ropert "Using Modern CMake Patterns to Enforce a Good Modular Design": [https://youtu.be/eC9-iRN2b04](https://youtu.be/eC9-iRN2b04) Stephen Kelly: Embracing Modern CMake: [https://youtu.be/JsjI5xr1jxM](https://youtu.be/JsjI5xr1jxM) Florent Castelli: Introduction to CMake: [https://youtu.be/jt3meXdP-QI](https://youtu.be/jt3meXdP-QI) More Modern CMake - Deniz Bahadir - Meeting C++ 2018: [https://youtu.be/TsddSCzYiRs](https://youtu.be/TsddSCzYiRs) How to CMake Good: [https://www.youtube.com/playlist?list=PLK6MXr8gasrGmIiSuVQXpfFuE1uPT615s](https://www.youtube.com/playlist?list=PLK6MXr8gasrGmIiSuVQXpfFuE1uPT615s) Sample code: [https://github.com/pabloariasal/modern-cmake-sample](https://github.com/pabloariasal/modern-cmake-sample) ...and probably many more! Here's an even more extensive link list: [https://github.com/onqtam/awesome-cmake](https://github.com/onqtam/awesome-cmake). &amp;#x200B;
Unfortunately, ISO (and ANSI) has rules. 
You should use both I would say, depending on circumstances. Not everything that doesn't go exactly as planned is necessarily an exceptional situation. For me, the further up the code hierarchy I go (the more application specific) the more I tend to use returned statuses;, because, the more application specific the code is, the more likely that it is going to be in a position to understand the context of the problem and recover or retry. The more general purpose and low level, the less likely that is, i.e. if something of that sort goes wrong, probably we need to unwind up to some application level code that understands how to deal with it. All the other code along the way usually just wants to give up and clean up. Of course anyone along the line can short circuit that by catching exceptions and return errors instead, if that's deemed appropriate. One thing I try not to do is use exceptions for non-exceptional things. It can be convenient but a huge PITA if you trying to debug by having the debugger stop on thrown exceptions. If you have exceptions popping off all the time for non-exceptional events, it's really annoying. For instance, though in some circumstances it might be an error to hit the end of a stream when reading in some data, in most cases you are always going to hit the end of the stream since you are reading it specifically to read it all. So that should really be an error return, which would only become an exception if some higher level code hit the end when it knows it shouldn't be at the end. At least back in the day the basic argument was, exceptions are not a stack unwinding mechanism, they are an error reporting mechanism. Just wanting to unwind the stack isn't an error. &amp;#x200B;
CTRE doesn't handle run time regular expressions.
In related notes about std::string_view, just yesterday I was surprised to find that this code, too, does not work with std::string_view. #include &lt;map&gt; #include &lt;string_view&gt; std::map&lt;std::string, unsigned&gt; testmap; void testfunc(std::string_view k) // std::string works { testmap.try_emplace(k, 5); } 
It's always nice getting handed some free extra performance, but I think on the whole I'd rather put in some work (not too much) upgrading code between successive versions, if it means having a smaller and cleaner language with less sharp corners and traps.
I was wondering this as well. In the meantime, it's not hard to implement something like: #include &lt;regex&gt; #include &lt;string_view&gt; using svmatch = std::match_results&lt;std::string_view::const_iterator&gt;; using svsub_match = std::sub_match&lt;std::string_view::const_iterator&gt;; inline std::string_view get_sv(const svsub_match&amp; m) { return std::string_view(m.first, m.length()); } inline bool regex_match(std::string_view sv, svmatch&amp; m, const std::regex&amp; e, std::regex_constants::match_flag_type flags = std::regex_constants::match_default) { return std::regex_match(sv.begin(), sv.end(), m, e, flags); } inline bool regex_match(std::string_view sv, const std::regex&amp; e, std::regex_constants::match_flag_type flags = std::regex_constants::match_default) { return std::regex_match(sv.begin(), sv.end(), e, flags); }
This is by design – the relevant constructor is `explicit`.
First: Thank you so much for the links! IMO the quantity of resources _is part of the problem_. While it's great to have a bunch of things to refer too, when it's new (even though I've got a good amount of experience with other programming languages and tech) it's hard to pin down the _quality_ of that documentation. Half the time I'd find a really good article that outlined a good portion of what to do, then I'd find another resource that identified half of the others commands were deprecated with some having alternatives with slightly different interfaces. But I feel like I'm just complaining now lol. This isn't really a problem localized specifically to CMake either. Dates on documents certainly helps, but identifying any solid source of best practices that wasn't rife with widely varying opinions in comments and other sources was more difficult than I think it should have been
Yet, it works in `emplace()` just fine. The difference is because `try_emplace` requires a `key_type` parameter (rather than anything that can be converted thereto).
Why a step backwards? I mean: let us say it is not super great, so, what are the pain points? I saw some but we should be concrete here. I saw the parallelization problem, seems real to me but think: 1. Most of the time you have incremental builds when working: once you compile the serial part of dependencies, this should not impact as it is described in real-life scenarios. I still think it ahould be fixed, of course. 2. You will not need to parse 1 billion times the same includes. 3. You will have much better isolation and symbol-based (as opposed to text-based) resolution. 4. ODR is now more difficult to happen. Do you really think this is a “step backwards from includes”? I know all the rant about the preprocessong and there are definitely some problems to deal with there, but it is better than what we currently have, at least from my limited judgement point of view.
Not helpful but roughly: Different people wanting different things from coroutines. 
And all of them teach things slightly different. Often without explaining why the use method X instead if method Y.
Well, the point for me is that it made me productive beyond what CMake did and I can still do everything I needed from it. But it depends on your use cases. For me it is just superior.
So what are the ISO rules preventing OP's suggestions?
It's not odd - the reason is that if you don't give us a key, we have to construct a node with the key (because it might not be movable), and then if it's already present, we have to destroy the node.
ISO dictates how a standardisation process should look like, including how each country's national standards body has a look into the ongoing draft, submits reviews and does their approvals. ISO C++ people don't just come up with this process to annoy the community. https://www.iso.org/stages-and-resources-for-standards-development.html 
I haven't used anything CMake in years, so I'm sure most of them are sorted by now. Can't remember the specific ones, but blender was one example for sure. Overall most problems seemed to stem from an over-reliance on that their permutations of settings actually works ( a lot of projects seemed to like to have a lot of possible checkboxes to tick before generating ), or the auto stuff would fail in some way. Beyond that, some things which I didn't like, granted it was some while so some criticism perhaps not relevant anymore: * As I said before it's a tool outside of your version control, this means that it's only a matter of time before issues start to appear because of people on the team being on different versions. I don't think there's really any reason at all to have a UI in any case for a build generator. Overall most open source software projects, CMake or not, are absolute crap in this regard, they don't value projects being self contained enough. You're interested in a project, but then notice it depends on a couple of SDKs, environment variables ( worst offenders ), build tools etc. Unless the latest commit is at most a few weeks ago you're almost guaranteed there's going to be problems building. * The projects generated were brittle &amp; overly verbose, project wide settings on a per-file basis &amp; absolute paths everywhere comes to mind * Beyond me not understanding the language at all, because it looks like nothing else, it seemed overly chatty &amp; rigid. You'd have something like add_some_source_files( src/a.cpp, src/b.cpp, src/d.cpp ), and then they'd be configured individually etc. In Premake you'd just recognize a pattern, then enforce &amp; apply it. For example, we have a premake_master.lua which defines the structure, it then checks the project folder for all it's sub folders, checks these for a premake.lua &amp; then invokes it in the context of the master file. The master file contains ( among other things ) something like [this](https://pastebin.com/pxR8LJCa), the first two functions are often enough to add the correct files to the correct configuration. The last part then makes sure everything ends up in the correct place.
1. No way to guarantee elision of the heap allocations of the coroutine frames. 2. Variable capture is messy. 3. Places a ton of logic into the compiler's front-end instead of having that logic exist in the standard library.
Yes exactly, but as you said ISO is about a certain process that has to be followed. Nothing is stopping you from adding additional steps to that process to make it easier for everyone to follow...
For those cases you still use the current &lt;regex&gt; implementation. From my use cases the compile time regular expressions are much more common, but I'm also not writing something like an IDE/editor :-)
There's a pair of competing proposals, namely "Coroutines TS" and "Core Coroutines" that have some philosophical differences. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1362r0.pdf does a decent job of laying out some of the differences. The author is the author of the Coroutines TS spec - much of it is dedicated to calling out some of the unsolved issues he sees in the Core Coroutines proposal. If you want to read both of them: * [Coroutine TS](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0057r8.pdf) * [Core Coroutines](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1063r2.pdf) 
Isn't that a reason enough to improve `&lt;regex&gt;` anyway?
I’m genuinely interested in the coroutines proposal, but haven’t really saw these arguments brought up. Can you please elaborate, especially on the first point. From the allocator standpoint, it is just a chunk of allocated memory, and should not differ from any other heap allocation. Not sure if i’m missing a point here.
&gt; How about the fact that addition is not associative? Strictly speaking, the same is true for ints. There you only need to be concerned with overflows though. But yes. I think that is what's catching most people of guard: Everyone knows that precision is limited, but many forget that that fact also invalidates many common mathematical transformations. That being said: I have yet to encounter a problem related to that in practice. 
&gt; I'd expect std::string_view to be rejected for the same reason. Rejecting &amp;&amp;string makes sense: who or what is going to own the data after ownership is transferred? But that doesn't mean you must also reject string_view, since there is no ownership transfer there. The semantics are perfectly clear.
You can still participate in regular discussion on the study group mailing lists and even write proposals yourself. You will probably want a comittee member to back your idea but a lot of of the people involved are open and approachable. It's all voluntary and the ones that are most involved tend to be because their employer allows (and luckily pays for) them to participate. It is a bit exclusive but still not impossible for anyone to get involved at some level.
I so fucking 100% agree with you. And even worse is that there are road blocks for using throw as a decent crash and show in case of not fetching it. Because for example in MSVC you can not get a backtrace and catch the exception at the same time for cheap. Except if you create and save a backtrace every time you throw, so now your throw is more expensive and eats more performance. That again makes it perform bad in cases where you want to catch it. We want ONE decent standard way. That does not come with performance traps, and that does not force you to decide between knowing the exception or getting a backtrace with only having the backtrace creation cost when you need it.
They are doing as much as they can. The reason papers now are P instead of N is to sidestep ISO bureaucracy. The meetings are open - anyone can show up and follow along - again a [sidestep of ISO](https://isocpp.org/std/standing-documents/sd-4-wg21-practices-and-procedures#other-topics). I think they're overall doing great. ISO is a heavy dance partner, but that goes both ways where things coming out of ISO has greater weight.
Unfortunately it takes perspective to recognize lack of perspective.
What I'm missing is an analogon in the context of memory safety
It's a bit wrong to say CMake is garbage because you're mixing 2 generators. Who has ownership if both define how a build should look? There's plenty of valid criticism out there for CMake, but I can't fault CMake, or call it garbage because you're using it in a way it was never intended for. I also think you might be talking about VS's implementation of CMake, not actual CMake. Are you generating the CMake from VS, or writing the CMake outside, and letting it generate the visual studio project files?
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/aqv0fb/learn_c_is_down_any_learn_c_ebooks/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Firstly, you've got to remember that almost all of WG21 happens in people's spare time outside of work. Only a very few are permitted to spend work time on this stuff. So please don't confuse lack of resourcing by C++ employers of C++ with "too old-school" or "lack of transparency". Re: your ideas: &gt; Migrating new proposals into a more up-to-date platform, which should be tagged and tracked with stages. Each operation should be associated with a specific person. There is an experiment currently being undertaken by Jens Mauer to track WG21 proposals using github issues. This would move WG21 closer to a Python PEP like proposal tracker and commenter. &gt; For semi-formal discussions like std-proposals, migrate it into an open forum like rust-users, and (optionally) forward all discussions to mail list. (Sadly they are doing the opposite, moving to the more-secret, unsearchable http://lists.isocpp.org/mailman/) I argued to the best of my efforts for the same. I did not win the argument, hence the choice of MailMan. I should say that the arguments were deliberated upon in depth. There is, however, a majority who find most of the posts on std-proposals to be ill informed and ill educated noise. Only a minority think it useful as a form of outreach and education (nobody disagrees most posts on there are poorly thought through noise). &gt; Pre-voting discussion should be public and streamed. No more "it's cool, but our company doesn't like it, so I vote SA" BS. The reasons and debates should all be recorded (at least in audio/video). Study groups generally hold their meetings online available to the public. Those are often recorded, and the discussion and votes are all in public. You just need to attend and listen. For anything under ISO, there are strict rules with good reason that that discussion is not made public, nor will ever be, outside the official published minutes. I would add that too many people don't realise that there **are** official published minutes from every WG21 meeting. You literally can go check why a proposal was rejected.
&gt; ISO does not normally allow experts to attend meetings as observers If this is ISO rules then it's completely BS. Why still constrain the evolution of C++ with these apparently non-sense rules designed for monopoly?
Apparently Google rules too
Disclaimer: I havn't looked at the more recent revisions of the CoroutinesTS It's more about ensuring that the typical `generator` style coroutines get their state allocated on the stack, rather than on the heap. Under the Coroutines TS a function being a coroutine is solely an implementation detail of that function. The result of a `generator&lt;int&gt; foo()`, even though you know the lifetime, may need any amount of storage for any state that `foo`'s implementation needs. This stops the compiler from being able to move the allocation on to the stack unless it figures out the size required (inlining, LTO, and crossing fingers). If you intend to use a lot of these for say, implementing a chain of filters for something like the RangesTS, you end up with an allocation for each individual filter. Eventually the perf v. code clarity trade-off doesn't look so appealing for coroutines. For the async operation use-case it's less of an issue, since the lifetime of the coroutine is rarely knowable: launching a coroutine is usually for concurrency. --- For the variable capture, it's stuff like: future&lt;void&gt; do_something(const string&amp; p) { // is p valid here? co_await something_else(); // is p valid here? } what places is it safe to use `p`? It may not even be valid on the first comment if the coroutine configuration uses `initial_suspend`. This makes lifetime issues really hard to gauge just by looking at code... which is the stuff of nightmares. With 'usual' async code it's usually obvious where control is returned to the caller, so it's easy to check if objects are either copied or it's documented that the caller must keep something alive until the operation completes. --- For 3, I actually prefer this. `variant` sucks because it's done in the standard library.
I hope you are not waiting for this to use coroutines. It's been available in boost for years and swapcontext in Posix for 20 years.
&gt; The meetings are open - anyone can show up and follow along - again a sidestep of ISO. Right, because it is easy for all of us to fly to Hawaii, Switzerland, America, etc, to participate in those meetings. It baffles me how anyone would think that sinking a few thousand dollars to go to a meeting is progress.
Thanks. I have never checked minutes before. If any other redditers are interested, here is the San Diego minute, http://wg21.link/n4790. You can find poll result for merging coroutine into C++20.
But that string_view might be constructed from a string rvalue.
Parce que C++ c’est LA Classe 😊
That's all nice, but how does it fare on: * Interacting with CMake w.r.t. dependencies. Can it use projects as dependencies that provide a CMake config file? Can I also build these dependencies in-line, as I can when just using CMake's `add_subdirectory`? * Providing integration into downstream CMake files. Can I use a project built using Meson in other CMake projects as a dependency? If these are not all "yes, that's easy" answers, then Meson isn't that useful in the real world, I'm afraid.
I think they all converge to pretty similar results. The newest resources probably teach the best paradigms, since many things were changed for the better CMake 3.11 and up. Although I haven't read it, my best guess for most comprehensive resource would be Craig Scott's book.
these would be more interesting if you came up with interesting solutions. at least have optimal runtime or memory. maybe discuss different versions?
I am a novice cpp programmer. 1) c++ is very fast. I deal with graphs that have million edges and hundreds of thousands of nodes. C++ is pretty good to hold such a data structure and write algorithms for it. 
&gt; 1) Why are you programming in C++ instead of C#, Java, Javascript or another programming language ? Performance. Ease of interfacing with low level &amp; C APIs. &gt; 2) Do you feel C++ is becoming bloated, obsolete or playing catchup to more modern managed language now ? you prefer modern C++ or like the old dayz ? No. There is only one language in the same ballpark as C++: Rust. Rust puts a much bigger emphasis on safety which is nice in some cases. In other cases where safety is less of a concern, it is one of the *very few* alternative to C++ (in game engines it's actually the only one) so I expect it to take a little bit of the market. I don't think it'll replace C++ any time soom tho. JAI could be another serious contender, but it isn't out yet. &gt; 3) Which new features of C++17 and C++20 you don't like ? or you won't use ? I haven't looked at C++20 much, but I use most of the stuff from C++17. It hasn't added anything that I don't personally like. There is a lot of stuff I don't really use (utf8 support, noexcept), but it's because I don't need it. &gt; 4) Are you a big fan of the STL ? Yes, my only problem with it is that it is missing a few useful things like open address hash maps and SBO vectors. I also really don't like the interface for allocators, but it's manageable.
I agree that there are a lot articles out there, and I have left out the ones that teach the wrong things (e.g. old-school CMake). Once you have identified the good resources, it's not outrageously difficult to adopt good practices. But it does cost some time. Having just \[bought and\] briefly looked at Craig Scott's book, I'd say that's the definite one learning resource, if you only want one (and are willing the spend a few dollars).
-Good performance -Small binaries -Abundance of high quality libraries -Target most platforms with ease -No need to deploy the runtime with executable. 
That’s for postmodern C++. 
1. To create efficient code that can be used across different (including mobile) platforms. 2. its becoming more modern and much improved. 3. initialization features. 4. yes, it's the bedrock.
When it’s an international standard, doesn’t it make sense to have meetings at international locations? Hawaii is far for almost everyone.
As a casual C++ programmer: 1) C++ is kinda fun and allows nifty things, also having to deal with annoying and bikeshed-level technical issues helps me to focus on them for very and keeps my depression away. There are enough issues between build system, performance, compile times, correctness, writing code that works everywhere, etc. to keep the depression at bay for some time. 2) I like how C++ evolves mostly, as a generic library developer the standard keeps geeting interesting tools to make things better. 3) I'm not really fond of fold expressions and I'm constantly sad that `if constexpr` isn't that useful in practice in my libraries, but that's pretty much it I think. 4) I like the philosophy &amp; design of the STL. When I write generic libraries I try to provide similar interfaces.
1. Can consume Cmake dependencies. No build inline. 2. You usually do that with some kind of custom target. It is what I did with CMake from Meson. I am consuming in my own projects through run_command projects from source and it works well. The time I spent fightimg CMake lang and cross compilation were greatly reduced in Meson. And no, it is not useless. Mature. Just not the most popular option, but far saner than it.
1) No choice, whole industry is build in C++ 2) Becoming? It has been for years. I prefer neither 3) I have no idea. My industry won't adopt it until 2020 at least, so I didn't pay much attention to it 4) Yes. It's one of the saner parts of the ecosystem 
Knowledge, control, portability.
mostly because all the rest are awful, primarily JS. I do program with C#, and albeit some idiotic decisions that have been made, it's a very cool language.
BTW. this library came as a replacement for MSVC implementation of the equivalent objects. &amp;#x200B; I think the developers working in the MSVC team (whether its the library team or the compiler team) are amazing, but I guess that even they have tight deadlines and schedule. &amp;#x200B; the VC++ implementation of the future/promise dou is a wrapper around PPL tasks. std::async also uses PPL which is a wrapper around the win32 thread pool. doing a little research, launching an empty lambda through std::async under MSVC allocates 3 different chunks of memory, and almost 1kb... for an empty lambda.. &amp;#x200B; I don't know if it's possible or acceptable, but I'll be honored if the VC++ implementation used parts or all of my implementation. 
&gt; SBO vectors I know it's not what you want, but in some cases `std::basic_string&lt;T&gt;` is a perfectly good, albeit unintuitive, SBO vector. It also works out of the box for built in types and it alows you to apply the whole string API to, say, `std::basic_string&lt;int&gt;`. For custom `T` you'd need to implement character traits.
&gt; For 3, I actually prefer this. variant sucks because it's done in the standard library. There are arguments why things should be in the library first. If the library version works fine, great, we can have new library features on old compilers. If it's like `std::bind` then the compiler based implementation is fine (in this case it's lambdas).
The interesting minutes unfortunately aren't public.
Nothing important should be decided in physical meeting. Physical meetings should be just for fun. The real progress, all the discussions should be happening transparently on the internet. &amp;#x200B; If they NEED physical meetings to make a progress then I dont even know what they are doing. And the language is going to lag behind.
&gt; There is a lot of stuff I don't really use (utf8 support There's hardly any utf8 support though. What little support was added in C++11 was deprecated in C++17 as far as I can tell.
You are not alone
Criticism is not whining. Anyways, push features when they are ready not in beta state.
Finally you admitted there is some benefit :) I do not disagree totally with you but I saw a lot of overstatements about the status of modules. Some fear could be founded. Some other is just exaggerated in my opinion.
A review might be difficult since it's more than 2500 lines of code in two files, without a single comment and without any documentation.
Take a sequential computational code. Rewrite it for parallelism, but the customer insists on bit-by-bit the same result as your original code. There you have your associativity problem.
Indented at 8 spaces.
No boost dependency allowed for me.
The standard have done several mistakes by pushing non complete features, but it never made a mistake by delaying. Just look at concepts now vs old concepts. Or how much modules changed on the past 6 months with the adoption of ATOM. I stand by my analysis that Modules is not complete, the only reason that I won't be against is that Modules is a satellite feature that I can just ignore.
No, it's using tabs. Your browser probably defaults at 8 spaces. You can use something like Stylus to inject `tab-size: 4` if you prefer.
`basic_string` does the job well enough in some cases, but it's still far off from a true SBO vector. The buffer length is limited to 22 bytes on most implementation and can't be changed which makes it useless for anything other than primitive types. 
To be clear: I didn't want to say that they don't exist, just that I personally haven't encountered them. Of course, your customer is free to ask of you whatever he wants (and you are free to reject the contract), but as floating point arithmetic is imprecise anyway I don't see a reason to require a specific result vs e.g. "result must not deviate from the arithmetic "correct" solution more than X". We all know, that you should not compare foating point values via `==` except maybe for trivial cases (e.g. is the variable still zero initialized), so giving a requirement `result_old == result_new` seems wrong (more likely lazy) to me.
1) Because I must. (E.g., low-level interfacing to OS such as monitoring network interfaces, device events, setting up ACLs, installing services, using libraries only available for C or C++.) 2) I prefer modern C++. The way things are going, it's *never* going to catch up with managed languages wrt. distribution and ease of use of prebuilt packages. Compilation to native code should be an implementation detail instead of standing in the way of getting goodies that Java and C# have had for decade(s). (E.g., metadata about precompiled code, reflection built up on it and all the goodies that follow.) NetCore is catching up with C++ in the area of high performance computing so in the future there'll be even fewer reasons to start a new project in C++. (One remaining reason being having a "supervisor" process with minimal dependencies that absolutely must not fail.) 3) No opinion. 4) Yes.
What's the best way to get involved if you are a college student? I like to follow news about the upcoming standard and to read papers, but I don't think that I have the knowledge or experience to make meaningful contributions yet.
Thank you for linking to a tweet that links to an article 
C++, like other older languages (Cobol, Fortran, C) will never be able to have the same governance model of newer languages like Rust. Rust, Python, etc. all benefit from the simplicity of having (1 person / small group) in charge and there is only 1 official implementation. This greatly simplifies the governance model as decisions can be made quickly and implemented. C++ however doesn't have an official implementation, all it has is the ISO standard which is then turned into multiple competing/complimentary products by multiple different vendors/organizations. This inherently complicates things as you no longer can have the "beneficial dictator" in charge. Can C++ do better, probably. But given what C++ is the fact that they are advancing the language on a 3 year schedule is a significant and major achievement that those involved should be proud of while they try to improve the process further given the limitations of what they are.
I didn't realized, sorry, I have just reuploaded the post with the correct link.
wow, a reblog? who does that?
Unfortunately that doesn't seem to be so easy. The only public mailing list is SG14. Do other SGs require some NDA or personal invitation to read them? I also tried to enter SG2's Google group - and got ignored for more than a year. That's very... welcoming. Other language projects are also voluntary - and yet they're order of magnitude easier to track. The simplest thing - status of current C++ proposals - requires reading through all those N1234/P1234 papers, without any proper grouping, linking discussion tracking etc.
1. Because CAD software is mostly written in C++ 2. Not that obsolete but increasingly bloated. The further the worse. 3. Haven't decided yet 4. Good idea with so-so implementation - iostreams/locales are designed so badly they need complete revamp - iterator-pointer interface conformance is one of the worst ideas I've seen
You've got a point. "Perfectly good" was a wrong choice of words. configurable inlined storage is definitely a problem. However, if you're okay with using Abseil, the have `absl::inlined_vector`.
&gt; only a matter of time before issues start to appear because of people on the team being on different versions We take backwards compatibility very seriously. Newer versions of CMake should not break old code at all. Warnings may appear about behavior changes, but they do not take effect unless explicitly opted into (either via `cmake_minimum_required` or setting the policy to `NEW`). &gt; I don't think there's really any reason at all to have a UI in any case for a build generator. The GUI is a convenience factor. I usually edit `CMakeCache.txt` by hand personally. &gt; &lt;isolated builds&gt; Yeah, but you're already requiring a compiler from outside. CMake itself is distributed as an isolated tool, so having a `get_cmake.sh` script in your repository for getting a"blessed" version shouldn't be too difficult. &gt; The projects generated were brittle &amp; overly verbose, project wide settings on a per-file basis &amp; absolute paths everywhere comes to mind Well, CMake generates absolute paths because relative paths are even more problematic in practice. I'd rather not have to rethink everything if the working directory is wrong for a command at least. Or if some other file gets interposed in an implicit search path thing and you end up using the wrong file. &gt; &lt;not DRY&gt; Well, if your project is that consistent, nothing stops you from having a single `myproj_library()` call which divines the magic from the calling scope and does it all. Granted, the primitives CMake gives you can be annoying for manipulating large blocks of text, but if Python is better for extracting information, nothing stops you from `execute_process` to get it out and then forward it to CMake.
Interestingly, this is how the D language handles this issue. They provide a \`cache\` function in their ranges module that does pretty much what you proposed: [https://dlang.org/phobos/std\_algorithm\_iteration.html#cache](https://dlang.org/phobos/std_algorithm_iteration.html#cache) In Python, \`filter\` traverses the underlying range (in Python jargon, an iterator) only when asked for the next element. This dodges the problem.
Why did you post this? It was posted here two days ago. By the original author. You don't even have to scroll hardly to see it. If people have more to say on this I recommend using the other thread for that, so as to not fragment the conversation.
C#/Java would *rock* if they provided decent interoperability with even a subset of C++; instead everything must be done via C interfaces.
Like, you want an analogy to help you understand it?
1. I use C++ just because most graphics libraries bind to it and it is a lot easier than to learn a wrapper. 2. I do think it's bloated and not as good as Java or C#.
1) They keep hiring me for C++ jobs, so it seems to be working out so far 2) It feels like we're a little stuck between the old and new ways. You kind of have to learn both in order to understand a large codebase. 3) Moving the return types to the right side and using auto for everything seems like an odd choice to me. 4) The STL is very nice, but not everyone likes it particularly due to exceptions. So you have to learn to work without it occasionally. &amp;#x200B;
It's a bit too much to read to quickly check for design and correctness issues in depth, but one thing I noticed: Your internal spinlock seems to not implement all recommended practices (that I'm aware of, they might be outdated or not relevant for your use case, though): - You yield the thread in the spinlock; however afaik you better put the thread to sleep for a short time - You don't seem to use exponential back-off, which is important when there is a large number of threads See https://geidav.wordpress.com/2016/03/23/test-and-set-spinlocks/ for some more explanation and a benchmark on spinlock implementations 
Python also has a 28-year history. Despite that they established an official implementation, I was wondering if it's possible to learn from them - e.g., delegate final decisions to an small group of people(the steering committee) to avoid current dilemma that only *safe* and mediocre proposals can pass, and useful-while-breaking changes are blocked by too much noises.
Taking minutes is really really really hard. I find myself being recorded as saying things I don't recognize. I don't think I did any better when taking minutes.
Participate in std-proposals
1: performance, availability across all platforms, Qt is great and only really supported in c++ and python. 2: C++ has always had a ton to terrible legacy. We are behind a bunch of other languages in a bunch of ways (reflection and macros, for example.) I don't think there is a problem with the language being bloated though. 3: there is nothing I particularly dislike, but plenty that I don't need. 4: It is a bit of a mixed bag. Iterators are a powerful concept, but not having container based sort/filter/map is inconvenient. std::string is pretty worthless because it doesn't know about encoding and thus doesn't provide useful string manipulation functions. I tend to prefer Qt for filesystem access, strings, regex, and threading. They just offer a much nicer solution than one standard does.
They're making a paper standard in standardese. It's not an open source project. Open source projects can communicate in code. ISO standards are only "compiled" in people's heads. This is a lot harder than you think. Meeting in person is actually required to not make a bigger mess than we already have.
“JITLua” really?
The only cmake implementation I'm using is the official cmake for Windows. The cmake files I am encountering are those from 3rd party libraries. The visual studio projects I use are created through visual studio itself, not through cmake.
There's non-Boost library implementations: https://github.com/lewissbaker/cppcoro https://github.com/jamboree/co2 
... and (finally!) they're starting to go up!
I've been using C++ since the 80s. Yeah, it's evolved quite a bit since then. &amp;#x200B; I've used many other languages in jobs over the years. I use C++ right now only in a few cases. I'm doing iOS audio development, so your choice for the real time audio render thread is either C or C++ (or that weird amalgamation Objective-C++). You simply cannot use Swift or Objective-C (iOS apps are either one or the other (or both)) in the render thread.
&gt; I don't see a reason to require a specific result The program was certified by someone above my pay grade. Never mind whether that mathematically makes sense. I'm entirely in your camp btw. Unfortunately sometimes the decisions higher up get made by people who don't understand this stuff.
1) I'm programming in C# as well, but I'm more productive in C++ than C#. I'm of the highly controversial opinion that C++ is less error prone &amp; gets more done with less than all of the mentioned languages ( although I don't know why Javascript would be in that mix ). Java &amp; C# lives in to high of an abstraction level for my industry, and I think trying to abstract memory away with a GC is a red herring. You just trade away one set of memory related issues for new ones + lifetime issues instead, all of which you have little control over. 2) In one way I think it's moving in the wrong direction with trying to cater to the Java &amp; C# crowd. On the other hand modern C++ is way better than 03 which I feel severely overstayed its welcome. 3) I'm just glad metaclasses didn't make it. I feel metaclasses is trying to solve a real problem in a poor way, it's to bloated. 4) I don't think STL fulfills much of a role nowadays. The huge dead time between 03 -&gt; 11 3rd party libraries started filling its shoes, in practice it's mostly a matter of search &amp; replace `boost::x` with `std::x`.
My software runs on my shitty laptop.
I can agree that initializer list was a mistake for sure. Yes, more time, more thought. On the other side, the best is to deliver early as long as the outstanding problems can be corrected. The problem is just the ones that cannot be undone actually.
I am not questioning the difficulty of being part of evolution of programming language, but I dont understand, why it cannot happen online. As I said, If they keep doing this, the lanuage will lag behind another language, that is easier to update. And the other thing is, are they going to keep up this "once/per 3 years" rate ? I mean the industry is accelerating, at some point this will have to be sped up, or again the language will lag behind, increasingly.
My take - I'm trying to decide if it's worth writing a paper about this - is that "Coroutines" are really trying to service radically different markets, and it might be best for C++ to follow in the footsteps of effectively other other modern language and provide distinct features for those use cases. **Generators** Basically a way to convert a function that fills an output sequence into an object that produces values. These can be almost trivially defined as a simple lambda, a la the original Resumable Lambdas proposals. Generators can produce values immediately/synchronously, but can also produce zero or more values. **Async Functions** A way to convert a function - and its whole call chain - into a series of continuations around async points. Async functions may not produce a value immediately, and may produce an error instead of a value (or produce a `Result&lt;Value, Error&gt;` if you will). They only produce a single result unless they error. **Exception Traps** The current Coroutines proposal can be used as a hack to trap exceptions into `Result`-like objects. Herb's proposal does this better. **Async Generators** A merger of generators and async functions. Asynchronous results, but may produce zero or more values (and async between each). **Actual Coroutines** Interruptible functions that can both receive multiple sets of inputs and produce multiple values. Can be used to create complex interactions between separate objects similar to Actor model. --- The Coroutines proposal currently in favor is a good solution to several of those problems (async stuff), an adequate solution to another (general coroutines), and a very bad solution for two of them (sync generators and exception traps). That doesn't mean that Coroutines should be blocked. Rather, I think the line of thinking that the Coroutines proposal is a One True Solution For All Problems thinking should be scrapped, Coroutines should go in right now to solve the problems it solves well, and the committee should be open to seeing better solutions in the future for the problems that the Coroutines proposal inadequately serves.
Unfortunately what you're essentially asking for (whether you realize it or not) is for C++ to stop being an ISO paper standard, and start being an open source project. While I sympathize, that's simply never going to happen. Rust has a single implementation, so everyone can talk about rust in terms of patches, so the discussion is extremely concrete -- it either compiles and produces the expected output or not. You can replace a long winded argument about hypotheticals and ABI compatibility and abstract machines and multiple implementations with a simple patch and some tests. C++ cannot, because it's writing in pseudo-english and has to support systems that possibly almost no one uses anymore, and has to not break compatibility with billions of dollars of deployed systems, including million dollar fighter jets and the systems that handle all your money. There will be ongoing attempts to make use of open source tooling where possible, but there's a fundamental impedance mismatch. And there are in fact people who participate meaningfully without attending all (or any) of the in person meetings. If you're motivated and capable, then nothing will stop you being a force in standardization -- you have to earn that recognition. And that's something in common with open source, just because you have access to a mailing list, doesn't mean anyone's listening to what you say. Lastly, while it may be that people have biases due to company affiliation, and there's nothing stopping companies from voting strategically, the committee really is acting in good faith for the betterment of the entire community. There is literally no one who says "I like it but my company doesn't so SA". Plenary votes happen in public and you tell who votes what.
Python has a single implementation.
The only thing stopping C++ from running as fast as it wants is having to support multiple independent implementations, and backward compatibility. Some people see those as benefits.
Thanks for letting me know about the typo.
Any language, once it reaches a certain installed base, reaches a point where there really can't be useful-while-breaking changes without an extremely good reason. Python created version 3 to allow breaking changes and even now, just over 10 years later, we are still dealing with projects and other code that haven't been upgraded to version 3 and to a large extent the only reason a decade later it is finally being dealt with is because someone made the decision to finally kill off official support for Python 2. So yes, we are learning from Python - we have learned that breaking changes in an well established / used language are a bad thing and thus need to be handled with care.
You need to put some more effort into it before you ask others to do the same. 
Someone should make fork, which is C++ minus verbosity. **Trivial** example: How about instead of `std::cout &lt;&lt; '\n';` you can just say `newline` &amp;#x200B; I end up using macros that I call //anti-verbosity #define newline std::cout &lt;&lt; '\n'; &amp;#x200B;
How do you*fork* an ISO standard?? Let alone convince anyone to use it. 
No, Python has four major implementations. More than C++, in fact.
I appreciate the frustration, but requiring physical attendence which costs serious money keeps the numbers down. It's already unwieldy enough with ~150 attendees, we definitely don't need more. Things go far faster with ~40 attendees, like on WG14. There major decisions get taken within a day. On WG21, that is usually multiple meetings.
An awful lot of Python's centralised steering success was due to Guido, who served in that role far longer than anyone should. Now he's retired, I would be unsurprised if Python evolves far more conservatively in the future because there is no single person with the authority to take really unpopular-but-necessary decision. I can see Python evolving very like C++ in the future as a result.
There is CPython (what most people use), IronPython (.NET based), PyPy (JIT'd Python running on CPython), Jython (JVM based Python IIRC), and I'm sure others too.
If there is a ISO C++ meeting in your vicinity, attend. I did that in Rapperswil, volunteering to help out and man the registration, then in the welcome session, there was a call that LEWG needed a minute-taker, so I volunteered and did that the whole week. I must say that after after the first day I got the hang of what was going on, and actually made one or two valid points. It's easier than you think ;) With the founding of LEWGI and EWGI, I'd suggest sitting i there. In LEWG in Rapperswil we did would often split into small groups to discuss smaller papers in parallel, and the present to the whole group, with some recommendations. Small papers are usually quite understandable for a new person.
The thing is that numbers are being kept down between those who can tank the cost and those who can't... rather than by technical merits.
Reminds me of modules
It seems that there's more interest in C++ standardisation than ever, and that's great! As someone who is personally very interested, but not in a position to attend ISO meetings, I completely sympathise with the OP's position. Nonetheless, there are reasons for things being the way they are, and they're hard to work around. Unlike most other popular languages, there is no single company calling the shots about the future of C++. That means development needs to happen through some sort of recognised standards body to avoid US (and other countries') anti-trust laws. In the case of C++ this means adhering to the ISO rules, which (IIRC) say that discussions may not be recorded or broadcast other than through officially published minutes -- discussions must happen *in camera* rather than on camera, as it were. As I say, I have found this to be very frustrating in the past, so I completely sympathise with the OP's position. I don't have a good solution: for a legal point of view, big companies will want some sort of anti-collusion protection. And as I understand it, the ISO process as used by C++ is already vastly more open an "democratic" than, say, Khronos. 
What you call "async generators" I'd call "cooperative coroutine" and your "actual" coroutines "pre-emptive coroutine". It's kind of weird for me because a lot of people care about the asynchronous use case, but I _only_ care about the synchronous one. It seems a bit strange to me to attempt to implement both as the same feature just for having similar names.
I dont argue against that, I am just trying to grasp what IS the limiting factor of the rate they are going. The feeling Ive got from reading these comments, that there not many people developing C++ full time, its more like collective free time hobby. If thats the case, the situation is more grim than I thought.
Draw? *Draw??* This is standard C++, we don't want to *draw* anything. A monochrome terminal window should be good enough for anyone. Pfft. *Drawing.*
Sire, the barbarians are at the moat, about 300 of them, they've been making quite a ruckus for the last few weeks, but now they're resorting to concern trolling. They say we're not being nice people because we don't let them inflict their zune-Windows-8 charms bar swoosher ideologies on "ancient" C++. Tell them that their princess is in another castle, tell them that the Rust, R, Chef and Jython, and Python castles 80 miles to the east are much more accommodating to their needs. 
Branch is bertter word, just like C++ branched from its parent languages.
In principle you are right. Those cyclic dependencies (hopefully) only exist on a library level and not on a actual file level. The problem is that individual libraries are the level of granularity on which package managers and most build systems work. It is simply a question of scalabilty (and as far as selective downloading is concerned also practicability). Also, if two libraries that are maintained by different people depend on each other, it is very easy to accidentially introduce a true dependency cycle (a headerfile including itself indirectly) which then really can lead to all kinds of madness. At the same time, Boost has imho become too big and too diverse to just treat it as a single library (although that's what the current release model still does). So sooner or later that is the dependency graph the user sees (vcpkg and believe conan too already have to work around this problem). I think the dependency graph could already be significantly simplified if boost libraries would move to and fully embrace c++11/14. 
And here I thought my own misery that is Valentines Day would at least be avoided on this subreddit.
I'm not really a C++ programmer, even though I've played with it in high school, did some courses on it in college and contributed to a bunch of projects written in the language. I did a few years in webdev and Java. Recently though I've been trying to learn C++ as a dev tool rather than a toy, so here's my perspective. &amp;#x200B; &gt;**1)** Why are you programming in C++ instead of C#, Java, Javascript or another programming language ? C++ still seems like the most "powerful" option, in terms of potential for high-performance code, massive ecosystem of libraries and tools, and being able to take advantage of native APIs directly. Other languages can be super convenient and fast to work with, but there's still a lot of things they can't reasonably do, that C++ is the obvious choice for. I want in on that. &amp;#x200B; &gt;**2)** Do you feel C++ is becoming bloated, obsolete or playing catchup to more modern managed language now ? you prefer modern C++ or like the old dayz ? In terms of language features, I've been pleasantly surprised by what C++ can do now. I'll admit I feel a bit intimidated by the pace at which C++ has been evolving since C++11, but I think it's a good thing. Feels kinda like going from Java5 to Java8, except C++ is way more complex and where Java just became more mature and capable, C++ was already a huge and complex language that got even harder to understand as a whole. I fear this may further increase the rift between C++ experts who have a decent grasp of its intricacies, and people like me who only use a small subset of the language. I just hope this evolution won't turn "everyday code" into a modern equivalent of the meta-macro-template-mumbo-jumbo some C++ libraries are written in. One place I think C++ is barely catching up to other languages is dependency management. I've spent an embarrassing amount of time figuring out how to live with CMake and Conan, and how to make them play nice with Visual Studio. Coming from maven/pip/npm, this really isn't a pleasant experience, even though I want to make clear I do appreciate what these tools can do for me. Still, lots of libraries with either no CMake support or crappy build scripts that make integrating stuff a mess. OTOH, I do like how much control I have over the build process, and that dumping third party code into my project tree is still an option if I need it. I remember maven giving me a hard time when I tried to do that kind of thing with Java, IIRC breaking out of the packaging system was always a pain, in case I wanted to customize a library I used. &amp;#x200B; &gt;**3)** Which new features of C++17 and C++20 you don't like ? or you won't use ? Since I'm starting with a clean slate, pretty much every feature I have a use for, that is better at solving a particular problem than the old way. I still see the "C++98 way" as being the simple way though, assuming it isn't 2x as much code. One thing I'm skeptical of is ranges in C++20, even if I can replace a screen's worth of code with a few lines of magical incantations, I'd be weary of doing so if those few lines would take longer to understand than old-style code. Then again I'll probably get used to them eventually, I remember being weary of C#'s LINQ and Java's stream API because I often came across examples that tried to explain their usage by gigantic blobs of convoluted code that made little sense in chained calls.
Jup, similar problem and I'd wager this is something big parts of c++ suffer from.
3 isimho a boon. The STL gets far too often misused to provide functionality that by all rights should be built into the language. And regarding 1: Almost every single c++ prgram out there is already heavily depending on the optimizer to remove all thos layers of abstractions. Why is everyone now suddenly so afraid of trusting the optimizer? Also, the more you leave to the compiler/hide from the program, the more leeway you give the optimizer, so I'm not so sure if the typical c++ mantra: "I need to have full control over everything" isn't actually hurting performance. 
More seriously, I do think this is pretty cute, and I'm actually surprised how easy it is to generate the SVG. One minor tip: I think reversing the y-axis using `std::for_each` and a lambda could also be done with unary `transform` and `std::negate`, i.e. std::transform(std::begin(vy), std::end(vy), std::begin(vy), std::negate&lt;&gt;{}); // or, soon std::ranges::transform(vy, std::begin(vy), std::negate&lt;&gt;{});
What do you have in mind? Because you still cannot extend the process in a way that would break the ISO rules.
1) I program in other programming languages as well, including C# and JavaScript, also Python. The question is not "why do you use X", but rather "when do you use X". 2) I feel it is becoming bloated. Obsolete - no; there is really nothing there to replace it. As for "modern", I prefer post 1998 C++ with RAII and STL. I absolutely detest template metaprogramming and such. 3) We are at C++ 14 at work, so I haven't tried any C++17/20 features. 4) I like STL and use it all the time.
Yeah the Unicode Study Group is working on fixing the Unicode problem in post-C++20 versions of C++. If you want to help with feedback, try Boost.Text (not in Boost, will be pushed for review some time in the future, but implementation is usable today) and report to the group.
1. I do use other languages, but C++ is my primary. C#, Java, and Javascript (or the browser for that matter) didn't exist when I started using C++. It was far and away the most practical choice. Then, my interested moved towards large scale systems development, and it's still the most practical choice for that kind of work, IMO. If you need a large code base that spans the gamut from low level bit tweaking to high level UI, and you want a single language architecture to do it, C++ is sort of it. 2. I feel that C++ is badly bloated and trying to be things it's not. It should concentrate on being good at what it is (systems development, embedded development, back end development) and not try to 'keep up' with C# or or Java. Though, one has to make a distinction between the language and the libraries (though the language is unfortunately becoming more and more tied to the libraries.) The libraries are really baroque and out of control, IMO, the language less so but heading in that direction. 3. I like those features that allow for more explicit semantic expression (and compile time type safety, where that doesn't conflict badly with rebuild times and understandable error msgs, talking to you Mr. Template.) Enum class, override, nullptr, explicit, and default are all very much in that category, IMO. The massive level of templatization is way out of hand, IMO. 4. From the above you can probably guess, no. &amp;#x200B; To me, it seems quite unbalanced that so much time was spent on the enormously generalized algorithms and iterators stuff, when things like this are not dealt with: 1. Decent enumeration support 2. Text encoding 3. Sockets 4. File system access 5. Security 6. Network protocols support 7. General cross platform development support &amp;#x200B; I mean, I would be more likely to run into most of those in a given day than I would really be concerned about removing every over number divisible by 12 unless it's followed by a prime number from a collection of numbers without actually having to write a for loop. Having to pull in a bunch of third party code to do stuff like that really just doesn't appeal to me. I'm so spoiled by my comprehensive, monolithic system where everything is in one package, all designed as a package to work together. I mean, if you want to chase Java or C#, chase them on that front, of providing a comprehensive runtime library system that covers the stuff that SO many programs require these days. &amp;#x200B;
That's the critical point. According to Herb, because it's a new feature it can change radically even if on the standard. I am just disappointed with the result of modules and the syntax is messy. It's already available so I don't see a huge benefit trying to rush in 2020 when we have so much work to do. If modules go through Belfast and Cologne will be devastating.
A question for you, /u/Cloud_Strifeeee: why do you start threads every few months asking [leading](https://www.reddit.com/r/cpp/comments/a78cza/do_you_think_c_is_bloated_now/) [questions](https://www.reddit.com/r/cpp/comments/9w2cgm/is_c_dying/), only to delete the posts later?
&gt;I'm not really fond of fold expressions I haven't found a *ton* of uses for fold expressions, but I've gotten pretty good mileage out of folding over the comma operator when I was writing a string formatting function to avoid the mess of needing recursive templates. Something like: template &lt;typename... Args&gt; void format_string(const std::string&amp; fmt, Args&amp;&amp;... args) { (do_format_string(fmt, args), ...); } where `do_format_string` is an overloaded function that replaces the next format placeholder with the textual representation of its argument. It's pretty basic I like it a lot for that, and there are probably other good uses for it
&gt; What you call "async generators" I'd call "cooperative coroutine" and your "actual" coroutines "pre-emptive coroutine". "async generators" are the terms (or close to) used in other popular languages that have the feature, fwiw, which can be helpful for comparing/contrasting what is proposed for C++ with what's actually used in the wild in other languages. I wouldn't call "async generators" a co-routine since they can't _consume_ values, only _produce_ them; a coroutine can do both. That said, you're totally correct that there should be a distinction between cooperative and pre-emptive coroutines, since there's different requirements. That said, I believe the Coroutines TS handles both of them fairly well. &gt; It's kind of weird for me because a lot of people care about the asynchronous use case, but I only care about the synchronous one. That's kind of the heart of the whole fight over the Coroutines TS. :) The TS is _primarily_ a way of introducing async functions into C++ but generalized enough to also handle a ton of other cases. The argument in favor of that approach is that we should prefer singular features that cover a wide array of use cases. The counter-argument is that this particular proposal doesn't cover all those other use cases perfectly. The further debate then is whether there is an alternative feature that could handle every use case perfectly, whether the Coroutines TS handles all the use cases _well enough_ to put the argument to bed, or whether there are other good features that handle those remaining use cases perfectly and is sufficiently orthogonal to Coroutines TS to not be a maintenance/education burden going forward. My personal opinion is that we should take the Coroutines TS and then also push for a very similar generator lambda feature, which basically just transforms the like of: `[]{ for(int i = 0;; ++i) co_yield i; }` into an object with something like `operator()`, `operator bool`, and `operator++` (or appropriately-named member functions so raw pointers don't count as generators), along with appropriate `Generator` concepts and `std::begin`/`std::end` support for range-`for` consumption of generators. A generic `std::generator` that is the multi-value analog to `std::function` and which also enables the full Coroutines TS machinery would bridge the gap between the two (so just return a `std::generator&lt;foo&gt;` and let it be an implementation detail whether that's a simple lambda generator or a full Coroutines TS object). I believe that will both _massively_ simplify the common case of writing simple generators for Ranges and other uses as well as satisfying the optimization/code-gen concerns for local generator usage, and there will always be the full Coroutines TS' machinery for recursive or async generators (not to mention all the other coroutine use cases that aren't generators). That of course isn't a fully-explored solution and I could be missing some key insurmountable detail. :) And I'll reiterate: I still think Coroutines TS should go into C++20 as-is. It covers some use cases very well, and the fact that it can be "abused" to (poorly) handle other use cases is indeed a feature and not a bug. I just don't want people to believe that Coroutines TS is the end of the story.
C++ will not evolve any faster, if more people participate in the standards discussions. On the contrary. The more people with differing opinions get involved, the more bad compromises will be made and the longer it takes to reach consensus. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/aqzzg4/i_need_help_with_this_project_euler_problem/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Well I was asking because you're talking about property pages in cmake, and it does not have a concept of that at all. I know visual studio has a weird setup with json files etc... if you let it generate the cmake project, and I avoid that like the plague, it's just pain and suffering, and not really a user friendly way of dealing with CMake. I don't really understand why they did it like that. Question, why don't you set the properties you want in the CMake file instead of the VS project? Also I'm not sure how changing project properties triggers a cmake rebuild for you, as cmake doesn't know at all about any of your project settings. CMake only triggers reconfigurations if it detects file changes, but it won't check output files like vsproj files to see if it needs to rebuild. It almost sounds like either your 3rd party library is doing something weird, or you're using a very strange VS setup. I can change any setting in both local and global scope of my VS project, and CMake won't do a thing (as it doesn't know about that), including setting warnings as errors, etc... I generate my "default" project using the commandline (or the gui tool on windows), pointing to the root CMakeLists file. From there on out I can do whatever I want in visual studio. As long as I don't touch the CMakeLists file, no rebuild can be triggered. I only started using CMake a couple of months ago, ironically using the visual studio "create cmake project". Which was a pretty bad experience, as visual studio has tacked on some concepts to "simplify" CMake projects, but ended up making things more confusing for a beginner. Once I stopped letting visual studio do anything to the cmake files, was the moment everything went smooth for me. And nowadays when I have an external dependency, I just point the cmake file to the git url, and everything gets set up for me.
Doesn't the width of a glyph depend on more than just its Unicode code points? Wouldn't it also depend on the font family, font size, OS accessibility settings, etc.? Also, some glyphs are *combined characters* that have multiple code points, such as: * Cyrillic **Ю́**, which consists of two code points: U+044E (Cyrillic small Yu) and U+0301 (Combining acute accent) * The Navajo vowel ‘**ą́**’, which consists of three code points: U+0061 (Latin small letter ‘a’), U+0328 (Combining ogonek), and U+0301 (Combining acute accent). I'm not sure if the 2nd and subsequent code points can make a glyph *wider*. If yes, you care about them. If not, you can ignore them (but they probably affect they *height* of the glyph).
1. For two reasons: a) I work in an industry where program speed matters, and b) the book Elements of Programming showed me some of the most beautiful code I've ever seen, and it was in C++ 2. C++ is growing, but I don't think it's getting bloated. It would be nice to shed some of the old stuff, but I'd hesitate to call it "bloat". I vastly prefer modern C++ over C++98/03. 3. For C++17, I like the new vocabulary types like `optional` and `variant`. For C++20, it's concepts, by far. 4. I'm a big fan of the STL.
std::for\_each is not c++17, it has been there since the beginning. 17 introduced the parallel overload that takes an execution policy which might have caused the confusion but this is not the overload used in the article. 
I seem to support them semi-correctly for now. What I don't support is the fullwidth chars because my UTF8 library (utfcpp) treats them as a single codepoint, and I use codepoints for my "caret" placement. See the bug in action: http://prntscr.com/mln7jr I don't care about the full range of unicode characters in every situation, I just want to support the most likely cases, and only in a terminal.
I would personally either use std::transform or a simple range based for loop in this case.
Agreed. I think tcbrindle's solution with transform and negate is quite elegant but I would probably go for the range based alternative first myself.
*Which rules*? Did ISO enforces the use of public mailing list over other platforms (where we can still post pdfs and forward it to a mailing list for archive)? Did ISO forbids creating a semi-formal forum? Current proposal procedure is acceptable, and the problem is the discussion *before* proposal and decisions made *after* it.
Game dev, doing c++ for several years now 1) Typically not doing object oriented super often, so object oriented geared languages don't have tons of appeal. Garbage collection is nearly a non-starter for what I'm typically doing. Strongly dislike js and don't consider anything its doing very practical. Can see the appeal of java/c# (even used them for a long while) but not really productive for me for the types of things I usually am working on. 2) Depends on the feature I guess. I tend to not use a lot of modern features unless I find a need. Lots of modern things are fine I suppose, just don't generally feel they are aimed at me or what I'm doing. I don't think C++ is obsolete by any means, it doesn't have any real replacement and I don't know if one is coming. Rust/Jai are interesting, maybe someday one of those or something inspired by one of those. 3) Nothing immediately jumps to mind but I haven't gone through it. Some of the compile time improvements that let me get away from template metaprogramming more seemed promising in their proposal but I haven't seen the final form of what/if made it into the spec. 4) Mixed, use some things sometimes. I'm not sure I'd say I'm a fan, but it exists and does things and its ok.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/ar08ov/ive_decided_to_learn_this_wish_me_luck/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; Why are you programming in C++ instead of C#, Java, Javascript or another programming language ? Performance, generic programming, easy interfacing with other languages (especially C and Python). &gt; Do you feel C++ is becoming bloated, obsolete or playing catchup to more modern managed language now ? Not bloated, not obsolete, and getting better. Inspiration/competition from other languages is a good thing. &gt; you prefer modern C++ or like the old dayz ? Modern C++. &gt; Which new features of C++17 and C++20 you don't like ? or you won't use ? Won't use some, indifferent to other. I don't feel like there's any feature I would see removed. &gt; Are you a big fan of the STL ? Overall, yes. I hope in C++20 ranges will make its use a bit more ergonomic. Some of the containers are not the best performance wise, but they don't have to be - they are good general-purpose implementations.
You can change tab size on GitHub by appending `?ts=N` to the link, e.g. https://github.com/David-Haim/concurrencpp/blob/master/concurrencpp.cpp?ts=4
I mostly do embedded stuff and C#/Java/JS/etc are basically non-starters. You can use a lot of "rich" features in C++ and optimizing compilers can generate compact, efficient, machine code that's suitable when you're working with tens of KB of space for program code and single digits KB of RAM.
&gt; since they can't consume values Oops, in that case I misunderstood. What I want are synchronous and symmetric coroutines, i.e. values can be consumed and produced both ways.
You missed a semicolon. "int n,a,b,c,s" should be "int n,a,b,c,s;".
the c++ parser doesn't really care about newlines. if you look at the token just before that std::cout, you would find that the 'int n,a,b,c,s' line is missing a semicolon. p.s. from the sidebar: &gt; For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow.
Geez, thank you man, I learnt this at school today and the teacher didn't put the semicolon there neither and I really wasn't understanding anything.. Thanks!
Compiler errors for unfamiliar languages and/or compilers can be a pain. We've all been there.
Basically, no. There is no such concept as a 'column' in Unicode (the closest thing is [this](http://www.unicode.org/reports/tr11/), which applies to east asian languages _only_), so the question is ultimately meaningless. What you're _probably_ looking for is text shaping, which is font-dependent and can't be done per code point or per grapheme cluster, it _has_ to be done over a whole text if you're trying to keep it generic because characters change shape depending on font and position in words and sentences in different languages. Either use a proper text shaping engine like HarfBuzz (or OS specific like Windows Uniscribe) - this is what I'd recommend you do if you actually care about getting text layout right - or otherwise if you _don't_ care about getting text layout right for some reason or another... just hack something together, maybe just follow the spec in the previous link or something.
Imho, the industry using c++ is all but accelerating.
What you're talking about is called a "Grapheme" and Unicode has descibed an algorithm for doing so. The bad news is that you need to use tables to find out which codepoints in which order create how many graphemes.
Isn't a grapheme a combination of one or 2 code units, e.g. "ë" is the grapheme but "e" and "¨" are the codepoints? Half vs Fullwidth is a different story that that
What I describe is the LLVM function [columnWidthUTF8()](https://github.com/llvm-mirror/llvm/blob/master/include/llvm/Support/Unicode.h#L60). It's used in many LLVM compilers to achieve what I'm trying to achieve. I'm just looking for a standalone version that I can use in my interpreter (which isn't entirely LLVM-based) 
These days, that’s no longer true. The idea of a full-width character was originally conceived for East-Asian scripts, but has since been extended to a whole bunch of other characters, including things like Emoji.
Does [libunistring2](https://www.gnu.org/software/libunistring/manual/libunistring.html#uniwidth_002eh) do what you need? I imagine it needs the unicode character tables as well as the library itself. The library comes in at a relatively svelte 381kb compressed deb package (at least when compared to libicu63 which is 8Mb or so)
I don't know that library, I haven't found any doc on it. I really just need one function to do the trick, if I had access to a list of range, I could implement it myself easily. LLVM has some [here](https://github.com/llvm-mirror/llvm/blob/6b547686c5410b7528212e898fe30fc7ee7a70a3/lib/Support/Unicode.cpp), but I don't know if I can borrow them :/
Download the [unicode files](https://unicode.org/Public/UCD/latest/ucd/) yourself, extract the relevant data to a binary file ahead of time, and do a binary search whenever you're given a code point. There are several cases to handle: * 0-column, unambiguously (combining, and some other zero-width characters) * 1-column, unambiguously * 2-column, unambiguously * explicitly ambiguously 1- or 2- column (you'll have to pick something - figure out what other people have chosen) * 1- or 2- column depending on context (these are pretty rare) * more than 2 columns (rare, you can probably ignore this, or else normalize ahead of time - e.g. some arabic phrases) * special - various line breaks, backspace, and other controls Additionally, regardless of what the unicode database says, there are some characters that act differently. Secondly, you have to know what version of unicode the terminal is implementing. If a newly-added character should take 0 or 2 columns, but the terminal doesn't know about it, it will take only 1 column there. I was working on a library that does this, but caught up in writing unit tests and never finished. *** Another approach is to print the character at a known position, then ask the terminal to report the current cursor position. By reading the response, you know how much the cursor moved, and thus how many columns the character was. This is the *only* approach that works if you don't know what version of Unicode the terminal supports. On some terminals, you can tell it to use invisible output if you don't want the user to see it yet. Setting foreground and background to the same color is less reliable, but more portable. *** Alternatively, you can just pray that libc's version of `wcwidth` is up-to-date enough. 
I think it'll remain what it is unless you're a billionaire who can fund all this extra work so that committee members can give up their day jobs
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Why dont you just create forum and the cost to enter is 5000 dollars ? That will surely "keep the numbers down". Plus it will be good for the environment.
&gt; LLVM has some here, but I don't know if I can borrow them :/ https://llvm.org/LICENSE.txt Why couldn't you?
You can look at an attempt at a generic implementation [here][2]. Or there's wcswidth_l on some platforms, or you can try using the Windows console APIs to print something out and then [see how many columns it took up][1]. [1]: https://stackoverflow.com/q/9900399/365496 [2]: https://github.com/llvm-mirror/llvm/blob/master/lib/Support/Unicode.cpp
Or even better, you can make an auction for first 150 user accounts.
&gt; I don't know if I can borrow them :/ It's licensed under the LLVM license which is essentially the Apache license. You can use it, even in closed source software, as long as you follow the terms. Just take their implementation, all the tables they use are right there.
Legally, you can copy code from LLVM - it’s MIT licensed. However, you really do want to use a library for this - there is no fixed set of code-points that can be listed as full- &amp; half-width - new versions of the unicode charater tables are released on a regular basis with changes to old tables and new characters added, so if you want your program to keep working in the future it needs to be able to parse the unicode character tables that come with the operating system. There’s nothing stopping you writing the code to do this yourself if you want to of course (or steal it from LLVM), but it’s not as simple as "here’s a list of full-width characters; job done"
Some great talks at the conference and I was lucky enough to be there in person. Hope the rest make it on to Youtube
IANAL, but: Currently, I use a subset of the LLVM libraries. I'm only using some header-only ones, they're stored in a "thirdparty" folder of my codebase, where I put the license text. This is (normally) fine. However, here, I'd have to copy-paste some pieces of code of the LLVM codebase and mix it with my own code. Does that work? I'll probably credit the source in the header, but will I have to do anything more than that?
1) Because it's fast and the people I work with will be able to contribute 2) It is what it is. It can definitely feel like a language for library developers at times. 3) Variant's weirdness compared to other languages. But besides that no real problems. 4) I like standardization that helps me jump between code bases easily and provides common idioms. As far as that goes, I like the STL
Huh? 👩‍👨‍👩‍👧‍👦‍👧‍👧‍👦 Is one grapheme, made up of 13 codepoints...
Do I have to put the license anywhere or is just crediting the source enough?
See the 'LLVM Exceptions' at the bottom.
yep, I agree. As I said, rekonf is still kind of demo of libdinemic functionality. It will be developed more in future, but now it is just simple tool to show how this framework works :)
There is some truth to that. But as in all areas of life, the wealthy get access and privileges which the less wealthy do not. Same goes for WG21 meetings. I would say however that *if* you get a paper onto the standards track, and you are poor, you can apply to the Standard C++ Foundation to sponsor you attending. They usually cover travel and board. They've sponsored me a number of times to attend WG21 meetings, or CppCon, for which I was and am very grateful. So if you really do want to go, and can't afford it, there is a path. It just involves lots of donkey work to make the case that it's worth sponsoring you. And that's no bad thing actually, too many WG21 papers don't come with proof of implementation e.g. standards library changes without a reference implementation. That kind of donkey work is good donkey work, valuable to the committee.
Then, it's not a grapheme I'm looking for. I think there's just a big misunderstanding: What I want to know is the number of column (= width of a ASCII char) taken on screen by a "grapheme" (or a UTF8 codepoint, which is what I'm currently working with in my code), so I can emit the appropriate number of "carets" when printing diagnostics in my interpreter. That's it.
So, if I just put in a comment in the header of my file: \`The unicode tables have been borrowed from [https://github.com/llvm-mirror/llvm/blob/6b547686c5410b7528212e898fe30fc7ee7a70a3/lib/Support/Unicode.cpp](https://github.com/llvm-mirror/llvm/blob/6b547686c5410b7528212e898fe30fc7ee7a70a3/lib/Support/Unicode.cpp). See the LLVM license at [https://llvm.org/LICENSE.txt](https://llvm.org/LICENSE.txt) for more information." It's good enough?
I would like to see the entire w21 process operated remotely, with a modern, custom social media web application deployed which is tailored specifically for the C++ committee process. Unfortunately there people who would not otherwise be able to attend if not for the face-to-face meetings, so there are competing requirements at play here.
C++ has much more than those, as proven by a quick go to cppreference, which doesn't even list the OEM ones for embedded development.
Sure.. Just for the record... I'm not proposing that this is some sort of conspiracy that only the rich have access to it. I'm just saying that the way it is currently done it makes the cut a bit arbitrary.
No, it absolutely is a grapheme. You need to chill with the ego, and fucking read.
Because it's cross platform, and native? Stop acting like there's a whole lot of options soyshit.
What? What did I say?English isn't my native language, so sorry if one of my sentence was insulting, I didn't mean to come across as insulting or egocentric. I'm terribly sorry :/ I'm just trying to understand this whole unicode thing. Up until now I only worried about codepoints returned from utfcpp, and now I'm learning about half vs fullwidth, graphemes, code units, etc. I'm just trying to grasp that so I can apply it to my personal project, that's it.
♪♫ I-rony ♫♪
Just watched Kate and Matt talks, both great. Looking forward to the rest. 
&gt; All strings must be freed with `rs_free()`. /facepalm Why is an "ANSI C" library that lacks basic C++ functionality like RAII benchmarking itself against C++'s stdlib rather than C's?
I cannot find any document to back up but in one of the standard meeting threads it is said that ISO was actually forbidding the process to be recorded. That is why we are only getting the post-discussion blogs. Though, I am not sure if similar exists for mailing or similar
cppcoro requires a compiler that provides coroutines TS. CO2 requires boost. Else, I tried https://github.com/tonbit/coroutine but while it works with Windows, it crashes when tried with XCode.
't was my first conference and I enjoyed it very much. It was a great experience and great talks.
I can't be of much help, but there are also double-width and ambiguous-width characters. I think Vim used to, and maybe still does, have problems with ambiguous-width glyphs.
Here's the relevant text from [their license](https://llvm.org/LICENSE.txt): &gt; 4\. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: &gt; (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and &gt; (b) You must cause any modified files to carry prominent notices stating that You changed the files; and &gt; (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and &gt; (d) If the Work includes a "NOTICE" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. &gt; You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. IANAL, but I interpret this to mean you need to: (1) distribute the llvm license.txt with your code and (2) keep the copyright block at the top of the files but (3) note any changes you made to them. I don't see any NOTICE file so I don't think 4(d) applies.
I think that for now I'll just not show the caret line for lines that have non UTF-8 characters. That's what LLVM (thus CLang and Swift) do. Complete unicode support is just not worth the hassle for me now, I'll come back to it later
The point of `std::for_each` is its return value – if you're not using a stateful function object then why bother?
foo() and bar() are now considered harmful and aggressive. 
You omitted the LLVM exemption at the bottom, which removes most of section 4.
You didn't say anything bad, he's just being a dick.
Probably a stupid question, but have you considered ICU or Boost.ICU? You probably did and I'm not even sure if those satisfy your use case. Anyway, good luck. Unicode is annoying.
My project is meant to be small/embeddable, thus I want to avoid bulky dependencies, which is why I haven't considered ICU :/
Understandable. That's why [ycmd](https://github.com/Valloric/ycmd/) [implemented UTF-8 manually](https://github.com/Valloric/ycmd/pull/894), but it doesn't concern itself with fonts or cursor, so it won't help you..
It just works with codepoints/graphemes and that's it?
My reading of the exception was that it applies to the following situation: I have a C++ program that I've written entirely by myself without so much as looking at LLVM code. I compile it with clang. Clang puts some binary artifacts ultimately produced from LLVM code in my final executable. I don't have to distribute the LLVM license with my program. As far as I can tell if I take LLVM source code then section 4 still applies.
Yes. It's a completion engine, so it's only concerned with whether variable `foo` comes before variable `bar` or not.
Apologies for the noise; I misread it initially and agree with your assessment.
It's because it's an ISO / ANSI standard. The only way to make it even more democratic would be to make it into an open source standard, which implies forking it.
PyPy have to work very hard to match CPython, which is why they only have an alpha of Python 3.6. I expect the same is true for the other non-CPython implementations. Python has a single official implementation, that everyone else has no choice but to try and stay compatible with.
Not everyone uses RAII and exceptions in embedded systems for instance. C's stdlib doesn't have anything to compare against except raw char*.
Except this isn't using C++ to draw. This is output as HTML
Was also my first conference and I was genuinely surprised at how not boring they all were. Awesome event.
If you were using something so constrained, you wouldn't be considering a `std::string` so the whole benchmark in the linked repo would be useless to you.
True. It's hard to see this being in direct competition with anything that has std::string as a viable alternative. But it's still some sort of performance comparison against something that most people know.
Most people also know about `char[]`/`char*` and that kind of strings is much more similar to this library, so that comparison would be much more useful. Besides the whole interface of the library is C-like. I'm not saying C libraries are bad, but I am saying that the comparison to `std::string` is useless.
Totally agree, it's just annoying when it was already in a library-on-older-compilers with boost, then gets imported almost directly in to the standard without fixing the main problems with the type: poor compile times, poor code gen, and poor usage interface through `std::visit` rather than tagged-union style access other languages have. To be fair, all of these are fixable with the current variant type. The first two would likely need compiler front end support for the standard lib to help implement efficiently, and the 3rd can definitely be added as a language feature and hooked up to variant. `std::bind` isn't exactly a great example, since it has the similar issues to variant in terms of poor compile times/bad code gen. And yet it still gets in to the standard in the same language release as lambas :/ None of this really ends up effecting the (stackless) coroutines proposals though. What they're hoping to do requires compiler front end support for the function to state machine transformation, all in the hopes of better performance.
100% agree it's arbitrary. But would be any other system with the limited resources available. If C++ had an executive with ring fenced funding of say ten million a year for a good few full time permanent staff, it would be a completely different story. But we don't, and won't, have that. So you get only changes by those mad enough to endure the process which nobody really hates. Hardly exciting, and definitely not long term healthy. Too much incremental change builds in suffocating technical debt. Some day someone will make a language which treats C++ like C++ treats C. So source compatible, but far more powerful and high level, and better in most ways. And they'll establish a better governance and evolution model too. Hindsight is a great thing. 
swapcontext is psychotically slow. About 40x slower than hacking setjmp jmpbuf, and about 80x slower than inline assembly (a context switch is just swapping the volatile registers and stack pointer.) My guess is it requires a kernel transition to perform. No serious code should ever use swapcontext. There's over 9000 (tiny) coroutine libraries for C/C++ that can be used. [Here's mine](https://gitlab.com/higan/higan/tree/master/libco) for just one.
I'll certainly check it out as I don't see CMake going anywhere any time soon. Hopefully there are enough keywords here for someone else to find it too lol. Thanks again!
&gt; That said, you're totally correct that there should be a distinction between cooperative and pre-emptive coroutines I mean, there is. A pre-emptive version of a coroutine is a thread. The co in coroutine stands for cooperative. (Not meant to be snarky, I hope this doesn't come off as dismissive.)
It output a well-understood graphics format – would it have been more valid as a .bmp?
You just need to call [wcwidth](https://linux.die.net/man/3/wcwidth).
syscall is necessary for signal state saving. &gt;There's over 9000 (tiny) coroutine libraries for C/C++ exactly my point
&gt; There is an experiment currently being undertaken by Jens Mauer to track WG21 proposals using github issues. This would move WG21 closer to a Python PEP like proposal tracker and commenter. That's kind of a step in the right direction, but GitHub issues are far too limited to be a feasible solution for this. Bugzilla or GitLab would be far more suitable. You can actually properly *track* stuff there and track relations, assignments, categories, updates, etc. I think also this would be a really big step forward, if not the biggest step, to make the C++ paper process more easily accessible, and more well-organized. A good "issue" tracker is desperately needed and the perfect tool to track all these papers. That way you can exactly find out what is going on with a particular paper, what the latest version is, why it was perhaps rejected, if it's stale or dead, whose responsibility the next action is, etc. Please committee, take this feedback to heart.
We've gone a long way in making working together remotely more and more productive, and it certainly works, but there's nothing like a few people sitting in a room for a couple of days, physically, in the same room, and working on a paper or problem together. The progress and productivity usually goes through the roof.
Intel's compiler doesn't count as major?
What do you mean by "small/embeddable"? Binary size? There is no escaping tables for majority of the task and they make up the significant portion of resulting binary. 
Sadly, for this task you're not going to get anything much smaller than ICU.
&gt; There is literally no one who says "I like it but my company doesn't so SA". ... I guess no one except Bill then. Also, didn't Michael Wong vote against removing trigraphs as IBM but for removing them as Canada? :)
We don't need people like you in this sub. thanks bye...
Have you tried using LibTooling? I've used it to generate code to do serialization/deserialization. I put the method declarations into the class, and then the method body is generated automatically.
lel I've contributed to this sub far more than ny of you in this thread have. Either way, he's wrong, and refuses to read up on how he's wrong so yeah, he needs to change his attitude, and so do you rando smartass #3
I thought it was funny
No, not snarky at all, no worries. :) Unfortunately I'm not sure the distinction or formal definition here is useful, because the Coroutines TS is more about _continuations_ than it is about coroutines in the classical CS definition. So we have to additinally clarify between "Coroutines as defined by the TS which could be pre-emptively-scheduled/parallel computations" and "cooperatively scheduled concurrent computations." And the Coroutines TS doesn't even really imply anything about whether the tasks are communicating in any way, so it gets even more muddled. :)
I'll keep that in mind next time I consider one of your arguments then :)
&gt; I'll keep that in mind next time I consider one of your arguments then :) I hope you are considering my arguments on the basis of the argument and not because they're coming from me :). I was referring only to things like straw polls. &gt; since how Canada NB votes is not public The plenary votes aren't public? Damn.
Pairs and tuples are rarely the right tool for the job anyway, since each part of it represents something but they are anonymous. It might seem like a bit of a pain, but making structs instead is much better in my experience. 
How Canada comes to it's decision is not public; ie. how any member helped the NB arrive at it's position. Of course the final vote is public, but that's not just any one person's opinion. I consider the arguments on their merit, but if someone tells me ahead of time they will vote the opposite of what they think it's best for C++ because they were told to, that undercuts how heavily I weigh their contributions. There is at some level a factor of trust. You're saying on reddit that doesn't apply to you...
What compiler and standard library implementation?
I have read maybe a quarter of it fully and picked out pieces that I needed from the rest. It is really very good - everything is very well motivated and summarized. You learn how to avoid pitfalls and good ways to structure your project in a modern way. It's also very up to date. Well worth the cost IMO.
I guess I get not using exceptions in embedded systems., but RAII ? Is there anything special about RAII cost that makes it not suitable for embedded systems ?
Let's keep in mind the context: op was saying C++ is being ruined by people who vote according to their company not what they think it's best. Now it stands to reason most people from a company think their company position is what's best, but the quote was "I like it but SA any way". Why would you be strongly opposed to something you agreed with?
I agree - it wasn't code I wrote - but I don't tend to go around changing otherwise perfectly functional code without a reason.
&gt;How Canada comes to it's decision is not public; ie. how any member helped the NB arrive at it's position. Of course the final vote is public, but that's not just any one person's opinion. Ah, that makes sense :) &gt;will vote the opposite of what they think it's best for C++ Often in the committee we are discussing things which don't have "what's best for C++" technical answers. &gt; There is at some level a factor of trust. You're saying on reddit that doesn't apply to you... I guess I trust people who are at meetings representing their employer to represent the interests of their employer. I am there to represent my implementation and my customers, even if I personally disagree with those customers. For example, there are things I don't personally care about like Windows XP support, or app-local libraries deployment support, use cases where the standard library need be unloadable, that my customers and employer obligate me to ensure function. For a recent concrete example of how that affects how I vote/discuss things, look at recent discussions about whether the Interface for Deferred Reclamation reclaims on a thread created by the implementation. If the implementation is required to create a thread to do this silently, that breaks the ability to unload a DLL that statically links with the standard library, since that would leave the background thread with return addresses on its stack pointing to an unloaded library. Personally, I think statically linking the standard library like this is somewhat disgusting, but lots of products my employer ships, and a lot of my customers, are doing that, so I have to vote no to that proposal in its current form (were it being proposed to be merged into the IS). If you think that's dishonorable or untrustworthy, I'm sorry.
You can try out the godbolt link and take your pick. As far as I can see anything as of the last few years has the problem.
&gt; op was saying C++ is being ruined by people who vote according to their company not what they think it's best Then I guess I just disagree with the OP's premise that voting in favor of one's employer's interest results in "ruining C++". If there's a proposal that gives an employer an allergic reaction, it's usually for reasons that would give a ton of customers an allergic reaction too. &gt; Why would you be strongly opposed to something you agreed with? Because often my employer and/or my customers do things with which I personally disagree; but at meetings I am there to represent my employer and my customers, not necessarily what I think is the One True Way of software design.
i feel like std::move is being underutilized
Then I'd argue you're still voting for what's best for C++ (just not you personally), which is a meaning I wasn't going for, but I don't want to argue semantics.
Makes sense. Like I said I don't want to dive into semantics, but I think you're capturing a meaning I or op didn't intend. Serving your customers is indeed doing what's best for the community.
He didn't say that what you posted wasn't a grapheme; he said "it's not a grapheme _I'm looking for_". You lashing out at other peoples' reading comprehension is hilarious.
It sounds like nothing is going to be done. &amp;#x200B; I'm deeply worried about this for two reasons: 1. It would be convenient for me to have. 2. I am concerned about the direction and philosophy of the C++ standardization committee. As to 1, this is not such a major inconvenience. &amp;#x200B; My concern with 2 is based with my prior experience with large (ISO) standardization committees and a similar concern I had about another STL feature. &amp;#x200B; My experience with other large standardization committees is that because of the nature of the voting process, each voter is incentivized to vote on things in such a way that together the language or protocol becomes bloated and unworkable. This can result in huge specifications that at best only one large commercial vendor even tries to get right, and often nobody does. Nobody cares about things working together clearly and harmoniously and maintainably. In the standardization processes I've been involved with or observed, once this process starts there doesn't seem to be a way to stop it. &amp;#x200B; Here, it is incredibly obvious that regex ought to support string\_view from a utility perspective (it's useful to programmers and easy for library implementors). Even if it wasn't obvious from the standpoint of utility, it's obvious from the standpoint of good design: a new data type should be usable in STL functions where it makes sense. I mean, that's kind of the whole POINT of the STL. &amp;#x200B; So, either (a) the standardization committee doesn't REALIZE it's bad design not to have regex support string\_view; or (b) the standardization committee doesn't CARE. I'm not sure which is more scary. &amp;#x200B; A similar issue came up in std::thread (std::thread doesn't support thread stack size). Just as here, when I raised the issue, I got some posters who knew nothing about the interface chiming in with incorrect assertions; and posters who knew about the issue but couldn't say whether or what the committee would do about it. &amp;#x200B; What \*really\* worries me is that the same thing is going as I've seen with other standards groups: focus on new "features" and disregarding harmony, reliability, performance and clarity. &amp;#x200B; The natural thing I've heard is "oh we're too busy". But if the committee is too busy to deal with things, how could it have the time to put all the preposterous variants of regex syntax into regex? Or the latest compile-time trick? Why are they arguing about new language features before cleaning up old ones? 
You're obviously right johannes1971. 
I agree money is not the right way to keep a handle on how many people can have a meaningful conversation at one time, but if you're talented and committed, you will (be helped to) find a way to be a force in standardization. Even just making really good points on mailing list gets recognized soon enough.
Ping me if you need someone to present your papers.
I have no idea what that means but it's hilarious
Moving a couple of scalars wouldn't help anything; the problem is the `memcpy` optimization isn't kicking in.
Does C++ have a way to override the results that `type_traits` gives? Something like how Rust has `unsafe impl Sync for Type` as "treat this like it's thread-safe", a "treat this like it's trivially copyable" compiler hint would help.
So why are char \* allowed?
No – 'trivially-copyable' is a term defined by the standard and your type either meets the criteria or doesn't.
Yeah, I guess it goes around back to funding. Surely, if you count all assets that use C++, you will easily get over 1 billion and possibly many multiples of that, but since the language is completely free, no significant money is channeled into its development. Thats really short sighted, by the industries that make use of C++. Is it completely unreasonable to make the language ,not free, for large companies ? I mean, it is in their benefit, that somebody is pushing the ball, the companies make the biggest profit, they must be required to give something back. Maybe what C++ lacks is good business plan or better negotiators. Surely, there will be pushback, but this "hobbyist" funding doesnt really make sense, since others make billions of dollars out of it.
I can think of some situations where being able to say "just pretend that it is" would help, like here where the user-defined constructor is only used for construction and doesn't require any operations on copy/move. The compiler would generate correct code here if `is_trivially_copyable` returned `true`, so being able to override it like that would be helpful and far from the biggest footgun available.
There is a way to "just pretend": memcpy.
Great. How does someone convince std::vector to pretend then?
I'm sure there's some horrifying method to monkey-patch stuff like that.
Reminds me of how tuple is slower than pair for multiple returns with gcc and they can't fix the implementation because of compatibility.
Haha, probably.
[It's as bad as I thought](https://stackoverflow.com/questions/1584907/how-to-implement-monkey-patch-in-c). Preprocessor abuse and swapping things out with the linker.
I was expecting OpenGV type of drawing.
Nice find. Have you reported this performance bug ?
fwiw there's some proposals to do this (for the highly related topic of relocation) in flight. Basically, they propose adding either an overloadable type trait (ew) or a side-band tagging mechanism consumed by the standard traits (... less ew) for containers like `vector` to know when `memcpy`/`memmove` are appropriate. The primary exemplar use case being `unique_ptr`, which is relocatable (e.g. it can be bitwise copied and then trivially destroyed as a replacement to a move+destruct) but that's not something the compiler could possibly implicitly intuit about the type.
Wait and signal (eg. Producer/consumer) rely on the pattern (unlocking from producer thread (when data ready), and locking from consumer (when waiting). The trick is to to start in locked condition. 
So... somebody defined `operator=` that goes from a float to a double and the `pair` isn't trivially copyable? 1. That sounds correct 2. You **do** use a feature =&gt; you are paying the price No? Also... I do not understand how mixing float and double could have ever been optimized, not from your explanation. I rather think you did not profile this before.
"Somebody"? [Overloads 2 and 4](https://en.cppreference.com/w/cpp/utility/pair/operator%3D).
&gt;Overloads 2 and 4 in a way you would think that as this is a template that is never used that the compiler would just not consider it as part of the actual code emitted from template instantiation and thus be able to optimize just as if it had not been defined (so in this case we don't pay for class members that aren't instantiated even though they exist in the template definition).... &amp;#x200B; Regardless in my testing running the code linked above instead of inspecting assembly on compiler explorer I am not observing a measurable (consistent) performance difference between pair and the custom struct. (YMMV).
One can be vectorized and the other can't; if your toolchain doesn't vectorize either of them, that's.. unfortunate, but frankly surprising and something I would regard as a notable QoI issue.
Whoops... I should have read that myself, thanks!
Personally, I find it sad that the compiler itself can't figure that out.
Am I the only one who read this as "Build your own 3D school shooter in a weekend"
Yeah, that bothers me. Those terms have been used in countless examples and teaching materials, and so far I presumed them to be nonsense made-up words that could be used as neutral placeholders when the focus was supposed to be on the algorithm, rather than the specific problem. Maybe it's because I'm not a native English speaker, but I was simply not aware of their obscure, almost 80 year old etymology. Should we now stop using them because some native speakers suddenly decided to start associating them with micro aggression? Or can we maybe just accept that the usage of these words, at least in programming, has progressed from apparently being rude slang to acceptable neutral names? 
Sorry my brain doesn't work like that. Can't edit the title either. 
(With the exception of MSVCs implementation) pair and tuple have disappointing compile-time and code gen performance too! As an academic exercise, I wrote my own replacements and reduced compile-times and assembly size significantly (especially with optimisations turned off - 10x improvements under some uses!). I wonder why GCC is unable to improve this? ABI compat?
That `pair` is not (necessarily) trivially copyable has nothing to do with the converting assignment. The issue is that the normal copy assignment needs be user-defined in order to assign through pair of references. Of course, nowadays we have ways to make things conditionally trivial. But back in the C++98 days there's no such thing, and it's probably too late to change that due to the dreaded three-letter acronym that starts with an A and ends with an I.
you can just copy/paste boost::asio::coroutine. It's quite simple and a optimized emulation for stackless coroutine. Actually, I'd just stick with boost::asio::coroutine, since coroutine TS optimization is unpredictable.
The issue isn't the templated converting assignment operator, but the noexcept specifier of the copy assignment that stops it from being defaults, and therefore not trivial. See https://godbolt.org/z/2bUxLJ As for why this is.. no idea. Also unsure why implementations don't base it on trivially destructible and copy constructibe.. no idea /u/STL ?
&gt; especially with optimizations turned off ???
Generated assembly in substantially better in debug mode (optimisations off).
Performance with optimizations turned off can be very important in some domains. For example, game development, where code is un-debuggable with optimizations turned on and unplayable with optimizations turned off when using a slow STL implementation.
I kinda agree. Github ain't great. Me personally, I'd prefer if the Python PEP tracking infrastructure were adapted as-is wholesale, but then we'd need someone to maintain that. Same goes for Bugzilla. Github's big advantage is that it is maintained for us.
I highly doubt it. If you can't use RAII then you're really saying that you can't use destructors. That is such a fundamental feature of C++ that can't use the language at all in that case.
have you actually tried writing using the proposal(s)? imo it's a mess. it feels very unfinished. it introduces tons of new bugs. it doesn't play nicely with many other parts of c++. it's way better for the standard committee to wait and be sure something is proven through use than to standardize something half baked which we'd then be stuck with
In other domains people write unit tests to avoid having to run up their entire program every time they need to catch a bug. Games aren’t special, we just have a weird fetish for monoliths
Unit tests (and integration tests, and automated tests) are used in AAA games development, in my experience. They don't help one bit when you're trying to figure out why movement feels "off" and "unnatural" or trying to understand a complex multi-threaded bug while the last ten stack frames have been inlined and none of the very useful transforms are visible in the debugger.
The big tech multinationals would say that they *do* fund C++, by the following: - Sponsorship of toolchains - Sending their toolchain folk to committee meetings - Funding the Standard C++ Foundation to the tune of X dollars per year These are non-trivial costs. If you look at the size of the Visual C++ team alone, you'll see that Microsoft invests tens of millions of dollars into C++ annually. Google and Apple do similarly with clang and LLVM. However as a rejoinder to that argument, all but the Standard C++ Foundation money is *tied funding*. There is no large, politically uninfluenceable, annual pot of money regularly invested into the ecosystem, directed by technocrats not employed directly by the tech majors, for the sole benefit of the C++ ecosystem. Languages such as Python do have that, but that was only because Guido took out a second mortgage and risked everything including his health to get that. There was also a significant hindsight advantage. &gt; Surely, there will be pushback, but this "hobbyist" funding doesnt really make sense, since others make billions of dollars out of it. You've got to remember that programming language choice has one of the lowest barriers to entry around, there are thousands of excellent choices for any new project. But there are very significant lock in costs, as early adopters of Rust are beginning to find. C++ competes very well on lock in costs, but only because the toolchains are so lavishly sponsored. The billions of dollars made isn't due to C++. C++ is just the medium for a given software expression. C++ employers fund accordingly. I can speak from experience that it is **very** hard to find an employer willing to sponsor participation at C++ standards, and in some sectors e.g. in storage it is actually completely impossible because there's no culture of seeing the choice of programming language as having anything whatsoever to do with storage (which is completely and utterly wrong, but good luck on convincing the bosses of storage firms). But it makes sense when employers don't see the language their software is written in. They see their software, not its tooling, and tooling is always underfunded and dysfunctionally misfunded appropriately.
I don't think anyone is aware of the source of the words and it's not even clear if the presenter actually is correct; the word she is referring to is 'fubar'. I doubt anyone will stop using them really, that ship has sailed 
`is_trivally_copyable` is the type trait that formally means "can be memcpyed". IIRC, there are certain types for which this is not a synonym of trivially destructible and trivially copy constructible. (This is the sort of thing that makes me say C++ is complicated, and I can tolerate a lot of complexity...)
I'd count a "major compiler" as being one which targets everything from the very small to the very big, across at least the four most popular CPU architectures x86, x64, ARM, AArch64. That would be MSVC, GCC and clang. The embedded toolchains which are not GCC nor clang based don't meet that that definition. Intel's compiler doesn't meet that definition.
Similarly, MSVC and GCC usually lag behind clang for language support. For 99% of Python you'd ever write, all the four major Python implementations work great. Similar for C++ on the three major compilers.
Things is really great!
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/ar7jo5/learn_socket_programming_in_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Genuine question: Why is using exceptions slower than manually inserting `BOOST_OUTCOME_TRY` into a stack of function calls? Hmm, maybe it's because returning a `Result&lt;T&gt;` reserves space on the stack for the error object, while throwing an exception has to allocate space somewhere else? That can't be the whole reason, because one extra allocation doesn't sound like that big of a deal.
There are fixed width fonts, for which certain unicode characters still need more than one column. I guess that's what the OP refers to.
that is such a shortsighted opinion. one really has to question whether you’ve written any substantial piece of software. how would you suggest “unit testing” bugs that are time sensitive, or exposed by race conditions, or depends on some underlying system that you can’t control? that’s where a debugger comes into play, and as the previous commenter said, good luck trying to debug anything when all your stack frames are no longer implicit and variables are inlined away.
Granted. But can you appreciate my point that having to run up your entire game to test player controller / locomotion seems a little .... monolithic? Complex threading bugs may be more difficult to track down when you radically alter the performance characteristics of your entire program by switching optimisations off. Sure it can help, but it's not as clear cut as your comment seems to imply. And it should be fairly rare in any case, right?
I'd prefer monadic approach myself. But exceptions are the only way to report failure from constructor or operator overload. 
Delete this 
The barbarians at the moats are the dipshits here who want to fix C++ by making it just like the community driven command hierarchy that lead to what manifested as the Windows zune handheld interface forced upon every windows user via desktop, laptop, surface, and handheld. Thus converting the entire Windows Toolstack to a content consumption only stack. And their gall to say: "Your systems are old and out-dated because they have rules to prevent these sorts of hostile virtue signaling takeovers". It's like a child walking into the biggest car dealership in the state and saying: "your model is wrong because it doesn't let me move all the assets of the company into my own account so I can rape all of you". Absolutely breathtaking. 
&gt; The only public mailing list is SG14. Though I can't speak for all of them, this is patently not true. SG16 uses slack and a mailing list for discussions, plus some videoconference thingy every two weeks, and a github repo to post minutes of those videoconferences. All of these are open to anyone.
https://ned14.github.io/outcome/faq/#what-kind-of-runtime-performance-impact-will-using-outcome-in-my-code-introduce
I don't know the PEP tracking infrastructure, but indeed it sounds like a great fit. Bugzilla is fairly low-effort maintenance-wise I'd say, but definitely it's not zero-maintenance, and that has to be taken into account. Anyway I'm sure the C++ foundation could find a couple of hundred bucks a year to find someone or a company to maintain it. And GitLab.com can be used as well for free and with all features for public projects, and it's "open-core" (I believe that's what they call it), so there is zero maintenance there at zero costs and zero configuration needed (one of the paradigms of GitLab). Many people haven't noticed or realised yet but GitLab has waaaayyyy surpassed GitHub in the last 2-3 years, it's amazing, and more open than the completely proprietary GitHub.
Move and copy for scalars is the same operation.
nope. Here i am that read it the same way.
Caveat is, you need to use define your own hash for a struct even if all your members already have a hash. That is, if you want to use it in some associative container
Guilty as charged.
That's an interesting point. I'd say on *nix, the closest thing to CPython is GCC, not clang (on Windows, it would be MSVC). Hence why clang by and large adopted GCC's flags and supports GNU extensions. &gt; For 99% of Python you'd ever write, all the four major Python implementations work great. For the longest time, PyPy didn't support NumPy. In fact, I just looked it up, and neither IronPython nor Jython even support Python 3. The last IronPython release was a year ago, and the last Jython release was almost four years ago.
&gt; In this case: a feature I never used is now making my code run slower. The "don't pay for what you don't use" has failed me. Let's be honest: STL is rarely true zero overhead (except maybe for the algorithms)
I was an early enthusiast of gitlab, and I entirely agree. But a *decent* web maintainer is just as expensive as a C++ committee member. I know the Standard C++ Foundation do have infrastructure maintainers, but they seem very busy as it is, and don't want to take on more work.
Interesting point
Most people still write Python 2 which also happens to run in 3. I know I do. But point taken about NumPy not working widely. Or indeed anything with a C component, and there are important bits of the Python landscape where a C component is unavoidable.
Curious about section 4. You say you're adding the GUI and make this comment &gt; like imgui, but my students somehow prefer SDL, so I am linking with it. imgui is an immediate mode toolkit for building interfaces with buttons, labels, etc. but SDL is just a graphics library, it doesn't have gui widgets, at least it didn't last time I played with it. It appears you're using SDL for a graphics library, even mentioning removal of stb, and I'm guessing you have it handling the keyboard and mouse events. How would imgui have been usable to do that?
Why are comments disabled for just this talk? https://www.youtube.com/watch?v=sQcPte0JNmE
The title says to see Kate's video but I don't see video of Kate Gregory's presentation?
Same reason they were disabled on *some* CppCon videos: I let you figure which.
You've heard of Boyer-Moore? Now meet Boyer-John :) :) :) 
&gt; [Please note: This version of the video is being replaced. A new version will be uploaded soon and will have a new URL, which we'll link to here] https://www.youtube.com/watch?v=p-b6CGvuWyA 
Wow am I seeing things? There's Kate's video, and it is in the cpponsea account, but it doesn't show up in Videos? How is that possible?
Well the answer is yes, sometimes you need to use it yourself. However, you can and should write unit tests for the situations you mentioned. It may be difficult, but definitely still possible.
Also it turns out I already saw it yesterday, lol... seems my memory is getting worse.
&gt; Dresden Files I really liked the T.V. show, too bad they canceled it
&gt; Most people still write Python 2 which also happens to run in 3. I know I do. By that measure, most people are still writing C++03, or C++11 at best. Many of the most important [libraries](https://python3statement.org/) have pledged to drop Python 2 support anyway.
Isn't the whole promise of C++'s performance that its features are Zero-Overhead Abstractions? I don't see the dichotomy here; C++ implementations *should* be able to match C's implementations performance, when comparing equal feature sets.
One thing I noticed here is that `sizeof(rs_rapidstring) == 32` on 64 bits architecture, whereas `sizeof(std::string) == 24` (typically, with SSO). This allows `rs_rapidstring` to store up to 31 characters without heap allocation, whereas `std::string` implementations are typically limited to 23 characters and AFAIK gcc's implementation tops out at 15 characters. This will likely influence results on short strings... but comes at the cost of slower *moves*. That is, shuffling an array of `rs_rapidstring` requires shuffling 33% more bytes than shuffling an array of `std::string`. It would be interesting to understand why `std::string` is slower, and where performance is lost, but my last foray in libstdc++'s string implementation was enough for me. 
Unless you can use magic get.. https://github.com/apolukhin/magic_get
Are you open to use cmake on the project i can provide a PR! Looks really awesome!! Great Job
https://github.com/simonfxr/fiber
Came here to say this.
lists.isocpp.org contained only SG14 when I wrote my comment. I do not deny existence of channels you speak. Discoverability is the issue. Does committee have some kind of landing page "SG X resources are here, proposal statuses are here"?
I'm pretty sure few other native speakers consider those terms offensive. If you want the G-rated version, "F-u" can simply stand for "Fouled Up". It's hard to imagine that anyone is honestly so delicate as to take real offense at the use of that term. At some point, you need to roll with societal norms.
I tried to make a point, that maybe there is a better way to position the C++ standart in free market economy. My intuition tells me, that development of one of the most used programming languages, shouldnt be dependant on charitability of those who use it and make huge profit, thanks to it. I dont believe, that there are many choices for language (if thats what you were saying) because the companies that already use C++ have really poor negotiating position, they will rather pay the "C++ development tax" rather than remaking their whole codebase (assuming its not absurdly high) I would let them have everything up to C++17 and if they want to use C++20 and use it commercially, they will have to pay some acceptable fee. I dont think, its such an outlandish idea. Really, there must be better funding strategy, than asking for handouts. &amp;#x200B; &amp;#x200B; &amp;#x200B;
Congratulations Niall! Can't wait to start using it :-) A question: in an [earlier post](https://www.reddit.com/r/cpp/comments/68tfxl/video_for_accu_2017_talk_on_proposed_c_expectedt/dh2i0am) you mentioned an error type with support for propagating a backtrace together with the error(error_code_extended). I searched around, but it seems like it has [been removed](https://github.com/ned14/outcome/issues/45)? Is there a way to achieve this with the current Outcome?
&gt; they can't fix the implementation because of compatibility. Should be the slogan of C++
CMake is a life saver, I have recently used it to build custom code generators and misc. build tools. If you follow "Modern CMake" you can learn cool things that can be done in just a few lines. set(output_directory ${PROJECT_SOURCE_DIR}/output) add_executable(codegen codegen.cpp) add_custom_command(TARGET codegen POST_BUILD COMMAND $&lt;TARGET_FILE:codegen&gt; ${output_directory} ) # for any target which relies on this build tool do: add_dependencies(some_target PRIVATE codegen)
There's a better solution if you're the author of the project. You can add an .editorconfig file to the project root, and GitHub will respect those settings. Here's an example config file: [https://github.com/JamesBoer/Jinx/blob/master/.editorconfig](https://github.com/JamesBoer/Jinx/blob/master/.editorconfig) And some sample code from the project: [https://github.com/JamesBoer/Jinx/blob/master/Source/JxLexer.cpp](https://github.com/JamesBoer/Jinx/blob/master/Source/JxLexer.cpp) Why GitHub doesn't add tab size as a simple user config is beyond me, though.
Coincidentally recently I also run into limitations of `std::pair`'s `operator=`. It's not `constexpr` until c++20, meaning I had to rewrite: std::swap(mapping, result[ij); to Mapping tmp; tmp.first = result[j].first; tmp.second = result[j].second; result[j].first = mapping.first; result[j].second = mapping.second; mapping.first = tmp.first; mapping.second = tmp.second; Annoying!!!
Thanks a lot! Please, spread the voice :-) Feel free to issue a PR. I guess that adding cmake support can’t do any harm, right?
&gt; By that measure, most people are still writing C++03 Last time I saw a user base survey this is still true.
I always feel it's kind of awkward to add a library like this to use something as simple as a struct with a hash. Interesting nonetheless.
but since the only thing it does is jump around using gotos behind macros, it cannot backup the state of the current frame -&gt; meaning no local variables in your coroutine
They tweeted earlier that they had to temporarily take it down to fix something with the slides
Microsoft used to charge for their compiler, and I'm sure would still love to. But the market forces you mentioned forced them to give it away for free to most developers. If you tried to charge for newer C++ versions, everybody would stick to the last free version forever. We saw that happen with ZFS, Oracle started charging, almost nobody upgraded. Same is going to happen with Java. It's very very hard to compete with "free". And "free" is incredibly distortionary. Wrecks entire business models. C++ has been distorted by "free", same as large tracts of tech in general. Me personally I think there is an untapped golden egg of money sitting in training and recruitment. There is an army of talent wasting away in crap roles. There is constant complaint about lack of talent. Better matching the two for a small percentage would be a great revenue earner, and help the ecosystem hugely in many ways. I have raised the idea multiple times, but I've not achieved consensus opinion yet.
It was renamed. https://ned14.github.io/outcome/tutorial/advanced/hooks/hook_result/
besides the fact that this is an (interesting) implementation of ***stackful*** coroutines, it also has some issues like not backing up all registers on x86-32. If you want a stackful coroutine. Either use features provided by the OS kernel (e.g. win32 fibers) or at least use boost::context/coroutine2.
I have had this problem, if you are generating your build files as a part of the cmake build process you can do [`add_custom_command`](https://cmake.org/cmake/help/latest/command/add_custom_command.html) which depends on a cmake executable target; you can also do [`add_custom_target`](https://cmake.org/cmake/help/latest/command/add_custom_target.html) if your build file generator is not a cmake executable target.
In general, if you want people to actually use your code, you should support cmake builds.
You guys are mixing up ***stackful*** with ***stackless*** coroutine implementations. We want stackless ones because they use way less memory (no additional stack required). But they require compiler extensions/changes. Stackful ones can be implemented in assembly (see boost::context) and don't have to be in the standard.
Fair enough, I think I was misunderstanding what OP was trying to do (I assumed they were trying to write GUI, but with the reference to llvm they're probably actually trying to write a CLI where fixed width is a reasonable assumption) 
yes, you are right. For local variable across yield point, you have to make it a data member or a lambda capture. It's easy to understand, not so hard to use and best performance for something similar to coroutine.
Please see issue #23 https://github.com/daniele77/cli/issues/23
It may even make the library better since the boost library could be turn into optional for those that just want the local cli. &amp;#x200B; Just one question is the library c++14 mandatory?
LOL this is horrific. Why should this even be a thing?
Sure, I used the same trick once. But I try to avoid it since I don't think the resulting code looks particularly good.
Yes. Unfortunately, it requires at least C++14 because it uses std::make\_unique and generic lambdas.
Only Americans I suppose 
Tabs are evil anyway. I've yet to see a project that allowed tabs and they were applied consistently. The linked file is full of wrongly mixed tabs/spaces for example (becomes apparent with `?ts=8`).
Not unfortunatly at all. If people want cool libraries like this ones they should update the compiler ;)
Initial support for Cmake [https://github.com/daniele77/cli/pull/30](https://github.com/daniele77/cli/pull/30) &amp;#x200B;
Much appreciated, thank you
&gt; you can and should write unit tests for the situations you mentioned You realize that testing for all combinations of external realities is an exponential problem. It's literally impossible. There is also no world in which having 1e6x as much test code as actual code is going to happen.
+1 You should create an OPTION to include the samples folder, which can then be turned off in the vcpkg portfile. Or it can be off by default, and those wanting the samples, can enable the option. 
I read that the same way as well. Putting "school" and "shooter" in close proximity just makes your mind go there these days.
What a silly mistake on my side not to think about that hahahaha. It should be fixed now :)
My first glimpse at the title left me thinking this was a poor taste post about how to 3D Print a weapon for school shootings. Way to clickbait OP ;)
The title had me believe this is an interactive sandbox to experiment with modern C++ code!
Yeah, I used a misleading title, sorry!
Low level memory is slowly being phase out of C++: as of C++11 the standard has had `std::unique_ptr` and `std::shared_ptr`, and as of C++14 the standard included `std::make_shared` and `std::make_unique`. If you want to learn low level memory, you might want to read through ‘The C Programming Language (2nd Edition)’, which will go through all syntax and features of C. While C is not C++, there is a lot of valuable content in that textbook, it’s condensed well and it’s quite short (about 300 pages). There is a C++ edition but it’s much, much longer, so I’m guessing you aren’t interested in reading the entire C++ standard. For fundamentals as a crash point I really like (tutorialspoint)[https://www.tutorialspoint.com/cplusplus/index.htm], and for referencing functions from the standard library I use (cppreference)[https://en.cppreference.com/w/], which has documentation on basically everything for every standard up to C++20. As for the compiler and toolchain, I’m not sure there are a whole lot of resources available but any specific questions you have can be answered here or on SO. Good luck and happy coding!
What about std::swap(mapping.first, result[j].first); std::swap(mapping.second, result[j].second); Definitely not ideal, but still only one extra line.
stackless coroutines are as useful as shot in the head. Unless for academic purposes, of course &gt; it also has some issues like not backing up all registers on x86-32. Not an "issue" as it is clearly stated there. They save all the registers. They are only not backing up the floating point state. This is the ONLY way to achieve any decent performance out of stackful coroutines. &gt; use features provided by the OS kernel (e.g. win32 fibers) I don't know who does any serious work on windows these days &gt; at least use boost::context/coroutine2. Why? Boost is a catwalk for inflated egos trying to impress everyone with overly complex, overengineered code. I know tons of companies that outright ban the use of boost. The guy above is one of them. 
[A Tour of C++ (Second edition)](http://www.stroustrup.com/tour2.html) &gt;The ``tour'' is a quick (about 240 pages) tutorial overview of all of standard C++ (language and standard library) at a moderately high level for people who already know C++ or at least are experienced programmers. It covers C++17 plus a few likely features of C++20.
Indeed. On the other hand that seems to be what all those new languages do
`std::regex` is one of the parts of the STL (e.g. `std::valarray`) that's been de facto abandoned. The implementations are not maintained (literally just decade-old versions of `boost::regex`) and you'd be much better off going with a different regex library.
* All discussed coroutine proposals are afaik stackless. All the concepts (async compute, generators,...) are possible to be implemented with those. The reason why one prefers those is simply that they are more efficient and won't fill up your memory after just a few thousand instances (depending on the stack size). * I must admit that I immediately jumped to the most complex part of the code due to curiosity about the implementation. Although: who says that you can guarantee that the optimizer of your compiler will never make use of the xmm registers. Therefore not including them in the backup is IMHO a huge risk. * Using win32 fibers is the first example which came to my mind. Of course other operating systems offer alternatives. Regarding your claim that nobody uses Windows. I'm aware that OSX is quite wide spread in the US but outside of it most desktop computers run Windows. (Personally I'm a Linux user but in the big picture that's unimportant.) * Boost is an extremely powerful c++ library, tested and utilized in the industry. Why you would prefer hand written incomplete assembly code from a small github project over a well tested and maintained library I anyones guess. Speaking from my experience the only bigger issues boost has is the improvable documentation and (at least in my opinion) the unique build system.
Okay, I hope I have not come out as ungrateful for what people, including you, who participated on C++, have achieved. I just really want to understand C++ in broader context and sometimes I have to poke in the flesh, to get satisfying answer. Teaching people C++ might make a lot of money, but I dont find teaching enjoyable (maybe because I am young) and also I learnt the basics online by myself and the combination of Youtube content (best for starting), books and Ask-anything reddit and stackoverflow, that means if you have the will, there is clear path to learn it. Working in particular project that you care about is very important for motivation. Teaching it, might ease the learning curve for sure. But before teaching it, explain the extreme utility and why should anybody learn this alien-looking syntax. Personally, I would love to see it in schools, just putting it as voluntary subject - definitely not forcing it. In my country (Czech Republic), there is almost noone doing it - in schools or outside. Also, I want to say thanks for your patient answers, have a nice Saturday ! 
I don't know other consoles, but apparently Windows cmd displays ’ (U+2019) as either halfwidth or fullwidth depending on the font used at the time of typing: https://imgur.com/a/JrNxEwv 
If you want to speak to C++ from .net, C++/CLI ~~is~~was the way to go. Beats COM interop any day of te week. (And I say that as someone who thinks COM is freaking amazing; there never was, **in the history of computing**, a more competent and comprehensive language interoperability layer). .net Core doesn't look like it will get a C++/CLI compiler, hence "was".
I can't find anyone named Kate in the thumbnails.
See this post below: [https://www.reddit.com/r/cpp/comments/ar03up/some\_c\_on\_sea\_talks\_are\_available\_go\_watch\_kates/eglem8l/](https://www.reddit.com/r/cpp/comments/ar03up/some_c_on_sea_talks_are_available_go_watch_kates/eglem8l/)
Why negate it there and not upon generation of the points? Is it only because we want to separate the generation of the parametric curve from format-specific manipulations?
&gt; All the concepts (async compute, generators,...) are possible to be implemented using those. I lack depth here but I don't think a stackless coroutine can implement any slightly complex generator but only the most trivial. Being stackless is a brutal restriction on what can be coded. &gt; Why you would prefer hand written incomplete assembly code from a small github project over a well tested and maintained library I anyones guess fair question. Let me follow up with another question: have you seen the asm implementation of boost::context, which coroutine2 is based? In particular compare https://github.com/boostorg/context/blob/develop/src/asm/ontop_x86_64_sysv_elf_gas.S with this https://github.com/simonfxr/fiber/blob/master/src/fiber_asm_x64_sysv.S 
This is very cool. I created a cli tool in python for one of our apps using python's cmd module. The best part was how easy it was to specify a command and the piece of code that needs to get executed when the user would run that command. All I had to do was inherit from the cmd.Cmd and simply create methods with "do\_" prefix. Through some reflection magic, this module figured out that these were in fact my commands. Any chance you can implement something like this C++ so your users need not register a name and a lambda explicitly? &amp;#x200B; To be clear, here is some python pseudo code and sample cli interaction to illustrate my point: &amp;#x200B; import cmd class MyCLI(cmd.Cmd): def do\_open(self, arg): """ Doc string that specifies command help """ \# process arg \# do open stuff if \_\_name\_\_ == '\_\_main\_\_': MyCLI().cmdloop() &amp;#x200B; $ mycli mycli &gt; mycli &gt; help Documented commands type help &lt;topic&gt; ==================================== open &amp;#x200B; As you can see above, I didn't have to register my command "open" explicitly. Just defining a method with a special prefix did the trick. Do you think, something like this can be done in C++ and hence remove the need to do the following in your case: rootMenu -&gt; Add( **"hello", \[\](std::ostream&amp; out){ out &lt;&lt; "Hello, world\\n"; }**, "Print hello world" ); 
I must admit it's been some time since I looked at the code. I'm therefore a bit surprised that boost::context also does not backup them. I will investigate this at some point! Thanks for pointing this out! &amp;#x200B; Regarding the possibilities of implementing those features with stackless coroutines: I attended last years meeting c++ conference at which a talk was given about the coroutines ts: [https://www.youtube.com/watch?v=RL5oYUl5548&amp;t=1s](https://www.youtube.com/watch?v=RL5oYUl5548&amp;t=1s) He showed off the common use cases for coroutines based on the TS.
The STL should be called GSTL - Generic Standard Template Library. I don't think performance has ever come into consideration in the design of the STL. Nor usability, I can only imagine. 
it's the ABI, not C++
In theory, yes, but everyone knows the adage about theory and practice – benchmarks are there to distinguish the two, and comparing disparate interfaces and idioms for entirely different languages only muddies the waters. As an aside, as a C++ dev I don't feel like writing C++ bindings for yet another C library; any library marketing itself for C++ devs should do this out of the box or it shouldn't bring up C++ in the first place.
wouldn't that be UB?
You're right. OTOH, you get this almost for free with C++17 structural bindings
C++ is not complicated - it HAS BECOME complicated, over-engineered I would say Go back to C++03 and complexity drops down dramatically, while performance stays the same or improves.
And then these barbarians broke through your unbreakable portcullis with laser and cyborgs.
Strongly disagree. Move semantics is responsible for major performance improvements.
Yes, this specific example is about ABI. But there are numerous examples of flaws in the standard that can never be fixed because of backwards compatibility (Looking at you unicorn initialization!). Staying (binary)compatible to previous versions and maintaining a compatibility layer with C is preventing the language to evolve and outgrow its problems. 
and _what_ is that reason? 
Move semantics is a solution for a fictitious problem created by STL's bad architectural decisions. If you don't use the STL move semantics become plain useless. 
https://issues.isocpp.org/buglist.cgi?product=C%2B%2B&amp;component=Library almost meets these criteria. It doesn't seem to be used by EWG though.
(I have no opinion about the object-level topic here.) Warning and advice: Please refrain from launching nuclear missiles, even if you're justified. Patiently tolerating wrongness and explaining correct information makes this sub and the C++ community a more welcoming place. It also enhances your reputation, which is ultimately more satisfying than the short-term gratification of pressing the big red LAUNCH button. (I speak from experience.) With the exception of this thread, your contributions since being unbanned have been positive as far as I've noticed, and I'd like to see that continue.
I got some Twitter questions about why single header distribution is not the future, but the reply didn't "quite" fit a tweet and then it kinda grew into this article.
"Do you think C++ is bloated now" was removehelp-ed by a moderator, while "Is C++ dying" was directly removed by a moderator. So, Cloud_Strifeeee isn't deleting their own posts. I am not a fan of negatively-phrased leading questions ("bloated/dying"), so I concur with those removals. In this thread, #1 is positive, #2 is largely negative, #3 is negative, #4 is neutral-positive, so I have mixed feelings. As this is phrased to prompt discussion, I am inclined to allow it (if the other mods prefer to remove, they can). However, thanks for identifying this pattern, /u/tcbrindle - future posts along these lines will be removed if they are repetitive or negative.
&gt; As an aside, as a C++ dev I don't feel like writing C++ bindings for yet another C library; any library marketing itself for C++ devs should do this out of the box or it shouldn't bring up C++ in the first place. I don't really advocate writing any binding either; I'm more interested in understanding why it's faster and applying the techniques/lessons to existing `std::string` implementations. &gt; In theory, yes, but everyone knows the adage about theory and practice – benchmarks are there to distinguish the two, and comparing disparate interfaces and idioms for entirely different languages only muddies the waters. I found the set of operations benchmarks reasonable. There seems no reason why catenating two `std::string` should not be as fast as catenating two `rs_rapidstring`, as both perform essentially the same work: reallocating memory if necessary and copying the new characters.
We can use code that's released under the Boost Software License. (Possibly other licenses in the future.) At this time, we can't change future/promise's implementation due to binary compatibility. /u/BillyONeal wrote an overhauled implementation in our binary-incompatible branch which will be released at some point.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ara3ho/cclike_languages_crash_course_for_proficient/egm69gr/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/aqvxl8/please_review_my_library_concurrencpp/egm6a9r/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I definitely started using Catch2 when I was less knowledgeable about the C++ build tool chain and wanted a quick, nice interface for testing. 
There are things you cannot implement without move semantics, like a strict ownership smart pointer. I would never want to go back to `auto_ptr`. I'd also be curious to know what you think are "STL's bad architectural decisions" wrt move semantics.
Indent you code with four spaces to format it.
Have you thought why intrusive pointers were never included in the STL although used ubiquitously in every latency-sensitive code out there? Or how is it possible that overflow() is called for every byte in iostream? Or have you considered that perhaps iterators are the wrong approach for being clumsy to use and invalidated often by perfect looking code easily leading to undefined behavior? You got to understand that the STL was ADDED to C++ at some point under the unrealistic expectation to be a one-size fits all, to cover every possible usage, instead of implementing something outright useful like python's standard. That was the seed of all evil. C++ exists without the STL. For a long time we could use C++ and just ignore the STL. However, the C++ standards are now making us non-STL believers pay the price to cover the STL's ass by introducing things like move semantics. That's two cents from someone who used C++ as the main professional tool every day for the past 20 years. 
Apologies for not being clear. You said: &gt; Move semantics is a solution for a fictitious problem created by STL's bad architectural decisions I was asking for examples of these decisions. I don't see how `overflow()` or iterators are related to move semantics.
I was personally invited to participate soon after SG16's formation, so I don't actually know how discoverable this is. So that's fair enough, I guess. I might bring this up next meeting.
I've read a lot about it and it really helped. Thanks again!
I think native support for reflection will be there in C++20/23. Before then, OP could add a pre processing tool like the one Qt has. That tool can then generate code to register all the functions it find (which maybe marked with a special macro to make them easier to find). 
ok you clarified your intent to narrow the scope of your question, that's fine. So try to build a very fast custom memory pool that is not a singleton and you will see that you cannot use it with the STL, even if you build a custom allocator. Now, do your research and follow this rabbit hole. I'll just add that a custom memory pool (perhaps BSD-type), a simple intrusive pointer and your own container will easily win in speed and complexity anything that STL and move semantics can achieve. 
Always a pleasure to engage in mature discussion. Thank you! 
Me personally, I'd ship multiple single header include editions, each compatible with one another, so more than one can be included into the same TU. I'd then split the functionality into lite, medium, heavy editions. That way people only needing lite don't pay the build time for stuff they don't use. I too used CATCH for years, but it become too heavy for me, so I ended up writing my own which is less than 160 lines long, and it does everything I want from a test framework, including spewing out junit xml and working well under multiple threads. 
There's nothing that says you can't `=default` an operator with a noexcept specification.
I find the benchmarks chosen not broad enough. Some of the results make sense from am interface point of view. E.g. it makes sense if you do a concatenation and call an interface that knows there won't be a reallocation (while std::string interface can't make such assumptions).
I like the designated initializer, but overall I find this highly complicated and complex with very little actual benefit. Sure it's type safe and supports any number of flags and you indeed don't need to maintain a list with pot values (although it's hardy complicated), but the tradeoff is that it turns simple one-line atomic operations into template hell. I don't think this is a tradeoff I'd personally be willing to make, especially if it affects compile times significantly. 
I get what you're saying, it just pised me off how he comes in here acting like I'm wrong on Unicode, I'm not saying I'm the worlds foremost expert or anything, but I literally rewrote the UTF-16 encoding and decoding part on the wiki article... it was a pain in the ass to track down before I did so, and wiki's original description was very confusing. So yeah, I'd say I know a thing or two about Unicode.
&gt; try to build a very fast custom memory pool that is not a singleton and you will see that you cannot use it with the STL, even if you build a custom allocator I'm not sure I understand: custom_allocator&lt;int&gt; a1(very_fast_custom_memory_pool_1); custom_allocator&lt;int&gt; a2(very_fast_custom_memory_pool_2); std::vector&lt;int, custom_allocator&lt;int&gt;&gt; v1(a1); std::vector&lt;int, custom_allocator&lt;int&gt;&gt; v2(a2); That works fine. &gt; a custom memory pool (perhaps BSD-type), a simple intrusive pointer and your own container will easily win in speed and complexity anything that STL and move semantics can achieve Anything can beat the standard containers if it's custom made for your particular problem. Move semantics have nothing to do with this. Standard containers are general purpose. For the vast majority of my uses, they work perfectly fine. The fact that move semantics _did_ have performance improvements on them allows me to use them in even more situations, and I don't even have to write or maintain anything. I let both STL and the STL do the work for me (thanks STL!).
Thank you very much for your comment! No, what you did in python is not feasible in C++ because it lacks runtime reflection. Actually, even if C++ provided RT reflection, I would not have chosen that design anyway because: - I want to be able to attach / detach new commands and submenus at run-time. - I want to be able to attach arbitrary (possible existing) code (e.g., a function from a third party library) without writing an adapter. - I want to be able to create an arbitrary complex tree of submenus. - I generally dislike huge stupid classes. BTW: In C++ I could have done the registration at compile time using template metaprogramming! But with registration at compile-time I would have lose the option to register/unregister commands/submenus at run-time (e.g., when the application is in a determined state). Yet, it would have be cool to show that I’m able to write template magics to do all the setup at compile-time. However, I believe a developer should consider pros and cons of design decisions, which should not be driven by the wish to use cool technologies :-) Anyway: my cli code has a cool design, in a way. It’s a good object oriented design, despite OO is not so cool nowadays :-) The whole composition of menus and submenus, the different types of sessions, and so on... Not the fake OO you find in typical java programs, though :-) 
what happens if you move one element from v2 to v1 and then delete both vectors?
I have, in a production project, and it's been nothing less than transformational. We've encountered a couple compiler bugs, but aside from that it makes us better programmers that write simpler, less buggy, easier to understand code.
Quite frankly, the idea of shipping libraries as single header files is pretty moronic. SQLite seems to be the only project that gets this right.
The same thing that happens if you were to mix any object and allocator, whether in a standard container, a custom container or in any context. This is not an issue with move semantics, nor an example of "STL's bad architectural decisions".
Is your test framework publicly available?
I don't like it. it is too easy to fuck over your lifetimes. it's infectious so you can't easily mix coroutines and non Co routines. and a lot of blocking calls don't have nice co awaitable interfaces so you end up with boilerplate. a language like Python has a clear case for generator functions but in something with more low level stuff exposed I think it's less clear how to handle the context
I've used this one with great success : https://github.com/cameron314/readerwriterqueue ; the API is trivial to use.
Does [Cling](https://github.com/root-project/cling) do what you're looking for?
First sentence: I share the sentiment, although I wouldn't use the same words. Second sentence: uhhhmmmm... no. This "amalgamation" is rather an abomination. I really do not get why anyone would want to bundle their code into a single header or translation unit in the first place. Building and installing software consisting of multiple source files (headers &amp; TUs) is extremely easy using CMake, both from a library/application writer, as well as from a consumer perspective. Catch2 already provides a CMake target, so as a user of it, I don't see any issues coming up.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ardqke/c_question_about_header_files/egmh1p3/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I extracted from that that she ment, "don't use them anymore because they mean nothing". They have no meaning for the example, where if you use "real" names for values and functions and objects then the example will make more sense of what your intentions with your example are.
Definitely be interested in the why as well.
My point is meta-level - you are interpreting this person's Unicode confusion, multiplied by their non-native English comprehension, as a personal attack on your experience. To everyone else, it looks like you're being a jerk for no reason, which undercuts the points you're trying to make. As a moderator, I am politely informing you that this is not appropriate, however correct about the object-level topic (Unicode) you may be, and that you should be more careful when replying in a pissed-off state.
We must be missing something, because I also can't see the advantage of single header file libraries. It might make things simpler if you don't have a build system, but I have *never* worked on a project that did not use a build system. At that point, adding one header is not really less work than adding one header and a source file. I use Catch, and my first step is always to create a catch.cpp with CATCH\_CONFIG\_MAIN to make it look a component.
&gt; extremely easy Like hell it is. 
swap isn't constexpr until 20 either.
[`boost::lockfree::spsc_queue`](https://www.boost.org/doc/libs/1_69_0/doc/html/boost/lockfree/spsc_queue.html)
Cool! So the infrastructure already exists and needs to be maintained. Basically what's missing then is that this is used consistently for all papers and that updates happen there! I wonder why then apparently Jens Maurer still pursues that GitHub avenue? It would only cause unnecessary fragmentation, if there's already an ISO C++ bugzilla. Should be much easier to get the remaining WG/SG's onto the isocpp bugzilla, and bugzilla has much more capabilities anyway.
I'm being serious about this. It's not that difficult. It's a solved problem. Not completely without boilerplate, but it could be much worse. The proposed alternative, screwing up the structure of the codebase, is an order of magnitude worse.
Solid points there. The python system certainly doesn't give the runtime flexibility that you can get with your system. With respect to the ability to attach arbitrary code without an adapter, how does your system facilitate that?
You created a mutex out of a mutex? I do mashups of Girl Talk songs, we should hang out.
Btw, I forgot to mention that my algorithm has been run through Relacy Race Detector many times: &amp;#x200B; [http://www.1024cores.net/home/relacy-race-detector](http://www.1024cores.net/home/relacy-race-detector) &amp;#x200B; Very nice. My algorithm works and does not use compare-and-swap. Only fetch-and-add. Take a close look at the code.
Did you even look at my algorithm?
A `.clang-format` file in the root of the repo is the way to go.
I don't understand, seems like a solved problem to me
Yeah this single header thing is very odd, don't people use s build system?
&gt; When you use a Catch-style single-header library via a package manager, you add an extra step, because you need to add another .cpp file to your project, where the implementation of the single-header library will live. Why is that? Are you sure? I would say that in that case there is no .cpp file, no .lib/.so/.a/.dll, and the install step just consists of copying the header to the package manager's install directory, and providing a CMake target that people can include. CMake supports header-only (interface-only) targets. No need to create a .cpp file just for package managers?
You should really start a Patreon page for Catch2!
Are we really doing this dude? This isn't an algorithm and you didn't invent anything, you made a wrapper around std::mutex with read and write counts. Why don't you explain what part you invented?
I invented the read/write algorithm. Take a look at struct ct\_rwmutex. Some people at Intel liked it in the past: &amp;#x200B; [https://software.intel.com/en-us/forums/intel-threading-building-blocks/topic/296471](https://software.intel.com/en-us/forums/intel-threading-building-blocks/topic/296471) (read all!) &amp;#x200B; Some of those old links are dead. So, study up on struct ct\_rwmutex. This is my read/write lock. Btw, have you even tested it against std::shared\_mutex on Windows and/or Linux at least? Have you even tried to compile it?