Boy, that was a bit of a resurrection. :P As for the extra stuff the GPL does - which depends on the version - yes, it's not really the same. However, the viral copyleft bit is the main sticking point in most cases when looking for libraries or considering what you want people to be (or not to be) able to do, so I don't think my statement is too far off the mark.
I think std::lower_bound requires a random access iterator, which a std::set does not provide.
Not only this, but `std::set` like `std::map` are tree structures so significantly better "algorithms" can bet used. Same for `std::find` and `std::set&lt;T&gt;::find` and other lookup functions: http://en.cppreference.com/w/cpp/container/set Notice that `std::set&lt;T&gt;::find` complexity is O(log(N)) whereas `std::find` is O(N).
[It does not](http://en.cppreference.com/w/cpp/algorithm/lower_bound); it requires only a forward iterator, though clearly random access would be better performing. Edit: on second thought, maybe that page is wrong. I'm not sure a forward iterator could guarantee the time bounds. I'll have to double check the standard
We designed it to be optimal and correct on each platform. On Windows, that means wide strings, because Windows uses this format internally (you want to avoid string conversions when calling Win32 APIs). On Linux, it is UTF-8, because that's the preferred format. To write cross-platform code, use the U macro for string literals and utility::string_t for expression types, as in: utility::string_t my_str = U("hello"); There is more on this on our codeplex site.
std::find is O(N), because the container does not have to be sorted. The same is not true for std::lower_bound. This is why std::lower_bound is O(log N). binary search on a random access vector needs the same number of comparisions as (if the tree is not perfectly balanced, then even less than) a search in a tree.
I don't want to use a different comparator. I am willing to implement a functor as comparator that I pass to the constructor of std::set, that has all the needed overloads. Of course it is my responsiblity, that they are all consistent, like it is my responsibility in case of std::lower_bound.
I want to specify a functor with all needed overloads, which is what I also would have to do in case of std::lower_bound. It is not the same function, but the same functor.
&gt; std::lower_bound is O(log N) This is not true. From the standard, section 25.4.3/1: &gt; [Binary Search algorithms] work on non-random access iterators minimizing the number of comparisons, which will be logarithmic for all types of iterators ... For non-random access iterators they execute a linear number of steps. `std::set` does not provide a random access iterator, so it will require a linear amount of traversals, making it O(N). `set::lower_bound` can do this in a logarithmic number of traversals, making it the better algorithm.
`std::lower_bound` requires only `ForwardIterator`s. Its complexity limits are written in terms of the number of *comparisons* it carries out. It can meet O(log N) requirements for number of comparisons, but not for the number of overall operations such as the total number of times an iterator is incremented. Just for example, if you use `std::lower_bound` on a linked list, it'll start by getting the size of the list, then walking through nodes one at a time until it gets to the middle element, so at that point it'll have done N/2 iterator increments, and 1 comparison. Then it'll choose which half of the list contains the desired element, do N/4 increments to get to the middle of that half of the list, and do one more comparison. This pattern will repeat until the correct position is found. Whether this will give a net gain over using `std::find` is open to considerably more question. It'll depend on the relative speed of traversing the list vs. comparing the (keys in) each node. If you have large keys that are slow to compare (e.g., long strings) `std::lower_bound` may be faster than `std::find`. If you have small keys that are fast to compare (e.g., `int`s), memory fetches and such to walk the linked list will probably dominate, so `std::find` will probably be faster. Also note that in the latter case, it'll depend on the CPU you're dealing with. High-end CPUs are generally a lot faster than memory, so they favor minimizing memory usage. Lower-end CPUs tend to be closer to the same speed as memory, so reducing work done by the CPU (in this case, reducing comparisons) is likely to help more.
I was comparing std::set::lower_bound to std::lower_bound on a vector (mentioned it at the top, don't want to mention it in every single comment). In that case std::lower_bound is logarithmic. See [jcoffins](http://www.reddit.com/r/cpp/comments/19gwhf/why_is_stdsetlower_bound_less_general_than/c8nyyfh) comment below.
Tagedieb, you have the patience of a saint. Every single post in this thread has missed the point, which is that std::lower_bound has been declared like this: template &lt;class ForwardIterator, class T, class Compare&gt; ForwardIterator lower_bound (ForwardIterator first, ForwardIterator last, const T&amp; val, Compare comp); Note that the type of val is independent of the type of the ForwardIterator. std::set::lower_bound has been declared like this: iterator lower_bound (const value_type&amp; val) const; What you want to do would work (assuming the rest of std::set's internals were appropriately templated) if std::set::lower_bound was declared like so: template&lt;class T&gt; iterator lower_bound (const T&amp; val) const; As for why they didn't do that, I can't say for sure, but I can think of some reasons for/against the decision in each case: - std::lower_bound must be defined the way it is if it is to be usable with pointers as iterators (i.e. cannot use the typedefed value type of iterators) - std::set most likely uses a tree structure under the hood, and templating the key type of std::set::lower_bound would likely require pretty much everything inside std::set to be templated in addition to the template key type. This would lead to absurd compiler errors when an incorrect type was actually used.
But the standard requires that `std::lower_bound` runs in log time, which means it's required to do a binary search too. So the same argument about the possibility of the functor used to order the sequence vs. the functor used to perform the binary search holds, and therefore it does not feel like a good explanation. As far as I can tell the explanation is much simpler: `std::lower_bound` has to be able to work on containers that don't have a comparison function template parameter, like `std::vector`, so it requires that the user can pass it as an argument, as that's the only way it can be overridden (and assuming that you don't want to or can't specialize `std::less`, e.g. if the ordering only applies for this special situation and not in general.) It seems like the question amounts to why `std::set::lower_bound` takes `key_type` and not any `T`. That seems to have been addressed elsewhere in the thread. 
Thanks! The basic API doc is [here](http://www.libgeodecomp.org/developers.html#api_documentation). Apparently the "documentation" tab is borked. Will fix that ASAP. But what's worse is that my site is lacking a user guide. :-/
Boost multi-container can do what you want, http://www.boost.org/doc/libs/1_53_0/libs/multi_index/doc/index.html. Specifically you want a list with fast look-up: http://www.boost.org/doc/libs/1_53_0/libs/multi_index/doc/tutorial/basics.html#list_fast_
yes, i stumbled upon this one already. didn't want to link against such a big lib as boost though.
http://c2.com/cgi/wiki?CppStaticRiddle
Multi-index is header only, nothing to link against.
Aw darn. Thanks for the link I really am glad it was answered. I'm just a little disappointed because I counted some the file private ones and class ones as their own... so I was expecting something cooler lol. Thank you!
Somebody [asked on Stack Overflow](http://stackoverflow.com/q/15165202/150634) if it was possible to generate a beta distribution in C++. Since C++11's random number generation library doesn't provide a `beta_distribution`, I thought I'd develop one myself. It's implemented in terms of two `std::gamma_distributions`. You can use it like so: std::random_device device; std::mt19937 generator(device()); sftrabbit::beta_distribution&lt;&gt; distribution(a, b); // Then generate values with: distribution(generator); If you notice any problems, please either let me know or fork the gist!
Interesting article. I liked it. Lambda expressions are neat and powerful. 
git repository is at git://git.bind10.isc.org/bind10 
Related: https://www.isc.org/wordpress/programming-languages-for-bind-10/ // Why BIND 10 had to be written in C++
When this played out on the mailing list, someone proposed the intriguing concept of a biased pair, where the first or second type can be copied or converted from the pair implicitly. While I agree with the #2 usage, I've found myself pondering that idea in other situations since. Particularly the pair of iterator, bool from associative insert methods. 
Yup. In general, simulating return type polymorphism by return a proxy type that automagically converts to other types as required, is a very useful technique.
I'm also curious in regards to the biased pair. Assuming I understand the succinct description from the article, I'm assuming we're basically talking about a "pair" that has two implicit conversions to first and second types. What happens if these were to be the same? What is returned? Is there are static_assert to ensure first &amp; second aren't of the same type?
I think the "active" implicit conversion is supposed to be chosen at compile time through a template parameter.
All after all, this is one point I love in C++ : even a trivial and obviously true statement like "there's no static constructor in C++", may be a subject of debate. ;)
As I just posted in a comment to the post the problem with `biased_pair` is that it still may break *some* code which uses `auto` since the type will be inferred to be the `biased_pair` and the casting operator will not be called. An error will then show up somewhere down the line when someone tries to use the returned value as an `OutputIterator` rather than a `biased_pair&lt;OutputIterator, InputIterator&gt;`.
Can anyone familiar with the project talk more about the Python that was used. How much does 17% of the code in Python really simplify the interfaces? 35k lines is a good size chunk though.
The idea was a pair would either have a bias for the first or second member, not both. 
You should use a number or character that the user inputs to indicate that the program should exit as the condition. Since this function is only add, if any operator other than + is used, it should return. Also, don't use strcmp to compare a single character, because single characters aren't strings.
Whoa. Didn't think of using `switch/case/break`. Why is `scanf()` bad? I used it in C, and it worked fine.
Switch statements are almost always preferable to if statements in situations like this. It's a tool you shouldn't forget about
Of course it worked fine in C. That doesn't mean you should use it in C++. Using C APIs means you can't use C++ features like `std::string` or iostreams, which have a number of advantages over the C way of doing things, such as being type-safe, not suffering from fixed-size buffers, playing nice with the rest of the standard library, and so on. In other words, C++ is not "C with cout", and treating it as such leads to very poor code, as it combines all the downsides of C with all the downsides of C++, but with none of the upsides of either.
While I'd normally agree with you... there are very valid cases where scanf performs much better than cin. scanf's format string can specify additional characters you don't want to actually read (sort of parsing out things). Example being the start and end of a memory page like read from a /proc/pid/maps file: scanf("%ld-%ld", &amp;start, %end). Of course there are many other fields to read, but the point is with cin you'd have to read in a character in the middle or a whole string and parse it out yourself. But yes... in verandaguy's case, cin is perfectly fine...
I am confused. The author seems to be mixing two different things here. His example made no sense. If you really want to compare what he is suggesting then the fact that one is a car and the other is a truck makes no difference. You do not compare their type as that does not matter. You compare their serial numbers. The example does not make sense in the first place, but I will indulge. Convert the two serial numbers to a common standard. Moreover, if you are planning on comparing values that are not in the same standard then you are going to have bad time. Comparing something in euros to something in dollars does not make sense unless you convert it to a common format. I am perplexed as to why this is even a debate. Comparison is situational and should be performed on things which are in the same format. Maybe I am missing something.
1. This is totally not the right place for a CMake question. 2. CMake regex doesn't support `.*?`; also, nothing wrong with just (.*?) in your case. 3. What you really, actually want is SET(CMAKE_DEBUG_POSTFIX "d") 4. http://www.lmgtfy.com/?q=cmake+debug+suffix
Thanks for replying! Cmake_debug_suffix seems to be only for DLL that you are building not for 3rdparty(already tried, didn't work). Could you point me in the right direction on where to ask the question.
Ok, I would personally still skip the regex, and do this with a for loop, something like foreach(library library1 library2 library3) target_link_libraries(target debug "${library}d" optimized "${library}") endforeach() BTW, you don't mean dll; you don't link a dll, you link a lib file which might later load a dll. The right place to post something like this would probably be the cmake mailing list, or stackoverflow, or some other place like that.
Thank you very much. Have an upvote. I wish I could find a nice source of information where I can read about type traits and templates.
I will explore that, thank you
Try SET_TARGET_PROPERTIES(TargetName PROPERTIES DEBUG_POSTFIX "d") instead - I wrestled with this a while ago, and I seem to recall that the global variable didn't work as expected but explicitly setting the postfix on each target did. 
Thanks for the reply however the problem is not with the target but with 3rdparty libraries linking
Here's what I ended up using, special thanks to [LeszekSwirski](http://www.reddit.com/user/LeszekSwirski). function(target_link_libraries_debug_release MODULE_BEING_BUILT LIBRARIES_TO_LINK ) foreach (l ${LIBRARIES_TO_LINK}) target_link_libraries (${MODULE_BEING_BUILT} debug ${l}${DEBUG_SUFFIX} optimized ${l} general ${l} ) endforeach(l) endfunction()
Generally, I have found that when I have an abstract base class with one pure virtual function, I can replace it with `std::function`. Not only is it simpler, but when combine with `std::bind`, it gives more powerful composability that you don't have with just objects. For example, state that needs to be passed into an object, now can be passed in as parameters to the function. It much easier to add parameters to a function, that members to a class, since a constructor must be written. With functions `std::bind` works as the constructor. &gt; The amazing thing is that calling a std::function is fairly cheap: It’s one virtual function call. Although, its easy to understand type erasure through using a virtual function, generally `std::function` is not implemented like so, since it is slower. Most are implemented using the way it was done in boost, which found a function pointer to be faster. See [Combatting virtual function "bloat"](http://www.boost.org/doc/libs/1_53_0/doc/html/function/misc.html#idp59643600).
A great example of this style of programming that predates C++11 is Boost's Asio. No dodgy Java-esk deriving from an interface and that sort of garbage.
still blows my mind, the infinite amount of detail in these fractals. where is that information? where does it live? where did it come from?
beware that it's difficult to see the contents of the multi_index_container from the (visual studio) debugger...
If performance is the issue, you should only care about it after you measure it anyway, Basically, _allways think of iostreams, adjust afterwards if necessary_; In most cases, it is not necessary to switch from iostreams to something else (because reading your inputs is not where your performance bottlenecks are), and when you _do_ need something better than iostreams, scanf should be your last choice because it introduces more problems in your code base than it solves. scanf requires that you match your input variables to your format string; When the variables are declared far away in your code base, such things are difficult to spot and track (especially with long-term maintenance). When you do not match them correctly, the resulting errors are only partially trackable by the compiler. For example, modern compilers will match your format string to the number of variables you use, but the fact that they have to parse the value of your parameters at compilation time, is already a sign of a bad interface. The problems left in code (the ones that the compiler doesn't spot for you) are usually buffers filled with garbage or buffer overflows that you (or your clients) will discover sometimes later. scanf also does not support custom types and exceptions. These two usually are enough for me to not think about using scanf at all. While you _can_ check the result of the scanf operation explicitly, I've only seen one large project that did so routinely (and it was a C project). Unless you do that (check for the return value explicitly), for all intents and purposes, scanf fails silently.
Very cute, I like it! 
AFAIK, they're very similar if not the same.
Just did some testing [on my own](https://gist.github.com/anonymous/f51ba03e0da70c149286), and I found that std::function is about 33% slower than a virtual function call (in g++ 4.7.2 -O3). That's not nearly enough to be a killer (for normal usage) on anything but embedded platforms. **tl;dr You can use std::function without worrying about performance.** (or at least without any more worry than a virtual function)
Firstly I'd like to say I wasn't thinking about performance. You are correct, it's almost never good to switch between them in most C++ applications. Now, scanf doesn't actually introduce errors into the code base. There are four things to check for when using scanf: 1. Are you using a buffer? Yes? then go shoot yourself and reconsider. Buffer overflows are a real risk with scanf and reading any sort of string with it is discouraged. 2. ALWAYS check the return value. scanf returns the number of arguments successfully read. If it's not the expected, then that's the failure case. As a note, reading an integer with int scanf("%d", &amp;i); if the input is a character and not a numeral, scanf will return 0. So it wont just fail _completely_ silently if it the wrong input is given to it. 3. If you need a non POD type, scanf is not for you. 4. If you use a non-constant format string you're as bad as the glibc (f)stat implementation and shouldn't be using scanf. (note: glibc's (f)stat implementation uses non-literal format strings for the printf outputs) gcc (and by extension g++) do check literal format strings for the types and number of arguments. You will get warnings if your argument types are inconsistent (-Wall required). scanf is a C function so you have to be aware of that when used. Since it's a C function you have to do all sorts of somewhat annoying things to cover failure cases, that's just how C goes. If you need to use it, think if it's really necessary first. It usually isn't. The only point I was trying to make is that there are valid cases where scanf is useful; so saying to never use scanf in a C++ program is wrong.
First Reaction: Oh so a list of Action&lt;T&gt; or Func&lt;T&gt; from C#. OK, nice to see more cool stuff like that in C++. Second Reaction: This feels like coupling. Third Reaction: Ok this is just another way to define an interface except that you lose typing. Instead it is a sort of implicit interface.
&gt; It is wrong to think in terms of interfaces though. Internally, it is a class, yes. This is totally irrelevant on the outside. The great thing about this is that you do not need an explicit interface definition. No ugly kludge like a "Callable" interface or something similar is necessary. It is absolutely great for callbacks, since I can use existing functions and objects directly with it, and do not have to wrap it in some interface implementation. And with asynchronous programming like in boost.asio (which is based on the Proactor pattern, the multithreaded variant of the Reactor pattern), you are using callbacks all the time. From the example given, there is a sort of interface defined. You need a method on a class (or constructor in this case) that knows to attach itself to a passed in container. The passing in of the container for attachment is the interface. 
Using this is just asking for trouble. If the lock succeeds, it tells you nothing about whether the object is usable. The object could die a smidgeon of a nanosecond after the lock succeeds; or, the object could be long gone, and all that's left are dangling locked versions.
Is GCC inlining or doing conditional inlining the virtual function? 
Agreed. This is worse than useless, it is dangerous. Never do this.
At least it was an interesting exercise for me. I'll add prominent warning to the post.
I found a similar thing, the performance hit does not really matter for most things, but it's an absolute killer for high performance applications.
This is because libstdc++ in 4.7 _always_ does a heap allocation for std::function. Both libc++ and MS's impl do the small size optimization, meaning you don't get an alloc for small (sizeof(void*) * 3). Also, gcc doesn't seem able to inline through std::function due to the alloc.
In such applications though, virtuals alone (whether internal to `std::function` or as a virtual member function) are killers so that's no real loss then.
Very interesting, I don't have access to libc++ (easily), would you be able to run /u/jasonthe test program?
I think that's missing the point. The way he did it by having structs add themselves via the constructor was just an example of the idea he was showing, which was one way of updating several different objects generically. The usual method, is to have a Base class pointer and each object implements the same function differently. This way, you no longer need objects. You can now just add and remove chunks of logic that needs to happen during the update loop w/o restricting yourself to one bloated type. So yea, you are doing the same thing as before in another way, but you're also allowing for many more things as well. You gain a bunch of flexibility this way.
Performance is an issue in debug mode though. The same author provides an alternative implementation of std::function that is faster than all other implementations he tested. http://www.reddit.com/r/cpp/19rn4v
Interesting! I love the direct-call trick. That said, people are too scared of virtual function calls. Branch predictors on modern CPUs actually do recognise indirect function calls, and while cache misses are a concern, they only really matter in very tight loops. 
[A small post about the Casablanca project](http://www.viva64.com/en/b/0189/) This is a good code written in a contemporary style employing capabilities of C++11. We have checked it using our static code analyzer PVS-Studio and failed to find at least one significant bug. Our respect to the Microsoft developers who have created this library!
And you are going to push your innovations into libstdc++ now. Right...?
Note that I am not the author of this article, but here you go, I filed two bugs: http://llvm.org/bugs/show_bug.cgi?id=15456 and http://gcc.gnu.org/bugzilla/show_bug.cgi?id=56551
I was wondering this, this is clearly a quality of implementation issue and if this is legitimately better implementation of `std::function` then it would be cool to offer it too stdlibc++.
Sure although that appears to be a quality of implementation issue. It seems that libc++ and MSVC do not allocate (in most cases). Not that this detracts from your issue, I agree. If I were you I would keep an eye on how libstdc++ progresses, maybe it will be feasible at some point.
How does this compare with boost's implementation?
&gt; w/o restricting yourself to one bloated type. This seems like a large assumption. My preference would be for multiple small interfaces, avoiding his "single large base class" problem. I just don't see how this is any more flexible than implementing an interface (which is a nice explicit tag on the object's type). I'll grant that it may end up being less code and less .h file messiness though. :) But that is caving in to a language issue! Edit: I can see if I am trying to avoid using an OO paradigm in a project, then this is a nice alternative that gives me the same capability for solving this particular problem.
Hmmm maybe I should have called it "Living without inheritance based polymorphism" 
I think your reactions grew less accurate as time went on. :) &gt; First Reaction: Oh so a list of Action&lt;T&gt; or Func&lt;T&gt; from C#. OK, nice to see more cool stuff like that in C++. C++'s std:function is very similar to Func or Action in C#, though C++ has had it for far longer than C# ([2001 for boost's version](http://www.boost.org/users/history/version_1_23_0.html) and 2003 for tr1, whereas C# didn't add Action until 2005 and Func until 2010). &gt; Second Reaction: This feels like coupling. It is far less coupling than with an interface. Enforcing that a particular interface is used demands that the implementer conforms not just to a function signature, but also to a a particular function name, a particular base class or interface, a particular memory layout, a particular calling convention, and a particular library to provide the interface definition. A std::function only depends on a function signature, and all the other differences can be abstracted away. Moreover, it doesn't matter whether it is a member function, a static function, a free function, a function object, another std::function, a boost::function, a (std::/boost::)bind expression, or anything else that might work, just as long as the signatures match. &gt; Third Reaction: Ok this is just another way to define an interface except that you lose typing. Instead it is a sort of implicit interface. I suppose it is a sort of "interface", though not in the C#/Java sense. I wouldn't say you lose typing, rather you minimalize the type requirements clients need to conform to. There are times where you want to explicitly require clients to implement a particular base class or interface, especially when you want objects with a particular bundle of functionality and not just one method (e.g. manipulating a stream with seek, read and write, etc), but there are times when you just want a single function and don't care where it comes from (e.g. C++ std::remove_if or C# Enumerable.Where).
A comparison is extremely cheap. I don't think the `operator bool` optimization will be worth it, but the rest looks good.
Does this class store lambdas? If so, how did you get around the explicitly deleted copy constructor? It seems you're using in-place copy constructors.
Lambdas are copyable.
Hmm, seems my memory is wrong, they're not copy *assignable*: http://en.cppreference.com/w/cpp/language/lambda 
I guess they can't be, because they might contain references.
Used extensively at Twitter: http://www.wired.com/wiredenterprise/2013/03/google-borg-twitter-mesos/
Here is my attempt to create a C++ code browser: https://github.com/woboq/woboq_codebrowser Demo: http://code.woboq.org 
Your server just spits out the content without any HTTP response headers, like "200 OK" or "Content-Type: text/html". Technically speaking, that's a valid HTTP/0.9 response, but not valid HTTP/1.0 or HTTP/1.1. The number of browsers out there that still support HTTP/0.9 is dwindling. Firefox displays the response as plain text without interpreting the markup, for example. You couldn't have tested this very well if you didn't notice this. There's basically no justifiable reason to be writing software that speaks HTTP/0.9 in 2013. (There would have been no justifiable reason a decade ago either.) 
The demo server at: http://vader.co:8080/Box2D/ isn't working.
Yes, i'm using the clang library
Firstly, this is good, I like how seemless it is with the standard you could probably drop this into generic code no problem. (unlike Qt style code). I also like you style (underscores for most things, CamelCase for compile time entities). Out of interest (and I don't really know anything about beta distribution) but how come you defaults in the constructor are like so: explicit beta_distribution(RealType a = 2.0, RealType b = 2.0) whereas say `std::uniform_real_distribution` has: explicit uniform_real_distribution(RealType a = 0.0, RealType b = 1.0 ); Finally does this work for interger types too, or just floating point numbers?
Honestly, I don't get it. Comparing two numbers, either of which may be either integer or floating-point, may come up in duck-typed languages, but it pretty much never comes up in C++. And if it did, it would not be in a situation where you cared about the 24th bit of precision. Can anyone give a realistic scenario where just straight-up comparison is not good enough?
The motivating example was from several articles previous, where the topic was ordering a collection of polymorphic objects, which was part of a yet prior discussion about the strict weak ordering requirement imposed on you by the standard library whenever writing comparison functions. Even if you think you don't care about the 24th bit of precision, you set yourself up for very strange and hard to debug problems if you violate the requirements laid out in the standard when using the library.
Funny story, I got curious once about how those game server widgets worked (the ones that tell you who's playing on your server). I started sending manual requests to the URL through netcat so I could look at the headers and such. I found out that if I omitted the "HTTP/1.0" in the first line the request became an HTTP 0.9 request, and that for HTTP 0.9 requests the server somehow sent the source code of the page rather than executing it. That was how I found out that the service was basically just a frontend for qstat, which is open source.
If you don't care about the 53rd bit of precision you can just use `double(X) &lt; double(Y)` for the compare function and `double(X) == double(Y)` for the equivalence function.
I have found the freelan project's [libcryptoplus](https://github.com/freelan-developers/libcryptoplus) to be the best OpenSSL wrapper for C++ that I have used. But good to see fundamentals being covered. 
No, you can't, because that would not implement a strict weak ordering and it would invoke undefined behavior when used with the standard library. 
I don't see how it wouldn't be a [strict weak ordering](http://www.sgi.com/tech/stl/StrictWeakOrdering.html). As far as I can tell, it satisfies irreflexivity, antisymmetry, transitivity, and transitivity of equivalence. Care to give a counterexample? EDIT: I know you have to handle NaNs specially, if your data can be NaN. That wasn't addressed in the article, anyway, though.
This is clearly addressed in the article under discussion: &gt; To make this discussion concrete, consider the floating-point format usually used for the float type these days. The fraction in this format has 24 significant bits, which means that N can be converted to floating-point only when |N| &lt; 224. For larger integers, the conversion will lose one or more bits. So, for example, 224 and 224+1 might convert to the same floating-point number, or perhaps 224+1 and 224+2 might do so, depending on how the machine handles rounding. Either of these possibilities implies that there are values of N and X such that N == X, N+1 == X, and (of course) N &lt; N+1. Such behavior clearly violates the conditions for C++ comparison operators. 
This is very awesome.
No my compare function doesn't have that problem because it doesn't assume N &lt; N+1. If two integers cast to the same double they're treated as equivalent.
What am I missing here? Isn't LLVM already a compiler for shared-memory computers?
*autoparallelizing*
I misinterpreted your comment and thought you were proposing to do that only when X and Y were mixed types, not when they were both integers. If you do that unconditionally (and handle NaNs separately, which was the topic of the previous week's article) then yes you do get a proper order relation. Still, that introduces a rather crazy side effect that distinct integers compare equal in some cases but not in others, and that a sorted list of integers might not actually be sorted in the traditional sense, i.e. this would be considered sorted: ... 9007199254740991 9007199254740993 9007199254740992 9007199254740995 9007199254740994 9007199254740996 ... 
What's going on with censorship on this site (http://www.drdobbs.com/cpp)? Relatively moderate comments are being deleted all the time. It seems as if the editor in chief sees the comment section as something he can model like clay. Anybody else seing the same?
Thanks [20c8e4399c](http://www.reddit.com/user/20c8e4399c), for the [help](http://www.reddit.com/r/MUWs/comments/19zeqf/request_rcpp/) :-) 
"We think the quit-recompile-restart-reload cycle we're all used to could soon be a thing of the past." ...
Probably off-topic, but could you tell us a little bit more about the game you're developing? Maybe a little bit about the use cases of RCC++ in your own project? 
We're not yet ready to talk about the game yet, since we're in the tech development stage so don't really have that much to share. But RCC++ has been really helpful. One feature I didn't plan to be so useful is fixing bugs. I can switch the compilation from optimized to debug, follow the code through, and make changes on the fly to narrow the problem down. For example cutting out functionality to see if it's part of the problem, or putting in conditional checks which are easier and faster than with the debugger.
Another plus is that I no longer need lots of data driven development parameters, as I can change 'hard coded' parameters on the fly.
Is there a hello world example for RCC++?
There's a ConsoleExample project, which is roughly equivalent to a hello world style program. It repeatedly prints out a string every second, allowing you to modify it on the fly. See here: https://github.com/RuntimeCompiledCPlusPlus/RuntimeCompiledCPlusPlus/tree/master/Aurora/Examples/ConsoleExample 
* Don't use global, but more local variables. (No need to have the numbers / operation stored outside of main()). * Switch for the s/t/c as well. * Don't use gotos. * Use else { if() {} } or else if() {}. Your code only really works because of the return 0;s. * Try not to use using namespace *, and if, then only on limited scope. With increasing complexity, knowing what namespace your symbols come from may help readability. * Improve formatting. * Instead of ans, you may want to use std::cout &lt;&lt; "The addition is: " &lt;&lt; (a + b) &lt;&lt; std::endl; * You may want to use "\n" instead of std::endl. (endl triggers a flush, thus might be lower performance, if you write a lot.)
Thanks! why not use gotos? how would i improve formatting?
you should submit this to the standard, contact them about C++14
Goto is almost universally regarded as something to be weary of. There are more manageable ways to do what goto does.
Thanks for the response! It defaults to `2.0` for both parameters because I seemed to find that that was a pretty common example beta distribution with a nice symmetrical shape. Admittedly, I didn't do much research on this though. It'll only work for floating point types simply because the beta distribution is continuous. The range of its output is always [0,1].
The standard really only specifies how the random number distributions behave - it doesn't give an implementation. I could suggest that it be added and be defined in terms of `std::gamma_distribution`, but I don't think I'm the person who should be writing up the proposal!
Goto is incredibly useful for a handful of situations, such as labelled breaks and error handling in C, but is really easy to abuse. If you don't have a very good reason to use goto, then don't use it.
Perfect opportunity to plug my [QuickCheck clone for C++](https://github.com/thejohnfreeman/autocheck)!
&gt; It's certainly led to a significant reduction in needing to quit the game to compile changes Also known as [Edit and Continue](http://msdn.microsoft.com/en-us/library/esaeyddf%28v=vs.80%29.aspx), which is part of Visual Studio for a long while now.
such as?
Because improved support for template metaprogramming is not the goal of the proposal. __is_valid_expr is an intermediate step to a better mechanism for expressing syntactic requirements, but such an extension would make the proposal a little less "lite" -- more for people to disagree on.
You are mistaken. The "requires" clause is not documentation. It is evaluated at compile time to determine if a declaration can be used with the deduced or supplied template arguments. Furthermore, those requirements are actually compared during overload resolution in order to choose the most specialized template. The proposal does not include a means of specifying requirements. The __is_valid_expr feature is a part of the implementation, but not the actual proposal. Your preferred syntax may yet return in the future. 
fucking shit fuck, that should help.
Apple had something like this not too long ago, but it was considered broken and not recommended by some experienced devs.
The short answer is that gotos create bad coding style in C-style languages *most* of the time. Not all of the time, but most of it. As such, gotos are something that you probably want to lay aside for the next several months, then revisit after you've got the basic groove / understanding of C++ under your belt. The long answer is that they are still useful, and in some instances, the right choice, which is why the language has them (were they purely useless / dangerous, they would have been dropped by now, right?). Some people, I guess Assembly people, will want to use them, because they have used a language which already uses them (well, the JMP instruction), and as such, it's familiar to them, and in some ways, comforting. With C++, like any language, machine or human, or whatever, you need to adapt to 'how' its spoken; whether what you are speaking is syntactically or grammatically correct matters little if the person / machine you are conversing with is not really used to that pattern of language (in this case, I guess the compiler would be doing the interpretation, and as using a lot of gotos would probably prevent the compiler from using some nice optimizations...you'd be doing yourself a disservice). Think of it as speaking Shakespearean English to someone from modern England -&gt; they'll ultimately understand you, but it will probably be a very painful experience for them, and possibly you. 
Allright, who keep saying "peg"? 
Absolutely. Our primary goal was to make iteration faster in game development without programmers having to use scripting languages (they're still useful for designers). This has been a significant issue on previous projects we've worked on. Much more information on the slides here: https://dl.dropbox.com/u/9619385/RCCpp_Slides_Develop2012.pdf For another example I've added graphics code on the fly, changing the C++ code as well as shaders. Basically if there's anything you can code, and you need iterative feedback to get perfect, this technique is really helpful. For an idea of the scope of changes you can make, check out the example video in [this post](http://runtimecompiledcplusplus.blogspot.com/2012/06/new-feature-include-file-tracking.html). Note that's a simple demo game, not the one I'm working on!
You're dealing with what is known as flow control. You can write your program as a single block of code, wrapped inside a main function, or you can break it into a series of functions, subfunctions, classes, structures, and so on. The former can be achieved using purely gotos, while the latter is what 99% of the programming world strives for. Anyone writing a 3,000,000 line C++ program using only gotos for flow control is either doing something extremely stupid, incredibly dangerous, or absolutely brilliant. Or possibly a mix of the three. As such, in the first case, the person should have anything more dangerous than string removed from their immediate person; in the second case, the MIB should be contacted; in the third case, well....it's almost never the third case. 
Compiling and loading code at runtime certainly isn't new, but what we're trying to do is develop a permissive open source portable and standard C++ solution which makes it easy to use. [Cling](http://root.cern.ch/drupal/content/cling) is another similar project, but it uses compiler changes to LLVM so you need to use that compiler, whereas our solution requires only small changes to get it working with any compiler (currently supporting Visual Studio, gcc, clang/llvm).
Damn it, who let Michael McDonald on /r/cpp?
a=0, a=1, a=2, b=0, b=1, b=2, c=0, c=1, c=2, n=0, n=1, n=2
So it's pretty similar to what Unreal Engine 4 has? If so, then wow, that's great. Watch the last minute of http://www.youtube.com/watch?v=MOvfn1p92_8
Do you have a reference, or name to help search for some info? Thanks in advance! 
looks very nice, i'm a big MPI and Hypertable user, do you know if theres been any word on HPX support or will I have to request and beg for that?
Malloc? Really? I didn't know we got that many C questions in here.
I was like, "function, c++11, code, ... no surprises here.. wait, c=2? really?"
"Fix and Continue" http://www.digitalenginesoftware.com/blog/archives/49-Xcode-and-Fix-and-Continue.html 
Shame that this is no longer supported in Xcode 4. However I did find [Injection for Xcode](http://injectionforxcode.com/), though this seems to be Objective-C only. It's interesting, and I may take a look at it at some point to see how it compares.
I am not a great fan of the concept, because of the general complexity of the whole system. It is mentally more appealing to me to run from a more traditional cycle that has certain operational knowns. 
I think I know what you mean, though I'm guessing it depends on context. Iteration speed is certainly considered to be important in games development (particularly for gameplay, AI, and UI), but it's likely not a concern for kernel programming for example.
I'm very excited for the project. Will it be OpenSource? Or atleast free for freelancers and small group of programmers? Will Cling help your project?
Iteration is certainly important, but more often I have found that when something is wrong it is some logic error that brings the whole system into an inconsistent state – which would not be saved by fixing some code.
I'm really surprised i=0 isn't in there. 
It's already open source, under a permissive license (zlib), code is available on [GitHub](https://github.com/RuntimeCompiledCPlusPlus/RuntimeCompiledCPlusPlus). Cling is indeed interesting, but we're trying to support multiple compilers so it's not directly useful.
Another valid use of goto is to get out of deeply nested for loops.
This is consistent, yes, but doesn't actually sort the data - nor does it solve the problem we're discussing. In fact, you seem to be missing the whole point of the article. Clearly if you cast all the numbers to integers, or all to float (as you are doing), then sorting is no problem. You can sort any finite subset of the integers, or you can sort any finite subset of the set of floating point numbers. But what about sets that contain both floating point numbers and integers? Your solution - cast everything to a float - is incorrect because it maps multiple distinct integers onto a single floating point value in some cases, and those integers do not get correctly sorted as a result. The problem is not "come up with a way to run the sort program on ints and floats so you don't get any errors". It's "sort a set of integers and floats _consistent with their real ordering_." Because your proposed solution uses a many-to-one mapping, it cannot possibly solve the problem. As Rhomboid [points out](http://www.reddit.com/r/cpp/comments/19wln6/comparing_an_integer_with_a_floatingpoint_number/c8sftwo), it's likely you'll actually get values appearing out of order if you do so. 
http://gcc.gnu.org/projects/cxx0x.html has all the features implemented in GCC, which seems like a good place to start -- it'd be hard to apply something if you can't actually use it. I did not know that gcc had support for template aliasing already, wow. 
I will give this a try.
&gt; Like I said in my first post, these are not realistic requirements. First, this is an article about the theory of programming. He poses an interesting problem - "how to sort items that might be either integers or floating point numbers." The answer isn't obvious and tells us quite a bit about floating point and about integers. So it's irrelevant whether this is "realistic" - it's instructional. But the fact is that this is realistic. This happens all the time... &gt; Any time you do have a heterogenous data set, my solution is actually what you want. Absolutely not so. The instant counter-example is the C++ code for the Python interpreter. Python has both int and float as primitive object classes and can intercompare them and sort containers containing mixed floats and ints. If Python used your strategy, it would fail to correctly sort some sets of integers. This would simply be wrong. While I'm not familiar with the actual code, I'm sure another example would be any symbolic algebra system - same issues as Python. Or look at my personal work. In my commercial codebase, I have DSP code that reads lots of different sorts of audio files and plays them out through a consistent interface. It turns out that there are all sorts of file formats where each sample can be e.g. 32-bit integer OR 32-bit float, depending on a flag in the header. While I don't sort the samples, I do all sorts of comparisons, or things that are mathematically similar to comparisons. I've had all sorts of troubles, and I've had to be very careful, by being a little wrong. The result isn't a gross error - the result is small artefacts in certain situations. What's happening is that you're doing waveform calculations tens of thousands of times a second, and you pass through a huge number of cases of values, and if you're occasionally a little wrong and that error is somehow correlated to the signal, the music, then you hear problems - "problems that people complain about and it needs to be fixed" sort of problems (in my case, some very loud/compressed music had a lot of extremely high fixed point values both plus and minus and the little calculation errors popped right out!)
I want to jump up from the bottom of a long discussion and say, "Well, there's your problem right there." Ints have many purposes and one of them is IDs - essentially random bit strings used to identify some software item. For such ints, you most certainly want all 64 bits of precision. If you're sorting your ID table so that you can use a binary search on it, you're going to be one sad cookie when some of those IDs turn out to be out of order... and the worst is that this might happen only quite rarely...
What you have just asked does not make any sense. Can you elaborate?
Compile it. But it doesn't generally make sense to submit object files, better check with the teacher. Perhaps he just meant the binary.
When the compiler builds a binary from source, the intermediate representation is object code. It's a blob of information that allows a compiler to include a library without the original source code (.cpp). These are *.o files in the source directory tree. Also, include your headers. Header + object = linkable into binary. [Would you like to know more?](http://stackoverflow.com/questions/3045603/what-does-an-object-file-contain)
How does this work exactly? from what I can understand from the presentation, it makes each class a dll, and reloads this dll if it changes. Am I missing something? 
When compiled normally, the source code is compiled into whatever output you choose - an exe, static library or dll. For the example projects all runtime modifiable code is compiled into the exe. When source code changes are made, the minimally required source is compiled and linked with minimal dependencies into a dll, which is then loaded, and the old objects are serialized to memory then back into the new ones.
Okay, good point, it makes sense you would have to handle this situation if you're writing the compiler for a scripting function. In that case your containers (eg python float and long types) are so ridiculously generic you can't reason at all about what's in them. But if you're working with audio data this shouldn't come up. Your code may need to be able to handle floating point and integer types, but not mixed together. For instance, if I copy a clip out of one track and paste it into another track, surely you would convert it to a common type, right?
This is a good example of when enable_if should **not** be used. Instead, tag dispatch should be used. Additionally, if choice&lt;N&gt; was necessary, it should derive from choice&lt;N - 1&gt; and terminate at choice&lt;0&gt;, in order to avoid arbitrary limits.
&gt; You will never have a situation where... Never say never. Trust me, just don't.
Thanks for the feedback! I specifically said "let's pick a silly example" at the beginning. I needed one that allowed me to easily create different overloads that are to be restricted, and fizzbuzz just sprang to mind. There are obviously many other ways to solve fizzbuzz, and I readily admit that this example is a rather poor way. :) If you have a better example in mind, please let me know. Thanks very much for your 'choice' advice though, I hadn't consider that option for some reason. You'd have to reverse the way you number the overloads, so I guess I'd rename it to 'score'. One drawback, though, is that I now wouldn't be able to provide a blanket 'select_overload' anymore, without introducing another arbitary limit. (Or atleast, I can't immediately think of a way to provide one.) This effectively means that the "user" has to specify his own arbitary limit (or just the highest score) when calling into the overload set. (Also, hi STL!)
Yep. There's G++ for it, and clang, both of which are C++ compilers. You can also just download and install XCode, which is perfectly capable of C++.
I'm learning with Visual Studio 2010 at school is this similar? What about submitting assignments? Any differences?
C++ has a standard library which is meant to be compatible on compilers for both Unix and Windows. Aside from some quirks you should be able to run the same code on Visual Studio and XCode and have it run the same. It's only when you start getting more complicated; linking against DLLs and libraries etc. will you have to look at more than just copying source files between machines. I personally like CMake, it should have what you need for managing projects between Visual Studio and GCC.
Xcode, a free download from the Mac App store, supports C++ without you having to add anything additional.
&gt; I specifically said "let's pick a silly example" at the beginning. Artificial/silly examples are usually fine (although realistic examples are better when they don't introduce too much length/complexity). What I object to are techniques that are used inappropriately. enable_if is very powerful, but also very dangerous. It is tempting to overuse, so if you explain enable_if to somebody without explaining when it is and isn't appropriate to use, they're likely to go crazy with using it everywhere. &gt; I needed one that allowed me to easily create different overloads that are to be restricted, and fizzbuzz just sprang to mind. fizzbuzz involves switching on the properties of integers. That calls for tag dispatch, not enable_if: C:\Temp\gcc&gt;type meow.cpp #include &lt;iostream&gt; #include &lt;type_traits&gt; using namespace std; template &lt;int N&gt; void help(integral_constant&lt;int, N&gt;, false_type, false_type) { cout &lt;&lt; N &lt;&lt; endl; } template &lt;int N&gt; void help(integral_constant&lt;int, N&gt;, true_type, false_type) { cout &lt;&lt; N &lt;&lt; " fizz" &lt;&lt; endl; } template &lt;int N&gt; void help(integral_constant&lt;int, N&gt;, false_type, true_type) { cout &lt;&lt; N &lt;&lt; " buzz" &lt;&lt; endl; } template &lt;int N&gt; void help(integral_constant&lt;int, N&gt;, true_type, true_type) { cout &lt;&lt; N &lt;&lt; " fizzbuzz" &lt;&lt; endl; } void print(integral_constant&lt;int, 0&gt;) { } template &lt;int N&gt; void print(integral_constant&lt;int, N&gt; n) { print(integral_constant&lt;int, N - 1&gt;()); help(n, integral_constant&lt;bool, N % 3 == 0&gt;(), integral_constant&lt;bool, N % 5 == 0&gt;()); } int main() { print(integral_constant&lt;int, 20&gt;()); } C:\Temp\gcc&gt;g++ -Wall -Wextra meow.cpp -o meow.exe &amp;&amp; meow 1 2 3 fizz 4 5 buzz 6 fizz 7 8 9 fizz 10 buzz 11 12 fizz 13 14 15 fizzbuzz 16 17 18 fizz 19 20 buzz This simple/artificial/silly example illustrates a surprisingly deep principle. Observe that with tag dispatch, I'm not "beating overload resolution into submission". I'm actually getting it to do all of my work for me, using the rules of the language as they were designed. In contrast, using enable_if is equivalent to telling the compiler that you know how to perform overload resolution better than it does. &gt; If you have a better example in mind, please let me know. The most compelling examples for enable_if that I'm aware of are the realistic ones: constraining converting constructors, especially pair's and shared_ptr's. The overload set I use as an example is meow(const pair&lt;int, int&gt;&amp;) and meow(const pair&lt;string, string&gt;&amp;) called with pair&lt;const char *, const char *&gt; (such as returned by make_pair("foo", "bar")). That was ambiguous in C++03, but it works in C++11. &gt; This effectively means that the "user" has to specify his own arbitary limit (or just the highest score) Yeah, it has to be the maximum of that set. &gt; (Also, hi STL!) Thought I recognized your name :-&gt;
I use a Mac for C and C++ programming. Personally, I use the Xcode command-line tools (which can be downloaded from the Apple developer website separately from Xcode if needed) and a precompiled version of gcc-4.7 from [here](https://github.com/sol-prog/gcc-4.7-binary). The newer version of gcc gives you some c++11 support which is good if you want to learn the new standard while the command-line tools, which also include gcc 4.2, give you the standard library headers that you'll need to do anything useful (not included in the precompiled 4.7 package). There are a few IDE's available which will get you similar functionality to Visual Studio however I've personally found it much more useful using a programmer's text editor and learning to write Makefiles. Sublime Text 2 is an awesome editor with syntax highlighting and basic autocomplete plus you can extend it with plugins for more advanced IDE-like behaviour.
Excellent idea with choice&lt;N&gt; (though I'd call it priority&lt;N&gt;). What I suggest, though, is increasing clarity by removing---or at least condensing to a minimum---the sections using standard conversion sequences. In the end, choice&lt;N&gt; is the vastly more elegant solution, but it gets buried in the previous presentation of getting to 4, 8 and 13 overloads.
I mainly wanted to express my thought process in those parts, and I can understand if it's a bit too abstract with the talk about implicit conversion sequences. I'll see if I can clarify / tone down that part a bit. The thing is, me realizing that I can use the derived-to-base conversion to generalize 'choice' to an arbitary amount only came through those previous tries and thinking how to exploit the subparts of a UCS, so I can't easily remove / modify them. (Also, 'priority' might be a good name, thanks.)
&gt; fizzbuzz involves switching on the properties of integers. That calls for tag dispatch, not enable_if: It does seem like the example draws way more attention than I intended for it to do. The premise of my post was that you already have an overload set that is (partially) restricted, with potentially overlapping conditions. I didn't mean to give the fizzbuzz example any meaning. I will try and see that I replace the example with something less distracting / more fitting. Maybe querying a capability (potentially with expression SFINAE). &gt; Observe that with tag dispatch, I'm not "beating overload resolution into submission" I'm all for going with tag dispatch where it is a better fit, and as I said, there are many ways to solve fizzbuzz at compile-time - tag dispatch was one thing that immediately sprang to mind as a more fitting way. The thing is, when you *have* a restricted overload set with overlapping conditions and two or more functions being equally valid (i.e., an ambiguity), you have two options to disambiguate them (AFAICT): constrain all overloads even more, potentially with the inverse of the other restrictions, or do something like 'choice'/'priority'/'score'. &gt; constraining converting constructors, especially pair's and shared_ptr's. Ah, but the thing here is that you only have one function template yourself, the ambiguity comes from a "higher level", where the type is being used. That doesn't lend itself very well to 'choice', is what I think. &gt; Thought I recognized your name :-&gt; Heh. While I have the chance to "chat" with you... any sneak-peek on the next Core C++ video? :)
This is a pretty cool idea. Im instead working on a functional library where I can define the function something like this: // A helper function to convert integral constants to values template&lt;class T&gt; typename T::type as_value(T) { return T::value; } $(function(print_fizzbuzz)(N) if (is_multiple_of&lt;N::value, 3&gt;)(std::cout &lt;&lt; "fizz\n") else if (is_multiple_of&lt;N::value, 5&gt;)(std::cout &lt;&lt; "buzz\n") else (std::cout &lt;&lt; as_value(N) &lt;&lt; "\n") ) Instead of being passed in as a parameter to the template, its passed in as parameter to the function. print_fizzbuzz(boost::mpl::int_&lt;3&gt;()); Without using all the macro jazz, I can define them all as function objects as well: // Requires macro for functions #define ERROR_PARENTHESIS_MUST_BE_PLACED_AROUND_THE_RETURN_TYPE(...) __VA_ARGS__&gt;::type #define FUNCTION_REQUIRES(...) typename boost::enable_if&lt;boost::mpl::and_&lt;__VA_ARGS__, boost::mpl::bool_&lt;true&gt; &gt;, ERROR_PARENTHESIS_MUST_BE_PLACED_AROUND_THE_RETURN_TYPE struct print_fizzbuzz_3 { template&lt;class N&gt; FUNCTION_REQUIRES(is_multiple_of&lt;N::value, 3&gt;) (void) operator()(N) const { std::cout &lt;&lt; "fizz\n"; } }; struct print_fizzbuzz_5 { template&lt;class N&gt; FUNCTION_REQUIRES(is_multiple_of&lt;N::value, 5&gt;) (void) operator()(N) const { std::cout &lt;&lt; "buzz\n"; } }; struct print_fizzbuzz_N { template&lt;class N&gt; void operator()(N) const { std::cout &lt;&lt; N::value &lt;&lt; "\n"; } }; static_&lt;cond_adaptor&lt;print_fizzbuzz_3, print_fizzbuzz_5, print_fizzbuzz_N&gt; print_fizzbuzz = {}; Which works the same way. It uses a `cond_adaptor` to combine the functions together. With this, if the first function is not callable, it will then try to call the second function. If thats not callable it will try the next function, etc. The `static_` template is used to allow static initialization of default constructible function objects, which is necessary for C++03 compilers. Ill try to post a link when I get something up.
Cool stuff. In the while loop at the end tho, the int c = pc_ seems a bit pointless, as c is never used and pc_ is uninitialized. Perhaps the intention was pc_=0 before the loop, and dropping the c entirely?
See it really seems to me like the correct answer is do what the STL does and just use operator&lt;. That's clearly the best solutions when you know your data is homogenous. It's also, I'm sure, faster than the solution in the article. I don't see why you're using a heterogenous container at all, why not a templated container? In both of the situations you described (opening a CD or streaming from a single source), the data would definitely be homogenous. What's a plausible situation where you wind up with heterogenous audio data?
The classic workaround for lack of variadic templates is preprocesor iteration. Look at BOOST_PP docs. Or just paste the code to support some reasonably high limit of arguments, which is what the preprocesor iteration would generate anyway. The new way is cleaner, no doubt.
Probably comparisons to the "old" way...
I don't think it would be a worthwhile optimization to make even if it was different. But you should time it yourself and see.
If I was going to make the choice between the two, I would do so just based on whatever improves code readability. 
On x86 this boils down to: cmpl $1,%edi vs. testl %edi,%edi The former is 3 bytes vs. the latter 2 bytes, although these become similar-sized micro-ops on recent Intel processors. You can use gcc -O2 -S -o - | as -al to inspect these.
Yes, and it also depends on what kinds of branch instructions you have on your target architecture. 1 is small enough that it can usually be encoded in the instruction as an immediate (on ISAs that support immediates in ALU/branch insturctions), so it only matters in terms of code size. Again, this is only worth worrying about if it is in an **extremely** tight loop, and even then you should probably trust your compiler to do the right thing in favor of making the code more readable. Source: I'm a compiler engineer.
Macports considered harmful. Homebrew is the de-facto package manager for OS X.
&gt; For example don’t expect an in-depth discussion of how the TCP, UDP, or ICMP this is fine, but does it cover the SSL aspects of ASIO in a manner that might help someone who is no necessarily familiar with SSL? (not that it should have to but it would make it attractive to me).
Got it, thanks for the response.
MSVC always had this option... at least msvc 6. What am I missing?
Projucer does look very cool. Like Cling it's based on LLVM/Clang, and our target was to allow folk to use any compiler with minimal changes. In the games industry we work in the compiler is often proprietor, so that was an early requirement. The RCC++ code base is also permissively licensed, so you can pretty much use it how you like, whereas JUCE is GPL and Cling LGPL.
thanks, great project.
There's a chance I'll be in London in May, I'll look you up if so! One of the other collaborators on the project is based in the UK, so he may be able to come along too. JUCE looks great overall by the way!
As with many such things, I don't quite see the point - no matter how flexible you'll try to make it, it will only work in 1% of real use cases. But I've been wrong before, about many things. God... oh so wrong... 
I'm using this in practice in the development of my current project, and it's certainly very useful. It really depends on the type of project. In the games industry in which I work iteration times during development can be crucial, and having to restart and load a project is a significant problem for which many developers turn to scripting languages. With RCC++ we hope we've shown that rapid development is possible in C++.
Actually I'm sorry for being a jerk. Here you are trying to do simething nice and i dismiss it out of hand. No, I think it's cool - I just dont get it. I mostly code in C#, and edit and continue have been around for a while. But it never seems to work right, and compilation time is negligible anyway. In your example you are in a rendering loop, and change a few parameters. That's great, and probably really useful to that kind of workflow. Good luck!
I inverted the colors to make a background: [link](http://imgur.com/LzQ6bf0)
I've worked with BOOST_PP before; and definitely consider it the nuclear option. So that is true, most, if not all of this could be done with brute force churning out all feasible route types powered through macro expansions. Although with a reasonable type list (string, int, char, double), you only can support 5-6 arguments max before you start having a stupidly large library. Perhaps the best thing about the new stuff is that arbitrarily complicated template instantiations collapse back down to roughly what you'd have arrived at if you had manually written the type/function. 
really? i've been using mac ports for years and never had any problems other than random packages not wanting to update, until they fix the bugs involved
&gt; targeting 32-bit x86 Why?
Recent Intel processors will actually fuse some test/conditional-branch instruction pairs into one uop, so looking at the instruction bytes doesn't necessarily tell you much about execution characteristics. Smaller code is always good of course.
Many thanks! I'll check this out and add it to the project shortly and try to keep it up to date. [update] Just had a quick look, saw that the Systems folder was added to the RCC_SOURCE project. It's actually part of the SimpleTest example, a confusion which is entirely our fault as the project structure grew out of the prototype demo we made for a talk. I'll modify the cmake, and at some point add more documentation and perhaps re-structure the project locations to make things more explicit.
please don't add it to the project. I will send you a pull request with a cleaner version eg. not all the source in one parameter. quick question what are the different target names in the project?
Thanks - I've already started experimenting on my own fork, but some help would be appreciated. I'll be offline for a while soon due to travel though. Targets for RCC++ (which are also the source dirs) are: * RuntimeCompiler - lib for basic RCC++ functionality. * RuntimObjectSystem - lib for a object system based on above. The example targets are: * ConsoleExample - "Hello world" style example for RCC++ * Systems - lib for SimpleTest * Renderer - lib for SimpleTest * RocketCore - from libRocket for SimpleTest * RocketControls - from libRocket for SimpleTest * RocketDebugger - from libRocket for SimpleTest * SimpleTest - executable graphical game-like example for RCC++
betchmark it for yourself man
If it's only got two possible values, why is it a number? Wouldn't an enum or boolean make more sense? And if it's an enum or boolean, the compiler then has more information to optimise the generated code better for you... As it is, with the number version I suspect the generated machine code for != 0 will be slightly more efficient simply because a comparison to 0 is typically more efficient to a comparison to non-zero.
Not really, if JIT is used. Java works fine in JIT mode for games.
The speed difference is more complicated than that. The actual comparison is irrelevant, but the effects on the branch predictor are complex. See http://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-an-unsorted-array for details. 
Well that depends how big (good) your game is. There aren't many serious (definition dependent) games written in Java.
I am currently working on a big MMORPG that's in Java. It runs fine.
Yeap, interpreter availability for a platform might be a problem. Perhaps the interpreter capability should be build into the language specs, so as that it's everywhere. 
In my work (not games but shares commonality) at least Java is NO WHERE NEAR fast enough. Maybe it's fast enough for needs but the way I see it using more efficient tools allows you increase the granularity (in the application of read texture detail and so on).
Just a little update the pull request is now sendt
Great - I've merged it. I'll look into the Windows issue soon, but have a few days of travelling to do first. Many, many thanks!
It doesn't support them in the STL. There should be some major disclaimers on the MSVC STL support. Yes it does implement a good chunk of the STL but obviously on in as much as those features don't make use of C++11 features which is needed for a lot things to work nicely. For example, the number of elements in a tuple is limited to some predefined macro which by default is 5, this can burn you in subtle ways for example if you have one library where it's defined as 5 and another where it was defined as something else... good luck spending weeks debugging weird crashes. I found it's safest to actually stick to boost as much as possible for consistency.
It supports initializer lists in the 2012 CTP, however the library was not updated to support this. You can see it in action however via uniform initialization: struct my_type { int x[4]; my_type () : x { 1, 2, 3, 4 } { } };
The standard library hasn't been updated to support them yet. I mentioned it in the post.
A few of the language features in the VS2012 Nov CTP column that the author has listed as "Yes" should be "Partial". For instance: Variadic templates are broken in some important cases: template&lt;typename... Args&gt; void f(Args&amp;&amp;...) { try { } catch (...) { } } int main() { f(1, 2, 3); } The above is perfectly valid C++11 which the VS2012 Nov CTP will not compile. Initializer lists are broken in some basic cases: #include &lt;initializer_list&gt; #include &lt;complex&gt; #include &lt;stdio.h&gt; struct X { int a; int b; }; void f(X x) { puts("1"); } void f(std::initializer_list&lt;X&gt;) { puts("2"); } void g(std::complex&lt;double&gt;) { puts("3"); } void g(std::initializer_list&lt;std::complex&lt;double&gt; &gt;) { puts("4"); } int main() { f({ 1, 2 }); g({ 1.0, 2.0 }); } Again, C++11 that VS2012 Nov CTP does not compile. There are more. 
That's good to know. I was relying on the documentation for this post, so perhaps it's overly optimistic. I'm also not quite sure where to draw the line between "supported but has bugs" and "partially supported". For example, lambdas, decltype and std::thread all have issues in VS2012. Depending on what you do, you may not encounter them at all, or you may find them really annoying. I guess I erred on the side of being generous when I listed them all as supported. 
Wow, GCC 4.8 essentially has only one core language feature left unsupported -- rvalue *this (the other is support for garbage collection, but who cares about that). If you compare this to the C++98 days, when it took decades for compilers to catch up (and some of them, like Sun CC, are still not there), this is really amazing.
I wouldn't worry about "supported but has bugs". All implementations will have bugs at some level. "Partial" should apply to things like `initializer_list`, since it's not implemented within the STL yet.
Competition is grand isn't it? 
This book is *also* on Safari.
http://www.safaribooksonline.com/ &lt;-- That.
Your code: else { goto moveon; } moveon: Is useless, and all five lines can be safely deleted without affecting good style, or the behavior of your program. It is very rarely the case that you need `goto`s, and those rare cases where you do, the code can be rewritten to use better style. In the even rarer cases where it can't be rewritten to use better style, they need to be used only very sparingly. A single `goto` in a well-written multi-million line C++ program is reasonably typical. You do not need `goto` even for the case of cleanup. Modern style dictates that you should take advantage of scope (braces `{}` around blocks of code) and the RAII ([Resource Acquisition Is Initialization](https://en.wikibooks.org/wiki/More_C%2B%2B_Idioms/Resource_Acquisition_Is_Initialization)) idiom to perform resource management so that cleanup is automatic on leaving a given scope. It makes the notion of `goto`s almost completely obsolete in C++. In regards to formatting, I notice that your switch statement is unindented, which makes the last two closing braces (`}`) look like an error at a glance. Keep your indentation consistent to avoid making your code visually confusing.
If you have specific questions, check out: http://reddit.com/r/cpp_questions. But most people here are not going to do your homework for you.
This looks completely pointless.
Boost Coroutine is a much better alternative for a foundation of generators because it has a much richer API. Still, pretty cool that the author used pthread stacks!
How so? Are you saying reflection itself is pointless or that this isn't a good method to use for it?
You mentioned libc++ not being complete on Linux. I think your information is out of date. I've been using libc++ with libc++abi to compile boost and a fairly large C++11 code base on Linux. See [my comment](http://www.reddit.com/r/programming/comments/1aa2ib/c11_compiler_support_shootout_visual_studio_gcc/c8vnsnl) in the /r/programming thread.
Pure FUD imo.
&gt; Prepare yourself to the heat of Hell, we starts C++11's black magick
Exactly!! I don't think the GCC folks would have had the change of heart they apparently have had without the pressure of a modern compiler like CLang and the LLVM infrastructure. This is also a win for open source as I don't think LLVM and CLang would be where they are today without it being open sourced and frankly open sourced with a less restrictive license than GCC. Corporate support is a big thing here too, many a large company is pitching in to make LLVM and the various supported languages a roaring success. 
I am a little confused here. How does the compiler know here to down cast to Aut? Aut operator()(const Aut&amp; aut) { ... } std::string Doc() { return "documentation"; } dynaut&amp; operator()(const dynaut&amp; aut) { return operator()(dynamic_cast(aut)); } Same with (does it deduce from the return type?) template &lt;class Algorithm, class... Args&gt; auto Call(Args&amp;&amp;... args) -&gt; decltype (std::declval&lt;Algorithm&gt;()(args...)) { auto fun = reg_[Algorithm::name() + VarStringBuilder::Build(args...)] return (*dynamic_pointer_cast(fun))(args...); } &gt;We simply upcast our automaton&lt;T&gt; to dynaut automaton, and then downcast it into their static type when needed for the algorithm. **That's a great improvement from calling a virtual function every time!** So, our dynamic automaton will contain context informations in a member string, and we have to use that to downcast it. I am probably missing the point to the above really. It is probably a simple example in how they are using this and it kind of makes me wonder if it is worth the effort. Also so call any algorithm you have to do a map lookup on a string, so I am not sure what they are really saving in the end. I am also confused on *dynaut.ctx* I assume this is a string that has some sort of information it is since they used it to build the string that will selection the algorithm. Can someone describe some use cases to me that I might find this technique useful? I can almost see a case where I was trying to write my own scripting engine and calling into c++ for a simple case but I can't quite get there in my head. 
I really wish C++ people would take a lesson from the Perl CPAN documentation "synopsis" section and put a practical base case usage example right at the top. So many of these C++ articles go into great expository depth on some facility/library implementation but they never show you a really clear and practical demo of its usage. The "Make a perfect bridge between templates and dynamic execution" article currently on the main page also has the problem. I have to read these articles for a few minutes before I can really figure out why I'd want to do what's being talked about. Anyway, this looks cool.
thats why i love shared pointers, not because of RAII but because with them i dont have to write any rule. rule of 3 or 5 is all good for simple classes that use native types, but when you have classes that access outside libraries (using pointers) and then you have another class that has an instance of the previous class, using the rules is just asking for errors and too much effort imo. write empty rules as private methods and use shared_ptr for (almost) everything, as long as you dont have circular references everything should work just fine, at least thats how i like it.
Ditto. This really needs a very clear and practical usage example up front.
That *does* look beautiful!
I couldn't disagree more, `shared_ptr` by default give you shallow copy (the less idiomatic) semantics and if this is not what you want you are going to have to write additional code and you might as well use a unique_ptrs, or even better just values. whilst the rule over 3/5 is absolutely valid, when actually writing code we should be striving for the cases where we don't have to write any copy/move/or dtor.
...for Linux.
Good feedback, I'll start doing that from now on. It is pretty heavy in text, especially for the first part. 
Castor also has a macro based implementation of 'yield'. http://mpprogramming.com/Cpp/Default.aspx
This would be a better post for /r/learnprogramming. You're off to a rocky start. "pointer to array" is really a misnomer. What you're passing is a pointer to the first element in the array, i.e. pointer to float. What you've declared is an array of pointers to float, which is not what you want at all. C and C++ let you write things like `float a[]` as a function parameter, but what that really means is `float *a`. They are exactly equivalent. This is meant to reflect the fact that when you pass an array it decays to a pointer to the first element. So your `float *a[]` is really `float **a` which is a pointer to a pointer to a float, and not what you want at all. 
I like this idea. I spent some time over the past year digging into Ada just out of curiosity, and one of the things that I appreciated about the language design was that these operations are managed explicitly. For instance -- if you have a "limited" type, the compiler cannot perform any copies of it, and will enforce it rigidly. Means are provided (in-place construction) for initialization and that is all. Similarly, if you extend the "controlled" type, you can explicitly override Initialize(post-allocation and construction), Adjust(post-copy), and Finalize(destructor), otherwise the compiler performs no operations. I think C++11 is an improvement to the implicit madness with the "= default()" and "= delete()" syntax, but I think it would be useful for the compiler to enforce these: each of these five operations must be defined by the user, or marked default or delete. It may lead to some extra typing, but it's better than the mysterious behavior when it turns out an object is being default copied or similar.
on windows with msvc this is already built in. Dmp with your pdbs and bam magic happens. 
&gt; `void main()` This is horrifying to see in 2013. Whatever source you're using to learn C++ (whether a book, a teacher, or a university), I'd recommend dropping it and going through a good book written by someone competent instead: &lt;http://isocpp.org/get-started&gt;
Tried it. Lots of warnings with strict compilation options switched on. Fixed them. Doesn't work. It's a shame because I've wanted something like this for ages.
Could you give more details, link, or example on this? TIA. Here is my usage for this. Occasionally, I have a recurring error at a customer site, that I can't reproduce easily in the office. What I was thinking is that I could put a debug version up, and make finding the issue much easier.
Sorry not of the top of my head, just google mini dumps, there was an article on code project that was decent. The pdbs have to exactly match the build. On winxp you can have dr Watson make dmp files on crashes and on 7 i there is some registries to turn on to generate them. You don't need a debug build, just build the release with symbols (don't forget the line numbers). Also look into minidumpwrite to have your app write the dump on crash as well. Also in 7 you can right click on a process and dump it as well.
GCC 4.8 comes with its own `libbacktrace`, but that doesn't support separate debuginfo. On the other hand, the GCC library is very careful about not calling `malloc`, unlike `Backward-cpp`. And in my experiments, `dladdr` return misleading data (probably when prelinking is enabled, but I haven't found the exact cause yet). This could well be a bug in `ld.so`.
Despite unique_ptr covering most of its use cases, a scoped_ptr provides some more context to the purpose of the object (that it can never be moved). I find those three are suitable for nearly everything.
IMO, learning C++ from incompetent teachers / sources written by incompetent writers (and I can only assume that's the case given that this looks like an assignment and "we" also suggests a class setting) is a surefire recipe for learning to hate the language instead of actually learning the language. The `main` function should really already be introduced at the "literally starting out" moment (read: the canonical hello world program), learning about pointers (as is the case here) usually happens (or should happen) much later. If it wasn't, and pointers are introduced before the `main` function, all the worse. Don't get me wrong, I don't think it's the OP's fault, quite the opposite -- it's whoever that's responsible for "teaching" here that is doing him/her a disfavor.
You are right, the more I think about it. The basic args to main are char\*\[\], which would immediately introduce both pointers and arrays, and how the alternative char\*\* is equivalent. 
I was actually going to start learning C++ in a week or two and I definitely don't want to learn from a bad source, would you mind telling me if the books I've chosen are good or not? C++ Primer 4th Edition and then possibly to Effective C++ 3rd Edition (I have an intermediate programming experience with Java)
Regarding "C++ Primer" -- I'd use the 5th Edition instead since it's been updated to C++11. And, yes, it's one of the very few good C++11 books currently available on the market. "Effective C++" is also a good choice from the "morality guides" category. // The author is also working on the C++11 version, but it may take a while: http://scottmeyers.blogspot.com/2013/01/effective-c11-content-and-status.html See also: http://isocpp.org/get-started http://www.parashift.com/c++-faq-lite/buy-several-books.html http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list
I guess that's fair. I was equating metaprogramming with TMP of which there is very little in this blog post. However, one could say that all programs are metaprograms if you allow this one to be, IMO.
I would go for an hydra where some of the heads are biting other necks. I think it's a good description of the multi-paradigm nature of the language.
It needs no such thing.
An octopus made by nailing extra legs to a dog.
Oh, I like this. It also alludes nicely to the fact that the more you know about the language, the more you realize you don't know. Compare to the hydra growing new heads when one of them is chopped off.
The Pushmi-pullyu
[This super swiss army knife](http://swiss-army-discounts.com/wp-content/uploads/2009/02/wenger-giant-knife.jpg)
&gt; Yes, the implementation is pthreads based. Nothing to see here, move along.
a void, damn it 0o
Stroustrup seems to think of it as an elephant. ;-) (see his "C++11 Style" talk)
Neat idea, bad proposal in that it breaks current code. Why not use a defaulted arg for the 'how' specification, e.g: std::vector&lt;int&gt; vec = {...}; std::sort(vec.begin(), vec.end(), std::sequential); std::sort(vec.begin(), vec.end()); // identical to above (legacy notation)
It's a little close to perl's "Swiss Army Chainsaw," but I like it anyway.
This useless, heavy multitool looks like Java for me. You have always more than you need, it makes heavy, difficult to operate on and... who would use it to open a bottle?
A sad panda.
Make sure your linker doesn't throw the whole library away because the global object responsible for setting-up signal handlers isn't referenced from your main code. Quick fix: include the .cpp file instead of the .hpp one, and try again.
The .cpp was included. Fixing the warnings might have broken it. It try it again on Monday.
I agree with some of their posters. they put the where as the first flag. what is being sorted is more important than what vehicle is being sorted. and frankly sorting isn't that interesting, other algorithms that fit with std::transform or std::generate are more interesting.
Good PSA for novices, but OP should mention that comparing unrelated pointer values yields unspecified behavior. Moreso, if you compare C and B pointers, it can yield equal despite being numerically inequal, as the implicit conversion will fix up the pointer offset based on type. 
[The Millennium Falcon](http://imgur.com/QnESo)
Yeah, any C++ veteran ought to know immediate the answer is "duh, multiple inheritance." This little gotcha, among others, is also why multiple inheritance is often discouraged, with the exception of purely abstract interface like classes (i.e. "zero sized" classes). Also curious why the post didn't include any mention of virtual inheritance, which makes the problem even trickier.
The same spirit, I was thinking Cerberus, or maybe a Chimera.
It doesn't break existing code, as the existing signatures stay. They're proposing overloading the existing algorithms, not changing them. It's an opt-in feature.
It says the last update was pre3.2, clang 3.2 is out. Definitely out of date, but maybe not entirely wrong. I cant remember if I ran the full test suite and most of the broken things listed there wouldnt effect my code. The others must have been fixed.
May someone please explain to me what he meant by "64 bit code, 32 bit data"?
My rough guess is that the you want the op codes in your instructions to be 64 bit to allow for greater compiler flexibility interms of optimization. However unless you need it you don't want to take the performance cost of 64bit multiply and divide which are very expensive.
x86-64 is a fairly large step up from 32-bit x86, but that doesn't mean that you necessarily want to use 64-bit values everywhere. If they fit your purposes, 32-bit values have less memory footprint and are quicker to compute with.
Hydra, definitely. 
Yep. Any chance I had of really enjoying programming (I was so excited about this course) has been destroyed. I still want to learn microcontrollers, but this class has been really discouraging for me, and I go to a top 100 school for engineering. Kind of sad. I know I need to be self-motivating, but the only reason I've been able to get through this class is because my roommate has been programming for 10 years. Thank you guys for all the advice by the way!
Here's a [video of this talk](http://vimeo.com/55639112).
A rope noose that can fire bullets and is always aimed at your feet.
Perhaps a [gun for shooting yourself](http://i291.photobucket.com/albums/ll301/hammerz71/SuicidePistol.jpg)?
Maybe like some kind of machine gun where the barrel is curved back so that it points at the shooter. Or even just a wadded up piece of paper with a bunch of weird scribbles on it. 
someones face after getting a penis rammed in their ass unsuspectingly 
I tried to come up with something funny by doing a google image search for [Bjarne Stroustrup with his leg shot off](https://www.google.se/search?hl=en&amp;safe=off&amp;q=bjarne+stroustrup+with+his+leg+sjot+off&amp;ion=1&amp;bav=on.2,or.r_qf.&amp;bvm=bv.43828540,d.bGE&amp;biw=1280&amp;bih=908&amp;um=1&amp;ie=UTF-8&amp;tbm=isch&amp;source=og&amp;sa=N&amp;tab=wi&amp;ei=umVFUer3M4Wr4ASV24HICA), but that just gave me the possibly most incoherent set of images I've ever seen...
Slicing is related but something different.
Depends on what you hope to get out of it. Visual C++ 6 was an awful C++ compiler. A lot of valid template code would be incorrectly rejected as having syntax errors, and the standards support just wasn't really there. That said, if you don't know any C++, the basic material is probably OK to get you started. Most simple programs on the book should work fine with newer compilers. That's probably about all it's good for though. For modern windows programming, the landscape is quite a bit different now, and even C++ has seen enough differences that you would want to have a newer source at some point.
Having learned C++ around this era I'd say pick a newer reference if at all possible (a good library can order a book in so money doesn't have to be an issue). The stack overflow book list on the sidebar is a good starting point. I recall attempting to learn some game programming stuff with visual studio 6 and getting bogged down in Hungarian notation, tricky win32 stuff and other nonsense I should have left to tackle later. In fact I'd strongly recommend learning "general" C++ and avoiding Microsoft specific things. If you go straight into C++ attempting to learn how to create GUIs in MFC you're just going to put yourself off. If your only planning to learn C++ because you have this book I'd seriously recommend starting with a different language unless you know that you need C++. C#, Java, and python are all decent options.
By Ivoir Horton? I acctually have this book, got it when it was new (I think, it was a long time ago). I got it from my dad when I was 14 or something for writing a tool for managing printers at his job. Apparently they still use it :/ I never really took the time to read it, but it seems to be to be quite outdated. For what it teaches I think you would rather either learn C# or C++, depending on what you like about it. It does seem to offer explanations on C++ and also how graphical IDE's tend to work. Note that it's very rare to do C++ like this anymore, most programmers who work this tend to just use C# which is literally made to do this kind of thing (although I'm no expert so I might be wrong about that) C++ have moved on since this book, and the compiler, from what I've heard, had it's own standard for C++ going on. I will say though, this author really took his time to write this book, it's fking huuuge. I mean if you got it as a gift you already have it, and it should teach you the basics of C++, although there are better books out now (I recommend Programming - Principles and Practice, only because it's the only book I've acctually tried!). However, it is better to read any book than noone at all. This coming from someone who never really read the thing, and only source of reference is that he has it in his bookshelf! Deong's answer is probably far better than mine honestly.
Throw it away, immediately. Even if you could learn from it, you shouldn't. There is nothing harder than trying to unlearn bad behaviors. [Here is a good book](http://www.amazon.com/Effective-Specific-Improve-Programs-Designs/dp/0321334876) that will teach you well.
This looks useful, but does anyone know of a cross platform implementation or when to expect one? Maybe a similar library that implements this already in C++?
If we are being nit-picky indenting after the "template" lines and having 110 line function definition + declaration (make_field) does not help readability of your code samples.
No idea if it's any good: * https://github.com/Amanieu/asyncplusplus/
Visual Studio 6 was the best C++ IDE in 90s, and I was using it until 2010. But in these days there is of course no sense to learn it. Also, Microsoft does not sell Visual Studio 6 anymore, and it is even not available from MSDN subscriptions. So there are no legal ways to buy it.
A concise, well-illustrated post with good, complete code samples - would recommend, even though (as [some](http://www.reddit.com/r/cpp/comments/1aepc3/why_this_sometimes_doesnt_equal_this/c8wqzgx) have already mentioned) the covered issue may not be surprising to many non-novice C++ programmers. I particularly like the calm, measured: &gt; Void* has its uses once in a while, but it is often avoidable. So whenever you are using a void* in your code, stop for a short moment to think about whether there is another solution that avoids it! instead of the [more common](http://www.parashift.com/c++-faq/mi-not-evil.html): &gt; YOU SHOULD NEVER USE `void*`, LOL!!1!
I need this like yesterday. Can't wait until 2014.
As a computational scientist once upon a time, my job required a high performance and high numerical/statistical quality RNG for monte carlo simulation that can run for a few days. in C++98, standard library of c++ requires expert knowledge in merely algorithm and operation system to maintain. These days it requires high level mathematics for complex maths functions and RNG, strong experience in threading. Just the topic of high quality RNG can generate quite a few papers for a few PhD students. I wonder how this is going to change the quality of standard library? 
grumpycat
According to [Wikipedia](http://en.wikipedia.org/wiki/Microsoft_Visual_Studio#Visual_Studio_6.0_.281998.29), that was released in 1998 the same year that the language was standardized. Its no wonder it didn't have standards support.
LPCTSTR lpClassName! Love hungarian^(*). ^(* no I do not)
How could it be standards compliant when it came out the same year?
I concur about the best IDE. I appreciated it, and even Visual Basic 6 for the simplicity they offered before the era of the .Net IDE (I remember the first beta)
You can reproduce this problem *without* multiple inheritance too. If a derived class introduces the need for a vtable pointer, a compiler may locate that pointer at the beginning of the object. A pointer to the single base object would then have to be adjusted to exclude that pointer. Last I checked, Microsoft's compiler took that approach.
Yes, but just looking at the release date mostly misses the point. Languages are standardized by committees that meet over the course of several years -- it's not as though they just dropped it fully formed on the world leaving everyone scrambling to support some completely new thing. By the time a standard is officially ratified, most compiler vendors already support most or all of the new language. See [the GCC page for C++-0x support for example](http://gcc.gnu.org/projects/cxx0x.html) -- note that most features were supported much earlier than the final standard. Even more significantly though, VC6 never really got any better. By the same source, it wasn't officially replaced by Microsoft until 2002, and was in active service in the field for a few years more even, and it *still* couldn't compile more than a piddling fraction of valid template code.
Microsoft has already recognized that it was a bad idea. In the new design documentation on MSDN it is advised to use Hungarian notation only on legacy code.
Any chance of a link to that documentation? Some of my coworkers still seem to use bits of hungarian notation and I'd love to have it to hand.
Nit picky is good, I really appreciate the feedback. Especially with heavily templated code, I should make it as readable as possible. I fixed that instance and reformatted some other long parts. 
It is part of the *All-In-One Code Framework*, which you can find here: http://1code.codeplex.com/ Search for *C++ and .NET Coding Guideline*, chapter 3.3.3: &gt; You can use Hungarian notation in parameter and variable names. However, Hungarian notation is a relic that makes code refactoring harder.
Um, GCC's template support in 1998 was just as incomplete as VC6. The [release notes for GCC 2.95](http://gcc.gnu.org/gcc-2.95/c++features.html) (July 1999) shows new features like namespaces and template members. Use of templates was sketchy across all compilers until the early 2000's. &gt; Even more significantly though, VC6 never really got any better. Well *duh*. That's like saying "GCC 3.1 was released in 2002 and never got any better". Obviously, because the next release was called GCC 3.2. &gt; Even more significantly though, VC6 never really got any better. By the same source, it wasn't officially replaced by Microsoft until 2002, and was in active service in the field for a few years more even, and it still couldn't compile more than a piddling fraction of valid template code. VC6 is still in use by a surprising number of people today, yes. But how is that VC's fault? That's like blaming GCC for people who stubbornly refuse to upgrade from GCC 2.95.
With all the work tuples cause for the compiler and traps in performance, I sometimes ask my self, if you should use them at all heavily.
The functions that return `sizeof(T)` and `sizeof(T) + i` should use `std::size_t` (from `&lt;cstddef&gt;`) instead of `int` for the respective types. The same goes for `TestFunctor::operator()`. Note also that `std::get` takes `std::size_t` as its non-type template parameter: &lt;http://en.cppreference.com/w/cpp/utility/tuple/get&gt; This is because `int` is generally too small to be used as a collection-size type. In contrast: &gt; size_t can store the maximum size of a theoretically possible object of any type (including array). See: http://en.cppreference.com/w/cpp/types/size_t
&gt; Well duh. That's like saying "GCC 3.1 was released in 2002 and never got any better". Obviously, because the next release was called GCC 3.2. Well, to be fair, the FSF isn't charging you money to upgrade. People were paying about $500 for Visual Studio around that time, and there was an expected period of time under which that software would be supported. There were several service packs released over the lifetime of VC6, and just because Microsoft's naming scheme of "Major-Version SP&lt;xx&gt;" differs from the GCC scheme of bumping major/minor versions doesn't mean we should treat them as being qualitatively different. In the only way that matters, both compilers were being updated, but only one was getting any better during the updates. Microsoft's developer tools have always been fantastic, but VC6 was a hot steaming mess of an exception that proves the rule. In all the time I've been programming professionally, VC6 and the weird "let's just checkout a random snapshot from CVS head" version of GCC that RedHat 7.1 shipped with are by far the two most painful compilers I've ever had to deal with. 
It's also worth mentioning that we can use [Boost.Fusion](http://www.boost.org/libs/fusion/) with `std::tuple`, thanks to (apparently undocumented?) `#include &lt;boost/fusion/adapted/std_tuple.hpp&gt;`. Edit: I guess the reason it's undocumented is that requires std::tuple to be implemented using variadic templates and, as a consequence, doesn't support MSVC: http://permalink.gmane.org/gmane.comp.parsers.spirit.general/23844 Examples: http://d.hatena.ne.jp/faith_and_brave/20111013/1318489797 http://d.hatena.ne.jp/osyo-manga/20121209/1355051595 http://d.hatena.ne.jp/osyo-manga/20130309/1362808740 // particularly interesting, uses `boost::static_visitor` to enable dynamic iteration (e.g., for-loop with run-time indexes) http://stackoverflow.com/a/13975665/859774 http://d.hatena.ne.jp/nagoya313/20111117/1321546656 http://d.hatena.ne.jp/harre_orz/20121225/1356437385 // ok, this one is possibly going overboard :D
Good catch, I fixed it and added a correction for it.
I do think that serious care needs to be taken about when and how you use tuples, or really any variadic templated structure. I'm not quite ready to write them off quite yet though. 
author of Backward-cpp here. cool finding with libbacktrace. about not calling malloc: yes this is a potential problem. If you get some signal while malloc is locking something, then any call to malloc in the signal handler will probably deadlock. This is a fairly rare situation though. Considering than in modern C++ programming most failure are assert and uncaught exception, you can assume that a signal occurring during a malloc function will be rare. Maybe I should put a comment about that in the readme! About dladdr: this is only when you configure Backward-cpp to use libbfd. The code using libdw doesn't use dladdr. I am really curious about what dladdr would be doing that is really different than looking up the symbol tables of all the loaded modules. I will take a look at the prelinking problem, its sounds really curious.
Author of Backward-cpp here: I am often compiling in C++11 mode with clang, sometimes I forget to check in C++98 and with gcc. Shame on me. I think I am using the strict C++11 mode, but not the strict C++98 one (when I do remember to try C++98). I also use gcc-4.8 and clang 3.3, that might make some differences too. I will check all of that and commit the fixes. Btw, pull request are welcome :)
I agree, that tuples can be useful, but aren't really the lightweight data structure, what they might look like at first glance. Eric Niebler gave a very nice talk about tuple implementation at C++Now last year.
Look at all the c++ compilers this time around. Its been a year, and still not complete. It is possible that if they had changed the compiler, it could break their customer's projects ongoing.
Apologies for the plug, but I wrote a similar thing a while back, and I think I did a better job at coming up with a tolerable API: https://github.com/simonask/reflect My reflection framework is geared towards marshalling, but I'm also using it in other projects to achieve things like a generic `Any` type (essentially a richer `boost::variant`) and RPC.
&gt; http://d.hatena.ne.jp/harre_orz/20121225/1356437385[8] // ok, this one is possibly going overboard :D I get the intent of the code but I don't get the rationale, besides exampling how to concatenate a tuple of strings is there a real reason for me to use this "soft_exception" code? 
&gt; Visual C++ 6 was an awful C++ compiler When it was released (early 1998) it was one of the best compilers. As far as I remember, KAI C++ was ahead of it when it comes to Standard compliance, but g++ was behind it.
More importantly, MSVC6 is *broken*. It's not very standards compliant and can encourage you to follow bad practices that won't work on even newer versions of MSVC.
Not much news to me. But I appreciate the effort. The wording is just unfortunate. It's immediately obvious to the reader that English is not your native tongue.
You can get used to it. The stabbing I mean.
Also, even what replaced it in 2002 (Visual c++ 7) still did not support partial template specialization. The outcry was so great that microsoft released visual c++ 7.1 in 2003 with a steep price discount for an upgrade (around $30-50). I remember writing boost code, and working around MSVC++ 6. Take a look at http://boost.sourceforge.net/more/microsoft_vcpp.html Note that at the top they say that the code works with gcc 2.95.2
A pointer
Slavic post is best post, no?
It's all perfectly clear. Just some syntax oddities.
Very cool, but what kind of situation would you need something like this?
I suppose it can be used as a nicer syntax for a bunch of std::conditionals. std::conditional is of course useful as it's a compile-time 'if'. The second view is that it's the index operation on type lists, which is useful for writing metaprograms in general.
Hey reddit, I missed ranges so I made them. This is my first time posting code so feedback is very appreciated.
http://www.boost.org/libs/range/doc/html/range/reference/ranges/irange.html
Just for fun, this is what the implementation of range could look in Python: def my_range(a, b=None, step=1): curr = 0 end = a if b is not None: curr = a end = b while curr &lt; end: yield curr curr += step edit: made a class-based one too, that'd be closer to the spirit of the C++ version: class cl_range: def __init__(self, a, b=None, step=1): self.curr = 0 self.end = a self.step = step if b is not None: self.curr = a self.end = b def __iter__(self): return self def next(self): if self.curr &lt; self.end: tmp = self.curr self.curr += self.step return tmp else: raise StopIteration
Wow there is actual documentation now. Maybe I'll stop hanging the debugger when I mess with these, too. 
&gt; I’ve always been disappointed that the range() function doesn’t work with non-integers. Now that I’m writing my own, I’d have no one to complain to but myself. The reason that Python doesn't support this (I presume) is because it can be very difficult to do correctly in the face of rounding. For example, consider the output of: for(double i : range(1.005, 1.006, 0.0001)) { cout &lt;&lt; i &lt;&lt; "\n"; } I get this: 1.005 1.0051 1.0052 1.0053 1.0054 1.0055 1.0056 1.0057 1.0058 1.0059 1.006 Oops, one too many steps. This is very difficult to predict; it doesn't happen with `range(1.05, 1.06, 0.001)` for example.
The only things that strikes me as a little off putting are two things: 1. "A license is always bound to a project (application) and cannot be transferred." If I am buying a license for a product that is a library, this restriction would be unacceptable. 2. The notification of your product on load is mentioned to be short, but the actual length of time isn't mentioned. If I were to make a game for a phone – I would try to minimize the loading time as much as possible. Company logos do not strike me as something adding to the user experience like you would see in most EA games. Something on a menu screen is a much better idea and user friendly. 
C++11 got standardized in 2011, yet Visual C++ 2010 already supported many features.
The error message: error: passing 'const std::string' as 'this' argument of 'std::basic_string&lt;_CharT, _Traits, _Alloc&gt;&amp; std::basic_string&lt;_CharT, _Traits, _Alloc&gt;::operator=(std::basic_string&lt;_CharT, _Traits, _Alloc&gt;&amp;&amp;) [with _CharT = char, _Traits = std::char_traits&lt;char&gt;, _Alloc = std::allocator&lt;char&gt;, std::basic_string&lt;_CharT, _Traits, _Alloc&gt; = std::basic_string&lt;char&gt;]' discards qualifiers Simplyfing the types gives you: error: passing 'const std::string' as 'this' argument of 'std::string::operator=(std::string&amp;&amp;)' discards qualifiers Which means you are trying to use the assignment operator on a const string. Try capturing by reference by reference instead.
Seminal reading: http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html
 import numpy # Happily works with floats # But can have the rounding problems you cite for num in numpy.arange(1.005, 1.006, 0.0001): print num 1.005 1.0051 1.0052 1.0053 1.0054 1.0055 1.0056 1.0057 1.0058 1.0059 1.006 # Works around the rounding confusion by letting you say # how many samples and whether to include the upper bound for num in numpy.linspace(1.005, 1.006, 10, endpoint=False): print num 1.005 1.0051 1.0052 1.0053 1.0054 1.0055 1.0056 1.0057 1.0058 1.0059
Why create a vector to iterate into when the same thing can be done by a function? template &lt;class T, class F&gt; void for_range(T begin, T end, T step, F func) { for(T val = begin; T != end; T += step) { func(val); } } And then using it is as simple as this: for_range(0, 5, 1, [](int i) { cout &lt;&lt; i &lt;&lt; endl; }); Much simpler, less error prone, less code, easier to reason about. 
First argument specifies kind-of "machinery" that will perform sort. Kind of object which will actually perform a method. In OO way it would be: policy.sort(v.begin(), v.end()) but we're in overloaded world of C++, so "overloaded way" is chosen. 
... and much faster, which is especially important.
If you need stack of other thread ....hmmm On win32, You actually only can get stacktrace of other, paused thread. See all those examples of StackWalk. On Linux, just send a signal to thread (search for gettid() syscall) and in signal handler collect stacktrace using your favourite function. To enumerate threads in process, at least on linux list /proc/pid/task/. Not sure about bsd, darwin. 
Great library, will have to try out. Nevertheless watch-out for licence when linking with libbfd - libbfd is distributed under GPL, so your program becomes GPL ... So for production, prefer linking with libdw which is licenced under LGPL.
Excellent analysis, very helpful. I happen to be using Haskell Platform's MinGW's g++, which apparently has terrible error messages. [FizzBuzz](https://github.com/mcandre/mcandre/blob/master/cpp/fizzy/fizzy.cpp) is now operational. I'd like to parallelize it, but MinGW doesn't support threading yet. :(
Doing it this way would definitely work, but if you were changing the state of lots of local variables passing them all to the lambda could be ugly, and to me doesn't resemble python anymore.
&gt; passing them all to the lambda could be ugly No, it wouldn't be. c++ lambda functions support closures. All local variables can be captured. &gt; and to me doesn't resemble python anymore. So? c++ is not Python. 
Great idea. I hope the execution is good and has a focus on using C++11 features starting off with a C++ focus (as opposed to using C++98 features and starting off with a "C with objects" focus).
There should be more creative commons textbooks. Khan academy should be all over sponsoring something like this.
porcupine 
First these guys need to read The Nature of Code; full stop. I have never read a better book on coding. The language covered in that book is the obscure Processing (a C++ like syntax) but it doesn't matter. That guy explains everything you need from pretty well zero to Genetic Algorithms in ways that I have never seen done so simplistically. Most shelf computer books meander through the usual OOP stuff such as circle and square inheriting from the shape base class but without really explaining why the hell you would need any of that. CS textbooks can't wait to show off the writer's math skills and while explaining one thing will throw in lambda calculus just for laughs. Also CS textbooks often contrive the need for something like a doubly linked list instead of leading the student up to where they hit a problem that is nicely solved by the topic. This is where you find the critical difference between obtaining knowledge to regurgitate on a test and building a skill set for life. One of the keys to the nature of code is that the writer is almost always doing something graphical. The result is that you can get a feel for what your code is doing while at the same time having concrete goals. I am sick of textbooks where they will introduce a vector &lt;string&gt; blah and then get you to sort and print the results. I doubt there is a person on earth who went into a CS course wanting to sort a list of names. But if you have a graphical bunch of rectangles and you put each rectangle in a vector and then have the student sort them that way and display them stacked, still useless but the student will probably get more satisfaction. Good luck with the book.
Not another thread, another stack in the same thread. Think fiber, swapcontext, boost::context. Only Linux, I don't need Windows support.
I'm surprised nobody commented on [N3613](http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2013/n3613.pdf) yet, Stroustrup's rejection of static if. Any thoughts on that?
/r/learnprogramming 
Think of cin as "Console In". cout prints something to the console, cin takes input in from the console. That way you can ask a player their name and have them enter it. - http://www.cplusplus.com/reference/iostream/cin/ FFlush takes all the data that is waiting to be written to a file and forces it to be written. - http://www.cplusplus.com/reference/cstdio/fflush/
Not to be too harsh, but reddit is not a google replacement. The sorts of questions that make it here should require more than 20 seconds of googling to find an answer
He makes some very good points. In general I think most of static if's use cases are covered by [N3580](http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2013/n3580.pdf) which allows a function to be excluded from the overload set using a predicate. (essentially a glorified enable_if)
I'm trying not to overload him right away. Just giving him a taste of what everything is.
Meyers's haircut is very distracting.
It kills me every time. Meyers' books and articles made me a better programmer, and I respect his knowledge, experience, and work. But I feel like I'm looking at a prince valiant comic.
 double getsqrt(){ double s; double guess; double result; double compare = 1/1000000; cout &lt;&lt; "Enter a number: "; cin &gt;&gt; s; counter = 1; guess=s/2; result = ((s/guess)+guess)/2; while(abs(result-guess)&gt;compare) { guess = result; result = ((s/guess)+guess)/2; counter = counter + 1; } return result; } what i have so far
Shouldn't cheat on your homework.
&gt; I'm not allowed to use any `&lt;cmath&gt;` operators No worries, http://www.boost.org/doc/libs/release/libs/math/doc/sf_and_dist/html/math_toolkit/toolkit/internals1/roots.html -- what, `&lt;boost/math/tools/roots.hpp&gt;` ain't no `&lt;cmath&gt;` ;-)
How can one otherwise learn intermediate c++ without writing a high performance expression template library? 
I like the GPL, but the restrictive license terms is making me choose to use Eigen.
For a while I was waiting for this library to get released. Now I realize that these kinds of libraries, including Eigen, only handle the lowest level operations with competence. Once you want to actually DO linear algebra, like computing eigenvalues and singular values, these libraries either don't have that functionality, or implement textbook algorithms with terrible performance and stability. You end up resorting to calling Lapack, and having to deal with all the pains of linking against Fortran.
The interface does not look nearly as sophisticated/polished as Eigen's. Additionally, it lacks a ton of features that Eigen has. I also don't see a clear explanation as to why blaze is supposed to be faster, and why the same speed could not be achieved by Eigen. So please: As long as you do not follow a _conceptually_ different approach -- contribute to Eigen instead of reinventing the wheel.
Their license sucks! The so called free version requires the acceptance of advertising. As other have already pointed out there are one other highly questionable conditions in the contract. Avoid this library at all costs. 
Eigen and Armadillo have bindings to Lapack and Cblas. I use Armadillo with Intel's MKL and I have zero problems.
There are literally hundreds of numerical linear algebra packages out there. This is the order of things I look at in order to decide to use them or not: 1.) Complex sparse matrices. Not supporting these is a deal breaker. 2.) Ease of API, documentation and examples. 3.) How active is the developer community, and how actively is it developed. 1 main developer, and no updates since 2007? Not even going to bother. Well written algorithms numerical can be around for decades. As GUI fads and OS environments come and go, the core science of technical computing doesn't really need to change. So someone writes a lazy evaluation template-this meta-that matrix library that on a few tailored benchmarks beats something. That is so low on my list for choosing a matrix library.
There's an exception: &gt; Blaze is published under the GNU GPL v3 and a special exception for linking and compiling against the Blaze library (the so called "runtime exception"). This means that Blaze can be freely used in both open-source and closed-source software packages. 
This can't be happening... I just compiled the RC two minutes ago. Anyways, good news. The *-Og* switch sounds interesting.
Wait, I've been using 4.8 for a long time now via macports. How is this one different from that one?
The mainline development branch was labeled 4.8 ever since 4.7 came out a year ago, as is the usual practice. If you build the mainline branch today you'll get something that calls itself gcc 4.9, but obviously that is a pre-release version. What you were using was likely labeled something like "gcc-4.8-yyyymmdd" to indicate that this was a snapshot not a release. 
Sadly, I'm not good with C++ operator overloading, but I can tell you in general what it's for. Say for example you have some class representing an integer: class Integer { int my_int; Integer::Integer(int a) { this-&gt;my_int = a; } public int Integer::add(Integer other) { return this-&gt;my_int + other-&gt;my_int; } } Forgive any instances of poor style; it's been a while since I seriously used C++. Anyway, would you rather do this: Integer a(1); Integer b(2); int c = a.add(b); or this: Integer a(1); Integer b(2); int c = a+b; If I overload the + operator for the Integer class, I can do fancy things with it. For example, in a vector class, I might overload ^ to perform a cross product, or * to perform a dot product.
Just a heads up, you shouldn't really include the **Integer::** qualifier on member functions. Visual C seems to accept it, but GCC flags it as an error. On a more minor point, this is stylistic, using **this-&gt;** to access member variables is very uncommon.
This should really have been better posted in [r/cpp_questions](http://reddit.com/r/cpp_questions), it's mentioned right there in the sidebar. You might find this [Operator overloading, C++ FAQ Lite](http://fisica.ciencias.uchile.cl/~jrogan/cursos/mfm0p01/c++-faq/operator-overloading.html) helpful.
Ah didn't even realize that sub existed. Sorry! I'll definitely check both of those links out though, thank you! 
I ran into this a while back when making my allocation tracker. I had a global std::set&lt;void *&gt; in which I would store addresses of all the allocated memory. It worked fine until multiple inheritance came into play. Using OP's picture, they would allocate a C and then tell it to delete the B. It would say "we have no records of this address." because of course, the addresses are different. The funny thing is that c++'s delete operator takes this in stride. I ended up just saying "ok, just check if the address you want to delete is *inside* any known allocation" IOW, checking if it was somewhere around what they allocated. IOOW, checking if it was &gt;= address &amp;&amp; &lt; address + size.
Do you have any insights on how the equal operator works in this case? When I allocate a C, and compare it with its own B-type pointer, how does it know that they are equal? C *derpC = new C(); B *derpAsB = dynamic_cast&lt;B *&gt;(derpC); derpC == derpAsB How does it know that derpC and derpAsB are actually equal?
I don't think so, but don't have access to it at the moment. Using -fpermissive allows it. As for the other, like I said, it's a minor enough issue of style. Personally I use a "_" suffix on members. Using a "m_" prefix seems to be very common too. But sure, whatever floats your boat.
More importantly, `other-&gt;my_int` is definitely an error. Since passed by value, `other.my_int` needs to be used, unless `operator-&gt;` has also been implemented.
The other thing that I find is that some libraries seem to suffer from a "not invented here" mentality in terms of algorithms, and try to roll their own everything. I really like that Eigen for instance, tries to provide (or is developing) hooks to SuiteSparse, MUMPS, and various other libraries, and leverage the work of others.
maybe. when i said in op that the thread needs to "clean itself up" perhaps i wasn't explicit enough, but there are resources in there that need to be released. if the thread just dies, they won't be released.
First of all, a few thousand pipes wouldn't even break a sweat on most systems. There are global limits and per-process limits in place, but they can be easily modified by the administrator. I just created a test program that created 250,000 pipes. It required about 500 MB of kernel memory, since each requires a pipe buffer of some size, but that's not a big deal if you have a lot of memory. But that's completely irrelevant. If you're using threads, then everything is shared, so you only need a single pipe, or two pipes if you need bidirectional communication. Any thread can read from the read end and any thread can write to the write end. Also, `select()` is not used by high performance applications because of the various limits of a fdset size, and general inefficiency of having to linearly scan that whole set. poll, epoll, kqueue, etc are some system-specific APIs that are used. 
First, the dynamic cast is unnecessary in this case, as B is a base class of C, and casting to base is implicit. Second, the compiler arranges for a cast to base class to always result in the same pointer value. Your last line behaves as though you wrote `static_cast&lt;B*&gt;(derpC) == derpAsB`. 
Unless you're using epoll, which is thread safe, you need a way to interrupt the grand central thread when you want to add or remove an fd from your poll/select set. You've not solved the problem, just moved it. You can use pthread_cancel and clean up resources as long as you use RAII. pthread_cancel is implemented as an exception unwinding the stack. I'm not very familiar with win32 so I can't help there. 
I can have a pipe that the grand central thread can add into its select(). whenever it's written to, the grand central thread will wake up, clear it out, and check its messages queue for anything that needs to be added or removed. It's just like my original, except we're only using 2 pipes, instead of 2n pipes.
Well, in my original scheme, every single thread would need its own pipe, because we would write to that thread's pipe to wake that thread up. If they somehow all shared a pipe, then we'd have every thread waking up when we only wanted one. Also, I thought we were limited to 256 file descriptors, how in the world did you make 250k? That's incredible!
That makes sense, thanks. So I take it this won't work with void* then, lol.
Why do you need to wake a specific thread up? Isn't this being used to tell all the threads to terminate? I think I'm now in that camp that says that this sounds like a really bad idea. On the system I was testing (Ubuntu Oneiric), the default settings allowed for 1024 fds per process (`ulimit -n`) and approximately 100,000 fds globally (`/proc/sys/fs/file-max`). I kicked both of those up to 1,000,000 fds, which would theoretically allow for nearly 500k pipes since each pipe takes 2 fds, but I then limited it back to a lower number with `ulimit` to avoid using too much memory. `FD_SETSIZE` is defined as 1024 on this system which puts a limit on the number of fds you can pass to `select()`, but that's irrelevant because `select()` is outdated and can't be used for high performance systems; `epoll()` has no such limitation. And anyway the testcase I wrote just created pipes, it didn't do anything with them. 
Not sure where you got 256? A file descriptor is an int, not a char. The limit per-process can be set with ulimit, so maybe your sysadmin has given you a low limit? On modern hardware limits of several hundred thousand aren't unheard of. select is limited by the size of fd_set, which is usually 1024 unless you've specifically changed it.
To be fair shadowing like that is asking for trouble. 
Absolutely, but I wouldnt want to rely on it. 
They license the EDG C++ frontend, so this is not that surprising. I just wish that Sun (Oracle) CC also gets on with the program.
&gt; String_buf Ugh, that's an ugly name.
Yeah possibly :), but It's a matter of personal taste. I don't like the cammelCase and PascalCase that much. But on the other hand, I find it useful to start type names with a capital letter to emphasize it's a user type, otherwise I would name it just 'string_buf'.
Bjarne Stroustrup also used the Ugly_name style in his book (TCPL). Interestingly, his provided the same reason as FipS did.
32-bit Solaris had a struct FILE where the file descriptor was stored in a char. That's not the same thing, but it might lead someone to the impression only 256 descriptors were allowed. http://www.oracle.com/technetwork/server-storage/solaris10/stdio-256-136698.html
Some nitpicks: * strlen&amp;strcpy together seems suboptimal as the string is read twice. You could use eg. strncpy_s or strlcpy instead. * There probably should be a constructor that takes the length as a parameter instead of relying on null-termination (and thus avoiding yet another redundant strlen) * `String_buf(const String_buf&lt;M&gt; &amp;rhs)` could maybe use memcpy instead of strcpy * The constructors and =-operators have almost identical code, they should be refactored to use common functions * `_vsnprintf_s` probably is not portable. it probably should be ifdeffed out overall I'd re-evaluate every use of `strlen` and `strcpy`, and at least provide some kind of fast path (ie. `memcpy`) when the lengths are known.
Based on the description labeling it as for "cancer" and "heart" seems overly restrictive. I'm particularly interested in the ode functionality, anyone know how it compares to existing tools like odeint?
Agree. I went through a phase of using python for a lot of tasks, so when I was first learning boost I overused boost::tuple quite a lot. Then I realized that everything I was using tuples for would've been better handled with structs.
Thanks for you feedback, these are all good points. Please note that this is just a sample code demonstrating a general idea, rather than a fine-tuned implementation. It's definitely worth getting rid of the inefficiencies and especially the length taking CTOR brings a very important optimization. 
I dev in linux, but noticed this on the microsoft developer center. "In Windows 7, Beep was rewritten to pass the beep to the default sound device for the session. This is normally the sound card, except when run under Terminal Services, in which case the beep is rendered on the client." Perhaps messing with your sound card, default sound device, sound card drivers might result in better performance if you're using Win7?
`string_buf` is so much cleaner and is in keeping with the standard style of naming things. (ie. `random_device`).
If you're interested in messing with small sounds being created with c++, you should look up SFML-Audio, it's a cross platform audio library that brings an easy way to create your own beeps / tones. As others said I don't think Beep was written in a way for sound play, but this library will be able to. 
Interesting implementation but I am missing infinite ranges from it (which, admittedly, Python’s `range` also doesn’t have). [My own implementation](https://github.com/klmr/cpp11-range) diverges from Python’s syntax to allow this, and has an IMHO nicer syntax for arbitrary step size: // Note: infinite range, *starts* at 0 for (auto u : range(0u)) if (u == 3u) break; else cout &lt;&lt; u &lt;&lt; "\n"; for (auto c : range('c', 'a').step(-1)) cout &lt;&lt; c; What I find most important, though, is that the compiler compiles this down to machine code that is the same as for a traditional `for` loop – so this abstraction has *no* runtime overhead (the same is probably true for OP’s code as well).
I have always wanted a safe way to use alloca with fallback to heap allocation past a certain threshold; I know msvc provides malloca which does so, but it is not standard. I suppose macros are necessary since by definition you cannot simply alloca within another function (unless you can somehow rely on inlining, which is bad idea)
Suggestion for improvement would be to implement format using variadic templates to ensure type safety (could even use static_assert to reject non-formattable types). Although you're using MSVC, which doesn't support variadic templates yet.
Yeah, I actually agree with these points. I mostly liked Lecture 1 (Compilation Pipeline) slides, might be a good reference as a very basic, step-by-step, preprocessor-compiler-linker introduction (looking at it I've realized I might be going too fast just starting with `#include &lt;iostream&gt;` and the hello world program when explaining these topics): &lt;http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-s096-introduction-to-c-and-c-january-iap-2013/lectures-and-assignments/compilation-pipeline/&gt;
true i guess its difficult to find innovative computational projects to contribute to these days in C++ http://stellar.cct.lsu.edu/tag/hpx/ http://code.google.com/p/elemental/
This was posted on HN, and a lot of people were confused by the post. I'm going to try to short-circuit the same confusion here; wish me luck. A guy named 'rusty' used GCC 4.8 to compile binary X as C, and again as C++. He then ran both versions of binary X against input Y, and measured the difference between the C and C++ versions of binary X. He did multiple runs, trimmed outliers, etc, and got what appear to be good results. The difference was almost in the noise, with a tiny (under 1%, maybe as slight as .1%) advantage to the binary compiled as C. Here's what confused people: X was gcc 4.7, and Y was the linux kernel. The fact that there were two versions of GCC in play confused casual readers.
Well I think they made all the C compilable by a c++ compiler, so by default that makes it c++ now. :) 
Another reason why you want to overload operators could be a debug log. If you just use strings everything is fine, but for some stuff you need actual values to understand what's going on. Without overloading you have to create a buffer and use sprintf to convert them into a string and then write it to disk, it's super messy and annoying, especially because you have to remember all the flags and 'odd' behavior. For example you can't feed a string, you have to use string.c_str(); It's just no fun. With overloading you can create a class, that does everything for you (and more). I can simply write.. debug_log &lt;&lt; "file/function name(); count: " &lt;&lt; &lt;int&gt; &lt;&lt; " result:" &lt;&lt; &lt;bool&gt; &lt;&lt; "\n"; That makes debugging so much easier, even better I can write a DEBUG_LOG macro, which automatically defines "class_debug_log debug_log; debug_log ", so I can be even more lazy. Even better my debug_log builds the string, then automatically looks up the global file_log and writes the lines to disk, which is super important if you have to log stuff in a multithreaded mess like me, because you only want to 'lock' the file when you're writing the line to disk and not while you're building it (to avoid slowing things down and because there's no easy way to automatically use a critical section).
Thanks for your helpful input.
Sadly, It seems to me that this can't be easily achieved. I think it's all about narrowing the use case. std::string works perfectly when you accept the fact that it allocates dynamically (usually from the heap), which is a fair requirement most of the time. On the other hand, C++ (thankfully) offers huge optimization opportunities in situations when you know the context well and are willing to accept some constrains. Sometimes it's viable to adapt standard components by e.g. providing a custom stack-based allocator, sometimes it's just not worth the effort... It all depends on the kind of applications you write.
Yeah, I quite like the ideal. The closest portable approximation to this I've seen so far is Chromium's stack-based allocator (http://src.chromium.org/viewvc/chrome/trunk/src/base/containers/stack_container.h?view=markup). There's a slight inconvenience with custom allocators though. Default std::string &amp; a std::string parametrized by a custom allocator are two distinct types, which complicates passing that strings around within a single system.
I happened across this a long while ago and could not recall what project or where I found it. Thanks a bunch for the link. The specialization issue with std::string is annoying; honestly sometimes I prefer the ATL/MFC CString due to things like this (and the memory layout equivalent to a char*/wchar_t*)
Have you googled yet? I googled for 2 minutes and found some tutorials, but they're not focused on visual studio. http://aneelkkhatri.wordpress.com/2011/06/14/setting-up-box2d-library-in-visual-studio-c/ this one does but does not really teach you anything except 'follow these steps', and it might be slightly different for vs2012.
To be fair, it's near impossible to demonstrate why RAII is a good thing, without first showing the infrastructure. I'd hope it quickly dives into showing "best" practices. A lot of the C++ developers I've worked with don't understand how it works, and is implemented. Few of them understand the difference between, say: std::string s; and std::string s = ""; and how the second generates for less efficient code. Trivial yes, end result is the same, but two equally equivalent constructs generate extremely different code. (Hint, the first construct results two instructions under g++ w/ -O2, two movq's on x86_64, the second generates numerous function calls and stack manipulation). Point is: it is worth and very valuable to understand how and why things work they do. And to demonstrate that, you need to start at the basics. Mind you, I very, very write C++ code that requires an explicit delete.
Have you looked at automake, cmake, premake and similar tools?
Using `shell find` to discover the list of source file dependencies means that if I delete a .cpp and .hpp file and recompile, it won't rebuild the executable. Is that okay?
wait, i dont understand. in that case, won't it not be returned in shell find, and so not included in the dependency list? seems like it would work fine...
The dependency list will change, but none of the entries in the list will be out of date. You don't depend on the list itself so you won't rebuild the output. For C++ this will result in strange behaviour for global constructors/destructors in that your code will still be run.
Probably worth including a couple of other globs in your find patterns. Particularly "*.h" for header files, as not all C++ headers use hpp, but I've also seen at least .cc and .C in the wild used to mean C++. Of course, for your own use, it only needs to match your convention.
Who cares? The variables `PRIMARY_HEADER_FILES` and `TESTING_HEADER_FILES` are not used anywhere.
The biggest thing you're lacking is dependency tracking. If you change a header file your sources depend on, nothing will recompile properly. Luckily, every decent compiler can handle this for you. I'll just give a quick example: $(PRIMARY_OBJECT_DIR)/%.o: $(PRIMARY_SOURCE_DIR)/%.cpp $(CXX) $(PRIMARY_CXXFLAGS) -c -o $@ $&lt; -MMD -MT $@ -MF $(patsubst $(PRIMARY_SOURCE_DIR)/%,$(PRIMARY_DEP_DIR)/%.dep,$&lt;)) That will generate a bunch of rule targets for your source files. Then, you can use the [`include`](http://www.gnu.org/software/make/manual/make.html#Include) directive to grab all of them. If you're lazy, use `find`, but that will cause a problem if you delete a source file. $(foreach x,$(patsubst $(PRIMARY_SOURCE_DIR)/%,$(PRIMARY_DEP_DIR),$(PRIMARY_SOURCE_FILES)), $(eval -include $(x)) ) Anyway, you're repeating these rule patterns for both primary and test -- I'd recommend a quick look at using `define`s with `eval` as a [template](http://www.gnu.org/software/make/manual/make.html#Eval-Function). But overall, good start! --- Oh...why is `main.cpp` given special treatment? It is a source file like everything else. A binary is made by linking all the object files together, regardless of what their name is. Get this right now and it will save you many headaches.
I didn't even read it that closely. I just saw the wildcards and that stood out to me.
&gt; Point is: it is worth and very valuable to understand how and why things work they do. Yes. &gt; And to demonstrate that, you need to start at the basics. No. It’s pretty firmly established that top-down is a more effective teaching method than bottom-up. Bogging students down in details from the start is discouraging and results in rote learning rather than understanding (even though that’s the goal) because the students cannot yet make the necessary connections – and *understanding is all about making connections*. Giving them a big picture and high-level tools first means that (a) they make faster progress which is motivating, and (b) they get the necessary overview to draw subsequently connections between low-level details.
Whoa you're really trying this aren't you?
All of the characters from id's games, Doom, Quake, etc... They do use C++ since DooM 3 after all, and somehow I feel like those are some of the most badass uses of C/C++ ever...
&gt; I thought it was fairly obvious this was about measuring compilation times, not speed of compiled binaries. He is measuring the speed of compiled binaries, which happens to be compilation times because he is measuring the speed of a compiler. He takes gcc 4.7, and compiles it as c++ and c. He then uses those compilers to compile the linux kernel, and compares how fast they compile it.
yup, and not only c++, math as well: http://en.wikipedia.org/wiki/Fast_inverse_square_root
Ah yeah, that too.
Oh Danny Boy, the pipes, the pipes are calling... from `sed` to `grep`, and down the mountain-side...
I seem to be missing the actual model. It seems like it's just a proposal to write a compiler tool that may be useful.
i regret clicking on that link
I too wish I could up vote this simple article more. I just turfed my BOOST_FOREACH for your for(x:v); very nice. I did know not to run a function every time but after all this C++ time I never thought of putting the size variable in with the for declaration as in my old with your new: int size=v.size(); for(int i=0;i&lt;size;i++)... to for(int i=0, size=v.size();i&lt;size;i++)... Thanks a tonne 
The article contains a nice overview of memory management in C and C++. However it completely fails to mention RAII and smart pointers, in particular std::unique_ptr and std::shared_ptr. These form the current state of the art in memory management in C++ so it would have been informative to compare them with the proposal. 
What does the standard guarantee on size() for a vector? http://en.cppreference.com/w/cpp/container/vector/size that says constant, but my memory says it wasn't at some point. Anyways my point is that is a bit of a trivial example for the point that is trying to be made. I am also on the fence about it, not sure if it is something I would take issue with until I needed to, but I guess the trend in generic code is moving that way by using non membered begin and end really anyways. 
vector size() has always been guaranteed constant. You're thinking of list size(), which could be linear in C++98/03 but is constant in C++11.
I wouldn't use an int as an index, the article used unsigned which is 'OK, but size_t it preferential in every-way.
Yes, it's way faster. Allocating on the stack basically means just moving the stack pointer up and down, while the heap allocation requires searching for a free block, which tends to be quite complex. Actually, the heap allocation is one of a few unpredictable operations in C++, so it's very often unacceptable in realtime applications, or more precisely within realtime/interactive loops. Extensive use of the heap allocator might also lead to heap fragmentation over time, which causes innefective memory utilization and might eventually cause the application to crash. It's also worth mentioning that a general heap allocator is shared between threads, thus needs to be thread-safe, which is not the case when allocating from the stack, as each thread has its own stack.
lern hau two engilsh
&gt; create a parameterized function where the details are passed in as a function to call. Its called a higher order function.
Am I missing anything or is it really misleading that they mention buffer overflows in the problem description and then describe a solution that cannot have any impact on buffer overflows? Also, this model is great for programs where the responsiblity is static, but not when it's dynamic. For example, what if you have an array of pointers used as a LIFO, where inserting an item involves a malloc and deleting an item involves a free. In this situation you have a counter that makes sure that memory allocation and freeing is done correctly. Now the static analysis would have to find out about this pointer and make sure that thishandling is done correctly everywhere. I very much doubt, that this is the case. There are a million of other possibilities where this approach can't work. All in all it is a very limited approach that can only handle the simplest of all cases. For every new program it certainly makes most sense to use an automatic pointer type (in C++). If you have to use C, then just don't make any mistakes :)
Ah yes. For anyone confused / getting their hopes up, there is no MIR code here. Just boost-like utilities.
You are right i was, I am not even sure how a vector would work if it wasn't tracking its size.
First and foremost, code in the book should rely on standard C++ libraries, not POSIX or Win32 libraries. C++11 features to include: * type inference -- especially 'auto' * nullptr (don't even introduce NULL) * range-based for loop * Initialization lists / uniform initialization * std::array (introduce this prior to C arrays) * strongly typed enums (personally, I'd introduce the strongly-typed enums prior to the weakly-typed enums, but that is just me) * hash containers * lambda expressions - these need to be introduced to make &lt;algorithm&gt; easy to use. * smart pointers - especially unique_ptr (the first time 'new' is introduced, it should be introduced with unique_ptr. New C++ students should associate new with unique_ptr instead of delete) * Late in the book: rule of 5 (instead of the rule of 3) * If you get to threads, use the C++11 threading and synchronizations features (not POSIX API) * static_assert * If time permits or features are needed: &lt;random&gt;, &lt;tuple&gt;, &lt;regex&gt;
You might want to check out this blog post, which shows an [alternate implementation](http://preney.ca/paul/archives/934). Last year Paul Preney (the author of the post I am linking) and myself had a race to see who could develop the most optimal implementation of apply_tuple. He used more template meta-programming to generate lists of indices and unravel the tuple in one shot, while I took your approach with recursive calls and perfect argument forwarding. While the runtime overhead of both solutions was effectively zero (the cost of calling the function with the arguments directly unpacked in assembler) his code compiled faster :( EDIT: I loved the writeup btw. Maybe with enough separate implementations we can make a proposal for the next C++ standard: more tuple manipulators.
Also: when using class templates you should always use this-&gt;, lest you be bitten by C++'s two-phase name lookup.
Very interesting! I've never thought of using the pack expansion mechanic quite like that. I actually was really curious on why one way might be faster than another. I wrote my own form of the indices expansion, and ran some numbers on all three (my original, my indices version, and his). What I found was that for a single function application, all three compiled at about the same speed -- for a size 64 tuple, it was around 7 seconds. But the more applyTuple's you throw out with different functions, you effectively have to do the recursive per each call -- unless you use the indices version from his blog, which defines the recursive struct independently of anything but the indices themselves. It seems both GCC and clang will simply reuse the indices struct, while for the recursive types with the functor type mixed in, they cant. I usually design complicated structures like this for readability/verbosity, mostly under the impression that all templated structs would take around the same time to compile. The fact though that one version is constant and the other grows linearly though is an excellent point to keep in mind, and a design consideration I'm going to start incorporating into my own work. And I hope they do add some more tuple manipulators, at least the apply function. The head/tail/print stuff is nice to have, but apply is at least as big an enabler as something like std::tie, and in my view bigger. 
C++ desperately needs a standard databases access library. SOCI is one of very few open source db access c++ libraries. I hope it will show up in boost very soon. The language is 33 years old and still no standard way to query a relational database. Just about every other major and minor language that came after C++ allows you work with databases in a standard way. Even a 4 year old [Go](http://golang.org/pkg/database/) has database access
Some of this is awful. The C++ standard shouldn't be a dumping ground for everybody's pet library (like boost is now). 
There were some pretty nice updates that came with C++11. I don't see anything spectacular here.
Mhm, when you separate components and use C++11 features, template meta-programs actually compile pretty quickly. In our lab at the University of Windsor Paul and myself tend to do a lot of this kind of stuff - we were breaking GCC every week during 4.7 and 4.8 development! We have a few hand-rolled libraries that act like some from boost (variant, any, etc) and taking advantage of things like variadics et al and foregoing older compilers, we see huge speed improvements. 
It is an interesting point, I think databases are generally seen as out of the scope of the standard library, there are so many ways in which they can be implemented and they almost all exclusive have major compromises here and there. I would be happy with a 3rd party library, I just wish there was one a universal as say the boost library written in modern straight C++.
C++11 was eight years after the last version. C++14 is only three years after. It won't be as big. The big changes are being planned for C++17.
I wrote some classes to wrap ODBC for work. I could easily publish some code on github if there is some interest, but to be honest it's the kind of project that needs plenty of user feedback. Let me know if there is any interest, because the code is the easy part!
C++14 is more a bug fix release, fixing some issues with and improving C++11. Also some new libraries might be added, C++17 will be the next big change to the standard then. At least that is the plan...
Personally, I'm really looking forward to N3542 - Proposal for Unbounded-Precision Integer type. Support for arbitrarily large integers is long overdue.
end1 is actually endl
That was my bad, it was actually endl in the program. Still looking at multiple build errors.
You should post the errors.
not sure what happened there, I typed #. Again with the typos on my part. maybe it's just operator error here, but it doesn't seem to show what the errors are. All it says about them is that they exist. 
Sorry, didn't copy the include &lt;iostream&gt; but I included it.
These are proposals not what has been accepted. 
Also fantastic username. 
http://liveworkspace.org/code/2SfQOM$0 Compilation finished with warnings: source.cpp: In function 'int main()': source.cpp:13:24: warning: right operand of comma operator has no effect [-Wunused-value] cin &gt;&gt; weight, height, age; ^ source.cpp:13:27: warning: right operand of comma operator has no effect [-Wunused-value] cin &gt;&gt; weight, height, age; ^ source.cpp:25:40: warning: 'height' is used uninitialized in this function [-Wuninitialized] return (static_cast&lt;double&gt;(weight)/height) * 2.9; ^ source.cpp:10:13: note: 'height' was declared here int weight, height, age; ^ source.cpp:30:46: warning: 'age' is used uninitialized in this function [-Wuninitialized] return ((height/weight) * 288) + (((age) - 30)/10) * 0.125; ^ source.cpp:10:21: note: 'age' was declared here int weight, height, age; ^ Note: `&gt;&gt;` is left-associative (groups-from-the-left) which means you can use `std::cin &gt;&gt; a &gt;&gt; b &gt;&gt; c` which is equivalent to `(std::cin &gt;&gt; a) &gt;&gt; b &gt;&gt; c` which is equivalent to `((std::cin &gt;&gt; a) &gt;&gt; b) &gt;&gt; c` which is equivalent to `(((std::cin &gt;&gt; a) &gt;&gt; b) &gt;&gt; c)` Explanation: You used the comma operator `,` -- it is meant to be used for grouping multiple statements http://en.cppreference.com/w/cpp/language/operator_other#Built-in_comma_operator `,` is also left-associative (groups-from-the-left) which means `std::cin &gt;&gt; a , b , c` is equivalent to `(std::cin &gt;&gt; a) , b , c` is equivalent to `((std::cin &gt;&gt; a) , b) , c` is equivalent to `(((std::cin &gt;&gt; a) , b) , c)` i.e., read `a` (more precisely: evaluate `(std::cin &gt;&gt; a)` and discard the result) do nothing with `b` (more precisely: evaluate and discard `b`) do nothing with `c` (more precisely: evaluate and discard `c`) 
Follow this tutorial: http://freakify.com/how-to-use-visual-studio-2008-for-c-oop/
(Why aren't you using something like boost asio?)
I guess I will need to read the discussion but this article doesn't seem to give any reasons how the parallelism in the language would be better than OpenMP. No need to include it if it will just do the same things openMP already does. I hope they have some reasons it would be better.
No, static_cast is used for almost anything that would have traditionally used a regular C-style cast (using parens). In other words, casting between types. He's using it correctly there. 
initialize age, height, and weight to values and then assign? 
Thank you for the amazing response! The link to details on the comma operator is really interesting. I never would've imagined to go looking for further details about how that functions.
They actually have removed a few features in the past: some usages of the original meaning of auto (no one used it), std::auto_ptr (horribly broken for many uses), export (most compilers didn't even implement it and it wasn't very useful anyway).
There ought to be a window down at the the bottom that contains the build output, and that should list the specific errors that the compiler output. You can usually double-click the error lines to jump to that section of the code. The only error gcc gives me is that main() needs to return int, not void. I'll try VS2010 in a minute and update with what I see there. edit: VS2010 allows main to be void. If I use the code as posted though, I get this: 1&gt;c:\users\&lt;me&gt;\documents\visual studio 2010\projects\hello world\hello world\hello world.cpp(14): warning C4627: '#include &lt;iostream&gt;': skipped when looking for precompiled header use 1&gt; Add directive to 'StdAfx.h' or rebuild precompiled header 1&gt;c:\users\&lt;me&gt;\documents\visual studio 2010\projects\hello world\hello world\hello world.cpp(19): fatal error C1010: unexpected end of file while looking for precompiled header. Did you forget to add '#include "StdAfx.h"' to your source? 1&gt; 1&gt;Build FAILED. The error is extremely clear. Add `#include "StdAfx.h"` to the file.
auto_ptr wasn't removed so much as replaced with unique_ptr &amp; shared_ptr/weak_ptr.
so we shouldn't use ram because we can end up thrashing. We shouldn't use processors with caches because we don't know when there will be a cache miss......yeah....99.9% of the amazing performance boosts we get are because of those. With optimization comes specialization and complexity - there's no way around it.
Would you consider the Java Standard Libraries a dumping ground?
You know, I'm just not familiar enough with Java to be able to answer that.
auto_ptr is still Standard, but deprecated. export and old auto were nuked outright.
Unfortunately, drdobbs.com seems to have been down for me the last few hours, so I've not an opportunity to actually read the article.
I was thinking the exact same thing. You can't optimize non-discretely when you're working with the hardware. You optimize for the largest set of cases that may make your code run slowly. Whoever's in charge of optimizing a program that may be making use of that allocator he described would need to tune the arbitrary threshold so that it makes sense for the program at hand. Different programs would need different thresholds. Sometimes, the optimization would also need to be moved higher and an attempt may be necessary to shrink down the size of the blocks someone is trying to allocate so that they fit under the arbitrary limit without needing to bump up the number.
How do i make a proposal?
I am not overly familiar with the tool itself, I tried the demo once a long time ago. But the idea of comparing old and new bugs is kind of interesting to me. Is there an easy way to do this, would be cool if I could point it a source control and have it generate changes over time of bugs and complexity etc. maybe there is other tools for this ones that work with CI, not really my area. Side note when I tried it it failed to find the bug, it did find others, but not the one we were looking for. We had a for loop using and array index and it was checking a[i] for null before checking if i was a valid range.
"Code logic contradicting code formatting" - who the hell writes multiple statements separated by semicolons on a single line like that?
May can't come soon enough. I have mine pre-ordered through amazon.
The process to make a proposal is documented at isocpp.org: http://isocpp.org/std/submit-a-proposal
Let's just say they have BigInt, which is for arbitrary length integers, synchronized containers, which is their name for thread safe stuff, a GUI library, parsers, serializers, sockets, http, ftp... A more experienced java developer could probably list more stuff here, but the point is that in Java, as opposed to C/C++, you will probably find everything other than your application's specific logic in the standard library. One of the advantages this gives is that your new team members don't need to spend a ton of time learning the specific libraries your project uses for basic stuff like XML parsing.
I believe `std::any` is on track for C++14 as well. http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2013/n3508.html undiscriminated unions in C++11 also make it pretty trivial to write something as convenient as `boost::variant`.
Welcome to smaller, but more frequent, release iterations. Baby steps in the right direction versus the colossal leap between C++98 and C++11. Seems like a good idea to me.
Have you looked at boost spirit? It's not easy to learn but well worth it once you have. http://www.boost.org/doc/libs/1_53_0/libs/spirit/doc/html This example at the bottom show parsing comma separated numbers directly into a vector. http://www.boost.org/doc/libs/1_53_0/libs/spirit/doc/html/spirit/qi/reference/operator/list.html
Also, regex iterators are less powerful but easier to learn.
You could use [Boost.Tokenizer](http://www.boost.org/doc/libs/1_53_0/libs/tokenizer/) with an [escaped list separator](http://www.boost.org/doc/libs/1_53_0/libs/tokenizer/escaped_list_separator.htm).
How about something from here: http://www.codeproject.com/KB/recipes/Tokenizer.aspx
Indeed, although I tend to use spirit over regex when ever I know the form of what I am supposed to be parsing ahead of time. Using regex for cases where the actual form is to be decided at runtime such as user provided patterns.
This is the official issues list, just presented in a different way. BTW, there is also http://wg21.cmeerw.net/lwg/ and http://wg21.cmeerw.net/ewg/ for Library and Evolution Working Group Issues... Enjoy if you prefer this format to the official big HTML files...
stupid sensationalist lame headline. immoral? no. unwise? sometimes maybe.
This is awesome, thanks! See you in April...
Having now had an opportunity to read the article, I would say no, optimization is not immoral, provided you've done the legwork pre and post-work to justify the effort. I've fought with coworkers about simple things about how to initialize an empty std::string. Why? Because there's a huge difference in the code emitted between doing 'std::string foo;' versus 'std::string foo("");'. Using the default constructor versus a literal "empty" string generally uses half of the number of instructions and far fewer memory operations than the literal. No one believes me, until I show them the assembly. I'm talking GCC, various versions between 4.1.x and 4.7.x, they all show the same behavior: the default constructor is inherently more efficient. Granted, this could be conceived as a micro-optimization, but if you're seeing this same pattern over, and over and over again in objects that are allocated in the millions range, it's an issue. And it's absurdly simple to prevent (and generally less typing!).
When in doubt: profile.
I've been using CxxTest and CDash for testing and coverage and just simple CMake for building.
It's fine. We usually use a tmpfs mount on the build folder so linking time is none. I don't like how CxxTest makes many binaries but we are working on reducing that.
It is received wisdom that top-down teaching is superior and yet we have a generation that don't even know what the stack is. Having experienced the result of Java being the language of choice for academia, I have to disagree with this sentiment (I realise that's taking the idea a bit further, but still). This doesn't mean that I approve of a C with classes 90s style book either. I think at least one chapter should be devoted to basics like the stack and heap along with manual memory management and then quickly move on to showing how smart pointers work/how to use them and RAII in general. It is a common mistake in this business to think that the old ways can be swept away entirely and this is a big mistake. Taking that approach just breeds ignorance. It is fair enough to de-emphasise things, but there is still a place for even the K&amp;R C Programming Language book on every programmers bookshelf in my opinion.
Yes I know, although auto_ptr (as others have mentioned) is depricated not removed, and it has a replacement (unique_ptr) so actually the library is overall bigger. No one ever used auto so it's existance was never really a problem, although I am a big fan of it's new meaning. And as you said, most compilers hadn't even implemented export. Non of these things really helped to drastically simplify the language, which would be point of removing features.
Hmm I've been declaring them out of habit just so I have a breakpoint area in visual studio. Guess thats pointless now.
* [googlemock](https://code.google.com/p/googlemock/) * [googletest](https://code.google.com/p/googletest/) * cmake using [ninja](http://martine.github.com/ninja/manual.html) * [clang-analyzer] (http://clang-analyzer.llvm.org/) 
I always find it difficult to remember these rules of when constructors are and are not generated, so I came up with an easier rule: if I declare any constructor or assignment operator, I declare all of them, either with bodies or with `=default/delete`. That way, it's explicit which functions do and do not exist.
&gt;Especially since visual studios create class Whooa. So people actually use those things? That aside, defining empty destructor/constructor is usefull (or required) at times - it can be used to prevent excessive inlining and ensure that you are deleting complete types. 
There's one time when you need to define a destructor: when you're making a base class its destructor needs to be virtual. You can do this: virtual ~MyClass() = default; ... Will defining it that way allow the compiler to automatically generate moves? Or is it necessary to also declare those explicitly as default? MyClass(MyClass &amp;&amp;) = default; MyClass &amp;operator = (MyClass &amp;&amp;) = default; I guess the goal is for it to become common practice to always declare the "Big 5" explicitly and either mark them `default` or `deleted` as the case may be? 
Having to implement five methods before you start? That's a lot of baggage for each and every class! 
Boost test seems to be the as good as any and if you are using boost anyway it makes a lot of sense..
There's also another case where the compiler even forces you to define a destructor. If you use a Pimpl with forward declaration and `std::unique_ptr` like this: class MyClass { private: struct Implementation; std::unique_ptr&lt;Implementation&gt; impl_; }; The above won't compile until you add an explicit destructor declaration: class MyClass { public: ~MyClass(); private: struct Implementation; std::unique_ptr&lt;Implementation&gt; impl_; }; 
&gt; There's one time when you need to define a destructor: when you're making a base class its destructor needs to be virtual. That's not true. Many coding standards say that you need a virtual destructor for all classes that have virtual members. Even that is not true. You only need to have a virtual destructor, if destruction happens in a polymorphic context. There are cases where you use polymorphism, but destruction is not polymorphic. Moreover, if you use the new smart-pointers of C++11 you don't need a virtual destructor at all (they use type erasure to call the right destructor).
I do because it creates the files and adds them to the project. Of course, I follow that by deleting most of the stuff that Visual Studio generates. But hey, it's still faster than creating and adding two files manually.
Type erasure with smart pointers has its limits... there are plenty of ways to construct or .reset() a smart pointer without providing the necessary type information for type-erasure to work. Sure there are special cases where you don't need a virtual dtor. But those are all special cases which leave your class open to unpredictable failures unless it provides copious documentation and other programmers read that documentation before using it.
 unless of course your Implementation is known at all places where the MyClass is used - admittedly, not useful for Pimpl. The compiler has to be able to generate a destructor body at the place your class is used if you don't declare your own, so it'll have to know the contents &amp; how to destroy them.
How about a PDF warning, smart guy?
Ah, I'm guessing you must be browsing without [NoScript](http://noscript.net/) or equivalent. I can only assume adventurous folks like you don't mind websites automatically loading PDF plug-ins on page load either way, otherwise you'd configure your browser :-)
&gt; Setting variables to base values etc. Not sure if you knew this, but you can do this at the declaration now. Makes everything look much cleaner IMHO. 
Perhaps it means that they do include the header as part of the translation unit but then don't report any SA violations that are found within those headers?
While I don't think we'll get to all of these (as you wrote), these are great suggestions! Stay tuned - we're set to write this weekend!
I'm looking forward to it! :)
If you use make_shared(), you are fine. That is not a special case, it should be the norm for shared_ptr uses.
so if i am understanding correctly it's to facilitate the possible extension/inheritance of Class B by some other class and to override Class B's functions? In that case, say Class C : public B { void f() {...} }; what is `C* c = new A(); (B)c-&gt;f();` doing? Polymorphism always throws me for a loop. Or did I make that declaration complete bass-ackwards?
for (auto i = dwa.GetSize(); i--; )
~~That's problematic with unsigned types (endless loops)~~, plus you are iterating in a different order (though that's irrelevant in most cases). Edit: Strikethrough, see below. 
It will eventually end. Has to hit zero sometime. (yeah yeah... heat death of the universe and all... buy a faster proc)
&gt;For backward compatibility 0 is still a valid null pointer value. Not everywhere. I could have sworn that the change to nullptr from NULL was purely for some extra type checking as well as to try and get people out of the habit of thinking that NULL == 0 on every system that you are on. EDIT: in trying to find a reference, I may need to back out my claim... http://c-faq.com/null/nullor0.html EDIT 2: Yup, I'm going to retract my statement. Some machines/systems have non-zero NULL values, but the compiler needs to sort that shit out itself. http://bytes.com/topic/c/answers/223220-references-machines-where-null-not-zero http://blogs.msdn.com/b/oldnewthing/archive/2013/03/28/10405881.aspx
+10
Except, NULL prefers to be interpreted as an integer. This is important in overload resolution. void foo(int) { std::cout &lt;&lt; "bar" &lt;&lt; std::endl; } void foo(void*) { std::cout &lt;&lt; "qax" &lt;&lt; std::endl; } // ... int main() { foo(NULL); // prints "bar" foo(nullptr); // prints "qax" } 
Yeah, that's the type checking that I was referring to.
What I meant was that the variable i always will be inferred to be int, because the type deduction inspects the literal 0, not the conditional. Even if i would be compared to, say, an std container's size() returning some (unsigned) size_t, it would still by an int (and that's wrong in signedness and possibly range).
&gt; What's the purpose of the subclass methods also being virtual? They are virtual regardless of whether you wrote `virtual` in the declaration -- any member function that matches the signature of an inherited virtual member function is by definition also virtual. Being explicit helps other programmers who are reading your code, by reminding them of the fact that this is a virtual function. 
That will not work; an 'A' is not a 'C'.
&gt; The C++ bindings were (intentionally) a more-or-less 1:1 mapping to the C bindings. Geez, why bother in the first place. Good riddance then I suppose.
this is why poly always gives me trouble thought it would work because a C is a B and B is an A so C should have everything that make an A an A so why can't C be an A?
ah, cool, thanks
Thankfully, there's a modern replacement: http://blogs.cisco.com/performance/i-can-has-mpi/
Critique ~~welcome~~ wanted.
That's backwards. C converts to A, but A doesn't convert to C. Otherwise you could have `class D : public A` and then do C *c=(A *)new D(); Which would be wrong.
Huh, glad to see ReactOS is not dead!
Guh, I really don't like the look of those "if for" blocks in N3587. It seems like it would be really really easy for a human reader to mistake the unlabelled "then" block for just some random nameless block.
About the "Concepts lite" proposal, a.k.a. constraints, why do you say it won't be in C++14? They (i.e. the members of the Study Group for concepts, SG8) seem to be heading for this timeframe, see the minutes of their last teleconference, [N3576](http://isocpp.org/files/papers/N3576.pdf). [Edit: spelling.]
Well, thats a nice goal, and would be cool if it happend. Just its not stated in the paper. But the goal of C++14 - as I understand it, is not to change the language such deeply. I also asked Michael Wong if this has a chance of being accepted to C++14, and his opinion is that it is too complex, so most likely C++17 will have full constraint/concepts lite support. Thats why I'm saying that it might not be part of C++14. Maybe this will be more clear after Bristol. And I didn't read yet through those Meeting Minute papers, its interesting that they aim for C++14 or shortly after. And want to ship a constrainted STL with C++17. 
didnt know about this, but looks really cool. Especially the chromatography application, its freaking awesome. im saving this for later.
If you don't add `virtual` to `B::f`'s declaration, then another class that derives `B` can't **virtually** override `B::f`. They can, however, still declare a non-virtual function with the same prototype as `B::f`. This will compile just fine (you might get a warning if you're lucky), but can create strange behavior at run-time if calling member functions through a pointer-to-base. You can make this more explicit and move the errors to compile-time (and provide more self-documentation) by adding a `final` specifier to `B::f` if you don't want a subclass to override that function. By using `final`, a subclass of `B` will fail to compile if it attempts to override `B::f`; also, the strange run-time behavior goes away. Note: `final` is a part of C++11 and is not available in all compilers (namely Visual Studio 2010).
It would also break a lot of existing code. I hope it gets rejected. Also, it's the complete opposite of python's for, then. It's a BadThing™ to do that in languages that are used together more often than not.
I don't think it would, "if for (something; something; something)" is not valid syntax at present, so nobody would have written it, and therefore that second block would never be treated as the "then" block.
The thenless version is incredibly awful, but with the 'then' I'm a fan of the proposal, since the thing it's fixing really is pretty awkward currently.
Yeah, the "then" keyword seems OK. It reminds me a little bit of of try/catch/finally in Java.
I really like Intellij for Java development. I would even use Java instead of C++ because of IDEA.
As mentioned in a previous thread (cppcheck update), until such applications (including cdt, qt creator et al) use clang as their backend for intellisense/code navigation/analysis/refactoring etc, they will be utterly useless. The cscope days are over wrt C++11, you just can't do simple string matching anymore, it wont work, the rules are just far too complicated for that kind of approach. Any IDE wanting to support modern C++ codebases will require at the very least a halfway compiler to do anything of real value. 
It'd be nice for N3594 to support "standard" begin &amp; end iterator arguments, as well as the new ranges.
Personally, I've felt that the MPI C++ bindings were less than useful from the start as it was largely just a shuffling of the C library bindings into an MPI namespace. Since C++ essentially has C as a subset, merely shuffling functions into a namespace and slightly renaming them without improving them to exploit C++ language features and idioms was clearly a waste of time and effort. Everyone coding in C++ knows that unless you use C++ language features to make it easier and better to code using C++ --one should just use the C APIs! Thus, the MPI Forum should not be surprised at any apparent the lack of usage and interest. Realistically people wanting C++ to be used with MPI either rolled their own specific-to-task designs and/or used Boost.MPI --after being puzzled/disgusted with the MPI Forum's bindings.
They are actually using Clang: &gt; The IDE will be integrated with Clang Analyzer, so that more than 2000 code inspections and error diagnostics results from Clang compiler would be shown right in the editor.
This is great news. IntelliJ is such a joy to use; I can't wait to be able to use it for my C++ work as well.
&gt; defining empty destructor/constructor is usefull (or required) at times - it can be used to prevent excessive inlining and ensure that you are deleting complete types. Defining an empty destructor is never a good idea, unless it's required. And the only time it (used to be) required is when you write a base class with a virtual (pure or otherwise) destructor. C++11 introduced the `default` qualifier here, so even then you can do without the empty braces. I don't know what you mean by "prevent excessive inlining". The compiler usually knows better than you when to inline and when not to. Sometimes a profiler knows better than a compiler, but you rarely if ever know better than either. So by default this is not a good reason to throw in an empty destructor. The deletion of incomplete types might sound like a good argument, but then I'd argue if you're deleting to begin with you're probably doing something else wrong. Don't delete. Don't even use a pointer if you can avoid that, but if you must, and you need that pointer ultimately freed, use a smart pointer. Back to where we started: no need for a destructor, empty or otherwise. A good C++ codebase has few destructors. A class needs a destructor only if it manages a resource. Most non-trivial codebases have relatively few resources compared to the logic that manipulates the resources. Generally, if you can avoid or remove a line of code, do. Even if with and without the line you get the exact same object code down to the last bit, less code generally means less complexity.
Awesome!!! ++++ 
me too...
Does that mean using Clang for autocomplete? (Including templates etc.) If so this is very interesting to me.
Well the blurb on their page talks about static analysis type of features. However from experience, once one starts parsing the clang-sa output, it's only a few more hours before one begins wanting to traverse the AST, which really only requires registering callbacks on things your interested in (when a new class/struct/function/typedef/auto etc is encountered), all the interesting information like line numbers, file names etc is available via the node passed via callback. This scan operation in conjunction with a well designed source code indexing structure, one assumes the likes of IntelliJ have already developed, will be more than enough to work through most modern c++ codebases. An example of such synergy is the tool CPPDepend. 
Or just spend an hour writing a fstring&lt;N&gt; wrapper around a std::array&lt;char, N&gt; and use a nice c++ class from then onward.
I was about to cheer. Stop using outdated, insecure, C-style functions. Totally on board! But then I run across this: &gt; The solution is… &gt; `strcpy_safe(buffer, “Thisisalongstring”);` What? &gt; Yes, to be clear, I am aware of the existence of std::string. For better or for worse most game developers try to avoid dynamically allocated memory and std::string generally implies just that. There are (somewhat) valid reasons to use string buffers, even if those valid reasons are just that you've been handed a million lines of legacy code with security and reliability problems in all directions. &amp;#3232;\_&amp;#3232; This reeks of micro-optimization. There is a reason std::string contains a resize() method if a programmer wants to set the string capacity, and this is as good as any reason to *employ* it.
Two of the slowest things you can do are 1) allocate memory and 2) dereference a pointer. std::string, by its nature, needs to do both. A string array on the stack, or in a structure, can be orders of magnitude more efficient. Often that doesn't matter, but there are domains where it does. The legacy problem is also real. I can make a code base much more robust with no regressions with s/strcpy/strcpy_safe/, and switching to std::string is a much bigger job.
Depends on how large the string will be. In the case of large strings, the stack wont help much either, you'll need to use the heap. In the case of short strings, most decent std::string implementations use SBO, which gets rid of the need for new/free.
I meant calling resize() *once* to set the size of the string up front as opposed to multiple times every time the data needs changes. I agree there are times when the direct use of std::string is inefficient, but I would argue that game development has few, if any, of those instances. I would also say an alias template around an std::array&lt;char&gt; would be sufficient to mitigate those inefficiencies. Legacy code *is* a bite-the-bullet sort of a problem.
Those programmers that insist in doing C style programming in C++.
Fully agree. Developers with C background seem to be infested with a virus where they known better than a code profiler. My golden rule is to only optimize code if the profiler shows there is a problem for the current application.
Sometimes it's really hard to avoid, but everyone should at least be aware that any solution that involves chopping longs strings to an arbitrary buffer size can be problematic. In the least-harmful case, it's a potential source of user data loss, which is a bad thing. It the worst case, it can even still be a security problem: for example, chopping a string with a path from "longfilename.exe.jpg" to "longfilename.exe" would be a bad thing. You can also imagine abuse string truncation in paths to write files to the 'wrong' location, or overwriting existing files. 
&gt; For better or for worse most game developers try to avoid dynamically allocated memory and std::string generally implies just that And for just about everyone else, stick with std::string. Or at least stick to good C++ design principles and write non allocating `std::string`-a-likes exactly like what LLVM &amp; boost have done with `string_ref`; using array primitives for strings is just shitty design in my book. http://www.boost.org/doc/libs/1_53_0/libs/utility/doc/html/string_ref.html http://llvm.org/docs/doxygen/html/classllvm_1_1StringRef.html
&gt; Besides those who have to deal with legacy code or embedded systems? I kinda think that's most C++ programmers at large companies.
I've been using their RubyMine IDE when I do Ruby development, and it's the only IDE I could consider to be better than Visual Studio in terms of available features. I think Visual Studio is the best *C++* IDE at the moment, so it will be very interesting to see a C++ IDE from JetBrains - especially considering that they plan to make it cross-platform. 
I am right there with you, although not for performance reasons, that's just a handy side effect. I just find people who do `std::string s="";` and similar do it simply because they do not know the C++ constructions rules well, this typically also means they aren't aware of other things like default constructors and destructor and when something is and ins't initialised. Generally "as little as needed" types. It's the gap in their knowledge, and an unwillingness to autonomously plug it, that bothers me.
Mea culpa, I missed the if in `if for`. That being said, it still is the complete opposite of python's for else. 
Only those companies that still use IE6 as their only browser though.
there needs to be a derogatory term for this besides "c with classes"
as a non c/c++ programmer. what happens if the string, that you want to copy in the buffer, is 1030 chars long? does it terminate the string at 1023 or set it to the character of the string?
Crabby Old C Kooks Still Using C++ Kludges Everywhere Really Stinks 
The main places where I've used the strncpy and similar functions was not working with actual strings, but working with byte-arrays extracting or formatting data for hardware.
Yes, you'll lose the last 7 characters. This is why we have dynamically allocated utilities like std::string.
Use a stack-based allocator ([example](http://home.roadrunner.com/~hinnant/stack_alloc.html)) and reserve() all of it right after construction. Seriously game programmers, read a book on modern C++ sometime instead of relying on your prejudices.
but according to [this](http://www.cplusplus.com/reference/cstring/strncpy/) you'll lose the last 6 characters (if i counted right) and it WON'T terminate then, which would create errors/buffer overflows like the article said. so this isn't a viable solution now, isn't it? shouldn't it be something like this to prevent that? strncpy(buf, "Hello", (sizeof buf) -1); this is the part i'm talking about: &gt;No null-character is implicitly appended at the end of destination if source is longer than num (thus, in this case, destination may not be a null terminated C string).
No you right it doesn't, but if you don't need to mutate the string you can do something like: char a[]="hello world"; string_ref sr=a; Or you can take the general concept and run with it and have a mutable string ref etc...
**tl;dr:** Stop using `strncpy`. Instead, use `strncpy`. Am I the only one who found this silly? 
It fills up the buffer with characters from buf[0] through buf[1023]. The result is thus not nul terminated, and not really a string as far as C is concerned. (i.e. you'll have to do buf[1023] = 0; yourself to make it a string)
That does not help. With strncpy(buf, toolong, (sizeof buf) -1); you are not guaranteed that the last character in buf is a nul terminator. You'll have to terminate the string yourself. And in that case it really does not matter much if you do strncpy(buf, toolong, sizeof buf -1); buf[1023] = 0; or strncpy(buf, toolong, sizeof buf; buf[1023] = 0; The only difference when the copied string is too long is that in the latter case strncpy copies one extra character that, which you overwrite with the nul terminator.
so that means your original post wouldn't solve the problem in the Original Post in any way? as i remember now, 0 isn't equal to the \0 Terminator so i know now why my "solution" wouldn't help in any way, but so would'nt yours as well.
I'll have nightmares tonight after see the codes caught by PVS-Studio. =O
My original post was to hint about the fact that strncpy has significant overhead, which many are not aware of. If you copy a small string into a big buffer, strncpy writes stuff to the entire buffer, which the other string functions do not, they just copies what's needed. I've seen a lot of code copying text into 64k big buffers with strncpy, which for the most part are small strings, but they've made the buffer big enough to cope with the longest string that's reasonable. Resulting in inefficient code writing 64k of data to a buffer when just 20 bytes would be enough.
Okay, guilty as charged of the irony. However, to be fair it is far better to use it once in a carefully controlled environment than hundreds of times. And the implementation of strcpy_safe could easily be written without it.
It is not possible to use a stack based allocator in C++ without making use of very new C++11 features only supported by clang and GCC. Furthermore as C++11 is not yet part of GCC's production line (it is still officially classified as experimental), a lot of companies will not use it for their production products. There are many hacks around this, notably one from Google used by Chrome but it's unbelievably ugly.
They are the same thing. '0' is not the same as 0, but \0 and 0 are the same.
Working with serial ports, strncpy comes very handy to read the input characters into a buffer and work with the buffer itself... I need to find a different way to do this, but it's the way I have been taught to work with buffers :/
&gt; It is received wisdom that top-down teaching is superior Not received wisdom – it’s actually confirmed by solid evidence from studies. Unfortunately the state of publishing in didactics is still woefully provincial, meaning that every country essentially has its own field of research and few findings are systematically shared. &gt; Having experienced the result of Java being the language of choice for academia **That** is the issue, and it has got *nothing* to do with top-down vs. bottom-up. Teaching in general is simply in an abysmal state, in particular at Universities. &gt; It is a common mistake in this business to think that the old ways can be swept away entirely and this is a big mistake. No, the mistake is to think that this can be avoided. Teaching methodology in the past simply wasn’t science, it wasn’t supported by any evidence and it was, quite frankly, complete bollocks. But we are starting to *have* that evidence and slowly, ever so slowly, this evidence will translate into improved teaching methods. Teaching at the moment is pretty much where healing was just as evidence-based medicine became established. It is telling that almost **no** teacher at a University has actually received any formal training in teaching, and people who *do* work in empirical research of teaching can only shake their heads at the ignorance that pervades the establishment.
Right, that's how Chrome handles it. Basically with one single declaration such as: StackAllocated&lt;std::vector&lt;T&gt;, 100&gt; container; The StackAllocated template class is basically a wrapper over a chunk of memory allocated on the stack that can store 100 objects of type T and the container std::vector&lt;T, C&gt;, where C is a custom allocator that makes use of the stack allocated chunk of memory. Then to access the container you use a method like so: container.c().push_back(...); Once again, sort of ugly but it works on a variety of platforms/compilers and does not depend exclusively on C++11 or a particular C++ vendor.
&gt; there are domains where it does. And what are those? The only thing I can think of is on an extremely constrained embedded system, but if you're on one of those then it's questionable why you would use C++ at all. 
It does make you wish that C had the binary "0b" notation like Perl and Ruby (and I'm sure others): 0b1010 == 0xa
isn't this same thing as what Intel compiler has for a decade?
The MS compiler has done it for a long time, too. He's not saying it's a new feature, he's saying it's an overlooked feature, and providing a gentle introduction to those who are not familiar with it.
It's C++, so if you have a C++11 compiler [you can implement: 1010_binary](http://stackoverflow.com/a/538101/10311). Alternately, GCC [supports 0b1010 as an extension](http://gcc.gnu.org/onlinedocs/gcc/Binary-constants.html).
On Windows, use StringCchCopy or StringCbCopy: http://msdn.microsoft.com/en-us/library/ms647527(v=vs.85).aspx
PGO is great an all, but it is an extra step, and a step that doesn't always improve performance by all that much. It is another tool to add to ones optimization toolbox, but like all optimizations, you have to know why your program is slow. If the answer really is failed branch prediction, well good on you because usually your bigger issue is something else.
There's also the old [binary constant macro](http://bytes.com/topic/c/answers/216333-binary-constant-macros) hack.
In hindsight I would have implemented strcpy_safe without using strncpy. It would have required about two more lines. So much for trying to be terse :-(
A fun exercise is comparing the asm generation between PGO and non-PGO. 
Qt Creator has it's own C++ compiler built in. I believe clang was looked at early in the piece and it wasn't fast enough to be run for the Qt Creator use case - ie as an incremental compiler. Last I heard some people were looking at changing it over to clang, although I lost track of the discussion shortly after.
Well, it technically is an extra step - but not for everyone. Usually one person does the PGO training and checks it in, then everyone building from that point forward can use the counts. It is true it doesn't always improve performance, though. It helps the most for large legacy applications that have a lot of cruft code; PGO can give massive CPU and disk I/O wins in these situations. Tiny applications, or applications where every code path is "hot", not so much.
I would recommend holding off on the IDE... You learn so much more about what's going on by working through your first few examples without the IDE doing everything for you (especially with regards to the preprocessor and what order things get compiled in). Just my .02.
When does the day come when people finally realize that system("PAUSE") is bad?
It's closing immediately for a subtle reason: when the user types 4, 7, Enter, then the characters '4', '7', '\n' (which are 52, 55, 10 in ASCII) are placed in the standard input stream, waiting to be consumed. When you say "cin &gt;&gt; age", the characters '4' and '7' are consumed (writing 47 to age). cin looks at the newline, notices that it isn't a digit, and does **not** consume it. Then, when you say cin.get(), this attempts to consume a single character from the standard input stream. If no characters were available, the program would wait for the user to enter input (which is what you intended). However, the newline is available. Therefore, it is consumed and returned (as you could observe by inspecting cin.get()'s return value). Basically, there are several problems here: * iostreams are complicated. They're safer than C I/O (e.g. printf), so they have some redeeming qualities, but they are definitely not a super awesome part of the Standard Library (unlike the STL proper which is super awesome). * Almost everyone is teaching beginners the wrong way to do input. Processing input is inherently obnoxious because users emit garbage that you have to validate and reject, but iostreams op&gt;&gt; is an especially awful way to consume input for this and other reasons. There are less painful ways to do it (a reasonably simple and robust way is to consume whole lines with non-member getline, validate and split them into chunks with regex, and then convert things to numbers as necessary; non-member getline does NOT leave newlines on standard input, which is the behavior everyone expects, and it deals with arbitrary-length input). * Almost everyone teaches beginners the wrong way to get started with Hello World. I am a strong advocate of learning C++ without an IDE. This leads to a more austere experience, but better understanding, and less confusion. If you're working with a plain text editor and MinGW (it would be especially hilarious if you were using [this MinGW distro](http://nuwen.net/mingw.html)), you're 99% of the way there. You just need to start a Command Prompt of your own, drive the compiler from there (g++ -Wall -Wextra hello.cpp -o hello.exe), then run your programs from there (typing "hello"), **not** double-clicking them in Windows Explorer. Then you don't have to do silly dances to keep console programs from closing. I have been thinking for a long time about better ways of teaching C++, and I am gradually becoming convinced that avoiding input parsing for as long as possible is probably a good idea.
* GoogleTest * Test coverage = unit-level testing * We don't. * Win: command-line &lt;-- CMake scripts, Lin: command-line &lt;-- make scripts
First off, thank you for the detailed reply. Second, could you recommend a good place to start learning? I have looked at youtube, various books, and even a free app on my tablet, trying to find a good place to learn. Most seem to be teaching the way I have written my hello.exe. You seem to be very knowledgeable on the subject and would be interested on what you recommend. Thank you again
I learned C++ in a strange way (self-taught starting with C - which I do **not** recommend imitating, that lesson cost me a year and a half - and then with mostly intermediate-level C++ books which taught me good techniques but were hard to absorb), and it was 10 years ago so my knowledge of beginner-level books is out of date. I have glanced at Programming: Principles And Practice Using C++ by Stroustrup, which looked approachable and detailed, and of course the author's knowledge and design sense are stellar, but I haven't actually read it. I strongly recommend *against* reading anything by Schildt (his notorious reputation is well-deserved). There are a bunch of signals that indicate high-quality books as opposed to low-quality, but unfortunately it takes C++ experience to really identify those signals. I could recite a list of shibboleths (anyone saying "void main" is clueless, for example), but the big one would be spending too much time introducing low-level tricky stuff, when the high-level easy stuff should be introduced first. The physics equivalent would be teaching quantum mechanics before the periodic table. In particular, pointers and especially arrays are C-era, and there are just so many issues related to their use (they are not inherently evil but it takes skill to know when to use them). Once you get beyond the stage of working with individual pieces of data (e.g. individual ints), std::vector should be introduced as the sequence container you'll be spending the rest of your career with. I personally think that classes are introduced too early, and inheritance introduced way way too early, although avoiding books with those problems may leave you with virtually nothing to read. The most important thing is to be writing code of your own in addition to reading books - there is no substitute for that experience. (Some people talk about the importance of "reading code" but at least for C++ it is just too difficult for a beginner to understand production code anywhere; this would be more important for other languages as first languages, or for an experienced programmer elsewhere learning C++ as a second language.) The secret to programming is becoming familiar with the limitations of your mind when it comes to handling complexity, and with how to overcome those limitations through abstraction, testing, and paranoia. That's in addition to the obvious stuff like learning syntax, semantics, and various libraries that do stuff. Someday I want to actually write materials of my own starting from the beginner level, but as my experience has increased from asking my best friend whether I could access Array[Size] to maintaining a Standard Library implementation, my free time has fallen to almost zero.
Oh, and I forgot to add - C++ is difficult to learn properly, especially as a first language, but it is incredibly powerful and rewarding. Stick with it! (As I like to say, "if C++ weren't so damn useful, nobody would bother with it.")
char ch; std::cin.get(ch);
If you are using notepad++ I guess you are on windows, in which case is recommend starting with visual studio to write, compile and debug your programs. Microsoft have an 'express' edition of vs that you can download for free (http://www.microsoft.com/visualstudio/en-gb/express - you want the last link) Having an IDE will help you a lot when debugging things like this yourself
Too bad Ankit doesn't know to break out of switch statements.
To find memory leaks I typically use [Memcheck](http://valgrind.org/docs/manual/mc-manual.html) for the [Valgrind](http://valgrind.org/) suite. Its VM approach slows down things a bit, but other than that there's nothing to really dislike about it IMHO. Profiling in general: * [Callgrind](http://valgrind.org/docs/manual/cl-manual.html) (again a little slow, but exhaustive), * [gprof](http://www.cs.utah.edu/dept/old/texinfo/as/gprof_toc.html) (faster, but less detailed) and * [likwid](http://code.google.com/p/likwid/) (reads CPU performance counters, thus 0 overhead, but harder to narrow in on certain code passages).
[Yes.](http://nuwen.net/stl.html)
My entire website minus like two pages is so horribly outdated :-&lt;
Would you say it would be a good idea for programmers to start looking at c++11 style coding and solutions as they learn c++ if c++ was their first language or learn a more "traditional" c++ core language style?
 if (a &lt; b) { printf("a is lesser than b"); } else { printf("b is greater than a"); } Ouch. 
You should learn C++11 as if C++98/03 never existed. Some C++11 features are for experts (e.g. variadic templates, expression SFINAE) but others are appropriate for beginners through intermediate-level programmers (e.g. range-for, auto, lambdas). We had to do lots of tedious, brittle stuff in the olden days, when C++11 allows us to express ourselves much more clearly.
What? Maybe path 1 needs to flow into path 2. Even more relevant to the exercise, because I've read those flows are harder to optimize than pure "case/break" switches.
I'm guessing "lesser". 
In my current application (optimization algorithm for a large scale graph problem), the control structure is largely dominated by switches and function pointers and I've noticed PGO had some effect (5~10% faster). I don't use it during testing, but when I'm generating large quantities of data (multiple runs over multiple data sets), the PGO is basically a "free" win. I optimize it over one important set (e.g. the largest) and I'll see a time reduction for each run, for barely any effort. It might not be suited for all types of applications, but I definitely wouldn't dismiss it for an often-trivial reason as "it's an extra step".
Ignoring the "or equal" case might be worse.
Grammar, newlines, and smart quotes aside, the else-printf is simply incorrect. When a &lt; b, it is simultaneously true that a is less than b, and b is greater than a. **Else**, a is greater-than-or-equal-to b, and b is less-than-or-equal-to a.
Not necessarily relevant, e.g. when all elements must be unique (which isn't uncommon). Also, I don't think it really matters. It's not about the code, it's about the structure. (P.S.: Smart-quotes?)
Wow, actually that's the thing I've been thinking but not being aware of (when I first heard what can hotspot compiler for java do). That's the missing step between AOT and JIT compilers. And it seems it's a kind of very cheap lunch.
Before you leak check or profile, make sure you're running your compiler with all warnings turned on. Then run it through a static analyzer like CppCheck. This usually catches a ton of issues but is not a substitute for using something like Valgrind.
I use my own memtracer. Its tiny and clean, no macro tricks, no source modification required etc Take a look if you want https://github.com/r-lyeh/tracey Hope it helps!
You have an interesting idea of "fun." :) Do you see certain specific patterns in PGO vs. non-PGO generated code?
I'll second the valgrind suite of tools. Also look into helgrind; it gives notifications of possible race conditions. Memcheck can and does hide race condition segfaults, so it's always good to use both if you are using threading at all.
Not feature complete but, but header-only modern C++ MPI implementation : https://github.com/motonacciu/mpp
I liked the article, very well written. I do have a naive question though.. The article mentioned that compilation can be done at the source file level. And by experience, you only need to optimize by speed for 5% of your application and the rest is optimized by size. Why is it hard to find the 5% of your source files that should be optimized for speed? I do embedded programming, so usually its not hard to figure out what algorithm should be optimized for speed. So I don't see a need for a tool to do this. Although, I will use the idea and find that 5% of my code that should be optimized for speed. Maybe windows programming is not that clear cut? So if I have 100 source files. I should find 5 or less to optimize for speed. Is that so hard? 
Oh, that is cool. :)
Accelerated C++ is one of the best books. http://www.amazon.com/Accelerated-C-Practical-Programming-Example/dp/020170353X
Or maybe they're two entirely different scenarios and merely examples of two common control structures? There's absolutely no reason to expect any of the three code fragments to be connected. 
It's not uncommon for code to deal with unique values only. Without context, there's nothing wrong with this code fragment (aside from "lesser than", which is a language error, not a coding one).
That's a very odd way of interpreting things. It's not about 5%, nor is it about source files. The problem is finding what code is taking up most of your time, and whether that time usage is acceptable. Depending on what kind of software you're making, that either means: * Finding out what functionality is too slow *for the user*. or * Finding out what part of the code is taking up the majority of the runtime. The first makes sense from an experience point of view; the user may be okay with waiting 5s before his game loads, but is not okay with waiting 5ms until his actions register in the game, even though the latter is still "much faster" than the first. The second makes sense from a bottleneck point of view. There's no point in optimizing code if the processor executing it has to wait until a different thread has finished. Even in non-parallel code, it's intuitive that the code taking up most time has the largest potential for savings. So, don't bother with source files. Look at the function calls, look at specific lines of code. Source files mean nothing to the compiled code [sort of]. 
Even when uniqueness is guaranteed and equality is impossible, when a &lt; b, it is **simultaneously true** that a is less than b, and b is greater than a. To put it another way, what is wrong with the following code? if (you_are_batman) { puts("Your butler's name is Alfred Pennyworth."); } else { puts("Your name is Bruce Wayne and you fight crime wearing a mask."); } The screenshot in the article had smart quotes in the strings.
One person's opinion: I learned C++ first, but I wish I'd started with Python or Ruby as a first (of many) languages. Edit for rationale: You want to know what's going on at the memory level (C/C++), as well as the assembly level. But starting with a scripting language with garbage collection lets you jump to the end goal faster: building stuff that does what you want. 
Looks like an interesting project and I understand that this code is just a utility for you... so take all my comments with an attached smiley, :-D or :-) as you please. Cred: I've done a lot of work with UTF-8 and even wrote a tiny but crucial UTF-8 utility that's almost certainly being called right now millions of times a minute for a famous search engine... One of the things about text processing is that it's very simple - but you do an awful lot of it, so it pays to be as efficient as possible. So I'm dubious even about the existence of this class in the context of the whole operation of UTF-8 processing. Why do you need a class to represent "bytes"? - they are already there in whatever string you're processing! And you're now representing one byte by three... Processing UTF-8 generally takes just a single class - a state machine that reads through the input one character at a time (or one codepoint if you're going in the reverse direction). Second, if you have determined that a class must exist, the access to this class could be stripped down. Returning non-const references to your private members is not a good strategy. If you want to restrict access, you need a setter - if you don't want to restrict access, make it a struct. (Indeed, if this class must exist, it should almost certainly be a struct, and you should throw away all the accessors...) Getting to more specifics, UTF-8 is a very well-known protocol, so instead of explaining to it, you should link to some well-known document that explains the format and use their terminology. It saves you writing and if the reader already knows that document, you're both ahead of the game. I personally like this one: http://www.cl.cam.ac.uk/~mgk25/unicode.html Finally, we get to your original question - should you use constants or enums (not #defines!) I spent several minutes look at the code and I have to confess that I have no idea if it's correct or not, so I'd say that the answer is yes. First, the eye is not naturally good at looking at two strings like 0xF0 and 0xE0 spread apart in code and seeing if they are the same or different. I think that if you even simply renamed them to A, B, C... there would be some marginal gain simply because your eye could instantly see if these constants were repeated or not. But of course that'd be lazy and silly. You could do a lot better than that. These numbers are basically masks. I think you should name them that way. namespace mask { typedef unsigned char Mask; const Mask LEFT_4_BITS = 0xF0; // i.e. the 4 leftmost bits are on. const Mask LEFT_3_BITS = 0xE0; const Mask LEFT_2_BITS = 0xC0; // etc. const Mask RIGHT_4_BITS = 0x0F; // i.e. the 4 rightmost hits are on. // etc. const Mask BIT_1 = 0x80; // i.e. bit 1 is on. // etc. } This is nice, because it describes what you're using them for. For example, when you use 0xF0, you're essentially masking off the leftmost four bits - so why not just say that? Hope this helps!
Holy shit, I just completely missed the fact that he switched around the positions of 'a' and 'b' in the text. I thought the only problem was excluding the possibility of equality. Thanks for pointing it out!
I don't, they are quesitonable in isolation. The first is factually wrong, the last is at leat questionable. Both are typical beginner mistakes, which isn't exactly inspiring confidence in the skills of the author. Now, yes, he could be a lousy programmer and an amazing program manager (whatever that is, following the visual studio blog it seems every dialog has its own a program manager) - but the "manager" part at least suggests he should know be able to cross check what he isn't sure about. Its not the first time the VSBlog raised an eyebrow (or a WTF parade for that matter). 
I just don't feel very assured when the "program manager for the backend C++ compiler" can't write correct code. EDIT: See [Tagedieb's comment](http://www.reddit.com/r/cpp/comments/1boxem/how_to_build_faster_and_high_performing/c98y9gv) for another example of incorrect code in this small sample.
Cool. Still trying to get used to the whole 11 scene.
Again: that's not *another* example, because this one isn't (necessarily) wrong.
Based on the response I guess the original code should have been this instead? int i = some_default_value; if(someConditionIstrue) { Do some operations and calculate the value of i; i = some calculated value; } use i; //Note this value is only used not changed. It should not be changed. 
[Judge Dredd riding a raptor who is riding a shark breathing fire... Also some rockets and a bit of pew-pew!](http://imgur.com/r/pics/bTg8pz8)
correct me if I am wrong, but the article mentions that at most 5% of the code should be optimized for speed. And I do think it is at the source file level and not the function level. When you compile a source file, you can't specify what function to optimize and how. Or is that what PGO is doing? Again correct me if I am wrong. But even if I am wrong if you are writing good code, optimizing at the file level is not a bad thing. Either most of the file will be optimized, so what matters if you optimize a few extra functions or you've got a very bloated class. Your example brings up more questions in my mind. I'm not that familiar with game writing so maybe that's what I don't get. My basic logic tells me that if I write a shooter game, then I probably need to optimize the code that deals with shooting and getting shot. I don't need to optimize the in game menu. Another question, how does PGO compare to profiling tools? If run a profiling tool on my shooter and it tells me the code with shooting and getting shot gets executed the most, then that's what I would optimize. And I wouldn't just let a tool optimize it, I would probably optimize the code by hand as well. The article made PGO seem like such a simple notion, but the more I think about it, the more I question of when its actually the right tool for the job.
The 5% is a rule of thumb for the results of the PGO (see screenshot above that line, where only 0.17% is optimized for speed). I imagine it optimizes the CPU bottleneck for speed and the rest for size. It's not something you can do manually I think; maybe you can, but I'm not sure you'd be very effective. You should be using whole-program optimization anyway for your final version. The thing with source files is that you can put whatever functions you want in whatever file. 5% of files makes no sense; if you put the critical 5% of functions into a single file, or spread them all over files, that 5% rule makes absolutely no sense. Chances are if you follow a strict class-based design you'll have critical functions in many files.
I'm not sure what's wrong with the ternary operator for the original problem: const int i = someConditionIsTrue ? someCalcFunc() : 10;
There's nothing wrong with it per se, it's just kind of distasteful to not be able to write things inline, especially if they need to refer to local arguments or other local variables. (You can of course add those as arguments to `someCalcFunc()`.)
What's wrong with this? int i = 0; if (someCondition) { i = someComputation(); } const int j = i; // Use j instead. It's constant and based on the value of i
&gt; Someday I want to actually write materials of my own starting from the beginner level, but as my experience has increased from asking my best friend whether I could access Array[Size] to maintaining a Standard Library implementation, my free time has fallen to almost zero. Your available time isn't going to increase because of a change in focus, but have you given any thought to skipping over the beginner level material and writing to intermediate C++ programmers? Your Channel 9 videos are a good example of the level of material I imagine targeting. It's always fun watching you navigate directly to the relevant section in the standards documents, or live debugging the MSVS STL implementation. I've always felt the step from intermediate to expert (or, realistically, just a more knowledgeable intermediate) is under served. The benefit of moving the target over a bit would be that you avoid the problem of posting material that goes "Here is how you get a hello world source file to compile and run, tune in next week for variables." and then hanging a reader high and dry if you lose the time to produce the material, or just decide to stop. You can avoid this by producing all the material beforehand so there is no risk of suddenly stopping (indeed, it could just be released all at once at this point), but this takes a large initial commitment. Intermediate material is more amendable to being self contained. Relatedly, since I imagine you're still producing Channel 9's Core C++ videos, has the Channel 9 team ever thought of attaching a wiki-like system to videos where the community could edit a textual version of the video? What I imagine popping up is a blog-post style summary of what was discussed in the video. It could either be corrected by other members of the community, or yourself coming in and saying "No, no, that's not at all what I was trying to describe." and editing it in two minutes instead of having to take an additional hour to initially write it up. The system could even release the videos early to past contributors to the wiki-system posts so the summary hit at the same time as the public posting of the video. I ask because I often take notes during the videos, and have thought about taking the extra effort to take more detailed notes and blogging the big picture. This has the same problem as I described above with the beginner material, that it takes initial effort at risk of going wasted (in my case, if nobody is reading the posts and I stop doing them). Apologies for going on a bit of a rant, but it is something that I have been thinking about both with your online videos and other materials for learning both online and off.
Does anyone know whether a Ranges proposal is currently being discussed?
This is, as they say, the dog's bollocks.
*What is it?* - A simple test and benchmarking suite for mathematical expression parsers that have been written in C++. There are at present 10 different parsers and 5 sets of expression tests. The tests range from simple to very complex expressions that are designed to demonstrate each parser's abilities with regards to *precision* and *performance*. It's a very simple benchmark. 2 parameters are passed 1. number of iterations per expression 2. benchmark test set. Every parser evaluates each expression "iteration" times, the total time for each parser is recorded and an average evaluation per expression is printed for each parser for every test expression. Parsers that can't parse the expression or produce a result different to the expected result (based on an normalized epsilon approach) are disqualified for the round. Points are then distributed based on position in a particular round (which is based on evaluation time shortest to longest). So for 10 parsers, pos 1 gets 10 points, pos 2 gets 9 points .... pos 10 gets 1 point, At the end a final summary is produced. Very simple, nothing complicated and nothing special about how it's done. The suite is in its early days so there's still lots more to come. We invite anyone that has a C++ mathematical expression parser to **submit** it for inclusion in the suite. 
I would be interested in some sample results. 
This is the optimization I most envy from managed languages. I wish there was a way this could be done more often in C++ - but alas it's a dream. 
I feel like this would be better with graphs.
@Jay: I can only comment on ExprTk, in short it is not thread-safe from an expression evaluation pov. The evaluation process can definitely be executed by multiple threads concurrently, but if there are variables being used and assignment operations within the specified expression then undefined behaviour will result. That said I find that in practice because the 'compiled' expression is very small/lean, that every thread can have its own instance of an expression, if required, with very little overhead.
its still too verbose
You really need to put some graphs up on the wiki of sample results.
I have to vote this down. You simply aren't presenting the information we're all interested in! You have a set of text tables - that's simply THE worst format (at least if you had CSV I could download it and process it myself). [Google charts](https://developers.google.com/chart/) is a really easy and light way to have sophisticated charts for free, for example. There's no summary of your methodology or your results. You expect us to do all the work to dig out any information we might be interested in. Fix these up and present it to us again - I'm very interested in the topic, personally...
 pprog = new glpp::program(); – Seriously. [Why?](http://klmr.me/slides/modern-cpp)
It's a global object that has no default constructor. The obvious fix of making it an `unique_ptr&lt;T&gt;` aside, it could be fixed by adding an uninitialized state to the class or making the global a `maybe&lt;T&gt;` that can be default initialized and later really initialized with the object.
oglplus seems nicer.
"the author of this library is seriously too pointer happy" Going forward this is definitely going to be the mark of people stuck in the past. Similar to how 500 line long functions and using the c api instead of the c++ api is today.
You can't really use the creator function to initialize GL globals as they reqiure a GL context to be created first. The way I usually solve it is that I create a class that has those global variables and functions as members and construct it after creating the window.
Contributes nothing to discussion. At least specify why.
I wrote a binary regex library a while back, this make me want dust it off and mess around with some low level code :) Also i think your code is fine even without enums just thanks to the liberal comments.
Stroustrup's [The C++ Programming Language, 4th edition](http://www.amazon.com/The-Programming-Language-4th-Edition/dp/0321563840) hasn't been released yet, but that's the book by the language's author. Josuttis' [The C++ Standard Library: A Tutorial and Reference (2nd Edition)](http://www.amazon.com/The-Standard-Library-Tutorial-Reference/dp/0321623215/ref=sr_1_6?ie=UTF8&amp;qid=1365443455&amp;sr=8-6&amp;keywords=The+C%2B%2B+Programming+Language) is one of the must-have references. The first edition of the book is excellent, and from the reviews, it sounds like the second edition should be just as good (while being updated to the new C++11 standard). [This stack overflow thread](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) offers some excellent suggestions, ranked by the experience level they expect you to have.
[C++ Programming by Larry Ullman](http://www.amazon.com/C-Programming-Larry-Ullman/dp/032135656X) This is the book that taught me how to program. Good for beginners. 
I recommend the Primer as well.
There is a nice list of C++ books on [Stack Overflow](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list).
I do know that Qt5 has introduced a QStringLiteral() macro which does exactly that: if on a C++11 compiler it generates a compile-time constructed string (and falls back to run-time allocation for older compilers). I don't think it does define any manipulation methods though. You can find more here: http://woboq.com/blog/qstringliteral.html
&gt; Stroustrup's The C++ Programming Language, 4th edition hasn't been released yet, but that's the book by the language's author. It's more a reference than a tutorial though. If you really want Stroustrup, try [Programming](http://www.stroustrup.com/Programming/) instead.
"a is lesser than b" and "b is greater than a" mean the same thing. It's the same problem as "Heads I win, tails you lose."
Stop being faggots and use the C API.
No. *Principles and Practice Using C++* is for people that don't know how to program.
I have seen the user manual for Metaparse before --- the string is constructed using a macro, e.g. MPLLIB("blah"). Before I asked the question on SO, I would have been satisfied with this, but Howard Hinnant's solution is more elegant (IMO), and doesn't use any macros 
In what ways is a compile time string different than a constant? Is the idea to be able to do things like compile-time concatenatations?
Exactly. See [this example](http://david.rothlis.net/d/templates/) that uses compile-time string manipulation (plus compile-time introspection of identifier names and compile-time "eval") to generate class methods at compile time. The example uses D, not C++, but.
That excellent list of books is actually linked in the sidebar of this subreddit which makes it extremely easy to find. Asking this general question makes OP not look very sharp or serious. The cool thing about that list is that it makes recommendations for books on many different levels and aspects of programming in C++. There is something for everybody in there. Since OP mentioned videos by antiRTFM on youtube, I must say after watching them for 20min I would not recommend anybody trying to understand to ever look at them. The "intuitive " concepts they are trying to convey are not only confusing in the long run, they are at times even plain wrong (and already the first video shows invalid code as an "example" of what purportedly could be done in C++). 
I would add that these days already being able to ask targeted and useful questions given some limited information can be very valuable. This post lacks even that strongly.
Dammit, I didn't even notice that. Must've left my debugging eyes somewhere else...
I wish this talked about *how* to use template specialisation and inline/raw asm. I mean, there are a number of ways to go about it in C++, and I'd love to know what they think is the best way to do it. Do they have a single `atomic&lt;T&gt;` definition and select the relevant methods with specialised templates relying on `T`? Like so: template &lt;class T&gt; class atomic { ... void fetch_and_add(T v) { detail::fetch_and_add&lt;T&gt;(data, v); } }; Or do they specialise the definition of `atomic&lt;T&gt;`? Like so: template &lt;class T&gt; class atomic; template &lt;&gt; class atomic&lt;uint32_t&gt; { ... }; ... And how do they link in the specialised asm? What are the pros and cons? Not enough implementation detail, which I think we need to discuss in the C++ "community" a lot more than we do! It's not always just about performance, it's also about style.
I'm interested to know what the use for this would be? It's an interesting discussion, but hopefully you don't actually need to do that much string handling on compile-time?
A URI library? This is C++, not Java.
&gt; inside the function, reference arguments are always lvalue references (because they are named). Terminology nitpick: types can be "lvalue references" or "rvalue references" (or ints, etc.), while every expression is either an "lvalue" or an "rvalue". This sentence is, confusingly, mixing up the terminology for types and for expressions. (The terminology itself is inherently tricky - we'd be better off if they were called red-expressions and blue-expressions - but it's what the Standard and all books use.) &gt; Since it seems to me that it is absolutely possible for the compiler to deduce that std::vector&lt;T&gt; would instantiate as std::vector&lt;int&gt; in some particular use of that declaration, I find the distinction somewhat lost on me. The template argument int for the template parameter T is deduced through the process called "template argument deduction". vector&lt;T&gt; is a dependent type, because it depends on a template parameter T. &gt; The key here is that reference collapsing rules allow the instantiation of f&lt;int&amp;&gt; with T = int&amp; to do something meaningful: the function argument type T&amp;&amp; becomes int&amp;. Essentially the compiler uses the flexibility it has to pick an argument type that allowed the template to be instantiated. This is why function templates with arguments like g(std::vector&lt;T&gt;&amp;&amp;) won't work: the compiler has no ability through modifying T to collapse the rvalue reference type into an lvalue reference type; and an lvalue actual parameter won't bind to an rvalue reference type. This is incorrect for a very deep (not trivial) reason. Reference collapsing is part of the story, but it's not the **key**. Here is a simple counterexample for why it is not the key: const T&amp;&amp; triggers reference collapsing if T is an lvalue reference or rvalue reference (try it with a typedef, or with explicit template arguments given to a function template). However, const T&amp;&amp; is not a "universal reference". The key is a very special sentence in the Standard, which I refer to as the template argument deduction "tweak". It is N3485 14.8.2.1 [temp.deduct.call]/3: "If P is an rvalue reference to a cv-unqualified template parameter and the argument is an lvalue, the type "lvalue reference to A" is used in place of A for type deduction." This is why T&amp;&amp; is special and const T&amp;&amp;/vector&lt;T&gt;&amp;&amp;/etc. are not. &gt; To complete the analogy, in template&lt;typename T&gt; void f(T t); the declarator type T doesn't always mean ‘non-const’. Actually it does (when template argument deduction is used instead of explicit template arguments), because decay is performed before template argument deduction for (T t). The example immediately below depicts "template&lt;typename T&gt; void f(T &amp;t)" which is very different, because (T&amp; t) inhibits decay. &gt; In other words, once again the compiler used the flexibility it had to pick a type T that allowed it to instantiate a version of the function template that allowed the call of f(xc) to compile. This is not really an accurate description of how template argument deduction works. The compiler has no "flexibility", really. Instead, it is following rigid rules, although they were designed by experts to produce human-intuitive results in the vast majority of situations. Here is a counterexample. Given f(T&amp;) and a temporary std::string - perhaps the function call is f(str + "meow") - if the compiler had "flexibility" it could choose T == const std::string, allowing const std::string&amp; to bind to the temporary std::string. But although C++ generally wants to compile your code, it will not do this. Instead, template argument deduction's remorseless logic chooses T == std::string, then overload resolution notices that f(std::string&amp;) cannot be called with a temporary std::string, and compilation fails (if this is the only overload).
How come the LOCK prefix instruction doesn't have any bottlenecks? put that before your instructions add witness the program's performance drop at least by half...!!! 
Not being a compiler guy, I was a little uncertain about the strength of your argument until I got to the last paragraph -- that convinced me you're correct. Good response.
You're usually safe to assume that [STL](http://nuwen.net/stl.html) knows what he's talking about.
The article says minimal... it is by far faster than a kernel transition.
What intrigues me is how the generated asm would differ from std::atomic. It might be implemented using intrinsics or inline asm; the former is most likely for portability among platforms or compilers. 
I presume it would be similar. Standard libraries will most likely opt for compiler intrinsics in `std::atomic`, which can generate the same code, but portably (i.e., on all architectures supported by the compiler).
http://isocpp.org/get-started
The article underplays the cost, it's not minimal, especially on weak memory platforms like Arm. But yes, it's way better than a mutex.
It's minimal in the sense that the cost is roughly the minimum of all implementations of that feature on a given platform.
How hard of a conversion from Qt GUIs is it to use this? We have a bunch of stand-alone UIs that talk to backend servers that I would love to make web-based, and this seems like it would simplify the effort. I know they've tried to keep the API similar, minus class names and whatnot, but how hard is the actual conversion?
It depends a lot on how complex your UI is. Wt is missing many widgets Qt offers. The backend should be easy to reuse thanks to the (included) wtwithqt library. 
I use Wt almost exclusively. It's wonderful!
Despite appearances, I'm a library dev, not a compiler dev. It's just that as an STL maintainer, I end up learning about most of the Core Language in extreme detail. (Not all of it, though. There are a few dark corners that not even the STL interacts with.)
I've been trying to figure this out for a while. Say I've got a socket service that I'm using to feed mobile apps and I want to pipe it to a wt web front end for everybody else. Do I wrap it in a wresource and have the communication go from wt process on the server to my socket server or do I figure out how to let them talk directly to the socket server (at which point how?)
I believe the event system is based on boost actually. They've mulled straight c++11 code but I don't believe it's in since there's no good/reliable way to ifdef in/out that functionality.
There are some tutorials for it and a website where somebody does that exclusively. It's a bit dated now but should still work I believe.
Being faster than a kernel transition is not equal to being minimal. Try benchmarking a loop without and with a LOCK prefix and you will see some big performance drop.
It is minimal in the sense that there is not a faster way to do the same thing though. Obviously interlocked operations are slower than non- which is why all operations are not interlocked to begin with. To add some numbers, comparing lock xadd vs inc is approx 3 times slower on my core2: 2.3ms vs 7.5ms for a million increments. 
I figured using the wt process as a gateway was the easiest option available for solving the problem. Any idea what the performance would be like if I wanted to pipe data from a [hummingbird type site](http://hummingbirdstats.com/) through the wt process to a person's display?
Oh shit, naked pointers everywhere. This is horrible. It's fine if a container takes ownership of its children, but then it should accept only unique_ptrs as arguments. Especially that line inside the loop in the widget gallery makes me cringe.
I wouldn't describe an event system that requires wrapping lambdas with std::bind as awesome. If they give that little of a fuck about presenting a nice API then I can't imagine other things being very pleasant to use.
oglplus: * uses the RAII idiom everywhere * all opengl macros are fully typed * uniforms are typed as well (as in, you can give it a vector/matrix instead of a list of arguments) * provides neat objects like lazy uniforms, automatic VAO/VBO setup * very good error handling * doesn't use pointers/heap objects for everything * allows the use of stl containers to upload data to VBOs * uses C++11 functionality if present (e.g. move constructors) * has a LOT of example code * is more mature (has been actively maintained/expanded for the past 2 years with regular updates) glpp: actually has very similar features to oglplus and similar design but less refined: * does error handling but exceptions doesn't contain much information (e.g. if shader compilation fails, doesn't include the info log, you have to fetch it yourself) * has enums for many opengl macros, but not all * setting VBO uses the C style API with void pointers This is after skimming quickly through the examples/source code of glpp. Correct me if I'm wrong on some of the points. 
The std::bind() is to bind away the optional information relayed by the signal, for example a mouse coordinates for a mouse event, or key information for a keyboard event. There is already [a fix being worked](http://sourceforge.net/mailarchive/forum.php?thread_name=CAAWqSO0h5XQs9b%3Dgz3FQY_ax7BTBT%2B9n5ei1TZyVH%2BsTjL7Umw%40mail.gmail.com&amp;forum_name=witty-interest) on so that this is done automatically for you. c++11 is new and Wt supports several compilers, so these things take time.
I, for one, do want to acknowledge and thank you for taking the time to reply wrt such "dark corners" --and additionally for all of your other posts and videos too! :-)
Move semantics and unique_ptr are supported from msvc 2010 and gcc 4.4 on, if I'm not mistaken. Does really anyone use something older than that? And even if one really wants to stick to pure C++03, there's still boost::shared_ptr, which could easily be extracted / replicated.
But you cannot call that minimal. Minimal means very small, not smaller than.
Realistically both are very small. In order to safely increment a word in memory, lock xadd has the minimum cost of alternative operations, hence it is minimal. Same with other interlocked / compare-and-swap operations.
Being stuck on Visual Studio just keeps hurting. 
[SDL](http://www.libsdl.org/) or [SMFL](http://www.sfml-dev.org/index.php)
Not trying to hurt your feelings but if you're asking this question consider something simpler than OpenGL
GLUT is also an option if you're new to opengl. It's simpler and easier to set up but far less powerful/flexible than SDL.
OpenGL is platform independent, so it C++. As long as you use a library which gives you platform independent interface to the audio,openGL window, and keyboard/mous input, you are all set. There are several libraries which can do that. Others have mentioned SDL. You can probably also use something like Qt. There are tools like CMake which you use to make your build system platform independent also. 
Care to elaborate?
http://www.megastormsystems.com/sdk/crm32pro_en.htm
http://www.megastormsystems.com/sdk/mste_en.htm
trmnl is either making a joke or is confused. [GLFW](http://www.glfw.org/) is a framework for OpenGL that lets you create windows, get keyboard and mouse input, etc. [GFWL](https://en.wikipedia.org/wiki/Games_for_Windows_%E2%80%93_Live) is a library that lets you interact with Microsoft's Live service, which is used for video game authentication, achievements, voice chat, etc. They're not at all similar in functionality, but their initialisms are anagrams of each other.
lol, well said.
Yeah, I don't know much about this. I was just asking this because I want to make a game, but if C++ is not capable then I will learn a different language.
Having the minimum cost is not equal to being minimal. For example, a Porche may cost less than a Ferrari, but that does not make the price of the Porche minimal. Minimum != small enough. 
I recommend Java personally. It's a good language for games
Are you talking about the long lasting SFML 1.6 on the site? If you check Laurent's github for SFML 2.0, it gets updated pretty often, he's probably waiting for a more "stable" release to arrive.
Hey, computation will not be your bottle neck. With long polling we limit ourselves to one outstanding request and thus the number of updates is limited by round trip latency. For WebSockets we don't do that (since there is no issue of sequencing over a socket) and then the number of updates will be limited by bandwidth (we serve updates at the rate that the TCP socket can send them). I'm not sure what hummingbird exactly does since their demo site is offline ? Regards, koen
Yes. But you may have to use a LOT of preprocessor directives.
Is a lack of default arguments for function templates really holding you back that much? GCC also has irritating bugs...the fan boys talk as if it's perfect. Nothing's perfect.
&gt; their C++ compiler team was tiny and they outsourced their standard library to a third party company that had only two employees Dinkumware, to be precise. In fairness, their C++ standard library implementation is excellent, although the version MS shipped had some crazy defaults for a while (checked iterators in particular). There was some rumor they were going to replace their compiler front end with EDG's - one can only hope...
I'm talking about 2.0. Even the latest from github feels this way. I'm afraid it's a matter of vision not going all the way to its logical conclusion. However, my armchair criticism doesn't count for much. His cross-platform media API is *way* better than the one I didn't write
The demo site / toy program simply pumps out real time stats either from a MongoDB or a set of test data using Node.js and jquery. As people click the buttons on the top to simulate adding things to carts or finalizing orders a circle appears on their region of the world relative to the quantity of activity in that area. Again it's just a demo / toy, but this idea could be extended to anything. Realtime traffic monitoring, piped from a log manager that shows security warnings / errors or any other visualizations you want to drive in real time.
I am not near a compiler to look myself, is it erring because the constructor is removed with SFINAE? Seems funny to me to use something that is not an error to make errors. If you use SFINAE to cause errors should it be called SFINAEE? 
They already use the EDG front-end, and have for quite some time -- it powers the squiggly red line (Intellisense or whatever it's called.) But this is just for the IDE and isn't used in the actual compiler. In some of the preview versions you could observe when the two front-ends became unsynchronized, such as when range-based for loop support was added to the compiler proper but the EDG front-end was not updated. You could compile and run code using range-based for, but it would show up as a red underlined syntax error in the IDE. 
&gt; They already use the EDG front-end, and have for quite some time -- it powers the squiggly red line (Intellisense or whatever it's called.) But this is just for the IDE and isn't used in the actual compiler. I know - that's when the rumors about switching to EDG for the actual compiler started.
Do you have a choice of IDE? 
I still use Visual Studio as the IDE. I rather like the IDE. Honestly I tend to bash MS when it comes to C++ but I really think they have a great development environment for C# and I do think VS is great. But when it comes to non-MS specific technologies like C++ and even worse C I consider it pretty embarrassing how little they support it, especially given how much marketing they produce talking about how the renaissance of native code and also given that Herb Sutter works for MS.
In a few channel9s I've seen developers that I would consider critical to the native msvc tool-chain, all seem to use anything but the VS ide in the videos - most shun away from the IDE discussion, one poor guy that was using emacs even apologized for doing so - wtf?. 
This was a fun experiment and I wanted to share my findings :)
I develop within the IDE and have the msys command line terminal open to build the application. I use CMake so I have both a VS project and a makefile.
Thanks for this serie of posts ! (this part seems the less interesting in terms of papers presented though)
&gt; GCC also has irritating bugs... Oh yeah, just take `&lt;regex&gt;` (hint: it doesn’t exist at all, just stubs). But in general I’d say that GCC has far better compliance in the “core” of the language that is needed today for productivity. That said, this particular has a very easy portable solution: [use parameter packs instead of default arguments](http://flamingdangerzone.com/cxx11/2012/06/01/almost-static-if.html). Caveat: Haven’t tried that on VS but it *should* work.
Just hoping to generate some discussion on this. This was [posted](http://www.reddit.com/r/programming/comments/1c5ne0/optimizing_a_program_means_making_it_run_faster/) in /r/programming but got no upvotes or comments. Here was my lonely comment on this subject... --- Reading this article really makes me nervous. It highlights an error in the way that I tend to reason about const-reference parameters. I've heard the guideline that you should pass builtins and small aggregates by value, and everything else by reference. But this does not really address my concerns, because: * It breaks encapsulation, so is an ugly solution * Applying it correctly to templated code can be tricky (and require a bunch of TMP magic) * My concern is really about semantics, rather than efficiency - even if I followed the above guideline, a similar situation as described in OP is possible with larger structures. The assumption of value semantics for const-reference parameters is apparently a mistake. 
Stephan-- Hugely appreciate your taking the time to respond in detail. In short, it looks like my poor description of the template argument deduction process created a fair amount of confusion: I didn't intend to imply that this was some 'magical' or heuristic process with a mission to make programs compile whatever it takes. I understand there are specific rules about what the compiler and deduction in particular are allowed to do. My post wasn't even primarily about template argument deduction; it was mainly intended to address the implication that the statement "T&amp;&amp; doesn't always mean rvalue reference" is somehow unusual and needs a new concept to explain it. My examples were intended to show that, indeed, "T&amp;&amp;" in a template function argument list could mean 'rvalue reference' or 'lvalue reference'; but, by the same token, "T" in the same context can mean 'const' or 'non-const'; and somehow we've learned how to deal with that without "universal constness". So, regarding your comment: &gt;&gt; To complete the analogy, in template&lt;typename T&gt; void f(T t); the declarator type T doesn't always mean ‘non-const’. &gt; Actually it does (when template argument deduction is used instead of explicit template arguments), because decay is performed before template argument deduction for (T t). Again, my post wasn't really about what deduction will or won't do, but do note that the example in my original post compiles under VC10: const X xc(2); f(xc); // is f&lt;const X&gt; producing the output in f&lt;const X&gt;(const X&amp;) But even if deduction didn't work in that case and I needed to explicitly call f&lt;const X&gt;(), that still doesn't invalidate my point that "T" in this case is "const X". And that doesn't seem to surprise anybody. Thank you again, for the reply, and for your Channel 9 presentations which are incredibly helpful and informative. Ben
&gt; Hugely appreciate your taking the time to respond in detail. You're welcome! &gt; My examples were intended to show that, indeed, "T&amp;&amp;" in a template function argument list could mean &gt; 'rvalue reference' or 'lvalue reference'; but, by the same token, "T" in the same context can mean &gt; 'const' or 'non-const'; and somehow we've learned how to deal with that without "universal constness". They're both valid ways of looking at things. (Personally, I don't think in terms of "universal references", since I know the underlying rules in detail.) However, T&amp;&amp; becoming any of X&amp;, const X&amp;, X&amp;&amp;, or const X&amp;&amp; is definitely more subtle than T&amp; becoming either X&amp; or const X&amp;. The latter is essentially powered by the compiler's respect for const, and it's easy for programmers to mentally substitute const X for T and see const X&amp;. The former is powered by the template argument deduction tweak, otherwise it wouldn't happen. I keep emphasizing this because I've seen several "explanations" of rvalue references/perfect forwarding completely skipping over it, as if it would happen naturally. And then, after the tweak happens, reference collapsing happens, and that is visually unintuitive (because fewer ampersands win). &gt; Again, my post wasn't really about what deduction will or won't do, but do note that the example in my original post compiles under VC10: Please read my previous comment again. I was objecting to something very specific: immediately after "To complete the analogy, in" you depicted "f(T t)", and then in the code box after that, you depicted "f(T &amp;t)" (followed by explicit specializations). I know it's a single character, but these are very, very, very different things. Taking T by value triggers decay, taking T by reference inhibits decay. &gt; Thank you again, for the reply, and for your Channel 9 presentations which are incredibly helpful and informative. Thanks for watching, I appreciate everyone who's willing to sit down for an hour and listen to me making cat noises at the camera.
At least no new suggestions like the swap operator :P.
I have a simple trick I use when thinking about const&amp; parameters: "assume the context is multi-threaded", it's as simple as that. Once you go through your check list of things that can happen in the mt context, all of these aliasing related issues (and a whole lot more) become apparent. From there you can decide which ones to ignore and which ones to think about more. The more you do it, the better you get at it. 
Thanks for this, I'm going to tshare this with my students in High-performance Computing!
Thanks. I don't generally worry about threading issues when I'm using stack-allocated variables. Do you mind explaining how you reason your way through a multi-threaded function call? i.e. What your thought process would be in this case, that would cause you to reason correctly about (and thereby avoid) the unexpected behavior? 
Optimizing = use less resources. This can well be run well on a low-end system or use less battery.
Sometimes it's the small things that bring great enjoyment! That was a nice piece of code!
Or less programmer time.
&gt; ... a const-reference will behave the same as a (non-const) reference at runtime. It's the compiler's job to enforce const declarations ... This is a very good point. I guess I was trying to have my cake and eat it too - passing large structures by reference for performance while simultaneously using the simplified reasoning of pass-by-value. Lesson learned. &gt; Just a note. The OP's example is a common issue when overloading operators Fair point. I'm aware of the danger of self-assignment when overloading operator=. OP probably shouldn't have surprised me as much as it did. I guess the problem was just that this particular example didn't trigger any of my usual cautionary heuristics - "be careful here!" I've adjusted my thinking accordingly.
For the example given in the article, the associated reasoning is quite simple: If one were to ask "if there were a hypothetical thread that has access to a reference to the value of 'x' prior to it being passed to the function, could it be guaranteed that the calculations within the function would still be correct?" It gets even more interesting when one assumes that the value passed in is in fact dereferenced from some pointer which could potentially be deleted during the process of the calculations by another thread altogether a const&amp; as the parameter type there would definitely be problematic. So there now is the situation of changing values and invalid memory to think about.... But there's still a lot more to consider as these are just the simple ones... :) 
What exactly is the problem that you have with it?
So is this a convenience wrapper around Qt for http oriented requests?
Yes. And has some extra features like a plugin system and WebSocket support. The API is highly inspired by [Node.js](http://nodejs.org/).
I don't know what that image is supposed to mean, but if you want to look at binary output you're better off viewing it in a hex editor.
Their excuse for dynamic c++ is this: "how can one convert dynamic data coming from relational or xml database to html without stumbling over the c++ type system?". It is not a good argument. Either data are completely arbitrary and don't have a type, and therefore all you need is strings, or data have a specific meaning to the application, and so they must be converted to the relevant classes. In either case, dynamic c++ is not needed in any way. 
It sounds like you're outputting raw binary values to the file, rather than converting them to text first.
Is there any way i can decode this into readable text?
How are you writing to the file? I'm assuming you're simply writing raw data - as TheExecutor said - so you'd need to read it in the same way that the program writes it. To do that, you need to know how the program writes it - which includes data types, endian-ness and sizes. In this case, I assume you're using an *int*. That is 4 bytes per value on Windows, and Little Endian on Windows. This means that the first four bytes of your data could be read as: 0F 07 4A 00 // Raw bytes 00 4A 07 0F // Corrected for Endianness 4A070F // Actual number 4851471 // Converted to Decimal Of course, I have no idea if the first four bytes actually do represent a 32-bit Int, or if they are Big or Little Endian, or anything else about it without knowing the actual data structures being written out...
It's not particularly inefficient (not that you need to worry about efficiency in a program like this), but it could be improved. The main issue is repetition: you have a lot of blocks like this int aX; cout &lt;&lt; " \n QUESTION " &lt;&lt; endl; cin &gt;&gt; aX; if (aX == 1) { cout &lt;&lt; "ANSWER" &lt;&lt; endl } else { cout &lt;&lt; "ANSWER" &lt;&lt; endl } You should have a database of questions and correct answers (even something as simple as a list of string/bool pairs), and loop through it, asking the questions inside the loop. Something like vector&lt;pair&lt;string,bool&gt; &gt; questions; questions.push_back(pair&lt;string,bool&gt;("Asia is the largest continent on Earth.", true)); questions.push_back(pair&lt;string,bool&gt;("Greenland is the Earth's smallest island.", false)); int answercounter = 0; for (int i = 0; i &lt; questions.size(); ++i) { string question = questions[i].first; bool answer = questions[i].second; int a; cout &lt;&lt; question &lt;&lt; endl; cin &gt;&gt; a; if (a == answer) { cout &lt;&lt; "Correct" &lt;&lt; endl; answercounter++; } else { cout &lt;&lt; "Wrong" &lt;&lt; endl; } } cout &lt;&lt; "Score: " &lt;&lt; answercounter &lt;&lt; endl;
"N3613 - "Static If" considered" rejecting `static if` is a shame, especially given Andrei's talk, "[Static If I Had a Hammer](http://channel9.msdn.com/Events/GoingNative/GoingNative-2012/Static-If-I-Had-a-Hammer)".
Great job as a first program. Here are a couple points to consider, which you will undoubtedly learn more about in the future. 1) What is the scope of your variables? For instance, you have separate inputs ab, ac, ad, ae, and af. After you use it the numbers just kind of sit around. Instead you could use a single variable (e.g. the "answer" variable) and overwrite it for each question. 2) How can you reduce repetitive code? You copy/paste &gt; \n \n \n Next Question (Question #" &lt;&lt; ++questioncounter &lt;&lt; "):" for each question. If you want to change the format to "\n\nQuestion X:" how easy/difficult is it for your current program? 3) How easy is it to add questions or change the order of questions? To reorder them you would need to physically/copy paste them in a different arrangement. What about randomizing? Yikes! You probably don't have the tools to do the above yet, but keep going and you'll start to see improvements you can make. Once you start making changes though, stick with just one change. One thing at a time and keep checking that your program works as you expect it. Good luck!
I will go with what every one else has said and make one more suggestion. Don't use abbreviated variables. Give them names that makes sense even or particularly if they are long to write. In general if you can't give something a good name then you might have to think about what you're doing. An "ax" variable will mean nothing to you in a few days or weeks. Go ahead and try and use meaningful names.
Thanks for the help but I'm not sure if I understand all of it (the code) , but with time I'm sure I'll be able to! It looks good though! I would like to make a game but this is as far as I can go at the moment, but I'm still learning! Would the database randomize the question order?
Thanks! Yes, I could use one variable on second thoughts, and to change the order, I would have to copy/paste, so randomizing would be good!
Thanks for the advice, I see where you're coming from! 
When people discuss and debate efficiency, it's typically in the context of more complicated programs than these kind of interactive programs. For these types of programs you could write extremely inefficient code and it would still run at the same speed (since the majority of the actual run time of the program is spent waiting for input from the user) and take up about the same amount of memory. So, "efficiency" usually covers one of two issues: CPU cycles and memory usage (there are certainly additional issues such as I/O, etc). Efficienly using CPU cycles involves things like carefully choosing the correct sorting algorithm (so that the program completes the sorting task in the fewest number of passes over the data) or by not needlessly recomputting the same value multiple times (e.g., if you have a program that computes various values for different shapes and you write code that keeps recomputing the area of the same shape over and over again -- where you could have computed it once and stored it in some variable). The other comment regarding the duplicated code is absolutely correct. In a sense, this hints at improving the efficiency of how humans read and understand code. The code that LeszekSwirski suggested would fit on one screen and makes it immediately clear what the code is trying to accomplish. Good luck!
The code, as written, will not randomize the order. But using std::random_shuffle from 'algorithm' this can be done easily.
They didn't include QVariant in the comparassion.
I feel like I'm nit-picking but try to think about the code you are writing as if you're the CPU executing the code. For instance, you declare questioncounter and set it to 0. Then you immediately increment it. Why not just set it to 1 when you declare it? It's a relatively insignificant correction in this context, but learning to think about code in this manner will pay off when reading and writing more complex code in the future.
I agree with your assessment, I would only add that one of the reasons you would use a bool over an int is because a bool is 1 byte vs. 4 bytes for an int. In this situation it's not wrong to use an int, in a larger scale (or embedded) situation it could be much better to use a bool for the memory savings.
A bool also makes your intentions for the variable much clearer than using an int would.
I've glanced at poco once or twice but there doesn't seem to be any documentation beyond 'look at these slides and read the code'.
Any compiler worth it's salt would optimize that out anyway. *That's* the real goal. Learning how various compilers optimize and writing code to reach an equilibrium between readability and optimizability.
AFAIK Poco offers encryption under boost license, some other nice classes, but the real stuff which could be interesting is under their commerical license available.
I think an int is more appropriate because the memory footprint of the answers is tiny and not a problem. The advantage with an int is that it's more flexible, allowing e.g. a value to denote "no answer" or multiple choice answers.
It seems a bunch of stuff is boost licensed. It's just not documented. I'd like a decent network API that implements websockets and http that somebody has written down how to use. They've got a plugin framework too which would be great rather than rolling my own but again the docs are just a set of slides.
It's kind of strange that at this time RAII still needs an introduction, covering several slides. This should be taught as one of the first big concepts. Back to topic: also see the [Rule Of Zero](http://flamingdangerzone.com/cxx11/2012/08/15/rule-of-zero.html) article if you're interested in resource management.
&gt; The only basic types are integral &lt;&gt; floating point integer, I believe you mean...
Nope, he was being precise (maybe not necesarily): &gt;Types bool, char, char16_t, char32_t, wchar_t, and the signed and unsigned integer types are collectively called integral types.
I thought this post was about the presentation, not some product of the same developers.
The answers so far are right but weak. Types are information that you, the human, tell the compiler about how to use data. Types dictate what sorts of operations are allowed on a given blob of data. Any variable, be it a bool, an int, a double, or a class instance are just blobs of bytes (exception: bit-fields, but same idea). By telling the compiler "this blob is an int", you have told it that you may do math on it. If you later try to dereference it as a pointer, the compiler will say "you said this was an int, not a pointer!". Likewise for a class. If you declare a FooBar instance, and then call a method on it, the compiler uses the type definition of FooBar to figure out what code to run. This is also true of const - you told the compiler "don't allow mutating operations on this variable". Type casts and const casts are the "escape valves" that let you say "I know I said this was an int, but pretend it's a pointer to char". Use these with caution. Usually the compiler is more precisely correct than you are.
Thank you! This is really helpful. What about unsigned integers? I take it that assembly actually makes a difference between signed and unsigned integers? Or does it supply special instructions especially for unsigned numbers?
One of the golden rules of C++ programming is to optimize later. Don't optimize until you need it, you might not need it at all. You can spend a good deal of time worrying about efficiency and coming up with faster ways to do something when you should be coming up with better ways to do something. If you use the right architectures, you can make things more efficient later. You should however architect first. Ensure your program has a good code structure and is maintainable so if you do decide you need to optimize something then you can go in and change it without having to redesign large chunks of code. In addition to that you are unlikely to know what the compiler is doing to your code under the hood. For example if you look at: int values; for(int i = 0; i &lt; 100000; i++) { value = value + i; } This looks like a big slow loop. But the compile knows the exact number of iterations because their specified. It will actually turn the entire statement into: value = 4999950000; Even when the compiler doesn't know the number of iterations at runtime, it can still do fancy things like make loops of various sizes: int num_max; // Size is taken from input, so the compiler has no idea how big the loop will be in advance (other than it will be less than the maximum size of an int) cin &gt;&gt; num_max; if(isDivisibleBy(num_max, 5)) { for(int i = 0; i &lt; num_max; i=i+5) { // Now 100000 is only 20000 loops value = value + i; value = value + i+1; value = value + i+2; value = value + i+3; value = value + i+4; } } else { // There are other loops that could be done, divisible by 2, 3, 50, 100,1000 for example. // Of course the more of them that are done the bigger the binary file will be } When you do need to optimize, you use a profiling tool that tells you exactly which parts of your code are running slow rather than just guessing.
Using a function pointer is a bit wasteful when an empty FreeLibrary policy object would do just as well without the extra pointer indirection. class module { struct fl { void operator()(void* module) const { ::FreeLibrary(module); } } ; public: explicit module(std::wstring const&amp; name) : handle { ::LoadLibrary(name.c_str()), fl() } {} // other module related functions go here private: using module_handle = std::unique_ptr&lt;void, fl&gt;; module_handle handle; };
I'm really not going for memory efficiency here, it was an entirely semantic choice.
Is this your first foray into any sort of programming? If so, I'd actually recommend not starting with C++, but rather starting with something like Python. That should do a much better job of teaching you things like lists or loops, and once you have a decent grasp of those, you can move on into C++.
I'm alright at HTML and a bit of CSS, which isn't really helpful with c++. I got quite good at java as well but due to the fact my computer cannot run it quickly I choose to switch over to C++.
Thanks for the help! Is the profiling tool a download that tests your program or is it built into the IDE?
That I never knew! I do now.
It depends on the operation. For example, on the x86 architecture, addition behaves the same for signed and unsigned integers so both signed and unsigned addition compiles down to an `add` instruction. This is not the case for other operations like division, so there is a `div` instruction for unsigned division and `idiv` instruction for signed division. Conditional branches sometimes differ as well. For example, `if (x &lt; y) {...}` may generate a `jge` (jump if greater than or equal to) instruction if `x` and `y` are signed and a `jae` (jump if above or equal to) instruction if either `x` or `y` is unsigned. However, equality testing doesn't depend on the signedness of integers, so `if (x == y) {...}` will generate a `jne` (jump if not equal) instruction regardless of the signedness of `x` and `y`. Different instructions will also be generated for types of different widths. `addl` adds two 'long' (4 byte) values and `addq` adds two 'quad' (8 byte) values.
There is more then that, but still the docs could be improved: http://pocoproject.org/docs/
Throwing exceptions from a constructor is [totally fine](http://www.parashift.com/c++-faq-lite/ctors-can-throw.html). The destructor isn't called, but that does not matter in this example, because the fopen call failed anyway.
The point of placement new is that you can call a constructor using memory that's already allocated. It's explicitly designed to work with RAII, there's nothing about initializing in the constructor that stops you from using it - you allocate the memory and use placement new to call the constructor later.
This is a good answer. The CPU does not know whether a particular set of bytes is signed or unsigned, but it does offer instructions that implement the standard signed and unsigned operations. The compiler knows, based on whether you told it the integer was signed or unsigned, which instructions to emit when producing assembly code.
So you imply that Qt's style is more similar to Boost's than Poco's? I start to think you haven't use any of them
Here's some more info on custom memory allocators. https://molecularmusings.wordpress.com/tag/memory-allocator/ [http://www.google.com/search?&amp;q=altdevblogaday+allocators](Google: Altdevblogaday allocators)
Prior to C++11 you can't really. The std::allocator isn't allowed to have state, so you could forward to a global PoolAllocator or whatever, but you couldn't pass in instance of a PooAllocator to a std container. C++11's std::allocator does allow your allocator to have state, but I haven't tried using it myself so can't give an example.
Thanks! I'm using codeblocks so I'll look at the standalone profilers! The other solution seems good as well!
I'm currently migrating (for learning purposes) a codebase from pre-2006 C++ to modern C++. This code is mixed with MFC and old school C++. I am changing the code to use smart pointers, STL algorithms, lambdas, move semantics wherever possible and migrating MFC containers (CList, CString) to standard C++ ones. I'll run your tool on the original version of that codebase to see what happens. Can an automated tool figure out the scope of new &amp; delete and use smart pointers instead? Or figure out that an int based loop (as opposed to an iterator based one) actually works on a vector and use range-based for? Or examine a loop and know that a standard algorithm can be used here? 
Pardon my ignorance, but what is the difference between using module_handle = std::unique_ptr&lt;void, fl&gt; and typedef std::unique_ptr&lt;void, fl&gt; module_handle?
&gt; is this class during its life being used by more than a single thread, or more specifically, is a certain section of code used by more than a thread It seems that the provided code only checks if the code is used by more than one thread *at the same time*.
Apparently the C++11 standard states they are equivalent; however, the using syntax allows you to create templates typedefs. 
Hey, We are already convinced that we want it. Just to let you know why we don't yet: The "yearly renewal" - together with the steep renewal cost of 80% of initial purchase - creates a big problem. We now basically have to create a "quality assurance project" and a lot of powerpoint slides and paper and and whatnot to get the OK for this. Management is hesitant with ok'ing "automatic repeated cost" that is hard for them to evaluate the benefits. Developers don't want an "OK maybe this year, but you have to convince management again every year". Please understand that this is not a complaint about the *price* as such. I understand the purchase is for five seats - and personally I'm totally OK with that because this forces us to not just put it on one desk. Also, at least I personally do not doubt the value matches the price. It is just that the pricing model makes it hard for us to purchase. The price looks bad on paper. A less steep renewal (percentage-wise) or a subscription that lasts for two or three years would be easier. --- to everyone else: Try it. On the biggest project you have running. It's fun! 
The importance of ADL is often overlooked in this regard. The rise of get, begin, end as free functions makes me wonder if a common verb convention for C++ could come in handy. 
Thanks for detaild comment. Please see [Why don't you sell unlimited time licenses?](http://www.viva64.com/en/d/0253/#ID0EFBAG) and [OK, sounds convincing, but why don't you let the program work normally and only quit providing updates and user support when the license expires (as some vendors do)?](http://www.viva64.com/en/d/0253/#ID0EPXAG) in [FAQ on PVS-Studio licensing and ordering](http://www.viva64.com/en/d/0253/). Also you can write us if you interesting to 2-years license. We can provide it for you.
This article was one of the reasons D implemented [Universal Function Call Syntax (UFCS)](http://ddili.org/ders/d.en/ufcs.html). One interesting feature that came because of this that wasn't really planned was how it allows you to chain random functions. import std.range, std.algorithm, std.stdio; void main() { recurrence!((a,n) =&gt; n)(1) .map!(a =&gt; a*a) .filter!(a =&gt; !(a%3)) .take(100) .writeln(); } That would print out the first 100 squares that are divisible by 3. 
'`std.stdio`' seems interesting, is there a reason for duplicating the 'std' part?
Legacy. It's basically a wrapper over stdio.h. The replacement for it is going to just be called std.io and isn't just a wrapper over stdio.h.
And what gain is there over Valgrind or other existing solutions? 'No gain' is a fine answer, but just curious.
crash and burn trying to compile with msvc11, x64. tracey.cpp(109) : fatal error C1060: compiler is out of heap space or tracey.cpp : fatal error C1902: Program database manager mismatch; please check your installation on windows we only compile in release mode, not sure if this is a problem or not. not a huge deal, I do all my hardcore development and analysis work using linux anyways.
Well it looks like it supports windows which Valgrind does not. Stuff like that should be more clear in the Readme file!
It should work with any 32/64+debug/release combination mode. Can you throw more information at this so we can fix it out together? Line 109 is an #error directive that has nothing to do with heap! Thanks for reporting :D edit: in case msvc compiler is running out of memory for some reason, does /Zm flag fixes it? 
Tracey keeps a map of pointers and related callstacks. For every malloc it creates an entry in this map, and for every dealloc it frees this unique entry. At exit, it prints all remaining entries in this map in a pretty way. That's the basic idea until it gets more complicated as you get into threads and recursive allocations. The runtime is slower than regular builds but it prints very detailed information. Thanks for reporting back! 
No gain, I guess. Just another alternative that works for me. Hope it helps someone :D
I can't count the number of times I've sent that article to someone to convince them to break up their huge class file...
if it is simpler than valgrind i've got one coworker already interested
Sounds just like what I want. How does it hook into malloc/free? Oh also: How dependent is it on C++11? It looks like std::mutex and friends are needed at least. This means that I'll have trouble trying it on my VS2010 projects - but I don't mind a bit of hacking to use boost threading and other workarounds for VS2010 to see if this is useful. I've lamented the lack of decent simple and free heap profilers or windows before so I feel compelled to do something about it!
malloc/free is not hooked atm :( looking some nice way to do it. tracey used to work on VS2008, with tinythread++ library instead! just include namespace std { using tthread::mutex; using tthread::thread; } :)
Great. I used the tinythread++ library before and was very impressed. Shame about malloc and free! Hooking these guys seems like the main reason heapcheckers could be tricky on windows. I'll let you know if I figure out a way to do it. Just new/delete should be useful enough for me right now! I see that you just define the relevant new operators in your code. Does this just override the ones defined by the standard libraries. Do you know if this a feature of C++ (the standard) or something MSVC and GCC let us do? (Sorry for asking so many questions, but I thought about creating a heapchecker before but was too lazy :)
Related: "[What's In a Class? - The Interface Principle"](http://www.gotw.ca/publications/mill02.htm) and "[Namespaces and the Interface Principle](http://www.gotw.ca/publications/mill08.htm)" by Herb Sutter Class (definition) A class describes a set of data along with the functions that operate on that data. *That definition is exactly right, for it doesn't say a thing about whether the "functions" in question are members or not.* * **The Interface Principle** + *For a class X, all functions, including free functions, that both (a) "mention" X, and (b) are "supplied with" X are logically part of X, because they form part of the interface of X.* * Therefore both member and nonmember functions can be logically "part of" a class. A member function is still more strongly related to a class than is a nonmember, however. * In the Interface Principle, a useful way to interpret "supplied with" is "appears in the same header and/or namespace." If the function appears in the same header as the class, it is "part of" the class in terms of dependencies. If the function appears in the same namespace as the class, it is "part of" the class in terms of object use and name lookup.
&gt; on windows we only compile in release mode wat
why not? we always compile everything release mode. debug builds are especially useless for heavily parallel programs. If there's problems I can usually recreate under linux, then do selective individual file debug compiles there as necessary. Build hell is something we avoid like the plague on windows, it's just not a developer friendly platform. I'll probably do more systematic checking tomorrow (build the sample), etc. and this did work out of the box fine on linux. It might be interesting to check performance against valgrind.
The PVS-Studio analyzer is intended to work on the Windows platform. It integrates into Microsoft Visual Studio and Embarcadero RAD Studio. 
malloc/free will need some more work indeed. there are some tricks to do it, but I would like to stay as clean as possible. overloading new/delete is a C++ feature :) http://en.cppreference.com/w/cpp/memory/new/operator_new
I just tested msvc12/x64 and it works. Must be some msvc11 issue. Some more info please? :)
okay that was easy. Change build from MD to MT and it blows up cl sample.cc tracey.cpp /MT /Zi -DkTraceyReportOnExit=1 tracey.cpp(109) : fatal error C1060: compiler is out of heap space even /Zm2000 doesn't help this.
/MT and /MTd are not supported. When using /MT Tracey should report something like 'tracey.cpp(118) : fatal error C1189: #error : Incompatible C Run-Time libraries compiler flag detected ( /MT ) : Use /MD instead'. I cant figure out why heap error is being printed instead, though.
Thank you for this great little tool! Some comments: - Couldn't build on Mac OSX Lion with Clang: backtrace() could not be found, because the line \#include &lt;execinfo.h&gt; was ifndef'd out. Commenting out \#ifndef \_\_APPLE\_\_ helped. - In lines 1065-1066, the first line is not needed: container::iterator it = map.find( ptr ); bool found = ( map.find( ptr ) != map.end() ); - I think "excellent" and "good" are mixed up. - Your trick with $windows $welse is neat, but it totally mixes up my debugger, setting a breakpoint in an enabled block jumps to the end of the block. I think it'd be nicer to stick to \#ifdef \_WIN32 \#elif defined(\_\_GNUC\_\_) \#else \#endif - The demangling of backtrace_symbols need to be changed for Mac, I'm working on that.
Hey, thanks for the input! Good catches! I just tweaked my code branch. Thanks very much. Waiting for that backtrace_symbols() for macosx! :D thx
That is the first entry on the list of things he's looking for help with.
Why oh why are some of the most useful Microsoft developer tools so hard to find?! Maybe I missed it because I first started looking whilst I was using VS2008. Any more neat tools I might have missed?
PVS-Studio is about 1/3 to 1/2 the price of "the big 3": Klocwork, CodeSonar, and Coverity. The big 3 also have high yearly costs. The big 3 though do support non-Microsoft compilers and non-Windows OSes.
Here's a idea. Run the tool on an old version of your software (from your source control) and on a recent version of your software. Then you can compare the results and find out how many bugs the tool would have identified for you. I'm sure you have metrics on how much developer time, QA time, and documentation time it takes to fix a typical bug that escapes past QA. (If not, a typical value in the industry is 24 hours or 3 man-days.) Using a static analysis tool can help you fix bugs usually in 1 hour or so. Using these numbers it is really easy to figure out how much money a static analysis tool will save you strictly in development costs. (Don't forget to factor in false-positives so that you get a more accurate result.) You can also mention opportunity costs for slower development. That value is more difficult to estimate and you might want to discuss with someone in sales and/or marketing to help you come up with numbers here This data can be used to give a quite convincing presentation to management (or possibly convince you that the costs of the tool are not worth it).
… Sorry, I guess I skimmed. My bad. :-P
Why bother when you have had access to the same kind of information for a long time through debugging symbols, both on Linux (libdwarf) and Windows (http://msdn.microsoft.com/en-us/library/x93ctkx8.aspx). You have just reinvented the hot water. EDIT: Giving credit where credit is due. In fact, using debugging symbols for reflection has been done in the past, see here: http://www.garret.ru/cppreflection/docs/reflect.html
Thanks for posting this :) Current status of the project is that it's very stable and compiles across 3 platforms (Windows, Linux, Mac OSX) and works in 32-bit/64-bit. I'd love to make a clang plugin but I have no time, currently. Containers need a bit of work bringing to maturity, there's not a great split of functionality between core and utility code and the build system is still a bit wonky. I'd love opinions on how any of this can be done better/simpler. Patches are even more welcome! Poor form from zvrba, though: using unchecked assumptions to accuse somebody else of unchecked assumptions... In developing clReflect I went over the entire spectrum of approaches to reflection in C++, from manual registration, through debugging to native compiler support. Here's my reflection engine that uses PDB debug symbols, written before clReflect: https://bitbucket.org/dwilliamson/rfl As you're so eager to promote hot water, I'll leave you to deduce why the approach is not as ideal, and has specific problems that can not be solved :)
A great and insightful article as always. You raise a concerning point about some compilers not implementing the new C++11 features quickly enough. AFAIK, gcc, clang, and icc are the only three compilers to implement most major features of C++. Since C++14 does not propose many ambitious features, hopefully it will provide enough time for all of the compilers to be on par with respect to standards adoption.
Yep I can't wait, by the time I have children and teach them to code, C++ compilers might have implemented the module system proposed in C++23. That's not a joke he didn't think modules were likely in C++17, and I assume C++20 will be another minor release.
I know it's generated but... for (auto &amp; elem : myVec) Please. If you can, don't use meaningless names for your auto variables.
Well, at least currently its not surfacing for C++17, but there is still enough time. The current trend goes to put up Technical Specifications, maybe a TS for modules comes with Chicago or next years meetings.
Ah, no swap operator? :P
I'm really hoping the Clang implementation will progress fast and will result in a mature proposal that can end up in C++17. I fear the scenario you're describing :-(
Why does C++ need a module system? And what do people mean by "module system"? Do we mean a replacement for headers or a replacement for DLLs/SOs? It's pretty tiring watching people trying to shoehorn every high level language concept into C++. 
More as a replacement for header files, and it would be a godsend, especially for template programming.
&gt; I’m pretty sure that there’s a better name for this, but I’m going with iterator_pair for the moment. Yes, it's [`boost::iterator_range`](http://www.boost.org/libs/range/doc/html/range/reference/utilities/iterator_range.html).
I'm curious how string_ref might interact with C-style string functions? Since a string_ref view may not be null terminated it could have to be converted back to a string or a char buffer to be passed to something like printf. Or is there some clever way of making this work that I haven't though of?
No, but I am still pleased to see that that they are keeping the vital [--&gt;](http://stackoverflow.com/questions/1642028/what-is-the-name-of-this-operator) operator.
This is very disappointing. I was expecting atleast 50% of the papers to be accepted. Atleast concepts lite has to be accepted. That will make most c++ programs human readable. BTW, what is a Technical Specification? How is it different from standard?
Most software is continually updated with bug fixes and new features. Maybe it's time C++ had incremental changes every 1 or 2 years. I imagine it would make the whole process a lot more manageable.
Thats explained here: http://isocpp.org/std/iso-iec-jtc1-procedures
Is that actually true? Can't the compiler check that i is a local variable and therefore *p can't be an alias of i? I compiled both versions with MSVC 12, and they both look the same: __declspec(noinline) void foo(int* a, int len) { 00D51270 push edi 00D51271 mov edi,ecx int *p = a; for(int i = 0; i &lt; len; ++i) { *p = 0; 00D51273 mov ecx,64h 00D51278 xor eax,eax 00D5127A rep stos dword ptr es:[edi] 00D5127C pop edi ++p; } } 00D5127D ret __declspec(noinline) void foo(int* a, int len) { 00F71270 push edi 00F71271 mov edi,ecx int *p = a; for(int i = 0; i &lt; len; ++i) { p[i] = 0; 00F71273 mov ecx,64h 00F71278 xor eax,eax 00F7127A rep stos dword ptr es:[edi] 00F7127C pop edi } } 00F7127D ret 
Moving to a new version every three years is already a huge step in that direction compared to the 13 years between C++98 and C++11 (C++03 doesn't really count, but that'd still be 8 years).
Why not just use std::for_each &amp; lambda?
 [**@sdt_intel**](http://twitter.com/sdt_intel): &gt;[2013-04-19 16:45](https://twitter.com/sdt_intel/status/325289093170864129) &gt;Clang is C++11 feature complete as of *just now*! Here's the final commit by Richard Smith: [*llvm.org*](http://llvm.org/viewvc/llvm-project?view=revision&amp;revision=179858) [#llvm](https://twitter.com/search?q=%23llvm) [#cxx11](https://twitter.com/search?q=%23cxx11) ---- [[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/1cor7b%0A%0APlease leave above link unaltered.) [[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [[Translate]](http://translate.google.com/#auto/en/Clang%20is%20C%2B%2B11%20feature%20complete%20as%20of%20%2Ajust%20now%2A%21%20Here%27s%20the%20final%20commit%20by%20Richard%20Smith%3A%20http%3A//llvm.org/viewvc/llvm-project%3Fview%3Drevision%26revision%3D179858%20%23llvm%20%23cxx11) [[FAQ]](http://www.reddit.com/r/TweetPoster/comments/13relk/) [[Statistics]](https://www.stathat.com/decks/PJSe8OF5J44Y) 
Color me impressed. It took only 2 years to have a C++ 11 standard-compliant compiler. What a difference from C++ 98 !
&gt; Those snippets make **great** quiz questions for my students. Have an upvote! You misspelled "terrible".
&gt;What square brackets really mean Yeah, the old'n'cute C trick. Thing is, in C++, most of the time, you're using an overloaded [] operator anyway. &gt; Most vexing parse Classical gotcha. Anything that can be interpreted as a function declaration, will be. &gt; Alternate operator tokens Do recent compilers still recognize digraphs? What about trigraphs? &gt; Placement new This is actually a good test for a book about C++: if it doesn't talk about placement new, you might want to try another book. But then again, its main use seems to be to reimplement `std::vector`. &gt; Turing complete template metaprogramming Alexandrescu has written a whole book on the subject: "Modern C++ Design". &gt; Static methods on instances &gt; Overloading ++ and -- &gt; Functions as template parameters Uh... "obscure"? These are pretty basic. Or, did I miss something? &gt; Function try blocks See [GotW 66](http://www.gotw.ca/gotw/066.htm). Overall, I find them rarely useful. 
Well, I dunno. A few of them are pretty terrible, but some (static methods, overloading ++, functions as template parameters) are basic C++ features that students must know.
&gt; Redefining keywords via the preprocessor is technically supposed to cause an error but tools allow it in practice. It's forbidden to do this in the presence of STL headers, and VC's STL will detect this and explode. (I plan to make this detection even more stringent in the future.) Never do this. &gt; Also, member function pointers may be up to 3 times larger than regular pointers. I believe the correct number in practice is 4 (it's unspecified, of course, in the Standard) for "unknown inheritance".
How is it detected?
&gt; I believe the correct number in practice is 4 (it's unspecified, of course, in the Standard) for "unknown inheritance". Interesting! I wasn't aware of the unknown inheritance case. I just checked and Microsoft's compiler does indeed use four pointer slots. Any idea on what the fourth slot contains? I couldn't find any documentation. 
Congratulations to the clang team. It is interesting how the pace has picked up from c++98. Also proof that C++11 is actually implementable with no features like C++03 export
Let's hope the elephant in the room (msvc) follows suit as soon as possible.
Solaris Studio is even worse. Much worse.
MSVC still has a lot of bugs and issues with C++98 that still haven't been fixed, particularly with templates.
Examples? I am actually curious about this. Currently working on some heavily templated VC6 code and I forgot just how bad it was back then curious on the issues now.
Newbie programmer here: How long did it take for a compiler that was C++98 feature complete to show up after the standards were available? I've been reading up on some of the new features of 11, and I like what I'm seeing; even as a newbie. I've only recently got into C++, however, so I don't know much about it's history besides the wiki page... I may have missed it.
There is an obscure feature called #ifdef.
Fortunately it's pretty much irrelevant.
I deserve so much more shame for that question. That is so obvious it hurts. 
That really hit the spot. I've been at this for the long time, but there was at least one thing that was totally new to me (function try blocks, outrageous!) and lots of my favorite weird parts of C++ which I rarely visit. A tasty article!
Now all that it needs is an install package for Windows. 
Hell, MSVC doesn't even support C99 properly.
And they probably never will. Maybe it's because so much open source software is written in C(99), that they just don't want it to compile on their platform with their own compiler? I dunno, maybe..
I compile my stuff on both from time to time to make sure my crappy code works on both of them. Clang seems to be a bit more strict at times. Anyway - probably a good idea to use both.
Last commit? Those are some big words :P
Never attribute to malice that which is adequately explained by incompetence. I believe they said they'll never support C99 because their users would rather more complete C++11, better optimizations and error messages, etc. than a more up-to-date C compiler, although where they announced this escapes me at the moment.
Well how about: "API doesn't support enums, unions and bit fields." vs "Reflection of: basic types, enums and their constants..." Debugging information isn't designed for that kind of usage, there will be plenty lost in translation and the reflection library will still have to pass output it's just dwarf rather than a compiler AST. clang however will parse the source code so should have complete access to everything. Only issue is that you will have to use Clang but libdwarf is a requirement with the other so I don't really see any advantage/disadvantage... Hopefully we will get proper standardized C++ reflection in C++14 (or more likely) C++17. Of course if you are willing to limit your compiler to Clang (as opposed to just requiring it in your toolchain) you might be able to get an experiential draft implementation early.
I never made the connection that function try blocks could be used on more than constructors, either. 
What was the first? Comeau?
AFAIK, they're not even trying: They've given up on C entirely. The have a very old C90 compiler for legacy code, and that's all.
How does Clang compare to GCC for C++ compiling?
In my experience it (clang) uses far less memory but takes longer to compile. The error messages look a little bit better in clang but g++ is getting better. I haven't done much to measure performance differences but they seem to be fairly similar in that regard, with g++ taking the lead.
For some reason the link is not working for me. I found a copy here: http://planet.qt-project.org/#itemadc4342c
I compile with both. gcc is still far superior when it comes to finding errors/problems/giving useful warnings and code output quality. As long as you're not using any feature that gcc doesn't support, why not?
:-&gt;
clang error messages are prettier and it compiles things faster, but gcc has lots more warnings and error messages and finds more problems with your code in general. Last time I benchmarked them against one of my numbercrunching applications, gcc produced significantly faster code, but that was about a year ago, roughly. In summary, there is really no reason to not use both. For the final output I use gcc, but whenever I stare at a gcc error message for longer than 5 seconds without understanding it/the cause, I just look at what clang gives me, since that's often better formatted and contains references to the original code etc.
operator= doesn't have to return a reference... though it can. You can even have it return void, and prevent such chaining.
PDB format has been significantly extended since the cited article has been written. (The link I gave reads PDB files generated by VS6). Also, for reflection, you need to know (among other things) field offsets within structures: this is exactly what a debugging format is designed for, but is missing in the basic AST. (The AST's meaning is independent of the concrete representation of the datatypes in question).
Most of the C++11 details were known from the C++ Technical Report 1 in 2007. GCC and Clang had at least that long to prepare.
- You can't use auto - You can't use break - You have to use return to continue, which is ugly - The whole syntax of for_each is more ugly than for
Ok so I got a this version to run without errors, but obviously I can't be sure that its doing what its supposed to do just because of that.. Can you tell me if this is correct? :) Customer (string a, int b) { name = a; balance = b; has_been_copied = false; cout &lt;&lt; "made a customer"; } Customer(const Customer&amp; copy) { name = copy.name; balance = copy.balance; has_been_copied = true; cout &lt;&lt; "copied a customer"; }
Most popular C++ compilers still are not C++98 compilant. GCC, clang, MSVC, Intel, Sun, ... they fail to support template export*. Probably a better question is when did the first compiler come out to support all C++98 features that are still a required part of C++11. But I don't know the answer to that. EDIT: I accidentally wrote extern template instead of template export.
std::regex. I need std::regex. Come on GCC!!!
Really? I thought GCC supported extern templates - I thought I had used them as early as GCC 4.1. Perhaps I don't fully understand the feature, so take that as you will. (I should do some reading tonight.) But the answer to the better question is simple: Comeau. I don't know when, but it was them. But both GCC 4.8.1 and Clang 3.3 claim full support for C++11, presumably including full support for those C++98 features not removed by 11. That just leaves... everyone else.
Oops... I meant 'template export', not 'extern templates'. My mistake. Comeau was the first commercial compiler with full support, but EDG was the group that did the front-end (which all fully compliant C++98 compilers use). GCC does not support template export.
Hasn't it been deprecated?
Done and done. http://www.ishani.org/web/articles/code/clang-win32/
I think this says it all: http://blog.llvm.org/2010/04/amazing-feats-of-clang-error-recovery.html
While we're discussing the lesser known rules of c++: namespace __hidden__ It's not a great idea to use double underscores in your names. I've actually had legacy code break because of that. "17.6.4.3.2 Global names [global.names] Certain sets of names and function signatures are always reserved to the implementation: — Each name that contains a double underscore _ _ or begins with an underscore followed by an uppercase letter (2.12) is reserved to the implementation for any use. — Each name that begins with an underscore is reserved to the implementation for use as a name in the global namespace."
Oh that one is neat. Looks like it works in 2012 though.
Intellisense says it is an error, but the compiler doesn't. 
I think the important thing is what the compiler does. btw the intellisense used in msvc is powered by an EDG frontend and is not the frontend used by the actual compiler. In short a compiler can't be called conforming where such simple problems exist. The day an msvc compiler completes plum hall with a 100% success rate, will be a really interesting day.
Well, the question says to create a copy constructor which copies the name and balance member variables and sets has\_been\_copied to true. Did you... 1. Define a copy constructor? 2. Copy the name member variable? 3. Copy the balance member variable? 4. Set has\_been\_copied to true? If you're not sure about any of these questions, ask away.
GCC has full C++11 support for a couple of days now. http://gcc.gnu.org/projects/cxx0x.html 
No! TR1 were just a few library enhancements. But you are of course right the C++11 details were known in advance and the standardisation process is open and both GCC/Clang started implementing C++11 features way before the standard was finalized.
It was removed from C++11.
Ok Clang, now get working on OpenMP.
GCC has improved their error messages immensely as well as compilation speed (after Clang gave them hell on both), but the one thing that I like about Clang is its modular design, which allows people to create all kinds of neat plugins and extend the tool chain. And Clang has a built-in static analysis tool — it's still rudimentary compared with professional solutions like PVS-Studio, but it has saved me hours in debugging already.
You need placement new to write stuff like a tagged union type, arena or a ring buffer too. I wouldn't call it obscure at all.
Absolutely. There was just a [question on S.O.](http://stackoverflow.com/questions/16049329/write-only-pointer-type) a couple days ago about creating a "write only pointer" that used this technique (question pertained to embedded systems, so it was of particular interest to me).
&gt; I wouldn't call it obscure at all. That we definitely agree on.
Thanks a lot!
It's painfully obvious that MS's compiler team is woefully understaffed, especially given it's importance to the platform. It's not malice, it's the fact they scarcely have enough resources to implement C++.
Thanks!
You are totally missing the usage of initialization list, the correct way to write you copy constructor is the following: Customer::Customer(const Customer&amp; aSource) : name(aSource.name), balance(aSource.balance), has_been_copied(true) { } note that with that semantic value of "has_been_copied" I wouldn't call it technically speaking a copy ctor
It has to, if you ever plan to keep elements that have it in standard containers.
Lambdas can't be any more terse. If you want to write just a parameter name and no type, how will you disambiguate an unnamed parameter? No choice for that issue will get past the committee; the ambiguity just has to be avoided entirely.
I believe that it got [changed a bit](http://lists.cs.uiuc.edu/pipermail/cfe-commits/Week-of-Mon-20130415/078426.html). It seems it now guarantees stack allocation and does support range based for. I'm not sure why you say it's stupid. It certainly is easier than using a vector for small n, and you get guaranteed stack allocation. You can still use std::algorithm, just like with a regular array. It's also fairly likely to get cached. It's already a language extension that every major compiler supports, and clearly is in high demand.
Can't wait for *The C++ Programming Language, 5th Edition*.
Thanks for your comment; I hadn't realized there was [a 4th in the wings](http://www.amazon.com/The-Programming-Language-4th-Edition/dp/0321563840); yay!
We had it in our original proposal. It was voted down. Syntax is always a hot-button issue in the committee, even moreso with lambdas. I'm guessing people didn't like it because it didn't fit into the spirit of the language (it is completely unique syntax for a function body).
I'd prefer to have fixed that by allowing the syntax for non-lambda functions if the inconsistency is such a deal breaker. The current lambda syntax is sufficiently terrible that I still use boost.phoenix fairly often. auto will help a little, but it's still a very boilerplate-heavy construct for something that benefits so much from being syntatically lightweight.
Well &amp; currently means capture by reference. But what's you're trying to do with move capture is capture by value but using a move constructor instead of a copy constructor. So &amp;&amp; is kind of misleading since it can be interpreted as capturing by reference.
Thanks a lot! using namespace std; worked. I remember using this in every program when I first learned C++. The book I am reading has a 1999 copyright. Maybe I will look for something newer. I took one semester of C++ and rarely used it again. Most of my curriculum was MATLAB-based. I had a teacher that gave us all of the cpp code so I feel like I didn't learn much. I am open to any suggestions on books for learning cpp. Thanks again I am happy! Thanks for the quick response. Working Screenshot: http://imgur.com/xejS4Cr
&gt; add "using namespace std;" at the top of your source. This solved my problem. Thanks for your help!
FYI there are people who suggest not using `using namespace std` because that means you can't, for example, name a variable `cout` anymore, but that's not immediately obvious from looking at the code. I'm not a C++ expert so you should probably look into that on your own.
Thanks for your help. I'll look at the sidebar and see what books I find.
[You might want to see this.](http://stackoverflow.com/a/1453605/559931)
Thanks! I'll try to never use "using namespace std;" 
&gt; Edit: Thanks to everybody that helped me. I would also like to thank everybody that downvoted me. This subreddit is so mean! I will unsubscribe. Sidebar says: &gt; For C++ questions, answers, help and advice see r/cpp_questions. Also, these sort of questions might be better suited for stack overflow.
Well working in C++ is already difficult. If I have to ratchet up the difficult a notch by only using Clang and implementing module map files for everything I just might.
Thanks for the information. It's interesting to see the difference in language evolution between committee driven and "benevolent dictator" style languages.
&gt; runtime-sized arrays as members ill-formed This really hurts usability. Of course, allowing this would make the implementation of runtime-sized arrays much more difficult. (Indeed, the current proposal basically allows the compilers to use the extensions for runtime-sized arrays that already exist.) But being able to use runtime-sized arrays as members would allow you to do things like conditionally use heap allocation.
It is called MSVC++, a C++ compiler not C. Microsoft already stated C is legacy on Windows and developers wishing to use C compilers to target Windows should use other vendors.
Making "a" mean "auto a" would be problematic for multiple reasons: * It copies, which is inefficient for std::string. * It copies, which is impossible for unique_ptr. Consider an algorithm like count_if(), which will present elements as lvalues to the predicate. * It copies, so modifications don't affect the original. I plan to propose "for (elem : range)" at Chicago (I wanted to for Bristol, but ran out of time), expanding to "for (auto&amp;&amp; elem : range)". This is because in a range-based for-loop, you almost always want to work on the elements in-place. I do not know whether this would be a good idea for lambdas.
You're welcome to make a proposal and hear about all the problems from other committee members. :) For one, your proposal is not how names are disambiguated anywhere in the language.