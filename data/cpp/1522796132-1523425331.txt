&gt;Imagine that you have X programs that statically link against library Y. If there is a bug in Y you need to recompile and distribute and install X programs. If they are dynamically linked you can simply replace Y. While a true scenario, if a new version of Y is deployed that has a bug or a compatibility issue then you've broken all X applications as well. &gt;The problem is that c++ doesn't have an single dependency management/ build tool This is I think the biggest issue, but what would such a dependency management/build tool look like for C++ since the end result is native binaries? Would it fetch say some form of pre-compiled or source code and build it on the fly for the target platform? Or do we just need a Maven type repository with pre-compiled binaries for each platform and use a classifier like we do in Java for native jars as for example the lwjgl (opengl for java) does to fetch the platform shared libs?
Here's my flow: Mandatory and not modified =&gt; const reference Mandatory and modified =&gt; reference Mandatory and moved (constructors, sinks, etc) =&gt; value For all optional values, prefer function overload that simply does not take the parameter. If that's too much boilerplate then use a pointer.
since C++11 `RandomAccessIterator{It}` would mean a temporary instance of RandomAccessIterator with It passed to the constructor. But I guess the same syntax meaning completely different things in different contexts is the C++ way... It's like they want to make the language hard to use.
&gt; really exercises modern C++ features like user-defined literals. There's a grand total of two user-defined literals in that paper that's specified in six lines total.
std::optional these days. Or the boost version.
C++17 is bleeding edge, not everyone has the luxury of using it. Even the changelog for GCC 7 states: &gt; Experimental support for C++17, including the following new features: &gt; std::string_view; &gt; std::any, std::optional, and std::variant; So you're looking at using a version of GCC that's about 7 months old to get a "stable" version of optional. As for actually using optional, well, needing `std::reference_wrapper` is a pain in the ass. The API is clumsy and bloats my text segment to boot. any, optional, and variant should be in the language.
Don't have output parameters. Return multiple values by struct. It's not inefficient in Modern C++.
This subreddit is a joke... you’re being downvoted for being reasonable, trying to show the opposite viewpoint without really spousing it as your own, and yet the crowd around think that personal attacks are in order.
Hello, Very interesting. I just have a little remark on your for_each implementation. Did you forget to tag the function constexpr ? (you use if constexpr inside) I had to make a for_each for tuple a while ago, I recall I came with an implementation looking like this : namespace details { template &lt;typename F, typename... Args, typename... Ts, size_t... I&gt; constexpr void for_each_impl(std::tuple&lt;Ts...&gt;&amp; tpl, std::index_sequence&lt;I...&gt;, F&amp;&amp; func, Args&amp;&amp;... args) { (std::forward&lt;F&gt;(func)(std::get&lt;I&gt;(tpl), std::forward&lt;Args&gt;(args)...), ...); } } template &lt;typename F, typename... Args, typename... Ts&gt; constexpr void for_each(std::tuple&lt;Ts...&gt;&amp; tpl, F&amp;&amp; func, Args&amp;&amp;... args) { details::for_each_impl(tpl, std::index_sequence_for&lt;Ts...&gt;{}, std::forward&lt;F&gt;(func), std::forward&lt;Args&gt;(args)...); } It's better to use an index sequences to avoid the recursive call. You can then unroll your tuple around the coma operator :) . Just my 2 cents.
Hi, thanks for your comment ! Indeed, the index sequence is better seems better than my recursive version, i'll do that c: A constexpr function has a lot of limitations : for exemple, if calling func can throw, the function can't be tagged constexpr. I don't understand how it should affect 'if constexpr' :s
It already exists with `enum class` though, right? Breaking C stuff is much harder since there are a lot of people opposed to it. I agree that all enums should be `enum class` by default unless you `extern "C"` them but this is probably not happening.
You mention kernel bypass, but I didnt see anything beyond in the read me. Can you elaborate? I.e. can this be done with commodity HW, or does it only work with certain vendors? I ask because we currently pay out the wazzup for solarflare cards for kernel bypass.
Thanks for ur question. kernel bypassing means two unrelated things to me in hmbdc. - completely avoid using pthread synchronization tools (or other kernel supported thread synchronization tools) in the performance sensitive code paths, - hmbdc-netmap uses the kernel bypassing netmap driver Also, hmbdc is developed and tested for commodity HW. The performance data list the HW model where the test was done at.
The first should be a bug, if you compiled against the same standard library. You can't mix two definitions of std::vector, for example. And, yeah, if you want to link system libraries, you have to make sure you're using the same ABI affecting flags, which usually means the same std level, -D options, etc. Other languages deal with this differently. Usually by compiling much later, if at all. C has the same problem, although somewhat less because there's less inlining.
It's no secret that C++'s syntax is context sensitive. Even `k * x` is ambiguous without knowing what `k` is. Also, currently `RandomAccessIterator{It} it = …` is not valid syntax.
ah man, this sounds like one of those academic types trying to explain to us that all our problems will be solved if we accept formal verfication/actors/Haskell... as our savior...
Frankly, I would have preferred the adjective syntax. I have a hard time believing it was refused because of the extra `typename`. template&lt;Number typename N, Numeric auto value&gt;
window
That doesn't solve everything. How would you go about this: template &lt; Mergeable{In1, In2, Out}, RandomAccessIterator{Out}&gt; Or void foo(Number{N} n1, N n2);
Hi! I didn't realize you browsed here. I've been experimenting with coroutines for a few weeks and I'm wondering if I can get your thoughts on a problem I have. I want something like the reverse of parameter preview: I have data in the promise that I want to access from a coroutine. My use case is in game development: I have several coroutines that return GameCoroutine, and I have a HameCoroutineManager that is responsible for resuming each currently coroutine, once per game frame. If you've seen Unity's coroutines in c#, I'm trying to get something similar. My game project has many GameCoroutineManagers - one per actor in my game. I want each of my coroutines to have a pointer to the GameCoroutineManager that owns it, so that one coroutine can start another coroutine on the same manager. How do I give this pointer to the body of the coroutine? I could take it as a parameter: GameCoroutine DoThing(GameCoroutineManager *Owner, int param1, float param2) { Owner-&gt;StartCoroutine(OtherCoroutine(param1, param2)); // ... } GameCoroutine OtherCoroutine(int param1, float param2) { co_await WaitForSeconds(param2); /// ... } But with that setup there's no guarantee that the Owner pointer is the same GameCoroutineManager that is running this coroutine. In fact, the Owner pointer doesn't even make sense at first, because when the coroutine isfirst started, it has no owner. It only has an owner when it is passed to the StartCoroutine method of a GameCoroutineManager. I could return it from a co_await statement: struct GetManager { GameCoroutineManager *ptr; bool await_ready { return false; } bool await_suspend(handle_t handle) { ptr = handle.promise().manager; return false; } GameCoroutineManager* await_resume() { return ptr; } }; // inside coroutine GameCoroutineManager *manager = co_await GetManager(); But this A: violates the principle of least surprise, because a reader of this code might assume that this call will suspend, but it never suspends. and B: my understanding is that the coroutine gets suspended and resumed if I do this, which isn't free. If would be cool if I could return a GetManager object from initial_suspend, but there would be no place to store the return value of its await_resume method. Am i trying to fit a square peg into a round hole, or is there some way to do this?
I read some of its page &amp; find it useful if you are system software developer. It will also help in understanding how C++ internally works
&gt; A constexpr function has a lot of limitations : for exemple, if calling func can throw, the function can't be tagged constexpr. A constexpr template will only actually be constexpr for types/callpaths for which constexpr is valid. It would be impossible to make constexpr higher-order functions if this weren't the case... &gt; I don't understand how it should affect 'if constexpr' : for me, these two 'constexpr' are not directly related. You're correct on this.
Sure you can tag a potentially throwing function constexpr. It will only lead to a compile error if your function tries to actually throw an exception during compile-time.
Let's look at this line: ``` Manager-&gt;StartCoroutine(DoThing(Manager, "abc", 6.0f)); ``` That is a lot to type and you specify the manager twice. How about instead writing: ``` DoThing(Manager, "abc", 6.0f) ``` Coroutine starts suspended. It captures the manager using parameter preview in promise constructor and stashes it into a promise. In its initial_suspend it goes to the manager and queues itself into the manager / starts itself. Probably there are other way to solve it, but, this one seems straightforward. (I think parameter preview made it to clang 6.0)
Helpful. 
There is already this fairly big cpp learning discord: https://www.google.se/amp/s/amp.reddit.com/r/learnprogramming/comments/6l65ve/made_a_discord_server_for_those_needing_cc_help/
I still recommend it often because it removes the mystery behind how the language works. Many C/C++ devs grow up thinking about code from bits and bytes and registers on up. But, to be very polite... a whole lot of graduates I’ve interviewed did not. For many programmers, particularly those raised on Java or even C#, that the language works is a given and how it works is a non-thought. I may be ignorant of something, but AFAICT, the book is still as relevant and accurate today as it was in 96. Everything since then has been layers of abstraction and convenience that eventually compiles down to mostly the same bits. If you are a assembly-up dev, the TLDR of the book is: Most things work in the simple, straightforward way you would expect until you attempt virtual inheritance. Yeah... do your best to avoid virtual inheritance... 
This is the best solution! 
I haven't read the book, but treating objects just as a collection of bits and bytes can lead to a whole lot of UB (type punning &amp; integer overflow being probably the two most common examples). Of course knowing about the physical layout is still important for performance reasons.
The problem is not output parameters, but input-output parameters. In C++ there is no way to consume a value so people can easily write: bug = foo(a); when they meant to write a = foo(a); because a can be used after being consumed without issues (even though it might have the wrong value). So for input-output parameters a reference at least does not have this issue.
I'm slightly confused because your version of for each does something completely different from what's in the library... And the library is using C++17, so you could also use std::apply, so something along the lines: template &lt;class T, class F, class = std::enable_if_t&lt;is_aggregate&lt;T&gt;&gt;&gt; void for_each(T&amp;&amp; aggregate, F&amp;&amp; f) { std::apply([f = std::forward&lt;F&gt;(f)](auto&amp;&amp;... args) { (f(std::forward&lt;decltype(args)&gt;(args)), ...); //if the guaranteed in order execution is important: //std::initializer_list&lt;int&gt;{(f(std::forward&lt;decltype(args)&gt;(args)), 0)...}; }, as_tuple(aggregate)); } 
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/89mbo0/is_inside_the_c_object_model_by_stanley_b_lippman/dws5wbi/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
At first I thought about reading about a C++ compiler implementation, such as g++ to understand C++ object model. But then I stumbled across this book. Very little has been published about C++ object model after this book.
That's a great suggestion, thanks! Right now, the GameCoroutineManager operates on instances of GameCoroutine (actually std::shared_ptr&lt;GameCoroutine&gt;, this allows other parts of my game to observe when a coroutine finishes, because the Gamecoroutine instance remains valid even after the promise is destroyed). But inside of a promise, I don't think we can get access to the GameCoroutine object, can we? So I won't be able to queue the GameCoroutine instance in the manager. One way to solve this would be to have the GameCoroutineManager operate on GameCoroutine::handle_t directly. Currently I keep some bookkeeping (an enum for state, a string name for debugging) inside the GameCoroutine object, but all of that could be moved inside the promise object. I really like the ability with the shared_ptr set up I have now to safely observe the state of the coroutine from multiple places, but it seems like coroutine handles are wrappers around raw pointers. Separately from the shared_ptr issue, one concern I have about parameter preview. I see this in the doc you linked: &gt; by assembling an argument list with lvalues p1 ... pn. If matching constructor is found, then promise-constructor-argumentsopt is (p1 ... pn), otherwise promise-constructor-argumentsopt is nothing. GameCoroutines can currently have arbitrary parameters -- this makes it seem like I would need one constructor for each set of parameters. I suppose I could have a constructor that takes a manager and then a variadic set of other parameters, and then ignore the variadic parameters? struct my_promise { GameCoroutineManager *owner; template&lt;class... U&gt; my_promise(GameCoroutineManager *owner, U&amp;&amp;... u) : owner(owner) { } // u intentionally ignored }; Thanks again for your response, this has given me a lot to think about
then I would guess it will make it in 2023
If I write: y = foo(move(x)); std::cout &lt;&lt; x &lt;&lt; std::endl; // using x instead of y I get no compilation error, no run-time error, no nothing. The only thing I might potentially get is undefined behavior, if that operation violates some pre-condition on `x`.
And you sound like an idiot ¯\\\_(ツ)\_/¯
One thing in terms of file I/O in C++ I always considered bad is the fact that you can't easily open a file and load entire content into string/byte array without using dynamic memory, inefficient iterators or unnecessary allocations.
That's a general issue you'll always have with moves and can only really be solved by convention. So far that is.
Ah sorry I misunderstood what you wrote. I get how `x = foo(move(x));` really conveys the intent and makes reading the code pretty clear. I guess I was just hoping of a lint or something that would help me write the code correctly in the first place. Luckily these bugs are not hard to debug.
With the proposed library, now one can. Performance is sufficiently bare metal that during testing on Intel Optane last summer, we noticed a statistical quirk on Microsoft Windows which we eventually tracked down (with Microsoft's help) to a bug in the Windows scheduler, which should now be fixed.
nice! is there an implementation somewhere ? I don't really care about it being in namespace std::, I could really have a use for it now.
https://github.com/ned14/afio
I thought this was a video but it turns out to just be marketing. Can we please tag these as not being content. didn't we go through this last year?
how would you load an arbitrarily sized file into a string without dynamic memory?
Your post has been automatically filtered because it appears to be spam (it was a link to clickbait site). If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Spam%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/89o48e/defensive_programming_with_new_c_standards/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; Why should the committee and vendors waste their (valuable) time on creating their own "perfect" version of Asio? This problem has two roots: * managing C++ dependencies: which is so horrible that often depending on the std library is already painful enough. This leads to people trying to cram everything they might potentially need into the std library so that they don't have to add a second dependency for this stuff. * the committee allows it: the committee is fine with putting all kind of stuff into the std library. A 2D drawing API? Sure, why not. IMO, if adding ASIO or cairo to any project would be as easy as adding 1 line to a text file in the project root people would not do this.
How is this on topic?
does discord have a financial model to make money? do they promise never to paywall content? I see this as quite the mis-step to move to yet another server.
&gt; you can't easily open a file and load entire content into string It says you load the entire file and makes no mention of any size limitation.
That's impossible, but the most typical code (using stringstream or operator &lt;&lt;) would write or allocate twice.
The documentation in Doxygen is unusable on mobile, you get only a tiny window with the actual content. 
I thought that C ++ programmers sometimes have to write code in C and for them it would be convenient.
Does memory mapping count as dynamic memory?
Presumably you'd know the file size ahead of time.
Right, but this already works, using `std::basic_istream::get`.
I must be misunderstanding something — [how is this code not doing what you want?](http://coliru.stacked-crooked.com/a/ed4d3cde1b568628) std::ifstream foo("foo"); char buf[3]; foo.read(buf, sizeof buf); 
Doxygen is indeed Doxygen. Chances are good we'll do a Standardese conversion at some future point, so you'll get reference docs strongly resembling http://ned14.github.io/outcome/reference/outcome/#standardese-outcome_v2_xxx__outcome-R-S-P-NoValuePolicy-
Hasn't the author done what you propose? I just thought he came to another conclusion: that not all people using the library have a C++11 compiler available yet. &gt; If you have an open-source project, odds are that some of your users are stuck with older compilers; in the case of QuantLib, for instance, we have users working in financial institution and whose compilers are mandated by their IT departments (which tend to be pretty conservative—and rightly so, given the stakes). If that is a "reasonable" or "conservative" strategy by the IT departments is another question.
&gt; that not all people using the library have a C++11 compiler available yet. Having the library dropping support for an ancient standard gives these people a very compelling reason to upgrade their toolchains.
&gt; This project seems to be a Desktop app and so the limiting factor will probably be older Linux distributions. Is it though ? I have no problem shipping AppImages that use C++17 and work everywhere from CentOS 6 to an up-to-date ArchLinux.
&gt; That's a general issue you'll always have with moves and can only really be solved by convention. So far that is. #include &lt;iostream&gt; #include &lt;string&gt; std::string foo(std::string&amp;&amp;); int main() { using namespace std; std::string x, y; y = foo(move(x)); std::cout &lt;&lt; x &lt;&lt; std::endl; } =&gt; $ clang-tidy -checks=bugprone-use-after-move tutu.cpp 1 warning generated. /tmp/tutu.cpp:9:16: warning: 'x' used after it was moved [bugprone-use-after-move] std::cout &lt;&lt; x &lt;&lt; std::endl; ^ /tmp/tutu.cpp:8:7: note: move occurred here y = foo(move(x)); ^ (paging /u/0b_0101_001_1010 too) 
It's exaggerating to say completely different, isn't it? What exactly is different (semantically speaking, it's entirely possible that the generated assembly is different, I didn't check).
&gt; rather than waiting 2023 Make that 2032
I have a meeting where I have to look presentable in 15 minutes and you just made me slobber. Gee, thanks /s
This code loads only 3 bytes. They talk about loading the whole file. By inefficient iterators they probably mean istream\_iterator. 
iostreams has serious problems. When running "perf top" the last thing I want to see is std::locale on that list. And that's what you get if you hack up a Q&amp;D file parser with iostreams.
Aah effectively, my bad ! But if the for_each were executed at compile-time, it couldn't have any effect because of it's void return no ?
As dodheim and kalmoc said : you can. Tagging your function constexpr just means that it exists a branch inside the function body that can be executed at compile time. There can exist throwing branch, it will just make a compile error if you're trying to execute this branch and : * assign it to a constexpr variable * use it as a template value parameter Your tag system is very interesting while I find it a bit heavy to write (if I refer only on the tests). After digging a little bit in the implementation, you have nice helpers to work with your tags :) . It's true that your recursive function is really powerful. I find the fact that its interface is close to normal for_each a plus. If I ever wanted a different interface as a user it would be so I can pass additional arguments staticaly (as shown in my code above) or to get params such as reference on parent tuple inside the lambda to do calculation, or the current depth you're in to do ponderation. Nothing too difficult. I'd also rather have those version with different function name. Did you try to implement other utility function on tuple ? Such as remove_if/copy_if, find_if, transform, all_ot/any_of/none_of, count_if, accumulate, replace_if, push_back, etc. ? I recall loving the fact that std::tuple_cat existed :) .
C++ 23 is achievable for this bottom most layer. It is relatively uncontroversial as we are merely standardising into C++ what POSIX standardised a decade ago, so apart from the one or two features which POSIX doesn't standardise e.g. retrieving the current path of an open handle, and unlike say in the Networking TS, there is little to none innovation in this proposed library. It's all just thin wraps of syscalls. Any iostreams v2 built on top would surely be later however. I know I'm very torn on which of the major serialisation libraries to choose. That's why I'll be asking for a dedicated Study Group, because I really am not sure, and I've been in this specialist niche for six years or so now, so I am suspecting that this is a "Hard (TM)" decision.
&gt; This code loads only 3 bytes. They talk about loading the whole file. … obviously increase the buffer to the file size (known ahead of time). If you had checked my link you’d have seen that my example file was three bytes long.
How did you fix the OSX problem? The PR linked in the bug seems to just remove the unit tests if compiled in OSX.
&gt; This is an ambitious and quite impressive proposal. It's been gestating since 2012, and is post a Boost peer review in 2015. Last few years I've been building fun toys like transactional key-value stores with it. So it's had most of the rough edges knocked off by now. &gt; However, am I right to assume this proposal mainly looks at systems that have fairly complex operating systems and is ignoring many embedded systems? Actually no. The goal is that it'll be Freestanding C++ compatible, *if* your embedded system provides a filing system with mostly POSIX semantics. If it provides a high quality C file i/o layer, that should be sufficient. Obviously enough, the classes implementing memory maps would not be available on systems which do not provide memory maps. The design is specifically designed to enable writing of code which works exclusively through `file_handle`, which can be instantiated as `mapped_file_handle` on systems with memory maps. Some other features may also be not provided on lower end platforms, but I went out of my way to be friendly to embedded systems. I am, after all, a former embedded systems engineer. I once worked for ARM :)
iostreams is pretty good at bulk transfers. It is less good at almost everything else. Here is a graph of benchmarking various serialisation libraries: https://github.com/thekvs/cpp-serializers. I really wish it also contained iostreams for reference :(
&gt; Tagging your function constexpr just means that there exists a branch inside the function body that can be executed at compile time. And for a function _template_ with a parameter `T`, constexpr just means that there exists _some_ `T` for which a branch inside the function body that can be executed at compile time – it need not be _every_ `T`. (Having no such `T` exist is ill-formed, NDR.)
OS X, and I assume really libc++, implements `std::make_exception_ptr` using a `throw` and `catch`. Which is insane IMHO, so inefficient. Anyway it thus means that if you disable exceptions, `std::make_exception_ptr` kills the process because it throws an exception. Thus the fix for exceptions disabled on OS X is to not run any of the unit tests which call `std::make_exception_ptr`. When Apple/libc++ fix their lousy implementation of `std::make_exception_ptr`, I'll reenable the tests. Otherwise Outcome performs excellently on OS X. No known problems.
It reminds me of [Dyno](https://github.com/ldionne/dyno). What are the main differences between other type erasure libraries and yours?
Fantastic! Thanks for clarification. I really look forward to see how AFIO evolves. 
Yep, these are good ideas I think. For the utility functions on tuples, I don't know where I should stop, and I don't really want to overlap meta programming librairies like Boost MLP/Fusion/Hana, but there are some which would be useful (especially with recurrence) I will surely make something like std::tuple_cat c:
Oh that's true... :S But now I can't see why this isn't failing in linux with libc\+\+ also. It looks like it should be using the same throw/catch "trick".
* vs 2017 15.6 does not have parameter preview. You would need to do a workaround similar to the one described here: https://wg21.link/p0914 * Yep. You do variadic template and throw away the rest * I think it is better to keep all the bookkeeping in the promise itself. GameCoroutine should just contain a coroutine_handle. You can get everything you need using coroutine_handle&lt;P&gt;.promise() * You can have coroutine refcounted, but, I wonder if you cannot get by with move-only coroutines. (You can look at shared_task in cppcoro to see how to use intrusive refcouting without relying on shared_ptr: https://github.com/lewissbaker/cppcoro
That's not a combo I test, so it's entirely possible it fails there too.
For optional parameters? I think that's too far.
This would require a language-level change, but one feature I'd like to see is the ability to bake arbitrary files (e.g. graphics or audio) directly into the binary.
Yeah your right. Completely different was the wrong wording. It just does something completely different when you call it with additional parameters :-) That being said: KISS - keep it simple stupid. That's why I would prefer the single function version that I proposed.
Not ATM, sorry. Possibly in the future, though, if the library won't end up being just an experiment. It shouldn't be hard to add VS 2017 but it's always tricky with MSVC ;)
I'm guessing the aim was to take out the guess work of how much memory to reserve and avoid reading files in fragments. Instead, devise a function that returns a buffer matching the file size and initialised with the file content in one fell swoop.
&gt; (which is fixed at compile-time) everything is easy if you know your limits beforehand
What has this got to do with filesystems?
Can I get a file descriptor? That's all I've ever wanted. Be able to call stat or whatever without the OS reevaluating a pathname...
Nothing stops you from defining a static const char array with your file binary hardcoded. You do not have tools to easily do it but that's about an only problem with it.
Yeah its quite expensive to book a full hotel for 3 days. As long as Meeting C++ was only two days, with one being Saturday, it was a win-win for both, but now with two full week days, we'll have to pay full price for all rooms and have to guarantee a large room contingent to be booked... But still, Meeting C++ is now per day cheaper then it was in 2016 per day: 699/2 vs. 999/3. Also Meeting C++ offers a way to attend for students and other groups not able to attend. Also volunteering will be possible again. And we're looking for speakers, so if you'd like to prepare a talk, submissions will start next week.
`std::basic_istream::seekg` in combination with `std::basic_istream::tellg` [is the established way of finding a file’s size](https://stackoverflow.com/a/525103/1968). But this doesn’t help you if you want to avoid dynamic memory and allocations.
Those are the links that amazon provides me for books when you request a link from them; I'll keep an eye out for that in the future.
&gt; Second, I think there is something wrong in 2018 with the whole organization of SG21 work. The need for a paper is irrelevant in a world where communication is so easy. I am not saying papers are useless, things must be written at some point. But a paper should be the end of the process, not the beginning. The number of papers could be reduced if the topics were publicly discussed and consensus found before the meetings. For example, there were five papers on the subject of concept syntax. The people involved could have discussed it somewhere before the meeting to find a consensus (that was not hard to find after all according to the reports). Other languages already have an open process, C++ could copy the good practices. \+ 100000. 
Yes you can, as with the Networking TS, there is a `.native_handle()` accessor on every handle instance. Though, if you want `stat()`, we've got that too: https://ned14.github.io/afio/structafio__v2__xxx_1_1stat__t.html. You'll notice that you need to specify a bitfield for what members you want filled in. This reduces the syscalls required to fill out the structure to exactly minimum. We also implement `statfs()`, which is the rich BSD form not the impoverished forms on other POSIX implementations such as Linux. Similarly, you need to bitfield exactly what members you desire to cause the most optimal number of syscalls on your platform. https://ned14.github.io/afio/structafio__v2__xxx_1_1statfs__t.html
QtCreator is not inherently unix. Quite the opposite; Qt is inherently cross-platform and the expectation is that the "Qt IDE", QtCreator, is inherently cross-platform. I would put the same expectation on QtCreator as I put on Qt: if you're going to advertise that you are cross-platform, then you have to test and fix bugs on all platforms. Either that, or you should stop the pretense of being cross-platform and advertise as linux only.
Is PhD required?
`operator &lt;&lt;` is for *formatted input*, not to read a whole file. `std::basic_istream::read`, which reads unformatted input, requires no double allocation.
Except your text editor and compiler are likely to choke if it's anything non-trivial. And it would be nice if there were a concise way of expressing it, as opposed to ultra-verbose.
I can only recommend to use it and not to attempt to remake it... Seeing the reference implementation in the standard library is a bit frightening.
As I envision it, "baked" files would obviously be static arrays under the hood, but would expose a file-like interface (`std::fstream` / replacement / similar).
I feel like a part is missing in the above. Big chunks of standard, like TSs, have a lifecycle. By convention, at the beginning is when to voice substantial concerns with them. They then go through a process of rareification usually during which stuff gets taken out, and other stuff added as feedback lands. As they approach finalisation, the bar for raising substantial concerns with them is raised - non-paper objections become frowned upon/dismissed, and the only way to really change the direction of a late stage TS is a powerfully written formal paper blowing a hole in the wisdom of some TS, mainly by conclusively demonstrating it is severely flawed. And even then, doing so is emotionally hard, you make no friends wrecking multiple years of work by your colleagues, and often friends. Allow me to personalise this a bit. It is well known that I have misgivings with the Networking TS, though not as many nor as strongly as others. I wish it were structured differently, broken into the really necessary bits (socket i/o) and separate from all the other stuff (everything other than socket i/o). But Networking is at a late stage now, Chris and many others have invested a ton of time and effort into the TS. And they know my objections already, and those of the others who object. We've discussed all that, years ago. So there is no point in reraising water under the bridge, even though my personal concerns have not been addressed. We voiced our concerns at the appropriate time, they were dismissed or handled, and it is both rude and childish to keep reraising them endlessly. At some point you have to draw a line under some TS effort and get on with it, or kill it off entirely. Most of the time we see success. Only very rarely does it get killed off. Now, for me personally, Graphics suffered from poor scoping. If you just want a LOGO-level toy graphics layer for teaching C++, then explicitly encode that requirement: this is a C++ teaching API. There are quite a few teaching graphics API libraries around which could be standardised easily. No need to invent anything particularly. But if you want more than that, then a single study group is too broad for all of Graphics, Input, Audio, UI, Fonts, UX and so on. Break it up into many study groups, assuming you can find enough interest to get separate conveners for each. There are lots of ways out of this. I personally like the idea of a teaching level graphics, input and audio API. I personally always liked the idea of a C++ification of the C library https://github.com/simple2d/simple2d as a teaching level API. I find its facilities to be just enough for toy projects, but nothing anyone serious might be tempted to use. But that's personal opinion.
You can, no? Use an extern const global and use the linker to embed the binary data into the executable.
Interesting idea, I'll try that out.
What a great document. Confirmed all my suspicions about futures being unsuited to anything except toy-town code.
&gt; I mean, is rust really going down the route of ‘to be compliant a rust tool chain must support linking objects/modules/whatever compiled with different language revisions’? Yes. To be specific: - N editions of the language, - 1 single toolchain, - 1 single *version* of above toolchain, - 1 single set of options. *Note: using the `cargo` manager, each dependency is re-compiled for each target and set of options, for each library that is compiled.*
I've used bullseye this way but it's not free
I've always used lcov on Linux but the html output looks like it's from 1998. Gcovr is nice as it outputs cobertura XML which can be visualised in Jenkins
I do such 'binary-include' by pre-processing files into a giant cpp with extern arrays for all data. All modern compilers work fine with it. About a year ago I was able to crash Android Studio by opening this giant file in the editor but it was fixed in some later versions of it. This isn't a nice solution and probably will not scale well to hundreds of MB of 'included' data. But at least it works and fully portable. Something like file literals (http://open-std.org/JTC1/SC22/WG21/docs/papers/2016/p0373r0.pdf) would be better, but looks like there is no any movement on this proposal.
I don't believe scoping is actually possible. Because nothing in graphics is simple. Creating a surface is not simple, Input is not simple, and displaying text is also very complicated. And you have to encompass everything if you want to be relevant / portable. The burden for the implementers would have been unbearable 
Stat was just an example, but there are plenty of other system calls that can take a file descriptor or pathname. The fildes versions eliminate the need for navigating the directory structure again, but more importantly, it eliminates the possibility of a race condition in which the the file I just called chmod on wasn't the same file I had open.
Is that useful though ? See https://hackernoon.com/a-cake-for-your-cherry-what-should-go-in-the-c-standard-library-804fcecccef8 for my complete opinion on the topic.
&gt; The people involved could have discussed it somewhere before the meeting to find a consensus The important thing that should not be lost when doing this is recording notes of the alternatives with strengths and weaknesses to minimize a well intended person coming along, saying the same thing as one of the original authors, and at best re-hashing it out because no one remembers why and at worst derailing the process.
It depends on what you define as useful. P0939 says we must improve teachability. It proposes a new study group just for that. I would not be surprised at all if graphics reemerges from the dead there, as that's a great tool for teachability. It also enables fun stuff like C++ programming inside a web page. Great for teaching and bringing in new blood to C++. But we just need to scope things better, specifically, down to volunteer achievable sizes. 
We're working on standalone tool which you can run across the whole project and it will be separate from code model :) It will most likely appear in 4.7
C++14 greatly relaxed the rules on `constexpr`; almost any function where at least one execution path doesn't dynamically allocate or call a non-`constexpr` function can now be marked `constexpr`. This includes functions that return `void`.
Qt Creator uses libclang which is a little bit more limited than clangd but has most of the features. it has not much to do with tidy support :)
That's actually, literally, https://github.com/simple2d/simple2d. A simple teaching front end to SDL + OpenGL.
Can afio and asio be merged into single library?
I like opencppcoverage. I don't think you'll find anything better that works on windows, unless you shell out for visual studio enterprise/test. 
Hey all, I'm a sales guy at Synopsys and would be happy to answer most questions on our products and services. The beauty of Reddit is that if you ask me a question, I have no way of hunting you down to ask for money. Also, thank you to /u/Sean_scoggins and others for your kind words about Coverity. We take great pride in it and are always happy to see that it is meeting folks' needs. If you have real interest I encourage you to seek out our account teams for more information as they can obviously be more open about things like pricing and licensing. 
I agree. I searched quite a while for a coverage tool under Windows, which doesn't require VS enterprise. And it can output cobertura XML, which can be nicely visualize visualized with Jenkins Cobertura plugin.
&gt; The people involved could have discussed it somewhere before the meeting to find a consensus Of course they could have. They *chose* not to. Dictating how other people should do things seems a bit condescending. There is a lot of value to writing papers. It forces one to think through the details and write them out. It gives others a complete view of what is being proposed (rather than a bunch of vague assertions requiring clarification that is often the nature of discussions.) But most importantly it facilitates interaction for large, diverse groups where the O(N!) nature of live discussion doesn't scale. 
Thanks for the link. I currently use lcov+gcovr, but I had some issues with correctly displaying the lines. I'll check it w.
We would not have reached consensus on concept syntax if we hadn't gone the route of voting for and against each paper. This all sounds great, but I recommend coming to a meeting to see that reality is not as nice. There are people on the committee who aren't very good at compromising and approaching certain topics without an emotional attachment of sorts. This would not be pretty. I think that a solid part of why C++ still didn't die is because the process has not been relaxed. (I don't particularly want to debate this, just making my opinion known.)
What I meant is, even if we mark it constexpr to allow it's execution at compile-time, it would be useless to use it at compile-time because it could not have side effects nor return a value (so the function would do nothing)
Qt has this: http://doc.qt.io/qt-5/resources.html
The root of the issue really seems to be that libraries need to be easier to manage in c++ on all platforms. There is little other need for this kind of thing to be in the standard than the convenience. 
I would like to see in std some common graphic structures and algorithms like std::point and generic game loop, so current libraries can use it, but actually drawing is imho too much.
Ask your coworker for an approximate size.
Are there 'diversity' discounts for Eastern Europeans?
Isn't Skia a de facto standard?
It might be useful to call in a `constexpr` function that does return a value. Think about stuff like `std::for_each()` (`constexpr` in C++20) or `__builtin_unreachable()`.
Very interesting read, a feature I'd wanted to implement for CMake at some point but quickly gave up (it was more an exercice than a real need). I'm not sure you are the author, but I will ask anyway. Have you heard about the method used by gn (generated ninja)[1]? They generate a "TOC" next to the .so with the `nm` tool. If the TOC didn't change, no relink is performed. If yes, how does it compare? e.g. is the ABI check less correct than with abigail. [1]: code available here: - https://github.com/o-lim/generate-ninja/blob/c9de6acc137a6239095b8990e26ef3d83d146bb5/build/toolchain/gcc_toolchain.gni#L371-L375 - https://github.com/o-lim/generate-ninja/blob/c9de6acc137a6239095b8990e26ef3d83d146bb5/build/toolchain/gcc_solink_wrapper.py
No, you can register to win an Accessibility Ticket, which is free.
Not exactly, simple2D is here to draw things. IMO, it would be the cherry on the cake and the very last thing to standardize. Everything lower level (windowing, events) is needed first.
I know (and use) SFML too. The ideal API would lie between (a subset of) SDL and (a subset of) SFML. Not everything should be standardized in those libraries. 
Citation needed.
Going to allocate a 20 GB buffer just in case. Works fine on his system. Two months later consistent crashes on some systems can be traced back to Linux refusing to allocate more to a process than available ram and swap. Turns out our customers don't have that much ram. 
Not even remotely. It's a very good library, but shockingly difficult to consume from outside of the Google ecosystem. Firefox is also in the process of migrating away from it, although for unrelated reasons.
&gt; There is a lot of value to writing papers. There is also a high barrier to entry that prevents valuable people to contribute to the standard. The example of SG13 is relevant in this case. Not so many people from graphics field contributed because they had not enough time to make a paper (that is evaluated as some person-weeks by Herb Sutter himself). The consequence is that the experts of the field could not give their advice on this proposal and make it go in the right direction. I repeat that papers are important but they should not be the only way to contribute to the standard.
Well, I do not believe a "toy" API that involves audio, text and sprites should be in the standard. It's as if you wanted to provide an API to print colored text with any font but did not provide a simple printf on the console. Getting a window and input events is not a new technology, it's a mature field. The only difficulty is that there are as many APIs (that looks quite the same) as platforms. SDL shows that they can be unified under a common and complete API. Why not standardize this? It would help so many people in so many fields. 
Slightly OT, but what are their reasons and, most importantly, what are they migrating to?
I'm the author. I'm happy to hear that you liked the post. I wasn't familiar with that specific work when I wrote this, but I was familiar with a similar mechanism proposed in the past to the SCons community, called [SharedLibrarySignatureOverride](https://github.com/SCons/scons/wiki/SharedLibrarySignatureOverride). Overall, I don't see how the nm output can be sufficient for these cases, as the ELF information lacks metadata about the size or layout of types, and the symbol entries do not even include the return type in the mangled name. So, yes, I would say that by my understanding the ABI check in those instances is less correct than what you get with libabigail, but I'm certainly interested to hear arguments the other way. Another difference is that you need the DWARF info around to get good data out of libabigail, while nm based tools can obviously get away with just ELF info.
I think "far superior" is a pretty big exaggeration. Language inertia is not the only reason to prefer being explicit. If you want to take a quick survey: out of Go, Swift, and Rust (3 fairly promising new languages, I even excluded Kotlin for you as that would be cheating almost), 2/3 support explicit/intrusive dynamic polymorphism. I'm not sure if either Swift or Rust have any support for type erasure (Go of course does). Rust even requires being explicit/intrusive for static polymorphism (I think Haskell does too). In other words, I'd expect that if something was "far superior" some reasonable consensus would form around it, but that clearly hasn't happened (not just within C++). The majority of use cases are that interface and implementation are owned by the same person, or that interface is owned by an upstream dependency and the user is writing the implementation. In both these use cases, being non-intrusive buys you nothing. Being intrusive buys you more clarity in the code, and catches errors earlier and more clearly. There are other use cases where being non intrusive is nice, but they're generally a minority use case, so you have to decide whether it's worth it. There's also a minority case where a type can implement an interface it didn't intend to, because the type signatures work out but the semantics don't (types after all don't encode the whole behavior). Anyway the library looks nice, I'd consider it for specific things. For the average use case for me in C++ though I'd have trouble justifying this (in terms of dependencies, quality of error messages, understanding what the code is actually doing). I'm curious how: // Define object which can hold drawable objects (No dynamic storage) void draw(te::poly&lt;Drawable&gt; const &amp;drawable) { drawable.draw(std::cout); } Doesn't dynamically allocate when you also have `vector&lt;te::poly&lt;Drawable&gt;&gt;`. If `te::poly&lt;Drawable&gt;` is really owning arbitrary classes, how is it not allocating? Is it just an optimization for small classes?
Oh I see, thanks !
&gt; The consequence is that the experts of the field could not give their advice on this proposal and make it go in the right direction. I disagree. I think this is more about not having the interest or time, in general, than having to write a paper. As /u/ramennoodle points out, writing papers forces one to think through the details, details they probably hadn't thought through initially. Writing a paper is a time consuming process not because of the time required to physically write the paper but because of the amount of time it takes to think about the points, structure the arguments, provide well thought-out support, etc. I think this is valuable when dealing with changes that will be permanent. Additionally, if the barrier to entry is too low, it will increase the noise and we may have the opposite problem: we lose great ideas and contributors simply because there isn't enough bandwidth to process all the "proposals".
I watched one of Andrei's Fastware talks and somewhere in there he talks of the law of small numbers. That most programs deal with numbers that are less than 100. If I modify n to 101, I get jumps! Amazing.
 "Dead" Man: I'm not dead. Dead Collector: What? Large Man: Nothing. [hands the collector his money] There's your nine pence. "Dead" Man: I'm not dead! Dead Collector: 'Ere, he says he's not dead. Large Man: Yes he is. "Dead" Man: I'm not. Dead Collector: He isn't. Large Man: Well, he will be soon, he's very ill. ... The proposal is not dead yet. There will be a specific discussion of its fate at the next meeting (Rapperswil, June 2018). I wouldn't be surprised to see it end in a TS. And literally _end_ there. ie perpetual TS, never in the IS. 
Even std::point isn't easy. (Just look at std::pair!) Do you make it N dimensional? Do you have .x, .y (and .z when N == 3)? Do you use pt[i] for the general case?
That is sometimes true, but I think a lot of proposals could move more quickly if we started with some email sketches before ramping up to a proposal. Of course, proposals (for library at least) are suppose to be pre-existing libraries. That _should_ imply no "sketches". Also, look at Boost library reviews. I think an email discussion can work well.
This is pretty cool. I like the resulting API. However, I think this is all based on UB because you're storing function pointers as `void*`, which I don't think is allowed by the standard. To workaround that, you need to somehow encode the signatures of the functions you're erasing somewhere, and that brings a lot of complexity.
If a type changed size or a function return type changed, then the header of the library will change too, right? And when the header changes, the traditional "compile dependency" management (as opposed to "link dependency") would trigger a rebuild of objects relying on it, no?
N dimensional, accessible like array and like tuple. That tagging mechanism would be nice. Xyz could be accessible in another class like std::pointx or maybe somehow injected via magic tag?
Yeah, personally, I consider gcc-4.8 the oldest compiler worth supporting. It has decent (although not full) c++11 support and is the default compiler on ubuntu14.04 &amp; rhel7. Debian Wheezy has even older gcc 4.7 but support is about to end anyway and afaik Jessie comes with 4.9.
We use the commercial Bullseye Coverage on Windows, because it supports branch conditional coverage. It outputs an XML format which we then convert into Cobertura format and display it with Jenkins.
Thanks, I used this version ! But the comma operator already ensures to evaluate from left to right, so why do we need to force it with the list ?
http://www.reedbeta.com/blog/on-vector-math-libraries/ Not perfect but good rationale by an expert that has *used* and *created* that sort of API. And I would also cite, for completeness [glm](https://glm.g-truc.net/) which is a well-known and widely used library for graphics, and [boost/qvm](https://www.boost.org/doc/libs/1_66_0/libs/qvm/doc/index.html) that provides some nice ideas. Why invent something like tags for points that nobody has ever used? It's a good theoretical point of view but not a practical one, because your could have to make an operation involving a window point and an image point. 
Yes, the post discusses this. We are thinking that assuming correct header discipline would allow us to replace actual library to library dependency checking with a simple order-only requirement, achieving the same results. In that case, you don't need even nm.
None of those design questions is really important (and I wouldn't standardize a taggable point - KISS and write a small wrapper when needed). Most important would be to have a standardized interchange format between different libraries out there that deal with coordinates (simulations, graphics, sensor processing, computer vision ...)
union { intrinsic_t v; std::array&lt;T, W&gt; arr; }; that is and how you use it is UB, you know that, right?
I agree with you, but I don't particularly think you should teach with the Cairo API (or the likes). So the current graphics proposal wouldn't even be good for teaching, in fact, it encourages many anti-patterns of today's modern C++ style.
Nobody is arguing that the process of writing a paper somehow prevents any and all future-looking poor design decisions. The point is that writing a paper encourages thinking enough about a problem and its details. It doesn't magically prevent you from producing incomplete, ill-considered, or downright awful proposals. But it does provide a push to make it harder to do so. It's not like every proposal in the mailings is impeccable. But the average quality proposal in the mailing is surely higher than the average quality proposal on std-proposals which, in turn, is surely higher than the average quality proposal in a reddit comment. And, mind you, the barrier to writing a paper is pretty small... 
&gt; I'm not sure if either Swift or Rust have any support for type erasure Rust supports type erasure via Concepts. You can use a Concept as a template parameter, and get type-erasure with static dispatch, and you can use the same Concept as an object's type, and get type-erasure via dynamic dispatch. 
Thanks. The Chromium implementation is referenced above, and appears to be based on nm. Do you know what Meson uses to detect ABI compatibility? It is not a build system I'm familiar with. If you are interested, could you please write up a PR against the github repo referenced in the post that adds a Meson build system? I'd be happy to merge it. Note also that using nm will never allow you to detect different but compatible ABIs, whereas a proposed extension to the libabigail model would enable that. That would allow you to elide re-links even when new functions had been added to a library. I'm curious if the chromium or meson build systems are capable of that.
&gt; Also, look at Boost library reviews. Mostly an in-crowd thing (the result known in advance), but your name is noted, when you offer your opinion...
&gt; And, mind you, the barrier to writing a paper is pretty small... Here is what Herb Sutter says about this (last link in the post): &gt; I realize that this is asking for serious work (...), you should realize that developing such a proposal will probably take at least person-weeks of time to come up with initial version to start discussion, with no guarantee that the committee will ever like it, and ultimately at least person-months if eventually successful. Also, it is formally optional but pragmatically highly desirable to support even an initial proposal with a working reference implementation that can be tried and inspected Is that what you call "pretty small"? 
On windows and with SFML, I always do this without difficulty, some (my) templated function(s) compile(s) any and all assets (image, sound, fonts, textures) into the binary... 
I'm talking about the general idea of writing a proposal, regardless of topic or whether anything comes of it Herb, in that post, is talking about pushing through a rebutting proposal to a long standing, existing design. Apples and oranges.
IMHO, this point should be clarified because at present, it makes it seem like it never allocates (via the comment) and doesn't mention any of these qualifications. This is especially bad because the equivalent "traditional" code is something like: void draw(const Drawable&amp; d); draw(Square{}); This *never* allocates; it doesn't matter how big `Square` is or anything else. Also: if this `poly&lt;Drawable&gt;` ends up owning the `Square`, isn't this going to call the copy/move constructor of `Square`? This seems really serious; the code makes it seem like you are passing by const reference, but because the original type and `poly&lt;Drawable&gt;` aren't related, you have to have an implicit conversion instead of direct reference binding, and since the original square is already owned, you have to create a new square that the `poly&lt;Drawable&gt;` can own. Maybe I'm missing a technique that you used but right now it seems like the nice example code can hide really massive performance issues.
https://github.com/acmorrow/abilink-demo/issues/1
Only managed to skim through the paper yet but so far it looks *very* promising and useful, thanks for your work on it. I guess I'll have to do some reading and playing around with the reference implementation in the next few days ;) 
Ostensibly the things you are saying make sense, but I must judge from what I see, and what I see is that C++'s proposals are disproportionately likely to be comically wrong in major ways. They frequently have oversights that just do not seem to happen in any other languages I have used. Some are broken or incomplete; others are nearly impossible to use correctly. For whatever reason, the way C++ does quality control observably does not work. To step into wild speculation, I am not just unconvinced that papers help the decision process, I would argue they actively impede it. The way things are set up seems to actively discourage discussion, changes of approach and practical validation. The seems to cement ideas and retard experiments and changes. It seems to close off or delegitimize tentative ideas and it seems to act as a defense to hide behind, to protect oneself not just from outsider criticism but the need to seek the support of the average developer altogether. It appears to feed into the allure that detail can substitute for substance, or that formalisms can substitute for quality. I would strongly encourage the C++ community to take a step back and see if they can find a way to make proposals that attract and pool together relevant expertise through natural open outreach and discourse, the way other communities^^^^\*_cough_\*Rust\*_cough_\* have shown is possible. 
How many people do you think can spend thousands of dollars, get visas, to come to a meeting? It is easy to say what you're saying, but next time look on the room and tell me how many of the attendees are making less than $90k a year. This kind of reply is the worst gatekeeper in this community when it comes to contribution.
`memset(&amp;hookCtx[idx].patchdata, 0, sizeof(MHOOKS_PATCHDATA));` you could replace with `hookCtx[idx].patchdata = {};` http://en.cppreference.com/w/cpp/language/zero_initialization
&gt; I wouldn't be surprised to see it end in a TS. And literally end there. ie perpetual TS, never in the IS. So, is this the "eternal torment" version that the committee reserves for bad proposals?
&gt; Now, for me personally, Graphics suffered from poor scoping. If you just want a LOGO-level toy graphics layer for teaching C++, then explicitly encode that requirement: this is a C++ teaching API. Hit the nail on the head! The answer given to every objection was: We want something simple that people can pick up easily. However, when was this ever stated to be the goal for a 2D graphics library? SG13 had gone off course from that point forward and they were way out of scope.
&gt; but shockingly difficult to consume from outside of the Google ecosystem. That's not true... I work for a small company and we use Skia for fingerprint imaging. The problem with Skia is that it was written for graphics experts, and it is extremely difficult to work with it if you want to do something simple.
Sean Parent also has a talk where he scrolls the implementation of std::pair... and scrolls... and scrolls... Just go look in the headers from your compiler. See how big std::pair is. And to find the right Sean Parent talk, just watch them all.
If you want, you can use owner&lt;T&gt; to document that the pointer is an owning pointer. One reason to use raw pointers is compile times. The memory header drags in a lot more than unique_ptr/shared_ptr. 
The simple inclusion of the memory header adds (on my personal laptop, a mediocre machine in 2012 when I bought it), a whooping 60 ms to compile time. I'm really curios what is this codebase you are working on that 60ms of compile time is more important than clear code ? And if so, are you using pre-compiled headers at least ? Because that will make any overhead that very template reliant code adds irrelevant ? Are you using the latest version of clang or at least gcc ? Compile time is an excuse people use to not to learn, nothing else. It's about as relevant as "binary" size or equivalent excuses given to use C instead of C++ on projects which should clearly use the latter.
According to [this page](http://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html), `-funroll-loops` is only enabled by `-fprofile-use`. I don't see any options enabled by `-O3` that would be loop unrolling. (Loop peeling is, but that's different). Further, we can confirm this using godbolt: compare [the output](https://godbolt.org/g/vmn7KD) when `-O3 -funroll-loops` is passed versus just `-O3`.
100% on point. Click the button, download the package, write "import...". Go learn and have fun kids! 
It is the intention of the Core Working Group to rule out the friend injection trick as invalid AFAIK.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Hmm, yes, storing a pointer to a lambda should work (and that's actually very clever). However, this is not what you are doing IIUC: vtable[N - 1] = reinterpret_cast&lt;void *&gt;(+[](void *self, TArgs... args) { return detail::expr_wrapper&lt;TExpr&gt;{}(*static_cast&lt;T *&gt;(self), args...); }); This first decays the lambda into a function pointer, and then `reinterpret_cast`s the function pointer to a `void*`, which is UB. Instead, you should do something like this: static constexpr auto lambda = [](void *self, TArgs... args) { return detail::expr_wrapper&lt;TExpr&gt;{}(*static_cast&lt;T *&gt;(self), args...); }; vtable[N - 1] = reinterpret_cast&lt;void const*&gt;(&amp;lambda); I believe that would work.
Did the left-to-right paper get anywhere?
&gt; I'm really curios what is this codebase you are working on that 60ms of compile time is more important than clear code? https://github.com/Ebenezer-group/onwards I don't think the code is unclear. &gt; It's about as relevant as "binary" size Mark Zeren is going to give a talk called "-Os matters" at the upcoming cppNow conference. Here's a tease about the talk: "At VMware we include binary size deltas in code reviews for large, C++, user-space, applications. You might be thinking "that's the most pointy haired thing I've every heard of!". Come to this talk and learn how this simple metric provides surprisingly strong counter pressure to complexity." If you look at my makefile: https://github.com/Ebenezer-group/onwards/blob/master/makefile you would see that I use -Os and run 'size' after building executables. I've been running 'size' for years. I haven't been using -Os as long, but probably for a year or so.
`boost::optional` is plenty "stable" and works very well in ancient versions of GCC with ancient C++ standards.
 sort(my_vector); There is a bit of doubt with this one, arguably. 
[This](https://github.com/boost-experimental/te/blob/master/include/te.hpp#L73) is also UB IIUC: return reinterpret_cast&lt;const TExpr &amp;&gt;(*this)(std::forward&lt;Ts&gt;(args)...); You can't `reinterpret_cast` unrelated types to your heart's will, even if they are empty. You can use [this trick](https://github.com/ldionne/dyno/blob/master/include/dyno/detail/empty_object.hpp) to work-around it in a safe manner. Sorry for picking on your UB :). 
All that this article says is that they consider -O2 to be the "default" optimization level. It has been so for years, and there is nothing new about it. This article does not say that -O3 will generate slower code, only that increased code size will imply cache penalties. Neither of these statements implies the other.
I've been thinking about this, and I think it might be possible to get a similar API for Dyno using the same friend injection trick. Basically, Dyno is a compile-time engine for runtime polymorphism -- whenever you can provide it with the information it needs to do its job, it can do it. That information is like the names of functions, their signatures and a function object allowing one to reach the function on a concrete instance. I think I can add a front-end that uses the friend injection trick to make this information available, and then the rest of Dyno could be used. The gist of the idea is that you would write something like this: struct Drawable { void draw(std::ostream&amp; out) const { dyno::register_virtual&lt;Drawable&gt;( "draw"_s = dyno::method&lt;void (std::ostream&amp;) const&gt;, [](auto const&amp; self, std::ostream&amp; out) { self.draw(out); } ); } }; And that would create a compile-time mapping with the appropriate information using the friend injection trick under the hood. Then Dyno could pick this up and do whatever it needs to do. I'll dig into this deeper when I get time.
That's the thing people don't get - you don't need to come to a meeting to participate. But the low quality of std-proposals makes me half sure that it's a necessary filter. (It's in no way sufficient, but I believe that it is indeed necessary.) Anyway, as I said: I don't want to debate this. A minor point: I currently make around $35k a year, because that's what you make in Poland. Just ask your employer; if you are good enough to really be able to make truly valuable contributions, you'll be able to convince them to cover your costs.
I strongly agree! Come back to me when you know how to do that within the ISO framework.
&gt; keep a record of all "coroutines" Yeah. This is true when you use boost::context, more precisely - when you have stackful coroutine. Once you start using stackless coroutines, every use of co_await, co_return affects function declaration and requires function to return "awaitable" - some sort of task - abstraction that represents operations that takes some time. This "infects" all code down to main() and you need to deal with tasks somehow. You can take a look into nice library that provides task&lt;&gt; type to be used with C++ coroutines. Here is example [1]: auto write = [&amp;](cppcoro::io_service&amp; ioService) -&gt; cppcoro::task&lt;&gt; { auto f = cppcoro::write_only_file::open(ioService, filePath); // ... co_await f.write(chunk * sizeof(buffer), buffer, sizeof(buffer)); }; As you can see you have all sort of things to keep in mind: tasks (cppcoro::task&lt;&gt;), schedulers/executors (cppcoro::io_service) and so on. This is what I meant with "managing tasks" [1] https://github.com/lewissbaker/cppcoro/blob/master/test/file_tests.cpp#L78 
&gt; If `begin` and `end` are iterators to a collection from the standard library, the above code will call the `std::for_each` algorithm thanks to the ADL Only if those iterators happen to have `std` as an associated namespace. `std::vector&lt;int&gt;::iterator` *could* be `int*`, for instance. If you're going to use `for_each()`, please just write `std::for_each()`. Thank you.
&gt; There is a lot of value to writing papers. No. We need fewer, better papers. Not more papers.
Are you suggesting we standardize compromising and eliminating emotional attachments as an ISO specification?
We've standardized some evaluation order stuff, but not as much as the original paper suggested. I'm not sure of the exact details. 
A standard 2D graphics lib is fascinating. Maybe I should dump something on GitHub at some point.
isocpp also has options to help with cost. It's not free, but it's not as unreasonable as described. 
Can C++ just like... be forked? It's not like a standard is something that is hard to copy.
You could certainly wander off and make your own language, but there's a phenominal amount of tooling and mindshare already associated with "C++." It'd be an uphill battle to convince everybody to adopt "tommo++" because any assertions you make about the improved process could only be evaluated after several years of evolution to see if it played out as you intended. And several years of evolution would only happen like that with people contributing if you already have users that have adopted it and have to help. Often times, the inane bass-ackwards things are the only ones that can be successful. 
I remember always having to check the coordinate system used by points in Qt and thus always having to read the doc for most functions taking or returning points. That's among the places where I indeed wished the points were tagged to know what they were supposed to represent and to avoid passing a point from the wrong coordinate system. It would have saved me both time and bugs.
There are organizations out there with rules, what software is allowed to be installed. If these rules make sense is another question, but you have to evaluate carefully what compilers your target audience uses.
There's a proposal to make ADL only work for types explicitly mentioned in the signature of found functions and not for every type under the sun in said function's namespace. The goal is that ADL only works for functions which are most likely designed to work with it.
Yes, I am also very confused on what the issue is here
That's bad design with accidents waiting to happen
&gt; since it would need concepts like an event loop I agree we probably don't want a full blown GUI, but I don't see a problem with just being able to create one dumb window. Just like iostreams doesn't care about terminfo or termcap, yet handles running in a console window, there's no reason why a simple dumb graphics library can't handle a dumb window (ie, with no event loop or other bells and whistles).
Depending on the OS/windowing system, no event loop means you can't do fairly expected stuff like move/resize/close the window. It also means that you need to create some sort of expectations about how to interpret the contents of the pixels buffer when you display it, which means you brush up against the colorspaces issues unless you don't care *what* gets displayed when you display it. At that point, you are definitely 100% making a feature that's only useful in toys. I have a hard time considering that useful for teaching/learning purposes, because it's learning stuff that can't ever be used in a real application. If I want to learn to make applications, that API just kind of winds up being an obstacle I have to get through in a course before I can get to something I'll be able to use. If somebody wants to add a display functionality as a subsequent proposal to the simple image container idea, cool. Let it get bikeshedded separately. But I still think there's value in just starting with the data structure for an image so the people who want to do a "display an image" proposal can just focus on the displaying part when the time comes. I am pretty convinced that "be something to many people" is a better starting point than "be some things to some people" or the "be many things to a few people" approach that SG13 fell into. I am pretty much just gonna be shouting NO at every reasonable sounding suggestion for "one more thing" like a deranged two year old. :)
Honestly curious what the point of standardizing a game loop is and what it would even mean. For me, that sounds a bit like trying to standardize the contents of the main function...
I think that is exactly the right approach: Focus on vocabulary types that can be used by the various libraries out there as an interchange format. I can't speak to the soundness of your suggested design aspects, but I agree, it is more important to have something that is easy to use and good enough the mythical 90% of the time instead of creating a fully generic and maximal powerful solution. I think the most reasonable approach would be to look at existing libraries, check what functionality their interface types provide and base the proposal on that.
About f, yes your right, just capture it by reference. To be honest I'm not entirely sure when something is executed in or out of order when it comes to variadic templates / parameter packs... maybe someone else can elaborate on that? I just know that if you use the initilizer list trick you can be 100% sure it works and there is no overhead (it's just some more boilerplate code).
Some of this sounds like what my colleague and I are working on.
&gt; I wouldn't be surprised to see it end in a TS. And literally end there. ie perpetual TS, never in the IS. That would be a second disaster. Because it would prevent another proposal to emerge.
&gt; I don't think you understood my point about Rust (or maybe don't understand the main point of Sean Parent &amp; co). The point is that in this type erasure approach, the trait itself doesn't have to be mentioned anywhere in the implementation All those type erasure libraries, including the approach of Sean Paren, explicitly add a "Concept" type whose sole purpose is to perform type-erasure. Sean Parent writes a `Document` concept in all his presentations. &gt; If you have an existing library, and you want to create a concept Cob that a type Foo in the existing library already meets, you'll still have to to write out explicitly impl Cob for Foo, and forward the function calls. This isn't that different then what Sean Parent &amp; co are already doing, i.e. it introduces pointless boilerplate in the sense of having to repeat every single function signature. Except, in C++ you at least only have to do this once per concept for all types, That's a difference between syntactic and semantic concepts. Rust concepts are semantic, C++ concepts lite are syntactic, C++0x concepts where semantic like Rust's and you had to add concept-maps to use them. C++ syntactic concepts basically mean that if a type syntactically matches the concept then it automatically implements it. It also means that if a type semantically implements the concept but the syntax do not match, you need to add boiler plate. This has two implications: * if you have a type that could implement a concept, for example, because it has all the methods with the right semantics, but the methods are called slightly differently, for example, because they come from two different libraries, you have to add a lot of boilerplate to make types conform to concepts - there is no language support for this boilerplate. * if a type syntactically matches the concept, but with incorrect semantics or preconditions, you can pass this type to code that requires the concept, and that can lead to undefined behavior. This is basically a soundness hole in C++'s type system (this is not a big deal, because the type-system is already full of soundness issues). &gt; I'm not sure if Rust can do that or if in Rust it would be once per concept per type. No, Rust explicitly requires you to write concept-maps manually for each type. This is a good thing, since it solves both issues mentioned above. If your Rust types can trivially implement a concept, however, you can use Rust meta-programming facilities like procedural macros (similar to Herb Sutter's meta-classes), to just generate all the boiler plate automatically. E.g. `#[derive(Copy,Clone,Default,PartialEq,PartialOrd,Eq,Ord,Hash)] struct Foo(i32);` generates the boiler plate for you. 
Please go to boost first. But most importantly, don't wonder what you *can* do, but what would actually be *useful*. If whatever library you come up with is less useful than what exists and that people use, why bother ? Consider use cases. Without text, you can't do much at all. And you can't teach a lot at all. For example, I do think it would be detrimental to the language to have to explain in a classroom setting "sorry, C++ can't do text". 
I look forward to any feedback you might have. It's not as big as it looks, it just wraps the syscalls, otherwise acts exactly like the syscalls.
 union vec3 { accessor&lt;std::array&lt;float, 3&gt;, 0&gt; x; accessor&lt;std::array&lt;float, 3&gt;, 1&gt; y; accessor&lt;std::array&lt;float, 3&gt;, 2&gt; z; accessor&lt;std::array&lt;float, 3&gt;, 3&gt; w; }; The accessor is a type which has std::array&lt;float, 3&gt; as member and overloads = operator and cast operator; the accessor&lt;T, 3&gt; would be overloaded to always return 1.0 instead of accessing the storage (T). Having an accessor for w component in a 3-dimensional vector would be very unconventional and weird, though. The z defaulting to 0.0 and w defaulting to 1.0 is more of an OpenGL thing; when input is for example a 2D vector and consumer is 4D, the defaults are muxed into the outputs implicitly but I wouldn't recommend the same convention for storage types. Just make the 4D vector constructor take 2D vector and initialize the members there or something similar.
One could write a book how to get Skia to compile across all major desktop and mobile OSes. There are people using SkiaSharp with C#, instead of Skia just to avoid dealing with it.
So you want to standardize std::vector&lt;uint8_t&gt; as an image format. I'm sorry, how is that helping anybody? - The concept of a container for pixels is not generally a problem that needs solving. It has already been solved, and considerably better than this. - This approach is incorrect anyway: you want an image format that doesn't need some kind of conversion step before hitting the screen. That means adjusting to whatever the OS demands of you. - This also does not meet the goal of getting beginners to easily get something on the screen. Not unless you want to start them by implementing their own line-drawing algorithms and whatever. - There are already numerous highly capable graphics libraries out there that could be used (whether standardized or not!), and are quite frankly a thousand times more attractive than having this kind of garbage in the standard. The naive approach taken to graphics by people working on possible standardisation stands in sharp contrast to the incredibly detailed approach taken in other areas, such as threads, atomics, sockets, file IO, etc. I attribute this to lack of experience in that particular field by the people involved: they simply don't have the knowledge necessary to come up with an acceptable 2D API. Given this clear lack of involvement by professionals in the field of 2D graphics, it would be a much better choice to _just leave it alone_. If we need a library for helping students get up to speed, provide it as a separate tool, and don't make it part of the standard. What the C++ community needs is a way to install that library. What we need is _package management_: some way for students, and professionals, to add additional libraries to their projects without spending days figuring out dependencies, build errors, and compiler settings. Once we have that, we'll have plenty of choices for whatever library we want to use. &gt; c++pm install https://www.curl.com/latest $HOME/packages/curl/latest &gt; c++pm add $HOME/packages/curl/latest $HOME/projects/my_project &gt; c++pm update $HOME/projects/my_project *That* is what we need. Can we please have that? 
One existing library is [CImg](http://cimg.eu/). It is the base for [G'MIC](http://gmic.eu/) which is integrated in many image processing softwares like the Gimp or Krita. 
There is no aliasing problem with unions if the members share common initial sequence. In above case that is not strictly true. A better approach is to use type traits to choose which expression to evaluate when reading or writing from members, like this: https://t0rakka.silvrback.com/simd-scalar-accessor The intrinsic vectors can be replaced with std::array for storage, for example. The union of array and struct is the worst possible choice (see the compiled code in the post). TL;DR summary: use same storage type for the union members and overload the cast operator and assignment operator. 
Package managers do exist you know (not that there isn't room for improvement)
Thanks for this comment. True, the Standard allows for _implementation defined_ definition of the iterator type, so the iterator does not need to live in `std::`. But all relevant STL implementations (libstdc++, libc++, MSVC's STL) have vector iterators in `std`. Now, I agree we should not rely on the things that the Standard does not guarantee, but the point of the post was not to use `for_each` without the namespace when you work with vectors and alike. It is vice-versa. It is about making `for_each` for your types which allows you to use the same vocabulary that you use with std collections with not-a-usual-sequence types. It allows for expressing intent of the code in the same way as with normal collections, and allows for switching out your type for a standard collection for testing. For testing, if you are unlucky for `vector&lt;T&gt;::iterator` to be a `T*`, you could make the tests have the `#include&lt;algorithm&gt;` and `using std::for_each` while the regular code does not. p.s. Would you be ok if I amended the original post - to add your comment and my reply to it to make the point clearer?
Doesn't at least one implementation use a regular pointer in release mode?
1) seems like weak_ptr would work 2) there's something called std:: optional and std::variant which should be used here, so even using pointers at all is wrong :'P
What Nathan Reed proposes is not standard (anonymous struct is not standard even if accepted by GCC and Clang, and with a warning by MSVC). But anyway, you could do something like this: struct vec { union { float x; float r; }; union { float y; float g; }; union { float z; float b; }; }; And it works, no problem of aliasing because the standard says: &gt; One special guarantee is made in order to simplify the use of unions: If a standard-layout union contains several standard-layout structs that share a common initial sequence, and if a non-static data member of an object of this standard-layout union type is active and is one of the standard-layout structs, it is permitted to inspect the common initial sequence of any of the standard-layout struct members So you can write x and read r and you get the same value. 
If binary size is the issue than why use c++ at all. It's well known at using C and writing your own algorithms and data structures will result in smaller binaries. Fuck man, have you heard of machine specific instructions? This thing called ask, Google it, you'd fucking love that.
For standardization? Or as an NVIDIA library?
&gt; std::image becomes the lingua franca between OpenImageIO, Qt, Wx Widgets, OpenCV, Vulkan, etc., etc., in a C++ application. You no longer need to worry about n-factorial glue wrappers between various image formats as you add libraries to your application to be able to bounce from any API to any API. That would be really great. Couldn't agree more with that. However I think that an `std::multi_dim_array_view` (whatever it would be called) solves this sort-of too, and perhaps even in a better way. Sure it would always be non-owning, but no library would probably going to switch their image format anytime soon, if ever, and they'd have special requirements anyway, that one generic image type wouldn't cover. So a standardized, generic, multi-dimensional view on the data might be the better solution. Maybe you or SG13 people should work towards that? I think the multi-dim array view people could use some help, if there is at all still someone working on it, it seems pretty dead. Apart from that, I'd like to see some small proposals that cover things discussed in this thread (https://groups.google.com/a/isocpp.org/forum/?fromgroups#!topic/sg13/gUr98RZMU7M): Cross-platform abstractions for graphics context, and handling OS events (windows, windowing, input) - and incidentally texture/image formats is also mentioned in that thread.
SFML?
Whatever options they might have, they won't ever be enough. Spending a lot of money to go to a meeting, taking time off work, away from family and life in general, thats all a big commitment that most people, especially experts with actual work to do, can't. if they just did everything online like other sensible languages we wouldn't have these issues. Theres no reason it has to be so complicated in this day and age. Theres an argument to be made for a filter, but an even *better* argument to be made that just "having money and free time" is a terrible filter and is probably more likely to filter out the people you *don't* want filtered anyway.(IE, any experts who can't just take off and fly to some meeting throughout the year) Plus it would get a much more consistent body of people discussing issues, provide more time for more people to discuss things in more detail(can i link examples or sources out loud?) and a bunch of other nice things.
Note that I don't get the whole "students blabla" thing. Step 1: install Qt Step 2: create a new project, pick one of the templates Step 3: Add to main.qml: Canvas { anchors.fill: parent onPaint: { var ctx = getContext("2d"); } Step 4: Using `ctx` draw 2D all you like
&gt; C++ devs sure love indirections... :-) POINTERS. It's clear that OP does not know about perfect forwarding.
`&lt;random&gt;` landed in because 1 person was very keen on statistics &amp; RNG and made a signicinat amount of work to deliver a great proposal. Motiviation was that something like this would help in work - much better than raw C `rand()`. The creator is very proud of it and the commitee accepted it because there was no other such expert in this area. They knew it was done right and shipped it. The API may seem a little overenginnered (so many egnines and distros) but, hey, it's C++, right? I still consider this header as one of the best designed APIs with large possibility to override, extend and reuse. You don't have to use everything and you get very high-quality mersenne twister PRNG in 3 lines of code.
Move more discussions to reddit?
No, Hotel rooms aren't included in the ticket. But its the whole conference center for 3 days + 300 Rooms guaranteed for each night.
We need some unending TS joke. It's like friendzone for a proposal.
I was thinking about the design more than the actual implementation. As I said, it is used in G'MIC, so it's maintained. I cited this library because I think it fits the description of this post. 
`std::lerp`? I keep writing it manually in every 2D/3D program.
I agree that we need better or even standardized package management. Imho that has nothing to do with the standardization of new vocubulary types. &gt; So you want to standardize std::vector&lt;uint8_t&gt; as an image format. I think that's quite unfair to say... That's almost like saying: It's completely nonsense to standardize std::string, when we already std::vector&lt;char&gt;
Step one: Get the address of the stack pointer. Step two: Increment the stack pointer by the size of the array needed. Step three: Load your data into your ~~new~~ stack array. Step four: Since you create the stack array before calling the read function, you can use it in your calling function. Step four: Returning the array *from* your calling function is an exercise for the user. ...I don't actually know how.
Did they check how much existing code would that break? Is there any alternative they could use instead?
Or, if people want more lightweight solution, there's is SDL library (it's C, not C++ though). Getting a line on screen is 4-5 LOC with SDL. Also, as far as I understand, SDL is a video game industry standard (though not for rendering specifically)
That code-snippet did not look like C++ to me.
[Replied here.](https://www.reddit.com/r/cpp/comments/89q6wr/sg13_2d_graphics_why_it_failed/dwufkbi/)
&gt; What Nathan Reed proposes is not standard (anonymous struct is not standard even if accepted by GCC and Clang, and with a warning by MSVC). This sounds like an ideal candidate for standardization based on existing practice.
Just curious, would it work with `using std::for_each; for_each(...)`?
Maybe papers should be deliver with implementation/library as a experimental Module? Just plug experimental library into your compiler...
Yeah, I remembered that after I posted - seems to work on the latest releases of gcc, clang and msvc. I didn't test the older releases.
I have to agree, seeding RNGs is a big problem. No easy way and no specialized API for it.
This article makes the impression that `weak_ptr` is a replacement for raw pointers, but this is quite far from the truth, since you can only get it from a `shared_ptr`(which is anyways usually a sign that ownership was not thought through).
&gt; Depending on the OS/windowing system, no event loop means you can't do fairly expected stuff like move/resize/close the window. You don't have to expose an event loop to the developer for that. The most that is really needed is to provide a callback for a resize event. Nothing else is needed. &gt; which means you brush up against the colorspaces issues unless you don't care what gets displayed when you display it. &gt; At that point, you are definitely 100% making a feature that's only useful in toys. Which is no different from iostreams. iostreams is really only useful in toys. Yet I would think most people would rather teach with iostreams than with the printf family. Everyone understands RGB. It's even the main colourspace for web programming. That hasn't held back web development from being more than just a toy.
As far as I know there is none that will let me: - download libraries without relying on a centralized repository - works across a range of platforms (including Windows and Mac) and compilers - works without me having to install a few gigabytes of build systems - let me install multiple versions of a library side by side But if you can think of one, by all means propose it for standardisation!
I still don't quite understand the use cases or demographic of this API, which is a bit of a problem. As a game developer, I have pretty high requirements for graphics libraries. I've used SDL for some 2D game things and it does a pretty great job for most things. But then I realized that I wanted to use [sdl_gpu](https://github.com/grimfang4/sdl-gpu) because I needed the shader support for cool effects (yes, for a 2D game). I have recently started considering switching to Vulkan (yes, still for a 2D game) because ~~I am stupid~~ it gives me more control and lets me do even more cool stuff. Besides, Vulkan is well on its way of becoming the industry standard, so I might as well get on with the times. However, I would love to be able to use the standard library for the less complex rendering, as mentioned in the text: &gt;Example of how to get our 2D contexts into an OpenGL render target for game UI So yeah, in order for this API to be usable for me I have to be able to smoothly integrate it into an already existing Vulkan application. And then there is input. With input as a part of this, it is not just a graphics API, but rather a window API. I mean, that's fine too, but it should be explicitly stated as such. Input and graphics are two completely different things and you shouldn't just shoehorn in input into an API that is about graphics. I really think the goals, intended use cases and scope all need to be more clear for the proposal to even be feasible.
Ah you're right of course, got a bit carried away by my refound joy of qml.
&gt; partially since you can only get it from a shared_ptr(which is anyways usually a sign that ownership was not thought through). It seems to me like you are repeating a quote you heard without understanding it. A `shared_ptr` is any ptr which at one time or another will refer to a memory area that another ptr will refer to. As long as the ptr is owned by more than one thread (or one function call, if you want to think of it that way) it should be a shared pointer. In a program with ownership semantic any non-owning pointer will logically be associated with a shared owning pointer (call that `arc`, call that `shared_ptr,` call that w/e), associating a `weak_ptr` with any type of single-ownership ptr (say a `unique_ptr`) can't and shouldn't have a non-owning pointer type associated with it, since it break the guarantee that said pointer should give (that the resource can't be seen or modified by any other thread in the code). The ONLY situation where weak_ptr is a bad replacement for a non-owning raw pointer (that I can think of) is: a) When working with external resources (e.g. network memory), such that your program and the other programs using said resource (or the "manager" of said resource) need to converse about who should access the resource and how it should be accessed through another channel. b) When you want to have some really convoluted non-owning caching and don't want to destroy a resource as soon as it's no longer needed but, rather, upon a condition being meet or after waiting for a certain amount of time. I'm not sure this kind of caching would even make sense.... but I've seen crazy caches before, so I will concede that maybe such a model could exist. So basically: Yes, `weak_ptr` is a replacement for non-owning raw pointers, pray tell me when it isn't (again, vast majority of cases, exceptions like the ones mentioned above exist but they are few and far between AND can sometimes be abstracted over with smart pointers anyway)
I'm not sure how this is a disagreement. When people don't have time or interest, it's most of the time not because they don't care, but it's because the process to actually comment on something is just not worth it. When you have to write a paper just to comment on something or oppose the proposal, I don't see why any expert would really bother. It's a very specialized topic and if you want people and more specifically well paid experts to engage, you need to make it possible for them to do so in an informal way. As long as the group is very small and nothing really interesting going on, it's near impossible to get a company to put some money aside for their devs to spend time writing papers and there are only so few people who after a hard day of work, go home and write papers. But on the other hand, some group chat, forum or other way of communication, certainly would let people casually engage in discussions after work and if there's one person that likes writing papers, they could start with continues input from the rest. The "You can't touch my paper until you write your own paper"-stance is really unproductive and doesn't move anything forward.
Good to know. I seem to remember a dev blog or something about that topic, but maybe it was something in the same area and not that.
I wouldn't call the EASTL irrelevant. Maybe in your profession, but we are a diverse group :)
Reading image files and even more so, reading video files, in in no way "smallish". Neither is it well-scoped, given that there are hundreds of formats, and most of them have dozens of variations. For example, no known application fully supports even JPEG specification.
Yes we are (fortunately) :) I agree. I guess I'm lucky to have only one compiler/stl implementation I have to worry about.
Using weak_ptr outside of specific data structures and perhaps threaded callbacks is a code-smell. Shared ownership is harder to reason about and is often not required. std::optional can sorta fit as an optional in-out param, but it’s usage is far from intuitive; the function would have to take it by reference, and to pass std::nullopt you’ll have to put it in a variable (because you can’t bind an rvalue to a non-const lvalue). All in all, a pointer is just an easier and more intuitive way to pass optional in-out params.
Interesting, thanks for sharing Ivan! Just to make sure I understand the use case, in this case begin returns something that is not an iterator, but still has a semantics of giving access to several things, right? And then ui::for_each has the semantics of std::for_each but adapted to the interface of this returned object? Besides the point that you're making clearly, that ui::for_each should preserve the semantics of std::for_each, the same way that operator+ should preserve the semantics of addtion, do you think that we should _try_ to give this begin an iterator interface (like the asynchronous istream_iterator one), in order to reuse std::for_each? Or do you find it makes things more complicated?
Note that I am not claiming there is no use of `shared_ptr`, I am just saying it is highly likely you don't need it (this also implies the same to `weak_ptr`). &gt; any non-owning pointer will logically be associated with a shared owning pointer For an example see something like iterators implemented with raw pointers which describes non-owning relationship. You can also take raw pointers to objects on the stack, which is not possible with `shared_ptr`. &gt; associating a weak_ptr with any type of single-ownership ptr (say a unique_ptr) can't and shouldn't have a non-owning pointer type associated with it, since it break the guarantee that said pointer should give (that the resource can't be seen or modified by any other thread in the code). `unique_ptr` does not have the guarantees you ascribe to it. Note that sharing memory != sharing ownership in most of the cases. &gt; Yes, weak_ptr is a replacement for non-owning raw pointers No, `weak_ptr` still describes ownership (temporary). The fact that you can't take take something's address as `weak_ptr` and you can't convert `unique_ptr` to it should tell you that this is not a valid claim. &gt; It seems to me like you are repeating a quote you heard without understanding it. No, it is you who is advocating for a `shared_ptr`-everywhere type of approach that I had in mind. Sure it is easier to just sprinkle `shared_ptr`, but I think it is better that you actually figure who should be owning that particular resource (even in a multithreading context). If it is really something that has shared ownership, then by all means use `shared_ptr`.
&gt; so maybe watch out for a Medium post by me in the next couple of weeks Please do. I was not aware of the shortcomings of `&lt;random&gt;` and I think that most people are in the same boat. A well-written post would be highly-beneficial to the community.
You know, trying to figure out what exactly an image is (from the point of view of image processing library implementor) is basically the subject of my Ph.D. thesis (that has started 6 months ago). I'm currently trying very hard to define a concept Image and list what are the possible models and model specializations of it. And when you want to have an approach that is compatible with the standard approach, it's not that easy. Reference work includes Range's design discussion here: https://ericniebler.github.io/std/wg21/D4128.html to have proper morphers and algorithms. Some image types that model the concept Image are (not exhaustive) : * ImageND (specialization, Image2D, Image3D, Hyperspectral) * bits (think of vector&lt;bool&gt; huehuehue) * image with look up table * graph, tree * yeilded by a maths function * ... I won't go into details but if you want a proper Image concept, you need to think of stuff like neighborhood, extensions, iteration, interleaves, buffering (for large image (TB astro), nmap, streams, over network), points (they can be anything, really, just need to model (IIRC) EqualityComparable and StrictTotallyOrdered. Well my point is, in my lab we've got a team (in which I am) that has worked the last 15 years on this problem, with publications, thesis, lib implementation to back up all of this. It's oriented impage processing but I think that, if the committee is willing to encourage work on this, we may be willing to get involved: this is stuff we know about. (I don't know who nor when though, need to discuss with my Professor about that)
&gt; For an example see something like iterators implemented with raw pointers which describes non-owning relationship. You can also take raw pointers to objects on the stack, which is not possible smart with shared_ptr Why not use &amp; for "pointers on the stack" ? As far as iterators are concerned, in a perfect world they should actually be "owning" to an extent in the sense that you don't want your struct's end/begin to change (or the struct to be deleted) during iteration. Ideally they should be bound to the scope and memory are of the struct in some way. But those are indeed more subtle ownership semantics that can't (yet) be implemented in C++ and should be CT bounds in order not to add overhead. But that is, once again, an edge case... unless you find yourself implementing iterators from scratch a lot. 
True; but for some use cases, 4096 bytes is enough to read through a file. Not store it, but certainly perform analysis. Although my most common case for stack arrays is itoa and related functions, where the result will be displayed immediately, and speed is desired.
best found out by attempting to get a random number out of it.
Yes, that would work.
creating a surface in opengl is not easy https://www.khronos.org/registry/EGL/specs/eglspec.1.5.pdf
template&lt;typename T1, typename T2&gt; struct pair { T1 first; T2 second; }; How hard can it be? 
Just curious about some of your issues: &gt; download libraries without relying on a centralized repository What is wrong with having a central repo? Works quite well in the Maven/Java world. &gt;works across a range of platforms (including Windows and Mac) and compilers Looking back again at Maven, it has the concept of a *classifier* which is often used to distinguish components that are platform specific. For example, lwjgl (opengl for Java) allows pulling platform specific native libraries for the OpenGL code using this model. &gt;works without me having to install a few gigabytes of build systems As long as there is only 1 build system needed that works across platforms this shouldn't be an issue. Now if you need different build systems for different libraries then yes, this is an issue. &gt;let me install multiple versions of a library side by side Why would you want different versions of the same library for the same platform for a given application? Shouldn't there be only one version for an app? Then so long as the deployed application can locate its version this shouldn't be a problem? I completely agree what C++ is missing is a solid build tool and dependency management system. With my limited exposure in recent years to current C++ (been in the Java world for a while) build systems I think CMake handles the cross platform build parts, so if there was just a way to handle dependency management in a commonly accepted way much like how Maven's dependency management is the defacto standard in Java, that would go a long way to eliminating the need to expand the C++ standard includes. 
&gt; Why not use &amp; for "pointers on the stack" ? If you are referring to &amp; as "taking address of", then that produces a raw pointer, yep. &gt; in a perfect world they should actually be "owning" What you are describing here is not really ownership IMO, more like lifetime. These are different concepts. &gt; But that is, once again, an edge case... Iterators was an example, having non-owning views (incl. raw pointers) is not an "edge case". &gt;&gt;No, weak_ptr still describes ownership (temporary) &gt; &gt; I would argue not, it describes the possibility of owning something, let's say... accessibility, but it's non owning as long as it's not turend into a shared_ptr I'd say that is what I said. In the end it feels like you are arguing for a (more) memory safe dialect of C++, but if this is your goal then please spell it out, because this is not generally applicable advice. Yes, in C++, you are responsible for managing certain lifetimes, no, it is not a good idea to try to solve this (in a general manner) via `shared_ptr`.
Yes, SFML is nice in most ways. But I would probably do away with `sf::Drawable`. I'll be looking at the SG13 forums to see what problems people had with the previous proposals.
Do you mean stateful TMP?
Conan fits all of these right now. There is a central repository, but you can use any additional repositories you want (including hosting your own.) It supports all major platforms and doesn't require building the libraries locally, so you don't need the build tools they use. It also specifies the version to download and will happily allow you to have multiple versions or even multiple variants of the same version.
Very nice! I really like the accessor trick.
Not easy to figure out if a number is actually random. Apparently there are many ways to initialize a generator incorrectly by only filling part if its state with random bits.
Well sure, but you will never cover 100% of anything. libpng+libjpeg+libtiff cover I'd guess 99% of all the images out there. Of course there are very specialized domains (for example medical imaging, or maybe movie studios) that mainly use different formats. But that's not relevant here. It's about having easy access to something that is useful to 90% of the people, and not to every single person on the planet.
&gt; If you are referring to &amp; as "taking address of", then that produces a raw pointer, yep. I'm referring to &amp; as in a reference, which is essentially "address of" only with prettier semantics, reference in C++ have some semblance of ownership semantics, at least in the sense that they can't be null when they are created and they provide a few other guarantees (e.g. against casting and modifying) that raw pointers don't. In that sense I'd argue they are closer to smart_pointers, a kind of proto smart pointer of sorts. &gt; What you are describing here is not really ownership IMO, more like lifetime. These are different concepts. Agreed, actually, it is closer to lifetimes... but considering C++ lacks such a thing as the concept of lifetime, couldn't it be expressed via a type of smart-pointers bounds to things other than the memory are they are pointing to ?
&gt; mainly stemming from that asynchronous i/o completing to a pool of threads like ASIO does is a bad default choice Except that's not the "*default choice*" for Asio: You can call `boost::asio::io_service::run` from as many threads as you want, so completion may go to a particular thread **or** a pool. Full disclosure: My opinion of AFIO has always been tainted by the fact that it doesn't reuse/incorporate Asio's `io_service`.
&gt; POSIX doesn't standardize it, because it is nonsense. All the major platforms implement some API for fetching the current path of an open file descriptor. It is ripe for standardisation. &gt; What path will you query if the file name was removed from file system (yet the file still exists until closed). Empty name? That is one option of many. &gt; And such an API just makes people write code full of race conditions. You now see the value of a standard suite of generic filesystem algorithms in the C++ standard. 
&gt; Except that's not the "default choice" for Asio: You can call boost::asio::io_service::run from as many threads as you want, so completion may go to a particular thread or a pool. True. But the design is the wrong way round. It is straightforward for the user to build a pool of threads using a single threaded i/o service, if that is what they want to do. There is no need for the i/o service to build in support of pools of threads, and more importantly, to be required to be implemented with all the machinery to work across threads even if the user never does that. &gt; Full disclosure: My opinion of AFIO has always been tainted by the fact that it doesn't reuse/incorporate Asio's io_service, and I think it would be misguided to both adopt this as-is and the Networking TS because of this. Firstly, AFIO relegates async i/o as very much a second class citizen. You are advised throughout both the proposal paper and the docs to avoid async file i/o. If you think you want it, you are almost certainly wrong. It's there for those who discover that they *need* it from empirically benchmarking a synchronous implementation, and they will be rare enough that in the proposal paper I entirely accept that async file i/o support should be dropped entirely from the standardised edition. Secondly, it is not technically possible to implement an i/o service which can dispatch both socket and file i/o completions both efficiently and portably. Linux is the main blocker here, MacOS, BSD and Windows can do it, Linux cannot. (AFIO v1 worked around these limitations so it would work with ASIO. It was slammed for it during the Boost peer review. So v2, as per Boost peer review feedback, drops the ASIO compatibility entirely)
Except you couldn't then call that vtable entry. You'd need to also store a pointer-to-member, which just kicks the can down the road. 
&gt; I'm referring to &amp; as in a reference References have nothing to do with smart pointers or ownership and nothing prevents you committing the same class of memory unsafety errors with it (the difficulty with raw pointers, I'd argue, is not that they are sometimes `nullptr`). &gt; C++ lacks such a thing as the concept of lifetime http://en.cppreference.com/w/cpp/language/lifetime http://eel.is/c++draft/basic.life &gt; couldn't it be expressed via a type You can typically trade off some runtime perf and/or coding standards for some safety, eg.: http://ithare.com/a-usable-c-dialect-that-is-safe-against-memory-corruption/ But writing correct programs does not require `shared_ptr` (again, excepting the special cases).
My suggestion (FWIW) would be to drop asynchronous I/O from the library completely, and am curious (genuinely) why this hasn't been done. Also, assuming that's a non-option (for whatever reason): &gt;You are advised throughout both the proposal paper and the docs to avoid async file i/o. So given this and: &gt;Secondly, it is not technically possible to implement an i/o service which can dispatch both socket and file i/o completions both efficiently and portably. Linux is the main blocker here, MacOS, BSD and Windows can do it, Linux cannot. Why not make it work with Asio for asynchronous file I/O (which is as you say a "*second class citizen*") using an inefficient workaround for Linux? In what way would this not be superior in every way to what exists right now? Then people who use Windows, MacOS, and BSD could benefit from the tight integration (and the kinds of design decisions and optimizations that allows) and people using Linux would be just as out of luck as they are right now. Cross-platform projects would have to fallback to using synchronous file I/O but that's what you advise doing by default anyway, so that's not really a problem.
Yes, +1. there are quite a few post touching upon [the problem of] compiling resources into a binary. On windows, I use the overloaded functions of LoadFromResource&lt;T&gt;(...) as defined in https://gist.github.com/degski/18b983d5153b85004eb28c9d8fd409fa . This mostly abstracts away all differences between resource types (sounds, fonts, images etc...) You''ll need to create a .rc file and a resource.h. I've included some examples of some I've used for a project, just to show what needs to be in them.
I don't know what you're going on about Desktop platform. We are a small company and we have a product shipping Skia on Linux/Mac/Win. We also support Linux ARM with no problem. We might have a point when it comes to iOS and other non-linux mobile systems, but the Skia team is quite open about how those platforms are not their priority.
Time waste alert - ignore this.
True, but C++ is not known for having concise APIs naturally supporting functional programming idioms :P
"Vocabulary type" is exactly the term I should I have thought to use when I was doing my brain dump. Thanks.
&gt; You don't have to expose an event loop to the developer for that. The most that is really needed is to provide a callback for a resize event. Nothing else is needed. If there is an event loop, it either blocks so the application developer's code isn't running except through some callback system, or it's in another thread and you can't display your image without the complexity of a multithreaded GUI. (eep) If the event loop exists then it'll potentially interfere with a main event loop, swallowing events and such if you try and use sthe std::display_window from a GUI app that is already trying to use events. That makes it toxic. Tons of people use std::cout in real applications. It doesn't make anything explode, and it's fast enough for many uses.
&gt; My suggestion (FWIW) would be to drop asynchronous I/O from the library completely, and am curious (genuinely) why this hasn't been done. There is a genuine use case for async file i/o, which is with unbuffered handles. I can foresee a useful generic bulk directory tree copying algorithm which uses async i/o with unbuffered files which doesn't need threads, for example. &gt; Why not make it work with Asio for asynchronous file I/O (which is as you say a "second class citizen") using an inefficient workaround for Linux? You're assuming ASIO's i/o service is best in class, and the best choice for dispatching async i/o completions. The "inefficient workaround for Linux" is especially inefficient. To my best knowledge, for every socket i/o completing, we would need to send and handle a signal. This is due to how Linux implements its async file i/o dispatch. Socket i/o would be hideously impaired. Even on Windows, using IOCP to complete file i/o is more than ten fold higher latency variance than using alertable i/o. IOCP is a *lousy* choice for completing file i/o. I will say nothing about its choice for socket i/o. &gt; Then people who use Windows, MacOS, and BSD could benefit from the tight integration (and the kinds of design decisions and optimizations that allows) and people using Linux would be just as out of luck as they are right now That's a valid choice for a software library. Even a Boost library. But not a standards proposal. We standardise **existing** practice. We don't (or shouldn't) invent practice. 
&gt; You're assuming ASIO's i/o service is best in class, and the best choice for dispatching async i/o completions. No I'm assuming that Asio's I/O service is pre-eminent in class and that the standards committee would be ill-advised to standardize two things which essentially do the same thing. &gt;Even on Windows, using IOCP to complete file i/o is more than ten fold higher latency variance than using alertable i/o. IOCP is a lousy choice for completing file i/o. Which assumes the latency with which the file I/O completes is important which I would argue it is not in the overwhelming majority of cases. &gt;We standardise existing practice. Best I can tell existing practice for file I/O is to roll something different for both Windows and Linux so should we standardize that?
Sounds neat. Obviously, if something like this came from nV, it'd get a lot more eyeballs than some rando with a reddit account. I'd be curious to hear where you guys are going with it.
[You're out.](https://i.imgur.com/kXE6X1F.png) However, my understanding is that you have to defeat a committee member in combat to be able to vote... who did you defeat? Didn't Herb Sutter lose an eye?
&gt; Optional in-out parameters. Hm, I wonder if something like this would be desirable... void sasuga(auto e, auto i, auto n, auto z){ if constexpr(decltype(e) != nullptr_t &amp;&amp; decltype(e) == any_kind_of_pointer_type){ do thing with e } ... } Would require that you put in nullptr to disable the parameter, 0 would not work. But would work nicely with all kind of pointer types. 
Again, assuming you have an embeded issue where binary size is still a problem... because you want to keep HW costs really low and are dealing in dozens of KBs, why use C++ at all ? Why not use C and inline the few things you need ? (Though nowadays my credit card has 30MBs of DDR3) Also, the example given was related to VMWARE, nothing related to the embeded space.
There is also C++Now in May in Aspen. http://cppnow.org/announcements/2018/02/2018-registration-is-open/
&gt; No I'm assuming that Asio's I/O service is pre-eminent in class and that the standards committee would be ill-advised to standardize two things which essentially do the same thing. There is widespread consensus that ASIO's i/o service design once upon a time was pre-eminent in its class. I doubt that's even a majority viewpoint now. Many of the early objections to its standardisation was exactly on that point in fact. I remember DMB making particularly strong arguments on that basis. Must we replicate what was once state of the art, but is now inferior, just because it "looks pretty"? We've not done that for optional, variant, any etc. They all got very separate APIs, each reflecting the trends and fashions and hardware imperatives of when they were first designed. It's no different here. What AFIO has chosen will age and become obsolete as well. Fifteen years from now I would very much doubt if copying AFIO's design would be wise. Hardware will have changed too much by then. As will the language. &gt; Which assumes the latency with which the file I/O completes is important which I would argue it is not in the overwhelming majority of cases. You would be surprised. Filesystem engineers spend a ton of time getting i/o latency variance down, creating lovely smooth latency curves, and then get very upset watching higher level code and languages piss all over their hard work :) Back when I reported the big difference between IOCP and alertable i/o latency variance, it was taken *very* seriously by the relevant folk at Microsoft. The cause, we discovered, was the scheduler team optimising perhaps a bit too aggressively for 10-40Gbps class NICs. Benefits there were very substantially punishing file i/o and less capable NICs. My argument, at the time, was that there are far more 1Gbps NICs and hard drives out there than 40Gbps NICs. No idea if that argument was accepted. &gt; Best I can tell existing practice for file I/O is to roll something different for both Windows and Linux so should we standardize that? Standardisation is always of lowest common denominator. If any one major platform chooses to segment its file and socket i/o completion mechanism, then that's what we standardise. &gt; Also best I can tell the existing practice for file I/O is synchronous, which brings us back to what I originally said: Drop async file I/O. Somebody needs to go write some empirical benchmarks to prove its uselessness across a wide variety of platforms. That would be sufficient for me to be persuaded. From my own testing, there is good benefit for bulk unbuffered file copies up to a certain queue depth, I found around 60 was about right. After that it becomes pathologically slower. I entirely agree that's just one data point. I'd like to see lots more empirical evidence on this before changing my current opinion. 
This is the real answer and side steps the whole problem. Who is writing the proposal for that? 
&gt; Must we replicate what was once state of the art, but is now inferior, just because it "looks pretty"? We've not done that for optional, variant, any etc. They all got very separate APIs, each reflecting the trends and fashions and hardware imperatives of when they were first designed. Sure which has nothing to do with my point. My point is that having two classes which are very close to being identical in the standard would be a travesty so either AFIO should use Asio's `io_context`, Asio should use AFIO's `io_service`, or a third option should be settled on by both. You have issues with `boost::asio::io_context`. That's legitimate. The question is whether those issues are worth imposing the overhead of two different `io_service`-like objects on people who want to use both Asio and AFIO. I'm going to assert that the answer to this question is "*no*," which is my point, and I think this "*no*" gets stronger considering you seem to want both these libraries to be (loosely) on standardization track. &gt;You would be surprised. Filesystem engineers spend a ton of time getting i/o latency variance down [...] Which has nothing to do with my point. Filesystem engineers are designing a filesystem for every use case whereas my assertion was about the overwhelming majority of those use cases. I've personally never directly worked with a filesystem use case which was latency sensitive. Throughput sensitive yes, latency no. Accordingly if the "*cost*" of async file I/O was tenfold latency increase I wouldn't particularly care. I'm not saying that those use cases don't exist, I'm saying that optimizing for them at the expense of everything else ignores the overwhelmingly common cases. &gt;If any one major platform chooses to segment its file and socket i/o completion mechanism, then that's what we standardise. Except this doesn't seem to be true since socket I/O completion on Linux is based on [`epoll`](http://man7.org/linux/man-pages/man7/epoll.7.html) and as per you file I/O completion notification on Linux is handled via signal which can be demux'd through `epoll` via [`signalfd`](http://man7.org/linux/man-pages/man2/signalfd.2.html). In fact [Asio already has a utility for doing exactly this](https://www.boost.org/doc/libs/1_66_0/doc/html/boost_asio/reference/signal_set.html).
Both eastl and stlport use pointer to T as their iterator.
It would really help if you'd clearly distinguish between the semantics of STL types like `std::shared_ptr` or ` std::unique_ptr` and whatever conventions you think should be followed when using some form of shared pointer (whatever your definition of that is). 
Much of this appears in boost GIL - could be a good starting point?
Basically, I think that GIL is *too* flexible to make a good candidate for inclusion in the standard. It's extremely generic to the point of supporting things like [non-byte-aligned](https://www.boost.org/doc/libs/1_66_0/libs/gil/example/packed_pixel.cpp) image data in its image classes. Which means that writing code that can handle all GIL variations becomes quite complex. Paring down to a minimal container means every library like GIL can interoperate with it. Obviously, if std::image doesn't support a pixel format used in GIL, you wouldn't be able to do a zero-copy to make it, but it'd be a single-copy/conversion to go from some strange raw sensor data format in GIL to std::image, and then zero copy to go from std::image to an FFMPEG AVPicture or whatever, because AVPicture would support the common format of std::image pretty easily. (Then from the AVPivture you might do some subsequent conversion to YUYV or whatever to stuff into a compressed video file.)
I don't know it and while I know what I expect from modules and what functionality a package manager should have, I have no experience and knowledge how to design and implement such thing well
&gt;why not just have the prototype accept unsigned char Probably because, as you pointed out: &gt; unsigned char nor equal to EOF &gt; EOF integer constant expression of type int and negative value 
unless you jump through hoops, weak_ptr requires the object to be dynamically allocated and if it isn't allocated via std::make_shared, it requires another dynamic allocation for the control block. Not to mention the overhead when you actually want to reference them. That is not something you should use to willy nilly replace a a raw pointer with. How exactly would you implement string_view (or any other view for that matter) with a weak_ptr?
Generic algorithm libraries author here: on top of my head the headers that I include the most are &lt;type_traits&gt;, &lt;utility&gt;, &lt;iterator&gt; and &lt;algorithm&gt;, not sure in which order :)
There would be no ambiguity unless you pulled both the std and ui version into scope and nothing else was more appropriate. There would be no reason to do that. 
That's not at all true. One of the stated reasons for a TS is the case where there is more than one possible direction, so we might release competing TSes.
The [overloads in `&lt;locale&gt;`](http://en.cppreference.com/w/cpp/locale/isalnum) are safe to call with `char`. (Still slow and, obviously, doesn't work with UTF-8). #include &lt;locale&gt; // helper function template&lt;typename CharT&gt; inline bool is_alnum( CharT c, const std::locale &amp;l = std::locale::classic) { return std::isalnum(c, l); }
&gt; an unacceptable penalty on every socket, not file, I/o. Where exactly does this come from?
Iostreams isn't a great example since we're hopefully gonna have fmtlib standardized which would be better for both beginners and real world programs. Also getting window resize messages still requires an event loop sonewhere. Either the user code is pumping the message queue, or there's some implicit thread spawned somewhere that takes care of all the window messages hidden away and just dispatching callbacks for specific messages, like glfw. I like glfw, but an explicit OS event queue api more like SDL seems like a better foundation.
Regarding (3), there was a proposal at the last meeting to introduce a new `char8_t` specifically for UTF-8 byte strings. I haven't seen any follow-up in the recent trip reports though, so I don't know how it was received.
These are also good resources: - https://isocpp.org/wiki/faq/conferences-worldwide/ - https://github.com/shafik/cpp_youtube_channels - https://www.meetingcpp.com/usergroups/
Right... You'd need to somehow cast the vtable entry back to a pointer to the actual lambda type, and then call that. But being able to know the type of the lambda at the call-site means you need to encode it somewhere, which goes back to the initial problem. Yup, I'm now reasonably convinced there's no way around storing the signature somewhere explicitly.
And I thought it had to do with the fact that `for_each` explicitly supports stateful function objects and encourages the user to wrap up their mutable state into a class with a call operator, like an impure sibling to `accumulate`. I guess that's not en vogue now that lambas+tuples+move semantics are in the picture...
Each time you write `te::call(...)` in your code, it registers a new entry in the vtable under the hood. For fun, try writing `te::call` twice in one method and look at the generated vtable -- it will have one entry for each call. It's very subtle but also very clever.
That's absolutely a fair point, thanks for your considered response. I wonder though if some of the (small c) concepts from GIL could be usefully turned into (capital C) Concepts in the standard. That would allow you to separate the storage from the valid operations on a notional image, which would feel much more like a C++stdlib feature than a somewhat customisable container would - IMO. I'd also be interested in seeing how GIL's more interesting iterators could work with Ranges. Pragmatically though, I can see that getting existing graphics libraries to interoperate with a fairly concrete std::image is an order of magnitude more likely than getting them interested in supporting abstract and esoteric sounding concepts. And of course none of this GIL-like stuff is likely to make graphics more approachable, probably the opposite!
Likewise, plus &lt;functional&gt;, and &lt;numeric&gt; if a ranges lib isn't handy.
Good point, I and guess this design decision pervades nearly all of the interfaces inherited from C for interacting with characters / strings. I guess the expectation might've been developers writing code like: int ch = getc(file); // might be EOF if (isalnum(ch)) { ... } // not UB, at least but it seems like normally one would, or should, validate they got something that wasn't `EOF` before processing it that way. (I'd be curious to read the history behind some of these design decisions, if it exists)
Has that ever happened before?
Plugging my way through https://github.com/torvalds/linux/blob/master/fs/aio.c, it looks like things may have improved in recent kernels. It used to be the case that the `aio_resfd`member in http://man7.org/linux/man-pages/man2/io_submit.2.html didn't work. Now, it may do so, and if it does, then an eventfd can be signalled upon completion of the asynchronous file i/o. An eventfd can be fed to `epoll()` which is what ASIO's i/o service uses, so maybe it could work now. I'd need someone to demonstrate it to me, and that it has good performance. There still remains the problem of MacOS. It lacks file i/o completion support (`EVFILT_AIO`) in `kqueue()`, which means you need to use signals :(. MacOS, via iOS, is no minor platform either.
The question explicitly states storing the entire file. 
Adopting a GIL image container into the standard certainly isn't the craziest idea anybody ever suggested. As much as I find it way too generic to be useful day-to-day (much like my nemesis, Boost Graphics library, which supports more permutations than it will ever have users which means that it's possible no two programmers have ever done quite the same thing with it!), a GIL container is still much narrower in scope that the windows, input, sprites, drawing, singing and dancing megalibrary that variations of SG13 have covered. I'd be a hard-no on including *all* of GIL since it has some utility functions for loading images from disk and the like that I'd firmly consider out of scope for a 1.0 effort. (Every library is currently forced to have some variation of a half-hearted image loader like that, since there's no lingua franca for populating your image container if you make one. Standardising means it's no longer in a vacuum, so the necessity is no longer there.) I am a stick in the mud. I am comfortable being a stick in the mud.
**Company: [AutoX](https://www.autox.ai/jobs)** **Type:** [Full Time] **Description:** AutoX’s disruptive camera-first AI brings self-driving cars out of the lab and into the real world. We believe that autonomous driving should not be a luxury, and we are making it universally available to everyone. We needs great C++ coders to help put all advanced algorithms into real practice for our **autonomous driving platform**; develop scalable frameworks to support many types of vehicles and configurations; design efficient components and optimize existing software for limited compute platforms; collaborate with other engineers to implement, integrate, and deploy **robotic perception, mapping, localization, and sensor calibration software**... **Location:** San Jose, California, USA **Remote:** NO **Visa Sponsorship:** YES we sponsor or transfer **Technologies:** C++ * For system&amp;tools: Operating Systems, Databases, Concurrency, Linux Kernel, Compilers, Distributed Systems * For perception: algorithms, data structures and math in general * For mapping: mapping experiences * Robotics **Contact:** Apply through our job page or email me at **fyang@autox.ai**
Yeah, but that still leaves us confused on how it does that, without dynamic memory allocation.
array and thread are obvious, less obvious are things like stable_sort or atoi, very few people know that atoi may rely on a locale in order to keep track of what is considered whitespace. Without a freestanding implementation, each team must make and enforce their own coding guidelines. There is some truth to linus torvalds rants about C++ secretly doing terrible things, its not true for your domain probably but for his domain (kernels etc.) it is.
Exactly. I parse a CSV, it gives me a std::string. I dome some processing and aggregation with a regex library that can operate on std::string. I review the results in a GUI that displays the contents of a std::string. I stuff that resulting data into a SQL database through an ORM using a std::string. I read the data back from the database and give a std::string to an HTTP API to shoot it out the network. And then you get a web page that says "John" is the most common baby name in the year you were born, or whatever. But I don't need CSV support in my HTTP library to do it. B'cause, you know... there's a std library that other libraries can build on top of.
I'll commit to at least putting some time aside for the attempt then.
&gt; The last one of the list, `utility`, was slightly unexpected for me. It contains things such as `std::make_pair` and `std::move`. At least the latter one is required for any class that does its own memory management. I don't think it's mainly used for memory management. The need for it pops up very often in classes that don't do any memory management whatsoever.
Just give me standard functions that *always* work with Unicode, not using locale-dependant multibyte and wide char encodings, and I'll be happy.
and rather tellingly - nobody tried to standardise CSV parsing or database access before we had a standard string. (That's a bit of a straw-man given the timescales involved, but still a useful talking point I think.)
Right, thanks for the feedback and tips. I really appreciate that. Going to try to make it happen.
Event loop: int main ( ) { App app; while ( app.is_active ( ) ) { app.run ( ); } return 0; } That's my game loop, no need for std support. 
Well I assume that std::function is slow due to type erasure and allocates. Maybe I am weird, but I do not find that hard to remember. But you have inline_function that fails to compile if object does not fit on stack. Not in the standard obviously... 
you're right, let me just go run `universal_cpp_package_manager install gfxlib` so I have that graphics library I needed. Oh wait, that's right; there is no universally used C++ package manager. I'm not even aware of a non-universally used one, although I'm sure such things exist.
&gt; When you actually check for everything, everything has to match exactly Are you saying that some of those don't implement iterators that have the correct signature for things like ++, *, that don't work with `std::advance`, etc? That would be surprising. &gt; As mentioned before, syntactic concepts are just another form of weak typing. They are on one hand very convenient (less typing!) and on the other hand very brittle. Again, to be clear, I don't disagree. There's value in being explicit, and it's rarely an issue (that was my first post). But sometimes being explicit is an issue and I've already explained how several times. Also: &gt; The Rust model is slightly less convenient, but never breaks. Come on, it breaks when the programmer breaks. Static typing is valuable but let's treat it as a tool, not a deity. At the end of the day most problems in most real code are caused by programmers misunderstanding specs, making logical errors, etc. No language can save you from that. Rust won't save from you implementing the totally ordered concept incorrectly for a type, for example, or implementing it for a type where it just doesn't make sense. &gt; Anyhow, first, you are incorrect in that this is not the case for C++ as well. For example consider the TotalOrder: it should only require PartialOrder but nothing else. Again, please accept the caveat that I agree with the fundamental point here, that two classes with the same syntax can have different semantics. That said, your example is wrong. PartialOrder is defined by &lt;=. Strict weak is defined by &lt;. And total ordering is defined by &lt; as well as ==. So the different semantics do in fact map correctly to different syntax. The standard library only ever uses strict weak ordering, and it only ever expects &lt; to be defined (it uses == for other things that are totally unrelated to ordering of course). &gt; Second, you are also incorrect that in Rust you have to always implement all concepts for each type, because you don't. That's not what I said. I said basically the opposite: you could have cases where there is a concept that is already satisfied by class(es) from library(-ies), but you would have to write out the boilerplate, per concept, per method of the concept, per class. I did not say that in every single situation you would have to do that. &gt; How so? In Rust you write normal run-time Rust code, and that code is executed at compile-time, and can manipulate the Rust AST at compile-time to create a new AST. AFAIK in Rust you write macros, which manipulate the AST, not "normal Rust code". Can you show me a Rust program that launches a thread at compile time? Macros in practice are basically used as a hack to provide certain day-to-day necessities, that can't be done in better ways because the facilities are missing. For example, there is no reason why you should have generic operations on one variable be generic functions, and generic operations on arbitrary numbers of variables suddenly turn into macros. There's no justification other than: macros kinda handle the common cases ok and we haven't done variadics yet. The same is true with reflection; macros can be used to hack in reflection to types that you control, because they are intrusive. But if someone else has a struct that you would like to serialize to json, you have to write out all the fields again by hand, because you can't reflect over someone else's struct. println! is another example; this has to be implemented in compiler (unless things have changed recently) probably because doing this with macros is just crazy. Compare to a language like D which has generalized constexpr, variadics, and compile time strings, and can do something like println in user space (C++ is only missing compile time strings for this, and they're available as an extension, so this is already implemented in the fmt library). &gt; FWIW, you can obtain the size of an object behind a box Sure, I mean essentially Box just adds a `size()` in the vtable and the implementation is provided generically. In any case though, that's probably the wrong part of what I wrote to focus on. The type may be erased in the function body, but it's still not actually erased because the function's signature will vary as it's passed different types. The whole point of type erasure is that it doesn't propagate the type outwards, but a generic function in Rust still propagates the type outward, the same way as a function template does in C++. So it depends whether you look at type erasure in the body of the function, which frankly isn't that interesting, versus whether the type continues to propagate outwards. The type propagating outwards is a major concern because there are a lot of limitations associated with heterogeneous types, e.g. a function that reads a user config file and returns something always has to return the same type. So generally, at some point, in some sense, if your program deals with data it only receives at run time, it has to eventually erase types.
Ooh thanks.
If i recall correctly, &lt;regex&gt; was not fully available until VS 2015 under Windows. This might be an explanation for its unpopularity.
Isn't it a reference implementation: http://en.cppreference.com/w/cpp/error/make_exception_ptr Also, strange to expect exception machinery to work with the exceptions disabled. It's really easy to step into the UB territory.
Conan?
vcpkg, Conan, apt, brew. I'm not saying it is as easy as it should be, but the situation has dramatically improved over the last couple of years. And integrating a simple 2D graphics library into your project is really not that difficult.
i don't get that argument. changing UB into defined behavior is surely not a breaking change. 
`path_view` seems to indicate that it is a view into a UTF-8 string. Does this prevent working with paths where the name can be any arbitrary sequence of non-zero bytes? (eg. on Linux)
[Works for me pretty well](https://ideone.com/ynv3ww)
It's been in MSVC since 2008 SP1, implementation-wise.
Yea, everything has to be in the header :( Still, a good compromise would be void sama(std::optional&lt;char*&gt; output) tells you in the interface of the call that the parameter is optional. 
Not exactly. It *presents* a UTF-8 string. It can be any representation underneath, the reference implementation supports UTF-16 and UTF-8, but easily could support more. And yes, arbitrary binary data works just fine, if you match up what your syscalls take with the view's source. It just passes through, untouched, the source.
Implementing `make_exception_ptr` using `throw` and `catch` is a very inefficient way of implementation. That's the cause of my surprise, one would have thought they'd just skip the `throw` and `catch` and make the exception ptr directly.
Well, even libstdc++ does that in some conditions: https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/libsupc%2B%2B/exception_ptr.h#L192 and behaved like libc++ version until gcc-7: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=68297 Probably the only reason it's not optimized the same way in libc++ is because no one bothered to create an appropriate issue (at least I haven't found any). Though this suggests that trying to use this emthod with disabled exceptions might indeed be UB: https://github.com/llvm-mirror/libcxx/blob/master/include/exception#L180 .
Since C++11 you can use `char32_t`, which is guaranteed to be UTF-32 across platforms.
Ah, you're one of those people ;)
Header occurrences look pretty zipfian. There is a VSauce video on this https://www.youtube.com/watch?v=fCn8zs912OE
Is borrowing a standard term in C++? I've only ever really heard it in context of its Rust meaning, which doesn't involve taking ownership.
&gt; One could write a book how to get Skia to compile across all major desktop and mobile OSes. I'm just pointing out as someone who has experience with this library. What you are saying is not factual. Installing python 2.7 and cloning depot_tools is a trivial tasks. In fact, we looked into using QT for imaging, but Skia was way simpler to integrate to our build. &gt; Integrate with each compiler and platform SDK being used This is another non-factual statement. There's nothing extraordinary about Skia when compared with any other library that only support MSVC, GCC, and Clang. I gather by all your comments that what you're saying is all from hearsay, and you have no personal experience building/using Skia.
Mind to elaborate?
Ah, not what I had in mind, but that's interesting to know. Thanks.
Xaxxon, since you asked nicely I'll make an effort to accommodate. But just to be clear, you'd like to have a conference, to which you don't attend or give financial support, produce quality content, for which you don't pay, and make announcements for this content in reddit for your convenience, but you are annoyed that the volunteer doing it does it in such a way that you occasionally see "marketing."
No the conference could not exist and I’d be fine with that too. I just don’t want to be clickbaited into ads for it which is all this link is. 
It doesn’t have to be out of scope; we can work with WG14 to make changes when appropriate. There is, of course, a high bar to changing functions that have significant history. In cases like these, newer more modern interfaces are likely better for the long term as they can incorporate actual Unicode semantics. 
So you want to watch the videos from the conference but announcing who the keynote speaker is and what the subject will be is "marketing spam"? Amazing.
Unfortunately, it is not true that char32_t is guaranteed to be UTF-32. The standard does state that u8 string literals are encoded as UTF-8, but it does not state likewise for char16_t and char32_t string literals. This is also the case for the C standard. Some standard library interfaces do require UTF-16 and UTF-32 in conjunction with char16_t and char32_t, but this isn’t universal. I hope we’ll be able to clean this up in C++20 (and C2x). 
It passed LEWG and EWG and was reviewed in CWG. CWG asked for some minor wording tweaks and an updated paper was submitted for the post-Jacksonville mailing. CWG also requested following up with WG14 to add char8_t to C and a paper has been submitted for Brno (http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2231.htm). LWG didn’t have time to review in Jacksonville. I hope we’ll wrap up char8_t in Rapperswil. 
It'll be nice to have another reference to point towards regarding UB and how important (and equally dangerous) it is to the language. For those who want a refresher, some earlier talks on a similar note I have bookmarked are: * [Chandler Carruth's “Garbage In, Garbage Out: Arguing about Undefined Behavior..."](https://youtu.be/yG1OZ69H_-o), and * [Michael Spencer's “My Little Optimizer: Undefined Behavior is Magic"](https://youtu.be/g7entxbQOCc) &gt; C++ occupies a tricky design point: on one hand, it wants to be able to assume that a pointer originating in one block of memory cannot be used to refer to another block, but on the other hand any pointer can be turned into an integer, manipulated arbitrarily, and then turned back into a pointer. He will guide us through the implications of these conflicting demands, some of which are still being figured out. This is really exciting though. `reinterpret_cast`s, strict aliasing, and relevant have been topics I've been wanting a good talk to refer to when I need a reminder of what is valid and/or why things are the way they are. I have high hopes this keynote will clear a lot of things up regarding this subject.
I would have absolutely no problem with it if it said "C++Now announces keynote: whatever" "marketing spam" wasn't the exact term I should have said. "clickbait" is what I have a problem with. 
I stumbled on this thread via a google search. If my input may help, I would like to add that I have used thrust in multiple projects for clients. It has allowed me to write accelerated code faster and in a much safer way. You can do some really interesting things with all the iterator types. Memory management is cleaner. Its a pretty useful library in my opinion.
Thanks for the clarification!
I think the reasons why C++ won't get a standardized 2D GUI / drawing framework are simple: - The graphics world moves too fast, what seems like state-of-the-art technique now is outdated once the API is implemented. Today, cairo is the new, hot library in town. Tomorrow, everyone wants a QT-like API. - They tried to cram everything in the standard library. This is a problem because neither can the community help out or contribute (like with a regular library) without going through comittees first, nor is it easy to seperate the concerns of the seperate distinct parts of the cairo-clone from each other. The most pressing problem is that there is no community involvement, because there is no easy way to contribute to this hypothetical framework, without writing papers first. The reason for that is that there is no seperation of concerns, everything has to be in one, giant library, instead of many smaller ones. The standard commitee just does something and the C++ community has to live with the result for the next 10 years. And I think the reason that they do it is because C++ has no standardized package manager. As an example, I just wanted to show what Rust does - it promotes creating loads of smaller libraries, which can be exchanged quickly if a better alternative pops up. This is how a GUI framework would look like, from an architectural point of view: some GUI framework: link it all together └ glium: wrapper for winit + glutin └ winit: open a window, handle input └ glutin: OpenGL RAII wrapper └ cassowary: do 2D layout └ harfbuzz: shape text └ rusttype: decode font files, read font metrics └ image: decode / encode images, do image processing └ webrender: do draw-call batching └ pathfinder: render text (using lyon) └ lyon: partition svg-like shapes into triangles for the GPU All of these libraries can be: - worked on seperately = more contributors in total than if this was one library - not optimized for a single use-case = versatile APIs (ex. `image` can do more than just load image files, but for GUI frameworks this functionality is not as important as for an image processing toolkit) - debugged seperately, instead of having to debug one giant library, one library doesn't know about the other - parts can be easily exchanged / upgraded if something better pops up This is why I viewed the 2D graphics proposal as a fail, right from the start. Instead of solving the problem: "How do we get more people with actual experience in the 2D graphics field involved?", they just tried to create something and then wonder why nobody wants it. The first step towards such a framework would be to standardize one package manager or come up with a protocol of how different implementations of package managers can talk to each other. Because without that there will be never an ecosystem of small libraries, there will always be some monster-libraries (like QT, for example) which give you everything-and-the-kitchen-sink. Those libraries are hard to replace. If they fail or get abandoned, they fail big (see: XNA). TLDR: standardizing 2D graphics without standardizing dependency management first is not going to happen.
thank you :)
I'm pretty sure the unpopularity is due to the correctness/performance issues implementations have had. GCC also didn't implement it until something like 4.9.
&gt; . The number of papers could be reduced if the topics were publicly discussed and consensus found before the meetings. I believe they may be some idiotic anti trust laws against this, I remember Herb mentioning this 5+ years ago when trying to recruit people to join ISO.
They never reply.
&gt;Most standard library implementations won't shoot you in the foot if you write this code MSVC does a table lookup, and will happily crash your application if you pass a character that's not in the acceptable range (although I haven't checked in MSVC2017). As for the rest: 1. It saves a single cast (to unsigned char) inside `isalnum()`. Of course it's not much of a saving, since now you need that same construct outside every invocation of `isalnum()` if you want to avoid UB... 2. Why, that means the all-important EOF-marker cannot be processed properly, of course. I'm not actually sure that it matters: I believe all the `isxxx()` functions, as well as `tolower` and `toupper`, do the same thing for EOF (i.e. -1) and its value when cast to unsigned char (i.e. 255) anyway. 3. No. I asked before. Apparently the performance loss of doing a single cast is considered unaceptable in a high-performance language like C++, taking away any kind of UB is beyond discussion because of its status as the Holy Bringer of Compiler Optimisations, and it's something brought in from a different standard (the C-standard). Apparently adding a footnote to the C++ standard is impossible. So is talking to the C standard committee. I suppose I could talk to the C standards committee myself. Given a choice of spending years of my life doing that, or just banning those functions from any software I'm in charge of and calling it a day, I chose the latter. Anyway, I think you're right: the way these functions are defined is unacceptable and unprofessional. They are the source of a great many bugs, since not many programmers are even aware of the problem. What's the most obvious place where you would call one of them? Why, when you are dealing with user input, of course! Which means that you end up with a set of dangerous functions, carefully positioned to allow attackers to craft input that will break programs in all sorts of interesting ways. I cannot imagine why they haven't been cleaned up a long time ago, especially since all it takes to fix them is a single cast. 
If only we had a way of communicating with the people responsible for the C standard. It's not like they don't have the exact same problem anyway... 
If your file contains any character in the range 128-255, then that call to `isalnum` is most certainly UB, and moreover, it _will_ crash MSVC, at least. 
Can someone post a link to code here that demonstrates this? I went to cppreference and copied their example and it didn't compile.
had the same problem, first zlib, then boost...
You might want to look at [hcc](https://github.com/RadeonOpenCompute/hcc/wiki) by AMD which is a fork of Clang for GPU stuff
Nice, I got used to calling functions with out of order parameters using arg_name=arg_val in python. While it's not exactly the same (i.e. the order still has to be preserved here), at least it is much more readable and it won't compile if you got the wrong order. The next step in making it more productive would be to have IDEs autocomplete the argument type as you type the arguments into the functions. I hope that when opaque typedef makes it into the standard, this is what we'll get from IDEs.
Yeah, I was just trying to come up with something quick as sometimes its easier to see rather than read :) Appreciate the links. I haven't heard of SYCL, looks interesting! 
Very cool, thanks for the link!
I think something like your `std::device` will come with executors (probably C++20). But I think it will be a much longer wait until executors support GPUs, and it will be an even longer wait until libraries like Eigen will support these std-Executors. Eigen has been adding some C++11 code with #ifdef's but it is large still stuck in the last century with keeping C++98 compliance... (PS: I know you only gave it as an example but using `&lt;&lt;` to build the "math" is pretty bad. This has to be `c = a + b;`.)
The reality was much worse. libstdc++ 4.8 let you include the header and compile code using regexes, but at runtime always returned placeholder values, e.g. true for matches.
The OpenMP4(.5) standard supports off-loading to devices. Compiler support is getting there. If you have access to a Cray machine and compiler, they definitely support it and it works wonderfully (not associated with Cray, just took a course in which they co-participated) IBM is working on the implementation in Clang/LLVM. This can be found in the following github: https://github.com/clang-ykt I've not been able to get it to work, but that's probably my fault. If I am reading the Openmp-dev mailing list correctly, progress is going well and hopefully it should be standard soon. Intel supports off-loading to the Xeon Phi, I don't think they will support GPUs anytime soon... For gcc I have conflicting information. Their own wiki page ( https://gcc.gnu.org/wiki/Offloading ) says that they don't support off-loading to GPUs yet, but apparently support is available since gcc/g++ 7.1. Just like in the Clang case, I was unable to get it to work. I built the adjusted compiler but no off-loading happened :/ Nvidia's own pgi compiler doesn't support it yet, but I think that will change shortly. Would be a great feature to increase that compilers usage in the HPC communities, as supercomputers become more and more hybrid! If anybody was able to get any of these compilers to work properly, please let me know! I really want to test them out myself :)
There are many problems to an interface like this (or any interface you would come up with). Generally, GPUs have multiple submission queues. There are also multiple memory types (device local, host local, coherent/not). Memory may need to be guarded by read/write barriers while transfers are occurring. Not to mention that all this must be synchronized with host code. Selecting memory types and all that is also subject to alignment requirements which are different for the various types of buffers that may be made available to the GPU. I think C++ is better off interoperating with existing standards/libraries for compute which have already figured out some of these abstractions. Streams in particular are not the way to go, since how memory is made visible to the GPU needs to be sequenced carefully. As for the command submission, I suppose you could have some sort of dynamic bytecode generation for the command stream you want to execute but this is vastly inferior to just writing a compute shader except for the examples so trivial as to be not very useful. Optimizing commands is also nontrivial and compiler implementers would need to know how/when to unroll loops, consider the GPU occupancy model (definitely not the same as the CPU occupancy model) etc. At the end of the day, a lot of the issues are cultural (in a technical sense). The compiler was written for the CPU, and it does a very good job at it. But there are many concepts for the GPU that do not map well, and based on your example as well, naive implementations will result in developers shooting themselves in the foot more often than not. Learning abstractions from things like CUDA, DirectCompute, Vulkan, etc is a good starting point, and it's hard to find a compromise of the features they provide that would mesh well with C++ (short of just integrating with those existing solutions).
I want #include &lt;game&gt; auto myGame = std::make_game&lt;std::FPS&gt;(); myGame.run(); 
This makes me incredibly happy
Care to elaborate a little (if you're not being sarcastic)?
[removed]
Strong typedefs are not that simple though: Does this work `w + 4`? This `w + w`? If you answer "yes", what about: using distinct Id = int; Id a, b; Id c = a + b; Does that make sense? You need a way to easily specify which operations should be exposed and which not.
Would be nice if we had typeclasses that a distinct type can selectively inherit
[removed]
If we only had metaclasses ... all we need would be a ValueClass and we could get all the operators for free... Only 8-11 more years to wait xD 
Unfortunately it is not supported by VS2010, so I had to rollback changes.
With C++0x concepts this was actually the case. They were like interfaces and you specified signatures, not the expression based complication we actually get. And there were concept maps to implement concepts for types that didn't have the required functions, strong typedef could easily generate those. Sadly that ship has sailed.
Wow... that's really great.
Check out the function 'std::nth_element'.
Have you considered to use std::nth_element ?
Well you could just store some aligned memory and static assert it is big/aligned enough. I believe function pointers need to be pod; they just don't have to be void pointer compatible. And a static assert failure is a reasonable failure mode for platforms with super large or otherwise strange function pointers?
I must say that this article is surprisingly insightful. I'm not a big fan of this blog, but this article offers a good to workaround the lack of strong-typedefs/named-args that looks simple and elegant.
Oh, and the Kokkos library (github.com/kokkos) tries to make life a bit easier. It allows you to allocate stuff on the GPU at compile time. Either through a hard coded template parameter or a configuration option. The nice part is that they use template metaprogramming to change the data layout depending on the target architecture. So coalescing when on the GPU, and 'normal' on the CPU (I forgot the proper word). They also give you some standard algorithms that work in parallel: parallel_for/scan/reduce. It's far for perfect, but for some quick prototyping it's quite nice, as some of the hard work is already done for you.
Khronos already has such a standard, it's called SYCL. Unfortunately, there's only experimental implementation of SYCL exists today. I think as long as Nvidia is dominating the GPU industry, we won't be seeing any such standard being widely implemented. Look at their implementation of OpenCL, it's update is progressing at a snail's pace, because OpenCL is in direct competition with their own product (CUDA).
The first "error" is #define SIZE 7 Learn C++, then start blogging about it.
Yes, this seems like something natural to write once you have prototype based reflection (which your library hacks into being with stateful template metaprogramming). A less hacky metaclass based one will be lovely.
Will be CUDA locked?
Will be CUDA locked?
The indexing in the odd case is actually correct, but the code is missing the size == 0 case.
He already said to much, I doubt will will elaborate, I am really excited to hear that also to be honest, I would love to see such level of integration in C++.
Top. People.
It's NVIDIA, as much as I love their GPUs and CUDA but when it comes to industry standards, they don't like any competition with their own products. Look at their implementation of OpenCL. They've just began upgrading to OpenCL 2.0 and the current standard is 2.2.
This is a very complicated discussion. OpenGL/OpenCL is outdated by design in my opinion for current times, for a complete graphics library we should redesign everything from ground, and remove all old stuff, including nostalgia and memories from old times. All this madness with DirectX/OpenGL/OpenCL/CUDA/etc is really getting way to connected to profits, and I do not like it. 
Similar to [this](http://en.cppreference.com/w/Special:PopularPages)
std::optional has more uses than "optional return". For instance having a struct that can have or not some members values, now you can use a std::optional instead of a nullable pointer for instance. Other use is for optional parameters like /u/raevnos mentioned.
TOP MEN Dr Jones!
Sorting is O(n log(n)) while selection (and thus median) is O(n).
Is it possible to extend ELF/DWARF (I'm not really familiar with them so this might be a dumb question...) so that compilers can emit a hash of the ABI for shared objects - which can be then used by the build systems? This seems like the cleanest solution... And it could be off by default if it takes some extra time... Currently all these steps seem like unnecessary overhead... A fascinating read though!
That's great news, and to be honest I'm quite surprised that it made it through at all, let alone with such speed -- I seem to recall there was a previous proposal for `char8_t` that didn't get anywhere, so I didn't hold out much hope for this one. Congratulations!
These are great news! Thanks for your work.
I’ve been out of the gpgpu game for a year and left my previous company looking into OpenVX. Is that still a thing? I know intel has stuff available for developers to use it for their CPUs. It seems pretty cool how you could just toss in image processing modules and openvx handles all of the scheduling and stuff for you. 
Probably not, as in C++20 concepts you only say "`foo(t)` must be well-formed and return something convertible to an `int`" and not "`int foo(const T&amp;)` must exist" as with C++0x. The C++20 version is more flexible but makes something like strong typedefs harder.
&gt; No error handling. Everything returns void and just logs error if something happens. That's cool.
Note that Codeplay people are actively participating to SG14 and proposals targeting heterogeneous computing (aka compile once, generate code for the whole machine)
Why do you want implicit conversion to and from the underlying type?
I agree, there should be *at least* warnings if someone does something risky for the optimizer or writes something unclear that the compiler writers have problems what to do with it. Given the length of your post, do you know any "promises" we might submit in the code that let the compiler do crazy optimizations? What an example promise would be - something like `[[never_zero]] int x;` or `[[always_unique]] void* p;`?
C is clear that `u` and `U` string literals are not necessarily Unicode; the `__STDC_UTF_16__` and `__STDC_UTF_32__` predefined macros indicate whether they are UTF-16 and UTF-32 respectively or whether they are ... something else. In specifying `char16_t` and `char32_t` string literals, the C++ standard uses Unicode terminology and limits, including mentioning surrogate pairs, but stops short of actually specifying an encoding. Presumably because of the relationship to C. We have a pretty good mess to clean up here. - http://eel.is/c++draft/lex.string It doesn't help that the C++ normative references to ISO/IEC 10646 still cite the 1993 revision. UTF-16 didn't even exist then! - http://eel.is/c++draft/intro.refs#1.7
Pretty much everyone was surprised. But it isn't done yet. I don't expect any significant trouble getting wording through CWG and LWG, but there is always the opportunity for objections when actually voting it into C++20 given that this does affect backward compatibility. Any decisions made by WG14 for C could weigh in as well. So, we'll see what happens. There is still work to be done to better qualify the impact to backward compatibility.
Something I'd like to be able to do is write code once, have it compile my functions with parameters done this way in debug mode in separate translation units with reasonably fast incremental builds, and then do a NDEBUG unity build where this approach isn't used at all but rather they're function templates (or equivalent, auto param or what have you). It's a lot to ask, and I fear if I try to pull off something like that myself I'll screw something up somewhere and introduce a gotcha I don't catch until it's too late.
Yeah..."top" people.
Yup it was late when I was looking at it haha. The two-element average is definitely wrong though.
Does c++ std have matrix??
The problem is that even defining what "risky" means is hard, given how the standard is worded. I mean, I've no problem admitting that, technically from the standard point of view, in the cases I had in mind, user's code is in the "wrong", and the compiler is in the "right", in the sense that the compiler is conforming, while the user's code is not. That makes emitting warnings particularly difficult because it could have too many of both false positives and false negatives. For that reason I think the standard should move quickly to allow for *less* undefined behaviors, targeting places where implementers are confident they will be able to conform, either because they actually implement it in some not-undefined way for now, or because they are confident they can reliably remove some without too much effort, too much risks, and too much perf regression. I'd like to have the standard concentrate in priority on major implementations, and not be vetoed by obscure ones. It is not a fatal issue if binaries are less optimized for obscure or obsolete implementations... On the top of my mind I can't think right now of any *new* declarative promise that would fit our discussion. If some come, I'll try to come back and note them. I'd have preferred that alias analysis be available in more targeted ways, but that is not what is in existing compilers, so maybe that ship has sunk (or maybe it would be better to have that one as a mere extension). But there are classic ones that do exist and are in uses in various implementations, like \_\_attribute\_\_((malloc)) (maybe somehow related to what you have in mind with \[\[always_unique\]\], although "restrict" might be related too) I'd be delighted if in the future, when implementers spot an interesting (according to them) optim allowed by an UB, they start their thinking by concentrating on the risk this implies on existing codebase, and maybe in some cases even move in the direction of removing that UB entirely from the standard and proposing explicit attributes instead. Because frankly, we even recently can observe quite the opposite: people discussing about how it would be great to maybe eventually not have char be a universal alias... wtf? Oh yeah, that would be a good candidate: if you really need that, that would be on specific spots, so \[\[dont_alias\]\] char foobar; would be interesting. Hm I'm back to wanting it for other types, then :) 
in summary: a bunch of awful hacks that were never intended to be used for it.
If it breaks performance, it can be considered a breaking change. I can imagine some implementations using the character value as an array index. If it breaks toolability, it can be considered a breaking change. There are heated discussions on toolability and changing UB -&gt; well defined behavior going on in wg21 right now. Some tools take advantage of the leeway that UB gives in order to allow for diagnostics to be printed in conforming code. If you make things well defined, you can't put a diagnostic in a place that could be intentional behavior (at least not while still conforming).
Indeed! I really hope we have proper tools in the future. We need concepts instead of abusing sfinae, and the reflection TS + function reflection is a great step forward. Edit: I would like to say however that even though they are hacks, I couldn't imagine removing all sfinae and all template deduction on function parameter from my code. If isolated, I could imagine myself removing tons of boilerplate by using "real" reflection instead.
Your code example doesn't really grapple with the fundamental challenge of targeting GPUs and similar processors. It's not a matter of designing the right library for targeting a GPU (though people are working on that, which Bryce hints at). The fundamental challenge is how to represent and manage heterogeneity: the fact that such a system contains multiple devices with different architectures and instruction sets. Standard C++ has no notion of anything like that. Moreover, there are ergonomic concerns. In practice, environments like CUDA C++ require the programmer to manually annotate their functions to indicate those to compile via a host compiler for execution on a CPU, and those to compile via a separate device compiler for execution on a GPU. The requirement for explicit annotation disqualifies the huge body of existing standard C++ programs from GPU execution. Once these annotations are introduced, they tend to proliferate by "virally infecting" the rest of the program's functions. As far as I know, no one has demonstrated a practical solution for managing the cooperation of multiple compilers to produce a single program, or a solution to the viral annotation issue.
&gt; that C++ is not adapting to support on the language level GPU programming. I don't understand. Both OpenCL and CUDA are basically C++.
I wish all the GPU manufacturers would collaborate on a standard here... Nvidia always seems too concerned with locking people to its specific hardware. Heterogeneous computing is the future. One day you will be able to configure a compiler for unique heterogeneous systems and it will generate code optimized for all processing elements available. This is not limited to just CPUs and GPUs but also highly customized external processing units such as custom FPGAs or even unique processor peripherals such a encryption engines. 
See also: https://www.reddit.com/r/cpp/comments/89h7r6/library_to_manipulate_structures_like_tuples_for/ This library works by providing all the overloads for structures (aggregates) up to 50 parameters xD Yeah some language support in this direction would be nice, but with your syntax x doesn't really look like a name of a tuple.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8abwp2/c_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Top... people, Dr Jones. We are both [designing GPUs to run C++](https://youtu.be/86seb-iZCnI) and [designing C++ to run on GPUs](https://wg21.link/p0761). We've already laid the groundwork by [adding facilities for expressing parallelism in C++](https://youtu.be/Vck6kzWjY88). Running C++ on GPUs is a problem that is mostly solved today. The challenge is in the interactions between C++ running on a CPU and C++ running on a GPU.
The preprocessor approach suggested here is really rough. You can do far better by combining a tiny bit of preprocessor, with a mostly CRTP approach. This retains all the advantages of the CRTP approach, and fixes the call stack, with minimal use of the preprocessor. Start by writing your NamedType template class with the usual CRTP plan, but don't bother make it variadic in the policies: template &lt;class UnderlyingType, class &lt;class&gt; PolicyType&gt; struct NamedType : PolicyType&lt;NamedType&gt; { ... }; Now, the plan is this: write a macro `STRONG_TYPEDEF(name, underlier, ...)`, which expands STRONG_TYPEDEF(Width, int, Addable, Subtractable) Into this: template &lt;class T&gt; struct WidthPolicy : Addable&lt;T&gt;, Subtractable &lt;T&gt; {}; using Width = NamedType&lt;int, WidthPolicy&gt;; Because WidthPolicy is an actual type and not an alias, it will not get expanded in errors, backtraces, etc. That means that no matter how many policies you give Width, the backtrace will not get any longer. It may seem like with this approach you could make `Width` itself a fresh class definition instead of an alias, however unfortunately in order to define things like `std::hash` in particular you really want all of your strong types to instantiations of the same class template because partial template specialization is the only way you can define a Hashable policy. Anyhow, I've had my own strong type implementation where I work for a while and read many of these articles, and this is still the best approach I've seen, though I'd be open to seeing a better approach or a drawback to the current one I'm missing. As to the implementation of `STRONG_TYPEDEF`, using boost PP the implementation is really trivial: #define STRONG_TYPEDEF_INHERITOR_TRANSFORM(r, _, CLASS) CLASS&lt;T&gt; #define STRONG_TYPEDEF_INHERITORS(SEQ) \ BOOST_PP_SEQ_ENUM(BOOST_PP_SEQ_TRANSFORM(STRONG_TYPEDEF_INHERITOR_TRANSFORM, , SEQ)) #define STRONG_TYPEDEF(NAME, UNDERLYING_TYPE, ...) \ template &lt;class T&gt; \ struct NAME##Policy : STRONG_TYPEDEF_INHERITORS(BOOST_PP_VARIADIC_TO_SEQ(__VA_ARGS__)) \ { \ }; \ using NAME = NamedType&lt;UNDERLYING_TYPE, NAME##Policy&gt;; Edit: as a bonus, not having variadics in the NamedType class actually simplifies some code, especially the implementation of the Hashable policy.
&gt; Will be CUDA locked? This sentence isn't coherent, care to clarify?
&gt; I'm not sure if CUDA has a similar single-source C++ interface. Of course it does! That's the whole idea of CUDA.
Will (whatever you're working on) be cuda exclusive
What about `[[pure]]`? I heard compilers can optimize a lot calls out if they know that the function has no side effects. And this is not risky
I'm talking about what the C++ standards committee is working on, which is the subject of this thread. This is r/cpp not r/cuda.
Found it. It's cheeky. You need to open the property pages of a c++ project **which has a .cpp file in it**. Then it's under Configuration Properties -&gt; C/C++ -&gt; Language. [ms docs](https://docs.microsoft.com/en-us/cpp/build/reference/permissive-standards-conformance#to-set-this-compiler-option-in-the-visual-studio-development-environment)
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8ac082/how_to_disable_permissive_option/dwxgp1i/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Thanks!!! I'm still having compilation issues. I get error: error C4596: '{ctor}': illegal qualified name in member declaration (compiling source file .. in multiple areas of my code even with the /permissive version off. When I was originally creating this project, I was doing it all through version control. I recently copied the project onto my Desktop and I am running it off of there instead of version control now instead -- could this be related to the error in any way? Any advice would be helpful! Edit: oops: switching this to the cpp_questions
I'm not op, just translating... but cool Edit: Also, NVIDIA is the first word in your flare... its not inappropriate for someone to think you may be referring to a specific NVIDIA project
I agree, doesn't that defeat the purpose?
[instant_quality](https://github.com/IsCoolEntertainment/iscool-core/blob/master/modules/core/monitoring/module/include/iscool/monitoring/instant_quality.h), I like that! Just add some water et voilà!
Yes you can always simulate variadics. This was done in the pre-C++11 implementation of tuple. I have horrible memories of simulating variadics with macros. x is not a tuple, but a parameter pack. It can easily be turned into a tuple of lvalue references via std::tie(x...), or a tuple of values with std::make_tuple(x...).
Reflection in C++ comming in C++ 38
We will be old men by that time.
Or C++ will be mostly irrelevant by then...
That is if World War 3 doesn't wipe every last one of us from this planet.
I'm working on an on-line code generator that [automates the creation of serialization functions.](https://github.com/Ebenezer-group/onwards) 
C has its own rules, not really relevant here. C++ specifies the encoding for character literals. &gt; A character literal that begins with the letter U, such as U’y’, is a character literal of type char32_t. The value of a char32_t character literal containing a single c-char is equal to its ISO 10646 code point value. That's as good as UTF-32. Encoding for string literals must be consistent with that of character literals, or else all hell breaks lose. The omission of encoding from the string literals section is either an oversight, or the standard simply assumes it is implied by the character literal encoding. UTF-16 can go away and die as far as I'm concerned, but the standard speaks about surrogate pairs in the string literal section, which indicates that the intent is to specify UTF-16. If it's not UTF-16, it's at least UCS-2, for the same reason as above. 
**Company: [AutoX](https://www.autox.ai/jobs)** **Type:** [Full Time] **Description:** AutoX’s disruptive camera-first AI brings self-driving cars out of the lab and into the real world. We believe that autonomous driving should not be a luxury, and we are making it universally available to everyone. We needs great C++ coders to help put all advanced algorithms into real practice for our **autonomous driving platform**; develop scalable frameworks to support many types of vehicles and configurations; design efficient components and optimize existing software for limited compute platforms; collaborate with other engineers to implement, integrate, and deploy **robotic perception, mapping, localization, and sensor calibration software**... **Location:** San Jose, California, USA **Remote:** NO **Visa Sponsorship:** YES we sponsor or transfer **Technologies:** C++ * For system&amp;tools: Operating Systems, Databases, Concurrency, Linux Kernel, Compilers, Distributed Systems * For perception: algorithms, data structures and math in general * For mapping: mapping experiences * Robotics **Contact:** Apply through our job page or email me at **fyang@autox.ai**
&gt; The software is under the BSD 2-clause license. &gt; An account is needed to use the CMW. I'm a bit confused. &gt; the Visual Studio version is "makefile.vs". If you're using a Microsoft compiler, you may want to rename makefile.vs to makefile. These seem like ancient practices. Makefiles? Makefiles on Windows? Renaming files to build...? I strongly suggest you to use CMake for proper cross-platform builds. Your readme would really benefit from an example. And the fact that you're not using Markdown doesn't help the readability at all. But I think it might be something like Qt's moc?
I'm not keen on CMake, but will add project files, or whatever they are called, if someone would like that. I primarily use BSD/Linux. My best example code is here: https://github.com/Ebenezer-group/onwards/tree/master/tiers There's also an example directory. The former is more realistic. The latter is more contrived. I think it's similar to Qt moc, but haven't used that. 
With c++20 metaclasses you’ll be able to do using Width = $double.as_new_type();
&gt; C is relevant Interfaces yes, source-level compatibility not necessarily. Why should C++ programmers be concerned with how C *literals* behave? Literals are source level constructs. The only reason this can be relevant is when mixed C/C++ headers are used, but I don't see too many C headers with string literals in them, especially Unicode ones. User-facing strings should in most cases be loaded from message files anyway. 
Do it perfect or don't do it at all. 
Hey... :) About the directory structure, I do agree. It looks bloated at first, but you quickly realize it's very well organized. The code looks really clean too ! Sounds promising.
I've actually started writing a paper but it is very much in its infancy. PM me if you're interested in collaborating. I think it might be possible to have something like this in C++23 or so.
&gt; All this madness with DirectX/OpenGL/OpenCL/CUDA/etc is really getting way to connected to profits, and I do not like it. This is why I'm really cheering Vulkan on.
I called it dead right after the announcement of SG13. I will keep pressing on the fact that this just doesn't belong in the standard, given how complicated and nuanced it is to mess with it from the beginning.
Compiler warnings alert you to the latter.
They do? https://godbolt.org/g/gMwJKx
&gt; So "const T&amp;" it is WTF are you talking about? Did you read the article? It is about FUNCTION DECLARATIONS (Not parameters, FUNCTIONS) int f(); vs auto f() -&gt; int;
You forgot the `[[nodiscard]]`.
That doesn't solve anything. Now I need to check in code-reviews whether or not you forgot the [[nodiscard]].
It solves potential problems at every callsite at the expense of writing one keyword in the declaration. My code is getting reviewed either way, so needing a review is not a "problem".
For one, it has significant issues with seeding RNGs that take a large state, like the Mersenne Twister that everybody uses. /u/profoneill wrote a bunch of on the topic a few years ago. [Here's one](http://www.pcg-random.org/posts/cpp-seeding-surprises.html)
To be clear, "significant issues" means seeding takes 3-4 lines instead of 1 – not ideal, but hardly broken IMO.
This doesn't make any sense. It's not like you just blindly apply [[nodiscard]] to every function that returns a value. Sometimes you do not care. So now the reviewers have to do extra work to determine if your function lacks the needed attribute or has extra attribute it shouldn't have. Needing a review is not a problem, but needing to do extra work to complete your review is a problem. 
You can get 20k random bits fed to the standard MT class in 3-4 lines of code? When random_device can return nothing but 42 if it so desires? And then deal with it only being a mediocre generator? Probably works well enough for most people, but if you need high quality random bits... 
Yes, `std::generate_n` is a thing. ;-]
Your hypothetical functional style sort function (I'm really sceptical about writing something like this in c++ - at the very least I'd give it another name like sorted_copy) would be the prone candidate for a `[[no discard]]` as it doesn't have any side effects and it doesn't make any sense to call it, but not use it's return type.
Where do you get the random seed bits from?
What doesn't make sense is having a language utility that solves your overarching issue and considering the fact that you have to type its name a problem. If you're writing a function that has no purpose except to produce output from the input you give it, and you _don't_ use `[[nodiscard]]`, you're writing a bad API. &gt; Sometimes you do not care. This time you do, obviously, or we wouldn't be having this conversation. &gt; needing to do extra work to complete your review is a problem Writing one keyword to avoid misuse of the API is writing the API _correctly_; reviewing code to make sure it's written correctly is the entire point of reviewing code. By your logic, having to review code in a code review is a problem. Not using the tools at hand is stupid. This argument is stupid.
Why do I waste my wit on you peasants.
This functional style is the style I prefer. When by convention I pass in everything by value/const ref and everything comes out via return value there is absolutely no confusion about whether or not the parameters are being modified by the callee. Today I debugged a problem for about 6 hours and I had to step in and out of about 50 different functions because the possibility of in-out parameters means that I can't be sure that the callee isn't modifying the data from the perspective of the caller.
&gt; By your logic, having to review code in a code review is a problem. You are completely misrepresenting my argument again. It's EXTRA work. Doing extra work is stupid. This argument is stupid. 
The thing is: You always have the possibility of input-output parameters in c++. So as long as you don't have a hard rule against them in your code, you have this ambiguity anyway (and even then, you have to deal with library functions that use them). And while c++ may support functional style programming to some degree, the much more common style is to work with mutable state, so that is what you have to assume anyway (where it makes sense). That is why my naming style explicitly calls out when I make a copy of a container and not, when I mutate it in place (think about the standard algorithms - and especially their ranges-TS versions - that do exactly the same). Btw.: why do you have to step in and out of functions to determine their signature?
Oh; your point is that `random_device` is underspecified? Well I certainly can't argue there... I haven't had it be an issue in practice, but then I stick to the big-three stdlibs. As to `seed_seq` meddling with input, it's at least well-specified, and again I haven't had that be an issue in practice. With regards to `random_device` in particular, AFAIK the only time it _can_ be an issue is if `unsigned int` &gt; 32 bits. I don't think &lt;random&gt; is ideal by any means, but I do think many of its problems are only theoretical for most people.
Anyone know if the current reflection proposal(s?) allow for reflection on custom attributes on things like data members? That way you could tag stuff inline in your class definition for something to make a decision on later? 
&gt; The thing is: You always have the possibility of input-output parameters in c++. So as long as you don't have **a hard rule** against them in your code, you have this ambiguity anyway (and even then, you have to deal with library functions that use them). A hard rule you say? That is why have guidelines and coding standards/conventions. The whole point of the article is that even when you have need for some "in-out" type parameters, most of the time you dont need to pass them in by non-const-reference. You can pass them in via const-ref/value and then return them by value... this is pretty cheap given that we now have move-semantics. When even those moves are too expensive, then I agree that passing in by reference, but that should be a **last** resort. The code can be understood more easily when you can tell at the caller whether or not the callee is modifying your data. &gt; the much more common style is to work with mutable state, so that is what you have to assume anyway (where it makes sense). I don't find this to be true. To be sort of generic here, my work mostly involves a lot of calculations (pass stuff around via const-ref) and then at some point you decide to mutate state. Most of our code is const-correct and we banned const_cast (except when interfacing with external libraries) so once you go into a function that has taken data by const-ref you can always assume that nothing in that function (or it's callees) can modify that data. &gt; That is why my naming style explicitly calls out when I make a copy of a container and not, when I mutate it in place (think about the standard algorithms - and especially their ranges-TS versions - that do exactly the same). That's great when you are working by yourself, but in my experience is is hard to get a good consensus on what is a "good" name once you get 3+ people working together and not everyone will understand each other. Everyone will always interpret things differently. &gt; Btw.: why do you have to step in and out of functions to determine their signature? Following the debugger is probably the fastest way to determine whether or not a callee is taking your parameter by value/ref/const-ref/r-value among other things? How else do you propose to efficiently understand how a complicated algorithm is using your data? 
You AGAIN miss the point of the article. The **function is in-out.** const &amp; for in. return value for out. Instead you have a bunch of people who insist of writing the former.
Thanks for the feedback :) The directory tree may look too exploded at first but I think it is the way to go to keep things clean on the long run. If you put everything into few directories it is a call to take shortcuts and make a mess. Here you can just `ls modules/core` and you already have an overview of the tools, then details like tests and Java code for Android are located in their respective module tree. We have mitigated feelings about documentation. On the first year of the project we had an extensive Doxygen documentation but in the end it did not follow the modifications of the code and we had stuff like `std::size_t _size; ///&lt; The size of the object`. Finally we never read it and went straight to the code when we needed an information so we just get rid of the comments (we do the same with some external libraries like Cocos2d-x or JsonCpp: we look at the code more often than the docs to get our answers). We think it would need some meta-documentation in a few readmes but again it is hard to keep it up to date as we work on our products. I hope that now that the code is open and quite stable we could come up with some documentation of this kind. Did you see something that would be better with returning an error code? In our products we work a lot with asserts during development and track the problems in production by looking at the crashes (we upload them in HockeyApp) and the logs (we send them to Logmatic). When we need to handle errors (e.g. the output of a network request) we usually work with something with two signals, one for the result and one that dispatches an `iscool::error::synopsis`. So there is some error handling, just not via return values nor exceptions.
This subthread _is_ the context. Your sentence was "It's intellectually dishonest to force use of an API with an inout parameter when you could just have a in parameter and then pass it back out via return value." There is no ambiguity here: you called the `const&amp;` parameter inout, while arguing against it, while arguing that it's what you prefer. Truly one of god's own morons.
I’ve not really thought too deeply about this but my initial thoughts are that I’d rather standardise an event loop (which is what a game and an application both are), than a graphics library. It’s much more difficult to write a correct, efficient event loop, even though modern c++ provides many of the tools you need to write one, than it is to copy 100 lines of boilerplate code to create a window. 
I didnt call MY signature parameter inout. Troll. 
Absolutely. When I see Graphics, I think “cool” then I see they’re talking window management, input handling... 
Pray tell, which signature is "yours"? Is it `std::vector sort(const std::vector &amp; my_vector)`, which [this entire subthread was in response to](https://www.reddit.com/r/cpp/comments/89iz17/inputoutput_arguments_reference_pointers_or_values/dwya33q/), which is clearly not an inout parameter? Because the only other signature you've shown is `void sort(std::vector &amp; my_vector)`, which you're actively arguing against. Either way, keep digging.
You are purposefully being dense. My signature `std::vector sort(const std::vector &amp; my_vector)` is in [response to your assertions](std::vector sort(const std::vector &amp; my_vector)) that compilers warn about unused results. This has nothing to do with whether or not `my_vector` is an inout parameter. That function could have had no parameters at all and just the same showed that no warning results. Go troll somewhere else.
**Company:** [Juelich Supercomputing Centre](www.fz-juelich.de/jsc) **Type:** Full time, PhD position **Description:** We are developing a C++11 tasking framework for today's and tomorrows HPC ecosystem. Scientific applications that focus on strong-scaling (like molecular dynamics) require parallelization approaches with only very little overhead. We are looking for a PhD student in the field of computer science to extend and optimize our current C++ tasking framework for future HPC hardware and applications that specifically target strong-scaling. The current C++ framework is very modular and supports intranode and internode (MPI) parallelization. To reduce overheads to a minimum different NUMA and locking strategies (Mutex, MCS) are already implemented. The tasking codebase will be used by a multigrid solver and the fast multipole method as plugin for other scientific libraries. ** Experience** Required: * strong background in C++11 * profound understanding of template meta-programming Desirable: * interest in C++-based tasking approaches * interest in low-level performance optimizations * no fear of numerical methods, in particular iterative solvers and time-stepping schemes * mild coffee addiction **Location:** Juelich Supercomputing Centre, Germany **Remote:** no **Visa Sponsorship:** no **Technologies:** Required: mainly C++11 on any Linux HPC hardware that we can find. **Contact:** Interested candidates should take a look at the [full description](http://www.fz-juelich.de/SharedDocs/Stellenangebote/_common/dipldok/d026-2018-jsc.html?nn=362310) and/or send an email to [i.kabadshow@fz-juelich.de](i.kabadshow@fz-juelich.de)
&gt; It's intellectually dishonest to force use of an API with an inout parameter when you could just have a in parameter and then pass it back out via return value. That's your statement, verbatim. You brought up inout params, no one else – no shit they're not relevant, but _you_ brought them up. You can't knock down my strawman if it was _your_ strawman. My assertion that compilers warn about unused results is perfectly accurate – _when_ you tell them to warn about unused results. Of course a shitty API is going to have shitty ergonomics; the **obvious** assumption is that the API is written correctly, and if it is then it has `[[nodiscard]]`. Out of all this rhetoric, nothing you have said refutes this; all you've written is inconsistent and self-contradictory.
&gt; That's your statement, verbatim. You brought up inout params, no one else – no shit they're not relevant, but you brought them up. Please show me where I said `const std::vector&lt;int&gt; &amp; my_vector` is an inout parameter. &gt; Of course a shitty API is going to have shitty ergonomics Why use shitty APIs if they're that shitty? Go troll somewhere else. 
I think, at the very least, there should be a warning if a block of code is eliminated because of something that happens logically later. I.e. here: if (ptr) { ... } // warning if eliminated. ptr-&gt;whatever But not here: ptr-&gt;whatever; // ok, assume pointer is fine from here on. if (ptr) { ... } // redundant test, feel free to eliminate. Even better would be not to eliminate the block (in the first case) at all. Odds are it's either an assertion (in which case it should be kept, since it provides valuable information on the presence of UB), or the function is broken (a part of it understands ptr can be nullptr, and another part doesn't). In that last case a warning would be far more appropriate than just silently removing the offending part. In the second case a warning is also appropriate if the test occurs within the same function, since again it indicates confusion on whether the function accepts nullptr or not. If it occurs within another function - fine, get rid of it, no problem there... 
Well, that's job security I suppose :) But stuff like: class MyAttr1 Foo { MyAttr2 int data; int more_data; }; Sure is nice to be able to treat `data` and `more_data` differently during reflection based on MyAttr2, potentially based on whether the class they are contained in is tagged with MyAttr1 or not. 
Thanks for the reply. Modularized directory tree is definitely a good thing. I just find it redundant having module path twice in source and test file paths. For include files I understand that because it allows good include path management. For source and test files, I guess it is for consistency but it is not something I would have done. I don't require full documentation and most classes and parameters were well named and self-documenting. But things like what socket_stream actually is something that should be documented. I though that it was some tcp-socket wrapper because tcp is the stream socket but by looking at the endpoint typedef I discovered that it actually was udp-socket. That just raised additional questions like "does this class have some enet style reliable communication built over udp". Had to check sources to verify that and seems like socket_stream is just wrapper over udp-socket. Basic usage shouldn't require searching souece files for information.
My parenthesis matching sense is twitching...
my bad
Right, I think the other way around is more natural. Actually, I've been experimenting with it last year. I made a proof-of-concept with concepts emulation and your Dyno library here -&gt; https://github.com/krzysztof-jusiak/vc. The idea was to have one concept definition and generate type erasure and mocking out of the concept. &gt; Example struct Drawable { template&lt;class T&gt; constexpr auto operator()() { return CopyConstructible() &amp;&amp; Callable&lt;T, void(std::ostream&amp;)&gt;( $(draw) ); } }; int main() { // constraint checking static_assert(Drawable{}.operator()&lt;Circle&gt;()); // type erasure type_erasure::any&lt;Drawable&gt; drawable = Circle{}; drawable.draw(std::cout); // mocking testing::GMock&lt;Drawable&gt; drawable; EXPECT_CALL(drawable, draw, std::cout); drawable.draw(std::cout); } // $(name) is a macro -&gt; https://github.com/krzysztof-jusiak/vc/blob/master/include/vc/concepts/callable.hpp#L32 Anyway, collaboration sounds great. I would love to help to make it happen in C++23!
CMake is quite awful, there are better options out there. Personally I'd recommend Premake + Conan.
Another advantage of *East End Functions* is specifying method return types where the type is a nested typedef. Given: template &lt;typename K, typename V, typename H, typename Eq&gt; class hash_map { public: using iterator = ...; iterator find(const K&amp; key); }; Compare: template &lt;typename K, typename V, typename H, typename Eq&gt; typename hash_map&lt;K, V, H, Eq&gt;::iterator hash_map&lt;K, V, H, Eq&gt;::find(const K&amp; key) { ... } Versus: template &lt;typename K, typename V, typename H, typename Eq&gt; auto hash_map&lt;K, V, H, Eq&gt;::find(const K&amp; key) -&gt; iterator { ... } I definitely prefer the latter.
It will be NVIDIA only, let's be realistic. 
Do people not use precompiled headers in their projects? Everything I've worked on professionally will include any common library headers in theirs. 
It isn't complicated at all. It gets complicated when profit margins come into play. NVIDIA, AMD and INTEL, the three biggest players in the CPU/GPU market are all members of Khronos group. If they think OpenCL is outdated then scrap it and build from scratch again. But you know what? That new one will end up in the bin with OpenCL as well. OpenCL got old because industry leaders ignored the standard and kept doing what they've always done.
Just philosophical (there's nothing inherently wrong with the above), but I don't like the code as it doesn't expose the loop itself. As this std::graphics-lib is placed under the banner of "teaching c++ to beginners" (god (Bjarne?) only knows why, but that's another issue), it therefor abstracts away too much. Additionally, as a beginner, I think sticking with the (queried) screen-rate (your video card will really not write more often than the advertised frequency) or just assume 60Hz (and enable (or not disable) vsync), is appropriate, so no need for the templated fps rate.
Check out [Toby Allsopp's talk](https://www.youtube.com/watch?v=mlP1MKP8d_Q) from last year's CppCon, it's about doing this and other similar [ab]uses of coroutines
no, there is still no way to non-intrusively make optional awaitable
Great that you have now added the bit-wise operators (I was the one requesting that feature), thanks! I prefer mp++ over BMP any time of the day.
apparently this another wrapper over GMP, the tittle is a bit misleading, I was expecting something else honestly. The problem with GMP is not the lib which is actually awesome, is the license.
You're welcome!
checked, his `return_object_holder` design does not solve the problem his code does not work (at lease on MSVC)
It is indeed *also* a wrapper over GMP, but all the arithmetic primitives for 1 and 2-limb integers are re-implemented from scratch and don't use GMP at all. Plus, it has a small buffer optimisation that avoids the mandatory dynamic memory allocation from GMP. These are the two main reasons behind the performance advantage.
For people who need to get serious about permutations (and combinations): https://github.com/HowardHinnant/combinations
I live in Huntsville, AL, and there is an NVIDIA building near me. Do you know if they are hiring at the location near me and what type of candidates they are interested in hiring? Thank you.
 &gt;&gt; data attributes. &gt; &gt;I don't know exactly what you mean by a data attribute.. Something similar of what you showed after. What I mean by data attribute is this: // Classes that represents our attributes. struct SerializeName { std::string_view name; }; struct Serializable { int max_depth = 5; }; struct Skip {}; struct [[Serializable]] SomeStruct { [[Skip]] int id; [[SerializeName{"bar"}]] std::string m_bar; }; Then use reflection to get the instances of the attributes (hypothetical): constexpr auto meta = $SomeStruct; constexpr Serializable serializable = std::get&lt;0&gt;(meta.attributes()) constexpr auto max_depth = serializable.max_depth; constexpr auto bar_member = std::get&lt;1&gt;(meta.members()); constexpr SerializeName attr = std::get&lt;0&gt;(bar_member.attributes()); constexpr auto name = attr.name;
Did some one already looked at [LibBF Library](https://bellard.org/libbf/) with MIT license?
OpenMP, though not part of the C++ standard, is standardised itself and IMO a very nice way of targeting various devices. At least from version 5 forward the feature-set will be quite complete with respect to e.g. what CUDA offers. With OpenMP you can write very generic code without the need for special standard library functions. One downside: Microsoft does not seem to want to support modern OpenMP versions.
Is there a tool to automate conversion to east const and trailing return types. I looked in the clang tidy docs and couldn't find anything 
&gt; [Stable release: 4.3 / November 16, 2010; 7 years ago](https://en.wikipedia.org/wiki/Premake) Are you serious? And even the latest alpha preview is 14 months old. To be fair, [their GitHub](https://github.com/premake/premake-core) seems quite active and it seems to even support VS 2017. I wonder though whether it can handle essential things like `/std:c++17`/`-std=c++17`, like CMake can. I've never seen premake used anywhere, literally ever. :-O
I am not aware of any tools that can do that at the moment, but I plan to add code cleanup checks to the next release of ReSharper C++ which will update const placement and convert function signatures to trailing return types.
Sorry, I meant 2018.2, but it should be available sooner in EAP builds if you really need it. 2018.1 is finalized and the release is scheduled for this week.
&gt; The problem with GMP is not the lib which is actually awesome, is the license. Why is the (LGPLv3) license of GMP an issue? Proprietary packages such as Mathematica use GMP without issue. If, as you say, GMP is an awesome library and thus does not require modification, its license should not be an issue even for proprietary packages.
OK great look forward to it. My feeling on discussions like east const, trailing return types, ... is that they are pretty irrelevant without tools to automate conversion. Maybe small projects and projects that have a lot of refactoring time on there hands can do conversions manually. However even then how do you police things post conversion.
The problem is that `get_return_object` is called before `return_value`, as you noted. Interestingly, MSVC calls `initial_suspend` before `get_return_object`, while Clang calls `get_return_object` first. I implemented such an [adapter](https://github.com/jamboree/co2/blob/master/include/co2/adapted/boost_optional.hpp) for my [CO2](https://github.com/jamboree/co2) lib. In CO2's emulation, you can control when the coroutine starts. I'm not sure how the Coroutine-TS specifies it though...
I checked N4680 it says get_return_object is called before initial_suspend. BTW I have questions on your implementation, get_return_type have coroutine_handle parameter? initial_suspend and final_suspend return bool, not suspend_always/never? await_ready as free function? Is that work?
Oh I missed that, my fault.
That was the thing that Apple said they would never support, wasn't it?
General question, not specifically to you: Why isn't this stuff upstreamed into clang so that the "out of the box" clang on any system can target CPU+GPUs?
Doesn't [Folly's optional](https://github.com/facebook/folly/blob/master/folly/Optional.h#L564) already do this?
Nice article. Nit: terminology. There's (as yet) no such thing as partial specialization of a function template. It's overloading.
&gt; These seem like ancient practices. and &gt; I strongly suggest you to use CMake Tell me about mental gymnastics...
It could well be done eventually, but right now you need a whole load of AMD specific stuff installed to actually use it - they might make an openCL version which is heterogeneous 
Look on the bright side of things! After WW3 the C++ will become relevant again! No surviving PC would be able to handle all the js/py/tuby/etc. bloat (or at least it would be really unwise energy/resource-wise!
For the postdoc position LSU requires a PhD. For any other position this could be negotiated. So please contact us through the email I provided above.
Doesn't the LGPL require to use (unmodified, as to what you allude to) libraries as dll's only? Can't say I find that "without issue".
Packing member variables could reduce performance -- example is if members have been grouped next to mutexes to reduce the impact of false sharing. A sequential layout option would mitigate that problem. Disallowing function pointer comparison would mean that you couldn't hash/sort them for a container key, or even assert that a global function pointer wasn't being replaced with conflicting functions. That seems overly restrictive. I'm not sure what circumstance would have the compiler specializing a function and exposing the pointer to the specialization anyway. For the common case of identical code folding it would suffice to have function pointers be non-unique unless the programmer indicated the need otherwise, such as by attribute. 
`using FunctionPointer = int(params);` works too (and looks less confusing imo) if you're okay with not including the pointer in the typedef.
Since newer versions of Premake seem to never come out of alpha, somebody forked it and created [GENie](http://github.com/bkaradzic/genie). One notable project using GENie is MAME: https://github.com/mamedev/mame/blob/master/scripts/genie.lua
&gt; It doesn't need to be unmodified, just that if you do want to change GMP, your changes also need to be released under LGPL3. I don't think I'll be modifying GMP anytime soon. Don't like dll's (and never use dll's with 2 exceptions, TBB and MKL), it's a fudge from the past (IMO), when, memory and disk-space were limited and expensive, i.e. let's "share". In the good old (DOS) days, you had overlays, which were even more fun, just copy some binary code to some memory area (the same you used before) and use it, need more code, more copies... I prefer statically linked static libraries (yes they're bigger, yes, there's redundancy, but it also always works with the above exceptions, but requires taking care of global variable initialization).
`constexpr` `std::fstream`s, anyone? 
Send an email with your resume.
2038 might be a bad year (or extremely good?) for those still in business
Well, not being allowed to statically link GMP is a show-stopper though for many...
To my understanding you can statically link LGPL object files with no problem. The catch is you have to also include your application object files to allow re-linking. It's a nuisance overhead issue. It's gonna take you a day to get it set up correctly to distribute valid object files and then you'll have to maintain it forever. But it's not this terrifying minefield a lot of people seem to assume. Using LGPL stuff in commercial products is fine -- just annoying.
My reading of the LGPLv3 license[1], specifically paragraph 4(d)(0), indicates that one may indeed create a Combined Work, including a statically linked library, provided that the Minimal Corresponding Source and the Corresponding Application Code are conveyed such that the user may "recombine or relink the Application with a modified version of the Linked Version to produce a modified Combined Work." The key here is that the user must be allowed to modify "the poritions of the Library contained in the Combined Work." This can be done either with a static or shared library. Even if the LGPLv3 did not allow static linking, I hardly buy that this is some huge issue preventing proprietary software from using it in an unmodified form. As /u/llkiwi2006 points out, even in modified form, it only requires the Minimal Corresponding Source, "excluding any source code for portions of the Combined Work that, considered in isolation, are based on the Application, and not on the Linked Version." Furthermore, shared libraries seem to work pretty well for a lot of proprietary software out there, and this notion that not being allowed to statically link libraries is a "show-stopper" seems exaggerated. [1] https://www.gnu.org/copyleft/lesser.html#section4
Because almost everything, including C++, is capable of interop-ing with C. So why bother. You can always write your own C++ wrapper library around the C interface, but there's no good reason for the OS to provide the APIs in many different languages.
If it ain't broke, don't fix it.
I didn't find the place where I mentioned a partial specialization of a function template. Cab you point it ou for me? Thanks.
I'm reasonably sure you can't overload functions based on their return types in C++…? 
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Attributes are supposed to have the property that they can safely be ignored by compilers without unduly effecting the semantics of your code (particularly to the point of making it mean something else or be ill-formed altogether.) We'd need a new syntax for 'decorators' (basically the same thing, but allowed to affect semantics _much_ more widely.) 
That is a good question but why not take it one step further to an even more modern language?
Because the way that the Unix API is written has been set in stone so deeply that an insane amount of programs uses it. It will probably never change as disruptively as switching to a new language. Maybe there are more modern OS'es though, new API's similar to the Unix one might be written in a different language.
I take it, writing a GetOpt wrapper, current method is just ugly to me 
Like what?
It wasn't until 2017 that ++C got string_view. If that had been available 10 to 15 years ago, maybe there would have been more interest in a ++C API.
Indeed. There was a paper at Jacksonville proposing it formally :(
Is there a reason for you to call it ++C?
With a better package sharing ecosystem (Conan might fit this description), it would be very easy to have more elegant, popular libraries that wrapped these awkward tools. The onus is on C++, not Linux, to accomplish that. 
doubt it. 10 years far too few years. In this day and age a lot of things change fast, but a lot also don't. As slow as some industries do adapt new technologies I firmly believe it'll take more than that. Unless something game-changing happens (Quantum computing, AI taking over :^) ). However, even then this will likely be technology for very specific tasks and processes. Plus, current programmes must be ported. Nah.. I don't see this happen for the signicifant majority of users and companies in 10 years. 
Not OP but ++c is pre-increment instead of post-increment meaning that ++c is one better than c while c++ will better than c after it's done.
Because C++ ABI isn't standard, whereas C ABI is (kind of) standard.
because C++ could be fast as C, but not faster. 
Or https://www.boost.org/doc/libs/1_66_0/doc/html/program_options.html
I got that from another user -- maybe named krum.
C++ mangles symbol names when compiling, and each compiler has different naming system conventions. C doesn't do that, and that is a reason why almost all languages offer C compatibility.
It's essentially down to the opinions of the people making Unix APIs. They aren't C++ people, and that's self-reenforcing.
&gt; I read from this that I can create a static library, from LGPL source. It does not say that I can create an executable, statically linked to a static lib. From section 0 of the LGPLv3, on Additional Definitions: &gt; “The Library” refers to a covered work governed by this License, other than an Application or a Combined Work as defined below. &gt; An “Application” is any work that makes use of an interface provided by the Library, but which is not otherwise based on the Library. Defining a subclass of a class defined by the Library is deemed a mode of using an interface provided by the Library. &gt; A “Combined Work” is a work produced by combining or linking an Application with the Library. The particular version of the Library with which the Combined Work was made is also called the “Linked Version”. Based on these definitions, I believe your interpretation that you can only create a static library from LGPL source and not create a statically linked executable seems to be too narrow. A static library is simply the collection or archive of object files and therefore requires no linking at all--creating a static library of the LPGLv3 licensed Library is obviously permitted as well--and has no bearing on the Combined Works section of the license. Based on my reading of these definitions, an executable, linked with the Library in either static or shared form, is indeed a Combined Work "produced by combining or linking an Application with the Library". Therefore section 4 of the LGPLv3 applies to statically linked executables as a Combined Work, and in particular as discussed previously, paragraph 4(d)(0) stipulates how this is to be done with conveying or distributing this Combined Work. I think the first sentence of section 4 makes the intent quite clear: &gt; You may convey a Combined Work under terms of your choice that, taken together, effectively do not restrict modification of the portions of the Library contained in the Combined Work and reverse engineering for debugging such modifications... There is nothing preventing the modification of the Library contained in the Combined Work (i.e. statically linked executable in this case), provided that as per paragraph 4(d)(0) the distributor provides the Minimal Corresponding Source and "Corresponding Application Code in a form suitable for, and under terms that permit, the user to recombine or relink the Application with a modified version of the Linked Version to produce a modified Combined Work". &gt; The executable can lead its own life without (distributing) my (local) static lib and can do this without exposing any of the source-code that was used to create the static library. The latter seems to be against the rule that the user should be able to "recombine or relink the Application with a modified version of the Linked Version to produce a modified Combined Work.", as no re-linking is possible in this case (without de-composing and re-integrating (with the modified bits) the the binary code). Without distribution, even the strong-copyleft GPL allows you to not expose the source-code of your modified library, static or shared[1]. Users outside of the organization which have not been conveyed or distributed this potentially modified internal, undistributed library certainly have no right or ability to link against it. This also applies to the LGPL as you suggest here, but this is not relevant to section 4 of the LGPL. Certainly an executable which does not link with a library, static or shared, is not a Combined Work, and can indeed lead a life of its own, distributed or not, according to whatever licensing is so desired for this unrelated executable. If I have misunderstood you here, and your suggestion here is that were the organization to distribute an executable linked against the modified internal, undistributed static library, without providing the Minimal Corresponding Source and Corresponding Application Code, then the organization would be violating section 4, then I certainly agree this would violate paragraph 4(d)(0) of the LGPLv3. However, this is easily resolved as discussed above by providing with the distributed statically linked executable the Minimal Corresponding Source and Corresponding Application Code, as per the same paragraph. &gt; The (L)GPL is a good license for an open source OS (definitely nobody should be able to take "control"), it's simply no good for anything else. Boost has the boost license for a reason, it's far more liberal as the (L)GPL (and then we have of course Apache, MPL, MIT (a.o.), all of which are far more liberal). I really never intended this to be a debate over permissive vs. copyleft licenses, as I understand the utility of each. However, this idea that copyleft licenses, and particularly the LGPL in the case of a library, are entirely unsuitable for use in proprietary environments seems to be altogether wrong. Your claim that copyleft is only good for an open source OS because no one should be able to take "control" of the OS is also somewhat concerning. Why is only the OS worth protecting? After all, what do you do on your OS? Do you only want to run proprietary code or code effectively controlled by a single entity under a permissive license which provides no rights to you? In particular, the permissive license gives you no right to the source code which the distributed binary is actually running, so unless you trust the distributor of said binary, you'll have no (simple) way to know what code is running. Corporations regularly use copyleft code in their daily business without issue, even with distribution. Maybe some corporations are afraid to do so because they can't be bothered to read the licenses, or maybe lawyers are overly cautious (hard to believe, I know) with their reading of it, but either way as far as I'm concerned it's their loss not to use (and hopefully contribute to) copyleft software where it makes sense. Wolfram decided it made sense to use the LGPL licensed GMP over a decade ago and has been selling its software ever since without issue. So either its competitors can decide to develop some (proprietary or open source, permissive or copyleft) multiprecision library, wait for one to come along which is superior to GMP and is permissively licensed, or they can use GMP like Wolfram did. The latter option means they can reap the rewards of the efforts put into GMP immediately, while the former options require either personal monetary and time investment on their part or hopefully just waiting for something better to come. [1] https://www.gnu.org/licenses/gpl-faq.html#InternalDistribution
That's a surprising claim. string_view is nice, but how is this critical for an OS?
Oh really? In C++, std::sort will generally be faster than qsort in C. Of course you could always go and implement your custom, type-specific sorting in C to be as fast as C++, but real-world usage of C or C++ is often not like that.
ugly isn't the driving factor.
do you have a benchmark?
No. C++ is too unsafe. It shoud be rewritten in D instead.
you r referring to the inline advantage, that doesn’t apply for OS api case since the OS is already compiled and running. there r many cases that C performances better than C++ due to it is simpler and easier for the compiler to optimize. However, carefully written C++ performs the same as well written C.
You forgot the biggest advantage of dynamic libraries: the ability to upgrade the library without having to recompile everything that uses it. Remember heartbleed? Would you rather update just the openssl library, or everything that uses openssl directly or indirectly?
Define modern. C++ had another standard ratified last year, with the next being planned for 2020. I wouldn't conflate modern with other reasons one might prefer another language over C++.
&gt; does discord have a financial model to make money? do they promise never to paywall content? Yes and yes. Both are written on their homepage and there exists a 'premium version' of discord but we aren't using it since we don't need those features :)
link please?
This thread is a disaster and this still the dumbest comment.
Nothing surprising whatsoever. There is a lot of divergence between the languages. Valid C code may well be valid C++ code with totally different meaning. People better get used to it.
For those of you talking about lack of standard ABI, why don't you consider [Itanium C\+\+ ABI](http://itanium-cxx-abi.github.io/cxx-abi/) as being standard on current unices?
I used fmt. Downloaded the header, included it, ran it.... Pretty sweet. Had a couple odd errors with error messages when I was doing something stupid. But I would expect a good round of standardization and some love in the code would iron those bugs out. I hope fmt gets added to cpp. It is clean and easy, and mostly feels natural to use. If the standardization committee focused on making it based in more natural expression, it would become even easier as opposed to more complex like they normally do. Should be fairly easy to conduct some studies in human computer interaction and natural behaviors to clean up some of the unnatural aspects of fmt. But overall, its the best I have used. With its speed, it should be focused on for standardization. 
Yeah, I pretty much only use streams for binary data (though I'm open to alternatives). Another issue I have with streams is that there is no distinction between serialized data and human-readable data, so you have no idea if an `operator&lt;&lt;` is going to give you something to present to a user or something to safe to a file.
It's actively developed (Premake 5). Even though it says it's in alpha it's usable and I didn't have any issues. There's support for selecting C++ standard, including 17. It's being used for significant projects: https://github.com/premake/premake-core/wiki/Who-Uses-Premake It's better than CMake in every way: It's faster, it's easier to use, it has better documentation, it uses a real general scripting language that people already know with an ecosystem and not a horrible hack, it has better support for extensions, it's easier to build.
Ah but then you can have component A requiring LIB version 1.2 and component B requiring LIB version 2.3. And you have to have both A and B in your project. Doable with DLLs where the two versions of LIB can live side by side, not doable with static libs where you get symbol conflicts at the final link if all of A, B and LIB are static libs. IOW, you have more control of symbol visibility with DLLs. A and B use each their version of LIB, but do not re-export LIBs symbols.
TL;DR ostreams do have downsides (in the age old printf vs stream debate), author suggests {fmt}.
C++ is 10 years behind in language development
I didn't mean to imply that, i don't think that at all. I actually should have included that as an example, too. But, you're mistaken if you think that changes my point. Being able to afford to go, or having a company that pays for you to go, is not a good filter. Those companies are just as able to participate online as offline, in fact, it'd be cheaper for them *and* allow more companies(that maybe can't afford, time or money, to send their experts off all willy nilly) to participate. 
Tons of work happens online between meetings, some of us do committee work pretty much every week of the year. Attending meetings in person is not the only way to participate, but it is the most effective. Wider participation is a fine goal. Moving everything away from face-to-face meetings to online is neither necessary nor sufficient to achieve it.
&gt; So what would happen in 10 years ? 10 years ? some unix APIs date back to 1970's and are still used, 10 years is negligible. A good part of LISP functions were created in the 50s and they are still used today.
behind... what ? quite a bunch of languages actively backport C++ features. See Java adding the ability to define default methods in interfaces, the focus of Rust on ownership (some 1996 c++ articles on it : http://www.aristeia.com/Papers/C++ReportColumns/apr96.pdf), C# acquiring the ability to allocate on the stack and getting equivalents to C++'s string_view, etc etc. And features like variadic templates are actually *more* advanced than quite a bunch of other languages's generic implementation ; this creates a whole class of function that you can implement in C++ but not in Haskell for instance.
Concerning your winner example - that's why I think it's more appropriate to overload a &gt;&gt; operator instead of burying that stuff deep in code. A bit similar to overloading java's toString() method. 
Meh. I wonder what positions require only that kind of knowledge. This sounds more like a list for a (bad) recruiter screen. 
C APIs (and POSIX APIs) accept `const char*` and length pairs when they want to accept string data for reading. Until `string_view`, the much more idiomatic way to do this in C++ is a `const std::string&amp;`, which is nice and safe but forces the data to be owned by a std::string, and not from eg. a memory-mapped file, a network packet in memory, the contents of a protobuf message, the insides of a streambuf, or many other places. If you have string data in any of these, `const std::string&amp;` requires an unnecessary copy, which is usually fine in most application scenarios, but OS developers and many high-performance low-latency developers are keen to avoid. Of course there's nothing stopping you using a `const char*` and size in C++, but `string_view` is a much more elegant abstraction.
The API to Unix is via syscalls... This isn't a C specific feature. It sounds like you are confusing glibc, a common C standard library, that implements syscalls for you with unix. Unix as an operating system cares neither here nor there what language you are using so long as you can put the right things in the right registers and trigger the right interrupt. See golang and it's ability to not use glibc when compiling.
It's does not cover enough. For example, it does not specify binary layout of standard library types, like `std::string`. See [corresponding section in documentation](http://itanium-cxx-abi.github.io/cxx-abi/abi.html#scope). 
Yes, that would be a problem, but I find that use case rather awkward and would adapt component A to accept LIB 2.3.
Thanks for mentioning this. I’d never heard of it before and it looks like what I’ve wanted for a long time.
It's funny because these same people also think C++ is adding too many things too fast.
Why do interviewers like to ask things that are Googlable? It's not university. "Cheating" is allowed.
You're right. C# is better.
&gt; I think it should be focused on for standardization There is already a proposal though.
I was thinking some strlen() calls could be avoided also since that comes with string_view.
Apparently, C\+\+ standard library is part of the software platform, not the compiler. So is C standard library, isn't it? AFAIR glibc and libstdc\+\+ \(under Linux\) both do provide versioned symbols in order to allow ABI breakage while keeping the old binaries able to run, for example.
Actually they are Googlable. To the point that someone has already answered that question on StackOverflow, and often raising more issues to the forefront that even many experienced C++ programmers aren't aware of. I mean seriously esoteric, standards-quoting, stuff. Stuff that, were you to give as answers in the interview, some interviewers will dismiss it as being wrong because it didn't match the answer they thought should have been given.
Reflection, Filesystem, Networking, Parrallel algorithms, Modules all these should have beein in c++ 11 not C++ 23
u”” and U”” literals were added to C in C11. They were added by the adoption of ISO/IEC TR 18769:2004. You can find the most recent draft of that TR at http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1040.pdf. C++ acquired these literals via C, but (thankfully) elected to make ‘char16_t’ and ‘char32_t’ fundamental types rather that typedefs. You are right that there are significant differences between C and C++. These differences exist for good reasons. The C++ committee really does try to avoid gratuitously diverging from C. 
Thanks for sharing. Indeed, as I said in the article, the preprocessor approach is inelegant, but its brutal nature often makes it easier to adopt by people. Using includes instead of macros mitigates some of the downside, like reduced debuggability. However, I like the way you package all policies under a single class. Maybe you should suggest this an an improvement to NamedType?
I do have Mathematica 11.0 installed on Linux, and they indeed are shipping a shared library for libgmp in the package. However, I would attribute this more to ease of integration with the build system and usual packaging/shipping mechanisms--shipping the Corresponding Application Code (i.e. the object files for the Application), is somewhat uncommon--than to licensing issues. Static libraries are frowned upon for many reasons¹, especially in the open source community, and the fact that shared libraries are easier to use is in alignment with my previous statement that "not being allowed to statically link libraries is a 'show-stopper' seems exaggerated." I should also point out that Wolfram correctly² provides the source[1] for the (potentially modified) LGPL GMP library. Not being permitted by the LGPL license to ship a statically linked version of the Application and the ease with which one can do so are two separate issues. In the end, the distributor has the rights according to subsection 4(d) of the LGPLv3 to choose which mechanism, shared or static linkage, they wish to employ, but I do not fault Wolfram, in this case, from choosing the former. In fact, I'd much prefer they and other proprietary distributors use shared linkage than static linkage--I've dealt with enough issues stemming from flawed implementations of statically linked libraries in proprietary software without the ability to relink the application. ¹shared libraries permit library interchangability without recompilation, result in smaller executables, and make it easier to see external library dependencies ²subsection 4(e) requires that when distributing according to paragraph 4(d)(1), as done here, "you must provide the Installation Information in the manner specified by section 6 of the GNU GPL for conveying Corresponding Source." Were distribution to have been done according to paragraph 4(d)(0), e.g. statically linked executables, "the Installation Information must accompany the Minimal Corresponding Source and Corresponding Application Code." [1] http://www.wolfram.com/legal/third-party-licenses/gmp.html
One aspect of ostream that I like is the append-like syntax. In the {fmt} example: fmt::print("{0} shows {1} and wins ${2}.{3:02d}", winner.name,winner.cards,pot_size/100, pot_size%100); As a reader, I have to do the compiler's job and figure out which variable is being put into {1} by counting the arguments. Tooling could help by color coding the arguments and variables, but it's still not ideal. Maybe there is an optimal syntax between these two options.
I need help
The first issue I see is the decission too count limbs instead of bits or bytes. Interesstingly the wide-int proposal started out the same way. It was a very bad idea there and it is here. If you don't want to be bothered by implementing sub-word sizes, simply add a `static_assert(N % (8 * sizeof(word_t)) == 0);`. Another thing, though I might just have overlooked it, is that I didn't find anything about user-defined-literals. IMO those are an absolute necessity for any serious C++-big-integer-library. Other than that: Certainly looks nicer than gmpxx.
Isn’t the point of this to help support i18n? The arguments have a fixed ordering, but depending on locale the order that the substitutions occur in the format string may vary? The append style of ostream simply does not apply itself to such an application. Being able to tag the variables inside the brace with a name rather than index would perhaps help solve your concern, but I’m not sure how such a thing would be implemented.
Call me stupid, but I still don't understand how to use it. The documentation simply doesn't tell what needs to be included and when. It's obviously not header only. There's even a Debian package which ships a static archive ... with building with -lfmt still gives undefined reference errors.
Thanks for that info. I think they would definitely benefit from making a better public appearance. Update their wikipedia page, bring Premake 5 out of alpha stage, have a better first-run example in the Readme, etc. &gt; it has better documentation At this one I really had to laugh because the first link you linked has a "needs documentation." notice all over the place ;-) Anyway, just a joke. But I don't think CMake's documentation is too bad. Sure, it could use some improvements, and in particular some more modern "first use" examples. 
Sorry for that. The new version of the docs should be more clear regarding what's need to be included: http://fmtlib.net/dev/api.html, but that applies to the master branch, not to version 4.x shipped on Debian. Normally you just need to include `fmt/format.h` (works on any {fmt} version).
As /u/aerphen said, it's already implemented (with slightly nicer syntax using UDLs)
Yes I just saw that reply, very interesting. Given the limitations of c++ I think that is actually quite an elegant solution to the problem!
Yep, here's the UDL version BTW: print("{name} shows {cards} and wins ${dollars}.{cents:02d}", "name"_a=winner.name, "cards"_a=winner.cards, ...);
&gt; anch, not to version 4.x shipped on Debian. That package is broken (ABI stuff ?), compiling from source and creating my own static library works.
Yeah it lacks some of it's documentation is WIP, but in general the documentation is more concise with better descriptions and actual examples - which are painfully lacking with CMake, which only gives ambiguous syntax templates.
Alternatively with user defined literals fmt::print("{name} shows {cards} and wins ${dollars}.{cents:02d}", "name"_a = winner.name, "cards"_a = winner.cards, ...); 
Yep, that definitely works. The output binary is almost the same size. What's even the point of not making it header only by default ?
That's really cool. Maybe with reflection, we could even default the argument name to the name of the variable that's passed in.
&gt; An implementation shall not declare any standard library function signature as constexpr except for those where it is explicitly required. Would allowing this break anything?
Looks like it going to be even simpler with initializer lists: {"name",winner.name}, {"cards", winner.cards} https://github.com/fmtlib/fmt/issues/665
&gt; Why forbid it? The blog's example `Rectangle make_rect(Width, Height)` —if you allow implicit initialization from the underlying type, you cannot verify that the user put the Width first and the Height next, and you cannot overload `make_rect` with a `Height, Width` variant. 
To tackle this approach I was thinking of implementing a Recipe file generator within the build system, which will let you generate Recipe files with the help of regular expressions, for the case you have a lot of source files.
I really dislike the east end naming style. I think the consistency argument shown in the blog post is rather weak, because the use case for auto + -&gt;decltype specifier is really rare. What about the consistency to 30+ years of existing code... I know it's not intended, but in my experience, lots of devs don't even care to add the type sepicifier once they write auto (if it compiles).
&gt;AFAIR glibc and libstdc++ (under Linux) both do provide versioned symbols For glibc its enough, but for libstdc++ its not. This is because libstdc++ provides you types you will use on the interfaces. libc always has ints, pointers and other boring types. If you link to one version of std::string and use library that linked to other version of std::string, sadness will ensue when you pass a string to that library.
I don't find the "function name should be first for readabiity" argument from the post very convincing, but your nested type example is very much so.
Wrong. C strings are zero terminated, so you don't pass in the size. "safe" in what way? Obviously not in the way of security, where string_view buys you exactly nothing over const char *. String views are a nice c++ feature, but the OP greatly overstates their importance for system level stuff. 
I seem to recall a Clang test failing for some obscure reason when someone tried to use a `constexpr` version of `std::invoke`.
Very less people use ostream to format string. The problem manifests itself when you try to use another language. That's why Qt has QString. std::cout is hardly used in real life project. The only frequent use of ostream is ostringstream to convert some data type to string type.
No, {fmt} is based on Python formatting and is similar to Rust's `std::fmt` which is also Python-based. AFAIK Go's fmt is loosely based on `printf`.
PRs are welcome =)
You are probably thinking of https://bugs.llvm.org/show_bug.cgi?id=23141. The issue is that "normal" and `constexpr` code behaves differently in e.g., SFINAE where e.g., `constexpr` function bodies are initiated eagerly. This seems to be something one should definitely take into account when designing generic libraries, but I cannot put my finger on it, yet.
&gt; As Jonathan already stated, NamedType is a zero-cost abstraction: given a sufficient level of optimisation (typically O1 or O2), compilers emit the same code as if arithmetic types were used directly. This isn't true for all platforms. Sometimes the ABI specifically penalizes using `struct my_int { int value; };` over `int` directly. However, something like `enum class my_int : int {};` is never penalized (`enum class` was designed to ensure it). I"m not sure exactly why some platforms penalize this, but you can see the difference in the codegen [here](https://godbolt.org/g/ru3sKC). Godbolt has other compilers that show the same result.
Indeed. At least, it seems to be for a minority of compilers. As always, one must profile *and* look at the generated assembly code when performance is important!
The Itanium ABI says nothing about library compatibility, though, and that has changed several times, and will change again. Without the standard library, you'd still be passing around `char*` strings, using integer return codes instead of `std::exception` hierarchies or `std::expected` or anything, and using opaque types like `FILE` instead of richer object-oriented interfaces. Changing languages has to actually be _worth_ something. Changing to C++-without-the-library isn't necessarily worth it. It's not even necessarily worth it to offer an official POSIX C++ library. Ideally, everything that POSIX offers would just be offered in the C++ standard library, and offered in a platform-independent fashion (e.g., `std::thread` instead of pthreads, `std::filesystem`, asio, afio, executors, coroutines, etc.). Lots of work left to do there, but hypothetically that takes us even further, since modern systems - even POSIX-based ones - have a lot of capabilities that aren't exposed in POSIX. (the simplest example: epoll/kqueue.)
Since when Microsoft takes standards so seriously? :P
I am aware that this title might be considered *a teeny-tiny bit* provocative, but I believe that `023 == 19` is indeed very stupid and should be changed.
Yea totally agree, they might as well just make it header-only :-) But I mean it doesn't make too big of a difference as a consumer - setting the define is trivial.
I often use + toString functions to build strings. Why is that not liked? Are the string constructors to expensive/can't be optimized away very well by the compiler?
Correct, it doesn't work on MSVC. Gor promises me this will be fixed at some point, but for now I think the MSVC implementation makes this impossible. It does work on Clang. I'm working on adding support for other monads and integrating with Vicente's monad traits proposal (https://wg21.link/p0650r2).
Having run into this and created bugs with this before, I fully support getting rid of leading-zero-implies-octal. 
https://en.wiktionary.org/wiki/-ful Like with many other parts of English (and other languages), it used to be okay to spell it that way.
I agree the "o" is a bit unfortunate, especially since these literals allow uppercase: `0O777` We could be cute and use "c", so the prefix reads like "oc[tal]": `0C777`. There's a risk of mistaking it for hex, but you have the same problem with binary: `0B1`.
The problem is there is not perfect lib and approaches like {fmt} have their own issues. The problem as i see it that we will end up with yet another way to do formatted I/O in a language that already has more than one solution (not sure what the count is right now). Personally I find the format strings that libraries like this use to be very ugly and in fact reduce readability and maintainability.
Still ugly as hell and even more verbose than a streams based solution. 
&gt;&gt; I think it should be focused on for standardization &gt; &gt;There is already a proposal though. &gt; &gt;http://fmtlib.net/Text%20Formatting.html What what be the earliest we could see it included in a standard?
strongly disagree, header only bloats compile times. Yes I know that fmt has done a lot of work to minimize compile times, but death by a thousand small cuts.
From the article, this is the equivalent ostream-like formatting: ``` some_ostream &lt;&lt; winner.name &lt;&lt; " shows " &lt;&lt; winner.cards &lt;&lt; " and wins $" &lt;&lt; pot_size / 100 &lt;&lt; "." &lt;&lt; std::setw(2) &lt;&lt; std::setfill('0') &lt;&lt; pot_size % 100; ``` Personally I'm less favorable with the ostream-like formatting (too many fragments). But as the article mentions, the major problem with this is i18n.
How to use a custom format (while keeping the text translatable)?
AFAIK purely theoretically it could still make it into C++20, though not sure about more realistic timeline but I heard it was rather well accepted. C++23? /u/aearphen ?
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8auqib/tutorial_websites_books_for_modern_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I hadn't heard of `osyncstream` before. Is it basically a `stringstream` that flushes itself to the target stream when destroyed?
If my company is kind enough to allow me attend the next committee meeting in June then I'll try to polish the wording by then and push for C++20. During the last meeting there was a strong support for major design features of the proposal in the Library Evolution Working Group (see http://www.zverovich.net/2018/03/17/text-formatting-jacksonville.html) and only requests for small changes which I already implemented.
The committee doesn't have either unlimited manpower or time to review and discuss proposals. Most of them wished it had made it back then as well.
Why wouldn't it? Number literals are still ints in the end. 
Still is, if we know what you mean. _Down with the prescriptivists_ !
&gt; Because C is weakly typed. This allows a memory location to be looked at as different types without any code executing. It's all done by the compiler, so there's no runtime overhead. Try godbolting some code, even without optimizations there is no runtime overhead when converting types when reinterpreting the data (it's also as unsafe in C++ as in C, just requires to be more explicit) &gt; Because C doesn't do reference counting or garbage collection. This makes it faster, which is important for system functions, but more difficult to program. You don't have to do it either in C++, garbage collection is almost never used anyway and there's plenty of reference counting even in C libraries (like with SDL, freeing a surface simply decrements the reference counter). &gt; Because C is closer to the metal, that is, you have to think about the hardware more, which is also important for system functions. What? There is nothing closer to the metal you can only do in C except stack allocated arrays of variable sizes. But C++ makes it easier to write custom allocators that can also use the stack.
I, too, have run into issues with this. The mistake I make most often is with timestamps: auto t1 = Time(12, 00, 00); auto t2 = Time(09, 00, 00); // error: invalid digit "9" in octal constant Thankfully these at least get caught at compile-time.
Doh. :) 
I just spent three hours trying to implement this. I came to the conclusion that it cannot be done with how much c++ I know. The arg function (in core.h) takes in a string view and a templated variable, and constructs a class called named_arg. The problem is that initializer lists need to construct an object, but the object, like the arg function, also need to be templated, and it seems like you can’t deduce templates in function parameters, so you need to construct the object before passing it to the function, which is not optimal. It sounds like a great feature though and I hope someone smarter than me could do it.
Thank you for your comment, but I dont think it is specializing coroutine_traits for std classes, but the MSVC's coroutine implementation that makes it not work. I agree with you that the standard does not allow specializing that for its classes, but the code is just for experimental purpose and fun. The "behaviour as expected" is also a possible result of "undefined" behaviour", doesn't it? (lol)
I was doing some work in a sawmill once and overwrote the wrong address with a value because I was padding decimal values with 0. That very literally could have killed someone. I've never used octal for anything other than `chmod`, so I say at least create a warning for its use.
Although I agree with your sentiment, I don't agree with your message. Reading a text without petty typography errors is objectively easier and nicer, so one should try to improve one's writing.
I actually thought this was what the article was about when I read the title. I was wondering how it could make any difference to be harmful.
I'm never going to complain about someone's imperfect usage of their second (or third, or fourth...) language, but I would agree that when you're writing for public consumption, spelling and grammar are important. It's not the end of the world, and "I'm not fluent in written English" is an perfectly valid defense, but it does make you look better if you can get it right.
It should be against the rules to be a prescriptivist.
'0t' is ternary.
Do you have a link? I found e.g., [issue 1581](http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_active.html#1581), but it appears neither recent nor resolved.
No, and probaly never will.
I got confused by you also using hex in your example, but that's really cool.
What questions aren't *googleable*? What questions do you like to see? I don't really understand the issue. I mean, if you don't know the answer then it's not like you will say "Excuse me, let me quickly check that on my phone". 
Upvote for actually finding another use for octal literals, even though I'm not sure that I would accept pull-requests that made actual use of this.
Yeah, I've spent some time trying to find a solution for this. Now I'm really curious is it at all possible to make it work.
Actually English really could use a couple of prescriptivists that push through a spelling-reform. Preferably a radical one. The one we had for German went into the right direction but was watered down too much, because lot's of dinosaoures complained.
Your point stands, but if this could have killed someone there are other issues in the process (lack of hardware locks, testing, maybe Ada is a more appropriate language)
u/jbandela has a [neat](https://www.reddit.com/r/cpp/comments/8a7so6/getting_the_benefits_of_strong_typing_in_c_at_a/dwx8s6w/) way of producing on-demand overlaods to out of order, very cool.
IIRC it was indeed the DR blocking algorithms that use swap (see the rationale of P0879). Unless I'm mistaken it was fixed during the latest committee meeting a few weeks ago and the resolution should appear soon enough in an updated list of CWG defect reports.
So the conference is so expensive because you do it in a hotel? Then I guess it would be better to make it next time not in a hotel? When I would be a guest, I would like to avoid subsidy the hotel guests. PS: Wouldn't be Frankfurt the best central place for such a conference in germany (central, best airport and train connection)?
&gt; What about the consistency to 30+ years of existing code... We've been writing functions (in maths) in this way for hundreds of years before programming was even a thing. I think this is a fundamental reason why so many other languages adopted this style of syntax. There is also the consistency with: using A = some_type; auto x = some_value; Both have a left -&gt; right style. It's more consistent with the cases when decltype isn't good enough and you have to drop the return type entirely, e.g. returning a lambda. As the OP mentions it emphasises the name which is the most important part (you can't call the function without it's name) but it goes further because the next thing you read is the argument list (telling you which function overload etc.). From this perspective, the return type is really additional information as the caller can't choose the return type and can always use auto. If you have to use std::enable_if or some other SFINAE black magic on the return type, I am fairly sure that is not the first thing you want to see when reading a functions interface. Anway, even with all of this, before we had the option of writing function declarations with trailing return, we still chose to write std::map as: std::map&lt;Key, Value&gt; and not: std::map&lt;Value, Key&gt;
 30.octal 30.base(8)
&gt; I was tired of repeating `if (!r) return nullopt` to propagate the failure up And this is why exceptions are so nice. You just throw them once, and then don't have to worry about propagating them through dozens of layers that really don't know or care about any possible error conditions. It all happens automatically. Also, `optional` is a lousy way to report errors. How are you going to create a proper error message? If you used exceptions, you could pass a relevant message in the exception object. All in all, you seem to be doing something incredibly complicated do achieve something very simple - and something for which there is excellent support on the language level already anyway. 
Thanks for the comments. I don't understand if your first point is a matter of user-interface or if you are proposing to make the limb type selectable by the user. Changing the interface so that it accept the number of bits in input rather than the number of limbs is easy, provided that the underlying limb type remains the same as it is now (``mp_limb_t`` - this would result in some padding in case the requested number of bits is not exactly a multiple of the number of bits in ``mp_limb_t``). On the other hand, letting the limb type completely user-definable is not doable at the moment, as the implementation of the small buffer optimisation hinges on the integer representation to match the one from GMP. Regarding the second point, you are correct, there are no user-defined literals implemented at this time. There's 2 reasons why I haven't implemented them: - I would need to choose either a single specific integer type that is produced by the user-defined literal, or at least I would need to implement a few different user-defined literals for the most commonly used static sizes. At this time it's still unclear to me how to take this decision. - due to the fact that the integer type is implemented on top of a union (for the small buffer optimisation), the constructors must all invoke placement new, which, at this time, makes it impossible to mark them ``constexpr``. So ultimately user-defined literals have to run at compile time even for small integers, which makes them not so appealing in my view. I am waiting to see if placement new will be allowed in ``constexpr`` contexts in C++20.
Thanks! It should work with Eigen, yes. See the Eigen docs on how to add support for user-defined scalar types: https://eigen.tuxfamily.org/dox/TopicCustomizing_CustomScalar.html I might add these Eigen specialisations to mp++'s core eventually.
it's useless, but never ever had a problem with it.
&gt; though the use of octal numbers outside very few areas is highly questionable to begin with. The `0`is indeed a wart that comes from C. Issue isn't to agree that it's bad, it's more handling the deprecation, the gain/loss ratio, etc. Note: there are lesser-known industries that use octal numbers, and have large C++ codebase that rely on that syntax. Deprecating the 0 notation might be ok, but at least a drop-in replacement (like `0o` or `0c`) should be provided.
&gt; When was the last time you productively used an octal number-representation? Yesterday &gt; For anything other then unix-style file-permissions? https://en.wikipedia.org/wiki/ARINC_429 Literally I use octals every day. 
It's brilliant, but I'd never ever allow this in production code. Here it is with decimal numbers: uint64_t swap_bytes(uint64_t x) { return (x &amp; 0xFF00000000000000) &gt;&gt; 56 | (x &amp; 0x00FF000000000000) &gt;&gt; 40 | (x &amp; 0x0000FF0000000000) &gt;&gt; 24 | (x &amp; 0x000000FF00000000) &gt;&gt; 8 | (x &amp; 0x00000000FF000000) &lt;&lt; 8 | (x &amp; 0x0000000000FF0000) &lt;&lt; 24 | (x &amp; 0x000000000000FF00) &lt;&lt; 40 | (x &amp; 0x00000000000000FF) &lt;&lt; 56; } The decimal version might be less elegant, but it is much clearer as you don't have that shock of realizing, "Oh, those are in _octal_, how _clever!_" The trouble with such tricks is that they screw up your concentration. You get diverted onto an irrelevancy and then you have to come back to the actual code you are following. The code with the decimal numbers is much better. On my first review of the code, I'd say, "swaps the bytes using bit-twiddling, probably right, check if there's a unit test" and pass my eye right past it with no hitch. 
I like this idea but... &gt; I guess there's a risk of mistaking it for hex, but you have the same problem with binary: 0B1. Let's see some examples: 0x3, 0xB, 0xFFF 0b11, 0b1010, 0b111111111111 0c3, 0c12, 0c7777 That last row is a bit dodgy, it's true. :-/ Thing is that 0b numbers are nearly always obviously binary because the number contains only 0s and 1. But that last row actually looks to me like hex.
I'm sure almost none of us could write in a foreign language as well as you do in English, but two seconds with a spell checker would clean up your already-excellent article. Spelling errors disrupt people's flow of reading...
Funnily enough I've used a similar style before (return type on its own line) precisely for the reason if lining up the names - and using trailing return types was a relief that I didn't feel I had to do that any more :-) We all have our preferences.
FYI, I discovered that JSON [does not](https://json.org) allow octal numbers, whereas YAML [does](http://yaml.org/refcard.html). Sort of annoying because I have a project that accepts both...
[Page 14, section 2.6.3](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0707r0.pdf)
&gt; What is the difference between realloc() and free() &gt; C++ Interview Questions
I wrote somewhere else that some industries also have come to rely on it. "Should we add octal integers in our new languages" and "Should we remove existing octal integers in our currently used language" are 2 different questions. 1st is probably "No", because indeed those are rather niche uses (or at least use a more sensible prefix). But it has been added, people are using it, thus the requirement to remove a functionality is much, much different than the requirement to add one.
Then where did the std::matrix come from?
Those were the days.. inputting a bootstrap by hand using the front panel switches on Data General Nova
`std::random_device` can throw an exception if e.g. /dev/[u]random is not accessible, or it can block the thread when it reads from /dev/[u]random. Also certain platforms (MinGW) implement random_device as PRNG.
Skia's weak pointer destroys the object. https://cs.chromium.org/chromium/src/third_party/skia/include/private/SkWeakRefCnt.h?sq=package:chromium&amp;dr=CSs&amp;l=124 ``` /** Decrement the weak reference count. If the weak reference count is 1 before the decrement, then call delete on the object. Note that if this is the case, then the object needs to have been allocated via new, and not on the stack. */ void weak_unref() const { SkASSERT(getWeakCnt() &gt; 0); // A release here acts in place of all releases we "should" have been doing in ref(). if (1 == fWeakCnt.fetch_add(-1, std::memory_order_acq_rel)) { // Like try_ref(), the acquire is only needed on success, to make sure // code in internal_dispose() doesn't happen before the decrement. #ifdef SK_DEBUG // so our destructor won't complain fWeakCnt.store(1, std::memory_order_relaxed); #endif this-&gt;INHERITED::internal_dispose(); } } ``` That's everything you need to know about quality of Skia.
I guess that makes you the minority, whose existence I never denied. Though I still question why you don't use enums instead of octal literals.
When will **you** start to do it?
Cool, Thanks! How certain is this to be in C++20? I'm already hyped! especially the possible implications for Qt.
Huh. I always thought they were "trinary numbers", but after a bit of research it appears that I was (mostly) wrong.
&gt; Thankfully these at least get caught at compile-time. If you're lucky enough to have an 8 or 9 after the leading 0.
Variants and containers - I miss a space optimized `vector&lt;variant&lt;int,char, huuuge_struct &gt;&gt;` which only supports appending and iterating from the beginning. The implementation would just write `tag,int/tag,char/tag,huuuge_struct` directly into memory. Or for the optional&lt;T&gt; case where T is quite large. [Boost.PolyCollection](https://www.boost.org/doc/libs/develop/doc/html/poly_collection.html) does not have this. 
Wouldn't it be much clearer with C++ 17 syntax to write: if (auto foundKey = map.lookup(i); !foundKey) { } else if (auto foundValue = foundKey.value(); /*foundKey &amp;&amp;*/ !foundValue) { } else /*if(foundKey &amp;&amp; foundValue)*/ { auto value = foundValue.value(); } I think this is quite verbose even without the comments. I also find the part about the vector of optionals a bit misleading. I mean when you just need the number of empty elements your suggestion is great, but this is actually not stated anywhere in the article. Imho the more natural use case for vector of optionals be that you care about the order of the elements. E.g. you iterate over another vector and you need to store some data (which could be there or not) in a vector of optionals. You could then iterate over both vectors at the same time to access this data, which would be faster than storing this data in a map and doing a lookup for each element. 
It won't be in C++20, at the earliest C++23.
The point here is that if 80% of the code is templates - they have to be in headers anyway - so being non-header-only only helps for the remaining 20%, and these are probably not the things taking up compile time.
&gt; Maybe there are more modern OS'es though, new API's similar to the Unix one might be written in a different language. Sure. [BeOS](https://en.wikipedia.org/wiki/BeOS), for instance. A tremendous success. /s
I still need to return a constructed integer object from the literal, and in its constructor I need to use placement new.
Yeah at the end of the day none of these "guidelines" should be set in stone. It's worth mentioning that there's a couple of places were you can NOT use trailing return types when using non-standard tools/libraries. e.g. declaring CUDA kernels or if you want to use Unreal's UFunction()
A good article, but there is no mention of performance except: &gt; in addition, {fmt} is type-safe, extensible, supports both ostream and FILE* as underlying streams (with the ability to add your own stream easily), beats ostream performance-wise, et cetera, et cetera Has anyone actually measured performance of fmt compared to iostream and cstdio?
If people wanted something clear and logical we'd all be speaking Lojban. English is an organic, slapdash language that mutates every day. I say let's not fight it.
The Github page for the library offers a table with performance comparisons. ([Here is the link to the current read me](https://github.com/fmtlib/fmt/blob/096c4051b2d99c166add0c5a58d943e111afec05/README.rst)) The values were updated 7 months ago but they also specify how the test was run so you can try it yourself if you want more up to date results.
I agree, that's nicer syntax. Regarding the order: Good catch, I update it to mention it.
Well, not just an alternate spelling because it's obviously pronounced differently. The strange thing is that I always used "ternary" for the operator and "trinary" for the number system, without ever noticing the discrepancy.
&gt; The standard library really likes default-constructible for some reason. This topic has been beaten to death around here: default constructible is typically a necessity for moving, for types that are non-trivial (i.e. types where you want moving to not just be copying). That's why the standard likes it so much. (Relatedly, no-throw moves, which are also pretty critical, are closely related to no-throw default constructors, which some containers in some standard libraries don't have). Also, in your `vector&lt;optional&gt;` example at the end, you change the code in various ways that aren't necessarily equivalent. You're basically assuming that the objects are stored in the vector out of convenience, and that neither the index nor the order in which the objects are processed makes any difference. Those are very big assumptions in a container that is, well, indexed and ordered.
A couple of years back, on CppCast, Andrei Alexandrescu mentioned inlining C++ code into D. [link](https://forum.dlang.org/post/n0unr5$24lm$1@digitalmars.com) Is this related to what he was talking about? 
std::optional needs reference semantics like boost::optional. If you start passing around T*, people start wondering about things like ownership. The map should have 2 separate lookup functions - one for the value_type and one for the mapped_type. Implementation here: https://wandbox.org/permlink/Ld9lwDGsoVyTkL7J map_at with an optional mapped_type will still return an optional optional, but this way you can dictate value/reference/const reference semantics, and handling each case becomes simple with the bind; outer handler handles the non-existent key and inner optional handles the empty optional value.
Examples? Just curious about why an industry would need octals specifically
In the industry of one of my previous employer, the canonic way to represent some identification data was using octal numbers. I guess hexadecimal wasn't kept because it would require "unusual" figures that wouldn't fit on a number pad, and base 10 was problematic due to invalid values. (I don't wish to be more specific to limit privacy/etc issues)
Well, you usually don't really need an App unless you depends on selling private data of your users for your survival, but if that's the case you should be ashamed of yourself and know that there is a special circle of hell for you. I'd support making it javascript over hurting yourself in making an actual App.
I see that as a potential issue with big O (though why would you set such a font in your editor?), but I've never seen it with small o.
&gt; Thing is that 0b numbers are nearly always obviously binary because the number contains only 0s and 1. Sames goes with octal, it will only have numbers from 0 to 7 While hex can have 8 and 9 and other letters. You'd be in big problems to interpret binary as hex or hex as binary those case can happen even if they kind of look obivously like hex... If you wanted number literals to be obvious, we'd have to replace the prefix by something obvious. So you could write number literal like this. 010101.dec 010101.hex 010101.oct 010101.ter .... It's obvious and consistent and extendable. Doesn't cause confusion with bad fonts and is also kind of intuitive so for new starters it wouldn't difficult to understand that it's hex and not some weird 0x number. But it's also never going to happen. Because people would rather save typing 2 letters... 
Completely agree, I wish Apple would update the standard library for Xcode/iOS.
Sure it's a edge case. But history taught me that in perfect condition this kind of thing would never happen. So we can only assume that will cause problem in the worse condition, which also mean it will add one bigger problem to something that was already terrible. I'd ratter see a more descriptive suffix like .dec,.hex,.oct,.bin than this strange literal syntax we keep. It's like trying to fix a suffix problem by adding a new suffix that will be as confusing as the previous suffixes. It's easy for us now that 0x is hex and 0b is binary and 0 is octal... while octal isn't always obvious but we learned it the hardway. so when you see a number starting with 0 you're already ready for something. But 0b1 could be hex or it could be binary... The thing is that if people want to fix the prefix for the octal literal, they could try to simply fix the number literals as a whole and make them all consistent and intuitive and throw the legacy syntax if it's confusing. 
This is rather timely as I was just thinking about this very problem. Say you wanted to parse a very large file into columns of data and there might be missing values indicated by a code. Each column holds a unique type. Do you go the traditional route of choosing an indicator value, perhaps the smallest or largest possible, for missing values or use optional/variant? Basically wondering if there is a zero-overhead abstraction for run-time determined types that require coding for missing data.
What? Seen any tech start-up lately? Or in the past 5-10 years? And I don't mean the ones that just want your private data. I'm talking about the tech, AR, VR, consumer, fashion stuff. A multi-billion dollar market and a pretty cool one at that. These things rely on real-time processing, often of the camera, and do some heavy processing, needing both CPU and GPU. All while not trying to drain one's battery too much while running at 30 or 60 fps and providing a good user experience. This is challenging, and probably no way you're ever gonna make that with a non-native app. And it is also where cross-platform heterogeneous computing would shine.
RemindMe! August 25th, 2038 "Does it have reflection yet?"
I will be messaging you on [**2038-08-25 14:51:35 UTC**](http://www.wolframalpha.com/input/?i=2038-08-25 14:51:35 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/cpp/comments/8aalir/reflection_in_c_part_1_the_present/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/cpp/comments/8aalir/reflection_in_c_part_1_the_present/]%0A%0ARemindMe! August 25th, 2038 ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
It has to do with writing to PLC control registers. They're globally available, and control the machines. Fortunately the one I wrote to on accident was unused. They definitely need (to use?) permissions for registers, I agree.
Kinda, it's designed for thread safety: &gt; The class template `std::basic_osyncstream` is a convenience wrapper for `std::basic_syncbuf`. It provides a mechanism to synchronize threads writing to the same stream. http://en.cppreference.com/w/cpp/io/basic_osyncstream Explicit flushes via `std::endl` is not performed until the object is destroyed. The buffer is then flushed in a thread safe manner, so that the output will not be clobbered by other write operations also using `std::basic_osyncstream`. That's my understanding so far.
TBH, it's a rather specialized use case that breaks a lot of assumptions of `std::vector`. While I agree, it can be useful, I am totally fine with it not being in standard library. We really don't want another `std::vector&lt;bool&gt;`.
But who uses D ? 
Thanks you! How probably is C++ support in not so far future ? 
An optional whose "monostate" would instead contain a sufficiently unique value from a static PRNG would be interesting as a key.
That's the plan!
Agree - but you can mitigate this somewhat by having coding guidelines, and these should clearly state that `T*` is only to be used for non-owning pointers. `unique_ptr&lt;T&gt;` is for ownership. But agree it would be good to have something better for `T*` that conveys semantics.
You're on the right track here. C++ has problems with compatibility, dependencies, complexity, variable library quality, etc. We try to address these problems via the standards process, but it's not really the right tool. It's obviously not an easy problem.
Hmm.. I can't shed the feeling I just read a *"How can people eat lobster? They are awful!"* rant. There are quite some details I could take objection with - but it's not the details that make me wonder. 
Oh no, definitely not in std! But it would be nice to have it in boost or so. I wonder if it is possible to write such a thing without repeating the types. `forward_variant_vec&lt; variant&lt;A,B,bigC&gt; &gt;` would have to extract `A, B, bigC` from the template argument, generate tags, maybe worry about alignment on each `push_back` so that it can hand out references...
I'm not sure I buy the fundamental premise that a disengaged `optional` is the same thing as _not having an object at all_. A disengaged `optional` is still an object that has semantic meaning. A `vector` containing 3 `optional&lt;int&gt;`s, with two disengaged, is not isomorphic to a `vector&lt;int&gt;` with a single value.
&gt; since I wasn't alive yet, but if I remember correctly LOL - you've got one hell of a memory! I have meant no criticism of anyone on the committee or ever on the committee or anyone who has participated in the design and evolution of C++. It's an amazing achievement. It has been successful. In fact, I would argue that it is perhaps a victim of that success. The idea of a "standard" minimal set of library components is a good one and has been fundamental to the success of C and C++. The problem is that the these types of components have already been made (for the most part). The ones that are left aren't minimal anymore. How could one graphics library simultaneously served the needs of teaching, forms type developers, virtual reality developers, GPU developers, etc. Such a thing would be so complex as to be unusable. Should the committee undertake to design 5 graphics libraries - not possible. As I said, it's time to step back and toss out some new ideas. Since this topic has got my goat, I'm planning on throwing my own bomb into the crowd - hope it's fun. Stay tuned.
Alignment could be quite tricky if you wanted the maximum space savings, as it would depend on the order of elements of the types have different alignments. You can of course align everything on the maximum alignment of all contained types (+tag). It can be done with partial specialization but I think such a container would have to implement a lot of `variant` functionality anyway, so it would probably be quite messy. So a specialized collection which takes candidate type parameters directly is probably a better idea.
Well, you could also do `std::variant&lt;T1, T2, T3, std::monostate&gt;` to capture more types in the same union. `std::variant` specifically is a superset of the nullable type.
I think you'd be surprised.
"How to give a talk when you don't have anything new you feel people need to know" Reasons I don't go to conferences anymore.
I can't actually go to talks, I'll just fall asleep
`std::monostate` to me feels like a disgusting conclusion of the C++ idea of putting everything possible into `std::`.
It's not necessarily forcing lame talks. One of the things I find when I talk to people about their presentations is that they're often surprised that people found their work interesting. Even within a company, giving talks to different teams often gets a bunch of "oh... That's cool!" Reactions from people who don't spend time with their nose buried in it.
If the common case is the small `A` or `B` one, wasting up to 2x `bigC` space if it shows up and `alignof` says you are out of luck should be worth it. But, can you build a variant reference, i.e. `variant&lt;..&gt;&amp;`, without knowing the layout and abusing `reinterpret_cast`? I think not, and you need the `variant` as a parameter anyhow and for final internal storage anyhow.
Well, it could have been `std::tuple&lt;/**/&gt; `, the empty tuple. But that would be a bit worse. Unit turns out to be a useful standard type, and it's better to have only one. 
&gt; Because people would rather save typing 2 letters... Has nothing to do with terseness for me. For one, number literals have used prefixes since they've been invented, so adapting to a suffix form breaks existing convention. That may not seem like a big deal to some, but just wait until the old method and the new get combined in a single source file. Besides, the way you've written it makes it look like 010101 is an object that the "dec" or "hex", etc. method is being called on. But that's not what's happening here, and if you write something like 0bABCD, you get a compile error. So if I were to write ABCD.bin or something akin to that, to remain consistent, I should get a compile error. But it's common for methods (which a suffix would look like) to do conversions, so some people would look at ABCD.bin and think "did they mean ABCD.bin()", do they really mean "1010101111001101"? Does 01010101.hex == 55.hex, or does 01010101.hex = 0x01010101? You know the answer, I know the answer, and anyone reading familiar with the new convention would be aware after a moment's thought, but at first glance, it's not what you're expecting.
`to_chars` and `from_chars` aren't template functions, so non-`constexpr` allows them to be defined outside the header (i.e. as dynamically-linked library functions). Among other advantages, this allows them to be added to the C standard library in the future. I'm not familiar enough with the current state of modules, but I imagine they'll allow for separating the interface and implementation of `constexpr` functions.
`to_chars` and `from_chars` aren't template functions, so non-`constexpr` allows them to be defined outside the header (i.e. as dynamically-linked library functions). Among other advantages, this allows them to be added to the C standard library in the future. I'm not familiar enough with the current state of modules, but I imagine they'll allow for separating the interface and implementation of `constexpr` functions.
I saw a couple containers such as this before not that long ago (about the same time variant got into the standard). IRC, there was even a boost proposal. A lot of them were basically just a wrapper other a collection of vectors (single vector for each variant type).
a &amp;&amp; b will return a boolean value of either true, or false. On this result, you call the less-than operator, with arguments int and bool, which causes the right side to be converted to an integer. The C++ standard says: &gt; If the source type is bool, the value false is converted to zero and the value true is converted to one.
Agreed, it's an equivalent argument to "why use std::optional&lt;int&gt; to represent an int, just use an int or don't have the variable"
It's not that people don't want it. They just don't to want to learn a new language. I'm sure they would appreciate it in the process of learning, but most people those voice/vote matters already learned their mother tongue (to some extent) by the time they can voice their opinion.
Did you read what they said? What do you think your code is doing?
Did you transcribe someone's pseudocode or something? Like, it's clear what the intent is ('return n1 if it's smaller than n1 and n2', and so on), but that's not what &amp;&amp; does...
I can google everything about Haskell yet I have never written a single line of it. Would you hire me to work on a Haskell codebase? I can google everything about dentistry. Would you hire me to pull your teeth out?
this was an option in a question where we had to choose the right answer, and i was unsure of the meaning of (n1 &lt; (n2 &amp;&amp; n3)). i ran the code and it returned n3 almost every time, i think i understand it now, it is forced to return it if we enter e.g. 4, 5 and 6? 
The phrase `n2 &amp;&amp; n3` returns a value of type bool that is true iff both n2 and n3 are not zero. Your test basically tests 'is n1 zero, and are n2 and n3 non-zero?' What you are looking for is `n1 &lt; n2 &amp;&amp; n1 &lt; n3`. 
&amp;&amp; is an operator which, in this context, operates on bools. ints get automatically converted to bools in C++ if they're used where a bool should be used. If an int is 0 it's converted to false, otherwise it's converted to true. &lt; is an operator which, in this context, operates on ints. bools get automatically converted to ints in C++ if they're used where an int should be used. If a bool is false, it's converted to 0, if it's true, it's converted to 1. So, if n1 is 1, n2 is 2 and n3 is 3, the first if statement will get evaluated like: if((1) &lt; ((2) &amp;&amp; (3))) . if(1 &lt; (true &amp;&amp; true)) . if(1 &lt; (true)) . if(1 &lt; 1) . if(false)
I understood that part, thanks. If you use those numbers you will have 3 conditions which are false, but why does it return n3 on the last, is it just because it has to return something?
Notably, the code doesn't return a well-defined value at all if none of the three expression hold. In that case, literally anything could be returned... including possibly the correct result or "almost always `n3`" or so on. In this case, `n1` would always be returned if it is negative, and will be returned if it's zero and both `n2` and `n3` are non-zero, and never returned if it's positive. Similar case with `n2`. The value `n3` would only be returned ever if it were negative. If you're ever seeing `n3` be returned when it's non-zero, that's just pure "luck" thanks to the undefined behavior invoked for positive inputs.
Thanks, thats the answer i was looking for.
It tests whether you are willing to impose the death-penalty as only appropriate punishment on whoever wrote it.
it is possible for this function, as you have it written, to fall off the end without returning. The caller will see a garbage value as its result. The important thing to make explicit is that each operator is evaluated one at a time, something like `a &lt; b &lt; c` doesn't make any sense to c++, instead you need something like `a &lt; b &amp;&amp; b &lt; c`
There is also a small benchmark in the paper: http://fmtlib.net/Text%20Formatting.html#Benchmarks. {fmt} is usually faster than iostreams and printf except for floating-point formatting where it falls back on `s(n)printf)`, but there are no fundamental reason not to beat `printf` there too, just lack of time.
If you interview someone and they can answer trivia about Haskell, would you hire them to work on your Haskell codebase?
I know, thats why I said "technically". I just thought it was worth mentioning that fact seeming as it was on cpp reference. http://en.cppreference.com/w/cpp/algorithm/next_permutation
Sick intro 🎸🎸🎸
&gt; At most N/2 swaps which isn't the same as `O(n/2)`. In any case, a minor criticism.
I do find most of these apps are cancer and are not bringing anything interesting. AR sounds good, but you'll never get a decent experience on a phone.
You don't want to have the ABI of the STL set in stone though, that would cause loads of issues (I don't even want to think about what would have happened during the libstdc++ std::string pre-C++11 to C++11 and+ transition...) So basically you could not use the STL in the API. So there would be pretty much no point.
Also another example: https://godbolt.org/g/72XQVV
Wrong: Posix does not gives a shit about what is a syscall and what is not, and actually defines the API by simply using C. So for all practical purpose Unix is defined by a C api. golang basically does not target Unix, but merely some particular implementations of it (which is fine for tons of software).
I'm not certain how closely the gcc approach (either in internals or resultant assembly) mirrors this, but as a general thing if you are interested in recursion to iterative conversions, this article on continuations and trampolines is amazing: https://eli.thegreenplace.net/2017/on-recursion-continuations-and-trampolines/.
&gt; I don't understand your confusion. I'm sorry that I failed to clear things up for you. Let me try one more time. If this doesn't help then I'll leave it at that. Thanks for your answers anyways. --- &gt; They are bad interview questions. This sentence for itself is just a subjective statement. Ok, I get that you don't like the questions, but more valueable information does this not provide for me. &gt; What's hard to understand? The reasoning. Because it's "googleable" is not a valid reason for me. I'm confused of what point you want to make here. Therefore I asked because (based on upvotes) a lot of ppl agree with your reasoning and I'd like to understand why. 
When compiling it as C++ code instead of C it generates the exact same assembly. https://godbolt.org/g/qc4C59
well besides the fact that you pulled those numbers out of your ass, you can instantiate things purposefully to avoid the compile time cost of templates in header files. If you're ok with the compile times, or you work on projects small enough that it doesn't matter, great. If it works for you, it works for you. But don't try and downplay the cost of header only on compile times. Not everyone gets to work on small projects.
&gt; That may not seem like a big deal to some, but just wait until the old method and the new get combined in a single source file. Well obviously that's also why I say it's not going to happen. Just like Dvorak keyboards didn't became mainstream even if Qwerty and Azerty are not meant to be effective. &gt; Besides, the way you've written it makes it look like 010101 is an object that the "dec" or "hex", etc. method is being called on Do you think you're calling .f function when you write a float literal? But it doesn't really matter how the syntax is. You could technically make a parser that parse `hex(number)` as a number literal. People would think it's a function but it would be a compile time directive like sizeof(). The only problem I see with my example is that to work, it would require the number literal to start with a number as `b1b1.hex` wouldn't work but `0b1b1.hex` would work. As far as I know, c++ doesn't allow symbol name to start with a number. So there shouldn't be a confusion that you're calling an object because no variable can start with a number. But having compile directive like hex(), bin(), etc... make it even more clear and should be easy to parse except that could be an issue with existing software with methods called like that.... 
Good !! &gt;/Zc:__cplusplus
Cute.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Becauce of C++ object destructors.. (probably just simple isCpp check)
Are you sure? Try compiling this: if (true and false) ; There's your standards compliance :P
I was wrong it generates the same output as the C version. Godot reset the code box when changing language and I didn't notice. What I did notice was when lowering the GCC optimization level from -O3 to -O2 the assembly was way smaller. and when setting both to -Os, GCC now gives the best (least) output.
I'm not 100% sure it would be interesting to fit a general purpose derecursing algo in a compiler (complete with custom management of a stack if it is really needed), and I'm not sure this is what is done here: however I *think* the compiler did some inlining, prooved some properties, and reduced the computation to a single recursive call. Nice! (although maybe the generated code could be shorter? I'm too lazy to study it in details)
Does anybody know if there was any work to bring this optimization to LLVM? I cannot imagine that nobody thought about it :D
The answer is yes, and no.
Well it isn't totally complete but it is pretty good so far. https://www.youtube.com/watch?v=18c3MTX0PK0&amp;list=PLlrATfBNZ98dudnM48yfGUldqGD0S4FFb 
If you read the whole thread, the "googleable" part is actually explained. You keep quoting "googleable" over and over again, without reference to the other things I have said relating to the word, does not help. Why don't you quote the other things I said and ask about those?
maybe someone used `#if __cplusplus == 199711L` to detect MSVC in the past? 
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8b33hz/complete_c_video_guides/dx3nfwl/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Only in a programming competition once. The problem literally boiled down to "What's the next permutation" and I knew the call existed. 
**Company: [AutoX](https://www.autox.ai/jobs)** **Type:** [Full Time] **Description:** AutoX’s disruptive camera-first AI brings self-driving cars out of the lab and into the real world. We believe that autonomous driving should not be a luxury, and we are making it universally available to everyone. We needs great C++ coders to help put all advanced algorithms into real practice for our **autonomous driving platform**; develop scalable frameworks to support many types of vehicles and configurations; design efficient components and optimize existing software for limited compute platforms; collaborate with other engineers to implement, integrate, and deploy **robotic perception, mapping, localization, and sensor calibration software**... **Location:** San Jose, California, USA **Remote:** NO **Visa Sponsorship:** YES we sponsor or transfer **Technologies:** C++ * For system&amp;tools: Operating Systems, Databases, Concurrency, Linux Kernel, Compilers, Distributed Systems * For perception: algorithms, data structures and math in general * For mapping: mapping experiences * Robotics **Contact:** Apply through our job page or email me at **fyang@autox.ai**
Yes, for brute force. There was probably a smarter way to do it but this made it simple and was fast enough as it was reconfiguring a small graph. 
That's my suspicion although I have not run them through their paces on big data. Currently using a sentinel value.
Yes, but not when called in that order since deletion on nulled memory is a co-op Also I'm pretty sure you can't call a delete[] on something not allocated by new[]
Looking at http://en.cppreference.com/w/cpp/compiler_support and adding the updates from above, it looks like MSVC is C++17 complete with respect to both compiler and standard library except for std::filesystem and elementary string conversions modulo bugs. Kudos to the MSVC for all their hard work. I remember just a few years ago when it seemed like MSVC was hopelessly behind Clang and GCC. In a few short years, the situation has dramatically improved and MSVC has a chance of being the first released compiler to completely support C++17 language and library!
&gt; except for std::filesystem and elementary string conversions modulo bugs Both of those are in 15.7, too; I assume the implementation is as-yet partial or the release notes would have mentioned them.
That ship sailed when VS2010 added lambdas without a guard flag.
Besides (I assuming) much easier development, what is their reasoning for that? Seems like everyone else supports it all.
Deleting after nulling will have no effect on the allocated memory. What you are doing is just causing a memory leak. Consider the following order instead: T* p = new T; delete p; p = nullptr;
But... why?
I did once, in a programming competition. The problem was pretty much checking if a condition was true for any permutation of a short list of numbers
That order gives me an error since I use the cursor variable as an iterator that points to the current position what the destructor is trying to do is the following: Node&lt;T&gt;* temp_next = m_curr-&gt;m_next; delete m_curr; m_curr = temp_next; 
Which pointer are you actually wanting to null in this code?
The following code is somewhat nonsensical. Bag&lt;T&gt;* cursor = new Bag&lt;T&gt;(); cursor = nullptr; // Won't free your memory. delete[] cursor; // Can't use array delete unless you use array new. As noted above, you can't null it before deleting it because you'll have a memory leak. Bag&lt;T&gt;* cursor = new Bag&lt;T&gt;(); delete cursor; cursor = nullptr; // so cursor doesn't dangle. You have likely found a bug in your memory management code. It sounds like you need to re-examine the correct lifetime of *cursor*.
I want to delete the current node, which is stored in m_curr. However to iterate to the next node one needs the current node to point to it, but if we delete it we can't know where the next node is, so temp_next is created. After deleting the current node that m_curr is pointing to, it should point to the next node stored in temp_next.
The reason you are getting an error is due to code that you have not posted. * Deleting nullptr is fine * Calling delete[] on something not allocated by new[] is not fine. * Leaking memory is not fine (by losing reference to allocated memory before freeing it, you leak memory) Your original code you posted leaks memory. 
Well there's a macro, so it was already not good code /s
I updated the op with more information regarding to the destructor the private variables, and node class that might help. 
I updated the op with more information regarding to the destructor the private variables, and node class that might help. 
Because nobody cares about C++03 now and there are very few things you are likely to miss when upgrading to newer versions. Also maintaining old versions takes time.
The destructor is freeing memory and afterwards, the object will be dead. Your code should just iterate over each Node&lt;T&gt; pointer and delete it. This doesn't really make sense at all: Node&lt;T&gt;* m_curr = temp_next; I think you meant to write: m_curr = temp_next;
Not quite. I've used variants of `next_permutation` occasionally. I often find that I need combinations, as opposed to permutations, or that I need some subset of permutations, such as reversible permutations. For example, given a bunch of cities, what is the best route to visit all of them. Unless the cities are connected by one-way roads, the best route won't matter if you travel it in reverse. So if you analyze a permutation, it is a waste of time of to analyze the reverse of it. Or I need to consider the permutations of N items R at a time (where R &lt; N). I've got 40 cities, but I can only afford to visit 5. Which 5 should I visit and in what order to maximize the bang for my budget? Oh, and I can visit them in the reverse order without cost, so that should be a list of reversible permutations of 40 cities 5 at a time. Considering a list of N items permuted N at a time is a very special case. Often even order doesn't matter and I need to think about _combinations_ of N things R at a time, not permutations. I've got 100 products, each with their own costs and profit. Some products share costs with other products (e.g. I can get bulk prices on raw materials if I buy in enough volume). But I've only got 10 production lines. Which 10 products should I produce? [Combinations and Permutations](https://howardhinnant.github.io/combinations/combinations.html)
That gives me a read access violation exception though. The function visual studios points to when giving me this error is in xutility though in the function: inline void _Container_base12::_Orphan_all() _NOEXCEPT and says this was 0x42702EC0.
If it's crashing when you execute: delete m_curr; Then you need to take a coffee or snack break for an hour and come back to your code. Go over it line by line and see what's happening. Are you a student? If so, I think you're failing to correctly reason about object lifetimes. In your case, it's probably not a super hard problem, but object lifetimes can be tricky. It would really help if you could post all the code.
Who would the users be for it? Supporting current consumers is the big reason why compiler writers have those flags. By maintaining backwards compatiblity you make it easier for users to use the latest version. However new users don't typically need such things and should be encouraged to use the latest settings.
I am indeed a student. What do you mean that something else owns the object? And how can I undo ownership?
The solution is likely to pass around thin interfaces instead. Something that won't change, but can interact with the data regardless of its form. Like views or such.
Filesystem is finished for 15.7 RTW (unsure which Preview will have the final version). charconv will be partial for 15.7 RTW: integer only. I am working on floating-point, no ETA yet.
This should be present in Visual Studio 2017 "15.7" Preview 3. https://blogs.msdn.microsoft.com/vcblog/2018/04/09/msvc-now-correctly-reports-__cplusplus/
We're not actively lying to you guys anymore! Let's celebrate!
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8b3wac/nulling_out_a_pointer_before_deleting_it/dx4065y/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It’s useful for exhaustive testing of STL algorithms. Why bother thinking of interesting cases when you can just test all of them? (Obviously, for small sizes only.)
Yep. Removed.
It’s the opposite, from the couple of build breaks that I saw. Code guarded for __cplusplus being a modern value, that MSVC doesn’t accept (either due to an MSVC bug, or a user bug that MSVC notices - even as innocuous as forgetting to include a header).
Because they didn't add the flags until one of the updates for VS2015. https://blogs.msdn.microsoft.com/vcblog/2016/06/07/standards-version-switches-in-the-compiler/ It's my opinion that they probably figured it was easier to add new features with flag conformance going forward but it would be too much work for little gain to go back and patch it in to the other features that were preexisting. This would also include resurrecting things which had been removed and then having to maintain that code as well as any new features. That's just my guess though but, if it was me, I wouldn't want to have to maintain potentially 5 different versions of something at the same time in the same codebase. That way lies madness.
Technically they never supported c++98 until recently since they didn't have two phase lookup.
And I've heard that CPU profiling has been silently disabled for Windows 7, which is why I'm not updating VS anymore.
And my bug: https://developercommunity.visualstudio.com/content/problem/102721/missing-formatting-option-for-pointers-and-referen.html
Mrmph, details? Reference?
That would be my guess too.
Yes, and we've been quite open about that fact, haven't we? 
looks like this isn't yet fixed and will be looked at for 15.8. 
this one is still open. there are some performance challenges associated with fixing it from the first investigation.
The bug is still open.
15.7p3 was feature complete except for intellisense where we just checked in CTAD support today. p4 has mostly bug fixes.
It also makes it easier to find function definitions: grep "auto functionName" (Inspired by https://twitter.com/nnethercote/status/981995009174978560 )
+1, this isn't recursion to iterative, it's just unrolling the recursion a bit.
Is it actually an optimization?
We already have `void`!
And they never will, because they never supported export (which eventually was removed IIRC in C++11).
Yeah, even compiler warns you about dangers of this code (which is kinda good news too!): return n + foo(--n);
Mostly for testing. It's simpler to test all versions of some input and have the computer generate it for you, than having to hard code the permutations yourself. I used it a lot to test some geometry transformations similiar. Basically I had to generate surfaces and edges for a 3d boolean grid, with certain limitations on winding order, etc. I could check all of those cases with all permutations of a 3^3 cube.
&gt; This topic has been beaten to death around here: default constructible is typically a necessity for moving, for types that are non-trivial Do you mind explaining why? Thanks.
Code that was never tested for contemporary value of __cplusplus - i.e. user bug. But it was extensive.
Worked at Bloomberg for 3 years until ~6 months ago. If you like C++03 and don't mind working with ancient compilers and platforms, then this job might be for you. Otherwise, one main reason I left was the considerable lack of interest in upgrading any part of the tooling.
"&lt;insert age-old pattern here&gt; now considered bad" "My 100 line program didn't need 'if' statements, and you don't either" "C++ isn't functional. Here's how to pretend it is"
I disagree with the title (pedantically), but agree with the general content. My reason is: testing. Quite frequently, my tests comprise of creating an object in a particular state, applying an operation to it, and verifying the result. This frequently takes the form of an equality comparison. For example, using GTest: ASSERT_EQ(expected_result, result); In the case of failure, this (and other unit test libraries, e.g. cppunit), prefer to use the streaming operator to output the content of these two objects. Thus, for maximum utility, my recommendation is that the streaming operators output human-readable _debug_ output, rather than human-readable _user_ output, which is what the article warns against.
Let's say you do this: class A { int val = 0; } class B { A * a = nullptr; B() { a = new A(); } ~B() { delete a; a = nullptr; } A * GetA(){ return a; } } int main() { B * b = new B(); A * a = b.GetA(); delete a; // b owns a, so what happens when b's destructor runs? // The program crashes because a will be deleted twice. // a is deleted once via 'delete a' and another time when b's destructor runs. } So you want this code instead: int main() { B * b = new B(); A * a = b.GetA(); // b owns a, so what happens when b's destructor runs? // a is deleted. // Program exits cleanly. } You often say 'owns' when you mean that one object is responsible for the destruction of another object. In this example, object a owns object b. &lt;&lt; And how can I undo ownership? This _really_ depends. Sometimes you just have to change code in your main function. Sometimes you have to change the classes. It really depends on what you're doing. Keep on keeping on!
Unrelated, but awesome: clang and gcc manage to optimize this down to single bswap instruction [https://godbolt.org/#g:!((g:!((g:!((h:codeEditor,i:(j:1,lang:c%2B%2B,source:'%23include%3Ciostream%3E%0A%0A%0A%0Auint64_t+swap_bytes(uint64_t+x)+%7B%0A++++return+(x+%26+0xFF00000000000000)+%3E%3E+070+%7C%0A+++++++++++(x+%26+0x00FF000000000000)+%3E%3E+050+%7C%0A+++++++++++(x+%26+0x0000FF0000000000)+%3E%3E+030+%7C%0A+++++++++++(x+%26+0x000000FF00000000)+%3E%3E+010+%7C%0A+++++++++++(x+%26+0x00000000FF000000)+%3C%3C+010+%7C%0A+++++++++++(x+%26+0x0000000000FF0000)+%3C%3C+030+%7C%0A+++++++++++(x+%26+0x000000000000FF00)+%3C%3C+050+%7C%0A+++++++++++(x+%26+0x00000000000000FF)+%3C%3C+070%3B%0A%7D'),l:'5',n:'0',o:'C%2B%2B+source+%231',t:'0')),k:36.27412896432192,l:'4',n:'0',o:'',s:0,t:'0'),(g:!((h:compiler,i:(compiler:g73,filters:(b:'0',binary:'1',commentOnly:'0',demangle:'0',directives:'0',execute:'1',intel:'0',trim:'0'),lang:c%2B%2B,libs:!(),options:'-std%3Dc%2B%2B17+-O2+-I/opt/compiler-explorer/libs/rangesv3/trunk/include',source:1),l:'5',n:'0',o:'x86-64+gcc+7.3+(Editor+%231,+Compiler+%231)+C%2B%2B',t:'0')),k:26.695246423959855,l:'4',n:'0',o:'',s:0,t:'0'),(g:!((h:output,i:(compiler:1,editor:1,wrap:'1'),l:'5',n:'0',o:'%231+with+x86-64+gcc+7.3',t:'0')),k:37.03062461171821,l:'4',n:'0',o:'',s:0,t:'0')),l:'2',n:'0',o:'',t:'0')),version:4](godbolt)
Oh yeah, and I think we merged constexpr char_traits for P4.
Thanks for the explanation. So the problem is that people switched on __cplusplus and - so far - only switched/tested for windows on the c++98 branch because the other wouldn't be touched by the msvc compiler anyway. I guess that makes sense. Are you keeping a list of breaking changes you intend to introduce on the next major VS release (like different default values for compiler switches). It might and I emphasis "might" help with adoption if people that write code now know what changes they should prepare for behavior
&gt; I don’t know what to talk about. Then don't talk. Or you'll waste not only your time but also a time of a lot of other people. And if you have something to talk about, better write it as an article.
Don't gcc/clang define that macro to the same value in c++98 mode?
It's not about the talk itself but networking and finding new gigs/clients.
`while (!is_sorted(f, l)) next_permutation(f, l);`
Finally, a sensible 2D graphics standard proposal.
If you have tables, I might go with exterior optionals; optionals where their engaged/empty state is stored outside of the object. I mean, after proving the size is a problem with a normal optional (KISS). That would permit not having the extra member cost there at the cost of simplicity/cache locality. If a large table, you would probably want to go with a sparse list if unengaged is a common case; that can slow down access when most everything is engaged, but massively reduce costs when almost nothing is. There ia going to be an infinite castle of optimizations here. Start with std optional and start improving after you get it functional and prove which costs are worth spending effort on. I would probably even keep the simple optional based version around to validate the more complex implementatons against.
Will filesystem work for UPW C++/CX too?
Particularly given std::image would have to have multiple channels per pixel.
Map of vectors usually works better for me because I end up caring about things like insertion order. Aside: ocaml has an interesting hash table type designed to support lexically scoped symbol tables and shadowing. If you add a key that's already present, it hides the previous value until you delete it. A map of stacks, basically.
Yeah I tried telling that to the people writing all of these "thank you for your job application" e-mails but they're all set to noreply.
https://godbolt.org/g/eDLjUD
Genius! :-D
Unreal's C++ is not the way to learn C++, IMO.
Maybe you could specify that you have experience with certain boost libraries, listing them explicitly. If you do need a portfolio, then I guess you could choose the libraries that you consider important and then use them beyond their tutorial. With the banking industry, I see they ask about boost IO or async, so you can try to target the field of your interest.
vector of bool? Eww...
`void` is the zero type. There are no objects in the type void, where there's exactly one object in the type `std::monostate`. Unless you're one of the regular void people who claim that `void x;` means something. 
You cannot have an instance of `void`; you _must_ have an instance of unit.
I've used std::next_permutation to check the validity of sorting networks thanks to the zero-one principle: a sorting network for N inputs works if it can work every possible combination of 0 and 1 of size N, so I basically used it for bruteforce checking.
Maybe so, but you still need to narrow down which set of libraries to make a project with; "all of them" is obviously not tenable.
Hmmm for the vector version you could also write: } bool isRegistered(EventReceiver const&amp; queriedReceiver) const { return std::any_of(begin(receiversRegistry_), end(receiversRegistry_), [&amp;queriedReceiver](const auto&amp; receiverEntry) { auto hasQueriedReceiver = [&amp;queriedReceiver](auto const&amp; receiver) { return receiver == &amp;queriedReceiver; }; return std::any_of(begin(receiverEntry.second), end(receiverEntry.second), hasQueriedReceiver); }); }
Because n!, but I like your style.
As of C++11, multimap cares about order of insertion too: http://en.cppreference.com/w/cpp/container/multimap/equal_range &gt; Since insert always inserts at the upper bound, the order of equivalent elements in the equal range is the order of insertion.
&gt; There is nothing closer to the metal you can only do in C except stack allocated arrays of variable sizes. or, uh, restrict semantics I guess. But I very much doubt there's any unix API dependent on that
That's 14 occurrences of "receive", can you feel the semantic satiation yet?
I just checked. Yup it does. I don't understand lol.
Did you try it with n1 = -1, n2 = 0 and n3 = 0 ? What did it return ?
Please don't post your promotions into /cpp. No one cares.
I edit this page http://en.cppreference.com/w/cpp/compiler_support, MSVC support std::filesystem now.
https://www.reddit.com/r/VisualStudio/comments/81djsl/upcoming_vs_2017_156_to_completely_disable_cpu/ I'll be checking this in a VM at some point.
Those emails are automated, so yeah, they probably aren't getting the message.
Good one.
&gt; You keep quoting "googleable" over and over again, without reference to the other things I have said relating to the word, does not help. The wishy -washy answers I receive do help neither. I'm sorry that I failed to lead the discussion anywhere, but I see no more value for me here. Thanks for your time and patience still.
I feel you there, I always fall asleep even when I find the talk interesting :/
Do a GSOC Boost project and people won't ask you anymore :p
It's called permutation sorting and it's terrible :p
interface differences aside, there are some memory management considerations too. while vectors will need to allocate less often, they will only grow in capacity. in bursty workloads, this could end up wasting a lot of memory without some form of garbage collection
Yoo Brother! West end const is the way to go. There is only one correct way to specify const and this is west const. I suspect every codebase which has east const. PS: This is a great example to show, it's best to give not so much syntactic possibilities. Otherwise people will choose a wrong style (east const).
Thanks, I wasn't aware of that impact from Meltdown--I've been focused more on Spectre V1. It makes sense. I'd think the CPU profiling would be broken at the OS level. Any version of VS (or any profiler) would have the same impact.
We support `export` now! We just need to get that Modules TS into the Standard!
**Company:** [FlightSafety Simulation](http://www.flightsafety.com/fs_simulation_landing.php) **Type:** Full Time **Description:** FlightSafety Simulation (FSS) develops flight simulation training devices from classroom desktops to fully immersive simulators with motion, visual systems, and interactive networked capabilities. We are looking for experienced C++ developers to contribute to our cross-platform frameworks and to build tools for other developers and simulator support personnel. Our group deals with many of the non-aircraft components of a simulator such as selection of development tools, integration of 3rd-party solutions, and publication/consumption of data for distributed training. Tasks may vary from creating virtual cockpit GUIs and CPU instruction set simulators to implementing the C++ Networking Technical Specification. While C++ is the primary programming language, multi-language programming with Fortran, Ada, Jovial, C#, Lua, or Assembly for Intel and Motorola may occasionally be needed. **Location:** Broken Arrow, Oklahoma (A suburb of Tulsa) **Remote:** No **Visa Sponsorship:** No **Technologies:** - New development: C++17/2a. Stable development: C++11/14. Long-term maintenance: C++98/03. - User- and kernel-mode programming with almost no limitations of the use of C++. - Driver development for Intel NICs, FireWire (IEEE 1394), CAN bus, and reflective memory. - OpenGL, boost, google test, DirectX, clang, gcc, MSVC, clang-tidy, Qt **Contact:** Please apply here: [Requisition 7007](https://careers.flightsafety.com/job/Broken-Arrow-Engineer-Okla-74012/433619600/) and PM me. 
Do something with boost.beast. Some micro service, that uses serialization to store/cache the data.
I know it's entirely besides the point, but what sort of event system declares "EventReceiver::reactTo(Event const&amp;) *const*"??
No, you "got fucked" when compiler implementer decided to add `constexpr` when the standard said they shall not.
I don't know off the top of my head, but I assume it would be fairly straightforward to implement std::multimap in terms of a map-of-vectors, so a suitable implementation probably never performs much worse. &gt; initially I'd always prefer the map of vectors If you're given no more information than that you need something that supports the operations of a multimap, and you always prefer a map of vectors, then when would you ever use std::multimap? Why do we even have that class? IMO when there's a well-defined data structure that matches what you need, you should start there instead of trying to cobble one together out of other structures. map-of-vectors is reasonably easy to understand, but every client needs to keep the distinction in mind for almost all operations (hope you were expecting size() to be the number of keys, not the number of elements; hope you don't want any other STL features, like support for generic iteration algorithms). If you try to encapsulate the structure, you'll just be back to making multimap, and the standard one has a more complete error-proof API (and possibly performance improvements). It's easier for a C++ novice to figure out how to use a map-of-vectors without looking up anything they don't already know, but I wouldn't say it's "easier to understand at a glance" when one of these interfaces is in the STL, and the other is an ad-hoc combination that doesn't enforce invariants (so I can't trust that other clients actually use it as intended). Similarly, "the reader will often have to look up" all kinds of things when they program; I've been known to whine about needing to learn new things when I could've figured something sufficient on my own, but... this is the STL. It's *part of the language.* If there's a better way to do things in there, "the API is less familiar" isn't much of an excuse, and it might be more familiar if you stopped avoiding it.
I've used it for stress testing multi-threaded code, launching the various contending operations in all permutations to help reduce bias. 
Probably no guarantee the vectors need to allocate less often, too, because under the hood the multimap implementation can do all the same kinds of amortized relocation (and anything else the vectors would be relying on, like only-growing), *and* a general-purpose multimap implementation might do that by managing a pool for the entire collection rather than one per-key, so you can pretty much count on utilizing the new block of memory as the collection grows (instead of potentially extending one of the vectors only to find that every subsequent insertion is for a different key and still requires more allocations). Of course it depends on the distribution of values and set of operations you're optimizing for. I could easily imagine the map-of-vectors making a lot of allocations at the start to get a reasonable buffer for each key, and then subsequently handling requests almost exclusively for some popular subset of the keys. In that case, the few subsequent insertions to unpopular keys are unlikely to require an allocation, but it's only because you were already wasting space on those keys, and few applications will want to optimize for the rare case anyways. That's a really good point about pegging to the high-water mark in bursty use, though. Now I'll always be wary of maps-to-vectors.
Just list anything that was standardised already... done.
Here is the relevant [link to the developer community post](https://developercommunity.visualstudio.com/content/problem/177958/starting-the-profiler-leads-to-computer-restart-af.html). As far as I understand, the mitigations work differently on Windows 10 or the CPU sampling works differently on Windows 10, which is why the sampling works there. There seems to be a different mode (Instrumentation), which should still work, but I couldn't figure out how to attach to a running program in that mode, so I just disabled the patch.
Yes, all VS versions are affected, but 15.6 disabled sampling on Windows 7, so at least you don't accidentally crash your PC, but older versions are still affected and it makes the profiling experience more limited on Windows 7. Here is the [microsoft developer community post for reference, if you are interested.](https://developercommunity.visualstudio.com/content/problem/177958/starting-the-profiler-leads-to-computer-restart-af.html). Sadly there are only workarounds suggested and no real fixes, but upgrading to Windows 10 or sticking with older VS versions and disabling the mitigations.
Didn't read the article (yet), but what if you spawn a notification which is received by multiple listeners? Then one listener could change the event item, the second listener would receive modified event. If you want to communicate some message form listeners back to event sender you need to be very careful not to overwrite one listener's message by another listener's. Use something like `vector` or set bit in a bit field (and deny clearing the bit).
Was the app to help you mom cheat or to help you cheat against your mom?
Yes, I've seen that post. `Instrumentation` is [PGO](https://msdn.microsoft.com/en-us/library/dn457343.aspx) in 'Whole Program Optimisation'. Never used it, though.
Thank you, that makes a lot of sense. But it seems like PGO is a bit cumbersome to use with DLL's, but I'll keep it in mind, for when I may need it in the future.
Thanks, yes, this bug makes perfect sense. Upgrading to Windows 10 is probably the best short-term fix. It looks like Allen's team is working on a different profiler implementation strategy. 
Is multimap allowed to do relocations?
Oh, that sounds good. I still have to profile applications on Windows 7, because it is an OS we still have to support, so I would really appreciate a different solution!
no. iterators into maps are guaranteed to remain valid on insert and delete, and so you cannot just move the nodes around.
Well, apparently they're ["typically implemented as binary search trees"](http://www.cplusplus.com/reference/map/multimap/), so that's probably not what they would do in practice. I skimmed the API and didn't see anything that was incompatible with an underlying map-of-vectors implementation, though, and FWIW the insert() operation is amortized-constant if you provide a hint that preserves the sort order (i.e., a valid insertion point). Aside from the introductory prose, I also didn't see anything different in the docs for vector to suggest that relocation was any *more* acceptable there. tbf I'm rusty on cpp, trying to come back after a few years off, so I'm not exactly sure how to answer this conclusively -- but it seems to me that if there's nothing special in the docs for vector, then it's *probably* allowed in general?
OK, I'm a bit rusty on cpp and trying to come back after a few years off, but -- does this actually imply that the underlying data can never be relocated, or just that you have to devise a way to do it without violating the iterator contract? Iterators were never required to be raw pointers to the underlying data anyways.
you need (a) the container to keep track of all iterators and (b) insert and delete would no longer be constant time operations. (a) is just wasteful, (b) is wasteful and contradicting the documented guarantee if you want realloc, just copy the whole map and destroy the original.
Yes, used it to implement k-combinations and k-permutation.
&gt; I don't know off the top of my head, but I assume it would be fairly straightforward to implement `std::multimap` in terms of a map-of-vectors, so a suitable implementation probably never performs much worse. Oh my sweet summer child ;) There are 2 hurdles: 1. In a `multimap`, the key or value may not be copyable or movable: - If you need to `insert` or `push_back` in a `vector` you need to copy or move its values. - A `multimap` exposes `std::pair&lt;K const, V&gt;` as its value type, which requires copying the `K` (1 for the key in `map`, one for the value in `vector`). 2. A `multimap` guarantees that its elements are stable in memory; that is, you can take a reference to a value (or an iterator) and as long as you do not remove this value from the container both reference and iterator remain valid. The second point is non-trivial, the first point seems like a deal-breaker to me.
Noted.
Last time I checked, `Boost.Multiprecision` used a fairly basic multiplication algorithm, if this is still the case my suggestion would be to add support for something slightly fancier, e.g. Karatsuba multiplication. This has the advantage of being fairly hands-on, demonstrating algorithmit proficiency, and due to being in boost it would probably also have its fair share of advanced template-metaprogramming involved.
It would probably be even cleaner to use std::find for the inner loop, that would reduce the receiverness of the code.
What about unordered_map?
&gt; first point seems like a deal-breaker to me Yeah, go figure, I tried to apply intuition to the STL and didn't remember all of the bits to check -- now that you mention it, multimap doesn't even rely on the key type to determine comparison behavior! Of course you don't necessarily need to know all this stuff if you're just trying to pick a suitable container and not adapt between STL APIs -- and personally, regardless of my choice, I'd still prefer to encapsulate it as a "multimap" (even if not an std:: one). It's a tougher call which to reach for first when the tradeoffs point in opposite directions -- std::multimap is a broader interface in terms of the requirements on the template arguments, but narrower if any client relies on the element stability. I try to make the choice based on which will be harder to replace (since optimization can always come later), but I'll admit that might not be so clear in this case. In fact, that almost suggests I'd prefer the map-of-vectors; my compiler will tell me if I switch containers and now the template args are invalid, but it won't tell me if I switch and my clients are still using invalidated iterators.
It should, but let us know if anything doesn't work.
Something that uses boost::asio would interest me. Good luck!
I think it will not happen. OS and C programmers are a significant grouping and doing this would effectively shut other languages out of the API because of name mangling and binary compatibility issues among other things. The flame war that would ensue if such a thing was adopted by some system like Linux would be so loud and brutal that it would make the systemd, "vi vs emacs" and "tabs vs spaces" debates seem like small skirmishes compared to a world war. Might be interesting to watch from the sidelines but no fun for anyone involved. But I think there are not a lot of technical barriers to creating a C++ library (and binary library standard) that provides a POSIX/UNIX like API based around modern C++ while calling the Syscall interface of various Operating Systems directly. I think you'd find that the syscall interface matches POSIX pretty well, but maybe the concept of resource safety through RAII in Unix APIs is incentive enough to create something like this. It might even remove some overhead in some cases. In theory if such a library was portable enough it might even replace some of the C leftovers in people's code across platforms. It could be rather useful in fact for including having networking code with exception safety and the like at a low level. But I am probably forgetting something that prevents this... It has been a long day of debugging already :)
"Better" without context is meaningless. From a performance perspective anything called a map in std:: is required to be bad.
Oh, yes. My bad.
What exactly prevents STL maps from being performant? Does that also apply to the unordered variants?
cpp (multi)map is just a tree. unordered_* versions however are implemented using hashes.
The short version is that basically if you are doing a non-trivial move construction, then after the move construction you have two objects: the moved-to object and the moved-from object: SomeClass a(...); // call some constructor of SomeClass SomeClass b(std::move(a)); The question is, what is the state of `a` after this code runs? If `SomeClass` is trivial (like a double, int, pod type, etc) then it's just the same state as `b` and moving is the same as copying. For something like a `string` or `vector` though, that would defeat the whole point of moves. So in this case where `a` isn't a copy of `b`, `a` should be a legitimate copy of `SomeClass`, but at the same time there isn't really any data (in the general case) to populate this state. So logically a's state should be an argument-less constructor, which is the same as the default constructor. Sometimes people work around this by essentially making the moved-from state a special toxic state not accessible any other way. This has its own major downsides and the standard library doesn't ever make use of it (AFAIK). There are exceptions to this, particularly with proxying objects. Actually, optional is exactly an example of this: a moved from optional isn't necessarily in the default constructed optional state, but rather if it contained a value then it still contains a value, but that value itself is in the moved-from state. Similar statement is true for variant. But this doesn't work for most classes. In particular one of my perpetual annoyances with C++ is that IMHO there is no good solution for "business logic" classes. Usually I'd rather avoid a default constructor, but I still want to have a move constructor. It's just a bit of a pain.
they're (realistically) required to have linked lists internally and linked lists are about the worst data structure imaginable from a memory access perspective. You cannot begin to load the next node until the current node has finished. Unordered maps are required to expose 'buckets" in their API which are a linked list.
Like others say, it's handy for brute forcing [verbal arithmetic](https://en.wikipedia.org/wiki/Verbal_arithmetic) puzzles. Here it is wrapped as an iterator, unpacking with structured binding... auto val = []&lt;size_t N&gt;(int(&amp;&amp;digits)[N]) { int ret{}; for (auto digit : digits) ret = ret*10 + digit; return ret; }; for (auto&amp; [s,e,n,d,m,o,r,y] : permutations&lt;8&gt;({0,1,2,3,4,5,6,7,8,9})) { if (m &amp;&amp; s) { int send=val({s,e,n,d}), more=val({m,o,r,e}), money=val({m,o,n,e,y}); if (send + more == money) { std::cout &lt;&lt; "send" "+" "more" "=" "money" &lt;&lt; '\n'; std::cout &lt;&lt; send &lt;&lt; "+" &lt;&lt; more &lt;&lt; "=" &lt;&lt; money &lt;&lt; std::endl; } } } 
SortedVector
What is even the purpose of exposing the implementation details that are these bucket? It's really sad for a (supposedly) performance-oriented language like C++ to have such huge pitfalls in its standard library. I know you can just use an alternative implementation but you have to know about it in the first place, and it's hard to imagine just how much performance has been wasted on having these substandard implementations.
probably some vendor early in the process who had a bad implementation and it became the standard... but who knows. The point is that you have to be selective about your data structures if they're in hot parts of your code.
Hi everyone. I created this library over the last few months with a friend to see how far we could stretch the use of constexpr. At this point I feel it is in a usable state and wanted to share--any feedback or contributions would be greatly appreciated!
I'm talking about address stability of the elements. Some containers are not allowed to move their elements from one address to another (re.g. std::list)
&gt;why not have map and ordered_map to at least get the one that's slightly better as the "default" Isn't that just the result of `unordered_map` being introduced later (in c++11 iirc)? Of course then the question is why did they only have the ordered variant before that.
 auto receivers = getReceivers(event); for (auto &amp; receiver : receivers) receiver-&gt;reactTo(event); Doesn't this just read better? As a _bonus_ (not a reason, the reason was readability) I also now don't care as much about the internal structure. `getReceivers` either does the equal_range thing (and converts it to something that does begin/end) or it returns the vector. You can have abstraction _within_ a class. It doesn't need to only be at the class boundary. I find the above code better than trying to flatten the nested structure. I feel that the event registration, as described, is inherently a nested structure, and code that "flattens" it by using a multimap (or otherwise) isn't better. Also, note that the code is optimized for for reacting to events (which makes sense), and pessimized for Receiver lookup (probably fine - until it isn't). Some day the code may have multiple maps (ie Event to Listener, and then Listener to Event, etc). Maybe the map of vectors or multimap become a boost::multi_index. Or something else. Still the emit code doesn't change. (Again, that is just a bonus beyond readability.) 
Maybe all the stuff inside is declared mutable.
I am very excited for this. Proper hot reloading will increase my productivity for sure. 
This looks SUPER cool and exciting. One gripe I have is that you say it's "Project Setup Agnostic" despite the fact that it only supports MSVC. I get what you're saying, and it's an important thing to say, but I really think you should mention this requirement much higher up on the page.
Why would they need to move them though? Each such container is already defined as a structure that stores it's elements in the dedicated "nodes". I.e. address stability comes with other implementation requirements.
Damn, I have to say that for one, you have good reason to prefer 0o and you probably weren't the first. Strangely I came across a bug with octal literal while "fixing" some code from python2 to python3... Guess what. Python3 deprecated the 0700 syntax and now it's 0o700 that is valid. So I'd say as other languages seems to be making the move to Oo... So the least I can say is for the sake of simplicity... if other languages are moving to Oo then it would suck to have to learn a new literal syntax for every possible languages. 
it says it supports a few of the winodws ide's using the msvc toolchain. But does't say it only requires msvc so I'm assuming theres more support?
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8bbiy3/beginner_at_c_looking_for_places_to_get_practice/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I've used it for test code. We had a system where tasks were registered in an indeterminate order, including declarations of dependencies that could be registered later, and then wired up into a DAG to be evaluated in the correct order. It turned out that we had some tasks which did not declare their dependencies correctly and so only worked when they happened to be registered in the correct order. As part of the fix for this, I added a test which used std::next_permutation to iterate over every possible registration order to verify that they all worked. 
Pretty cool! Do you see any actual use for this library beyond proof of concept for constexpr?
&gt; std::launder is now supported. Finally I can launder money with one std call.
The problem with having papers on April 1st is that there are April fools proposals that are not real. One example is: P0989R0: Standardizing Extending Integers which proposes that long modifiers double the number of bits, and short modifiers halve the number of bits as well as entangled bits. That is obviously not a real proposal. And some April 1st proposals that are real: For example "P0983R0:Plan of Record for Making C++ Modules Available in C++ Standards" looks like a real paper (i would be very disappointed if it was not one) 
Aww thats neat. I tried doing something similar for arbitrary-ranked tensors a couple of months ago. Turned out to be messier than i expected so i ended up abandoning that project
"Your int value changing at random is because its bits are entangled with another ints. It's unspecified, not undefined, behavior."
`void` has one value, you just can't store it anywhere. I'd like it if we lifted that restriction. C++ already lets you return `void` explicitly (`reuturn void();` or `return voidreturningfunction();`), so it's better than other curly languages on this. (This means that templated scenarios work nicely and there isn't the duplication of `Action&lt;T&gt;` and `Func&lt;A, T&gt;` that C# requires.)
I guess I am one of the "regular void people". Does that mean there are already proposals for this?
I guess I am one of the "regular void people". Does that mean there are already proposals for this? 
Very cool. Is it possible to use deduction guides to avoid specifying the size and type of vector. Here is what is used for std::array http://en.cppreference.com/w/cpp/container/array/deduction_guides That way instead of constexpr cotila::vector&lt;double, 3&gt; v1 {{1., -2., 3.}}; You could do constexpr cotila::vector v1 {{1., -2., 3.}}; You might also be able to do the same thing with matrix, but I am not sure. 
!removehelp
This is a great idea, I hadn't seen this portion of C++17 yet, thanks!
I considered doing tensors first, but realized I couldn't think of many problems that need anything beyond matrices at compile time.
&gt; http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0806r0.html &gt; We propose to deprecate the implicit capture of this in a lambda expression with a capture-default. Users should explicitly use one of [&amp;, this], [&amp;, *this], [=, this] or [=, *this]. do the people writing such proposals *actually write code* ? 
I work in signal processing, where we tend to use *a lot* of lookup tables. If you're lucky, the definition of the table might be annotated with the MATLAB script used to generate the values. I started generating as much as I could at compile time with *constexpr* but really just wanted a framework around it. If you're curious, the particular problem that inspired me is least-squares channel estimation in communications, which basically requires the Moore-Penrose left inverse of a (constant) matrix.
yeh, this is a dumb proposal. Capture by reference [&amp;] and value [=] are convenient short-hands for explicitly capturing each variable individually [&amp;v1, &amp;v2, =v3, ...] anyway. Why make a very common use case harder when there's already a way to avoid the ambiguity
That is why we plan to extend it to user defined types as well. It is very common for code to be entangled at great distances, but it seems no language has built in support for this common pattern. C++ can be the first!
P0989 made a lot of sense to me.
Vectors are a rather large data type though so it can be very wasteful. 
I already did Post-modern C++. https://www.youtube.com/watch?v=QTLn3goa3A8 https://www.youtube.com/watch?v=GPP64opjy_Y C++Now will have a quantum talk. http://sched.co/EC6v Modules will be well entangled on their own probably. Or maybe some post-quantum entanglement could handle modules AND build systems and package management... 
Effective Modern C++
Thank you. I'll check it out. 
There's more stuff below too (I'm personally excited for the template argument deduction): &gt; * Added five new rules enforcing items from the C++ Core Guidelines regarding use of the Guidelines Support Library. We allow public base classes in aggregate types, so that they can be initialized using aggregate initialization syntax without writing boilerplate constructors. In the braced initializer list, bases are initialized first, followed by data members. &gt; * Extend template argument deduction for functions to constructors of template classes – when you construct a class template you no longer have to specify the arguments. &gt;* C++17 has changed the definition of qualification conversions. Previously, these were permitted between multi-level pointers and mixed pointers, such that qualifiers could often be added at levels other than the first; however, this did not similarly apply to arrays. &gt; * Refined the expression evaluation order for major C++ operators that were previously left to compiler implementation detail, for example, member access, assignment, and array index. &gt; * Expand the using declaration to support pack expansion semantics for variadic base class members, which can then be used inside the derived class. &gt; * We are now complete with the full implementation of Expression SFINAE, and have made the corresponding Standard Template Library changes. &gt; * Implemented parallel algorithms conforming to the ISO C++17 standard. See the source file located at [VSInstallDir]\VC\Tools\MSVC\&lt;ver&gt;\include\yvals.h for additional details. &gt; * In /std:c++17 mode, the warning level of C4834 ("discarding return value of function with 'nodiscard' attribute") is increased from W3 to W1. In addition, the compiler can now deduce the type of a non-type template argument that is declared with auto.
That's not what the proposal is. The proposal is to always require `this` to be explicitly mentioned in the capture list if it is needed, since apparently it is confusing that [&amp;] captures both locals and members by reference, but [=] captures locals by value and members by reference. The confusion mostly exists in the authors mind, I'm guessing, thinking of `this` as 'the collection of all member variables' rather than a pointer. Since it's also a breaking change, I'm guessing it won't get very far.
Not sure this is a problem, this is pretty consistent behaviour when you have temporaries...