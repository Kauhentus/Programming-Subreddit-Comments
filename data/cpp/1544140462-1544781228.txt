I compile program as dynamic linking then follow bellow steps. 1. Use dd tool to resolve and copy all depends libraries to a directory "lib". 2. Use patchelf tool to change rpath and reinterpreter's path to "lib" 3. It works on any linux machine (same machine architecture)
Depends what you are doing I would say. If you are in a situation where you are delivering a library, then no private functions (as they bring no real use for the library user), but if it's a header that is internal to a library that is intended to be used by other programmers that work on it, then I would consider making it private.
Lookd really interesting. Is there a design philosophy you guys use for this project? Some goal or mantra? Do you guys have a roadmap of where you want to go to with this project?
&gt;everyone should be compiling with -W -Wall (and probably also -Wextra) I would also suggest -Wsign-conversion and -Wnarrowing, . If you are feeling especially adventurous, try -Wsign-compare.
Why is this library header only? There’s no template code (nor a ton of need for it) or much constexpr. 
Mainly for ease of use. Much easier to throw a single header file in a project, as well as because I felt the size of the library would fit well with a single header.
Since `dlopen` is architecture, executable and OS dependent. It's quite (read extremely) complicated to implement. Also compilers can use their internal functions instead of libc implementation. But there's a simple way to show that `dlopen` is just a function that opens a file and then maps its content according to ELF specs and does the relocation and then protects the memory region as read-only by running an executable using libdl under `strace`. `strace` is a command that traces the "real" system calls to the kernel. I found [this](https://github.com/examplecode/dlopen-demo) simple example on Github and run the example `myplugin` with strace; the relevant part of the output is below: $ strace ./main ....... openat(AT_FDCWD, "./myplugin.so", O_RDONLY|O_CLOEXEC) = 3 read(3, "\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0&gt;\0\1\0\0\0@\20\0\0\0\0\0\0"..., 832) = 832 fstat(3, {st_mode=S_IFREG|0755, st_size=15896, ...}) = 0 getcwd("/tmp/myplugin", 128) = 14 mmap(NULL, 16432, PROT_READ, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7f9bfaa8f000 mmap(0x7f9bfaa90000, 4096, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1000) = 0x7f9bfaa90000 mmap(0x7f9bfaa91000, 4096, PROT_READ, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x2000) = 0x7f9bfaa91000 mmap(0x7f9bfaa92000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x2000) = 0x7f9bfaa92000 close(3) = 0 mprotect(0x7f9bfaa92000, 4096, PROT_READ) = 0 ......... As you can see there's no magic `dlopen` call. Only filesystem and memory calls.
I just don't understand why we couldn't make this aspect of modules work like headers, and enforce that foo.bar is at foo/bar.module, relative to some include path that you specify to the compiler. That's a proven scheme that works with all build systems. Maybe I just haven't read up enough on the current module proposals, but a system where module names aren't tied to something on the filesystem just doesn't seem workable. It's an incredible amount of extra complexity for dubious benefits. 
It's probably a bad idea to quibble with a member of the ISO committee, and the author of the amazing range-v3 library, but the more I think about this the more I'm convinced this case would not be UB. - The referent of `string_view` must be contiguous in memory. - `string_view::operator[]` may not bounds check. - `string_view::operator[]` may not have side effects. So, AFAICT, it's not possible to implement `string_view::operator[]` such that using the result of the expression `&amp;sv.operator[](sv.size())` is UB.
&gt;GCC has weighed the benefit of -Weverything for discovery against the risk of misguided devs applying -Weverything in their build options, and in their opinion that risk is not worth the benefit This sentence contains the "risk" word at least two times and sounds a bit like The Future Of The World Is At Stake. So what's the actual "risk" to consider here? Your code won't compile? Would it run slower or crash on Fridays? Or maybe it's just about the signal-to-noise ratio in your build log? &amp;#x200B; &amp;#x200B;
&gt; It's probably a bad idea to quibble with a member of the ISO committee, and the author of the amazing range-v3 library, You're right. :-) http://eel.is/c++draft/string.view.access#4.note-1 "[ _Note:_ Unlike `basic_­string::operator[]`, `basic_­string_­view::operator[](size())` has undefined behavior instead of returning `charT()`. — _end note_ ]"
And above, `Returns: data_­[pos]`. Taking the address of the one past the end element is always well-defined.
It's much easier to do `-Weverything` and disable the ones you don't want than trying listing all those that you do want. &gt; but every time we upgraded our compiler, we’d have to update our build flags to include a whole slew of additional -Wno-... options. I'd much rather fix my build flags every now and then, than miss out on new warning flags. Trying to maintain a list of warning flags across numerous project is annoying and error prone, `-Weverything` fixes that.
So, I am using `-Weverything` plus a few `-Wno-xxx` (e.g, `-Wno-c++98-compat`, `-Wno-c++98-compat-pedantic`, etc.). My code compiles without any warning with most compilers. What is so wrong about that? &amp;#x200B; Let's summarize the reasons mentioned in the article: \- Some smart people say it's bad: Ok, but why? \- `-Weverything` has conflicting warnings: I actually never experienced that, I'm probably lucky? \- It will generate new warnings with new versions of compilers: Good, I want to see them. \- Then, there is an example that triggers `-Wc++98-compat-pedantic`: Yes, but I use `-Wno-c++98-compat-pedantic` \- You need to add new `-Wno-xx` very often: The last time I had to do that was 6 months ago. It's fine, really. \- GCC does not support `-Weverything`: Yes, so I don't use it with GCC. &amp;#x200B; I also use `clang-tidy -checks='*,-not-xx'` (e.g, `-llvm-header-guard`). Are you also against it?
&gt; Well, `span&lt;&gt;`, like `std::string_view`, has an inherently (memory) unsafe interface, unlike the older standard containers. This reads as if you are implying span and string view are containers. If you think so you may be confused. And I could see that being upsetting. 
All but one bullet point seems not only reasonable, but, I'd like to think, expected to be complied with even without something like this proposal ever reaching WG21. The one bullet point I don't agree with is the ban of capital letters in module names. Why does that matter? Why shouldn't I use `BorisStaletic` as a module name? It can definitely be made unique and unambiguous.
&gt;it's not valid C Neither is `decltype`.
I was also put off by this syntax and similar examples. To the point where my brain just refused to read that kind of code. I'm pretty sure I wouldn't be able to write that, but I'm surprised that right now I don't have troubles reading that. I don't know when this change in my brain happened.
I'm a big fan of single header libraries. Don't let anyone tell you your intuition isn't right.
&gt; []&lt;SemiRegular T&gt;(bool b, T x) { Can't it be changed to `[](bool b, SemiRegular auto x) {`? Is terse concept syntax applicable to lambdas? That would tidy up the above example a lot.
&gt; Well, in the real world I can easily log how the container changes by computing size2-size1. As of C++20 (or in pretty much any exiting implementation) you can just do `ssize_t(size2 - size1)`
&gt; But why? Because we're talking about making a containerized application. Everything you said is true, but not really applicable. Containers are supposed to be immutable. Updating the third party libraries in an existing container is a total anti-pattern. The right thing to do is deploy a new version of the container with the updated code. Since that's the case, you lose little by statically linking, and can potentially get substantial space savings. Ease-of-deployment and size-of-container are important metrics in a container-based ecosystem. Self-contained binaries in a trivial environment (like Alpine) are much easier (and faster) to deal with for most people. There's a reason Go is such a popular choice in container-land. 
Signal to noise is important if you find -Weverything and wanted -Wall you might give up and just use the normal set. Honestly believe advanced features are better but I see the logic behind what GCC does.
It means forced inlining which always means increased compile times and execution size bloat. In many cases it will also lead to reduced performance due to thrashing the instruction cache. 
Having the `inline` keyword means forced inlining? TIL...&amp;nbsp;&amp;nbsp;&amp;nbsp;/s
I would think that anyone who tries `-Weverything` in clang learns quickly that it turns on things that make no sense, like the hey-you're-using-C++11 warning, even when you do `-std=c++11` (and probably the equivalent for later standards, too; I haven't tried `-Weverything` lately, so I wouldn't know).
At least in GCC `-Wsign-compare` is enabled by `-Wall` (for C++) or `-Wextra` (for C).
No need to be snide. It’s not guaranteed but certainly much more likely with the definitions inlined in the header. 
It seems very nice to develop Andriod and iOS app with native cpp
&gt; -Wall, and friends like -Wextra and -pedantic, include a well-defined set of warnings, so you can assured that your code won’t generate new warnings with new versions of your compiler. That is not true at all, compilers do modify the set of warnings covered by `-Wall` and change the warnings when it makes sense. Optimization can also affect some warnings. But getting new warnings is not a problem unless you are stupid enough to add `-Werror` to your build flags so just don't do that. If anything use `-Werror=...` to error on very specific warnings and even then it's better to change your project culture to deal with warnings instead of forcing developers to fix warnings in code unrelated to what they're working on just because you use a newer or different compiler.
The ONLY thing the inline keyword does is elide the one definition rule. After that it’s up to the compiler implementation 
My comment wasn’t even referencing the use of the word inline in his code at all. 
Why?
It's almost certainly because you're using Ubuntu 14.04. You really should upgrade.
If there's no template code, and the library is header only, then you are of course referencing the use of the word inline. If you weren't then it was a non-sequitur, I guess..?
I always regret posting here because nobody is willing to admit when they are wrong.
There's a difference between build flags used in source distribution to end users and build flags used for development. If we're talking about end users installing your packages by building from source, where they may be building with a compiler version that wasn't even out and couldn't have been tested with a particular release of your project, you shouldn't include lots of warnings and shouldn't have strict settings like making all warnings into errors. For development builds having very strict flags, enabling tons of warnings, turning all warnings into errors, etc. is desirable. Using -Weverything in that context is fine, and enables a 'subtractive' strategy for managing warnings as opposed to the more common 'additive' strategy. Instead of having to manually check every new compiler version for new warnings you might want, instead you just turn everything on by default, and explicitly disable just those warnings which, after evaluation, you find have insufficient value. Then when a new compiler release comes out you automatically get all the new warnings. If any are problematic then you turn just those ones off.
&gt; Well, everyone should be compiling with `-W` `-Wall` (and probably also `-Wextra`). `-W` is a deprecated alias for `-Wextra`. So just `-Wall -Wextra`.
For me any code that relies on the fact of the value returned by postfix increment, decrement operator is too clever.🙂 Every time I read such code I have to make some mental effort to convince myself it's correct. And i'd like the code to be immediately obvious why it's correct. the same with --&gt; "operator"
&gt; To be more precise, it's undefined by the STL, but well-defined at the language level, which takes precedence. The language *disallowing* something takes precedence, but any library can state some behavior is undefined regardless of language legality. ;-]
Have you measured the JNI performance penalty on Android?
This is all getting pretty language-lawyery, but undefined != disallowed. It's always conforming to define something that is undefined. In this case, the behavior of the library is defined by the C++ language itself. http://eel.is/c++draft/expr.sub#1 http://eel.is/c++draft/expr.add#4.2 In any event, I think you and I can agree that this is sort of like whether it's legal to use `malloc` without placement-new; an interesting academic discussion but not a RL issue. This example is pretty clearly just a case of poor wording—what's *meant,* since `string::view` does not always refer to a C string, is that if the referent string is not NUL-terminated, and also the result of the subscripting operation is used, then the behavior is undefined.
Have a look at [webview](https://github.com/zserge/webview), it might be relevant for your use case. Qt has QWebView which is nice but locks you into the whole Qt ecosystem. In my opinion there is no great way to use web technology for building the UI of a C++ application right now, but I would love to be proven otherwise.
Even better, I set `-Weverything -Wno-... -Werror -Wno-error=...`, then you enable all warnings, but can disable a few ones you don't want, and you can downgrade a few categories from errors to warnigs.
I guess people followed a similar line of thought, wenn they assumed `memcpy(nullptr,0,nullptr)` was safe.
The point is that it's simpler to just do `-Weverything -Wno-... -Werror -Wno-error=...` instead of having to keep track of all the new warning categories that gets added in every single version. I maintain both a GCC and a Clang build and the Clang build is a lot easier because of this, while the GCC build I have to remember to go through the documentation every year when there is an new version to make sure my flags are up-to-date.
Agree, I maintain both a Clang and a GCC build and the GCC is a lot more frustrating because I constantly have to keep up to date on whatever compiler flags they add in each version. With Clang I just do `-Weverything -Wno-... -Werror -Wno-error=...`.
Yeah I have never seen a good argument for why you shouldn't use `-Weverything`, it's great. Same with `-Werror`, obviously it needs to be enabled, especially on CI builds. Only time you disable it is on released versions for future proofing.
No you're missunderstanding. Weight is an affine type, think like time points and durations. The type a weight and it's difference wegith1-weight0 are not the same. But the subtraction operator for a an `unsigned` type is also an `unsigned`. So again, I have two weights x and y, if I use unsigned to model them computing x-y will give me the wrong answer.
Yeah mean? ssize_t(container2) - ssize_t(container1) Yep it's good that we get a signed size function. This is also what I'm currently doing.
If you are always up to date with the latest compilers, then yes. Otherwise it con become pretty annoying for people using your software.in particular if that someone wants to use older versions of your software with newer toolchains available at the time. As someone else mentioned: You have to distinguish between warnings during development and warnings in release versions (which becomes somewhat tedious if master is your release)
OTOH, when I am teaching, newbies using GCC/Clang always ask why the fuck `-Wall` means "relatively small subset of warnings"... Yes, you don't want people new to the language to stumble on `-Weverything`, but `Wall` implies the same thing by the name, it just happens to be broken because of back compatibility.
&gt; I'm trying really hard to understand that, but I currently simply cannot. How does relaxing the domain of a certain value give you stronger guarantees at compile time? Because you choose the type with the stronger behaviour guarantees. Ok let me try to reformulate. Since `unsigned` models Z/nZ and not Z+, to make it behave like a non-negative number you have to cast it to sign everytime you do arithmetic (well, in particular subtraction). This is error prone as you need to remember to do it. I want my types to automatically guard against this. By choosing signed my arithmetic will match the real world expectations of what a non-negative number will behave and I don't need to remember to cast. The consequence is that you instead have to assert (or better, use the new contracts in C++20) that parameters in a function are non-negative. The correct solution of course is to create a `non_negative` type. It comes down to that you don't have non-negative integers as a primitive type in C++, and `unsigned` is misstaken for being one.
Splitting interface and implementation properly is more important and easier to use than make it single header. Use header for interface and cpp for implementation.
Yes as mentioned elsewhere in the thread, you do `-Weverything -Wno-... -Werror -Wno-error=...` during development and on CI, but you drop the `-Werror` for release version. If you want to start using older versions on newer compilers, well it's noise in the log which you don't look at as a user, and if you're a dev it's trivial to disable if necessary. 
Seems there is the trend that header-only libraries are becoming popular, at least from what I saw in this subreddit. I really don't like it. C++ has very good mechanism to separate interface (put into header) from implementation (put into source file) but we are abandoning it. 
Er, `ssize_t` is a type (signed `size_t`) not a function? Also, unsigned arithmetic (then converting to signed like above) is necessary in case the subtraction overflows.
I am thinking if it would be a nice idea to make std::size\_t its own strong type and the difference a delta type, with compile errors when using one in place of the other but convertible through casting. I think this would ensure better behaviour?
Supporting several versions of clang becomes hell with different sets of `-W-no` based on version.
Ah sorry I meant to type std::ssize()
It's rather painful to see this kind of very bad C++, especially when in book form: vector&lt;struct strip&gt;* result = new vector&lt;struct strip&gt;; This line alone contains four mistakes: - Use of `new` to create a vector on the heap when one on the stack would have sufficed. - Use of `new` rather than `make_unique`. - Unnecessary use of `struct`. - Repeating the typename rather than just using auto. So what would be the correct solution then? Just this: vector&lt;strip&gt; result; Not understanding when to use the heap and when to use the stack is a huge red flag, as is doing manual resource management. We might hire someone like that, but with the understanding that that person would need lots and lots of training, and only if we had no better candidate.
Yes a big reason this is a problem in C++ are all the implicit conversions
Yea case and point. I’m talking about the inlining of actual implementation into your source code. Literally anyone I’ve worked with will tell you I know inlining isn’t guaranteed but you just won’t let it go. 
First let me say that I do the same in our build system, both for compiler warning settings and for clang-tidy, but since you asked: Yes I have been annoyed by contradicting (clang) warnings on more than one occasion. Especially in clang-tidy it has grown so bad over recent years that I have switched to a slight variation where I no longer enable everything by default but try to enable categories as coarsely as possible while leaving out the problematic categories. Actually I have the generals feeling that clang-tidy has steadily declined in quality over recent years, because a lot of the checks report obvious false positives that border on the moronic, because, for which it is obvious that more thorough checking of the preconditions/circumstances could have prevented it. So I find myself even disabling very desirable checks because the s/n ratio is just too low for them to be useful. As a final side node, with clang (as the compiler) it has only occurred 2 or 3 times and for GCC I never had the problem of contradictory warnings at all.
No, because the standard specifies `string_view::operator[](size_t i)` returns `data[i]`, and `&amp;ptr_to_n_contiguous_objs[N]` (or, in this case, `&amp;ptr_to_n_contiguous_objs[N - 1]`) is always well defined, no exceptions.
It's a trade off between one-time install cost for the library, and recurrent compilation cost. To be honest, I'd rather keep the compilation cost down...
&gt; You increase memory consumption and get rid of the ability to update 3rd party libraries without recompiling your software for a so-called portable executable. The inability to upgrade 3rd party libraries exposes your application to potential security threats I don't remember one time in my life when any of the software I used only updated one DLL. For my software, if there is a security update I just launch a new round of CI with the updated libs, which produces complete installers for windows / macos / linux anyways, I'm not going to ask my users to go in myapp.app/Contents/Frameworks and replace whatever dylib in there, and people downloading the software don't have to mingle with 36 patches like the old days, they just download the full latest version and they're good. 
It might sound stupid, but for just what reason constant std::string https://github.com/tinfoilboy/atomizes/blob/master/include/atomizes.hpp#L35-L50
Several points * Namespaces are usually lower case and we want consistency between ns and modules. * In the previous article I talked about naming modules and the files that declare them consistently - Because different file systems handle case differently, lower casing everything avoids some issues * Less freedom make it easier to find what you want to import ("Is Boost `Boost`, `boost` etc ?) * It sidesteps the question of whether `boost` and `Boost`can co-exist and how we enforce they don't. 
Boden is still in its very early stages. Our overall goal with the project has been to provide a purely native and modern alternative to cross-platform development. This means 100% native code (no scripting languages) plus native OEM widgets. A thing that, to our knowledge, currently no other cross-platform framework offers. A core vision of Boden is to re-enable individual developers and smaller software development shops to build native apps at competitive prices. From our perspective, App Store models and platform fragmentation have recently led to a situation where a lot of developers appear to be forced to move to web or hybrid technologies (e.g. Electron) to still deliver applications to a broad range of audiences. We feel that this often compromises performance and usability. One of our main intents with Boden is to try and change that. We don’t have a fixed long-term roadmap yet, but we are happy to share our ideas for the next months. * Boden currently has a very limited number of widgets. We will add a lot more. Most likely, we’ll be starting with lists/tables in the near future. * There is no way to set up navigation or tab view controllers right now. That’s another high priority point on our list. * Boden’s layout system needs serious work. We already have a good starting point for laying out views in e.g. columns or rows, but the layout system is currently very limited. * We are thinking about making the framework idiomatic C++ only. Currently, we’re using our own smart pointers and, partially, containers. We are also thinking about going C++17 as compiler support seems to be mature enough at this point. * We got feedback on HN about the current licensing model not being adequate for App Store distribution. We are currently exploring which options could work better. What do you think? We’re happy to hear your ideas!
We use wxwidgets at work, which also goes the native widgets route. The pain of maintaining this code on three platforms (win/linux/macos) has led me to believe Qt has the right of it, there's so much small incompatibilities, focus issues, down to things that downright don't work with wxwidgets, I haven't experienced such pains when doing Qt development. What's your take on that?
If your build tool is unable to enable only the -Wno flags that the Compiler supports, you sgould probaply use s different ine
So which build tool does that and how exactly? Running a compiler and testing error message for each possible build flag? I mean I'm totally fine with Visual Studio way of ignoring specified flags for not yet existing warnings but it never worked with gcc/clang.
Nope. [See for yourself](https://godbolt.org/z/aJIi2I). static_assert(0u - 1u == UINT_MAX); // passes static_assert(int(UINT_MAX) == -1); // passes
As long as you stick to the features and widgets that Boden provides, yes. If you want to use functionality that is not yet included in the Boden API, you will have to write cross-platform code using the respective languages (Swift/ObjC on iOS, Java on Android). As Boden matures, the need for writing custom cross-platform code will most likely be minimal, so only exceptional use cases will need platform-specific code. 
Do you even know, why my example memcpy broke in real world code? It was due to special source annotations in the standard library that told the compiler "passing a nullptr here is UB". There is nothing stopping a stl library implementor to slap a similar annotation to `string_view::operator[]` (might become relevant if compilers start to optimize based on unchecked contracts). In other words: The library can absolutely turn "library UB" into "language UB" even without performing a "language UB" in its implementation.
Who says namespaces are usually lower case?
I like to follow the advice issued for most webservers. Use whitelists by default. Blacklists are dangerous because you might miss something. &amp;#x200B; In a sense, -Weverything is a whitelist approach.
Frankly, no, we did not yet measure performance penalties induced by the JNI bridge on Android, but it’s on our list of things that need to be done. Do you think there will be serious performance issues with the way that Boden bridges to Java? 
No, my point was more that the original STL seemed to specifically avoid any dependence on raw pointers in its interfaces. This, in part, allowed for the (at least theoretical) possibility of a (slower, but) memory safe implementation of the STL. But `std::string_view`, departed from that by having an interface that depends on raw pointers for commonly used functionality. For example, if you want to construct a `string_view` that spans a subset of a string, you would use this constructor: constexpr basic_string_view(const CharT* s, size_type count); The consequence of this dependence on raw pointers is that a memory safe implementation of `string_view` is not possible. So if you consider this example: vector&lt;int&gt;::iterator it; { vector&lt;int&gt; vec1{1, 2, 3}; it = vec1.begin(); } std::out &lt;&lt; *it; there exist (memory safe) implementations of `vector&lt;&gt;` (and `vector&lt;&gt;::iterator`) that will throw an exception rather than access invalid memory. But if you consider the next example: string_view sv; { string str1 = "abcd"; sv = string_view(&amp;(str1[1]), 2); } std::out &lt;&lt; sv; there is no way to implement `string_view` such that it could avoid accessing invalid memory here. But it could have been different. For example, rather than the constructor using a raw pointer, `string_view` could instead have had a more general constructor something like: template&lt;typename Iter&gt; constexpr basic_string_view(Iter s, size_type count); So that the example would become like: string_view sv; { string str1 = "abcd"; sv = string_view(str1.cbegin()+1, 2); } std::out &lt;&lt; sv; In which case, it would be possible to implement `string` and `string_view` such that the `string_view` would throw an exception rather than access invalid memory. The same goes for `std::span`. Does that make sense?
&gt; As the GPU memory is a separate resource Only if you have a dedicated GPU with dedicated memory. It isn't the case on phone, current gen consoles and most laptops. &gt; In these situations should a different exception be used instead? Probably. If you throw a bad_alloc and catch it, how are you going to know that you are out of GPU memory and not CPU memory ? &gt; Why is the what string not customisable like those defined in Because using a custom string would probably require allocating memory. 
I stand corrected, yes what you originally wrote does indeed work
&gt; - Namespaces are usually lower case and we want consistency between ns and modules. But if the top level namespace of a project also has capital letters? Should the project change the namespace too? &gt; - In the previous article I talked about naming modules and the files that declare them consistently - Because different file systems handle case differently, lower casing everything avoids some issues That's a fair point. &gt; - Less freedom make it easier to find what you want to import ("Is Boost `Boost`, `boost` etc ?) - It sidesteps the question of whether `boost` and `Boost` can co-exist and how we enforce they don't. That kind of freedom already exists at the namespace level, but I don't think anyone wondered if it is `boost::python` or `Boost::Python`. Granted, that's maybe because boost is so popular. Recently I've been playing with the abseil library. The first thing I tried was `absl::string__view` and `absl::flat_hash_map`, but then the second thing I used was `absl::Hash` and then `absl::InlineVector`.
For cmake there is the [CheckCXXCompilerFlag function](https://cmake.org/cmake/help/v3.12/module/CheckCXXCompilerFlag.html) . The problem with -Wno-xxx flags is that some compilers do not warn if it not supported, so you need to check against -Wxx
That’s probably one of the hardest questions to answer properly. The trade-offs involved with wrapping OEM widgets vs. “drawing your own” have been a big discussion point in the team from day one. The main challenge appears to be that native OEM widgets have to be treated as kind of a black box. For each widget, there’s a vendor-specific implementation that we can’t control. From our perspective, this boils down to the question of whether you can find a compromise that’s “good enough” for most use cases and does not lead to the situation of small incompatibilities adding up to a lot of trouble for the developer. React Native seems to have found a feasible way to deal with this and we are convinced that we will be able to do so too. There’s also one architectural key difference in the way Boden handles native widget wrapping. We employ platform widget “cores” that are loosely coupled to platform-independent classes. The platform-specific implementation is pretty much isolated in this way. This allows us to swap platform implementations with relative ease. So it is still possible to provide a custom “platform” that conducts the rendering on its own. Another aspect of Boden is that it is open to substituting widget functionality which is not available on a certain platform with a custom implementation. The Checkbox on iOS is a good example for that. This allows us to maintain more coherence on the platform-independent level while not sacrificing the native widget approach for all the functionality that is available on a certain platform.
The article spills lots of electrons on `const Range &amp;` vs `Range &amp;&amp;`, an issue that's already been resolved in the range-v3 design and in the C++20 Ranges library. Use `Range&amp;&amp;`, or `Range and` if for some reason you prefer that. There are two basic reasons for this: - Correctness: just because `T` models `Range` doesn't mean `const T` does. In particular, things like `filter_view` caches `begin()` to ensure amortized O(1) complexity, so it can't provide a `begin() const` without undue overhead. - Ranges are not necessarily deep const; most views aren't. Thus, `const Range&amp;` offers but an illusion of safety.
I can't find a place where the standard mentions it explicitely, but this is intentionally to avoid the requirement of allocation when bad_alloc is thrown. In your situation, you are advised to throw an exception derived from `std::bad_alloc`. This alos allows you to introduce your own 8static) error message, since - as has been commented - ou-of-gpu memory may correlate with process memory starvation. struct out_of_gpu_memory : public std::bad_alloc { const char* what() const noexcept override { return "out of GPU memory"; } } This allows programs to catch your exceprtion specifially, but also ncludes it where std::bad_alloc is caught. 
&gt; Currently, we’re using our own smart pointers and, partially, containers. Wow okay - that would be enough reason for me not to commit to a new framework that claims (or aspires) to be native and modern. I'd suggest to change to `std::` as soon as possible. &gt; We are also thinking about going C++17 as compiler support seems to be mature enough at this point. Your statement is true but there's too many important, big frameworks, with which a lot of people need to interact, not ready for C++17 yet. Just naming Unreal Engine for example (or CUDA but that's not too relevant for Android/iOS). I suggest to stick to C++14 for now (but go full-blown on that, not just C++11) but I hope that some time mid-2019, the full switch to C++17 can be done.
It looks really great, nice work, and will for sure be following the project! However GPL makes it prohibitive to use. How about at least offering an LGPL option? &gt; We also plan to offer Boden under commercial licenses in the future, including a free commercial option. It might also be good if you think about this soon and put some plans/fee structure online. Otherwise it'll be a hard sell for people to buy into something they don't know what it will cost in the future. What do you mean with "including a free commercial option"? Depending on what you mean with that, the best might be to make the project Apache/MIT/BSD. You might get a lot of adoption and contributors.
So you say we should use ` CheckCXXCompilerFlag` to check for any error/warnings flag that we add? That would be a pretty long and convoluted CMakeLists file?
Unfortunate since sphinx actually is not good for anything where you actually want to document code in a ergonomic manner.
Yeah that makes sense so the custom exception type is probably the best. Are there any use cases for throwing bad_alloc at all then? 
Super thanks for the feedback :). 1. Use of new is unnecessary. I totally agree with you. I have removed it and replaced with a stack variable 2. Use of struct is unnecessary. Got rid of struct 
IIRC library writers are advised to use exceptions that inherit from those in std:: So, Except for "this is just a one-shot and I'm to lazy to introduce a custom exception" and "I'm actually imlementing the C++ standard library" of course ;)
Personally I use a cmake function which checks if a flag is supported and if it is it sets the flag. 
&gt; Wow okay - that would be enough reason for me not to commit to a new framework that claims (or aspires) to be native and modern. I'd suggest to change to std:: as soon as possible. Yes. We got that feedback on HN as well and we’re listening. As feedback such as yours comes in, the issue of moving to std:: is becoming a fixed part of our 2019 Q1 roadmap. &gt; Your statement is true but there's too many important, big frameworks, with which a lot of people need to interact, not ready for C++17 yet. Just naming Unreal Engine for example (or CUDA but that's not too relevant for Android/iOS). I suggest to stick to C++14 for now (but go full-blown on that, not just C++11) but I hope that some time mid-2019, the full switch to C++17 can be done. Hopefully so. Switching to C++17 would allow us to commit to a lot of standard functionality and syntax that would be highly beneficial for a modern cross-platform C++ framework. However, we understand that there are roadblocks in the way and we take those seriously. Those decisions are always kind of a compromise.
Thanks a lot for your praise! With regard to your comment: Yes. To be frank, we don’t like it being GPL either. Unfortunately, we’re in kind of a catch-22 situation. If Boden is to be maintained commercially in the long run, there needs to be some kind of business model supporting it. Currently, we are financing its development with investments, but this won’t be viable forever. Adding LGPL would be an option, but that still wouldn’t yield a very clear legal situation from our point of view. A free commercial option could provide for legal App Store compatibility while keeping the license open to monetization at a later point in time. Going all MIT at this point would probably lock us in to a situation where we’d have to base the business model on support, training, and/or contract work to fund Boden’s development on a sustainable basis. This is currently an active thought process and our main goal with making it GPL for now has been to not lock us in to unsustainable licensing conditions. Still we understand that having it GPL-only will probably block adoption and is not what the overwhelming majority of users want. We are happy about further thoughts on this!
DevOps Engineer here. This is cool and all that you are showing a starting point for doing this kind of thing in C++, but ideally what you want to do here is a multi-stage Dockerfile/image where the first is for the build and the second is the runtime where the statically linked binary is placed. This greatly decreases the image's size and improves security and performance.
Hey there, are there any numbers on performance and build time?
Yeah it's a C++20 feature. It's not supported yet, sorry.
Sorry, we do not have any hard performance data yet. Build performance is hard to measure as it varies based on system specs. Runtime performance appears to be multifaceted. In what kind of data are you particularly interested?
Maybe when you want some common interface/wrapper with null-returning (or otherwise differently signaling exception) allocators.
Err, what? You should have absolutely have Werror. I thought this was common knowledge? People tend to delay and procrastinate fixing warnings if they don't actually affect the build. Over time warnings accumulate making it impossible to see new ones, making the warnings useless. In practice I don't know how a codebase gets much value from warnings without Werror.
I think you don't get my reasoning. I am totally aware that C++ defines the result type of the subtraction of two unsigned integrals to be the same unsigned integral. And this is the root of the problem: the actual result type must be a signed integral type. Just like the result type of subtracting two pointers (another indexing type) isn't the very same pointer type but rather \`std::ptrdiff\_t\`. Or the difference of two \`std::chrono::time\_points\` (yet another indexing type in the wide sense) isn't the same \`std::chrono::time\_point\` but rather \`std::chrono::duration\`. Or the difference of two points in an euclidian geometry isn't a point but rather a vector.
 Qt creator has very strange warnings these days and its annoying, for example, what exactly can i do about [these](https://imgur.com/a/DPhNycV) warnings? I think it should shut up about them. 
The overload resolution uses `std::ptrdiff_t`, but the actual built-in operator shows no preference to any specific integer type ([\[expr.sub\]](http://eel.is/c++draft/expr.sub#1.sentence-2)).
I agree, it is far too noisy by default, and in some of my projects, the warnings/errors are plain incorrect (e.g. warnings about missing types).
We are using CloudFlare now, thanks!
The compiler "picks" it. There's rules for how it is to pick it, and if it doesn't follow the rules and pick the right one then it isn't a conforming compiler. But it is still chosen by the compiler at compile time.
you can choose whatever warnings you want here : http://doc.qt.io/qtcreator/creator-clang-codemodel.html
I think he meant functional casts, in general, aren't valid C even if the equivalent C-style cast would be. e.g. `int(x)` vs. `(int)x`
Rust has a lot going for it. No denying it.
&gt; And this is the root of the problem: the actual result type must be a signed integral type. Agree, absolutely. As you say the correct way to solve it is something along the lines of what `std::chrono` does. The second best way would be to signed numbers throughout. The wrong solution is to use `unsigned` and then manually having to remember to cast everywhere.
The examples near the end are the sort of thing I'm more likely to write (and indeed have been with existing range libraries).
In most code I have sitting around fs is `namespace fs = boost::filesystem;`. Doing it this way makes it fairly easy to switch which library you're using to provide the namespace alias fs.
&gt; Many people use using namespace std; While I appreciate there's a reasonable amount of safety in doing it in a smallish function or even a .cpp file where you can easily hold the whole file in your head at once... I don't know of a good reason for doing this.
I don't see the need for -Werror on CI builds. What I prefer to do is crank the warnings through the roof there - including even things I don't want to fix - and have it track the counts &amp; severities over time and fail if there's an increase.
Yep I agree, `-Werror` is the only realistic way of maintaining a warning free build
The effect is the same though? Any new warnings is a build failure. It has some nice advantages in that it's a bit easier to gradually introduce to a legacy code base, the downside (in my experience) is that it's not entirely reliable, but probably good enough. My workflow in the past to fix warnings in large code bases has been to enable all warnings and then fix one warning category at a time followed by making that specific warning an error. That way you can gradually chip away at the warnings.
I was going to use those strings a few times in the code and felt it was better to make a constant for them as opposed to typing them repeatedly.
-Wno-missing-prototypes is really useful btw because it helps you putting code in anonymous namespaces. Which in turn help you detect dead code due to various Wunused warnings.
Say for example a similar UI built with this project and native Android, on the same dev machine, how much time is required for building? Performance of the toolkit itself is harder to measure, I guess you can build a very complex UI to the point where one toolkit cannot maintain 60fps anymore, and see how the other is holding up. Not very specific, definitely not scientific, but just understand where your toolkit is when compared against native UI.
LSP support is nice. I've tried it on some python script and it worked really well. Something like VS Code is still probably better designed to handle the vast variety of languages, but now it'd be much more pleasant to edit few extra scripts in a mainly C++ project.
Same storry here. The missing -Weverything in GCC basically make GCC flags unmaintained compared Clang where the flags are always up to date.
Eric, thank you for your work on Ranges! I have some question/comments on the article: *maybe_view* It is sad that we need this wrapper instead of optional directly treated as container. I know historical reasons (boost authors thinks that optional models a different concept, and They Are Obviously Wrong™). Even Java Optional was fixed in Java9 and now can [produce stream as any other container](https://docs.oracle.com/javase/9/docs/api/java/util/Optional.html#stream--). *for_each* Oh. Either concepts are pretty bad at describing real world code or it should be possible to rewrite this `flatMap`-analog signature to something clearer. *yield_if is overconstrained?* Why is it require `Semiregular` T? It makes it unusable with `std::unique_ptr` and other move only types. As a side not `yield_if` takes it second parameter by value (as oposed to by name), so it must be created even if it will be never used :(
&gt; The effect is the same though? Extremely similar. &gt; a bit easier to gradually introduce to a legacy code base And also tolerant to warnings you decide you don't really care about. Basically what I'm saying is if you introduce new warnings that you feel aren't worth fixing you can get away with it if you go fix some old warnings to compensate. &gt; enable all warnings and then fix one warning category at a time followed by making that specific warning an error. A perfectly reasonable approach, especially if one warning category has a high risk. Even when I'm not doing -Werror I still do -Werror=return-type because just not returning from a non-void function is insane.
Im baffled by the inability to understanding the workflow of others. Passing -Weverything does not mean you beleive all warnings should be enabled. It is simply a tool to catch up with compiler changes. I do not understand what is so controversial with this approach. 
My company has done some JNI measurements on Android before and we were surprised how slow it is. Your JNI classes and guards are very nice, I like those a lot.
The argument you're making here is simply false. The library states that the precondition of `operator[]()` is that the index must be less than the size. A perfectly valid implementation is: assert(pos &lt; size()); return data_[pos]; A different perfectly valid implementation is to use Contracts and hit the violation handler if it's enabled. A differently one would be to check this condition and throw an exception. Or it could have no checks in any mode and just happen to work. The point is: do not write code that violates library preconditions. It is simply wrong to do so. Full stop, without qualification. 
You can still hire that person to write a book :D
Ambitious project! Any plan for desktop application?
Span and string view's runtime state cannot contain such iterators. It would have to extract safety information into a type erase validation, which starts getting insane, and practically bans the types from being pods.
I'm surprised that (thin) class wrappers for `size_t` and `int` haven't been brought up. I mean, given that a) there appears to be little hope of the standard library switching to signed sizes in the foreseeable future, and b) while arguably a big improvement, that wouldn't be the ideal solution anyway, integer wrapper classes are a practical solution that is available right now and is arguably a better solution. Pretty much any operation (comparison, arithmetic, assignment, conversion) that has an integer wrapper class as one of its operands automatically does the right thing, right? Including things that native integers can't provide. Things like: i) Any arithmetic operation that could result in a negative value returns a signed type. ii) The `size_t` wrapper has run-time checks on its `-=` operator (or disables it). iii) Narrowing conversions are checked at run-time for loss of data. iv) Check for division by zero. v) Prevent use before initialization / value assignment. vi) Optionally check for overflow on arithmetic operations. Again, even if the standard library's `size()` functions return a `size_t`, as long as the other operand in the operation is a wrapper class, the right thing should happen. There seem to be (I haven't tried them all) a number of integer wrapper class implementations available, including: [https://github.com/dcleblanc/SafeInt](https://github.com/dcleblanc/SafeInt) (does overflow checking) [https://github.com/foonathan/type\_safe](https://github.com/foonathan/type_safe) (does not allow uninitialized declaration) [https://github.com/boostorg/safe\_numerics](https://github.com/boostorg/safe_numerics) (supports integers with custom ranges) [https://github.com/duneroadrunner/SaferCPlusPlus#primitives](https://github.com/duneroadrunner/SaferCPlusPlus#primitives) (shameless plug) (does not do arithmetic overflow checking by default)
Single header libs are just a symptom of not having a dominant package manager and build system IMHO. Golang and rust aren't twisting themselves into pretzels over software delivery and build integration. It's a solved problem. I'm hopeful the layout "evoke" is championing gains traction. That would solve the build problem.
Yeah, you probably wouldn't want to retain the safety mechanisms by default (in release builds anyway), but it could be useful to do so in test/debug builds. Or perhaps even some other situation where performance is not paramount. Again, kind of analogous to microsoft's [debug iterators](https://docs.microsoft.com/en-us/cpp/standard-library/debug-iterator-support?view=vs-2017).
For people who aren't familiar with this concept here is an example. [https://github.com/vinniefalco/CppCon2018/blob/master/Dockerfile](https://github.com/vinniefalco/CppCon2018/blob/master/Dockerfile)
Along a similar vein, I've used [CDE](http://www.pgbovine.net/cde.html) to generate minimal Docker images before: http://www.pgbovine.net/automatically-create-docker-images.htm. Essentially tar up the resulting CDE root and import as a Docker image.
&gt; Ok, but why? Because it turns on warnings that are flat out broken / in development. It's a thing for people that work on the compiler. If you run it for testing purposes or something that may be fine, but when you put that into published build scripts you make it so that people consuming your library are arbitrary blocked from using later versions of the compiler.
Re `maybe_view`: I agree. Giving `std::optional` `begin`/`end` members makes sense to me. The Committee heard that suggestion with tepid enthusiasm. Re `for_each`: Is this any better? ``` template &lt;Range R, IndirectUnaryInvocable&lt;iterator_t&lt;R&gt;&gt; Fun&gt; requires Range&lt;indirect_result_t&lt;Fun, iterator_t&lt;R&gt;&gt;&gt; auto for_each(R&amp;&amp; r, Fun fun) { return std::forward&lt;R&gt;(r) | view::transform(std::move(fun)) | view::join; } ``` Some of the awfulness is the use of the lambda. Re `yield_if`: yes, it's over-constrained. If this were ever standardized, I think it should only require `MoveConstructible`. We still need to change the `InputView` concept to permit move-only types. And yes, the interface for `yield_if` is not ideal. Perhaps it should take a nullary callable that produces a value.
When you do something that the spec calls undefined behavior, it means literally _anything can happen if you do this_. An implementation may look like this: ``` CharT&amp; basic_­string_­view&lt;...&gt;::operator[](size_t n) { __assume(n &lt; size()); // The compiler may now optimize assuming the condition is true return _data[n]; } ``` The compiler may then generate code that is actually invalid when `n &gt;= size()`. Why can a Standard Library implementor do this? **Because the text of the Standard says they can**, and because it might improve code generation for conforming code. Arguing this point is wrong-headed. If you insist on writing code that explicitly invokes undefined behavior, you will live to regret it. Period. Compiler implementors will have no mercy on you.
Yes, it could, but the body of the lambda would need to be changed to use \`decltype(x)\` in the place where it currently uses \`T\`. I find \`decltype\` distasteful and avoid it when I can, so in this case I prefer the lambda with the explicit template parameter.
...and this is why absl gives us the Time library.
Padding size warning with implicit capture? That's an llvm/clang issue but you should be able to silence it. https://bugs.llvm.org/show_bug.cgi?id=31709 I agree though that there are a lot of unnecessary warnings with the llvm/clang code model. Overall I do appreciate the new code model more than I dislike it. 
for the love of god don't put werror in your published build scripts. It really does tie you're library to a specific version of a compiler. It's fine to turn it on in CI, and on dev machines but please don't inflict it on package maintainers, or people using you're library as a subproject
any recs for structured logging or do we just directly use journald and the event log? Is there something on macOS that is similar?
Okay, it looks like you and others are right. Apologies for being arguey. That said, it would have to be a pretty merciless library implementer, since `string_view` is meant to be a vocabulary type, and virtually always refers to a NUL-terminated string; there are of course many legitimate use cases for accessing the terminating NUL, characters after the "end" of a prefix or interior slice, or, in unevaluated contexts, the one past the end character of the referent string. Implementing it like that would introduce severe memory safety bugs in a whole lot of real if technically nonconforming code, for near as makes no difference no performance improvement. IMO it's a defect in the standard; it violates POLA in a major way for `string_view` (as well as smart pointer, `string`, `span` and `valarray`) `operator[]` to have semantics inconsistent with `array`, `deque`, `RandomAccessIterator`, `vector` and built-in `operator[]`.
I suggest using something that doesnt require allocation or indirect access. Constexpr const char[] or string_view.
 include (CheckCXXCompilerFlag) include (parse_arguments) function (is_cxx_compiler_flag_supported _flag _result) set (${_result} FALSE PARENT_SCOPE) #! \note GCC accepts any -Wno- flag as valid flag for cross-version #! compatibility, but complains about it when any other error #! happened. Thus, for any warning we disable, check if the #! corresponding warning exists, and only then add the flag. string (LENGTH "${_flag}" _length) if (${_length} GREATER 5) string (SUBSTRING "${_flag}" 0 5 _prefix) string (SUBSTRING "${_flag}" 5 -1 _suffix) if ("${_prefix}" STREQUAL "-Wno-") is_cxx_compiler_flag_supported ("-W${_suffix}" _corresponding_supported) if (NOT ${_corresponding_supported}) return() endif() endif() endif() string (MAKE_C_IDENTIFIER "CXX_COMPILER_SUPPORTS_${_flag}" _test_variable) check_cxx_compiler_flag ("${_flag}" ${_test_variable}) if (${${_test_variable}}) set (${_result} TRUE PARENT_SCOPE) endif() endfunction() macro (add_cxx_compiler_flag_if_supported _FLAG) is_cxx_compiler_flag_supported ("${_FLAG}" _is_supported) if (${_is_supported}) set (CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} ${_FLAG}") endif() endmacro() add_compiler_flag_if_supported (CMAKE_CXX_FLAGS -Werror) add_compiler_flag_if_supported (CMAKE_CXX_FLAGS -Weverything) # covered by CMAKE_CXX_STANDARD add_compiler_flag_if_supported (CMAKE_CXX_FLAGS -Wno-c++98-compat) add_compiler_flag_if_supported (CMAKE_CXX_FLAGS -Wno-c++98-compat-pedantic) 
Why the downvotes? Isn't it C++ related?
It seems no one bother with [googlelog](https://github.com/google/glog)?
Only do so in debug mode***
&gt; Yes, so I don't use ~~it with~~ GCC. 
Fuck that. Everything I do is in PascalCase, and I'm not changing that.
If we're doing stylistic nitpicking, do you have any objection to the following? inline constexpr auto yield_if = []&lt;Semiregular T&gt;(bool b, T x) -&gt; maybe_view&lt;T&gt; { return b ? {std::move(x)} : {}; };
I would just use the base class std::exception.
Amalgamation can improve compilation speed. I wrote a scripting library [Jinx](https://github.com/JamesBoer/Jinx), and then later wrote my own [amalgamation utility](https://github.com/JamesBoer/Heady) for automating the process of creating a single-header version. The amalgamated header version definitely compiles quite a bit faster. But I think the primary reason for amalgamation of source (rather than a "Unity build") is to simplify distribution and integration of the library. C++ doesn't have a standard build or project management system. About the closest we have is CMake, and you can't call it a real standard at this point, even though it seems to be leading the popularity pack. If you boil the project down to just a header, or maybe a header and single source file, it's vastly easier to integrate into a new project. Unfortunately, even a library that supports CMake isn't a guarantee of drag and drop compatibility. I'm currently upgrading my game engine to build using CMake, and thought I'd update some of my third-party libraries, while at the same time using their "official" CMake configuration. Haha... nope! They just blow up with some missing variable or other indecipherable error. It was actually easier for me to delete their CMakeLists.txt file and just replace it with my own than trying to figure out WTF they wanted me to tweak in order to simply get the project built, which is just... sad.
"C++ Frontend \[API Unstable\]" Weird. I expected a stable API from a stable release.
\+1. Came here to say this.
A few days ago someone posted some dice rolling class, with which most of us weren't impressed. Instead of complaining about it I decided to make something better. This is a flexible dice roller implemented as a random number distribution (as in `&lt;random&gt;`); you can build a set of dice either from its component parts or by parsing a string. As a bonus, I also included a simple rational number class (needed to support dice arithmetic that returns a fractional result). Example: auto dice = Dice(2, 10) * 5 + Dice(3, 6) + 10; dice = Dice("2d10x5 + 3d6 + 10"); // same thing std::minstd_rand rng(42); std::cout &lt;&lt; dice(rng) &lt;&lt; "\n"; 
UDLs for `2_d10` and `3_d6` would be cool.
Good idea! I've just added them.
Subjectively, I'd place prioritization (#8) at the top if you have more than a few people, as they will most likely have different minor (or major) agendas. Without priority, you may circle around on design at best, and effort at worst. If it's appropriate within this context, defining short term and long term goals or metrics of success are nice - high-level, like "make reproducible ML results on a novel architecture in 1 year, awesome code framework in 3 years", not superficial like LOC or # of PRs or issues closed. Actually drill through priorities to really see how things should be ordered. If you care about generating a demo video in a rapidly short timeframe, by all means forgo as many formalisms possible and just get it done. If your goal is to get a ton of open source users, prioritize the API design, then release process, issue tracking, etc. will be top of the list. Etc, yadda yadda.
That's a lotta code for a rather terse deployment procedure... If you're able to say, is this something like numerical modeling, process control, business logic, software framework, or more of a web-based e-commerce like solution? (My guesstimate is mebbe medical, bio, or oil?) What's the product? Everything up to deployment + tuning, just a binary that they run, a webservice, a library with an API, or just a means to an end (e.g. control software in an end product)? If you can't say, can you at least post a picture of a kitten?
Isn't the use of `string_view` causing undefined behavior? For example in the example code: auto dice2 = Dice("2d10x5 + 3d6 + 10"); Since the string passed is an rvalue, it's getting destructed before the `string_view` is accessed. So it's accessing a dangling pointer? Same with line 10 in Dice.cpp? (I also think the `static` here doesn't actually do anything since it's getting destructed when the lambda finishes executing? Am I wrong? ) static constexpr std::string_view whitespace = "\t\n\f\r "; I'd love if someone with more experience than me would pitch it, I usually avoid `string_view` because of these dangling "issues", only using it in later stages as an optimization. Since you're using MSVC I'd also replace `strtoll` to `from_chars` just for the hell of it. [this blog post](https://www.bfilipek.com/2018/12/fromchars.html) was posted here recently, which introduced me to it and it looks pretty neat.
That tooltip tells you which warning is triggering (-Wpadded) and gives you a link to Annotation settings. Why don't you just disable that warning in the settings?
String literals are lvalues. https://stackoverflow.com/q/10004511/1833497
&gt; is this something like numerical modeling, process control, business logic, software framework I mix of these. &gt; What's the product? A package of data acquisition sensors and the software to process them.
You're right, I got the terminology wrong. Aren't they still temporary though? Getting destructed before the `string_view` is accessed?
A string literal is a pointer, so it's the same as passing e.g. the literal 1 to a function. The constructor takes that pointer by value, so it's simply copied and remains alive for the call of the function.
I agree with this. C++ is a brilliant language but putting together a software using numerous 3PP libraries is truly painful. Especially when you’re aiming for at least two architectures. Messing with Cmake, Makefiles, selecting the right compiler, etc.. is a big let down when you know that this is ridiculously simple for go, rust and not mentioning python and it’s package manager. Single header libraries are a community reaction to the lack of a simplified and straightforward package manager for C++.
Oh! You're absolutely right. It's also mentioned in the notes on the [cppreference page](https://en.cppreference.com/w/cpp/string/basic_string_view). I didn't realize the lifetime of string literals worked like this (though it makes perfect sense with them being `char*`), thank you for pointing out my mistake and teaching me something. I'd still argue against using `string_view` in both cases, safety in the constructor and short string optimization in both. Though these arguments are fairly subjective and you're completely correct about it not being undefined behavior, so the use of `string_view` here is not wrong.
String literals aren't pointers - they are arrays that can decay to pointers.
What is the difference in semantics?
Looks good. Very readable style, loads of tests. Thanks for posting. I don't know of other such backports, so it fills a gap.
Basically, the python API is their primary focus and the C++ API is new and is essentially a preview release. I see nothing strange about this.
Suggestion for improving your type traits would be to copy the `is_detected` machinery (See [cppreference](https://en.cppreference.com/w/cpp/experimental/is_detected) for what I mean and how they're implemented). Makes writing traits like `is_invocable` MUCH simpler: template &lt;typename F, typename... Args&gt; using is_invocable = is_detected&lt;invoke_result_t, F, Args...&gt;; Also, the implementation here of `invoke_result`/`invoke_result_t` matches the standard. But in my experience, you (a) only ever use `invoke_result_t` and (b) never in a context by which you need it to be a non-deduced context. Your mileage may vary. But to that end, you could get improved compile times by defining the alias directly: template &lt;typename F, typename... Args&gt; using invoke_result_t = decltype(invoke_hpp::invoke(std::declval&lt;F&gt;(), std::declval&lt;Args&gt;()...)); This avoids having to instantiate a few more templates. 
One workaround, that makes code even more complex though, is to do RPC over Handler/Looper messages. Have you guys measured that route as well?
Views should work like pointers do. Using `const T&amp;` works with pointers and is there to ensure that the function doesn't reassign to it. It is not there to ensure what it dereferences is const. Views that cannot be used when passed by `const T&amp;` should be considered fundamentally broken.
If you pass one to an overload set where one function takes a `const char*` and the other takes a `const char (&amp;)[N]`, the latter will be selected
Thanks for posting! It may be good, except for the last part. Do not modify `CMAKE_CXX_FLAGS`, these times are behind us. Use the target-based approach and set flags on targets, not globally with the `CMAKE_CXX_FLAGS` variable.
Don't forget the T and C prefixes. :)
I generally agree on that approach and we do so for includes and linking and target configuration defines or fpic, but I really don’t see what the advantage is when it comes to warnings or generic stuff like optimization level, cxx standard/features even (which I only assume goes out of sync a commit later), or ABI/linking changing things. In fact it feels like a good approach to have those things be set exactly once. Even for dependencies, for the sake of compatibility and not breaking. Is there any writeup/Talk ging a real advantage for that part of compilation flags? Last cppcon there have been a lot of people advocating the single environment/build everything from source style instead.
There are lot of backports from Martin Moene: [https://github.com/martinmoene](https://github.com/martinmoene). There is invoke-lite: [https://github.com/martinmoene/invoke-lite](https://github.com/martinmoene/invoke-lite)
Well, I have been compiling with `-Weverything` for years, and I don't see any broken warnings. Some of them are useless and I disable them. What are the ones you consider broken? Also, It will never prevent someone from using my library. They are just warnings, not errors, I don't use `-Werror`. &amp;#x200B;
And the best part is... One can do all that while using CMake. Which is even more fantastic!!!! 
A C++ frontend wrapper around a python backend? What a world we live in!
I think the ultimate backend/core is written in Lua, isn't it? [Torch](http://torch.ch/). And PyTorch is the Python "frontend" for it? It's a bit strange though that the C++ frontend is then part of PyTorch and not Torch itself?
Written in Lua? That says it uses LuaJIT as the scripting language. It looks like it wraps lots of libraries up and exposes them with LuaJIT. It isn't written in LuaJIT and is definitely not written in Lua. That would make the speed unusable, not to mention writing all these libraries would be impossible. 
To add to what the others said, even if the literal were a temporary it wouldn't matter. The string view is converted in the constructor of Dice and the temporary isn't destructed until the end of the expression in which it's used (i.e. when Dice's constructor returns). It's a fairly pointless use of string_view anyway as the first use of it is to convert it into a std::string.
PyTorch is not a Python frontend to Lua Torch. Installing it should not require Lua at all. (But it is possible that they might be sharing a common C backend hence the name, but I am not sure)
PyTorch has a C++ back-end, and the now-released C++ front-end is an API for it, just like the Python front-end. The C++ API does not interface into Python, nor is PyTorch based on Torch, nor is any core written in Lua. To remove confusion, Torch should be renamed to "LuaTorch\_OLD", and the C++ front-end should be called CppTorch. ;-)
What do you look for in a Junior C++ engineer and are there opportunities for those with only 6 months professional experience?
Why would one do it this way rather than just calling the Callable?
Pytorch does not have a Python backend.
Ooh I see! So the "old" Lua Torch from http://torch.ch/ is basically dead/deprecated, and PyTorch its "successor" so to speak?
`sizeof` and `decltype` can observe the difference. A reference to an array can bind to a string literal, but it can't bind to a pointer.
IIRC, "modulo" is available because integer division instructions usually write the remainder to another register if you let them?
That is not true due to the arcane details of how overload resolution works. However, it is possible to observe if you carefully craft your overload set: C:\Temp\gcc&gt;type meow.cpp #include &lt;stdio.h&gt; void meow(const char* ptr) { printf("meow(const char* ptr) %s\n", ptr); } template &lt;size_t N&gt; void meow(const char (&amp; arr)[N]) { printf("meow(const char (&amp; arr)[N]) %s\n", arr); } void hiss(const char* const&amp; ptr) { printf("hiss(const char* const&amp; ptr) %s\n", ptr); } template &lt;size_t N&gt; void hiss(const char (&amp; arr)[N]) { printf("hiss(const char (&amp; arr)[N]) %s\n", arr); } template &lt;typename CharT&gt; void purr(const CharT* const&amp; ptr) { printf("purr(const CharT* const&amp; ptr) %s\n", ptr); } template &lt;size_t N&gt; void purr(const char (&amp; arr)[N]) { printf("purr(const char (&amp; arr)[N]) %s\n", arr); } int main() { const char * p = "pointer"; meow(p); meow("string literal"); hiss(p); hiss("string literal"); purr(p); purr("string literal"); } C:\Temp\gcc&gt;g++ -Wall -Wextra meow.cpp -o meow.exe &amp;&amp; meow meow(const char* ptr) pointer meow(const char* ptr) string literal hiss(const char* const&amp; ptr) pointer hiss(const char* const&amp; ptr) string literal purr(const CharT* const&amp; ptr) pointer purr(const char (&amp; arr)[N]) string literal 
Yes? But the language is not restricted by the instruction set. Python define signed integer division as rounding towards minus infinity, and therefore enjoy the benefit of having a signed remainder that follow modular arithmetic. The only reason C++ chose to not do so was because of Fortran taking the "wrong" stand.
The closer you hew to hardware behavior the faster you are; this is the reason for lots of UB and IDB; C allowing space for different hardware behavior to let things like signed integer division be hardware-accelerates. 
Because you can want to call class member functions for example. Or get a class member variable. Call by reference, by pointer, by std::reference\_wrapper and other cases :)
Well, Torch, from http://torch.ch/, which I am quite sure is the "original Torch", is definitely LUA, or possibly the core is written in C but it's use is from Lua.
Is this special for string literals, or is it true for any array? I completely expected `meow("string literal")` to output `meow(const char (&amp; arr)[N]) string literal`.
Can't you do all of those things using normal C++ syntax and not these two functions, though?
Different syntax for each; this gives an option for a single, unified syntax.
Of course you can do it. But in template code you have common case when you should call something in a one syntax. This is a very common case in functionality like \`std::bind\`, \`std::function\`, \`std::package\_task\` etc.
When you have a C++14 standard library available, `invoke` can be implemented in a few lines by letting `std::mem_fn` do the hard work for member pointers. `is_invocable` and `invoke_result` are slightly trickier but not too much: the bulk of the work can be outsourced to `std::result_of`.
That makes way more sense. Thanks the info.
As someone who wrote c++ for many years with vim + plugins and vs code on the occasion. Visual studio's debugger is simply fantastic. If you work very closely with memory the introspection it provides is absolutely wonderful. 
Welcome to Reddit, interesting first post. For me the main reasons are the debugger, ease of use (fuck cmake and anything that isn't selecting a list of files / requires learning some single-use DSL) and familiarity (been using it since Visual C++ version 5 in the 90s).
very cool! if you dont mind sharing - how many years of C++ experience do you have? how did you get so good? :)
Thank you! About 12 years of commercial experience and 3 non-profit :-)
Debugging experience is infinitely better, the solution system is actually pretty good and I don't understand why people hate it so much, it has a lot of built-in features that work nicely together, there are a lot of "hidden" advanced items (e.g. dissasembly, etc.) and, well, it actually comes with the compiler.
A huge gain in the parallel stack and profiler. If you deal with heavily multithreaded applications you'll find a huge advantage over vs code. If you can debug with printf, most likely won't be able to experience the difference. Having the ability to break and see exactly were every thread is a huge advantage. Letting the tools determine which blocks spend the post time on the CPU, priceless. 
thanks for the response! I'm going to try to understand this had been looking for this for a while :)
The most immediate things that come to mind: - VS proper has somewhat better and more reliable C++ navigation (Intellisense) for the time being, though the popular VSCode C++ plugins are slowly closing that gap - VS proper has *vastly* superior C++ refactoring support and plugins (VAX, Resharper, etc.) that make it even better by leaps and bounds - VS proper has some proprietary plugins like VAX and ReSharper that make that Intellisense and refactoring _even better_ - VS proper has a rather more capable and easier-to-use debugger than the one provided by the Microsoft VSCode C++ plugin - VS proper has an integrated CPU and memory profiler - VS proper has multi-monitor support in its UI - VS proper has graphics (Direct3D) debugging and profiling tools - VS proper has a lot of out-of-the-box support these days for development on Android and other platforms that require tons of manual configuration in VS Code - VS proper has tools for UI visual editing for Windows desktop developers - VS proper has some "Enterprise-y" tools for modeling, ops, teams, etc. that matter to some people
Pretty much, yeah.
I think the inherent difference is that an IDE is designed not just to edit code, but is also responsible for managing the entire project's build process. When using a stand-alone editor, you might, for instance, delegate that to a set of build scripts. But because an IDE has an inherent knowledge of the entire project, certain tools tend to work together a bit more smoothly. Others have mentioned the smooth integration with a debugger, but there's also things such as refactoring, profiling, and so on. That's the "integrated" advantage in an Integrated Development Environment. That being said, I don't think you're going to see a huge difference when working in an editor versus an IDE. After all, at least in my experience, the vast majority of my time is spent in a pretty straightforward edit-test-run cycle. But I think an IDE provides a slight edge in ease-of-use when you occasionally need to reach for other types of tools. 
Don't post click-baity titles that require clicking on to figure out what the project actually was. 
It’s true for any array. The issue is that overloading values and references can behave unintuitively, even if you know about decay. The hiss() example shows that the template tiebreaker is even involved. This is one of the reasons why I say that overload resolution needs to be treated with care - it works well if you know how to avoid creating complicated scenarios.
The fastest method is probably using SIMD intrinsics to unpack a 32-bit value into 32 zero-padded 8-bit values.
Hm, I really should learn about how to code with SIMD.
If you install the C++ extension you can use the same debugger that comes with normal VS, though you have to edit a json file to fill in all the settings and stuff like that. I don't know if all the debug engines are supported but garden variety native C++ debugging works fine.
It differs per CPU vendor. Intel has a great site that lists all the instructions here: https://software.intel.com/sites/landingpage/IntrinsicsGuide/ For example, assuming you're targeting a machine with AVX2 support (because it uses a 256 bit register size == 32 bools from the uint32_t) I would do something like the following. (I have not tried this, and I may have endianness flipped in a few places, but it should give you an idea...) uint32_t source = /* */; // source8 = {source, source, source, source, source, source, source, source}; const auto source8 = _mm256_set1_epi32(source); // bytesShift = {0, 4, 8, 12, 16, 20, 24, 28}; const auto bytesShift = _mm256_set_epi32(0, 4, 8, 12, 16, 20, 24, 28); // maskLower4Bits = {15, 15, 15, 15, 15, 15, 15, 15} const auto maskLower4Bits = _mm256_set1_epi32(15); // spread4Bits = {(source &gt;&gt; 0) &amp; 15, (source &gt;&gt; 4) &amp; 15, (source &gt;&gt; 8) &amp; 15, (source &gt;&gt; 12) &amp; 15, (source &gt;&gt; 16) &amp; 15, (source &gt;&gt; 20) &amp; 15, (source &gt;&gt; 24) &amp; 15, (source &gt;&gt; 28) &amp; 15} // (that is, each int in the register will have 4 bits of the original int) const auto spread4Bits = _mm256_and_si256(_mm256_sllv_epi32(source, bytesShift), maskLower4Bits); // turn each int that now contains 4 bits into 4 bools by shifting the first 4th bit to 24, // 3rd bit to position 16, 2nd bit to position 8, and leaving 0th bit at 0 // (That is, for each int32 in spread4Bits, // result = original &lt;&lt; 20 | original &lt;&lt; 13 | original &lt;&lt; 7 | original) const auto withDupeBits = _mm256_or_si256( _mm256_or_si256(_mm256_srli_epi32(spread4Bits, 20), _mm256_srli_epi32(spread4Bits, 13)), _mm256_or_si256(_mm256_srli_epi32(spread4Bits, 7), spread4Bits) ); const auto maskBoolBits = _mm256_set1_epi8(1); const auto resultBools = _mm256_and_si256(withDupeBits, maskBoolBits); bool results[32]; // or a pointer you got from somewhere, whatever _mm256_storeu_si256(reinterpret_cast&lt;__m256i *&gt;(&amp;reuslts), resultBools); That gives you 32 bools produced in ~11 instructions (I'm assuing the constant set and set1s get factored out of the loop by the optimizer)
Probably not too helpful, but it has to be said: VS brings a c++ toolchain, VSC doesn't ;). The answer depends a bit on what toolchain and plugins you are using with VS code.
What about hardware breakpoints and viewing disassembly? This was a pain point that caused me to discontinue my attempts to use VSCode in the meantime.
In addition to Billy’s example, there was a good CppCon 2018 talk about processing UTF-8 with SIMD.
Nice presentation, I will have to check this out. Does anyone have any experience of how clang's static analysis holds up against commercial static analysers such as Coverity or PVS studio?
https://www.youtube.com/watch?v=5FQ87-Ecb-A
Hmmm it's the same debugger *engine* but I don't know if those things are exposed.
Thanks for the reply. Yea my sense was that the hooks provided was essentially the lowest common denominator across debuggers for a number of languages (JS, TS, C#, etc), which totally makes sense but leaves me crawling back to gdb/lldb/VS at the end of the day.
Non-SIMD method: #include &lt;array&gt; #include &lt;cstdint&gt; #include &lt;cstring&gt; std::array&lt;bool, 32&gt; get_bools(uint32_t bits) { static_assert(sizeof(bool) == 1); constexpr uint64_t bit_offsets = UINT64_C(0x80'40'20'10'08'04'02'01); constexpr uint64_t bits_low = UINT64_C(0x01'01'01'01'01'01'01'01); uint64_t bits_0 = ((static_cast&lt;uint8_t&gt;(bits &gt;&gt; 0) * bit_offsets) &gt;&gt; 7) &amp; bits_low; uint64_t bits_1 = ((static_cast&lt;uint8_t&gt;(bits &gt;&gt; 8) * bit_offsets) &gt;&gt; 7) &amp; bits_low; uint64_t bits_2 = ((static_cast&lt;uint8_t&gt;(bits &gt;&gt; 16) * bit_offsets) &gt;&gt; 7) &amp; bits_low; uint64_t bits_3 = ((static_cast&lt;uint8_t&gt;(bits &gt;&gt; 24) * bit_offsets) &gt;&gt; 7) &amp; bits_low; std::array&lt;bool, 32&gt; ret; memcpy(&amp;ret[ 0], &amp;bits_0, 8); memcpy(&amp;ret[ 8], &amp;bits_1, 8); memcpy(&amp;ret[16], &amp;bits_2, 8); memcpy(&amp;ret[24], &amp;bits_3, 8); return ret; }
VS is IDE, VS Code not
Intrinsics come in all manners of shapes and sizes. https://en.wikipedia.org/wiki/Bit_Manipulation_Instruction_Sets#Parallel_bit_deposit_and_extract #include&lt;array&gt; #include&lt;intrin.h&gt; std::array&lt;bool,32&gt; boolDeposit(uint32_t rn){ const uint64_t spreadMask=0x0101010101010101ULL; std::array&lt;bool,32&gt; result; auto alias=static_cast&lt;uint64_t*&gt;(result.data()); auto interm=static_cast&lt;uint64_t&gt;(rn); alias[0]=_pdep_u64(interm,spreadMask); alias[1]=_pdep_u64(interm&gt;&gt;8,spreadMask); alias[2]=_pdep_u64(interm&gt;&gt;16,spreadMask); alias[3]=_pdep_u64(interm&gt;&gt;24,spreadMask); return result; }
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Omg just tried to install vs code to test it out as a replacement for VS. I uninstalled it the same day. Immediate issues: * Side panels can't be hidden automatically when I am in the editor. Such a waste of space and it really kept distracting me. * To get cmake support I installed about 4 plugins. Seemed to work but one of the pluggins kept showing error popups. Really annoying and I don't really know what was the issue certainly nothing wrong with CMakeLists * cmake Install tatget was not missing. The bug is reported on github but the dev doesn't seem to think it's important. Of course it's important my DLLs are all installed in this step how can the program run without it? * Debug/Release combobox is quite important but in VS Code it's placed on a status bar with tiny font size? * There is no font/color theme which would match VS2015/17 default exactly. So that doesn't help when someone like me wants to switch So although VS Code shows some potential it's not there yet. Too buggy and much less usable for me. 
Great, thanks!
&gt; just because T models Range doesn't mean const T does. In particular, things like filter\_view caches begin() to ensure amortized O(1) complexity, so it can't provide a begin() const without undue overhead. &gt; &gt;Ranges are not necessarily deep const; most views aren't. Thus, const Range&amp; offers but an illusion of safety. Awesome! I'm grateful to you for taking the time to explain this. I've edited your remarks into the post. Thanks :)
Awesome! I'm grateful to you for taking the time to explain this. I've edited your remarks into the post. Thanks :)
Once again, it uses LuaJIT as a scripting language, it is not written in Lua, and no one is writing a C++ program to call scientific numeric heavy stuff written in straight Lua.
So... you missed the second to last sentence?
&gt; it uses LuaJIT as a scripting language, it is not written in Lua Sorry, I don't understand that sentence. It doesn't make sense to me. But I am not very familiar with the Lua ecosystem. Care do elaborate?
I’d be lost without the ability to freeze all threads except the one I’m debugging, such an insanely useful feature.
+1, interesting. I still think this will lose to the vectorized version because `pdep` runs on the "slow int" unit and there is only one of those per core, this still needs 4 movs, etc. but wouldn't know without actually benchmarking. (Skylake has 3 SIMD bit manipulation units per core)
I can't even get C++ working in VS Code, do you have any good resources to get started? 
A better scrollbar. [https://i.imgur.com/fRvBcfi.png](https://i.imgur.com/fRvBcfi.png) &amp;#x200B;
In my experience Coverity finds a lot more stuff. A big part of this is because the clang static analyzer for the most part only looks at translation units in isolation instead of looking at the entire program. Also, if you want to run the clang static analyzer, I would highly recommend using codechecker as a frontend. It gives you a lot of the report tracking stuff that is missing from the static analyzer itself that you may expect coming from the commercial tools. 
What part doesn't work
The "C++" part. It's been a while since I even tried, but back when I was attempting to, I couldn't even get a development environment running in it. 
Well the advantage of cmake is that you are not locked to visual studio. Something that gets more and more important. Cmake isn't that hard I was scared of it as well but it turned out to be quite ok.
that's no less vague.. did you install clang (or gcc if there's an extension for it)? did it work in console? Which extension did you try to install to compile with? What was the error message? 
pdep has a latency of 3 cycles and throughput of 1 per cycle, so it seems pretty fast. I think the two end up about the same, just adding up the latencies.
I would use a 64-bit input instead and do shift+mask, avoiding the need to splat bits across lanes with a multiply or broadcast -- ret[0..7] all bit 0s, ret[8..15] all bit 1s, etc.. Also, while bool is 0/1 on all mainstream platforms that I've worked on, is there one that uses a different storage representation? 
Latency doesn’t matter here because it’s still 1 cycle per instruction; you can still retire one every cycle. If anything latency favors this solution because there aren’t dependencies between the instructions. But this one needs 4 times as many movs and 2 times as many shifts. That’s why I was saying it needs benchmarking
Yeah, that's way simpler, I feel silly. I've updated to use your method.
Isn't PDEP really slow on Ryzen? Thought it was something like 18 cycles non-pipelined.
Do you know the difference between using a scripting language to wrap libraries together and having the the whole thing written in the scripting language? 
Amazons print-on-demand fees are insanely expensive, this would easily double the price. I'm surprised PacktPublishing oder APress isn't going to help here, they publish almost everything.
It seems so according to Agner Fog's instruction tables. TIL.
Great tip, CodeChecker looks like a really nice frontend.
Great tip, CodeChecker looks like a fantastic frontend.
I can assure you personally (being one of the scheduled speakers) that it is all legit and Phil is putting quite the effort into making it a top-notch conference :)
What OS are you running? What issue in particular like compiling and debugging? 
I can get it working but it annoys me that it requires setting up the same thing again and again. And it annoys me it needs setting up simple things like using the system compiler, include paths, etc. I mean if literally every other editor can work that stuff out and "just work" then why can't VSCode?
No you can't. At least not a beginner. Documentation is the worst and reason whey CMake is unpopular. Almost all that comes up by google is totally outdated (thank you google algorithm).
I followed these directions, on Windows 10: [https://code.visualstudio.com/docs/languages/cpp](https://code.visualstudio.com/docs/languages/cpp) &amp;#x200B; Nothing would compile, like I was just typing plain text and expecting it to just 'run' as a final output from a CPP program, and I decided it wasn't worth my time when 'full' Visual Studio worked. I just want to figure out how to get VS Code to work so I can use something smaller and more lightweight.
Windows 10, following these directions: https://code.visualstudio.com/docs/languages/cpp Nothing would compile in VS Code (I might as well have been typing plain text), while 'full' visual studio worked just fine.
BTW He organizes the [CppUserGroupCracow](https://github.com/CppUserGroupCracow/Meetings) meetings.
It is not only legit, but given the schedule [https://cpponsea.uk/schedule/](https://cpponsea.uk/schedule/) (many great C++ experts and top speakers, most of them you can find them in twitter), it is going to be a relevant and interesting conference.
Maybe this is related? I dunno. I had 'full' visual studio installed and working at the time, so maybe VSCode's issues with system paths were somehow related to another working development environment already being present? I don't know. It was super frustrating, but needing a full-up version of Visual Studio is annoying when I just need to write and edit 'smaller' pieces of robotics software (and VSCode seems like it *should* be able to do so, while taking up less resources).
Its 6 ops with a latency of 18 cycles.
Nah VSCode is just a bit manual compared to everything else I have used. It relies on two json files for managing it all and it is just a bit of a crap way to do things imho. 
It's a little weird that one of the organizer's sponsors also happens to be his employer.
Hmm to be honest I've only used vs code on Linux. I use visual studio community on Windows.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a4pegu/confused_on_how_to_use_particle_swarm/ebgi1tr/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Yes it would definitely be slower than a vector variant. The only benefit is no memory alignment requirement and not having to worry about any SEE optimizations the compiler might have stuck in before hand. 
I've applied for a student ticket so I'm hoping it's good
That is exactly what the illuminati would say.
How so?
Sarcasme i guess
I mean, even in visual studio you have to compile, its a compiled language. it should just run on hotkey press. did you read this step? &gt;Note: The C/C++ extension does not include a C++ compiler or debugger. You will need to install these tools or use those already installed on your computer. Popular C++ compilers are mingw-w64 for Windows, Clang for XCode for macOS, and GCC on Linux. Make sure your compiler executable is in your platform path so the extension can find it. The extension also supports the Windows Subsystem for Linux. 
Yes, I installed the compiler. I get that it needs that. My issue is, having in theory setup VSCode just fine, the same known-good CPP file compiles in 'classic' Visual Studio and not in VSCode. 
Yes! There's a lot of big names in the C++ world who will be talking about interesting things. It's going to be worth it! 
Stuff like Hello World? Weird, if anything classic visual studio would be likely to have more warning flags on
Yeah, I've had little issue with it on Linux, but I've also stuck to Python in Linux. I also have no issue with it using Python in Windows - but that just Python not caring about much more than using the right syntax. 
I believe I posted this to r/programming about three years ago and got a decent response to it back then (and some suggestions to clean it up that I still use to this day). The issue was that I hadn't really tried to clean up the code since then. This library is my most popular (and still gets the occasional star on GitHub to this day), so I decided to spruce it up, add better testing using \[Catch2\]([https://github.com/catchorg/Catch2](https://github.com/catchorg/Catch2)), add CMake support, and overall clean up the code. Hope you all like it/can make use of it!
I'll poke at the JSON files. I'm familiar with the PITA they can be, I've had to set them and re-set them multiple times thanks to using VSC for LaTeX, and needing different build chains for different documents. 
One nitpick from reading the README: ALLCAPS should be reserved for macros. I guess it is typ late at this point to change your library's namespace, but something to keep in mind for future projects.
From known working, complex robotics programs, basic logic programs (IF-ELSE tutorials, essentially), all the way down to *HELLO WORLD*. It was really weird, and not worth the effort when Visual Studio Classic was working. 
Looks to be most interesting. However the company nference title left me disappointed, I was kinda hoping the conference was on a cruise ship someplace close to the equator. Let’s face it going to Britain in the middle of Feburary isn’t as appealing to actually being on the sea where the sun is shining and the temperature is 80° F. This leads one to wondering if cruise ships can even accommodate this sort of business? I tend to avoid cruises due to the feeling of being inprisoned I often feel on boats. However a conference like this might actually engage my brain enough that I would not mind. 
Care to enlighten me?
I'll definitely keep that in mind, thank you!
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/a4qesp/need_help_with_gross_pay_assignment_error_is_left/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The standard way of doign what you want isn't with `std::uniform_int_distribution`, which is mostly optimized for arbitrary ranges, but `std::independent_bits_engine`, which is designed to output fixed amount of bits. In theory, STL implementors could do all the optimizations suggested elsewhere in this thread, but in practice they don't, since it's generally the same speed, or faster, to output a new `word &amp; 1` with a fast generator than doing all that unpacking.
That happens all the time. I think it’s a good thing that employers support their employees outside endeavors. When companies are looking to sponsor events they want to make sure the event is legitimate. One their own employee is organizing is a safer bet. Seems like a win-win situation to me. You suspect something nefarious?
Ping /u/philsquared who will hopefully set your mind at ease :)
It looks to be a great conference, IMO. Wish I was speaking there, but didn't fit my schedule :-(
&gt;We are thinking about making the framework idiomatic C++ only. &amp;#x200B; This would be so nice.
It's also a little weird to be making this comment when it's about your former employer :-P
Nobody here suggesting to abuse `vector&lt;bool&gt;` for it? Obviously you go into implementation-defined land, but a packed implementation would allow you to dump your 32/64 bit random values into it. You don't have to use `vector&lt;bool&gt;` explicitly, you can just take inspiration of the proxy methods and use them when accessing your data.
&gt; VS proper has multi-monitor support in its UI Quality of the support may be limited if your monitors have different DPI. It seems to be better than it used to though.
It's nice, but one thing that is quite common is to roll for successes or to have exploding dice. It would be possible to implement this by passing some lambda as an additional parameter. It would be called after each roll, and its return value would be used instead of the basic return. For example: auto explodingDice = Dice(1,10,1, [](int roll, Dice* this){ return roll==10?this-&gt;operator()+roll: roll;} //rolls again and adds the result recursively if roll returns 10. ); auto successDice = Dice(1,6,1, [](int roll, Dice* this){ return roll&gt;4?1:0;} //1 for success, 0 for failure ); You can also add syntax for the string parsing, but allowing arbitrary processing functions would be awesome, it would actually make it superior to Roll20 in some cases (though this interface is limited because you can't do things like reroll once or keep n among m dice), so I guess you'd need a different interface.
No, because if you don't know that much, I have no idea why you would confidently claim that torch was C++ calling Lua. This is the basic structure of why things like torch work at all. If you don't understand that, then you don't understand them on a very fundamental level.
Speaking as someone who has never been on a cruise, don't cruise ships usually have very poor internet? That seems exceedingly important for a C++ conference.
the other maintainers of such a project might not be so excited to accept a major refactoring. they might not know modern c++ and they might not want to take the time to familiarize themselves with all your changes. maybe ask before you do all that work if you care about your pr being accepted. that said, I hope someone gives you a better answer and good luck. 
Here, go nuts: [https://github.com/espotek/labrador](https://github.com/espotek/labrador) Wrote it straight after finishing university; background was in electrical eng. I'm now a junior C++ developer at a tech company with fantastic software practices and I cringe every time I go over the old code. Zero STL use, plenty of C-like idioms, tangled-up classes (including UI and backend!!), non-use of stdint, dumb compile options (e.g. forcing -O0 for ARM) and more. Somehow works well without bugs, though. Happy to send you some free hardware by the way, if you're proper serious about the refactoring.
Refactoring is what you do in academia. In the real world, you deal with it. Assume you have a messy code base that works well in production. How do you convince management to spend time on refactoring it? What's your business case? Just jumping in and rewriting other people's code is also more likely to piss them off than it is to build a good working relationship. If you have a hard time navigating any non-trivial amount of code - learn to navigate any non-trivial amount of code. Maybe look for a project that has a lot of automated testing so you quickly figure out what you're breaking.
That's a good suggestion! I've now added this to the benchmark. While it's a lot faster than the uniform_int_distribution version, it is still about 2.6 times slower than my original post, even with the `sfc64` random number generator which is one of the fastest I know. http://quick-bench.com/f1NuFGw8phZiwkwkxxiIdS2Sa74 
Is this your project? It's fantastic. I have a labrador :)
Hmm. Fair point. I really didn't considered it from that point of view... I guess I'm just too focused on technical skills and I forgot that there is someone who wrote the code. &amp;#x200B; Regarding your last point, I think that I'd actually need to be doing some work in the code in order to learn to navigate it. Maybe it wouldn't be necesary per se, but I'd probably go crazy if I had to read and navigate through a codebase without being able to make any changes...
Ah yes, I hadn't really considered that. I don't intend to send in a pr anyways, as this is something I want to face as a learning exercise and not much more. &amp;#x200B; Thank you!
Isn’t DWM fundamentally a canvas styled backend?
It's maybe lacking buzz only because it's the first time this is hosted. Phil Nash is reputable enough in the community to ensure that this is not a scam. Though I perceive it's not lacking buzz at all -- it's being mentioned on [CppChat](https://www.youtube.com/c/Cppchat) all the time (unsurprisingly), and also has been mentioned on [CppCast](http://cppcast.com/2018/05/phil-nash/) once or a few times. Same for [Twitter](https://twitter.com/search?q=cpponsea), as another poster had already mentioned.
Kind of depends on the company and the team and the type of refactoring needed. From what I've seen people don't jump straight into a full scale refactor. Make one ticket to change one idiom across the codebase, make one ticket to convert raw pointers to smart pointers, etc. If the codebase is large, convert it for one subdirectory first.
Ohhh thank you very much! I might take you up on that hardware in the future haha! For now I'll just start going through the code to try and get an idea of how it works.
They do fund a lot of C++ conferences as part of their business strategy - including other important events such as CppCon and Meeting C++. While it probably didn't take Phil a lot of convincing to have them back C++ on Sea as well, they probably would've considered it either way regardless of who's organizing it.
What "C/C++"? All I see is C.
Thanks! It being a scam wasn't a high probability hypothesis, but you know, when you're spending £1800 plus lodging and travel you want to double check. I mostly want to know how big this is going to be though. I have no idea how many people are expected to attend, and can't get an estimate based on previous years. 
You could try my unfinished project. I can't remember if it compiles :P https://github.com/mdrost/evolution https://i.imgur.com/Hkhv9uU.png https://i.imgur.com/saTrPwE.png 
I would take what two\_more\_beer says with a grain of salt. There are many companies (which all happen to be great places to work) that refactor semi-regularly. Usually not whole projects, but definitely parts. The two most important questions you should ask potential interviewers are: \- What is your code review policy, and what is the code review culture like (a good company will review just about every commit and reviewers will always try to offer some form of constructive feedback) \- How often do you refactor old code (there are many good responses, and sometimes critical code should be left alone, but if they don't think about it at all then that's a red flag!) 
[cppcheck](http://cppcheck.sourceforge.net/) can detect loops that could be rewritten using stl-algorithms. See [here](http://pfultz2.com/blog/2018/11/04/stl-alogrithms/)
I bet I could find 100 tutorials with exactly this information
Hey, that's awesome! I run into Labrador users every now and again and it always makes my day. Were you one of the backers for the Crowd Supply campaign or did you get it afterwards? (Yeah, it's my project. :P)
Awesome. Feel free to message me if you have any questions. First thing I'd do, before reading a thing, though, is compiling the software and running it. :)
Wait. I find Geeks for Geeks has [exactly the same material](https://www.geeksforgeeks.org/socket-programming-cc/). What's happened?
I sure hope it catches up soon. The amount of time it would save the world would be unbelievable.
Well it's named C++**20** for a reason ;)
I wasn't a backer. I got it just a few weeks ago. It's almost like a pocket DMM, but with a signal generator 😀
When I was developing for Android, I've overridden the new operator (with the overloads), and allocated the requested memory region with an additional header (using malloc). The header contained the location of the allocation, the size, and some linked list pointer to store the allocated regions in a global list. When I've allocated the region, I added it to the global list, and returned a pointer with an offset to the allocated region. (Offset is the size of the header) By overriding the delete operator, you decrease the parameter pointer to access the header, and remove the entry from the global list. This solution worked for me on Android, and other operating systems as well (iOS, Win32, UWP, Linux, macOS). In order to get the location of the allocation, I used a macro for the redefinition of new #define new new(__LINE__, __FUNCTION__) //or something like this, I don't remember There are probably more pitfalls for this solution, but this was a long time ago for a hobby project, and I didn't search for any third party solutions beforehand. It's not a too big hassle to implement this, but a good learning experience nonetheless. Also, you'll need a global function that you call when you exit the app to list all the not deallocated regions.
The standard doesn't give any guarantee about header paths or names etc. So the "proven scheme" isn't standard, it's just how it's currently working on most impls. It is workable because that makes modules only be hierarchically related by if there is a dependency. It's not complicating anything. It might make module names inconsistent with file names but that's not a new issue either.
Where have I confidently claimed that torch was C++ calling Lua? I've read my posts again in this thread and your statement is outright wrong. I wouldn't claim such a thing because I do not know, which is exactly the reason why I am asking here. And you're being extremely condescending. Anyway, all the best bathing in your enlightenment, I am sorry I do not understand the fundamental concepts here and I am sorry that I asked and got a dick to reply.
Thanks for the extensive answer, I hope we'll be hearing more of this project in the future : )
&gt; I don't see how time differs. And lets be real here, the fact you can't add seconds to minutes by default makes it unusable for many application. No. The fact you can't add seconds to minutes by default makes it safe. If you want to add second to minutes, you will have to _explicitly_ decide if you want a result in seconds (writing for precision) or in minutes (writing for approximation). The compiler cannot take this decision for you, so instead of you writing code that is ambiguous (and forces maintainers of your code to guess what you meant in that code in the first place) you now have to write with explicit semantics and make your intent clear. This is the advantage of strong typing. Here's a similar design example in the standard library: `std::min` and `std::max` take a single argument type. (that is, you have `template&lt;typename T&gt; T std::min(T, T)`, not `template&lt;typename X, typename Y&gt; &lt;presumably some use of std::decay_t?&gt; std::min(X, Y)`. The second form would allow you to write `std::min(x, y)` for whatever two comparable types. The fact that you cannot do that, forces you to write `std::min&lt;return type&gt;(x, y)`. Specifying the return type like this makes it explicit and documents your intent in code (if you wanted the comparison performed in integers, then use `std::min&lt;int&gt;(x, y)`; if you wanted it for doubles, then write `std::min&lt;double&gt;(x, y)` and so on).
I can't tell you how many people are going to attend, but it looks to be great, great program, great speakers, and I am sure Phil Nash and the organizers are doing a fantastic job. They did advertise quite a bit on social media (Twitter), but I agree it's weird that Phil doesn't list it on his website and the sponsors don't. Maybe if Phil is reading this, these are some good hints at what to improve? If I was from anywhere in Europe, I'd certainly go and I would be quite confident that it'll be worth the trip.
Clang has AddressSanitizer. Not sure if Android is supported.
I'll throw you a suggestion: https://github.com/iondbproject/iondb This is a key-value store for Arduinos and other microprocessors that I worked on as part of a team for a few years. It uses a C back-end interfaced through a thin C++ API, but the back-end wasn't ever built for such a use case, so it's very kludgy and user unfriendly to actually use in a project. If you do end up working on it, feel free to fire me questions. I'm intimately familiar with the project, and if you make significant progress I can see about potentially getting your changes merged upstream.
We've had 98 years to implement it!
Ad hominem. ಠ_ಠ
Interesting that you feel there is a "lack of buzz". As others here have been able to assure you before I've got here - this is definitely a real thing! I can quite understand those alarm bells going off, though - with no history, and coming out of nowhere with an apparently rich schedule - you're right to double check before spending the money! &amp;#x200B; I suspect you and I inhabit different bubbles. From where I'm standing (which is, admittedly, the epicentre) there is a lot of buzz and I'm really pleased that the community is already so excited about this event. There's clearly more I can do to promote it more widely, and it would be great to know where you would expect to see it coming up more to feel that there is more of a "buzz"? &amp;#x200B; As for my website - that's a fair point. Since I started putting the conference together (a big job in itself), on top of my full-time role at JetBrains, I also started co-hosting (and producing) [cpp.chat](https://cpp.chat) \- and started attending ISO C++ meetings! I've not really had time to put anything on my blog. The fact that the [cpponsea.uk](https://cpponsea.uk) site gets significantly more traffic right now doesn't help that! But, you're right, it does seem a bit weird and I'll correct that soon. &amp;#x200B; Jetbrains have mentioned the conference, though. As have some of the other sponsors. As has been mentioned elsewhere it is regularly mentioned on [cpp.chat](https://cpp.chat) (of course), but also CppCast. And the cpplang Slack. There's also a dedicated channel on the #Include&lt;C++&gt; Discord. &amp;#x200B; So, in short: thanks for raising this. At the very least, anyone else with the same concern might end up here after a bit of googling. Ideally, though, I'll plug whatever gap led you to the concern in the first place. And, finally, hope to see you there :-)
Rumbled ;-)
:)
&gt; I wouldn't do it and the reason would be human overhead. Commits have to be reviewed and before you know it, it's been a day. You push your team towards accepting a small dose of cognitive dissonance in your code. Most coders (sorry for the strawman) handle that by ignoring code comments and (later) claiming them to bring more problems than they solve. &gt; There's dozens if not hundreds of those lines in my team's repo but I don't have the fortitude to withstand the bikeshedding that would ensue. This is also something that your team causes (by accepting lower standards in code review). These comments will just take some attention from developers from time to time and introduce noise in your code. More than this, the presence of such noise in your code base opens the door to other issues (like the opinion that comments in code are bad because they "go stale" - somehow by themselves).
Go nuts: https://github.com/tldr-pages/tldr-cpp-client
Yes!
That's a great question - and I look forward to finding the answer :-) I can tell you, though, that I'm expecting somewhere between 200 and 300 people for this first year. I was originally shooting for 200, but I've revised that up a bit given the interest I've seen from the community - along with tickets already sold (and comparing that with historical stats and trends from similar conferences). I can also say that we've already broken into triple figures. Given that most conferences have a hockey-stick shaped registrations curve, that's a really promising position to be in at this point - still two months from the event (too many people leave it very late to get tickets!) - but we might follow a different curve, of course. I had one person email me recently to say he was worried about tickets selling out because he's still trying to get all the approvals from his employer - but expects himself \_and 13 colleagues\_ to be going! We've had a few group bookings already - some from some well known names (which I obviously can't mention here) - but I expect those to be the later bookings in general. So we could have an explosion yet! We have a bit of headroom in the current venue. I think we should be able to accommodate up to about 400 before it gets too crowded (if we change some things around a bit). If it does become that successful I've got the next venue in mind already (which will continue to live up to the name!)
Such conferences (on cruise ships) do exist! They have their problems, though. I have been joking that, if Brexit makes it too hard for people to attend in the future, I might move the conference to Sealand ;-) &amp;#x200B; I see the British Winter as an advantage in this case, though. If it was too tempting to stay outside then people might miss more of the conference (and the networking opportunities along with it). This venue gives you the comfort of being indoors, on dry land, but with views across the channel!
Thanks Tristan!
Wouldn't it be weirder if they weren't, Dmitry? :-)
Thanks! And for anyone interested in the student or volunteers programmes, there's more info here: &amp;#x200B; [https://cpponsea.uk/news/volunteer-and-student-programmes.html](https://cpponsea.uk/news/volunteer-and-student-programmes.html)
I've also found that actually properly writing deduction guidelines can be very tricky. So now we have a feature that, when the library writer managed to use correctly, works fine for library users 90% of the time, but if the library writer isn't "an expert" all bets are off. 
Hope to see you next year!
By which I mean the year after, of course
I did the same in one of my personal projects: I spent approximately two hours writing a C++ cli app to do the switch for me (generating header guards based on "relative path from root dir") but this only worked because I was editing my own code (so I could make assumptions like "the include guard will be on the first two and last line in the file).
**Company:** Denuvo is a leading gaming security company specialized in the development of software protection systems for games created by the largest development studios and publishers of computer games around the world. Whilst combatting the fight against gaming pirates/hackers, you will be part of a tight-knit mid-sized technical team. As fully owned subsidiary of Irdeto, Denuvo is embedded in a global network of digital platform security companies. For more information visit: [www.denuvo.com](http://www.denuvo.com/) **Type:** Full-time, permanent contract **Description:** We are looking for multiple forward-thinking Software Engineers with a passion for programming applications using C or C++. Your task will be to develop new security concepts in cooperation with our customers. You will be performing security analysis, design and discuss new features and implement them in the next iteration of our technology. The team follows the agile process which you will also join in on related activities (Scrum). At times this position may also require you to travel to our customers/offices. **Location:** Salzburg, Austria (HQ) or Wroclaw, Poland. **Remote:** In exceptional cases this might be considered, though preference is to relocate to one of our two offices. **Visa Sponsorship:** Yes. **Technologies:** We expect you to have obtained a technical degree and be focused on programming in C or C++ using object-oriented development methods. We are using Visual Studio 2015 which relates to C++11 with some C++14, predominantly on Windows. Debugging techniques on the binary/x86-64 assembler level is a big plus, using tools such as IDA, WinDbg, etc. **Contact:** Please apply directly via our career portal https://career4.successfactors.com/sfcareer/jobreqcareer?jobId=21701&amp;company=irdeto&amp;username= this way we can ensure the team reviews your application 😊
Android does not support Leak Sanitizer yet.
Thanks for posting this here, never heard of it but it's close by and looks well worth going, I'll try to come with some colleagues.
If you’re interested I started x64dbg as pretty much C with some C++ standard containers. It’s more around 200kloc, but jumping in to big codebases isn’t really a challenge if you can keep all the code in your head amirite :) Me and the community are available for any questions you might have and you will pick up some operating system skills on the way.
&gt; This logic assumes that in line 2 below […] our intention was more likely to make a copy. So now programmers are free to choose a semantic which is either 1) unambiguous and verbose, or 2) arbitrary best guess. This is heading in the direction of Perl 5. Who the hell thought this is a good idea?!
Kinda, the main difference is that it's shared across all processes
I think Android Studio added a support for native C++ objects in their [memory profiler](https://developer.android.com/studio/profile/memory-profiler) some time ago.
What's the current status of `vector{v}`? If I understand correctly this originally deduced a single-element vector regardless of the type of `v` , but this was changed to deduce the copy-constructor if `v` happened to be a vector. Has this change actually been made yet or is it still waiting for C++20?
Ha, could use one for my masters thesis. Though Ive only got 1.2k LOC
&gt; “I like features that work 100% of the time. I hate features that work 99% of the time. Working 99% of the time is much worse than working 50% of the time.” There are no features that work 100% of the time.
[replxx](https://github.com/AmokHuginnsson/replxx) would definitely benefit from some refactoring. As project owner I could guide you what could be done in the first place.
The C++17 behavior is that `vector{v}` is a copy if `v` is a vector, not a single-element vector.
If i++; sometimes added 2 to i, I would be sad.
Thank you. I have a feeling that this will turn out to be a mistake. But we are where we are.
With operator overloading no one is stopping you from doing that. 
`===` and `!==` in C++ when
I'm currently refactoring a legacy codebase from C99 to C++17. So refactors do happen in real world. The business case is usually: time spent per ticket and tickets generated due to bugs resulting from bug fixes 😂. The biggest issue in dealing with real-world legacy code is lack of test suite as well as lack of bugs on the not-a-bug-but-a-feature list. Strongly agree with your viewpoint though. It was really hard to get them to agree to invest in the refactor. PS: I wanted to use Rust, but sadly management didn't want a niche language.
And what would the semantics of that be? Will they be overloadable? 
non-overloadable (using `==` and `!==`) but disabling any implicit convertion
Another example when you may still need to stick to make_ is when referencing a template inside of that same template: template&lt;typename...T&gt; struct S { S(T...){} auto foo() { S s{42}; // no CTAD here, S is a type, not a template } }; There is [workaround](https://godbolt.org/z/YO8MBM) that does not work for MSVC. 
Or, you know, you could move it to Zeeland, the dutch province after witch Dutch cartographers named, what is now know as New Zealand, to (from Staten Land to Nova Zeelandia) which James Cook then anglicised. Actually, just move it to Amsterdam, that would make my live easier :P Joking aside, I'm looking forward to attending with 3 of my colleagues! PS. podcast is great.
Yup! I was able to build and run quite easily, thank you!
* `long == int`: fine I guess * `optional&lt;T&gt; == T`: I am already *very* skeptical here and would prefer to add an explicit constructor-call on the right site * `optional&lt;T&gt; == U`: This is terrible and shouldn't be allowed Given the text, the only sensible interpretation of `f6` should be that of `optional&lt;T&gt; == T` and as such the only reasonable answer is `false`, everything else is idiotic and should be considered a bug in the specification.
Looks like it's been pulled
Did the link get taken down? I get a 404 on mobile.
You can write `::S s{42};` instead. 
If you create PR, and if u/fafaflunkey is ok with it, I would like to participate in the code review. I want to improve my code review skills, so that a win-win situation for everyone ;)
Isn't the exact place where you should have a `mutable` member variable (the cache) and therefore being able to have a `begin() const`?
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/a4wgns/taocpp_project_foss_looking_for_help_with_msvc/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
``` i = INT_MAX; i++; ``` You can start being sad now.
[removed]
&gt; Of course it's important my DLLs are all installed in this step how can the program run without it Not that I don't agree it's an important bug, but the way you word that is odd. Do you mean that you run the install target during normal dev/test cycles just to get your own DLLs into place? If so, there are better ways to handle that. On Linux, you just use RPATH (or RUNPATH on OSX), and on Windows, you can copy the DLLs as a post-build step, or just use the `CMAKE_RUNTIME_OUTPUT_DIRECTORY` so they end up next to each other and it just works.
[removed]
&gt; I think the ultimate backend/core is written in Lua, isn't it? https://www.reddit.com/r/cpp/comments/a44q/pytorch_10_stable_released_includes_c_frontend/ebd9w4m/ 
&gt; There is no plan to support Windows. Stopped reading right there.
Thanks!
Intellisense is lightyears ahead of the C/C++ extension for navigation, colorization, and auto-complete. I can't stand it on even small projects. The C/C++ extension does not have provide theme overrideable colors for the majority of themable items that Visual Studio has. Also VS Code uses an Atom / HTML based thing to render code and it causes massive slowdown on files greater than 15k lines on even my high end gaming rig with no extensions other than the C++ one. Enable even the most basic extensions and good luck. 
Have you compared performance and ease of use with e.g. spdlog? I'm also a current user of Boost.Log, but I've been considering a switch for a while.
So a sentence starting with "I think" and ending with a question mark is a "confident claim"? Oh my. And that sentence doesn't mention anything about C++ calling Lua. It is _asking_ whether the Torch backend is written in Lua, which I thought it was, because 5 years ago, Torch &amp; Lua was all the hype. From what you're saying now, I can guess that the core of Torch is actually all written in C, and they provide a convenient Lua front-end "library", so people can code their scripts in Lua. So is that how it is?
Nothing like this is ever written in Lua. It uses LuaJIT to wrap other libraries. You would know this if you read the anything on the page that you linked yourself. 
So far I agree with you. What about `optional&lt;T&gt; == optional&lt;U&gt;` where `T` and `U` are implicitly convertible from one another?
I was thinking that too. What about something like `optional&lt;std::chrono::seconds&gt;` and `optional&lt;std::chrono::minutes&gt;`?
Just use 60x`==` to make it obvious that seconds are 60 times smaller.
The standard library's thread safety guarantees means that you'd have to perform some sort of synchronization (hence the reference to "undue overhead").
Cool, thanks the heads up. I'll check it out later.
1998, but who's counting?
It'd be faster (probably a no-op) to construct a `std::bitset&lt;32&gt;` from `bits`.
Sure, but that just means you decode later, which is a good idea in some scenarios, and a poor one in others.
That sounds like a reasonable approach for a very small code base. For a large code base it's non-starter.
No I didn't. We had already the dependency on Boost, so we just user it as Boost.Log works for our scenario
Such as when? Mask/shifts are always going to be much faster than movs.
Oh god please no.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/a4y8h8/arduino_car_simulation_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
If you have an API that takes a slice of bools, for example.
How does this compare to something like Wt?
Refactoring happen all the time. It's up to technical leadership to make the business case, and it's often pretty easy to justify. Also, in most cases the process is gradual, not "lets break everything at once" There are some pretty hard-line prerequisites for doing that though, such as having decent CI in place, unit and integration tests etc.
Presumably, it was created in 20 AU, so we've had 2,771 years.
I'd consider it to be a bad feature. Avoid it.
this is why the standard should be written after the feature has been implemented in a compiler and tested by actual projects
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a4ycqy/arduino_car_simulation/ebij05k/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Well... which part do you think is wrong?
Astronomical units?
Smart because they do an auto delete of the underlying object. You wouldn't use them on primitives like int.
You’d be mad to run a website on windows, wouldn’t you?
Is this still a common choice for new projects? Or are other frameworks like Qt better?
You are using smart pointer in a very stupid (as in Undefined Behavior stupid) way. Smart pointers help you manage the memory. There is no memory management in your snippet, you just have a non-owning pointer. Non-owning pointers are still a thing.
&gt; pointer. 2) It takes no more time to assign the primitive to another primitive than to assign one smart pointer to another one The example you pulled is a different one. The snippet OP has posted can't be justified, this is a pure and nasty bug.
It depends on how important the really native look-and-feel is for you and your users. For some projects, a more permissive licence can also be a consideration.
Ad urb condita. What are you, a *Carthaginian*?
It's probably pretty nice if you can actually get it to compile.
The issue is not really about the value being a primitive or not, but rather, about it being stack or heap allocated. Creating a smart pointer to a heap allocated value is gonna try to free something on the stack, which is most likely UB. Smart pointer on primitives can be useful for passing data among thread (ie g2o takes a pointer to a bool to allow the user to stop a bundle adjustment) 
It's a client library too.
Rather not: The optional might be used to indicate an out-of-bounds-error in which case the intended values might be the same and you could argue that they shouldn't compare as non-equal in that case. This is less of an issue with `T` and `U` directly as they cannot hold a representation-error. Consider this example: template&lt;typename T, typename U&gt; std::optional&lt;U&gt; try_narrow(T value); auto o0 = try_narrow&lt;int16_t&gt;(1000); // optional(1000) auto o1 = try_narrow&lt;int8_t&gt;(1000); // std::nullopt o0 = o1; `o0` and `o1` clearly should not be equal, but given the way they were derived I am not sure that they should be non-equal either; keeping them unordered (= non-comparable) really is the most sensible thing.
Good luck!
The problem with raw pointers, is the clean up (memory management). So if you call `new` you have to call `delete` at some point. Smart pointers will do this for you, not much more (but it's great!!). class Foo {}; int main() { Foo* x_raw = new Foo; // you have to call delete somewhere delete x_raw; // or use auto std::unique_ptr&lt;Foo&gt; x_smart = std::make_unique&lt;Foo&gt;(); // Now I don't have to worry about delete } So when to choose which? My rule of thumb, first try to go with unique\_ptr, if that does not work for you specific case, only then try to go with shared\_ptr. shared\_ptr is "easier" at first, but lifetime can get a mess.
Ah, fair enough 
Yes, /in general/ you can avoid using bare pointers. Think of smart pointers as more restrictive cases of general pointers: that is, they are saying (by their type) what you can and cannot do with the pointee. They're getting the semantics of the language to help you keep the pointee in a certain role (unique, shared, etc.). In terms of understanding, I suggest that you consider how you might implement one (remember that they are library types, not built-ins; Boost, for instance, has more kinds of smart pointers than the standard library currently includes). A scoped pointer might begin like this: template &lt;typename T&gt; class naieve_ptr { T *x; public: naieve_ptr(T *x) : x { x } {} ~naieve_ptr() { delete x; } }; ...and although this is far from a "good" scoped_ptr implementation, you can already use it in a powerful way, something like: { naieve_ptr xp(new int(5)); } // the int is destroyed here (As others have pointed out, your example has an issue: the int "x" is going to be on the stack, and cannot be safely managed by unique_ptr&lt;&gt;.) So you can compare this. When you write something like: auto xp = make_unique(Foo(1, 2, 3)); ...you can start understanding how the pointed-to value will be managed, why it can't be directly copied (think of the operator overloads), and in general what the /type/ unique_ptr&lt;&gt; is helping you to do and not do. I hope that helps!
The qualities that we look for in junior engineers is the same that we look for in our senior talent. We are looking for individuals who are motivated and driven to be the best at their craft. We want folks who love to code; specifically C++ - the greatest of all the programming languages. While it is helpful to have had experience building scalable, distributed systems, there are opportunities at 128 Technology for junior engineers as well where you can readily make an impact on the product and to our customers. 
I wouldn't exactly call code review a difficult skill, but sure, go nuts.
A fairly widely used one : https://github.com/ninja-build/ninja It's insides are very difficult to read. 
I usually see bigger projects moving away from it (usually to Qt). But that's my biased statistic. Don't have any fancy data to back it up.
Ascii-paint could use a coat of paint https://bitbucket.org/bpio/ascii-paint/wiki/Home. Drop a line on twitter @eigenbom if you tackle it.
How much does it follow paradigms of modern C++? Maybe the question to ask is, what's the minimum required compiler/C++ standard? How much legacy cruft do you have in the project, and what's the plans regarding C++11/14/17/20? I am asking because it looks really great, but it's also quite an old project, so I would be very afraid of buying into an old, legacy codebase, that will stay C++98 compatible forever.
Yeah, OK, I forgot about the thread usage. That makes sense.
The library is still written in C++98, but this isn't really relevant for the applications using it. Here is a minimal (compilable, runnable) example of an application using wx: #include &lt;wx/wx.h&gt; class MyApp : public wxApp { public: bool OnInit() override { auto window = new wxFrame(nullptr, wxID_ANY, "Hello, wx"); auto button = new wxButton(window, wxID_ANY, "Say it"); button-&gt;Bind(wxEVT_BUTTON, [](wxCommandEvent&amp;) { wxMessageBox("Hello to you too"); }); window-&gt;Show(); return true; } }; wxIMPLEMENT_APP(MyApp); // This defines main() or WinMain() So even if the library doesn't use e.g. lambdas internally, nothing prevents you from using them in your code -- and, in fact, this is very commonly done and is extremely convenient. Being interoperable with normal, standard C++ code is one of the explicit goals of the project and IMNSHO wx succeeds in doing it not too badly.
* Ab urbe condita 
Qt is certainly a bigger project that covers a much wider range of problems. So it's "better" if that's what you want. But the flip side is that Wx is "lean n' mean" in comparison, and much more narrowly focused and has a smaller on-disk footprint, etc. Personally, I really like Qt and use it for my own stuff. But it's very opinionated. It requires extra build steps, and it's not convenient to integrate with other large, opinionated frameworks. If you specifically want a reasonably featureful portable GUI library, Wx may be a great fit.
Is it?
[Yes](https://github.com/an-tao/drogon/blob/master/examples/client_example/main.cc)
My phone's autocorrect is a Punic spy. It has been thrown from the Tarpeian Rock.
Is there an IDE that allows RAD development with wxWidgets? I tried C::B at one stage but it's horrible really. QtCreator is light years ahead. 
It wouldn't even be hard. NT/WinAPI generally have better interfaces for many things than POSIX/Linux, with mantly things having no good analogs like fibers and registered IO. Even if you didn't want to support such things, WinSock already gives you very nearly a POSIX API.
Works fine for me. Source: `long long i;`
Ah, thanks! I did not get that from README
That is FUD. There should be no problems getting wxWidgets to compile. For me, it has always worked out of the box. When you compile wx, you will see a number of warnings emitted, but these come mostly from third party libraries. wxWidgets by itself compiles quite cleanly.
from my time evaluating it i wasn't happy with all the libraries it was pulling in. Not sure if that's much of an issue nowadays.
I started it as a simple project to learn Python. It was wildly successful for that, but now I kinda wish it was C or C++. It would have been much easier to maintain. Lots of work went into fixing silly defaults in Python and explaining to C++ developers how to install and run Python applications.
Then use GTK+?
Can you provide examples that were tricky? I'd like to know more.
This is a very good idea for a self-preparation project. As others have mentioned, having good unit tests is an excellent practice and safeguard to have in place when doing refactors; and writing tests for legacy code is a valuable skill for the real world in and of itself. Writing tests for existing code is also a good tool for verifying a bug fix and supplying it with a regression test for the future. In cases where legacy code has bad interface designs, poor encapsulation, poor enforcement of class invariants, or leaky abstractions, it can be hard to write good tests. Identifying what it was about the code that made it difficult to write clean and modular tests for, can be a good source of ideas for how to improve the design or the abstraction. Unfortunately, where interfaces are bad or broken, you won't have the luxury of writing tests for the better interface to begin with, if you want the tests to provide a measure of correctness. Tests that conform to the legacy interface are good for making sure you don't break functionality when cleaning up an implementation, but when you clean up the interface itself, you have to update the tests themselves. I don't know of good testing techniques for those kinds of safeguards for when the interface changes -- maybe other can chime in there. &amp;#x200B;
How so? Using CMake it's trivial. Otherwise all you do is give it a few linker flags and include paths to your headers, which is still very easy.
You're thinking of c++XX.
It should be an explicit overload in the operator (on `std::chrono`). Basically allow comparison of optionals only if a comparison operator with `T` and `U` exists. No implicit conversion.
What if it’s two like quantities that don’t have an obvious scale factor, such as miles and cm? Why should users have to do all the conversions manually?
Writing a comparison operator for all permutations of comparisons between time types is not a reasonable solution. Perhaps that can be templated. Hmm. 
\`std::variant\` only ever holds one thing, that is what is designed to do. It represents an or relationship. \`std::get&lt;1&gt;\` would work as that points to \`\_ScalarType\` in the variant list.
20 year's after Rome's founding? Gotta use the Old Italic Alphabet and Italic Numerals. 𐌂𐌄𐌕𐌄𐌕𐌢𐌢
Why not use djinni? Way less boilerplate to write yourself 
Off-topic, but you came to /u/STL's domain with stolen `_Cap` names that belong to him. I'd start fearing for my life.
Well it'd be templated obviously. Also you probably don't want to have that many comparisons with different types since it tends to be a bad idea.
I don't have any personal experience with it, but it's my impression that C::B and [CodeLite](https://codelite.org/) are the most popular ones.
One trick that I use (IDE authors HATE HIM) when I want to quickly get familiar with a codebase is to run all the code, especially the headers, through doxygen. This doesn't typically create useful documentation, but what it creates that is useful are the inheritance and usage diagrams, plus links between types, symbols, etc. It's just a quick way to get a hyperlinked map of the sources. Within about 10 minutes I have a rough idea of the parts, and dig in from there. You can use any decent IDE. MSVS, eclipse, etc will all give you some of this, but IME doxygen's diagrams are oftentimes more useful.
if your using VS Code and CMake , I recommend CMake Tools extension by u/vector-of-bool. If you have MSVC compiler already on your system CMake Tools can 'scan for kits' and automatically find the various toolchains (2015 x86, 2017 x64, etc…). VS Code on it's own is just a code editor that can manage git repositories and debug javascript and related technologies, the real power comes from language specific extensions, for C++ my must have extensions are: C/C++ by Microsoft, Clang-Format by xaver, CMake(syntax highlighter) by twxs, and CMake Tools by vector-of-bool.
I like to think that `_Ugliness` is its own punishment, but seriously, such names are reserved for use by the compiler and standard library. We use them to avoid stomping on user code, so please don't stomp on us.
Types representing real-world quantities should all be comparable, IMO. I don't think it's a bad idea to be able to compare all of these types: std::chrono::nanoseconds std::chrono::microseconds std::chrono::milliseconds std::chrono::seconds std::chrono::minutes std::chrono::hours std::chrono::days std::chrono::years
In this case `std::optional` was modeled after `boost::optional` which has been around for awhile in actual projects. I'm assuming people's experience with it drove the standard design.
This is a cpp forum. The NS in there is implicit
Can anyone explain to me "why we need this ?" .
You don't have to use them explicitly though, you can template on the ratio and underlying type like the STL already does https://en.cppreference.com/w/cpp/chrono/duration/operator_cmp I'm not entirely convinced by their use of `std::common_type` since it creates potential issues with floating point, but the idea is there. 
Noted! Still getting acquainted to the rules.
Does wxwidgets support anti-aliased rendering yet? I remember it wasn't supported when I tested it a few years ago, so I went with Qt.
There is [wxFormBuilder](https://github.com/wxFormBuilder/wxFormBuilder) that gives you a visual designer and provides various paths to integrate the result in your program, for example you can create a C++ base class. I used it successfullly, but the documenation is incomplete/missing. 
Isn't that AU**C**?
The problem here isn't so much with optional, but with nullopt. There are an infinite number of types of null - a null for each type. A null `optional&lt;optional&lt;T&gt;&gt;` isn't the same as a null `optional&lt;T&gt;` and nullopt can't cover both. So we picked it to mean the outer one (IIRC). But there was a paper about a typed-null, such that you could, when necessary, tell them apart. wg21.link/p0196 
Why not kqueue on Mac/BSD?
Doing a code review isn't really difficult, but it expose you to other people code. And catching all errors is difficult (programmers are really creative in that area !).
&gt; I don't know of good testing techniques for those kinds of safeguards for when the interface changes -- maybe other can chime in there. Have good test coverage for your new interface? Make sure the consumers of your interface have good tests? Gabe a good spec for your new interface
I had to work with Wxwidgets recently. Worst experience I've had with any library. Full of compatibility problems, obscure bugs, no documentation etc. We couldn't get it to work on some platforms btw. A funny but I've had : I had a window class or something with some attributes, it worked fine but at some point (when I didn't change anything in the class) one of these attributes started being randomly affected a value. This one attribute was getting the value 336 at random places. I tried to add breakpoints or debug messages to see where it was getting this value but it was never at the same place and always between completely unrelated lines. After an hour of debugging I added an attribute before the buggy one just to make my debug messages more readable and to my surprise, that fixed the problem. Now it was this new attribute that was getting the value 336. Instead of the useful one. It's like my object was being casted into something else and affected a value at a random memory offset, all in another thread. This decoy attribute is still in the code. I was not the only one who had that kind of bugs, everyone had them. And my god the documentation was terrible. So yeah I would not recommend it.
Wouldn't be my first choice, bur why?
Carthago delenda est!
I hope this stays out of the clang code base.
I’m not sure about that, this would take a pretty substantial refactoring for cross-platform support. Just taking a look at some of the includes: &lt;sys/wait.h&gt;, &lt;sys/poll.h&gt;, &lt;unistd.h&gt;, &lt;fcntl.h&gt;, &lt;dirent.h&gt;... they really went all-in with the POSIX API.
If you are wondering "why we need another" - It could be a result of work, because the author was not satisfied with other web frameworks out there. If you are wondering "why we need a web framework" - To write web apps. If you are wondering "why we need a web framework in C++" - for high throughput. 
Wt is heavily influenced by Qt. The last time I checked and IIRC, you will write Wt widgets like Qt widgets and it will be rendered as HTML.
Simple my ass. And what's the point?
I will give this a try, thank you. 
What about "why do we need a web framework based on C++11 when C++14 and C++17 have been released and stable for quite a while?" 
&gt; try_emplace() doesn’t steal from original arguments if insertion fails. This is in contrast to emplace() and insert() It's so sad that instead of just fixing emplace they added another, [15th?](https://xkcd.com/927) way of doing that, with a ridiculous motivation ["this fix is unobservable"](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4006.html). 
thats cool, but i assume it expects a function pointer right? so if you try to capture something it won't compile :/
I was wondering the same thing. After a cursory look at this, Drogon looks like it is implementing a conventional request/response paradigm, with a templating engine based on C++ (with a custom preprocessor). So I think it operates on a different abstraction level. Wt's interface is widget-based (initially inspired by Qt), designed to make web development a bit more like desktop application development, aimed at the development of single page applications.
You'd be surprised by how many Wt users use Windows. I know I was. I guess they're not Wt applications are not conventional "websites" though. Still wouldn't be my personal choice of course :-).
Ah! I should have looked that up myself. Thanks!
Because there are plenty of projects those use just subset of C++11 and won't to upgrade to C++14/17 in the near future.
God no
I too like the idea of using the most recent standard of the language and take advantage of the new language features. But I am not the author. 
Qt Creator is quite nice also
Isn’t the goal for C++ to have every new aspect of it be compatible 100% compatible with legacy code? If that’s the case do they ever deprecate any old stuff?
As much as Qt Creator seems nice to me, the lack of having the embedded tooling in the open source version gives me no reason to switch from my one true love, Vim.
It's not the goal to be 100% compatible. Things have been deprecated and will be in the future. But the ones in charge are very careful with making breaking changes, and doubly so if it's a change that doesn't cause a compiler error but just silently changes the semantics of the code. That sort of change is rarely done.
Ah, I heard wrong then. Going back to the first comment, there’s just so many ways to do the same thing in C++ with its standard library that it’s kind of jarring, especially for newcomers, like how arrays, std::array, vectors, and lists are basically all the same thing.
I was a fan of Code::Blocks for many years. I still think it does many things right, but I've moved onto Visual Studio Code for everything now.
I dont think `nullopt` is a problem - you have the same question about mixed disengaged optionals regardless of how you get there: f6(optional&lt;optional&lt;int&gt;&gt;{}, optional&lt;int&gt;{}); f6({}, {}); f6(none&lt;optional&lt;int&gt;&gt;, none&lt;int&gt;); // or whatever syntax
&gt; with a ridiculous motivation "this fix is unobservable". It is indeed a ridiculous motivation if one doesn't read the next few sentences: &gt; From within the language, a user cannot tell whether her platform conforms to the fixed semantics. When moving to a different platform that is lacking the fix, the code would continue to compile, but silently behave differently. This is surprising, hard to catch, and against the spirit of providing clean transition paths. Conversely, a user eager to rely on this fix would find himself hard-pressed to guarantee that it will work as intended on all deployed platforms.
No, it does not expect a function pointer. You can capture anything you want.
No, this assumption would be wrong. `Bind()` takes any callable and stores it using type erasure internally.
double underscore is reserved for the implementation ¯\\_(ツ)_/¯
Yes, it's hard for newcomers. Especially since much info on the net is completely outdated. But C++ wants to provide specialized tools for special situations. arrays, vectors, and lists all do the same basic thing but their underlying mechanics are suitable for different scenarios. There are no one-size-fits-all solutions in any programming language so C++ gives you the choice.
It's perfectly ok not to recommend wxWidgets and it's fine to find [its documentation](https://docs.wxwidgets.org/3.1/) terrible although I wish we knew a bit more details about why do you think so. It's a bit dishonest to claim that the documentation is both terrible and doesn't exist ("no documentation") at all in the same comment however. It's unfortunate to hear that you couldn't make it work on some (I assume, supported) platforms without ever saying what these platforms were, let alone which problems did you encounter. And it's frankly ridiculous and a bit sad to blame the library for what looks like a bug in your code. There are plenty of bugs in wxWidgets, but it's not going to corrupt memory in your application without your help.
Yes, it does when you use [wxGraphicsContext](https://docs.wxwidgets.org/3.1/classwx_graphics_context.html) for rendering.
I have used wxWidgets for a few years, and I can tell you that I agree it is not perfect. But what open source library is? There are not that many of them. Did you report your bug? If so, you would likely see it fixed within a short time - probably suggesting a work-around to apply in the mean time. For support, I have found wxWidgets to be top-notch. Also, the documentation is generally quite good. 
But otherwise a fine article.
yes
How is that different from any other change in the language? They banned COW strings. The fix is unobservable. Shouldn't we have new strings just in case? They made signed integers [two's complement](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0907r0.html). The fix is unobservable. Shouldn't we have new integers just in case? They defined [evaluation order](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0145r3.pdf). The fix is unobservable. Shouldn't we have a new way of sequencing things just in case? In all these (and many other) cases "the code would continue to compile, but silently behave differently" on some platforms. Why emplace is a special snowflake? 
Ok maybe I was a bit harsh. First of all I know developing that kind of library is extremely difficult and requires a lot of work and I don't blame anything on the developers, especially when it is open source. When I said "no documentation" I meant that a lot of the time, it's just a list of the different methods and a small description that is basically the name of the function but with spaces. The bug was probably caused by my code, but it was not that big at the time and I spent hours debugging. There was literally nothing in my code interacting with that object. If my code caused this bug somehow but in an indirect way that is impossible to see, it means something had to be badly designed somewhere. But let's assume I'm stupid and didn't see something obvious in my code that was causing it. My coworkers also encountered all kind of different bugs. For example on a specific OS, I don't remember which one, everything worked perfectly but I you put the computer into sleep mode while the program is running, the UI is gonna be super laggy after the wake up and you have to restart the program. Some parts of their code worked on some platforms but not others. One of them spent like 8 hours trying to get wxwidget to compile on Mac without success. Pretty much everyone agreed that this project was a nightmare but I don't know, maybe there is something none of us understood ? Or maybe the version we had to use was a century old
Why not zip your input ranges and work with that?
Get Visual Studio if you use Windows, as of now Microsoft's compiler is the only one that guarantees support for all C++17 features.
Yes, our long-term plans definitely include desktop support.
The issue is not so much about changing the behaviour but it would also imply changing the signature of \`emplace\`. Like all the other containers in STL \`emplace\` is expecting some arguments to be able construct a \`value\_type\`, \`value\_type\` being a \`pair&lt;const Key, Value&gt;\` for any associative containers. Now the problem is that you can construct a \`Key\` with other things than an instance of \`Key\` itself, it could be any single argument accepted by the type \`Key\` in one of its constructor. At the same time, you really want to have a \`Key\` to compare/hash, so you can check the existence of the key inside the map, so you are forced to somehow use, and potentially steal, the key argument of your emplace call to construct a \`Key\` to check for its existence in the associative container. \`try\_emplace\` solves this issue by forcing the first argument of being of type Key at the price of being less generic and having a signature that is different from all other \`emplace\` functions on all other containers. Now there are other issues that \`try\_emplace\` still does not solve, which I wrote about here: [http://jguegant.github.io/blogs/tech/performing-try-emplace.html#performing-try-emplace](http://jguegant.github.io/blogs/tech/performing-try-emplace.html#performing-try-emplace) . 
Building the Boden library usually takes under a minute. Once the library is built, there's usually no need to rebuild it during development. Linking will be a bit slower as the library needs to be linked, but that's probably negligible on a modern machine. The gradle build process is more of an issue. Gradle loves to take its time on configuring projects, which currently is a hit on build performance if you start a new Boden project from scratch. We're working on that. Runtime performance should be fine. We didn't test edge cases like property animations yet, so it's really too early to tell if there are any serious bottle necks. I guess those would be the cases where performance measurements really matter. We'll definitely investigate this in the future.
Unfortunately there are plenty of ways to have mysterious bugs in C++ and wxWidgets doesn't protect you from all of the different ways to misuse the library. It tries, and has plenty of asserts checking for various problems, but it's definitely not perfect. Still, memory corruption problems like this are usually not that difficult to find with modern tooling (valgrind, address sanitizer, Intel tools under Windows, ...). For the problem with UI slowing up after wake up I really have no idea, sorry. I have trouble believing that it's wxWidgets fault because I personally use a program using wx which runs for months on different computers (Windows and Linux only though, not Mac) which are put to sleep quite often and have never seen it, but this doesn't prove anything, of course. The trouble is that if you've encountered this problem and didn't report it, we just never had any chance of fixing it and this is unfortunate. Finally, I still don't understand what could you be doing during 8 hours to fail to build wx under Mac. It's just a simple, standard `configure &amp;&amp; make` and is tested by [Travis CI](https://travis-ci.org/wxWidgets/wxWidgets) and most definitely works out of the box (the library doesn't have any non-optional third party dependencies, so as long as you have a working C++ compiler, it should build).
I've never ever had that kind of bugs before in C++. But that and the sleep mode thing are just two examples we've had dozens of bugs like this so I don't know either we're stupid or we used a bad version. I don't know why it didn't work but they tried everything to get it to compile, followed every tutorial and tried every stack overflow answers possible and nothing worked. 
Mingw and sublime text cause I like how simple it is and I hate vs or vscode
🎵You say "deferred temporary potato" and I say "guaranteed copy potahto..."🎵 
Afaik practically every platform/compiler implemented two's complement and evaluation order the same way so there was no real practical change. emplace wasn't snowflaked. Initially [they wanted to just fix emplace](https://cplusplus.github.io/LWG/lwg-active.html#2362) but noticed that there were additional issues that made fixing it problematic: &gt; This poll was marred by the fact that we didn't notice or call out that emplace() must construct the key before doing the lookup, and it must not then move the key after it determines whether an insert is going to happen, and the mapped_type instance must live next to the key. So they looked at the situation in detail and came to a different conclusion than for things like COW strings.
&gt;How is that different from any other change in the language? Why are you arguing with itself? You were the one who proposed that &gt;with a ridiculous motivation "this fix is unobservable". and now you somehow arguing with that showing why this was not a motivation.
What embedded tooling does vim provide
&gt; like how arrays, std::array, vectors, and lists are basically all the same thing. No? `arrays, std::array` to some extent, but that's all. And it's the same thing in most languages. Java has "vectors", lists and arrays too.
Get one of the nightlies and its alright, the code completion isn't as robust as visual studio but its pretty fine overall
Mingw-w64 should be feature complete right? Is anything notable missing?
MSYS2 is pretty good for C++17. It has a very up-to-date clang.
A `std::array&lt;Byte, 4&gt;` is basically a `uint32_t`. Just XOR them directly, it'll be a factor of 10 faster or so.
Why?
For me Code::Blocks has been very buggy, so I started using Visual Studio Community and I'm very happy.
What's a debug/release combobox?! Ah, the build configuration? I have 3 and (for silly reasons TBH) none are called debug or release.
For OP and others' benefit, the way to safely do that is uint32_t ua, ub, uc, uresult; memcpy(&amp;ua, &amp;a, 4); memcpy(&amp;ub, &amp;b, 4); memcpy(&amp;uc, &amp;c, 4); uresult = ua ^ ub ^ uc; std::array&lt;Byte, 4&gt; result; memcpy(&amp;result, &amp;uresult, 4);
That's true but not really helpful. Imagine the length is larger than 8, or the types aren't bytes, or the operation isn't xor, or ...
"Safely" of course assumes `sizeof(array&lt;Byte, 4&gt;) == 4`, `sizeof(uint32_t) == 4`, and `is_trivially_default_constructible_v&lt;Byte&gt;` are all `true`.
This is awesome. Now I can have factory functions that do exactly what I expect: construct the result in-place, even if it's stack allocated.
None, that's the point. If the one interesting thing about it isn't there in the open source version, and it's subjectively worse than other IDE's/more featured editors to me then switching makes no sense.
Compared to \`boost::beast\`?
I really wish they had called *insert_or_assign* as *update*
 template &lt;typename T&gt; std::optional&lt;T&gt; call_if(bool condition, std::function&lt;T()&gt; func); I expected much better than this.
It is, in the end, guaranteed copy elision. You can think of it as deferred temporary materialization, but the abstraction leaks when you try to initialize a base class subobject (or something that can be one, via a delegating constructor) and find that a temporary is materialized anyway.
&gt;the only one that guarantees support for all C++17 features. clang?
I think parallel STL might not be fully supported. /u/CubbiMew would know best
&gt; Imagine the length is larger than 8 Even then, though.
What was the underlying motivation for banning CoW strings, anyhow?
Nice!
I tried getting the GCC source in MSVC, just for editing. Never again.
Clang is available and buildable Windows-native, though.
Leading underscore too.
That's a stdlib feature, not a compiler feature, and the only supported (i.e. non-experimental) stdlib for Clang on Windows is MSVC's.
That is exactly what I meant
What is stopping those projects from upgrading? 
[removed]
Well, that's painful. There is an NT implementation of dirent, at least.
Why would you ever do that? I can see maybe on a Mac, but it also doesn't quite make sense to me
Different factors. Some applications work on rather old platforms, some work on some rare platforms with specific compilers. Some projects are really big and porting of it to new version of compilers require some time and some money and not all project owners want to pay for that.
Because MSVC has one of the best C++ editors. It just couldn't handle GCC.
I believe it's because it can result in exceptions happening at unexpected places. Eg: string s1 = "hello, world"; string s2 = s2; char ch = *s2.begin(); // Throws bad_alloc. Reason being, begin() is non-const, so needs to copy the string bytes in case the caller modifies them, and the copy can fail.
&gt; None, that's the point. If the one interesting thing about it isn't there in the open source version, and it's subjectively worse than other IDE's/more featured editors to me then switching makes no sense. just for the clang / clang-tidy / clazy integration with in-line fixits it's worth it, and let's not forget the visual debugger, profiler, excellent code navigation with ctrl-k which has a semantic understanding of your code, etc...
What do you mean it couldn't handle it? If you cloned the entire repo then tried to open every file I could see that happening but there's something else going on if you can't even import it as a project
A generic std::transform was actually a motivating example that /u/louis_dionne suggested me for a second revision of [P0478](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0478r0.pdf), which would have allowed to deduce non-terminal parameter packs in some cases. Alas, the first version was shot down quite quickly.
Another BS from MSFT folks. Guranteed copy elision does not elide copies, and this is why it is called guaranteed copy elision in standard? Seriously? It does exactly that, it completely elide copies \*\*semantically\*\*. The copies were never there even before C++17 with any optimizations turned on, but copy (or move) constructor had to be available and callable, otherwise program wouldn't compile, even if (N)RVO would still kick in and nothing would be actually copied. The whole semantic thing was nothing but nuisance, and it's great C++ comitee did away with it.
It also requires synchronization if you want to support multithreading.
&gt; it ends up analyzing the implementation of std::string, std::vector, std::map and so on. Could be edifying to explain why that's a problem.
Standard library probably generates a lot of false positives as so much of its code is in headers due to templates.
What were the reasons it was shut down?
What's the policy on outside contributions? (e.g. do you accept patches too?) 
If you download the IDE standalone it doesn't come with a toolchain. If you download it as part of the Qt SDK package you have the option of several mingw toolchains though.
Why not use a [Bernoulli distribution](https://en.cppreference.com/w/cpp/numeric/random/bernoulli_distribution) that produces `bool` directly?
My guess is that it relies on GCC extensions (though I'm not 100% certain since I've never tried), so it can't be compiled by anything other than GCC itself or something that strives to be GCC compatible (like clang).
&gt; Guranteed copy elision does not elide copies, and this is why it is called guaranteed copy elision in standard? The standard never uses that phrase.
Yes. Proving the correctness of the implementation of `std::string`in libc++, with small buffer optimization and other tricks, is pretty hard. And that's just one class. Think about `std::map` with its red-black trees, `std::unordered_map` with hash-maps, etc. Remember that IKOS is fully automated. I think you are underestimating the complexity of theorem proving and **sound** static analysis. &amp;#x200B; As /u/steinwoo said, the analysis will actually work but you will get a lot of false positives.
If the moon isn't made of green cheese why is it called the green cheese moon? Eh? Eh?!
I dont think anybody disagrees that it is possible, for these specific types, for this specific operation, to do better than generalized, multi-arg transform. But the point of the blog is to show a way how to do generalized, multi-arg transform. XOR-ing bytes is just an example. 
In theory, we can accept patches but the author will have to sign a few papers. In practice, I need to ask our lawyers where to get these forms..
**Company:** [FlightSafety Simulation](http://www.flightsafety.com/fs_simulation_landing.php) **Type:** Full Time **Description:** FlightSafety Simulation (FSS) develops flight simulation training devices from classroom desktops to fully immersive simulators with motion, visual systems, and interactive networked capabilities. We are looking for experienced C++ developers to contribute to our cross-platform frameworks and to build tools for other developers and simulator support personnel. Our group deals with many of the non-aircraft components of a simulator such as selection of development tools, integration of 3rd-party solutions, and publication/consumption of data for distributed training. Tasks may vary from creating virtual cockpit GUIs and CPU instruction set simulators to implementing the C++ Networking Technical Specification. While C++ is the primary programming language, multi-language programming with Fortran, Ada, Jovial, C#, Lua, or Assembly for Intel and Motorola may occasionally be needed. **Location:** Broken Arrow, Oklahoma (A suburb of Tulsa) **Remote:** No **Visa Sponsorship:** No **Technologies:** - New development: C++17/2a. Stable development: C++11/14. Long-term maintenance: C++98/03. - User- and kernel-mode programming with almost no limitations of the use of C++. - Driver development for Intel NICs, FireWire (IEEE 1394), CAN bus, and reflective memory. - OpenGL, boost, google test, DirectX, clang, gcc, MSVC, clang-tidy, Qt **Contact:** Please [email me](mailto:douglas.wood@flightsafety.com?subject=candidate%20via%20reddit) and PM me.
Qt's amazing documentation is just as important, if not more important, than their actual framework.
&gt; "guaranteed copy elision" &gt; "no copies exist in the first place". Yes, that's what _eliding the damned copy means!_
You sure about that..? You can't omit something that doesn't exist.
If I remember correctly, it was because it was felt that partial ordering in the presence of template parameter packs is already quite fragile as it is, and the committee thought that the problem could be solved more generically via parameter pack indexing (which I don't agree with, especially when using concepts). I could have arguably provided better motivating cases from the start, but hey it was my first paper :P
Don't ask other people to do your homework for you.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a5c8yt/how_to_solve_these/eblgvh6/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Mac mini
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/a5ccj9/project_help_poker_dice/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Leading underscore, followed by a capital letter.
It doesn't exist _because it's been elided_. The difference here as that before eliding the copy was an optimization and therefore still had to exist if there would have been visible side effects, but now it's elided at the semantic level.
I'm not criticizing the blog, I'm just pointing out something I think would help the author.
Well, not Standard, I misspoke. Rather, a proposal which was voted into Standard is called "Guaranteed copy elision through simplified value categories"
It's good for beginners. Its easy to get set up.
Incorrect. Copy could be elided even if there were side effects, it was explicitly allowed.
In the global namespace (as in the linked post) anything with a leading underscore is reserved for the implementation.
It was called "copy elision" in previous versions of C++, and now it's guaranteed. It would be called something else if C++ were a new language.
Why does IKOS use double underscores?
No, it would have violated the "as if rule". That fact is why guaranteed copy elision was added in the first place.
You cannot remove something that does not exist. There is no object, therefore there is no object to copy, therefore there is no copy to elide.
They're still different things. See my other comment.
Well it's because it ought to be part of the STL.
&gt;throughput By the way, the author also public some benchmark at : [https://github.com/an-tao/drogon/wiki/benchmarks](https://github.com/an-tao/drogon/wiki/benchmarks) They have not compare with other web framework yet, but by the number we can consider that Drogon can handle high throughput. 
Why? They don't keep a C ABI anyway?
The kernel doesn't even have a stable API, let alone a stable ABI. This argument is void. 
No, elision was not as-if. GCE was added so the copy/move ctor no longer has to exist. Elision was allowed to not call it even if there where side effects. 
&gt; Each identifier that contains a double underscore __ or begins with an underscore *followed by an uppercase letter* is reserved to the implementation for any use. http://eel.is/c++draft/lex.name#3.1 Emphasis mine.
My bad, you are right. I knew this point : http://eel.is/c++draft/lex.name#3.1 But I seem to have forgot of the one you were referring to : http://eel.is/c++draft/lex.name#3.2
&gt;You can also use IKOS to prove arbitrary conditions using `__ikos_assert(condition)`. ​If you want this to be used in C++ code, you'll need to put it in a namespace or rename it. As long as it's in the global namespace, it's undefined behavior. &gt;5.10 Identifiers [lex.name] &gt; (3.1) Each identifier that contains a double underscore __ or begins with an underscore followed by an uppercase letter is reserved to the implementation for any use. &gt; (3.2) Each identifier that begins with an underscore is reserved to the implementation for use as a name in the global namespace.
Use CLion
No prob, I don't think there's anyone who can really keep all the little subtleties straight.
You get class sizes almost perfectly but otherwise not really, some names but that's about it.
Attacker with access to your binary knows **too much** about it anyhow. I really don't think it it will care about RTTI.
They said just edit, nothing about compiling it
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/a5fa3h/best_books_for_non_programmers/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Those symbols are reserved for the implementation, but the static analyzer *is* the implementation.
I tried that too, but this is by far the slowest solution.
From a 2005 draft of the standard n1905 12.8§15 &gt;When certain criteria are met, an implementation is allowed to omit the copy construction of a class object, even if the copy constructor and/or destructor for the object have side effects. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2005/n1905.pdf (this is the oldest version I could find free online)
Not when you're trying to build the code with an actual compiler.
Finding a good book with examples and challenges is great because it boosts critical thinking skills. I learn great from books but you might be different.
&gt; The kernel doesn't even have a stable API, let alone a stable ABI. Stable or not is not important. It has API, that is important and obviously it has to do things by itself. For loading modules with has to "loading the ELF object, mapping the required segments, performing all the relocations" and you suggest add here handling of virtual tables, exception tables and so on, that in addition have no specification? 
Hard to say what he meant in terms of "could not handle it", but using MSVC to even edit GCC source files probably ended up with tons of syntax error which might lead to "could not handle it" situation, as Flashmozzg said
So is VS Code, and it’s objectively better than Code::Blocks in every single regard. It’s an unfair comparison of course because one is backed by a huge corporation and the other is backed by a tiny team but the end user doesn’t care about that.
One guy I knew who was reverse-engineering one game to make an open-source implementation, was really thankful to developers for not turning RTTI (as well as debug information!) off in the release build. For an expert attacker, I don't think the lack of RTTI would mean much, but a more casual tinkerer can become frustrated more quickly without it. Maybe. If he's not very motivated.
&gt; Why? They don't keep a C ABI anyway. I suppose we have misunderstanding in terminology. The set of functions names, it's arguments and so on things that can be used for cooperation between modules inside kernel is one thing. The way how you write assembler code to call specific function with specific arguments is another thing. For example you want call `void * kmalloc(size_t size, gfp_t flags); ` from your code in module. You know exactly that you need find address of "kmalloc" in symbols table, put in specific way arguments into registers/stack and you done the call in case for example ABI for amd64. With C++ you even don't know name of symbol "kmalloc", with one compiler it's name will be "bla-bla-bla_kmalloc", with anther "foo-moo-doo_kmalloc"
I would argue good text books will always be better than random, free, online tutorials. Don't know that particular site, but [this is a good source for books](https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list), and C++ Primer by Lippman and Co. is a good starting point. Lots of great exercises throughout aimed at learning and understanding the standard library, and also the nitty gritty details. But I think they put their focus in the right place. AKA, they don't teach C with classes, but C++.
stroustrum? Link?
Usually that sort of stuff gets hidden behind a macro, so it's only visible to implementations that recognize it. You'd have the same sort of problems building code that used MSVC's `__forceinline` with GCC.
For boost to stay relevant in a post-C++11 world, it will need to adapt. C++' s rapid(every 3 years) evolution is now a core part of the language. The language itself had to adapt to new programming models. This can be an advantage or a disadvantage depending on one' s perspective.
Probably won't take you much effort to get your old C++03 code to compile with C++17, and if the place you work at won't let you use the latest C++ tech, it might be a good idea to look for greener pastures. At my job we have an old 20+ year C++ code base, it was quite easy to get it to compile with C++17. &amp;#x200B;
What if you guys start to understand that not everyone lives in places where one can freely look for greener pastures because he dislike employer toolchain?
you just need an image loading library for the format your images are in ; most will then give you your image in the form of an array of unsigned char which correspond to your RGB(A) components
freeimage
[http://stlab.adobe.com/gil/](http://stlab.adobe.com/gil/)
It's not that easy. Sometimes especially when cross-compiling new toolchains are hard (costly!) to get.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
OpenCV is primarily a Computer Vision library, but it has pretty good I/O for various image formats (and video too). It also has some potentially useful image processing functionality which you might find useful too, of course.
There are many, check out opencv or openframeworks Opencv usually used for AI stuff, openframeworks for art/creative coding 
Mac user
OpenCV or stb_image is what I would use. OpenCV has loads of other functions too.
Out of interest: What toolchains are you using?
You think that boost dropping 03 support would make your employer spend the money to upgrade your toolchains?
Cimg is header only. Also imagemagick has c++ bindings, so you could use all arsenal of imagemagick processing functionality. 
&gt; Never, ever use [class template argument deduction]. Not even by accident! (I hope to see `-Wctad` in Clang soon.) This is radical news to me. Is this a popular belief? Have I been doing harm by telling people that their `std::make_tuple` could just be `std::tuple` in **most cases**?
Also in Boost. The “interleaved_ptr” example shows exactly how to access RGB components by pixel.
You must be referring to P0135R0, "Guaranteed copy elision through simplified value categories", which opens with "The approach described herein achieves this not by eliding a copy (...)"
OpenImageIO is widely supported by the VFX industry, and supports pretty much all image formats.
A working `std::random_device` :p
His issue is that it doesn't work as expected in 100% of cases, not unlike any other feature of C++. I mean, it's not like auto or const sometimes surprise people, right? 
If you just need that there are tons of libraries that do that. If you want some additional multimedia capabilities on top of that I'd recommend taking a look at SDL; It has an image loading companion library (SDL_image) and otherwise gives you both direct access to in-memory images (SDL_Surface) and efficient 'accelrated' images (SDL_Texture).
OpenCV is probably the easiest one to use that I've run across. I think ImageMagick has more manipulations they can do, but I don't care for their API as much. If you need to do GIS type things you can look at Gdal, but I remember being horrified by their API when I looked at it.
Hm I wondered the other day if there is any image loader that is designed to handle very large images that you want to load piecewise, to be able to abort the loading prematurely if necessary (for example because the image was being loaded to generate a thumbnail for said image, and the user now wants to navigate to another directory). Any ideas?
How about Selene [https://github.com/kmhofmann/selene](https://github.com/kmhofmann/selene)? If you want something simple and modern.
This is going to come down to the format first. Tif files have the ability to be saved by scanline and by tile. Exr images have similar capabilities. I'm not sure of the extent of memory mapping in the reference exr library but it is worth a shot.
System no longer needs linking? Thats rather huge change am I right? :)
Wt 3 is a C++03 codebase and I keep Boost up to date for our binary Windows releases, but we've released Wt 4 (C++11) a little over a year ago. I guess if Boost deprecates C++03 support, that'll be added leverage for us to stop maintaining Wt 3, which I personally think is a good thing, so I vote "No".
&gt; New Libraries &gt; TODO Is boost::todo anything like std::packaged_task?
That sounds awesome to me too.
It's for auto-generating todo lists from Todo: x comments in your code.
Anyone mind giving a brief tldr on what boost is? I see it referenced alot but am not sure.
Nice
Just a large and popular collection of free, high-quality C++ libraries. Some stuff now in the standard library started in Boost, such as `optional`.
https://twitter.com/TitusWinters/status/1058852062878789632
Sounds like slow compile times tbh
This is terrible code in every way and not a great argument for not inheriting from standard types.
Haha it have been notified and will probably be fixed very soon.
But why? I thought VS/VS Code worked fine there.
Anyone else's Windows 10 Defender detecting a virus in the boost\_1\_69\_0.7z download? Defender recognizes it as "Trojan:Win32/Spursint.F!cl"
That was my first thought too
OT here, but do you have a timeline for dropping Wt3 support? Our application is still Wt3 and I'm responsible for our long term development schedule, so any hints ("next month, next year, in five years....") is appreciated.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
It's boost; that was already a given.
New libraries is now showing only Safe Numerics. I thought Outcome was scheduled to be part of this release. Anyone know about this?
When did you tested vs code the last time? I'm asking because the intellisense has improved as hell in the last few mounths and is now comparable to the visual studio one (its the same engine), so I don't get the "lightyears ahead" thing.
[Text](https://tzlaine.github.io/text/doc/html/index.html) not in yet?
What do you mean you can't hide them "automatically"? CTRL+B will hide them. About CMake, I have [this one](https://github.com/vector-of-bool/vscode-cmake-tools) installed. Which works fine for me. I assume you are using the same since they have the same bug. In that case, its not an universal bug and saying the devs "doesnt think its important" is out of place as only one person reported it and didn't provide more informations. Tbh for something you've used for not even a day is don't like an overstatement. Most of your points are preferences. Less usable for you I understand. Buggy no. VS code is not an IDE, and so you should expect a bit of work with plugins you use (cmake warnings). But even then, I'd expect to have a bit of work to do if I switch over visual studio.
I'm not few to reddit. Just lurking haha. I understand your point, but this is more a reason of choosing an IDE over a text editor tho. VS code provides a visual debugger (might be less advanced than the one is visual studio for now tho).
I was using it as my full time editor on OSX until I switched jobs in April. I do still use it but no longer as my primary editor now that I'm at a mostly Windows shop. I would be genuinely surprised if it is the same engine as Visual Studio if we are talking cross platform but I'd be willing to give it a fair shake if you say it has been improved significantly. 
I'd have to discuss that. At the moment we haven't fully switched away from Wt 3 in our own projects, and some of our projects use JWt, which is still Wt 3 based. I'm working on getting JWt 4 out the door. I would guess we'll be maintaining Wt 3 for at least another year, but we'll avoid adding new features.
Interesting indeed. Thanks.
Mostly opengl stuff. Using MinGW, CMake. 
Thread Oriented Debug Objects
Does anyone know what changed to allow this? Last I looked into it, it was said that the design of the API required a library. Something about how error code and category objects compared equal using memory addresses.
Debug symbols are much more important than RTTI, you know where every non-inlined function is and the name of that function as well as the names of the types used to call it thanks to C++ name mangling.
I'm afraid I wrote a poorly worded question. Some people are answering the question "what is an IDE and what is an editor, and here is why I prefer to use an IDE". My question was more like "I already have a toolchain in place, plugins which works for auto-completion, debugging, cmake. Now what can visual studio brings me over that? Does it have tools that I am un-aware of? Tool that would increase my productivity?". I wanted non-vague answer, and asked a vague question. Nice irony haha. But I think /u/SeanMiddleditch answered my interrogations. And I get the same feeling as you. I don't think I'll see huge differences, because it seems quite specific. I think I'll still try it for my next personnal project.
Thanks for your answer. I think its the most descriptive of what I was looking for. I'm not sure a switch will be worth tho, but I think I'll try with my next project to have a good idea of how better are debugging/intellisense. 
The fact that the CTAD for `pair` doesn't work the same as `make_pair` is kind of artificial though, not specifically linked to CTAD itself. Plus there is a proposal to actually make the `pair` and `tuple` CTAD behave the same as their `make_*` equivalents.
In april I believe it was still a tag parser. Or maybe intellisense was available but hard to configure and not the default. Right now it's context aware and works pretty well. I think I've read somewhere that it was the same engine. I might be wrong, or maybe it's only a subset. I'll check that fact. Either way it has really improved and is in no way comparable to the tag parser there was 6 months ago.
damn, I was hoping that it would generate the actual code through machine-learning algorithms ran at compile-time from the `//TODO:` comments
But the tutorial I follow was on stackoverflow. Three different method I tried, none of them work for me. One even destroy my gcc installation somehow. And sublime, no compiling plugin is required. Simple command+b and there you have it. If I need the latest protocal, maybe I'll try it on my windows machine. But I don't need it, actually...
By the way, codeblock for mac is old. No update 
It's a playground for stuff that might make it into the STL. It's a collection of libraries. It's not *a* library, it's libraries. Some are good, some are bad. Some libraries are thriving, others are quietly abandoned, and nobody gives a shit about fixing bugs. They're labeled as "high-quality" but the documentation is mostly sub-par, and the source is unreadable because of template overuse. There is no overarching design or leadership. There is no quality control. It's not a community project, because nobody really wants to be part of it, again because of the template abuse. Only "smart" people are touching it, and that's exactly what it looks like. With the latest versions of C++ and the STL you mostly don't need it anymore. Alright. Let the downvoting begin!
&gt; It's not a community project, because nobody really wants to be part of it, again because of the template abuse. Well, judging from the activity on mailing list and the the sheer number of new libraries, proposals and ideas, I'd say that your statement is a slight exaggeration. 
Here's a proposal: Format format(32, Format::UNORM, Format::BGRA, 8, 8, 8, 8); Bitmap pic("hello.png", format); u32 *image = pic.address&lt;u32&gt;(); There you go; access to raw image data. The format is override to force the decoder to create a buffer in specific format, regardless of the file content (8 bit, 16 bit, etc). You can also do this: struct Pixel { u8 b, g, r, a; }; Pixel *pixel = pic.address&lt;Pixel&gt;(x, y); That is not recommended, though, because the overhead is completely unnecessary. You want to work with the image in linear order (scanline or tile) so that the local address computation is cheaper: for (int y = 0; y &lt; pic.height; ++y) { Pixel *scan = pic.address&lt;Pixel&gt;(0, y); // TODO: do your thing for current scanline } After you're done: pic.save("result.png"); There is more stuff going on but that would be the basic workflow. Some code examples: https://github.com/t0rakka/mango-examples/blob/master/misc/image_loading.cpp Build scripts and project files are provided for latest Visual Studio, XCode, Android ndk-build, make (on some systems) and cmake (most platforms). WARNING: some of the image decoding/encoding routines are very fast and might damage your CPU. (/joke) 
This is... not great advice. Your argument against inheriting from STL container was that CTAD doesn't have great interaction with your object if you inherit publicly. Bad interactions with CTAD are all over the place and you don't need to inherit from an STL container to show you it's not a particularly safe feature to use everywhere. On the other hand, inheriting from containers is not _always_ bad practice. In fact, inheriting from containers in particular is a good way to enforce invariants on custom containers without writing a lot of duplicated code like you would if you just had the container as a member: ```c++ #include &lt;vector&gt; class NeverEmpty : std::vector&lt;int&gt; { using base = std::vector&lt;int&gt;; public: // Custom ctors here. using base::emplace_back; using base::push_back; using base::begin; using base::end; std::size_t size() const { if (base::size() == 0) { // Throw some exception. } return base::size(); } }; ``` If everyone takes your advice to heart, engineers will have a lot of fun writing all of the overloads for `emplace_back`, `push_back`, `begin`, and `end`.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a5h5em/what_is_a_good_image_editing_library/ebn4eqj/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Oh, I understand.
Yeah, the CTAD bit wasn't what made this code a puzzle for me; it was the everything else.
Doesn't this belong to the sticky "who's hiring" thread?
Safe Numerics is a huge help for avoiding undefined behavior in normal looking code\*. [https://www.boost.org/doc/libs/1\_69\_0/libs/safe\_numerics/doc/html/index.html](https://www.boost.org/doc/libs/1_69_0/libs/safe_numerics/doc/html/index.html) &amp;#x200B; * A lot of undefined behavior results when you are doing something weird and you know you are doing something weird (for example messing with unions or using reinterpret\_cast). ODR violations and integer overflow can bit you when you are not doing anything weird just defining variables or adding 2 integers together.
!remove
OP, A human moderator (u/blelbach) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a5k9ef/objectoriented_c_developers_needed/ebn7ry0/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
pebkac
The [C++ Middleware Writer](https://github.com/Ebenezer-group/onwards) provides serialization support for a number of containers in Boost, including intrusive::list, intrusive::rbtree and [some of PolyCollection](https://github.com/Ebenezer-group/onwards/tree/master/src/cmw/poly). 
To mark code in reddit formatting, indent every line of the code snippit with four spaces.
You most likely want a file format engineered for the specific requirements like that. As ShillingAintEZ wrote OpenEXR has tiling support. Any format that has any compression usually is in-order so you have to decompress everything up to the point of interest. This keeps the compression ratio better but makes random access impractical. 
It isn't like completely remove old version of boost from the world. Old codebase can still keep using old version of boost. You have to deal with bugs in old boost by yourself, but we can't put that burden to the understaffed boost mainteners. At some point we have to decide whether stuck with old environment and deal with bug by yourself or upgrade toolchain and do through regression test on your code.
Ya eventually it all boils down to that. Any attacker with enough time and determination could reverse engineer a binary. I just wasn’t sure if disabling RTTI provides any valuable degree of obfuscation. I guess not.
 try { read_comment(); } catch(bait b) { throw; // nope } 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/a5l8x6/need_a_book_recommendation/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Sounds good enough for us. One year is a reasonable timeframe we can switch.
Does the checksum match? It looks clean on virustotal: https://www.virustotal.com/ru/url/e42cd5f643ab765cb9c21da805d73e1f0223f1d88164c047d0870688a0a09ee6/analysis/
&gt;What is the type of `my_string`? Code says `maybe_string`
Worse than just not great. Its misleading, its toxic, and if people adopt this advice, expensive in the long run (added cost of writing and maintaining alternatives). This pattern of "don't trust X because I can craft a pathological example," needs to die.
I don't think it even has been scheduled for review yet. 
Fixed. Thanks!
I think it's Defender seeing it as a false positive. I had to unblock it in Windows Defender to run the hash (it quarantined it as soon as the download finished from both Chrome and Firefox), but once I did I re-downloaded and checked the hash in the JSON file and it matches.
Full disclosure: I actually hope that boost drops c++03 support and one of the reasons is indeed my hope that this will have a ripple effect. So I'm happy to hear this. Actively banning c++11 features from an application codebase is imho pure stupidity in 99% of the cases.
Can you explain what is meant by runtime. How is this different from say the golang aws lambda functions release
Is this guy actively trying to use ctad in the most unsuitable circumstances just to prove a point? I don't care, that ctad can do strange things in super abstract generic code. I care about that it makes my normal day to day code more readable. We are not all standard library implementers.
It's more like GCC 4.8 regex support.
I would too. Or at least a shorter description of my experience and some contact info to take the discussion off of Reddit.
Somewhat torn, because I'm not sure Reddit is a proper platform to find extra work (which is probably what most people here would be interested in).
Unrelated, but were there ever updates on the previously announced move to cmake? http://boost.2283326.n4.nabble.com/CMake-Announcement-from-Boost-Steering-Committee-tt4696934.html 
Aren't there industry specific subreddits for that? I know /r/gamedevclassifieds exists at least...
I have to say, I agree with boost being a collection of libraries, some of which are better maintained and have better documentation than others. I have been bitten in the past by obscure bugs that had been patched years prior yet still the patches had not made their way to any release. Everybody's mileage differs because it is such a large collection of libraries/components/classes that obviously nobody uses them _all_. Can't comment on the rest, obviously. 
This is a good idea, but I think we should consolidate it into a single sticky. For Q1 2019, we can generalize the sticky thread from "Who's Hiring" to C++ Jobs, with a stickied comment for individuals to post their resumes or availability.
So is Outcome coming in 1.70 then?
My mistake then.
Snooping around a bit, it looks like 10 of the 21 review comments have been addressed: https://github.com/ned14/outcome/milestone/4. In [this comment](https://www.reddit.com/r/cpp/comments/7vdpyu/outcome_accepted_into_the_boost_c_libraries/dtri0pl), u/14ned indicated that this represented the work required to get the library ready for release.
I promise I'll consider it in the next rollout. I don't promise I'll apply it. I'll either do it or I'll have a reason not to have done it. Thanks a lot for the suggestion, @rodhysurf!!
Is anyone reading here looking to hire cpp developers? I assume everyone here is already a developer, so the target audience for such a thread seems like it would be very small. Anyone serious that is looking to hire would probably also post in the other thread, so I'm not sure it would lead to any more *good* connections being made. There is also a possibility it will get spammed by hundreds of resumes by the same people every month which will make it hard to find the good ones. On the other hand there is very low cost to trying it out for a month or two...
C++ Lambdas uses the Custom Runtime API to communicate with the Lambda backend. Go, Java, .net and the earlier announced languages use a different mechanism to communicate to the backend. You need to link your Lambda function to this C++ library for it to work.
&gt; Probably won't take you much effort to get your old C++03 code to compile with C++17 FWIW, it took us an amount of effort I'm pretty sure would be measured in man-months. I wasn't super involved in that so I'm sort of guessing based on my limited involvement and how long it took from start to end. It's not the "get your code base to compile with C++17" that is most of the problem, though that wasn't anything like a snap your fingers and done kind of thing. The big problem is getting all the compilers in place. We had to switch from using whatever GCC happened to be on the system to packing up our own compiler (in our case we went Clang) and using that instead. That means getting that compiler to build on all of our system. It meant patching the compiler with bugfixes (some of these I think have made it upstream) so that it properly uses the correct libc++ in all relevant places (or... something like that? I don't know details).
Thanks a lot for this blog post. Pretty much my opinion. The good outweights the bad for sure.
&gt; What I'm wondering is, how many of those 03 users are actually using the latest version of boost and hence would be affected at all. FWIW, this was us until a few months ago. A year ago, we were on 1.63. We've since made the switch to C++17. &gt; What would also be of interest is which c++03 boost libraries you are using in your 03 project. From a couple quick greps of part of our code base: optional, static_assert.hpp, variant, algorithm, smart pointer, range, pool, random, math common factor, functional, bimap.
 ## Object-oriented C++ Developers needed 📷 **Company:** [Stellar Science](http://stellarscience.com/index.html) **Type:** Full Time regular W-2 employment with phenomenal benefits. **Description:** **We hire smart software developers** who love to create and maintain high quality, extensible, scientific code: OOP in C++14/17. **Support software development in the following domains:** computer vision and image processing, image simulation, high power microwave systems modeling and simulation, laser source generation and effects modeling, computational electromagnetics (CEM), space situational awareness (SSA), high performance computing (HPC), and computer aided design (CAD) tools, among others. **Location(s):** Albuquerque, NM or Vienna, VA **Remote:** Remote work is not immediately available. **Visa Sponsorship: NO -** US Citizenship is required + willingness to undergo background investigation. **Technologies:** C++14, C++17 - Cross-platform software development on Linux, Windows, Mac **Experience in any of the following is a plus:** · 3D graphics using Open Scene Graph and/or OpenGL · User interface development with Qt, Java Swing, GWT · Supercomputing, OpenMP, threads, MPI, GPUs · Google closure or similar tools for large-scale javascript development · OSGi, Orekit, or Apache Commons Math **Contact: Apply for the specific jobs** Vienna, VA - [https://stellarscience.applytojob.com/apply/cA5cQy7NTB/ObjectOriented-Software-Developer-NoVA?source=reddit-cpp](https://stellarscience.applytojob.com/apply/cA5cQy7NTB/ObjectOriented-Software-Developer-NoVA?source=reddit-cpp) Albuquerque, NM - [https://stellarscience.applytojob.com/apply/Ldz2Im5PlG/ObjectOriented-Software-Developer-ABQ?source=reddit-cpp](https://stellarscience.applytojob.com/apply/Ldz2Im5PlG/ObjectOriented-Software-Developer-ABQ?source=reddit-cpp) POC - John Jones - Technical Recruiter - [jjones@stellarscience.com](mailto:jjones@stellarscience.com)
Nope, I even compiled it.
I have deleted the post and moved to the "who's hiring" thread. Thanks.
I have deleted the post and moved to the "who's hiring" thread. Thanks.
Yea, once I downloaded the ZIP it worked just fine. Also once I unquarantined the 7z file it seems to be okay and matches the sha256 hash, so I'm assuming it's Defender giving a false positive.
Can't hurt to try it!
please no, that would be a mess
&gt;the analysis will actually work but you will get a lot of false positives. If false-positives are OK, I'll write you an "analyser" that simply flags every single line of code. It will never miss a bug ;)
Have you looked at [casync](https://github.com/systemd/casync)? Its primary design goal was versioning rather than parallelness, but it ended up making many of the same decisions.
So yes, we accept contributions, but you have to sign one of the two CLAs here: [https://github.com/NASA-SW-VnV/ikos/tree/master/doc/contribute](https://github.com/NASA-SW-VnV/ikos/tree/master/doc/contribute)
A lot
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/a5neg6/book_other_than_stroustrups_principles_and/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Eh. As long as it's infrequent, it really wouldn't get in the way.
This is interesting, and I'll have to give it a deeper look! I'm in a similar boat of being a graphics programmer (primarily) who was hoping to find a more parallelism-friendly compression format for packing assets into. Especially because I'll eventually have things like compressed textures that are massive on disk that I want to stash in archives... and for those, I'll have multiple versions based on the hardware capabilities and so on. And that's not even getting into storing geometry, SPIR-V binaries, etc. Cool stuff though, and nice writeup!
Ycombinator news does monthly “who’s hiring” posts where companies post mini-ads. That would probably be the best format. 
Thanks for the link, didn't before now. Looks like the use-case is different: content delivery but there are similar design choices there indeed. For me the important bit is that it's all-in-one file, which makes it easier to do other tricks. For example, one dude asked one time if I can "load" from Windows resource file (WIN32 specific stuff) and I noticed that since I am already doing memory mapping.. I found it was easy enough to add API to use raw memory as "FileMapper" ; I can construct Path object with raw memory pointer (from WIN32) and indicate that it is a zip, rar, snitch, whatever-file and the existing mechanism takes over. This allows to embed compressed folders easily into executables with existing WIN32 API's and build tools. So, basically, now virtually anything can be a "Path" (=FileMapper interface) as long as the relevant member functions are implemented. Long story short, that is something I absolutely must-have. On the other hand, this thing doesn't really fit streaming AT ALL. Streaming would benefit from doing things in certain order to take advantage of streaming compressors but I don't have anything for that (in this format thing).
We have that quarterly, but it's employer-focused, so individuals can't post their availability.
To be clear, what I envision is preserving the current structure - top-level comments from employers - but adding a single top-level comment for individuals who want to post their contact info, replacing the "meta questions" sticky comment.
&gt; I would be genuinely surprised if it is the same engine as Visual Studio VS has used EDG's front-end for IntelliSense for years, and EDG is _very_ cross-platform. VSCode uses it, too, for a few months now.
I wrote the writeup in one sitting so it's not that well thought-out and might do some revising along the way to make it easier to read. Please do check out.. first you want to compiler the mango thingy.. for UNIX systems the cmake is currently the "best" way to compiler, that was also contributed to me and I just have tweaked the scripts a bit.. basically: cd build mkdir x cd x cmake .. -DBUILD_SHARED_LIBS=ON make -j10 sudo make install You should be rocking after that. If the dynamic libraries are a hassle, the default is indeed static libs (.a). If you compile shared libs, you can still use them "windows .dll -style" by having the elf loader look them up from the current folder: patchelf --set-rpath '$ORIGIN' my_binary_name Magic! This way don't have to "install" anything to target machine but run the whole show from the same folder (if that floats your boat, does mine with exotic libraries which are not standard). The next step is to compile the snitch/unsnitch to get to play around with the toys.. there is no scripts provided for that, you're on your own. Here's a quick start compile.sh: g++ snitch.cpp -o snitch -O3 -std=c++14 -lmango Didn't really need anything more fancy yet as it's just one file (+ one file for unsnitch.cpp ;) 
The `.catar` mode is single-file FYI.
If management doesn't understand what upgrading toolchains inherently brings to the table, then I doubt they know or care what Boost brings to the table either.
One of my file formats/loaders was explicitly designed to aid streaming file data, mainly textures, to APIs wanting pointers, such as D3D,, without requiring intermediate buffers.
Wait, people still use C++03? I’ve started upgrading my projects to C++20, what is happening?
Same thing going on with this. The APIs this works with also do direct memory-map-to-texture decoding w/o intermediate buffers. There are convenience wrappers for getting up to speed fast in the usual ways: Bitmap bla("fn.jpg"); Bitmap bla2("fn2.jpg", Format(32, Format::UNORM, Format::RGBA, 8, 8, 8, 8)); Etc.. but internally they find ImageDecoder for the file, parse the ImageHeader, use the info there to match the content with the 3D API capabilities, allocate storage, then decode into the allocated storage (D3D, Vulkan, in-memory-buffer, what not). The best performance is when you can tell the GPU that the compressed data is here, in client memory. iOS has capability to do that with hw compressed textures; we don't really "load" anything.. just provide the ptr to the GPU. So there is some synergy between the different layers and how the format was engineered to support that. 
How does it compare with xz (and its -T0 option)? Note that xz -0 (the fastest/worst compression ratio) is probably better than the highest of zip.
The difference is that mine don't allocate storage. You get a pointer. No allocations for intermediate storage are performed by the library or user. The pointer is OS managed, and how exactly depends on the OS (works best on NT).
Define cool for yourself, write down some ideas, then figure out how to do them. Expect to learn new stuff. I have not once already had all the skills I need before starting a new project. 
xz is using lzma2? I got both lzma and lzma2 as compressor option. Lzo, lzfse, lz4, miniz, zstd, ppmd8, bzip2, etc. Interested in more options.. recommend good ones and I can test.
There are lots of niche industries that need C++ developers though. I like the idea. If it's just one stickied post per quarter it's not too much noise at all IMO. 
Exactly. Same thing when STORING in snitch. If you compress or encrypt then there is a buffer. Stored files are mapped from offset they are at in the archive.
Even for compressed files, I just pass a pointer to D3D/whatnot, without an intermediate for storing the file decompressed.
I think so, lzma2 is the default. The main issue with making your own compression format is that then others need to use your special compressor/decompressor tool to interact. Is it possible to use a commonly available tool to open your file?
If I could get page fault handler in user space, we could decompress when reading off the offset within a compressed block. That would be a beauty. Probably slow as well but conceptually pleasing. No go, so not worth worrying about. xD
Rgr.
Oh okay. What are some stuff that could be made from what I already know?
If I wrote a plug-in, then yes. Not really something I care too much about myself.. if there ever is any indication of demand that would warrant a check how I allocate my attention. So far it works for me better than anything else I know about. Emphasis on KNOW ABOUT. 
That's best used with compressed texture formats, since they don't need any parsing. That's how it already works internally. I do need external API to expose THAT specifically for the COMPRESSED case.. uncompressed is already zero-copy. Yeah, I see how compressed case also benefits in certain conditions.. :)
I mean, I literally can feed it a zlib-compressed file, I get a pointer in constant time without decompressing it, and I can give that pointer to D3D or such. I can't go into the details of *how* yet (wary of software patents, working that out still).
Well, we got to the moon with less, so I'm going to say the sky is the limit. 
Your code *will* be reverse engineered if anybody at all cares about it, period. Literally nothing you can ever do will stop that. Obfuscation is about _slowing down_ "attackers" rather than actually stopping them. Every little bit of helpful information that you provide to people naturally helps them work faster. Leaking class names and such via any means will naturally help them piece together whatever puzzle you're trying to hide. There's tons of ways to help "attackers" that are more valuable than RTTI. Debug symbols are the holy grail of reverse engineering, of course. Any symbols help almost just as much. Leaving usage of `__FUNCTION__` or `__FILE__` in your released code is huge. RTTI will just be one little clue to the puzzle, but it's a clue nonetheless. If you've eliminated all the other clues then you'll probably want to eliminate this one, too.
Yup. But what are some actual stuff though?
According to [this](https://www.youtube.com/watch?v=fHNmRkzxHWs) (around minute 45) std::map is slower than it could have been. What alternatives do exist that support this as well?
&gt; I only know the basics such as boolean, loops, arrays, input buffering, strings and those are not even basic, &gt; I'm learning how to do graphic.h so cute 
If you have any large-sized projects at all, you're ahead of the game.
This is just stuff I learnt in HS. I know they're really really simple but wanted to know what I can get out of them.
I have absolutely nothing against AWS or this project but, for crying out loud, what does "v0.1.0" even mean? Is it ready for public consumption? Is it full of bugs? Is it missing basic features? Is it only 10% complete? Should I wait until an actual 1.0? Will there be a 1.0? And if this a "perpetually updated project", why isn't this version 1.0?
Some companies are stuck with rather old compilers - it all depends on the industry you work in. Those with the old compilers work in an industry with heavy safety requirements such as aerospace and may use a specially certified compiler, perhaps targeting special hardware. Those industries most likely can not use boost, however.
&gt;&gt; How should I deal with revisions in the 0.y.z initial development phase? &gt;The simplest thing to do is start your initial development release at 0.1.0 and then increment the minor version for each subsequent release. [From Semantic Versioning](https://semver.org/#how-should-i-deal-with-revisions-in-the-0yz-initial-development-phase)
This answers none of my questions.
Sounds like completely different from what I had in mind and out-of-scope for file formats in this context. From the sound of it, if you do NOT decompress anything but simply pass the ptr to the 3D API the only thing that makes any sense in this scenario is that you are doing compute decompress-on-GPU or something like that. Apologies if my guess is completely off-the-tracks but that is literally the only thing that comes to mind when you specifically stress the fact that you DO NOT decompress anything prior to passing the ptr to the GPU. (I am/were a GPU driver/hardware engineer by profession turned consultant in the past few years so I have some idea about the driver-hardware end of the business. Worked on ATI Technologies/AMD and Qualcomm drivers and GPUs). Since this went a bit off-tracks, my thoughts before reading what you wrote above were as such: A) The non-compressed (=store) case is least overhead if we get the ptr to the memory mapped "file" ; this is literally O(1). B) The compressed/encrypted case is more efficient if we have API where the caller passes ptr to the decompress/decrypt buffer, but requires client to trigger the mechanism in specific sequence: 1. what we have here? 2. act based on the step(1) like allocate storage / prepare target ptr 3. pull the trigger on decompression after the target storage is setup based on the step(2) This would be O(n). The (A) would be inefficient with the API for B, since it would always trigger a copy operation at step 3 when all we want is ptr to existing storage location (provided by the kernel). The (B) would be inefficient with the API for A, since it would require extra copy from internal decompress buffer to the client's target buffer. So the optimum solution with this setup would have different path for the compressed and non-compressed data. But, after reading your response above this line of thinking is not applicable. That's kind of a relief, since I rather just keep the STORE mode O(1) optimal, constant-time and let the decompress case suffer the copy as it is just peanuts thrown on top of the decompression CPU cost. Pretty cool that you have figured out something new, my stuff is just application of same-old-stuff that has been done since forever. :) 
OK, if you insist on a list * Text based game * Calculator * Compressor * Interpreter * Parser * Scientific simulation * Cryptography * ASCII art * puzzle generator This list is not exhaustive. 
It means it's a starting point. Because it has no major version, there isn't a stable public API. Expect rapid iteration of design and feature-set, with possible breaking changes as better ways of doing things are found or defects in the API are revealed.
Cryptography? How would that work?
The dude is being a dick, don't worry about them. You're at the very beginning of programming in general, so while you can't do anything too complex, you can make simple text adventures and just about anything based on text. Try implementing something like https://en.wikipedia.org/wiki/Cowsay, where it's a variety of images with some inlaid text.
I see. I'm gonna assume you can do more complex stuff. How do you meant by yourself to be able to do that?
You take a plain text input and apply either a standard or homemade transform to it to get encoded data. Then you apply another transform to get the plain text back. Alternatively a secure hash applied a one way, repeatable, transform to plain text to get a fixed size hash value that can be used to verify the plain text was not modified, or to act as a storage key in a hash table. (it will be a while until your course work gets to hash tables) You can find good descriptions of simple (and even complex) encryption and hash algorithms online. (Google and Wikipedia are your friends here)
What about a text based game using graphics?
&gt;How do you meant by yourself to be able to do that? If you're asking how you would go about doing that, you need to break the problem down, so start by printing a pretty simple rectangle to the screen via printf, then make it resizable based on some input, like `10,10` would make it 10 rows high by 10 columns high, then add a little ASCII cow next to it.
Is this a way of saying that "the kernel does it for you" -kind of deal is going on? That should still consume CPU time, just visible in SYS instead of USER. To be honest don't know how to interpret that. I know the memory compression in macOS, Linux and Windows but for that to be useful portably they should share some common properties you could take advantage of. I dunno... I am out of my depth here.. 
Sorry, I was asking how you're able to learn the complex stuff by yourself.
Sure
Building up a skillset over time, starting small but always trying bigger things, and a heck of a lot of failures. I've been programming for about 8 years, and did a bunch of online tutorials. Try to get an IDE that autocompletes and highlights errors for you. Something like Visual Studio Community or 20XX, I don't think VS Code does any of that. The last public thing I made was [a game on Steam](https://store.steampowered.com/app/731420/Roguebreaker/), but the very first game I released in 2012 was made by following a [fantastic tutorial](http://www.roguebasin.com/index.php?title=Complete_roguelike_tutorial_using_C%2B%2B_and_libtcod_-_part_1:_setting_up), and since it was a roguelike it didn't need any art.;
That's a pretty valid concern if you look at this from file-archiving point of view; how would this integrate into an everyday workflow. I want to send a couple of files to my friend and how could he easily with zero-effort access the stuff. How can I check what's in the archive w/o unzipping it two years down the road. Right? My goals were a bit different from those outlined above. Meeting those goals would indeed require a multi-platform GUI and other nice tools, lots of add-ones to OS and so on and on. I set out to create a format that integrates into graphical application production pipeline. How to pack stuff into a game, or demo, and stuff like that. In a format that is blazing fast, as fast as the hardware the application is run on. For example, if I use zip format, which works fine, by-the-way, the problem becomes how to serialize data out of the zip file *fast* -- the only way is to access multiple files simultaneously -- one thread for each file. This is because the LZ77/Huffman (=Deflate) bit-streams are in isolation from each other. This of course, sets restrictions how the asset loading pipeline must be constructed and how the files might depend on each other. A modern task-oriented parallelism is more efficient and scales better, almost linearly with number of hardware resources so it made more sense to engineer a solution that uses the hardware. Cellphones, even cheap ones comes with at least 4 cores these days. That's insane. Even more insane is loading screens for seconds, even tens of seconds, while only 25% of the hardware is actually utilized. Crazy. Then the energy efficiency. If you only use one core, you want to blast it at full speed to get anywhere. This consumes a lot of energy. It is more energy-efficient to run 4 cores at 50% capacity than 2 cores at 100% capacity. The battery lasts longer! Save the planet! Use snitch! J/K. But on a serious note, it would technically be possible to create some support infrastructure in the ways you are questioning but that would require serious investment and commitment to the cause. Basically, I only have one customer at this time: me! If I can't please myself anything else is completely pointless. So far I have been very pleased with the outcome even though there is still quite a bit of work ahead to polish the "product", so to speak. Making it work is just 80% of the work, the remaining 80% (!) is keeping at it, improving, polishing, fixing bugs, endless grind to make something "perfect". This is NOT perfect or finished product. I simply got excited that got it "out the door", so to speak. I needed something like this for years, heck, decades. I built similar tools before but this is the first time that I managed to address the issues I outlined earlier, so that's COOL! 
What did you mean by scientific sim?
Im kinda new to all this but want to learn. How does everything come about together? Like engines, programming concepts, good graphics, etc.?
Simulation of systems like Newtonian Physics, Chemistry, Fluid Dynamics, Population spread, etc. This covers a lot of ground from simple cannonball shooting, planetary orbit calculation, "the game of Life", airfoil design tests, all the way to neural networks. 
That's too broad for me to answer, can you be more specific?
Oh I see. Is it possible to make checkpoints and save them if you were to make a text based game?
Honestly, how does everything work together to make something? Like how do you use programming concepts + graphics + an engine + some other stuff to make something. Just in general?
Yes
Yes
I mean it's all code, a set of functions to draw to the screen, a set of functions to take user input, a set of functions to handle animations between the input and the screen. 
What I mean is that xz's file format implements what you did and packed it into a standard file format. I guess you could achieve the same performance on its file format? Then you would get the best of both worlds: great performances, yet on a common enough file format that you can open on any OS you can think of.
I see. What about actual softwares? Like how are those made and do work. Like the ones that people actually pay for?
Yes
What do you mean? It's all functions and code all the way down.
I wouldn't say that I've created a complete game or anything I'd consider a large-sized project. At most, I've created game systems and elements of gameplay. The art &amp; VFX assets that I used were free and not created by me. However, it is my intention to complete a simple 2D game before the end of the summer. 
And yet, people have been tempted to write i++ + i++;
Have you looked at blosc? It sounds like a much more mature variant of what you're aiming to do: https://github.com/Blosc/c-blosc/blob/master/README.md Multithreaded, fast, it can use different encryption schemes, and breaks down the input into blocks to be compressed that are cache friendly. And it's extremely well tested, it's used for Pytables.
Code generation is still quite bad though: [https://godbolt.org/z/q4C\_gl](https://godbolt.org/z/q4C_gl)
Ah, I see. Yeah, definitely misunderstood, so I'm glad you got a clear answer. To answer your question directly myself... No, I wouldn't anticipate any significant increase in productivity. The only exception is when you can make use of some specific tools that Visual Studio may already have built in (some of which Sean mentioned). But honestly, not enough to worry about until you find a specific need for them. 
I disagree with the OP’s reason (CTAd snafus) against inheritance. But I also disagree with your example. Alexandrescu’s and Sutter’s C++ Coding Standards Item 35 is almost identical. The feel your pain of writing one line delegates, but still recommend: "Admittedly, it's tedious to have to write passthrough functions for the member functions you want to keep, but such an implementation is vastly better and safer than using public or nonpublic inheritance."
now I feel dumb for searching for the todo library
/u/STL this is the first major version update/upgrade for VS that I am observing closely. Would all of these improvements also make it to VS 2017? Or would they be VS 2019 only? 
&gt;When the compressor was much faster than the device, the compressed blocks kept piling up and memory usage went through the roof. This was on 10-core machine and I was compressing something like 200 GB of files as a stress-test. &gt; &gt;The solution was simple and effective: keep the thread pool slot reserved until the write has completed; there is zero point to use CPU until the compressed data is flushed out. I don't think this is optimal... storage has latency, and by blocking compression for a thread during the write, you're wasting time. I would have used a FIFO buffer between computation and writes, with computation being blocked if the buffer is full.
I noticed you don't really talk about decompression rate-..? &amp;#x200B; For me at least, decompression rate is way more important than compression rate, and LZMA2 is not a fast decoder, what only 50 mb/s? &amp;#x200B; I use ZSTD for most files, it claims 1300mb/s although I've never seen more than 600mb/s, and even it is still what I'd consider rather slow(for files I need loaded immediately I use LZ4 instead). &amp;#x200B; I'd like a version of ZSTD that breaks the file into blocks like what you are doing, but instead of focusing on threads for decoding them, using vector lanes. If I ever have the spare time maybe I'll try doing that-- &amp;#x200B;
Cool article, scary how that might work on you without realizing.
&gt; This means that the abstract machine has to stop and tell you that something is wrong with your program, and terminate the program (in the case of most compilers today, that means stop compilation. But if you were running C++ through, say, an interpreter, then that means stop execution). No, that's not what ill-formed means.
If you check the commit history I indeed had a FIFO there at first; the SerialQueue does literally execute the tasks in the exact order they are committed. In effect, this is a write FIFO. The only difference to circular buffer -like arrangement is that there is no fixed amount of pre-allocated memory. The memory allocation overhead is not even visible on call graph since the compression work completely dominates the runtime. The compression is currently blocked by I/O, when it can't keep up and can saturate every available CPU core with compression work when the I/O can keep up. The blocking does not consume any CPU time; the CPU is available to other work, the only limitation is that the other work cannot come through the pool as it is the pool executors that are blocked (since the blocking is done in the compression task). That is something I would try to avoid to keep the pool clear of crap like that but in this case it does not matter since the only work it is doing at the time is the compression work. As mentioned, I did have the write FIFO in form of SerialQueue at first but it did not add any value so I removed it. If I changed it to work so that the compression task would request target buffer from the circular write buffer, we would just move the blocking to the memory request from flushing the buffer to disk. The throughput would remain more or less the same (we are blocked by I/O, after all). It is nice that you took your time to reply, appreciated: thanks! :) 
I'm not sure why std::pair is always used as the example of CTAD. std::pair is dumb, nobody should use it in the first place! It only takes a few lines of code to define a two-member struct, the "rule of zero" means that you shouldn't need to add any functions, and you end up with much more meaningful names than "first" and "second". // this is bad void print_complex(std::pair&lt;int, int&gt; c) { printf("%d + %di\n", c.first, c.second); } // this is much better struct Complex { int real; int imag; }; void print_complex(Complex c) { printf("%d + %di\n", c.real, c.imag); } The same thing often applies to std::tuple, but tuple is fantastically useful in certain template metaprogramming scenarios. std::pair has no such redeeming qualities. The one place I've found where I can't avoid using it is when iterating through a std::map, and I look forward to structured bindings making that obsolete. 
It's not always money. E.g. in safety environments you usually use certified compilers/tools and to certify a compiler in regards to safety standards is a very difficult and expensive process. And to do that you need to have a pretty good business value besides "I want to use C++20". But then in such environments you're probably not using Boost anyway.
I might have forgotten to mention a lot of things as I wrote the thing in one sitting. Currently the compression method is configured to be same for all files (the format allows it to be different for each block) so you can choose between compression time, decompression time and compressed data size using the knobs available. The block settings are currently fixed but probably expose those eventually as well after add a proper command line parameter parsing in there (that haven't been that important until now). Large files, which need most help, are indeed broken into blocks so the decompression can be done in parallel for those files. I don't mean "unsnitch", that tool is just extra, the main use case for me is serializing stuff OUT of the container from C++ source code. That is the case I care most about. The choice of algorithm has quite the impact on overall throughput. It's just extra that I plan to add "--exhaustive" and other flags to the compressor so that can also make "as small as possible" resulting compressed files when I need or want to. The idea of exhaustive is to be super-slow in compressing since it will try every algorithm and pick the one that results in the smallest file (super slow, like 10x, but might come in handy, or maybe not, don't really know yet). These are all just options around the basic framework: the main thing is the format layout, if that needs changes to cater to new features then I need to bump the version number.. hopefully not too often..
The scariest ODR violation I've seen in the wild was when it overlapped with the fact that functions defined inside a class are implicitly inline. In this case, there were two completely unrelated unit tests in two completely different files, in a project with hundreds of unit test files. Both of them happened to declare a helper class, and because they were both following a common pattern, the result looked like this: // somewhere in the first file: class TestHelper { int i; void Initialize() { i = 5; } }; // somewhere in the second file: class TestHelper { std::string s; void Initialize() { s = "hello!"; } }; This is an ODR violation: we have two different functions named TestHelper::Initialize, which are both implicitly inline. When the second one was added, the bug manifested as the first one suddenly initializing its member variables to garbage, because the linker picked the new one for whatever reason. If I remember correctly, we only noticed this issue because it caused a unit test to fail, and we only managed to solve it because single-stepping through the failing unit test in a debugger landed you in the other file when you got to the call to Initialize. If this had happened in a less obvious place, I don't know how we would have figured out it was the ODR. 
Sounds pretty much like a money problem to me. The business case usually comes down to less lines of code, better performance without resorting to manually coding assembly, support for safer coding idioms (particularly in c++20) and faster compile times. And nowerdays, you can even get problems hiring new people if they are only allowed to program in c++98. I'm not saying that it is always and in all cases worth the effort and money (and often c++ might be the wrong language to begin with), but the cases where it isn't are imho few and far apart and as you said, it is questionable if boost (let alone the most recent version) is used there at all.
yeah. still i am amazed how it kinda seems(! :-P) to work out in the end every time. and now consider you use an external external prebuild/precompiled library. we take it for granted that it works but i cant imagine that ALL compilerflags and ALL other dependent things in the development enviroment are exactly the same for every translation unit and library component. its scary :-O
Whilst I agree with your criticisms of `pair` and `tuple`, I do like using them because I don't like to introduce a new type just to return multiple values from a function, especially when I'm using structured bindings (currently still `tie` :() on the call site anyway.
You seem like a very nice and positive person. Here's what I see when I see 0.1 in a semantically versioned project. &gt; Is it ready for public consumption? 0.1. No &gt; Is it full of bugs? It's 0.1. So there are probably bugs. &gt; Is it missing basic features? Basic? Probably not. Does it have all features? No. Does it have the features you need? Probably not all. &gt; Is it only 10% complete? Not how semantic versioning works &gt; Should I wait until an actual 1.0? If you need the whole thing. Yes. &gt; Will there be a 1.0? If it's using semantic versioning. Yes. I'd much rater get a 0.1 to play with and help this project evolve than get a 1.0 that isn't delivering on everything it should have or wait a year to get a 1.0
Unittests are full of such classes and functions with generic names. Imho best practice is to wrap everything in a unit test cpp file into an annonymous namespace. 
And that is why conditional compilation in header files (and to a lesser degree in source files) is evil. Another common example that is missing are assert macros: Effectively, any assert in an inline function in an ODR violation waiting to happen. My personal preference would be that only preprocessed headerfiles get installed on a system (os or package management system) 
I agree with all but this: &gt;Will there be a 1.0? &gt; &gt;If it's using semantic versioning. Yes. It also depends on the popularity of the project and other incentives to keep it alive. Remember ASL adam and eve?
2019 only, except that we might retrofit 2017 charconv for completeness (non-intrusively).
Now we just need to make it applicable to std::array too
I've lately been wondering if we could do without header files at all. Would it be feasible to have the compiler scan the source, identify all classes, functions, etc. and use that as the input for the real compilation? It would make things massively less complex - well, at least on source level...
Oh sure. I'm being positive here :) It's also written by one of the guys that works on aws at amazon. So I think it's likely :)
&gt; It requires the implementation to issue a diagnostic. What about 'ill-formed, no diagnostic required'?
Behold our savior is near: c++20 modules ;)
The format is pretty decent now that I really looked at it. On hindsight it might have been a viable candidate. On the other hand, there is more control over your own creation in a sense that when I need something changed can just go and do it. It might make sense to write xz container support into the back-end library since I already do zip and rar. Thanks for making me take another look! 
That means your code is not actually C++, it just looks a lot like it, and the compiler isn't required to realise this is going on.
I wonder if it would help to consider which TU the functions were defined in during linking. Sort of make translation units "namespaces" for linkers. Such a linker could make the case you described work as expected, or at least diagnose the problem.
I think you need to differentiate between devs wanting to be hired full time but remotely (and can't find remote work), and devs looking to do piecemeal work to bolster their CV, add a bit of cash on the side, not be bored to death in their main job etc. The two are *very* different categories, though people in the former will often dip into the latter to fill in income until the next gig turns up. I myself am back to unemployment after a twelve month full time contract, and I'm likely to dip into piecemeal work until something long term turns up. I had been more thinking of asking the Standard C++ Foundation for funding of said piecemeal work implementing various experimental compiler forks, but in the end all piecemeal work for me is a stopgap bridging me to the next long term remote working role. After all, got children to feed, and no other income into the house. What I will say is that I get quite a few work leads from being here on Reddit. There are definitely people looking to dole out piecework to known-competent devs. They just couldn't be arsed sorting through the muck on odesk etc.
I believe that still holds to the notion that something must be at least be declared before it can be called, thus forcing a build order on a project. Why not do away with it entirely? Instead have two-phase compilation: first scan for definitions, then compile. Remove all compilation order problems, and the ability to have ODR violations at all. Would it be possible?
Thing is, that sticky comment is currently associated with full time, usually non-remote, roles. What we're talking about here is likely 100% remote piecework. It's not the same kettle of fish. There are definitely people on here looking to dole out piecework to known-competent devs. I've received a fair few approaches. So have others on here. It's been worth it to me to regularly appear here as a result. Similarly I remain unconvinced that the effort to appear on Slack is worth it, currently.
Yes. I've asked for https://github.com/ned14/boost-outcome to be added to the 1.70 boostorg super repo. The code has been finished for six months now, reasonably debugged by a large number of devs and multinational corporations. It's just that damn documentation ... I hate, hate, hate writing Boost-quality documentation.
Anonymous structs should be a thing for function return types. Fun fact: in msvc this is already available: struct { int a; double b; } test() { return { 1, 2.0 }; } main() { auto[a, b] = test(); } This compiles.
&gt; Yeah, okay, that’s not feasible. Why, though. It could produce a unique hash of the function's content (or of its AST during any defined stage of the compilation), those would be rather easy to compare.
I'm not sure what the win is here over using a pair/tuple?
Checkpoints in c++? I thought you couldn't do that
Umm. Something like antivirus softwares or let's say Spotify.
Why you even throwing, though? Just do nothing.
Only if you use the old layout. The redesign can render the format starfreakclone used. But that doesn't make me use the redesign
As I said: That is pretty much what is happening with c++ modules. Also, you can have the same effect if you put all the code into headers and have a single TU. 
`boost::beast` is very low level. It is like comparing Rack to Sinatra. `boost::beast` can be used as a building block, but not as a library or framework. 
No templates. No external dependencies. Good names.
If that's the case, why do I hear so much grumbling about module build order being an (almost) unsolvable problem? And I wasn't asking because I wanted to write toys. Having everything in a single translation unit is not an option.
structured bindings are also pretty shitty tho. why aren't they variables? why are they names?
Hat some fun with a C library function crashing on me. Because I defined **bool close;** in global namespace. And the linker used that one as the function pointer for close(). Yay, fun!
&gt; I'm not sure why `std::pair` is always used as the example of CTAD. Because `std::pair` is one of those class templates that doesn't have reasoning issues with CTAD. Assuming this compiles: std::pair a(x); std::pair b(y, z); `a` is unconditionally a copy of `x`, and `b` is unconditionally a pair containing the decayed types of `y` and `z`. It makes for a great example because it's easy to explain and it's easy to reason about, always. Makes for a good example. 
&gt; Also, you can have the same effect if you put all the code into headers and have a single TU. You still have to have declarations/definitions in order, even in a single TU.
Nope. A definition is always also a declaration.
ONG I had exactly this same problem a few days ago and things were initializing wrong and ON A WHIM I decided to change the test helper's name AND IT FIXED THINGS. As a side note, I think this is why in some codebases all Translation Unit-local classes are wrapped in an anonymous namespace, because that allows the compiler to generate some weird mangling name to make them different? Or maybe they do that for another reason, I'm not sure.
Ever heard about unity builds? I'm not saying I'm advocating it. Just saying it is a possibility. I'm looking forward to modules as much as the next guy, but personally, I like the interface / implementation split (afaik that will still be possible with modules) And I have no idea what grumbling you heard and how it relates to what I wrote ;)
If some classes or functions reference each other, you still need forward declarations, even in a single TU. I think what /u/johannes1971 is proposing is completely removing the need for forward declarations - use a symbol even if its defined later. You cant do that with current C++.
why not? game checkpoints have nothing to do with your language, they depend entirely on the design of your game. 
Had a fun one recently, where we managed to include two different versions of the same header-only template library (no defines/macros!). One version used malloc/free, but the newer one called new/delete. Final executable called malloc followed by delete :)
&gt; As a side note, I think this is why in some codebases all Translation Unit-local classes are wrapped in an anonymous namespace, because that allows the compiler to generate some weird mangling name to make them different? AFAIK that's how it worked. However, since C++11 anonymous namespaces have internal linkage. So I guess that removes the need for generating unique names.
I think you underestimate the cost of hashing the contents of every translation unit before optimization. Each individual entity would need to be hashed. Then, you would need to compare every single entity in the case hashes match. That means you need a full AST (beyond debug info) for every single translation unit. That is a HUGE serialization cost, then loading that from your object files for the linker to check... It's not worth it.
Yeah that's the conclusion I have too. Thank you!
I suspect it depends on the project style. For one written in a heavily OO style, I'd say there's potentially a lot more you can get, because you can determine entire class heirarchies, find the vtable for each class, and track that back to figure out what functions in the program are class methods, which functions override other functions, etc. I don't think I can legitimately call myself a reverse engineer (though I work on RE *tools*), so I don't know for sure that someone who is deep into this stuff would use that information, but I suspect it would be useful.
Yep, and for OP the IDA plugin ClassInformer does this automatically, but the fields within still need to be mapped out which is where most of the time is spent.
Assert in inline function would be an ODR violation ONLY if the inline function is also compiled into binary outside of the current build tree, which is not necessarily the case. You are overgeneralizing.
This post by a very smart and experienced commentator illustrates to me what is the main problem with C++ today. People who make the decisions are too smart! &gt;The correct way to program a generic function is this: *Know what you are doing*. &gt; &gt;That is incredibly unhelpful, I’m sure. A more elaborate answer is that one must understand the exact API and requirements of the types you are dealing with, and the subtle ways in which they may break from a naive understanding. This requires that anyone who reads this code keep in mind a raft of arcane rules with lots of special cases and conditions. It's the language equivalent of writing code riddled with side effects. One can't predict what it's going to do without investing a huge amount of effort reading the standard documents. In practice we don't do that. We just compile it and see that happens. This is not an effective way to produce demonstrably correct code. &gt;This is vaguely reminiscent of the fear of auto that plagued (and still does, to an extent) the C++ community for years. Cries of *auto* *will do the wrong thing!* have echoed through Internet message boards for nearly a decade now. I can’t provide precise figures, but I would estimate that I’ve used auto roughly 100,000 times so far. Of those, the number of times it has done “the wrong thing” is probably 100. Of those, 90 of them were compile errors and fixed immediately. Of the remaining ten, eight were a bit trickier to track down, and two of them resulted in spooky behavior that required a debugger. Same problem here. When we use auto, we're hiding our intention from the compiler and permitting anything to work. This suppresses one of the main benefits of a type safe system - forcing us to declare our expectation and enforcing that expectation at compile time. Sure its faster to use auto - but I believe it results in lower quality, more obscure code. &gt;I’ve never seen an auto \-related bug ship. LOL - I've never seen any bug ship - that's why its a bug! The larger issue is what is C++ supposed to be? Is it supposed to be a simple and transparent way to describe the work you want to accomplish, or and endless guessing game/research project figuring out what your code is supposed to doing. It's evolved into the latter and this article demonstrates that. &amp;#x200B;
Big kudos for simplified multi\_index key syntax.
I don‘t think hashing the ASTs would be any kind of bottelneck compared to the other steps of compulation. You also don‘t have to store the ASTs or compare them - you just issue a warning if the AST hashes of a symbol are different in two compulation units. That indicates that OPs issue is present. With any cryptographic hash, the chances of a false positive warning are practically zero.
It actually returns a copy of the original string. So maybe people used to call .clone()?
Ahh. Didn't know that. Bad reddit. Fix your shit.
That's covered by string a = b;
`string` is just a typedef of `basic_string&lt;char&gt;`, and `wstring` is a typedef of `basic_string&lt;wchar_t&gt;`. Plus more. So, `s.substr()` is a neat way of obtaining a copy without specifying the type. But since it's an rvalue expression you can't pass it to a reference argument. And so I fail to see any use for it. For what it's worth, it's been like that since the first standard, C++98. 
That's why I mentioned .clone(): in some language assignment operator= doesn't copy :)
My thoughts on this (which I've expressed once or twice on the list): Boost is a disparate collection of projects with little central authority to enforce consistency in terms of standards compliance. On one hand, some of these projects are bleeding edge, but on the other hand, some are ancient and poorly-maintained and barely work with modern C++. Boost is currently trying to have its cake and eat it. It's trying to cater to everyone, and in doing so, it's failing everyone for different reasons. It's firstly trying to cater for users of all compilers back to the first C++98/03 compilers. This results in a huge amount of compatibility cruft, as well as retaining libraries which have long been replaced by equivalents in the standard library. It's secondly trying to develop cutting-edge libraries with the aim of standardising them prior to proposing them for inclusion in the standard library. These two goals are to some extent incompatible. My personal take on this is that Boost should drop libraries after they have been standardised. There's no need for `array`, `tuple`, `shared_ptr`, `filesystem`, `type_traits`, `any`, `variant` and the rest now that these are available in the standard library. Some of them are inferior to the standard versions because they drag in stuff like MPL which exists only to serve pre-C++11 compilers which lack variadic templates. Thus users of modern compilers pay a price for catering to old compilers both in quality of implementation and complexity. There would clearly need to be some time overlap to wait for the standard features to become more widely available before dropping them from Boost, but some policy to that end would be useful. All the features added for C++11/14 could be safely dropped at this point. In addition to dropping libraries, I also think that libraries should be kept up to date with modern standards and practices, rather than being left to bitrot. There's no reason for MPL now we have variadic templates, for example, so any library using it should be updated. When we consider the users who require support for older compilers, I don't think it's reasonable or fair for these to be supported by the current Boost releases. There are old releases of Boost which aren't going away. If you've frozen your compiler requirement to a decade+ old compiler, why haven't you also done the same for Boost? These old systems are costly to support, but the people asking for this support by and large are not the ones paying for it. But it is a hindrance which every user of a modern compiler has to pay for. There's always going to be some tension between backward compatibility concerns and requiring or allowing use of new features. But Boost does seem to have it's collective head buried in the sand on this point whenever it's discussed. The lack of central authority in making a concrete decision on its future direction means discussions are never resolved, merely repeated. A clear plan would be a good start, e.g. a baseline of C++14 with all the compatibility macros for rvalue refs etc. removed.
Maybe somebody did this thinking that maybe someday in the future we would have named parameters such that you could get the first N characters via `s.substr(len=N)`? Probably not, but it's an interesting thing to think about.
It depends... We use Boost here, but we're only using gcc 4.8.5. We did turn on the experimental C++11 support, though, for our latest release. Basically, we use what's available in the stock package manager of our base OS (CentOS) and don't pull in extra external stuff if we don't have to. Our main issue is that Red Hat chooses to continue shipping ancient compilers as the stock compilers in RHEL and, by proxy, CentOS. While they do provide a method to use newer stuff in RHEL via their developer toolset package, apparently it requires some extra hoop jumping to get it part of CentOS, especially since there is no "official," signed CentOS repo for them.
If you use a RHEL-based Linux distro for production and only use the stock compilers, you're pretty much stuck with C++03, although you could turn on "experimental" C++11 support.
Neat in this case means clever and confusing to the reader.
I totally agree with you, and I think it's a great idea!
I said it is an odr violation **waiting to happen**. Not that every assert actually results in an ODR violation. Obviously I'm exaggerating, but that headers are ending up in different build trees is quite common unless you really build everything froms scratch. Consider libraries that are installed on your system or from your package management system. 
Pretty much my thoughts except that I would be a bit more conservative (c++11 seems the better base line for me at the moment than 14, but there should be a clear path forward to 11,14,17,20 etc.). Regarding modularity: There are different kinds of modularity. Boost is modular in the sense, that you can only install a subset of boost libraries, but almost all of them drag along hughe chunks of boost-internal dependencies. Even Boost.Hana - arguably one of the most modern TMP-Libraries - depended on boost::mpl indirectly last time I checked. 
I think that's actually how "static" works. You can have two different static functions with the same name in two different TUs and it works fine. It's totally possible to write a static function in a header file, and the result is similar to making it inline. There are a few subtle differences, though - the one that comes to mind is the treatment of static variables inside the function. As far as diagnosing the issue, I'm not sure why linkers don't already do this with the information they have. Maybe there's no way to do it efficiently?
You can do it if you wrap the entire TU in a class body so that everything becomes members. ;) But then you can't `#include` anything, or specialize `std` templates, or write `using namespace std;` (so, good?)... and you end up with different rules for overload resolution. So I guess even as a joke that doesn't work. https://wandbox.org/permlink/hbG6Z1X24ytZRh9l
But without needing to create a named variable
Default arguments were in fashion when std::string was "designed"
I just wanted to second the add\_subproject idea. As someone new to CMake, it seems to me that ExternalProject and FetchContent are on opposite sides of a spectrum. ExternalProject is a pain because the targets aren't available to import until after it's built for the first time. FetchContent seems to eschew the need to export targets altogether because targets of the third party library just become available to you. Something like externalProject that makes its targets automatically available at configure time would be nice. &amp;#x200B; &amp;#x200B;
Or you could just do `string{b}`
Some older string implementations used reference counting with copy on write semantics. Not sure if any had substr force a copy. 
Link to the cheat sheet itself: [https://github.com/srcmake/cpp-stl-algorithms](https://github.com/srcmake/cpp-stl-algorithms) Link to the tutorial on Pairs, Lambda Expressions, Iterators: [https://www.srcmake.com/home/cpp-stl-algorithms](https://www.srcmake.com/home/cpp-stl-algorithms) I was inspired by a certain CppCon talk showing the STL algorithms, especially since I participate in programming contests and the algorithms seem useful. I couldn't find any resources that actually explained the algorithms in simple words or that gave short enough examples for me to find useful, so I decided to make my own. The STL Algorithm cheat sheet that I wrote on github is meant to have a very short description of each algorithm and provide 2-5 lines of example code showing how the algorithm is used, and what gets modified/produced as a result. &amp;#x200B; If there were better resources and it was a waste of time, please let me know lol because I'd love to know where everyone else gets their C++ resources from. But if you find this useful, please star/share the project on github so more developers can \[easily\] see how these algorithms are used so that they can learn/use them themselves. (And if I made an error somewhere or you see room for improvement, please let me know.)
Btw since this relates to the Standard/C++ resources, how do I ask for this to be put on [isocpp.org](https://isocpp.org) ? I'd like to share it there since the homepage has other resources, but I don't know how people are supposed to do that. I'm not part of the Standard Committee so...
I'm hoping that the recently created SG on education and teaching provides some kind of push back against features like this, which make the language harder to explain to novices. In this case, CTAD intentionally blurs the distinction between types and templates. That's a really important difference for new programmers to understand, especially because of all the contexts where CTAD doesn't apply. 
I think idea of the user package registry is good, but the current implementation is bad. This goes back to c++'s need for a good package manager. I've been using vcpkg for a little bit and think they're on the right track although it's still not quite cross OS / cross architecture as it needs to be (but in principle could be because it's built on cmake). I think the user package registry would be better if it was all contained in a user specified directory. In other words, if I had a directory structure like /home/user/my_third_party_libs ├── x64-linux │ ├── include │ | ├── awesomelib_v1 │ | └── awesomelib_v2 │ ├── lib │ | ├── awesomelib_v1 │ | └── awesomelib_v2 │ └── share ├── arm64-linux │ ├── include │ | ├── awesomelib_v1 │ | └── awesomelib_v2 │ ├── lib │ | ├── awesomelib_v1 │ | └── awesomelib_v2 │ └── share └── my_third_party_libs.cmake and then when I want to use one of the libs I would just have to explicitly point find\_package to /home/user/my\_third\_party\_libs and specify the lib version I wanted. &amp;#x200B;
I like this
I was going to list issues I have with that, and I have started doing it and named following: How is it better than [https://en.cppreference.com/w/cpp/header/algorithm](https://en.cppreference.com/w/cpp/header/algorithm) (the page) STL does not mean standard TEMPLATE library for about 10 years for now std::pair is NOT a container, it's a struct template. Lambda is CERTAINLY not a different way to write a function, it's very different from that. And than, when you started talking about auto as a lamba type, I just realized you are not really familiar with the subject. May be you should learn more and teach less?
I can try to lead you on the right path. Are you familiar with how CPUs work with the kernel? Interrupts? Vectored exceptions/signals? Logical memory management?
One man's "neat" is another's WTF.
I've experienced pretty much exactly this ODR failure mode, but in live code, rather than tests. So, production runs just started failing with sufficiently new toolchain and the right (wrong) bits coincidentally linked in.
With any deterministic hash, the chance of a false positive warning is exactly zero - you're talking about identical definitions hashing to different values! The concern would be around false _negatives_, where functions of the same name but different content nevertheless hash the same, and thus *fail to emit a warning*.
It is nowhere near the quality of materials for isocpp.org.
You're not doing any sort of all-to-all comparison - you're only comparing whether an instance of a given symbol is already present (which the linker already does), and if so, compare the hash value stored alongside it to the hash value stored alongside your present instance.
Isn't [softwarecollections](https://www.softwarecollections.org/en/scls/rhscl/devtoolset-7/) not the canonical location? It's all supported directly via yum. I've been using this for a good while without any trouble. Not any more difficult than doing it on RHEL, other than the first step being slightly different. There aren't any extra steps to take, so I'd class it as being just as easy.
If you're restricted to using a specially certified compiler and tools, why are you using a new Boost release without also rigorously testing and certifying it as well? How do you justify the "business value" of a new Boost version compared with a new compiler version? Both bear risk.
That's why I wrote the last sentence.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/a5x1h0/suggestions_for_tutorialsbooks_on_implementing/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Not shipping with known bugs just means your testing is too limited (for any nontrivial program).
That's correct. Maybe advocating is a strong term, but I'm curious to learn if it would be feasible to do this or not. It would simplify things a lot. 
I'm already using unity builds, which helped both compile time and compile size (I mean diskspace used for generated files) a lot. I'm hoping modules (or some similar solution) would get rid of the downsides of unity builds, though. 
As I said in the video and the materials themselves, the way I described those things (pairs, lambda expressions) isn't meant to be a definitive bulletproof explanation, it's supposed to very easily let someone who never used them before understand that they do. To be honest, the fact that you take such offense to a very short definition of these things is what I find to be wrong with most C++ educational material: the point should be that the user understands the concepts behind ideas enough to actually move further and learn how to write the code for it. I don't see why a user should read an entire manual page for pair when they can just understand "it holds two things in it" and move on to other concepts. TL;DR it's supposed to be simple and easy to understand for beginners. If you honestly think that someone needs to know "a pair is a struct template, not a ""container""" to be able to actually understand what a pair does, then you're focusing on the wrong things. 
Against these kinds of mistakes, I really like gcc's [`-Wmissing-declarations`](https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html) / clang's [`-Wmissing-prototypes`](https://clang.llvm.org/docs/DiagnosticsReference.html#wmissing-prototypes) + [`-Wmissing-variable-declarations`](https://clang.llvm.org/docs/DiagnosticsReference.html#wmissing-variable-declarations). They warn you about any functions not previously declared, forcing you to either include the proper header (if applicable) or put them into an anonymous namespace, as /u/kalmoc recommends. I think these are among the most useful warnings not covered by the usual `-Wall`-like groups.
It may be the case that C++11 is a better baseline. However, when I evaluated this for all of the Linux, BSD, Mac and Windows compilers I have to support, it turned out that all of the C++11 compilers all supported C++14 [for the featureset I require, at a minimum], so I was able to raise the minimum requirement without any changes to the supported platforms. The main annoyance was CentOS 6 and 7, both of which are served well by devtoolset-7 to provide GCC 7.
substr predates the current meaning of auto by several years. 
There's also null-termination if you use `[]` (the standard requires that `&amp;s[s.size()] == s.data() + s.size()`).
What does STL mean?
There's no member `length`. Maybe you meant `s[s.size()]` which is guaranteed to refer to the character after the last `e` and has value `0`.
Your material quality varies from incomplete to misleading to outright wrong. It is actively harmful. One reason why good C++ educational are actually quite involved is not because their authors are stupid and don't know how to present material. It is because C++ is a complex language with often quite complicated and counter-intuitive concepts, and in order to master them, one needs to have a very good grasp of the basics. Yes, it is important to understand that pair is not a container, because container is a very specific term in the Standard. Containers provide certain functionality, which is not provided by pairs. It is also important to understand what is what. And pair is not that simple at all, contrary to what you think. How about this constructor: template&lt; class... Args1, class... Args2 &gt; pair( std::piecewise\_construct\_t, std::tuple&lt;Args1...&gt; first\_args, std::tuple&lt;Args2...&gt; second\_args ) - do you know what it is and what is it for? I strongly suspect you don't, and it is very important to know about it, because it's usage plays a great role when populating associative containers. And I honestly think that beginners should stay away from your materials. And next time you feel like educating someone, keep in mind that a very clever man once said "A wise person loves to learn, stupid one loves to teach." 
It doesn't seem to be supported by yum unless you go out of your way to add its repositories to yum's search list. From what I recall with our problem, it seems like the packages on Software Collections aren't properly signed, or at least aren't signed in the same manner as stock CentOS packages, so they break something with our own internal packaging and distribution system.
Oh okay.
Standard Library. 'Template' was dropped long time ago.
&gt; As far as diagnosing the issue, I'm not sure why linkers don't already do this with the information they have. Maybe there's no way to do it efficiently? Gold has a `--detect-odr-violations` flag. My impression of what it does is look for a public symbol that is defined in two different object files where the sizes differ. That's something that can be done efficiently and is a good heuristic, but is also far from complete. A full-blown ODR checker would be pretty expensive.
&gt; why do I hear so much grumbling about module build order being an (almost) unsolvable problem? It's solvable, see `build2`. I think it's jsut hard for conventional build systems (they need to parse C++ code to generate dependency graph).
Thank you! Don't hesitate to report on your experiences with key terse syntax.
C++ in a nutshell.
Great news ! I won't have to build Boost separately for my projects now for all my targeted platforms :D &amp;#x200B;
The material is the algorithm cheat sheet. I'm not sure why you're so fixated on the pair, lambda expression, and iterator explanations lol. Honestly, I used the word "container" in the English sense of "holds something", not the C++ language definition. I don't want to (or have the time to) argue, but I don't think your perspective/mindset is actually aligned with what beginners learning the language actually care about or would understand. (Once again, I tried to explain things in English to get the point across in the context of using the standard library's algorithms. If you want to learn about a pair, that wasn't the video for you. And honestly, for you think that a 1 minute explanation of pair could somehow be totally complete is way too ambitious. I'm not sure what you were expecting lol.))
no u
Those beginners are going to start calling pairs 'containers' and everyone will be confused and worse off for it. Terminology matters; details matter; even for beginners.
And? Would `std::string copy = original.substr();` still be better than `std::string copy = original;`..?
It seems to me that linking objects together that were compiled with _any_ different \[system\] macros is asking for ODR violations, not just `_NDEBUG`...
Does someone know why, since version 1.67.0, Boost is not tested for Android ?
The auto code response was in reply to " a neat way of obtaining a copy \*\*without specifying the type\*\* " . 
Absolutely. I just wanted tomentioned one common one., that was not covered in the article. 
Fair enough, I hadn't noticed that as it wasn't in the quote preceding the code. That said, offhand I can't think of a context in C++03 where I have an object but don't know its type but magically know it's some `basic_string` specialization so I still don't see the overarching point. ¯\\\_(ツ)\_/¯
IIRC, ubuntu 14.04 comes with gcc 4.8, which doesn't have c++14 support, but I think that won't be supported anymore once the next boost release comes out so maybe that is not sm issue. 
I daresay, it matterst most to beginners. After all, experts know what container is. Beginners don't.
I am familiar with the topic. The basic building block is MMU, which allows to map linear address into physical address through indirection (table lookup). Without MMU the allocated memory would have to he contiguous physically, which would make memory management a lot more expensive as it is with virtual addressing; we only need a continuous address space to map the physical pages into. The same problem appears if we have a GPU without MMU, especially in UMA architectures since the GPU-accessible physically continuous address range has to be reserved at boot time (so called "graphics memory). I have ran into this problem while working on GPU drivers for architectures w/o MMU. Of course, later revisions have included one but the damage has already been done: the driver has to support both flavours of memory management. Long story short; yup, I am familiar enough (I think) about the topic as I have written protected mode code since 286 was introduced. That was a while ago (I'm pretty old, I guess). 
Me what?
 auto test() { return struct { int a; double b; }{ 1, 2.0 }; } int main() { auto[a, b] = test(); } This is legal. ;-]
No one forces you to explain what pair is. You could simply say that knowledge of pairs is prerequisite. By the way, don't think that the rest of your material was steplar correct. I simply stopped keeping count one you started mumbling about auto type for lambda and how capture is an insignificant detail not worthy of attention.
 auto test() { struct { int a; double b; } ret{ 1, 2.0 }; return ret; } int main() { auto[a, b] = test(); } This is legal. :-]
ASL was written by guys at Adobe; didn't mean much. ;-]
It is interesting how MSFT pivoted about 10? years back and really embraced Linux. Now they even post how to use Linux kernel namespaces on their Visual Studio blog. May be they would release Office for Linux?
This is the only sensible answer. If you were forced to pick a default argument value, 0 is the only sensible case, so that’s why it was chosen. So the question is really “why is there a default argument on substr?”
There is no clone() for C++, and std::basic\_string::copy copies the characters, not the string object. std::string::operator=(const std::string&amp;) is copying into an existing object, but really the equivalent of doing std::string::substring() would be std::string::string(const std::string&amp;), which back in the day had some parsing fun issues.
Is it an issue to build the code with different (more modern) toolchain and then deploy it into the production environment with all of the needed dependencies?
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a5obru/recommendations_on_source_code_samples_for/ebqig60/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a56puy/is_codeblocks_any_good_late_2018/ebqigzm/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Wtf? Are you kidding?
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/a5zu9m/cse_college_courses/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I thought it was shut down by one of the Boost main contributors or something. I remember seeing the discussion here in some thread about build-system not that long ago (maybe summer?).
Nice that Ms is embracing C++. Not exactly on topic, but I just got back into developing for Windows and noticed that the single-threaded CRT is gone. From MSDN: &gt; The performance of the multithreaded libraries has been improved and is close to the performance of the now-eliminated single-threaded libraries. /u/stl any idea if there's some secret dev switch to not spawn 3 threads for a hello world app in modern MSVC?
I just checked, and plain programs don't spawn extra threads. (Our `std::thread` behaves in an unusual manner if you construct one, though.)
Could you go a bit further and explain why it's "vastly better and safer than using public or nonpublic inheritance" ? There have been multiple occasions I've wanted to extend the STL containers a bit but decided against it because I didn't feel like doing the work/investigation to make it work smoothly. Intuitively, it felt like the STL containers were not built to be inherited from / extended. I don't remember why, I just remember looking at the problem and deciding it wasn't a 30-60m thing and decided to just work around it at the time. But, I've always liked the ability to extend objects in other languages, I know if I really wanted too, I could extend STL objects but to see that it's recommended against, well I'd love to hear the reasoning behind it.
This looks good. Are you still looking for candidates?
[removed]
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/a5hicf/dont_inherit_from_standard_types/ebqq9u2/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I applied a while ago. Never got any sort of response. 
&gt;When we use auto, we're hiding our intention from the compiler Sure. But no different from `typename` . &gt;and permitting anything to work. Demonstrably not true. Just as `typename` doesn't permit anything to work, neither does `auto` . Type checking still happens at compile time for both those cases. They both may produce surprises from time to time, but that's far from anything.
ooch you’re going about it the hard way. Most games have an engine that stays loaded and all the map/level info is stored as configuration and state data. If you are stuck with this approach you will need to build the loadable cpp files into dynamic libraries (.dll in windows, .so in linux) so that you can load and unload them on demand. 
I will most likely just keep the data loaded. I was looking at it and if I do it right it shouldn't take up much memory at all. Though I still will look into dll files. Thank you
nice
The irony with the first inline function example is if he had used a macro instead of a function it would have worked fine. So while macros are the source of all this evil, they can also avoid it.
Use that only if your rooms can't be generic enough to be stored into a different descriptive language that you would parse. Loading/unloading dlls works but it can make the resulting binaries much bigger. Also it's going to be extremely painful if you mess up the symbol exports, not to mention if you use Visual Studio you have to make one project per room. Cmake makes copy/pasting settings between targets much easier. You can make a template for your projects to use with VS though, and if you have many rooms I'd definitely look into that.
I believe the issue with this in C++ is the dependence on ordering for parsing - you can't even parse C++ without knowing all of the declarations that came before, i.e., int main() { blah * foo(baz); } will either declare `foo` as an uninitialized local variable of type `auto(baz) -&gt; blah*`, declare foo as a local variable of type `blah*` initialized with `baz`, or call `operator*(blah, foo(baz))`, depending on whether `blah` and `baz` are type names.
But why are you stuck with stock compilers if rhel has official support for more recent toolchains?
Could you elaborate what you mean by unusual?
I don't think I have heard of musel before.
I like the quotation marks around "designed". It immediately makes me think of `std::vector&lt;bool&gt;` - which seems to be mostly about showing off new C++ features. (New at the time; not new now.)
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a610dt/import_from_a_variable_new_to_c/ebr3kqn/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a610dt/import_from_a_variable_new_to_c/ebr5saj/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I dunno, it seems like a logical default value to me. Just because calling it with 0 arguments doesn't make sense is no reason not to include logical default values. Also, you could do some shenanigans with std::bind to use e.g. only the second argument. 
Multithreaded library means it can handle multiple threads, not that it uses extra threads for no reason. 
https://stackoverflow.com/a/34826385 Maybe you are seeing these threads?
It's my favorite library, btw. ;)
For what it is worth: At least I agree with the Idea of not overcomplicating things for beginners (I haven't had a look at the actual material or the video though, so I can't speak for its quality).
You can change the domain to \`new.reddit.com\` to just quickly take a look at it in the redesign. Won't change your default.
The cited C++ Coding Standard book has several items on this topic. Preventing slicing and undefined polymorphic deletion (a `std::vector` doesn't have a `virtual` destructror) are some of the risks that you must be aware of. It can all be managed, but it requires much greater care not to fall victim to the pitfalls.
True, I'm no longer supporting it myself, using 16.04 as the minimum.
It sounds quite interesting, is this being used in production?
The short story is that it needs people to do the work for this to happen and so far it have progressed a little but it's far from being finished. I believe you will hear about the subject again next year.
&gt; If everyone takes your advice to heart, engineers will have a lot of fun writing all of the overloads for `emplace_back`, `push_back`, `begin`, and `end`. I did this. It's not fun!