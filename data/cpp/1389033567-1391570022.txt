Manual memory management in C++11 is really discouraged. If you don't have C++11, use boost - ptr_vector/shared_ptr are your friends. Also, for removing elements from a collection, std::remove/std::remove_if is far less error-prone than writing it manually. Unfortunately, unlike the name suggests, they don't remove the elements from the collection - they just move all the elements to be removed to the end of the collection.
It goes a very long way, and Qt is very pleasant to work with in my experience. I wish it could do without the MOC.
std::remove/std::remove_if do the part of finding the matching element/range to remove &amp; moving it to the end of the array.
Is there a solid date for the release on 3.4 yet? I'm really not looking forward to merging to my fork but I have big plans for the new `constexpr` rules...
Bizarre, I checked the release page and 3.4 wasn't listed, just refreshed it and there it is! Thanks!
If there were awards for the most important software project of the decade I'd vote for LLVM/Clang. It's amazing what these guys achieved in such short time.
as long as you don't inherit from QObject you don't need the MOC. And I guess most tasks without UI will be fine without QObject..., just replacing/simplifying parts of Boost.
May I suggest that you pre-allocate a bullet pool and add an 'in_use' flag to every entry. This will save you a fuckton of dynamic allocations and keep down memory fragmentation. 
What is the reason you are maintaining a fork?
Absolutely. Plus they really shook up the competition, too. gcc and even MSVC are better than ever, in my opinion largely because there is a very powerful contender on the market. 
Well, some facilities, like signals/slots, depend on MOC, even if they don't need to. I hear Qt 5 improves this, though, but I'm not familiar enough with it to comment.
This.
My company uses a proprietary 16-bit MCU, and I forked Clang/LLVM 3.2 over a year ago to bring them out of the ASM dark ages. I did my best to stick to just a custom target in LLVM's backend, but unfortunately there are too many assumptions in both the LLVM and Clang source that break my target, especially on high optimization settings. The issues *mostly* revolve around assuming a byte is 8-bits (my MCU does not have 8-bit instructions) I do not mean to speak ill of it though, and I have to applaud the guys at Clang/LLVM. We have a remarkably solid, production quality compiler from only a few months of solo, after-hours work for our target and its all possible because of them.
I wonder if it's just the first 5 chapters of the The C++ Programming Language (4th edition) which I already own in my library.
One almost "batteries included" is the /u/STL [nuwen c++ "distro"] (http://nuwen.net/mingw.html). (Which is great by the way, thanks STL!) In my opinion it would be nice to have a "C++ platform" a-la haskell platform. (For those that are not familiar, haskell has a 'best-libraries + ghc' bundle called haskell platform). For more tight-coupling/full-blow 'batteries included' there are several general-frameworks (QT, Juce, and Pocco comes to mind).
signal/slot in Qt5 is possible without MOC, using standard C++11 :)
LLVM did win the 2012 [ACM Software System Award](http://awards.acm.org/software_system/year.cfm). Previous winners include: - UNIX - TCP/IP - World-Wide-Web
Awesome! :)
`remove` and related algorithms do not change the size of the container they operate on. They simply rearrange the elements so that the desired elements are at the beginning. If you want to actually reduce the size of the container you then have to remove the extra elements at the end as a second step. One reason for this is that not all containers actually can have their size reduced. For example an array has a fixed size. 'erasing' elements from an array consists of updating some external counter and pretending elements at indices beyond that counter don't exist. const int capacity = 10; int foo[capacity] = {1, 2, 3, 4}; int size = 4; auto new_end = std::remove_if(foo, foo+size, is_odd); size = new_end - foo;
Damn. That's pretty respectable to be given the same award as the Internet and Unix.
Do gcc and MSVC care about market share? What benefits do they get from a larger share of the market?
std::auto_ptr is since C++11 deprecated.
Previous winners also include some shitty softwares... make, Eclipse, Java...
VC++ is sold for money. Bigger marketshare = more money. GCC is a FSF project, and furthering the FSF's goals requires that people actually use their software.
Thanks, that was very helpful!
Not primarily. More about ownership semantics, avoidance of blank pointers (especially owning ones) and stuff like that.
You are correct that raw pointers still have a place. This is not one of them.
No it wont. Unless they are really low impact (like auto original meaning or export templates) and/or really easily fixable (like literal to char* conversion). And rightly so. Backward compatibility is one of C++ greatest strengths. There is deprecation mechanism in the standard, but it does nothing apart from 'shaming' stuff.
You wouldn't want to learn to program from it, but I'd recommend it as a good crash course in C++ for experienced programmers coming from other languages.
&gt; ownership semantics What, exactly? That child widgets are owned by their parent widgets? &gt; blank pointers (especially owning ones) I'm not familiar with this term, is it the same as null pointers?
I tried that, but when I close the program, it says I've triggered a breakpoint, critical error at c0000374. This is my code for(unsigned int c = 0; c &lt; bullets.size(); c++) { if(bullets[c]-&gt;age &gt;= bullets[c]-&gt;range) { if(c != bullets.size() - 1) { Bullet* tmp = bullets[c]; bullets[c] = bullets[bullets.size()-1]; bullets[bullets.size()-1] = tmp; bullets.pop_back(); }else { bullets.pop_back(); } } }
&gt; It's an alternative. Not a replacement. That's the case now. But initially, I get the impression that it *was* intended to be a replacement. But I'm not certain
Actually, never mind, in my actual code I left out the else statement. It works beautifully, thank you very much. I really appreciate it.
Were concepts ever put into C++11y? I didn't see concepts listed on a quick search
I want a port of Python's argparse library. Current solutions for building CLI is annoying me.
Alternatively, if order doesn't matter, replace std::remove or std::remove_if with [std::partition](http://en.cppreference.com/w/cpp/algorithm/partition).
No, concepts were briefly in a C++11 draft but were removed again before C++11 was released. C++1y (likely C++14) contains relatively minor improvements to C++11 - nothing on the order of concepts. There are efforts underway to get something like concepts into future versions of C++, and it's possible we might have them in C++17.
lame i'll try to make a push for concepts, that was one of the things i was looking forward to
I thought C++14 was going to have "concepts lite".
That doesn't necessarily mean much of anything. `strstream`'s been deprecated for 15 years.
That's always been aimed at C++17. Way too big for C++14.
I would tend to disagree... C++ was for all intents and purposes, abandoned by the standards committee for nearly 15 years if you don't put much value in 2003 corrigendum. Then you also have the degree of toolset compatibility over the same time period with most major compiler vendors refusing to compile code they once accepted as correct. And then there is the issue of writing code that is compilable with multiple versions of the same compiler, and then for the truly motivated, you can try to write code that will support multiple compilers and multiple versions of those compilers and for the really insane, you can try to support various implementations of the STL. Just as an example, if you look at the hoops libraries like Boost go through to make seamless support of multiple compilers work, you can easily see that C++ in practice is as far away from backwards compatible as the Earth is from Andromeda.
Great! Just lets see if Apple again takes years to update their shipped version...
No, concepts *lite* will (apparently) be in C++14. Concepts lite is like the original concepts, except: - no concept maps - no new syntax for defining concepts - no new scope and look-up issues Source: http://channel9.msdn.com/Events/GoingNative/2013/Opening-Keynote-Bjarne-Stroustrup At around ~58 minutes. [I believe GCC has it implemented](http://isocpp.org/blog/2013/02/concepts-lite-constraining-templates-with-predicates-andrew-sutton-bjarne-s), but it is not offiicaly within the standard. &gt;Concepts was a major feature planned for the C++11 standard, but it was eventually dropped due to concerns about both the description and implementability. Since the publication of C++11, people have been working on scaled-down versions of the concepts feature. One approach to concepts, known as Concepts Lite, has been prototyped in GCC and seems likely to be published as a Technical Specification around the time of the next standard. Source: http://gcc.gnu.org/projects/cxx1y.html 
I'll give you Eclipse and Java, but make is a very good program that very few people know how to use correctly.
I'm absolutely not a Make or build-system expert, at most an occasional user. However, FWIW, what I mostly expect from Make is to resolve the described DAG, and not much more.. and it seems to suck for that : http://gittup.org/tup/make_vs_tup.html , http://martine.github.io/ninja/manual.html#_comparison_to_make
http://llvm.org/Features.html lists one of the LLVM features: &gt; A profiling system similar to gprof. I'm having a hard time finding any information on this feature. Can anyone clue me in?
GCC definitely followed clang's lead on some stuff, and vice-versa too (clang adopted some GCC things). I don't see anything in either clang or GCC that benefited MSVC. MSVC still uses the same error messages, has barely improved in terms of warnings or other static analysis, honestly I'm not sure what MSVC may have improved upon as a result of either GCC or clang. Seems to be MSVC was scheduled to have its given features regardless of any other product.
&gt; C++ was for all intents and purposes, abandoned by the standards committee for nearly 15 years if you don't put much value in 2003 corrigendum. This is simply incorrect. C++11 was not developed instantaneously; it took most of a decade.
I also really want to know why Clang people don't even mention the concept features. At C++11, they at least marked as N/A for features they won't implement.
Would it make any sense something like C++11's async/future stuff? Just for people who cannot use C++11 due to compiler locking and such
I posted a [pretty table](http://blogs.msdn.com/b/vcblog/archive/2013/12/02/c-11-14-core-language-features-in-vs-2013-and-the-nov-2013-ctp.aspx) on VCBlog. &gt; Boss refuses to upgrade my VS2008, until full c++11 support is provided. That's completely irrational. 2008 is slow (no rvalue references!) and full of bugs that I've spent most of my career in VC fixing. 2013 isn't fully conformant, but it's way way way better.
TIL
Are any of those changes worth revealing to the LLVM/CLang community?
They aren't that bad. Further I wouldn't want Apple updating the development environment with every release of the LLVM suite. I'd rather see stable well tested developer tools. Having lived through early iOS SDK releases, I have no desire to work with a buggy set of development tools. 
If you only want to resolve the DAG then use ninja. Ninja is the logical step from stuff like CMake (extremely ugly language though) which autogenerates the build files. Make however is designed to be written manually. Which can be quite handy for certain tasks. Although it might not longer be the prime choice when your task is building a large C++ project. 
&gt; I'd rather see stable well tested developer tools. I haven't used the Apple LLVM stuff. But from my experience with their botched up GCC version I'd much rather see them updating to the latest released. Because just if their compiler is old and badly patched doesn't mean it's either stable or well tested.
you can use [boost.future](http://www.boost.org/doc/libs/1_55_0/doc/html/thread/synchronization.html#thread.synchronization.futures).
You might want to take a look at [Boost.program_options](http://www.boost.org/doc/libs/1_55_0/doc/html/program_options.html) if you haven't already.
Well, I was thinking too in people who found Boost to large. 
&gt; What, exactly? That child widgets are owned by their parent widgets? AFAIK they use a large amount of shared ownership which often implies bad design. &gt; I'm not familiar with this term, is it the same as null pointers? something like foo* ptr; instead of std::unique_ptr&lt;foo&gt; ptr1; std::shared_ptr&lt;foo&gt; ptr2; 
silverlight itself was built with C++, so I don't think the language is the problem here.
Woah, that guy is mad.
I know, stable releases are fundamental. I just waited eagerly for C++11 support when XCode5 still wasn't released, it felt like an entirety. 
I've looked at QT, I know that it includes most of this and is probably the most complete out there, but it always seemed to have the feeling of being a C++ based DSL to me. Mostly that was around the MOC extension stuff it uses and now they've added yet another extension in the form of QML (though this one is more optional). I'm not arguing that what that provides isn't well designed or powerful, its just that it feels off to me. But I should probably give the latest version a second look since it really is the closest to a complete system. 
&gt; clang adopted some GCC things clang aims to be a drop-in replacement to gcc, they are implementing the same extensions. &gt; I'm not sure what MSVC may have improved upon as a result of either GCC or clang Some years ago it was the norm that compilers are incomplete and buggy. MSVC is now pushing hard to achieve standards compliance, a trait that was not something MS would have done otherwise. Why they are so slow about it, that is beyond me, but I'm quite sure if there weren't clearly better alternatives now, they would be nowhere near even their current level of standards compliance. (Their bullshit marketing still drives me nuts, e.g. when they claim they had full C++11 *standard library* support when they still don't support some language features that are needed for that).
&gt; AFAIK they use a large amount of shared ownership which often implies bad design. Not that I've seen, there's pretty clear singular ownership. &gt; something like &gt; foo* ptr; &gt; instead of &gt; std::unique_ptr&lt;foo&gt; ptr1; &gt; std::shared_ptr&lt;foo&gt; ptr2; Qt has had its own smart pointers for a while: https://blog.qt.digia.com/blog/2009/08/25/count-with-me-how-many-smart-pointer-classes-does-qt-have/
And for comparison, GCC is [very nearly there](http://gcc.gnu.org/projects/cxx1y.html) as well. They're still missing some features but looking at the list, most of the interesting things for me are already there.
&gt; I've looked at QT, I know that it includes most of this and is probably the most complete out there, but it always seemed to have the feeling of being a C++ based DSL to me. I don't feel like this at all. You can write just normal C++ with it, with c++11 you don't even need the moc for signals and slots, apparently. And the moc stuff is just that, extensions (or additions), the rest is still plain old c++. &gt; yet another extension in the form of QML (though this one is more optional) QML is a completely other beast, and it is as you say, completely optional, "normal" widgets haven't gone away. Though the more use QML the more I like it, even if it requires a significant shift from when I write the c++ part of my application.
I do that on my shoot'em up: for(size_t i = 0; i &lt; bullets.size();) { Bullet* bullet = bullets[i]; if(!bullet-&gt;update()) // Update returns false if Bullet is dead { delete bullet; bullets[i] = bullets[bullets.size() - 1]; bullets.pop_back(); } else { ++ i; } } You need to increase the index (i in my example) only when current bullet has succesfully updated itself. Otherwise we delete the current one, get another one from the last element of Bullets and remove one element (the last one) from vector, as it has been copied. Edit: oops I see now others already answered that question, my fault.
The place that GCC is lagging behind is (IMHO) library support. 
heh, I wish everyones name was equivalent to the project they are working on, "steedee" would fit perfectly :)
Apple regularly ships versions of clang which are *newer* than the official stable release.
Perhaps you should give [this](https://github.com/axilmar/parserlib) a try.
Before the release of Xcode5 it was not possible to use all C++11 features with the Apple clang version available. The only solution was compiling and installing clang from the source yourself. I don't know how that would have been if I were enrolled in the charged developer program as I am now (so having access to betas), but no, official C++11 support came a long time after clang had it stably implemented.
Potentially! I will keep that in mind when doing my merge to 3.4 and keep track of changes that are noteworthy. A lot of it are silly hacks to just get the thing going on my target without exploding, but maybe even sharing *what* I needed to hack is worthwhile.
I was using c++11 with the clang from Xcode long before 5 came out. 4.6's wasn't quite feature complete, but it was very close. The only particularly notable change WRT C++11 in Xcode 5 was that the default C++ standard library was switched from libstdc++ 4.2 (which doesn't have any C++11 stuff) to libc++, but using libc++ before that did not require compiling it yourself.
Looks interesting. My main issue is LGPL license. The LGPL does not interact well with C++ templates. I think having the LGPL will cause a lot of people to not use it who otherwise might. Would request that you consider Boost License or similar.
What's your go to resource for learning how to use make correctly? I'm more of a tup fan myself, but given how philosophically different it is from make I'm curious to know if there are good uses of make that I'm not aware of.
No matter how far programming advances there will always be one truth: We really should have made X a library.
Do you mean Express/Professional/Premium/Ultimate editions? All compiler/library features are available in Express.
&gt; when they claim they had full C++11 standard library support when they still don't support some language features that are needed for that I have never claimed that (and I am the authority here, being Microsoft's C++ Standard Library maintainer). I speak very precisely, and I always mention the compiler feature caveat. [For example,](http://blogs.msdn.com/b/vcblog/archive/2011/09/12/10209291.aspx) "In VC11, we intend to completely support the C++11 Standard Library, modulo not-yet-implemented compiler features. (Additionally, VC11 won't completely implement the C99 Standard Library, which has been incorporated by reference into the C++11 Standard Library. Note that VC10 and VC11 already have &lt;stdint.h&gt;.)" If MSDN or somewhere else is claiming "full library support" without any qualifications, let me know and I'll rattle some cages.
If stringbuf::setbuf wasn't optional, there would have been a replacement for strstream already... (that, or boost::iostreams::array)
Its a tad invasive, but you can inherit from a counter class that will keep tabs on the number of instances via a static member and constructor/destructor. Of course you have to use CRTP pattern to ensure the counter object is unique per object.
But TCP/IP seems pretty close to Internet.
Thank you for pointing this out. I understand that there will be some difficulties for some people to use the existing license. But the nature of this library is it is not intrusive to the user class model. One can easily wrap it to a module and expose a clean defined interface to interact with this library even with template. I will provide more information on how to do this in the web page. I would be also interested know what is the feature that most interested you and also what do you think is lacking?
there is Xlib, X has a very basic libs for drawing shapes and basic toolkit widgets. It suck so no modern apps use it and is the reason why Qt and GTK exist for the most part. 
Those 21 days books maybe useful to experienced programmers who is already understanding all the concepts used in C++ from other languages. But it doesn't mean even those people really can finish it in 21 days.
The manual is surprisingly helpful for everything except learning how to do automatic dependency generation correctly.
Try to buy a 1998 Buick LeSabre new from the factory, and see how far you get. :-&gt;
OK, so here's my updated list of well-known and well-respected C++ people on reddit: * [andralex](http://www.reddit.com/user/andralex) = Andrei Alexandrescu * [sdeetee](http://www.reddit.com/user/sdeetee) = Stefanus Du Toit * [STL](http://www.reddit.com/user/STL) = Stephan T. Lavavej * [WalterBright](http://www.reddit.com/user/WalterBright) = Walter Bright I know I've seen others around here, but I forgot their handles. Can anyone help fill in the list?
Ok, I'll keep that in mind
Are you replying to me? Your comment doesn't really seem to be relevant to my points. 
The version still didn't have full C++11 support (emphasis on full support) while the "official" clang had. I personally missed some features that weren't accessible; I don't just try to rant here, I actually am pretty pleased with my OSX setup, that was just one thing that I had a problem with.
The frustration users felt about how long the new standard took to be released was also felt by members of the committee. It was a long hard decade and we owe a lot to members who worked so hard for so long. Thank you!
I think the confusion here might be that Bjarne refers to Concepts Lite as a C++14 Technical Report (at about an hour into his talk). Being a TR means that it is *not* (yet) part of the Standard. Calling it a "C++14 Technical Report" may be misleading. I think what he means is that it is a Technical Report that will be released in the C++14 time-frame so that it can be considered for the next release of the standard (C++17).
You know, ZMeson, if people just used their real names this mapping wouldn't be necessary. I mean I can guess who WalterBright is and I was able to guess who STL was, (but I wasn't certain until I saw him write a code example with cats in it--then I knew without a doubt).
You'd think that would help, but people still ignore usernames. Here's an example of someone basically telling Walter Bright that he doesn't know what metaprogramming is http://www.reddit.com/r/cpp/comments/yid69/does_anyone_else_prefer_older_c_code_19982003/c5vzw7x?context=2
It doesn't really seem to do that much again - and then it costs money. Seems like a waste.
Oh the horror, Apple's clang release was slightly behind for three months after four months of being slightly ahead. Definitely cause for whining about how slow they are to ship updates!
Perhaps. But I'm not in control of what others do. As for me... well, I'm concerned that what I write will not always be popular inside the company that employs me, so I prefer to stay anonymous most of the time. I do have another account with my real name, but (a) I'm not smart enough to write ground-shaking or insightful things and (b) I'm not well-known or well-respected enough for people to really care about my opinion.
[I'm using a simple, application specific 16-bit MCU](http://www.elevenengineering.com/products/chips/XInC2.php), not really a capable CPU. What are you looking for exactly? I worked from a lot of resources in the DCPU16 community, which is actually just a theoretical processor for a video game: [DCPU16 Specification](http://pastebin.com/raw.php?i=Q4JvQvnM) [DCPU16 LLVM](https://github.com/llvm-dcpu16/llvm-dcpu16) [DCPU16 Clang](https://github.com/llvm-dcpu16/clang) Note that the Clang/LLVM repos are pretty out of date, and are a bit buggy. My work is a fork off of these.
I think that erase/remove is a good direction. You can also try another path: auto pivot = std::partition(begin(bullets), end(bullets), IsInactive()); std::for_each(pivot, end(bullets), BulletDeleter()); bullets.erase(pivot, end(bullets)); The `partition` algorithm will reorganize (probably using cheap swaps) the collection so that the elements from begin to one before pibvot are active, and the elements from pivot to one before end are inactive. Then with foreach you will perform a predictable serie of dectructor calls. Finally you actually remove what's left from once pointers. The last step may in theory be cheaper with a resize call, but it is also possible that STL is optimized for the deletions of the vector's "tail". Note: you have to provide the IsActive functor using one of the methods given in other answers. Also you will need a deleter, but actually c++11 STL has a default solution i.e. default_delete&lt;T&gt; that can be used here.
Cool. Remember that sometimes doing the if test is more expensive then what's inside it. Copying the last element over itself occasionally maybe be less expensive than testing for it all the time. Also you don't need to copy the value you are going to pop into tmp since you're going to throw it away. Just do the copy: if(bullets[c]-&gt;age &gt;= bullets[c]-&gt;range) { bullets[c] = bullets.last(); bullets.pop_back(); }
Very odd issue, looks like a bug in GCC. Saying "use emplace_back" isn't a solution; in this case the performance should be equal (since they're both compiled with -O3).
Since std::vector&lt;Item&gt; is completely defined within this file, I don't see how that's "case closed". This repro clearly illustrates a missing optimization in the compiler (that just happens to be done by the LTO). ie. It's an optimization that should be done by the compiler, not the linker. I agree you should always have LTO on, but this is still clearly a bug.
Registered, flights and hotel reserved. :) Sadly I won't be able to present this year though.
Not sure about the feasibility of the current most upvoted answer - isn't lto horrifically slow? I know the "whole program optimization" option available in visual studio is basically unusable with large C++ projects.
I don't like Boost.program_options. The API is too complex for such simple thing. I want to build CLI in more simple and elegant way. :)
Ok, thanks a lot, didn't know you could do that
Those are the moments I cherish the most.
This is a C++ group. Unless it's a POD, the layout of a C++ struct/class is mostly unspecified. There is also a great many things that compilers (C only also) do with data layout outside the confines of structs.
For C++ (if you have a C++11-compliant compiler), use [raw strings](http://en.cppreference.com/w/cpp/language/string_literal) if there's a large number of escape-needing characters..
That open source projects tend towards terrible documentation and for some reason build automation tools are particularly bad. CMake's (which I love to death) only real "tutorial style" documentation is a big expensive book.
I don't know of any C++ compiler either. I was saying C because there are many more C compilers than C++ compilers in which to do crazy things. Yes, the layout of non-standard-layout types is not specified by C++. However it is specified by the ABI of the system. I can guarantee you that both gcc and clang do not change the data layout of types that cross function boundaries. The closest thing to this that compilers do is [scalar replacement of aggregates](https://llvm.org/svn/llvm-project/llvm/trunk/lib/Transforms/Scalar/SROA.cpp) which is not an interprocedural optimization and not really a data layout change in the sense of the original article. What data layout optimizations are you referring to?
With such a simple struct would there be a difference if the test item would be a class with a defined move constructor? or simply define one in the struct or because the members are scalar will a simple one be generated at compile time?
Why not just put it under the boost license? That seems to be suitably permissive to allow it be used from commercial and non commercial applications.
Will the presentations be on github like last time?
STL *is* my True Name - I'm lucky to have gotten it on reddit.
C++ has been out for 30+ years and relatively few people know how to use it correctly (although that fraction is much greater than for make).
I'm sorry, but I'm going to have to put my STL maintainer hat on, and say that this is a terrible idea. The problem is that `partition()` is non-stable, so it'll jumble up your "good" elements (and the "bad" elements). In contrast, `remove()` and `remove_if()` preserve the order of the "good" elements. (The rest of the range is left in an unspecified but valid state; it does not necessarily permute the range, and typically will not.) `stable_partition()` is stable (and more expensive), but this is a solution to a problem you shouldn't have. That is, having to run a "BulletDeleter" before erasing an element is an anti-pattern, because anything that throws an exception will destroy the vector without running such a functor on its elements. This is the same reason why vectors of owning-raw-pointers are thoughtcrime. Elements should manage their own resources via destructors, after which you can simply erase them and be done with it.
Kranar is correct for erasing a single element in constant time (and jumbling up the remaining elements; I have never seen this scenario in practice, but it does make sense). remove()/remove_if() are linear-time scans and (combined with erase()) they are the correct way to cleanse a vector of all undesired elements.
&gt; i = bullets.erase(i); No! No *no* **no** *NO* **NO**!!! You've written a quadratic-time algorithm. Every single-element erasure has to move all of the following elements one slot closer to the front. The correct thing to do is (1) use unique_ptr or shared_ptr and (2) use erase-remove_if which is linear time.
It's hard to call this a bug, more a missed optimization opportunity for this very specific scenario. Function inlining is an an optimization that is by no means mandatory and depends on various heuristics as well as a balance of factors such as whether inlining would be at odds with code bloat, instruction cache misses, etc etc... Sure maybe in this case more permissive inlining would result in faster code, but there's no general solution to the problem of when to inline code or when to avoid doing so. Clearly if you explicitly tell the compiler to aggressively inline then it will carry out the optimization.
It's pretty freaking slow yes, I actually have three build types, one for debug, one for general release with the default set of optimizations, and then one with full blown optimizations enabled. The difference in compilation times between configs can be literally a factor of 2-3x.
Move constructor makes no difference in this case; it can only provide a performance improvement when the copy constructor does something expensive (usually calling malloc and copying a bunch of values that are about to be free'd by the destructor). For types with trivial destructors correct move construction and copy construction are equivalent, unless the user has created them and is using them to do something highly unorthodox.
It'll add padding for one. Can't think of one that will not. Every compiler I know will also rearrange the vtable at the slightest whim. Also, keep in mind that my reply is not at the top level. Make sure you pay attention to the post to which I replied.
Yes. I don't see why it will be different this year.
I would really like to see that in some near future :)
Seems they changed their policy. Its free to download now.
Looks great! My first thought was that I will extend my mini reflection tool (https://github.com/hun-nemethpeter/cpp-reflector-mini) with this a remote interface definition file generator option. So that boilerplate code can be auto-generated. Mysecond was this thread about async/await implementation https://groups.google.com/a/isocpp.org/forum/#!topic/std-proposals/5YT_bMfXLIM
Yes, this is standard behavior: overload resolution is considered before access restrictions hence the error.
This seems totally normal and expected to me. You are saying that the result is "const Unit &amp; unit", which is const. So it should be calling the const version. But it can't know that. You could be trying to call the non-const version of the function, but then promise yourself that you will not be modifying the result. What you need to do is call the function on a const GameState. Notice you declared your GameState to be non-const. That's why it is trying to call the non-const version. If you instead declared a const GameState it would work as expected. Essentially, it is doing exactly what you are telling it to do: Call a non-const member function because your object is non-const. The way you were able to get it to work is by making a const version of your object, and then calling the function. Does this make sense?
The rationale is that changing the access control on something should not affect the behavior of the program, beyond it compiling or not. (This is not quite true anymore in C++11 but the subtleties are relevant only to experts who want it that way.)
I understand this logic and read it from the spec In my mind I just assumed that you would want a const function to be called if it was 'legal', and if not to see if the non-const version could be called. 
Why would you ever want a private `getUnit()` member function in the first place? Code internal to the class should access the unit directly from whatever data member it's stored in, hopefully a vector. There is no reason for internal calls to go through a getter that looks like `return units[index]`. That's cargo cult programming.
PLY seems to derive most of its simplicity from being stringly typed – the grammar is actually defined in docstrings, not in checked code, which makes it inherently harder to work with (e.g. to debug). Boost.Spirit uses static type checking by hoisting the grammar *inside* C++ code. This makes a few things complicated since we’re now constrained by C++ language rules but it’s also a huge boon because you get C++ type checking and compile-time resolution of much of the grammar. Once you’ve grasped the basics of Spirit, this makes it *easier* to work with it for many applications. Boost.Spirit is also strictly more powerful than PLY since it’s not constrained by a LALR(1) parser (it uses the more modern PEG instead).
Internal getters also allow you to change the data structures used for storing information easily. They additionally reduce code duplication when retrieval is even slightly non-trivial. **EDIT**: Even stuff like `return data[index+UNITS_OFFSET]` can go terribly wrong when you duplicate it numerous times.
I tend to name my public nonconst-getters something like "mutableWidget()". It circumvents this and a handful of other quirky behaviors and also makes it clear to people who read the source code what is going on. But I try not to give out non-const references to managed data structures if I can prevent it. IMHO the owning object should be responsible for manipulations - even if this means writing some boiler plate code.
As already explained, the problem is overload resolution before constness. You have the same problems with templates, where type deduction doesn't happen for returning argument types. A solution for this problem would be a const interface to the Unit type, or returning the type by value.
Don't exaggerate. I never whined about this. I made a slightly sarcastic statement about late updates based on personal experience and after that just reasonably answered your comments. 
A few years late for C++. We have string literals now.
The people below me have explained why, but typically I do this when the internal storage is non-trivial. There is a semi-complex data structure holding the units which allows for some nice constant running times over certain operations (which are specific to my application). Also, you can add very nice debugging or profiling features to your get() methods which would be very tedious to add if you didn't have them. For example, you can trivially count the number of times you accessed a unit by just adding an increment within the get() function. Also, 
[Read this Twitter discussion for starters](https://twitter.com/migueldeicaza/status/325321487592599555). I think that qualifies as trolling. Or at least as being deliberately rude and not engaging with opponents’ arguments. Which is a shame, I had high respect for him before that episode.
Completely off the top of my head - principle of least surprise. Imagine it fell back to use the public const getUnit if access control prevented the use of the non-const version. If I make the calling function (class, whatever) a friend function or perhaps move the code into a member function of Unit, all of a sudden with the same code I'm calling a *different* function altogether. I imagine there are other cases where changes in access control can subtly change the behavior of existing code, which of course could cause difficult to track down bugs.
I would actually solve that using a friend function, with static scope limited to the cpp file that implements the class. Unless it is a virtual method, I think that having it outside the class to limit its scope would be a better solution.
The current license can be used in commercial application with some effort to wrap it as a module.
Sounds interesting. :)
To get to know this library, the examples are intuitive enough to get started. If you want to know more about the exact behavior, go for the documentation.
&gt; I agree you should always have LTO on I was wondering why it was not enabled by default, and digging through the man page for g++ I found this: Link-time optimization does not work well with generation of debugging information. Combining -flto with -g is currently experimental and expected to produce wrong results. In short, you can't make a debuggable program.
C++ generally never looks at the return type when resolving overloads — the context in which the function is called, i.e. how the return value is used, doesn't factor in. If it weren't, a number of currently valid cases would become ambiguous, such as when the return value of a function is used in parametric overload resolution. // If this were valid: int foo(); std::string foo(); // ... and you had this code: void bar(int); void bar(std::string); // Then which version of bar would be called? bar(foo()); In short, you have to choose sides when resolving overloads, and overloading on parameters is deemed to be by far the most useful thing to do. :) By the way, this is also what happens with `const` methods — a method has an implicit parameter `this`, whose type is either `T*` or `T const*`, as indicated by the method's `const`ness. So `const` overloads are not a special case any more than other methods.
I can understand the reluctance to add a separate compilation step, but at the basic level RMI is nothing more than turning some data into a wire-transportable format, sending it to another location and having that data reconstituted into a format appropriate for the receiver then acted on. Then the receiver does the reverse to send the data back. So the issue is to devise a serialization model of the data understandable on both ends. Been a while since I did any in-depth C++ coding, and nothing like remote calls, but what I see as being the big issue with a common library in C++ is that serialization step. In Java I can hand a Java object to a tool like XStream and because of the reflection capability, it can generated on the fly an XML or JSON representation for me for any Object. In C++ I don't see how you could do that with standard objects. It seems to imply you have to up-front define specific transport structures to use that you maybe map in/out of the C++ classes like with a ProtocolBuffer approach. Do the newest standards provide alternate approaches to having to define external data payload structures now? 
Saw license was GPL and stopped looking at it. Boost MPL has the permissive Boost License. Your license is GPL that requires every use of your library to be an open source application (and there is no way I will buy a commercial license for this library). With C++11 template metaprogramming, I would rather use Boost MPL or roll my own, than be dependent on an GPL licensed library.
Unfortunately it is GPL, this way it is not an alternative to Boost MPL.
C++ still lack of reflection capability to fully support automatic serialization. That's why we still need to manually specify the serialization data like in many of the current c++ serialization and reflection libraries. About your view on RMI, what you described is correct. Most of the time when working on client server application, we still spend much effort repeatedly in specifying the message structure for a call, serialization and wrap in to a class to feed our OOP model. This are all plumbing works for infrastructure. If a library can bring the abstraction up so that we can focus on out business model implementation, that will be a good start.
In case it hasn't been noted already, putting this code under GPL will stop many people - including me - from even considering it. 
Yeah I just checked the wrong option for the license in my IDE, and didn't realize it until now. Will fix that asap, I am sorry for that.
What is wrong with GPL? I don't know much about.
It is sticky. Which means that if you have a project under some other license (free or otherwise), you will have to re-release it under the GPL if you use this library. I like GPL for applications, but for libraries I tend to prefer a more permissive license. 
It is infectuous: very very roughly GPL demands that source code is available for free and any product that uses GPLed code is also available under GPL or a compatible license. The idea is that only participants of the "free" software movement should be able to benefit (or, to put it nicer: people are encouraged to participate, or else..). "Free" is in quotes here because it has a very specific meaning: giving the end user the freedom to modify the programs they run. The infectiousness is the main problem: If I use a GPL library n my application, I must release its source under the same (or compatible) terms. That's a big NO for any commercial development, for any development that contains trade secrets etc. That also means that I cannot even use other libraries that are not GPL compatible. 
Don't be sorry. I am happy to read a comment from you. I didn't think about throwing destructors which is indeed terrible, but isn't throwing from a destructor a terrible thing as well? On the other hand I disagree with the stability argument. I think that depending on the game objects' order in the collection is in general a bad idea. ...and so is storing game objects via pointers.
The problem with that idea is that a lot of the new features are restricted versions of old features, like references or smart pointers vs. pointers. When applicable, the restricted version should be used over the general version, but it's not a complete replacement. I think that some of the warnings given by the `-Weffc++` flag are related to old-style constructs, though.
Google has puplished tools that can automaticly refactor "old code" to "new code". http://channel9.msdn.com/Events/GoingNative/2013/The-Care-and-Feeding-of-C-s-Dragons
Have you used these tools? Could I reasonably expect my code to still work and do exactly the same thing? 
It is good if you are working on an open source project (with a compatible license), it is bad if you are developing a closed source application. The sticky behaviour is not bad in all situation, for example is one of the reason why GNU/Linux is more used than *BSD operating system; but for libraries even the GNU foundation is using LGPL to have them used by software that is using a different (even commercial) license but at the same time "protecting" the developer. By protecting I mean that with MIT and Apache license you can (essentially) take the work from an open source project and use it on your commercial application, without any positive feedback to the original project; on the contrary with LGPL you are forced to give changes back to the original project, enhancing it on the long term.
This is unfortunate. Even though a high level of optimization like -O3 already makes a program very difficult to debug, some debugging information is still useful. If -flto messes up the debug info completely then it's much less attractive to use.
I think I'm like a lot of other developers - 95%+ of my builds are non-optimized debug builds. I only do an optimized build when I'm testing for a release, and it's comparatively rare I do two in a row - only when I find an issue in release that doesn't occur in debug (which hasn't happened to me in, well, years now! How nice! ... because I learned from my mistakes I guess). Since a lot of what I'm working on is DSP, I also find that the non-optimized build "compensates" to a certain extent for the fact that the machine I'm developing on is a lot bigger and faster than the typical client machine. I get it so it's quite fast as a debug build, and then when I make the optimized build it blazes - and runs quite fast even on the slow, small client machines.
:( http://i.imgur.com/Z34NUWV.png
Yeah, it will follow the ABI for alignment and order. These aren't optimizations. The fact is that it's easy and effective for programmers to optimize the layout of data structures. Thus I disagree with the sentiment that: &gt; I know a whole lot more people who think they can outperform the compiler in optimizations and _data layout_ than I know people who actually can. /u/yodacallmesome is correct when he says that a compiler will not reorganize data structures.
Thanks for the feedback. I updated the oovcde-1401-2-win.zip so that it now contains a few mingw files.
&gt; `template&lt;int i&gt; using int_ = std::integral_constant&lt;int,i&gt;;` ...is a c++11 template alias (colloquially "template typedef") that makes `int_&lt;foo&gt;` the same type as `std::integral_constant&lt;int,foo&gt;` for any integer `foo`.
This is awesome! I was trying to develop a compile-time map the other day and then back-burnered it because it was too hard. How lucky!
GCC has -Wold-style-cast
What are the subtleties?
The only bug I encountered running clang-modernize on 60k lines of C++ was that it wanted to convert `auto_ptr` to `unique_ptr` in places where that wasn't possible (because they were for a `boost::ptr_vector`), but that manifested as compilation errors so it wasn't a big deal, and I haven't encountered any unexpected semantic changes from the transformation. One of the benefits of building tools on top of clang is that it's now much easier to build tools that are actually correct.
The llvm tool chain has a tool that does even more, with the correct options you can 'modernize' your code, it will change for loops, move operations and more
It wasn't (entirely) true in C++03 either, but the case is was also subtle and unlikely to change any real-world behavior. Exceptions can be caught by reference to any *public* base class. So changing the access control of a base class of a type used as an exception could change the behavior of the code at run time. I don't want to work on that code base. 
A template library is a bit unusual in that it's impossible to use it from a proprietary application and comply with even the LGPL. If that's your goal in choosing the license then that's fine, but if your goal is to get external contributions to your library then it's counterproductive. Only having some of the proprietary applications using your library contribute their changes to upstream is still more than you'll get if there are no proprietary users (I'm assuming open-source users will contribute either way).
On Windows, it can build itself if the test/trunk-oovcde-win project is opened in Oovcde, and the component settings are set under Build/Settings. For Linux, I think I still have to upgrade the trunk-oovcde-linux project to refer to CLang 3.4. Otherwise Eclipse is needed. 
So, this means that getUnit(); and getUnit() const; actually do different things under the hood, the difference is not just the const vs non-const on the return type? Easy to fix by using different names. Maybe change your private member to getUnitForEdit(); or something similar.
Is there a target or other build system that you need? 
nice!
In C++11 and beyond, Expression SFINAE is sensitive to access control (N3797 14.8.2 [temp.deduct]/8).
&gt; I didn't think about throwing destructors which is indeed terrible, but isn't throwing from a destructor a terrible thing as well? Throwing destructors are thoughtcrime (in particular, the STL forbids them), but I'm referring to anything that throws while a vector&lt;owning raw pointer&gt; is alive. &gt; On the other hand I disagree with the stability argument. Depends what the container is being used for - the order may or may not matter.
&gt; I'll give you Eclipse and Java On your website (http://nuwen.net/gcc.html#whynotjava) you write &gt; Java is a terrible programming language developed by incompetent programmers. It is not an undue exaggeration to say that everything Java does is wrong. There is nothing interesting that can be learned from Java, except how such an awful programming language can become so popular. […] I often wondered to what degree this is still your opinion?
I did not use them till now. I recomend (as allways for refactoring) using unit tests to ensure that nothing bad happens.
One benefit of doing frequent optimized builds, is that you are more likely to detect [undefined behavior that is present in your code](http://blog.regehr.org/archives/213). 
Great finale to an excellent series of blog posts! So, do you expect that Boost.Unordered and the various Standard Library implementers will follow your new scheme?
&gt; The author did not specify any ordering requirements. As a library developer, I think generically - not just about a specific situation, but about all possible situations in that area. Someone who learns how to eliminate elements from a vector is almost certainly going to use that technique in different contexts. &gt; the remove_if would have to move all the elements in the vector in order to preserve stableness. Sure, partition() is cheaper for that input. But look at my original objection - I said that jumbling up the preserved elements was undesirable, not anything about performance. partition() can easily be more expensive than remove(). For example, when your elements are POD, and are half bad followed by half good. partition() has to swap half of the range with the other half of the range, while remove() will simply overwrite the first half (POD moves don't modify the source). In any event, both are linear-time scans, so even without profiling I mentally classify them as having roughly similar performance.
I wrote that a million years ago (I really need to nuke about 90% of my website and rewrite the rest), but I still loathe Java.
The newest version of C++ will introduce the [[deprecated]] attribute to go further into maintainability, see : http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3394.html
Already done! Thank you.
&gt; Great finale to an excellent series of blog posts! I hope I will be able to publish soon a followup with measurements for libstdc++ and libc++. &gt; So, do you expect that Boost.Unordered and the various Standard Library implementers will follow your new scheme? I don't know. My intention has been to back up my design decisions in the somewhat underdocumented area of C++ unordered associative containers' data structures. Unlike other containers (std:list, std::set) with straightforward or de facto universal implementations, here each implementor has their own recipe: this ultimately tracks back to the (in my opinion) contentious resolution of [LWG issue #579](http://www.open-std.org/jtc1/sc22/wg21/docs/lwg-closed.html#579), so I hope the information provided on these posts can at least provide a framework for further discussion.
But to the average user who may not actively search for C++ news, the effect was that it was "finalized". Compare that to the progress of C# or even the slower moving Java.
I agree. The important takeaway as I see it is that the committee realizes that faster turnaround is important for the future success of the language.
Not at the moment. The class drawing analysis only requires that some include paths are set. It also recursively searches from specified root paths. The build system was intended to be as easy as possible. So it automatically finds source files in the project, and then in the Build Settings dialog, allows the user to specify if a directory is for a library or executable. Then it automatically finds the dependencies. It will currently work for many typical projects, but will not work for complex settings where the tools and settings are different for each component. If there are situations that are fairly common, I will add features for them. 
btw, which program do you use to make these nice colorful pics?
Why, PowerPoint and Excel.
http://i.imgur.com/VnOKbfK.png
If you had something like cmake to build it that would be awesome. Edit: Just to be clear. I want to be able to build oovcde, not have oovcde build things.
Have you tried this on any big projects yet?
Only about 1000 source files. I would imagine the drawing analysis should be able to handle fairly large projects. The build system only handles fairly simple types of configurations.
I checked in a bunch of CMake files, but since I am unfamiliar with CMake, it may take a bit longer to fix them.
&gt; generally never ;) I'm not sure if this counts, but type information seems to flow backwards in [this](http://ideone.com/5LO5ut) example.
I had to make a few modifications in order for it to compile. http://pastebin.com/tm2jqrjF
This looks really cool! I've not been working in C++ at home lately, and I have a feeling my work project is too large for it right now, so I'll have to spin up a pet project to play with it.
Now that the License is changed, have started looking more at it. What compilers are known to work with this library?
...and Glib::RefPtr https://developer.gnome.org/glibmm/2.38/classGlib_1_1RefPtr.html
It's not, and was never intended to be.
Failed assertions should result in the termination of the process. That's their point, if they fail, something is seriously wrong
thx, added to the list.
I believe a good overview of C++ smart pointers should include Loki::SmartPointer - the "uber" smart pointer that can be customized via policies. http://loki-lib.sourceforge.net/html/a00528.html 
I've seen it last night, but couldn't dive deep enough into it to actually make an educated guess, added to the list.
Well, I'd still bet good money on a memory leak. Have you checked? How?
I'm not sure how I should be really checking, but I open up the task manager to see the memory usage, and it doesn't seem to go up while my game is on
Thanks a lot. I will check them in and they will be in the next release.
Why do you insist on cleaning up the memory yourself? The OS does it very well and much more efficiently.
Yup, unless you are saving something, let the os worry about resource freeing.
Surprising ! Do you know the rule that allow this ? Is it only for templates ?
I have checked in the CMake changes made by klusark, but have not tested them. They will be in the next release.
people suggest exit, but also try _exit() - it does not perform any cleanup for you, and tends to be 'instant'.
I think so. I remember seeing something very similar in I think one of Going Native or one of STL's talks.
I did step through it. I know that my constructors are returning. I also noticed that when I don't call my renderHUD function, which just uses SDL_ttf to display text on the screen, it closes instantly. But I can't seem to find a memory leak or anything in that function 
&gt; Obviously something is wrong with his program. I'd don't think it's that obvious. Calling `free()` many many times can take a while.
One more small change needed that I missed. http://pastebin.com/PGHEUKjf I made an AUR package for you too https://aur.archlinux.org/packages/oovcde-svn/ Have you decided on a license? I couldn't find any information as to which one the code is under? 
Are you posting display events from a timer to get a constant frame rate? The events could be piling up and keep your main loop busy until they've been all processed. Maybe?
Not really. It is entirely feasible that the program is caching a boat load of textures for quick reuse. Calling free on every one of those textures at exit is a pointless exercise, you are doing in a slow fashion what the OS can do in the blink of an eye. There is absolutely no point in freeing up every byte of memory in a program that is exiting. The only thing you should worry about freeing up are things that won't be returned to the OS when the program exits (almost nothing falls into that category) and saving off anything you need (very rarely will this happen in the exit stage). Exiting an application should be instantaneous from a user's standpoint. If it isn't, you are likely doing something wrong.
If you are on linux, give Valgrind a look. That should point out your memory problems.
Hmm, sounds interesting, how do you recommend I do that?
If that's what it is, you could have a counter that you increment whenever you post a new timer event and decrement every time you handle one of the timer events. You can then check the counter before you post each timer event (if it's &gt;0, it means the main loop can't keep up and you might want to drop the frame by not posting another event).
While this is largely true, there are two problems: 1) This is terrible practise and will lead to memory leaks later when you change your code. 2) In the newer SDL we have SDL_Texture which is often optimised to use your GPU driver, so it stores the texture on the GPU. It's important to free stuff from the GPU, because not all drivers will clean up the leaked memory properly when the program closes. So again, bad practise really, and it could come back in the form of some difficult to find bug..
30 seconds? Are you serious????? How many frees can you do in 30 seconds? 
&gt; some might not even have threadsafe reference counting. std::shared_ptr is required to do this, and boost::shared_ptr also does it.
Thanks for all of the above. On the Sourceforge web site, I listed the license as GPLv2. 
Well, let me put it this way. Lets say there is some bug in the closing code where some non-obvious execution path takes a stupidly long period of time. If that happens only in the exiting situation, who cares? Why waste the debugging time and effort to discover a bug which only affects the program in the rare scenario of exiting? The solution of just dropping exit(0) and not caring is simple, it may mask a deeper issue, but if that issue never rears its head in regular gameplay I wouldn't waste my time trying to figure it out. Perhaps if the OP has nothing better to do or is trying to learn better debugging skills then the exercise might be worth it. For me, I wouldn't waste a day looking into something that won't move forward my release goal.
&gt; This is terrible practise and will lead to memory leaks later when you change your code That's not an argument. You can strive to work correct code and still not use the memory freeing part of it if the OS does a better job at it. You can have tests for the destructors that you don't use. The second point is a good one though, thank you.
I think you should also add a license file in the repository to make it really clear what license it is under.
It's going to be a lot harder to find memory leaks if you intentionally don't free your resources.
yes, the standard and boost are threadsafe, but there are a lot of other implementations of this idiom. Not sure how its about Poco and others. Qt probably yes, wxWidgets not sure.
&gt; If that happens only in the exiting situation, who cares? It's happening only while exiting *now*. Also, if it takes longer to exit the longer the program is running, that implies that while the game is being played, it's wasting time and memory building up *something* that's getting worked over before exit.
The answer is "already happened": "export" was removed entirely from the standard.
[From the peanut gallery] I find some of the comments here disconcerting, to say the least. There's the topic at hand - Miguel de Icaza's distaste for C++ (well, the real topic is understanding what's wrong with C++ and why some people - who program/programmed in C++ - dislike it) - and there's the person - Miguel de Icaza. Distaste for something generally results from experience in practice, in the real, with the offending thing. What's actually behind Miguel's (and many, many others') dislike for C++? What happened to them while using the language and toolset/environment that formed their level of dissatisfaction with C++ over the years? The topic of this linked-to blog post doesn't really answer any of these questions. The topic of Miguel de Icaza the person needs to start with: Miguel is a brilliant programmer and his incredibly hard work has helped push the boundaries of open source software in the real and to democratize a decidedly platform-specific (and popular) programming language (C#) and environment (.NET), bringing Windows technology to iOS and Android and, ultimately, back to Windows in the form of apps. For those attacking the person, better to attack the _problems_ behind the person's clear dislike for C++. So, what are the answers? Well, what are the questions? Let's start there. Why do some (many) experienced C developers dislike C++? What's wrong with classes, polymorphism and generic facilities (yes, templates are not perfect, but template-based generics is a powerful feature of the language. High level machine abstraction without compromising execution performance is a property of C++ - one it's supposed to _guarantee_)? In the spirit of building knowledge out of the positive experiences we have with C++, why not start a thread about what's _good_ about C++ -&gt; then the good and bad become clearer, in plain sight, for all to see (including programmers who have never programmed in C++...). The linked-to post points out missing C++11 features in Moonlight's implementation as part of it's argument that Moonlight doesn't really employ C++, so what could Miguel have been talking about? I find that a weak premise to base an argument. C++11 is C++, of course, but it's C++11. C with classes and some amount of C++98 is how Windows is largely using C++, how Office is largely using C++, how the CLR and JIT employ C++... Does this mean that these technologies don't really employ C++ because they don't use modern idiomatic C++ features? That's not the question. Why do people hate C++? That's a different - and more interesting - problem (for C++).
Debug assertion failed means they tried with a debug build with a debug CRT, and yeah, if the debug CRT of ms asserts, code is in UB land (meaning "crashed").
That is way too misleading. Both the standard assert and ASSERT inform you of an assertion, and only in debug builds (if you define /_DEBUG and do not define NDEBUG). In other words, in release builds, the two are **the same**. In debug builds, however, ASSERT will display the "problem! Continue?" dialog, whose **only** use is some further debugging when you guess that you can ignore. Tl;dr: the two are the same, don't muddle it up.
That's a fairly nice writeup. I'll nitpick. &gt;But shared pointers are only good in a few places. This is a fairly good advice, but somewhat poorly motivated later. 0. As said else-thread, chances are, shared pointers will be thread-safe (*as far as recounting is concerned*, they will not magically turn pointer into something thread-safe). In particular, standard and boost ones are (but for boost you can IIRC turn it off by playing with BOOST/_HAS/_THREADS). 1. People tend to over-use shared per to handle ownership. I understand that ownership isn't easy, but use of references and simpler smart pointer forms (typically unique/_ptr) go a long way. (which is why shared pointers are interesting less than people think, and TFA is correct!) 2. const and thread safety do interact, but it is somewhat misleading to say "use sharedptr&lt;const t&gt;" as if it answers all. If nothing else, an equivalent of const/_pointer/_cast of boost is there, and the usual pitfall of having a mutable object in one place, but passing a cons ref to it to a thread, applies. &gt;Interestingly this triggered far earlier in debug mode "Earlier" is the whole point of the debug mode. Debug mode of a good compiler/library, standard lib implementation included, is **purpose-made to be hostile** towards errors in code, find them sooner and chop your head off when it does 😉. Therefore, it is normal (not interesting).
I think you did not build your code in Release, but in Debug config (which is part of my point: both variants do the same in release, which is nothing).
I don't see that original point up here. The very first post doesn't know what "debug assertion failed" means, and nobody else said anything about a release/debug distinction before I came in.
Maybe it's my years of C++, but I actually understood all of those terms. What's worse, the implications are exactly as I expected. Well, I guess it's time to retire to management.
No explanation of how it works. Too bad. The 2x slowdown is also too bad, because quite a few programs, most importantly web browsers, really need this functionality on full time. Almost every web browser RCE is caused by this class of error.
I've implemented something similar before, using roughly the same technique. You can find it [here](https://github.com/Rapptz/sol). There are however, some cautions that the writer should be careful of. Such as the fact that function calls in parameters is unspecified order. So you have to push/pop in a specific left to right or right to left order using some more complex tricks than presented.
Oh no. You implemented left to right properly (one way, which is using recursion), however there are some cases if I recall where I had to do right to left, which I didn't see. The implementation is fine as-is. However, using an underscore and an uppercase letter is a reserved identifier, so I would change it.
It's a lowercase 'L' haha. But yea, if there's one thing I've learned from all the talks on exceptional c++ over the years, it's to not rely on single statement execution order being anything in particular.
I meant for `_Pop`.
ah good catch, I think I habitually prepend an underscore to all my private members and named it `_Pop` instead of `_pop` for some reason. Thanks I'll change it.
As I said, you can free them in you test program. You could even have `#ifdef DEBUG` around your memory freeing code.
Any one with the -std=c++11 switch that supports variadic templates. Most of them really (gcc, clang, latest visual studio)
Cool, but there's already [luabind](http://www.rasterbar.com/products/luabind.html) which has syntax more-or-less compatible with Boost.Python.
Also, there's squirrel as an alternative to Lua, made with C++ in mind. Has anybody used both Lua and Squirrel and feel like comparing?
Any compiler which supports constexpr (although you can probably work around this), variadic template and template aliases. AFAIK this means GCC-4.8, Clang-3.3,intel 13.0 and VS2013 (if you replace every `constexpr` stuff with old style enums).
It's a debugging tool and not meant for inclusion in release builds. Also they do explain how it works which is by replacing malloc and is similar to the way VC does it with similar performance.
&gt; No explanation of how it works. Too bad. From the _first page of the article_: &gt; [AddressSanitizerAlgorithm](https://code.google.com/p/address-sanitizer/wiki/AddressSanitizerAlgorithm) -- if you are curious how it works. And you wrote: &gt; The 2x slowdown is also too bad, because quite a few programs, most importantly web browsers, really need this functionality on full time. The "2x slowdown" is phenomenally good. It's really hard to see how you could do much better. Remember that it has to do validation _every time the processor uses an address_ - which is all the time! And that validation isn't cheap - it has to somehow figure out that this address is going somewhere it shouldn't. You're replacing many very common single instructions with dozens of instructions. I frankly have no idea how they do as well as they do. Reading that explanation, I see it comes partly at the cost of quite a lot more stack memory - which is in fact a lot more problem than CPU, because your average web program is limited by RAM and not CPU resources. You aren't going to get this checking for free - or even close to free. This is a pretty amazing tool, particularly as an open-source project you don't have to pay for.
The two projects have slightly different goals, as I understand it. Personally, I'm relatively new to Lua but think it's sort of ingenious how it's implemented (read the whitepaper). One big problem I have is that Squirrel is rather opaque about its implementation since its newer and authored by a single person. I have a harder time reasoning about its runtime characteristics than I do when I code in Lua.
While this has different goals than your project, you might also be interested in [LuaWrapper](https://bitbucket.org/alexames/luawrapper/src). It essentially lets you push and get and class you want to lua in a type safe way using templates, and the whole thing is &lt;700 lines of code in a header file that you can just drop in your project. Rather than re-imagine the C interface with C++ in mind, it just takes the existing C functions and makes generic templated ones so you can call functions like `luaW_push&lt;T&gt;(L, obj);` (and it also handles inheritance and the issues that go along with that too)
Why wouldn't we put value into the 2003 corrigendum? There was also TR1. Not to mention that a lot of the Committee's work in the intervening time, like concepts, will likely be introduced later.
You probably know this, but using a lowercase L as a variable name can quickly get confusing for readers.
Hi! Dev here. This is a bit of a pet project, but I haven't found very many light weight / easy to use libraries that fit this niche (I have project X that is embarassingly distributable / parallelizable but I don't want to deal with writing all of the code to distribute it). I'm aware that hadoop / gridgain might be considered as having similar functions, but to me those both feel heavy and a pain if you're not writing in java in the first place. Anyway, if something like this already exists, please point me to it. If not, cool. Either way, opinions welcome. I haven't made a C++ library in a long time, so please forgive me if there are any embarassing facts about the way it's laid out. Ease of use was my #1 goal.
He did, at least he mentioned template argument deduction in his [don't help the compiler](https://channel9.msdn.com/Events/GoingNative/2013/Don-t-Help-the-Compiler) talk (around 52:40-54:00). I knew I've seen it somewhere.
it would be nice if your `make` functions returned a `unique_ptr`
If I had found something like this some months ago, I probably would have tried it. I think the problem is that most task/message queues tend to get overly complex to accommodate general workflows. In my case, it's a mixed Windows/Linux environment with about 20 computers, and I found MPI a little finicky on Windows. My tasks are long (as in several seconds to minutes) and I ended up with a simpler setup using [beanstalk](http://kr.github.io/beanstalkd/), so it needs a lightweight server but the client/worker binary is stand-alone and I just keep it running on background. I do use Boost Serialization too and it really simplified the process. Since my home-baked solution worked in little time, I haven't put much more thought on it. I will probably revisit it in some months as I add different job types, so I would love to hear opinions on your approach too (and possible alternatives). By the way, I didn't see a license file in your repository. Remember to add it if it's not really there.
Curious why you called it a stream when it isn't really a stream by interface convention.
"I don't want a dependency" and "don't like how it works" is hand-waving IMO, care to expand?
Boost is a huge dependency. For many projects, requiring to link to boost is actually a deal-breaker. My last sentence hopefully expanded on what in particular I didn't like. In addition, I don't care much for the C style functional interface (somewhat nitpicky). In the end, I don't think it's a bad project, but it was a bit heavy for me and I felt I could produce a cleaner end result with a less code. 
The opacity of something is completely a personal preference. I don't like using anything unless I'm reasonably sure about how it works. Lua has been around for a while and comes with several very good publications detailing how it handles closures, coroutines, the stack, interop, etc. Squirrel is sort of lacking that and I simply haven't had time to investigate further. I have no idea how threads in Squirrel are implemented, and a number of other things. This isn't to say it's better or worse. Just that I don't know, which for me, is enough not to use it. Again, this is just me, but I'm sure I'll investigate it again later. I never write off any technology, but I always want to be an informed user.
&gt; What this is trying to say is that if you declare an inline function as dllimport, the compiler treats it just like a plain old inline function: it inlines the function based on the usual rules for inlining. Of which there are none. &gt; The Simple­Value constructor and the Simple­Value::get­Value method are exported inline functions! Consequently, any change to the constructor or to getValue requires a recompilation of all code that constructs a Simple­Value or calls the get­Value method. End update. This isn't a given. It is very often the case that "inlined" functions are not. This actually recently saved my ass. Someone had written this class in a DLL that was shared both by the program that I was maintainging and by a program written by another team. There were templated functions and inlines galore. However, our program and theirs have completely different release schedules -- not my design, don't ask me. So the other guys would not be recompiling based on the library changes that we absolutely needed to fulfill a feature set we had already claimed was done. Step in these guys 8 months later and they're finally trying to test theirs with our almost production version that had changes utterly incompatible with their build. I had to work out how to make those changes in a way that would not cause massive crashes and just plain not running. It was a nightmare to say the least. I was fucked if the compiler had chosen to inline the functions that are inline in the code. It would not have been possible. So I made the changes I needed to and tested...it worked. Nuclear disaster averted...but only because inline functions don't work how people think they do. In fact there are no predictions you can make about them at all unless you take their address, and it's only there you can say anything.
Well, maybe you want to take a look at HPX: http://stellar.cct.lsu.edu/2013/11/hpx-v0-9-7-released/
Well, i think he makes a point.
The Windows version of clang doesn't come with a standard library so you have to install something like Visual Studio Express.
Looks like an impressive analysis engine with the benefit over say System Architect being the generation of sequence diagrams without jumping through some compile hoops. Tried running Oovcde on windows with the two example projects. Class diagrams were as expected but sequence diagrams only show a single arrow, not as per your tutorial examples. I selected various operations that had several method calls but all just showed the top level call
Maybe I missed something, but what does this do that `std::function` and `boost::signals(2)` doesn't?
It's less flexible, but faster. The shown implementation won't handle free functions or lambdas, but at the same time, it doesn't pay for the virtual call needed to disambiguate between those.
TIL. My point stands, though. Boost.Function needs at least one additional function pointer call compared to the implementation linked here. 
It may have to do with the compile options under Edit/Preferences. I think I saw this problem when I didn't have the -std=c++11 switch set. At the moment, it may not update some of the temporary files when the compile options are changed. It is possible to delete the xmi directory, and the oovcde-incdeps.txt, and the oovcde-comps.txt files and try again. I will most likely be working on this problem for the next version. 
Libc++ is currently only supported on OS X. On Linux it's best to use libstdc++ (from GCC), and on Windows the platform libraries. 
It may have to do with the compile options under Edit/Preferences. I think I saw this problem when I didn't have the -std=c++11 switch set. At the moment, it may not update some of the temporary files when the compile options are changed. It is possible to delete the xmi directory, and the oovcde-incdeps.txt, and the oovcde-comps.txt files and try again. I will most likely be working on this problem for the next version. 
&gt; is_base_of you are right the implementation is by no means complete. The implementation we use at work is more sophisticated but makes it even harder to understand the concept. With this post my primary intention was to talk about a nice usecase for variadic templates which a delegate implementation is for sure. in my original delegate implementation I did not use variadic templates but write out the code by hand which get's pretty convoluted once you start adding argument type parameters. (the implementation without variadics is *a lot* longer then with variadics)
I got llvm/clang 3.4 compiled with mingw 4.8.1 using the STL of mingw/gcc. Clang compiles simple C++ programs, but as soon as there are streams involved the compiled program segfaults. 
what is this clang-cl?
I was doing exactly this (except more ugly) all through this week! Somehow I missed tuple_cat while implementing my equivalent of pop, so ended up solving argument evaluation order by unpacking some indices with the types. I'll probably try it myself soon, but do you think/know that the compiler can eliminate all the temporary tuples with tuple_cat? With my longer approach, the generated code is at least pretty efficient, invoking lua_toX with constant parameters, and constructing C++ types in a single large stack frame with no copying or moving. Definitely waiting to see how more elegantly you can implement binding C++ functions to lua. I ended up writing a glob of templates for unpacking a tuple and invoking a function with them, but it ended up messy. Seems to me that something like that ought to be in the standard library!
It's a command line replacement of cl.exe which is the Visual Studio C++ compiler. It's supports the same command line parameters so you can use it as a drop-in replacement.
You can't use the MingW files. You have to install either the Windows SDK or Visual Studio.
Template meta programming is getting cleaner with C++11; here's some experiments I tried.
I'm sorry, but what are the advantages to this over the well defined idioms of `type_traits`? Why would I use these type functions over their respective `type_trait` counterparts? 
~~I don't see the point, to be honest. What if your type isn't default-constructible, or isn't copyable? `type_traits` works effortlessly with such types, and in C++14 you get the nice `_t` syntax.~~ BTW, all your examples are strictly C++14, since you're using return type deduction.
so I have to use either of those? No other option currently?
yup, i think you just put it simpler than i had thought of it. in that case "normally" would just be "round to even", which is the default. but is there a function for that? i didnt see one in cmath that sounded like it'd do that, maybe i missed it
The Type&lt;&gt; wrapper is default-constructable and copyable regardless of the wrapped type. I'm not trying to replace type_traits; I'm looking for a simpler way to create metaprograms. Implementing type_trait-like functionality is a test case; if it couldn't do that then it'd be a dead end.
Mea culpa, you're right. With that out of the way it does look pretty interesting.
Don't sweat it. Have you figured out your problem?
This is interesting, and you can probably still support higher-order programming with it(which you can't with `concept bool`). Plus, it looks like it would play nicer with generic lambdas as well. However, I find this a whole lot cleaner: template&lt;class Cond&gt; using demoIf = if_&lt;Cond, int, double**&gt;; Even in C++03, its still cleaner: template&lt;class Cond&gt; struct demoIf : if_&lt;Cond, int, double**&gt; {}; than this: // demoIf's return type depends on Cond template&lt;class Cond&gt; auto demoIf(Cond c) { return if_(c, Type&lt;int&gt;{}, Type&lt;double**&gt;{}); } 
Gotcha, thanks.
Mingw 4.7 have changed the ABI. Clang 3.4 is compatible only with Mingw 4.6. To work with Mingw 4.7+, you have to compile clang from svn.
Yes, overly complex software is hard to justify anymore. There are often simpler alternatives that will take significantly less time to learn and work just as well. That's too bad to hear MPI is finicky on Windows - we're all linux so it works well. I appreciate the communication pathways existing from the start, and IPC is super fast. But it doesn't provide much for you other than that. I've looked at beanstalk, but mostly I want to get away from client &lt;-&gt; server for my purposes. Mostly it's nice to not have to set up a server. I like being lazy. MPI with job_stream lets me do that. Since I do my computations on a remote cluster, it's the best fit I can imagine. Is your code open source? I'd be interested in seeing it. Not sure what opinions you'd like on my approach, but so far it's ridiculously easy to use and gets the job done. Most of my needs for streaming / distributing are just checking if a monte carlo simulation is accurate enough yet, and if not, starting some new trials, maybe with tweaked parameters. Then gathering and processing results, and maybe sending those out to some visualization tools. YAML's great for configuration, and tying these different (small) pipelines together is a breeze. License added, thanks.
I'm not sure if this would work, but assuming you have a round-to-even func, you might be able to do: int roundToOdd(float f) { return roundToEven(f - 1) + 1; }
Thank you. While I couldn't get clang svn to compile, I found working binaries for mingw on the way: MSYS2
Use MSYS2 packages, they work out of the box.
msys 2 packages?
Yes, that part makes me cringe. I was able to keep it down to 1 macro, except for the asserts used in the test cases.
Even though they're not used at runtime, they still have to follow all the normal rules. Without the Type&lt;&gt; wrapper, all T would have to be default-constructable and copyable.
Generic lambdas should prove interesting if they work; I think I'll go try it.
I downloaded it, but can't find clang nor Qt libs. Are there additional packages available? 
5.1.2/2: &gt; ...A lambda-expression shall not appear in an unevaluated operand... ~~I'll have to pull the calls outside of the decltype() to make this work.~~
Well, have a look at the wiki http://sourceforge.net/p/msys2/wiki/MSYS2%20installation/. They explain how to get the necessary packages installed...
You just need to use `std::declval` or an equivalent (`Type` as shown in my example above). Basically, redefine `Type` as template&lt;typename T&gt; T Type(); and you can use it with `decltype` like so: decltype(whatever(Type&lt;T&gt;())) Slightly shorter than your `EXTRACT_TYPE` and won't chase away the people scared of macros :)
Seems cool, but the page/wiki lacks a lot of information...
So is this done by MSYS team or did they just hijack the name?
I like the shortening, so I'm gradually working through your ideas. These work: template&lt;class T&gt; Type&lt;T*&gt; ptr(Type&lt;T&gt;); template&lt;class T&gt; Type&lt;T&gt; removeCV(Type&lt;T&gt;); template&lt;class T&gt; Type&lt;T&gt; removeCV(Type&lt;const T&gt;); template&lt;class T&gt; Type&lt;T&gt; removeCV(Type&lt;volatile T&gt;); template&lt;class T&gt; Type&lt;T&gt; removeCV(Type&lt;const volatile T&gt;); I'm still trying your ideas for dropping Type&lt;&gt;.
Like always with open source: time versus money... 
Although i compile clang my self, i use MSYS2 here as well. That pacman thing is awsome!
MSYS2 seems really good. Though it seems the g++ is one third slower as my comparing mingw-builds toolchain. Since you also use it, do you get the compiled boost libraries linked in? That doesn't work for me. I get many "Cannot get section contents - auto-import exception" errors.
Ah yes.
I havn't had a time to look into as classes started today. Whats the difference between this and the msys thats supplied with minGW?
Well, about everything I guess... They provide a complete toolchain with packagemanager that works in many respects...
Just wanted to pop in and say that CPM now has caching. Implemented it yesterday and it ensures that you only have to download a repository once if you use a common caching directory. Thanks for the suggestion!
Superb news, thanks for the heads up and congrats!
I just found this. This seems legit : * http://sourceforge.net/mailarchive/message.php?msg_id=31326466 * http://www.mingw.org/wiki/MSYS2 Does anyone have more information ? 
Some package manager for libraries, making it easier to include and link libraries into a project. It took me 2 years to half confidently build and link boost into my projects and I still need to look up a guide to do it. But if I want to use a library for Ruby, it's just one line in the console to install it and I'm off.
eh, and I was there thinking that Sourceforge was dead...
My code is not open source right now, I hope to open at least some of the libraries by the end of the year after I finish my thesis (by March). The distribution of tasks though is very simple and not at all mature, but works for me. The relevant part of the slave processes goes like this: Beanstalkpp::Client bsClient("beanstalkserver"); bsClient.connect(); bsClient.watch("commands"); bsClient.use("results"); while (true) { // Wait for a new job Beanstalkpp::Job job = bsClient.reserve(); // Deserialize the job description from job.asString() using Boost Serialization //... // Process the job //... // Serialize the results //... // Send the results bsClient.put(resultStr); // Finally delete the job bsClient.del(job); } If I do stick with Beanstalk later on, I'll write a better client for it (using [Beanstalk++](https://github.com/thomas-burger/beanstalkpp) at the moment). I do like your approach, especially how simple it is to use it in the final program. 
No, this MSYS2 is totally unrelated to MinGW.org's MSYS2 effort (which was never finished anyway) 
I'm sure it will be fixed... when you buy Studio 2014 (!)
There was an L-R interaction fixed during 2013's development, but apparently another sneaked through. R is special because of C++11 raw string literals.
But AFAIK "L" is not C++11. So it's really just a string literal bug, not really having anything to do with C++11?
It helps that I have a bad habit of dumping everything in one directory, maybe throwing certain headers in 'include' if I'm feeling super tidy.
Yeah, L"" has been around since C++98. VC's preprocessor was fragile to begin with, and clearly something was further broken by raw string literals.
&gt; your build directory should live outside of the directory where your repository root is. Why?
I guess it has a different selection of libraries but is this any different from http://nuwen.net/ 's distribution which seems to work nicely?
For some news Zeecrowd now supports Qt 5.2 version. You need to download the client from the [website](http://www.zeecrowd.com) to benefit from it. Zeecrowd also integrates a new launcher that automaticaly updates the client when it detects a new version is available. The platform also installs the Qt framework. Meaning you can now develop Qt5.2 applications from the get-go. This new version of Zeecrowd allows for the development of applications in C++ (in addition to the ones in Qml) thanks to Qt plugin system. There's a tutorial available [here](http://www.zeecrowd.com/developers/tutorials) and there's also now a RSS flow on the developers part of the website. In the upcoming days we will often be updating the client and the store applications Indeed, Zeecrowd has been chosen as support for a school project. Zeecrowd brings a private and secure environement with a system of rights management for the members, inside the crowd but also inside the applications. Then, the students will be able to collaborate under the monitoring of the school's teachers for their project. We're still motivated to bring Zeecrowd for other platforms. The integration of TeamSpeak3 (eventually prefered to Mumble) is currently in study. Our internal applications, now on the store, will very soon be made available on github.
We've just created a subreddit for Zeecrowd, feel free to check it out : /r/Zeecrowd
My distro is a MinGW, which generates native Windows executables. MSYS is a Unix compatibility layer, which allows you to run configure scripts and things like that. They are totally different things.
Right, sorry. I saw MSYS and my brain read MinGW.
Not unless and until clang decisively supersedes mingw-w64. From what I've heard, clang isn't ready for prime time on Windows.
I thought of clang as an alternative/addition to gcc not mingw-w64, or is clang going to provide a complete Windows compile environment?
Even if the access is trivial, wrapping it in a private member function gives you an opportunity to apply a name to the action. This can help self document the code for anyone reading the code in the future. It's not *always* helpful, but it can be.
Why post that here, it's a pretty simple question? 
It was new for me, so I thought may be helpful for someone..
Thought you were trying to get more input about it here, nm.
Sorry i don't have boost installed at the moment.
Surely that came in form C?
because 2003 was more bug fix than anything and the end user wouldn't have really noticed much. TR1 was additions to the library, by then most people had been using boost or some other library to fill in the holes in the standard, and even then the C++ standard library has so many glaring holes compared to pretty much everything but C and assembly language. I would just challenge people to look at the evolution of a language like C# which has a good degree of backwards compatibility and is relatively easy to port to new versions, especially if you do that port with every new release where needed.
it wouldn't in this case, as it's just a more complicate way of assigning the leftmost/rightmost value to a variable. this is the same grammatical statement that allows for multiple statements in, say, a `for` loop, e.g: for(int a = 0, b = 10; a &lt; b; a++, b--) or more specifically, the `a++, b--` statement. essentially, the reason you can do this is due to the grammar definition that is intended for cases such as the one i described above (`for` loop), but has side effects that allow you to use it in an ambiguous and unnecessary manner such as in the OP.
Assuming bullets is vector&lt;Bullet*&gt;, and you want to delete a bullet at index [index]: vector&lt;Bullet*&gt;::iterator bulletPointerAtIndex = bullets.begin() + index; Bullet* temp = *bulletPointerAtIndex; bullets.erase(bulletPointerAtIndex); delete temp; This will first retrieve an iterator that points to the bullet at an index, erases the bullet from the vector, and finally kills the bullet. 
You'll never be an "advanced" programmer if you don't understand this stuff first.
I strongly disagree. Novices should start with high-level machinery and work their way down, not the other way around. vector and shared_ptr should be used long before new/delete.
Start by learning whatever language you want to learn, you don't need to learn them in any particular order. Java is fine for a first language. Good luck and have fun!
You might want to checkout /r/learnprogramming
First this is the wrong subreddit. Second what exactly do you want to achieve? Is this for fun? Is this for a potential career? Are you actually just interested in programming theory in general or do you want to see how to create an application? Also how much of the language do you want to learn? It takes a long time before someone actually has a really decent knowledge of a language, I'm talking years of consistent use.
Hmm, why would one downvote a link to a GotW (which isn't a repost)? I find all of them at least very instructive, and many of them are even documenting best practices.
People are probably downvoting this submission because it's the 'question' post, not the 'answer' one. Given that in a few days another post will be made containing the same stuff but with an instructive discussion from Herb in it, perhaps people are just trying to avoid getting this subreddit flooded
Reddit does not accurately display the number of downvotes a post has received, they always hover around a 3:1 ratio or so for every post.
This subreddit is in no danger of being flooded ;)
Apparently MSYS2 is a fork of the latest Cygwin with 64 bit support, but with changes to maintain the old MSYS behavior (MSYS 1 itself was a fork of an ancient Cygwin). The author/maintainer of the fork seems think the changes could be merged back into Cygwin ([link](http://permalink.gmane.org/gmane.comp.gnu.mingw.user/42292)): &gt; If you read mingw-w64 ML's you can see our hot discussion with Corinna about forking Cygwin. I think in near future all MSYS functionality will be added to Cygwin sources directly and we don't need anymore to create MSYS. From what I found [in a thread](https://www.mail-archive.com/mingw-w64-public@lists.sourceforge.net/msg07475.html) of the mailing list, it seems Corinna ([co-leader](http://cygwin.com/who.html) of the Cygwin project) believes that there is no need for the fork -- there could be a MSYS distribution based on unaltered Cygwin DLLs, but with different packages to suit the current MSYS needs. I hope that happens. 
From the mailing list, it's the the same effort listed in the official wiki (led by user Alexpux).
Thank you so much for this answer. Everyone was recommending smart pointers, but I knew there must be a way to do this without them. I really appreciate this, thanks again.
This does give me a breakpoint though... :( The last() function wasn't recognized, so I used back() instead, and then back() - 1, but those also gave me breakpoints.
That's true..... but still, it's better to have no posts at all, than irrelevant posts, even if it's only a few. That said, milliams is right, Herb's blog is awesome, but it should suffice to send in the answer only.
I find the use of `typeid` ghastly, for compile-time computations why don't you use `static_assert` instead ? template &lt;typename T&gt; constexpr bool is_same(Type&lt;T&gt;,Type&lt;T&gt;) { return true; } template &lt;typename T, typename U&gt; constexpr bool is_same(Type&lt;T&gt;,Type&lt;U&gt;) { return false; } static_assert(is_same(ptr(Type&lt;int&gt;{}), Type&lt;int*&gt;{}), "ptr did not work as expected!");
EDIT: (for civility) I disagree.
Hi thanks for your comments. I've actually already changed the implementation of the pop to use sequences on my own haha. The custom deleter seems like a good idea and eliminates some boilerplate for sure. However, I encountered a scenario where I actually needed to null out (lua_State *) in order of the propagation of the destruction to occur properly to child objects owned by lua_State. I'll have to chew on it. A new blog post is happening which is going to go over the tag dispatching you seem to already understand. I've seen the fake argument idiom and I actually use it elsewhere in the code right now. In the case of `Read`, I don't know that there is any advantage to using one approach over the other. To me, specialized templates seem simple/usable enough and easier to call for the user. Thanks for the comments!
I agree, it hasn't ever bothered me that much. But then, maybe I've just never worked on a project that takes long enough for it to matter :-P. The longest any of my projects has ever taken to compile is my current one which takes around 1 minute on my slowest development machine (mostly due to use of Boost Spirit). That would be pretty slow if I had to build that every time but that part of my project only gets changed very rarely so I hardly ever need to rebuild it.
How are you going to do that?
Regarding build speeds, here are two of my major points: 1) Project layout. When you have 30+ projects with 10-20 files each, it gets hard to figure out what to put in a stdafx.h, and what each header file should include (if anything), etc. I can go into a lot more detail here, but this has a big impact on build speeds, and it's not trivial to get it right 2) Templates. I used to try to do a lot of cool stuff with templates (state machines, generic programming, CRTP, etc.), but then had to rip it all out because of build speed issues. I was spending &gt; 30 minutes on a build, and that's when I decided to start using virtual functions and pimpl aggressively and cut that part of the build down very significantly. Something along the lines of this guy: http://www.cplusplus-soup.com/2012/09/cpp-netlib-http-api-plan-updates-part-i.html 
You forgot the "buy an SSD" option. Fundamentally, build times plummet with drive speed. So as I said in the quiz: I could be open to paying for build speed improvements if you're significantly cheaper than SSD [SSDs provide many other benefits, too]
Do you have any idea who you are talking to?
By question 6 it is clear you are making a product, link?
I've built a fair amount of internal frameworks which make heavy use of template meta programming. Changes which cause a lot of template recompiling take *forever* to rebuild.
I am working on a 5~6 MLoc project only gotten bigger since I started. We keep using aggressively optimizing compilers so builds should be slow, but with modern hardware from 3 years ago 45 minutes was a full build, now 3 minutes is. 
That really does make a huge difference. Easily the best investment for improving compile (and link) times.
Also see this thread on StackOverflow: http://stackoverflow.com/questions/15199356/speed-up-compile-time-with-ssd. SSDs helped me, mainly because we have a lot of pch files, and they can get big, but your mileage might vary.
http://imgs.xkcd.com/comics/compiling.png
[Original Source](http://xkcd.com/303/) **Title:** Compiling **Title-text:** 'Are you stealing those LCDs?' 'Yeah, but I'm doing it while my code compiles.' [Comic Explanation](http://www.explainxkcd.com/wiki/index.php?title=303#Explanation) **Stats:** This comic has been referenced 48 time(s), representing 0.53% of referenced xkcds. --- ^[Questions/Problems](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Website](http://xkcdref.info/statistics/)
Work out how long you spend sitting in any given year, around waiting for a compile; typically that's time literally impossible to use for anything else, because it's short enough to not warrant a task switch. Add on how long it takes your security folks to deal with a contamination [or whatever you need secure erase for] each time. Calculate how much that time is costing your company [don't forget to include overhead, etc; don't just work off your paycheck]. Divide that by number of times you need secure erase, each year. If that amount is higher than the cost of a new SSD, you have a compelling case: each time you need secure erase, the drive goes to the great drill press in the sky, and the company is still saving money.
Is this solely from using SSDs? If not, what else have you done?
Full disk encryption isn't enough in some cases, where I work. But as you say, a wood chipper is. I also have a paper somewhere describing what temperate is adequate if you want to take the autoclave route.
Wow, this blew up quickly! I have about 130 responses already, with quite a few people filling in the open questions. Thanks, everyone! This really puts 'small subreddit' into perspective. With regard to the question "What do you waste" most time on": I know due to my title, I've already pointed somewhat towards build times. However, I didn't want to lie and say it was a general survey. I'll try and compile a list of the most popular answers to this question, the list is pretty impressive!
I think it is important to note that a whole lot of the time a c++ compiler spends building c++ software is just reading and parsing header files, it is truly astonishing how much code can come in the form of includes. This along with the fact that the transitive nature of textual inclusion is enough to make me really pissed. I hope modules get into c++17
It seems to vary a lot. About 1/3 answered 4 or 5 (and a lot of those people filled in 'build times' as biggest waste). 10% answered 1 (basically: don't care at all), and most filled in 2 or 3.
I saw, thanks for the response :-) I don't have an SSD myself, but now I'm definitely considering buying one... Honestly, I don't know yet what the improvement can be, since I'm only at a very basic prototype right now. I wanted to see if people actually care about something like this before I go and spend another year on it ;-)
I've worked on projects where linking takes minute(s). That shit is irritating.
For a release build with link time code generation, then yes this can be painful. But that doesn't tend to be done as often, at least in my case.
It's be interesting to see the results, after the survey is completed of course.
For bigger projects, build times should be less than 10 minutes. I have worked on projects with 250k Loc build less than 10 Minutes, and on projects where 250k loc builds 50 minutes. If you have tasted quick build time once, you realize how crappy long builds are. 
That's what [IncludeWhatYouUse](http://code.google.com/p/include-what-you-use/) does.
My current favourite, Catch, is missing :(
Link time is painful for me and getting an SSD helped. It's still too long though :/ (about a minute, whereas I'd like it to be 5s at most.)
If you can use ccache you could even do a full rebuild without being overly bothered (even more so if you can put your all sources and/or the ccache database on a fast medium like SSD into RAM e.g. with tempfs). At that point what really is slow is parsing dependencies (e.g. thinking of recursive automake) for which there are solutions, or linking (but doesn't have to be an issue if you can use shared libraries and don't overlink).
I love gtest, it handles everything I throw at it wonderfully.
What you're missing is that raw speed isn't as important as random access times. You're not accessing 10 or 100MB of continuous memory, you're accessing dozens or hundreds of small files all around the disk, where, in most cases, your HDD's head has to physically move around. That's bound to take time.
Personally I am big fan of BOOST test, mainly because boost is pretty much always a dependency for my projects anyway.
The one I've enjoyed (but in my current role can't really use) is TUT http://mrzechonek.github.io/tut-framework/
Apply() should probably be called “operator()”.
It doesn't matter (+ appeal to authority). When someone suggests that someone use smart pointers and RAII before understanding how normal pointers work with malloc/free or new/delete they are wrong. Is someone suggesting they never learn this? Or that they go "oh I got this smart pointer/RAII stuff down pat, time to switch to bare pointers everywhere!". What's worse is that this high level machinery builds on low level concepts. You can't possibly understand what you're using, why you're using it, or how it works unless you understand the fundamentals first.
I am [always wary][1] of function template specialization, the two-phases overload resolution: 1. Resolve *base template* with closest match 2. Search for a more precise match among specialization of *that* base template is a recipe for head-scratching; and is especially nasty because includes can change the base-template of a specialization... Of course, in your case, since you have a closed set of types to start with, the issues might not apply. [1]: http://www.gotw.ca/gotw/049.htm
Yeah sorry, too much time spent in Unreal's engine. But back() should work. back() - 1 doesn't make sense. back isn't returning a number it;s returning the value that's in the last element of the vector.
I was under the impression that boost test was borderline unsupported, or else is the work of one lone guy. That was enough of a deal-breaker for me to go the gtest route.
It wasn't an appeal to authority; I was merely curious if you knew who he was. You are suggesting that his philosophy is &gt; 100% wrong , you think that going from low level to high level is the right way to go, and he believes it to be the other way around. I guess I'm closer to your camp as well, but with modern C++ you'd still do yourself and everyone else using your code a favor if you use the new tools provided by the language / standard library. Just because you are using smart pointers doesn't mean you don't get to understand pointers; it's just less likely to introduce memory leaks.
True dat. It's easy to get polarized in online forums.
I've enjoyed QTestLib from Qt(http://qt-project.org/doc/qt-4.8/qtestlib-tutorial1.html), but as a Boost user here noted, it's being used mostly because Qt is already heavily integrated into the project.
Is there a way to make it work with the XCode version of clang via the commandline clang on OS X? I have the most recent XCode version (Apple LLVM version 5.0 (clang-500.2.79) (based on LLVM 3.3svn)) and it tells me that address is not a supported argument for option fsanitize= 
250 KLoc is medium, not big ;) I work on projects with ~20 open sources libraries and ~100 middleware libraries *on which you start building*. That's a lot of headers to bring through so you better be careful about your includes (or cry).
I've never used this `stdafx.h`... I seem to recall it being a VisualC++ thingy ?
Note that you need multiple rounds of running it because removing includes sometimes give more opportunities to remove includes. Amusing :)
The SSD option is especially attractive as your dependencies grow. On the projects I work on, we have more than a hundred libraries as dependencies (I am lucky, some of my coworkers start with 5x that amount). This means at the very least a hundred `-I` directives to the compiler, and therefore a worst-case of searching through 100 include directories to resolve that `#include &lt;...&gt;` preprocessor directive. You can of course organize your directories in an order that attempts to minimize this search (by moving more often used directories first), but it's a tough battle. So... 1. Minimize the includes in your headers 2. Might want to try out `gcc -remap` or precompiled headers 3. Just buy a SSD for very fast directory checks The latter is easy (and it costs less than a day of work!), the first is an ongoing battle (Include What You Use helps a lot). I really, really, wish for modules.
Hi, I actually decided against this specifically because `Apply` is not meant to be called by the user at all. It is the worker function called from the lua function. If anything, it should be a private function and the _lua_dispatcher should be a friend function.
1. Ah this is a very good point. `X -&gt; void* -&gt; X` is fine but not `X -&gt; void* -&gt; Y`. I will change this. 2. Didn't know this. Time to read the C++14 spec. That's very cool
I responded in the survey, but in case (and for others) if you've not looked at [Ninja](http://martine.github.io/ninja/), it's a very nice system for fast builds. It's largely geared toward fast incremental builds, but if you're stuck on an older tool chain that doesn't have good parallel support, it excels there, too. I'd only recommend using it within the context of a good metabuild system like CMake, though. There are some other build systems with support for it, but I can't opine there.
I've always thought other [ C++ &lt;--&gt; Lua ] bindings(not sure if this is the term I'm looking for) were a bit clunky, this seems like a very clean use case. Nice job!
So everyone should start out with writing the executables in a hex-editor before being allowed to use assembler? Because without understanding the fundamentals of how a program is executed, it is pointless to write programs.
Possibly, but it works fine for me and for my uses. The fact it's there and I don't need an additional/optional dependency is enough for me.
C++ isn't a managed language and every pointer isn't a smart pointer and there are different kinds of smart pointers. I agree that if you were using a managed language you don't really need to understand this stuff. Actually that is a good argument for avoiding the concepts entirely in introductory CS courses and using languages like Scheme. And are you honestly saying that most professional developers don't understand what a memory address is? Seriously?
My own: [xUnit++](http://bitbucket.org/moswald/xunit/).
The argument-less throw inside a function is a technique I wasn't aware of but that I'm sure I'll use in the future. Great post.
I think qunit wins. Unit testing comes with so much bullshit, I don't want to learn another language ffs. Anyway, it lives here if you are interested http://qunit.sourceforge.net
i don't know how you want to "parse" it, but I'd suggest writing a simple FSM to parse it however you want to.
Fsm?
finite state machine, most parsers use that concept even simple ones.
A string is an array of characters, I would like to parse the index , search for certain symbols and remove them or place the symbols which are needed into a new string
Can you write a pseudo example?
Precompiled headers are now supported by VisualC++, GCC, and Clang. stdafx.h is just the defacto standard place where some people put the compiled header.
Sweet. Hopefully they will support clang 3.4 soon :)
With static libraries, you still have all the header includes, and also static linking a program takes longer than dynamic linking.
There is an ongoing [thread on the Boost mailinglist](http://lists.boost.org/Archives/boost/2014/01/210295.php) about updating the Boost.Test docs. Apparently, there are many new features in the pipeline, but the maintainer hasn't been pushing this to any of the recent Boost releases. Perhaps once the dust has settled after the recent Boost transition to GitHub, the new documentation and features will be released.
Seems to include lot of boilerplate code? For example, why define a test method twice. Once in a class declaration and secondly when implementing it. Some years ago we compared alternatives for CppUnit and the main goal was to make adding new test as easy as possible. It just needs to be so easy that difficult test frameworks won't be the dealbreaker. We ended up choosing GoogleTest and all developers like it. (60+ devs, 5MLOC C++, Microsoft Visual Studio environment)
The problem is that incremental builds can be very long too. On my current project, with a good machine with an SSD, an incremental build can take up to 4 minutes.
Static libraries are not good enough. The problem is templates which are being used more and more as generic programming becomes more common, and all the code has to be visible at compile time in every unit that refers to that code.
It matters for me - sometimes. Small changes compile in a few seconds or tens of seconds. But other times, I can make a one character change to a line and because it's in a template that's needed in 30 other places it takes 2 or 3 minutes to rebuild. It breaks into your workflow badly when you have to keep stopping and can;t just try something and carry on without a few minute wait.
Wait, are you using C strings or C++ strings? Your description sounds C-string like. For example, removing all "x" characters: char* Remove(const char* str, char x) { const n = std::strlen(str); char* newStr = new char[n+1]; char* out = newStr; for(const char* in=str, end=str+n; in != end; ++in) { if(*in != x) { *(out++) = *in; } } *out = '\0'; // terminate your stuff return newStr; } This, however, sucks. For example Remove(Remove(myStr),'x'),'y') would remove all 'x' and 'y' characters from myStr - but would also leak memory. A client would need to do char* noX = Remove(myStr,'x'); char* result = Remove(noX,'y'); delete noX; noX = 0; or the marginally less terrible char* result = 0; { // scope noX char* noX = Remove(myStr,'x'); result = Remove(noX,'y'); delete noX; } C++ strings at least push this new/delete business into the class. You could do something similar, or take advantage of the find() or replace() methods.
Doing a build is 1. Find out what you need to build and what order those things depend on each other (ie, what can you build right now) 2. Queue &amp; execute each of those builds. To do 1, most build setups (all make, cmake and VS for example) run through all files you have and check their modification dates. This means they have to 1. Load all build scripts at the same time, create a full dependency graph for all sources 2. Check all sources for "modifications" Both of these are slow steps. Reading 25000+ file modification timestamps in Windows is notoriously slow - you can't get your build faster than a few minutes for large enough software subsystems as the build step itself takes that long to find out what to build. Alternatives are: - Lots of caching. *LOTS* of caching. Have your memory at least 8x your source-tree-including-build-outputs size. For the company I work for that's not possible - the build tree output for a single build is 27GB, let alone if you do multiple build targets. - SSDs. - Cleverer build setups that do not rely on file modification time stamp checking. One option is inotify to be notified of file modifications. When you have this, you can then try only to figure out the build steps that these files may contribute to. Sadly, makefiles, cmakefiles etc. are set up such that you can't know this.
And it's a VC thing because MFC.
With a decent build system and coworkers that understand the importance of forward declarations, yeah. For those of us living in dark ages where there's no dependency checking in the build and where massive use of typedefs has made forward declaration use pretty impossible...build times can suck dirty assholes. Takes two hours to build the program I work on. I'm pretty much required to do a complete, clean build any time I think about checking in because the build system will not necessarily catch my changes without it...and the build server does a clean. It's frustrating and sad...but not the language's fault.
Actually, statically linked libraries would make for slower link times; so no... not at all. I want modules to avoid the `#include` copy/paste mechanism and dynamic linking to avoid the "link the world" issue (hint: when you have ~500 libraries you depend on, static linking is not even funny any longer).
Thats a lot of dedication for hash tables...
I'm learning a lot along the way. Hopefully it's just one more blog entry to go.
Yeah, although for my needs boost test provides what I need. And I've had no issue with the doc. That said, I would be interested to see an future improvements too
Nope it doesn't bother apart from in one case, it bothers me when I have a tricky bug where a debugger isn't of much use (often due to environment issues or a problem with a binary) and I am trying to iterate to a fix then it becomes a really annoying. A part from that it's a non issue. For the likes of say templates especially boost, yeah it takes a long time, but because it's doing so damn much. It still take a whole lot less time then it would take me to write the code myself, and doc and test it.
Well in years RAM and number of processing cores has gone up, meaning you can have a greater level of concurrency in your build system. 
I figured it out you call it like an array so string str = "hello"; Cout &lt;&lt; str[0]; Will return "h" 
I'm aware. I was just impressed by 5-6MLOC in 3 mins. For comparison, I have an 8 core machine (3 years old), 8 GB RAM, HDD (non SSD), 2MLOC, parallel builds, pre-compiled headers, etc.... The build still takes 12 minutes. We do use a lot of STL and other templates.
The only problem I've had with gtest is that, hilariously, it doesn't pass cpplint.
That's much better
&gt; This means at the very least a hundred -I directives to the compiler If you're at the point where the number of include directories is causing performance problems then just installing the headers for all of your dependencies to a single directory seems like a really obvious solution.
The gcc/clang approach supports much more fine-grained precompilation, but a single VC++-style precompiled prefix header (or one per grouping of files) often turns out to be the optimal choice.
I think you're doing a great job :) So hopefully its more then one more entry :D
Do you have any links to papers showing data recovery from a zero'd out SSD? Most of the secure erase stuff is complete security theater. Especially when combine with full disk encryption, and the build in encryption of most SSDs.
4. Get more RAM. A decent OS should cache the contents of those files, making stats and even reading those files nice and fast (see ninja).
I don't recall seeing anything like that. SSDs are still a largely unknown quantity at this time, and at the rate they're changing, they'll stay that way for a while. While I'm not familiar with any legitimate attacks against a nominally zero'd drive, I can envisage several. Encryption doesn't help if [rubber hose cryptanalysis](http://en.wikipedia.org/wiki/Rubber-hose_cryptanalysis) or a [five dollar wrench](http://xkcd.com/538/) is something you actually think about.
Most other languages seems to use hash tables for everything.
Citation please. A lot of languages have key-value maps, but that doesn't necessarily mean they use hash tables, you can also use a tree based data structure such as implemented by `std::map`, which has been in the STL since it's inception.
Many dynamic languages will use hash tables, and variants thereof, to provide fast access to fields and methods etc. [Luas tables](http://www.lua.org/source/5.2/ltable.c.html) uses, I think, optimizations similar to cuckoo hashing with a [Chained Scatter Table](http://www.brpreiss.com/books/opus4/html/page230.html). Python has [some notes in its source tree](http://hg.python.org/cpython/file/32f9e0ae23f7/Objects/dictnotes.txt) on its use of dictionaries (hash table implementation for the object model is in [dictobject.c](http://hg.python.org/cpython/file/32f9e0ae23f7/Objects/dictobject.c)). I'm not aware of a popular language that uses balanced trees or skip lists for these use cases.
Either that or gcc remap, the latter does not seem too bad either. Only investigating this on and off though :/
Good point, for incremental compilation specifically you often hit the same files over and over so caching should help tremendously.
I use UnitTest++. http://unittest-cpp.sourceforge.net/UnitTest++.html
I find it somewhat surprising that `multiset` and `multimap` require equivalent elements to be iterated over in the order they are inserted but `unordered_multiset` and `unordered_multimap` apparently do not (they only require that the relative ordering of equivalent elements be preserved through reshashing, the reason of which is unclear to me).
Well, [LWG issue #518 resolution](http://www.open-std.org/jtc1/sc22/wg21/docs/lwg-defects.html#518) mandates that equivalent elements not be shuffled around upon insertion, erasure and rehashing, but it does not say anything about where a newly inserted element should go to: to me, this is in fact a good thing, as it allows for more efficient implementations (as the libc++ vs. libstdc++-v3 discussion shows) and unordered associative containers do not satisfy any particularly useful ordering guarantee to begin with (if a user needs those, she should go to regular associative containers). The rationale of issue #518 resolution is that it allows for the common idiom where elements are erased on range traversal: for(iterator it=...;it!=c.end();){ if(pred(it))it=c.erase(it); else ++it; } BTW, the resolution says nothing about the relative ordering of non-equivalent elements, which would render this idiom valid only for traversing equivalent element ranges, not the whole container. (??)
Slower lookups doesn't seem like a good tradeoff. 
Commercial software devs are lazy apparently... They get something for free and complain they can't use it without effort.....hahaha 
Which particular tradeoff are you referring to?
I don't think that's fair at all. As a commercial (as well as FOSS dev) I can say that I can't use anything GPL for obvious reasons, however there are loads of times when I use permissive free software and if we come across bugs in it, it's not like we chuckle to our self and keep our changes hidden. It's in our best interest too to feed back into the code base that way future versions will have the fix and the quality of the code base improves. Hell they have financial incentives to see a FOSS lib improve, hell if you have a FOSS lib you want commercial users. 
What obvious reasons can't you use GPL FOSS? GPL does not prevent commercial development and LGPL is specifically for libraries...
I mean, sure you can talk about the infamous integer overflow bug but I think you're just being pedantic. For a person learning to code, I'd say that person should take a more hands on approach, compiling and verifying that assumptions are met and the expected results are accurate. Dijkstra speaks from a position of academic authority to be sure, and I similarly came from an academic background. However, not everybody seeks to learn programming to become a computer science theorist, and I would loathe to think that any single approach could possibly be an optimal approach for everybody. Are you *really* going to tell somebody who's looking for answers to a beginning C++ book to start learning some other random academic language with no implementation? I don't believe you actually believe this yourself.
Interesting, although one thing that bothers me is that the lifetime of the object that you are passing to the delegate must be maintained while the Delegate object lives. That sort of thing makes me a bit nervous. 
I am not surprised about saying nothing about non-equivalent element ranges given that such elements might end up in different buckets after a rehashing. Thanks for pointing out the LWG issue, it does clarify the purpose of this rule :)
On my system76 galago ultrapro: Intel 4th i7 1.6 to 2.4(?) ghz 16gb 1800 mhz RAM RAID 1 of high performance SSD, theoretical throughput of 1.1 GB/s measured at around 400 because of encryption, when not encrypted it is close to theoretical. On my custom AMD machine: AMD 8350 speed non-variably clocked to 4.7GHz 32gb of RAM overclocked to 3200 MHz RAID 1 of corsair force3 gts slightly worse speed than the galago This machine is water cooled to get these speeds. I know it is crazy, but I bought the machine as a toy, but I also lapped the CPU and GPU. I mounted a custom block of Copper on the GPU too, it was required to get GPU plate I bought attached correctly. I got so lucky on the AMD machine. I tried so many things that each on their own could have destroyed the machine. I guess I just took enough precautions, but I have voided every warranty on every part. Both machines run Ninja instead of make. Similar idea to make, it is written in C++ and has a simpler execution model. That took between 15% and 20% off my build time by itself. I make certain to run 9 build threads. I tested both at 8(The number of logical cores in each), 7, 9, and 10. Benchmarks revealed that 9 is either the fastest or close enough to 8 to not matter. I run Ubuntu on each and I always add PPAs for any software I think might affect build performance(except the compiler itself). Up until recently that meant cmake, QTCreator and ninja, but there seems to be only minor features in PPAs now for those. I still use the QTCreator PPA but I have not measured builds from command line vs QTCreator in a while. No precompiled headers, they are crap. They complicated linking, on most compilers they require disgusting changes to source, they break if you look at them funny, and they are not very portable. If the headers don't change the object files will still be around for the compiler to use. This code uses a ton of STL, no boost though (I have nothing against it, this project just opted against it), and a fair amount of template metaprogramming that probably slows the compile down (but we like it because we think it makes the code prettier)
Ah good point, I don't think it will prove to be an issue though since I doubt re-hashing occurs on erasing.
Sure, it's just a matter of formal correctness in the standard text.
Thanks!
Is there somewhere an all-and-everthing comparison between clang and g++? I'd be interested to see which containers and algorithms are faster and which are slower plus a round-up or an average. Anyway, good work here, interesting comparison! I think I understand the reason for disabling SpeedStep and Turbo Boost, but wouldn't enabling them give a more real-world comparison? If you wanted a common test base you could use a VM with limited, yet guaranteed resources (if such a thing exists).
I really like where your library's going! Are you planning to add class/object support (like [LuaBridge] (https://github.com/vinniefalco/LuaBridge) has) in the near future?
&gt; No precompiled headers, they are crap. They complicated linking, on most compilers they require disgusting changes to source, they break if you look at them funny, and they are not very portable. If the headers don't change the object files will still be around for the compiler to use. I'm confused about how you are using precompiled headers that it changes your source files. My approach (the linux build, for example): 1) For a particular shared library, create a module-name.h file that includes commonly used headers like iostream, Log.hpp, string etc 2) Create a dependency in the build tree to build a module-name.h.gch from the module-name.h _before_ any other dependencies 3) Modify the CXXFLAGS to -I modular-name.h on the command line of each build translation unit. Passing -H in the CXXFLAGS will let you know if it's picking up the .gch No modification to sources at all. And certainly, no complicated link stage either... I do see a 8% -&gt; 15% speedup when using it with GCC. With Clang++ under OSX it can be as much as 20%+.
I was surprised not to find any mention of this closely related proposal: [marray](http://www.andres.sc/marray.html) Still, thanks for posting.
Don't unrestricted unions in C++11 mostly address the use cases of a variant with a limited set of types it may represent? If so, they should be almost trivial to implement in C++11, whereas an `any` type is not so simple.
Actually, it's silly, but unrestricted unions do not really help. The problem: template &lt;typename... Args&gt; struct variant { size_t index; union { Args...; } _; // error: cannot use pack extension here (and how would you access it anyway!) }; What really helps, however, is `std::aligned_storage`. You need some helpers (a variadic `max`) to get the right size/alignment, but at least you automatically get aligned storage. And I would disagree regarding the simplicity; given the much smaller interface of `any` compared to `variant` + `recursive_variant` + `static_visitor`, it might well be that `any` is much simpler.
Unions are not type safe. Nothing prevents the user from (accidentally or not) reading the wrong type, and they have to keep track of the current type themselves, and dispatch manually via `if` or `switch`. `boost::variant` encapsulates all this in a `static_visitor` which makes its use statically type safe.
What are the restrictions in Spirit's any implementation that make the boost::any approach a better basis for the standard? It seems like Spirit's implementation (minus the stream operator requirements that are spirit-specific) offers better performance for the same API.
This is now implemented: https://twitter.com/CppQuiz/status/425346070256701440
The main reason is that it's bad practice to have generated files live inside your repository. By having your build files live elsewhere: 1. you're less likely to delete important files if you have a typo in your rm command. 2. cannot accidentally commit build files 3. ensure's that you're unlikely to have misconfigured your build setup (i.e. files in your repository are really unlikely to be accessible to your build steps)
I don't see anything in the proposal that'd stop you from using `hold_any`'s implementation. `hold_any` has no documentation and the same interface, so I'm not sure how basing the proposal on it would be any different.
Glad to see this finally moved from draft to proposal. I've been following it for about a year now (even wrote an implementation that followed it as closely as possible)
I hope std::any is faster than boost::any. Recently I had a need a need for a data structure to process lost of data from text a file and store the tokens in different data types. I benchmarked boost::any against boost:variant and wxVariant. boost::variant turned out to be much faster. boost::any had the worst performance, at least for my use case which is a shame because boost::any is much easier to use.
One library that I would really like to see in that package is boost.
All 3 authors seem heavily involved with Microsoft. What would be the reason for Microsoft to push for this? And what would be the benefit of having Cairo in the C++ standard?
It's Herb Sutter's pet project, not an official MS thing. He spent a while talking about why he thinks it's important in his [keynote at GoingNative 2013](http://channel9.msdn.com/Events/GoingNative/2013/Keynote-Herb-Sutter-One-Cpp).
I'd imagine this is because boost::any allocates on every assignment. I haven't used it in a while, so this might have changed, but that did cause a major performance problem when we used it in a student game engine a few years ago. The solution we ended up going with was pretty naive, though it gave us the performance improvement we were looking for. Basically, for our game objects, we implemented a slightly modified strict_any, which had the constraint of only allocating on first assignment, and asserting on assignment of types that were larger than its initial allocation. This fit the use case for our game properties, because we were storing values in a single any that would not change type. Clearly not a general solution, but I'm curious if a simple constraint like that would make a significant impact in the performance. Relevancy depends on the way you structured the tests, to be sure.
My thinking is that there should be a native UI library in the C++ standard before we start to delve into graphics... Yes, I know that there are lots of libraries available for platform-independant UI, but I mean one built into the standard library
Here's an argument against that, at least in its current form, using qt as an example. Qt widgets aren't accelerated by graphical hardware beyond whatever sparse 2d acceleration you can get out of the platform api (direct2d, cairo, etc). But it *is* pure C++, so you can make whole stack programs with complex UI in only C++. But they didn't like that approach, because in practice the modern world doesn't have time to waste cycles on drawing and rendering on the cpu. Everything has a beefy gpu now, and qml was designed to address that - a lot like how you write GLSL to program on a graphics card, QML is a declarative UI language mimicing the gles scene graph. That way every element can be gles accelerated, so the whole application doesn't waste cpu cycles. If you don't put application logic in Javascript in the qml, you are also running a minimum of interpreted code, since all the qml-foo is implemented in C++ and GL. So if you wanted to add in UI widgets to C++ itself, you wouldn't be able to assume platform acceleration availability, and since they would have to be native C++, you are forsaking yourself to cpu-bound rendering of at least a good chunk of your UI since you need deep interaction with widget classes. So what I'm kind of saying is that, first, C++ isn't a really good language for widgets, and I really like the qt approach. And that reason is because it is a hyper-performant bare hardware *general* programming language. That is why we have shader languages, for programming graphics hardware, where UI widgets are best implemented. So while 2d in the standard is ok (I agree it is somewhat superfluous) any UI toolkit bound internally to the STL would be crippled out the gate by having a limited ability to accelerate the entire GUI due to tight coupling with your x86 / arm / mips / whatever assembly.
It's the Cairo API they want in the standard, because it's proven and well suited to a C++ implementation. Though it's likely the existing implementation would be used as that would greatly speed up the work of library implementers. If you mean what's the benefit for MS? Well maybe they don't have any ulterior motive.
However, it would slow down future development on the library. Or alternatively the standards compliant version would run behind on Cairo. Microsoft already has platform specific libraries for this kind of work and there are plenty of high quality cross platform libraries too.
Yeah, also it would limit UI features to a the subset of features every OS supports.
I'm surprised that the proposal rejects the idea of creating a new 2D drawing API with the explanation that &gt; Unfortunately this would not have implementation and usage experience, This is not true, of course, as [wxGraphicsContext](http://docs.wxwidgets.org/trunk/classwx_graphics_context.html) is exactly such an existing API which efficiently maps natively to Cairo, CoreGraphics and GDI+ (although not Direct2D yet). This API is not perfect, of course, but at least we do have experience with both implementing and using it. It's a pity that this seems like a non-starter because IMHO this is the best approach.
Which I'm pretty sure is zero these days. Ergo, the C++ standard library already has a cross-platform UI library.
This isn't really an argument against C++ widgets. Firstly: actual shader languages are *terrible* for regular widget drawing. Not only are they limited to a very small set of primitives but they are too closely coupled to the hardware. You want a sophisticated (and hence: not on the graphics card) display language to handle rich drawing instructions and abstract away the render target (be it CPU, GPU, printer or file). Second: almost everything about widgets happens in the CPU (binding to data, construction, events). The idea that a widget must be on the GPU doesn't really make sense. Even QML is fully parsed on the CPU before building a display list that is subsequently sent to the GPU. All the UI interaction, scene management and animation though, remains on the CPU. Which gets to the third point: even if you are rendering on the GPU, you're going to need to build the display list on the CPU. Cocoa uses C/Objective-C/C++ on Mac and iOS to build UI views and generate CoreGraphics drawing instructions but all views are backed with a GPU layer and can the actual Quartz display list can execute on either the CPU or the GPU as required (the app doesn't even know which approach is used). WPF on Windows works in largely the same way: C# builds the display list but the execution of the rendering instructions is deferred and performed on the GPU. Just because the drawing API is in C++, doesn't mean you can't GPU accelerate. All you need in your graphics API is an abstraction between building the display list and the execution of that list.
For widgets and 2D drawing there are so many use cases I don't think it's ready to be standardized just yet. There is also a need to do 2D drawing for computer vision which would be different than for displaying on screen. I prefer at this time for 2D drawing to be out of c++ standard and just choose a library specifically for my needs first.
Well it wouldn't surprise me if MS do build their implementation on top of Direct2D. Possibly as little more than a lightweight wrapper.
Because all languages should come with batteries. C batteries are called UNIX.
Drawing 2D things is a big part of a UI.
Perusing through the sample chapter, you say that "you can't declare a variable to assign a lambda expression to without `auto`." This isn't correct as you can use the template type `std::function` to store lambdas, functors, and any other callable type.
This is an exceedingly bad idea, I really hope it gets shot down by the standards committee. It isn't that Cairo is a bad thing, it is a good library. The problem is that it isn't a standard controlled by the committee. If the standards body wants to do a 2D graphics library (a very good idea in my mind) then do one that is based on modern C++ and is looking forward to a world of heterogeneous systems. It is foolish to try to incorporate any library into the C++ standard that isn't controlled completely by the people developing the standard. It is all about destiny, and keeping control of that destiny. Frankly I wouldn't be bothered if the lib was modeled some what on Cairo. Cairo obviously works well enough as we see it used widely. However working good enough isn't a good reason to incorporate it into the C++ standard! after all there are plenty of other good 2D libraries out there. However modeling isn't using Cairo. The other big concern is licensing. I'd rather see something license free as much as the rest of the standard library is. The LGPL shouldn't come anywhere close to a standardized language feature. 
Yes, I included a bit of an overview of the C++14 features as well. Mainly I wanted to compile all of the C++11 stuff into one book, but without the rest of C++.
Why do cross platform. I'd rather see them take a Java approach where the UI is unique to C++ but runs on multiple platforms. This is far different that making a lib that appears native or nearly so on each platform. Maybe I'm stretching definitions here, but any C++ UI needs to be independent of the underlying operating system. After all it wouldn't be surprising to find this GUI code running on hardware with no operating system. Even embedded processors come with GPUs these days or lesser video hardware. In any event a UI lib is a long way off. We need to get a C++ based 2D lib in place first. 
`std::function&lt;int()&gt; fun = []() { return 3; }` Maybe I'm misunderstanding what you're trying to say. Where is the auto in the above?
not `int x = 3;` `std::function&lt;int()&gt; double_x = [x]() { return x * 3; }` ? "Closure" to me means a function with a reference context. I still don't see why auto is needed. Would `auto double_x` here produce anything different than something of type `std::function&lt;int()&gt;`?
I think we're thinking about slightly different things when using the word closure. Let me quote from the standard: "The type of the lambda-expression (which is also the type of the closure object) is a unique, unnamed non- union class type — called the closure type ... The closure type for a lambda-expression has a public inline function call operator (13.5.4) whose param- eters and return type are described by the lambda-expression’s parameter-declaration-clause and trailing- return-type respectively." So, the type of the lambda expression is this "closure type", which is basically a functor. It isn't an instantiation of the `std::function` template, however. So the answer to your question is yes, `auto double_x` would produce a variable of a different type than `std::function&lt;int()&gt; double_x`, despite both being initialized with the same expression. 
Just another note on why the distinction matters: `std::function` can/will have higher memory requirements and worse performance compared to the closure type inferred by `auto`. Have a look at this post about `std::function`, for example: http://probablydance.com/2012/12/16/the-importance-of-stdfunction/
But this is one of the huge sticking points. A lot of people prefer the wxWidgets approach of wrapping the native UI API, I know I do. For example, on the topic of Java, I personally hate how IntellJ or Eclipse stick out like a sore thumb on Windows. Now I'm not saying I'm right, but any thread about a portable UI library, for any language, throws up these two polarising views. Trying to develop an international standard in such a climate would *seem* impossible.
&gt; versions 4.8.1 and above, which have full C++11 support I really wish you'd quit promulgating this non-truth. gcc 4.8.1 may have complete support for C++11 language features, but it does not have complete library support. Try using C++11 regular expressions in gcc 4.8 for example and you'll be left wondering why the code seems to compile but always throws an exception. (Answer: because it's not implemented fully in gcc 4.8, you must use gcc 4.9.) 
With auto you store a lambda, the variable has anonymous type: auto l1 = [](){}; l1 = [](){}; // type error, they have different types! With std::function&lt;void()&gt; you create a type-erased container that is able to store any callable entity taking zero arguments and returning void: std::function&lt;void()&gt; l1 = [](){}; l1 = [](){}; // no error even tho the closure objects being stored have different types! Yes, you can store a lambda in l1, but l1's type is std::function, not anonymous. The point being: *a std::function Is Not A Lambda*. Because of type-erasure, calling a lambda stored in a std::function would also perform very differently due to the overhead of an extra virtual function call which might also prevent its inlining. EDIT: fixed a typo
Nice. Will buy it for sure!
On page 19, second example, it should really be **std::**declval. Other than that: looks nice.
I decided to implement this small utility since I was previously tied to the C++ compiler used to compile Boost, due to Boost.Filesystem's static library dependency. I also had some use cases in which I needed to iterate over large numbers of files efficiently, which is why I decided to use the raw system calls rather than `readdir()`. I thought that others here may also be interested in a lightweight library for fast directory iteration. It currently only works for GNU/Linux and OS X, as these are the operating systems that I use. Comments, criticism, and requests are welcome!
It's not like they're going to bundle Cairo into the standards paper. This proposal does essentially what you say it should. It's describing an API which is defined by a machine translation of the Cairo API. After that, it's up to the platform implementation to do whatever it feels appropriate to conform to the spec. On Windows, Microsoft could implement this API using only Direct2D and have no actual code from the Cairo project in it. On Linux, it would make a lot of sense for the C++ API to be a pass-thru into the actual Cairo API. Luckily the whole Oracle v Google trial regarding the Java API has made it roughly clear (IANAL) that APIs cannot be patented; so LGPL doesn't come into play here. The proposal is only based on the **API** for Cairo, and not its implementation.
I think you've missed the point. A UI C++ library would just draw in the right way for the platform. Just like a 2D library would. A UI library doesn't require a 2D library be standardised, as the implementation would do the right thing. C++ specs would define API not implementation. You need only look at Qt for your example. It draws in multiple different ways on multiple different platforms, and the programmer using Qt doesn't care in the slightest.
Can you ship to the UK? Is there a Kindle/eBook version?
It looks very interesting, not only directory iteration part but also the other utilities (dynamic library loading, formatting, etc). Any hope of a Windows version of your directory iteration library?
yep, I would also be interested with a Windows port. boost::filesystem is nice because it works everywhere.
I see now, thanks for the reference.
Will standard filesystem stuff come in C++14?
.7z lel, if I only knew how to open that.
Arg! I had missed it. [It](http://en.cppreference.com/w/cpp/types/aligned_union) says the first parameter is `Len` which is the minimum size, from which I deduce that I can always use `0` if I just want the tightest size available... ... am I off ?
ccbase.dynamic is something I've wanted for years. A shame that I don't need it right now, but my hat is off to you! Does it work on Windows? (Unfortunately, a lot of my code has to work on Windows, even though I develop on Linux or OS/X.) The title is a bit weird - static library dependencies generally aren't as bad as dynamic library dependencies (since you can't link in the dynamic libraries and have to distribute them separately). It seems to me that you have no library dependencies, except for the standard C++ libraries which are essentially for all non-trivial C++ programs. Is this right? 
That's exactly what I say, *language* features.
All my examples assume `using namespace std` for brevity, otherwise it gets hard to fit them into the page width!
Thank you!
It's an ebook, so shipping is no issue :) I provide PDF, EPUB and Mobi. I'm not sure about the value of ebook formats though - it's hard to make the code examples look nice on a Kindle, for example.
It's unfortunate that this is a terrible habit to get into :x
 &gt;But this is one of the huge sticking points. A lot of people prefer the wxWidgets approach of wrapping the native UI API, I know I do. Nice but what if you are writing for a platform with no OS or supporting UI API? The problem I have is that C++ is used extensively for embedded projects where there is little in the way of OS support if there is a OS at all. A UI kit or even a 2D graphics kit needs to be independent of the underlying OS's out there to allow for the broadest use. Otherwise what is the point when so many wrapper libraries already exist? &gt;For example, on the topic of Java, I personally hate how IntellJ or Eclipse stick out like a sore thumb on Windows. So! Not to be an ass but after years of Mac and Linux use I can't stand windows. That doesn't mean I like Eclipse by the way, I hate it for the bugs and trashing of my code. The problem as I see it is that the issue of UI support has already been solved for the major operating systems. What C++ needs is a base capability for implementation of solutions outside of the major OS's. What that UI looks like isn't as important as you may think considering how poorly many embedded GUI appear to be. &gt;Now I'm not saying I'm right, but any thread about a portable UI library, for any language, throws up these two polarising views. Trying to develop an international standard in such a climate would *seem* impossible. Actually the thread started as a discussion about a 2D drawing lib that things such as a GUI can be built upon. Doing a 2D library should be very doable. A full blown GUI is another thing but honestly simplicity is more important than bloat here. As it is I'm not hearing a lot of resistance to the idea of a 2D library for C++. I do reject the idea of using Cairo as the basis of that library. I suspect most people could see and do see the value in a robust 2D library, it is just another basic feature much like lists and other data structures these days. 
 &gt;I think you've missed the point. A UI C++ library would just draw in the right way for the platform. Just like a 2D library would. A UI library doesn't require a 2D library be standardised, as the implementation would do the right thing. C++ specs would define API not implementation. Sure it does. It is very difficult to create a UI lib if you don't understand how the stuff gets drawn on screen and have a standard way to do that. Beyond that you make a fatal assumption here that the system you are developing for would have a drawing lib to target. &gt;You need only look at Qt for your example. It draws in multiple different ways on multiple different platforms, and the programmer using Qt doesn't care in the slightest. So how does QT do that? 😜😜😜 
&gt; Sure it does. It is very difficult to create a UI lib if you don't understand how the stuff gets drawn on screen and have a standard way to do that. Beyond that you make a fatal assumption here that the system you are developing for would have a drawing lib to target. We're not talking about creating a lib, we're talking about specifying an API. The implementation would target a drawing lib, but that's the library implementation. There is a massive difference between an API and its implementation. It's entirely analgous to the fact that C++11 now specifies threading primitives. When you use them and build for UNIX, then for Windows, you'll get one application making use of pthreads, and one making use of Windows threads -- without changing your source one jot. The same would be true of a UI library -- how it draws on screen is not your concern as a user of the library. That, in fact, is the very point of a UI library: to abstract the drawing primitives away. &gt; So how does QT do that? 😜😜😜 Abstraction. At no point do you have to make any X calls, OpenGL calls, or Windows drawing calls when you use Qt. All of that is handled by the implementation. Now of course they build against different graphical back ends in their implementation, but you as the user of Qt don't care about that. Qt is excellent in that respect, it's highly cross-platform, and I've used it for exactly that on numerous occasions. Your hysterical emoticons indicate to me that you meant that question sarcastically; that in turn makes me suspect you've never used Qt, (or wxWidgets) nor appreciated what abstraction is for. Hopefully the previous paragraph makes it clear. TL;DR. In no way would the addition of a UI library to C++ require a 2D library first.
I wouldn't expect any library to be perfect with respect to 2D drawing or even the GUI components. The trick with C++ is to define a library that has wide applicability in as many domains that C++ is used as is possible. Frankly the GUI issue for the majority of the big OS's isn't a problem. The problem is defining a component that is usable in a wide array of systems that haven't been standardized by fiat. In a nut shell the problem I see here is that people are thinking in terms of Mac, Windows and Linux when those systems already have a 2D lib. C++ simply has broader usage than that. 
An answer as precise as your question: you're causing the crash. What code? What are its goals? Which libraries? You should atleast have a clue to what part of the code is causing the crash. Start with something simple: litter your code with cout &lt;&lt; "entering function X". And see where it blows...
 &gt;It's not like they're going to bundle Cairo into the standards paper. This proposal does essentially what you say it should. It's describing an API which is defined by a machine translation of the Cairo API. I'm not even sure that is good enough to escape the licensing problems. Beyond that machine translation simply doesn't inspire me. All of the brouhaha between Oracle and Google over Java doesn't inspire me. &gt;After that, it's up to the platform implementation to do whatever it feels appropriate to conform to the spec. On Windows, Microsoft could implement this API using only Direct2D and have no actual code from the Cairo project in it. On Linux, it would make a lot of sense for the C++ API to be a pass-thru into the actual Cairo API. This part I understand. It is what I want a standard to do, define a spec for implementation. I'm just not clear that the proposal on offer really does that. &gt;Luckily the whole Oracle v Google trial regarding the Java API has made it roughly clear (IANAL) that APIs cannot be patented; so LGPL doesn't come into play here. The proposal is only based on the **API** for Cairo, and not its implementation. I'm not convinced it is all that clear. It really isn't so much a patent issue as it is a copyright issue in my mind. Frankly I can make a good argument that a machine translation is a copy of a work rewritten in another language. The other problem I have is how would this translation look when put up against modern human engineered code. Honestly this library really needs to be forward looking, adapting the latest C++ techniques and understanding the nature of GPUs in modern systems. I guess the issue is will this so called machine translation produce sound C++ code or will it produce C++ code that looks like a bit of C warmed over? I'd rather that they take Cairo as a basis and say how would we refactor this to be a better API in C++. The idea of throwing a machine translation of a C library out there and saying this should be our new C++ standard just gives me the willies. 
I used to think that, but I came to dislike the incessant noise of `std::` everywhere. I think it's more a matter of preference now. 
There's only Linux and XNU implementations in load.hpp.
Thanks! ~~Unfortunately, I still use several C++11 features that are not supported by MSVC yet.~~ The porting itself will not be very hard, as most of the headers in the library are very light wrappers over the OS-specific calls. The [formatting header](https://github.com/adityaramesh/ccbase/blob/master/ccbase/format/format.hpp) on its own should probably compile OK, but I might have to make some minor changes. Edit: It seems that VS 2013 v1.1 supports almost all of the features that I use. I will begin porting on Windows after I get a chance to set up a Windows box.
`char buf[end - glob + 1];` [That](https://github.com/adityaramesh/ccbase/blob/master/ccbase/filesystem/range.hpp#L38) isn’t valid C++11. A `std::string` or `std::vector&lt;char&gt;` seems more indicated here anyway. You should compile with `-pedantic -Wextra -Werror` at the minimum. The rest of the code seems very clean, on a glance. As a hint: `-I.` is very brittle if you accidentally produce an executable which has the same name as a standard header. This happened to me once. Hours of debugging later I realised that I had a file `iterator.cpp` which compiled to, naturally, the output file `./iterator`. And the compiler subsequently tried including it when encountering `#include &lt;iterator&gt;`. It’s more robust to put include files into an `include` path. Furthermore, for library headers I’d use `-isystem` instead of `-I`, which means that warnings in those libraries are ignored. That’s helpful if you want to use very strict warnings (as you should).
Look at MinGW-w64 for GCC on Windows.
Just glancing over the code I didn't notice anything not supported by VC++ 2013 other than noexcept.
Thanks for looking at the code! I just enabled `-Wextra -pedantic` and moved the include files into a separate directory. I know that VLAs are not standard C++11, but I did not want to dynamically allocate memory just to copy a small part of a string. I'll change the VLA to `std::dynarray` once the major compilers support C++14.
This post is the shortest of the three mainly because many of the techniques used for this section were covered in the previous two posts.
On the other hand, it's not really that hard to build those in MSVC... Qt, for example: configure -platform win32-msvc2010 qmake nmake
`0` or `1` are perfectly acceptable.
Hm, you're right. After checking with VS 2013, it seems the only unsupported features that I use are Expression SFINAE, constexpr, and noexcept. I'll try compiling on a Windows machine the next time I get the chance.
Too bad, I think it's a very importante feature to have in the estandard :(
What about using std::array?
Can't see it :( 503 Connection timed out
It's difficult to bound the length of the glob of pattern within the path string in advance. I could perhaps set a limit on the the length of the glob pattern, but I opted to use VLA's instead of imposing such a limit.
The syntax is just inhuman. I'm still stuck using boost::bind and boost::function, since the syntax is **gasp** more readable. Sorry for adding noise to the topic, my eyes still hurt.
It was useful for me, when I had to compile Qt 4.8.3 with VC++ 2012. VC++ 2012 was not yet a supported profile for this Qt version.
&gt; It is what I want a standard to do, define a spec for implementation. I'm just not clear that the proposal on offer really does that. It does. The proposal states this pretty clearly, IMO. &gt; I'm not convinced it is all that clear. It really isn't so much a patent issue as it is a copyright issue in my mind. If APIs were a patent/copyright issue, then Wine and ReactOS should be terrified because they've re-implemented the Win32 APIs. &gt; I guess the issue is will this so called machine translation produce sound C++ code or will it produce C++ code that looks like a bit of C warmed over? The result of the machine translation is provided at the end of the proposal as a header file of declarations. You could technically write code against that, just don't expect it to link. If we're lucky, someone will come along and actually implement the proposal as a pass-thru to Cairo and you can actually play around with it. After skimming the translated API in the proposal, it seems reasonable to me. The proposal even states that some parts of the translation have been intentionally messaged to make it more idiomatic.
Also, [Herb reached out to the Cairo community](http://lists.cairographics.org/archives/cairo/2013-December/024858.html) at the end of last year; it would be odd for him to continue with this proposal if he didn't get their okay.
This series has been great. One of the things I think is missing from the interop though, is a way of calling Lua functions transparently. Something like replacing int x = state.Call&lt;int&gt;("foo", 1); with auto foo = state.Function&lt;int&gt;("foo"); ... int x = foo(1); This should be pretty easy to implement though, with some sort of `LuaFun` object that holds a reference to the state and has an overloaded `operator()`.
&gt; Instead of &gt; &gt; #define DEBUG 1 &gt; &gt; void printBackTrace() { &gt; #if DEBUG &gt; // do something &gt; #else &gt; // do nothing &gt; #endif &gt; } &gt; &gt; we can write &gt; &gt; enum class Configuration &gt; { &gt; Debug, &gt; Release &gt; }; &gt; enum class Platform &gt; { &gt; Win32, &gt; Win64, &gt; Linux &gt; }; &gt; struct ConfigurationDriver &gt; { &gt; constexpr Configuration configuration = Configuration::Debug; &gt; constexpr Platform platform = Platform::Linux; &gt; constexpr ConfigurationDriver() {} &gt; }; &gt; &gt; // start using ConfigurationDriver &gt; $use(ConfigurationDriver driver) &gt; { &gt; &gt; // function with a driver &gt; void printBackTrace() &gt; { &gt; $if (driver.configuration == Configuration::Debug) &gt; { &gt; realPrintBackTrace(); &gt; } &gt; $else &gt; { &gt; // do nothing &gt; } &gt; } &gt; &gt; // function with a driver &gt; void foo() &gt; { &gt; $switch (driver.platform) &gt; { &gt; $case Platform::Win32 // fallthrough &gt; $case Platform::Win64 &gt; { &gt; WinApiXyz(); &gt; } &gt; $case Platform::Linux &gt; { &gt; GlibcCallXyz(); &gt; } &gt; } &gt; } &gt; &gt; } // $use Not the most motivating example...
Good to know if you're developing a compiler!
I feel like most of this is too bloated. He found a problem which he is trying to attack with a waaay too general approach.
&gt; Not the most motivating example... One of the main goal is is to deprecate the C preprocessor and the template metaprogrammng thing. The quoted example only a minor part of the whole plan. If you have a better idea i will update my proposal which is here: https://github.com/hun-nemethpeter/cpp-reflector-mini/blob/master/Proposal.md
I wrote this paper to response "N3814: Call for Compile-Time Reflection Proposals" http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3814.html
Especially because a decent compiler will do dead code elimination on that example code without the static if/switch statements.
FLTK is okay for a simple project. It is extremely easy to use.
$if { } does not introduce scope.
I'm not saying the proposal is bad, just that the above example doesn't present it in a great light.
I think it's more about having constructs like $if and $case, which introduces actual, real metaprogramming instead of the template gobbledygook. I see this as a huge improvement.
I think you are talking about N3613: "Static If" Considered http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3613.pdf But my proposal much more complex then a simple "static if". e.g. I introduce a $define language object which is #define successor. A $define is as safe as a normal template. so $define + $if + $for ... is for C preprocessor replace, and $use is for deprecating template meta programming through constexpr objects. And there is a new keyword astnode (other option is call it $grammar) which leads to a native DSL solution.
I think the confusing part is that I introduce the $define keyword earlier and I don't mention it in that section. The C syle #define e.g. not namespace friendly, and not type safe and can not interact with constexpr. $if and $switch can interact with constexpr and the new so-called drivers.
Not necessarily. People working on C++ are interested in making the language more accessible, more powerful and more usable. They are also, by requirement, interested in 99.99%+ backwards compatibility. The combination of that means that any power added makes it harder to understand the full language, as they can't really remove anything. What would you like to change about the language?
Not me; I have other fish to fry. c++ is a nice way to get things done without having to write several versions of the same function.
Heh this looks like function currying which would be pretty cool. I'm not really sure how to implement this generally because the arity of `foo` is not known when you declare it in your example. If you wanted to, for example, use `std::bind` to create the function, you'd need to know at compile time how many arguments to pass to it.
I should note that on your end, this is really easy since you know how many arguments you wish to supply (runtime determination). auto foo = [&amp;state](int arg) { return state.Call&lt;int&gt;("foo", arg); } int x = foo(1); Does this work?
I would like to see a language that takes the features that committee feels are best and most useful (proven by existing code), and features they want to have (modules, concepts, etc) and design the language from the ground up without having to consider backwards compatibility. See what that looks like. (assuming it isn't D ...)
I think I might be. Then on the other hand I think that's true for anyone who is interested in a language. Every language has a cult.
Isn't that how D started out? (A re-engineering of C++) The problem is that clean break types of ideas almost always end up falling on their face because it takes so long to reach feature parity that no one even cares about the insanely huge task of porting all their existing code. [This](http://www.joelonsoftware.com/articles/fog0000000069.html) is a great article on that issue and it's definitely worth reading, if you haven't had a chance to yet.
This problem is true of any language used. It really depends on the experience and competentcy of the developer. The best developers are systems engineers first and developers second. Figuring out ways to solve the overall problem tends to be the best way to approach things, although certain constraints and requirements can harm that.
More to the point: constexpr combined with "static if" gives you most of a compile-time scripting grammar for conditional compilation and more. Along the same lines - and this is really more of a critique of GCC than anything else - there's no good way to forward the original line numbers to the compiler through the generated output. This can play havoc with anyone's ability to read GCC error output let alone debug output. Static if gets you around this by working within C++, not ahead of it.
So this is impressive. Yes, there's quite a bit of machinery added - but the results are IMHO worth it. * You can get rid of a lot of preprocessor uses - perhaps all? but I'm not sure how you'd do stringification and token concatenation. * Conditional compilation becomes very similar to an if statement and will be correctly indented by your editor. This is a small feature but very satisfying... * Get rid of a lot of template metaprogramming - perhaps all? * Supposedly allow you to do all sorts of meta-things: style checking, asserts, constructs that create classes "on the fly" (at compilation time), and quite a lot of reflection - perhaps all reflection things that you'd ever use? Comments on the article: * There's an omission in your list of $ keywords - you're missing `$else`. * I'd consider dropping `$switch` as redundant to `$if`/`$else`. * I've read the Struct-of-Arrays example three times, and I still don't understand it. * * I believe that you end up creating a new class called, er, `SoA_vector_of_S` which "looks like" S, except that every member is replaced by a vector of the original type - but this is a guess only. * * More commenting, an example of using `SoA_vector_of_S`, and even more important, a comparison with the same structure as created by hand. * I don't fully understand how the CodingStyleChecker could work if you are getting an AST which is surely coming after the tokenizer... * If you must mention "cannot be used for header guard" as a downside, then you should point out that for all C++11 compilers, `#pragma once` works and is a better solution - in other words, this just isn't a real downside. * The other downside - "`{` and `}` does(*) not introduce scope but it seems so from the syntax" - is real, though certainly not a deal-breaker. * * Can it be worked around somehow? Could the braces actually introduce a scope where possible? Absolutely not. What about using different symbols - like `${` and `$}`? "Your ideas are intriguing to me and I wish to subscribe to your newsletter." Do you have sort of mailing list for this work? (* - actually, it should be "do" rather than "does" but your English is super-excellent for what I guess is a non-native speaker...) 
Great, their C++11 support is still subpar and buggy, eg things like `std::packaged_task&lt;void ()&gt;` don't work, but hey, good thing they already started with ~~C++14~~ C++17. Don't get me wrong, this is great work. But C++11 is standardized since almost three years now, and Microsoft is really lagging behind GCC and Clang in this regard. 
That's what every language does. And then you figure you want to add this thing. And then that thing. And then that other thing is nice. And you're stuck again.
What do you think about await and resumable?
Just copy and paste it from the appendix? It does look quite nice. It appears to be a better version of what I end up creating for every C++ project.
Having had first hand experience with node.js' callback hell, I can only welcome it! I think resumables and await are a great addition to the language. I'm not entirely sure if I like `N3722` though, off loading the scheduling to the future is a bit ambiguous in my opinion. However, that might just be because I'm used to writing high performance multithreaded C++11 applications and like having control over the scheduling of the workload (and also my lack of knowledge of the proposal itself) Edit: Words, grammar and the lot.
I haven't read the proposal too closely yet, but it appears to have the same general problem as the similar C# feature in that it's overly focused on solving a single problem when there are other approaches that solve the same problem and many other problems (e.g. C# async is embarrassing when compared to F#, despite F# not having the highly-targeted feature for it). That said, it does look like a nice feature; it's just not immediately obvious that it's nice enough for the added complexity to the language.
You only need to know the arity of `foo` when it's actually called. Something like the following would suffice: template&lt;typename Return, typename String&gt; struct wrapper { String fn_name; State *state; template&lt;typename... Args&gt; Return operator()(Args...&amp;&amp; args) { return state-&gt;Call&lt;Return&gt;(fn_name, std::forward&lt;Args...&gt;(args)); } }; template&lt;typename Return, typename String&gt; auto State::Function(String const&amp; name) -&gt; wrapper&lt;Return, String&gt; { return wrapper{name, this}; } (You could obviously make it strongly bind the function rather than the function name if you prefer)
With the advent of C++11, I can’t think of any big problems I have with the language any more when it comes to getting things done.
Yea something like this could work. The only weakness I can think of to this approach is that if the state is destroyed, objects like this will persist. This is also true if the function itself that you were attempting to call was deleted. But perhaps this is not so bad... Incidentally, what is the purpose of the auto -&gt; syntax there? You aren't using a decltype so wouldn't `wrapper&lt;Return, String&gt; State::Function` suffice?
What added complexity comes from just await? I think it helps with code brevity and clarity.
This seems confusing because the Standard has a split personality. Core considers everyone other than compiler devs to be users. Library considers everyone other than compiler and library devs to be users. So from Library's perspective, you may not specialize things in std for const char *, that's Core's type, nor may you specialize things in std for pair&lt;int, int&gt;, that's our type. But pair&lt;Foo, Bar&gt; has user stuff in it. (There is a very simple rationale; the Library may need to separately compile or otherwise play sneaky games with stuff like pair&lt;int, int&gt; which would be unaffected by user specializations. We can't possibly separately compile something like pair&lt;Foo, Bar&gt; though, so that's safe.)
I'm sorry but I disagree. For those who know the rules of `auto`, this alternative would be extremely confusing and out of place. Let's not adapt the language to fix human ignorance: C++ does not need more *special* cases.
I like it. I didn't even realize that auto&amp;&amp; behaved similarly to T&amp;&amp;. Regarding the constant range, does it cover enums? Iterating enums is annoying in C++, especially unnecessarily so when they form a contiguous range of values, but having one for non-contiguous ranges would be good too so that one could right an iteration over the enum range without having to worry about holes.
Yup, workin now :)
&gt; Template meta programming does its 'magic' through types, constexpr are still values. How can you replace that? The trick is $use convert a type to an AST node wich is a value. Look at carefully: template&lt;typename T&gt; $use(EnumDriver driver) // here T is a type ... constexpr EnumDriver(const EnumDecl&amp; enumDecl) // T is now an AST node ... $for (auto enumValueName : driver.enumValueNames) // we got back a set of typed token ... .Case($enumValueName.asStr(), $enumValueName) } // repasting tokens So the pipeline is type -&gt; $use -&gt; AST node value -&gt; produce typed tokens with a constexpr object (meta::type_name, ...) -&gt; repasting tokens with $
I don't know. There are so many places in c++ where you need to *understand* if things will be copied or if not how you can use const/non-const references that adding a default in one place to make things easier for beginners doesn't seem like much of a win. It just makes it easier for people who don't know what they are doing in c++ to get a bit further without having to learn how things actually work. I'm not against it, and c++ could certainly do with making easier. I'm just not sure that hiding some of the complexity in one specific case by adding yet another way to introduce variables with new rules to learn is a good thing. As I said, I'm not against it, but I'd take some persuading to overcome my skepticism.
Thx, &gt; but I'm not sure how you'd do stringification and token concatenation. In the SoADriver: members.emplace_back({field.getTypeName(), field.getName() + "s", }); // field.getName() + "s" is token concatenation In the Json::readFrom example: // here we repeat the .Case method call, and repasting token enumValueName as a string with the help of asStr() .Case($enumValueName.asStr(), $enumValueName) } There is a TODO section for token repasing syntax. Maybe $(enumValueName.stringify()) would be better &gt; There's an omission in your list of $ keywords - you're missing $else. Thanks, for spotting this, and the $case also missing &gt; I'd consider dropping $switch as redundant to $if/$else. Hmm, if it is really confusing I will remove it &gt; I believe that you end up creating a new class called, er, SoA_vector_of_S which "looks like" S, except that every member is replaced by a vector of the original type Yes. So this paper is based on this http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3814.html, so the result was given: struct SoA_vector_of_S { std::vector&lt;int&gt; as; std::vector&lt;int&gt; bs; std::vector&lt;int&gt; cs; }; &gt; More commenting, an example of using SoA_vector_of_S, and even more important, a comparison with the same structure as created by hand. There will be no difference with the hand created one. The task was to automate hand made vectorization. &gt; I don't fully understand how the CodingStyleChecker could work if you are getting an AST which is surely coming after the tokenizer... The clang AST API contains a SourceManager class. Here is an example: https://github.com/hun-nemethpeter/cpp-reflector-mini/blob/master/MetaClassGenerator.cc#L51 And you can get a token start, end positions with this method: https://github.com/hun-nemethpeter/cpp-reflector-mini/blob/master/ClangSourceManagerHelper.hh &gt; What about using different symbols - like ${ and $}? I give it a try but I removed: https://github.com/hun-nemethpeter/cpp-reflector-mini/commit/78dc62f161aead5f8f0466a52d1e4e0019b7ce96 removed in this commit: https://github.com/hun-nemethpeter/cpp-reflector-mini/commit/f15f2b53a06f538230e73e300b577ed9fcc22183 &gt; Do you have sort of mailing list for this work? https://groups.google.com/a/isocpp.org/forum/#!forum/reflection But I got a feedback there: "I'm not sure there's anyone except you who wants to extend the language grammar, at least in this mailing list. "
&gt; Regarding the constant range, does it cover enums? That would require a range type - a perfect idea for the Ranges SG. Currently you can iterate over braced-init-lists but you can't directly say "all the values of this enum".
When iterating through containers or arrays, how often do you want to copy elements, versus observe or mutate them in-place? All of *iter, *ptr, and ptr[idx] work in-place. I'm betting at least 99% of your loops are in-place; mine certainly are. In fact, I can't remember the last time I wanted to copy elements before operating on them (as opposed to copying them into a second container, which is different). Everywhere other than loops, I agree - you gotta know about copies versus references. But loops are special.
So historically after I created the $define I realized that the C macro is not needed any more, so I started replace other parts of the macro system. The conditional compilation was solved with this syntax. $if is a #if replacement here. Tokens won't parsed if you use $if in a $use {} context. But I think it will be safe to use $if in a drived template context, where tokens will be parsed. But there was a big discussion earlier so I removed this possibility from my paper.
I build a little helper for iteration of enums in c++11 here http://www.codeduce.com/extra/enum_tools 
Looks great, but there is another thing I would like for range-based for-loops: The index (like in D): for(index, value: {4,8,7,3}) { std::cout &lt;&lt; index &lt;&lt; ": " &lt;&lt; value &lt;&lt; '\n'; } This should print: 0: 4 1: 8 2: 7 3: 3 The same should apply for maps: std::map&lt;std::string, size_t&gt; map{{"foo", 1}, {"bar", 2}}; for(key, value: map) { std::cout &lt;&lt; key &lt;&lt; ": " &lt;&lt; value &lt;&lt; '\n'; } should be printed as: bar: 2 foo: 1 I admit though, that I am not entirely sure about how this should be implemented: Maybe use key, value if the dereferenced iterator results in a std::pair and the indexed version otherwise?
Looks like it has been fixed
&gt; "for (auto&amp; elem : range)" or "for (const auto&amp; elem : range)", but they're imperfect (for proxies or mutation, respectively) What are proxies?
I'd suggest using http://cppreference.com instead. Cplusplus.com is not the most highly regarded site for a number of good reasons, the simply have very good SEO.
Coming from python I was hoping for something like this too: for x, y in zip(x_vector, y_vector): print x, y I have seen some implementations of zip using boost and annother using the stl but they end up being of the form: for (auto i : zip(a, b, c) ){ std::cout &lt;&lt; std::get&lt;0&gt;(i) &lt;&lt; ", " &lt;&lt; std::get&lt;1&gt;(i) &lt;&lt; ", " &lt;&lt; std::get&lt;2&gt;(i) &lt;&lt; std::endl; } and the whole get&lt;0&gt;(i) is pretty ugly. 
I hope the Range working group will come up with something like this. I expect to see something like Boost's Range Adapters that are usable in the for-range loop.
In this specific instance, STL was thinking about vector&lt;bool&gt;::reference which actually refers to a class and not a reference type, a class for an object that is supposed to behave like a reference as much as possible. vector&lt;bool&gt;::operator[] does not yield a reference but a temporary object with which the logical vector&lt;bool&gt; element is accessed.
Ah, but a special case which may have more applicable uses in the future. I would like to see this syntax be adapted to generic lambdas and terse lambda syntax coming in C++14: auto iter = find_if(students, [](s) s.name == "Bob"); //&lt; Some range-based find_if(). Where the omission of the type implies `auto&amp;&amp;` just as in STL's proposal.
I'm not sure if auto-generating the index is all that useful. But as far the map example goes, this seems pretty straightforward to me: for (auto&amp; kv : map) cout &lt;&lt; kv.first &lt;&lt; ": " &lt;&lt; kv.second &lt;&lt; endl;
I have seen that method. I would like it if I could name the variables e.g. for (auto&amp; obj_name, auto&amp; object : map){ //do something with the object and its name. or for (auto&amp; obj_name, object : map){ // shorthand //do something with the object and its name. which assumes auto&amp; for key and value Thoughts?
If you are interested I got halfway through a very small header library which did something like your first example: // prints 0123456789 for(auto num : interval[0](10)) { std::cout &lt;&lt; num; } // prints abcdefghijklmnopqrstuvwxyz // note: This is non portable as static_cast&lt;char&gt;('a' + 25) isn't guaranteed to be 'z' for(auto letter : interval['a']['z']) { std::cout &lt;&lt; letter; } Trying to emulate the well known open/closed notation in maths e.g. [0,10). It was mainly used for quick loops like this and basic interval arithmetic. I got halfway through some of the more complex interval arithmetic functions before I got distracted with other projects! I can put it up on github when I get home if there is interest. EDIT: Added note of non-portability raised by CTMacUser below.
Added complexity to the language. Obviously it makes the code using it much simpler.
Omitting the type in lambda expressions doesn't work because you can already legally have just one token there, since supplying names for the arguments is optional. I'd prefer to have the types optional and the names required, but alas, I do not have a time machine. The proposal for the single-expression lambda was rejected, unfortunately. Rationale was that it was too different from normal functions, and there was a lot of opposition to just making normal functions also able to be just a single expression.
If "Enumerator List Property Queries" (n3815) proposal will be accepted then cover enums should be pretty easy. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3815.html
I agree that C++ need Reflection support, but this approach appearers to pretty unpractical. Probably all concerns again static if can be applied to this approach too, but one can add a lot more. &gt; Deprecating template metaprogramming It is just not possible, because a lot of modern libraries are using templates. Now the main question is where template programing ends and where metaprogramming begins ? Is using type_traits metaprogramming ? &gt; Deprecating C style macro It would be great to have proper and safe replacement for C Preprocessor, only then we could think about deprecating it. But again new C++ need to be compatible with C and older C++. 
 &gt; Now the main question is where template programing ends and where metaprogramming begins ? Is using type_traits metaprogramming ? "My proposal is to issue a deprecate warning when template instantiation depth reaches a low number e.g. 16." You can use type traits but why? They are just methods/members of an AST node. Everything you can do with type_trait you can do with AST node methods. &gt; It would be great to have proper and safe replacement for C Preprocessor, My proposal contains a safe replacement of a C preprocessor. My proposal is backward compatible.
Wait, the terse single-line syntax isn't coming? That's pretty unfortunate IMO. I really wish the committee would see lambdas as a way of providing an ultra terse syntax that can be used for situations like my example. The extra syntax isn't helping anyone in that example, IMO. auto iter = find_if(students, [](const auto&amp; s) { return s.name == "Bob"; }); Yeah, that's not anywhere near as nice as my first example.
Thanks for the good answer. Have you considered starting your own private mailing list just to discuss this?
No, I think we should use the https://groups.google.com/a/isocpp.org/forum/#!forum/reflection mailing list. It is a public mailing, and I think this topic is belongs to that list. Just nobody interested in this proposal yet there, but if you go there it can change.
&gt; Let's not adapt the language to fix human ignorance Agreed. &gt; For those who know the rules of auto, this alternative would be extremely confusing and out of place. Why would it be confusing?
Is this a stepping stone to variable declaration syntax with `:=` ? E.g: // inside loops for (elem : range) {...} // outside loops elem := range.front(); 
1. Regarding indices: you can go halfway with an `enumerate` function packing stuff in `std::pair&lt;size_t, T&amp;&amp;&gt;`, but *unpacking* pairs and tuples has never been automated in C++. I think you would *first* need unpacking before introducing this change in the `for` loop. 2. See previous point about unpacking.
The unfortunate effect of this is that a simple *typo* can create a new variable instead of assigning the value to an existing variable. I don't like **subtle bugs**.
Nyah. I prefer C++ over C for: 1. STL containers, by which I mostly mean `std::vector` and `std::map`; 2. RAII; 3. The genericity provided by basic templates. That's pretty much it, but those things make solving a lot of common problems a lot easier.
I wonder why settle for `auto&amp;&amp;` instead of going the `iterator_traits` way. More specifically, something akin to: typename std::iterator_traits&lt;decltype(__begin)&gt;::reference elem = *__begin; // (1) Less cute than `auto&amp;&amp;` certainly, but *it seems it would just work for proxies*. (1) Note: might need some adaptation around `decltype(__begin)` to get those top-level cv-qualifiers and references/pointers out of the way.
Functional data structures are specifically designed for sharing, which is the antithesis of uniqueness. This is explained in some detail in the first installment of the series: http://bartoszmilewski.com/2013/11/13/functional-data-structures-in-c-lists/ .
It would be nice to be able to do auto { x , y } = ...; or { auto x, auto y } = ...; in many places in the language, not just inside `for( : )`. This would unpack return values that are pairs (or tuples). --- Extra: we can (~~I think~~ I was wrong, we can't) already do: struct { int x; string y; } xy = ...; I would like if we could do struct { auto x; auto y; } xy = ...; This is a fairly minimal change (superficially) and it's pretty clear. But I guess it's a bit verbose.
I don't think this is a good idea. First, it's already clear that `for (auto elem : range)` is taking copies, because `auto x` always means 'by value'. This syntax seems quite explicit about the copying, so I don't see any problem with 'hidden copying'. Furthermore the existing range-for syntax provides exactly the intuitive behavior for whatever declaration is used. This new syntax, on the other hand, hides that information and just expects the programmer to know that it expands to `for (auto &amp;&amp;elem : range)`. Second, IME it's actually not quite that common that I want `for (auto &amp;&amp;`. I did a quick look through some code snippets I have on gist.github.com and found that every use of the range-for syntax was either where copying was fine (due to the type of range), or I used `for (auto const &amp;`, to avoid copying. Even most of the examples using regular for loops and iterators didn't mutate the collection. I did see one loop that used iterators and where `for (auto &amp;&amp;` would have been appropriate. It's not a huge sample and it's mostly utility or toy code, but still, it's indicative that not everyone would use this "99%" of the time, as STL suggests. Third, I don't agree with the argument that `for (auto &amp;&amp;` is hard to teach, or that teaching this, `for (auto &amp;` and `for (auto const &amp;` involve teaching references earlier than otherwise necessary. `auto`, of course, should be taught early anyway. As far as I'm concerned teaching `for (auto &amp;&amp;elem : range)` simply involves telling them how to use this magic incantation the same way students are told how to use the magic incantation of `std::cout &lt;&lt;` without being told about operator overloading or iostreams or anything. Lastly, this syntax is quite different from the usual declaration syntax and the benefits don't seem valuable enough to justify the added oddity. This is the same reason I'm glad that generic lambdas did end up using `auto` despite the verbosity. Generalized lambda captures exhibit this problem but there at least they have the excuse of being consistent with C++11 captures, which seemed okay to me at the time because I never thought of them as declarations.
Am I missing something? It would never escape the scope of the range-based for loop. The semantics seem pretty clear to me, but the issue pointed at by matthieum is much more troublesome. JavaScript is really bad about this, for one.
For Haskell, GHC has a parallel comprehension syntax, so while you can do: [x + y | (x, y) &lt;- zip xs ys] You can also do: [x + y | x &lt;- xs | y &lt;- ys] This doesn't require explicitly zipping and then pattern matching on tuples. Not sure how one might adapt this structure for C++ though.
We are relatively close to automatic unpacking since we have std::tie: std::pair&lt;int, long&gt; func(); … long x; // sic long y; std::tie(x, y) = func(); works perfectly. Also: not having something doesn't mean that I cannot hope for it's introduction.
+1. I'm tired of the `END` enum value popping up everywhere.
&gt; As you realize, this does not and cannot obsolete preprocessors and template metaprogramming. I think you did not understand my proposal. But I am curious. What do you think what part of preprocessors and template metaprogramming can not be replaced with my proposal? And why do you think that e.g. a TutorialChecker is not useful for a new developer?
Thanks for posting this, I learned something today! I didn't know foreach loops did a copy, which caused me a great deal of headache yesterday.
No, not when someone is specifically looking for answers to C++ exercises, nor does my comment suggest that the OP should follow such a course. However if one is looking to learn _programming_ in general I think there's merit to the idea. I still would probably choose a real language and allow students to run the programs, but I would definitely want to impress upon the students the fact that running a program and observing the expected output for a given input does not at all verify the program to be correct. &gt; I mean, sure you can talk about the infamous integer overflow bug but I think you're just being pedantic. Undefined behavior goes far beyond integer overflow, nor is it pedantic to be concerned with UB. UB causes real problems in real code. Even instances of undefined behavior that are not currently exploited by compiler optimizers are time bombs just waiting for compilers to get a bit smarter. A correct understanding of UB is fairly important to practical use of C and C++. Furthermore, my example was undefined behavior because that's one obvious way that running a program is insufficient to demonstrate correct program behavior. Dijkstra's argument goes beyond that, however. He argues that letting students run and test their programs encourages them to verify programs by testing them with a few inputs and observing the output but, he argues, that approach is inferior to verification by proof and results in less correct code and poorer programmers.
Typing into reddit's box so this might come out wrong std::vector&lt;int&gt; values; int aValue = values[0]; // ... some code int sumOfValues = 0; for (aValuue : values) { sumOfValues += aValue; cout &lt;&lt; "Adding " &lt;&lt; aValuue &lt;&lt; end;} According to the standard if you reused aValue above it should give a warning, but here is a typo that is a subtle bug that wouldn't hit said warning. To be clear, this same problem would exist if you wrote for (auto&amp;&amp; aValuue) except that it's explicitly creating a variable and that is more clear to me.
Maybe rather the opposite: *most* C++ users are not interested enough in what is admittedly a highly complex language. As a consequence, they write appallingly bad code. In personal projects as well as in large-scale commercial applications. I think this is worse than for most (if not all) other programming languages. This admittedly makes the remainder of the C++ users seem dogmatic and pedantic by comparison. As an example, yes, I *do* care about not abusing pointers in the code. Because they *are* routinely abused – probably in the majority of C++ projects – and lead to brittle, overly complex code.
&gt; This would be the first place in the language where you declare a variable by just name dropping it. [(source)](http://chat.stackoverflow.com/transcript/message/14249520#14249520) For this^ reason. Also some might expect a declaration of the "element identifier".
&gt; Extra: we can (I think) already do: Not in any place where it'd actually be an interesting thing to do, since there's no conversion from `tuple` or `pair` to your anonymous type (and it's not quite possible to create one).
Subscribed!
The only thing I wonder about is that the programming world seems to be moving towards immutable (`const`) by default, and mutable only when explicitly asked for. Lambdas are an example of C++ adopting this philosophy where by they require the `mutable` qualifier (correct term?) when necessary. This proposal seems to adopt the opposite approach.
did you include &gt;using namespace std;
You can always say `for (auto&amp; p : m) { auto&amp; k = p.first; auto&amp; v = p.second; BODY; }` at the cost of a couple of extra lines. It's not especially terse, but it does make the body prettier; I'd do this if I had to refer to the key and value a whole bunch of times. I don't think I want to propose more extensions to my syntax even if I can imagine `for (elem : key = elem.first : val = elem.second : m)` creating an arbitrary number of `auto&amp;&amp;` variables, all after the first requiring initializers (like of like init-captures).
I don't think so. Range-For: TNG really wants to avoid creating new objects, so it always creates references. For something like your := syntax, you'd want objects (remember, C++ loves value semantics most of the time). This is what init-captures do, so they would be the stepping stone.
Init-captures don't mention types either. (They are followed by initializers after an equals, but Range-For: TNG has the range after a colon, which is philosophically the same, as I mentioned in the proposal.)
Yep, it's a subtle danger. Hopefully we can make it less dangerous.
Well, it's "the same constness as the range", because elements are not viewed as independent of their range. If you really wanted to avoid modifying those elements, you should have made it a const range.
I recommend looking at a Working Paper (N3337 if you want C++11ish, or the current WP if you're more familiar with what's being added to C++14 and what your toolchain supports). The Core Language Standardese is admittedly not for the faint of heart, but the Library Standardese is simpler to read, especially if you just want function signatures. This has the added bonus that as you get more comfortable reading Standardese, you can read more of it, and your power grows exponentially.
+1the greatest thing about e.g. your [Core C++ video lectures](http://channel9.msdn.com/Series/C9-Lectures-Stephan-T-Lavavej-Core-C-) is that you show relevant sections of the Standard and encourage and empower viewers to do the same!
Fortunately, most programmers are not ignorant to the point of not knowing what `auto`, `auto&amp;` and `const auto&amp;` means. And even if they were, do you believe this is the correct solution? Cripple a language because people are too lazy to [read a book](http://stackoverflow.com/q/388242/493122)?
Sorry. Of course. You're right.
I disagree with this proposal. Programmers should learn to use rvalue references. If they can't learn those, then they should use another language. 
/r/cpp_questions would probably be more helpful for you. Do you have #include&lt;iostream&gt; at the top of your code?
Would something simple like assigning to variables inside the loop to give them clearer names be slower than referring to p.first p.second? (like in your example) (auto&amp; p : m) { auto&amp; k = p.first; auto&amp; v = p.second; BODY; } Or would the compiler optimize that away?
Oh, I think it could replace it, probably nearly all of it. The point I was trying to make is that you very likely won't actually be able to deprecate the old functionality. That means you're adding functionality &amp; complexity, not replacing it. For a new developer, you're introducing a pile of new syntax rules and syntax rule modifiers, which makes parsing it much harder and understanding it as a new developer equally much harder.
http://www.phoronix.com/scan.php?page=article&amp;item=llvm_clang33_3way&amp;num=1 That's one of the better clang vs gcc comparisons that I've seen.
"Edition." The word is "edition."
So, this proposal is a compile time reflection proposal with that feature that it can replace C preprocessor and template metaprogramming. For C preprocessor, so yes.. we can't drop C compatibility, but that is really a C thing. So a new programmer should start this C++ macro system, not the old C one, and it only differs in one character # -&gt; $ :-) But the template metaprogramming part will be drastically simplified, and boost::mpl, type_traits will disappear. I think the parsing will be faster and simpler if we can limit the template instantiation depth to a low number. And please check the C++ modules proposal, not the parsing is slow, but the amount of the code is large now due to the textual inclusion system: http://isocpp.org/blog/2012/11/modules-update-on-work-in-progress-doug-gregor
woops. In a rush
Ah ok I get it now, thanks. I should have known you'd have thought about this much more deeply than my few musings. :)
It could conceivably be slower, but only indirectly. You definitely won't get any additional copies, because you're binding references to everything. However, although references are very different from pointers, the optimizer will ultimately see pointers here, and optimizers hate pointers due to alias analysis. I wouldn't worry about it, though (the loop is already infested with pointers for the container, element, and iteration).
I definitely agree on the introduction point, however I think it would a rather significant change syntax wise and I am unsure on whether it could fit in a backward compatible-way. In any language where tuples are first-class concepts, unpacking is just *so* useful :x
The problem here is not about naming variables so closely, it's about stupidly tripping on the U key on the keyboard :(
Could you not augment the proxy with `void operator&amp;() const volatile = delete;` ? `addressof` would still be working, I guess, but it would already help a lot.
Well, range-for (TOS and TNG) always creates a new variable for the element, so either the programmer was choosing scary names, or they misunderstood TNG's behavior and thought the outer variable would be reused but typed it. The former is indefensible; the latter is possible, but less dangerous than unintentional copies.
Good points, thanks for the info.
&gt; The average "C++ Joe" can now savely use C++11, even (hopefully) at work. I wish. RH6 uses GCC 4.4, which has some very limited C++11 support. It will probably be 2 or more years before I see RH7 on my desk, and I'm not even sure what compiler it will have (maybe 4.7?).
4.4 does have quite a few interesting bits - rvalue references, `auto`, variadic templates, initializer lists, `decltype`, `enum class`, thread-safe static initlaization.
&gt;The average "C++ Joe" can now savely use C++11, even (hopefully) at work. It's not even true. A lot of C++11 code compiles in 4.8 but throws exceptions because something isn't actually implemented yet. 4.9 is supposed to better in this respect. But it's not ready for prime time.
That took me a minute (and some embarrassed Googling). [Ford] Aerostar. (-&gt; *)
It took me a while to compile all the answers from the [original post](http://www.reddit.com/r/cpp/comments/1vb2q5/c_developers_of_reddit_i_come_to_you_with_a_short/), since "What do you waste most time on while developing?" got a huge amount of totally different responses. Still, the results are available now, so I hope they're interesting enough :-)
Results available now: http://www.reddit.com/r/cpp/comments/1w24bm/followup_to_the_c_build_speed_survey/
Hmm. That is actually a great idea for vector&lt;bool&gt;::reference, independent of my proposal. I'll put it on my todo list of things to write up, thanks!
Do they sell that Ford in Europe? XD
*Here is the text of the [accepted answer](http://stackoverflow.com/questions/6586205/6586248#6586248) to the [question](http://www.stackoverflow.com/questions/6586205/what-are-the-pointer-to-member-and-operators-in-c).) linked above, by user [Armen Tsirunyan](http://stackoverflow.com/users/469935):* --- &gt;I hope this example will clear things for you &gt; &gt; &gt; &gt; //we have a class &gt; struct X &gt; { &gt; void f() {} &gt; void g() {} &gt; }; &gt; &gt; typedef void (X::*pointer)(); &gt; //ok, let's take a pointer and assign f to it. &gt; pointer somePointer = &amp;X::f; &gt; //now I want to call somePointer. But for that, I need an object &gt; X x; &gt; //now I call the member function on x like this &gt; (x.*somePointer)(); //will call x.f() &gt; //now, suppose x is not an object but a pointer to object &gt; X* px = new X; &gt; //I want to call the memfun pointer on px. I use -&gt;* &gt; (px -&gt;* somePointer)(); //will call px-&gt;f(); &gt; &gt; &gt; Now, you can't use `x.somePointer()`, or `px-&gt;somePointer()` because there is &gt; no such member in class X. For that the special member function pointer call &gt; syntax is used... just try a few examples yourself ,you'll get used to it &gt; &gt; --- ^[about.StackBot](http://www.github.com/gabrieldain/StackBot) ^| ^(downvote to remove)
&gt; How much would you pay for a significant build speed improvement. OP, I hope that hadn't crushed your get rich scheme. 
I don't have a 'get rich scheme'. I simply have an application I'm working on, and I wanted to see if anyone would actually be interested.
And I'm stuck with IAR, which AFAIK doesn't even plan to ever do C++11.
(That was in jest BTW, I realise Poe's law may have made is sound sarcy). I think success of such an idea would depend on how easily it could be added to existing build systems.
4.3 (and maybe 4.4?) had a dangerous implementation of rvalue refs which were allowed to bind to lvalues! This led to some bizarre bugs (I would find that objects had been moved-from when that shouldn't have happened). Can anybody comment on when g++ because sufficiently modern that it was (reasonably) correct for the subset of c++11 that it did support?
If you're able to, install devtoolset 1.1 from RedHat. It provides gcc 4.7.2 in a set of packages directly from RedHat. I know devtoolset 2.0 was coming that should have gcc 4.8. It might be out already, but I haven't looked for it recently.
Sorry, the joke went over my head :-) I agree, it would have to be easy to add to existing systems. Additionally, it would have to be 100% reliable. So, err, I guess I shouldn't waste too much time on Reddit :-p
That is a lot of "stuff". I thought the idea behind C++-14 was to clear up loose ends and firm up the standard. Seems like a lot of new stuff here. I'm very worried that the committee is rushing into 2D graphics support also. C++ could use 2D support don't get me wrong there, I'm just not sure about the wide applicability of the suggested approach. 
First, put questions like this in /r/learnprogramming. You're looking for [lambdas](http://en.cppreference.com/w/cpp/language/lambda). For example: #include &lt;iostream&gt; #include &lt;functional&gt; using namespace std; function&lt;int(int)&gt; make_adder(int num_to_add) { return [=](int x){return num_to_add + x;}; } int main() { auto add3 = make_adder(3); auto add7 = make_adder(7); cout &lt;&lt; add3(4) &lt;&lt; ":" &lt;&lt; add7(8) &lt;&lt; endl; } 
thank you that what i needed
I would pay for a polished, cross platform, easy to deply build tool, that combines all the features of icecream, ccache, and tup. Ideally it would require no changes to my existing CMake based build system.
[you could always ask him yourself, if no one else knows](http://www.stroustrup.com/). Anyone know if the 4th has good enough info over the 3rd edition to make it worth picking up?
C++ build speed will be fixed the moment the language gets modules. Anything else is just bandaid. However I do agree that waiting for C++17 to see if it gets modules, and a few years more until all major compilers adopt the standard, will put us in 2020 or so. Which means still around 6 years, a lot of time in computer time.
Use Visual Studio.
Well I haven't read it, but Bjarne and others have said that C++11 feels like a whole new language. If you can't use 11 yet maybe it doesn't matter, but, I think all the new stuff will take a long time to get used to. 
Compilers will be C++17 compliant in 2017. IMO.
The title is a little misleading. This is a very very specific situation of catching undefined behaviour in *constant expressions*. A *constant expression* is something the compiler computes at compile-time, such as the size of an array: int a [5 / 0]; // the compiler has to compute this at compile time, and gives an error because it's division by zero But the compiler can't be expected to catch this potential error int f(int x, int y) { return x/y; // undefined if y==0 } Getting rid of undefined behaviour in C++ is essentially impossible. You could decide that division-by-zero should throw an exception, and there are lots of other similar things you could do to make things more 'defined'. But you'd probably have to get rid of (raw) pointers and references too!
Yes, it worth it. I bought it and I do not regret it. It is not that advanced but it is very nice to have such a reference. Moreover I don't know any other book doing a coverage that complete
Yes, and okay I will move the post, thank you
Like they were C++11 compliant in 2011 you mean?
I've got both 3rd and 4th. Honestly they are like different books. I don't feel like I would be wasting time reading both. On that basis I'd be willing to shell out again for a c++14 version.
Bjarne is really a nice and down-to-earth guy. You shouldn't feel afraid of him scolding you for asking or something.
Very glad I could be of help :)
[People like accelerated c++](http://www.amazon.com/Accelerated-C-Practical-Programming-Example/dp/020170353X) - as it focuses on using the std library over pissing around with the low level stuff for strings and what not. While it's good for that - it's presentation of code is something left to be desired IMHO.
I will take a look at this one for the STL coverage.
Ah very nice. Thank you. 
If you are using CMake, take a look at https://github.com/sakra/cotire
clang and gcc are just two of many among C++ compilers available out there, specially when looking outside the desktop space. One can only write portable C++XY code when all required compilers are compliant.
Since you have previous experience with C++, I highly recommend the first book in that list: A Tour of C++ by Bjarne Stroustrup. It covers a lot of ground very quickly and includes templates, algorithms, containers, concurrency, and more.
This is exactly what I needed, I feel foolish for not just intuitively knowing this was the book I needed.
MSVC has not caught up, but is it worth mentioning ?
Note that AC++, while a fantastic book, is not a C++11 book. Still worth reading if you're new to the STL. The C++ Primer (http://www.amazon.com/Primer-5th-Edition-Stanley-Lippman/dp/0321714113/ref=sr_1_1?ie=UTF8&amp;qid=1390666156&amp;sr=8-1&amp;keywords=c%2B%2B+primer) is pretty good I've found for a read and I use it as a reference too. Note that Barbara Moo is also an author of this one and I consider it to be in a similar spirit to AC++. Also, you mention `auto_ptr` but this has in fact been deprecated in favor of `unique_ptr` and `shared_ptr`.
It’s hard to beat Bjarne Stroustrup’s book The C++ Programming Language, which has been updated in the 4th edition to cover C++11. It is unfair to expect the quality of code in books to be of the highest standard, as the purpose of example code is to teach. However, Bjarne Stroustrup does a remarkable job of demonstrating every detail of the language from an end-users perspective, without being overly verbose. I have it on good authority (thanks, Amazon!) that Scott Meyers is due to update his book Effective C++, which will no doubt become an essential read. You can probably expect more books to be revised and published this year. The next C++ standard (C++14) is due out this year, and is generally expected to be a ‘bug fixed C++11’, so you can rest assured that much of what you learn about C++11 will be relevant to the next increment of the language specification. However, above and beyond all, there is no substitute for practice! I highly recommend getting a hold of GCC or Clang for your preferred system and reworking a few katas for the new language - you may be pleasantly surprised by how much of what you already know is still relevant! Good luck!
&gt; But damn it I miss C++ and feel like it has moved without me. I see smart pointers, auto_ptr, unique_ptr `auto_ptr` is deprecated - C++98 (and older) that you're not supposed to use any more. `unique_ptr` replaces it and does other jobs too, and is less bug-prone. So if `auto_ptr` seems new, I assume you just didn't use/see it much. It was never a popular C++ feature, though it was created for a good exception-safety reason. 
I'm trying to understand this. As for: Face_Class ** local_face; Is local_face intended to somehow resemble a two-dimensional array? In other words, might you be writing something similar to the following later in your program? local_face[i][j] Although it is possible to implement a two-dimensional array by means of a pointer to pointers, it is *very* tricky.
Yes it is 2 dimensional like local_face[i][j] At the moment I am basically just inetersted in Int_Type boundary_patch_num; maybe this makes it a bit easier to explain
clang already has partial support for modules
Thanks, I really feel that with a good grip on STL is essential for me to become as productive with C++ as I am with C#.
&gt; instead of copying the object I only set the pointer? Looks that way. Your copy is deep in the first dimension and shallow in the second. I suspect you want to be deep in both. [object copy](http://en.wikipedia.org/wiki/Object_copy)
That's why i thought but the copy constructor I implemented didn't work Face_Class( const Face_Class&amp; obj);
Nowadays I just use C++ from time to time, given the JVM/.NET usage at the enterprise level. However, from the C++ code I stumble from time to time on the enterprise, I do get the idea that many C++ developers don't take advantage of the C++ capabilities to write safer code in relation to C. Many just compile C code with a C++ compiler actually.
&gt; interesting, however why do_pointer_from instead of just providing the option to add an overload pointer_from looked up the ADL way ? Most people don't know the correct ADL dance for swap. Asking the user to provide something in their namespace is relatively easy, it's calling via ADL that's obnoxious.
Yep - the STL is the whole reason to use C++.
Well, there is a bit of a hurdle. You have to actually sit down and learn the difference between values, references, and pointers (and what it means to have them each as parameters or return values), how references and pointers to objects on the stack behave differently from references and pointers to objects on the heap, etc. But you're really supposed to be using smart pointers most of the time. And now we have lvalue references as well. It's just *complicated*. Contrast with C which is relatively straightforward (but still people new to programming have problems grasping pointers), or Java (which doesn't have value types) or Python (where you usually don't care and it only occasionally bites you because you forgot that dicts are reference types, etc.). I'm not saying C++ is bad, I personally love it, but it takes time and effort to actually learn.
By the same token, the 3rd was quite different from the 2nd. 
The most dramatic change I would assume in C++11 was the new memory model, which I assume that most C++ programmers are unaware that it is significantly better in C++11. And also the extensions to the std.
I have to disagree. Portable code is standard compliant code that avoids undefined behaviors. If a compiler for a specific platform does not conform to the standard the code is written in then blame the compiler not the portable code. For those cases, if you have to use old compilers just stick to an old standard revision, no?
As a student I haven't been really exposed to such code, but what I hear about it sounds terrible and infuriating. And then these people, who produced utter crap come out of their holes and claim what a terrible language C++ is because their code is unmaintainable. In Germany there is a great saying about such kinds of people: “Wenn der Bauer nicht schwimmen kann, ist die Badehose schuld.” (“If the farmer cannot swim, it's the swimming trunks' fault.”) 
One thing that I do on occasion is reading the plain reference at http://en.cppreference.com/w/Main_Page. It is in fact not as dry as one would imagine. The other thing that can give a short overview is the C++11-article on the English Wikipedia, that covers many of the core-language-changes. https://en.wikipedia.org/wiki/C%2B%2B11 And then there is this great talk by Bjarne Stroustrup that every C++-programmer should watch: http://channel9.msdn.com/Events/GoingNative/GoingNative-2012/Keynote-Bjarne-Stroustrup-Cpp11-Style
#####&amp;#009; ######&amp;#009; ####&amp;#009; *Here's a bit from linked Wikipedia article about* [***C++11***](http://en.wikipedia.org/wiki/C%2B%2B11) : --- &gt; &gt;**C++11** (formerly known as **C++0x**) is the most recent version of the standard of the C++ programming language. It was approved by ISO on 12 August 2011, replacing C++03. The name follows the tradition of naming language versions by the year of the specification's publication. &gt;C++11 includes several additions to the core language and extends the C++ standard library, incorporating most of the C++ Technical Report 1 (TR1) libraries — with the exception of the library of mathematical special functions. C++11 was published as ISO/IEC 14882:2011 in September 2011 and is available for a fee. The working draft most similar to the published C++11 standard is N3337, dated 16 January 2012; it has only editorial corrections from the C++11 standard. &gt;Work is currently under way on the C++14 and C++17 standards. --- [^(about)](http://www.reddit.com/r/autowikibot/wiki/index) ^| *^(/u/F-J-W can reply with 'delete'. Will also delete if comment's score is -1 or less.)* ^| ^(**Summon**: wikibot, what is something?) ^| [^(flag for glitch)](http://www.reddit.com/message/compose?to=/r/autowikibot&amp;subject=bot%20glitch&amp;message=%0Acontext:http://www.reddit.com/r/cpp/comments/1w43p5/can_anyone_recommend_a_good_book_on_modern_c/ceyt9ch)
Why not? What is so bad about using namespace std?
Check this material out from Scott Meyers: http://www.artima.com/samples/cpp11NotesSample.pdf 
Losing information about where symbols come from. You want to keep that information to make understanding your dependencies easier.
Thinking in C++ is what I'm using now and I like it so far.
Or /r/learnprogramming, which is much more active and has plenty of C++ expertise.
I prefer dog pictures myself, or beach pictures if the mood strikes. 
You can use [tuple_element](http://en.cppreference.com/w/cpp/utility/tuple/tuple_element) to get the type of the element as you are declaring the variables you want to unpack to. Maybe something like this? template&lt;std::size_t I&gt; using foo_t = typename std::tuple_element&lt;I, decltype(foo())&gt;::type; foo_t&lt;0&gt; a; foo_t&lt;1&gt; b; std::tie(a, b) = foo(); Still pretty verbose, but it saves you from having to create a new variable.
I fully agree. The problem is that many tend to measure compiler compliance by what gcc and clang accept, while there are lots of compilers besides them. The pain it was to write C code in mid-90's when compilers were between K&amp;R and C89, with their own quirks. C++ was even worse, they couldn't even agree which parts of the C++ ARM to support.
I never liked C, having spent a few years using Turbo Pascal before learning C. It lacked modules, OO and all safety that TP offered. By luck, I got to play around with C++ shorthly thereafter, so it grew on me. Sure it was still unsafe as C, but it provided abstractation mechanisms to write safer code, and other productivity features. So I readly adopted it, back in 1993, only using C when required to do so. I have been in C vs C++ flame wars since then. Another guy, once used Borland C++ as an Assembler, by sticking asm{} blocks in all functions. The only C++ code was the functions names. Nowadays I mostly do JVM/.NET stuff, but still come back to C++ every now and then.
Everything from the name of the contest, to the categories, to the cheater who did exactly what I would have done and tried to hack the grading scripts themselves, was amazing.
I agree for largely same reasons. This is also the only actual argument against adding this feature in the entire thread.
That sounds pretty stupid. On GCC's part I mean, do they really believe someone would read 3GB of error messages? I think it should stop writing error output (for a single compilation unit) after some hard-coded limit. No one should need more than, say 1MB or so.
Because what I _actually_ want is multiple return values -- the fact that I'm using a tuple to keep those return values together is an implementation detail.
640k of error messages ought to be enough for anybody.
That's a common misquotation; Bjarne Stroustrup never said that.
In case anyone is interested, here's a simple implementation of `UNPACK` using Boost Preprocessor http://coliru.stacked-crooked.com/a/bb32e710d8554c77 The usage is as follows: auto foo() { return std::make_tuple(0, 2.0, "test"); } int main() { UNPACK((a,b,c), foo()); std::cout &lt;&lt; a &lt;&lt; std::endl; std::cout &lt;&lt; b &lt;&lt; std::endl; std::cout &lt;&lt; c &lt;&lt; std::endl; return 0; } which outputs (as expected) 0 2 test But, keep in mind that this is a hack and will fail in a lot of situations, as it's not actually a single statement, e.g. in if(true) UNPACK((x,y), bar(i)); A real implementation would need language support.
It would be nice if it was smaller than the previous ones. :-) (Not because Effective C++ was a big book, but because, maybe, C++ has becomes a smaller language.)
Unfortunately the problem with the macro is the lack of support for reference types and other non-default constructible types. Thus, instead, I would turn the unpack on its head: _uniquely_named_tuple const tuple = foo(); std::tuple_element&lt;I, decltype(tuple)&gt;::type X = std::get&lt;I&gt;(tuple); Of course, it requires coming up with a unique name for the result of the expression... 
gvim will open it
The 2D support is thought as a means to have something a C++ developer can expect for basic graphics regardless of whatever platform s/he developing for. This is specially important for beginners, I would say. For anything complex, there are plenty of C++ frameworks to choose from.
Not to mention the whole lot used in embedded development and comercial UNIX systems.
Of course it has, Doug Gregor from Apple is the one driving C++ modules design.
Well, if you want different qualifiers then you could always use one of the more verbose syntaxes -- the syntax I'm thinking of would simply alias the results of `std::get&lt;I&gt;` (same as `auto&amp;&amp;` maybe? or as `decltype(auto)`?)
I've started writing a blog on programming, which will probably be predominately about C++. I'm fairly new to this kind of writing, so please let me know where I can make improvements or where I've made technical errors (I'm sure there are a few despite my best efforts).
The static variables within the function will be initialized the first time the function is called. Wrapping the static variables inside that function gives a deterministic initialization order for all of them.
Ok, but why not: HoardHeapType * getMainHoardHeap (void) { static HoardHeapType th; return &amp;th; } 
Suppose you have some global object with a initializer, and suppose somewhere in the process of constructing that global object, a heap allocation must occur. If you used your method, it would be a random coin toss as to which object (the `HoardHeapType` or the other global object) was initialized first, and if the wrong order occurred, you get silent and deadly undefined behavior. The standard only says that static constructors are ordered based on the order of definition in a translation unit, but gives no requirement on the order of initialization of objects in separate TUs, which means you can't rely on it. But function-scope static objects are initialized when the function is called, so by making all accesses to the global object go through a function call, you can ensure that the initialization occurs in the desired order. This is the construct-on-first-use idiom. Also, `static HoardHeapType th;` would not work because static objects have internal linkage, which means they are only accessible in the translation unit in which they are defined. You would need just `HoardHeapType th;` without the `static`, i.e. a regular global variable. 
If you did that you'd have the same problem all over again with destructors. If you had some static object with a dtor that is going to access the heap (which seems quite likely) then it's a coin flip as to which dtor runs first, the heap or the other object. By using placement new and never calling delete you essentially ensure that the heap's dtor is never called -- an intentional leak, but one which doesn't matter because the process is about to exit anyway. The alternative would be somehow ensuring that the heap is only destructed after every static dtor has been run, and there is no portable way to do that (but there are compiler-specific extensions.)
Hmm, that's an interesting point but it doesn't explain the author's comment which only talks about initialization order.
Wow... Metashell is simply awesome. I wish I had this years ago. 
Thanks for writing this (and citing me! :-&gt;). Now I'm going to help you by nitpicking and tearing it to shreds. &gt; The utility of this cannot be overstated. Template argument deduction cures cancer and solves the halting problem. &gt; The type of a string literal in C++ is const char[] Incorrect. `const char []` is "array of an unknown number of const chars". The type of `"cats"` is `const char [5]`, which is "array of 5 const chars". These are different types (try asking `is_same`). &gt; so the function specialization would look like transmogrify&lt;const char[]&gt;(const char[]) Incorrect (even after fixing `const char [5]`). You declared `transmogrify(T t)` taking `T` by value. Therefore, template argument deduction decays `const char [5]`, so `T` will be `const char *`. Try asking `is_same` in the function's body. This one is a big deal. Note that `const T&amp;` does not trigger decay. &gt; template&lt;typename T, size_t size&gt; Conventionally (although not universally), template parameters are capitalized. `Size` would follow this convention. This makes it easier to see which things are compile-time constants. &gt; It is not sufficient for the types to simply be convertable to one another. Typo (repeated later): "convertible". &gt; because the compiler cannot deduce a consistent type for T. Okay, but how do I fix this? There are at least two ways, one usually good and one usually bad. &gt; void main() { This is nonconformant. &gt; So this [...] Foo f{10}; //T is deduced to be int [...] will not work. Suggestion: Your hypothetical example contains a comment stated as fact, which is confusing. It would be better to rephrase the comment indicating that you are presenting something which is Not C++. &gt; Foo&lt;T&gt; operator=(const Foo&lt;T&gt;&amp; f){...} First, although `Foo&lt;T&gt;` is correct, it is unnecessary - you can say `Foo` within the class definition (this uses the injected-class-name). Second, the return type should be `Foo&amp;`, not `Foo`. &gt; f1 = f2 //fails to compile Well, you forgot the semicolon! :-&gt; &gt; The above fails to compile because f1 would be deduced to have type Foo&lt;int&gt; This is a misleading explanation. It fails to compile because there's no such thing as template argument deduction for classes. As soon as the compiler sees f1's attempted declaration, your program is ill-formed. Instead your explanation says that it's because the assignment below can't work. &gt; template&lt;typename T&gt; Foo make_foo(const T&amp; t) { This will not compile because you said `Foo` for the return type, but it must be `Foo&lt;T&gt;`. (This is a free function, so you don't get an injected-class-name.) &gt; The STL makes use of it at several points with make_pair, make_shared and others. `make_pair` and `make_tuple` are traditional examples (although they are somewhat subtle in that they need to decay), but `make_shared` and `make_unique` are not. That's because they require an explicit template argument: `make_shared&lt;Thing&gt;(args, args, args)`. The naming is perhaps inconsistent ("make" is usually used for template argument deduction helpers). &gt; This fails because func in the last line is a shorthand for &amp;func Not quite - it is true that functions readily decay to function pointers (like how arrays readily decay to pointers), but they are actually distinct. For example, if you have an ordinary non-templated function `int Meow(short)`, and you have `Purr(const T&amp; t)`, calling `Purr(Meow)` will deduce `T` to be `int (short)`, a function type. `t` will be `int (&amp;)(short)`, a reference to function type (the `const` is smashed out as it is irrelevant). But if you called `Purr(&amp;Meow)`, `T` would be `int (*)(short)`, a function pointer type, and `t` will be `int (* const &amp; t)(short)`, i.e. "reference to const pointer to function taking short and returning int". (This reference-to-const is bound to a temporary function pointer.) &gt; it is not possible (or meaningful) to take the address of a template function Incorrect. `&amp;functionTemplate` is valid *if the context disambiguates it*, which is the only time in C++ (that I can easily think of) where information flows "backwards" from the surrounding context into an expression. This special rule has a whole section of the Standard dedicated to it - some of the contexts which provide type information are `static_cast` to a particular function pointer type, assignment to a particular function pointer type, and being passed to a function where the parameter is a particular function pointer type (and not templated). The Standardese is N3797 14.8.2.2 [temp.deduct.funcaddr] and 13.4 [over.over] (it applies to both templated and overloaded functions). &gt; So, the following will work callFunc(func&lt;int&gt;,10), but we have again reverted to explicitly writing the template parameters. Correct; and this is really bad, as I spent an hour ranting about at GN 2013. Heh - I see you linked it below. &gt; A very similar approach to the above appears in the C++14 augmentation of std::less and std::greater available here authored by the great Stephan T. Lavavej. Interesting - that was not among my rationales, but I agree that is a valid use case. Thanks for teaching me something about my feature :-&gt; &gt; The complete rules of TAD may, of course be found in 14.8.2 of the latest working draft of the standard available here. Pro tip - sections are occasionally renumbered, so providing the stable id allows people to find what you're talking about even if they're looking at a later (or earlier) Standard/Working Paper. For example, I would cite this as N3797 14.8.2 [temp.deduct]; that allows people looking at N3797 to use the bookmark tree with the numbers, and people looking at other drafts to search for the stable id. (This is especially useful when citing specific paragraphs, since they get renumbered more often; N3797 14.8.2 [temp.deduct]/6 allows something reading a later WP to go back to N3797, see what the paragraph said, and search their later WP for the same kind of wording, as long as it hasn't been totally rewritten.)
Wow, thanks for the reply! I'm working on correcting the things you mentioned, though some of them will probably have to wait for a more through rewrite. I really appreciate you taking the time to give it such a thorough vetting.
This is very similar to what's called a "[Meyers Singleton](http://stackoverflow.com/questions/1661529/is-meyers-implementation-of-singleton-pattern-thread-safe)." Basically the punch line is, the first time you call that method / function, the object gets created, and it's not created until it's needed. After the first time, only a reference / pointer to the original object gets created. It's a smart way to create a singleton when you need one, considering it's essentially two lines of code.
* CINT is a C interpreter -- it executes given C code * Preshell is a preprocessor interpreter -- it runs the preprocessor on some code and prints the expanded result * Metashell is a type interpreter - it resolves templates and prints the resulting type
`HoardHeapType` seems to only have a trivial destructor, so the problem you describe wouldn't happen here.
Just wanted to say that what you're doing is great and will certainly help primarily yourself, and secondarily others. Writing can take a lot of discipline to get things right but it is well worth it in the end. Keep it up!
Probably at least one more year before I'll be able to use C++11. We have 2 toolchains to support without any C++11 support.
No he is a nut job. I unfortunately work at GS, and it took us 6months to get him transferred to another group. He is really as crazy as he was back during libc days. "Octoploid" Hmmm... 
Similar to what patch said, it is probably only going to help you. I've noticed you have written some other stuff. Taking that into account, one must remember that C++ is a totally different beast when compared to say javascript. Both from a language and community pov. In both cases C++ is far more sophisticated and advanced. One may be able to cobble together a few paragraphs of blog post on something javascript related and receive a whole bunch of oohs and aahs from the js community, but it'll take a lot more than that to even get a whimper out of the C++ community. Furthermore artificially quoting members of the C++ community with good standing so as to attract more attention to your blog post probably isn't the best approach. As mentioned previously the community is generally far more sophisticated than that. In any case all the best on your journey with C++. 
It's because you don't tell the compiler to convert foo to `tuple&lt;int,int&gt;` and there's no `operator=` for `tuple&lt;int,int&gt;&amp;&amp;` and `Foo&amp;`. If you [explicitly demand a conversion](http://ideone.com/xZo7fX), it works.
Right of course I could specify the type either with a static_cast or with a qualified template type. I was just wondering if there was a sneaky way of performing what I want without resorting to that.
A more basic question I've just come up with is: where is the executable code stored, and how does the code know where "itself" is? Are executables stored at a standard location in memory, and we rely on virtual memory to keep them apart? The location of the code for each function is fully defined at compile time? Or does the kernel put the executable wherever the kernel deems fit, and initializes the Program Counter (PC) register appropriately? This would mean that the code can't know, in advance, the address at which a particular function is stored and would have to calculate offsets relative to the PC (or some other, equivalent, mechanism). The former seems simpler, and maybe faster, but something like the latter is needed to make shared libraries work?
Yes. Yes, it’s interesting to people. Write a proposal (if there isn’t one already – I haven’t checked!) I think there’s eminent use for it, and I *suspect* that the proposed syntax is relatively unproblematic (but I might be mistaken). The `for (auto (a, b) : tuple_list)` form is particularly interesting, of course. For one thing, it would finally allow iterating over two containers simultaneously without resorting to indices (`for (auto (a, b) : zip(as, bs))`), over maps (example given by you) or over items with their indices (`for (auto (i, v) : enumerate(list))`), all similar to Python.
The problem here is, as you say, that `std::tie(a, b)` is of type `std::tuple&lt;int&amp;, int&amp;&gt;`, not `std::tuple&lt;int, int&gt;`, so the cast is never considered. However, you can fix this by templating your casting operator like so: struct Foo { int x, y; template&lt;typename T1, typename T2&gt; operator std::tuple&lt;T1, T2&gt;() { return std::tuple&lt;T1, T2&gt;(x, y); } }; And then this works: http://ideone.com/NvT7m6 EDIT: Having said that, I'm not 100% sure it's safe to return a tuple of references to member variables; it's possible that `std::tie(a, b) = Foo();` would be undefined since `Foo()` is a temporary. Then again, it shouldn't be destroyed until the end of the expression, by which time `a` and `b` will have already been assigned to. Sounds like a GotW problem to me...
Template metaprogramming is something like a macro, but you have to program it with a functional style. Many people thinks that it is the worst part of the language, but some people like it. http://www.stroustrup.com/bs_faq.html#metaprogramming http://stackoverflow.com/questions/21102154/why-doesnt-c-make-it-easier-to-make-compile-time-queries-on-types "Template metaprogramming, SFINAE tricks &amp; co. weren't actually designed to do this stuff. Template metaprogramming in C++ was moslty discovered. Templates started just as means to write type-generic code, more capabilities were added to cover corner cases (SFINAE was born to avoid compiler errors that could happen when unrelated templates were pulled in the same program), then some day someone discovered that the C++ templates provided a Turing-complete metalanguage that allowed to perform queries about types, carry out computations at compile time and the like. So, template metaprogramming in C++ is ugly to understand, ugly to write, ugly to debug, tragic to compile because it's mostly an abuse of stuff that was intended for other usages. Templates just happened to be so powerful, but none actually designed them for this. C++11 provides some library support to this usage (and some core language support as well), but that doesn't change the essence of the situation. Also, if you want my opinion, template metaprogramming is currently heavily abused; with it you can build monstrosities like Boost.Spirit, but you probably shouldn't. "
This is the correct answer. And furthermore in C++11 it's thread safe. In C++ it really is the only sensible way IMO to make a singleton (should you actually NEED one).
Make a casting operator to `tuple&lt;int&amp;, int&amp;&gt;` instead of `tuple&lt;int,int&gt;`. Then you'll probably need one for const references and one for rvalue-references.
I think the "C++ magic" in the comment is just referring to the singleton pattern rather than the use of placement new to construct the singleton over the array. The double array and placement new combination is probably just used to force the alignment of the memory.
#####&amp;#009; ######&amp;#009; ####&amp;#009; *Here's a bit from linked Wikipedia article about* [***Placement syntax***](http://en.wikipedia.org/wiki/Placement%20syntax) : --- &gt;In the C++ programming language, **placement syntax** allows programmers to explicitly specify the memory management of individual objects — i.e. their "placement" in memory. Normally, when an object is created dynamically, an allocation function is invoked in such a way that it will both allocate memory for the object, and initialize the object within the newly allocated memory. The placement syntax allows the programmer to supply additional arguments to the allocation function. A common use is to supply a pointer to a suitable region of storage where the object can be initialized, thus separating memory allocation from object construction.[citation needed] &gt; --- ^Interesting: [^V2 ^word ^order](http://en.wikipedia.org/wiki/V2_word_order) ^| [^New ^\(C++)](http://en.wikipedia.org/wiki/New_\(C%2B%2B\)) ^| [^Allocator ^\(C++)](http://en.wikipedia.org/wiki/Allocator_\(C%2B%2B\)) [^(about)](http://www.reddit.com/r/autowikibot/wiki/index) ^| *^(/u/vanhellion can reply with 'delete'. Will delete if comment's score is -1 or less.)* ^| ^[**Summon**](http://www.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/) ^| *^note: ^/u/allinonebot ^is ^an [^impostor](http://www.reddit.com/r/autowikibot/comments/1w9t4e/impostor_bot_uallinonebot_spamming_with_double/cezzfhc)*
Yes, more then just generic programming. Just follow the link to github there are some examples there: https://github.com/sabel83/metashell e.g. you can create a condition, with the following pattern, start metashell, and paste: template&lt;bool Condition, typename Then, typename Else&gt; struct if_c { typedef Then type; }; template&lt;typename Then, typename Else&gt; struct if_c&lt;false, Then, Else&gt; { typedef Else type; }; if_c&lt;true, int, char&gt;::type if_c&lt;false, int, char&gt;::type And you can wrap the true, and false values to template&lt;bool BoolValue&gt; struct bool_ { typedef bool_ type; static const bool value = BoolValue; typedef bool value_type; }; typedef bool_&lt;true&gt; true_; typedef bool_&lt;false&gt; false_; With the help of these you can create a if_ template where the "expression" start evaluating with ::type So a meta program start with ::type
This is a really good question and taught me something I didn't know about C++ -- placement new (per [vanhellion's comment](http://www.reddit.com/r/cpp/comments/1w7tkg/whats_the_point_of_this_c_magic_in_hoard/cf04py7)). Thank you for asking this! The discussion about alignment, etc. makes me curious though if this really has significant benefits over whatever the compiler will optimize for?
Yup this was it. So simple! For some reason, I didn't think to use the `tuple` constructor itself. The `make_tuple` function obviously doesn't know how to deal with references so a fully qualified tuple is the way to go. Edit: I see your edit and that was my initial concern too. I ran a few test cases and things seemed to work fine although I'm not sure the behavior is defined. If anybody else has information, feel free to shed some light.
For your edit, I have to say I'm not sure what the lifetime of objects is when both the LHS and RHS are temporaries like that. But a simple block would obviously avoid the issue { Foo foo; std::tie(a,b) = foo; } by forcing foo to exist before and after the object used by std::tie. Though to get back to the original issue of lifetimes, it'd be trivial to create two classes with destructors that print out a statement and see what happens when you have a call like that. My *guess* is that your above line is essentially a call to std::tuple&lt;int&amp;,int&amp;&gt;&amp; std::tuple&lt;int&amp;,int&amp;&gt;::operator=(const std::tuple&lt;int&amp;,int&amp;&gt;&amp;) so the LHS and RHS have to exist through the entire assignment, and it merely discards the reference returned since it is not being fed into a copy/move constructor. (It may be a call to std::tuple&lt;int&amp;,int&amp;&gt;&amp; std::tuple&lt;int&amp;,int&amp;&gt;::operator=(std::tuple&lt;int&amp;,int&amp;&gt;&amp;&amp;) though. I'm not sure if this is correct syntax, I haven't used rvalue refs much but the fact there's a call to Foo(), a temporary, in the idea suggests that they may be invoked.)
I don't think it helps the perception of the C++ community much to put C++ on a pedestal and downplay javascript. It comes off as elitist. C++ is certainly designed with much more rigor than a language like javascript which was initially never intended to scale to a codebase larger than a few hundred lines. That said, I think constructive criticism (like what STL did) is more in order than generalist criticism. If you don't have a specific thing to point out, it's better to not say anything as opposed to a blanket statement that the article isn't sophisticated enough. C++ is an intimidating language to say the least, and there is a need for high quality tutorial oriented material (currently completely missing).
The object feature looks great so far! I don't know how much work it would be (as I haven't worked with the raw Lua API before), but will you add a feature for declaring classes, so that you can instantiate them in Lua (with Lua lifetime) and derive from them in Lua? I think I'm going to use Selene for my current project.
It could be similar to how your object registration looks; I'll try to make an example in pseudo code: state["ClassName"].SetClass&lt;ClassToExpose&gt;( void(*)(void), //constructor here void(*)(double),//maybe overloaded constructor with variadic template magic? "doFunc", &amp;ClassToExpose::foFunc //methods like in SetObj ); *(I don't know if it would be necessary to specify a constructor at all, or if that could be handled behind the scenes.)* The created variable[or table?] would merely be a function that creates an object with Lua managed lifetime. Instantiaton in Lua could then look just like `local c = ClassName()`. You're right about the inheritance topic. It's just something that would be good to be left possible, because LuaBridge, that uses a somewhat similar class mechanic as above, does explicitly not support Lua classes deriving from C++ classes. I don't know about about the possibilities in this respect though. (On another note, do you plan to add some sort of container type to Lua table conversion? I don't know if all this fits into the scope of the project though!)
Well, you'd have to specify a constructor because of construction overloading. Then there's copy and move construction to worry about. There's no way to infer which constructor is the one you want to expose, or how to expose it. A lua object, as far as C++ is concerned, is just a bunch of functions stored in a table. You can manually construct such a table and then instantiate from it in Lua as you like.
typeclasses/concepts are the one feature i've been really looking forward to.. Is this the RNG paper you mentioned? http://open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3847.pdf If so the random number generators are great as is, you can create a simple wrapper class to solve all aforementioned problems. I really like the flexibility it gives you and I use this current feature heavily 
I can't speak for this code, but if you're writing an allocator that might be used to allocate data accessed by SSE instructions you must align on 16 byte boundaries otherwise your program will crash after you try to load an unaligned address.
#####&amp;#009; ######&amp;#009; ####&amp;#009; *Here's a bit from linked Wikipedia article about* [***Position independent code***](http://en.wikipedia.org/wiki/Position%20independent%20code) : --- &gt;In computing, **position-independent code** (**PIC**) or **position-independent executable** (**PIE**) is a body of machine code that, being placed somewhere in the primary memory, executes properly regardless of its absolute address. PIC is commonly used for shared libraries, so that the same library code can be loaded in a location in each program address space where it will not overlap any other uses of memory (for example, other shared libraries). PIC was also used on older computer systems lacking an MMU, so that the operating system could keep applications away from each other even within the single address space of an MMU-less system. &gt; --- ^Interesting: [^Position-independent ^code](http://en.wikipedia.org/wiki/Position-independent_code) ^| [^X86](http://en.wikipedia.org/wiki/X86) ^| [^X86-64](http://en.wikipedia.org/wiki/X86-64) ^| [^PaX](http://en.wikipedia.org/wiki/PaX) ^| [^Code ^segment](http://en.wikipedia.org/wiki/Memory_segmentation) [^(about)](http://www.reddit.com/r/autowikibot/wiki/index) ^| *^(/u/gidoca can reply with 'delete'. Will delete if comment's score is -1 or less.)* ^| ^[Summon](http://www.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Well, now we are getting into the real world and vendor non-standard compliance. :)
That would be great, but I haven't the foggiest how to even start writing a proposal. This is another reason why I wanted to start a discussion. As for your second point, the similarity to Python is not coincidental!
 cout &lt;&lt; year"\t" &lt;&lt; Forested"\n"; is invalid syntax. You can't have a variable and a string literal next to each other like that; there's no operator implied in that statement. Note that with string literals you can have cout &lt;&lt; "Hello " "World" &lt;&lt; endl; What you want is cout &lt;&lt; year &lt;&lt; "\t" &lt;&lt; Forested &lt;&lt; "\n"; // Prefer std::endl to "\n" Also your code has *huge* problems. The least of which is that it will not at all do what you want, but will print out a ton of repetitive garbage. And that's only on the condition it prints *anything* at all due to buffer flushing. Also, it's standard practice in C++ to initialize variables with a value if they have one. Prefer, for example, float Forested = 2500.0F; to float Forested; Forested = 2500; // Technically an int to float conversion here Lastly, year should be an int not a float and the expression year++ returns a copy of the previous year. You would prefer ++year to (year++) -- the parenthesis are completely unnecessary here. Don't mean to be a dick, I know you just started, but getting these things straight help you understand exactly what each line does rather than just saying "Well, this does work so I can use it."
You can't really Google syntax errors - you have to work through the syntax yourself. &gt; cout &lt;&lt; year"\t" &lt;&lt; Forested"\n"; When using cout like this, all identifiers must be separated by &lt;&lt;. This includes both variables and string literals. The correct line might then be cout &lt;&lt; year &lt;&lt; "\t" &lt;&lt; Forested &lt;&lt; "\n";
Thought you'd be interested in https://github.com/jeremyong/Selene/issues/12
thank you everyone 
are you unit testing functions with random inputs or the classes for generating the random numbers?
no shame in making sure :)
I forgot to mention, if you write `void woof(const char s[])`, something special happens. Arrays taken by value (of known or unknown bounds) are immediately rewritten to pointers; this rewriting is so immediate, sizeof and decltype observe a pointer. This rule goes back to C (and additionally applies to functions taken by value, although nobody ever exercises that one in practice), and is widely considered poor form to declare. That said, const char [] and const char * are still distinct types, as observed everywhere else but function parameters.
a) Im a huge fan but I dont always agree with you :) ( see b) :) ) b) I write asymptotically bad code but I put assert(something like cont.size()&lt;5000) in code. Example: I needed to write a simple functionality: you can add and remove elements from a list, and every x seconds do something with n elements(going circularly around the list, not randomly) and I used a set + slow circular current_idx(if I skip item or do it 2 times in a row it is not a big problem, so no big problem that current_idx gets invalidated(shifted) on inserts or del) that was doing linear advance from begin it every time I needed to get next batch. I could have prob thought of a better alg but I didnt want to bother... It would be super irritating to remember current it and then make sure to update it to correct value when I do remove... new current is current +1 unless that would make it be .end(), then it is .begin(), but only if size() after removal is &gt;0 , if not then it is .end() ... :) Also recently in some code(that I did not write) I saw a algorithmically slow implementation of set_diff on 2 vectors (A= A - B)but sizes are small, and STL set_diff cant be done inplace(so you need new temp container), so STL code would be maybe even less readable to noobs than manual for loop...(I am &lt;algorithm&gt; nazi but being realistic here :) ) 
cppreference has clickable links :) faster than ctrl+f + enter n times...
I just want to point out that I am current looking at some template code that is used in radiotherapy and radio surgery that is used to fight cancer so your first statement isn't 100 percent true :P
Wat 
uh... a [compiler](http://en.wikipedia.org/wiki/Compiler)?
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Compiler**](http://en.wikipedia.org/wiki/Compiler): --- &gt; &gt;A **compiler** is a [computer program](http://en.wikipedia.org/wiki/Computer_program) (or set of programs) that transforms [source code](http://en.wikipedia.org/wiki/Source_code) written in a [programming language](http://en.wikipedia.org/wiki/Programming_language) (the source language) into another computer language (the target language, often having a binary form known as [object code](http://en.wikipedia.org/wiki/Object_code)). The most common reason for wanting to transform source code is to create an [executable](http://en.wikipedia.org/wiki/Executable) program. &gt;The name "compiler" is primarily used for programs that translate source code from a [high-level programming language](http://en.wikipedia.org/wiki/High-level_programming_language) to a lower level language (e.g., [assembly language](http://en.wikipedia.org/wiki/Assembly_language) or [machine code](http://en.wikipedia.org/wiki/Machine_code)). If the compiled program can run on a computer whose [CPU](http://en.wikipedia.org/wiki/CPU) or [operating system](http://en.wikipedia.org/wiki/Operating_system) is different from the one on which the compiler runs, the compiler is known as a [cross-compiler](http://en.wikipedia.org/wiki/Cross-compiler). A program that translates from a low level language to a higher level one is a [decompiler](http://en.wikipedia.org/wiki/Decompiler). A program that translates between high-level languages is usually called a [language translator](http://en.wikipedia.org/wiki/Translator_(computing\)), source to source translator, or language converter. A language [rewriter](http://en.wikipedia.org/wiki/Rewriting) is usually a program that translates the form of expressions without a change of language. &gt;A compiler is likely to perform many or all of the following operations: [lexical analysis](http://en.wikipedia.org/wiki/Lexical_analysis), [preprocessing](http://en.wikipedia.org/wiki/Preprocessing), [parsing](http://en.wikipedia.org/wiki/Parsing), semantic analysis ([Syntax-directed translation](http://en.wikipedia.org/wiki/Syntax-directed_translation)), [code generation](http://en.wikipedia.org/wiki/Code_generation_(compiler\)), and [code optimization](http://en.wikipedia.org/wiki/Code_optimization). &gt;==== &gt;[**Image**](http://i.imgur.com/pSMft9p.png) [^(i)](http://commons.wikimedia.org/wiki/File:Compiler.svg) - *A diagram of the operation of a typical multi-language, multi-target compiler* --- ^Interesting: [^Optimizing ^compiler](http://en.wikipedia.org/wiki/Optimizing_compiler) ^| [^Compilation ^album](http://en.wikipedia.org/wiki/Compilation_album) ^| [^Java ^compiler](http://en.wikipedia.org/wiki/Java_compiler) ^| [^Just-in-time ^compilation](http://en.wikipedia.org/wiki/Just-in-time_compilation) *^\/u/kraken_calamari ^can ^reply ^with ^'delete'. ^Will ^delete ^on ^comment ^score ^of ^-1 ^or ^less.* ^| [^(FAQs)](http://www.reddit.com/r/autowikibot/wiki/index) ^| [^Magic ^Words](http://www.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/) ^| [^flag ^a ^glitch](http://www.reddit.com/message/compose?to=/r/autowikibot&amp;subject=Glitched comment report&amp;message=Here's what's wrong: &lt;description \(optional\)&gt;%0A%0A---%0A%0AReply no. 35290:%0Ahttp://www.reddit.com/r/cpp/comments/1wh0ch/how_are_the_c_files_used_to_make_browsers_like/cf1vfoy)
Your question is rather muddled. The file you linked to is from Mozilla, not Chromium. And it has nothing to do with graphical interfaces, it's only concerned with string parsing. In general, a browser is an extremely complicated program, consisting of millions of lines of C++. Firefox and Chromium use GTK+ on Linux (which is as close as you can get to "native" there), and the native windowing APIs on Windows and OS X (Win32 and Cocoa, respectively.) In principle it would be possible to use a single toolkit across all platforms like Qt, but for something as large and complex as a browser, you'd probably be pushing the limits of cross-platform toolkit, which is why they go native. 
Stupid question: What is concurrency? OK, I did some courses on parallel processing, using a cluster of (heterogenous) machines that communicate with each other over a network ([MPI](http://en.wikipedia.org/wiki/Message_Passing_Interface)) to solve a problem. So that's "parallel computation" - I'm very comfortable with that, but I don't know much about other approaches. I also know what threads are. Multiple threads executing at the same time (or time-sliced aggressively), and running in the same memory space. And each thread will have its own stack. Threading can work on a machine with a single processor; there is no requirement that the operations from different threads occur at exactly the same time. Is 'threading' the same as 'concurrency'? If not, what is 'concurrency'? That link mentions SIMD instructions. That makes me think that 'concurrency' is simply 'real multitasking', where dedicated hardware really can do multiple operations at the same time. This makes me think that 'concurrency' is just a low level thing, but that doesn't feel right either. We have all this talk of `future`s and promises, which are high-level topics. What's the relationship between threading and concurrency? And, more broadly, I think we're missing something in terms on non-linear computation. Where do 'coroutines' fit in? Personally, I don't like the ad-hoc nature of the event loop in graphics libraries - I feel there should be a more consistent approach to cover all these 'event-driven', 'non-linear' approaches to flow control.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Message Passing Interface**](http://en.wikipedia.org/wiki/Message%20Passing%20Interface): --- &gt;**Message Passing Interface** (**MPI**) is a standardized and portable [message-passing](http://en.wikipedia.org/wiki/Message-passing) system designed by a group of researchers from academia and industry to function on a wide variety of parallel computers. The standard defines the syntax and semantics of a core of library routines useful to a wide range of users writing portable message-passing programs in [Fortran](http://en.wikipedia.org/wiki/Fortran) or the [C programming language](http://en.wikipedia.org/wiki/C_(programming_language\)). There are several well-tested and efficient implementations of MPI, including some that are free or in the public domain. These fostered the development of a parallel software industry, and there encouraged development of portable and scalable large-scale parallel applications. &gt; --- ^Interesting: [^Open ^MPI](http://en.wikipedia.org/wiki/Open_MPI) ^| [^Supercomputer](http://en.wikipedia.org/wiki/Supercomputer) ^| [^Microsoft ^Messaging ^Passing ^Interface](http://en.wikipedia.org/wiki/Microsoft_Messaging_Passing_Interface) ^| [^OpenMP](http://en.wikipedia.org/wiki/OpenMP) *^\/u/SkepticalEmpiricist ^can ^reply ^with ^'delete'. ^Will ^delete ^on ^comment ^score ^of ^-1 ^or ^less.* ^| [^(FAQs)](http://www.reddit.com/r/autowikibot/wiki/index) ^| [^Magic ^Words](http://www.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/) ^| [^flag ^a ^glitch](http://www.reddit.com/message/compose?to=/r/autowikibot&amp;subject=Glitched comment report&amp;message=Here's what's wrong: &lt;description \(optional\)&gt;%0A%0A---%0A%0AReply no. 35479:%0Ahttp://www.reddit.com/r/cpp/comments/1wgt5k/c_papers_for_issaquah_concurrency/cf1zubb)
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Concurrency (computer science)**](http://en.wikipedia.org/wiki/Concurrency%20%28computer%20science%29): --- &gt;In [computer science](http://en.wikipedia.org/wiki/Computer_science), **concurrency** is a property of systems in which several [computations](http://en.wikipedia.org/wiki/Computation) are [executing](http://en.wikipedia.org/wiki/Execution_(computing\)) simultaneously, and potentially interacting with each other. The computations may be executing on multiple [cores](http://en.wikipedia.org/wiki/Multi-core) in the same [chip](http://en.wikipedia.org/wiki/Computer_chip), [preemptively time-shared](http://en.wikipedia.org/wiki/Preemption_(computing\)) [threads](http://en.wikipedia.org/wiki/Thread_(computer_science\)) on the same processor, or executed on physically separated processors. A number of mathematical models have been developed for general concurrent computation including [Petri nets](http://en.wikipedia.org/wiki/Petri_nets), [process calculi](http://en.wikipedia.org/wiki/Process_calculi), the [Parallel Random Access Machine](http://en.wikipedia.org/wiki/Parallel_Random_Access_Machine) model, the [Actor model](http://en.wikipedia.org/wiki/Actor_model) and the [Reo Coordination Language](http://en.wikipedia.org/wiki/Reo_Coordination_Language). &gt;==== &gt;[**Image**](http://i.imgur.com/aEFQnMp.png) [^(i)](http://commons.wikimedia.org/wiki/File:Dining_philosophers.png) - *The "Dining Philosophers", a classic problem involving concurrency and shared resources* --- ^Interesting: [^Computer ^science](http://en.wikipedia.org/wiki/Computer_science) ^| [^Actor ^model](http://en.wikipedia.org/wiki/Actor_model) ^| [^Concurrency ^semantics](http://en.wikipedia.org/wiki/Concurrency_semantics) ^| [^Distributed ^computing](http://en.wikipedia.org/wiki/Distributed_computing) *^\/u/meetingcpp ^can ^reply ^with ^'delete'. ^Will ^delete ^on ^comment ^score ^of ^-1 ^or ^less.* ^| [^(FAQs)](http://www.reddit.com/r/autowikibot/wiki/index) ^| [^Magic ^Words](http://www.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/) ^| [^flag ^a ^glitch](http://www.reddit.com/message/compose?to=/r/autowikibot&amp;subject=Glitched comment report&amp;message=Here's what's wrong: &lt;description \(optional\)&gt;%0A%0A---%0A%0AReply no. 35515:%0Ahttp://www.reddit.com/r/cpp/comments/1wgt5k/c_papers_for_issaquah_concurrency/cf20kgf)
It's not a stupid question. It's something I'm fairly sure I had wrapped my head around at one point, but have now forgot a few of the subtle points. I'm going to ignore that you mentioned specifically threading, and focus just on concurrency vs. parallelism. Here are a few resources: * [Rob Pike: Concurrency Is Not Parallelism (video and slides)](http://blog.golang.org/concurrency-is-not-parallelism) * [Stack Overflow response to a question about the above video] (https://stackoverflow.com/questions/11700953/concurrency-is-not-parallelism#11701186) * [Similar to the above, but on Programmers stack exchange](https://programmers.stackexchange.com/questions/155109/parallelism-implies-concurrency-but-not-the-other-way-round-right#155110) * [Robert Harper: Parallelism is not concurrency](https://existentialtype.wordpress.com/2011/03/17/parallelism-is-not-concurrency/) * [Simon Marlowe: Parallelism /= Concurrency](http://ghcmutterings.wordpress.com/2009/10/06/parallelism-concurrency/) The last link there is linked to from the Robert Harper page, but I included it anyway. From the Robert Harper link: &gt; The first thing to understand is parallelism has nothing to do with concurrency. Concurrency is concerned with nondeterministic composition of programs (or their components). Parallelism is concerned with asymptotic efficiency of programs with deterministic behavior.
I've detected a hexadecimal color code in your comment. Please allow me to provide visual representation. [#155110](http://color.re/155110.png) *** [^^Learn ^^more ^^about ^^me](http://color.re) ^^| ^^Don't ^^want ^^me ^^replying ^^on ^^your ^^comments ^^again? ^^Respond ^^to ^^this ^^comment ^^with: ^^'colorcodebot ^^leave ^^me ^^alone' 
If you teach one person to fry eggs while reading a book, he's doing it concurrently because he still can only do one thing at a time. Concurrency has to do with "multitasking." If you get two people to fry eggs and read a book, this is parallelism as the two tasks are being worked on at the same time.
Concurrent tasks may in fact be executed simultaneously, not just with time sliced multitasking. The difference between concurrency and parallelism is in which aspect of the relationship between multiple tasks is being referenced. The term concurrency references how tasks communicate or interact, whether or not the tasks execute with physical simultaneity. E.g. mutexes and concurrent message queues are tools for concurrency. Parallelism instead refers to the execution of the tasks without regard for how, or even if, they communicate. E.g. multi-core CPUs and beowulf clusters can execute tasks in parallel.
You likely didn't mean for it to be, but your answer comes across as really condescending.
But it would cause a race condition if another static performed an allocation and didn't free the memory until it was destroyed. 
Thats great; I just happened to change a small memory allocator to work in a similar manner few weeks ago. The initial implementation constructed the allocator on first access but that didn't work if code tried to free an memory from a static destructor it as it resulted in a race between the heaps destruction and the other object. It felt like a massive kludge and I hate the intentional leak but couldn't think of a better solution without structural changes which weren't practical. 
How so? A trivial destructor means that no code is run for destruction. For all ordering purposes, it's destroyed last and atomically, when the executable is unloaded and all other destructors have been run.
How do I guarantee it is the absolute last destructor run though? Static object B constructs Static object A allocates memory, causing the heap to be constructed. Static object shares a reference to the allocates memory with B. ... A goes out of scope. Heap goes out of scope. B goes out of scope, releasing the last reference to the allocated object. At that point, B tries to return the memory to the heap which was already destroyed. Yes, we could have the destructor of the heap not do anything so using the 'invalid' static object may be 'safe' (in the undefined sense).. Via compiler extensions, it may be possible to construct the heap earlier (ie construct the static during lib static construction rather than user) but its still difficult to guarantee it will be unused during static destruction unwinding. Of course, the best solution would be to get rid of statics, particularly those with destructors which release memory or have other dependencies. I'd love to do that but it isn't practical when dealing with a few million lines of code, middleware using the allocator, etc.
We're talking about globals. Global memory deallocation can only happen after all code dealing with it has run, that's why it "happens last". The trivial destructor does nothing, so the object isn't invalidated before its memory is unloaded, and at this point it's safe to say that it happened last and atomically with all the rest of the memory. **MAJOR EDIT** K, looks like HoardHeapType has members with non-trivial destructors, so none of this applies.
afaik that causes universe to implode because http://stackoverflow.com/a/11176568/700825
A concrete example, mutexes limit concurrency since threads are serialized through a piece of code that is guarded by a mutex. That is only the thread owning the mutex is allowed to execute the guarded (critical) code, all other threads must wait for it to unlock. AFter it unlocks only **one** of the waiting threads can acquire the mutex and progress. To maximize concurrency you try to limit the critical code to be as short as possible, as to reduce the serialization.
+/u/goldcointip 20 gld
+/u/goldcointip 20 gld
+/u/goldcointip 20 gld
Another alternative without copying: auto ret = foo(); auto&amp; a = get&lt;0&gt;(ret); auto&amp; b = get&lt;1&gt;(ret); But it seems that proper tuple support on a core language level would be neat.
why this is in this subredit? am I missing something?
Look at stdlib function rand() Edit: here you go http://www.cplusplus.com/reference/cstdlib/rand/ Edit2: To fill the array, just loop over it in a for statement and use rand function as shown in the sample. 
[Do not use `rand`.]( http://channel9.msdn.com/Events/GoingNative/2013/rand-Considered-Harmful) Seriously, why are you giving bad advice?
For the scope of such a beginning project I think using rand() will be fine... K. I. S. S. 
I'm assuming a person asking how to fill an array with random numbers on reddit won't be using it for professional cryptographic purposes, and will be fine with a slight disproportionate distribution of probability. For a more in-depth discussion, please refer to [this post](http://www.reddit.com/r/programming/comments/1rnudl/quite_interesting_why_cs_rand_is_considered/) Edit: Also see discussion [here](http://stackoverflow.com/questions/18726102/what-difference-between-rand-and-random-functions) and refer [here](http://c-faq.com/lib/randrange.html) for a breakdown of rand()'s caveats and their solutions.
How is using `rand` keeping it simple? `rand`'s behaviour isn't well-specified. What's its range? You can't rely on that, since it's not specified exactly. It's between 0 and `RAND_MAX`, but that isn't useful when prescribing exactly which values are and aren't valid for your program. So what do you do? Use a bunch of hacky and incorrect techniques to change the range? Reimplement the proper techniques used behind-the-scenes of the `random` header? You've already thrown your supposed simplicity advantage out the window. So what **is** the simplicity advantage? That you don't have to instantiate 1-2 objects (a generator and optionally a distribution)? And for those 1-2 lines of code you're willing to suggest use of an old, fundamentally broken interface?
Have found ~~[ClangFormat](http://clang.llvm.org/docs/ClangFormat.html)~~ and [Vera++](https://bitbucket.org/verateam/vera/wiki/Home) to be promising. EDIT: ClangFormat is not flexible enough and some properties such as AllowShortFunctionsOnASingleLine do not work.
&gt;namespace A { namespace B { namespace C { But why?
You want to minify your C++ code?
That is our code style. Nothing more to say is there?
What do you mean 'minify'? Make smaller? That is not the goal, I just want to format it a particular way.
There's usually a reason why though
And a lot less readable.
Perfectly readable to me. Each to their own I guess.
I saw your comment about spacing and it seemed like it.
Which comment? If anything, I want more spacing. A lot of our code is something like a==b whereas I'd prefer a == b 
Yes definitely. Having looked at a few options, I'm coming to the conclusion to combine say clang-format and maybe astyle and use the parts I need from both, then Perl to finish it off.
I don't know why you would say that performance, compile times or memory usage are easy to measure. We do a lot of that and it isn't easy. Getting a global number such as total amount of memory used by the application is easy, but getting meaningful data that you can act upon (which is what I consider measuring to be) is much harder. Where are the allocations coming from? Are your memory categories correctly split? Why are memory allocations slowing down? (and in turn, why is this pool fragmenting so much?) Etc. Same goes for performance. Easy to capture the average frame rate of game. Harder to capture the spikes or what causes them. What about profiling load times? I have had warnings set to the highest level and warnings-as-errors on most games I've worked on (for each of the 3 compilers we use), and while I could list you a few warnings that I think are actually crucial, many of them are meh. If you care about that sort of thing, something like lint will give you better mileage. There are many things that influence code quality and readability *much more* than paying attention to warnings. On the top of my list would be writing less code. And if you want people to be able to afford higher churn, unit and functional tests (to a certain degree) will help much more. Cheers. 
C (and C++) only require the decimal digits to have contiguous, in-order code points. The English small letters don't have to have that requirement. In ASCII and its super-sets, 'a' through 'z' have contiguous and in-order code points, but it's not true for ASCII rival, EBSDIC (I think).
Oh I didn't know this. Now my lovely alphabet example is horrifically non-portable! If anyone else is interested, the relevant bit of the standard which guarantees the decimal ordering but omits letters is in 2.3.3: &gt;the value of each character after 0 in the above list of decimal digits shall be one greater than the value of the previous
As much as I love Wikipedia, it's just useless in some cases. I did look at it. Anyway, I think we need one, very general, term to cover all of this stuff. Let's say it's "X". "X" includes parallel processing, where developers manually communicate over an explicit networking protocol such as MPI. It also includes conventional (preemptive threads) thread-based computation using locks and semaphores. (And that funky transactional memory stuff I don't understand yet). I would also include both preemptive and non-preemptive (cooperative) multithreading. I'm not entirely sure what coroutines are, but I'll include them; I'm quite confortable with Python generators, and they're included. Finally, I would even be tempted to include lazy computation; where execution is delayed until the consumer demands a result, without requiring anything that looks like threads (or any other 'fancy' technology). I guess this final inclusion is a step too far - lazy computation is very easy to do. So maybe it should be kept out of "X". Anyway, is "X" the same as "concurrency"? If not, am I correct to assume that concurrency is a subset of "X"? If so, which subset?
Well, the subgroup is named Concurrency. So that's why I named the blogpost that way. Next up will be Concepts, Core and Evolution.
Dammit, not a single one (in Germany at least) is on a weekend :/
Weekend is always hard to get a place and a lot of people are busy with family. Afaik only the meeting in russia is on the weekend.
Does anyone know whether there are ever any meetings in the Washington DC area? Thanks!
You're assuming that he needs a big range and perfect uniformity. From the OP, it looked a lot like he was a new coder(either to c++ or to coding in general). Using rand() is far easier and simpler then the random header, provided he won't use it for a work that doesn't need perfect precision and/or safety. As someone who has started coding not that long ago(circa 3 years), I know how discouraging it can be to run into some weird, hard to implement and hard to understand code while trying to do something simple. rand()%N is simple, elegant, and good enough for most purposes. That aside, there are a lot of online judges and crappy old school computers with outdated compilers that do not use c++11, so for school purposes, he better know rand() as well. I'm not saying rand() is perfect. It's not. And the random header is awesome. But for most purposes, using rand() can be faster, simpler and/or more useful.
&gt;he can concentrate more on the overall design of his solution, rather than the details of his code. And the "*overall design of his solution*" will be "*old school C*". Which language's subreddit is this again?
I should really start one in Karlsruhe, but if I do the planing it will most likely end in total chaos. :-(
&gt;rand()%N is simple, elegant, and good enough for most purposes. It's not simple or elegant. It's the worst kind of complicated -- it **appears simple but is horribly broken**. I.e. it is the **exact opposite** of what you want to expose a beginner to. A beginner has enough to worry about without being force fed **wrong and dangerous** habits. Besides which, even if I accept your explanation -- that it was/is okay because in the use case the shortcoming of `rand` probably don't matter -- you didn't provide an qualification. If you'd been the only one to reply, what impression would the OP have left with regarding `rand`? Did you point out that it's not suitable for real world applications? Let's just tell him to use `sprintf` while we're at it. I mean buffer overflows are no big deal right, I'm sure he'll make a buffer big enough for whatever he's doing? Besides `snprintf` or `std::stringstream` will just addle his poor mind with complexity.
You're right about the second paragraph, I should have warned him of its shortcomings, and I'll edit that post when I get the chance to provide a proper comparison of the two. But otherwise, I maintain that rand is good enough for most purposes. 
Are people from the Frankfurt Main area interested?
Heidelberg is in the Pipeline...
Not much to do. There has been already a discussion for Karlsruhe, with the KIT it should be easy to launch: https://www.xing.com/net/prid507fdx/moderncpp/lokale-treffen-713621/c-ug-karlsruhe-43586382/
Would totally attend one in Phoenix.
Isn't this just what called *hygienic macro*? I don't know why the author is trying to re-explain well known concepts.
Good to know.
In general, yes, it is good practice. Internally the vector/map will allocate heap memory as needed. However you are going to run into problems if you are setting up a vector/map of a base class type, and trying to add derived type instances to it. (I'm not entirely sure from your post if this is your scenario.) In that case you'd probably want to set up a vector/map of std::unique_ptr&lt;BaseType&gt;, create unique_ptr's that hold the various derived type instances as needed, and move them into the vector/map. (assuming C++11)
oh no, that is not my scenario, and I want to avoid getting there :)
Implicit move is exactly the reason why `auto_ptr` sucked. Understandably they removed the implicit part for `unique_ptr`.
Can you give us an example of what you mean. Regardless using new and raw pointers is generally considered bad practice. 
If not C++11, boost::ptr_vector http://www.boost.org/doc/libs/1_55_0/libs/ptr_container/doc/ptr_vector.html
What exactly happens at these meetings?
Personally I prefer to keep it in XML form and just query the XML objects for information, rather than build and maintain a mapping to custom objects. That aside, some things to consider: 1) vectors are single chunks of memory. If adding an item to the vector needs more space, you have to reallocate the *entire* block of memory, and copy over everything already added before freeing the original block. This can happen multiple times as you're building your vector, so if you are able to glean information about how big the vector will be beforehand, it can be a significant speed improvement to pre-allocate the memory in the vector. 2) Related to the above, if you really don't know how big your vectors are going to be, it may not be the data set for you. Do you need constant time access to a particular index inside the vector? If not, a list, set, or map may be more appropriate. On the other hand, vectors can be faster to iterate through than the previously mentioned data structures due t caching, so if you really care about the time it takes to iterate through each item in the container without needing to worry about some overhead when constructing the containers, vector may be the way to go. If you're use case is more often 'search for object in the container, use that object', set, map, or their unordered counterparts can be *significantly* faster than a vector. 3) Why are you debating between vector vs map, instead of vector vs set?
In general it can be said that using naked new in C++ is often very poor practice and the keyword should be avoided like goto (aka: use it when needed, but be aware of the problems). Using stdlib-containers on the other hand is usually the way to go. I am not sure about your use-case, but probably it's ok.
It can be good practice. It can be the wrong tool for the job. Depends on the situation. This is the correct answer for most vague programming questions, and the proper way to think about your options. Always consider the situation.
actually thinking about this I dont like it: if you wanna fix rb for loop: then this is imho optimal: for( &amp; elem:cont) for( &amp;&amp; elem:cont) for ( elem: cont) with const variants ofc for(const &amp; elem:cont) aka just remove the auto, please dont make it you need auto in n-1 cases, in 1 case blank means auto&amp;&amp;
If you can, just supply an rvalue (in the form of a nameless temp or function call): my_vector.push_back(Type(args)); my_vector.push_back(make_type(args)); These things are rvalues, and will be moved automatically by my_vector (provided that Type has move construction).
That would defeat the purpose - the easiest (i.e. least syntax) variant *must not copy*.
For your run-of-the-mill code, vectors should completely replace dynamic sized arrays ("new"). There are a number of scenarios where they're not a good option, but it's usually quite obvious; if it matters, you'll know. Maps, however, are something quite different. They serve a specific purpose. The words "std::map/vector" worry me, because they're hardly similar in use or purpose.
Works for me: $ clang++-3.4 --version clang version 3.4 Target: x86_64-apple-darwin13.0.0 Thread model: posix $ cat test.cpp #include &lt;iostream&gt; #include &lt;memory&gt; template&lt;typename T&gt; constexpr T pi = T(3.1415926535897932385); int main() { auto f = [](auto x){ return x; }; std::unique_ptr&lt;int&gt; p{ new int(5) }; auto plus_p = [p = std::move(p)](int x) -&gt; int { return *p; }; std::cout &lt;&lt; f("ran") &lt;&lt; std::endl; } $ clang++-3.4 -std=c++1y test.cpp -o test $ ./test ran The headers missing suggests that you didn't install libc++ and whoever built it didn't point it at the location of libstdc++ on your machine, so you'll need to do that manually.
I'm using clang 3.4, without any such problems (Though on Fedora, not Ubuntu). It's probable the PPA you found somewhere is just broken, and you might also be missing the proper libc++-dev package. 
Aha! Compiling with *-std=libc++* enabled the features I was missing, but it still fails to compile *&lt;cstdio&gt;* or *&lt;iostream&gt;*. Anyway, thanks.
Try wrapping it in #if __cplusplus &lt;= 201103L instead of commenting it out. 
gets() is removed in C11 which I believe is incorporated into c++14/1y. To fix, either manually update to a newer libc++ &amp; gcc/libstdc++, or edit cstdio. With libc++: #if _LIBCPP_STD_VER &lt;= 11 using ::gets; #endif Not sure of the equivalent gcc/libstdc++ macro.
Maybe I'm not fully aware of those differences, I just see std::vector as a python list() and a std::map as a python dict()...
3) A/ Maybe because I'm really new to C++! I'll search for information about set to know what my options are, thanks!
Pretty correct from a Python perspective, but the point of C++ is efficiency. Vectors are linear, sequential storage containers. Maps are self-organizing search trees. How you use data structures is where performance is focused. Adding something to a map takes O(log n) time, whereas adding something to a vector takes O(1). Python is a fantastic language in terms of usability and ease of creating working code, but it doesn't teach you much about algorithm efficiency. The way you mentioned both structures in your title made me cringe because I interpreted it as if you used them similarly.
I wish people would file bugs instead of blog posts. We've got an active bug about `bind()` consuming more space than necessary, and `function` storing empty allocators. A couple of weeks ago, I noticed and fixed the other bug partially mentioned here. We thought we were reserving 3 `void *`s worth of space (i.e. 12 bytes on x86), with one invisibly consumed by the vptr (and another invisibly consumed by the allocator that shouldn't be there). In fact, due to the maximum 8-byte alignment that we have to mark the space with (since we don't know how aligned the user functor is, we have to use `max_align_t`), we were really consuming 16 bytes on x86. Fortunately, we were actually using all of those 16 bytes, but this wasn't really intentional. I've overhauled this in my local changes - now we won't be confused by alignment, and I am increasing the reserved size. My target (suggested by James McNellis, our CRT maintainer) is that `function` should be able to store a functor containing a `string` (which is significantly larger than our current space). Fixing the unnecessary allocator and the `bind()` bloat is still on my list of things to do (note that lambdas supersede `bind()`, especially C++14 generic lambdas).
Nope, sorry. Even within MS, our TFS database requires DevDiv Work Items permissions which are not automatically granted to employees outside DevDiv (e.g. someone in Windows or Office would have to manually request access). I don't blog about our active bugs, partially because my bosses and boss-like entities would frown, but also because I could spend that time actually fixing bugs. For example, I finally got an uninterrupted week to fix the Dreaded Facet Allocation Mismatch Bug that had been around since 2006. Overhauling the clocks and &lt;functional&gt; is next on my list.
&gt; I wish people would file bugs instead of blog posts. It's in one's professional interest to make a blog post like this, though. It showcases some knowledge.
Fair enough - I wish people would file bugs *and* blog posts.
Oh cool, you're on the VS CRT team I take it?
That's quite a coincidence!
The STL licensing and originating codebase maybe unusual, but other than that I don't think it's weird writing standard libraries at all since the position makes sense. I remember watching a Channel 9 video a while back and someone that worked on STL was the person being interviewed. They claimed it was unusual but I don't see anything wrong, maybe I'm just not seeing the the weirdness in it. Thanks for all those links, I love the microsoft dev blogs, it's interesting to know what's going on in the company.
Being an STL dev isn't unusual (although there are at most a dozen of us in the world), but it's unusual to specialize in code review and bug fixing the way I do, for an actively evolving codebase.
Looking into it but loving the quote already about stack overflows ;) I did http://ds9a.nl/mtasker many moons ago so I know what you are talking about.
Neat, any reason why you avoided boost coroutine?
you should add an example with for:range since you support iterator, it's the way I remember python generator, without having to advance to the next yield.
This looks really nice to use! However, depending on boost makes it hugely less useful to me :( I'd love to see a version that only depended on C++11's standard lib.
Bug report: http://gcc.gnu.org/bugzilla/show_bug.cgi?id=57619
Mainly that I was working on this before it was released. Right now though I just find its source to be too complicated, and its documentation to under-par.
I used to have an anti-Boost bias as well, but I find that now that Boost has been split into many subprojects it is much easier to work with. You might want to reevaluate your opinion.
What's wrong with shared_ptr?
No need - in fact it would generate more work for me. DevDiv#490878 in our internal database tracks the allocator and bind issues, while I have a local fix for the alignment issue.
The first example shown should use `for-range`, since whether or not I can use the generator with existing C++ things is going to be one of the main things I care about (other things being how stable it is and what the overhead is like (some basic benchmarks would be nice to have)).
Thank you. Very nice bit of (hopefully soon unnecessary) information to have.
Ok, great. Thanks.
Yes that's what I meant. I read the other comments and noticed you show that in demo.cpp
Of course, you realize that it **cannot** be done only with the C++11's standard library, unless you are willing to replicate Boost.Context yourself which involves writing low-level assembly code ?
It's still hard to actually use just the subprojects - even though there's a tool to supposedly extract "just what you need" I still have yet to get out with less than hundreds of include files", even for the most trivial uses. 
You can't do generators without writing assembly code? Sorry, I don't see it - do you have some sort of argument for this point of view we could see and evaluate?
Impressive! I bemoan the use of exceptions to stop the generator, though I do understand that using an unwinder would be significantly more involved. If I may: - allow move assignment, so that the generators can be stored in STL containers - disallow `yield()` unless the object is `Yield&lt;void&gt;`, it's a pitfall your users will stumble in - in C++11 we gained `std::exception_ptr`, did you investigate using it to marshall an uncaught exception out of the generator ? (it would certainly be preferable to undefined behavior) - did you think about *yielding back* ? In essence, `O Yield&lt;I,O&gt;::yield(I)`, with `O = void` in general. It would be slightly unusual but Python 3.0 does support it I believe.
It is a quite unfortunate over-use of `std::move`. One of the reasons I am so interested in Rust is that C++ keeps accruing more and more sources of undefined behaviors as it goes, for example in C++11: - using `std::move` on a value and then doing anything else than destroying or assigning to that value is undefined behavior - a lambda capturing a reference to the stack is better not returned *below* the frame in which that reference lives, otherwise it's undefined behavior Of course I do understand that it's tough, and that are compilers are not smart enough to diagnose this... but I cannot help to wonder whether it's less a case of compilers not being smart enough and more a case of the type system not being good enough. Case in point, Rust's lifetime semantics and the linear typing analysis used by the borrow-checker/unique types.
I have tried a few times to get into Boost, but I always stumble at some point. I want the following: 1. A simple tool that. given a boost `#include` directive, copies all the relevant headers into my project. Ideally, this would download from the internet by default, or otherwise from a local repository if I already downloaded it. 2. A simple, and *effective*, mechanism to compile the bits of Boost that need to be compiled. If I put a project on github that includes Boost Filesystem, other users should need only `g++` and `make` and other standard tools. Nobody, neither me nor the users of my software, should have to go through the hell of compiling all that 'build-system' shit that Boost has. (Sorry, I really want to get into Boost, but it pisses me off every time.) 3. The simple tool that finds the relevant headers (mentioned at 1 above) should *itself* be easy to compile. In short, I want a short document that explains everything about getting Boost to work, *in particular* in the context of people who want to put complete self-contained pieces of software onto github.
It can't be done*. Here's the source code for where boost context actually implements context switching: https://github.com/boostorg/context/tree/master/src/asm *This is only sort-of a lie. There are a number of other options, but all of them are incredibly unpleasant. It's worth noting that it's true to the extent that it can't be done in portable, standards-conformant C++; there's simply no provision that I'm aware of for leaving a scope and coming back to it later. Even using `std::async` with `std::launch::deferred` won't let you pause a function in the middle of execution- it's just callback-passing. - [`makecontext`](http://linux.die.net/man/3/makecontext) and friends. This is essentially exactly the same as `boost::context`, but it's linux-only, has a more complicated API, and was removed in POSIX-2008. - I am considering trying them anyway, because I think linux still has the headers anyway and it'd be nice to have an implementation that doesn't use boost, even if it's no longer cross-platform. - [`setjmp`](http://en.cppreference.com/w/cpp/utility/program/setjmp) / [`longjmp`](http://en.cppreference.com/w/cpp/utility/program/longjmp). Hoo boy was this a fun rabbit hole. Basically, way back before `boost::context` or my generator project, I tried to implement generators using `setjmp` and `longjmp`. The idea was going to be that I `setjmp`, put a `char` on the stack and save its address, then launch the context. When you want to context-switch, it creates another `char` on the stack and gets ITS address, saves the stack (defined by the space between these 2 `char`s) to a `vector`, and `longjmp`s back. For this design to work correctly, every context resume would need to take place on *exactly* the same place on the stack, so that the manual `memcpy` of the **stack** wouldn't break everything. It also would rely on horrible horrible levels of undefined behavior. I never got even a working prototype and abandoned it. - Stackless. As seen in [`boost::asio`](http://www.boost.org/doc/libs/1_55_0/doc/html/boost_asio/overview/core/coroutine.html). The idea here is that you put all your context switching into macros, and make the whole thing a big, invisible `switch`. None of the context stack data is preserved, and macro magic makes it so that when the context is resumed, it immediately uses the switch block to switch to where the context left off. It's a fascinating, useful, and honestly very clever trick, but macro-magic and stacklessness were both major things I wanted to *not* have in my own implementation. - GNU Pth. GNU Pth is an implementation of portable, user space threads- threads that only switch context when explicitly told to by the user. While I could implement generators with them, there'd be no reason to, because they essentially do everything that generator does already. They're more of a competitor than anything else. Also, like `makecontext`, I'd be locked into linux platforms. - Windows Fibers. I only bring this up because it's mentioned in the `boost::context` docs. I imagine it's essentially GNU Pth but for Windows.
I love long build times, they give me coffee and bathroom breaks
Rust does show pretty clearly that the problem is that the type system isn't powerful enough, but also that making the type system powerful enough is *very* difficult.
Assuming we're talking about generators using the existing C++ facilities (i.e. we're not restricting them to a subset of the language) each generator needs its own stack. The generator's stack can't be placed in the same memory allocation as the main stack because the main stack could overwrite it with sufficiently nested function calls, so it has to be in a separate allocation. In order to get the generator to use the separately allocated stack we need to alter the stack pointer. The only standard C++ function that can arbitrarily alter the stack is `longjmp`, but that requires `setjmp` to have been called while executing on the new stack, which is a circular problem. This doesn't preclude restricting yourself to a subset of C++ which ignores these problems, but if you want a general coroutine library you'll need to either write the stack switching code yourself or find a library that does it for you.
I assume you're speaking about windows, where yes, I agree with you. A lot of boost depends on other parts of boost, especially for detecting performing compiler- or platform-specific compilation. As far as I know, there's no tool for just getting the parts you need. Then again, the github-modularization is a very recent development, so hopefully they're working on useful dependency resolution through that system. If you're on linux, then in all likelihood there's a package available that DOES do all that for you. Here's how I got boost::context set up for this project: sudo apt-get install libboost-context1.54-dev This installs all the headers and (where relevant) compiled libraries, so all I needed to do was link against libboost_context (`-lboost_context`) and I was golden.
Actually, general-purpose coroutines is what I'd eventually like to do here. However, in this case, I figured that between yield-by-reference and function-object-by-reference there were already plenty of available tools for 2-way communication between generator and caller.
&gt;using `std::move` on a value and then doing anything else than destroying or assigning to that value is undefined behavior I don't see how you figure this. This may be true for **some types**, but it's not true -- as far as I know/can tell -- for **all types**. The receiving move constructor/assignment operator does **something** to the value, and if that **something** leaves the object in a valid state for which the behaviour is well-defined, then you can continue using the object as per normal. &gt;a lambda capturing a reference to the stack is better not returned below the frame in which that reference lives, otherwise it's undefined behavior Sure, what's your solution?
Fun story- see my comment just above yours (http://www.reddit.com/r/cpp/comments/1wvn0k/after_many_months_im_finally_ready_to_present/cf63zpm). Basically, I attempted to use `setjmp` and `longjmp` but first copy the whole stack to a vector and restore it when resuming.
1 does exist (bcp). It's just not very useful since in most cases just the bits you need is a large enough portion of boost that it's pointless. Boost.build is a terrible build system, but `./bootstrap.sh &amp;&amp; ./b2 --with-filesystem` is really not meaningfully different from `./configure &amp;&amp; make`.
The bug is not due to over-use of `std::move`, but to *mis-use* of `std::move` where `std::forward` was intended. It's ironic that we've spent the years between C++98 and C++11 telling programmers that casts are bad and their use is to be avoided, and then C++11 introduced two new and special casts - hidden behind the names `std::move` and `std::forward` - whose use is required to support the features of the new standard. It comes as no surprise that - just as for other casts - incorrect use leads to horrible bugs that the compiler doesn't really have a chance to diagnose. &gt; using std::move on a value and then doing anything else than destroying or assigning to that value is undefined behavior This may be true of types that you write, but it is not true of types that I write or the types defined in the core language and standard library. The standard requires of library implementations that (C++11 17.6.1.5/1) "Objects of types defined in the C++ standard library may be moved from (12.8). Move operations may be explicitly specified or implicitly generated. Unless otherwise specified, such moved-from objects shall be placed in a valid but unspecified state." It *is* possible to destroy or assign such an object, as well as call any of its other member functions that do not have preconditions. &gt; a lambda capturing a reference to the stack is better not returned below the frame in which that reference lives, otherwise it's undefined behavior Storing a reference to an object beyond its lifetime is hardly new to C++11 or lambdas. I will agree that lambda syntax provides an easy way to leak references that isn't nice and visible as it would be in the return value of a function.
`std::move` is just a cast - [An Effective C++11/14 Sampler](http://channel9.msdn.com/Events/GoingNative/2013/An-Effective-Cpp11-14-Sampler) @ ~4.20mins. So it inself won't do anything. After being *moved* from, objects should follow the standard libraries behaviour where &gt; Unless otherwise specified, such moved-from objects shall be placed in a valid but unspecified state. See [What constitutes a valid state for a “moved from” object in C++11?](http://stackoverflow.com/questions/12095048/what-constitutes-a-valid-state-for-a-moved-from-object-in-c11) @ SO.
&gt; Sure, what's your solution? Raise a compiler error if you try.
No. The Rust compiler keeps track of variable lifetimes and will raise an error if it detects a reference could outlive the actual object. So taking the reference isn't an error, but returning it is.
&gt;The compiler checks whether that actually happens, and errors if it does. What if the body of the function you're calling isn't available for examination? Besides, that's actually a legitimate use case. What if I'm passing lambdas to a thread pool, and then I'm going to wait for all of them to finish before proceeding? That's safe, that's defined behaviour, that's a legitimate use case.
The check is done when compiling the body of the function. It doesn't need to examine the callee to do this, so it works with separate compilation. I agree that that's a legitimate use case. In Rust you would need to write code in an `unsafe` block where you can ignore lifetime checks, or put it on the heap and use the ARC module (which uses `unsafe` blocks internally) to share it.
&gt;put it on the heap That's kind of missing the point. We put values on the stack because they're going to be used locally, don't need dynamic lifetime, and we don't need the overhead of the heap manager.
Linux actually, I should have made that clear. Yes, I know there are some boost packages in Ubuntu, but they mightn't be up-to-date and it might be awkward for others to use my code. I guess it's not difficult for me to specify that others should install the boost package also. But if I develop on Linux, and try to make the code reasonably portable, I'd like to just include the relevant boost code in my project. (with suitable licenses) Basically, I'm not willing to invest time to learn Boost if I can't make my code available in a relatively easy-to-compile format. I'm an academic and make my software available with my published papers.
As I've said in your other thread, I've looked at it briefly but I think it was written by someone who is used to write C++ based on the following things: - use of initializer list - use of const reference and const method - namespaces - operator overloading - class pre-declaration instead of include when possible - use of non-standard `#pragma once` (but supported on most compilers) - C++11
You're correct, of course. I meant all in userspace- no kernel threading.
std::unordered_map is a python dict(). std::map has the property that its keys are always in sorted order.
The problem with c++ community is to scare beginners with unwanted information. Few guidelines: 1) When you have two options, using new and not using new. Do not use new. If not sure, do not use new. new is for low level advanced code. 2) When you want python list like functionality, use std::vector. 3) When you want python dict like functionality, use std::unordered_map. If you want the contents sorted, use std::map When you think the program is having a performance issue and you find it is due to the data structure choice, you can take a look at the other comments to improve.
&gt;objects should follow the standard libraries behaviour [...] Why? It makes more sense to me to have objects behave as though they'd just been default constructed, unless that involves some kind of resource acquisition/memory allocation. Why does it make more sense for objects to be in a "*valid but unspecified state*" -- i.e. worthless unless you want to construct a new object and assign it to them -- than for them to be in a default state? Especially with containers, where moving from them usually means moving a pointer. You move the pointer, set the old one to `nullptr`, and then either: A. It's back in its default state. B. Its default state involved actually acquiring some amount of internal memory before any objects were actually added to it. I'd argue that B should be considered harmful. Default constructors should not-throw where possible, and allocating memory can throw.
Note that this alignment is not required on all platforms but *is* required on Mac. 
&gt; Why? So that you can use those objects with the standard library. Basically you don't have to follow the standard but then your classes won't work properly with standard containers, or tuples or other functionality provided by the STL. &gt;It makes more sense to me to have objects behave as though they'd just been default constructed, unless that involves some kind of resource acquisition/memory allocation. This would ruin the overwhelming majority of use cases and would no longer justify all the hard work that went into introducing r-value references. r-value references were introduced primarily as an optimization because of many use cases where you create an object, use it momentarily and then pass it on to another variable, on and on. In the overwhelming majority if use cases the original object will no longer be used, so having a move constructor default construct an object after a move is effectively a waste. &gt;Why does it make more sense for objects to be in a "valid but unspecified state" -- i.e. worthless unless you want to construct a new object and assign it to them -- than for them to be in a default state? Once again this is a performance consideration. It basically means that the object still exists and can still technically be used but that the writer of the move constructor can focus on performance. For all intent and purposes, performance is like a first-class citizen of C++. Unlikely maybe Java or Python where performance is a desired afterthought that the language designers consider after usability, convenience, safety etc... in C++ all features must prioritize performance. The suggestions you provide would all make sense in a language that didn't require such stringent performance considerations, or was willing to sacrifice performance for other properties, but that's not what the bulk of C++ users expect or want. That's not the target audience for C++.
I like how you totally ignored my actual example, and instead just focused on hypothetical examples that were nothing like what I said. I explicitly said: &gt;unless that involves some kind of resource acquisition/memory allocation. And then: &gt;Especially with containers, where moving from them usually means moving a pointer. You move the pointer, set the old one to `nullptr` How does specifying the state of -- for example -- a vector to be empty after being moved from cost you in performance?
I didn't ignore your example, I'm giving you the actual real world justification for why a large body of people made the decision they did. You can argue that you know better than the ISO C++ committee and have all the answers they overlooked, but you should at least understand what their position is. Move constructors effectively only work and provide an optimization in cases where there is some kind of indirect allocation of a resource or memory. That's why move constructors are effective for an std::vector, but don't provide any performance benefit for aggregate data types. Your whole qualifier/exception about "unless that involves some kind of resource acquisition/memory allocation" isn't an exception at all, it's the 99% of use cases that move constructors were designed to address. Take for example the case of std::vector, the default constructor of an std::vector does not initialize its internal pointer to null. The default constructor for an std::vector allocates a certain amount of memory which can be queried using std::vector::capacity() const. That is a default vector actually does allocate some memory behind the scenes, but leaves that memory unused until you call push_back. What the standard states is that if someone invokes a move constructor on an std::vector, that std::vector does not need to perform this default allocation since the 99% of use cases that the move constructor is designed to deal with will be cases where that vector is never used again. In the very rare situations where it will be used, well then the vector can hold off on reserving that capacity until the time comes that the user resets the vector or performs an operation that actually requires it. Hence if an std vector wishes to implement its move constructor by setting its old internal pointer to nullptr, that is likely a valid implementation, but that implementation is different than what you suggested, which is to default construct a vector as if it had just been allocated/declared. Furthermore there are even optimizations that are possible where no such internal pointer has to even be reset at all, for example an std::string implemented using the small string optimization is free to implement its move constructor by simply copying its contents over and leaving the original string entirely unchanged if the string being moved is small enough. So there's no need to reset its internal pointer to nullptr or reset anything for that matter. These details and many others are ones that have all been considered and talked about for close to an entire decade by rather qualified and intelligent individuals who made such trade-offs to address C++'s common use cases. Yes it's tempting to just read superficially some aspects of C++ and then judge them as being unneeded or overly complex or whatever... but actually once you begin to understand the rationale and why these decisions were made you begin to have an appreciation for it.
&gt; that implementation is different than what you suggested, which is to default construct a vector as if it had just been allocated/declared. I explicitly pointed out that I believe that allocating memory for containers when they're default constructed should be considered harmful.
What I'm trying to explain to you is that your so called "considered harmful" exception isn't an exception at all, it's the rule, and that rule is used by the standard for its own classes. I explicitly pointed out that move constructors only provide an optimization in cases where an object must allocate memory. If you have a class like: struct Object { int x; std::array&lt;double, 10&gt; y; std::tuple&lt;int, char&gt; z; ... // Other aggregate types. }; Then move constructors do not provide you with any optimization benefit. The use case that move constructors are designed to provide an optimization benefit for are when you have some kind of unique ownership of dynamic memory or indirect resource, for example: struct Object { std::unique_ptr&lt;int&gt; x; std::unique_ptr&lt;std::array&lt;double&gt;, 10&gt; y; std::unique_ptr&lt;std::tuple&lt;int, char&gt;&gt; z; ... }; Now Object can implement a move constructor that will provide an optimization benefit.
as a bonus &amp; versions are similar to lambda capture syntax. although in lambdas const is implied. 
&gt; My general impression is that this was written by someone that's more comfortable in a scripting world than the world of C. I wonder if you think comfort in the world of C is helpful or even desirable to write C++. That isn't the case, and many (including me) think it may be harmful at times. Otherwise agree with /u/aaptel/.
You originally questioned why a group of C++ experts from the around the world working for close to a decade came to the conclusion that the implementation of move constructors for the standard library should leave objects in a valid but unspecified state as opposed to a default/reset state. Since you seem to disagree with these experts about their conclusion it only follows that either you really are some kind of genius and expert on the matter that no one knows about, in which case the burden is on you to provide your credentials and substantiate your arguments, or that you actually are misinformed about what move constructors are and what they do, at least to some degree. I'm not saying you're 100% clueless about it, but yes, to some degree you are misinformed about what the purpose of a move constructor is and how to efficiently implement one if you don't understand that many classes in the C++ standard library require additional work in order to reset to a default state after a move operation is performed. This work would go to waste for the overwhelming majority of the use cases move constructors are intended to be used for. What I'm trying to inform you of is the rationale that the existing group of C++ experts came to when they stated that the standard library is to implement move constructors in such a way that they leave the object in a valid but unspecified state. This decision enables optimization opportunities that would not otherwise be available if they were FORCED to implement their move constructors so that the object is in a default initialized state. Examples of such optimizations include small string or general small object optimizations such as those used by std::string, std::function, std::bind or optimizations used in std::vector&lt;T&gt; where T satisfies the std::trivially_constructable type trait, or optimizations that depend on compiler intrinsics, basically operations that are built in directly to the compiler. If you KNOW something that they don't, then please produce the evidence to back up your knowledge of the subject.
I had two points: 1. I don't think that allocate-on-default-construct for containers is a healthy behaviour. 2. I think that, where possible, resetting an object to default constructed state after moving from it is healthy. There are many instances wherein you create a container, but may never put anything in it. For example, consider a method that looks for and returns a collection of all objects of some type or which match some description. That there are no such objects may be a very common case, but if you default construct a `std::vector&lt;T&gt;` with the intention of populating it, and then search and find nothing, you allocated memory for nothing. Given that containers have indirect blocks for their storage, that pointer can be `nullptr`. Given that you're moving from them, you need some way to tell that object's destructor not to clean up the memory -- e.g. setting it to `nullptr`. My argument is that collections -- at least -- can very easily be made to reset themselves rather than entering an unspecified state when they're moved from. You just see that the internal pointer is `nullptr` and allocate memory as you would if the collection was full.
boost was annoying before I start using waf (build system). Now it's just a matter of specifying the path where boost is located and where it built its libs. On Windows: - download boost, extract it to some dir, run bootstrap.bat, then b2.exe - in your project, with waf and a configured wscript, run: python waf configure --boost-includes=c:\boost_1_45_0 --boost-libs=c:\boost_1_45_0\stage\lib - then python waf build You can check [the example here](http://code.google.com/p/waf/source/browse/#git%2Fplayground%2Fboost) with the batch file and wscript. Not sure if it's still up to date, you may need to add --boost-linkage_autodetect to the configure command line. But the whole thing is pretty easy with waf, and cross-platform.
Better formatting: #include &lt;cmath&gt; #include &lt;iostream&gt; #include &lt;vector&gt; using namespace std; void main() { int i, j, k, n; double sum, xmult; cout &lt;&lt; "enter n:" &lt;&lt; endl; cin &gt;&gt; n; vector &lt; vector&lt;double&gt;&gt; a(n+1, vector&lt;double&gt;(n+1)); vector &lt;double&gt; b(n+1); vector &lt;double&gt; x(n+1); for (k = 0; k &lt; n-1; k++) { for(i = k+1; i &lt; n; i++) { xmult = a[i][k] / a[k][k]; a[i][k] = xmult; for (j = k+1; j &lt; n; j++) { a[i][j] = a[i][j] - (xmult * a[k][j]); } b[i] = b[i] - (xmult * b[k]); } } x[n] = b[n]/a[n][n]; for (i = n-1; i &gt;= 1; i--) { sum = b[i]; for (j = i+1; j &lt;= n; j++) { sum = sum - a[i][j]*x[j]; } x[i] = sum/a[i][i]; } }
I'd start with #include &lt;Eigen/Core&gt; and work from there. ;)
&gt; I don't think that allocate-on-default-construct for containers is a healthy behaviour. That's probably true for a lot of **classes**. But is it true for all classes? If not then making it a requirement could have serious consequences. I say classes because move semantics also made it possible to return and move around objects for which copying didn't make sense. 
Thanks! :D
Wouldn't you have an issue with saving registers though ?
Definitely difficult, I am waiting impatiently from Rust to see exactly how it pans out. Specifically, how often one must use `unsafe { }` to accomplish anything.
For existing ways, `T const&amp; cons(T const&amp;);` and `return cons(T{});` work very well, I fell for it a couple times already :/
&gt;Whether Qt Creator will follow KDevelop in this Clang route is still being determined. [Not really, it's coming.](https://qt.gitorious.org/qt-creator/qt-creator/source/f4f8f97258e2c4aa7ee176bef31a0e27c419908b:src/plugins/clangcodemodel)
Yep, it works fairly well too. Though, it's really slow, uses a tonne of memory and completion unpredictably fails sometimes, but otherwise, it's decent.
lol. You must be british
Honestly I feel that the committee really dropped the ball when it comes to constness in lambdas. Lambda's should have been mutable by default - like everything else in C++ with const being allowed via [x]() const { ++x; } // Error same as current behavior [x]() { ++x;} // Should mean mutable And then this behavior that Scott is talking about is just annoying. Its good that it will have a workaround in C++14 but now it means that C++11 lambdas have a major flaw that make them painful to use. All of this in the name of what? saving a few keystrokes? I'm not sure what the original motivation was behind the capture system in C++11. In hindsight I feel it should have been implemented like so... someClass::someFunc(){ const int x; auto func = [auto a = x; someClass* const self = this;]() {++a;}; } To me the code I demonstrated above would be easier end users to understand and would not have had these issues with constness since it would basically just expand out to.... class unnamed{ int a; someClass* const self; public: unnamed(int a, someClass* const self) : a(a), self(self) {} void operator()() {++a;} }