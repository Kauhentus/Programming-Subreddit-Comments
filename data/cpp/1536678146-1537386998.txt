From my understanding the real bottleneck right now is hard drive speed, which we are still advancing in.
Heh, that email delay filter was a shell script hacked into a sendmail MTA. This was a *long* time ago, early 1990s, top tech talent in a company is always hassled for help! For those of us who still run their own server infrastructure because we don't trust the tech multinationals, that kind of customisation is easy. But for gmail? I am afraid I don't use it, and so don't know, sorry. (I have had a thought: in France employers can no longer deliver email to after 6pm by law, so perhaps gmail had to roll out some sort of plugin or solution for pausing gmail delivery in France. Might be worth a search)
&gt;Very occasionally, an org actually wants nothing but top end talent because they actually genuinely want quality software, rather than just pretending they do. Everybody working on a piece of software is as good as the org can acquire for any money, and usually you only need about six developers if they fit well to achieve almost anything. It's a life changing experience to work in a place like that, the productivity is truly astonishing. You get to see how software really ought to be developed if the world were perfect and the industry actually wanted quality. That's interesting. Was this a firsthand experience? Where was it?
auto x = ... is always successful regardless of what .. is.
I was with you early on but am starting to think this whole post might fit better in /r/iamverysmart.
I don't understand anything after the comma in the title
this is language layer for cpp support in spacevim .
C++ isn't dying, but there's all this newer stuff (JS, Java) that can get the job done quickly and with less experience/care. It's just going to be very bloated and slow unless you go out of your way to optimize (the "low level details"), but nobody who actually makes the web stuff cares about that. And that's most of the hiring these days, it seems like.
Bro, if only you could see my resume...
I feel the best way for making vim as IDE for CPP is to use LSP with a server such as clangd/cquery/ccls. 
It sort of is, though, because we’re approaching the limits of transistors with known physics. Just see Intel’s repeated delays in introducing a 10 nm process (current rumors say the upcoming ”10 nm” is more like 12 nm). There’s also the fact that the cost of new fabs increases exponentially as the transistor pitch is lowered. We’re already at the point where only 2-3 companies in the world have resources to invest in the latest fab tech.
You're right, but it is also true that lower barrier of entry which has some positive stuff, also can create a larger amount of lower quality professionals. In the web dev area, is not that uncommon to find people that call themselves senior devs having learned to program less than 5 years ago. I cringe at the code I wrote when I was that inexperienced of a programmer. Hell, sometimes what I wrote a couple of years ago from now is not that good, but at least it means I'm still improving.
That is indeed interesting, thanks for sharing. I say this because I'm looking to go long term somewhere in January, and so have been avidly studying all possible sources of remote C++ jobs since July, and I don't remember seeing a role advertised anywhere I would look which matched what you describe. So far, to be honest, I have been screened out by firms insisting on me taking a coding test before talking to any human being, and me pointing them at 20 years of personal github appears to carry no weight. So to date I've demurred on those roles, but maybe I'll just need to go bite that bullet in order to reach a human. First though I need to finish my San Diego mailing papers for WG21, then I'll have a lot more free time for stuff like coding tests.
What I also would like to see is how to setup include paths (as an example in CMake). E.g. with the following setup: include/foo/foo.h src/foo/mod1/foo.cpp src/foo/mod1/bar.[h|cpp] src/foo/mod2/baz.[h|cpp] test/foo/mod1/foo_test.cpp test/foo/mod1/bar_test.cpp test/foo/mod2/baz_test.cpp test/foo/test_helpers.h How would you setup the include paths? And where? A CMakeLists in src/foo/mod1 would need to use `PROJECT_SOURCE_DIR/src` which might be bad if you later move this, but then again: 1 Project per (external) submodule with the same main structure should solve this. How to include the test_helpers header? With `#include "../test_helpers.h"`? Set an include path to `PROJECT_SOURCE_DIR/test`? How to include `bar/baz.h` from the tests? The external include is `foo.h` but we may want to test smaller parts that consumers of the library should not see. So `PROJECT_SOURCE_DIR/src` as PUBLIC in the src folder is bad, so do it again in the test folder? And finally (as we had this discussion recently): `#include &lt;full/path/header.hpp&gt;` or `#include "myHeader.hpp"`? Where would you make the distinction? We resorted to always-angle-brackets as it was to hard to define a clear distinction when to use which.
&gt;Well, yes. That's kinda how it works. &gt; &gt;I don't know what else to tell you, because now I don't really know what you're asking. That is the issue is pointing, a CS degree doesn't make you a developer. And probably shouldn't. So the issue is not necessarily with CS courses but with HR switching to using that as a proxy for being able to code. It's lazy, and it gives bad results. Look up Joel Spolsky's fizzbuzz and related posts.
I think your SFINAE should match your actual operation, for logical consistency. Your actual operation uses move, so your SFINAE should, too.
Well C++ is hard because it's hard to wrap your head around the complexity. [Said that:](https://i.imgur.com/rbQ6Ga3.png) 
I've never felt old about it, but I felt sad when I saw colleagues and peers taking the easy road. "Typing is hard" -&gt; use dynamically typed languages for literally everything -&gt; unmaintainable nightmare -&gt; Typescript &amp; hacked in annotations. "Security is hard" -&gt; write garbage, unsecured software thinking obscurity is enough -&gt; cost billions -&gt; 800 talks about basic input sanitation. "Defensive programming is hard" -&gt; segfaults -&gt; "C is a bad language". I find it completely insane that you can get a CS degree without PL for understanding proof and type systems or AppSec to know how to prevent most malicious user attacks.
yeah tell it to someone almost twice your age who has only programmed in Algol, PL/1, FORTRAN, C++, Turbo Pascal Delphi, C# strictly for the desktop. and there are more "web frameworks" out there than LOCs I've written in my life.
\&gt;I learned QBasic in the 90s because most of them were born after 2000. Wow, I actually started with QBasic in the 90s too, before transitioning to learning C/C++ a year later. I've programmed in Go but it hasn't clicked with me so far. I think part of it is the syntax -- very different in relation to C/C++, compared to, say, JS and Python, which were a piece of cake to learn. I don't get why Rob Pike chose to put the type name after the variable name. I've done a bit of reading on it and I can see how it can be the right tool for certain situations. But I did read that most of the people who are drawn to it are coming from Ruby and Python, not C++. I'll probably have to use it at work soon -- hopefully it turns out to be a decent language that I can appreciate.
Second hand experience I am afraid. I've never worked anywhere more than 18 months in my career to date, I haven't been able to stick it for any longer than that. But to answer your question, it's widely known that a certain team in Adobe consists of nothing but top calibre people, or their understudies being trained up to become top calibre. I have heard of case studies being written about them by academics as they have unbelievably good productivity metrics. The other instance was in Acorn computers, a UK firm, who after botching their next gen OS they basically locked their six best non-kernel applications and games engineers into a room to deliver a hail mary "save the company" whole operating system plus GUI applications stack from scratch. They delivered what you can see at https://www.youtube.com/watch?v=mFwpsb75omg in just over a year, and what you can see at https://youtu.be/5M6OIOIND-0?t=21m29s [1] within another thirty months after. I knew one of those six engineers personally as one of my first bosses. Learned a very, very great deal from him. He wrote the filing system and storage layer, the memory allocator, the builtin heap sort syscall and a few other bits. The OS they built was a marvel of engineering beauty, built by applications and games folk rather than kernel folk so it was built around the user experience, the whole thing was simple, consistent, elegant and almost bug free, which is such a rarity nowadays. But then great engineers with a good fit together tend to not write code with much bugs, so they only spent six months on bug fixing, some of which was very extreme e.g. to debug the filing system, they bought a stack of hard drives and whacked them hard with a hammer whilst running to test the error handling in the filing system code. That kind of debugging. Oh did I mention most of the whole thing was written in hand coded assembler? Some of the GUI applications were written in C or BASIC, but pretty much the rest was in ARM assembler. Yet still virtually bug free. And source control was implemented by a stuffed purple dinosaur, whoever had it got write permissions to the source code. [1]: Pedants yes I know the video shows RISC-OS 3, not RISC-OS 2, but almost everything in the video was also in RISC-OS 2 and unchanged in RISC-OS 3. 
&gt; I don't know if it's bad coworkers so much as inexperienced ones. Then it's your job to train them. Give them some pointers and let them figure out the rest on their own. Also: give them responsibility. Design an interface for some subsystem and make them implement it. If you find out it doesn't work, they'll have to debug it. If it works, hey, who cares if it's ugly. If you can, carve out some time for code review and suggest improvements. Yes, inexperienced developers are ineffective, but that's part of life. It's your choice whether to complain or use them and help them get better underway.
\&gt; and there are more "web frameworks" out there than LOCs I've written in my life. XD And I still don't understand what exactly a framework is, since I don't do web dev -- I suspect it's something similar to a library but I am not sure.
No matter what happens, you should be glad you're a programmer. Imagine all the construction workers, restaurant employees, teachers, customer service reps, etc. who will lose their jobs in the upcoming decades due to AI and robotics. I do believe C++ will remain at least a little relevant for another century, but even if you can't find any jobs programming in it, at least you'll have the fundamentals to transition to a new language.
Same here, have been programming in C/C++ since the early 90's. Demand for them has gone down somewhat along with demand single-instance performance. Still, I cannot find myself programming in another language, esp. the ones you mention, mainly on the account of the shitty performance and lack of versatility. Also, that feeling of being old? It's actually good. I enjoy it very much.
Of course chaining the operations makes the most sense for that API. I simply wanted to stay as close to the original example as possible. I agree that self assignment is an entire different topic (e.g. could be unsafe / induce a performance penality, etc).
I'm thinking of doing something with webassembly. You can compile C++ to webassembly and call JavaScript for UI stuff. I am excited about the possibilities now that all major browsers support it.
Glad to hear it! I'm surprised that there's a high school out there taught C. Mine didn't even have a computer science class until I was a senior. Don't worry about shooting yourself in the foot -- it's part of the process of how you get better. :) I've lost count of how many times I've spent an hour debugging a single segfault. Thank God there is the new stuff introduced in C++11 and later versions -- make sure you learn those things so you don't have to do things like new/delete.
&gt; Your problem appeared because you started to use auto I have no problem. In my example, I'm using the syntax properly. You are glossing over the disadvantage that you added with the old syntax and this is less consistent and less expressive . If they really want the type to always be a float in your style you should really be doing: float f = static_cast&lt;double&gt;(foo()); Otherwise, you aren't making your intention clear that you want the conversion. The l2r auto syntax takes care of this for you cleanly. And when the time comes to change the type returned by foo() then it is a much higher maintenance cost to go through and try an determine the intention of the caller of foo in each case.
But Moore's Law is the number of transistors in a *CPU*, not a CPU core or the width of transistors. Moore's Law is easy (relatively speaking) to continue just by packing in more cores. That's why in the Wikipedia link for Moore's Law you'll see a 22-core Xeon processor and GPUs. All we have to do to keep Moore's Law alive is just keep adding cores. This can still happen for a couple more years before we flatline. We are certainly close, but we aren't there yet. But, yes, only a few companies really do have the resources to continue Moore's Law.
Happens. Report it to your manager since it’s affecting your performance. Take into consideration that the company will probably still favor the team over the individual. 
\&gt; I**'m a 34yo C++ programmer but I already feel like an old man.** I've been saying this since 1676!
0xA0000 is the 10th segment of 64k, offset 0.
&gt; I feel like an old man even though I'm still relatively young. Here's where you go wrong. You're 34. There's nothing young, at all, about a 34-year-old. You *are* old. So go ahead and feel it if you want. (BTW I'm older than you)
Segment is left-shifted by 4 ;-) And I'm pretty sure that's what they were saying. As a flat memory location, the pointer would actually go to 0xA0000, and would normally be written in a `segment:offset` format. It just looks odd to see a notation that makes it look like a single 32-bit number, instead of either a 20-bit num or a pair of 16's.
I cant tell if this is sarcasm or not. God help me
&gt; Then return std::string and stop leaking inconsistent implementation details... I agree with you, but that was just example copy-pasted from comment above and untouched as much as possible to show the difference between boost::hof::first_of and priority_tag&lt;&gt;. Other details are not interesting for that example
Out of curiosity, did you post your opening [here](https://www.reddit.com/r/cpp/comments/8vuc05/whos_hiring_c_devs_q3_2018/)?
Indeed, C++ itself is evolving at a rather impressive rhythm, with this new "standard every 3 years" cadence.
One of the things I knew was bad was approaching C++ as if it was C with classes. I decided to get a proper book (C++ Primer) which treats C++11 as a default, not as an addendum. It’s not my only source though. The funny thing is that what got me interested in C++ in the first place were probably CppCon talks that I found on YouTube by a chance (so I saw things such as std::enable_if even before deciding to start learning the language). Also, I consider the C++11 solution to complex memory management as an integral part of what C++ is today. Without that, I wouldn’t probably want to learn the language today.
No way. All the new grads don't even know what pointers are because they are taught python and java. Sure they will soak up the meat grinder entry level jobs but I feel more in demand than ever by companies doing the hard/fun stuff.
here's a salary report from 2014, so it's a few years out of date. You will take a pay cut to work in games but you can still live comfortably. https://www.gamasutra.com/view/news/221533/Game_Developer_Salary_Survey_2014_The_results_are_in.php 
A framework's kind of like a library, except that in most cases, I think it's the framework's code calling yours instead of you calling the library's code. Sort of like a game engine, but for websites. Some are heavier than others. Did you ever do any Visual Basic? That was basically a GUI app framework, where you specify callbacks for different events, like the load of a new form or clicking a button.
Use a grep that groks .ignore files, like ripgrep
They ask for it so they don't get a bunch of bad applications from people with no experience or skill. If you know your shit and have experience in at least the C++ industry, the chances are good.
&gt; this is less consistent and less expressive How is "writing `auto`" every time more consistent? It is just a stylistic choice. Unless you have OCD, that is (which is fine, all of us have for something). &gt; If you really want the type to always be a float in your style you should really be doing: Sorry, no. That line of code means `f` will always be a `float`, period; and whoever writes that code is expressing just that. This is C basics. You are arguing that `float f = foo();` means "well I don't care what the type is". Don't you see how wrong that is? &gt; Otherwise, you aren't making your intention clear that you want the conversion. That line of code does **not** say we want conversion. It says we need `f`to be a `float`; which is a very different thing, and independent of `foo()`. With your way of coding, we would be writing things according to the return function of others, which means dependencies all the way long. That is just crazy, and I think Herb just went a bit overboard with his AAA talk. We must code the other way around: fix the types locally, and reason about code locally. That is why we say "this type must be `T`, so that the following code makes sense", instead of "I will pick whatever this guy gives me and make do with it". It is in generic code where `auto` makes the most sense; and even there, we are moving towards a Concepts world, where we will be able to easily limit --- locally! --- what a type can get to be. &gt; The l2r auto syntax takes care of this for you cleanly. It does not take care of anything, it is just another syntax for expressing the *same thing* (and a ugly one at that). If you are using `auto` just to have name-then-type syntax, it is another discussion. &gt; And when the time comes to change the type returned by foo() then it is a much higher maintenance cost to go through and try an determine the intention of the caller of foo in each case. That does not make sense, because of the reasons stated above.
If I ignored all e-mail for 48 hours I'm trying to decide if I'd get fired for ignoring everything my boss sends me or fired for ignoring everything customers send me, causing them to e-mail my boss wondering what the problem is
Oh you of course whitelist your boss, and their boss. You might also want to whitelist everybody at your bosses grade or higher just to be safe. But customers, well it's not healthy for them to get a reply within 48 hours. I'd even say a week personally. Forces them to figure stuff out on their own. Certainly for support requests on my open source libraries, I make everybody wait three days minimum. Most of the time, they figure it out on their own and cancel the support request. Or some other user answers them.
It really depends what domain you're working in. Application development for desktop has lots of "easier to use" frameworks/languages that tend to be great for rapid prototyping.
I want to argue, but my last e-mail from a customer was that our app was printing a "file not found" error, and it was because they'd typoed the filename when passing it to us
I'm mid 40s. I've used C++ for almost 20 years, pulled down good money and lived below my means. If I lost my job tomorrow and never found a new one, I'd be ok financially. However, for an increasing number of tasks I now use Python. I've started to use C#. Much of what I work on is performance critical though, and C++ won't go anywhere for that. But it's becoming more of a niche thing. Younger co-workers I've had often had more energy, more time, and were me up-to-speed on new technologies. They were, on average, better at software engineering on a lot of levels. But 20 years of experience do help a lot. I feel like I can compete with most of them still. So, mid 30s is hardly too old. But we oldies have to keep learning, have to adapt, and honestly probably be prepared to not be able to complete in our 60s, or many 50s. 
Go is really easy to get into going from C or C++. It's a really rewarding experience.
And that's what I'm talking about. C++ is going to be around and still there best solution for a lot of things for a very long time still. But it's domain is shrinking. If you're in a business domain and want to stay in the business domain, your time is coming up. Being a developer who can work in C++ will always be valuable, but being a "C++ Developer" in a domain where C++ is considered overkill won't continue to hold it's value. Never limit yourself. Never pigeonhole yourself. Always be adaptive and willing to learn.
It's wonderful how Google has transformed from "Don't be Evil" to basically "Be as evil as possible". And by their standards I suppose you're a dinosaur.
Could be much worse.
And in their 60s.
I don't think it's unreasonable to assume that getting good at C++ requires a higher IQ than javascript, ruby, et al. Using C++ as a proxy for intelligence and aptitude isn't completely outlandish. At worst, there may be better proxies.
no. I'm 46 and have professionally coded in 4 industries and just about every language. These days I do embedded real time avionics systems in C and C++, this is where are the greybeards are. I am happily working 100% remote, and intend to do so until I retire. 
The people who have those backgrounds are probably working in positions which don't require C++. I work for a hardware robotics company, and in this field, I cannot see C++ leaving the foreground for \*\*at least\*\* another decade or two. The only language that could can probably match C++ performance wise, while keeping the level of freedom, is Rust. I can't see Rust ever taking over C++ besides niche projects and markets (I know Rustaceans will vehemently tell you otherwise). We basically won't hire any software developers without good C++ skills. I know a lot of other companies in my field are the same way. Also, it seems that jobs which require C++ experience are on average higher paying\*. That said, it would probably be most wise for the developers that come out of college diploma mills and just want to make money to choose C++ jobs. While I don't think you should just do it for the money, I also want more people to use C++ since the alternative programming languages aren't exactly as exciting or fun to use... \* This is based on my anecdotal experience and assumptions, so take this with a grain of salt please
No, that looks like a good option for the future though. 
The rules for `build/` and `_build/` are mostly such that the names are reserved, not that they are mandatory. I could see people starting to do the hardcoding of paths, but I've found that to be an already-existing problem. This may be a matter of good teaching. exe/lib splitting is still divisive, and there is not yet a clear winner on the best option. The current trend shows a slight preference toward the `src/{bin,lib}` option, and against the `src/my-program.cpp` option. Multiple root dirs is in the middle.
I am a math major droput with only 4 CS courses under my belt. It wasn't as easy as if I just got the degree in CS, but there are quite a few companies out there who break out of the CS-program bureaucracy mold. All but one of my software coworkers/interns did something other than CS too. My position and company may be an outlier, though.
Get a job somewhere else. Dynamic language programmers who do front end stuff and C++ programmers who work on high performance projects are as different as electricians are to plumbers. Go find a job where you're surrounded by other electricians and you'll feel much more at home and comfortable. I work on a team that works on llvm. Hell, some of the guys are big contributors to libcxx even. C++ is much beloved on my team. My love for diving into libcxx to learn how things work is highly promoted where I work. 
I strongly recommend you to join a contract software engineering company for a few years if you havent already. It was very eye opening every month or so to work on a different project, language, project management style ets. Having to always think in terms of your billable hours and the client's budget puts your work into a different perspective. It also opens your eyes how easy it is to pick up a new language or platform you may have never used before and to come up to speed in it very rapidly. Because you understand what is going on under the hood, its much easier to figure it out as you go.
char *vidmem = MK_FP(0xa000,0); As I remember it (no dos extender ;)
!removehelp.. sizeof(p)== ?
Yes, but import declaration does not depend on the physical location of the file, which gives us more freedom in the directory structure.
&gt; It's just going to be very bloated and slow unless you go out of your way to optimize (the "low level details"), but nobody who actually makes the web stuff cares about that. It's the user's problem if he doesn't have a fast enough phone/computer with a ton of RAM. Its all a matter of attitude. When you say that, What I hear is an opportunity to out innovate their bloated slow solutions... Look at how fast uTorrent replaced Azureus and how much better it was.
42 here, been writing code on a daily basis since 8. It's weird, I know there are several of us out there, but most days I feel really lonely when it comes to coding. It's rare to run into people with enough experience to have meaningful interchange. I dropped out of the work loop several years ago, the whole industry has turned too toxic and backwards for me. Java and Go were not created for us; they're for the drones, so they can go on doing their drone stuff without stepping on each others toes.
I agree, but one feather in C++'s cap is [on-line code generation](https://github.com/Ebenezer-group/onwards). 
what do you mean size of p ???? its a char\* 
that's how I felt until I discovered GROOVY. now life is just groovy, man.
From the sidebar: &gt; For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow.
So much __restrict, __assume, __likely, __unlikely, __attribute__((const)), and such in my code. One thing that bothers me is that __const__ doesn't allow dereferencing arguments... but almost everything in C++ is passed by reference, and it prohibits member functions from being __const__ because of the implicit dereferencing of `this`.
How is doing the same thing every time more consistent? It is the definition of the word lol.
Dont gauge your value based on Linkedin recruiters. They often send out shotgun solicitations without paying any attention to your actual skillset. As I said above, you should look into contract embedded SWE work. The pay is good and you learn a crap-ton on the job to expand your resume.
Good read. I have used Qt for a few applications &amp; enjoyed the experience. Really looking forward to reading topics 4 &amp; 6 when you finish them. 
We were listing for some pretty specific expertise applying C++, so depending on what you were looking for our roles might not have come up. Frankly, I say screen out the firms with the coding tests, at least below a certain size. At the senior level if someone is truthful on their resume you shouldn’t need to verify if they can balance a binary search tree. I can see why enormous firms use such tests to filter large candidate pools but really it’s rude in other situations. We’re not hiring at this exact moment but will be growing the team more through the end of the year, shoot me a PM if you want more details! 
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9f0due/c_how_to_convert_a_char_to_a_string/e5szbfy/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Packing more transistors into a cpu requires either smaller transistors or larger die area. Larger die area inherently means higher cost (fewer cpus per die) and this places a practical limit on the size of the cpu (outside server / hpc niche). So in practise we have pretty much reached ”peak transistors” and are living the gradual demise of Moore’s law.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programminglanguages] [Use std::array, Luke](https://www.reddit.com/r/ProgrammingLanguages/comments/9f16fw/use_stdarray_luke/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I learned how to program hard mode with C++, so when I got around to learning another language (python), It took a day to learn all the syntax and less than a week to get up to full speed.
There are plenty of people that make web stuff that care. There are just plenty more that are too lazy. Andrei Alexandrescu worked at Facebook for a while, during which he gave a number of interesting talks about optimization and performance. Facebook uses C++ for backend stuff because it's more efficient, meaning they can serve the same amount of traffic (or sell the same number of ads or whatever) with fewer resources, saving money. Same for smaller tech startups. Sure you can whip up something fast in node.js, and scale it up on AWS as you grow. But as you scale, you pay for those resources. Ive heard stories of companies being able to cut back resource requirements by orders of magnitude by re-implementing their services in C++ or rust or similar. Also have a friend that works in the aerospace industry, and his co-workers on the software side (who are about your age) bemoan the difficulty of finding fresh CS candidates that know how a computer works these days. So many CS departments are teaching JS or python instead of the C family, ostensibly for the benefit of teaching quickly, at the detriment of actually understanding the systems that the program runs on. Long live C++.
This may be a stupid and/or offtopic question, but is there a reason this code uses assert over static_assert?
That was going to be my suggestion: make sure your malloced data is at least 16-byte aligned. Use posix\_memalign if you want old-style C allocation. Or your suggestion.
Much appreciated. However, switching to `aligned_storage_t&lt;MAX_SIZE&gt;` and using `&amp;_val` in place of `_val.begin()` currently gives me a general protection fault when constructing `Var`. Still investigating...
&gt; [`std::any`] also doesn't allow obtaining references to the stored value Sure it does. For example, you can `std::any_cast&lt;T&amp;&gt;(x)` when `x` is an lvalue `any` that holds a `T`.
I would introduce Slots &amp; Signals before Events/Event loop because you don't need to understand the event loop before you can use slots and signals in Qt, and slots/signal is a big benefit of Qt. You rarely use events directly in Qt too, so introducing that right off the bat points people in the wrong direction, IMHO. Your content seems great though overall, and I think your topic list is spot on. I've avoided using QML for years, so I'll definitely come back to read that chapter. :)
What would be much more substantial than recompiling like rariez would be to take programs that don't need any special IO that a web page can't already give, and to make them single files that run in a browser. Something like abi-word ported to a browser would mean that anyone could easily have a word processor with no install regardless of platform from here on out. 
That's good news then :) I didn't manage at the time but I might have messed up otherwise. Still, I'm not even taking advantage of reference semantics yet.
Looking at `snabl/var.hpp`: you have a lot of code in here that expects `x.begin()` to return a pointer when `x` is an instance of a specialization of `std::array`. That's not guaranteed, and indeed not the case for many implementations. You should use `x.data()` when you really want a pointer.
&gt; Remember that feeling of accomplishment that you felt 20-30 years ago when compiling something that works. The problem is that, back then we were experimenting, had no ideas of how stuff worked unless we actually build something... Nowadays, with much more experience and knowledge, including theoretical - it doesn't seem productive. i.e. you know how compilers work, how OS is implemented, etc... So it doesn't make much sense to actually do it and reinvent the wheel unless you're working on some tiny part in the state of the art - academia/research...
So are you using C++ for UE4 scripting?
Got it, thanks.
Maybe you should ask yourself in which languages were the other languages written? The Oracle JVM is written in C++. Javascript engines like Chrome's V8 and Mozilla's are written in C/C++. The Oracle Java compiler is currently written in Java but how long did it take to get a native compiler? The same for C# compiler, it also used to be written in C/C++. Python is typically written in C but there are other implementations. Ruby is implemented in C. Do you really want to spend the next 20 years coding, languages aside? I know I don't. Getting paid to code only nets so much. There is more to life than coding, professionally or for pleasure/personal use.
A lot of these questions are/will be addressed in the final proposal.
Ah, I get it; copying aligned_storage, or any kind of bytes buffer containing imaginary values really; copies bytes, not values. I just pushed an update using `std::aligned_storage` instead.
How do you upgrade lldb on a mac (without upgrading the whole OS)?
yea my timeline was php-&gt;javascript-&gt;go-&gt;python-&gt;c++ in terms of learned sequentially. Looking back I think it's reasonable for early career developers to learn high-level languages first and then go down to the high-performance languages as the need develops. You'll be a better c++ developer too after seeing clear efficient high-level code. Learning c++ from the start I expect leads to giant files and globs of first-time code that "just works".
What do you mean, 'const doesn't allow dereferencing arguments'? Or that something prohibits member functions from being const?
 #include &lt;stddef.h&gt; #include &lt;stdio.h&gt; :( Parallel Algorithms STL have so much potential. std::execution::gpu? std::execution::heterogeneous? Could be really good when it matures.
No, i don't really want half-assed web developers being able to run whatever they want in my browser
When writing console test programs all day, `puts()` is convenient. Even `printf()`, as dangerous as it is, can be more convenient than remembering how iostreams manipulators work (even as a Standard Library maintainer I can never remember those things, whereas `%016llX` is easy). These are different concerns than production-quality application code, of course. (We are also huge fans of `using namespace std;` for similar reasons.) As for `&lt;cmeow&gt;` vs. `&lt;meow.h&gt;`, aside from the headers that introduce extra functionality, I view them as essentially equivalent - `&lt;cmeow&gt;` provides no actual increase in namespace cleanliness.
These are convenient because they require essentially no effort to enable and no additional dependencies (if you're already using msvc). But they don't catch, for example, general iterator use-after-free bugs. Shameless plug: If you want to catch all invalid memory accesses you can use the drop-in standard container replacements from the (header-only) [SaferCPlusPlus library](#https://github.com/duneroadrunner/SaferCPlusPlus). The modern "range-centric" C++ coding style de-emphasizes explicit use of iterators and tends to obviate the kinds of bugs that msvc's debug iterators catch. It does not, however, intrinsically solve the (implicit iterator) use-after-free issue. That problem is meant to be addressed by the lifetime checker, [when completed](https://www.reddit.com/r/cpp/comments/8zle4k/current_state_of_the_lifetime_checker). And for the most part it should, but in my estimation, as currently envisioned, the lifetime checker will be too restrictive to command complete adherence, so it'll still be valuable to have more flexible versions of the containers and iterators that can enforce memory safety at run-time when necessary. My 2 cents.
Everybody does. This is an educational blog post though. Please don't teach my students stuff I have to iron out again.
He's talking about GCC/Clang's `__attribute__((const))` which has nothing to do with the C++ `const` and instead declares a function to be strictly pure - meaning it cannot access anything not passed directly via arguments. GCC developers really could have picked a better name.
Depends on who you're asking, I guess...
You're not really old yet but you are gaining experience. Don't underestimate that. If you want some perspective, update your resume and have a look at the postings on a job site to see what companies are looking for even if you're not in the market at the moment. Keep your skills polished, seek out new programming experiences, play. Exercise your curiosity. Try new languages. Try new domains. Challenge yourself. Be optimistic. "if you succeed in doing this, tell me how"
&gt; But they don't catch, for example, general iterator use-after-free bugs. Can you explain further? Our debug iterators do detect when parent containers have been destroyed. (We can't detect more egregious misuse, like freeing the memory that a container object lives within and not actually destroying the container, or multithreading mischief.) We also can't detect pointer misuse (since they aren't class types that we can modify), so of course more powerful sanitizers are possible.
`superpure`
This is one of the reasons why I have a hard time buckling down to one language and trying to get a job that pays more than what I get now in my backup career(heavy diesel mechanic). Everything and everyones demands changing and not knowing where to keep restarting so I can stop turning wrenches.
I'm new to Qt so it's a good chance to know what it is, thanks :)
I don't think the others are necessarily dumb -- a lot of them are smart. I never said anything about intelligence. But a lot of people I weren't that good at problem solving, didn't use Google search for answers often enough, etc. It's really matter of persistence and being able to teach yourself. But most places that are hiring aren't going yo screen for those qualities when they give a coding interview. Not even the top industry names.
Oh, my mistake then. Was this always the case? I'm not sure why I had the impression otherwise. ... I just tried this code: { std::array&lt;int, 3&gt;::iterator it1; { std::array&lt;int, 3&gt; arrint1{ 1, 2, 3 }; it1 = arrint1.begin(); std::cout &lt;&lt; *it1; } std::cout &lt;&lt; *it1; // &lt;--- not caught } { std::vector&lt;int&gt;::iterator it1; { std::vector&lt;int&gt; vint1{ 1, 2, 3 }; it1 = vint1.begin(); std::cout &lt;&lt; *it1; } std::cout &lt;&lt; *it1; // &lt;--- caught (exception thrown) } The use-after-free was caught for the vector, but not the array. Is this right? &amp;#x200B;
That's right. I forgot about the `array` exception - that one's special because `array` must be an aggregate, so we can't inject our parent/child tracking. We can perform bounds checking, but not lifetime checking. All other containers track their children.
I had similar feelings around that age, but they are gone 8-10yrs later. I think the language itself does not matter that much, changed jobs a few times and realized that the environment affected my well being more than the stack. Being a lonely C++ guy will not be as motivating as working with N others together who are passionate about the language and pushing the codebase together to be better. (I did a year of Objective-C detour and enjoyed that too.) Ohh and had kids too, which first killed all side projects, but then I realized that I have to work harder on my focusing skills. Don't just sit down to learn a language, pick a problem and use that language/technology to solve it. Passion can help to get energy from, so a good project will help to get through the hurdles of learning a new ecosystem.
Ok, that makes sense. &amp;#x200B;
Start with java, JavaScript, or python. Probably in descending order if I had to choose. The changing demands are the impression you get when all the articles are written by bandwagon jumpers. There are plenty of companies whose main code base is in one or a combination of those, and they hire, but they're not writing articles. It's work, it's just not sexy work. (Ditto C and C++. There are more companies out there using those than you'd think from reading articles, but I don't usually recommend those as starter languages because it's learning to swim by jumping into the deep end.) Once you're in the door and have an idea how things work you have the perspective and opportunity to branch out.
&gt;std::execution::gpu? std::execution::heterogeneous? Executors will allow for this (2023?). Although I rather doubt the standard will every have anything to say about GPUs.
I don't see the pun, so it's unintended, yes :)
Is there any way to write my own executors?
Not really. I'm almost as old as you and i started my career with C, jumped to Java after a few years, learned JS, python and odd languages along the way. Of course if you want to learn stuff like Erlang that's harder, and to truly master any of them it takes time, but if you have a good base to start, these hype languages are easy to learn and start working with.
I think for outputting tables, printf is simply the superior tool (which says a lot about iostreams). I hope fmt will get standardized soon.
It is beyond me why this is posted. If you ever spent time programming in VC, at some point you will run into the `iterator debug level mismatch error` (linking mixed debug and release libs is the cause), that's when you learn, that debug iterators do a lot more than just iterate. The linked docs page is from 2016, but this goes back far further than that, the page just got updated then.
Indeed!
i thought 2 sigma did mostly java?
It's not webassembly but I think with GTK+ Broadway this could be possible.
&gt; recommend to use a build directory that is outside of the source one rather than a build/ directory within the source tree Do you mean outside of `src/` but still within your project's directory (i.e., still within the `git` root directory, if you use `git`)? Or do you mean outside of your source-controlled directory altogether? For the former, I didn't even think that needs to be a "recommendation" these days - that seems like holy gospel at this point. For the latter, that's more debatable.
C++ has never made me feel old, on the contrary, has made me feel younger :) your work and daytime job don't/shouldn't define you, you can pick any language in the morning or evening or weekend if you are interested in them, I highly recommend it, if not that's fine too, just do what you feel like :)
I actually have an embedded background from my university days. Where do I start in finding contract-based embedded work?
So what would you think about a corresponding debug version of `std::string_view` that, when constructed from an `std::string`, stores a debug string iterator instead of a raw pointer? I mean, a couple of reasons not to do it are that a) the lifetime checker will at some point presumably address the safety issue, and b) `std::string_view`s constructed from raw pointers would remain unchecked. But the on the other hand, a) it would be fairly easy to implement/maintain, and b) I think it would catch a lot of bugs. Just throwing it out there.
We'd call it "programming", but yes. There's normally some amount of blueprint "script" as well, but it often gets converted to C++ for performance reasons.
Yes, FBX SDK. Unfortunately, it's closed-source, so only Autodesk can make such port.
A build directory completely outside of the source folder.
Tell us more about your openings!
Sure I get that it is not mandatory to have the build directory in the source tree. Also I am not saying to forbid a build directory in sources. But I think it would be better to insist in the documentation to build out of source, in this idea of "good teaching" like you say. For experienced developer this may seems obvious, but someone that begins to learn C++ and stumbles on this proposed layout should be reminded to build out-of-source, in my opinion.
&gt; not being able to rely on a standard in-tree build location I am sorry if it is obvious, but I fail to understand the benefits of having a "standard in-tree build location." What is the rationale for this approach?
Indeed, but the same is valid for null pointers: if the pointer is null, an empty string should be printed.
Nobody said anything about control. I spoke of sponsorship. GCC and clang have been ahead of Microsoft on language features only. They have behind on standard library conformance, sometimes by a large amount. Microsoft is where the big ticket features such as Modules and Coroutines were sponsored. Lots more big ticket features are in the works, too, at Microsoft. MSVC is also the only remaining full stack C++ compiler wholly sponsored, from top to bottom, by a single company. You may not be aware of just how many people paid to work on MSVC, it's several fold the number of people paid to work on clang or GCC. Microsoft are one of the main financial sponsors of the biggest C++ conference in the world, and fund the largest proportion of WG21 expenses and running costs. So I think my claim that Microsoft is the primary multinational sponsor of the C++ ecosystem is a fair one. Google, Redhat et all come much further down the ranking in terms of money amounts invested.
My rationale is standard build locations means tools that manipulate build artifacts are simpler to write and use. No need to configure a bunch of output directory locations. That's the benefit of a standard location. The benefit of having them be in-tree isn't as big, but I like knowing that the affects of running build scripts inside a directory doesn't drop anything outside of it to build up. You can also just name the directory something generic (like "build") without worrying about different projects' builds clobbering each others' output. I'm open to being convinced that I'm overestimating the value of these things.
[removed]
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9evu37/im_a_34yo_c_programmer_but_i_already_feel_like_an/e5tztzh/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
https://en.cppreference.com/w/cpp/header#C_compatibility_headers Those headers are considered deprecated for C++ usage and are only there for C compatibility. Promote good practice, such as using non deprecated headers. 
also Andrzej's other article: [Using std::terminate](https://akrzemi1.wordpress.com/2011/10/05/using-stdterminate/)
https://gcc.gnu.org/onlinedocs/gcc/Function-Names.html &gt; These identifiers are variables, not preprocessor macros, and may not be used to initialize `char` arrays or be concatenated with string literals. 
&gt; auto x = ... is always successful regardless of what .. is. This "is not a bug, it's a feature". It allows you to change the type without going through the code to change it everywhere (similar to typedef-ing the initialized type). &gt; So if ... doesn't do what I intend it to, I will get a compile time error. You will get a compile error if you try to access a member on the auto-typed variable when that method no longer exists. &gt; This is an essential tool in designing a bug free, demonstrably correct program. ... and this is a red herring, because: - eliminating bugs through the type system doesn't make for a bug-free, demonstrably correct program; mistakes in writing software are a human problem, not a type-system problem (and bugs will show up outside of what you can enforce through the type system). - while you use auto, _you still rely on the same strengths of the type system_. Adding an inflexible point in code (explicit declaration of your type) simply means you will have to go and change one more thing manually when you refactor.
Python is a nice language for REPL stuff. I personally use it for data visualization.
Although they don't seem to impact these programs behavior much, usage of rand() makes me nervous. Did you check that it gives you, in your case, actual uniform random values? Anyway as long as there are cache misses i suppose it's not important.
Yes, SFML and other libraries like that. Seems like most non io libraries would work anyway, it's mainly io, data storage and networking that are impacted when targeting WebAssembly (though I didn't have time to play with it yet, I might e wrong).
assimp is ok for simple things. But then you try to run thousands of files created by artists using different software during several years you'll get a lot of failures: broken animations, parts of geometry missing or with a wrong transform. Just look at their issues page for examples: https://github.com/assimp/assimp/issues?utf8=%E2%9C%93&amp;q=is%3Aissue+is%3Aopen+FBX FBX format is really ugly and assimp library need to reverse engeneer all this ugliness handling which is present in FBX SDK. And by my esimates they are several human-years away from fully handling current versions of FBX.
I don't know why you're being downvoted. @snarfy: If the people I tried to mentor had as much enthusiasm for broadening their understanding by following all the stuff I taught as I had for teaching them when I started the job, I wouldn't be writing this stuff. But most of them seem to just learn the 10% bare minimum that was necessary to do the immediate task, forgetting the rest, and then return to me for help a few weeks later instead of taking that initial training and digging deeper on their own. Now my attitude toward mentoring is that unless the person I'm going to mentor demonstrates a good attitude toward learning, and not just doing the bare minimum, they need to leave me alone instead of wasting time that I can spend getting my own work done.
I didn't check that, but I don't think that high-quality random values are necessary to avoid prefetching.
It's not all peaches though, right? Can't work from home, there are insane restrictions on how you access the Internet, everybody expects you to work through the lunch hour, and the office competition is unhealthy. Just off the top of me head. 
I wonder if Skynet is written in C++17.
Only if you apply to work at one of the big tech multinationals. They'll have several segments on compsci theory, and you need to rote learn the answers, else you won't solve their problem in the way they like to see. It's just a hoop to jump through. You cram for two weeks before the interview, and if you pass you pass.
It will depend on where you are located. I would seek out any local companies that do electronic systems design and engineering projects for other companies. I worked for a smaller company that staffed about 30 in house engineers, half of them hardware half software and we supplemented some of our larger projects with outside contractors when needed. I was an in house sw engineer which was nicer as you have more stability between projects. Independent contracting does pay a lot more but it can be feast or famine, so you have to plan for that.
I'm pretty sure par_unseq is supposed to allow gpu execution, but it requires a crazy amount of compiler support.
It's irrelevant now. I left the team two months ago for a better one that doesn't have a lot of the problems of my old team. But it's performance review season. I wrote up my personal accomplishments list and was struck by the absurdity of having all these little mentoring items on my list rather than having more big promotion-worthy items.
&gt; Threading is outside the scope of this series but it is very well covered by the qt documentation. Not really. QThread is steaming pile of trash, you should tell people to avoid it. 
... in German.
I skimmed over the Google translated version, and it almost as good as the one in German: [https://translate.google.com/translate?hl=en&amp;sl=de&amp;u=https://blog.fefe.de/%3Fts%3Da5686503&amp;prev=search](https://translate.google.com/translate?hl=en&amp;sl=de&amp;u=https://blog.fefe.de/%3Fts%3Da5686503&amp;prev=search)
Yawn. Mindless rant on bounds checking due to not understanding the zero-overhead principle.
[https://translate.google.com/translate?hl=en&amp;sl=de&amp;u=https://blog.fefe.de/%3Fts%3Da5686503&amp;prev=search](https://translate.google.com/translate?hl=en&amp;sl=de&amp;u=https://blog.fefe.de/%3Fts%3Da5686503&amp;prev=search)
Why would it be?
That's his (Google translate) answer: Update : A terrible number of readers now write that Range Checks cost runtime and C ++ has just promised to stay neutral. I gave a talk about compiler optimizers over ten years ago . What was state of the art back then, not science fiction. And there is a section about range checks. Do you know what's there? Look for yourself! It's linked on my homepage. I'll wait that long. Finished? It says: Range checks cost nothing. Why? Two reasons. First, the compiler can optimize away unnecessary range checks. Not only can not do it. So they are only there in the unobvious cases. And when the range check lands in the code, it does not matter because the CPU is waiting for memory essentially all the time. A single L2 cache access takes long enough to completely hide multiple range checks in latency. And here we are talking about an iterator that you want to dereference. This means that there is guaranteed memory access. So and now homework: Build your own Vector with Range Check and do a few things with it. And then look if the compiler optimizes the range checks. And if not, then make a benchmark and try to measure the cost of the range checks. And THEN you can come back and try to tell me things.
Yeah not really anything interesting in there. Whoever wrote this post has no idea why always checking bounds for every array access is generally not the best idea( and a lazy way to say you don't know when exactly it could overflow). Range based for loops, vector.at(), etc. If you need safety you can have it, but I don't want to pay that cost for every access.
&gt; CPU is waiting for memory essentially all the time And mobiles will throttle down to save power if the CPU is really just waiting. Or throttle up and overheat if it is performing useless bounds checks alongside such memory waits.
&gt; I'd say the disappointment was due to thinking that all the engineers were as conscientious and motivated as I was. Which might have been true at one point. But recruiting is a mess, and all software engineers have equal standing in the company regardless of actual ability and background, so, yeah... Something's gone very wrong inside Google in recent years. It's widely recognised, including within Google, but there is a lack of leadership in there. Microsoft went through similar pains after Bill Gates left, took them over a decade to sort it out. Basically it has to go s**t for long enough that everybody buys into the steps necessary to des**t the situation. So I expect Google has at least another decade of dysfunction ahead of it. Regarding conscientious workers, that's a problem everywhere from the professions through to people who fill potholes. Most don't care, they're there for the money, and will do the absolute minimum possible to not get fired. If that means stealing work, plagiarism, riding coat tails, whatever. Remember they really, really don't care, they just say they do. In my opinion, I've seen the same happen everywhere, so it's obviously a fact of the modern workplace. Marcuse's *One dimensional man* and all that. I've also seen individual teams, even whole divisions, where there were no free riders, everybody cared deeply, and the culture was both proactive and positive. So orgs *can* do this if they want. If they don't do so, then they don't *want* to do so, and there are usually very good (and usually financial or strategic) reasons why they don't. They just don't tell you the substitutable cog in the machine, as you are irrelevant. Once you've working within enough orgs, it starts to all blur together. You don't sweat it. I also recommend taking a degree in Management, like I did. It's an eye opener on why orgs behave like they do, why they sow dysfunction, why they stamp down on employee motivation, and so on. All I can say is that usually it's incompetence, but sometimes it's deliberate. Organisational behaviour theory says an org must be tortured into real change. Cue much of what we see in the current US political climate, and how its tech multinationals are managed. Go theory! 
I actually think he has a valid point. Especially because he is talking about std::span subspan ([https://en.cppreference.com/w/cpp/container/span/subspan](https://en.cppreference.com/w/cpp/container/span/subspan)), which imho should behave equal to std::string substring, which actually throws ([https://en.cppreference.com/w/cpp/string/basic\_string\_view/substr](https://en.cppreference.com/w/cpp/string/basic_string_view/substr)).
After reading the article I was curious about a couple of things. - When talking about which algorithms to keep serial you state that performance didn't improve across your test machines. I was wondering if you had more information on what machines you used. Did you see any performance gains on increasing the number of threads to match the number of memory channels on the hardware? - Additionally I didn't see any mention on NUMA. Does your test machines include NUMA hardware, and if so did it see any performance improvements? - Is it possible in the future to have algorithms such as copy determine if they should be serial/multi-threaded based on the runtime hardware?
My take is that you can put everything build-related to another directory, and it will remain contained in this said directory. Personnally I have everything related to development in a `devel` directory, with sources under `devel/source`, and builds under `devel/build`. In any case you will have to configure the output directory locations; if you do not do it, it is because your tools have a `&lt;source&gt;/build` hard-coded somewhere, or it is the default configuration. Which means that if you do not have to configure it, someone who has a different approach will have to do so. This is not the same burden as-is for tools dealing with sources, since the point of reference for a project is the soure directory. In any case, I am not saying that having a build directory should be forbidden. My argument is that it should be encouraged by this document to have a build directory outside of sources, because this kind of advice may be followed by someone new to programming. A neophyte, not yet confortable with programming/compilation, would be more likely to use hard-coded paths, which would be easier to do with a in-source build directory. An experience programmer still has the opportunity to ignore the recommendation, knowing what he/she is doing anyway.
Well depends on where you work. Bloomberg is a good option, and is basically a technology company. Really good place for programmers to work. 
Haha, I'm yet to encounter the mythical unicorn dev team actually balancing search trees in day to day work :p I think those tests are pretty much BS and I think most teams are coming around to that too, I think 14ned is dead on that the only places you'll consistently see them are the huge firms and then it's really just a prep test. 
Interesting. I don't know how much has changed within Google since I hadn't worked very much in the main tech stack and code base until the previous job -- I had been on some other teams that were more specialized, and learned a lot from them. This job was the first job that actually made me suspect there was some intentional organizational sabotage a few levels above me to keep the projects from getting done quickly and efficiently, because then they'd have nothing to do and would be forced to come up with new projects.
&gt; This is at least partially because Windows supported Unicode before the existence of UTF-8 UTF-8 was officially unveiled in January 1993 (see [wikipedia](https://en.wikipedia.org/wiki/UTF-8#History)). Windows NT was the first Windows to support Unicode, and it came out in July 1993 (again, [wikipedia](https://en.wikipedia.org/wiki/Windows_NT#Releases)). They could theoretically have rewritten their public-facing APIs in the six months before release, right? :P Slightly less ridiculously, Plan 9 From Bell Labs was using UTF-8 in 1992. See Rob Pike's [history](https://www.cl.cam.ac.uk/~mgk25/ucs/utf-8-history.txt)
Thanks for posting here, always like to read and keep track about what's going on in the build-systems/packaging world. A few comments regarding your [canonical project structure](https://build2.org/build2-toolchain/doc/build2-toolchain-intro.xhtml#proj-struct): I disagree with many of your choices and arguments and would never use them like that in my projects. For example prefixing libs with `lib...`, and not separating public API headers from private headers (there might be sensitive code in private headers, so it's important that private headers are separate and _not_ `install`ed. Also I personally put tests into a separate directory - even though tests "belong" close to the code that they should test, it's just not nice to have a huge directory with all sorts of `*.cpp` files. Tests can go nicely in their separate `tests/` directory. How well does build2 support these from your perspective "non-canonical" layouts? Can I keep my preferred layout and still easily benefit from all of build2's cool stuff without having to make adjustments and configuration changes? On many things that you say I of course completely agree, like to include files with their folder/namespace prefix, etc. One question regarding `"..."` vs `&lt;...&gt;` though: You say "_The problem with the "" style inclusion is if the header is not found relative to the including file, most compilers will continue looking for it in the include search paths, the same as for &lt;&gt;._" But if that's the same with quotes and angle brackets, why use angle brackets? From your text I don't see the difference or why not to use quotes. You should get in contact with that other person that posted a survey here a few days ago about project layouts. The approaches of you two differ quite a lot.
My guess is you may have compared a debug build with a release build. :) Probably the most frequent elementary goof I've seen people do when testing perf without using a reliable benchmarking framework and doing AB testing in a single binary. :)
GCC has ASan and UBSan. Both have TSan. Few checks are implemented in one but not the other (check the Sanitiser project online which documents these differences). GCC has been improving in terms of diagnostics. All and all, both compilers are pretty close imo. I think people throw too much flak at GCC. Granted some criticism is warranted, but credit should be given where it is due, and GCC has taken us very far.
I can't say for Google, never worked there, they don't hire C++ contractors any more. But I can say that I've worked in a number of multinationals where I was explicitly ordered by my management to use all available technical measures to sabotage divisions who were a problem for our division's progress. So, for example, to fake-create or create products or services deliberately designed to make a competing division's products or services look inferior and made by incompetents by showing up their failings; to sow discord during technical meetings to promote stridency by the leadership of other divisions in order that they look shrill and partisan in front of management; to throw technical banana skins in front of other divisions to tie up their best staff in pointless rabbit hole work to damage their productivity ... well, you get the picture. This no doubt will sound terrible to most on /r/cpp, and I'll no doubt get down ranked and probably lots of meme bullying on Slack for it, but in the end this is how big multinationals work the closer you get to the Board, in any industry. Most developers never see this stuff, they're insulated from it, they also tend to have overly moral reactions to it. But basically there's a pie to be sliced, top management are almost always overloaded and make decisions based on relative weighting of appearances rather than accurate information, and it's very, very competitive. Failure to compete means your division loses head count relative to others, because believe me the other divisions are doing the same stuff to your division so they don't get left last man standing. And there are a lot of very bright middle management people all reading the same Management literature as everybody else. So you get this stuff happening, unless senior management demonstrates some leadership to prevent it. One enormous advantage of contracting is that you opt out of that stuff. You get to be a worker bee. You don't really care what you work on. It's whatever the client want you to do e.g. copy and pasting all day every day for a week, sit in meetings for a week. You don't think too hard. After 12 months you move onto the next client after a well earned vacation. Prevents emotional investment, prevents all the politics, prevents disappointment. You work to live, not live to work. 
Just partially, C++ has been slowly fading away from user space code on the UWP front. Even the UI team now does their high performance visual composition layer demos in C# (.NET Native), although the underlying implementation is in C++. On one of the presentations of C++/WinRT there was the remark that app developers didn't picked up C++ for UWP development as WinDev group was expecting they would.
if using python, you will feel much much more older. because even a 5 yr old kid is learning python.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9f7vvb/hello_fellow_devs_what_are_the_most_important/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Nice to see this project alive.
LLVM has stricker rules to get patches in, I think.. Many devs will give you valuable feedback and with every feature/bugfix you need to provide set of new tests.. Sometimes you send a new feature (maybe just 20 lines of code) and a test file for it has 600 lines :D 
And the same is for gcc. Patch + test + review
\&gt; How well does build2 support these from your perspective "non-canonical" layouts? I'm experimenting with build2 and have participated to feedbacks, so I can probably give you a good answer on this: \- The standard layout is more like a strong recommendation than a prerequisite, just to be sure it's clear; \- You can not use "lib" as a prefix, the only effect is that you will get a warning if you do so when using "bdep new mylib -t lib ... " (personally I don't like to prefix library names); \- Almost all the layout is basically dependent on how your buildfile is described, so you can have include directory if you want (personally I do not like to have an include directory in most projects); \- There are some layouts that are definitely not supported but they do make sense and are extreme. Like using the "build" directory name at the root of the project might be problematic as it is used by build2 to find some of the build scripts. Boris can probably give better examples. \- If you read the mBuild System Manual, you will see other layouts that kind of show that; \- "bdep new mylib -t lib ..." will create a library project that will have this standard layout, but as said most of the layout is dependent on how the buildfile is written, so you can modify the buildfile to your convenience to match how you want to setup the code. &amp;#x200B; Honestly, I don't think build2 will impede anybody with files layouts. In some ways, the project is clearly defined (what is test, what is installed, what is not installed, etc) in the buildfile which are declarative enough to make finding the info you want easy.
Mailing list vs. *Phabricator*
I agree, I think you are correct and I misread it. That said, I do think there are several passages that make it easy to misread/misunderstand. The definition of type erasure is still IMHO really the definition of polymorphism, and that combined with seeing templates alone in the sub-title and in the chart led to some confusion on my part. So I accept responsibility for misreading and apologize for that aspect, but I do still think the post could be improved significantly.
My only complaint with GCC was GNU Contributor Agreement. I had found a bug in libstdc++ and the solution was quite simple. I thought I'd just send in the patch but following links after links I realized that I need to sign some papers and send them to FSF, instead I just opened an issue in bugzilla. Granted this was years ago and things have changed or maybe I misunderstood some of the parts and process was not actually that complicated but at that time I thought that barrier of entry was a bit higher for GCC.
&gt; for C++ developers - a blog post series103 points · 4 comments · r/cpp Posted by u/alexfagrellPosted byu/alexfagrell20 hours ago &gt; 4 I'm interested to know what you don't like about `QThread`? What would you use instead? moving a `QObject` to a `QThread` is rather straightforward and by using signals and slots you can easily and safely pass data from the worker thread to the main thread. Also perhaps I can improve the wordings by using "running concurrently" instead of "threading", in order to incorporate things like `QtConcurrent::run`.
Luckily I have a principle of not working anywhere that requires me to participate in silly tests (be they coding or personality tests). If references, list of publications and code sample aren't enough, I doubt it's a place I'd enjoy working at anyway.
I think GCC and Clang a close. Bute check the difference when it comes to vendor compilers... Or closed source compilers. I think we can be really happy to have clang and LLVM.
Hey, thanks for your comment! Appreciate the feedback. It's a very good point that signals and slots will be used more compared to the event system and arguably more important. My thinking was that the event loop is one of the first thing that you'll encounter, i.e. `app.exec()` in main, when using Qt. The fact that the flow of the app is _event-driven_ is important to understand when working with a GUI toolkit and thought it would be good to introduce early on. Perhaps not as a first topic though. Hmm... I'll have to thinking a bit more about it. Also, considering all the up-votes you've got, people seem to agree with you. Thanks again!
I rant about that the OP didn't rant in English.
It isn't happening if you disable javascript. And WebGL. And geolocation? webRTC? Cookies?
This is a very lazy argument. Declaring bounds checking universally free because the overhead disappears in some workloads does not mean it's never a problem. I have had to change code using gsl::span&lt;std::byte&gt; to pointers because debug builds where unbearably slow. Similarly the debug features of Microsofts stl implementation make it a pain to debug iterator heavy projects on windows. We are not talking about small differences here - it's going from milliseconds to seconds - and that adds up fast. There can be a very real performance impact from bounds checking in some circumstances. Being able to opt out when needed is important. As a side note: std::string has bounds checked accessors, they are just optional to use. &amp;#x200B;
GCC has gotten significantly better over the past couple years
They are quite close as far as compiling code to instructions, yeah. The huge difference is when you try to build tools that benefit from integration with the compiler or wish to re-use some of its functionality. For example: 1. Using the compiler's lex/parse layers to drive code completion, type inference and jump-to-definition functionality inside my IDE. 2. Integrating tools like AddressSantizer or UndefinedBehaviorSanitizer that require instrumenting/intrusive compilation. 3. Using the lex/parse layers to implement linters and sanitizers without reimplementing anything. 4. Using the AST and lex/parse layers to dynamically rewrite code, for instance when updating a library interface in some automated way. Google is big on this, I saw a talk where they basically said that teams pushing internal libraries are permitted to modify company-public API if they provide an automated upgrade tool, which is just awesome code-modifying-code-as-data. 5. Using the AST to write a code-to-code compiler (transpiler?). I've seen a few projects where people were like "well, my stupid &lt;embedded device&gt; only understands &lt;some arcane dialect of a moribund language&gt; so instead of learning that language, I wrote a tool using clang to transform some subset of C/C++ to that language". Check out some of the [examples](https://github.com/loarabia/Clang-tutorial) here. Clang is [b]not just a compiler[/b], it's a whole set of modular layers with documented C++ APIs for each stage of the compiler pipeline. See also http://swtv.kaist.ac.kr/courses/cs453-fall13/Clang%20tutorial%20v4.pdf and https://kevinaboos.wordpress.com/2013/07/23/clang-tutorial-part-ii-libtooling-example/ for some more narrative approaches to explaining the power of clang. 
&gt;!Despite the fact that Boost.Beast is a great library and is bright example of C++ masterpiece, we think that usage of Boost.Beast for simple tasks is an overkill. Simple things must be done much simpler than approach proposed by Boost.Beast.!&lt; s/simple/easy
 Hi /u/berium, quick question: is there any documentation with examples/instructions for adding build2 support to an existing project, in parallel with an existing CMake build system? 
You make a decent point, but it would be a more useful post if you'd give some examples. For instance, I love the way tuples are simplified. auto [result_is_valid,result_value] = function_that_maybe_returns_something(); V.
Not at the moment though we are considering adding an example of how to support the split `src/`/`include/` layout (seeing that about 50% of the C++ community prefers it). However, if you read through the build system [Introduction](https://build2.org/build2/doc/build2-build-system-manual.xhtml#intro), you should have a pretty good understanding of fundamentals to handle pretty much any project layout. In other words, there is no magic or black boxes.
Thanks! Yes, the project is very much alive and kicking. In fact, the previous release was only 3.5 months ago. Looking back, I can't believe we've managed to cram this much. Talk about C++ being a slow language to develop in.
&gt; However, a manually implemented function is considered as user-declared by the standard, whereas a function that has been explicitly defaulted at its first appearance is not. In turn, having user-declared constructors or not influences whether a type is considered an aggregate, You mean user-provided. struct Foo { Foo(); // user-declared and user-provided Foo(Foo&amp;&amp;) = default; // user-declared // implicit destructor =&gt; none of those };
As someone who’s done LLVM upstream patches, and also tried to do GCC upstream, my experience was identical. It’s a sad fact of the litigious nature of some countries wrt copyrights.
The blog post written today says the first non-Windows builds using LLVM will land in the next nightly and as far as I can tell the Windows build first landed around a week ago or so in betas/nightlies. Are you running a non-production release channel?
&gt; On one of the presentations of C++/WinRT there was the remark that app developers didn't picked up C++ for UWP development as WinDev group was expecting they would. I do have to admit that if I were writing a UWP app - or indeed *any* GUI app - I would not choose C++ for it unless there were very good reasons that I must.
Oh absolutely. GCC has taken us far, but it is deeply crippled by an (explicit) desire not to be a modular set of tools with well-documented formats and interfaces. As I wrote in another post, it's a perfectly competitive compiler just for taking code and making products. It falls apart when you want to do things like taking intermediate output, rewriting code or other tasks that would benefit from modularity.
What's so [complicated](https://cdn.rawgit.com/adishavit/Terminators/master/termination_graph.svg) exactly here?
&gt; We think that Boost.Beast is a great library. But it is too low-level. funny considering that Beast was made because "Boost.Asio is a great library. But it is too low level".
indeed. whatever you do it all comes to the END.
I can't take seriously a library author or community who thinks it is worth spending time slagging off the competition, especially when boost is doing a great job in facilitating C++'s usage in an area where we usually don't thrive much.
Many parts. Usually the engine.
&gt; The thing about these choices is that they are well-substantiated (IMO) with rational arguments (in the numerous notes) I agree and I've read the notes. However you know as well as I do that there are well-substantiated, rational arguments for doing things differently too. Many of these things boil down to how an individual or company weights these pro/cons arguments, and we all weigh them differently. This is a topic where there's really not "the one" answer for many decisions. This other person that has posted a couple of threads here over the last few days, he/she has gathered much community input over the past weeks and months, with the goal of (also) coming up with a consensus, "canonical" project layout for C++. I'm sure you can find the threads on /r/cpp and the link to GitHub. It's similar to yours in many points but it's also different to yours in many points. Some of them I've highlighted, and the source/header split you acknowledge by yourself that around 50% of the community do it differently, with very valid, well-substantiated and rational arguments. &gt; Do you see any flaws in that reasoning? I do, it's mainly what I mentioned: I don't want to maintain a separate list of which files are the public API headers, and which ones are the private ones, to make sure we only ever install the public ones (the private ones are not for the public eye!). And even with such a list, mistakes are bound to happen if all the files are in the same directory - and mistakes in that case can be costly (you're shipping things that a client is not supposed to see). I also don't buy your "cons" arguments - navigating is not harder if they're all in one directory, on the contrary, it's much easier to find the appropriate files if they're in separate directories. A good IDE (or configured cmd-line editor, if you wish) can help too. Okay you're not wrong and I guess you can say navigating is harder because you need to open two file explorer windows instead of just one - so yea you're not wrong but there is as many rational arguments for exactly the contrary, and you and I just weigh them differently. I also don't buy "it is common for public headers to include private" - no, a private header should never be included by a public header - it's private code, so it would only ever be included by a .cpp file, and not exposed to a client, ever. What you mean is a sort-of "implementation details" header, which you rightly say could be put into a `details/` folder/namespace - this is something else: It's an implementation detail, that can be put public, but you're "hiding" it from clients, mainly to not confuse them or because it's an internal detail where you don't give any guarantees that the API will stay stable. This is different from private/public headers. &gt; You could use `"libhello/hello.hxx"` since it is unlikely to trigger the "relative to includer search" (but still possible). It's just looks strange and why take that slim chance if we don't have to? Understood, thanks! So the double quotes (can) trigger relative include search, while the angle brackets only search all the include paths that have been given to the compiler. Hence we should only use double quotes for relative includes (which should be used only in rare circumstances like private headers anyway), and otherwise always angle brackets.
I'm 35 and feel like and old man but that's because I'm an unhealthy slob. C++ goes through ebbs and flows but right now it's definitely in a flow. I don't think you will have a problem finding work. There's a lot of renewed enthusiasm post C++11. There's a lot to love about a lot of languages. I use C++, CMake, and Javascript at work and Javascript at home. I do a ton of bash scripting in both places. I admit that I have done things in Javascript that are extremely powerful and would require _a lot_ of C++ code. It'll run like crap and I've come to terms with it. On the other hand, Javascript is a complete nightmare sometimes. There is no perfect language for everyone and for every job it's impossible. Anyway, my 2¢ is that you are continually improving and changing the way you do things in C++ as the language evolves and switching to a different language is going to be the same way so don't sweat it, you just start with a different syntax/paradigm. Additionally, I think that working in different languages has helped me to improve in C++ so I recommend it. Try Rust. Try D. I am positive you will find things you like over C++ and things you don't.
I'd be interested how you call into a C++ backend with C#, performantly.
Personally I see a problem with Boost libraries. There are many C++ developers (especially young and not experienced) why look for libraries in Boost only. They want something to work with HTTP and they look into Boost and see Boost.Beast. They think "Hey, it is the best way to work with HTTP in C++. Just because it is Boost." They don't look further. And they write a lot of code just because Boost.Beast is low level library. It's a building block for something more simple and comfortable. But many just don't understand that. For example, there is a new library that was discussed on Reddit recently: [https://github.com/0xdead4ead/beast\_http\_server](https://github.com/0xdead4ead/beast_http_server). It's a high-level wrapper around Boost. And many C++ users need something like that. But they don't look futher than Boost and because of that they use low-level library. And just don't know about alternatives. So, if you want, our example is just a reminder: Boost.Beast is a great building block for something complex and powerful. But if you have to build a simple RESTful service, then it is better to search something outside of the current Boost.
&gt; hen someöne throws an exception Mööse-launched?
Please, make it happen. I hate myself for setting up those projects over and over again. :(
&gt; I'm a 34yo C++ programmer but I already feel like an old man. I'm a 37yo Java/JavaScript programmer who writes C++ at home *just for fun*, and I must say these young JS programmers have a much more "old man" behavior than me. They know a few tools besides JS itself and they refuse to learn anything different from what they already know, because they believe to be the cream of the crop. Even worse: most of them fail to understand basic Computer Science concepts like data structures and complexity analysis. They don't even know what Assembly is (oh yes, I've heard about WebAssembly, it looks so cool, I'll write a Medium post about it!). Sigh.
As I said, I have not had to write a ”proper” CS algorithm even once during my 20 year software developer career. Requiring offhand knowledge for such just sounds so bizarre given that vast majority of software development is more or less trivial shuffling of data and applying domain specific knowledge.
Maybe I am biased as I spend most of my time on managed languages, however I do feel that C++ has lost the GUI "war", as with the exception of Microsoft, all major UI platforms use it for the graphics layer/composition engine, but then stack something else on top.
&gt; I don't want to maintain a separate list of which files are the public API headers, and which ones are the private ones, to make sure we only ever install the public ones (the private ones are not for the public eye!). And even with such a list, mistakes are bound to happen if all the files are in the same directory - and mistakes in that case can be costly (you're shipping things that a client is not supposed to see). Ok, I can see a need for this. In other words, you private headers are proprietary information. &amp;nbsp; &gt; I also don't buy "it is common for public headers to include private" - no, a private header should never be included by a public header - it's private code, so it would only ever be included by a .cpp file, and not exposed to a client, ever. What you mean is a sort-of "implementation details" header, which you rightly say could be put into a details/ folder/namespace - this is something else: It's an implementation detail, that can be put public, but you're "hiding" it from clients, mainly to not confuse them or because it's an internal detail where you don't give any guarantees that the API will stay stable. This is different from private/public headers. Ok, so there are public headers (installed), implementation detail headers (installed, kind of like C++'s `protected` in a sense), and private headers which should not be installed. It seems your main concern is making sure private headers are never installed. So I am wondering won't this be better achieved by placing them into a subdirectory, say, `private/`, similar to `details/`? Especially if we start considering moving to modules where there is no longer a need to have the interface/implementation split. 
Easily, ever heard of C++/CLI?
Yes, exactly! :-) &gt; So I am wondering won't this be better achieved by placing them into a subdirectory, say, private/, similar to details/? I would say no, for two reasons: First, in that sense, the .cpp files are private too, yet you don't put them into a private/ directory (maybe that's not a good argument). Second, maybe more importantly, it still means you need to either maintain a separate list of which headers are public API and to be installed, or you need to rely on a regex in the build system to install everything *but* files in any `private/` directory. That would work I think, but personally, I really prefer to have a separate `include/` directory where it's clear that everything in there is public API, and a separate `source/` directory where it's clear that everything's private (not for public eye), and I think it's less likely to mess up or make mistakes that way. I have to say that I do not know too much about modules, so you may very well be right that your approach is better if modules are being taken into consideration.
&gt; First, in that sense, the .cpp files are private too, yet you don't put them into a `private/` directory. Why not? In the `build2` canonical project structure you keep the source file (and its unit test file) next to the header. You have to admit there is some simple elegance to that ;-). &gt; you need to either maintain a separate list of which headers are public API and to be installed In `build2` headers are installed by default so you would need to specify which ones to exclude. If all your private headers are in `private/`, it is as easy as: \ private/hxx{*}: install = false \ Which, BTW, is the same mechanism you would have to use to not install headers from `src/`. So either way one extra line in the `buildfile`. &gt; I really prefer to have a separate `include/` directory where it's clear that everything in there is public API But what about `details/`? It will also have to be in `include/` (since it has to be installed).
True; no one is watching over my back here, this is all for the joy of creating useful tools. Coming back to C++ after a break brings plenty of surprises. It was complex enough to reason about when I left; these days it's a mine field. Especially move semantics, I'm still not sure when I should and when I shouldn't bother; in some situations it makes all the difference, but comes with its fair share of undefined behavior. I stole my first C++ compiler from the school library in 94; it's been a long, long ride.
The zero overhead "principle" COMPLETELY depends on compiler optimizations. Otherwise, C++ is absolute garbage when it comes to perfs (just look at the assembly produced in a debug build, and the depths of non-inline templates). So yeah, bound checking is virtually free, and even if it was not, it is quasi-criminal to not include it *by default* in 2018 given what the security picture has become. And you know what? Even the "virtual" part in what I wrote: "virtually free"; I take it back. Compared to tons of other C++ features and designs (virtual functions, template insanities, design of iostreams, etc...), bound checking IS free. At least it is "more" free than TONS of other features. So not calling it free by making an informal appeal to a not well defined principle of zero-overhead is bullshit. 
&gt; This is a very lazy argument. You can't just declare bounds checking universally free because the overhead disappears in some workloads. So what? Make [] mandatorily bound check, and introduce a unsafe_at() methods for the 0.1% of people who are better than the compiler at optimizing the 0.1% of the code that needs to be. 
You don't understand how a CPU work. It will certainly not change its frequency while waiting for memory accesses.
&gt; LLVM has stricker rules to get patches in, I think.. Not harder than any decent OSS project you can find, say, on GitHub. Create a patch/diff, send a review, update according to feedback - done.
How does webassembly change things for someone who has JavaScript disabled?
GCC still optimises code better in some cases that I encountered. In benchmarks that I did for numerical code it produces faster code than clang. GCC is not dead.
The c++ designers went for consistency with c arrays for [] and added a bounds checked method in addition. I think it is better this way. Especially as you don't use either of them very often in c++.
&gt; The zero overhead "principle" COMPLETELY depends on compiler optimizations. Otherwise, C++ is absolute garbage when it comes to perfs [...] I would say that this is a little bit too extreme, but I agree. The fact is that compilers are allowed to optimize your code only if the optimization do not change its meaning. If the compiler cannot prove that you will never go out of bounds, the bound checking code will have to be generated. On the other hand, if the bound check code doesn't exist in the first place, that possibility of having an extra check in the final binary is zero. --- &gt; Compared to tons of other C++ features and designs (virtual functions, template insanities, design of iostreams, etc...), bound checking IS free. Then use it. Use `.at` instead of `operator[]`. Write your own wrappers around `std` containers or your own containers. If your project can take the potential performance hit, then I see no reason to not have bound checking. However, the Standard Library cannot make that assumption for every project, therefore it provides both `operator[]` and `.at`. 
&gt; you keep the source file (and its unit test file) next to the header. You have to admit there is some simple elegance to that ;-). Simple yes, elegance I am not too sure ;-) I'll stay in the "separation" camp for the time being :P Some private headers may not have an associated .cpp file. So basically with your idea, you'd put them into `private/`, as well as the .cpp files that have .hpp files which are private. Well yea, I don't know, maybe that'd make sense. Still, I think it's really about separating "public API" from "Private implementation", and I see the pros of that separation (into separate directories) way outweigh the cons. Even though I completely agree with you that build2 seems to make it super-easy and more or less fool-proof to for example add a regex to not install private headers. I'd put `details/` inside `include/`, yes, since they're supposed to be installed, and clients can technically use them if they really wanted to, but the documentation and namespace makes it clear that if they do, they're on their own.
We're limited in what we can do with `constexpr` iterators (http://eel.is/c++draft/iterator.requirements.general#13). The iterator debugging machinery necessarily needs to perform all sorts of side effects to link iterators to ranges (and vice versa) which is not possible in a constant expression.
Interesting read. Please keep on writing.
Well, when I've read initial bug Firefox report/issue on switching to clang I remember a lot of reports on regressed performance and binary size. Maybe they've managed to fix it with LTO/PGO,
&gt; On the other hand, if the bound check code doesn't exist in the first place, that possibility of having an extra check in the final binary is zero. Yes. And that's the problem. Not the solution. The compiler is going to be smart enough in the cases that you would have been. For the others, you will 99% of the time not write a proof that your bound checks are not needed, so short of any serious evidence that they are not, they should be there. Especially given what usually happens if they are not, and a mistake was done. Which *always* happens in non-trivial projects. As for the costs that are minimized, that's merely an informal tendency, but if you consider the language comprehensively, there are even areas where major implementations are stupidly slow compared to what could/should have been done in an optimized way. Dynamic cast navigation through complex class hierarchies comes to mind. So at this point AND given the technological context that the C++ is used in, calling for zero-overhead feels more of an excuse than of an up to date sound rational. Especially when the *default* is to be unsafe. Which project does comprehensively use .at() except in profiled places where optimization is known to be needed? &gt; However, the Standard Library cannot make that assumption for every project, therefore it provides both operator[] and .at. That's not needed ([] could be checked, and unsafe_at() could be provided when it is actually *needed* to be guaranteed to be unchecked, which is something extremely weird to desire, but whatever), but I understand that it is now historical and that this basically can't not be much changed for *EXISTING* classes. For new stuff, no reason to be unsafe by default. Not even consistency, given all the other things we discussed (*most* of the time checked version will be free). That's one of the major point of the linked text.
Same. My dream web framework would be based on C++. I do a lot of web dev these days, but I come from a C++ background. JS is great for small services and websites, but you really want a strongly typed language with compile time safety for a large project. &amp;#x200B; I basically want Node++. Unified C++ front end / back end with semi automated shuffling of data between the two. One can dream. &amp;#x200B;
&gt; the litigious nature of some countries wrt copyrights The USA?
Do you mean cross-compilation by architecture or source-to-source transform?
HPC is an excellent example of an area where all the advantages of Clang/LLVM are less salient. Also, I didn't say GCC was dead, I was just hoping that they get on board with the 'a compiler is a set of modular tools with well defined interfaces and data interchange formats such that they can be reused to do different tasks beyond just compiling code into executables'. It's not that they will die if they don't, but that there is a lot of value in having an ecosystem built around a compiler.
Still crippled by an extremely arcane and archaic codebase.
Clang does better in other cases.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9fc842/help_with_code_for_class/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I often end up with several `build` directories. Personal project will have gcc, clang, libc++ vs libstdc++ , with x86 and rPi variants. Work Linux, Solaris, and AIX, possibly 32 and 64 bit, plus intrusive instrumented builds. Reserving `build`, `.build`, `_build` is ok, but don't expect anything there, or maybe multiple things. This currently shows up in finding a clang compilation database. Tools get lost. We can all agree that .o don't show up truly in-tree, in the same directory as the source? 
&gt; Does Clang have PGO like gcc -fprofile or AutoFDO? https://clang.llvm.org/docs/UsersManual.html#profile-guided-optimization
I'm experimenting with this case (I have made some attempts but lacked documentation on some parts, notably exporting libraries, which is now a solved problem) so I will try to take notes if I end up with something that works most times. Don't hold your breath though, I don't know if or when I'll have enough info.
&gt;Still crippled by an extremely arcane and archaic codebase. I once tried reading the GCC source to make a quick fix. Never again. 
Saying that extra work isn't a problem as you're cache-size limited anyway is nonsense when that extra work will result in more instructions, bloating code size and increasing cache pressure further.
With clang it is as easy as passing `--target arm-linux-gnueabihf` or similar argument depending or your target. As long as it was built with arm code generation target, it will work just fine. Here's [example](https://github.com/mmozeiko/rpi) how I compile for raspberry pi from my desktop. Check out boostrap.sh script that compiles clang itself (nothing special, just running regular cmake), and setup.sh that sets up env variables &amp; clang command-line arguments.
No mention of automatic template type deduction? Definitely one of the best QoL features (makes `pair`, `tuple`, container initialization, constructor value return, etc so much easier)
Whoa thanks, i never knew, i've been on GCC for way too long and assumed i need a crosscompiler. `clang --target=arm-none-eabi -mcpu=cortex-m0` does what i expected
Sorry. I thought the first part of the title would be as fun as the first part in the recent post "[Get Rich Quick! Using Boost.Beast WebSockets and Networking TS (CppCon 2018)](https://www.reddit.com/r/cpp/comments/9e0thl/get_rich_quick_using_boostbeast_websockets_and/)". Because my post is just a direct consequence of that Vinnie Falco's post.
But Edge is the safer, faster browser. [Microsoft says so](https://www.theverge.com/2018/9/12/17850146/microsoft-windows-10-chrome-firefox-warning)
yeah but skynet isn't the Linux kernel
[It’s at least in C++](https://bitbucket.org/jlippuner/skynet) Some dumbass probably doomed the world by throwing from a destructor. “// can never happen”
You’re right, see my other post in this thread.
And because Microsoft says so, you believe it? Edge is also terribly slllooooooowwwwwwwwwwwwwwwww!
Yes, `build2` has three level of, let's call it *project separation*: 0. You can have a component, say a library, as a subdirectory in an executable project and just include its `buildfile` and reference its target directly. In this case, they are one and the same project. 1. You can make the library a separate project and import its target from the executable project. In this case, you have several options as to how the library project will be found: You can still put it into the executable making it a *subproject* -- this is physical bundling. Or you can have them as two independent projects in which case you will normally configure them in a shared build configuration so that they find each other automatically (I think this would be similar to that CMake functionality you refer to, though we don't we don't have any machine-wide registry of configured projects). And, yes, this will also work for installed libraries (including the `pkg-config` functionality). 2. You can make your library project a package and in your executable add it as a dependency (as well as which repositories it comes from). This will make it possible to automatically fetch the dependency from a remote repository if it is not available on your (or your user's) machine. The first two levels (where your dealing with build system projects only) are covered in the [Build System Introduction](https://build2.org/build2/doc/build2-build-system-manual.xhtml#intro). For the last level (where you are starting to package things), see the [Toolchain Introduction](https://build2.org/build2-toolchain/doc/build2-toolchain-intro.xhtml#guide).
I hope you have seen the irony in the original post. I don't see it in yours. Actually, Edge often feels much snappier than firefox to me. But I use it very rarely, so that might just be specific to individual sites or a specific pair of browser versions.
No, you didn't :). What's its GitHub link?
[I think this is what you're looking for.](https://www.youtube.com/watch?v=dQw4w9WgXcQ)
No, I am sorry to say that I didn't, I must be losing my sense of humor (even though I did see the MS-link before the OP's post). Thanks for re-minding me. I find that Edge is slow to open, that's what I was mostly referring to. If you use it rarely you might also not have many (or any plugins, I have most of the ad-related plugins, maybe you haven't) installed, which might make it compare favorably to FF (where I have even more plugins installed).
Maybe a topic on creating a qml app and deploying it to an android phone? It's a relatively painless experience with high rewards. And maybe I missed it, but I'd also provide code samples + cmake files to jump-start readers.
You were the one curious about how to call C++ from C# in a performant way. For the CLR JIT compiler and COM runtime infrastructure it doesn't matter what language was used. Any .NET developer that doesn't understand the tools available to them isn't taking proper advantage of the platform.
If you're on a trading desk, that's all true, but then you're also being paid a lot of money. There's a lot of more IT-ish jobs in finance that are nicer for work/life balance. The finance industry is competing against Google for devs, so there's been a trend of making the culture more tech-like.
Ok so I'm asking you then. How do you call C++ from C#?
The coolest thing here is IMO that they got cross-language inlining going so that Rust can be inlined into C++ and C++ code into Rust. This should be able to work for all language front-ends using llvm, like D’s LDC, Julia, etc. 
anyone has exprience here how many gigabyte is [this mercurial bundles (mozilla-release)](https://hg.cdn.mozilla.net/) when uncompressed? Does this mean that, with only that single bundle source, can I build and target for windows,linux and android one right?
By using C++/CLI or COM/UWP naturally, like any experienced .NET developer. .NET is a polyglot runtime with out-of-the box support for C#, VB.NET, F# and C++. The quality of a senior developer shows on how well they take advantage of the tooling on their toolbox. Granted C++/CLI support on .NET Core is still work in progress, so on those cases one is stuck with P/Invoke for the time being. 
what I would like the most is being able to use libc++ for windows. Is there progress on this front ? 
I publish the slides and code for my talk early, as a service to attendees so they have the option to get more familiar with the material and thus get more out of the presentation. That said, it seems dishonorable to publicly critique a talk on social media BEFORE the presentation is given.
You can make this code even simpler by using `std::string_view`.
I wasn't able to find a proper guide on how to compile clang, and I've been asking around. This is crazy - what the heck is LLVM, clang, and the million thousand libraries that are released? I wasn't able to find anywhere the explanation of what's what.
I asked how to call C++ from C#. I know C++/CLI exists. 
If the code to be called is straight C++ - Create a two project .NET solution, with a C# and a C++ support respectively - Create a .NET CLS or UWP compliant class in C++ via C++/CLI or C++/CX (C++/WinRT in the future) - Call that class from C# If the code to be called is already available via COM or UWP - Create a .NET solution, just with C# - Import the COM/UWP control into the project via the "Add Dependencies" dialog - Call that class from C# If targeting a platform where C++/CLI isn't available or there are no devs with C++ skills - Create a .NET solution, just with C# - Use P/Invoke to define a wrapper class with external methods, by best practices convention should be called NativeMethods - Call that class from C# 
So you are saying that in order to call C++ from C#, you need to create proxy classes in languages other than C#.
Offtopic: what about the opposite problem: compile time number printing? My task is: i would like to print `std::ratio`s. It would be waste to format it in run time if it can be done in compile time. The only solution I found so far is in the Howard Hinnant's [`date.h`](https://github.com/HowardHinnant/date/blob/6b51ca8271741f0530b08fe742e94a4de6a76e78/include/date/date.h#L7761-L8311). Is there any library for this task? 
You could also symlink the binary to `arm-none-eabi-clang` and it'll pick up the target from that. It's sometimes easier to integrate into build systems like that.
Part of it was that I was specifically hired to provide guidance to the team. Part of the problem was that the manager who hired me quit the company after a few months, leaving me without any guidance. I didn't try to make code brilliant -- I was just trying to help them to get things working -- doing the bare minimum to help them get unblocked. The problem actually wasn't so much that I spent a lot of time in total -- but that I was doing this so frequently that I was jumping around too much and unable to focus. My current boss would call it a low bus factor -- I was often the only one with the ability on the team, that if I got hit by a bus, the team would be in trouble. The team really needed more expertise but it seemed like there was more work to do than number of people available with the right expertise to do it. And you can't build expertise overnight -- it takes longer time than what was available for project schedules.
Oh I did not know there was a second edition of this book and it looks like a decent price too. Are there any major differences between this version and the prior or is it a minor revision book?
The title of the CppCon 2018 talk doesn't drag someone else's name through social media. &amp;#x200B;
&gt; {fmt} is an open-source formatting library for C++. It can be used as a safe and fast alternative to (s)printf and IOStreams.
You really don't want to understand, why bother.
Still, though ... 2.2x is amazing. How in the world do you take something that was already fast and make it so much faster? Was there any impact to compilation speed?
Removed a bunch of `sleep(50)` calls he left in for just this occasion.
https://thedailywtf.com/articles/The-Speedup-Loop
... is that you, Scotty?
Because to me it looked like you were trolling, hence my tone. So, have you ever bothered to decompile MSIL from C++/CLI? To the CLR, it doesn't matter if the code came from C# or C++, it is all MSIL, so naturally generated C# code is calling generated C++ code directly. Of course there is the caveat that one might need to use C++ features that don't map into safe CLI, in this case, an unsafe mixed mode Assembly is generated with MSIL and native instructions. Again it just looks all the same to the CLR, regardless of the source language. So compiling everything from source into MSIL is calling directly, there is no translation taking place, this is the way for best performance. Naturally if the C++ code lives in COM/UWP it needs to go through the COM/UWP runtime, but that is the same to any language that targets COM/UWP, even if going from .NET to .NET or C++ to C++ COM implementations. A reason to prefer C++/CLI or C++/CX on UWP's case is that when one understands C++, it is much easier than fine tuning P/Invoke declarations, which yes, does introduce a marshalling layer. 
Step Backwards is a nifty feature! A nifty tip for those who need a step-backwards: run your debug programs inside a VM and create snapshots while debugging. You can use VM Snapshots as an effective "step backwards" when you need it.
But there are still some sleeps left for the next round of optimizations.
1. Streamline default formatting (`{}`) - don't construct or process `format_spec` object representing parsed format specifiers in that case. 2. Use `strchr` to find `{` and `}` (idea stolen from Folly Format). Two passes with `strchr` turned out to be much faster than one naively written pass. 3. A ton of little micro-optimizations found by looking at perf and identifying the hot spots.
Gosh we really need to mark function parameters as constexpr. It would act just like a non type template parameter but passed around in parenthesis. Whether you need or may use a parameter as constexpr should not impact the syntax of users. Fmt compile time parsing need a macro to work properly. Let's fix this!
Exactly!
The link I provided points to a range of lines that contain the relevant code.
Well that's a little frustrating. `constexpr` iterators are a C++20 thing? One could argue it might still be worth it (you know, societally) to still do it for the C++17 (and maybe earlier) versions. The `constexpr` iterator [proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0858r0.html) says that it "proposes changes that do not break existing code and do not degrade performance", which I guess is technically true, but it seems here we have a situation where it may be interfering with potential safety/debugging features. Not that that's a drawback sufficient to justify stalling the proposal, but, for example, the problem could be addressed by adding support for `constexpr` and non-`constexpr` "overloads", sort of like `const` and non-`const` member function overloads, right? I wonder if there's any technical reason we couldn't have that? &amp;#x200B;
Every editors do that to sell maintenance and keep improving their softwares :p
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9fk6oy/algorithm_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
No. The Grisu2 implementation is almost complete though, which will give most of the benefits for FP formatting. Might be worth looking into Ryu afterwards. `to_chars` is interesting because on one hand it's a low-level API and on the other hand it doesn't lend itself to an efficient implementation.
Looks like the first edition only covered c++11. So I'm guessing this will cover 14 through 20.
What’s the problem with to_chars efficiency? (Ryu is dramatically faster than Grisu as far as to_chars is concerned; its bounds checking and interface overhead is fairly small. Fmt may have larger overheads that make the perf difference between the algorithms less noticeable.)
Maybe 17 but I don’t see how it would cover 20 when it’s not 2020 yet... but maybe you are right about the contents.
Seems fine, similar in structure to what I've seen in commercial codebases. :) I'm not generally a fan of off-the-shelf libraries for these kinds of things since they need to integrate so tightly into the rest of the engine, but as a hobby project it's certainly cool. I'd avoid the raw pointers more and avoid the C strings though; even if you don't use the C++ stdlib, RAII is nice and good and prevents bugs and leaks and helps games get developed more gooder. :) Howver, incoming pedantry warning. :) This isn't ECS. Unity's core object model isn't based on ECS either. This isn't about perf or data-oriented design, it's about the core functionality and architecture and concepts. ECS doesn't stand for "entity-component system," as in a system that uses entity-component architecture. It stands for "entity-component-system," as in an architecture that explicitly uses Entities, Components, _and_ Systems, which have a relatively specific roles to play in the overall architecture. :) You have no Systems in this library and don't provide the key underpinning features necessary to correctly implement Systems on top of it. You can't have "an ECS" the same way you can't have "an OOP." :p You could certainly have "an ECS framework", but this isn't one (again, neither is Unity). This is more like a "Component-Based Game Object Model framework." DonerCBGOM :p I bring this up because in an interview, I'd fully expect non-junior game developers throwing around terms like ECS to fully understand what ECS *really* is rather than pointing to non-ECS engines like Unity, so this clarity of definition could be relevant to your or another reader's career path someday. :) /pedantry
FP perf should be OK, but for integers `to_chars` API may force the client to do additional copy because there is no way to precompute the output size.
Not official C++20, but bits and pieces they're already working for C++20. 
Ahh that would make sense... I’m undecided if I should get it or not still have a huge backlog of books to get to.
Yeh, I'm still figuring out C++11.
Do you use raw `char *` for your strings? Both std::string and std::string_view store the length separately.
Would maybe something like this be of help? [https://github.com/SephDB/constexpr-format](https://github.com/SephDB/constexpr-format) I think you need everything available compile time for it though, but maybe that is what you have.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9fld04/please_help_me/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Maybe for this reason, we just ought to get the ability to pass any constexpr-enabled type as a non-type template parameter.
You don't even need that user defined literal :)
I'm not trolling. I just wanted an answer to my question. So thanks for that.
Sadly no new feature for non-enterprise users :/
But VM snapshots are pretty expensive.
Yeah. Which is why its good that Visual Studio 2017 is getting step-backwards. But I'm sure there are a lot of people with Linux C++ code and GDB that they need a "step backwards" like feature. Not much for me to say aside from... get an [NVMe SSD so that you can write at 1600MB/s (yeah, 1.6 GB/s) to get those snapshots really quick](https://www.tomshardware.com/reviews/hp-ex920-ssd,5527-2.html).
Just chiming in to say I freaking love the fmt library. It's awesome.
Yes I am sure. The restriction is only for `const char*` and reference to that non-type parameters, not for class types.
This is really great, thanks!
Alright, cool!
Also see: https://docs.microsoft.com/en-us/windows-hardware/drivers/debugger/time-travel-debugging-overview Setting breakpoints and running C++ programs backwards is pretty cool
There are at least three GDB-based solutions that are likely better. * If you do this a lot, consider purchasing an [UndoDB](https://undo.io/products/undodb/) license. I don't know how much it is, but it could be worth it. (I have no relation to the company, but the company I work for has licenses and I make good use of it on occasion, and have been very happy with it.) * Much slower than Undo is GDB's native [reverse execution](https://sourceware.org/gdb/current/onlinedocs/gdb/Reverse-Execution.html#Reverse-Execution) support. (You'll also need to read about [record and replay](https://sourceware.org/gdb/current/onlinedocs/gdb/Process-Record-and-Replay.html#Process-Record-and-Replay)) * But what might be better than *that* is GDB's native [checkpoint](https://sourceware.org/gdb/current/onlinedocs/gdb/Checkpoint_002fRestart.html#Checkpoint_002fRestart) feature to do most of the same thing you suggest, but much much faster. It just takes a fork of the process when you take a snapshot and keeps a handle of that around, and if you restart from a checkpoint it starts executing that fork. The main place this fails in comparison to a full VM snapshot is if the program needs to re-read something from standard input, or does file system manipulation.
Historical debugging, huh? Does that mean we can undo the nazis?
15.9 Preview 3 will contain C++17 floating-point to_chars() overloads for shortest round-trip decimal. As with all STL features, this will be available for all editions. (Precision decimal and hexfloats are the last remaining overloads; I'm going to need probably a month or two for them, couldn't possibly get them into 15.9.) A few functions might seem minor, but this is anywhere from 9.6x to 36.6x as fast as the equivalent CRT functionality depending on the types and platforms involved (yes, times not percent). We'll be the first C++ Standard Library to ship this functionality powered by Ulf Adams' novel Ryu algorithm.
`50ms` because UDLs are awesome.
Okay I was a little riled up when I wrote this. Also it sounds like you are working on middleware which is a much better place to be from what I've heard. Games isn't all bad of course. I went to Digipen which was a really good school and was a really good primer for the industry. The CS, math, and physics classes were top notch and set me up for success. Unlike OP, I was offered ZERO programming classes in High School, so aside from a brief stint in robotics club (which was little more than fill-in-the-blanks C programming) I had no CS experience going in to college. The game projects weren't my favorite but they were good experience with working with a variety of people of varying ambition and work ethic. Truly I don't want to shit all over the entire games industry, and there are a ton of good people and projects in it, but so many of my peers have burned out and left the industry in search of greener pastures that I feel like something must be wrong. Still, maybe OP would fit right in, maybe not. Who knows.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9fmoul/com_sci_201_lab_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I ran a quick benchmark against Milo's implementation (found at https://github.com/miloyip/dtoa-benchmark ). to_chars() scientific double is 1.7x to 1.9x as fast (i.e. 70% to 90% faster) depending on whether I compile with MSVC or Clang 7. Additionally, Ryu rounds correctly, unlike Milo's implementation. Perf numbers on my machine (i7-4790@3.6GHz): to_chars | dtoa_milo | Speedup Ratio | Platform ---------|-----------|---------------|--------- 110.7 ns | 189.1 ns | 1.7x as fast | C2 x86 80.2 ns | 151.0 ns | 1.9x as fast | LLVM x86 55.7 ns | 96.8 ns | 1.7x as fast | C2 x64 46.8 ns | 88.1 ns | 1.9x as fast | LLVM x64 Here's the rounding issue I encountered (it may be "by design" for Milo's code, but it would be a bug for Ryu/charconv). These are just the 2 differences I observed in the first 10 random numbers I tested. to_chars: "1.9156918820264798e-56" dtoa_milo: "1.9156918820264799e-56" Hex: 345E0FFED391517E Bin: 0 01101000101 1110000011111111111011010011100100010101000101111110 ieeeExponent: 837 Unbiased exponent: -186 2^-186 * 1.1110000011111111111011010011100100010101000101111110_2 Wolfram Alpha: 1.9156918820264798304697259580969850238274553049712402682383820475568894602249045068669791533515337051740662751959686751160473057369296827063924471001854499263572506606578826904296875 * 10^-56 Comparing to_chars vs. Milo vs. Wolfram Alpha's exact result: 1.9156918820264798e-56 to_chars 1.9156918820264799e-56 dtoa_milo 1.91569188202647983046... Wolfram Here, the final digit needed for round-tripping is 8 in the Wolfram exact form, and the next exact digit is 3, so rounding down is correct (according to charconv conventions, which demands the least possible mathematical difference, and round-to-even for ties; no tie is involved here). to_chars: "-6.6564021122018745e+264" dtoa_milo: "-6.6564021122018749e264" Hex: F6EA6C767640CD71 Bin: 1 11101101110 1010011011000111011001110110010000001100110101110001 (dropping unimportant sign; charconv also must write the '+' in the exponent, also unimportant) ieeeExponent: 1902 Unbiased exponent: 879 2^879 * 1.1010011011000111011001110110010000001100110101110001_2 Wolfram Alpha: 6656402112201874528659820465758725713547856141003805423059160188248838951345850569365211016306052909073027432808339145046352717312004932903606648991710177876814916512842752964290190420774041671562000941792300114015553768328982381262942784578955934386595255975673856 Writing side-by-side so we can see the differences: 6.6564021122018745e264 to_chars 6.6564021122018749e264 dtoa_milo 6.65640211220187452865... Wolfram Here, the final exact digit is 5 and the next digit is 2, so rounding down to 5 introduces the least mathematical error (again, no round-to-even tiebreaker is necessary; that rare case occurs when the next digit is 5 and all following digits are 0). Milo emits 9 here. That might round-trip, but it's inaccurate.
That makes sense. I've never really thought about the specifics of EBDIC machines and the standard thereon except to make pedantic posts on Reddit, soooo... :p
That's... not the goal of it? Create an instantiation each time? I don't see the problem with the code.
But it is a problem. You have a function returning multiple types depending on something, but it's not a template? The point of instantiation of the returned object would be like a template, but the function is not a template. You basically have a function that behaves like a template. An EDG compiler dev told me that that would be very hard to implement because the constant evaluator can't instantiate templates (it's like an interpreter that feeds on the AST).
I'm going to admit something... I stopped looking at the lib some time back as soon as I got to the part about needing to use "operator&lt;&lt;(std::ostream &amp;os..." for user-defined types since my brain's toolset no longer accepts iostream types/headers. Is this still the case? Is there another way to more generally append the UDT string representation into the string in question or are you exploring other ways for users to hook their types?
Average clocks stopped growing and actually went down a bit somewhere around the pentium 4 iirc
&gt; The upper bounds are easy to determine though - is that insufficient? Sometimes it is but often not. If they inverted the control and provided a temporary buffer and the size the API would be optimal (or close).
Only available for Enterprise though. :( And that's rather expensive.
It was never the case. You can use `operator&lt;&lt;`, but it's optional and the main extension API (http://fmtlib.net/dev/api.html#formatting-user-defined-types) doesn't rely on iostreams. You probably got an impression that it was the case because the extension API was in flux due to changes related to standardization effort, and therfore wasn't actively advertised.
I found it, just starred :)
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
We already have an existing example of something that looks like it is not a template, but it is. Consider the following code #include &lt;array&gt; #include &lt;type_traits&gt; template&lt;char... c&gt; constexpr auto operator""_c(){ constexpr std::array chars{c...}; // Strawman parsing return std::integral_constant&lt;int,chars[0] - '0'&gt;{}; } constexpr auto foo = [](auto var) { return std::array&lt;int,var&gt;(); }; constexpr auto f = foo(5_c); With lambda foo `auto` implicitly makes a template (even thought it does not look like it). The semantics don't seem much different from the proposed &amp;#x200B; constexpr auto foo(constexpr int var) { return std::array&lt;int, var&gt;(); } &amp;#x200B; Except the compiler is just doing some syntactic sugar in automatically converting an integer to the moral equivalent of converting an integer to and from std::integral\_constant&lt;int,?&gt; &amp;#x200B; &amp;#x200B;
We can always use smart people. Relocation depends on how smart I'd say... :) Drop me an email on suter@darkvisiontech.com, preferably with a resume attached. Thanks!
Hmm, I was sure I've done that already, but apparently not =). Thanks for bringing this to my attention.
https://i.imgur.com/bjOtlOv.jpg Totally unreadable on mobile.
&gt;The trick is to slowly introduce sleeps in between releases Do you work for Apple? 
It seems Unity themselves are getting the terminology wrong then. They're describing it as [_the_ Entity Component System](https://unity3d.com/learn/tutorials/topics/scripting/introduction-entity-component-system-and-c-job-system) in Unity.
&gt;it sounds like you are working on middleware which is a much better place to be from what I've heard I currently work for a contracting firm that get pulled in to help on other people's games, normally for the last year of development. We almost exist to help mitigate crunch! Most of my work is engine level, but we _are_ working on specific games. Before that I worked for Epic, on the UE4 engine itself - though occasionally implementing features specifically requested by different game teams (e.g. the landscape mirroring tool was requested by the Paragon team).
the base system in Unity is a GameObject with components. But they introduced a real ECS lately.
Step Back is really cool feature... what about bring it to LLDB? @Teemperor
I've never actually used an EBDIC machine either, but I've got a bunch of old "TV computers" that I bet don't use ASCII. But then, they don't do much data interchange with other systems either, and people rarely code for them in C-like languages (basic or assembly rule those machines). So really it's all an obsolete thought experiment.
Perhaps a decade from now I'll be able to build muh CUDA with this. 
&gt;And I want some compile-time replacement. There is something I'm curious about when I see this much enthousiasm about compile-time computation, and it's this: surely the vast majority of your data is not known at compile time? And even if it is: isn't building a highly optimized executable, and having it do the work, far more efficient than getting the compiler to do it for you? Note: I'm not asking about the general use of constexpr here. I absolutely love to be able to calculate hashes over strings and use them as labels in a switch, for example; that's something you cannot do otherwise. But the vast majority of computation going on in any given application takes place on data that is simply not known at compile time. So what problem are you trying to solve that constexpr would actually make a difference? 
That is a little units library I am writing. Think of Boost.Units but much more lightweight and C++11. While values are essentially run time, their dimensions are known at compile time. The current printing function generates huge amount of terrible code, for printing something that should be known at compile time. That just bothers me. It is definitely not a showstopper, I was just curious about the solution. In the meantime, I have also found several "static string" libraries, that could be used for the task. For example Anrzej's https://github.com/akrzemi1/static_string
Chrono's just awesome generally - I have the following definition in my gameboy emulator, which allows me to duration_cast directly from elapsed time from the high precision timer into gameboy cycles and get the correct number of cycles to step, without going via floats or worrying about overflow or truncation during the conversion :) using cycles = std::chrono::duration&lt;int64_t, std::ratio&lt;1, 4'194'304&gt;&gt;; gb_emu::cycles elapsed_time_in_cycles = std::chrono::duration_cast&lt;gb_emu::cycles&gt;(now_time - sync_time); (I'm using int64_t because when I used int32_t previously I got an overflow in the resulting number of cycles after a debugging session which caused the emulator to think it was several minutes _ahead_, making it stop ticking. Whoops.)
You missed Mozilla RR
&gt;however I do feel that C++ has lost the GUI "war" I feel like even C# has lost the GUI "war" and web apps have won. That said Qt is still being used by many companies for writing GUI apps for both the desktop and even embedded devices (e.g. many car companies use Qt).
Great piece of text. It really needs a TOC and titles that can be navigated to/from though (Markdown would do the job). This should be added to the man pages indeed.
It also covers website content. Visually that is...
C# doesn't need to win the GUI "war" just to be a contender, which C++ no longer is, on the context of desktops and mobile devices. Yes there is Qt, but it isn't an OS vendor framework. All attempts to bet on it failed on the market (Blackberry, Jolla, Ubuntu). On Windows C# will be around for longer than MFC will, and as mentioned apparently not many companies are really investing into C++ with XAML. I tried to use Qt on mobile before they switched their focus to devices and the experience was much worse than Xamarin, because they don't provide a good support for device APIs, while Xamarin folks have dedicated teams creating wrappers for them. On my case the effort to write the wrappers myself, meant that in the end I dropped Qt, kept the business logic in C++, and then made use of Objective-C/Java/C++/CX for the view layer. Also regarding Qt, many of the new features are actually only available via QML, C++ Widgets seem to be in a kind of maintenance mode only for desktop applications as target, as far as I can understand it.
Given this code fragment: std::vector&lt;int&gt; values = {1, 2, 3, 3}; erase(values, 3); what elements do you excpect vector to have? Is it {1, 2} or {1, 2, 3}? I honestly expect it to be {1, 2, 3}. IMO erase-remove should be named `erase_all_of` and `erase` should be implemented as find-erase: template&lt;SequentialContainer Container&gt; bool erase(Container&amp; container, const typename Container::value_type&amp; value) { using std::begin; using std::end; auto e = std::end(container); auto it = std::find(std::begin(container), std::end(container), value); if(it != e) { container.erase(it); return true; } return false; } 
The proposed `std::erase` is an `erase_all_of`: https://en.cppreference.com/w/cpp/experimental/vector/erase
Official CUDA support is the biggest roadblock when upgrading for me as well.
&gt; experimental color support This is interesting
Not just bounds checks although those count too, but more importantly you can write from the end of the buffer and then return a pointer possibly in the middle which is faster.
**Company:** Veeder-Root **Type:** Full-time **Description:** **Veeder-Root** ([www.veeder.com](http://www.veeder.com/)) is the world's leading supplier of automatic tank gauging and fuel management systems in more than 500,000 underground storage tanks around the globe. · You’ll have the opportunity to work from the lowest levels of embedded software to support our automatic tank gauges to the highest levels of cloud-based applications to help support our fuel management solutions. · Design, develop, and execute software solutions to address business needs on our Automated Tank Gauge and related platforms · Bring your knowledge of newer technology stacks and frameworks and identify where there should be applied, helping the rest of the team get up to speed. · Help promote a DevOps culture and build followership to help transition the team towards DevOps · Collaborate with peers, electrical and mechanical development teams, quality assurance and others as needed to produce game changing solutions · Troubleshoot critical and difficult code problems · Mentor junior engineers on best practices in design and coding as well as transfer technical knowledge about newer technologies **Technologies:** C, C++, Node.js, Ionic, React, Angular, SpringMVC, SpringBoot, Java, Python  **Location:** Simsbury, CT, USA **Remote:** No **Visa Sponsorship:** No **Contact:** [https://fortive.taleo.net/careersection/External/jobdetail.ftl?job=VEE000962](https://fortive.taleo.net/careersection/External/jobdetail.ftl?job=VEE000962)
At first I thought it just seems to work because `class` introduces a forward declaration (which is obviously a type name) but it also works for non-class types.
 using std::begin, std::end; FTFY
If, like us, you use predicates for removal and you need to know which values were removed, then use std::partition.
That's a totally different thing. Mike Acton and some other started working on a real ECS and job system for Unity, which is very separate from their core game object and component architectures.
&gt; However, this only works in specializations. If you put it in the class template field yeah, [but you can use it outside of specializations.](https://godbolt.org/z/4kt62-)
There is another way, by using the Microsoft's SAL - Source Code Annotation Language which can be used to explicitly show the parameter intent, whether it is an input, output, input-output or optional. It is widely used to annotate the Windows API code. For instance, &amp;#x200B; `HANDLE CreateRemoteThreadEx(` `__in__ HANDLE hProcess,` `__in__ LPSECURITY_ATTRIBUTES lpThreadAttributes,` `__in__ SIZE_T dwStackSize,` `__in__ LPTHREAD_START_ROUTINE lpStartAddress,` `__in__ LPVOID lpParameter,` `__in__ DWORD dwCreationFlags,` `__in__ LPPROC_THREAD_ATTRIBUTE_LIST lpAttributeList,` `__out__ LPDWORD lpThreadId` `);` &amp;#x200B; A legitimate case for using input/output parameters is when there is a need to create some C-wrapper to C++ code. This annotation can be easily implemented out of Windows by using macros such as. `#define __In__` `#define __Out__` `#define __In__Out__` &amp;#x200B; More info: * [https://docs.microsoft.com/en-us/visualstudio/code-quality/understanding-sal?view=vs-2017](https://docs.microsoft.com/en-us/visualstudio/code-quality/understanding-sal?view=vs-2017) * [https://www.osr.com/blog/2015/02/23/sal-annotations-dont-hate-im-beautiful/](https://www.osr.com/blog/2015/02/23/sal-annotations-dont-hate-im-beautiful/) &amp;#x200B;
Facebook, but the sleep technique is an industry standard. Apple just applies it more consistently.
Does this matter at all
* C++ to C++ case 1 =&gt; As long as you are using the same compiler for the whole code base, you can safely call classes, STL and functions from a code compiled as DLL or SO shared object. But it falls short if the DLL is going to be called from codes compiled with other compilers since the C++ ABI is not standardized and incompatible among different compilers and also between different versions of same compiler. In addition, STL implementation varies among compilers and may be incompatible among them. * C++ to C++ case 2 =&gt; Use C++ interface class with only pure virtual functions (aka abstract methods) and only C-types and pointers at the class signature. This is the strategy by many plugins and Microsoft COM/OLE and the new window runtime which is based on COM. * C++ to C case 3=&gt; Pass class as void\* pointers and create functions wrapping the class methods with extern C. The disadvantage is that writing wrapper code sucks as it becomes more difficult to maintain as the code base becomes bigger. Another way is to automate this by taking advantage of CLANG library parser or python CLANG libtools parser. * C++ to C and any language - case 4. Use SWIG wrapper generator. This tool parses the C++ header files and the interface definition files generating C binding code for specific programming languages C-API, for instance it generates Python bindings from the C++ for Python C api allowing to create a native python library. In addition to Python bindings, this tool can generate Pel, Ruby, .NET and Java bindings by generating C specific code for those languages C-APIs. 
There is useful technique, which doesn't seem to be mentioned anywhere, for a special case when you need to remove a single element from a vector without preserving the order of elements. You can do it in O(1), whereas using just `vector::erase(pos)` does it in O(n). The trick is to swap the element you want to remove with the last one, and then remove just the last one: template &lt;typename Cont&gt; void remove_from(Cont &amp; c, typename Cont::iterator pos) { auto last = prev(end(c)); std::iter_swap(pos, last); c.erase(last); } I use this technique quite often, I feel there should be a standard algorithm for it.
No, because Boost...
There is a "standard algorithm" for it - it's called using your brain, as you did. :) Programming languages are NOT supposed to think for the programmer, but too many try to do so, and become stupidly bloated for it. "OMG I CAN'T DO THAT BECAUSE IT ISN'T IN MY FAVORITE LIBRARY" isn't an acceptable answer.
Is not that frightening that language needs blog posts and reddit discussions for removing elements from containers, and that you need to write some boilerplate code? 
Something tells me you are serious.
&gt; Is a sequence container the right solution for the problem? As opposed to what? I mean, I agree that the `set` interface may often be a better match for this kind of problem. Conversely, sets come with specific performance characteristics. Sequence containers come with others — and it turns out that, even for reasonably large containers, it's more efficient to occasionally erase from (even the middle of!) sequence containers than sets, despite the worse asymptotic complexity, due to better overall access patterns.
Just a useful tip. If you can use C++14 or later, you can use the enable_if_t helper. If you have to use c++11, you can always define it yourself. I do this myself in c++11 because it's so useful. template&lt; bool B, class T = void &gt; using enable_if_t = typename enable_if&lt;B,T&gt;::type;
90% of &lt;algorithm&gt; can be reimplemented "using your brain", but it's in the stl because it's generic, useful and doesn't have much cost. And an "unordered_erase" would be to. "Just implement yourself" is not a reasonable excuse for why C++ doesn't have a standard way of splitting a string.
If you're already assuming vector (which you pretty much are if you're assuming this is efficient) you might as well use `pop_back` instead of erase.
constexpr is very confusing. &gt; "function arguments are never constexpr." But why the following code is valid? class TestCE { public: constexpr TestCE(const char *p) : p_(p) {} constexpr int foo() const { if(p_[0] != 'a') return 1; else return 2; } const char *p_; }; int arr[TestCE("bbb").foo()];
yeah sure, why don't you write your own version (in addition to the existing 1001 custom ones that can be found elsewhere) of trim() or uppercase() or replace_case_insensitive() because you know C++ can't be bothered to provide them because you know they don't make sense for the Klingon language or the Bushmen clicking language and thus cannot be part of the standard...
Until you need to format floats. But I agree it’s better than anything else. 
&gt;The use of #includes is a very old, error-prone, and rather expensive way of composing programs out of parts. If you #include header.h in 101 translation units, the text of header.h will be processed by the compiler 101 times. If you #include header1.h before header2.h the declarations and macros in header1.h might affect the meaning of the code in header2.h. If instead you #include header2.h before header1.h, it is header2.h that might affect the code in header1.h. Obviously, this is not ideal, and in fact it has been a major source of cost and bugs since 1972 when this mechanism was first introduced into C. what a fucking surprise! but he still chose to keep the same shit in C++.
No, not really. ### Blog Post The fact that a blog post *exists* isn't evidence that it was actually needed. This post is simply covering ground that's been well-plowed for decades. ### Boilerplate Needing boilerplate is marginally more annoying, but if we're going to deal with annoyances, we should prioritize the list--and when we do, the remove/erase idiom will be a *long* ways from the top of the list. To an extent, the boilerplate involved also shows something of a strength--easily combining existing functions to produce a desired result is a good thing. ### Language Vs. Library I'd note that none of this is actually related to the *language* at all. It's solely about the design of the library. It would be entirely possible to change the library to work quite differently without changing the language itself at all (and, in fact, precisely this has been done--for example, see Eric Neibler's [Ranges](https://ericniebler.github.io/range-v3/) library. ### Alternatives If one wanted to complain about the language (or more accurately, the library), they should justify that by pointing to otherwise similar containers in other languages that provide the desired functionality more cleanly *without* incurring the problems that the STL design was intended to avoid. Most other languages don't provide anything close to that. Java (for one obvious example) pretty much requires Google's Guava library to get containers even *close* to as cleanly designed as those in the C++ standard library--and even with that, they're pretty clearly inferior. ### Summary Most of your premises are basically false--the blog post is decently written, but hardly *needed*, the boilerplate involved is mildly annoying at worst, and most designs that avoid this particular shortcoming also have other disadvantages that outweigh those shown here. 
Compiler bug. An elaborated-type-specifier cannot name a typedef-name.
That's a stupidly dogmatic "argument" for someone advocating using their brain elsewhere in this thread.
It works with MSVC, GCC and Clang
Haha yeah, I know but thanks for the tip! This is purely an example, so using it ruins it.
So a widespread compiler bug. Next?
better replace: iter_swap(pos, last); with using std::swap; swap(pos, last); 
This isn't a bug with SFINAE, this is a bug that allows class to be used as typename in template specialization.
There's no bug. \`class Foo&lt;T&gt;::Bar\` is known as an \_elaborated-type-specifier\_ and is a perfectly valid way to specify a type, and the \`Foo&lt;T&gt;::Bar\` in it is assumed to name a type without the need for \`typename\`. However, an \_elaborated-type-specifier\_ cannot name a typedef-name like the member \`type\` of \`enable\_if\`. Thus in your example substitution into it always fails (which is technically ill-formed NDR) and the specialization is never used. &amp;#x200B; &amp;#x200B;
Widespread compile bugs exist, which MSVC, gcc and clang miscompile. Here's one I found a while ago: struct X { X() = default; X(const X &amp;) = default; void operator=(int); } x; int main() { X(x) = 1, 1 + 1; }
Are you sure it's ill-formed NDR? It's not not-dependent, and I can always provide an explicit specialization.
Ah. I wonder why there's so much misconception around it then... I haven't really looked too much into ECS.
Yes of course, but if we ignore that part then it's not, right?
On mobile, does that compile?
I'm sure it's not easy, but have you considered switching from MSVC to clang? It can compile CUDA code.
The voices in your head?
 using cycles = std::chrono::duration&lt;int64_t, std::ratio&lt;1, 4'194'304&gt;&gt;; ok, defined somewhere. std::chrono::high_resolution_clock::time_point now_time = std::chrono::high_resolution_clock::now(); ug. auto now_time = std::chrono::high_resolution_clock::now(); that type name gives no useful information, other than repeating "the time type that `now()` would return from this clock". gb_emu::cycles elapsed_time_in_cycles = std::chrono::duration_cast&lt;gb_emu::cycles&gt;(now_time - sync_time); I'd be on the fence here. Name is short enough. 
Step Backwards is unfortunately only for Enterprise, not for Community :-( So basically only for companies with the big money :( Would be awesome if Microsoft reconsidered their policy for this specific feature.
`std::iter_swap` already does that. It's required to be implemented to have the effect of `swap(*pos, *last);`, but in the context of the `std` namespace where `using std::swap;` isn't required. At least that's my interpretation of the [standard](https://timsong-cpp.github.io/cppwp/alg.swap#lib:iter_swap), of the example implementation on [cppreference.com](https://en.cppreference.com/w/cpp/algorithm/iter_swap) and of the results when I tried it myself with : #include &lt;iostream&gt; #include &lt;vector&gt; struct foo {}; void swap(foo&amp;, foo&amp;) { std::cout &lt;&lt; "My swap\n"; } int main() { std::vector&lt;foo&gt; my_vec{ 2 }; std::iter_swap(my_vec.begin(), my_vec.begin() + 1); }
What I am really looking forward to is the C++ modules special meet.
That's not well formed though and should be a compiler error. It's an example of the Most Vexing Parse. You can fix it by changing `X(x) = 1, 1 + 1;` to `X{x} = 1, 1 + 1;`
Weirdly, it's often *not* faster - the CPU is very good at linear operations (such as moving all elements by one) and bad at random ones (such as accessing the tail of a vector. Past a certain size it's superior, but if you have a large vector and are removing elements from the middle you may be using the wrong container anyway!
No it's not, how is 1+1 a valid declaration? 
Eytzinger layout FTW. :-]
It's a C++17 addition.
I'm not sure what you're saying "No it's not to." To clarify for yourself and to others... there is no compiler bug causing your code to be rejected, your code is simply invalid C++. Your snippet of code is attempting to declare a variable `x` and assign it to the value 2, but type `X` has no constructor that takes an `int` as a parameter, so the compiler rejects it. What you likely intended to do with your snippet of code is something along the lines of make a copy of `x` and assign it to the comma expression `1, 1 + 1` which evaluates to 2. If that was your intention, then you have to disambiguate the syntax to avoid triggering C++'s most vexing parse. The way to disambiguate that is to use list-initialization: `X{x} = 1, 1 + 1`; That will make a copy of `x` and assign that copy to `2`. Once again, I reiterate that these details are trivial minutiae.
Sorry. I meant that the code is well-formed. There is no ambiguity here, because 1+1 is not a declaration. Also, the comma expression had the lowest precedence, so I would be assigning 1 to the copy, and then evaluating 1+1. I find those details interesting :)
&gt; What you likely intended to do with your snippet of code is something along the lines of make a copy of `x` I think not – `X(x)` is a declaration of a variable named `x`.
&gt; Weirdly, it's often not faster - the CPU is very good at linear operations (such as moving all elements by one) and bad at random ones (such as accessing the tail of a vector). In this particular case I don't see how it can be faster to do the linear delete. Neither algorithm can't complete until the final element is loaded into the cache. If the linear algorithm spends a lot of time doing copies and that takes longer than the prefetcher takes to load the final element, the linear algorithm is **slower** even if it never stalls due to a cache miss. Plus, you've now trashed your cache by unnecessarily loading a large part of the vector into it. Your overall point about linear algorithms frequently out-performing random-access due to the prefetcher is definitely true, but I don't think that it applies in this case. The linear algorithm might win if the entire vector will fit in the cache and you're making multiple remove_from() calls in a row, but even then I'm not convinced.
&gt; zero throws How are you handling errors? In general, if an error is rare, exceptions are far faster than error codes.
The snippet of code in your original post is not well formed. There is no bug or issue with any of the compilers and they are correct to reject that snippet as invalid C++. I believe my post explains sufficiently well why that code is not well formed but if it's still not clear then I suppose we'll have to agree to disagree.
&gt; Useful advantage: no need to deallocate anything on program termination You can do that with dynamic allocation as well... Lots of software does the minimum of cleanup, and then just terminates. Not much of a good reason to go about free'ing memory that the OS is just going to throw back into a pool once the program terminates.
I read it _and_ quoted it, and disagreed with it; what's confusing here?
&gt; It seems to me that Modules are not the top-priority of the committee The committee organized 2 exceptional sessions out of the normal planning, in less than 2 weeks, specifically for having more chances to be able to enter Modules and Executors in next C++ version. If that's not putting Modules in priority... &gt; So, why not? I haven't heard any strong argument against this. What is the cost-benefit argument that dismisses this solution? Because it would make the compiler have to know more than it needs about the system? Because it would mean standardizing at least some of the building context? Because the compiler only needs to associate name used to names that exist? Etc? Other languages just forces you to have files in specific organization. There is only one build system (when it's not runtime) and they started with the specific setup from the beginning. That's a very different situation than C++.
So that's what's holding Modules back?
You seem to believe that because the first part can be a declaration, then it is (most vexing parse), but actually, that applies to the whole statement. There is no ambiguity, because the full statement can never syntactically be a declaration. Ok then, feel free to ignore me :)
I guess no one has ever been bitten by the Most Vexing Parse, everyone who has ever written `double x(int());` or similar always intended to declare a function `x` that takes a function of type `int (*)()` and returns a `double`. It couldn't possibly be the case that someone actually intended to declare a variable `x` of type `double` and initialize it to the expression `int()`. Of course...
Okay, simple question then... Is the snippet of code in this post valid C++ or not? https://www.reddit.com/r/cpp/comments/9frxv3/til_you_can_substitute_class_for_typename_on/e5z96r7/
&gt; The committee organized 2 exceptional sessions out of the normal planning, in less than 2 weeks, specifically for having more chances to be able to enter Modules and Executors in next C++ version. Sure. I hope this leads to having Modules in the next standard. &gt; Because it would make the compiler have to know more than it needs about the system? And this is bad? Maybe that's the way to go for having a working and well-behaving dependency management during the build. &gt; Because it would mean standardizing at least some of the building context? Still, I don't see if this is a bad approach. Maybe the giants (e.g. Google, Microsoft) present in the committee takes such a strong position in this regard that makes an agreement impossible. Why standardizing the build context would be so troublesome? &gt; Other languages just forces you to have files in specific organization. I don't know about Java, but C# doesn't have such limitations, yet it has one of the nicest dependency management designs I have seen. Also, forcing an specific organization is not inherently a bad thing, as long as the same tasks can be accomplished. I even argue that a well-designed build system with clear limitations and rules are superiors to a free-form build system (e.g. running script from CMake) where a developer can do anything and it is hard to trace it. 
Well to be short, - both main authors of modules proposals agreed on a merged proposal; - that proposal was not yet reviewed and there will be only one session to allow it or not in the next standard; That they agree do not mean that it will be voted in "as is" or "with a few tweaks". So they need to have more chances of having reviews and feedback and time to apply changes and finding solutions. From what I understand, the main points being discussed are related to the features allowing or not to export/import macros and the ones related to handling mixes of modules and include files (which are related points). I can't give more details but you can read the merged proposal there: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1087r0.pdf
You're right, that's a good case for auto, though you were a little unnecessarily blunt in how you pointed that out. The real code is actually slightly more complex than written - actually casting the elapsed time into a `cycles` duration would truncate every time and potentially cause advances by very small numbers of cycles at a time or running away to processing large numbers of frames at a time if updates are slower than real speed
Better floating-point formatting is coming. Stay tuned =).
Ah, ok. Is there a reason this only works in specializations, and not normal template declarations?
What's the bug and what's that code supposed to do?
The code is valid but all three compilers reject it. It copies `x`, assigns `1` to that copy and then evaluates `1+1`.
&gt; but C# doesn't have such limitations C# doesn't have incremental compilation though (and doesn't need it since the compiler doesn't optimize to machine code) and all files of an assembly are always compiled together.
Having to work with Java at work, the term 'type erasure' frightens me.
You can ignore it insofar as you only need to know the order of the file or data stream itself. The point of the article is that you can ignore the *host* order because the same code will work regardless of the host's endianness, both for encoding into a specific byte order and decoding from a specific byte order.
Why wouldn't you just put the title in your title? 
The blog's author has a history of blowing up well-known things into "issues" and problems.
The linear version isn't faster, but it's frequently exactly the same speed. The moves happen while the cache loads the next line, so take "no time at all". People rarely remove elements from a vector large enough for remove_swap to matter. It's more useful in the case where the element type is really expensive to move, but that's pretty rare. Remove_swap is frequently a premature optimization.
Easier said than done, but it's a hot topic. Feel free to file a tracking bug though because I don't think there is one yet.
No. The _statement_ `X(x) = 1, 1 + 1;` is not a syntactically valid _declaration_, because `1 + 1` is not a valid _init-declarator_. There is only one possible parse, as an _expression-statement_. As noted in p2 of \[stmt.ambig\], "If _the statement_ cannot syntactically be a _declaration_, there is no ambiguity, so this rule does not apply. The whole _statement_ might need to be examined to determine whether this is the case."
Ah yes, you're absolutely right here. I shortsighted the first part of the expression.
Easier to monetize? To also reach those C++ programmers who are functionally illiterate? Who knows... 
Great video for beginners :) Short and nice explanations, and not unnecessarily long! One thing that drives me crazy: Why the space before parentheses... `begin ()`... it looks so weird and is so hard to parse for the brain. The parenthesis are the function call operator that invoke the functions in front of them, so why would you put a space there to separate what's before the parentheses with the actual parentheses. And one question: Why do you use `v.begin()` and not `begin(v)`? I thought it was recommended to prefer non-member begin/end. It's quite a commonly agreed recommendation I thought, like from the CoreGuidelines or GOTW or something.
How is this C++-related?
`v.begin()` might as well be a habit that the person doesn't care enough about to change it.
Wrong subreddit. Deleted now.
 From the preface ([http://www.stroustrup.com/tour2preface.pdf](http://www.stroustrup.com/tour2preface.pdf)): &amp;#x200B; This book gives an overview of C++ as defined by C++17, the current ISO C++ standard, and implemented by the major C++ suppliers. In addition, it mentions concepts and modules, as defined in ISO Technical Specifications and in current use, but not scheduled for inclusion into the standard until C++20. &amp;#x200B; Here is the table of contents: [http://www.stroustrup.com/tour2toc.pdf](http://www.stroustrup.com/tour2toc.pdf) .
`begin(v)` syntax is useful only if you plan to write a generic library which can deal with non-standard compliant collection which don't have `begin()` member method and cannot be modified (so a very few amount I suppose). So to make the custom weird collection compatible with generic code, you can add a non-member function without modifying the collection class itself: auto begin(SuperWeirdCollection iCollection) { return iCollection.SuperWeirdBegin(); } But IMHO even this argument isn't a good one since the begin iterator is a inner property of the collection so we should call a member function to get it. C++ lacks Uniform Function Call Syntax.
Is the free function form better? Sure. Is it worth the effort to change? Doubtful... Now for someone new to the language probably best to learn the free function form. Honestly your biggest win, will likely be time saved due to people not bugging you about it.
Well the thing is, it can be very confusing for beginners/intermediate programmers. You hear the "prefer non-member begin/end" rules from many pro's, and then you see videos from other pro's not using it. What are you supposed to think now?
Not everyone is in the business of making videos for beginners. I am presenting my justification. Everyone will have their own.
Isn't this actually what std::remove does?
To qualify as a premature optimization, I think you have to be adding complexity to optimize performance that may be irrelevant. But in this case, it doesn't seem like remove_swap is any more complex than remove+erase
It is not better but has different advantages and disadvantages. 
&gt; I don't know about Java, but C# doesn't have such limitations, yet it has one of the nicest dependency management designs I have seen. Dependency management != modules. Modules are at the file level, whereas dependency management is at the packages/project level.
I have to assume ad money. Maybe you ttube pays better than a blog would, no idea. But I really hate these, otherwise very informative, videos that really should have been a web page.
Committee members around the world will be working nonstop for years to prevent the Y2k98 problem. The solution will be to change the C++ version to a template that references the previous version. No longer will there be years. It will be ISO/IEC 14882:`std::version_v&lt;std::version::cpp95&gt;::next`.
Meta standards development?
We might get modules in 2098.
C+++98
C++ will no longer be relevant in 2098.
C++98++
(++C)++. And the problem was resolved forever. #FOREVER.
True, but boring ;)
There was never really even a semi-formal name given to the general component-based architecture other than just saying "components" so I think people just latched onto ECS as a short acronym that covers that concept (albeit it's technically a very specific approach to using components as data with logic split off elsewhere). Some folks talk about ECS in terms of data-oriented programming, though that's not technically part of the concept. One could make an ECS-based system that was very much non-data-oriented; the gist of ECS is more about structuring composability. It'a a response to a more naive component model (like this Doner system or Unity's) runs into problems where too much game logic lives in components alongside their data in a way that makes complicated interactions hard. Ironically, one of the first component models published formally, the one from Dungeon Siege (disclaimer: I worked for GPG, but years after they made DS!), was closer to an ECS model than to the naive component frequently seen in engines/games during the intervening decades. :) The classic example of the problems with the naive component model is a game that allows wooden structures to burn and for fire to spread; where does that logic for spreading live, in the fire component or in the burnable component? How is that dependency between components coded? How easy is to find the dependency and debug it? ECS makes components just data and then has clear Systems that contain logic. Your fire spreading logic might then live in a clear FireSpreadSystem that consumes data from Fire components and mutates Burnable components, or something like that. There's some clear benefits to readability, debugging, and multi-threading in the model. The data-oriented parts come in because you can structure your components and system logic in exceedingly CPU-cache-friendly ways, which is probably worth it if you're following the ECS pattern in the first place. Folks online (past-myself included!) get confused because ECS doesn't strictly mean that you have conceptual types Entity, Component, and System; it's a pattern, and an incomplete one at that. You also kinda need more framework to even make it work, since you need to actually store the components, serialize and query entities, schedule systems, etc. It was the Overwatch ECS talk a few years ago at GDC that started to sell me on the ECS concept not being \_totally\_ a hyped fad. Disclaimer: I now work for Blizzard (not on Overwatch), though I saw that talk and started warming up to ECS back when I was working for Wargaming.
It'll surely be namespaced in std::chrono::twenty_first_century::C++98 Either that, or they'll just forcibly upload a mind virus into our cyberbrains at re-education camps to eliminate all knowledge of the 20th Century to avoid the naming overlap.
std2::c++98
Finger crossed 
It’s alive and well way past 2098 https://cdn-vox--cdn-com.cdn.ampproject.org/i/s/cdn.vox-cdn.com/thumbor/83B0-FVHoG066dife7jvSvNZmaI=/0x0:2324x1148/1400x933/filters:focal(977x389:1347x759):no_upscale()/cdn.vox-cdn.com/uploads/chorus_image/image/56977777/Screen_Shot_2017_10_03_at_1.59.42_PM.0.png
2098 -&gt; 2.98 .. that will be great 
I was going to say by that time we won't have any more legacy C++98 code left so it won't matter, but then we probably will.
Maybe I'm being silly but I don't get why we need different names anyway? Isn't that what the `++` is for?
Is there a sscanf alternative to complement this?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/shittyprogramming] [What happens in 2098 with C++?](https://www.reddit.com/r/shittyprogramming/comments/9g3wrj/what_happens_in_2098_with_c/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
&gt;Screen\_Shot\_2017\_10\_03\_at\_1.59.42\_PM.0.png Yeah, but Star Track takes place in \*long ago\* in a galaxy far away. Not in the future...
Different countries will have different C++ versioning formats because reasons.
Yeah, you wish.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9g3zr0/can_someone_recommend_a_book_that_is_specifically/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Great post, thank you for the write-up, particularly part 2! It's great to see that (and how) embind works. I remember checking it out 6-12 months ago but there was some serious caveat at that time and my conclusion was that it was not an option at that time. I forgot what that was (maybe it only ran with a very old emscripten/clang version at that time and didn't have C++14 support?). But in any case it seems there are no longer major caveats, which is great news.
“Thus solving the problem once and for all!” “But—” [***“Once and for all!!”***](https://youtu.be/gONcDfFrPis)
C++098
c+++98 (yes, we will have the hyperincrement operator by then)
What?
Still around? Sure! Relevant? I doubt it. What keeps C relevant is that it is the lingua franca for all other languages thanks to it's simple and stable abi, a convenient target for high level code generation and that is simple enough that you can easily write a compiler for any new platform. Almost none of this is true for c++. Of course there will still be tons of legacy code and some specific applications where c++ remains the best choice, but I would not be surprised if c will outlive c++.
Pretty easy solution: just skip that year and after 2100, start the naming convention with three digits intead of two. I don't think C++83 is an issue because nobody calls it that. &amp;#x200B; Alternatively, we can call it "C++ 100th Anniversary Standard"
by 2098 it's 80 years in the future - that's longer than programming as we know it today exists and c++ will be more than 110 years old by then (depending on how you count much older). I really hope that by then we will have better tools to program whatever the systems will look like then. It's probably just a question of you you define "relevant" anyway. 
oh wow, the line numbers don't match up exactly and every single line is commented out lol
&gt;C++ allows compilers or runtimes not to call destructors in such cases in order for them to be able to provide more efficient implementations of exception handling mechanism. Therefore, programmers are often encouraged to wrap function main with exception handlers that catch every possible exception: Is this a common thing to do? Wouldn't you lose track on which function actually threw the exception? &amp;#x200B;
&gt; begin(v) syntax is useful only if you plan to write a generic library which can deal with non-standard compliant collection Or built-in arrays, which is the primary purpose of non-member `begin()`.
Well, the string literal restriction also applies to any pointer of reference members of class NTTPs just like it would if they were top level NTTPs, so you can't dodge the rule just by wrapping a `char*` in a `struct` like this: struct A { const char* str; }; template &lt;auto&gt; struct B{}; B&lt;A{"foo"}&gt; b; // ill-formed But other than that, everything /u/Rakete1111 said is spot on. Full details [in the paper](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0732r2.pdf).
We might even a type like ConstantString in the standard at some point - some work was done on it already ([paper](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0259r0.pdf)); the working name for it is `std::fixed_string`. It's currently dormant, and in need of someone to pick it up turn it into a complete proposal.
undefined behaviour
Looks like the declarations out of `Windows.h`.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9g4s8e/noob_question_about_assigning_arrays_elements_to/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
* C++98: C++++ * C++03: C++++++ * C++11: C++++++++ * C++14: C++++++++++ * C++17: C++++++++++++ * ... * C++98: C++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ Problem solved.
C++ will be renamed to T++ once everything is a template, so this problem won't happen.
C+=2, obviously.
Well, seeing as C++70 would probably let `auto` generate the entire program for you _at compile time_ with _zero overhead_. I don't think that revision of the standard would be needed.
Star Trek and Star Wars are two different things.
The singularity will happen around 2038. Then we won't need to write software any more.
Ah yes. I forget about this one since I didn't use them for a long time. 
Sir, you have just saved the thread.
C++ 98 2: Electric Boogaloo
It’ll be like windows 10 and just become C++ 99 or C++988 or something. Because...bad maths. 
If they're really evil they'll utilize the unused years and offset the releases so that we get C++97 &gt; C++98, C++02 &gt; C++03, etc.
What I would like to see is some proper testing of this stuff before it gets in the Standard. What are the hidden pitfalls once your codebase gets to 100 MB of source? What about 10 GB of source? I don’t like the idea of experimental standards. But it seems to me that no one is going to understand the problems that can come up with fundamental constraints on the build system until we bake it into an ISO Standard. And that does concern me a little.
Not really that novel. That's what Ayxia Logger has done for years, only it has a hierarchical trace channels and some other cool features.
C++ is run by the ISO, tho
Let the machines decide
We all switch to Rust.
Sorry mate, I think you missed the joke.
Ah yeah sorry... I don't want C++ to die just as I'm falling in love with it. I know it can change, and I know it can get better 💕, even if it is much older than me 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9g6a3z/please_help_me_with_my_homework/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
C++2k98 :)
Do you ready think that c++ is going to be around in 2098?
How do you guys miss such an obvious joke? Or at least an attempt at one.
C++ 98 2: Electric Boogaloo
This should be made into a show.
UB
Are you saying that `c+++98` has UB? It doesn't.
You're forgetting about the ISO wars of 2027.
I think C++ will be dead by them because AI will replace human programmers and will write everything directly in machine language because their minds won't be limited by obsolete biological hardware to the point where they need higher level languages. 
If there is a lot that can go into its own compilation unit, I think the STB style is the best - basically mash the header and .cpp file together, but wrap the .cpp in a define that let's someone choose when they want the implementation.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
We won't have to worry about this, because everything will be JavaScript/Electron. In fact, we won't even be speaking English, instead we will all be speaking JavaScript.
It looks like what /u/TheThiefMaster said about not needing to swap could be incorporated into your impl. Something like: if(ptr!=ptr\_last)\*ptr=\*ptr\_last; &amp;#x200B;
https://github.com/tesseract-ocr/tesseract/blob/master/src/ccmain/equationdetect.h https://en.wikipedia.org/wiki/Tesseract_(software)
Ok but what about FORTRAN then?
And they will know how to use commas, and won't write run-on sentences.
Or they just won't be grammar nazis on social media, seeing as that serves no other purpose than to annoy others. 
yeah, it was meant to be a joke, but came out sounding snooty.
Lol amateurs. Perl6 will be mocking all of you. /s 
In my early programming years, I had big plans to write Tea (to play on both C/C++ and Java), but specifically not call it Tea++, because I wanted to leave room for the next person.
I've only recently become aware of that. I'm not sure yet that either mechanism here is better than the other.
BlackBerry had this as well. It really is the way best way to do it. So although NanoLog isn't novel, it is nice to see something out in the open, instead of hiding in a proprietary codebase.
But Go still won't have generics
At that point, it seems like I'm losing some of the benefits of a header-only library, which is mostly its ease of use. It's non-conventional enough that I think it's going to add a bit of friction, which is exactly what I'm trying to avoid by creating a single-header-only version of the library that doesn't require anything but "include it and use it." If I'm going to require a source file anyhow, I think I'd prefer the SQLite approach of consolidation to a single header and a single source file. It's good to see other approaches people have taken though. The STB style seems to be more or less the same thing, except you're using the same file in two different modes, depending on that define.
Yeah header-only is simple, but the SQLite way of having a single source file and header is far superior and just as simple
This might be extremely hard to implement but I've seen this cause nightmares. Basically a way to detect a lambda is referencing capturing a variable in a scope that is destructed when the lambda is invoked. Example: struct Foo { std::function&lt;int()&gt; callback; void create_callback(int x) { callback = [&amp;]() { return x * 2; }; } int get() { return callback(); } }; that will seg fault and in a much larger practical scenario it can be very hard to find, especially for those who haven't had much experience with lambda's and how the capture works.
cheers for that
We're not coding anymore in 2098, AI will code for us. I would even say that in 20/30 years coding will not be really done anymore. 
brainfuC++, i got you buddy ;)
No thas brainfuD
That's not even just for lambdas, but has existed for decades. struct T { T (U const&amp; x) : x_ (x) {} U const&amp; x_; }; is so dangerous, and often breaks stuff. The terse syntax in lambdas just makes it a tiny bit easier to write.
Absolutely agree. Especially as that is structure that lambda would create, but that isn't obvious to those using lambdas who aren't familiar with the capture. Maybe you're right a warning that you referencing a local variable (which does exist in some cases I believe), but if it could be incorporated into lambda capture I feel like that would be very beneficial.
Hi all. I was going to code this again for yet another project and thought it would be better to make it standalone. Any feedback would be greatly appreciated. 
[removed]
Thanks! I will check it out!
[removed]
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9g3dkt/what_happens_in_2098_with_c/e62erjj/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
\&gt; Just use an interface. Go advocates, probably.
C++98++
I don't know how you're supposed to type tabs in a browser text box
I found a way.
`ALT + numpad plus + 9` works fine for me.
I found only one which satisfies my needs - [gigabase](http://www.garret.ru/gigabase.html). But your needs might ve differrent. Here u don't need any code generator you describe the schema as C++ classes and then you acces the records through them. It has also a lower level layer to access database with unknown schema. Surprisingly fast and convenient. Other option is to use sqlpp11 to add a type safe layer on top of SQL db. But I feel like all the problems of sql remain. Unpredictable performance because of sql variety, no support for basic data types like arrays etc.
The two-digit naming scheme is only colloquial. The *standard* encodes the full year and month in `__cplusplus`, and it uses `long int` just to be extra sure.
The auto idx = d-&gt;map.size(); d-&gt;map.emplace(idx, callback); pattern is broken. Removed a similar one from company code a few days ago... Try: csari::Subject&lt;int&gt; s; csari::Subscription sub1 = s.subscribe([](int i) { std::cout &lt;&lt; "sub1(" &lt;&lt; i &lt;&lt; ")\n"; }); csari::Subscription sub2 = s.subscribe([](int i) { std::cout &lt;&lt; "sub2(" &lt;&lt; i &lt;&lt; ")\n"; }); sub1.reset(); csari::Subscription sub3 = s.subscribe([](int i) { std::cout &lt;&lt; "sub3(" &lt;&lt; i &lt;&lt; ")\n"; }); s.next(42); If you need a unique handle for the subscription, why not just use a pointer/iterator to the subscription in `map`? Iterators into a `std::list` are stable.
*Disclaimer: guessing.* Having worked on similar logging architectures, I'd bet: 1. Streams cannot be easily optimized (dynamic parts, possibly spread across multiple expressions), whereas with `printf` you can (a) assign an index to the format string and (b) assign meta-data to this index indicating the number and type of each parameters; making for efficient compression. 2. Streams allow arbitrary objects, which requires work at log time, whereas `printf` only allows built-in types, so they can be `memcpy`/`strcpy` and formatted later on (decompressor). For low-latency logging, I've yet to see a better way to do it.
I'd like to be able to opt in to Rust-style lifetime analysis.
The standard will just be released in 2099, making it C++99 and resolving all ambiguities. 
We'll have been replaced with low level JavaScript by then.
My first implementation had a vector where I replace subscription functions with empty std::function. My hacky solution would be keeping a std::size\_t counter. I never knew that the iterators to the \`std::list\` were stable, this would save me from using \`std::unordered\_map\`. I will check into this! &amp;#x200B; Thanks a lot!
I enjoyed reading it anyway.
Far before that, it will be C+++, the. C++++; but it will just be written as C#.
How about [this approach](https://vittorioromeo.info/index/blog/2016_cpp_library_configuration_api.html)? I think that's much simpler. I think [fmtlib](https://github.com/fmtlib/fmt) does something similar. You don't end up with a single header, but that's not really a problem most of the time.
I am all for eliminating dead code. As our project goes on and on, it inevitably grows in size. I would like to know which classes, functions, members, methods, arguments, ... are not used. Also which statements are dead code because they have no side effect... compilers can do some, but I would *really* love to see unused members (yay less memory usage for my classes) and statements (yes, compilers can do it nicely for built-in types, but Foo x; is not caught because compilers (that I use) cannot figure out Foo has constructor without side effects).
Odb is nice, although I have not used it in production yet
What do you find insufficient with [sqlpp11](https://github.com/rbock/sqlpp11)?
If there were a few explanatory lines here, people might be more inclined to click and upvote... just saying :-)
A lot of the clang-tidy checks would be useful, particularly from the "bugprone" domain: http://clang.llvm.org/extra/clang-tidy/checks/list.html
https://github.com/fnc12/sqlite_orm
&gt; Academia (primary/secondary education) &gt; Academia (tertiary education) As a non-native English speaker, I don't understand this. It is very likely also very country specific, so you better elaborate. In all the countries I know, for example, schools (e.g. where you teach pupils and they are 13-19 years old) is *not* considered academia. Also while one can certainly google those terms, in the countries I know, people would not really regularly use (or know from the top of their head) what exactly you mean with for example tertiary education. Wikipedia is also not really too clear in my opinion. So please clarify, what should people check as A) School teacher (for example teaching 13-19 year olds), and B) if they teach in academia (==Universities, Higher Education)?
have you succeeded in production, is it dependable, performs nice, manages complex join queries, is not dev stale?
[Mandatory go_unicode_generics.jpg](https://i.redditmedia.com/PiTwgjEp7i5lHqxYd9KpZ7pey7-EbCEvRYcg2fOtCew.jpg?s=37d8b6cfc0e1df0fb5f5fbe8659ca42b)
&gt;Using magic numbers. Development is in progress, it was almost done when I saw it on LLVM Phabricator.
If a passed in variable in a function call is unmodified, a warning to use a const &amp; would be nice. &amp;#x200B; \-&gt; Also, almost done in LLVM. :) 
Greetings! Being true that the previous name was misleading (DonerECS) as it wasn't a ECS framework, I've decided to do some renames and to modify some explanations to make it clearer for the user. Hope you like it!
[That's horrifying.](https://xkcd.com/1172/)
Many of those are available in clang-tidy :)
What compiler? clang basically has most of the things you want already.
STB is great in general. But, I don’t get everyone’s facination with it packing 2 files in 1. Seems to me it would be much simpler to have 2 files as 2 files. 1.h and 1.cpp. Making a place to conditionally extract STB’s cpp code is an unnecessary complication.
Why share it twice in 3 days?
We had a system like this at work about 5 years ago, same premise of offline logging and a bunch of static template magic to reduce runtime computation of string sizes, etc. It also worked on nanosecond precision and accuracy, I think we were in single digit nanos for trivial writes too. Interesting that this tech is only hitting the general public now.
Hmm, I have to use gcc4.9 at work, not LLVM, oh well. &amp;#x200B; I am not certain I could ever convince my company to switch to LLVM.
[libpqxx](http://pqxx.org/development/libpqxx/) has been one of the few examples for libraries that could say about itself that it was fully modern C++ in spite of being a C++98-lib. They recently switched to C++11, but minor details aside it was always one of the nicest third-party-libraries to use. The only “downside” is that it limits you to Postgres, but since there aren't any convincing reasons to use anything else (maybe with the exception of sqlite) anyways, this shouldn't really limit you.
Also, there will be autoCMake, which will use a DSL to generate CMakeList.txt files. 
Are you developing a game with it?
Or flagging a function cost if it doesn't change any member variables
That is going to be incredibly slow beyond belief. Swap is pretty slow to begin with, even on an SSD, let alone one 250GB large. I'd argue your C++ program is flawed... People have calculated 10 *trillion* digits of pi with 95GB of RAM. 
No, an SSD would die very quickly. There is a reason why we don't use SSDs for RAM. A typical SSD has 100000 ( SLC) Write Cycles ( It depends on what kind of technology is used ). Meaning you can write it 100000 times from 0 GB to 250GB. I don't know what kind of program are you writing but I think you should optimize it to use less ram and try to fit it into you ram. 
This does not look like a c++ specific question to me. You might be better off asking somewhere else (r/bigdata maybe?). Keep in mind that SSDs are still orders of magnitude slower than RAM and that you can easily rent servers with that amount of RAM in the cloud for a couple of bucks an hour.
Well, the first time I presented it with a different name, and people complained because it didn't reflect how the framework works. Some people insta drop it because of this. Now I present it again with that feedback applied, with the hope now the discussion will be focused on the implementation and possibilities of the library and not focused on its name. 
If your program needs that much ram, probably you aren't solving the correct problem. A description of what you're trying to solve will be helpful
While I agree with most of what you said, I would argue that a typical SSD today is not SLC, but rather TLC, which makes this even worse.
A Paper regarding this topic: https://dl.acm.org/citation.cfm?id=3190524 Generally i do not think its a good idea. The latency of ram can be 100x times faster then the latency of ssds. The same is true for memory bandwith
tl;dr: Whats the biggest difference between this and https://github.com/skypjack/entt ? ( also recommend tagging your repo with cpp14 for discoverability ) 
wow you nerd
[Good documentation](https://www.jinx-lang.org/documentation.htm) isn't something Jinx lacks, so hopefully users don't feel the need to wade through the header to extract all that information. I can definitely understand how users might appreciate the amalgamated files. For instance, I use the Ogg Vorbis lib for my game engine, and it's a bit of a PITA to set up that project on all the different platforms I support, due to it's complex internal directory and file structure. Had I known about the amalgamated versions, I certainly would have preferred using those.
we use msvc, clang, and clang-tidy. Clang has better diagnostics in this regard than MSVC, but still does not catch most non-trivial stuff
There are quite a few users of LLFIO (https://ned14.github.io/llfio/) who use it to work with multi-Tb datasets, using the machine's RAM (usually 64Gb or more) as a cache. Performance is very sensitive to your choice of algorithm and data layout, specifically when and how you access the dataset. You need to know what you're going to access long before you will, and use worker threads or async file i/o to go fetch the data far in advance of needing it. Obviously enough, you will be limited by the maximum throughput of the device (3Gb/sec for NVMe), but also the latency (40 microseconds), and for SSDs you need to keep queue depth as high as possible (QD16 or higher). Achieving all of this is highly non-trivial, but if you have no choice, you just got to suck it down and get it done, or employ a storage specialist consultant at a hefty day rate to do it for you. Good luck!
There are quite a few users of LLFIO (https://ned14.github.io/llfio/) who use it to work with multi-Tb datasets, using the machine's RAM (usually 64Gb or more) as a cache. Performance is very sensitive to your choice of algorithm and data layout, specifically when and how you access the dataset. You need to know what you're going to access long before you will, and use worker threads or async file i/o to go fetch the data far in advance of needing it. Obviously enough, you will be limited by the maximum throughput of the device (3Gb/sec for NVMe), but also the latency (40 microseconds), and for SSDs you need to keep queue depth as high as possible (QD16 or higher). Achieving all of this is highly non-trivial, but if you have no choice, you just got to suck it down and get it done, or employ a storage specialist consultant at a hefty day rate to do it for you. Good luck!
Humans won’t be programming in 2098. 
That would be so much nicer if things like if statements had return values like other languages. Lame as make it okish but being able to assign from an if would be much nicer. Auto const f = if () 1 else 2; Is much nicer for complex statements. 
Linux will likely let you allocate 250GB of heap, but it'll most likely kill your program when you actually try to use it. Very useful.
I've started using slqpp11 recently and I'm starting to like it very well.
No, that would be brainfu++C.
What's wrong with the ternary operator?
How this compares with full engines like [Godot](https://github.com/godotengine/godot)? There are any plans to integrate it into engines or build an engine around it?
Consider just renting some cloud computer with 250+GB RAM.
xor eax, eax
I didn't say people looked through the header to figure it out, I said the documentation is pasted into the beginning in the comments. This way you are never without some good documentation, or the implementation.
Also the benchmark code for other libraries is not present in the repo, so the results are not reproducible, and it os impossible to tell if they used other libraries the optimal way (for example, did they use async mode for spdlog?) 
I will investigate cloud options, but the program uses CUDA and I need a real time video output... 
Thanks
Thanks you for your complete response. The plan is to do it myself, so I am a little bit afraid of these big data tricks :D But hey, that is why I love coding.
I will calculate the theoratical amount of data used per hour. Thanks you for reminding me that SSD are not eternal :D
You're thinking in bits. My figures are for bytes. Mine are empirically tested including kernel overhead.
I do most of my development in MSVC, so apologies if these already exist in gcc or clang... #Lifetime warnings Lifetime warnings on certain local lifetime violations would be nice, such as here: auto &amp;root = xml_document ("...").root (); root.crash (); In this case root is a view, rather than a copy, so it dies when xml_document goes out of scope. I've neutered this particular one by adding `root () &amp;&amp; =delete;` so you can't actually do this anymore, but the general principle remains. And here: std::unique_lock&lt;std::mutex&gt; (mymutex); // code here is considerably less well protected than you might think... And here: auto foo = make_unique&lt;...&gt; (); func_call (move (foo)); foo-&gt;crash (); These are all errors I find myself occasionally making, and almost without exception they occur within the scope of a single function, making them at least potentially amenable to analysis. #Cost analysis Some kind of guidance from the compiler on relative cost might occasionally be useful. In particular: - asking for move when it will actually generate a copy (for example, because the moved object is const). - moving something when it would have been better off as an elided construction. - passing a const-ref when just copying it would have been cheaper, or vice-versa. #Padding Maybe not quite so semantic, but MSVC has warning 4820, which warns for padding in structs or classes. However, it is overly sensitive: it warns on all padding, whether you can avoid it or not. A warning for _avoidable_ padding would be a cheap way to reduce memory consumption a bit. For example: struct foo { bool a; int b; bool c; }; This takes up 12 bytes on common architectures, but just rearranging the last two variables would reduce that to 8 bytes. A warning for enums that are overly wide would nicely augment that. Now that we can declare `enum foo: typename`, we can have a warning saying "enum foo can fit in a smaller type". 
a few of these are in the clang toolchain, clang-tidy has been mentioned but also clang-modernise for your for loop to ranged for request.
I believe the `setMemorySize()` has an error: while (d-&gt;memory.size() &gt;= d-&gt;nMemory) { d-&gt;memory.pop_front(); } ...should be `d-&gt;memory.size() &gt; d-&gt;nMemory`. 
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9gcgcy/using_a_nvme_ssd_as_a_giant_swap_250gb_for_heap/e63dc4v/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Or const auto f = [] () { //blabla }() ; it's quite a nice syntax for complex initialization. 
Programmers are a tough crowd :)
After Concepts are implemented, I'd like to have some sort of "strict Concepts" mode - In which template classes and functions will fail to compile if calling a function that is not known to exist for the implemented type (specified as a concept requirement). Duck typing in templates is great in some aspects, so I guess that we could have a magical "AnyType" concept, but I'd prefer that if some type does not implement a requirement I'd find it as easily as possible. Personally, it's hard to say which warnings are the most useful - all of them are great and are almost always bugs. It's just a shame that the default warning level for many compilers is so low. Why would anyone want to keep unused variables and functions? Shouldn't `-Wunused` be the default? This applies pretty much to all warnings in `-Wall` and `-Wextra`, which should be treated as errors as well.
That's OK. Mixing up ST and SW is the most offensive thing you can do when talking to fans of either so I knew it wouldn't go over well but I couldn't help myself... ;-)
You are absolutely right. I have added a unit test to expose the bug, and put your fix. Thanks :)
That's actually fairly similar to how I've been approaching the problem. I've found I need to prepend a macro to conditionally allow function definitions to be inlined. The difference that I've just gone ahead and merged everything into a single header using a utility (at which point I replace the macro with the ```inline``` keyword), rather than include multiple from headers using a set of macros. In principle, I think it's pretty much the same thing, except I'd posit that the single header file is a tiny bit more convenient. Appreciate the info!
I like Postgres and think it's the best choice in the vast majority of cases, but saying that limiting your code to it is not a drawback is rather ridiculous. In addition to the half-mentioned case of wanting to use an application-private database (covered by SQLite), how about having to integrate with an existing SQL Server or Oracle database? You don't always have the luxury of making all the choices.
:)
Lambdas aren't an ideal solution from a language design standpoint, but they work brilliantly for this use case.
Writing text 
Loading from and saving to a file would be a bonus.
vscode does a great job with minimalist. it is just a text editor but with a lot of features packed into json files which are easy to edit/script/etc. plugins are literally a button click to install and they aren't intrusive. I find it very powerful while still being minimalist.
It seems like something I would not like to have in my dependency tree.
C+098 No, that's not octal.
The state is currently dreadful, and I'm talking this by personal experience, having done two full SQL client implementations for my employers. First, most of the options available rely on exceptions. Sometime ago, I mentioned that `-fno-exception` support would be interesting to one library author in this sub, to which he replied that I should fix my code. Another thing I usually see is poor implementation, and too much reliance on ODBC drivers. There's actually not a single implementation of TDS (used by MS-SQL) in C++. The lack of descent SQL clients in C++ actually hurts its adoption on the market, IMO, and I've seen projects, where C++ would be a perferct match, be given to other teams working with different languages, merely because the hurdles involved in getting a C++ application talking to a MS SQL server.
I really, really, really don't want to discourage, but this type of thing pops up every once in a while. It's not that it's bad, it's just that it's ... is this really a huge problem for anyone?
I agree, also kinda defeats the purpose of a *meta* enum when you add runtime overhead (potential to optimise out but still). It might be nicer to add a ifdef DEBUG around the member of string but that is a bit messy, just my thoughts.
Then your previous post is irrelevant and duplicated, please remove it.
&gt; Some kind of guidance from the compiler on relative cost might occasionally be useful. I've long thought it would be cool to have some kind of annotation or something that would enforce that (N)RVO is performed on a function, and produce a diagnostic if something disqualifies the function from that optimization.
In my opinion, no it doesn't solve a "huge problem" but it does solve a "small problem" so it is still valuable. &amp;#x200B; The biggest gain by having automatic string conversions of enum values is lessened friction when developing. If i am debugging an algorithm that at some point uses enum values, then it might help me to be able to debug-print them textually to make sure I am on the right track or similar. To have to copy-paste and create a toString() function for the enum just for this purpose is just too much friction so I won't, instead I might have a bit of a harder time implementing the algorithm. A solution like this removes that friction at basically no cost. &amp;#x200B; Furthermore, in my experiences I have seen that different people get bugged to different degrees by boilerplating. Maybe you're one of those that don't mind it.
I guess that I have yet to encounter a case where automatic stringification noticeably reduced my development friction. I mean, so just look at the values while stepping through code or in the watch window. 
My autocorrect went haywire. That’s what I was trying to say I don’t like. Having to make it a lambda hides the intent that you want it to run inline. Plus it adds a bunch of punctuation that hinders human parsing. 
Sucks for complex stuff. That’s why I said complex stuff. 
They’re not brilliant. They are better than what was available before but in languages with better rules lambada are just a bad solution compared to optimal. 
Thank you for rephrasing "they're not ideal from a language design perspective".
Could you elaborate? I see absolutely nothing in modules that would help unit-testing.
You're trying to divide a string type with a float. 
you should check out http://reddit.com/r/cpp_questions or one of the many cpp online chat communities 
Ok, when I change numGuests to either int or float, I get this error with getline [http://prntscr.com/kv7pom](http://prntscr.com/kv7pom)
yeah I misread it, I thought it stored a std::string_view for each enum value, my bad.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
TDD is all about unit-testing, where dependencies are injected to free the code under test from the ties of the real dependencies. Modules do not provide that at all. Conversely, nothing stops you from having a well-defined public interface for anything, modules or not.
[removed]
I'm pretty new to c++ but have been using Unreal Engines shared pointer system for awhile and "unreal c++". I always thought default shared pointers were not supported by all devices. Writing the code once and sending it to mac, PC, iOS, android, linux, switch, xbox with only slight changes. Idk like I said I'm still learning "real c++" as I'm moving over to rendering, graphics, and ai nonsense.
I might be mistaken but aren't modules injected using the import keyword? Are you saying with C++ modules, in all cases you still need a header file in addition to the import statement? I understand that a header is needed if the module uses types in its interface that aren't visible in the client code. &amp;#x200B;
Modules versus headers hardly change anything from unit-testing perspective. That's basically precompiled headers with some extra conditions. They don't remove the need for virtual base classes. They don't remove the need to design your library to be "mockable" when it has dependencies. With modules, you still need GMock as it is, no improvements there. Also, you really should stop saying TDD when you mean unit-testing. Unit-testing is widely adopted and praised practice used by everyone, TDD is controversial and often referred to as "fanatical" and not everyone uses it.
Thank you, I somehow couldn't find this page, and the pages I have been running into were not useful at all.
I really haven't used modules yet. The impression I got about the modules feature is that you could use C++ module interfaces in unit-test instead of mocking classes and relying on macros. The C++ import keyword should only import the module's interface. Like what's done when you add the virtual base class (interface) header to your code, for the purpose of using a factory to import the component from its library (module). The client object doing the import only knows about the interface. It appears that the C++ import keyword will be a cleaner way of doing this import even during unit-testing. Not saying you don't design or stop using virtual bases when necessary, only that the modules feature appears to have eliminated one need for them &amp;#x200B; I see what you mean about TDD but I can't remove all of them. &amp;#x200B;
I use boost::bimap pretty effectively
Did you maybe look up the meaning of the word "inject" **in the context of TDD and unit-testing**? Because that's the meaning I had in mind. From that standpoint, modules are not "injected". The correct word is probably "loaded", but the meaning of the mechanics is completely different. Let's say that I have a class X program A, using classes Y1 to Yn in module B, also containing classes Z1 to Zm. I wand to write my program using TDD, and I want to unit-test it. That normally means *injecting the dependencies of class X* into the test code. Dependencies are Y1 to Yn. I want a *test implementation* of these. If I imerely mport module B, I can't achieve it =&gt; modules are completely orthogonal to the TDD/unit-testing situation.
&gt; How it achieves this insane performance is by extracting static log information at runtime, only logging the dynamic components at runtime, and deferring formatting to an offline process. This basically shifts work out of the runtime and into the compilation and post-execution phases. Ah, look, Windows event log! 😁
Don't confuse interface (polymorphic base class) with interface (an entry point to a piece of code, as in API) and with interface (the code the user now sees when importing a module) C++ modules won't change anything in unit tests beside changing `#include` to `import`. You'll still need mocks, you'll still need the macro to generate the mock, since we don't have reflection yet. &gt; only that the modules feature appears to have eliminated one need for pure virtual bases. I don't understand how moving a class from a header to an exporting module unit will remove a need for a pure virtual base. You're aware that no matter how you consume code (whether via import or include) the semantic remain exactly the same? Import will only make it easier (and possible) to only export the desired declarations from some code (a module). It may also remove most of the need for separating class declaration and function definitions, making it harder to trigger ODR mistakes. It will also greatly help reducing compilation time.
Why such low limits? 8192 maximum game objects? This is 2018. If I want a million entities, that should be between me and my RAM.
&gt; It's not that it's bad, it's just that it's ... is this really a huge problem for anyone? my hands shake every time I have to do this
Doesn't support SqlServer and ODBC is "experimental".
Yup
Your component methods are all virtual. This is slow and unnecessary. Use is_detected instead that's how unity does it aswell.
Could you explain what is wrong in your example? Im learning C++ and don't see whats wrong there.
There is nothing wrong directly, just with how to use that class. It is very easy to have a dangling reference: T x {function()}; x.x_; // the return value of function has been destructed at this point T f() { U x; return {x}; // f().x_ is a reference to an destructed object since the scope of f() ended and x was destroyed } While there are legit use cases that don’t heave any issue: U x; T y{x}; y.x_; // totally fine: x outlives y g (y); // can safely access y.x_ It is just really easy to misuse. 
I use auto with string literals if I have multiple strings: using namespace std::string_literals; auto abc = "abc"s; 
What about: std::map&lt;int, std::tuple&lt;boost::signals2::signal&lt;void(const event&amp;)&gt;&gt;::const_iterator ? I wouldn't write an explicit typedef for this (as long as it can be avoided) and I would not write the type explicitly for a declaration either.
Thanks for clarifying.
There was a survey recently showing that more than half of the C++ community do not use C++ exceptions, due to their very controversial nature, including the performance penalty they can incur into. I'm not gonna get into this debate regarding exceptions or not. All that I can say is that you're lacking a little bit of insight in this subject. The very web browser that you're using was written with C++ with exceptions off, so if you think like that, and write libraries like that, you're just hurting adoption of your lib.
&gt; There was a survey recently showing that more than half of the C++ community do not use C++ exceptions Can you give a link?
More like: if (ptr != ptr\_last) \*ptr = std::move(\*ptr\_last;)
Wow, this is awesome. Enums will be so much easier to maintain now. I can practically write them and not have to keep flicking back to them 40 times a day now. Praise be.
C++11 onwards has a library \`shared\_ptr\`, so it's not a "default" thing. You have to use it explicitly, but it is available on all devices with a C++11 compiler. You may very well need to manage your own memory allocation and release, but what that means is understanding your allocation and deallocation patterns so that you're not allocating for every little thing. That may mean memory pools or ring buffers or what have you that has their own management outside of \`new\` and \`delete\`.
Can anyone weigh in on this vs. [Better Enums](https://github.com/aantron/better-enums)?
Interesting, but too much work to do in my opinion. Also, it works only for sqlite
Mhhh agree. But libraries that allow you to write type-safe SQL-like queries directly in your source code can be quite convenient. As I said in my post, I struggle to find something in C++ that catches up with Java frameworks.
sqlpp11 is probably the most interesting one. As zvrba mentions though, not all platforms are supported.
why?
If you want much more powerful and less brittle single library include generation than your Heady utility, check out https://pypi.org/project/pcpp/. I've some some hideous things with that tool, like assemble all the Windows headers into a single unit :)
it all depends on how you throw and handle the exceptions, and whether it is debug or release build. you could also use something like \`BOOST\_THROW\_EXCEPTION\` which adds function/file/line info to the exception so you don't loose the info even if you catch the exception.
Quoting Howells’ cover letter in full (``153622549721.14298.8116794954073122489.stgit@warthog.procyon.org.uk`` for LKML subscribers): Date: Thu, 06 Sep 2018 10:18:17 +0100 From: David Howells &lt;dhowells@redhat.com&gt; To: linux-api@vger.kernel.org, linux-kbuild@vger.kernel.org Cc: Michal Marek &lt;michal.lkml@markovi.net&gt;, dri-devel@lists.freedesktop.org, virtualization@lists.linux-foundation.org, keyrings@vger.kernel.org, David Airlie &lt;airlied@linux.ie&gt;, linux-nilfs@vger.kernel.org, linux-nvdimm@lists.01.org, "Michael S. Tsirkin" &lt;mst@redhat.com&gt;, codalist@coda.cs.cmu.edu, coda@cs.cmu.edu, coreteam@netfilter.org, Rob Clark &lt;robdclark@gmail.com&gt;, linux-arm-msm@vger.kernel.org, Kent Overstreet &lt;kent.overstreet@gmail.com&gt;, Dan Williams &lt;dan.j.williams@intel.com&gt;, linux-bcache@vger.kernel.org, Coly Li &lt;colyli@suse.de&gt;, Jan Harkes &lt;jaharkes@cs.cmu.edu&gt;, Yann Droneaud &lt;ydroneaud@opteya.com&gt;, Masahiro Yamada &lt;yamada.masahiro@socionext.com&gt;, Ryusuke Konishi &lt;konishi.ryusuke@lab.ntt.co.jp&gt;, Jason Wang &lt;jasowang@redhat.com&gt;, Mat Martineau &lt;mathew.j.martineau@linux.intel.com&gt;, netfilter-devel@vger.kernel.org, linux-fsdevel@vger.kernel.org, freedreno@lists.freedesktop.org, linux-kernel@vger.kernel.org, dhowells@redhat.com Subject: [RFC] UAPI: Check headers by compiling all together as C++ Message-ID: &lt;153622549721.14298.8116794954073122489.stgit@warthog.procyon.org.uk&gt; User-Agent: StGit/unknown-version Content-Type: text/plain; charset="utf-8" List-ID: &lt;linux-kernel.vger.kernel.org&gt; Here's a set of patches that inserts a step into the build process to make sure that the UAPI headers can all be built together with C++ (if the compiler being used supports C++). Note that it's based on a commit from the sound tree to fix usage of u32 and co.. Most of the patches perform fixups, including: (1) Fix member names that conflict with C++ reserved words by providing alternates that can be used anywhere. An anonymous union is used so that that the conflicting name is still available outside of C++. (2) Fix the use of flexible arrays in structs that get embedded (which is illegal in C++). (3) Remove the use of internal kernel structs in UAPI structures. (4) Fix symbol collisions. (5) Fix use of sparsely initialised arrays (which g++ doesn't implement). (6) Remove some use of PAGE_SIZE since this isn't valid outside of the kernel. There's also: (7) Move the coda_psdev.h header file to fs/coda/. And lastly: (8) Compile all of the UAPI headers (with a few exceptions) together as C++ to catch new errors occurring as part of the regular build process. Changes for v2: - Merge commit from sound tree to fix u32 usage issues - Use a switch to fix sparse array initialisation - Simplify nilfs2 by performing bitwise ops in LE space not CPU space - Handle conflicting fix to use of 'private' in keyctl.h - Move kernel internal coda bits to coda internal headers - Move coda_psdev.h header to fs/coda/. The patches can also be found here: http://git.kernel.org/cgit/linux/kernel/git/dhowells/linux-fs.git/log/?h=uapi-check Thanks, David --- David Howells (11): UAPI: drm: Fix use of C++ keywords as structural members UAPI: keys: Fix use of C++ keywords as structural members UAPI: virtio_net: Fix use of C++ keywords as structural members UAPI: bcache: Fix use of embedded flexible array UAPI: coda: Move kernel internals out of public view coda: Move internal defs out of include/linux/ UAPI: netfilter: Fix symbol collision issues UAPI: nilfs2: Fix use of undefined byteswapping functions UAPI: ndctl: Fix g++-unsupported initialisation in headers UAPI: ndctl: Remove use of PAGE_SIZE UAPI: Check headers build for C++ 
Hi guys, I just released a new version of transwarp. With transwarp you can easily create a graph of tasks where every task can be executed asynchronously. Any feedback is appreciated!
Also, why does API return plain pointers?
just skimmed both and it looks like their pretty similar, but meta-enums doesn’t have quite as much preprocessor black magic
useful, thanks!
Not your standard text book but worth reading carefully. It contains much information, spelled out very nicely.
Would care to elaborate the "non-standard" aspect of the book ? I myself feel very tempted to get my hands on this book and would like to know a bit more about it.
UAPI = Userspace API. These headers allow C (or, hopefully, C++) applications to access Linux-specific functionality that the kernel exposes to userspace. Generally this involves filling in some complicated structure and poking it at the kernel using a system call (or an ioctl, which is a special case of a system call where the first parameter is a file descriptor).
It's extremely important. There is a huge list of cases where input/output on enum values is needed: log files, configuration files, GUI lists, etc.
I'm well aware exceptions are "controversial" and I'd be happily supporting any library showing the middle finger to that C++ fraction. Outside of real-time applications (i.e., deterministic response time), turning off exceptions is nothing more than looking backwards. &gt; The very web browser that you're using was written with C++ with exceptions off That's incorrect. I'm using Edge, which uses Chakra JS engine which does use exceptions: https://github.com/Microsoft/ChakraCore/tree/master/lib/Common/Exceptions So there's that.
thanks, good point
&gt; Use is_detected instead that's how unity does it aswell. This is inconvenient and unnecessary. If you're programming on a console, I will give you a pass for reflexively repeating this gamedev "tribal wisdom". But if you're targeting computers, and following the vtable entry is your performance bottleneck, your design sucks anyway.
Have you reported the clang bug?
We should also get support in the standard lib for a Wipeout 2098 clone.
&gt; R's and Pandas DataFrame in modern C++ using native types, continuous memory storage, and *no virtuality* for data analysis and machine learning What is "no virtuality"? Do you mean no virtual methods? Maybe I'm just reading the sentence wrong. &gt; a C++ statistical library I think more correct would be "a C++ library for statistics"? Your readme could really use some basic things like what minimal compiler versions it is supported on (clang/gcc/msvc/AppleClang), what standard, and a simple example in the readme.
Cool thank you!
Had a quick glance, and doesn't look like there is a way of specifying a custom string to output for an enum value. This might be important for certain use cases like https://google.github.io/styleguide/cppguide.html#Enumerator_Names which require appending `k` in front of names, but doesn't print that in the output string.
 There is FreeTDS, and yes it is a C library and not a C++ library but also since it is a C library it fits in with your requirement of no exceptions. In fact many open source languages that need to talk to MS SQL use freetds under the hood.
&gt; why this is relevant for C++? There is an effort to move the arguably most important C code base out there towards C++ compatibility. This is just userspace part but Howells did state his intention to achieve the same for the kernel side eventually. Also, the patches illustrate just how much (or how little, depending on your expectations) the two languages diverged, and also what workarounds we’ll see on the C++ end. &gt; As a non-kernel developer I also don't know what kernel UAPI headers are As u/scatters wrote, you need them to talk to the kernel via the ioctl(2) syscall. This API is somewhat peculiar in that it allows passing raw structured data between user space and the kernel whose layout isn’t described by the signature of the system call itself. Instead, the kernel provides a bunch of headers for user space applications to define those structures. There’s an (apparently incomplete) list of uapi headers in the [ioctl_list(2) manpage](http://man7.org/linux/man-pages/man2/ioctl_list.2.html). 
Yeah... I don't doubt it... but honestly this sort of database glue code is not really C++'s sweet spot...
The docs and examples are in DataFrameDoc.pdf. Re/ English sectances, you are probably right 
If you're talking about ``CGameObject* CreateGameObject();`` it should return a ``CHandle``. I'll fix it asap!
If you look to CHandle implementation, it's only 32bits so it's the maximum I can track. Anyway, probably I could make it 64 bits so that would give you from 549,755,813,888 to 2,199,023,255,552 GameObjects, depending on how many bits I reserve to increment the number of different components and different versions. Probably you're right and 8192 is a pretty low number :P
Well to be honest I'd like to see the platforms &amp; a hello-world right away, without having to go search for (or click on) another link or document. That's what the readme is for. Time is precious, and I won't go searching for that PDF. Okay, in this case I can see now that it's directly in the root of the repo - but still, it's one more additional step. Unfortunately, the PDF is also rendered very badly on GitHub - not sure if that's GitHub's fault or if your PDF is weird. I've also spent a minute now with that document but wasn't able to find out minimal compiler support. In the example in your PDF, you load data from `vector&lt;T&gt;`'s. Can your library also load data directly from CSV or other file formats? Or do users need to do all the parsing by themselves?
Thanks a lot! :-)
I haven't worked with it, but AFAIK Godot is a complete engine, supporting not only GameObject hierarchies and so on but also rendering, physics. It has an editor. It's multiplatform... it plays in a completely different league :P DonerComponents aims to developers making their own engine in C++. They will save all the work that implies creating a component framework from scratch. About your second question... I'd love to see any engine integrating DonerComponents as its components framework, but I think it's early to see something like that happening. As for myself, I'd like to develop a small, full game using DonerComponents to put it to test and see how far it could get. That'd imply creating my own simple game engine ofc :D
Ah you’re right! I saw public at the top and didn’t see protected later on down. Sorry about that!
Perhaps you can have a separate function to format the name to your liking?
I will put the compiler info in there. But you need C++14 or above. The library can read from and write to csv files. And there are many different ways of loading the data. They are all in the same doc file I am looking for people to contribute. Specifically I am looking for binary file read/write and more statistical routines/transformations
&gt; but to create a user on their bugtracker you have to send an email Yes, mine sounded something like "hey, I need an account because I made your compiler segfault", with proper punctuation. I got an account within an hour, so it's not that scary. &gt; feel free to do it if you have an account I do have an account, but I also didn't hit this bug, as I'm still in C++11 era. Adding to that that I don't have too much time this month, it just won't happen. I'd like to also point out that in open source world, compilers included, we are responsible for the software we use. 
Tools are awesome.. gonna try them .. subscribed channel.. awesome contents I must say
Well it's the male parent of a baby sheep of course!
No direct criticism at this project, but it's hard to imagine wanting a library like this without an interpreter/repl.
No worries
Related to this, I was poking around with it and was able to fix it except for the complex case by changing the macro as follows: using namespace std::literals; constexpr static auto Type##_meta = meta_enum_internal::parseMetaEnum&lt;Type, UnderlyingType, Type##_internal_size&gt;( **#__VA_ARGS__ ## sv**, []() {\ You can see the changes functioning here: https://godbolt.org/z/R66r9U
I admit that ease of translation from Python/matlab to this library was not one of my significant design considerations. But as long as you have the data in a common format (currently this library can read/write CSV files) and as long as you have the same statistical routines, the translation shouldn't be bad. It might not be a trivial task depending on what you are translating. Re/ benchmarks, I don't remember specific timings. But I created a test to do simple bucketing and averaging of S&amp;P500 constituents' tick-by-tick data for a week. Python/Pandas never finished and crashed. This library ran to compilation in I think less than a minute. It was on a friends personal PC running ubuntu with 4Gb of ram 
Sure. Why are you surprised? I usually use either boost test or gtest, but Catch2 is easily on par with those.
Goes doubly for me, since I can't click a link to a google form.
&gt; so just look at the values while stepping through code or in the watch window. -4286 Now find the header in which it's defined and what it actually means.
Because the benchmark support is undocumented and very, very, very, experimental.
Still in uni and have yet to touch lambdas. Is this common in the real world? Btw the explanation and compiler view really helped get my head around the concept. 
Booleans in user interfaces make me sad. They are opaque at the call site and subject to integral type conversion. Named parameters can help with this, but I don't see them being part of the language for a while (if ever). In situations that aren't a (measured!) performance bottleneck, I like to use [this](https://godbolt.org/z/4OdSfH) method. With optimizations turn on, the compiler emits just the boolean check and no inheritance baggage. In performance-critical cases or where code duplication isn't too bad, I would use a type trait and tag dispatch- especially in C++17. The particular case I was looking at is the `load_column`. For example, load_column("my_col", beg, end, true); load_column("my_col", beg, end, false); becomes load_column("my_col", beg, end, pad_with_nans{}); load_column("my_col", beg, end); 
Last time I checked, Better Enums doesn't actually create a true native C++ `enum` that you use directly - it creates a `class` and holds the integral value as a member. (similar to the old [Dr. Dobb's intelligent enums](http://www.drdobbs.com/when-enum-just-isnt-enough-enumeration-c/184403955)) Due to this it appears to have some limitations in some usages/statements, that make it necessary to promote its value type explicitly. And it means you cannot use the faux-enums for non-type template parameters, since user-defined classes aren't supported for non-type template params in C++ (yet). Compared to Meta Enum and [Wise Enums](https://github.com/quicknir/wise_enum), which both create true C++ `enum`s or `enum class`. Better Enums can be used even in C++98. Wise Enums can work in C++14. Meta Enums requires C++17. Better Enums also cannot be declared within a `class` - only a namespace; to solve that you can write a `using`/`typedef` in a `class` to bring it in. I don't know if Meta Enums has this limitation as well; Wise Enums did have this limitation, but its author thought it wouldn't be hard to overcome it. There are, of course, other solutions such as: * https://github.com/therocode/smartenum * https://github.com/nadult/fwk_enum * https://github.com/flaub/boost-enum * https://www.codeproject.com/Articles/318690/C-11-Non-intrusive-enum-class-with-reflection-supp 
Interesting. How do you compare your technique/tag dispatch vs. using enums? For one thing, your technique/tag dispatch is more tightly typed but more lines of code.
This is correct (the link covers this in more detail). Tertiary education covers university, technical schools, private colleges (not university), and so on. Essentially any form of education after high school.
How can I add a description to a Reddit link? I was not given an option.
It kinda depends on the language. But now that they exist in C++ I don't need opaque "context" pointers anymore.
Thoughts about an enum class instead of a bool in the interface: enum class nan_policy { pad_with_nans, dont_pad_with_nans }; void load_columns(..., nan_policy p) 
Would be good to start by explaining whether it's compile time reflection or runtime reflection. Vaguely it looks like runtime reflection from skimming the code; if that is true then it's rather ironic that you complain that you found high overhead in other reflection frameworks. &gt;First of all, it is necessary to answer the most obvious question: why didn't you use something already existing? &gt; &gt;The answer is just as simple. I always came across some details that I didn't like: macros, being intrusive, high overhead. I was looking for a non-intrusive and (possibly) macro free library with low impact and some features that I didn't find anywhere. Finally, I decided to write such a library for myself. The biggest problem with being non-intrusive, is that the moment you are non-intrusive you can't get out of repeating all the fields, somehow. Whether you write it out yourself, or you use codegen. I also don't see the grounds for being super against macros that you only need to invoke as part of a library API. The alternative to that is either even more repetition, or codegen, which in turns requires error prone manual work or build system integration. All the options here are pretty bad I think but a well written macro I think works very well. FYI, Boost Hana can be used both intrusively (saves repetition) and non-intrusively, it's compile time reflection so it has no runtime overhead at all, and it's also realistically one of the highest quality libraries of its kind in existence (written by someone very knowledgeable, and passing boost code review by numerous very knowledgeable people with high expectations for boost code). It has macros but they work extremely well and I've never had issues. I'd highly recommend you give it an honest shot before rolling your own.
In this case, with just two options, I wouldn't. In general, I also tend to stay away from enums in interfaces. Although scoped enums are strongly-typed and also can have expressive names, they are just too much like writing C for me- and I like to keep my C and C++ separate. It's not necessarily a bad design, but it's not the one I reach for first.
Lambda was introduced in C# long time ago.
I'm confused about your use of the term submodules. The usual way I have seen submodules is in the sense of [git submodules](https://git-scm.com/book/en/v2/Git-Tools-Submodules). These are typically kept in a folder called extern and aren't actually part of your project. They are just git references. The word "module" has a lot of meanings, as does the word "submodule." Essentially if Cmake is done correctly, the software becomes a module, and it can be used within a larger project as a "submodule," but the idea of a submodule as the equivalent to a git repo makes a lot of sense too, and the "git submodule" linked above is one very awesome way to think of submodules. Regardless, any modern CMake project template and setup should absolutely work with local submodules and "git submodules," and there should likely be a distinguishing difference between the two within the project and folder structure.
I see your note on external regarding git submodules, but what I don't necessarily understand is all the language in the section regarding submodules. You start off by talking about large projects, but my point is that to be a submodule, there isn't any requirement that it be part of "very large projects." It seems that every component in software could be thought of as a module or a submodule depending on the context, regardless of how big or small it is. How do you define the difference between a submodule and a software component that might be re-usable within larger contexts?
Maybe mandated LTO should be considered.
A submodule is distinguished by a few important factors: - It may produce it's own linkable. - It has it's own distinct include directory. - It may have a unique set of dependencies. - It may be omitted from a project build. - It is optional for consumers to use a submodule distinct from other submodules, barring inter-submodule dependencies. The "Submodule" here has a very precise term. So do "physical component" and "logical component." The distinction between them is essential.
You're right. I should have mentioned it. This is a tool for runtime reflection, that was my requirement. I've still to integrate it in the rest of the library though, so you cannot see it in use yet. Btw it creates a web of objects to consume at runtime as you pointed out. I'd be glad to discuss the reasons and the purposes of that, but I think it goes far beyond the scope of a post on Reddit.
I think it's a useful abstraction (and also useful from a consistency point of view) to treat targets in a project the same way as submodules. If a project only consists of a single library, it should be a repository with a single sub module in the base directory. Creating a different layout for submoduled projects makes it more difficult to programmatically reason about where things are.
&gt; It may produce it's own linkable. well, so everything then ? executables, shared libraries, static libraries... they can all be linked to. 
Unsure if this is lamedad joke or a lambad one.
C++17 isn't that big of a jump, C++11 is. This book is from 2008, I would recommend finding something more recent. 
This is my fault, I should have mentioned that it's a runtime reflection system because that was what I needed. Unfortunately I've still to integrate it in the rest of the library, so you cannot see it in use yet. &gt;Vaguely it looks like runtime reflection from skimming the code; if that is true then it's rather ironic that you complain that you found high overhead in other reflection frameworks. It would be ironic if it wasn't optimized both to reduce memory usage and to speed up operations. Btw you said it: you just skimmed the surface, so I guess you didn't get it as a whole. It's rather ironic that skimming the surface may seem enough to comment on performance and memory usage though. I'm pretty sure I did something wrong, but comments made out of facts would be more helpful to improve it. &gt;The biggest problem with being non-intrusive, is that the moment you are non-intrusive you can't get out of repeating all the fields, somehow. \[...\] I also don't see the grounds for being super against macros that you only need to invoke as part of a library API. \[...\] All the options here are pretty bad I think but a well written macro I think works very well. Being non-intrusive has drawbacks, this is true. On the other side, this is a library (used even by Mojang in Minecraft) that stands as a non-intrusive tool on which to build games and applications in general. It's a choice, with its pros and cons. I'm also not *against* macros as a tool. I don't like when they are used to place a friend declaration or a public keyword in your types by hiding them behind a statement like - *put this macro in your class and the magic happens*. No, dear, the magic doesn't happen, you're just breaking my design!! To be honest, I think I'll develop a set of macros to ease reflecting types sooner or later, more or less because of the reasons you mentioned. &gt;Boost Hana can be used both intrusively (saves repetition) and non-intrusively, it's compile time reflection so it has no runtime overhead at all I know Boost.Hana and I used it. In fact, it's all what I don't need at the moment and responds to different needs than mine (listed above and in the linked documentation). Use boost.hana because *\[see reasons above\]* is a pretty pointless suggestion in this case, forgive me. It would make more sense to tell me - *use* [*rttr*](https://www.rttr.org/) *because \[put here your reasons\],* although also this library lacks some of the features I need, as well as Boost.Hana.
Hey, I've been looking into string to decimal and vice versa conversions for my library StringIO, and I stumbled upon the Dragon4 algorithm, and I was wondering if you guys took it into account, or if you've ever heard of it? it's pretty cool tbh, it allows sane rounding (3.0000000000001 == 3.0), and even cooler, it by default uses the shortest, unique representation, so that decimal -&gt; string -&gt; decimal will have the same exact bit pattern. 
Hey /u/hmoein cool! Really ambitious project as well! We're working along similar lines with xtensor and xframe. Maybe there are some opportunities to collaborate? https://github.com/QuantStack/xtensor https://github.com/QuantStack/xframe
The 2nd edition came out in may 2014 and advertises with the usage of both C++11 and C++14 features. That should be fine then, right? 
yes
You got owning raw pointers and wish you had unique_ptr's already? Well, technically could just gaslight the vector: auto rawvec = std::vector&lt;int*&gt;{ new int(2), new int(3), new int(5), new int(2) }; auto &amp; vec = *reinterpret_cast&lt;std::vector&lt;std::unique_ptr&lt;int&gt;&gt; *&gt;(&amp;rawvec); vec.erase(std::remove_if(vec.begin(), vec.end(), [](auto const&amp; pi){ return *pi % 2 == 0; }), vec.end()); Sorry for the cringe but *"it works"*...
Ha, and there are people who say C++ is complicatet! ;-)
I'm not sure this is a solution I'd allow anyone to write, ever. I think just enunciating it should be a capital sin, punishable by segmentation fault.
Aren't properties (something you can set on almost every reflected thing) what you call metadata? In what they differ?
Oops, sorry, totally blanked out on that part. Perhaps you could also add an example of putting a property on members (a good motivating example could be like adding a range to a numeric value).
Regarding the last point, I already use and strongly recommend an app folder for executable code. It makes it easy to exclude the whole subdirectory in cmake if building the executable or sample code is not desirable by the user. I prefer a separate tests folder for the same reason. For storing unit tests adjacent to the source files they pertain to, I find this annoying in practice as managing the cmake test project is now “a thing” and its complexity scales with your project size. It also makes discovering existing tests more of a chore. One thought I’ve had is to put unit tests inline with the source files. These are compiled out generally but activate when building a testable version or debug version. The test executable simply has a different entry point. This way you are generally checking automatically if the tests compile at all and the existence of unit tests is easily checked. The overall file count doesn’t double in the worst case, and the cmake code to do this is simpler too
Uhm, I don't think this is valid code, is it? `sizeof(int)` is 4 (on most platforms) whereas `sizeof(std::unique_ptr&lt;int&gt;)` is 8 on the same platform...
That was what I was wondering too, I thought the memory layout of std::unique_ptr was different from *int?
It's very bad code but it sizeof(int*)
How about deleting the pointer in the `remove_if` predicate? v.erase(std::remove_if(v.begin(), v.end(), [](auto&amp;&amp; i) { bool c = *i % 2 == 0; if (c) delete i; return c; }), v.end());
&gt; I'd be happily supporting any library showing the middle finger to that C++ fraction You clearly feel very strongly about it, so not the sort of person to have a balanced discussion on the subject.
1. As engineering professionals, we should at least review the code and licenses we are pulling in, establish whether the dependencies' coding practices are acceptable and whether vulnerabilities are present/relevant; by that time, most problems are solved ad hoc. I've shown that on a JSON serializer, a std::variant implementation and Utf-8 escaping/validation. Ad hoc solutions are always better and should be preferred if possible. I doubt you face a problem where you _really_ need a dependency on an ORM framework. It's more "I would _like_ to have an ORM framework". Write what you have to write, this ain't no Ruby on Rails or NVM where it became pretty normal now to mesh up applications instead of engineering them. 2. Most probably one compiles C++ into machine code. The opportunity for vulnerabilities there is high. So, more control is warranted. 3. Generating C++, in my opinion, should be motivated only by optimizations or an integrated validation process. Else use templates or some other C++ voodoo. Code generation is a complication to build systems and doesn't make sense semantically (what do you have the compiler for? drinking tea?). This I've found out the hard way when using a code generator for state automatons; terrible experience.
&gt; Grisu3 is considerably faster and avoids the need for bignums Oh that's nice! I was actually writing a bignum system for that, thanks for the tip.
It is really important if you consider what is involved on getting cross-platform support for ODBC and MSSql drivers.
Unless you have a deleter... http://www.bourez.be/?p=19
The article doesn't mention \[boost ptr\_containers\]([https://www.boost.org/doc/libs/1\_55\_0/libs/ptr\_container/doc/examples.html](https://www.boost.org/doc/libs/1_55_0/libs/ptr_container/doc/examples.html)) at all, I wonder how this would apply to those?
I will repeat a question that went unnoticed in part 1. What if the C++ portion of the codebase is a dependency of another portion written in another language? Or what if it's the other way around and the C++ code embeds the interpreter for some high level language? What's the recommended Pitchfork project layout?
Gosh, sometimes a good ol for loop will do. More explicit and readable and no need to remember the finer semantics of all the STL stuff.
This isn't one of those times
Before I would say that sorting an array of unique_ptr is slower than sorting an array of raw pointers, I'd measure; perhaps I'd also have a look at the generated assembly, via godbolt. And even if it works, it shouldn't be done, the reason being that there are many ways to shoot yourself in the foot with C++, there's no reason to add another one. These thoughts scare me.
Your suggestion is what I normally do. There is no problem deleting the pointed to object.
To answer my question about the potentially improved std::sort performance, I fooled around with it a little bit and it results indeed in a small speedup: With MSVC 2015 x64 and full optimization on my machine I get pretty consistently ~2% faster times sorting a unique_ptr vector as a vector of raw pointers than when I sort the vector without the cast. On wandbox.org with recent versions of gcc and clang I got results in the region of 5-8% but far less consistent probably due to other stuff running on the machine as well. These are of course not very scientific results but I find it kind of interesting and it's almost enough improvement that it bothers me to have it wasted for pretty much nothing. After all, this is C++ and we always get told that we have to deal with all the anachronistic memory allocation issues for the oh so holy zero cost abstraction, but 2-8% is more than zero. #include &lt;vector&gt; #include &lt;memory&gt; #include &lt;algorithm&gt; #include &lt;iostream&gt; #include &lt;random&gt; #include &lt;chrono&gt; template &lt;typename T&gt; int sortVec( T &amp; vec ) { auto start = std::chrono::steady_clock::now(); std::sort(vec.begin(),vec.end(), [](const auto &amp; lhs, const auto &amp; rhs){ return *lhs &lt; *rhs; }); auto time = std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(std::chrono::steady_clock::now() - start); return time.count(); } std::vector&lt;std::unique_ptr&lt;int&gt;&gt; createVec( int size ) { std::srand( 123 ); std::vector&lt;std::unique_ptr&lt;int&gt;&gt; vec; for( int idx = 0; idx &lt; size; ++idx ) vec.push_back(std::make_unique&lt;int&gt;(std::rand())); return vec; } int main() { const int cnt = 50, size = 1000000; int time = 0; for( int idx = 0; idx &lt; cnt; ++idx ) { auto vec = createVec( size ); time += sortVec( vec ); } std::cout &lt;&lt; "unique_ptr&lt;int&gt; time: " &lt;&lt; time / (double) cnt &lt;&lt; '\n'; time = 0; for( int idx = 0; idx &lt; cnt; ++idx ) { auto vec = createVec( size ); time += sortVec( *reinterpret_cast&lt;std::vector&lt;int *&gt; *&gt;(&amp;vec) ); } std::cout &lt;&lt; "int* time: " &lt;&lt; time / (double) cnt &lt;&lt; '\n'; } 
You could certainly get better benchmarks if you didn't measure the execution time in integer milliseconds and you would use the high resolution clock. eg. `auto time = std::chrono::duration_cast&lt;std::chrono::duration&lt;double&gt;&gt;(std::chrono::high_resolution_clock::now() - start);`
Technically it's undefined behaviour
I agree, this is not something that should be done in regular code but I wonder if it would be something that a standard library implementation could do with a template specialization of std::sort for unique_ptr ranges as this is probably a somewhat common use case. The library implementer would of course know if and when it's perfectly safe to do. I'd really like to know what /u/STL thinks about this.
Is it? I mean sure, it's not guaranteed that this will work, but is there any actual *undefined behavior* in the C/C++ sense involved here? I mean if I wouldn't use the std classes but implement my_own::vector and my_own::unique_ptr of which I know the exact memory layout, would it trigger any actual undefined behavior of the language?
First you write your `delete` in the predicate, than the condition becomes more complicated and gets extracted into a function/functor, than you reuse this functor in another algorithm, which is not guaranteed to evaluate the predicate only once... Better not break the single responsibility principle. BTW, for pointers how about this: for(auto&amp; i : v) { if(predicate) { delete i; i = nullptr; } } v.erase(std::remove_if(v.begin(), v.end(), [](auto&amp;&amp; i) { return !i; }, v.end());
It's a strict aliasing violation for a start. vector&lt;T&gt; cannot be aliased as vector&lt;U&gt; , unless T and U are the exact same type
It is under the LGPL. That shouldn't be a problem if you link to the shared object / dll.
What happens if you run the vector&lt;int*&gt; first?
&gt; The signature does not need to have const &amp;, but the function must not modify the objects passed to it. But why?
Here is one way to do it but I think it looks neither much better not far worse. auto ptr = vec.begin(), dest = ptr, end = vec.end(); for(; ptr != end; ptr++ ) { if( **ptr % 2 == 0 ) delete *ptr; else *dest++ = *ptr; } vec.erase( dest, end ); 
I've seen something similar to convert a `vector&lt;ChildClass*&gt;` to a `vector&lt;BaseClass*&gt;` in a getter (where re-creating a `vector`was judged too costly)
Hi, easiest way (if you want) is to hop on our gitter channel: https://gitter.im/QuantStack/Lobby Would be cool to chat with you! 
For those who wonder about: &gt; (for reasons outside of the scope of this post, vectors of `unique_ptr` can’t use a `std::initializer_list`) https://stackoverflow.com/questions/9618268/initializing-container-of-unique-ptrs-from-initializer-list-fails-with-gcc-4-7 Excerpt: &gt; `initializer_list`s always perform copies, and `unique_ptr`s are not copyable. This is something really annoying about initializer lists. You can [hack around it](https://stackoverflow.com/questions/8468774/can-i-list-initialize-a-vector-of-move-only-type/8469002#8469002), or fallback to initialization with calls to emplace_back.
Good call! When I do the raw pointer run first it's now 2% slower with MSVC 2015. So there is no actual performance improvement from the cast. I'm a bit surprised by this as I thought the 50 iterations would already mostly eliminate effects like this. When I run only one variant per executable in a loop I get the the same faster times for both variants.
Honestly it's a lot worse: I had to look at it for quite a while until I was sufficiently convinced that the memory-leak I first believed I saw was not in there.
I realize that "injected" was used out of context. I said "injected" because I assume the C++ module import would add code that also causes the module to load after a function is called on the interface. If you're using a test version of the module, the injection would occur through the import. The point was that if a module's interface can be reused, it's possible to reuse the interface for unit-testing a component that depends on it . When you say the "dependencies are Y1 to Yn" I believe you really mean that class X program A depends on the interface(s) used by classes Y1 to Yn. In TDD your class X program A would not mention those classes (Y1 to Yn) in their implementation, neither would they need to know they existed. Anyway I need to try out the experimental implementation of GCC to see how C++ modules work at this point. I was thinking they're adding the the "separate interface from implementation" into the compiler itself. 
You shouldn't use `std::chrono::high_resolution_clock` for this as it is not guaranteed to be steady (and usually isn't); instead use `std::chrono::steady_clock`.
Yeah, benchmarking is hard. You're only talking about a 2% difference, so it's pretty easy to get it subtly wrong and make one of the algorithms look better. If you are wondering if something is having an effect on the results, a nice way to test it is to run a benchmark comparing the exact same code and make sure the times are the same.
Can't you call `delete` ob `const` pointers anyway?
If I were to allow nullptr in my vector (maybe for re-using or to indicate that index is invalid). This code wouldn't be identical to the OP's. Yours delete all the nullptrs regardless of the predicate.
&gt; When writing C++, I’ve never used sibling test files. In fact, I rarely see people who do use sibling test files. I was biased against it, but included it as an option for completeness. I also wanted to hear the justifications from those who use sibling test files. I didn’t expect to have my mind changed. Despite this and the survey results, I'm *very* happy to see sibling test files sanctioned. This is what we use for unit tests where I work (that the rejected Option 2), and I very much prefer what we'd have if unit tests had to be separated out somewhere. As you say, this works well if you have headers + source next to each other, and I actually have a hard time seeing why, for mid-sized projects and above with hundreds or thousands (or more) files you'd want to "have to" mirror the `src/` tree under `tests/`.
Yea, I'll look at the experimental implementation. The summation of what I was saying is that, the C++ module feature would probably generate a pure virtual base for each module, and the implementation would be a library that rely totally on the virtual function table. This would be different from include files. From what's being said here that's not what the implementers are doing.
Nah, just wanted to clarify. I'm implemented several similar systems and used a few in big games engines, and wanted to be sure that's what this was. :) That said, as an unsolicited opinion, I personally think it's the wrong way to go these days. I'd really like to see a nice precompiler (Clang-based, probably) to generate intermediate IDL-like files from code/type structure, which are then easily consumable by custom code generator passes. I don't want a runtime data structure that I have to iterate to generate script bindings or to run serialization; I want to generate efficient type-specific functions for doing those things, and only on the types that actually need it (but letting an optimizing linker throw away versions that do get generated but go unused). Plus the intermediates can be used to generate non-C++ code, e.g. to generate interop libraries for C#, GUI data structures, downstream IDLs for protobuf or the like, in-app script wrappers, deserializers for external scripting languages like Python, etc. Games at scale these days are a lot more complex and interop with servers, services, and tools take so much more time and effort than most things core in the game engine! We've used runtime reflection to basically just do all the above in the past, but at much greater complexity and cost. Basically, we loaded the game as a library, and iterated the runtime data to spit out what we needed. Required tons of bespoke C++ code for each use case and still left the runtime bloated and inefficient. Unfortunately, the open-source Clang-precompiler reflection systems out there (that I know of) still just generate some kind of runtime-oriented data structure in the end rather than feeding intermediates back into the build system. I know several proprietary engines that have systems like I'm talking about, but nothing that's really freely available (that I know of).
That’s not as simple as you’re suggesting.
It is up here: http://eel.is/c++draft/algorithms.requirements &gt; The function object `pred` shall not apply any non-constant function through the dereferenced iterator.
I'm sorry to break the fun, but C++ modules won't generate code, and won't implicitly create classes with overhead (polymorphic base classes). If you export a class with a bunch of non virtual member function, importers will see *exactly* that. Did you read the technical specification of modules? It's really interesting, and will help you when trying them out! Actually I'm really happy modules won't imply every function call will be done through virtual calls. I have a game engine that has almost no virtual functions beside private classes, and I pass stuff mostly by value. Keeping this low overhead is really important for many C++ programmer.
I see what you did here. You have `remove_if` algorithm implemented in the loop. The time and space complexity is better than `stable_partition`. 
How does QPointer work? Does it register itself with the QObject which in turn signals listeners that is has been destroyed from the destructor?
Thank you very much, I'll go for that book. May I ask you though what you're referring to exactly when you're saying that "C++'s philosophy of engineering is different to all other programming languages"? 
`mutable` all the things.
While executables can be linked to if you do some trickery, I'm referring to dynamic/static libraries as the linkables. You can have multiple executables in a source directory, but at most one library per source directory.
Join us in the games / graphics industry and you don't have to worry about any of this :)
I understand the hesitance with sibling files for testing when using CMake, but I think a simple CMake function is all that is needed to provide the necessary organizational control. As a CMake user and teacher, I plan to write additional materials on how this layout will interact with CMake. I've taken close consideration of how this layout might effect CMake projects since that is what I will be using primarily for the foreseeable future.
[I've written a response to that comment](https://www.reddit.com/r/cpp/comments/9gn63x/pitchforks_part_iii_layout_survey_results/e67c99g/). I'm hoping the layout will work with most any decent build system, and possibly new ones that haven't even been written yet.
You can use only standard algorithm that use `swap` to move container elements with Boost pointer containers. For example, `std::partition` can safely be used with `boost::ptr_vector`, but `std::remove` will likely cause memory leaks or double deletes.
For embedding or exposing an API to a different language, this is the job of a Submodule in `extras/`. I've written Python extensions before, and I may have a write-up showing how to use `extras/` in this way. For embedding in a larger project, the entire C++ project tree will just be a subdirectory of a larger project. Pitchfork is designed to be embeddable in this way.
Thanks for all the really good input. 
I'm not sure I'm comfortable with using Borg technology.
Cmake is one consideration (your cmake stuff is great btw) but also other utilities. Checking lines of code in a codebase. Renaming files (don’t forget to check and move sibling files too). What if unit tests require mocks - should those be siblings too? Alternatively, should mocks for classes also be colocated by the same principal? The hardest thing for me though is really the thought of navigating through 2N files in the sidebar of an ide or editor. 
Do you usually start your day with "how much undefined behavior can I get way with today?"
We currently mutate stuff through remove_if in Clang, GCC, and MSVC and they all produce deterministic correct results so no idea. If there's some legitimate reason why that rule is in place then it just means I have to write my own version of remove_if that allows mutating inside pred(T).
Any one ? 
Let me play a sad song for you on the world's smallest violin. (PS: then don't press the button)
Orgasms in clang
Fluent cpp is good Watch cppcon talks
I meant to mention this the other day when you posted this: it's interesting that you turn the macro's arguments into a big string and parse the string at compile time. Most macro's I've seen for creating enums process the arguments as regular, individual preprocessor function arguments. I can't decide if doing it your way is genius or insanity, or both. :) It feels like your way would be more brittle, in the sense that it has to deal with all possible legal tokens/statements for each argument. For example, can your meta enum handle setting an enumerator value to a namespaced value? (e.g., `Second = ::foo::bar::value`) On the other hand it might be _less_ brittle as it might avoid issues with extra comma's being preprocessor function arguments. For example as your test file handles with `Second= sum(1, {(2, ")h(),,\"ej", 1)}, 4 &gt;&gt; 2)`.
Thanks for this; boss just suggested CppUnit and I hadn't heard of it. I'll be sure to rank it low on the options list.
yea "lol" I am just pointing out the Survey question could probably need some improvement if you need to google first to know what these terms mean. Do you want people selecting the "wrong" answer because they might be guessing what these terms mean? I mean not every teacher is from the US and familiar with these terms.
[removed]
I think what he means is "Catch2 benchmark", not "Catch2". Of course people use Catch2, but I also have never heard of Catch2 benchmark before. :-)
If you want to submit it as a link, people usually post a comment, and that usually gets upvoted most and is always/immediately visible at the top.
Not sure if this applies but a check for integers (or types) of the same size in for loops (and comparisons in general) would be handy. For example: uint64_t max{5000}; for (uint8_t i = 0; i&lt;max; ++i) { ... } That would loop forever since `i` would wrap at 255. If you use `auto` it also is not so obvious. uint64_t max{std::numeric_limits&lt;uint64_t&gt;::max()}; for (auto i=0u; i&lt;max; ++i) { ... } `i` is unsigned int which might be 32 bit and would possibly wrap before reaching max.
Web searching algorithms Specifically, ones including the query "stackoverflow" 
If they were in a code review, I'd reject. Then again, we haven't fully migrated to c++11 yet. Then again, lambdas are a terrible abortion of an idea that shouldn't exist outside of functional languages.
I am really surprised this wasnt done a long time ago 
I was suprised to find out it wasn't already a thing.
All programming languages have a philosophy which is embedded in the way you write programs. For example, the way in which you write programs using Python is very different to the way in which you write programs using C++. This isn't just at a syntax level: it permeates the semantics and the very way in which you design and think about building a program, which is what I'm referring to when I say 'the philosophy of engineering a program using `${LANGUAGE}`'. There are large sections of software engineering that are independent of a language's philosophy, for example, requirements analysis, test-driven development, teamwork, version control, and so on. I'm not referring to this sort of content (although PPP2 *does* try to cover at least some of that).
Where are you getting your definitions of a submodule? 
&gt; The problem is that there is no portable way to do what you described in a way that compiles on GCC, clang and MSVC, am I wrong? Given that most major game projects already need to compile on Clang-based platforms (one or several of PS4, Linux, MacOS, Android, iOS, Switch), it's not unreasonable to expect source code to compile cleanly with both a Clang-based preprocessor and your native compiler(s). The downside of course is double-parsing your code. That's not really the most major overhead in C++ compilation, but it's something to consider. Template-heavy pure C++ reflection systems however just impose a different kind of compilation burden, so you'd really have to measure a specific tool vs a specific C++ reflection library to really understand which is faster. &gt; It would be great to explain you what's exactly the purpose for which I developed this. Feel free to contact me if interested to contribute and improve EnTT. I'm happy to have a discussion on Reddit. It's hard to justify my time investment in private conversation; public conversations at least have potential value to others reading the thread so it doesn't feel like as much of a time loss. :) &gt; What I mean is that the way you described would be good to some extents if you're developing an engine (let me say) as a whole. It doesn't work well if you allow for plugins that introduce their own types, as an example. I don't think that's true at all. Plugins can expose generated code just as well as a core engine. If anything, relying on external code generation even makes some things like automating plugin interfaces a lot easier. The approach I'm talking about still lets you do the exact same things you're already doing, btw. You can generate the code that emits runtime data structures, potentially in a more static fashion; e.g. emit static readonly data structures (no runtime construction overhead adding seconds to game startup and no wasteful duplication of construction data vs runtime data) and then just link up the structures from plugins into the root runtime registry. I mean I guess what I'm saying is that the code generation approach is almost completely positives over the in-C++ approach, save naturally the complexity of the build system additions. Which is why I'm bummed there isn't a nice open solution out there with existing integration support for popular build systems.
Start with the rules for the subreddit. 
Real C++ Programmers like living on the Edge. Just press the button and give yourself a Thumbs Up! ;-)
Read the [*C++ Core Guidelines*](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md).
If by 'break' you mean 'force you to fix the errors that were generated whenever you tried to build under clang', then sure. 
Just out of curiosity, have you some links to commercial solutions along this path (for I got that you don't know of open ones)?
&gt; Although it doesn't say why I believe predicates in programming must be [limited to return bool](http://guyhaas.com/bfoit/itp/Predicates.html). &amp;#x200B;
People from a computer science background also don't study it in-depth. Back in the day (studying computer science at university, 28 years ago) I learned C++ as an add-on to a computer graphics course; the teacher was annoyed that we didn't know C++ and spent all of half an hour explaining it to us. That's pretty much the entire depth and width of what we learned, other than through self-study. Generally languages were treated as an irrelevant detail, secondary to the much higher goals of math and algorithms. "It's not a programming course, so there is no need to learn this stuff" was something that was frequently heard. If you already have some actual experience with the language, and are willing to learn some more, you'll be fine. Advise... Stick with the more modern parts of the language, apply RAII for all resource management, and don't invent your own thing when there is already an STL thing for it. Dogma is only good until it isn't. Understand O-notation - both what it means and what it doesn't mean. Measure, instead of guessing about performance. And keep things as simple as you can, the guy trying to understand your code next might very well be you. 
That's horrifyingly bad advice. Lambdas are an excellent tool; they markedly improve code in numerous situations. What is it with people trying to improve C++ by leaving significant parts out? What imagined problem do you think you are avoiding here, exactly? 
Do you know if VSCppUnit is more or less the same? 
Project is continuously being built by clang, g++ and VS. Last 4 updates broke the build. So no, that's not what I meant.
Thank you, that helped. I think.
I've found this in the open issues list: https://cplusplus.github.io/LWG/issue3031 &gt; Algorithms and predicates with non-const reference arguments Proposed wording is: &gt; The function object pred shall not apply any non-constant function through the dereferenced iterator. **Given a glvalue u of type (possibly const) T that designates the same object as *first, pred(u) shall be a valid expression that is equal to pred(*first)**.
No, never heard of it actually.
I know a lot of this is personal preference and subjective, but I really think tests being "sibling files" - i.e., `src/my_library/foo.cpp` with `src/my_library/foo_test.cpp` is a bad idea, beyond really simple projects. Sibling subdirectories is a lot cleaner (i.e., `src/my_library/test/...`), imo. When you have a bigger project and start writing lots of tests you also start creating common test helper utilities in separate source files, along with plenty of header files, files that just have test injection values, input files, etc. Some of these you'll put in a common test directory somewhere, as a test library; some of these though, belong with the specific tests that test a specific executable or library. So to intermix those with the "real" source code files becomes messy. For example when you grep/search your entire project for things, you want to be able to discern which results are in test files and which not, at a glance. Or give grep a pattern to exclude them. So then you'd end up putting "test" as a prefix or suffix to every test-related filename. But just like C/C++ names, the common prefix/suffix is just an indication that you should have "namespaced" them to begin with - i.e., put them in separate directories. Doing so also helps if you ever write scripts later on to execute tests in various conditions (e.g., with/without valgrind). If your build directory structure mimics your source directory structure, then when the test executables are in "../test/" subdirs, the script can not only easily find them, but also any meta-data files you might need for the script. For example you might have meta-data files that indicate whether valgrind can be run with a given test or not, or whether it needs to be run as root, or should be skipped on certain platforms, etc.
Some of us are still stuck with C++03 compilers :-)
[Check here](https://api.csswg.org/bikeshed/?force=1&amp;url=https://raw.githubusercontent.com/vector-of-bool/pitchfork/spec/data/spec.bs#into.bg.pkg), and also [here](https://api.csswg.org/bikeshed/?force=1&amp;url=https://raw.githubusercontent.com/vector-of-bool/pitchfork/spec/data/spec.bs#submod). I refer to "submodule" in the context of the pitchfork document, where it is explicitly defined.
I'm not sure about the relationship between VSCppUnit and CppUnit, but if VSCppUnit is the framework bundled with Visual Studio and the default used by the Native Unit Testing project template, then I would strongly recommend not using it. We have been using it at work and compared to more modern frameworks (such as Google Test or Catch) it is a very painful experience. For one thing, everything you use in an `Assert::AreEqual` has to have an overload of their `ToString` function defined. This gets old pretty fast. Another annoying thing about the `AreEqual`function template is that both arguments have to be exactly the same type. Anyway, it's annoying and discourages one from writing unit tests. Visual Studio 2017 comes with adapters and project templates for Google Test and Boost Test, both of which are much better choices, in my opinion.
Other suggestions are great. I'd make a nice command-line application while following 'good practices'. A to-do list app is always a good place to start (gets UI + saving state at the least).
All of the lookup tables I'm using so far (for Ryu, and my additional code for `chars_format::fixed`) occupy 11 KB of constant data in the executable image, which I view as a fair expense for to_chars' blazing speed. I am keeping an eye on the tables, though; I want to use more for `chars_format::fixed` but I wouldn't add something like 500 KB for it.
I always update asap. It's like injecting a vaccine in my code: it's robust sooner (after I work around potential bugs).
Just wanted to say thank you for your thoughtful blog post and the proposal. There is nothing I dislike in the last in the hypothetical layout for Clang tools! &amp;#x200B; Well, maybe one thing, but it was not in the hypothetical layout: I'm not sure if I prefer the top-level test directory to be \`tests\`, versus \`test\`. \`src\`, \`app\` and \`third\_party\` aren't pluralized, even though there can be multiple of them. &amp;#x200B; Same thing for the documentation directory, which we can sometime find in a project. Is it \`doc\` or \`docs\` (or something else)? &amp;#x200B; I would be interested to see what comes up with one or multiple language bindings (e.g. python, python + go). And how to organize generated code, like protobuf, flatbuffers, ... &amp;#x200B; I just read the blog post, and will take a look at the proposal now, so sorry if I spoke too soon.
I find most of their technologies very helpful. My background is also Physics, and I did my PhD analysis based on Protobuf - very quick and easy to use technology. Btw, I forgot to mention in the list tools. Learn how to: - build: cmake, bazel (by Google - very good one) - VCS: git - shell: sh(1) for scripting, zsh/tcsh for interactive work - tmux - /bin and /usr/bin utils, e.g coreutils - CI like Travis
11kb already feels very bloaty to me... How much does the current algo takeup?
Add Catch to your list of possibilities. I recently did a pretty thorough comparison of all of the big frameworks (Catch, gtest, boost.test, CppUnit, CxxTest) and Catch was my favorite by a significant margin. It lacks a couple of advanced features from the bigger libraries, but it is also a *lot* easier to use (in my opinion). 
Interesting point, where to put test data when using a merged layout for tests?
Run away from your boss. /s
The 11 KB cost is paid only when someone includes charconv and calls the shortest round-trip overloads (otherwise the tables will be discarded as unused). The cost is unnecessary if someone specifically needs only `chars_format::hex` shortest round-trip (not yet implemented), which I can live with. In exchange, the runtime performance is 9.6x to 12.6x faster for floats and 24.9x to 36.6x faster for doubles (depending on compiler and architecture) compared to CRT `%.8e` `%.16e` round-tripping, over 3x faster than double-conversion Grisu3, and 70-90% faster than `dtoa_milo()`'s Grisu2 implementation (which is mathematically inaccurate). Having been a Standard Library maintainer for over 11 years, I not only think that this tradeoff is worth it, I would give my right eye for those performance numbers. Other Standard Library maintainers may choose differently; I look forward to their charconv implementations. I'm not sure what you mean by "current algo", since `to_chars()` is shipping for the first time in VS 2017 15.9 and there is no previous implementation. I am not sure how the compiled code+data size of Dragon4/Burger-Dybvig, Grisu3 + some fallback, or Errol would compare. (Our CRT uses modified Burger-Dybvig but the code size can't be examined in isolation and it differs dramatically from what to_chars shortest round-trip needs to do.)
Thanks. I'll trust your competent judgements then. :)
It's easier to make sure there are unit tests and get the renaming correct if the tests live with the code. Tests off in a different directory are, admittedly incrementally, harder to keep in sync. Mocks are an interesting question. I prefer that the mock be paired with the interface that it's mocking. There should be one of them, kept in sync with the interface. However, it's in a separate physical library so as not to have a false dependency on, e.g. gmock, in the main library. This is particularly important when you're distributing your interface to other teams. They shouldn't have to maintain their own mocks. 
:-) This is also why I chose to ship charconv in header-only form instead of compiled into our DLL. Within a DLL, everyone pays the cost even if they don't use it; header-only code means you don't pay for what you don't use.
I've been looking at gtest, boost, cppunit and a little bit of catch.
It's the integrated c++ test framework in vs. 
\`src/my\_lib/foo.{cpp,h,t.cpp}\` scales to thousands of files via existence proof. See for example: [https://github.com/bloomberg/bde](https://github.com/bloomberg/bde) , e.g. [https://github.com/bloomberg/bde/tree/master/groups/bal/ball](https://github.com/bloomberg/bde/tree/master/groups/bal/ball) If you have test infrastructure that is shared, you have new components that need to be tested, too. Yes, those get their own libraries. Sibling files work well for unit tests, not integration tests, and certainly not where you have to have a lot of infrastructure to run the tests. Those should go elsewhere. 
I'm from the US and I know the different terminologies used in other foreign countries for various topics. Whenever I come across something I'm not familiar with or know, I end up googling it. Which I heavily recommend for majority of people that don't know what something is.
Thanks for this series. I've been searching for a good GUI toolkit for a while, have been using QtCreator for non-GUI projects a few months to get used to it and quite like it ... hoping to make the leap into GUI code soon :) I always used to use Embarcadero but they're always behind the 8-ball on compiler support, plus expensive. 
I concur your advice is terrible. Structuring code with facilities provided in std::algorithm decouples the mechanics of what the code does from the backing data structure and provides superior semantics. Often lambdas used in this fashion have no performance penalties, and makes std::algorithm much easier to use. 
Thanks for making this! Having only really learned C++ after 11 came out, `new`ing up raw pointers that are cleaned up by parent QObjects makes me a bit squeamish. I had to diagnose memory leaks in a Qt application a while back, and being unable to implicitly trust any `new` has made me weary. I would like to make "this pointer is owned by another QObject" more explicit, but I'm not sure if the actual solution is "just get over it and be responsible going forward". What are your thoughts?
I wish QT would add a template make_qobject member function and put it in QObject. This template would be a glorified wrapper around ‘new’ similar to std::make_unique, except it would pass ‘this’ as the first parameter to the target objects constructor. Assume MyType with constructor that take ptr to parent and an int, and local scope ptr to qobject ‘parent’. Ex: auto myobj = parent-&gt;make_qobject&lt;MyType&gt;(42); 
The 15.8.x series has given me a lot of grief too. Much more than previous rounds.
Interesting question. Also does anyone know who the tallest midget in the world is?
I don't know of any off-the-shelf commercial solutions, no. So far as engine, Unreal has a very rudimentary version of the idea in their UPROPERTY system, but it's not quite the same thing. I'm led to believe that Valve uses such tech in their newer work, but I don't know any real details or have any real confirmation of what exactly they have. We had a prototype at WGS some years back but nothing that ever went into production; we ended up keeping our runtime reflection system due to the sheer amount of existing code we had built around it and some of the political concerns in making such fundamental changes to a cross-studio shared code base. :) I do know a few different proprietary engines that in some capacity do the opposite of what I'm talking about: primarily authoring IDL files that then generate C++ types (in addition to everything else), rather than authoring C++ that generates IDLs (and then generating everything else). Those even stretch into the realm of protobuf and the like. You could consider things like swig a version of what I'm talking about. If you use the XML swig target, you've basically got a (terrible) IDL. You'd then have to write your tools that consume the XML for further code generation. Swig has its own bespoke C++ parser though that I wouldn't inflict on anyone these days if I could avoid it. :) Outside of games, there's various serialization toolkits in C# and similar languages that do kinda what I'm talking about, but mostly by parsing things like .NET assemblies to generate intermediate IDLs. It was even one of the potential selling points of Gaby's original C++ modules proposal and the IFC file format: tools could consume the IFC files much more easily than raw C++ source for the purposes of analysis and code generation.
Why would you use something else than 4 though? If you start doing dynamic dispatch on your deleter, you're probably asking for trouble. You are most likely better off using a virtual destructor in your object. The only times I wanted a custom deleter was to free structs returned by a C library.
It would be relevant if compilers actually cared about strict aliasing violations /s 
First off you are a fresh graduate. Are you working? Experience is important for getting a job like that. Secondly c++. C++ is a major language for robotics and is pretty important for ml. I haven't heard much of rust in ml. And there is honestly no promises that rust will get big. C++ is the way to go hands down
To me it makes since to learn C++. It’s the language used in the field your interested in. I’m not familiar with any self driving companies using Rust (not to say there aren’t any). Should the industry shift and move to Rust, it isn’t drastically different from C++. Making the transition to Rust less painful. 
If you're interested in machine learning and image analysis, your focus should be on acquiring the prerequisite mathematics and statistics to do that. The amount of effort you spend learning a language is nothing compared to the difficulty of the problems you are wanting to solve. That said, I work in advanced algorithm development and machine learning, and i use almost entirely cpp.
Taleo is such a pain to apply to, i'm not even going to bother. Send me an email and I'll send you my resume.
You're in a cpp subreddit and you're asking whether or not to learn C++ for ML/Robotics? And of course the responses here would be biased; everyone will say that you learn use C++ for ML/Robotics. And they'd be right.
I'll be the outlier here. If you have the time and the chops for it, Rust. Rust because it incorporates the same concepts as modern C++, and Rust enforces good behavior. It's a harder language than modern C++, but it will make learning modern C++ not only easy, but it will make you an exceptional dev too.
This title is somewhat easily confused with Clang's libTooling, which is what I was hoping for (that's honestly the remaining reason I'm disappointed MS decide to rejuvenate their existing C++ front-end instead of adopting Clang; even if VC grows a plugin architecture, it'll be Yet Another Interface(tm)).
\+1 for catch. Incredibly easy to learn, integrate, and use.
Nice, thanks for the details! Is a similar mechanism used to automatically disconnect slots/signals when a QObject is destroyed?
Mmmm... no? What do you think should be swapped?
boost test has good plugin support in VS. and it is portable.i dont know whether vscppunit is portable.
Yeah, C++ would be the way to world. Thanks for the advice!
Yeah they're right! Actually I cross posted this on r/rust (and others) to avoid bias. Thanks for the reply!
Yeah I completely agree with you. If it ever comes the AGV companies shifting towards rust, It'll give enough time for devs like us to learn rust in that time. Thanks for the suggestion! I appreciate it!
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9h0enb/c_or_rust_for_mlrobotics/e68ptlf/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It would be safer to call setParent since some subtypes can ignore the parent argument in their ctor
At work, we have been stuck at C++11 for a long time, so `boost::make_unique` is probably the most common thing I use from boost. I've also started using boost::adaptors::indirect a lot when looping over collections of pointers.
&gt; for example, cases where seekg(0) would not reset the streambuf position even when the current offset was nonzero. wtf!
&gt; Overhauled std::ws to Do What The Standard Says. And what has been std::ws doing before?
It was fixed in 15.8.0. Shortest round-trip decimal to_chars() will be in 15.9, I checked it in just before the feature-complete lockdown. It’s the first charconv implementation powered by Ulf Adams’ new Ryu algorithm and it is ridiculously fast: I’ve measured it as 9.6x to 12.6x faster for floats and 24.9x to 36.6x faster for doubles (depending on compiler and architecture) compared to CRT `%.8e` `%.16e` round-tripping. (It’s also roughly 3x faster than double-conversion and 70-90% faster than dtoa_milo if you’ve seen those.) chars_format::fixed has decent perf in 15.9, better in 16.0 and possibly even more in the future. Shortest hex and precision decimal/hex remain to be implemented; I’ll work on them after CppCon. Each of these chunks has taken multiple months but I hope you’re pleased with the results. 😸
One major use is callbacks. Instead of passing a function pointer and some kind of `void*` to keep track of relevant parameters, just pass a lambda. There's no need to define a function or function object far away from where it is used, the scope is generally much more pleasant (it can precisely capture what it needs instead of relying on that `void*`, and it does away with the ugly cast you'd need to get your parameters back. Another is passing tasks to other threads. I'm using a messaging system where instead of a message ID and some parameters, actually you just pass a lambda which gets stored in an std::function and which performs the task on the context of the other thread. It avoids having to create a whole range of single-use message classes somewhere away from the call site. Another is generating complex initialisation values: `const auto Foo = [] {...} ();`, where Foo might rely on various other local variables. Another is defining tiny inline functions that make little sense as full-fledged member functions, where you would otherwise use a macro to expand source. Really, there are plenty of reasons to use lambdas: they generally bring code closer to where it is used, and get rid of endless single-use objects littering your code and nasty casts in callbacks. As for it not matching the precise mathematical definition, assuming we even have one, I wouldn't get too hung up on that. Lambdas are a programming construct, not a math construct, and they are what the standard says they are. 
Awesome! Switching to `from_chars` in my project made loading point clouds from giant text files several times faster versus naive iostream usage. I'm sure it's been said before, but I think there's a reason your initials are STL! 😃
Oh sorry, I didn't mean to imply that the library be made unavailable, but I believe it would make sense to have Boost versioned along with the standard: Boost 11, Boost 14, Boost 17, etc. where Boost features that made it into the standard are simultaneously removed from Boost itself. Or maybe only for major updates. That would leave us with Boost and Boost 11, at this time. 
\*whooosh\* I completely understood the article from the first reading, thank you very much. The idea is that the machine.-endianess does not matter - the data endianess does, when you build the integer type from byte-sized packets. That fact is well understood since 1980's by me when I started coding for 8 bit micrcocomputers. On the latest versions of clang and gcc, of course, you can rely on the byte serialization to compile into the expected instructions. Code written before these compilers recognized this idiom should not be written again just to comply with this dogma because the code is still doing the right thing (compile into efficient instructions). The rewrite would only have possible adverse side-effect of generating sub-standard output when the compiler is the wrong one. At least the code will be correct so that's a bonus. Please do explain this me one more time if I missed something obvious.
c++ needs an std::observable&lt;T&gt; class, with specialization for single values and for std containers. Observable classes are the basis for implementing so many things, from model-view patterns to event-oriented (aka data-flow) solutions...
&gt;Implemented a fast path for binary I/O in iostreams, **quadrupling** bulk I/O performance. Wow ! Just wow :)
Similar here, stuck on an earlier version so we're using the counterparts from `boost`. We're also using `boost::optional` with references, so can't easily replace it with `std::optional` in the future :/.
Yay! I’m glad it helped your code. Note that if your text files don’t need to be especially human-readable, reading hexfloats with from_chars should be even faster. (You can use sprintf to emit hexfloats before I ship that in charconv.)
Qt is a framework with multiple libraries implementing different methods to draw an UI - a traditional one with QtWidgets, and a scenegraph one with QtQuick. More options are always better.
I might be wrong here, but it seems to be a library and API that's aimed for developers who are familiar with Qt Widgets and not Qt Quick/QML. The API resembles the Qt Widget API but sits on top of the Qt Quicks modules and its graphic stack. No need to include the Qt Widgets module then...
There are two editions of CppUnit in fact. The older one is indeed terrible, run away. The newer one is not source compatible with the old, and is markedly better than the original. Still, there are far better alternatives to either. CATCH is a very solid choice. Boost.Test has become usable since its big refactor a few years ago. Google Test remains popular, but I find it clunky. (I have to admit I switched to my own ultra light weight unit test suite a few years ago, and I haven't looked back. It provides the most used part of the Boost.Test API, but without any Boost.Test. Plus it works well with exceptions globally disabled, and with multiple threads without synchronising, and it spits out JUnit XML, and does all that within 600 lines of code in a single header file. I can't see myself leaving it any time soon to be honest. https://github.com/ned14/quickcpplib/blob/efc6c12dca3b8f2210d741a985a53b162383dfdf/include/boost/test/unit_test.hpp)
The following 3 parts are about using AST Matchers and FixIts (both part of LibTooling) to create a clang-tidy extension. This post is called 'part zero' because code which has never been built with clang needs to be updated at least do that before you start (part 1). The following three parts assume your code builds with Clang and shows how to use LibTooling. So, if I've understood that part of your post, you will be more interested in the follow-up posts.
Do you absolutely *have* to require clang 7? I'm sure I speak for many when I say that since clang 6, you usually get working Windows binaries now, and I'd like to keep my CI test jobs on as old a clang as possible for as long as possible. But also whilst upgrading VS, because it's the limiting factor for what C++ I can use. In other words, you have always had an amazing STL far sooner than the other STLs. I'd like to stick with older STL versions, but want to iterate the MSVC compiler as quickly as possible, but also keep with as old a winclang as possible. Does that make sense?
@stl Out of interest, how might this fast path affect randomly seeked i/o on iostreams?
&gt;Fixed C++17 std::filesystem‘s support .obj containing a __declspec(dllexport), causing unusual conditions like .exes with export tables. Well _that_ might explain why my current project was building an export lib for my exe. Seems to have stopped now.
would be great to see those perf tests :)
You haven't heard about the `sahred_ptr`? 
&gt;By early 2012, every C++ developer quickly read up on these new smart pointers and understood their importance and their usecases. This was swiftly followed a by massive refactoring of most open source C++ libraries and projects to nullify the use of raw pointers. Private companies, personal codebases and teaching material soon followed suit. Is this satire?
I'd guess `Guard` controls which row is selected.
`std::optional&lt;std::reference_wrapper&lt;T&gt;&gt;`
Code typo: in `std::string&amp; operator=(std::string&amp;&amp; o)` you `return this` instead of `*this`. 
&gt;std::map &gt;data-driven Pick one.
And also a !&amp; operator:- (a &lt; b) &lt;=&gt; (a &lt; b) (a &gt; b) &lt;=&gt; (b &lt; a) (a &lt;= b) &lt;=&gt; !&amp;(b &lt; a) (a &gt;= b) &lt;=&gt; !&amp;(a &lt; b) (a == b) &lt;=&gt; !&amp;(!&amp;(a &lt; b) !&amp; !&amp;(b &lt; a)) (a != b) &lt;=&gt; !&amp;(a &lt; b) !&amp; !&amp;(b &lt; a) 
Yeah, before Is started this library, I chatted with Wes and looked at Arrow. My understanding of Arrow is that it is designed to be the "under-the-hood" for Pandas. It is not a coherent and well interfaced C++ library. Its main target is Python not C++, although it has multi-language features. My intentions were to build a self-contained and well-interfaced heterogeneous container with data frame functionalities in C++ for C++ 
If your willing to pay for a subscription service I highly recommend www.safaribooksonline.com/ That book and hundreds more on C++ are available. There is a free trial so you can take a look at the full book and others. 
maybe this? https://godbolt.org/z/gfvPlH
How does the look up happen, though? Where the execution code is stored is less important imo. 
I would actually prefer the map way - but consider that for integers switch can be much faster, depending on the concrete data.
The to-be-switched value is the index into an array of code-pointers. Compiler are quiet creative here and will range-shift your values and/or generate multiple layers of indexes.
I was thinking `T*`, but I have noticed avoiding raw pointers seems to be some kind of holy grail these days.
To be honest this is optional reference though in it's simplest form.
For some reason nobody seems to have mentioned that `std::map` *allocates memory*, in fact, lots and lots of small blocks. Approx O(log N) of them for bookkeeping the underlying red-black tree. And then each lookup involves dereferencing O(log N) pointers to non-adjunct allocated blocks i.e. highly non-deterministic unless your entire RB tree is in L1 cache. Meanwhile, a switch statement allocates no memory at all, and the compiler will choose some implementation algorithm which makes it as fast as possible. The CPU will speculatively execute that algorithm, ensuring determinism most of the time. So use switch statements wherever possible (or even a long sequence of if else statements, the compiler doesn't care). If you're using maps, you probably should be using unordered maps, except where either (a) the sorting is important or (b) the data selecting the key might come from an untrustworthy source. And we so very much need a constexpr hash table into Boost, or better, the standard, already. At least one Boost GSoC has made such a thing. Just need it into Boost, or the standard. 
Fizzbuzz
Assuming your lambdas have no captures (otherwise I don't think you can even store them in a map in the first place). Here are pros and cons that I was able to come up with. Might be wrong on some of them, so any corrections are welcome. What *you* need to do is decide which of these pros and cons are relevant to your use-case and pick accordingly. --- `switch` statement: + O(1) lookup guaranteed^* + does not touch heap – not modifiable during runtime – not extensible during runtime – can only have a type implicitly convertible to an integral primitive as "key" --- If your keys are sequential from 0 to some N-1, consider using `std::array&lt;std::function, N&gt;` instead of `switch`-`case`. That's usually the preferred way. For enums with no initializers that means adding an extra member named `Count`, `Last` or `End`. `std::array` has all the pros of `switch`, plus better readability (imo) and ability to modify its elements during runtime. `std::array`: + O(1) lookup guaranteed^* + does not touch heap + modifiable during runtime – not extensible during runtime – requires sequential keys – can only have a type implicitly convertible to an integral primitive as "key" --- Any map: + dynamically extensible and modifiable + can have a custom type as key – allocates on heap^* `std::map`: – O(log n) lookup guaranteed^* – requires a comparer for custom types `std::unordered_map`: + O(1) lookup on average^** – O(n) lookup in worst case – requires a hasher for custom types --- ^(* I think) ^(** Note that this involves calculating hash of your key, so it's still slower than `switch` or `std::array`)
Easier to write https://godbolt.org/z/wLZoTq
\&gt; And we so very much need a constexpr hash table into Boost, or better, the standard, already. At least one Boost GSoC has made such a thing. Just need it into Boost, or the standard. &amp;#x200B; It sounds like you have a few in mind, but for those who don't, this is a nice header-only implementation with CMake support. [https://github.com/serge-sans-paille/frozen](https://github.com/serge-sans-paille/frozen)
&gt; Approx O(log N) of them for bookkeeping the underlying red-black tree. I'd say it allocates *exactly* N nodes ;)
As a beginner, I have a question. When you use signal and slots in Qt, is it possible to use smart pointers (like unique_ptr) or one does still have to use raw pointers and then use QObject::deleteLater() when the slot is called?
**Company:** [Terma BV](https://www.epos.dk/REK/Terma/Joblist/ShowJobOffer.aspx?dbalias=EposREC_Terma&amp;lang=en&amp;jobOfferEntityId=1348&amp;joblistId=1) **Type:** Full time **Description:** We are looking for a Software Developer working on Satellite Command and Control System related products and projects in our office in Leiden, The Netherlands. These systems cover a wide range of software engineering: data communications (space specific protocols as well as TCP/IP and the like), real time/near real time systems, data processing, MMI development, data bases, etc. Applicants shall have a university degree, ideally in Computer Science or other relevant disciplines. Mandatory skills: * Broad Knowledge of C++ and object oriented programming * Knowledge of scripting languages (ideally tcl/tk) * A disciplined approach to software development, knowledge of software standards (e.g. ECSS) Desirable Skills: * Extensive knowledge of the different aspects of QT5 * Knowledge of modeling technics using UML, Enterprise Architect * Knowledge of Java and related development tools We would also consider candidates lacking a formal degree providing they have very convincing relevant experience. Experience working in an international environment is desirable. The working language is English. **Location:** Leiden, the Netherlands. **Remote:** no **Visa Sponsorship:** yes **Technologies:** C++11, Qt5, MySQL, PostgreSQL, TCP/IP, MIL1553, SpaceWire. **Contact:** Please contact us via the button at the bottom of the [linked page](https://www.epos.dk/REK/Terma/Joblist/ShowJobOffer.aspx?dbalias=EposREC_Terma&amp;lang=en&amp;jobOfferEntityId=1348&amp;joblistId=1).
Thanks, I always forget inline initialization. I also ran a simple quick-bench but the results were indeed a clear win by switch. However it doesn't have to be that way. In this case the full map is known at compile time so it should be possible to fully unroll it. This might be a use case for a constexpr map type :)
I am unaware of any specific space complexity guarantees required by the standard for `std::map`. The standard simply guarantees O(N log N) complexity for creating a N sized map, and that's it. So you need to assume the worst when using `std::map`. I do remember once seeing a `std::map` implementation which used a generic system-provided RB tree API internally. It always allocated exactly O(log N) bookkeeping nodes for N objects in the map, because the bookkeeping nodes couldn't store data, they simply acted as chains to the leaf objects.
Yea I think that requires heap allocation ellision
&gt; O(log N) This is not enough. Any binary tree must have N non-leaf nodes. 
Another, Ranges based design, is https://github.com/BoostGSoC17/static-views
Depends again on implementation. A common technique is to fold an object storage into its binary node. This lets you reduce the number of nodes allocated to exactly N, but at the cost of extra complexity during rebalancing etc.
Can you elaborate on that? The number of pairs is known at compile time. Both keys and value are also known at compile time, so why should we still require heap allocation?
Columns are messed up (shifted by one?)
That time I used boost.crc (who else here used boost.crc?) as a semantic action in spirit to fail the parse in case of mismatch (that device used non-standard crc on some of its message types) Also wrapping Linux's inotify in boost.asio was memorable, I bet I won't be able to do that with networking TS.
Yup. We have some boost::optional&lt;T&amp;&gt; in our code as well and are looking into upgrading to C++17. To be able to replace boost::optional with std::optional completely, we have decided to go the `T*` route. And boy has it caused some lively discussions...
[A Tour of C++](https://www.amazon.com/Tour-2nd-Depth-Bjarne-Stroustrup/dp/0134997832/)
sent you a PM
[https://cristianadam.eu/20160410/c-plus-plus-i-slash-o-benchmark/](https://cristianadam.eu/20160410/c-plus-plus-i-slash-o-benchmark/) &amp;#x200B;
Because of how `std::map` is implemented. I don't think it'll be possible for `std::map` to do this any time soon. Luckily, there are [some alternatives](https://github.com/serge-sans-paille/frozen).
Ahh interesting, it works on old reddit but is broken on new reddit. New reddit doesn't like it when the first cell is blank. Should be fixed now.
Apparently new reddit doesn't like it when the first cell is blank, but old reddit handles it fine. Should be fixed now.
No one mention this one -&gt; [https://github.com/onqtam/doctest](https://github.com/onqtam/doctest) ? For me it's the best alternative at the moment.
Hi, you can send me your resume at [rbendroth@veeder.com](mailto:rbendroth@veeder.com) and I can forward it to the hiring manager. If we would like to move forward with you, I will need you to apply in Taleo. Thanks! 
How should you perform dynamic polymorphism using smart pointers if you have an abstract parent class? Has this model changed since the introduction of c++11?
The core question is what's their purpose but I can't think of any simpler optional reference replacement than simply a pointer. Should be OK if that pointer is not an owner.
&gt; Luckily, there are some alternatives. Great stuff! I even appreciate the naming pun :)
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Mhm that's like saying "compilers have bugs, don't trust compilers". 
In exhibit 3... giving out a weak ptr as "you don't own it" doesn't help much if the caller turns it into shared - and keeps that, perhaps unintentionally. But good article!
This is my worst fear about shared_ptr. "Here's a weak_ptr for you so you can detect if I have deleted it." "Nice, now I also own your internal stuff lol."
The reason `this` is a pointer but not a reference is that `this` was added to the language before references. C++ guuarantees that always `this != nullptr`.
Built in or user types? So those subtypes are broken?
A small tip - you can use [std::exchange](https://en.cppreference.com/w/cpp/utility/exchange) in the move functions to make things a little cleaner. `data_ = o.data_; // data_ is a char*` `o.data_ = nullptr;` becomes `data_ = std::exchange(o.data_, nullptr);`
Networking TS is based on asio. In fact, Chris Kohloff the author of boost asio maintains a networking ts implementation which is automatically generated from asio [https://github.com/chriskohlhoff/networking-ts-impl](https://github.com/chriskohlhoff/networking-ts-impl) If you find that there is something that you can do in asio, that you cannot do in the networking TS, please make some noise, as the C++ community needs to know that before Networking TS becomes part of the C++ Standard proper.
Maybe clang can't determine that sin returns the same value both times. I mean, theoretically, "sin" could be a random number generator, as far as the compiler is concerned. 
Is that the benchmark code the article refers to, or what does this two year old benchmark have top do with the latest improvements in VS 2017.8 ?
This is a great time to be a C++ developer. We got 3 free, high quality implementation of the C++ compiler and standard library. I think that there is a very good chance that on the day C++20 is approved, all the language and library features will be available from GCC, Clang, and MSVC.
they know what std::sin is, your compiler will be happy to replace `printf("test\n");` with ˋputs("test");`
This was /u/BillyONeal’s fix.
Removed as off-topic; simply being written in C++ doesn’t prompt useful discussion.
Are you considering the third to be msvc? I was under the impression it is still far behind clang and gcc regarding bugs. 
Will Clang 7 work for VS2015, or does it have to be v6?
Someone would say that lack of "standard compiler" is one of the main problem in C++ world. It's not like Python world. Just an observation on perception of C++ today.
No, std::sin must conform to the spec. 
Love these kinds of posts so thanks! The problem I've found with non-intrusive systems is there's no way to query the type or the actual properties present given a pointer to a base type.
You dramatically overestimate the understanding a compiler has about standard library types. What it sees are a lot of dynamic allocations, pointer chasing
They're the only ones with a parallel algorithms.
Not an unfair point, but a bad example; there is a distinction between Python (the language) and CPython (the reference implementation). Writing to the quirks of CPython is no more correct than writing to the quirks of gcc or msvc - look at some of the things the PyPy team had to do to make it work in the real world.
[This proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0847r0.html) might incidentally give you a reference that you could return.
Thats not really the thing I prioritize highest. 
Sorry I phrased myself poorly. It was early in the morning. What I'm saying is that MSVC gets eagerly upgraded. Winclang does not. Unlike with MSVC, newer clangs are usually not needed with newer STLs. I'm not saying please never break older clangs. Rather I'm asking please don't not support older clangs without good reason e.g. they're broken. Does that make more sense?
I’m not seeing much in the way of C++ improvements in 7. Anyone find a c++ list of improvements? Their release notes don’t seem to have anything. 
I think what's going on is that Clang does not know that `std::sin` does not modify global state. To Clang, it's a function like any other, with arbitrary behavior. To test this, I declared that function as (instead of including `&lt;cmath&gt;` -- don't do this, it's just a test): namespace std { [[gnu::pure]] float sin(float); } This is a GNU attribute that marks a function as pure, which tells the compiler that it's not necessary to call the function twice with the same parameters. Adding that, your code compiles as you expected. So how do MSVC and GCC optimize this? At least for GCC, it actually uses [a built-in `sin` function](https://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html). That way, it knows lots of special information about how these functions behave, including their "pureness." I don't know why Clang doesn't have similar built-in functions, or why `sin` doesn't have that attribute in the standard library. You'd have to ask a Clang developer. As a workaround, you could write a function to wrap `sin` and apply that attribute.
std::sin can't mark be marked as pure because it \_does\_ modify global state (namely, the error status).
Looking at [https://clang.llvm.org/cxx\_status.html](https://clang.llvm.org/cxx_status.html) It seems that Clang 7 only implemented a DR with respect to CTAD
In general you can always use newer Clangs (even when the version check is present, it rejects only too-old compilers). Whether Clang 7 accepts VS 2015’s STL is up to the Clang devs; we’ve fixed various conformance issues in the STL over the years but can’t go back in time. (Around 2015.1 we were testing with Clang/C2; I switched over to testing Clang/LLVM later but can’t remember exactly when.) I strongly recommend upgrading to VS 2017 which is binary-compatible with VS 2015.
Not at all! They are not ABI compatible! You cannot even pass a string across from code built using clang to code built using gcc... It's so sad. 
Yeah, here I am in 2018 throwing raw pointers left and right.
Lack of "standard compiler" is one of the greatest features of C++.
What is winclang? Is that just Clang targeting Windows? Such releases are always available for the latest version. Newer Clangs are absolutely needed with newer STLs for the same reason as C1XX. The reason to increase the version is that we need features and fixes present in the latest Clang (Clang 7 supports shiftright128 for charconv). There’s an escape hatch, but then you can’t complain if things don’t work in an untested scenario.
It seems like if many std functions are not builtin or tagged appropriately, clang will miss out on a lot of optimization opportunity. Is this statement totally off base?
I am aware of why it is a pointer. I can still wish that it wouldn't be.
This is not a bug-tracker (though it sometimes may function as one). IMHO, this is much more suited to be a proper bug report (have you created one?) rather than a thread on subreddit.
&gt; I was under the impression it is still far behind clang and gcc regarding bugs. Regarding bugs, probably, but regarding language/lib support they've caught up or even overtook the competition.
You can, and I do frequently. It's libstdc++ and libc++that are not ABI compatible, which is why clang++ on Linux usually defaults to using libstdc++ as far as I'm aware. 
Unfortunately, some dependencies come as binary and I cannot rebuild to link with libsdtc++. Basically, I'd have to go all the way and rebuild everything to switch to the same std Lib implementation. 
The first and for a while the only to support the modules and coroutines TSs as well. (Maybe others.)