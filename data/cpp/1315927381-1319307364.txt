* full use of smart pointers. * full use of STL containers. * object oriented when required, simple functions otherwise. * no preprocessor macros, unless absolutely necessary.
Shared pointers were probably the biggest change for me. Not only did they make things easier, they forced me to think more seriously about object ownership, which helps to improve the overall design of whatever I'm coding.
Pretty much every time I have a lambda longer than a line or 2, I assign it to a named variable. It pretty much just acts like a function at that point, but since you can declare it inline I think they are usually pretty readable. Just have to be super careful with how you capture variables - I really hate that part about lambdas.
Except the problem of too many layers of abstraction!
[Aggregation instead of inheritance](http://cowboyprogramming.com/2007/01/05/evolve-your-heirachy/)
I wonder what *other* mathematically obfuscating techniques can be implemented in common programming structures? You know, like loop incrementation with weird-ass changes within the loop? Perhaps depending on pseudo random numbers to increment the loop? =D Or conditional logic using dodgy half-processed logic states (maybe grey code) for complicated comparisons... Using single letter function names, and things like that is just so old fashioned!
Are you sure? I keep seeing people try ... 
You see people fuming in traffic honk their horns at everyone else. Doesn't mean traffic gets any better.
Short answer: With caution. :)
Interesting. What follows is a few comments from a casual programmer, one that often reaches for Python first. It is interesting that you discount the STL and it's containers. STL is one of the reasons I often consider C++ as the containers often make quick and dirty programs easy. I'm not to sure I'd consider C++ for anything I do if it wasn't for STL and the stuff that goes with it. I'm a big fan of RAII myself. I often find memory management and debugging very tedious, thus often reaching for Python. Once compilers more completely support C++x11 I'm hoping to relearn or maybe unlearn old practices and place more emphasis on the newer ways of doing things. In the end I probably use C++ just enough to write simple programs compared to what professionals do on a daily basis. Most likely my personal set of core features is far more limited as a result. However that doesn't seem to be a problem, it does what I need done without a lot of complaints. 
with circumspection.
he means following idea: //clients dont see this template&lt;class T&gt; void foo_impl(T) { /*stuff*/ } //only these void foo(int a) { foo_impl(a); } void foo(char a) { foo_impl(a); }
By the way, [CodeAnalyst](http://en.wikipedia.org/wiki/CodeAnalyst), [CodeTune](http://www.thewallsoft.com/codetune/), [GlowCode](http://www.glowcode.com/), and [Very Sleepy](http://www.codersnotes.com/sleepy) are free profiling tools for Windows. You don't have to pay for profiling tools on Windows.
Pretty much the same ... I think understanding the point of RAII, how it relates to exceptions etc, was the most important aha-moment. I couldn't imagine coding in a language without destructors now. Error handling becomes so very cumbersome without RAII and exceptions. so far though my code has mostly been sequential. I think the next step will be to use more lambdas, and more use of threading and/or concurrency::parallel_for_each.
Unfortunately, I started with a book that said you should learn C to learn C++. Which means, I wrote pure crap for a long time. (In my defense, Accelerated C++ wasn't written yet.) Today, I don't even attempt to manage memory myself. I rarely write `delete`, and never outside of a destructor. And I tend to prefer static polymorphism (templates); I only fall back to dynamic polymorphism when templates are not practical. What I should do: start using Boost and C++11 seriously. 
int main() { cin&gt;&gt;testvar; if (testvar == false) cout&lt;&lt;"ERROR"; else cout&lt;&lt;"PASS"; system("pause"); } I started working through the process and I believe I understand it now. Above was a quick test program I made. Inputting an incorrect type flags the variable as false and flags it. I believe im on the right path but if im not id be appreciative of guidance.
Ahh man that pretty much matches my own path exactly. I've just recently transitioned to your current step and really enjoying the steeper learning curve on parts of the language I'm either massively less familiar with or never knew existed anyway! RAII was a great technique I picked up pretty early on though - in your step 4-5 I reckon. I've also started recently needing/wanting to look things up in the C++ standard (03 for now though), and that's really helped me to understand exact details of facilities available. I've really 'absorbed' a lot around template specialization, parameter deduction, and argument-dependent lookup (ADL) which have been great in increasing my code quality.
I tried writing an answer but it's not very clear. &gt; what exactly is the while checking? while cin does not equal 0? Yes. &gt; but characters still have a value right? Sure. &gt; so wouldnt they also not be 0? The value of cin is not actually a character. In that expression cin is converted to a pointer to void actually and that void* is the null pointer if anything(including the conversion to an int) failed. Hm that's not very clear. Let me try with code and made-up function names: cin &gt;&gt; var; // can be thought of as cin.read_something(var); // where read_variable returns a reference to cin itself. if( cin ) { // check if conversion succeeded 
You are on the right path, but it's cin which gets "flagged as false". There is no way to flag ints such as testvar as false.
So what is then getting put into testvar to make this line work if (testvar == false) cout&lt;&lt;"ERROR"; When I input a char it does come out as false which to me would mean that testvar is becoming false. Is it just getting null data? 
Instead of focusing on the features of the C++ language and various libraries I think it is more useful to learn software design patterns. The [gang of four](http://en.wikipedia.org/wiki/Design_Patterns) book was very enlightening for me. Also, I've found working in Python exposed me to learning and exploring a lot more patterns easily which I could then take into C++. Another thing is to expose yourself to software frameworks which employ many useful patterns and may expose you to new concepts. Once these designs become your friends then you can fruitfully seek out C++ (or Python) language features and libraries that will help implement them.
Nothing gets put into testvar. "false" is a bool value, and bool variables are converted to ints automatically when used in expressions with other ints, so (testvar == false) is the same as (testvar==0). Try for instance int testvar = 42; cin &gt;&gt; testvar; // and input "xyzzy" or something. Or "bopshua" or some other non-number of your choice The value of testvar after that will still be 42. Your testvar probably just happened to be 0, which compares equal to false. Edit: To sum up/repeat/confuse some more: the conversion failed, and the value of cin is 0, but not 0 the integer, a pointer to void with the value 0.
 int main() { int testvar = 0; cin &gt;&gt; testvar; cout &lt;&lt; testvar &lt;&lt; endl; if (!testvar) cout &lt;&lt; "Error"; else cout &lt;&lt; "Pass"; return 0; } Simplest way to check why a variable is behaving a certain way is almost always by displaying the variable's actual value. 
Sure it does "I'll just define this new hierarchy that completely wraps the old one in a much better way!" I see it all the time. Heck I'm fighting the urge to *do* it right now.
You rule, but maybe you meant if (!cin) // instead of if (!testvar) 
I don't really like the traditional design patterns. Almost all of them seem to devolve to a pretty simple functional-style problem that is solved by passing a higher-order function around. That's a pretty simple part of functional programming...
You may want to actually test this, as it's not true (at least with g++4.6.1). xxx@xxx:~$ ./a.out frrrttt 0 Error With code int main() { int testvar = 5; cin &gt;&gt; testvar; cout &lt;&lt; testvar &lt;&lt; endl; if (!testvar) cout &lt;&lt; "Error"; else cout &lt;&lt; "Pass"; return 0; } Edit: Unless you mean that testvar turns into a pointer to void with the value 0, in which case you may be right, I have no fucking idea.
Not in this instance, as his original in this thread was &gt;if (testvar == false) cout&lt;&lt;"ERROR"; Testing cin should give completely different results, which depend on the actual input type rather than the value. int main() { int testvar = 5; if (!(cin &gt;&gt; testvar)) cout &lt;&lt; "Error"; else cout &lt;&lt; "Pass"; cout &lt;&lt; endl &lt;&lt; testvar; return 0; } Yields the same results with char input, but 0 passes now since it's not evaluating the actual value, but the type.
You are right, I should have tested it, it is not very pro to answer something without 1) providing something more substantial than my snippet of pseudocode 2) testing and running it In my defense I did actually look up whether cin's operator&gt;&gt;(int&amp;) may change the int in case of error, but it's hard reading and I might screw up. I make those apologies and now another one in the hope that once again I can be forgiven for not testing before yapping on the internet, I can't help myself.
It happens, man. Now we both know for sure!
It should be noted that this is probably slower than using a temporary variable (arch dependent, of course). Moreover, you should never implement a `my_swap(int &amp;x, int &amp;y)` like this unless you're absolutely sure that `x` and `y` will never alias.
Actually I'm still not sure because I just tested your code with g++ 4.4.1 and MSVC 10 and got xyzzy 5 Pass 
Okay, I don't know what you just said.
Which is why I mentioned g++4.6.1 :V Compiler is a huge variable with shit like this.
`cin` is an istream. The code `cin &gt;&gt; var` is using the istream's member function `operator&gt;&gt;`, and that overloaded operator does not return 0. It returns a reference to an istream (itself, actually). An istream has an `operator!`, which actually is the equivalent of the `fail` member function, which returns `true` if failbit or badbit is set in the stream. Basically, there is a ton going on there, more than beginners think there is. 
Who would desire such a thing? Anything involving Visual Studio any version is not something to be proud of.
This is incorrect. Read my post above. Good luck, it's a fun language to learn! :) I'm not sure where you're learning from, but I can see key small bits that tell me you're learning from the wrong place. Things like your use of "`system("pause")`", parenthesis around your return value (like in `return(val)`), and your lack of understanding of what's going on here. Please make sure you're using a *good* resource on C++. It sounds like you are using an old college textbook or something, either way my bet is that it's very dated. You are going to spend years unlearning all of the bad stuff it's taught you. A lot of people recommend [Accelerated C++](http://www.amazon.com/Accelerated-C-Practical-Programming-Example/dp/020170353X). I've only thumbed through it as I haven't needed that high-level of tutorial in a long time, but I can definitely tell it teaches you the *correct*, good and modern C++ way. Remember that in programming, and especially C++, there are many ways to do something. Some ways will be correct, some will be incorrect but still (appear) to function correctly, others will be flat out incorrect and not function correctly, still others will be stylistically or semantically incorrect making code very hard to read and understand later. Bottom line is, please get a better resource - I'm fairly sure you aren't using a good one.
The system("pause") was mainly me being lazy and writing up a few test lines in 30 seconds. My source is a horrible college intro class. I took a few years of programing in highschoool C++ and Java and then spent the last few years in LSL language (secondlife scripting). My class after 4 weeks finally opened c++... I on the other hand had been messing around with it getting my feel for it again and just sorta learning my own stuff. Not really coming from a source but more messing about till it worked. 
From the link: "You can't uninstall the Windows Developer Preview."
Gotcha. I guess the bottom line I'm trying to get at is this: there's actually more going on in those few statements than you can probably comprehend right now without a more complete understanding of the language. Learn to appreciate the high level parts before delving into the low level parts and internals. C++ gives you a ton of freedom, and it's really great, but it also has many high level features which are what you should be focusing on now. Above all, the expression `while ( ! (cin&gt;&gt; var))`, which I believe is where your question lies, means "while the stdin stream (standard input, normally from the user's keyboard) is good", where "good" means "is not EOF (CTRL+Z on Windows) and can be interpreted as the type that `var` is, which in this case is an `int`".
Thanks for the explanation. I've been using that for getting input for Programming Challenges, but wasn't completely sure why it actually worked.
Yeah I ended up figuring out what was actually being evaluated. And that when you put a char into an int the In gets flagged as something is up. Which in our programs simple output, input, output programs caused it to freak out and run through without accepting anymore inputs. I came across that (!(cin&gt;&gt;var)) test and was like cool that works... but why... It bugs me to not know the reasoning behind something like that. Like in math when they say 'well it just works like that' And I do agree the higher stuff is where I should be now. It was just like I said one of those things that I wanted to know why not just 'cause it does'
http://www.cplusplus.com/doc/tutorial/basic_io/ http://www.cplusplus.com/reference/iostream/istream/ This is a great site for examples and actual class documentation. There really isn't anything that will tell if its an integer or not other than testing for a sane value. cin will just read the number of bytes from the stream based on the size of variable be read into or call the extraction operator on non-integral types. It will then assign that data to the variable who is destined the data. Your use of the negation operator will just tell you the stream is good still, not if you read a number off the stream.
I'm guessing you don't yet know about operator overloading. `cin` is an `istream` object, an input stream. It knows how to read the series of characters you type at the keyboard, like reading characters from a text file, and convert the series of characters into `int`s or `float`s or `string`s or whatever. I figure you know what a function is. Well, `cin`'s `&gt;&gt;` operator is a function. It doesn't happen to look like a function because you don't use parentheses to call it, but it is a function. This function is defined for `istream` (for `cin`) in the standard library. If your `var` is an `int`, the expression `cin &gt;&gt; var` automagically invokes `cin`'s `&gt;&gt;` function with `int` `var` as its argument. You know that some functions don't return anything (they're `void`), and some functions do return something according to their return type. The `istream &gt;&gt;` function does several sophisticated operations and returns the `istream` itself (`cin`) when it's finished. `cin &gt;&gt; var` reads characters until it encounters a space or you hit the return key. Let's say you type `42` and hit return. `cin &gt;&gt; var` reads the `'4'` and `'2'` characters and gives up when it encounters the newline sentinel. It then combines the `'4'` and `'2'` and attempts to convert them into an `int`, storing the result in your `var` variable. This is successful, and it sets some sort of internal variable indicating success. But let's say you input `Fred` instead. The function reads `'F'`, `'r'`, `'e'`, `'d'` (or maybe just `'F'`, I don't remember) which cannot be converted to an `int`. Instead of crashing terribly, the function just sets an internal variable indicating an error. The `cin` object knows the internal success or error variable(s). Invoking `cin.clear()` clears `cin`'s error state. So, now the question is, what's with `if` and `while`? As I said, `cin &gt;&gt; var` automagically calls `cin`'s `&gt;&gt;` function which returns `cin` itself when it's finished. Therefore, `if (cin &gt;&gt; var)` figures out whether `cin` itself is true or false after the `&gt;&gt;` function is finished. Well, `cin` is always an `istream` object, never really a `bool`, so the question is, what is the value of `cin` when it's in a "boolean context"? It turns out, `cin` (an `istream` object) also has a `bool` operator. The `bool` operator is a function which is automagically invoked whenever `cin` is evaluated by an `if` or `while` statement. `cin`'s `bool` function checks `cin`'s internal success / error variable(s), and returns true for success or false for error. Quick summary about operators. An operator is a function which automagically gets invoked by special syntax. Edit: `istream` has `operator!`, not `operator bool`. See below. 
This right here cleared up where the true/false was coming from with the (cin &gt;&gt; var) thank you.
If you do not see problems with code you wrote 6 months ago you are broken. Pretty much my mantra. I have been with my current employer for 11 years now all with c/c++.
This person gave you a far lengthier explanation than I had time to give tonight. The only small and super pedantic complaint I have is that an istream does not actually have an `operator bool`, it has an `operator!`. But for all intents and purposes here, it basically means the same thing. The true/false is actually coming from cin (as an istream)'s `operator!`.
I think making the assumption that everything specific is homework is naive. Some people are learning on their own and run into specific concepts that they need help with.
Thank you. I defer to your expertise. I was writing off the top of my head, which is normally filled with Python. A Python object automagically invokes the `__bool__` (or `__nonzero__`) method in boolean context. 
Example 1 seemed legit and worth an answer, example 2 did not. Also, the non-homework example seemed reasonable because the poster was simply looking for projects and problems to work on that would help him/her better learn the language.
Yes help them as much as you can. If you are new programming can be overwhelming. Sometimes it takes assistance finally get it to *click* for you. Worst case these guys get an easy A and never touch programming again. People are not going to sail into programming jobs if Reddit does all their work for them forever.... eventually they'll get it or they'll quit. 
The internet broke the classic homework model years ago, if a course is worth it's salt it will pose problems in such a way as to discourage crowd sourcing. That said, I'm not going to upvote or participate in these discussions because they generally are not very interesting.
The questions are harmless, easy to answer (AND explain), and in no way would be an entire assignment. I remember the first year or so of CS classes and how much one small problem would halt *ALL* productivity. I wish a community like r/cpp existed back when I was new.
Is performance better? Seriously, they introduced some pretty terrible performance problems in the last iteration.
`operator!` returns bool, and as I said, I was being pedantic - your explanation was the most correct one here by far. This is reddit, not freenode - so I have no problem saying that everybody including the OP (and me of course) was at one point was a beginner and there's absolutely nothing wrong with that. C++ is definitely best learned in increments - there is no reason to harp on minor details (except to say that one thing may be incorrect, if only to illustrate that it may be important later). Knowing what I do know, having used C++ daily for the last 10 years or so (and I'd be a fool to say I know everything), I love to illustrate how complex the lower-level stuff in C++ is. It's really hard to thoroughly answer the OP's question in terms a beginner can understand. That said, when I was learning C++, one of the profound realizations I had was this (and I understood it less than than I did now): Pretty much everything not involving two POD types (int, pointers, etc) is a function call. Also, pretty much every operation returns something. It's actually a marvelous and lovely language. Python is also quite beautiful, but C++ gives you the reign of the empire so to speak. There really isn't anything you can't do with C++, and it has the added (really big) advantage that it's translated into native code for the CPU you're running your code on. Personally, I use C++ for just about everything (including heavy web development, though very simple things I don't use C++), and Python for anything I need to "just cook up a quicky thing". For web stuff, I've spent years writing my own code to make that easy in C++. Python is a great tool, and I'm sure you know way more about it than I do, as I use it as a tool more than I use it as a programming language.
swap(x,y)
What's wrong with helping out with hw? Some TAs are crap as are profs. If you genuinely help the person help themselves, what's wrong then? Just don't straight-up hand over the answer.
I keep seeing them fail :)
So you are effectively passing around your own implementation of the this pointer but as a function?
It has been a while since I have really used cin directly. But will it really fail for F if an int is supplied as the argument? I could have sworn you would get the equivalent of (int)'F'.
I may possibly have figured it out. In C++03, I think the relevant passage is 22.2.1.2/1: "If an error occurs, val is unchanged; otherwise it is set to the resulting value." For C++11 I looked at the draft in N3291 and found this in 22.4.2.1.2/3: "The numeric value to be stored can be one of: zero, if the conversion function[in this case strtoll] fails to convert the entire field." Ok strtoll returns 0 if it can't convert anything anyway. I checked 4.6.1 and reproduced your results. So it looks to me like the committee changed the behaviour of num_get in the new standard, breaking compatibility. Edit: I found issue 1169 in http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2011/n3312.html , explains it nicely. Although it does not give a reason why they broke compatibility.
Here is a fun little program: Declare 3 x,y coordinates that are the corners of a triangle. Declare a 4th point starting on one of the corners of the triangle In a loop randomly choose one of the 3 corners and take your 4th point and move half way to the point you chose. Each move you make, draw a dot (print out the coordinate) Loop about 1 million times. Afterwards plot the points you printed out. See what you get! (could you guess it before you started?) Enjoy.
I think that if one can help without solving the question in hand. If you want to help and thinks that this is a homework type question simply give directions to material on-line that can help the student get his answer by himself. Alternatively you can explain the concepts without directly answering the specific question, much like a teacher would do.
Being a relative new comer to C++ I am in a fairly good position of having learnt C++ as C++0x (now 11). This influences the way I code greatly. Just about everything I do is on the stack. I rarely use new, and much prefer std::array&lt;&gt; to a vector where ever possible, I happily return by value knowing that move semantics will kick in. I try and think about what can be done at compile time where possible however my template-fu is not the strongest, although do use them where I can. I use boost and intel tdd and other high quality libraries as though they were just in the std lib. especially considering they are mostly header only. I don't mind using high quality third party libraries, but hate using 'java style' (I am looking at you QT) or C with classes style libraries. If I have the time I would rather make a wrapper around the C API myself. I generally end up with lots of small (little inheritance) interacting classes.
&gt; much prefer std::array&lt;&gt; to a vector Why is that?
I see your pedanticism and raise - istream doesn't have an operator!, it has an operator void*. iostreams are so wonderful.
Ah, that would explain a lot. So pre-C++11, best practice would probably be to set initial value to 0 anyway, and post-C++11 it doesn't matter either way (but would probably be a good idea to do the same thing). C++11's behavior is what I personally would have expected it to be in the first place, but I guess they have their reasons for making it function a certain way.
Maybe look into a multimap. http://www.cplusplus.com/reference/stl/multimap/
take a look at: http://www.cplusplus.com/reference/stl/multimap/count/
 map&lt;string,vector&lt;string&gt;&gt; myMap;
Actually it has both. And in this case, `operator!` has [higher operator precedence](http://en.cppreference.com/w/cpp/language/operator_precedence) than a cast operator, so that gets called. Go ahead and try it out in a debugger. :) `operator void*` can be implicitly converted to bool, but since `operator!` is there, that's called instead. Consider: int main() { struct S { operator void*() const { std::cout &lt;&lt; "operator void* called" &lt;&lt; std::endl; return NULL; } bool operator!() const { std::cout &lt;&lt; "operator! called" &lt;&lt; std::endl; return false; } } s; if(!s) { std::cout &lt;&lt; "!s is true" &lt;&lt; std::endl; } return EXIT_SUCCESS; } The output is "operator! called". If you remove the operator!, it compiles and works as expected.
You are right. Fascinating. I see the committee felt this was too simplistic - in C++11 we get one more: "explicit operator bool() const", nice.
*Three* new core language features compared to VC10. Great. VC11 will be the new IE6.
Yup, it's like a whole new language. I can't wait until we have full support for it in all the compilers, sadly that may not be for awhile.
I'm very interested in this, but the link appears to be dead now. Is it still active?
&gt; the inputs to each operation depend on the results of the previous operation Wouldn't this also apply when using a temporary variable?
Not really, no. A large language gives you plenty of flexibility in what you know and choose to use.
All the more rope to hang you with. :)
Or build a really cool rope bridge (that you can jump off of or hand yourself from - double the fun!)
So the operator! gets invoked due to the "while" containing "! (cin&gt;&gt; var)". What if it was written another way, say "(cin &gt;&gt; var) == 0"? Looking up an STL reference it doesn't seem "operator==" is overloaded for an input stream, which seems a bit messy to me.
He did say new comer, the only real difference is an array has its size determined at construction and not re-sizable.
You get better localisation and no dynamic memory allocation calls.
I guess since the topic is how do you use it I should go into more details. * ***I make heavy use of code already written anywhere and everywhere*** * I currently work in a multithreaded client/server application * Use of templated arguments to functions where possible * Use of stl, ace, openssl and pretty much any sdk I can get my hands on * Use of polymorphism, even containers inheriting from stl for concurrent operations * As many of the C++0x features as possible, no more fors for stl containers all for_each with lambdas now. * auto is now my preferred declaration type where assignment happens during construction. * thread local storage to avoid most reasons for locking if possible * http RESTful webservice is the transport being used for the server side of the application * ace is heavily used for threading and ipc * openssl for encryption * I want to start using boost for building a python extension for application automation testing * Google testing frameworks for unit testing * A homegrown DAL to binary, xml, text and embedded dbs I still live by the words the best developers write the least amount of code. 
treat objects like structs. set/get should be avoided in favor of direct member access and struct should have a method to check for valid.
I just learned a new tactic in Chess. What a poorly designed game!
Sounds like you are looking for a mechanical switch keyboard. [This](http://www.overclock.net/keyboards/491752-mechanical-keyboard-guide.html) is pretty much the definitive guide to mechanical keyboards.
I have used C++ for the better part of 20 years, and I, too, am still learning new things.
Considering it takes far, far longer than 2 years to learn how to program, that's very unsurprising.
thanks man! reading it now:)
Programming languages are not games. Good games are supposed to difficult in that way. A programming language should be as transparent as possible. (Take a look at [this](http://en.wikipedia.org/wiki/Malbolge) if you prefer a programming language that is designed to be hard) I am a C++ programmer and think it is a really powerful tool, but I would never say, that it is an example in elegant design. It really takes a rather longer time to learn than it should. And IMHO it takes more mental effort to write sufficiently correct programs than in many other languages. Once you start to do template meta-programming, you are deep into [Rube Goldberg](http://en.wikipedia.org/wiki/Rube_Goldberg_machine) country. If you don't think that's insane, then you should take a 3 month vacation from C++ using other programming languages and then return; then you'll see. There are few languages that occupy the same "niche" that C++ does. I can really only think of D as a language with similar design goals, but that one is certainly a lot nicer than C++. Looking at its history it is perfectly understandable why C++ evolved the way it did, but that does not help you learn it any better.
Nono, I have been programming for 20 years. 
I'm pretty sure you're not looking for a mechanical keyboard at all. A mechanical keyboard is what I would consider the exact _opposite_ of a laptop keyboard. Very late EDIT: I love my mechanical keyboard though; I don't understand why you'd want a laptop-style keyboard.
&amp;#3232;\_&amp;#3232; I'm not about the nuances of object oriented programming. I am taking about the lexicographical complexity of C++. It would be the equivalent of discovering a new move in Chess that you hadn't known before.
The auto-vectorization and auto-parallelization features sound interesting. Does anyone know whether this is available for LLVM or GCC?
I want one of [these](http://djmp.org/statik/2009/05/new-typematrix-2030-ergonomic-keyboard) 
If you want something like a laptop keyboard, try the Apple ones. I'm very satisfied with my one. http://www.apple.com/keyboard/
&gt; instead find ones which have been updated to reflect the latest version of the standard? I don't think there are any yet. The book publishing pipeline is a couple of months at least I think I've heard, and probably authors were waiting for close to the time of the official standard so they wouldn't be caught too short. How long are you willing to wait? _Books are free_ - relative to the amount you earn per hour. Most of the stuff that's in 'old' books won't be irrelevant, it'll all still work; some will be superceded by better ways later maybe, but, what can you do? Supplement with blog posts. edit: you don't mention _Effective C++_. If you're a beginning programmer - just finished a class or, the equivalent of _teach yourself C++ in 21 days_ - I'd try to read that one, before any of the others even. To keep you out of C++'s gotchas. 
I like my MS natural 4000; soft, quiet. Try one at your local Fry's / Best Buy. 
Also there is no one compiler which has full C++0x support.
Auto-vectorization is available in GCC I believe. Intel's ICC is the best at it, though. Auto-parallelization looks similar to what's accomplished by OpenMP. I'm not sure exactly what the differences yet.
GCC, language, for comparison: http://gcc.gnu.org/projects/cxx0x.html Unfortunately the [stdlib link](http://gcc.gnu.org/onlinedocs/libstdc++/manual/status.html#status.iso.200x) doesn't seem to have been kept up. From the visual C++ post: &gt; Concurrency-safe containers package, which provides thread-safe versions of std:: data structures such as priority_queue, queue, vector and map. What does _that_ mean? That they weren't, before? **edit**: should have been clearer: I meant that (and maybe I've forgotten the right term) you could use different _instances of the class_ from different threads, ie they don't share a class allocation pool or something like that. (Who'd do that? Well GCC did for their std::string class a long time ago.) I expressed shock at the VC++ news because to me it's nuts to do Java-style locking of every method, whether you need it or not, which surely isn't what such a parallel-aware product is doing. 
They wouldn't have been. For example you can't push stuff into the same std::vector from multiple threads without locking.
&gt; That they weren't, before? There is a lot debate about *should they?* For many tasks, an "inner lock" (i.e. epr container operation) isn't sufficient, consider for example: tVec::iterator it = vec.find(something); if (it != vec.end()) { // ... } A thread-safe vector doesn't help you anything in this scenario, you do need an "outer" lock if another thread may modify the vector. This, OTOH means that many operatons will actually acquire two locks. This has performance and lock hierarchy implications. ---- I'm not saying one choice is "better". It's a tradeoff between at least "more comfortable" and "potentially faster". C++ typically considers comfort is for other languages - though that attitude seems to change. 
Das Keyboard. Such a great feel to the keyboard, and it's got a great click to each keystroke so you feel like you're hitting a million keys a second.
IBM model M, there are no other keyboards
I have no specific comments, but I'm both highly intrigued and amused by this line of thinking. I'd love to hear other people's opinions.
What about compilation times? One little implementation change requiring recompiling the world will quickly make actual development annoying and counter-productive. My general feeling about templates, decltype and friends is that, just like any other C++ feature, should be used with care and when appropriate, but not excessively. It's not that I disagree with you and I love the way Haskel does this. I just don't think it will ever become a viable way of doing things in C++
Inlining every function is not practical and will lead to code bloat. See [Inline Expansion](http://en.wikipedia.org/wiki/Inline_expansion).
Luckily it's a feature that has been confirmed, so there's still more to come. Edit: I was wrong. VC11 is a joke. Sorry.
There are lots of other good choices, but I prefer my un-inked Das Keyboard Ultimate. Home and work. http://www.daskeyboard.com/model-s-ultimate/ It is absolutely nothing like a laptop keyboard; typing on it sounds like being in a hail storm under a tin roof. However, you will never get stuck, and Cherry switches are amazingly sensitive.
C++ needs to be replaced with another language that follows the same principles but has none of the problems of C++. (and before you say D, D is not a replacement for C++. D is in competition with Java and C#, not C++. A true successor of C++ wouldn't have garbage collection). 
[[citation needed](http://xkcd.com/285/)]
I hardly think the ability to use the language to write a program that some compiler takes a long time to compile should warrant completely removing the ability... EDIT: I accidentally a word
Because they've removed the fake variadic template from &lt;memory&gt;/&lt;xxshared&gt;, but if you need an employee to say so, you can read it [here](http://channel9.msdn.com/Shows/Going+Deep/C9-Lectures-Stephan-T-Lavavej-Advanced-STL-6-of-n).
The compiler is the one who decides if a function will be inline or not, simply defining the function inline will not really make it inline but will give the compiler the option to inline it if he wishes.
I was going to reply the same, but the OP's requirement of "sensitive &amp; soft keys" doesn't really fit. I had one colleague complain about the noise of my Model M at the last contract I had :) 
One of the objectives of C++ is catching errors sooner, defining return types keeps the type system strong. The side effect is that generic types can become cumbersome to write, for instance 'std::map&lt;std::string, std::pair&lt;std::string, std::string&gt; &gt;::const_iterator', so the 'auto' keyword was created to help in this situations. But if abused it can make programing harder, postponing error diagnostics and creating longer error messages or perhaps even unpredictable run-time behavior.
You gave me a good WTF laugh. The last sentence topped it all. :-D C++ has a very quiet demographic, but that demographic is extremely stable and they are using C++ exactly because C++ is what it is. Plus C++ is one of the few languages that are actually taken seriously. And don't worry, C++ will evolve faster. The C++ landscape has changed greatly from the last standard. When C++98 was released, there were no compilers for it, and the support came very very slowly, with C++11, there are already compilers that support the new standard almost completely. The committee has already announced that they will release updates faster, most likely in the form of technical reports.
Why can't C++ become that language? It's almost there, just needs a few more things added. Basically, all of the low-level types and things should be optional, but the default should be nice, compiler-deduced magic around the basics of C++.
None of those things I posted in the OP would involve any change to the code that was actually generated, so run-time worries aren't applicable. One of my points (concepts) are there almost specifically to ASSIST error messages. Currently, there are 0 restraints on template parameters at all until the implementation of the template classes calls something that's incorrect. By adding the ability to specify constraints for template parameters, it should make errors much easier to identify and fix.
pretty pricey though :O. Eventually I'll have to invest into something properly so I'll keep this one in mind
C++ is used by various organizations around the world that the C++ committee doesn't want to piss off by introducing breaking changes. Another reason is that the C++ committee doesn't want to admit their choices are wrong. As with most things in life, it's a matter of politics than technical issues. 
Others have already brought up the effects on compile time, but one of the major points of header files is abstraction. It allows for separation of the interface/API and the implementation. It's a powerful tool and something that shouldn't go away anytime soon.
It doesn't really though. All the private members are right there in the header files, and the inline functions are there as well. Any kind of templates throws it all out the window as well. Do we even really need file-level abstraction?
You may want to go with a [Black Widow Stealth.](http://store.razerzone.com/store/razerusa/en_US/pd/productID.235228400/categoryId.49136200) It's a gaming keyboard, but it uses Cherry Brown switches for the keys, giving a nice mechanical feel while staying relatively quiet. (Compared to the IBM Model M or the original Black Widow.) A mechanical keyboard is IMO the best keyboard for any type of typing; you don't need to press the key all the way down, there's a satisfying click when you type, it's easier on your hands because you don't need to press the key as hard and once you get used to it, you can type faster than on a regular keyboard.
I arn't sure there is such thing as soft and sensitive keys. Soft keys are doughy because of rubber domes and therefore are not crisp. Laptops scissor keys are crisp because they are not rubber based. I think if the OP wants to type fast he should certainly try a mechanical keyboard of sorts. Not necessarily an IBM, if they don't want the typewriter experience but on based on cherry switches or whatever.
All those classic C++98 books are still very good (anything by Herb Sutters or Scott Meyers). C++03 was a small bugfix version where nothing changed. These are best practice books, and it will take time before we we get best practice books on C++11. This book claims to have some C++11 material though ... http://www.amazon.co.uk/dp/0470932449/ref=asc_df_04709324494423030
Filco Linear R with Cherry MX Red switches, and some engraved keycaps. Bad phone pic: http://www.esreality.com/files/placeimages/2011/84227-kb.png I've also got a 104-key (full-size) Filco board with blue switches, but lately I've been using the red most. You definitely sound in the market for a mechanical keyboard, or possibly a scissor-switch like the Apple aluminium keyboards. Mechanical keyboards are lighter and nicer to type on though in my opinion.
Can't tell if serious.
&gt; That they weren't, before? They were "as safe as an int".
rather than bringing all of functional programing in C++, you can just use one, like Haskell. C++ is crazy enough as it is. And anyways, people don't use C++ to simplifying their code, they use it to gain full control over it. 
It's already *in* C++. The STL and boost libraries heavily encourage it as well - the syntax just needs a little bit more tweaking.
[Thinkpad keyboard](http://www.google.com/products/catalog?q=thinkpad+keyboard&amp;hl=en&amp;client=ubuntu&amp;hs=X1E&amp;channel=fs&amp;prmd=ivns&amp;bav=on.2,or.r_gc.r_pw.&amp;biw=1024&amp;bih=680&amp;um=1&amp;ie=UTF-8&amp;tbm=shop&amp;cid=12957121682293152801&amp;sa=X&amp;ei=3hxyTpPAMcvY4QSwmZzBCQ&amp;ved=0CGwQ8wIwAA)
I dont think its our job to police students homework, thats the teachers job. Or its not even the teachers job. It's the students own life. If they want to take the easy way ... thats their choice. Cheating can only get so far though. A cheater will mess up sooner or later anyways. While you might manage to cheat and not do your homework. It only going to punish you when you take that test, interview, or job.
The _easiest_ way is to use one of the many web frameworks out there, though I dont know if there's a C++ one. However, given your stipulation of C++... Right. Emebed a web server in your app. Itll have a callback or something for the request and you can whip up a dispatcher for this request. Then take a couple days to write up a quick templating engine and you're good to go. Or just spit out the html, but thats no good. It seems much easier at first, but if a) you have to write a ton of it its a pain or b) you have to maintain it, its a pain. *Edit: We also had a decent Class&lt;-&gt;Table mapper. Without that it starts to become a world of pain, at least in the windows world. At least, the OLE code I stepped through seemed to indicate. I did this for Carbine to serve up details about their server farm. I used .. I believe it was a thin wrapper around IIS. Basically I had a request waiting in asynq that would get notified when the request came in. And for commercial work there's no decent templating engine, but theyre suprisingly easy to write. For mine I could do: tmpl-&gt;BeginSection( "ServerRows" ); for( int i = 0; i &lt; serverList-&gt;size(); ++i ) { tmpl-&gt;Bind( "Name", server[i].m_name ); } tmpl-&gt;EndSection( "ServerRows" ); It would also decompose the template into chunks so it didnt have to regexp or anything stupid at runtime. 
Stephen Prata's C++ Primer Plus 6th ed. is supposed to be out soon &amp; cover some C++11 stuff. Stroustrup knows he has to write a 4th edition but it's not on the immediate horizon. I'm a big fan of Lippman's "C++ Primer" (4th ed) but I'm not sure if that will be updated with a new 5th edition (I expect so but can't find a single shred of evidence to support that). But to answer your question, most of the information in the "classics" is still worth reading/knowing and will continue to be useful. Sure there will be some small areas where there will now be a "better" way, but a) that doesn't mean the pre-C++11 "best" way is crap, and b) as others have said, support for the new standard won't be widespread for a while. I work on embedded systems, there are hundreds of cross-compiler variants, it'll be a while before some of them are even up to C++03 :-( One other thing - you'll most likely encounter a lot of code that is pre-C++11 (certainly now, and for quite a long time going forward - "legacy code") - these "classics" will help you understand idioms, design patterns &amp; best practices that were contemporary at the time the code was written.
I can assure you that you are not alone in that regard. Nowadays (after ~15 years) I'm pretty solid on the language, even the dusty corners for the most part, but what I'm still learning is ways to use the language *effectively* (I really can't think of a better adverb than that, hat tip to Scott Meyers).
Just use PHP. Most hosts support it.. and if you are running the web server then it is easy to set up.. and it will take you 5 minutes of googling to hook it up to a database
Wasn't there a court ruling that comfortableness had to remain 500 meters from C++ at all times?
Yeah, I wasnt a fan when I evaluated the existing templating engines. I dont remember the exact reason, Im sure its in an email at my past employers ;)
I think the distance was 200, but the unit of measurement was "implementation defined". 
There is Wt which basically turns the browser into an application frontend. However it uses a DBO internally to handle objects defined in its own way. I have no idea how you would populate a widget with arbitrary data from an ODBC layer. Presumably you could thou.
Try the Logitech dinovo or dinovo edge. I have one and absolutely love it! They keys are so quiet and easy to type on. I feel like I can type so much faster on this keyboard. http://www.amazon.com/gp/aw/d/B000J43HJ8
Any language that can be actually learned is a toy language. Or to put it other way. If you think that you know a (real) language, you are kidding yourself.
Accelerated C++
That kind of asinine comment doesn't even deserve a response. 
Congratulations! You invented python!
yes
I think this is what I will do. Later I can add JQuery if i want to get fancy. Thanks. 
Why would you expect them to be thread safe?!
I always thought it'd be good follow the Loki approach of policy based mechanisms based on type-traits, so you could select how thread safety was implemented in your data structures.
I used the Game of Life ten thousand years ago when I learned LISP and again 5,000 years later when I learned Ruby. It's quite a simple way to familiarize yourself with a language's control structures and I/O.
That definitely has some merit, as the decision isn't one the library can make (it can just try to be less of a problem). However, I see some points that limit that approach in quite some scenarios: **First,** design of the public interface has a strong impact on thread safety. Not designing with thread-safety in mind can make it impossible, designing for "internal lock thread safety" may give you a sub-standard interface. Example: struct stack { T &amp; top(); void pop(); /* ... */ } can't be made thread-safe with an inner lock, but might be a preferrable choice e.g. by avoiding copies. struct stack { T pop(); /* ... */ } can be made thread-safe, but not exception safe if you have to support types T where copy, assignment or move-copy may throw. struct stack { pop(T&amp;); /*...*/ } can do both, but sucks in use cases and forces a copy (unless resource pilfering is guaranteed to be available) **Second,** available synchronization primitives have a strong influence on acceptable implementation. Having or not having 64 bit atomic operation affects the ideal data layout, this pretty much affects the implementation and can affect the interface. **Third**, template infection. Everything that works on your type must be a template. Rarely avoidable in this case, as you typically can't afford the impact of virtual calls for synchronization primitives. ---- There are still many scenarios where a template parameter that is either a real mutex, or a no-op dummy works very well and is a good design choice. Still it removes degrees of freedom.
I dont have much issues with 'homeworks'. This is because this is pretty low traffic subreddit, and: At worst someone will just pass his homework without any thought on his side (will probably bite him back sometime later, don't care much about them personally). At best we can have some interesting discussion and not only OP learns something.
Are you a new programmer? If so a couple of the classics would be highly recommended as there is a lot of C++ code out there. You will need to know what is going on in old code. However from the standpoint of educating yourself I would suggest spending most of your cash on books that support the new standard. C++ code should start to look a bit different when the new standard is widely implemented. The problem right now of course is that there are zero texts that really take a fresh approach to C++ and leverage the new standard features. It may take awhile for those books to come out too. Beyond that support in modern compilers is thin so actually writing code is a problem. In effect you have to learn a bit of the old to get anywhere right now. It will likely be that way for a year or so, hopefully in that time compilers and texts will gel into something usable. Now I realize the two paragraphs above sort of conflict with each other. What I think is important in the long run is to concentrate your learning on the latest x11 features and build good habits around those features. The idea being to be skillful in the x11 variant for the next decade. Or another way to look at is that education is about the future, much of the past can be picked up as you go along. 
I don't know either. I haven't used `cin`, or even C++ (!), in years. As I mentioned elsewhere here, I was just writing off the top of my head. 
There are idioms such as PIMPL that can keep the private members of a class hidden. 
&gt;people don't use C++ to simplifying their code, they use it to gain full control over it I've been having a hard time describing where C++ stood in the language continuum. Thank you for the words I was trying to say.
No, The C11 is still not widely in use (sadly) and is still not fully implemented in all compiler vendors. It'll take time for companies to adopt it, You should learn "Old school" but use online tutorials to be aware of the new standard. Remember! once you go Lambda you can never go ... back a
I love this book. Actually teaches you to use the more powerful C++ features.
Yeah, well, you get what you pay for. My Das is four years old, and the only reason I replaced the last one is it got lost during a cross-country move. Cherry switches last forever as long as you keep them sort-of-clean. Lots of people spend on their graphics cards, their CPU, their hard drives. I spend on the two things you use every time you use your home PC: the monitor and the keyboard. Here's a thought experiment, if you're game. Go to your local big box retailer, and chill out around one gigantic monitor. Hook it up to a garbage machine if you can get away with it. Now hang out around an expensive machine, and hook it up to a garbage monitor. Which one is more comfortable?
To your points: 1) One of the policies for thread safety can be an externally manipulable lock. The policy itself can add methods to the interface so you can acquire, top(), pop(), release. Alternatively you can have a policy to invoke a callback in the case of a copy failure, or even have a specialized case for when operator=() is a std::nothrow. 2) Absolutely, which is why templates can be wonderful. You basically can have a structure that won't *compile* or which uses SFINAE to autoselect the most efficient alternative at compile time. 3) I'm not sure I get this one. Typically you typedef your policy combinations and then have callers work on those typedefs. To a large degree the rest of your code doesn't even need to be aware of the existence of templates. 
They also have [full size ones](http://store.apple.com/us/product/MB110LL/B).
&gt; T pop(); Can be made thread-safe and exception-safe if T is required to have (non-throwing) move constructor. Just thought I'd throw(!) that in there.
You see, i haven't invented anything here. This just seems to be the path we are slowly heading towards. You could also say its approaching lisp, along with every other language.
&gt; * A rich task-based programming model that supports asynchrony and continuations. &gt; * Agents and Messaging, which lets developers express dataflow pipelines that naturally decompose into concurrent units. The first sounds like it could be covered by [TBB](http://threadingbuildingblocks.org/); I'm eager to see how the 2nd looks; I'd love to see an open-source equivalent. 
Why write what already exists? There are already web apps that let you view database tables. For example http://www.phpmyadmin.net/home_page/index.php 
I'll tack my das Keyboard recommendation here under yours. I use the quieter variant (ignore the marketing, it's only silent by comparison). As far as typing speed is concerned -- I'm at 86 wpm on this keyboard after two weeks, where I was at about 50 wpm on stock keyboards. I've been faster in the past. To go to the minimal travel extreme, some of the the Datamedia 1500 terminals available back in the late 1970s and early 1980s had such sensitive keyswitches that I could have sworn hardly touching the key was enough to register a keypress. Disconcerting, because you would get a lot of accidental keypresses just from resting your fingers on the home row. I can use the Apple keyboards (mentioned elsewhere), they have the low keypress distance you want. They are (imho) slightly less irritating than the cheap PC keyboards, but I can't hit top coding speed on them. 
No.
I know the GCC that shipped with Xcode has had autovectorization support since at least 5 years. It was a project build setting in Xcode for ages. GCC 4.0.*something*
Right, I have to upgrade the english encoding to C++ 11!
&lt;: makes no sense there! What a mistake to make!
Indeed, written that way there's no problem. Hint: Written the original way, it causes a *compile*-time error.
'&lt;:' in '...ptr&lt;::foo...' is an alternative token for '['
What do you mean? scoped_ptr is a template, hench the &lt;&gt;, and we want the global "foo", hence the "::" prefix.
[Bingo.](http://en.wikipedia.org/wiki/Digraph_%28computing%29#C) You get a bizarre and totally unhelpful error message from the compiler. Apparently, this is because C99 said to silently convert `&lt;:` in code to `[`. Despite reading the Wikipedia article, I'm still a little fuzzy on what problem this was supposed to solve. Even [EBCDIC](http://en.wikipedia.org/wiki/Extended_Binary_Coded_Decimal_Interchange_Code) supports square brackets.
Yes, but your *keyboard* might not 
There are keyboards that have angle brackets but not square brackets? In 1999?
:&gt;
You can try [CppCMS](http://cppcms.sourceforge.net/wikipp/en/page/cppcms_1x). It has embeded http server and [CppDB](http://art-blog.no-ip.info/sql/cppdb/) for easy SQL connection to several popular databases. Take a look at the hello_world examples.
I think this is less of a "bug" and more of a "syntax error caught at compile time".
There were a lot of crazy keyboards back in the day. See also: lisp keyboard
If your keyboard is 30 y.o., maybe. The only very old keyboards still used today are Model M keyboards, and they're not old enough to need trigraphs.
More like, shitty default compiler options. Trigraphs and digraphs have been useless for a very long time now.
Exactly. You understand perfectly!
Every "lisp keyboard" I can find on Google Image Search has square brackets.
But they looked different, though. That's what you were supposed to see
What just happened?
Hurray for digraphs and trigraphs! :)
Actually, shitty standards bodies. The C99 standard mandates that compilers honor digraphs and trigraphs.
I think he's making a joke about how it looks like a smiley.
zootsuit closed the &lt;: before it became a problem. :&gt;
Your implementation is at risk of a signed integer overflow, which is undefined behavior.
Even the [ASR-33 Teletype keyboard](http://www.baudot.net/gil/tty-machines/pics/M33-ASR-Gil-Keyboard-Typing-Unit.jpg) that I learned programming on in 1972 had square brackets. If your keyboard doesn't, don't put alternates in a widely used language, just get a new damn keyboard! Whoever decided this was a good idea should be fired, then rehired, and then fired again. *edit: fixed link. I need to go to bed.
di and trigraphs were "invented" to let people with shitty terminals write code. (not every low cost terminal had all needed keys for writing C code)
&gt; Whoever decided this was a good idea should be fired, then rehired, and then fired again. Yeah, fire K&amp;R ...
python, webpy and sqlalchemy is your simplest bet.
IT'S NOT 2006 ANYMORE, BIG S
It's not shitty to observe that the rest of the world wants to write C too. They could shut them off with a compiler flag or a pragma. (I for one think a formal pragma along these lines would help boatloads.)
You ... could riot, then throw back a bottle of beer.
Okay, *fine*. I retract the suggestion, and will capitulate that everyone can have an off day. Sheesh! edit: ;-)
What part of "the rest of the world" has keyboards with no square brackets?
K&amp;R had something to do with the C99 standard?
There is a whole bunch of C++ related videos from the BUILD conference [here]( http://channel9.msdn.com/Events/BUILD/BUILD2011?t=c%2B%2B)
There is a whole bunch of C++ related videos from the BUILD conference [here]( http://channel9.msdn.com/Events/BUILD/BUILD2011?t=c%2B%2B)
LOL'ing at C++ developers being labled *"performance nazi's"*. I smell meme worthiness. Another good one is labeling the automatic move, on function return, as "*organ donation*".
C uses nine characters that aren't in the basic 7-bit ASCII plane. C is old. Old keyboards were quite different. Pascal *only* digraphs `[]{}', yet there they are. I confess I don't have the trivia knowledge of the 1970s to know who this particular offender was. [The ARM probably knows](http://www.amazon.com/Annotated-C-Reference-Manual/dp/0201514591).
I'll be honest ... All those language extensions to make c++ classes ABI safe and talk to the new Windows API makes me uneasy. Generics in native ... hmm. Seems like the managed languages are spilling over into C++. Partial classes ... hmm. Isn't that what base classes are for? While I would prefer the WinRT vectors to have a std::vector interface ... its nice that you at-least can use stl algorithms on them and convert between them. I guess its better than Com though, or the new Windows API only being available to managed languages. Edit: Copied from comment &gt; *"Please answer this question: If I decide to write C++ GUI application in Metro style am I forced to use all these proprietary ref, sealed, ^, Platform::String^ extensions for GUI components or not?"* &gt; @Tomas: No, you are not forced to use them. We are providing two supported ways: &gt; - These language extensions (C++/CX). &gt; - A C++ template library (**WRL**), see Windows Kits\8.0\Include\winrt\wrl as Yannick mentioned. WRL is a C++ library-based solution sort of along the lines of ATL, which offers what I think you're looking for -- template wrapper/convenience classes and explicit smart pointers and such. That's a relief
Is this any good? TLDR (more info than the title obviously)?
&gt; *Many people think of C++ as the same language they experienced in college or just as “C with classes”, but the C++ language has evolved extensively over the years. In this session, we’ll cover how you can use C++ to write innovative, expressive and beautiful apps that deliver power and performance apps. Join us to see how the newly finished C++0x standard can make writing C++ as productive as many other languages.* And here are the [slides](http://video.ch9.ms/build/2011/slides/TOOL-835T_Sutter.pptx)
He speaks about the "new" ways to manage memory ( they already existed, but now they're part of the standard and will have greater support ) , lambda syntax, move semantics, and type inference with auto. Making c++ easier, and more performant.
Digraphs weren't made a mandatory part of the language until C99. It had nothing to do with the 1970s.
Before C99, digraphs were not a mandatory part of the language. After C99, they were. K&amp;R had nothing to do with that decision.
&gt;&gt;Doh! Your browser doesn't seem to support Silverlight or HTML5 video or we don't have an HTML5 video for this one. what the fuck? Silverlight?!
More specifically, the C++/CX extensions are controlled by the /Zw compiler switch. Turn it off, and it'll compile standard ISO C++. WinRT components themselves are all exposed via. COM (actually, a more advanced derivative, but COM is close enough). Both the managed (C#, VB.NET, JS) and the native (C, C++) languages communicate to WinRT through COM. But COM is not exactly the easiest thing in the world to use, so each language has its own "projection" to make it simpler and easier. C# does this by mapping WinRT types to CLR types (eg. HSTRING in WinRT -&gt; System.String). C++ does this using Component Extensions (HSTRING -&gt; String^ ). You can, of course, turn off CX and fall back to using COM if you want.
Been coding in C++ since 1997 .... still learning, reading, buying books. This language is a mammoth.
so, now we need to handle with processor idiosyncrasies and browser bugs/incompatibility
Oh look, it's Google Java or Google Flash or Google Silverlight. I guess it was inevitable, really.
If you don't like it you can just use HTML5 instead of Silverlight (it defaults to HTML5 anyway, Silverlight is the fallback). The video is encoded in H.264 so you need a browser which supports that.
But those were just trigraphs -- much less likely to be accidentally triggered. **Di**graphs were added in C99. And I can't imagine why. 
you should become politician. always an answer :]
+1 google
None of the examples work for me on vista ... I get "Native plugin is not allowed". Edit: Should have read the documentation ... - Type about:flags in the Chrome address bar. - Scroll down to "Native Client" and click the "Enable" link. - Scroll down to the bottom of the page and click the "Relaunch Now" button. Edit2: &gt; *Note: The Native Client toolchain has its own default library and header search paths. Thus if you use a specific third-party library in your non-Native-Client development, the Native Client tools won't find that library. If you want to use the library for Native Client development, then look for it in naclports, or port it yourself. The toolchain intentionally leaves out some standard libraries and header files; in particular, for sandboxing reasons.* I wonder what that means for boost ... cant see them being used in any of the examples. Without them I'm not as interested.
This is more similar to activex
I didn't look in detail... but can't you just bake the boost you use into the binary?
To be honest ... I don't think any programmer is limited by typing speed. It's the thinking speed that's the limit. Its like optimization. If you got a slow things happening after fast ones.. making the fast things faster isn't going to make a difference.
Boost is header only (mostly) so I would hope so ... 
I confess to being confused about C++ culture today. It’s like there’s a reality distortion field around the people advocating it a lot of the time. C++ certainly has its strengths. It does surprise me that to this day no-one seems to have produced a better alternative with a similar level of flexibility and fine control but with much better safety, syntax and high-level abstraction tools. Still, as long as that remains the case, C++ will be one of the few reasonable language choices for the kind of low-level/systems programming tasks that are its “home territory”. On the other hand, take a look at slide 6 here, which is presumably intended to show “how elegant it can be to write code in today’s C++” (slide 3). The comparison to C++ of days gone by may be somewhat accurate, but it’s been *many* years since we were writing code like the stuff on the left, so it’s not as if avoiding `delete` is somehow a new gift since C++11 arrived. However, I think the reality distortion field is hiding the third column on the right, in which this sort of manipulation is done *in a single line* in almost any other modern programming language from Python to C# to Haskell. The C++ solution isn’t clean, it’s absurdly cumbersome. It isn’t safe, it’s got a null pointer/iterator bug just waiting to happen if you forget to check for it in the comparison. It might be fast, but so is everything else at this kind of work. So by all means, let’s make programmers aware of the new features in C++11 that will help. But please, let’s not pretend that it is something it isn’t. That is not going to help anyone decide whether C++ is the right tool for any particular job.
Why not integrate shared ptr in to the language? shared_ptr&lt;Circle&gt; circle(new Circle(1)); becomes: Circle' circle(1); Both creates a shared ptr to Circle. shared_ptr given how often it is used 
Next step: nacl on the serverside. Appengine with native apps. Reduces energy costs.
It is integrated into the language - its in the standard library. 
As long as you don't resize or push, you shouldn't be allocating memory...
Being in the standard library isn't the same as being part of the language. For one, as pure_x01 pointed out, if a feature is part of the language then it can have any syntax necessary to make it convenient. When it's just code in a library, it is limited to the syntax the language supports (in this case, requiring the rather verbose line of code that pure_x01 stated). So there's a lack of abstraction. Another issue is debugging. Debugging support is a requirement for built-in language features, but tends to be glossed over for library code (since the precise implementation is unknown). This means you have to understand the data structures to look at the data they hold; in practice, debugging STL data structures can be very difficult. It also makes it more difficult for the compiler to catch usage errors ahead of time, or give meaningful messages for the ones it does catch, as anyone who has dealt with STL templates can attest to.
&gt; It does surprise me that to this day no-one seems to have produced a better alternative I think people have... for certain domains. What is "better" in your book may not be "better" in someone else's book. D, Objective-C, Java, and C# are all touted as better alternatives. One of the things that C++ has going for it is it's vast code base and ease of working with C code. For many that alone that outweighs the benefits of moving to something like D or a managed language.
Why should shared_ptr be integrated into the language? shared_ptr isn't *the* smart pointer; unique_ptr, weak_ptr, etc... are very useful. I think it would be confusing to have a special syntax for one type of smart pointer and a different syntax for the others -- especially considering how closely shared_ptr and weak_ptr exist.
HERP DERP, lets see the 100x faster benchmarkets...or GTFO....damn fud machines are everywhere
Why are all the collection algorithms like for_each and find_if etc not tied to a base class of the collections. Example: myVector.for_each([] (int&amp; a){ cout &lt;&lt; a &lt;&lt; endl; }); That would be the object oriented way to do it. 
Discussion at ReactOS site: http://www.reactos.org/forum/viewtopic.php?f=14&amp;t=9563
Rule #1 in C++, no one solution fits all. I don't always use smart ptr, I like from time to time to manage memory on my own.
you can download other versions.
I will have to disagree. In my experience a majority of C++ programmers, are still writing pre-C++98 code. Delete everywhere, no exceptions, and no STL ... printf, casts, and c-arrays everywhere. But most importantly no RAII. About the 6th slide. You say there is a null pointer reference bug waiting to happen. You say that like other languages solved this problem. As long as reference types are allowed to have an empty or invalid value, you have to check for it. Pretty much every language has something like that. What other languages like Java and C# lack is support for RAII. They don't have destructors so dealing with exceptions are cumbersome and error prone. In C++ you dont need to write a single try or catch, and your code will still be exception safe as long as you use RAII. I'll admit that the only example I am not convinced is more readable is the: &gt; for( auto i = v.begin(); i != v.end(); ++i ) { } vs &gt; for_each( begin(v), end(v), []( string&amp; s ) {}); The first is better in the sense that nowwhere did you have to mention the type *string* explicitly. C++ still has ways to go. Ranges and concepts would do much for for usability. 
I rarely want to use a managed language, but D looks quite promising. I thought it could interface with C code in much the same way that C++ can? 
How would the compiler know what you wanted to do with Circle circle(1); From my point of view most of the time I would want it to mean one of these, but which one: * Allocate a Circle on the stack * Allocate a Circle on the heap via a scoped pointer * Allocate a Circle on the heap via an auto_ptr * Allocate a Circle on the heap via a shared pointer All of the above have their uses, both in function and in communicating to other developers what my intention is with the lifecycle of my Circle object. 
[It is not quite automatic.](http://www.digitalmars.com/d/2.0/htomodule.html) Unfortunately, this makes it challenging for very large libraries. *EDIT: Formatting
The ' character .. Circle' circle(1); The ' could be any character.. and different characters for the scenarios you pointed out
What's so verbose about: auto circle = std::make_shared&lt;Circle&gt;(1); Everything is mentioned exactly once. There is no need to clutter core language with features that can be put in library - this is the mindset of standardisation committee, and i think is pretty well motivated one. Debugging is entirely different thing, and just cramming features in core language wont magically make debuggers working with them seamlessly. On the other hand, VC handles stl collections pretty well without it being in core language. Ill admit that template errors tend to be cryptic - concepts were supposed to help here afaik.
ok, understand now. I thought the quote character was a typo :-) But then you'd have to remember the correct quote character for each of the usage types. It might be better to extend type inference. (I'm not yet familiar with C++11 in detail ... there might be a way of doing this already.) shared_ptr&lt;&gt; circle(new Circle(1)); or even shared_ptr circle(Circle(1)); or perhaps shared_ptr&lt;Circle&gt; circle(1) 
I saw the link you showed but he didn't say that variadic templates will be in VC11. In fact I'm now watching [Herb Sutter's talk from //build](http://channel9.msdn.com/Events/BUILD/BUILD2011/TOOL-835T) and he **does** say that variadic templates will **not** be in VC11.
Just what we need, another way to poke holes in browser security. It will be interesting to see how their sandbox holds up over time. 
C#++!!! I love the comments below the video. Everyone there is saying what I am saying, that this new C++ is not C++ at all (Unlike reddit). 
There is no documentation on WRL. Is it going to be a 2nd class citizen for Microsoft?
So ? Every time we invent a new collection we have to rewrite all the algorithms that may apply ? And how could we add new algorithms to already existing collections ? This is totally cumbersome. OO is not always THE solution. The STL wasn't object-oriented, and it's a feature.
If you have a base class that supports this you would only need to inherit this base class. Example Scala:s Iterable: http://www.scala-lang.org/api/current/scala/collection/Iterable.html 
&gt; In my experience a majority of C++ programmers, are still writing pre-C++98 code. The trouble is, when there are millions of people in the world using a certain programming language, no one person’s own experience as a practitioner will be broad enough to generalise. I suggest that a more useful benchmark here is what someone reasonably skilled and knowledgeable in C++ would have done before and after C++11 came along. Certainly such a person would have been using techniques like RAII since long ago. &gt; You say there is a null pointer reference bug waiting to happen. You say that like other languages solved this problem. Several of them have. There are plenty of languages with type systems where nullability is explicit: functional programming languages typically support algebraic data types, .Net languages have `Nullable`, etc. In such cases, a value can only be null if you deliberately allow that possibility, unlike pointers in C and derived ideas in C++. In the weaker cases, you might get some sort of run-time failure if you try to access the underlying value of null data. For example, in C#, you’ll get an `InvalidOperationException`. Even there, you have to explicitly ask for the underlying value or you’ll get a compile-time error, so you can’t just mistake nullable data for non-nullable. With the stronger type systems, you can’t even compile code that could attempt to access the underlying value of null data. &gt; What other languages like Java and C# lack is support for RAII. They don’t all call it that, but plenty of languages have idioms that capture the acquire-release cycle for a resource without explicitly calling some sort of clean-up function every time. Even Java can do it these days, since try-with-resources was introduced in Java 7. 
I’m thinking specifically of low-level or systems programming tasks here: operating systems and device drivers, database engines, high-performance maths libraries, that kind of thing. I suspect there are much better choices than C++ for almost any more general application programming task today, potentially including the languages you mentioned in a lot of cases.
Except this won't work with C++. See how Java failed at this exercise (see the native arrays) 
&gt; I’m thinking specifically of low-level or systems programming tasks here: operating systems and device drivers, database engines, high-performance maths libraries, that kind of thing. Well, there you go. That's one specific area. There are other areas people use C++ for and for which the "better alternative" would have different requirements than systems programming. But even for systems programming, there's still a lot of different opinions. Torvalds argues C is best; Walter Bright and Andrei Alexandrescu would argue that D is perfect for this; the people at Microsoft Research would argue that Singularity is great for systems programming; other people are convinced that functional languages are best even for systems programming. There are still tradeoffs to each approach (Singularity and D have garbage collection, but that can be detrimental to timing determinism -- yes, yes, I know there are real-time garbage collectors out there, but they seem to still be stuck in "research" at this point and haven't made their way into systems). Anyway, the people listed above all know C++ really well. It's not that people in the C++ community don't think that there are better languages (though some still believe C++ is king); there just isn't a consensus. I don't know if we'll ever have consensus on what's best. And frankly, I don't find this surprising.
&gt; Well, there you go. That's one specific area. There are other areas people use C++ for and for which the "better alternative" would have different requirements than systems programming. I think we’re talking at cross-purposes now. In my original post, I was careful to specify which combination of C++’s qualities has yet to be bettered by any alternative I have encountered. That combination very much lends itself to certain kinds of low level/high performance programming task. It does not lend itself to most other programming tasks, and there are plenty of better alternatives to C++ these days for those.
It was only after my post that I've read the shocking [featurelist](http://blogs.msdn.com/b/vcblog/archive/2011/09/12/10209291.aspx). GCC it is!
&gt; It does not lend itself to most other programming tasks Really? What about cross-platform GUIs? Java requires a runtime and Java GUIs don't look that good to be honest; Python has its issues (bundling; version control; etc..., etc....); Qt, WxWidgets, and some others offer really good cross-platform abstraction, build-ability; install-ability, and integration you just won't find with other solutions. I don't buy your argument that C++ is only best at low level / high performance tasks.
Alright, I only occasionally work with C++ (when I need to help track down and fix a bug, and people are on vacation), but I see the code that the presenter labeled as "C with Objects" all the time. And not just in the code-base, in all the books/tutorials I look for on the matter. Is there a solid all encompassing book I can get that teaches you to do C++ as in the "right column"? I'm a VS2008/10 user so books with example projects that target those devenv would be preferred, but I'd like to keep my C++ knowledge as platform agnostic as possible.
I thought it was in the Premium edition as well?
http://www.cplusplus.com/doc/tutorial/ start at Classes (I) and work your way down.
The one-stop place for standard C++ is the C++ language standard - it is, after all, authoritative. But it's quite dense and hard to follow. The best book I've found for learning C++ is [Accelerated C++](http://www.amazon.com/dp/020170353X). It's a very easy to follow, well-written guide to the language, somewhat in the vein of the classic "C Programming Language" by Kernighan and Ritchie. Since you already know C, you might also find [Thinking in C++](http://mindview.net/Books/TICPP/ThinkingInCPP2e.html) to be an excellent resource, as well as [The C++ Annotations](http://www.icce.rug.nl/documents/cplusplus/). As a quick-reference, I've found cplusplus.com helpful, *but it's riddled with errors*, so don't use it as a primary source.
+1 for a good book. I have Accelerated C++, and it's nice, and relatively compact. C++ Primer is another good one, if bit more verbose. Of course if you can stomach it, Stroustrups The C++ Programming Language contains most of what you need to know about C++. But it's not an easy read. I'd also avoid old or otherwise just bad web tutorials. At least until you learn to recognize them. One resource I have found useful is [C++ FAQ](http://www.parashift.com/c++-faq-lite/). There is also complimentary [C++ FQA](http://yosefk.com/c++fqa/) which may, or may not, be as useful. One thing to remember with C++ is that it's very large language, and a lot of people dislike certain parts and use other parts. So everybody basically has their own view of what "good" or "proper" C++ is, based on the subset of C++ they like. edit: And one thing that you should probably know: C++ is currently in a sort of metamorphosis. A new major version of the language has just been finalized, and it brings a lot of new stuff. The new version is officially called C++11, but many call it also by it's work name C++0x. The previous version was C++03 (not so surprisingly released in 2003). But the basics have stayed the same, so it probably won't affect your first steps very much. 
Accelerated C++ +1
Work yourself through the following books, in listed order: * Accelerated C++. This one is hard. Don't skip any parts and try to do all exercises. * Effective C++. At this point you have a good foundation for your internship. PS: I followed this path myself, for the same reasons as you do. 
Oh wow, that didn't work - working on formatting it correctly. Please have patience. &lt;3.
What do you want help with? 'The whole thing' is not answer. 
I used http://www.cprogramming.com for a long time and still use their message boards. Great site and pretty good community. http://www.cplusplus.com is also a great resource as someone has already posted that link. But really the best thing to do is just start building something and learning the parts you need to learn. It will all fit together after a bit.
I'll try and write you a test program for just $10, and we'll see how well you can go from there. I am also in an intro C++ class but we have covered similar things.
That sounded as if I was asking for $10, I meant that I will write the program as if the item was $5.50 and you payed with $10. You would obviously want $4.50 back.
This should get you started, left incomplete on purpose. I have left a critical bug in there you will need to fix in order for this to work. int fifties=0,twenties=0, tens=0, fives=0, expertsexchange=1337, etc...; float price; float paid = 0; cout &lt;&lt; "enter price:"; cin &gt;&gt; price; while(paid &lt; price) { cout &lt;&lt; "enter paid:"; cin &gt;&gt; paid; if(paid &lt; price) cout &lt;&lt; "you cheap bastard, pay more."; } float remaining = price; while(remaining != 0) { if(remaining &gt;= 50) { fifties = fifties + 1; else if(remaining &gt;= 20) twenties = twenties + 1; etc. etc. etc. } cout &lt;&lt; "change is: " &lt;&lt; endl &lt;&lt; "50$ bills: " &lt;&lt; fifties &lt;&lt; endl &lt;&lt; "20$ Bills: " &lt;&lt; twenties; etc. etc. 
What can you do? Can you write a program that says "hello world"? Can you write one that gets input from the keyboard? Can you write one that has variables declared? Can you write one that calls a function you wrote?
NO. If someone "helps you out" for this first program, you will not have learned anything and will be no better off for the next project. Don't blame your teacher, clearly you are not learning all by yourself if you need help with something this simple. If you are having trouble in class, talk to your teacher. That is what he/she is there for. If you still need help, simply googling "C++ get text input" would be a good place to start.
http://codepad.org The logic behind it? x=multiples of space y=multiples of star x+y=linelength
So let's say the user inputs the width, the center is width/2. For each row from 0 to width/2, for each column from 1 to width, check to see if the absolute value of width/2-column &lt; row (in other words, are you as close to the middle as the # of row?). If so, write # in the column, otherwise write a blank there. I think that should get you the top half of a diamond. To get the bottom half, you can count row backwards from width/2-1 (so you don't count the same row twice as above) to 0. 
Okay, I can do that. Just a question, what was wrong with my pastebin ones? 
Well, did you write the pastebin code? If not, work out on your own how to write it. If you understand how to write that, you should be able to generalize it to a diamond. 
Start a line with four spaces to get code-like formatting.
pastebin doesn't have highlighting. x=multiples of space y=multiples of star x+y=linelength 
I tend to just tab, what's wrong with that? D:
It /looks like/ your first one doesn't like 'pause' - that doesn't work in Unix / Linux (or Mac maybe), if you're there. 'fork' is the unix command to spawn a new subprocess, which is what system() does (other than that, the first one works for me. You do an 'endl', so that should flush the output... dunno). The other one I don't know, it looks like your compiler crashed(!) -- oh, no, I see, it's just a compilation error... 
User is not inputting width, just how many rows there are. :# SOrry, should have said that.
Obviously not.
That's not the problem, thanks though.
If the whole shape is N stars wide, how many stars (expressed in terms of N and R) will appear in the in the Rth row? How many blanks will appear before and after those stars? (again, expressed as an equation using only N and R) Given those two expressions, you can modify the triangle example to print the correct number or blanks, then the correct number of stars, then the correct number of blanks, given N and the current value of R.
Sorry, what I input is how many rows there are, not how wide - so that changes the code behind it quite a lot. :3
Pick any other quadrant to do, just the one quadrant. When you've got that figured out, do another one etc - then work on how to do them all, in the diamond shape. 
Well, your picture isn't all that clear, but I was assuming you wanted shapes like this: * *** ***** *** * If so, then the relationship between width and number of rows is not complicated...
&gt;int main(char **argv, int argc) the fuck?
The width should be the same as the height
Let me just remind you I'm in an intro to C++ class. This looks nothing like what we've been learning, I appreciate you trying to help though. :3
My reasoning behind this has been the same as why it is: int *a; and not int* a; The latter makes more sense IMHO as we talk about the type of 'a' being an int pointer, thus the * should be with the definition of the type, not with the identifier. But if you were to define multiple variables, it would be written as... int *a, *b, *c; and not int* a, b, c; This same reasoning would be applied to &amp;.
Explain? That's not what it shows in my picture of the diamond :3
The rationale for the former is that when you are defining multiple variables this may be confusing: int main() { int a=7; int &amp;b=a, *c=&amp;a, d=a; } //b is a reference to a //c is a pointer pointing to a //d is an int with the value of a That said, I also prefer sticking &amp; (and * for pointers) with the type, as i avoid above anyways.
From your second link you can see the diamond is actually made up of two triangles, one upside down. So you could do it by having one loop draw a rightside up triangle, then have the second loop reversed to it draw it upside down. (an odd number of rows would have one of these two triangles contain one row fewer than the other, there are several ways to do this, one way is rounding up the half-row-count for one triangle and rounding down the half-row-count for the other) Each line has two more stars (and one fewer spaces) than the one before it. Row 0 always has 1 star. Loop up to half the total number of rows (rounded up) printing out the right number of spaces, then the right number of stars. Now loop down from half the total number of rows (rounded down this time) and print out spaces and stars the same way you did in the first loop (a function like `printTriangleLine(rowNum, totalHeight)` would make the two loops easy to read
This sounds like it'd be really helpful, but I've read it a couple times now and none of it makes sense to me, fuck! Time to go change my major..
I thought your picture was messed up
Its basically a hack to allow consistent behavior when defining multiple variables on one line. Much better solution: just don't do that.
Be brave - learn templates before classes!* *not actual advice
I vote for MyClass&amp; x; because it makes more sense to me to. I almost never define multiple variables in one statement, unless it's something trivial like int x, y; 
If you can't figure out the logic behind something this simple, programming may not be a good career choice for you.
&gt;Let me just remind you I'm in an intro to C++ class. Which means you should be doing your homework and figuring it out for yourself - not asking for solutions from people who have already put in the time and effort to learn basic logic.
To avoid arguments over it I just write MyClass &amp; x (or MyClass * x)...
I hope I've illustrated this well enough to be useful, feel free to ask questions to clarify your understanding. Let's draw the diamond we want, we'll use 7 as the target height: * *** ***** ******* ***** *** * This diamond contains two triangles * *** ***** ******* ***** *** * So now the problem is broken into a few pieces * How do I know how big the triangles have to be? * How do I draw a triangle? * How do I draw just one of the triangles upside down? -------- ** How do I know how big the triangles have to be?** For even numbers it's trivial, both are half the total height For odd numbers one will be bigger, how do we get 4 and 3 from the 7 we have? * Well, `7 / 2 = 3.5` * `ceil(3.5) = 4` where `ceil` is round up * `floor(3.5) = 3` where `floor` is round down (note, to use the `ceil` and `floor` functions you'll need to add `#include &lt;math.h&gt;` to the file near where it already does the same thing with `iostream`) ------- ** How do I draw a triangle?** One line at a time. So what's in a triangle line? Some spaces, then some stars. How many? Well it depends on which row (where the tip is row 0) and the final height of the whole diamond. Specifically, the number of spaces can be calculated using this: numSpaces = floor(diamondHeight / 2) - rowNumber using this row 0 (the tip) in a 7 tall diamond has 3 spaces, the next has 2 and so on and the number of stars using this: numStars = 1 + (rowNumber * 2) using this row 0 (the tip) has 1 star, row 1 has three and so on Using those equations you can make a function that takes a row number and the total height, it puts the results of these values into variables, then does two loops, one to print out spaces, then another to print out stars, and finally it prints out a newline "`\n`" Once you have that function you can write a loop that counts from 0 to the height of a single triangle and passes that number to this function each time, the result is that it will draw a triangle from the tip down. ------ ** How do I draw just one of the triangles upside down? ** Drawing the other triangle upside down is a matter of having another loop that counts from the height of the second triangle *down* to 0. This draws a triangle from the base and ends at the tip. 
He explicitly stated he doesn't want code, he wants help understanding the process he's trying to implement. achacha simply chose to write code anyway.
I like MyClass&amp; and int\*. I just think they look better that way, which makes it easier for me to read. &gt; int \*a, \*b, \*c; For this specific case, if I were to do it instead of specifying them on separate lines, I'd be inconsistent with myself and do it the way you do it. That little bit of inconsistency doesn't bother me either.
This almost looks like multiplication and is hard to read for me. Is this something mandated by a style guide that you have to follow?
The reason is that C++ derives its declaration syntax from C. In C, there is a philosophy that the declaration should mimic use. Suppose you have a pointer to `int` named `x`. To deference `x`, you would write `*x`. Therefore, the definition is int *x; because the expression `*x` is of type `int`. This could be just as equally defined int (*x); The `*` operator is applied to the variable, not appended to the type. This is flexible and nestable, if not particularly readable. For instance, C has pointers to functions. To call a pointer to function `f`, you (in theory) write `(*f)(1, 2)`. So the definition is int (*f)(int, int); More examples can be found in Section 5.12 of *The C Programming Language*. C++ took this syntax and grafted references onto it. The problem is that there is no syntax for using a reference; they're completely invisible. So C++ made up the symbol `&amp;` to represent a reference. But it's a prefix operator, just like `*`, so it's applied to the variable in the definition. Therefore, if `y` is a reference to `int`, it's defined int &amp;y; or equivalently int (&amp;y); In hindsight, it was seen that having declarations mimic usage was not the best way to go. The Go programming language, for example, behaves as you were expecting and applies the pointer marker (I think it was `*`) to the type. Edit: TL; DR: In C, and C++ by extension, declaration mimics use.
&gt; But to me, &amp; seems like it's part of the type so why not: ... MyClass&amp; x ... The ultimate reason is because the C language designers thought it would be cute to have a pointer or function variable "look" like the way you would get a value of it; for example, int *x, y(), (*(*z)())(); means that you get ints out of these variables like so: int a = *x; int b = y(); int c = (*(*z)())(); Because of this, the pointer and function modifiers to the type have to be applied *to each variable separately* rather than only once to the type itself. To be consistent with the way that pointer/function modifiers work, the "&amp;" reference modifier introduced by C++ likewise needs to be applied to each variable separately. Unfortunately this is not as "cute" as the other modifiers because you don't use the expression "&amp;x" to get a value out of a reference variable "x", and it means that if you forget that you need a "&amp;" on every variable in the declaration then your code might compile perfectly but give you different behavior from what you were expecting. That is to say, if you carelessly wrote the following code, int&amp; i = a, j = b; thinking that this would make "i" and "j" be references to respectively "a" and "b", then the following will *not* do what you intended ++j; and later you will find yourself tracking down the reason why the variable b ended up with the wrong value. Edit: Cosmetic tweaks to fix things I missed.
exactly, the reference / pointer "binds" to the variable, not the type; putting it there is a sligth reminder lest we forget. 
I know it's not the most important issue with programming but I just want something comfortable. My current keyboard is going to suffice for the time being :p
I like it better the other way around. To me it makes more sense as I use a pointer (or reference) to something of type int. I read it as "a is a pointer to an int", to me the fact it is a pointer is not relevant to the type of the object. P.S. Just wanted to share my point of view, not sayint it is "better" or makes more sense :)
&gt; I read it as "a is a pointer to an int", to me the fact it is a pointer is not relevant to the type of the object. That's not correct, though. The type of "a" is int*, not int. Pointers are completely distinct types from the pointed-to-object, and it doesn't make sense to think of a pointer "in terms of" the pointed-to object.
How do you handle mixed declarations of int pointers and ints? For example int *i, j, *k;
It is incorrect from the point of view of the standards, but whether the instance I am using is a pointer or not, it has the same API. The only difference you *see* is the star and the use of '-&gt;' insteand of a simple dot. It is a handle to manipulate an object of type A. Whether the handle is the actual object A a; or a pointer A* a; or even a reference A&amp; a; I am still using an A and not a B. 
I find these declarations easier to read with my approach. I read this as "I declare i as a pointer to an int, j as an int, and k as a pointer to an int."
&gt; It is a handle to manipulate an object of type A. Whether the handle is the actual object &gt; A a; &gt; or a pointer &gt; A* a; &gt; or even a reference &gt; A&amp; a; &gt; I am still using an A and not a B. class B : public A {}; B b; A a1 = b, *a2 = &amp;b, &amp;a3 = b; Two of these are a B instead.
This fails code review.
[Herb Sutter thinks that in general free functions are preferable to member functions](http://www.gotw.ca/gotw/084.htm) Because for_each is not a member of some STL collection base class, it can be used on other non STL containers e.g. arrays. 
I'd like to suggest that you chose the worst of 3 options ;). Why are you multiplying MyClass by x?
If it helps, break it down like this - Object type on left, access type on right. e.g. "MyClass" is your object, and "&amp;x" is the way you access it, i.e. by reference. That's not an explanation for why, but it might help.
Yes, but the confusion here comes from bad variable naming. What they **are** and what you use them **as** are two different things.
&amp; is part of the type. You want MyClass&amp; x. For multiple declarations on one line, as in { int *a, *b, *c... } well, just don't do it. It's an easy way to have un-initialized variables in your code, which lead to hard to find bugs. int* a = 0; int* b = 0; int* c = 0; is much safer.
Thank you very much for that!
Well, I'm kinda assuming anybody reading the code knows C++ syntax to a certain degree. :) And no, just my personal preference.
Figuring out the logic is an essential part of programming courses, asking for the logic is just as bad.
At that level class it's about learning how to figure out that logic. To learn something you need to be shown how to do it. Taught the process.
I've been a Linux programmer for 15 years and always used an MS Natural. That used to cause me more mental dissonance than it does now. 
As an addendum, Bjarne covers this exact topic in his Style FAQ: http://www2.research.att.com/~bs/bs_faq2.html#whitespace You pretty much hit the nail on the head, and Bjarne calls what you described as "C-style" whereas "C++-style" would put the emphasis on the type, meaning "x" should be shown as type "int*" (or "int&amp;" as in the OP).
This explanation implies that the reference-ness or pointer-ness of the variable is a separate property from the type itself, which I would posit is not the case. 
Because the guy who wrote the STL [hates OOP](http://en.wikipedia.org/wiki/Alexander_Stepanov#Criticism_of_OOP).
Scumbag Microsoft: says C++11 is awesome; introduces nonstandard extensions.
Binds in the sense of the parser: teacoder has shown the canonical sample where it matters. Maybe it's nto the best wording, but that's the thing that helps me remember. *edit, so yes, the parser interprets this not as a modification of the type, but as a modification of the variable.
Which is exactly what the class itself is for.
What? Even if I had to choose between the two, debuggers let you find errors in logic, memory leaks, etc. Stepping through the program and seeing every memory value as it goes is invaluable. That said, they both do completely different jobs, so I have no idea what you're talking about.
FYI Visual Studio uses /Ze by default which disables digraphs. 
Out of curiosity, what do you want in a logging library?
* syslog integration would be good, * some kind of performance consideration as the s/w i'm writing carries high load * simple api that doesnt get in the way * configurable levels which can be enabled/disabled at run time * log file rotation management * configurable formatting * *edit*: thread safety I would roll my own, just seems like this is something that would be out there. I've written several things like this before, but this time i'd just like to focus on my own problem. 
I've been using Apache's log4cxx. Very java-y, but it does the job.
Have you considered Google's logging library? [glog](http://code.google.com/p/google-glog/)
They wrote two different logging libraries and couldn't agree on which one to use.
&gt; for(x=0;x&gt;rounds;x++){ If x is 0, it is unlikely to be &gt; rounds, so the loop body never gets executed. You want the condition in the for statement to be what is true while the loop runs.
You are never setting the while loop variable, gameon, to false after you completed the number of rounds you are playing.
Yes, this explains why it runs forever, while my comment explains why it prompts without playing the game in this infinite loop.
One might joke that this is just like the boost guys :) OTOH they really are very smart and a lot of their stuff is well thought-out, so it really isn't like them at all.
It was kinda joke ... So many logging frameworks ... and then a lot of people hand-roll their own ...
What you want is for(x = 0; x &lt; rounds; x++) You should make a few variables const, have better input checking, and better variable names.
Well, there are websites out there that have tutorials. [http://cplusplus.com/](http://cplusplus.com/) is pretty good I think. If you're looking for books, there's [Effective C++](http://www.amazon.ca/Effective-Specific-Improve-Programs-Designs/dp/0321334876) by Scott Meyers, which is pretty much required reading for anyone who wants to get serious with the language. Also, the languages creator has written a [new book](http://www2.research.att.com/~bs/programming.html) targeted at newer programmers, but I'm not sure how good it is. 
may I ask what do you mean better variable names. Isn't that subjective as there is no universal variable naming scheme?
Yes it is subjective, but variable names can help make the program easier to read. IMO variables should describe what they represent. For example, the op uses variable names in1 and in2. It would be easier to understand what data these variables hold if they were named something like user_selection, cpu_selection. in1 and in2 just tells me these variables hold the first and second inputs. He made good choices with the names compscore and userscore, I know exactly what these variables represent, no need for me to analyze the logic of the program to figure out what they hold.
Personally, I suggest looking at C before C++. It'll help you understand a lot more about what's going on. I think [the K&amp;R book](http://www.amazon.com/Programming-Language-2nd-Brian-Kernighan/dp/0131103628) is still the bible.
1 answer: What does this line declare: int* x, y; How about this one? int *x, y; Same for references: int x; int &amp;y = x, z = x; // Declares a reference-to-int and an int, clearly. int x; int&amp; y = x, z = x; // Looks like it declares two references, but it doesn't. Case closed. 
This is a good, side-book for getting up to speed on C, [Practical C Programming](http://shop.oreilly.com/product/9780596004194.do). He did a follow-up, I never used it though, [Pratical C++ Programming](http://shop.oreilly.com/product/9780596004194.do). When you want get Expert at C, try [Expert C programming: deep C secrets ](http://books.google.com/books?printsec=frontcover&amp;id=9t5uxP9xHpwC#v=onepage&amp;q&amp;f=false) 
If you liked the instructional form by which you learned Java, see if your college has a lower division CSci course which teaches C/C++. Even check local community colleges and adult education. I find it a bit interesting that a senior CSci major wasn't introduced to C/C++ in first year.
&gt;I've written several things like this before, but this time i'd just like to focus on my own problem. So say we all.
Yeah, I use it too. I'm not a really a fan, but it gets the job done. The fact that it is a dll is a bit of a maintenance pain. A boost header only lib would be more convenient.
Get Accelerated C++, it'll teach you modern C++ practices and have you up and running in no time.
My impression is that it is increasingly more difficult to get any non-trivial library accepted into boost. The barrier is very high and the review queue is booked for many months in advance. This has been discussed quite a bit at Boostcon 2011.
Oh nooes! Please don't. Like the saying goes: *"The worst person to learn C++ is a C programmer"*. As in, bad habits stick. I suggest instead reading Stroustrups new beginners [book](http://www.amazon.com/Programming-Principles-Practice-Using-C/dp/0321543726). It teaches C++ the right way around, C++ and STL first and C last, and then only the few good parts of C.
in main()
Boost.Log version 1 was conditionally accepted on some changes: http://lists.boost.org/boost-announce/2010/03/0256.php The author is still developing v2 for official Boost inclusion: http://sourceforge.net/projects/boost-log/ We're using Boost.Log v1 at work but it would be worth asking the author if there is a stable v2. For the most part v1 is good, we've found the time stamp formatting can be slow compared to log4cxx (due to Boost.Time though). I compared them: http://sourceforge.net/projects/boost-log/forums/forum/710021/topic/3457549 Another logging library that was considered and rejected in 2009 (I think) was "Boost.Logging" but it looks like it's abandoned: http://torjo.com/log2/doc/html/index.html. Hold tight, I'm waiting eagerly too. 
You can use it statically as well. That's what we do specifically to avoid yet-another-dll floating around.
I would look at log4cxx, its a port of log4j. Performance is decent, the API is pretty good. Both boost log libraries that were being worked on had kind of obscure API's in my opinion. I used to use log4cxx, it worked well. Its biggest drawback was that it used the apr libraries, and integrating those was a lot harder than it should have been. 
I'll have to get a copy then. I suspected it would be good, after reading his other stuff.
The OP said he was a senior and was planning on majoring in CS in college. I assume that means a senior in HS. There still is hope for the educational system...
Accelerated C++ is a good quick introduction to C++. Whatever you do avoid the C first route. C++ is a dramatically different language and is even more so with the latest rev. Which brings us to a very important point, C++ is a language in transition. Due to this reality up to date texts are very hard to come by, thus you will have to rely a bit on the Internet. You should strive to learn the languages new features and practices that those features will lead to. Especially if you intend to spend 4 years in college as I suspect that adoption of the standard will be in full swing by graduation day. However all of that being said if the school you are attending teaches with C++ I wouldn't spend a lot of time learning on your own, the head start you have already will likely lead to some boring first quarters. You would be far better off finding out what platform your school uses and learning it inside out. So if it is Linux learn bash, Python, the various command line tools and the use of a good editor. At least in my experience becoming proficient with the platform and tools is never covered in class. I mentioned Python because a scripting language has potential application throughout college. Like the other tools on a UNIX platform a little bit of skill and confidence goes a long way. My guess is that the course will be taught with GCC on either Linux or a Mac, if Windows and Visual C++ I'd be careful. No because VC++ is bad, it is actually very good but rather it seems like many colleges using Visual Studio think their goal is to teach Visual Studio and C++ in that context. That is not computer science in my mind. I also use the word careful because many schools do take a proper approach with VC++. 
&gt; and then a lot of people hand-roll their own ... That goes to show that the existing logging libraries are non-trivial to learn/use. (I also rolled my own)
that does look fairly good, i have to admit. the macros look about as clever as i'd need them to be. No mention of thread safety though.
I have used lambdas in gcc4.6
We roll our own. The thing about existing logging frameworks is that it depends entirely on your needs what you need from a logging framework. They're not hard to write, so making a custom one for your own needs is usually fine. For us (game company), we have approximately the following requirements: * Supports all our platforms (360-C++, PS3-C++, PC-C++, PC-C#) * Zero overhead (impossible, but ... close) * Some things are errors and need to be displayed prominently to our artists immediately * Some things are important events that need to be recorded and printed to the console or whatever. There can't be very many of these, because printing to the console is relatively slow and having a large spam buffer doesn't help anyone * Some things are unimportant events that need to be recorded but probably not inspected unless there's a specific hard-to-reproduce bug that we need to chase down. It's like for printf debugging - QA sends back a bug and a log and some other info. * Integration of ASSERT and the like * Integration with auto-submitting bugs from the game to our internal bug tracker Do you know of any existing logging frameworks that have those characteristics? That's a tall order for a general purpose library. That's why everyone writes their own.
Nah, it shows that logging libraries are easy to write and often grow organically from: DEBUG("A macro that logs stuff if #DEBUG is on"); Also, the risk of hand-rolling isn't high since they're so trivial to write. Without being rude ... if someone finds a logging library non-trivial to use ... well ... nevermind.
I'm using v2. No problems yet, but it's still early in my project. I'd like to see it become stable before we ship or soon after.
I highly recommend Stanley Lippman's "Essential C++" http://www.amazon.com/Essential-C-Stanley-B-Lippman/dp/0201485184 I think that "Accelerated C++" is a little too clever for beginners, whereas "Essential C++" is elegantly clear and straight forward. Regardless of which book you start out with, good luck!
I've been using glog for about a year in a multithreaded server; so far it looks pretty solid. Several types of log-sinks (stderr, files, syslog) are provided, writing another one isn't much trouble. The different verbosity-levels (per filename[-wildcard]) via flags library or env-variables are really great, from memory of the glog code switching during runtime ought to be easily achievable as well - i haven't tried though. The default to-file sink behaviour is to scatter the logs into multiple files; too much clutter for my taste. You may need the mailing list (or the source) as the documentation is pretty succinct. I like the stream api, but there is no accounting for taste.
Most C++ compilers include non-standard extensions. GCC, llvm/clang, Digital Mars, and Sun definitely do. I'm too lazy to look at others. Non-standard extensions is nothing new.
Ah, that makes sense. I misread the first sentence as 'a senior ... majoring in csci in college.'
std::vector will allocate in the free store/heap/whatever-the-standard-calls-it on construction, std::array will not.
My personal experience with boost log v1 and v2 started off well. I used v1 for over a year, then migrated to v2. It worked, had some nice features, great. But the more I tried to do with the lib, the more frustrated I became. I was always annoyed at how severity logging requires building and formatting the log string before checking the severity level. Extending the library was quite confusing, and poorly documented. It feels a bit over-engineered to me, and I am a big advocate of metaprogramming. Once the static lib and pdb for v2 started requiring a couple hundred megabytes, I was done. I ended up extending glog and ditching boost.log. To summarize, I started off needing a quick, simple logger. Of course I ended up needing more advanced functionality, and performance with severity logging became an issue, and the massive size of the compiled lib + pdb really began to bother me. Seriously, virtual functions and interfaces have their place, too. 
Ah okay, it seems like the best course would be learning a scripting language then, as it is applicable to the whole process. As for which platform my school will use, I am still unsure of what college I will be attending, therefore making the scripting path a stronger option. Thanks!
Returning the value from the function does no good unless you set a variable to the result of the call, like newval=gamescore(...). Both variables in gamescore() only exist for the short time when that function is called, when the function goes away so do those variables, and when you call it again they'll be created new and set to 0 ... unless you declare them as static int instead of just int. Can you find a way to make it work without using static variables? Don't give up!
There's something very weird about the design. What does the gamescore function do? I recommend getting rid of that function and just updating funscoreuser and finscorecomp within main. Don't forget to initialize them to 0. You might also look into enums.
I was going to try to explain a simple fix in the context of this program, but as I read further I realized that you seem to lack a fundamental understanding of the way scope works and functions behave, judging by your inclusion of the completely useless and redundant gamescore() function and use of the int(int) constructor. I would suggest talking to your instructor about the basics of the language, as you seem to have gotten lost somewhere along the way.
i wish i could not use a function but my professor strictly told us we need to use a function for this. 
Please email me the answer thanks.
In my experience and understanding, *doing* is a better way to learn than attempting to master the entirety of the thing before actually *trying*.
What I'm trying to say is that I feel any attempt to assist the OP, other than just writing the whole thing for him and working over each line individually, would not be addressing the real problem here. EDIT: On the topic of "doing before trying", I must say that I disagree completely. If anything, I would say that the best way to master a skill is by setting a goal and then *trying* to *do* it. However, without basic understanding of the fundamentals of a skill, it would be really hard to "do" or "try" anything. Running in blind is rarely the best way to approach a task, especially one that is going to be assessed.
A function for *what* specifically? Using a function just to increment the score (I assume that is what you were trying to do) is definitely not the way to go. 
OK, here we go: 1) You don't need the forward declaration of gamescore. Just move the entire function up. It's not using anything that's declared later. Also I would recommend putting it in an anonymous namespace unless you plan to use it from outside this TU. 2) Separate the logic where you ask the user if he wants to play a game from the actual game logic. Move the latter into another function, gameLoop() or something similar. 3) Make rock, paper, and scissors enums. Nobody wants to look at a '3' somewhere in the code and try to remember what the hell it stood for. 4) Use more descriptive variable names. in1 and in2 don't tell me anything. There's no reason not to call them userChoice and computerChoice or something like that, and it's immediately clear what they do. You're not on a timeshare machine with 4 kilobytes of user disk space. Don't be stingy with variable names. 5) Inside of your if .. else if .. else if you keep calling gamescore. Why? Keep track of which player won with another enum. After all the if-else checks, do a comparison on the enum to increment the total score. Like this: enum WhoWon { userWon, computerWon, nobodyWon }; WhoWon whoWon(nobodyWon); // doesn't matter what you init with really ... // all your game logic if (whoWon == userWon) ++userTotalScore; else if (whoWon == computerWon) ++computerTotalScore. 6) Remove your gamescore function. It serves no purpose, especially if you use something like what I wrote above. 7) You don't need a second using namespace expression. The first one is still in scope.
Perhaps he/she meant your function should check the user and computer inputs and update the scores accordingly, not just update the scores. That would at least make a small amount of sense. This makes none. Example: you could change the function to compare rock vs. paper, etc. and return either a -1 for a computer win, +1 for user win, or 0 for a tie. That seems unnecessarily complicated to me, but if the point is to teach you how to write basic functions, then you have to ignore whether something makes sense or not. At least for a few semesters. When you get out of school you can focus more on entire projects which are unnecessarily complicated and make no sense.
i appreciate the advice but I'm just not that far into c++ to understand it. thanks anyway man!!!
i think thats best for me as well. but different people also learn different ways. i wish mine where by doing lol
http://en.wikipedia.org/wiki/Swap_(computer_science)#Parallel_execution
Many people here have given you good advice. Lippman is a great book. Moo is a great book. Koenig is a great book. Given that you're already taking Java, many of these concepts will be old hat to you. I would suggest that you read ability oriented books like Alexandrescu and Dewhurst, then if that's got your interest, to move back to practical technique oriented books like Meyers, Sutter and other-Dewhurst. Alexandrescu: http://www.amazon.com/Modern-Design-Generic-Programming-Patterns/dp/0201704315 Dewhurst: http://www.amazon.com/Common-Knowledge-Essential-Intermediate-Programming/dp/0321321928 Meyers: http://www.amazon.com/Effective-Specific-Improve-Programs-Designs/dp/0321334876 and the two sequels Sutter: http://www.amazon.com/Exceptional-Engineering-Programming-Problems-Solutions/dp/0201615622/ref=sr_1_2?s=books&amp;ie=UTF8&amp;qid=1316780104&amp;sr=1-2 and the two sequels Other-Dewhurst: http://www.amazon.com/Gotchas-Avoiding-Common-Problems-Coding/dp/0321125185/ref=ntt_at_ep_dpt_2
No, you were right before. C++ is your path. There's a reason Python programmers don't really make interesting stuff outside the web.
Amusingly, both Kernighan and Ritchie advocate learning C++ before C.
Stroustrup's book is an excellent reference, but a terrible primer.
Tell me what parts you didn't understand and I will explain them better.
I don't imagine C as a very big language... what are its bad parts?
Its not about the size, its about the bad habits. C is a weakly typed language, C++ is a strongly typed one. So if you mix the two you ... well its the weakest link type thing. C++ is a safer C. So it offers safer ways of doing most think you could do in C. If you avoid the C way and always use the C++ alternatives you will be writing safer code automatically. It better if you never learn how to do it the unsafe way. For instance: * C arrays are overflows waiting to happen. (use vectors) * Manual malloc and free is leaks waiting to happen especially on when an error happens. (use RAII) * void* pointers and casts are examples of when type information has been lost and the user is telling the compiler, often incorrectly, something it should already know. (never cast and when you do do it the C++ way) * Return error codes that have to be checked manually, are fatal errors waiting to go unnoticed. (use exceptions instead) * Using the C standard library, forces you into most of these bad habits. (use STL and boost instead) Its relatively easy to write safe code in C++, if you just think what C would do and then do the opposite.
This is basically an updated version (for Lion) of an old post. Apple has changed gcc to point to the LLVM compiler instead of the GNU gcc 4.2 ... so trying to compile directly from sources gcc 4.6 on Lion will fail unless you instruct the shell to temporary use the 4.2 GNU compiler instead of LLVM.
My version: sudo port install gcc46 But then you have to be sure to use the gcc from `/opt/` instead of the default path (and have [MacPorts](http://www.macports.org) installed, obviously).
The solution linked here will keep your system clean. Meaning that it won't mess the default Apple installation, will remain confined in a folder in the user_name (Home) folder. This is advantageous for the one that wants to play with the new C++11 features from gcc-4.6.1 (clang simply does not have all the C++11 features implemented by gcc) or for the one that needs the last gfortran with Fortran 2003 and 2008 extensions (Apple does not supply gfortran with Xcode). 
You should give us some code to work with. Otherwise it will be really hard to answer your question. But maybe this helps: While-conditions are evaluated only at the beginning of each loopcycle, not every time the condition variable(s) change ...
About readability. I do think auto, because its so convenient, can result in more ["write only code"](http://searchcio-midmarket.techtarget.com/definition/write-only-code). Iterators make good examples for when to use auto, because their type is cumbersome to type out and everyone already knows their interface. But what about other types? Say you have a function that returns a complicated nested tree-structure-like-type with levels of vectors inside pairs, inside maps inside lists etc. Now you hold the return type by auto. Now what? There is no visual aid of the type written out in code. You have to do some serious mental arithmetic to find out the interface of the first level, the second, and so on. This might sounds like a contrived example but is one that actually happened to me and is what convinced me to only use auto for iterators. Edit: Added a helpful link to the definition for "write only code"
well i fixed it by: infile &gt;&gt; x; while (x != 3) { outfile &lt;&lt;x &lt;&lt;endl; infile &gt;&gt; x; } I just tweaked the code around but I don't really know why it works that way, where I can read up about these nuances in C++?
&gt; There is no visual aid of the type written out in code. You have to do some serious mental arithmetic to find out the interface of the first level, the second, and so on. I think modern IDEs eliminate that problem.
I (respectfully) disagree, I think auto makes code more readable. I write a lot of C++, and a lot of C#, and auto/var reduces visual noise so that I can focus on what matters. Everything is typesafe, intellisense exists, and the rhs of the assignment has a particular return type.
&gt; Now what? (…) You have to do some serious mental arithmetic to find out the interface of the first level, the second, and so on. Wait a second. Functions still have to declare their return type. You only need to look at the function you're calling to find out what the type of your `auto` variable is going to be.
MacPorts provides similar isolation, although not in the user's home directory by default.
What were you doing when it didn't work?
That code should work. Why don't you give us your real code? You can find full-on documentation at www.cplusplus.com. Depends on your experience, though.
Exactly, that means you have to jump from one file to another just to figure out what is going on. How is that good for readability? Lambdas for instance are good for readability, exactly because it means you don't have to jump around like this. 
It didn't work when I only using infile within the while loop, I have already read the C++ documentation but it doesn't mention about these nuances.
I think intellisense should be used as a tool and not a crutch. You want to be able to understand the code just as easily if it was printed out on paper. Think of it this way. Imagine you replaced all your explicitly spelled out types with auto everywhere you could in your codebase. Now tell me you haven't lost some readability. I'm not saying auto should never be used, but are you saying it should always be used?
show us the code so we can tell you what went wrong
this is actually homework for my engineering class so I don't want to be posting the solution all over the web, I just want to know about the nuances related to C++, such as the reaons in the difference of putting an infile before the while loop so as to prevent the program from reading the last entry.
The loop snippet you gave should do the right thing for you. You put an `infile&gt;&gt;x;` before the loop to make sure x has a valid value in the while (x!=3) loop. You then print the valid value, and prime another value, which the while loop will test again. The 3 should not output unless you have another line after the loop where you outfile &lt;&lt; x; again.
thanks
I think that anyone who wants to try gcc4.6 knows how to do a couple ./configure
I disagree. I find for the most part that when I can't infer the type just by looking at it, it's because the variables/functions are rather poorly named. Otherwise, you're just completely unfamiliar with the code base, at which point you'll spending plenty of time looking at the interfaces anyway. Take for example, some snippet like this: auto a = b-&gt;create(); Totally useless. Instead if it was: auto mesh = sphereGen-&gt;create(); Much better right? I admit though, that create() can return a more complicated type than you first exected: shared_ptr&lt;Mesh&lt;PNUV2Vertex,unsigned int&gt;&gt; mesh = sphereGen-&gt;create(); but that would have been clear a few lines down, and once you've realized that your code base prefers returning shared_ptrs rather than raw pointers, then it'd be pretty obvious to you.
You would be amazed at how many Mac user don't know how to use the shell (not everybody has a Unix background when starts to use a Mac). Also, there are always beginners in programming and in shell usage. 
&gt; Exactly, that means you have to jump from one file to another just to figure out what is going on. How is that good for readability? You would have to do that anyway, to figure out which type to declare — but I thought your complaint was in "writability", not readability. Either way, it's the programmer's choice. I could easily imagine coding conventions embracing styles, where `auto` is used only when it benefits readability (such as iterators, lambdas, and certain complex template declarations). One huge benefit of `auto` is the sudden independence from "type APIs". All STL classes use subtypes for iterators such as `std::vector&lt;T&gt;::iterator`, and all algorithms that deal with collections need to use the proper iterator class. template &lt;typename C&gt; void some_algorithm(C&amp; collection) { typename C::iterator it = collection.begin(); typename C::value_type first_value = *it; ... } Now, if your custom collection uses `MyArray&lt;T&gt;::Iterator` and `MyArray&lt;T&gt;::ValueType`, due to different coding conventions, the above function is suddenly useless and not so generic. A truly generic version could look like: template &lt;typename C&gt; void some_algorithm(C&amp; collection) { auto it = collection.begin(); auto first_value = *it; ... } That's the main benefit of `auto` in my opinion.
Heh, have you seem some logging libraries, like the boost ones? I would say that they are non-trivial to use in that you had to read pretty much all of the documentation to use them. Its not hard, but I wouldn't call any sufficiently featured logging library trivial to use, at least not properly. 
I hear you. I am having some template meta programming backlash lately too after dealing with some in-house libraries. It might just be due to immaturity with using these techniques, but the api's produced often seem to have tons of MPL noise injected into their interface, to the point where its hard to even make a connection with how the API is trying to solve the particular problem it was written to solve. MPL code often seems like the writer wants to prove how smart they are and how "generic" they can be, even at the cost of making the simple use case (that is used 95% of the time) quite painful to use. 
Nope. But ... it just feels like because logging is rather straightforward ... ... actually ... I've spend days trying to get log4j play the game in Tomcat ... maybe I'll shut up now ...
They are really well thought out, but both were kind of abstract. I think most people want something considerably more robust than a std::cout, but I don't know that anyone wants logging to be so complicated that they have to read a whole manual on it before they can use it. I know in the last review, there was a simple use case put in, which helped. There was still a large gap between the usability of the simplest use case where everything has a default set for you and the case where you want most of the defaults, but just want to set a few things yourself. 
&gt;You want to be able to understand the code just as easily if it was printed out on paper. Why would I want this? Limiting how comprehensible something is to how it's expressed on paper sounds like an artificial limit. If another medium can better express a piece of code, why shouldn't I take advantage of it? &gt;I'm not saying auto should never be used, but are you saying it should always be used? I would take it to the absolute extreme. Types are something that should, as much as possible, be inferred by the compiler. In fact, if the compiler could infer types not just at the point of declaration but based on how it's used, it would give statically typed languages one of the major advantages that dynamically types languages have, without the performance penalty.
That's the same argument people made for (systems) hungarian notation. Prefixing your variable names with their type (eg. iFoo, strBar) can theoretically help readability, because you can tell a variable's type without having to look for its declaration. But after a few decades of software engineering experience, people started to realize it was a dumb idea. Whatever readability hungarian notation provided was vastly outweighed by the cost to maintainability. And in the end, it didn't actually provide anything that your IDE couldn't tell you. It's the same story with auto. It makes code easier to write and to maintain, but you don't lose any information that's not trivial for your IDE to provide.
 I see I wont convince anyone. I guess time will tell. I think once people starts plugging in auto everywhere they can (like I did, especially on the user side) they will realize there is a time and place for auto. Hard to read code becomes even harder to read, when the types are not explicitly spelled out. I can imagine no more important property of an object than its type. Important thing like that should be visible in code and not hidden. Sometimes, say when writing generic code or creating iterators, its not important to know the exact type. Other times it is. I predict over usage of auto will mean bad practices like Hungarian notation will make a come back. That would be fighting the symptoms though.
Fair enough but then how do you explain the success and ease in understanding dynamic languages? I think the evidence demonstrates that the strict type of an object is not at all what's important and often just results in having to fight with the compiler to get code to work.
I agree Hungarian notation is a bad idea. Names should be logical names, and not encode the type in them as well. It tries to solve a problem that isn't there. In C++98 its not hard to find out what type a variable is, so Hungarian notation gains you nothing and costs you much. You only have to look back a few lines to where the variable is defined. "Oh its a string and not a char*, alright then, that means it deallocates itself when its scopes out later etc ... ". That's looking back to the definition, to figure out the type, gotta be one of the most common programming task involved in reading code. With auto that task becomes harder. Looking back to the definition of the variable wont help you figure it out other than by inference, so you have to jump to the declaration of the function used to initialize the variable. You pay a context switch cost, and do a mental page fault. Too much work for nothing. Code is written mainly for people not computers, and it is written once and read many times. Saving on writability at the expense of readability is a bad idea. Ironically I can imagine hungarian notation having a come-back because of over use of auto. Because the simple method of looking back a few lines to figure out the type of a variable no longer works ... people might start embedding type information back into the name again. 
Personally I dont find them that easy to read (thinking of perl). They are good for prototyping, as in they are easy to write. Types are often in the way when prototyping. Once you have finished your prototype its good to lock down the types. Not only for stability but also for readability. Thats actually how i use auto now that i think of it. Its often convenient to just use auto for return types I dont care enough to figure out the type of. But later I replace the auto with their proper name, as i find it help readability. Just my 2 cents. I think I'll stop now.. I ranted enough today.
Does this mean that every time you call a function, you make sure to explicitly declare a variable, with type, to hold the return value, before passing it as a parameter to any other function? What I mean is: &lt;long type&gt; v = f(); is better than auto v = f(); so what about f(g()); how do you know what is being passed to f? Its argument types are declared elsewhere, g is declared elsewhere, how can you know what is going on? So surely it's better to do this: &lt;long type&gt; temp1 = g(); f(temp1); Maybe not. I think the point Koenig is making is correct. The compiler can determine the type and the type is consistent with usage. After programming for a long time in languages with Hindley-Milner type inference, I haven't found the lack of explicit type information to be an issue. This relatively basic local type inference shouldn't be a burden on the reader, in my opinion. 
I appreciate your point of view.
Good point. To be honest I do think the more cumbersome to write alternative is slightly more readable. Still I would not recommend it. Its got performance implications. Even if it didnt ... I think the big difference is that there is no variable with long lifetime the user has to ponder over here. So its not as important as an variable of unknown type living in a scope hundreds of lines long. 
&gt; Exactly, that means you have to jump from one file to another just to figure out what is going on. How is that good for readability? Um, no. An IDE can do that "jump" for you. Even vi or emacs could be made to do that I'm sure.
I know a lot of programmers who think like you - in general I think their background has tended to be in languages that are neither dynamic nor type inferred, and type information is always explicit at this point (though implicit at others). A lot of people don't want to give that up. My argument above is that these two situations, where types are implicit and types are explicit are very similar, if you can tell what's going on in the second case, then it should be possible to tell what's going on in the first case. Even though there's a longer lifetime the point of definition has the same information. But really, more important than that argument, I think it needs to be tried and used. As I said I haven't found it a problem even when there's a lot less type information explicit (and in environments with no ide support whatsoever). If desired, the type can be specified, for places where it improves readability. I prefer this situation - where I can leave as much type inference as possible to the compiler, and annotate where I consider it useful. That's a personal preference. An argument against it is that programmers that you work with will differ as to their preferences. I'm not sure there's ever going to be a solution for that though :)
As someone who doesn't know any C++ I enjoyed it. These sound like great improvements and also dispel some of the negative assumptions I had about C++. For those of you who have been using some of these techniques for years already: hopefully this will make maintaining average C++ 10 years from now much more pleasant.
Search for PNaCl (Portable Native Client).
Many issues are simply not worth the time to work out on your own. Especially things like inconstancies in API usage. Even for basic data-structure issues asking for a point in the right direction can save a great deal of time. The important thing is to recognize when you find a weakness in your personal knowledge and evaluate wether it is worth your time to study further. It boils down to a cost/benefit analysis. If I can figure something out in short order I will, if it seems like it will take some time I will ask around.
It's almost always faster to figure something out yourself if you can. Only ask for help if you know someone is going to save you time.
Usually I give up, start to ask for help, and realize the solution halfway through typing up my question. But to be serious, I get nervous asking other people because I'm afraid of wasting their time or some nonsense like that. Still if I'm really having trouble and frustrated I ask for support.
I prefer working things out for myself. When it's not trivial, I will go to existing documentation first then do extensive Google searching. If it takes more than a couple hours I will ask a coworker. Usually they will have an answer or at least a clue. With that, I can get the code working more quickly and still learn the details of the problem, coming back and examining it further if I'm not satisfied with my understanding. It's definitely a tough balance to make sure you don't waste too much of your own time or that of your coworkers. Forum posts are great for some problems but the ones I run in to tend to not be well suited for the medium. They're a last resort for me and so far I haven't needed to make one myself. Part of that is because most questions which can be answered well via forum have been asked and answered on a myriad of forums already and come up during my Google search phase.
As you know there are a lot of good reasons to figure things out on your own, so I won't go into those. Here is why you should ask for help: If you don't ask for help, you miss out learning from other people, and will make "classic mistakes" and miss out on some elegant solutions you would never have thought of on your own. 
Scripting and platform tools! Like I said if the school uses C++ for teaching you would be best off learning it fresh and how they teach it. Mainly to avoid going into class with bad habits already. Note though that some schools do not start with C++, they may very well iluse a different language in the first couple of quarters. This is often done on purpose to expose you to different languages. The reason I recommend Python or another scripting tool before college is that such a tool can be used to quickly solve problems. It is sort of like going to a construction site with a set of tools, if you have the right set you can make quick work of a project. By the way one tool you should be aware of is Vim (GVIM, MacVim &amp; etc.). Vim is a text editor that can come in handy even if you are using other iDEs or editors. 
I liked the approach Accelerated C++ took, but these are opinions and the poster needs to look into what fits his learning style. The big problem as I see it right now is that we will be seeing a significant change in how C++ is taught, thus most texts are very much outdated for a new student. So a light weight text might hold him over until Cx11 texts start to surface. In the end he will need the legacy texts to understand older code. As a new student though, which I assume is a year away, it would be best to learn the new ways first to give him a context for all that legacy code hanging around. 
&gt; If you don't ask for help, you miss out learning from other people I don't really think that follows from not asking for help. You can, for example, read the responses to *other* people's requests for help.
If you've been coding for 20 years without asking for help, you are either a genius or a bad programmer. Your metric should not be "becoming a stronger coder in the long run" but "how quickly you can solve the problem well". When people ask others for help, it's because they struggled on the problem for a while and *understood it'd be quicker to ask for help*. And frankly, the idea that you'll be a stronger coder if you figure it out for yourself is just bullshit. In fact your entire post is kinda WTF. If you said this in an interview, you'd be out on your ear. 
I think there are two types of people, and programmers. The ones that solve problems by thinking aloud and bouncing ideas off other people. And then there are the introvert ones that like to understand the problem and try some solutions before asking others. I'm off the seconds sort. But some times I have spent a day on something a co-workers could have told me in a minute. These are usually questions about a code base they are more familiar with ... 
&gt; Your metric should not be "becoming a stronger coder in the long run" but "how quickly you can solve the problem well" That completely depends on the context. When I'm coding stuff for fun, why should that be my metric? If I am employed in a long-term position as a coder and my boss would prefer me to invest some time learning how to be a stronger coder so that I can save more time in future, why should that be my metric? Your position is ridiculous anyway. Even something like reading the documentation on a library you need to use is trading off "quickly ... solv[ing] the problem well" for "becoming a stronger coder in the long run". I highly doubt you would oppose reading the documentation for a new library.
Hah I have a coworker that does that to me all the time. He'll get me over, asking for my help, and usually it's just as I'm sitting down with him that he'll say "oh, nevermind - worked it out". I think it's something about the mental manipulation required to get the question ready for me usually frees the bit his brain has been caught up on.
That kind of thing always happens to me. What I do when I am stuck on a programming problem is I explain what I am trying to do and what and I am having trouble with to someone else. It does not matter at all if they know how to program. Usually when explaining it to them I will come up with a solution for myself.
Maybe clippy wasn't such a bad idea ... you could "ask clippy" your question, discover the answer in the process of framing the question and save the other person the hassle...!
Learning something does not mean not asking for help. There's no fundamental difference betwen any of these: (a) looking up documentation (b) reading responses to other people's questions, and yes (c) asking for help. The fact that you distinguish between these speaks volumes about your personality, which is why what you said is WTF and an automatic interview fail.
[Rubber ducking](http://en.wikipedia.org/wiki/Rubber_duck_debugging).
I should try that. I even happen to have a rubber duck on my desk.
Well, I guess I was thinking more of person to person environment. For example I was recently working on a program in Java (which is new to me) and asked a guy how to do something. He explained, but than said, by the way, I'd do it this way. His suggestion was more elegant, but because I had a solution I have kept working on my clunky solution, maybe never realizing there was a better way. 
&gt; I highly doubt you would oppose reading the documentation for a new library. True. But documentation isn't always perfect. And sometimes you misread. Last week a colleague called me because his code (calling a function of mine) didn't work. Turned out he tried to access `foo-&gt;bar` while he should have written `foo-&gt;baz-&gt;bar` instead. He could have wasted a couple hours identifying the typo, and that wouldn't have made him a better programmer.
&gt;The only downside I can see is that sometimes I can struggle with thorny issues for a long time, which is obviously not ideal if I'm working to a deadline. It's also a little weird seeing just so many forum posts and the like asking for help, when I just don't ever do it. Well you see, at work I have two options. * Figure it out myself (which is my preferred option), piss off my boss and have to go back and fix shit later because I overlooked something and my solution had a pitfall of some sort * Ask someone for help One thing I've noticed is that (a) most of the excellent programmers I know will ask for help fairly early on, so they can be more productive and (b) the guy who knows the answer will have already gone through the tedious process described &amp; will probably be capable of condensing the central aspects down in a manner that actually aids understanding more than hacking something out (eg what if there are hidden gotchas or your solution is suboptimal for some reason) Programming as a field is entirely dependent on communication between programmers regarding the most efficient, most optimal or most elegant ways of solving problems. Without that communication you start to see large codebases that appear severely malformed or ass-backwards simply because the coder was stabbing around in the dark for a solution. The first way a problem is solved is rarely the most elegant (eg consider ancient protocols such as FTP versus the much more efficient Bittorrent). IMO the main reason why people (including myself) are afraid to ask for help is ego or reputation. Neither of which make a good programmer. 
I do ask for help when I'm new to a particular API. I'd rather capitalize on collective experience than waste hours of my time on learning ins and outs of an API that I don't even know I'll commit to. To be honest, I find it extremely hard to believe you've never ever had to google for a solution (btw, looking at other people's questions and answers is very close to asking, you re just not the one writing the question). So in 20 years you, 1. have never run into compiler quirks, bugs and non-standard behaviour, 2. have never been curious about how a particular language construct is specified by the standard? Surely you don't get your information in a complete vacuum.
Actually, reading documentation (especially if it is a printed book) may require you to read a lot more than just the piece that you need. Even more so if you aren't quite sure what you're actually looking for. Thus, you probably learn more, but also probably spend more time than just asking someone who knows. Furthermore, research and problem solving are fundamental skills in programming, so I think you should usually try to do things yourself before asking for help. This also helps you in asking the right questions and understanding the answers you get. On the other hand, asking someone who knows is still often the best way (especially when documentation is poor or little research has been done on the subject). I guess it just depends on you and the problem at hand.
&gt; He could have wasted a couple hours identifying the typo, and that wouldn't have made him a better programmer. Well, it depends: Spending a lot of time debugging a stupid mistake should in principle make you more careful when coding (and reading). Of course, in your example, I think he was better off asking you, but when you are still learning, you need to make sure not to deprive yourself of some key learning experiences.
There's a huge difference between a) and c). If I worked with you and continually did c), I would assume you were totally inept or worse, actually illiterate. People didn't waste all those years writing fucking man pages for nothing. This is why so many programming forums are full of "RTFM" responses. What's really shocking is that you think this is an automatic interview fail. If you did c) instead of using Google first, I'd walk *you* to the door. 
I think the thing he is getting at is that if you don't ask others for help and ideas you only ever get one perspective on the problem. Of course you'll find a solution on your own, but you may find 5 other better solutions along with explanations why and saved a lot of time if you simply asked for help. You can definitely learn bad practices and being a social programmer helps to not form those to begin with by keeping yourself in check.
Googling is not at all the same thing as asking someone for help. It's just delving into the relevant literature surrounding the topic at hand. Sometimes it points you to further documentation. Sometimes it points you to examples and use cases. Sometimes if points you to forums where you might find a question asked that closely matches the once you are looking to answer. It's far faster than asking someone for help, and you'll probably learn a great deal more.
That's not what he's saying, of course try to find it out on your own, but recognize where other's input is valuable. To say you *never* in **20** *years* have asked for help throws up red flags. 
It's unsafe to use `GetLastError()` like this (in the middle of an iostream operation). The underlying `WriteFile` or other calls can wipe out the real error. Save it first before printing anything. 
Admittedly, that code is contrived. I threw it together to see if it spanned all my code or just the one project. The *real* code throws an std::exception if hLib is NULL. That said, std::exception has some stream stuff associated with it as well and I'm not entirely sure what it does on instantiation. I'll tinker and see if I can get GetLastError to return something other than 0. **EDIT:** Yep. After explicitly throwing GetLastError to my custom exception class (instead of letting it call GetLastError on its own), I now get error 126 (module could not be found). Thanks for the help. Unfortunately, I still have NO IDEA why it's giving me error 126 for loading user32.dll... or any other library for that matter...
My understanding is that development of these languages does not happen on public mailing lists. I think the best way to get something is to approach your compiler vendor, who can then forward the request to standards committee.
Loading user32.dll is a bit odd as it should have been loaded and mapped into your windows process. I did find this http://lists-archives.org/mingw-users/08702-cannot-loadlibrary-user32-dll.html Hope that helps you. What are you trying to get from user32? Is it not finding the API call that is in user32? Is you project maybe not including default libraries (check linker setting) and you may need to add USER32.DLL to the linked libraries list (did it somehow get removed by accident?)
Thanks. I sent an email to the GCC mailing list.
A bunch of Windows 2000+ functions, mostly. GetLayeredWindowAttribuyes, UpdateLayeredWindow, etc. At first, I thought for sure user32.dll WOULD be mapped. It *has to be* because I wouldn't get any sort of graphical functionality if it weren't. I *can* create windows via normal user32 functions (CreateWindowEx works just fine, as does RegisterWindowEx).
The process is different, but the source of information is the same: the other people's answers, which you benefit from passively. Whether you like it or not, you are using the collective experience of the community when you look things up on forums and mailing lists. I have issue with OP's "lone wolf" attitude, more than anything else.
Honest question: can't you just compile your C code using a C++11 compiler?
No, because then he wouldn't have access to certain C-only features. C++ is not a superset of C, and C is not a subset of C++. Close, but not quite.
I can't help you with mailing list but how would you have Lambdas in C. Lambda would have to resolve to a type in C++ they are syntactic sugar for a Functor. Something C doesn't support.
Honest answer: Heck, I could just code in Lisp. But I want to be able to do functional programming in C.
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/ http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2005/ http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/ http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/ http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/ http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2009/ http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2010/ http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2011/ Those are the official post C++03 papers and mailings ... and here are the C ones http://www.open-std.org/JTC1/SC22/WG14/www/docs/?C=M;O=A
This is due to the fact that arguments to functions are not evaluated in any specific order. Since the above is equivalent to a series of nested function calls to the operator&lt;&lt; function, the evaluation order is not guaranteed. [Relevant blog post](http://blog.barrkel.com/2008/04/c-evaluation-order-gotcha.html)
Thanks, I avoided this by: cout &lt;&lt; countNumberOfTimesCalled() &lt;&lt; " ";. cout &lt;&lt; countNumberOfTimesCalled() &lt;&lt; " "; cout &lt;&lt; countNumberOfTimesCalled() &lt;&lt; " "; cout &lt;&lt; countNumberOfTimesCalled() &lt;&lt; " "; for everyline, etc. Thanks.
I've been programming for 25 years and I've never posted a programming question on a forum, mailing list, IRC, or asked coworkers. I've spent plenty of time answering questions on mailing lists, forums, and from coworkers. I even answered a few on IRC on #macintosh way back in the late 80s/early 90s. I don't think of this as "lone wolf". I just generally find that the things I am having difficulty no one I can personally ask will no the answer to. Regarding libraries and APIs, before the days of Google, I would read the documentation several times over, experiment, and experiment again. I used Jasik's Debugger on the Macintosh extensively, because it was often the only way to know how to make something work in the good ol' days before getting questions answered was easy. Then I used NextSTEP for a few years, and if I really had difficulty I'd step through assembly. I found a bug in one of the mid 90s Mac ROMs. I also found a gcc bug. If I was having difficulty with data structures, algorithms, etc., I'd read the literature. Nowadays, I tend to avoid languages that have closed source VMs, because it can be maddening battling with a VM that doesn't behave as you'd expect, and not being able to look at the source. But, I still don't ask questions on forums, because I almost always find what I need via a combination of Googling and research. Note that the OP was specific. He didn't say he didn't use Google or read documentation. 
Yeah, I saw those. How do I subscribe?
Before including windows header I remember I had to set a #define to "enable" the APIs, maybe that could be a problem. http://msdn.microsoft.com/en-us/library/aa383745%28v=vs.85%29.aspx The default depends on which SDK or Visual Studio you are using.
Yeah, figured that out finally. It still blows my mind that LoadLibrary, a KERNEL FUNCTION, fails.
Get hired by a company that will pay to have you on the standards committee
Nice one, I was after this just the other day and could've sworn that I read C1X had lambdas, but at least compiling as C++11 worked in my case. Makes sense to have it in both :)
It could resolve into a function pointer, something C does support. There's no need for lambdas to be functors.
And what do you do with the closure variables, i.e. the variables from the scope in which the lambda lives that you want to access from within the lambda's body? 
This explanation is not correct/complete, you need to at least add that there is no sequence point between the multiple invocations of operator&lt;&lt;, and therefore the order is not only unspecified for every single invocation, but also for the whole lot of them together! 
Yeah, that may be more of a problem. Lambdas may have to be limited in C. If you restrict yourself to inlining code and not using closure variables, it should be straight-forward. Of course it is possible someone much smarter than myself may be able to figure out how to solve the general closure variable problem.
The newsgroups comp.std.c++ and comp.std.c are commonly considered being the correct place. Unfortunately for you comp.std.c doesn't seem to be very maintained. https://groups.google.com/group/comp.std.c++/topics https://groups.google.com/group/comp.std.c/topics
&gt; How and when do you ask for help? Usually, if I have a blocking issue ("Accessing the DB started raising an exception") I look into it for about 10-20 minutes. If that doesn't work I start asking around. &gt; Do you prefer to work out problems yourself, or are you ok with posting on forums? I prefer not to ask for the solution from forums, because getting a response usually takes too much time. I do search for an already-posted question though. If I get stuck for a longer time, one of the steps I take is to post on stackoverflow, but usually by the time I get an answer I will have figured it out. &gt; What criteria does a problem have to meet first? I can't solve it _quickly_. 
&gt;ERROR_SUCCESS Someone must have laughed while creating this ..
Please don't do people's homework for them. You're screwing the other students on the grade curve. `:(`
Toss the function pointer, and pointers to the closure variables, into a structure. Add the function pointer as an initial parameter to the lambda function. The structure pointer becomes the representation of the lambda. No problem ; ) 
LoadLibrary is #defined to LoadLibraryW if UNICODE is #defined. Try calling LoadLibraryA("user32") or LoadLibrary(TEXT("user32")). I suspect this is the issue. Also note that calling LoadLibrary on an already-loaded library returns the handle to the already-loaded library, and is useful (and perfectly valid, contrary to some of the comments here.).
Why not add member functions, templates and namespaces while your there?
Wouldn't this be **unspecified** behaviour? Undefined behaviour means that the program is malformed, this program seems perfectly OK to me (I mean the OP's program not your `a+++a` line). 
Not sure. If I remember correctly, the standard says that each term of an expression should be evaluated only once, but not the order. An expression where terms get evaluated more than once leads to undefined behavior.
It depends on what is causing the problem. If I am having a problem with some in-house developed API, where the documentation is often poor, the getSomeValue() call just isn't working in the expected manner, its often far easier and more productive to ask someone who has either worked with that api before or ask the guy who developed it. It often happens that either the name was entirely misleading, or I missed some fundamental concept to the library that would have required many hours of reading code and debugging to figure out. As for forum posts and IRC, I have only resorted to those a handful of times, usually after getting stumped for a day or two. 
If that is all what you need to know about C++ Multicore threading, it isn't much. All of the above could have been done in C/C++ for years. I was expecting more of the language features, and not just some stuff that is now built-in to standard library instead of being an external library.
I'm also a little disappointed. I was expecting at least something fresh, like futures/promises. std::mutex/lock isnt rocket science. Everybody and their dog do it this way since forever - either with their own versions or with boost.
you van get notified of changes by using page2rss.com As a c++ user you can give feedback on the papers at http://groups.google.com/group/comp.lang.c++.moderated there are plenty of people on the standards comitte there ...
[Less Clicking](http://www.informit.com/articles/printerfriendly.aspx?p=1750198)
It's called help. He didn't do it for me, he didn't code it for me - he hinted at how to do it. For that I thank him.
Shirley only if they're modified, I hardly think that `int square(int x) { return x*x; }` is UB.
Your professor wouldn't see it that way. Neither would the other students in your class. 
I think the big thing with C++ multithreading is related to the memory model being standardized. So while the standard itself maybe doesn't provide wide featureset, it now enables library writers to write better libraries on top of it, without depending on implementation or undefined behavior.
Most professors and students I've ever run across are OK with students seeking help when they're stuck as long as it's not blatant copying without any thinking or effort.
Funny thing: every single student code of conduct I've ever seen explicitly forbids it, and I'm willing to bet money that you won't let someone ask *your* professors. I'm really not interested in a discussion of how an anonymous person thinks it's okay to break the grading curve. This isn't a matter of public opinion. This is a matter of the rules of the school, and there does not exist a college or university which permits schoolwork to be farmed out to the public.
Your 'Apple' class is broken. Its members are pointers unnecessarily. Make them actual objects (just drop *) and you should be good to go. What actually happens is at line std::vector&lt;Apple&gt; apples(NUM_OF_APPLES, Apple()); You are making a temporary Apple which is copied to vector num_of_apples times. Each time it is copied, bitwise copy of its member is created (since you didnt provide copy-ctor). Suddenly you have lots of objects that point to the same memory with their member pointers. When the line completes, the temporary Apple is destroyed (and it deletes memory pointed to by all the other objects). Later access to shape, x or y causes access violation. As a rule of thumb, if you have written destructor, copy-ctor, or copy-assignment operator you usually want to have all three implemented. In your case you want neither (just drop dynamic allocation).
Assuming you are using at least Visual C++ 2010 Express running it in the debugger should cause it to stop on the line where the out of bounds memory fetch occurred. I am not familiar with SFML but I would probably also change the members of Apple to be in place rather than separately allocated on the heap. Java and C# sort of force you to use the heap a lot more that you would in a C++ program where you chose yourself where stuff goes. Additional note, you should almost never need to write ‘delete’. Look up std::shared_ptr and std::unique_ptr. Check out this recent talk by Herb Stutter about modern C++ best practice. http://channel9.msdn.com/events/BUILD/BUILD2011/TOOL-835T 
I'd like to again emphasize using the debugger. This is a perfect situation where you can use the debugger to narrow down your problem area so that you can figure this out yourself. Not that you shouldn't even ask for help, but trying to run it through the debugger before you have an issue will also help the people who are trying to help you.
I take it function *bool CollisionDetection(...)* is meant to be commented out, otherwise you have a multi line comment starting from /*x = rand() % HEIGHT; and finishing at the end of said function You didn't define an assignment operator for Apple but are using one to needlessly explicitly assign to its default ctor. Why are you reducing perf by wasting heap resources arbitrarily? You ain't from 'round these parts is you Javite? 
In Java, you work a lot with pointers (or references). Writing `a=b` means that `a` points to the same object as `b`, except for some types (like numbers). In C++, we tend to work with values. From time to time, you'll want to take a reference or a pointer to an object, but most of the time, you take the object itself. The idea is that an object works like `int`. So, writing `a=b` means that `a` is an independant deep-copy (think Java's `clone()`) of `b`. Anyway, for your first program, I'd recommend not using pointers or references at all. Sure, passing `const` references as parameters is pretty common, but it's merely an optimisation, that you can skip for now. It's pretty obvious that you should never use `delete`. What's less obvious, however, is that you can make pretty big programs without using `new` at all. 
Nope I'm not :(
Thanks, I followed your recommendation of not using pointers and references and it's running better.
At a quick glance of the code, you're absolutely correct. Not only (as noted) is the heap usage for the floats here unnecessary, but likely the cause of the crash. I'd add as a general rule of thumb: PODs should be stored by value, and simply derived types comprised of a few or several PODs (i.e. std::pair&lt;double, double&gt;) should be stored by value. Although, a good profiler will tell you for sure where you're wasting cycles. Also worth noting, a float is typically 32-bits, a double 64-bits. A pointer to a float here, assuming a 32-bit machine, occupies the same space as a pointer to a float. However, the dynamically allocated float has the downside of detrimentally affecting cache performance for no real reason. Also, copying a float here (or the class as a whole), strictly requires a new allocation and assignment. Without the dynamic allocs, a copy is a simple bitwise copy, achievable in a single instruction. Conversely, if you were inspect the instructions necessary to dynamically allocate a new float, then assign it, you would likely encounter several hundred instructions, if not thousands, as wells as several transitions from user to OS space.
A few comments in addition to what's already been said (and maybe some duplicates): * Your include of SFML/Graphics.hpp should use quotes rather than brackets as it's not a system include. While this isn't very well stated in the standard, that seems to be a widely accepted interpretation. * I'd suggest putting your constants in an anonymous namespace. Put `namespace { }` around them... * As a beginner I'd suggest that you don't put in using statements... it'll help you get a better grasp of what's in the standard namespace, etc... I personally prefer to always fully qualify the scope of things, but I couldn't defend telling you to always do that except for in headers, where you don't want the side-effect of the using statement to affect other people's code. * Contain your floats by value, not pointers! * Your class will have a default copy constructor and assignment operator, but you'll get a shallow copy, not a deep copy, which will probably surprise you! * If you must use pointers (in the future) use std::unique_ptr or std::shared_ptr (as appopriate) if you have a reasonably new compiler, otherwise consider using boost versions if you're allowed to. In absence of those, write your own non-copyable scoped pointer RAII wrapper. * If x &amp; y never change (seems odd), then set them in the initializer list... make them const * It's generally bad practice to "hand out your internals"... never return a non const reference to something that is part of your internal representation (the shape object in this case) as it breaks encapsulation -- you can't enforce class invariants. * Your loop counter, `i`, should be declared closer to where it's actually used (in the for loop) * Speed should be declared const -- consider moving it to the top -- also consider a more descriptive name, such as SpriteSpeed. * What are apple1, apple2, apple3 for? They're unused. I'd remove them. If they're there for some work in progress, consider learning to use source control and feeling more freedom to throw away such work in progress, always keeping the code clean as you go. * ElapsedTime should be declared const * Consider always using { } around the body of a loop (such as your for loop)... I've seen innumerable bugs over the years caused by people adding a line of code to the body of a loop, indenting it properly, but not adding the now needed braces! Seems unlikely, but I've lost count of the number of instances. * Consider using a standard algorithm (such as std::for_each) for operating in all elements in a vector... this is even easier if you have a new compiler (g++ 4.5 or newer, or Visual Studio 2010) because you can use a lambda function, which is even clearer. * When incrementing a variable, `i++`, prefer to use a pre-increment by habit as it avoids a temporary. Yes, the compiler will optimize this one away, but it's good practice to get accustomed to doing it the other way for those times when it won't/can't be optimized away. * C++ doesn't require you to return anything from main on success... EXIT_SUCCESS comes from &lt;cstdlib&gt; (which you neglected to include!), but is seldom really used.
A bit more controversial: Consider using alignment to make code with repeated patterns more readable, and to make the differences stand out... it'll help in readability, and it'll help you spot copy/paste bugs more quickly. Consider the following: if ( App.GetInput().IsKeyDown( sf::Key::Left ) ) Sprite.Move( -Speed * ElapsedTime, 0 ); if ( App.GetInput().IsKeyDown( sf::Key::Right ) ) Sprite.Move( Speed * ElapsedTime, 0 ); if ( App.GetInput().IsKeyDown( sf::Key::Up ) ) Sprite.Move( 0, -Speed * ElapsedTime ); if ( App.GetInput().IsKeyDown( sf::Key::Down ) ) Sprite.Move( 0, Speed * ElapsedTime ); Or, some variation thereof... perhaps with less whitespace on the right parameters, such as: if ( App.GetInput().IsKeyDown( sf::Key::Left ) ) Sprite.Move( -Speed * ElapsedTime, 0 ); if ( App.GetInput().IsKeyDown( sf::Key::Right ) ) Sprite.Move( Speed * ElapsedTime, 0 ); if ( App.GetInput().IsKeyDown( sf::Key::Up ) ) Sprite.Move( 0, -Speed * ElapsedTime ); if ( App.GetInput().IsKeyDown( sf::Key::Down ) ) Sprite.Move( 0, Speed * ElapsedTime ); 
For the most part in my university classes the marks come from exams. Getting someone to do your assignment for you will just have you end up failing the exam. The help this person got was to fix an undefined behaviour that there is no way they would have learned about in school. Chill out.
C++11 has futures and promises
Would Microsoft even care, since they use C# and friends?
Thanks for the links!
it's not a question of caring, those are, iirc, part of the requirements to get on standards committee, and only committee members get write/post access to the mailing lists. Which is annoying, I know. 
That was, like, my point. I expected to find this in an article about multi threading in C++11.
Is this simply a path issue?
http://www.tiobe.com/index.php/content/paperinfo/tpci/index.html Note that C and C++ have separate rankings. So learn C++, and take some scripted language like Javascript with that and you should be done.
I think Herb Sutter put it well in his //build keynote - [C# is for programmer productivity, C++ is for performance](http://channel9.msdn.com/Events/BUILD/BUILD2011/TOOL-835T). You can get things done faster with C#, but there is a performance penalty compared to C++. I think of C# it as today's Visual Basic. C++ is still the best blazing fast, to-the-metal language out there.
My professor has set up a forum for us to ask questions and ask for help, from both him and the other students.
That's quite different than asking the public. One is fair to all the students, and within the professor's control and scrutiny; the other is not.
I work in industries that need to use every last watt of power to its full potential (scientific programming on clusters, digital signal processing on lower power systems, etc.). If you don't know C or C++, you'll have a hard time getting a job in my community. I do understand this community does not represent some huge fraction of developers, but there are still plenty of places where the trade-off for programmer productivity doesn't close in the financial loops. Then you need C and C++ programmers and they better be bright.
Language is a tool. Just like tools, each exists for a particular job. They work best if applied to a particular problem. Like C/C++/D for high performance, small footprint code, JAVA/C# for enterprise productivity, Python like languages for quick prototyping and personal projects and so on. People do it other way round, which causes all the friction. Find a job, apply the best tools. Don't take a hammer and try to fix everything with it. C++ lends itself well to domains which require dealing with h/w directly, or where high performance, low memory footprints matter. Which is found on projects dealing with embedded systems, High Performance Computing, resource constrained devices, games and so on.
In my line of work (high performance and/or low-power, resource-constrained embedded systems) C and C++ are still the go-to languages. There isn't Java or C# inside a missile warhead, an implanted medical device or a 6-axis CNC machine. Other industries, such as gaming and quant/HFT applications, also rely heavily on C++, although I have no experience in them. A lot of people have trouble seeing outside their own world (I'm not saying you do). But something like 99% of the processors on the planet are not x86 desktop/server processors, but embedded processors running things like elevator controls, engine management, anti-lock braking systems, handheld GPS, etc. And most of these are programmed in C, and to a lesser extent, C++.
* ¿Need performance? ¿Execution speed? Then C++ * ¿Javascript is cool? V8 is written in C++, as the coolest Node.JS * ¿Want to make computer games? Then C++ * Do you see that cool database? MongoDB? is C++ * The browser you are using now is written in C++ * Any cute GUI multiplatform library? Yes, Qt, is written in C++ * Anything else?
Tbh, the solution is even stranger than the problem.
Is there really a meaningful bottleneck in C# ? Considering how much is done in the GPU and via APIs I doubt you'd see much difference except in the most CPU intense algorithms. C#'s weakness is that MS refuses to make it platform independent. Beyond that I'd wager it can replace C++ in 99%+ of applications and I'd easily use C# over JAVA if platform independence did not matter. The argument that C# is not missions critical is stupid. It's a brand new language, but it's managed so in the long run you'd rather have C# or even Java in a missile warhead. I don't think resource constraint is legit problem these days. Any modern hardware has more than enough power to run C#, but the CLR layer has to be written for that hardware, which is great is it's Intel or soon ARM. I think we'll see C# continue to gain ground and blow up as the new game programming language and a replacement for VB and C/C++ in most cases.. just not for platform independence though... MS can port C# to any hardware for that matter the entire .NET framework is highly portable, but only when MS wants to port it. Sadly it's easily the smartest complete development framework model out there though you can adapt Java or C++ to any hardware .NET is ultimately more flexible and has a far better tool selection. Most code bottlenecks are programmers error and that's why you'd more likely find C or C++ running slower because the situation that C# becomes the bottleneck would be very rare. Across the board realistically C++ might be a max of 15% faster and C# is more than 15% faster to code and coding time is arguably much much more important. C# is not mature and the amount of tools aren't there, but performance wise I don't think there is any real argument to be made against C# other than perhaps some type of buggy performance which is a testament to it's maturity more than a design limitation. 
True but those days are likely ending more and more and interpreted languages will certainly take over. Currently we have a huge move for MS to the ARM processor, which might reshape the mobile market in coming years. 
Yes.. but most of that is tradition not a limitation of C#. I wouldn't chose C# in this scenario because it hasn't been around long enough, but to argue that you will get more performance in the big picture or less crashes with C/C++ is just not a strong argument. If C# was 20+ years old it would an ideal language. It's really little more than managed C++ with some upgrades and lets face it managed code is eventually going to take over. I don't buy the performance argument because in the big picture most of your performance bottlenecks are probably from bad code.. code which you'd have more time to review and less likely to screw up using a managed language. Breaking the tradition and the infrastructure investments in C/C++ are the hard parts, not creating a better language. Close in financial loops? I think you'd eventually find that averaged performance and up-time will be higher with managed code, but getting a company to switch from what it's used to can take decades. You are a programmer.. I can tell by your sentence crafting skills :P 
I agree C++ is the ideal language to learn for now, but if C# was more mature it would be a better choice because there is little to no performance difference and managed code is the future. It doesn't hurt that it's backed by Microsoft.. well maybe it does, but it's not going to vanish anytime soon. 99% of C++ programs could be ported to C# with no performance difference and likely better stability. You also then have an easier to maintain program, but you won't get platform independence. In the end it's two main factors to consider industry wide acceptance and platform independence. On the other hand if you want those JAVA can offer that and with much higher job demand than C++
Right. I was wondering if Microsoft bothered to get onto the committees, since they don't normally use C/C++.
Accessing variables outside the lambda from within isn't even my first concern (though it is necessary). My first concern is finding a way to create lambdas inside of call statements (e.g. `sort(things, a_comparison_lambda)`) and how to write signatures that handle arbitrarily typed lambdas (e.g. `element* gen_array(element_generator_lambda)`).
What do you mean they don't use C/C++? They use a METRIC SHIT-TON. The core of a LOT of their products is written in C or C++. From the kernel, to their compilers and so forth, they are a MAJOR C++ developer, they logically have a major interest in the direction of the language. that said, they've historically been rather egomaniacal about language growth outside of the language. Managed C++ being a recent example :) 
Yes but if you are going to add Lambdas you add them properly to make it worth the extra clutter you add to the language. The fact is in C++ a lambda is mearly syntactic sugar for an object with operator() overloaded and constructor (AKA a functor), then passed into a function that is templated or assigned to the template type function&lt;&gt; or auto. Non of these are available to C. And you did magic them in, then you would have to look at C and C++ interoperability, would C++ then have to support 2 types of Lambda or will there be a crude split like VLAs?
There are 10 comments (now 11) in this thread, and 4 of them are you repeating some C# spiel... Care to justify your crap?
Hmm, by Visual C++'s lack of support for user configuration files, coupled with C#'s priority in documentation, and the ever-expanding list of .NET languages like F#, Visual Erlang, IronLua, etc. etc., I wouldn't have expected that. Why does Microsoft use so many languages? Apple champions Objective C, but do they also use a smatter of languages?
A lot of good points/suggestions here; I particularly like: "As a beginner I'd suggest that you don't put in using statements... it'll help you get a better grasp of what's in the standard namespace, etc... I personally prefer to always fully qualify the scope of things". My caveat to this is to absolutely never, ever do a "using namespace" in a header. Using a specific type (so long as it is constrained within another namespace is fine, but do your utmost to unnecessarily introducing names into the global namespace (especially if you're writing a lib - I would consider this a cardinal sin when writing a lib).
I think there are times for alignment like this: if the code is similar and can't be otherwise expressed. In this particular case, I'm seeing a code smell: this should be a switch statement on which key is pressed, or an if/else cascade (unless you expect Left &amp; Right to be pressed at the same time). Although, I don't always follow it, I think this sort of formatting is helpful as a visual cue to the subsequent maintainers.
buh?
&gt; 99% of C++ programs could be ported to C# with no performance difference and likely better stability. [Citation Needed] Where'd you come up with this 99%? We've been hearing that managed code is the future since 1996 and still are using almost entirely native code for every application we use. Also, have you ever done what you propose? Have you ported a C++ app to C#? I have. Even with a significant amount of native code using PInvoke, we could never get the performance we wanted. Large C# applications are very slow and bloated compared to their C++ counterparts. First, RAM usage will go up by an order of magnitude. Second, you'll need to offload all of your core routines to C++ if you're doing anything interesting. 
&gt; C#'s weakness is that MS refuses to make it platform independent Do you know the difference between C# and the CLR? &gt; It's a brand new language C# and the .NET framework are over 10 years old now. How is that new? &gt; it's managed so in the long run you'd rather have C# or even Java in a missile warhead Do you understand that every layer of abstraction creates more risk for failure? &gt; I don't think resource constraint is legit problem these days. Resources are *always* constrained. &gt; Any modern hardware has more than enough power to run C# Until it GCs. Then your missile crashes. &gt; I think we'll see C# continue to gain ground and blow up as the new game programming language Name one major game written purely in C#. &gt; replacement for VB Out of your whole comment, this is the only thing that makes sense. C# is perfect for VB programmers who are writing business applications used by car dealers. &gt; Across the board realistically C++ might be a max of 15% faster Where are you coming up with these numbers? In my experience with the two, the coding time/performance comparison is a complete myth. C++ and C# are not that different when it comes to implementation time. Herb Sutter, as much as I respect him, is probably only mentioning C# at all because he works for MS. &gt; C# is not mature and the amount of tools aren't there WTF are you talking about? Microsoft has been pushing the C# agenda now for 10 years. If anything, their C# tools are being favored over C++. C# is hugely mature, and it still can't be used for serious applications. 
Yeah, that's what I meant by my comment about headers... I couldn't justify that as a hard and fast rule, EXCEPT FOR HEADERS. You said it more clearly. Never use using statements in headers!!! More abstractly... never have more side effects in your headers than necessary... that means: - No unnecessary includes (forward declare if possible!) - No global typedefs to alias types, unless they're part of your interface - No using statements, even as an alias - no pragmas that change compiler behavior etc...
Yeah... I considered suggesting a bigger rewrite, but decided to simplify it to just alignment. Cascading ifs could also take advantage of the alignment in this case, and a switch is definitely preferred when possible.
Microsoft has always been very pro-developer (fsvo "pro-developer"). All those languages you mention are built on top of the CLR, the middle layer and backend are all common,the only stuff on top is a language-&gt;CLR compiler, right? still, large chunks of core functionality is implemented in C++. and Visual studio has long been a best of breed C++ IDE (i for one don't know of any ide that even comes close). 
As I said, Visual C++ lacks support for application config files. You have to switch to Visual C# just to add persistent user settings to your apps.
You'll need to format that better; it's unparseable as-is.
void asdf(const char z_p ) should be void asdf(const char *z_p ) So, the for loop checks if *z_p (not z_p, but the memory content to which z_p is pointing) is an end of string special symbol. While it is different, prints whatever z_p points to, and then z_p++ advances the pointer one position, so z_p will then point to the next contiguous element of the type (next char). Basically prints a string. There were errors in the code you posted and this was a really shallow answer, but I hope you get the idea.
You need to change the first part to &gt;void asdf(const char *z_p) ... and the for loop to &gt;for ( ; *z_p != ‘\0'; z_p++ ) Then it becomes an ~~inefficient~~ way of printing C-style strings. C strings are an array of characters (char) in memory. You start with a pointer to the first character, and the array is null-terminated (meaning that the last character in the array is the null character, or '\0'). This function starts with a pointer to the first character, prints it out, and then increments that pointer (so that it points to each successive character) until the pointer is pointing to the null character, at which point it ends. EDIT: Removed "inefficient" since it may not actually be any less efficient than the alternative cout &lt;&lt; z_p;. I am not familiar enough with the inner workings of the C++ Standard Library to pass judgement.
This would make sense if the parameter was a char* and not a char. To understand this you need to understand that a pointer is simply an address that **points** to somewhere in your memory. So if you cout a pointer, you en up with something like 0x02df1234. When you use '++' on a pointer you increment this address, making it point on the next byte in memory. When you declare an array of 5 chars : char foo[5]; you know that those 5 chars are going to be in a contiguous memory location, so for instance (and to simplyfy I'll use two-digits addresses) you array starts from 0x10 and will end at 0x14. So. When you use the '*' operator on a pointer, you look at what is at the pointer location. You have to know that memory is not initialized with zeroes or anything, and is left in the previous state, so if you print random places in memory, you will get random garbage. cout &lt;&lt; *foo &lt;&lt; endl; will print whatever is in memory. But if you initialize it first char foo[5] = {4, 3, 2, 1, 0}; you will set those values at the place in memory that is pointed. Back to your misterious function. It iterates over the values of the pointer (I hope you can see that now) and will stop when it hits '\0' which is the character used to terminate strings (NULL-terminated string). For each of those addresses, it will simply print the contents of the memory pointed (in this case, a char). Hope this answers your question. 
There are better general explanations for pointers out there, also here on reddit, I'll just focus on the function. I presume it's void asdf(const char \* z_p ) { for ( ; \*z_p != ‘\0′; z_p++ ) cout &lt;&lt; *z_p; } z_p is a pointer to a character. This is usually - but not necessarily - a C string: an array of characters (sequence of characters stored sequentially in memory), terminated by a character with the value 0 ("ASCII-Zero", which is not the character '0'). This is how strings look in C: char const * str = "Hello, World!"; reserves memory for 14 characters (the string, plus the terminating 0), and makes str point to the first one. ---- Now, let's take that function apart: * \*z_p dereferences the pointer ("looks into it") and thus accesses the character. * cout &lt;&lt; *z_p will output the character z_p currently points to * ++z_p increments the pointer - i.e. increases the address where it points to by 1. i.a.W. z_p is moved to the enxt character in the array * '\0' is the character representation for an ASCII 0, equivalent to (char)0. It simply tests if we are at the end of the string. Now, when you call this function like this: char const * str = "Hello, World!"; asdf(str); what do you think happens? ---- There's an important concept here: only you, as the programmer, know the "true meaning" of z_p. The compiler will usually not know if z_p is actually such a zero-terminated string, or something else. You could write: char someChars[] = { 'H', 'i', '!' }; asdf(someChars); and the compiler would happily let you do that. But the function will not find a terminating zero after the exclamation mark, incrementing the address over and over until it either finds a zero, or tries to read from an address it can't read. 
Oh, okay. I actually the though the loop would print out the memory address of each character until it terminated. Thanks so much! You were very helpful. 
This cleared things up quite a bit. Thanks so much, mean it :D. 
Pointers are elementary when it comes to C and C++, and you will need to understand them if you ever work with any of those languages. Understanding C/C++ pointers and references will help you understanding what happens in memory in any other language, and I cannot recommend learning that enough. Also, for a question this simple, try google. Your google-fu is your best friend when you are programming.
The formatting is italicizing everything between pairs of asterisks, so void asdf(const char *z_p ) { for ( ; *z_p != ‘\0′; z_p++ ) cout &lt;&lt; *z_p; } became void asdf(const char [ITALICS]z_p ) { for ( ; [/ITALICS]z_p != ‘\0′; z_p++ ) cout &lt;&lt; *z_p; }
Yeah, I know. I did some googling, I just wasn't getting whether cout &lt;&lt; *whatever &lt;&lt; endl; would print out the address or the character in the address. 
That is exactly what happened. lol my bad guys
This is functionally equivalent to both of the following: std::cout &lt;&lt; z_p; printf(z_p);
 void asdf (const char *z_p) { for ( ; *z_p != '\0'; z_p++ ) cout &lt;&lt; *z_p; } just to make things clearer
I like to think operators as functions myself. Dunno if it helps, but that statement could be thought as: cout.operator&lt;&lt;(whatever.operator*()).operator&lt;&lt;(endl); This way it is imho clearer that *-operator is evaluated first, resulting the value pointed by whatever. That value is then passed to operator&lt;&lt; of cout, which then prints it to standard output and returns itself. Then another call to operator&lt;&lt; is made, with endl as parameter, which prints newline and flushes the output stream, again returning itself. This return value is then discarded.
We have actually started using google test and mock for our unit tests. The mocking of objects is pretty sweet to handle some of our ipc mechanism and force error conditions.
Your questions a bit silly as it depends. Seriously C++ is perhaps one of the most used languages going. However in your case it really doesn't matter what language you use. Again it is pretty simple, you need to use a language regularly to build up the skill level to use it effectively. Even a casual Python programmer has to put in the time to grasp the platform well. Contrary to popular opinion C++ is suitable for many things including personal projects. With the new C++11 features I expect usage to expand. 
Silly? Dude, I am not new to programming. I've been a web developer for 7 years now. I am well aware that programming in a particular language takes practice before you are proficient in it. I find your response condescending and I hope it is not indicative of the general attitude within this community.
The biggest benefit, and the biggest problem, with managed languages is this: Garbage collection. Garbage collectors must almost always sacrifice efficiency for convenience. Some GCs are optimized to work optimally under specific circumstances, but no GC is optimal under all circumstances. This is why people use C++ in the above mentioned applications — they have a specific memory usage pattern, and they can use the memory more efficiently if they don't have to deal with a garbage collector also.
No, unless you meant printf("%s", z_p). Passing a string directly to printf is a huge security hole (what would happen if z_p was "%n", for example?).
Majoring in math this particular problem should be no problem for you. Just write down on paper how you would do it for some test cases, then find a general way and voila, you can easily code it. You obviously acknowledge the existence of a for loop, so you know a little. And I don't really think anyone is going to make your assignment for you. Have you thought there's maybe a reason they're making you take this C++ class? 
Good luck with finding someone to do your homework.
That wasn't even a good attempt and you presented none of your own thoughts upfront. Besides, Google will give you enough solutions to this exact problem.
what happened to this subreddit? homework-questions all over? I'm here to speak about Sutter and Stroustrup not your dumb assignments… fuck off
Sheesh! Not sure why you got so many down votes except for your argument for C# in a C++ forum. Here's an up. Honestly, I think I would have argued your point a couple years ago and can't quite disentangle if I have been influenced by the opinions of Sutter, et al. or if I've come to my change in opinion independently. If history is any guide, neither of us has any idea how all of this will play out in a decade. With the most recent upgrade to C++, it's becoming more difficult for me to tell the difference between managed and unmanaged code. I mostly use shared pointers in my code (so they handle memory collection for me) and much of the boiler-plate code is drifting away. However, C++ does give me easy access to lower-level memory management -- you have to work against the language to do that in managed code. It's not clear managed code has increased expressiveness to C++, especially if I get my lambdas and templates. Clearly, I'm in a minority community, however I am often attempting to push against the very limits of the hardware in my code. I agree that "most" code written these days doesn't need what my customers do, and clearly there will be tons of Java and C# programmers for the near if not the long term -- precisely because you don't need the additional power. But if I started in managed code to get my users their application, they'd soon be asking me to rewrite it in C or C++ to get the additional 10% they absolutely need. That's clearly not all customers. All that said, I'd like to have a project I could write in C# because the language does look fun. I'm going to take your sentence crafting comment as a complement -- because I am a programmer and quite proud of it. ;)
Agreed. This sub is about "C++", not "Avoiding C++"
&gt; ¿Want to make computer games? Then C++ I would word that as &gt; ¿Want to make graphically intensive computer games? Then C++ If someone wants to learn how to make games, I think they can use any language they are comfortable with that they can setup easily and figure out how to draw stuff on a screen with. BASIC, Processing and Pygame come to mind 
Certainly, a good point. +1 for you.
Perhaps of interest: http://walfield.org/blog/2010/08/25/lambdas-in-c.html
Here you go: int main(int argc, char *argv[]) { if (strcmp(argv[1], "binary input base") == 0) { puts("decimal"); } return 0; }
This is a forum to share articles regarding C++, not a solve-my-homework forum. Get bent, and do your work yourself. People like you polluting the market with a degree you haven't earned are the reason why I waste time interviewing that have no business being developers in the first place.
How can somebody program for seven years and ask the questions you did about C++. The response is not condescending in any way as your question is sillly. C++ value depends upon what you intend to do with it. 
&gt; most of that is tradition not a limitation of C#. No. In some industries, most of that can be a critical business requirement. I was working a few years back on a real-time billing server for mobile networks; "the server" was actually a dedicated server farm, and the performance requirements were for 10000 messages processed per minute and at most one hour of accumulated downtime per year; At that point you wanted no background threads except the ones you defined (i.e. no VM), a perfectly flat memory profile - no new allocations - or deallocations - at all, memory duplicated between threads so there would be no locks and so on. We probably could have written the whole thing in C (yuck!), but C++ gave us OOP and templates over that. A managed language was not even on the table. &gt; It's really little more than managed C++ with some upgrades Not at all. Out of the top of my head, C++ supports template meta-programming and functional programming, (I know there are others) that C# simply doesn't have in it's toolbox. On top of that, it is deterministic (no VM). In all cases where those things matter, C# is not even in the running. &gt; and lets face it managed code is eventually going to take over. For the "typical desktop application" ( that means, probably GUI oriented, using a DB somewhere and requiring _ decent performance^TM _ ) you're probably right. For high quality graphics games, you are not. Nor are you for low level code (have a look at Haiku OS, linux - though linux is in C), performance critical code, embedded systems or simply places where you really don't want managed code at all. For example, the scripting support in your browser is (probably) written in C++, because having a VM running an interpreter that processes JavaScript would be downright stupid (and lead to **I N C E P T I O N**). As another example, I had an interview for a C++ job with a company developing positronic particle accelerators for cancer treatments. Their HW was controlled with a C++ application, because they wanted 100% deterministic behavior (the risks of something going bad were bad enough that they didn't even consider anything managed). &gt; I don't buy the performance argument because in the big picture most of your performance bottlenecks are probably from bad code For amateurish applications ("I wrote a python script to download my gmail") or the typical website or desktop application, you're probably right. For a server platform where weekly performance testing throughout development was a requirement from the design stage of the product, there is no "most of your performance bottlenecks", because the whole server is designed from the ground up to avoid all conceivable performance bottlenecks. At that level you have to be familiar with memory allocation policies (and sometimes implement several of them in several parts of your code), thread synchronization alternatives (i.e. "don't use mutexes at all") numerical methods for approximating a function's results with a faster-implemented approximation, processing parallelization, in-memory databases and others. Managed code just doesn't cut it. On the other hand, the performance argument is not the only argument to consider. For example you may want low-level control (C, C++, ASM, D, ...), C-like performance (ASM, C, C++, D, ...) with higher-level abstractions (C++, D), with good cross-platform support (and suddenly C++ is the only candidate remaining). &gt; I think you'd eventually find that averaged performance and up-time will be higher with managed code, Just "no". This also ignores the cases where the performance is "so critical" that you want to avoid the overhead of the VM itself. It may apply for high-performance applications, but not for performance-critical ones. 
look at the atoi function and then in the cmath header.
I will give every damn homework question a big fuck off if this won't stop! so: FUCK OFF!
That's no good; you aren't handling fractional inputs. I'd suggest reading [Exploring Binary](http://www.exploringbinary.com)'s series on decimal-floating point conversion, in particular [Correct Decimal To Floating-Point Using Big Integers](http://www.exploringbinary.com/correct-decimal-to-floating-point-using-big-integers/); the algorithms discussed are applicable to any base.
[This](http://www.amazon.com/Logitech-Wireless-Solar-Keyboard-K750/dp/B004MF11MU) is the keyboard you want. Short throw, inverted T arrows, wireless, solar.
Very interesting. I'm on Lion. I did export variables on the shell for gcc but when try to compile mprf it says that gmp has another ABI (I put --gmp* flags as on the post) Any clues?
Doesn't work on Lion: https://trac.macports.org/ticket/31171 
Doesn't handle hex very well...
Make me a sandwich.
I did not know c++ had a puts function. I can't believe I actually just learned something from an "OHAI GUYS I CAN HAS MY HOEMWURK PLS" post O_o
Jackass. I haven't programmed C++ for seven years, I've been programming in web technologies, i.e. JavaScript, HTML, CSS, PHP, etc, which an entirely different ball game. Seriously, fuck off. I'll ask any question I feel like asking.
Interesting. Care to back that up with a reference?
I agree with you; I commented on another thread a week or so ago about Ruby code I have written that I now struggle with because of the lack of explicit type information. Auto is great for idiomatic stuff like iterator-based loops, for other things not IMO.
I haven't heard much of use of virtual constructors, but [this](http://www.parashift.com/c++-faq-lite/virtual-functions.html#faq-20.8) could be a useful answer. For virtual destructors, they're pretty much a must if you want to delete the object using the its base class pointer. E.g. if you have a `DerivedClass` that derives from `BaseClass`, and you want the following to work BaseClass* p = new DerivedClass(); delete p; then the destructor in `BaseClass` must be virtual.
There's no such thing as a virtual constructor. It's a fundamentally meaningless concept, and it is unsafe to call virtual methods from constructors. The virtual method table (vtable) for each object is chosen when constructing an object, so no object has a virtual method table before the constructor is called. Any destructor of a base class must be virtual, if an object is ever referred to by a pointer to the base class type — otherwise only the base class destructor will be called when deleting the object, not the destructor of the derived class.
Virtual constructors don't really exist because you always explicitly construct the object. If you do Base *base = new Derived; You have explicitly said you want to construct a Derived, and thus will call the constructor for Derived. Virtual destructors however are a different matter. They exist because your derived class may require additional cleanup that the base class does not, and therefore a virtual destructor is needed when you call delete on a pointer of the base type that actually points to the derived type. If you don't have any additional cleanup (this includes additional members whose lifetime is tied to that of the derived class, but do not require explicit cleanup!), then you can get away with a non-virtual destructor. However, for safety (and sanity)'s sake, you should always declare the destructor of a class you intend to inherit from as virtual.
That is one gap in the type-system IMO. The fact that you have to write a clone method to do virtual copy construction. And even then virtual copy assignment is practically impossible. That would require multimethods or very cumbersome boilerplate. All that being said .. virtual construction is not as common in C++ as in Java because in C++ value semantics is the default, not reference semantics as in Java..
To answer your question... you want a virtual constructor, more commonly called a clone method, when you have a base pointer to a derived object ... and you want to make a copy of that derived object. Usually when you do copies in C++ though you are working with values ... and those are easy to copy. Virtual destructor are more common. They are used to ensure that when you delete a base pointer, that the destructor of the derived type is also called. You wouldn't want only the base destructor to be called. If you use values instead of pointers you can completely avoid think about any of this stuff. 
Virtual constructors aren't supported directly by the C++ language, but they can be simulated as ICantThinkOfNothing says. Take a look at http://www.parashift.com/c++-faq-lite/virtual-functions.html#faq-20.8
&gt; and it is unsafe to call virtual methods from constructors. "Unsafe" is unclear. You can call virtual functions from a constructor. It will work just fine. However, the type of the object in `C::C()` is always `C`, and never any derived type. 
&gt; However, for safety (and sanity)'s sake, you should always declare the destructor of a class you intend to inherit from as virtual. If a class has at least one virtual function, the destructor shall be virtual. If a class has no virtual function, but you expect to inherit from it, it depends on the use. For example, `std::binary_function` doesn't have a virtual destructor. When in doubt, put a virtual destructor. And most of the time, the destructor will actually be empty: struct C { virtual ~C(){} //... }; 
I don't think std::binary_function is a really good example for this. std::binary_function is not something used for traditional inheritance, but rather is an interface for polymorphism through template programming. For templates that take binary_function as a template parameter, you could instead pass your own class so long as it satisfies the following criteria: * It has a typedef called first_argument_type * It has a typedef called second_argument_type * It has a typedef called result_type * It has an method result_type operator()(first_argument_type, second_argument_type) However, binary_function already has the first three defined using its own template parameters, and thus is there for your convenience. In some cases, you probably don't even need the first three typedefs, only the operator() is used and thus that's all the compiler requires. Also, having a virtual method does not imply you need a virtual destructor. You could, for example, have a strange set of classes like this: struct binary_integer_op { int arg1; int arg2; virtual int operator()()=0; }; struct add_integer_binary_op : public binary_integer_op { virtual int operator()() { return arg1 + arg2; } }; struct sub_integer_binary_op : public binary_integer_op { virtual int operator()() { return arg1 - arg2; } }; If that is the whole extent of the use of this set of classes, then there is no requirement that says you must have a virtual destructor. The destructor for the abstract class will do just fine in cleaning up for its two subclasses. This is only dangerous because in the future someone might decide to do this: struct keep_result_add_binary_integer_op : public binary_integer_op { int result; virtual int operator()() { result = arg1 + arg2; return result; } }; Now the destructor for binary_integer_op is no longer sufficient for cleanup. Note that if you did this for binary_function, in most cases it would be no problem because binary_function is only an interface for a template, and thus when you template it on your new class, the expanded template will explicitly use your class rather than some binary_function\*. But if someone decided to take a binary_function\* (which is ridiculous, it has no members/methods already defined) and carry it around your derived class would face similar trouble.
There are some nice lines of reasoning that can tell you whether, in a particular instance, it is safe to not have a virtual destructor. Do you trust everyone else maintaining your code in the future to think about the issue, to be aware that changes they are making might invalidate them, and to insert one at need? So think about the question from the other direction, too: *measure* the performance impact of having a virtual destructor, and if the impact is trivial, you might as well have one. And think about this: if you are spending a significant amount of time bouncing in and out of destructors in your application, it is just barely possible that you have some opportunities to improve your code ; ) 
&gt; is not something used for traditional inheritance, I suppose by "traditional" you mean "Java-style" inheritance. Basically, there are two distinct reasons to have base classes in C++: To use dynamic polymorphism, and to group functions (or variables) common to several classes. In the first case, you necessarily have a vtable; in the second case, it's usually not necessary. In both cases, if you want to be perfectly safe, it's better to put a virtual destructor. But in both cases, it may not be necessary. Example: struct B { virtual void foo()= 0; }; struct D: B { virtual void foo(); }; void bar (B&amp; b) { b.foo(); } int main() { D d; bar (d); } If you use dynamic polymorphism, you already pay for the vtable, so adding a virtual destructor is a free seatbelt. &gt; struct add_integer_binary_op : public binary_integer_op Note that the `public` here is pretty useless. (In fact, another rule of thumb I have is that I use `struct` when everything is `public`, and `class` if I need `private` stuff.) &gt;Now the destructor for binary_integer_op is no longer sufficient for cleanup. Are you sure about that? I think the memory cleanup will work fine. If you replace `int` with a class that has a nontrivial destructor, OTOH... 
&gt; In both cases, if you want to be perfectly safe, it's better to put a virtual destructor. This is more or less what I said. &gt; Note that the `public` here is pretty useless. That is not what `public` means when it comes to inheritance. It is entirely necessary if we want our expected polymorphism. Private inheritance allows you to access the `protected` and `public` members/methods of the base class, but does not expose the public members/methods of the base class to outside classes. Thus, if it were privately inherited, you could not convert an `add_integer_binary_op*` to a `binary_integer_op*`. &gt; Are you sure about that? I think the memory cleanup will work fine. If you replace int with a class that has a nontrivial destructor, OTOH... No, I'm not entirely sure. I don't know if this behavior is specifically defined in the spec (if someone could point it out to me, it'd be great to know). But the idea is the same.
&gt;&gt; Note that the public here is pretty useless. &gt;That is not what public means when it comes to inheritance. Uh... What? I didn't say anything about its meaning. If you use `struct`, everything (members and inheritance) is `public` by default. If you use `class`, everything is `private` by default.
&gt; Do you trust everyone else maintaining your code in the future to think about the issue, to be aware that changes they are making might invalidate them, and to insert one at need? Nope, but I do trust the compiler to complain. (Unfortunately, for some reason, `-Wnon-virtual-dtor` doesn't seem to be included in `-Wall` any more in recent versions of g++. I really wish they would stop changing the meaning of their options every other day.) 
My mistake. I forgot that struct also changed the default inheritance.
Well, you can call pure virtual functions from a constructor, but it won't "work just fine". :P
You can not call a pure virtual function from within a constructor. Fabien4 is correct that when a function F is called from within a constructor for type C, it is strictly a call to C::F. If C::F is a pure virtual function then it will fail to build, more specifically you'll get a linker error that C::F has no definition.
Technically you are right, C++, the language, has no concept of virtual constructor, but you can always emulate it with a factory method that dispatches manually on the constructor arguments. From the perspective of the client, it's equivalent to virtual constructor.
There are many, many very helpful people in the C++ community. Andrei Alexandrescu (who's written quite a few C++ books) and Walter Bright (who wrote one of the first C++ compilers and who has a company that still sells up-to-date C++ compilers) frequent Reddit and are helpful. There are also very many other helpful people who use C++ professionally who visit here as well as other forums. Anyway.... Yes, C++ is still relevant. I think it would be useful to expand your knowledge. It is certainly different than what you're used to. I find that learning new languages -- even if I won't be using them professionally -- helps me learn new ideas that I can implement professionally. I program C++ full time, with a bit of C# and Python at work. I've been learning OCaml, F#, and Objective-C recently.
&gt; There isn't Java or C# inside a missile warhead, an implanted medical device or a 6-axis CNC machine. Actually there is. (I know because I worked on it.) The C# code though is just in the HMI GUI ([this product uses C#](http://www.beijerelectronics.com/web/beijer_electronics.nsf/AllDocuments/DC5CB208D50ED234C125736B0023E0D2)). The controls are all C, C++, and ASM.
You are mistaken sir. My company pushes the performance of processors -- not because we need stellar performance, but because if $5 can be shaved off the price of a processor then that can be 1/2 million dollars of the life of a product (not to mention the extra parts higher-performance processors require like fans). And the difference between high-performance x86 processors and cheap PPCs or ARMs much more than $5.
&gt; "Unsafe" is unclear. Yeah, the reason I chose that word is that I was not entirely sure what behavior is guaranteed by the standard, and what isn't. Thanks for clearing it up. :) I would always recommend against calling virtual methods in constructors and destructors, anyway.
Can you elaborate on what would be the semantic reason to view a virtual factory method as a "virtual constructor"?
The C++ specification states that this behaviour is undefined - there's nothing preventing the compiler from allowing you to make that call. In fact, practically all compilers *will* allow you to perform a pure virtual function call from within a constructor so long as you do it indirectly. Observe: class Base { public: Base() { Bar(); } virtual void Foo() = 0; void Bar() { Foo(); } }; class Derived : Base { public: virtual void Foo() {} }; int main() { Derived b; } This will appropriately explode at runtime.
This needs to be said louder, methinks.
*.aspx?
It's a form of dispatch. With virtual functions and virtual destructor the dispatch is on a type of "this" pointer. Virtual factory method doesn't have an instance, but it can manually dispatch on argument types or, more commonly, values.
Alright, that does make some kind of sense, I guess. I would probably still avoid the term "virtual constructor" in this case, because it's potentially quite confusing, given the existence and well-definedness of virtual destructors. :)
This is not a question/answer forum. Do a proper search on stackoverflow.com or something!
Odds are you have asked for help, just not directly. If you've ever researched an algorithm, or looked up some API quirk, or some other issue you couldn't solve on your own, you were finding answers to questions other people already asked. 
There are compilers/linkers that do not enforce this. I have the digital shrapnel wounds to prove this.
Thank you! A helpful response. Much appreciated :) Do you know of any books in particular that are good for learning the language? I am currently reading "C++ Primer Plus" as I've heard it's good. There is Bjarne Stroustrup's books, but I think they are a bit heavy at this stage. I will look up material by the names you mentioned.
&gt; If a class has at least one virtual function, the destructor shall be virtual. No, it shall not *be* virtual, you should *make* it virtual.
[Here's a great list](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list).
Awesome. Thanks!
&gt; You have to do some serious mental arithmetic to find out the interface of the first level, the second, and so on. I like statically typed languages especially *because* of this arithmetic. It is something I always do, be it in a language with full type inference, a language with `auto`/`var`, or a language with explicit/manifest typing. It's simply how I reason with code (and more largely with ideas), in fact in dynamically typed languages. So I can't even begin to understand the argument about `auto` because for me it's a feature to save typing and is not related to using types (I can't stop using types). If you feel the need to put a type check into code, then dispense with `auto` for that case and explicitly mention the type, the way one uses type annotations even in a language with full type inference.
First, **construction** in C++ is never virtual (If I remember correctly virtual functions are not guaranteed to be defined until the constructor has finished running). Second, if you use inheritance, only the most specialized destructor will be called unless you declare the destructors as virtual (that means "unless you have a very good reason to keep a destructor non-virtual, make it virtual"). There is also a pattern called "virtual construction" or "virtual initialization". You do this by creating a virtual (public or protected) initialization method, and calling it after the object has been constructed.
&gt; only the most specialized destructor will be called Actually the destructor of the the static type of the pointer you're calling delete on will be called, plus any of that type's supertypes' destructors.
Thank you all for making it so clear. Really appreciate.
Create a move assignment operator first, then your move constructor looks like this: object::ctor( object &amp;&amp; that ) { *this = std::forward( that ); } 
This will almost work. A proper move assignment operator will free the current value, which looks as if it was left uninitialized. As well, std::forward is only called for when using special rules for &lt;class T&gt; T&amp;&amp; references (which can take on either an rvalue or lvalue reference); here you should use a "std::move(that)" instead. However, a simple pattern that _does_ work is to define a move constructor, then a single, value based assignment operator that works with both move and copy semantics. If you have a swap operator, the definition is: object::object(object&amp;&amp; that) { // move values from 'that' into this } object&amp; object::operator=(object that) { this-&gt;swap(that); return *this; // &lt;-- this formulation } void object::swap(object&amp; that) { // swap each field between *this and that } This definition is exception safe and correctly avoids lifetime management issues. You don't need to explicitly free from operator=; the temporary object will do that for you. One operator= definition works as both a move and copy assignment; if rvalue, the argument will be move constructed, else copy constructed. While this formulation is "clever", it cuts down on redundant code (separate move/copy assignment), and is formulaic; the user doesn't need to modify the formula, further reducing risk of defects. For example, a simple smart pointer like the one in the article: class block { size_t len; char* p; public: explicit block(size_t len) : p(new char[len]), len(len) {} ~block() { delete[] p; } block(block&amp;&amp; that) : p(that.p), len(that.len) { that.p = 0; } block(const block&amp; that) : p(new char[len]), len(len) { // NOTE: nowbacktowork noted this copy ctor is buggy! See later comments memcpy(p, that.p, len); } block&amp; operator=(block that) { this-&gt;swap(that); return *this; // &lt;-- this formulation } void swap(block&amp; that) { std::swap(p, that.p); std::swap(len, that.len); } }; Edit: corrected my initial misunderstanding, nowbacktowork's code is closer to working than i originally thought. Also, expanded code samples. Edit-2: removed unnecessary move() call in operator=(). Added bug notes elsewhere.
&gt; object&amp; object::operator=(object that) { &gt; this-&gt;swap(std::move(that)); return *this; // &lt;-- this formulation &gt; } But this code makes a copy of the argument, which means that you have don't actually have a move assignment operator, you only have a copy assignment operator.
I think you might be confused, let me try and address the issues here individually. Also perhaps if you saw my move assignment operator you will better understand the purpose. object &amp; object::operator=( object &amp;&amp; that ) { if( this == &amp;that ) return *this; std::swap( this.member, that.member ); /*or if the member supports it*/ this.member = std::move( that.member ); return *this; } 1. dtor: here you are missing a check for nullptr before calling delete. 2. move ctor: here are you not resetting the value of len, this can be accomplished through std::swap. 3. copy ctor: here are you are missing a check for nullptr before you memcpy. 4. move by value operator: here are you missing a check for self assignment. your parameter is being passed by value so you are essentially swapping memory a completely new object. 5. swap function: this function takes an lvalue parameter not rvalue parameter, this code shouldn't compile. There isn't a swap operator, what you have essentially done is moved what should be the guts of your move assignment operator to a utility function, swap. I use this concept which I have shown in a multi-threaded client/server application which makes heavy use of stl containers. I hope this helps clear up the confusion. The move assignment doesn't have to free the current value if it swaps the data values with object being moved. when that object goes out of scope, its members should be freed. And forward isn't completely necessary and could be replaced with std::move, you were correct here.
&gt; this code makes a copy It does not copy if you pass an rvalue. Rather it invokes the most suitable ctor — in any case where overload resolution would have chosen move assignment, this formulation will result in ’that' being move constructed. Additionally, if no copy ctor exists, calling with an lvalue is an error, just as it would have been with operator=(object&amp;&amp;)
Thanks for taking the time to reply; let me take these one at a time. &gt; \1. you are missing a check for nullptr before calling delete delete (and delete[]) of a null pointer is valid, and has no effect, so this code is correct. &gt; \2. move ctor: here are you not resetting the value of len There's no need to in this case, but i should document the invariants. "if p, len is the length of the buffer. if !p, len has no meaning". Since that.p == 0, any value of that.len is valid so we skip touching it. By keeping the move constructor small, it increases the odds that it will be inlined, which we generally want. &gt; \3. missing a check for nullptr before you memcpy *gasp* you're entirely correct. I should have written block(const block&amp; that) { if (that.p) { p = new char[that.len]; len = that.len; memcpy(p, that.p, len); } else { p = 0; } } This is what happens when I'm not paying close attention :-) &gt; \4. you are missing a check for self assignment It is self assignment safe, but you're right to point out that it can't check for self assignment either. If one writes "x = x;", a copy of x will be made, and then assigned. If one writes "x = std::move(x)", then x will be moved into the argument 'that', and then moved back. Keep in mind that conditional branches are one of the more expensive operations you can perform. If self assignments are common, you'll want to use a different pattern as the unnecessary copy constructions will hurt you. However, if they are rare, this form is preferable as it doesn't tax your branch predictor. &gt; There isn't a swap operator I don't understand what you mean. My swap operator properly implements swapping. &gt; what you have essentially done is moved what should be the guts of your move assignment operator to a utility function, swap I agree with this entirely. I prefer this formulation because, in my limited experience, I've observed peers having an easier time implementing swap than implementing move assignment. In practice, I actually recommend this along with your move constructor, to avoid unnecessary bugs: "object(object&amp;&amp; that){ /*initialize an empty value*/ *this = std::move(that); }". However, this form does tend to create some sizable unnecessary work for the optimizer (or, if it fails, unnecessary runtime work). It really depends on your audience; most of the time, developer efficiency is more important than a micro-optimization, but you'd want to hand-write the move constructor in library functions. But in general, one can write really efficient code by writing a single move constructor, then using move-construct-temporaries as a very cheap and trivially correct way to uninitialize things. E.g. { auto tmp = std::move(x); // x is now empty, but its value is kept alive until // end of scope, e.g. if x was holding references to // some other objects we were using } &gt; I hope this helps clear up the confusion Some. I should be clear; I think the way you've demonstrated writing move construction/assignment is generally fine too. One should choose the appropriate option for the task, and writing a new implementation afresh carries some addition costs/risks, but can also carry greater reward. It all depends on your goals. &gt; The move assignment doesn't have to free the current value if it swaps the data values with object being moved. Actually, not clearing out the current value can cause subtle problems, which is why the STL libraries provide the post condition of move constructors / assignment that the moved from value be empty. For example, from the C++11 draft spec for shared_ptr::operator=(shared_ptr&amp;&amp; r): Effects: Equivalent to shared_ptr(std::move(r)).swap(*this). And from its move constructor: Postconditions: *this shall contain the old value of r. r shall be empty. r.get() == 0. To see why, consider this correct (and reasonable) program that would become incorrect if we removed this post condition: struct listnode { shared_ptr&lt;listnode&gt; next; } void remove_next(listnode&amp; node) { if (node.next) { node.next = std::move(node.next-&gt;next); } } With node = a, and a =&gt; b =&gt; c being links in the list, consider if operator= behaved as swap. In that case, a.next == &amp;c, which is desirable, but then "node.next-&gt;next", which refers to b.next, would be set to point to the present value of node.next, which == &amp;b. That is, b.next == &amp;b. The node 'b' now contains a reference cycle, leading to a leak! In other cases, the resource simply gets held longer than absolutely necessary. In any case, it's wasteful, so when designing move constructors / assignment, you should always remember to empty the original object. In my formulation, the move constructor does that duty. You can also do this by "object(std::move(x)).swap(y)" to move x into y. Or, if you don't know the type of x, you can "{ auto tmp(std::move(x)); tmp.swap(y); }" and tmp will be destroyed at that end curly brace. Pardon the long post! You took the time to write all that out, so I wanted to make sure I properly addressed your comments. Thanks for bearing with my verbosity!
Correction, it was late when i wrote this, and I was not referring to a previous implementation. The std::move in operator= is superfluous. It should be: object&amp; object::operator=(object that) { this-&gt;swap(that); return *this; // &lt;-- this formulation }
I see now looking back at your example after your explanation. You are essentially turning one move operation into two and letting the compiler take care of optimizing simpler operations for you. { i = 0, j = 1; //now swap em y = i; i = j; j = i; } Looking at your explanation I like the pattern very much. 
&gt; letting the compiler take care of optimizing simpler operations for you That's exactly it! Glad you enjoy it. Like I said before though, both ways are valid. If the data type is likely to be used in a performance critical path, it might be worth the extra time to hand tweak each of the constructors/assignmenets individually.
Shame about the GPL. And no I don't want to "Contact" about pricing. Put a damn developer license price on the web site.
&gt; I like the pattern very much. As an FYI this is the copy-and-swap idiom. edit: come to think of it, I guess the proper name now is construct-and-swap.
We will put pricing on the web, we are just working out the kinks to avoid confusion. Also, if you had a chance dealing with us, you would know we are not your typical cut-throat, sales-driven corporation. If you do contact us, we won't ask you for a laundry list of information or bug you for the rest of your life. Plus the license prices are more than reasonable (that's what we were told, anyway). So give us the benefit of the doubt, I am pretty sure you will be pleasantly surprised. Also, regarding the GPL, note that if you only use your application within your organization, such as running it on your company's servers, then you can use ODB without worrying about any of the GPL restrictions.
more like construct-copy-swap...
Well, that seems unfair. The idiom is not called copy-copy-swap, so I don't see the need to now call it construct-copy-swap :) I guess it *is* an argument to call it move-and-swap though...
A complete guide would be a good thing.
Oh! I see; that's cool. :-)
This is wrong on so many levels...
Ignore the licensing nerds, GPL/Commercial is a great way to give, and get. Looks interesting but I will agree there should be some sort of pricing on the webpage
?
&gt;Discussions and articles about the C++ programming language or programming in C++ It says right in the description it can be used for this purpose.
This article is so wrong! Does anybody at Microsoft know C++ at all? Their copy assignment operator is not exception safe. You should get kicked in the balls for such kind of blatant mistakes.
about the same thing, it's developed at my university: [Includator](http://includator.com/)
The problem with these tools (disclaimer: I wrote one myself) is that it's merely damage assessment. A "repair plan" would likely require symbol-level analysis: where to recommend a formward declaration, PIMPL etc. I'll try that tool on my "big bad codebase example" when I'm back in the office.
Just to nitpick: the true generic version would use the begin(), end() functions instead of members(for the case that you use MyArray&lt;T&gt;::Begin() for example) 
Good point!
&gt; class B; &gt; &gt; class A { &gt; A(); &gt; B *_b; &gt; static const int SIZE_OF_B = 20; &gt; char _b_storage[SIZE_OF_B]; &gt; }; &gt; &gt; // a.cpp &gt; &gt; #include ”b.h” &gt; &gt; A::A() &gt; { &gt; XASSERT(sizeof(B) == SIZE_OF_B); &gt; _b = new (_b_storage) B(); &gt; } This is actually incorrect since class B can have stricter alignment requirements than the memory "allocated" for it using the char array. [This blog post](http://www.codesynthesis.com/~boris/blog/2010/07/20/pimpl-idiom-without-dynamic-allocation/) describes how to correctly implement this technique. 
Looks interesting, shame it's only for Eclipse.
as we are forced to use eclipse because the c++ course includes [CUTE](http://cute-test.com/) tests, and as the only plugin is for eclipse, it's not really a problem anymore. i think they just want to advertise their products to us students (those two are developed at the Software institute in our university)
this is super duper jigga bigga digg
After you start to think you know it all, the next logical step in learning is to teach. You will find gaps in your knowledge while consciously trying to formulate the answers.
Very nice presentation and some surprising (for me at least) facts. On a side note, did anyone else experience a significant slow down of loading the next slide about halfway through?
PDF version: http://www.pvv.org/~oma/DeepC_slides_oct2011.pdf
&gt; On a side note, did anyone else experience a significant slow down of loading the next slide about halfway through? Yup! Couldn't make it to the end before I ended up having better things to do than wait for another arrow to load... It's a pity, I loved the parts I saw!
I wonder if this slowdown allows conclusions about the underlying implementation of the page. I assume the slowdown comes from some weird construct where the server actually iterates through all slides from the beginning instead of directly accessing the requested page.
Thanks!
I wondered the same thing. It's inherently impossible to tell, but it does appear as if viewing page `n` is an `O(n)` operation. :) Perhaps the server has the slides stored in a linearly compressed format, so it needs to decode the entire series up to page `n`. PDF could cause that.
Yup, noticed the side effect. Found out that if you refresh the page, and enter the page number you were and press enter, it starts fresh again for some reason. See also a .pdf version someone linked in comments. 
I knew most of the stuff the girl pointed out. Some references to why the people who made the standard came to a certain conclusion and the likely output of unspecified behavior I did not know though -- but these aren't really part of the languages. But one thing is for sure; that girl comes off as super stuck up -- a language lawyer. She might be the perfect candidate for writing a compiler or as a consultant providing a finished library or application. She likely would not get along well with a team though with her attitude and I would not want to hire her where team dynamics are important. (Her knowledge is fine as long as she could get along with others ... but in these slides she doesn't show that.) I would expect good, knowledgeable candidates to point out things the language specifies without going on and on with speculation and trying to "show off". Anyway, I know the point of the slide show was to learn some new things about the C and C++ languages, not how to really interview someone. That's fine. I can get behind that. I just don't want some programming manager to accidentally come across this and then expect good candidates to act like the girl.
Is the example on page 171 correct? I though left to right was specified, and because puts is a call to an external compilation unit the ordering has to be respected.
&gt; I would expect good, knowledgeable candidates to point out things the language specifies without going on and on with speculation and trying to "show off". Someone is a little defensive.
It is correct, see 1.9 p15: "Except where noted, evaluations of operands of individual operators and of subexpressions of individual expressions are unsequenced." 
Well, maybe. I admitt it is difficult for me to be objective. I will say though that I haven't had to be an interviewee for a long time, but I have interviewed perhaps two dozen people this last year and many, many more over the last 5 years. I really don't want my company hiring someone who acts like the girl. Her knowledge: good. Her attitude in the slide show: bad.
I'm not going to do your homework for you, but I'll give you a hint: char a = 'a'; What value is stored in a?
Left to right is specified in Java, but not C/C++.
This is exactly what I was thinking.
&gt; and while she is on the roll, she might continue with: &gt; &gt; &gt; What will happen if you try to compile, link and run this program?If this is C99, the exit value is defined to indicate success to the runtime environment, just like in C++98, but for older versions of C, like ANSI C and K&amp;R, the exit value from this program will be some undefined garbage value. But since return values are often passed in a register I would not be surprised if the garbage value happens to be 3... since printf() will return 3, the number of characters written to standard out. &gt; &gt; Also, if you allow me to be a bit pedantic... the program is not really compliant, as the standard says that the source code must end with a newline. \[While discussing C code\]: &gt; Why do you think static variables are set to 0, while auto variables are not initialized? &gt; &gt; &lt;snip...&gt; &gt; &gt; &gt; &gt; And to be precise, in C++ however, static variables are not set to 0, they are set to their default values... which for native types means 0. \[After discussing structure sizes\]: &gt; So what about this code? &gt; &gt; &lt;snip...&gt; &gt; &gt; And by the way, it looks weird to specify func(void) instead of func() as void is the default in C++. This is also true when defining the main function. Of course, no kittens are hurt by this, it just looks like the code is written by a die-hard C programmer struggling to learn C++. &gt; &gt; Are you compiling with -Wall? You should consider -Wextra - pedantic and -Weffc++ as well. Without warning flags you might not notice the mistake here. But if you increase the warning levelsl it will scream the problem in your face... The principle of compiling with warnings turned up is a good one. But she comes off quite ... err... preachy here. A simple "the compiler would likely alert you to the problem if warning flags are turned up all the way" would suffice. (I have to say I'm surprised she didn't mention the -Werror flag given everything else she spouted off.) \[In code that uses one class member variable named 'sz_' -- which there is no problem whatsoever in using\]: &gt; &gt; You seem to use different naming conventions for private member variables, but as long as it is private stuff I think you can do whatever you want. But I guess either postfixing all member variables with _ is fine, so is prefixing with m_, but you should never just prefix with _ because you might stumble into reserved naming conventions for C, Posix and/or compilers. EDIT: Formatting
It'd be funny if his teacher said that the input is using another character encoding. 
It's the way she said it, not what she said. I could have expressed the exact same sentiments but on the listeners level as opposed to a golden pedistal.
Exactly!
Definitely, but doesn't the [C++ reference](http://en.cppreference.com/w/cpp) wiki cover it?
I've got an honest question for you, as a 'language lawyer' How can we answer questions asked of us without the appearance of "showing off"? Here's my problem: I entirely enjoyed the language lawyer (LL) here. Conversely, I found the non-LL guy to be _flaunting_ his willful ignorance. Pardon again if I've made the same error as the girl. Honestly, most of us are just trying to help others by using the knowledge we've gathered and practiced at great effort. Some of us are trying very hard to help. We're already self-conscious from being accused of "showing off" when we're only trying to help, and trying to set aside our own discomfort with others behavior while trying to help them. Is there something we should be doing differently?
I've integrated something like this into my own C++ dialect; it's pretty useful when you need to generate something that would be otherwise generated by an external script, though keep in mind that the effort necessary to integrate this into your build setup might not be worth the effort if you're not going to use it heavily.
&gt; How can we answer questions asked of us without the appearance of "showing off"? You keep your answers on topic and do not elaborate unnecessarily and without such a "know-it-all" attitude. There are times to elaborate, but the girl elaborates way too much. When dealing with a team, people will start viewing this type of person as a "know it all" with an "I am better than you" attitude. That destroys teams. &gt; Here's my problem: I entirely enjoyed the language lawyer (LL) here. Conversely, I found the non-LL guy to be flaunting his willful ignorance. I understand; the LL-girl actually reminded me of ... *me* before I learned through 5 years of tutoring individuals and groups and several years of working on a development team. Obviously, they picked two extremes (and I understand that for the purpose of the presentation). And I would never hire the non-LL guy. (The LL-girl would certainly be higher on my list than he, but she wouldn't be at the top of my list.) &gt; Honestly, most of us are just trying to help others by using the knowledge we've gathered and practiced at great effort. There are ways to better communicate though when helping someone. She will appear like that "know it all" in high-school trying to spread their knowledge about math to you. The information may be correct; you may even be interested in the material; but you won't want to get to know or work with her. I'm all for helping others; I actually fulfil the language-lawyer role with the company I work for, but people come to me asking questions; I've received high marks in my yearly reviews about working with people, making people feel part of a team, and mentoring them. I have not (according to my manager anyway) alienated people. I'm not perfect in my communication, but I do strive very hard to mentor while still building a team. &gt; We're already self-conscious from being accused of "showing off" when we're only trying to help, and trying to set aside our own discomfort with others behavior while trying to help them. &gt; &gt; Is there something we should be doing differently? When asked a direct question, answer it and in general don't elaborate. If you really feel like elaborating will add a fair amount of value, then elaborate on one or two small points -- don't go off on a long tangent. Get an understanding of your co-workers' attention span and don't test that attention span. When reviewing code, explain why certain non-important practices are better. (Obviously, important details must be dealt with.) Try to stick to a couple of closely related points. Don't overwhelm someone; stuff will come in time. Send interesting articles, news, and tutorials to the developer e-mail list. A note such as "Hey guys, here's an article I found interersting. I thouht you might be interested" works well. An e-mail that says "Hey guys, you should read this. It will improve how you do things" can offend. Look to mentor new employees. Those with little experience, you can show them the best way to do things. Those with experience, you can explain why something is done in the company the way it is. When bugs or problems arise, offer solutions and show how it is easier. People will listen when you can demonstrate simplicity. When you work on designing new stuff, do it in such a way that people see the simplicity and/or elegance. People will recognize your talent, then seek you for help. Endear your co-workers to you. Engage your coworkers in non-work activities; go have a beer with them sometime. Bring cookies to work, or if you have a fruit tree or garden some stuff to share. Talk to them about sports, their vacations, photography, or whatever interests them. Show them you're a real person. Lastly, and most importantly, talk to your manager frequently how you are doing in your communication with and mentoring of others. Find out from them what the best approach is to communicate something to that person. A good manager will have a good feel for how the people under them work and learn and will also have a good feeling for how people view you. Remember, team first, coding quality second. You will not be able to improve the quality of the project alone and you will be alone if you alienate people.
It might be an `O(n)` operation if separate transitions show as different slides.
I wonder if this could be added to gcc as a plugin, in the wake of [this](http://lwn.net/Articles/459982/) recent LWN article. [Also related](http://gcc.gnu.org/ml/gcc/2011-06/msg00293.html)
I don't understand slide 159. Due to precedence, doesn't **a** get incremented to 42 with ++, then assigned to itself? Sure it's undefined by the spec, by won't the compiler do the above?
Precedence does determinate that `++` has higher priority than `=` here and the line is equivalent to `a = (a++);`. The problem is that the side-effect associated with `++` is not guaranteed to have happened until the next sequence point, which is not until the semi-colon. In such an expression and on a very pedantic level, `a++` doesn't mean '`a` get incremented to 42', it means 'return the value of `a` and schedule `a` to be set to `a+1`'. However the assignment means 'schedule `a` to be set to the value of the expression on the rhs'. That's two writes in the same window between sequence points, and that's UB according to the Standard.
Could definitely go for another 2000 pages of this...
Thanks for clearing that up. So if the compiler is very good it will spit out an error, otherwise it gives arbitrary order to the writes. &gt; and on a very pedantic level Ah, the only level to really approach these problems :)
Note that if you're more interested in C++ that C++11 has changed its approach. There are no sequence points anymore, the new concept of 'sequence before' is used instead. Additionally, some things that were UB before are now unspecified behaviour or even well-defined behaviour, for instance ~~~`i = i++ + 1;` (which is equivalent to `i += 1;`)~~~. Looks like the SO answer below got that wrong. Tons of (C++) information on [this](http://stackoverflow.com/questions/4176328/undefined-behavior-and-sequence-points) Stack Overflow question, the two leading answers are concerned with C++03 and C++11 respectively. It's more accessible than reading Standard text, although that's not saying much.
I don't feel like creating an account to point out slide 159 is wrong. Undefined behavior includes (from draft n1256.pdf which is the 1999 ISO C standard with the technical corrigenda integrated): &gt;NOTE Possible undefined behavior ranges from ignoring the situation completely with unpredictable results, to behaving during translation or program execution in a documented manner characteristic of the environment (with or without the issuance of a diagnostic message), to terminating a translation or execution (with the issuance of a diagnostic message).
I liked this, but anyone who is bothering to read this is probably more blonde guy than smart girl, so constantly insulting the blonde guy about getting him an ice cream is kind of a stupid position to take when writing. To be honest, many of the C++ "programmers" I've met make the blonde guy look pretty knowledgeable.
There's also [cog](http://nedbatchelder.com/code/cog/).
I think you'll get more feedback if you ask your questions as precise as you can. The term "to show" for example doesn't make it clear if it's related to printing a number or if it's more related to manipulating strings. There are many Websites about learning C++, but also many good books. (I like [C++ Primer](www.amazon.com/Primer-4th-Stanley-B-Lippman/dp/0201721481/).)
Yes, I totally am. Just FYI, do you already know this site? [C++11 FAQ by by Stroustrup](http://www2.research.att.com/~bs/C++0xFAQ.html)
Can you describe what you're trying to do? Are you trying to remove the first character? Multiply by 100? Show all digits after the decimal? You're making us guess what your question is.
pseudo code inc: x = 0.48f; while x mod 1 is greater than 0 x *= 10; I haven't tested this so let me know if it works, the mod operator is easy to get mixed up.
$403!?
Heres my code.. #include &lt;iostream&gt; using namespace std; int main() { cout &lt;&lt; "How many pennies do you have?"; int count; cin &gt;&gt; count; double total = count * 0.01; cout &lt;&lt; "How many nickels do you have?"; cin &gt;&gt; count; total = count * 0.05 + total; cout &lt;&lt; "How many dimes do you have?"; cin &gt;&gt; count; total = count * 0.10 + total; cout &lt;&lt; "How many quarters do you have?"; cin &gt;&gt; count; total = count * 0.25 +total; cout &lt;&lt; "Total value = " &lt;&lt; static_cast&lt;int&gt; (total) &lt;&lt; " dollars" &lt;&lt; " and" &lt;&lt; total - static_cast&lt;int&gt; (total) &lt;&lt; " cents"; return 0; } Whenever I run this I get an outcome like : "You have 2 dollars and 0.48 cents" I want the 0.48 to show just as 48 
Thanks for the link!
* For a light use or as a starter to manual edits, something like ' find . -name '*.meta' | xargs python metapy.py' should be enough. * For a heavy use, the integration in the build system is clearly needed. I posted an example for cmake (see the README) and it's quite simple.
Why not just multiply by 100?
Here is the free draft: http://open-std.org/JTC1/SC22/WG21/docs/papers/2011/n3242.pdf
... and the one identical to the pay one: http://www.open-std.org/jtc1/sc22/wg21/prot/14882fdis/n3290.pdf. It's password protected ... but I wont judge if you see that as a challenge.
&gt; &lt;&lt; total - static_cast&lt;int&gt; (total) * 100 &lt;&lt; like that
You could also try [include-what-you-use](http://code.google.com/p/include-what-you-use). It is a very nice tool built on the [clang](http://clang.llvm.org/) compiler. It uses the full power of the AST.
Yeah, especially since the mod operator wouldn't work here. You'd need `fmod`.
If your teacher told you to use doubles that's fine, but in general you should never do that for things like money. Use an integral type (like long) for how many pennies you've got. Otherwise your math will start doing things that money shouldn't do.
I don't get why they charge for it. They'd better be making a significant amount from it. Does anyone know? I assume it's dwarfed by the tenure or other salary to the authors.
I disagree with this post. I bought it last week and am on page 155 (Chapter 9, Classes) The book is written and praised for being in a different format from others. Praised because it writes real programs first, showing you both the benefits of C++ and the most useful features for nontrivial stuff. Whilst the idea seems nice, in practice it's quite hard. You go down a "I know one way of doing this approach". I'm sure it leads to a class full of students who use Vector&lt;&gt; for every single data structure, because the book presents over 100 pages of it and discussion of map and list are tiny in comparison. A structure shows up on page 52 in an example program in one form and is never discussed again. (I think it's actually in the next chapter), so that knowledge isn't transferable until this point because I've only seen one example and I'm not sure what the side effects are, how it can be expanded and used. What it is capable of. Somewhere else a random function pointer shows up, in a function parameter list. I can't find it, but it's around page 80~. I haven't seen that again either yet, so there is no transferable knowledge really. I know function pointers from C but had I not, that would have been nothing but a stalling block, detracting from the rest of the example. I could say the same about throwing Exceptions as well. The impact of throwing an exception in chapter 3, when the reader has only seen maybe 4 examples of different flow control techniques looks like it's there purely because it's a C++ feature not in C, rather than being because it's the right time to introduce it. You're forced to read the book in it's entirety and sequentially less you miss some tid bit or feature that would be useful. Some things it does get right. Last time I tried to learn C++, I didn't get References (because I knew pointers) and I didn't really use Templating (because I came from Java 1.6 where it hadn't been added yet). They seem seamless to me now. Perhaps it's the fact I have so many languages under my belt that I didn't like the format. I wanted to see a feature, see it working at it's best, then learn everything about that feature, including it's pitfalls and so forth. Then at the end of the chapter it's another tool in my arsenal. The book has a details section at the end of each chapter but it doesn't really seem quite as complete. I think on reflection I should have bought a different book but each to their own I guess. Hopefully my comment will help people make a more informed decision.
ISO wants to recoup the investments involved, i bet? also, is that the print version? as the article states: &gt; Preemptive note for those who are concerned that ISO charges money for the final official text of the standard: There are, or will soon be, several good options ranging from cheap to free. First, all of the C++11 working drafts and papers are freely available at the WG21 committee page, including near-final drafts of the standard, except only for the final text where ISO asserts copyright. Second, as national bodies ratify and publish the standard themselves, you will be able to purchase the final text of the standard from them instead of ISO if you prefer (the only difference will be the cover page); for example, ANSI published the previous C++ standard in PDF form for $18, which is much less than most C++ books. 
Better: #include &lt;iostream&gt; using namespace std; int main() { int total = 0; cout &lt;&lt; "How many pennies do you have?"; int count; cin &gt;&gt; count; int total += count; cout &lt;&lt; "How many nickels do you have?"; cin &gt;&gt; count; total += count * 5; cout &lt;&lt; "How many dimes do you have?"; cin &gt;&gt; count; total += count * 10; cout &lt;&lt; "How many quarters do you have?"; cin &gt;&gt; count; total += count * 25; cout &lt;&lt; "Total value = " &lt;&lt; total / 100 &lt;&lt; " dollars" &lt;&lt; " and" &lt;&lt; total % 100 &lt;&lt; " cents"; return 0; }
Thank you.. All !!!! :DDD
...and C++11 edition: #include &lt;iostream&gt; #include &lt;map&gt; #include &lt;string&gt; using namespace std; int main() { map&lt;string,int&gt; coins { {"pennies", 1}, {"nickels", 5}, {"dimes", 10}, {"quarters", 25} } int total = 0; for (auto it = coins.begin(); it != coins.end(); ++it) { cout &lt;&lt; "How many " &lt;&lt; it-&gt;first &lt;&lt; " do you have?"; int count; cin &gt;&gt; count; total += count * it-&gt;second; } cout &lt;&lt; "Total value = " &lt;&lt; total / 100 &lt;&lt; " dollars" &lt;&lt; " and" &lt;&lt; total % 100 &lt;&lt; " cents"; return 0; }
You mean C99.
I taught myself C++ at university 5 years ago but never got myself using it properly (It wasn't taught in the course, so I learnt outside til the pressures mounted) I've come back to start teaching myself 3 weeks ago and this presentation is absolutely fantastic. A brilliant sell of how the language has adapted to be as simple a Java and C# and still remain incredible fast.
I'm late to the party but will put this down for anyone else reading after. The guys above are not referring to 'The C++ Programming Language'. Bjarne has wrote another book more recently called 'Programming: Principles and Practices using C++'. I'm reading it now, as a beginner, and am really enjoying it. I've tried other C++ beginner books before trying this one but always feel I'm never truly learning anything due to the lack of exercises. PPP is full of end-of-chapter drills/exercises that really help make sure you understand the chapter you just read, in the same way a maths textbook does. Too many programming books throw chapters of information at you with no way to express your new found knowledge.
I am well aware of to what book they refer. I simply feel that it is a terrible primer. I would much more quickly reference the actual primer he wrote with Barbara Moo, or Meyers, or Sutter, or Dewhurst, or Alm, or Aho, or Beckett. Hell, I might even go for Eckel first, and Eckel's chock full of wrong.
None of the people on the C++ committee get paid. Its all voluntary work. The committee has no income either ... to pay for whatever expenses there are (I assume its mostly for renting meeting space). Something's gotta give. I think the only people who actually buy the standard are compiler writers. The rest of us just buy Stroutsrup's book.
I have done something very similiar. Except it was different. I had the $() syntax to evaluate an python expression and output to the file. And then I had the $... {} to evaluate blocks. So you could write something like this: $for i in range(64) { #define ARGS_ELEMENT_$(i)( $for j in range(i+1) { _$(j) $if j is not i{ , } } ) _$(i) } would generate something like this: #define ARGS_ELEMENT_0( _0 ) _0 #define ARGS_ELEMENT_1( _0 , _1 ) _1 #define ARGS_ELEMENT_2( _0 , _1 , _2 ) _2 #define ARGS_ELEMENT_3( _0 , _1 , _2 , _3 ) _3 ..etc You could use it standalone like that, or you could have a python script run to create a context for the file. I would like to upload it to github sometime. I just need to clean up the code a little bit, when i get a chance.
The 3290 was the final draft. The core content might be identical, but the file isn't (3290 is labeled final draft, not standard, and some of the formatting is slightly different).
You probably noticed, but it loads the slides with AJAX. I can think of a million ways that could have been implemented improperly and cause the slowdown experienced.
Why did he have to be under educated *and* somewhat obnoxiously and completely willfully ignorant?
Is OnScopeExit somewhat similar to Loki's ScopeGuard? Haven't looked at it for a couple years so I could be foggy...
I wanted to make sure to thank you for your time, for such a detailed reply. Much of it reminded me of the book [How to win friends and influence people](http://en.wikipedia.org/wiki/How_to_Win_Friends_and_Influence_People); I'm curious if that's a common influence? I'm curious about one more thing, if you can spare the time. How do you handle how each individual person perceives attitude? E.g. some of what you suggest, I find to be a patronizing attitude. I've learned now to instead identify the actual attitude they're attempting to project, and 'bear with it' (I know this isn't at all unique; we all have people we don't like but have to get along with!). Any advice on adapting to different personality styles? Suppose someone else hired LL-girl; how would you go about endearing her? Pardon, but this is proggit -- do you have a look up table of personality-type =&gt; rapport techniques? :-)
&gt; Much of it reminded me of the book How to win friends and influence people; I'm curious if that's a common influence? No, I haven't read that. But the summary points look excellent. I will try to get a copy. Thank you. &gt; some of what you suggest, I find to be a patronizing attitude. I'm sorry; I'm having a difficult time following that paragraph. Are you asking about other people having patronizing attitudes, or are you saying that the attitude that I would project given my earlier suggestions would be patronizing? Anyway, each person is an individual; you do have to feel them out. However, I have found that talking to my manager is a great way to find out more about people's character that I can't pick up. I frequently ask her "how should I approach such and such person on this topic?" There are some people that I still haven't been able to crack. Generally speaking though, I'm on really good terms with a majority, "good working acquaintances" with most of the remainder, with only a couple that I clash personality-wise. &gt; Any advice on adapting to different personality styles? Well, I try to find some common area with aperson. So with the LL-girl, i would certainly discuss some of the corner areas of the language, how we can encourage good practices on the team, and how to prevent snafus. I would try to give her insight into the personalities of the team members and encurage her to not overwhelm people because people learn better when they can focus on one thing at a time. &gt; do you have a look up table of personality-type =&gt; rapport techniques? :-) No. But I have taken those personality tests with my wife, kids, anf friends (the tests that categorize people on 4 axes). Anyway, the analysis of those types and how one can interact with those types is very informative. So, perhaps I should say that such tables exist, I've read them before and have learned a bit from them, but don't have them on hand today (or the last couple years).
I don't care about exception-safe coding. My code is safe. With exceptions.
That's exceptional!
Thank you again for your insights, definitely very helpful to hear another point of view. &gt; or are you saying that the attitude that I would project given my earlier suggestions would be patronizing? Yes, though I would avoid phrasing it as "you project...". I wanted to draw a distinction between a person's behavior and how others perceive it. Generally I've observed the language of "attitude" as blaming the behavior and never the observer. Perhaps I don't enjoy such behavior, but knowing how actions can be misinterpreted I should seek a other conclusions, such as the possibility that you're trying to establish rapport through small talk. Particularly poignant for me was non-LL-boy in slide 152, with "Yeah, I told you - I never write code like that." I'm probably uncommon in this regard, but that struck me as very arrogant; in context it appears as if he's trying to deflect attention from his own errors, or criticizing the importance of the interviewer's questions. When I step back though, another plausible interpretation is that he's expressing frustration with a series of questions he wasn't prepared for. I hope that clarifies. &gt; There are some people that I still haven't been able to crack. I think everyone can identify with this!
Yep. That's because I use exceptions only for exceptions, or in other words - only if I need to exit anyway due to some unrecoverable error, and in that situation I could care less if every bit of memory will get freed or not. Due to the fact that exceptions are inherently broken concept, *especially* in C++, I consider using them for normal/non-exceptional error handling as an error.
&gt; Due to the fact that exceptions are inherently broken concept, especially in C++ &amp;#3232;\_&amp;#3232; What's broken about them?
It's a form of caching. I brought up the patience and it caused a stack overflow around page 400. Reloading the page and typing in the page number caused that page to load quickly &amp; the rest was then still quick. 
I'm not confident *any* C++ code I've ever written was exception safe.
&gt; (I have to say I'm surprised she didn't mention the -Werror flag given everything else she spouted off.) I'm surprised you didn't mention -pedantic-errors as well. &gt; In code that uses one class member variable named 'sz_' It uses two, "sz_" and "v". 
If I were writing a naive implementation of code generation, I would generate code for that sequence as such: ; a++ mov eax, [a] inc [a] ; a = [previous result] mov [a], eax leaving it at 41 despite doing a proper inc as you requested.
&gt; To be honest, many of the C++ "programmers" I've met make the blonde guy look pretty knowledgeable. That... so much... they just look at you blankly if you call something "undefined behaviour" or if you tell them not to start their typedefs with an underscore and a capital.
Why use exceptions then? `abort()` or `exit()` would be far more adequate.
&gt; What's broken about them? First and foremost, **anything anytime may throw an exception**. It's not feasible to document what may throw what as you would have to follow whole call stacks manually; when adding a "throw X" to function F1 you would also have to mark function F2, F3, F4 and F5 which call F1, and you would also have to mark any function that calls any of those functions, and then functions that call those functions; I'm sure you can see where this is going. Not only you don't know from where an exception will pop up, but you also can't know what exception specifically you are going to get. This is exceptions' biggest weakness, which makes them totally broken. An unhandled exception thrown from the darkest corner of our program will just make it crash, and it's virtually impossible to *properly* handle every possible exception for any bigger program; we could of course just catch everything at the top level but then we risk introducing pretty serious bugs.
&gt; What's broken about them? C++ is evil.
&gt; when adding a "throw X" to function F1 you would also have to mark function F2, F3, F4 and F5 which call F1, and you would also have to mark any function that calls any of those functions, and then functions that call those functions; Sounds like voluntary checked exceptions from Java. Java's solution actually doesn't work as badly as I thought it would. You should be able to know what types of exceptions you can receive, or at least the base classification of them. You don't need the exact type, you just need to know in as much detail as you want to handle. It sounds a lot like your biggest problems is people using exceptions while some people don't count on them happening. Perhaps people are using exceptions to report expectable results?
&gt; Why use exceptions then? abort() or exit() would be far more adequate. That depends on what I'm working on. *Sometimes* it makes sense to use an exception, sometimes not.
&gt; You should be able to know what types of exceptions you can receive, or at least the base classification of them. Unfortunately with non trivial call trees this isn't really feasible. If you add to the mix some third party dynamically linked modules that throw exceptions too and can change without notice it gets even more *fun*. &gt; Perhaps people are using exceptions to report expectable results? That is also a **very** common problem; some people *serously* overuse exceptions by handling errors that are nowhere near exceptional.
&gt; third party dynamically linked modules that throw exceptions too and can change without notice Sounds like a good place to put a facade or something. That sounds horrible!
Exceptions are very easy to use well. First off, what kinds of error handling are there and when should you use them? - Return codes. Use these when the one handling your error is nearly always the function calling you and when the error can be expected. Examples: File::read, Socket::connect... - Exceptions. Use these when the one handling your error is usually not the one calling you, or when the error is very unexpected. Examples: Socket constructor, ComplexFileReadingOperation::parseFile (and subfunctions). - Global handlers. Use these when your error is not handleable by your caller (or any of its parents), but when the handling is always the same. Examples: out-of-memory situation (try to remove stuff from caches). - Assert/abort. Use these when there is no valid way of recovering from your currently detected error. Don't continue as you will mask the state and cause ghost bugs in other parts of software. Examples: memory corruption, null pointers for objects that should never be null. Keep in mind that cleanup / closing functions *can never fail*. This isn't because they can't fail - anything can fail - but because no handler could possibly fix it. (as proof: Suppose there's some kind of handling it could do. Move that handling to cleanup/close function. Now it can't fail.) They should therefore never throw exceptions, ever. Don't throw an exception because something fails. Throw an exception because the handling of it is according to how an exception works. ***TL;DR:*** yes.
Thanks, this will make for good watching while I'm stuck at home with a cold.
kouteiheika, I don't want to sound defensive (I'm the one that did the video), but I think you might find watching the video useful (I know that it is long, but I promise I cut out all the fat). The issue of knowing what can throw and what cannot is central to the exception-safe approach. The key is that we assume that most functions can throw and we don't need to document which functions actually do throw and what they throw. It is, of course, critical that **some** functions do not throw and I'm careful to identify those functions and how to implement them in a non-throwing way. I also explain how to write code safely under the assumption that almost all functions can throw (either currently or during maintenance). I'd very much like to hear from you after you watch the video. My contact information is on the linked page. Thanks for your interest.
You're very welcome. I'd like to hear your comments after you watch.
&gt; I'm surprised you didn't mention -pedantic-errors as well. I'm a gcc newbie and am still learning all the flags. The -Werror was one of the first ones I learned though because we wanted to treat warnings as erorrs when we started the projects. &gt; It uses two, "sz_" and "v". My mistake. I missed that. &lt;sigh&gt;
Yepp, read Sutter's "Exceptional C++" and "More Exceptional C++" several times, and have thoroughly internalised the idea of RAII and "transactions", i.e. do everything that can throw on a copy, then use a non-throwing swap, etc...
It is a real pity GCC still has no tr1/C++11 regex support.
clang and/or llvm-gcc should be available on all major Linux distributions.
Yes it is but it has lambda and threads for e.g., in the meantime you could use Boost, the syntax is similar. I didn't check but I think clang on Linux supports regex, has anyone tried clang on Linux ?
I do not. I know you can have codepad.org run code in all sorts of languages, including C++. As for example problems to run and explore, I'm less helpful. Good luck!
C++'s `throw()` annotation isn't any sort of checked exceptions like in Java. It's only a promise that *this* function will only throw the listed exceptions. It may call a function that throws different ones. (Weird, I know.) It's also been removed form the new standard. `throw()` function annotations are going away in favor of `nothrow`. Unexpected exceptions that aren't handled immediately call your `unexpected_handler` and terminate the program.
mmm. no. the throw() annotation ensures that function doesn't throw any others. If there's an unexpected exception that you don't handle immediately it's translated to an exception of the type (I recall something like) std::bad_exception. If you don't include that one in your throw() annotation then it terminates the program. Those comments you referred to sound like they are the voluntary variant of the checked exception, which also appears in Java.
Yes. I prefer my implementation of course, but it is the same idea. 
&gt; Not only you don't know from where an exception will pop up, but you also can't know what exception specifically you are going to get. This is exceptions' biggest weakness, which makes them totally broken. Does that really matter? Exception types are meant to be treated polymorphically, so on those sites that have to catch (e.g. where passing the exception bucks stops) then you can catch `std::exception`. Or if for whatever reason you're using insane APIs that don't throw types derived from `std::exception` you can still catch anything. // the exception buck stops here try { // Optimistically write your throwing operations } catch(some::api::network_error const&amp; ex) { // log, report or otherwise handle the network error // a sane api would provide information accessible from ex } catch(other::api::foo_error const&amp; ex) { // etc etc } catch(std::exception const&amp; ex) { // ah shucks } catch(...) { // push comes to shove } With C++11 writing 'exception-translating' functions is very easy: try { // throwing operations } catch(...) { std::throw_with_nested(my_very_own_exception_type {}); } Although personally I'm using Boost.Exception and `boost::errinfo_nested_exception`.
What happens in practice if you try this (the incorrect version) and you don't luck into proper alignment. Are you likely to get an error or warning from the compiler? What does the runtime error usually look like?
A real in-depth rationale and explanation of move construction and related issues would be great. The real brief descriptions I've read so far don't leave me feeling like I really get it.
Cool post. I haven't really gotten that much into C++11 yet, so all the new stuff still surprises me.
*Idiom*. It doesn't make much sense at least on first read, but it's a common enough pattern to be recognized. 
Thankfully we'll be able to use: v = move(vector&lt;T&gt;()); When compilers support C++11, which should happen in about 5 years if we're lucky.
C++11 fixes this by adding 'shrink_to_fit', except it does not, since this is only a request and capacity isn't required to change after it.
It's already leaked to the Pirate Bay.
Your use of move(.) is unnecessary since vector&lt;T&gt;() already refers to a temporary object (hence it's an rvalue). G++, clang and MSVC already support rvalue references as far as I know. Also, what you propose does not necessarily release any memory. v's capacity might still be as high as before.
&gt; v's capacity might be the same as before. Only if it's capacity is the same as a freshly default constructed vector. The standard specifies that the moved-from value be in a default constructed state.
What about v.resize(0);? Does it actually free memory?
No, it does not free memory.
I forgot about that!
&gt;Your use of move(.) is unnecessary It was just meant to provide an explicit example. &gt;v's capacity might still be as high as before. v's capacity is required to change to that of a default vector. &gt;G++, clang and MSVC already support rvalue references as far as I know g++ and clang only provide experimental support for C++11. Even with respect to move semantics their implementations are not complete and contain some bugs, some of which are pretty severe. MSVC provides production support for move semantics although overall MSVC has the absolute worst implementation of C++11. It should be obvious from my post I meant full support for C++11, not experimental support for some features here and there.
The classic C++ approach.
$Forbidden
Sutter's work is in my bibliography for the talk and has been very influential in my thinking.
Move the fin.open call to outside the loop. Or if it's actually supposed to open a new file each loop you need to call fin.close() at the end of each loop (or leave it in the loop scope so that it gets handled for you automatically).
Oops, left that out the example, but yes each pass opens a different file than before, and in my code there is a fin.close() at the end of the loop. It still failed to read each time. It wasn't a critical failure, crashing the program or anything major like that, it just wouldn't grab the number, until i put the declaration inside the loop of course.
What's the something inside the while loop predicate?
maybe after fin &gt;&gt; num; try adding if(fin.fail()) cout &lt;&lt; "ifstream errror flag hit"; and seeing if it happens. also after fin.open(...); insert if(!fin.is_open()){ cout &lt;&lt; "ifstream not open"; continue; } and see if there's an issue there. How close is this to your example? the iostream libraries tend to be finicky about the error state, so if something is getting messed up on the first loop it is most likely just setting the fail/bad bits in the ifstream and canceling any further operations silently.
Read, and be enlightened: http://www.cplusplus.com/reference/iostream/ifstream/open/ Note the part where if a file is already open, the ifstream::open() call fails.
That shouldn't be relevant since he calls close() before any subsequent open(). ifstream::open() "If the object already has a file associated (open), the function fails." ifstream::close() "Closes the file currently associated with the object, disassociating it from the stream."
I'm curious what would happen if you compiled the two versions with optimization disabled. Unless you left *ahem* something out, I'm not sure what else it could be (other than a borked ifstream::close() implementation).
Hmm, good point. I don't see that it resets any error or failure flags though (and could possibly even set a flag), which perhaps has something to do with it.
In your loop you have: &gt; fin.open("somefile.txt"); //different file every pass Unless your code is actually different, you are opening the exact same file and reading the same number from the beginning of the file each iteration. Hence: &gt; This didn't work except for the first pass. Subsequent outputs would simply be that first number read. Both of the versions you gave here *should* give that same output. If you are trying to read subsequent numbers from the same file, move the open and close out of the loop. ...or are you actually opening a different filename each iteration? Edit: saw your comment below, you are opening a different filename each iteration.
That's why I was curious about the predicate in the loop. Usually when I do while loops to read files I will declare the stream outside the loop, perform a read, then use the stream name as the predicate so when I run out of things to read it will stop. Though I guess that method wouldn't work if you're wanting to access a new file every time through. In that case the OP would need some sort of variable to count through each iteration and have another way to change the filename based on the value of that variable. If they're command line arguments, argc would help with that.
I just wrote it that way for the sake of an easy example. But yes, in the loop is code that scans the current directory for files and opens each file successively each pass. So really "somefile.txt" is a variable that holds the file to be opened. I didn't want to copy/paste the code itself because it wasn't my own, but everything worked fine (reading the file name, etc) except those successive file openings. I'll edit the examples to reflect this.
Thanks for the advice. I had assumed it was a problem reading, but that'd make more sense if it was a problem opening the next file, especially since the first open and read obviously worked.
Sorry but i don't get this. Those are common "errors" in many programming languages (see the scope one). That's how they're intended to work and how they're taught.
-Wall -Wextra, problem solved?
Agreed. I looked at all the examples and my first thought was "anyone who writes code like this should be shot".
Pretty meh. One thing strikes me though. Why everyone insists on 'a = b;' having a value? C does this, C++ pretty much requires this formally for UDTs, hell afaik even D does have this. Whats the benefit? Supporting 'if(a=b)'? Supporting 'a=b=c;'? These are all brain dead usecases that wouldn't go through code review anyways. Only if(Foo* foo_ptr = dynamic_cast&lt;Foo*&gt;(bar_ptr)) would be OK for me, but this isn't assignment and is special anyways afaik.
Are you clearing your error flags each iteration as well? I'm not sure open() clears previously set error flags, such as eof() (which I assume you're checking as you read). 
Suggested rename: &gt; The Top 10 Ways To Identify Screwed Up Programmers Mangling "C" **Edit:** From the linked article: &gt; To get on this list, a bug has to be able to cause *at least half a day* of futile head scratching If you're writing code frequently enough to come up with that list of ways that one of the most widely used systems programming languages in the world is "screwing" you, and it takes you *at least half a day* to sort out why your terrible code doesn't do what you think it should be doing due to these so-called language design flaws, then please do yourself and the rest of the world a favor and give up programming in favor of something less taxing on your intellect, like apple picking.
Woops. No, not doing anything with eof, checking, setting, or otherwise. How would I clear that out, and why wouldn't it clear out after the close() anyway?
Close doesn't rest the flags, so you can check if there was an error closing the file. The last cpp standard doesn't say that open should clear the flags. Which is a bit odd. This is true for all stream based classes. Either redeclare in the body like your example or you could call clear() 
Ah, "clear()", thank you. I should really read cplusplus.com more :)
declare the fstream in the loop. That follows scoping. Don't declare variables outside their needed scope, its a premature optimization.
#1 - If you use // instead of /* then it is a non-issue. All C99 and numerous compilers before 99 supported //. #2 - A lot of compilers will give a warning if you do if(a=b) c; so it is basically a non-issue too. 
Any programming language can "screw" you if a) you're a frigging idiot, or b) you DON'T UNDERSTAND THE PROGRAMMING LANGUAGE YOU'RE USING. Look, if you don't understand how to close a goddamn comment, if you don't understand the difference between the "&amp;" operator and the "&amp;&amp;" operator, etc. you deserve what you get. I'll admit that C (and of course C++) allow you to get into trouble if you don't know what you're doing, but if you compile with heavy warnings on and/or use a good static analysis tool (hat tip to Gimpel's tools - sorry Andrey), you'll get a heads up. Anyway, there is no substitution or knowledge/skill/experience. That fact transcends any one particular programming language.
 while(thingy=readSteam()) { use thingy } It's incredibly idiomatic and in K&amp;R
Yes its in K&amp;R, why other guys keeps on pushing that (C++/D)? Also its trivial to rewrite that to: while(thingy_t thingy=readSteam()) { use thingy } And be good without problems i mentioned.
Not if you're still living in a c89 world :'(
This is interesting, but doesn't gcc 4.6 have better C++11 support than clang? If you are going to use linux anyway, why don't you just use that? It comes preinstalled in ubuntu 11.10 and works perfectly
This was my first impression too, that gcc 4.6 has better support for C++11, after playing a bit with the last version of clang and equally important last version of libc++ I think clang covers better some parts of the standard. In gcc you have dummy headers for all the new features of C++11, and some of them are actually implemented. For example I lost an hour trying to debug a simple regular expression in g++-4.6 with no errors or warning in the compiler phase, all I get was a cryptic error something like: terminate called after throwing an instance of 'std::regex_error' what(): regex_error Aborted You could say that gcc 4.6.1 and clang 3.1 are complement each other, at least today. 
Clang is getting a lot of attention, some benchmarks state that it has shorter compiling time than gcc and that the executable is better in some cases (faster smaller).
Actually that error message means that an exception was thrown and you didn't catch it I'm pretty sure. I could be wrong, I've never used regex support in either compiler, but my experience with stuff like std::bind and std::thread gcc worked fine
Same code just works with clang and Visual Studio 2010. You could try the code on your machine if you wish, you could find it in the linked article.
I need a small clarification, when creating a vector of type by value (int or even a class by value). In the example of vector&lt;int&gt; v; v.reserve(100000); v.clear(); Will it still not free the memory? will it hold a capacity of 100000 values but the size will 0?
I notice you are adding GCC header directories to the hardcoded system header search paths. Does that mean that clang will use those headers instead of libc++ ones? btw a minor thing, but you can install multiple packages with a single apt-get invocation: `sudo apt-get install gcc g++ subversion`. And I'd usually prefer installing `build-essential` package which contains everything essential to build stuff (gcc etc). edit: another minor note: you are copying libs to /usr/lib which is usually reserved for system managed libraries, and user managed ones are conventionally placed in /usr/local/lib or somewhere under /opt. Though this is more of a personal style rather than strict rule. On a related note, I'd give the target directory explicitly for `make install`, for the same reason.
By default clang++ will use libstdc++, however you can specify that you wish to use libc++ at compilation with: clang++ -stdlib=libc++ Thanks for your other suggestions, I'm obviously not an expert in compiling things from source code, but I usually manage to do it when need it (by trial an error).
Tried this tonight, but didn't pan out that well. My build (from SVN trunk) didn't pass 4 of it's tests (`make check` which is quite essential for software like compiler). I might need to try out their releases.
It is not guaranteed to change the capacity. I don't think it is guaranteed to *not* change the capacity, either.
No mention of [Pantheios](http://www.pantheios.org/performance.html)? &lt;- comparison against 8 other logging libs (not Boost log v2 though). (Note that the scale is logarithmic.) Matt Wilson is the guy who wrote 'Imperfect C++'; I'd put him just below Andrei Alexandrescu in C++ wizardry. 
Ah ok, And if I pushed 100000 items? After calling clear will the vector still hold a continuous buffer of 100000 * sizeof(T)? I know that STL doesn't guarantee that size function will be O(1), so how can it know that the buffer he holds is "empty"?
too soon
Given that background, C++ is possibly the worst imaginable language to start with. I recommend you try Python, or (if you're feeling particularly masochistic) straight C. Even a Lisp variant would be smarter.
Congratulations! Learning C++ is a good way to a better understanding of programming. I suggest you get a copy of C++ Primer Plus - it's a lot better than any tutorials I've seen. Good luck!
Care to explain why it's such a bad idea? I can see how one would easily transition to python from VB, but if C is acceptable but masochistic, why is C++ unacceptable?
It's not, he's probably just dumb or doesn't realize that syntax isn't an issue for a lot of people.
I wouldn't call it "the worst imaginable", but if you are going to learn C++ then you are going to spend a **lot** more time learning C++ than learning how to program; that is the reason why picking a language that will let you focus on the problems you'll want to solve instead on the language itself may be preferable.
Don't listen to that person. Also, pick up a copy of "Accelerated C++", it's one of the best books I've seen. It teaches you the C++ way of doing things first, and delves into the lower-level C stuff only later on (where a lot of other books do it the opposite way). 
What? You think my objection to C++ for a guy who "hasn't done anything with programming" in "about a decade" is because of the fucking _syntax_? Someone who's coming from fucking VB5? C++ is the most complex major language in existence. Tiny subsets of it are so complex as to be Turing-complete languages in themselves. Every orthogonal part of the language is huge, and _constantly necessary_ even in simple code. I love C++ and I will defend it to the death but if you jump from VB5 in 1999 to C++ in 2011—especially _self-taught_—you will have a really shitty time. Python is a great language that's both powerful and easy to learn.
Because C++ is immense, and immensely complex. Things which appear benign aren't. You need to intuitively know side-effects of actions which appear to have no side-effects. You need to know obscure syntax and precedence rules to make sense of compiler errors. As I said below, I love the language and I'll defend it to the death. But it is manifestly _not_ a good learner's language, especially for someone who's self-taught.
So what is the proper way to get into C++? Three days with no food, no water and no encouragement? Which languages do I need to consume on my path to enlightenment? I didn't select C++ out of a hat, I chose it because it's so powerful and complex. I'm looking forward to the challenge presented by C++.
If you're not doing complex applications, C++ is not a complex language. You're making it out to be this behemoth that's super tough to learn if you're not already familiar with it when, in reality, it's only as complex as the program you need to create. A basic understanding of memory and types is required, but outside of that it's really not that hard to pick up for basic things.
I've got [that book](http://www.amazon.com/Accelerated-C-Practical-Programming-Example/dp/020170353X/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1318870110&amp;sr=1-1) too and I like the way it teaches things but it is definitely harder to understand initially than some other books. I suggest getting it along with another C++ book (I have [SAMS Teach Yourself C++ in 21 Days](http://www.amazon.com/Sams-Teach-Yourself-Days-Yourself/dp/067232072X)) so that when you're having trouble with Accelerated C++ you can switch over to the other book and just read about a particular topic (such as pointers) and maybe go back to Accelerated C++ with a little more understanding.
If you're keeping with Windows development, [CodeProject](http://www.codeproject.com) has many decent articles and tutorials. Installing local help is invaluable, make no attempt to clutter your brain with WINAPI function parameters. **Learn to work outside of and not depend on the MS development environment.** 
Start with pure C: learn basic syntax, program structure, etc. Conditions, loops, simple functions... most of it will be usable in C++. Then, learn about object oriented programming, and how to implement classes and inheritance in (OO) C++. Then add some polymorphism. Later, learn about templates and the STL. These are, IMHO, the core things to get started with C++. It is a language that takes years to know really well, but I don't think you need to be a senior programmer to use it efficiently. It is sometimes more obscure and unforgiving than younger, friendlier languages, but that's precisely one of the things I like about it.
This is exactly the kind of reply I was looking for, thank you. As I said, I'm going through the tutorials and the conditions, loops, functions and syntax all looks very familiar. If I continue with C++, will I be able to learn/use pure C if I need to go to it for any linux dev that I might wander into, or would it be that much more beneficial to start with C?
I would say C can be seen as a subset of C++. Or C++ is C with added stuff. It really isn't, but they have a lot in common. Syntax, for one, is pretty much the same. The thing here, IMHO, is not getting confused at first with C++ abstractions and more sophisticated tools. Pure C is really straight forward, a completely functional, direct and neat language. Once you know some C you can translate everything you've learned to C++, which adds sophistication layers and more abstract ways of doing things. You'll do things differently in C++, but the learning process will be much smoother and everything will make more sense. If you jump directly into C++ you will be confused. Also, make sure you understand how to use pointers.
Honestly imho STL is the first thing that C++ programmers should learn, not the last. I don't really see the value that beginning with pure C gives, and losing the large standard library (not only stl, but other stuff too) is a huge downside. 
I guess that the ptrb is trying to say that you should first learn programming before diving into C++. I'm not sure if I agree, but there is still some truth in his words.
I disagree. C is straight forward: you have variables, operators, and you define functions that make programs. It has not object oriented stuff, (different types of) constructors, destructors, operator overloading, templating... for a beginner it's much easier to learn a smaller (yet totally usable) language at first, and then add things on top of that, than to learn a bigger one. If you want to run a marathon you start by training to be able to run 1 Km, not the whole 42. As for the STL, I don't see the point of learning that without knowing about inheritance or templates. Of course it's still very useful, but on the other hand, you might as well go for VB.Net.
In C, to make a dynamic array whose size is only known at runtime, you have to be familiar with: - pointer syntax - how arrays degrade to pointers and how they are related - malloc - sizeof - free, and how and when to arrange to call it - how to maintain the size as a separate value - bounds checking - for resizing: memcpy/realloc, more ugly pointer syntax In C++, this is all you have to be familiar with: std::vector&lt;int&gt; foo; foo.push_back(42); That's it. I don't see how anyone can possibly say that it's harder to learn STL types than the truckload of concepts necessary to deal with manual memory management. You don't need to know squat about inheritance, and of templates you only need to know that you write `&lt;int&gt;` for a list of ints.
How is learning to manage memory by hand (without raii and smart pointers) and rewriting common datastructures easier than learning how to use std::string, std::vector and std::map?
It's also exactly wrong. C++ is a totally separate language from C, with totally separate idioms and constructions. That C is seen as a stepping stone to C++ is a historical accident, and not something you need to replicate in the modern world.
Without a doubt, you need a teacher. That can be a coworker, a peer, or a professor, but you need someone with an expert-level understanding of the language who will field your questions and guide you on the right path.
As I said, with that mindset you might as well grab VB.net or other friendlier, safer language. Not that there's anything wrong with that, but if you want to really learn, and if you want to know C++, I'd start with the basics. Otherwise I wouldn't recommend C++.
Nobody is suggesting that you don't learn those concepts eventually, at a later date. The point is that all that junk gets in the way of learning at the beginning stages. C++ allows beginners to hit the ground running and write useful code before delving into the details, which makes it a better starter language than C. I really think it's a false dichotomy to suggest that just because a beginner might not want to slog through all the dirty laundry of a language that they should stick to Visual Basic. 
Jump on STL and Boost soon after you have familiarized yourself with the basics of the syntax (if you know OO and such from another language that is)
* Learn the stl * Use std::shared_ptr and std::unique_ptr, never use delete directly * Learn C++11 lambda syntax * Remember that boost is an R&amp;D library and most of it should be avoided for use in your own code. Most of the good stuff is now in the stl. * Resist using much inheritance; it tends to be over used. * Using an IDE like VC++ are defiantly the way to go but there is a bit of stuff to learn because it has design decisions made for professionals that confuse things when just starting out. * Case in point ‘pre-compiled headers’ often referred to as pch.h of stdafx.h. This is an optimisation to improve compile time (and intellisense speed). Avoid these when starting out. You can get to a reasonably large amount of code before this becomes an issue. 
I think the advantage of learning C (or even assembly language) is that you build an understanding of what is happening internally when you operate on high-level data structures. This helps in both debugging and optimizing.
I think anybody remotely knowledgeable about C++ or programming and books about the subject will tell you to absolutely avoid anything titled "Learn X in Y Z" where X is a programming language, Y is a number, and Z is a unit of time. You are absolutely not ever going to "learn" C++ in 21 days. Try 21 *months* before you're able to tackle something even semi-important, and five or six years to be truly and fully comfortable (while still having lots to learn). Also anything made "for dummies" is only going to make you a dummy at the skill you're trying to learn. Definitely stay away from the SAMS book - the rest of us don't need any more bad C++ programmers. I started learning from that exact book 12 years ago or so, and to this day I still regret some of the bad habits it taught me. Habits with programming start early on, make sure to teach yourself the right ones. That said, if you're learning, feel free to PM me or post here in /r/cpp if you have questions about C++. I make this offer to the OP as well. Sometimes I like to brush up on the newbie stuff.
i disagree somewhat w/ the idea of using an ide early on. I think it spoils you and you don't learn some key concepts. that said, i LOVE the vc++ debugger and as a (now) unix developer, i miss it sorely. I will say that you should NEVER EVER EVER EVER use a code wizard. You should try and avoid, like the plague, systems which generate code for you that you're not supposed to modify, much less understand. (This is easily my biggest beef w/ Qt, for instance) . 
&gt; Other resources that move a little faster? I learned C++ from the book [Accelerated C++](http://www.amazon.com/Accelerated-C-Practical-Programming-Example/dp/020170353X) and I recommend it to everyone that wants to learn C++ seriously. The learning curve is a little steep, but with some dedication you can work yourself through it in a month or three.
It might be your beef with Qt, but millions of other have no beef with it. So don't tell OP not to use such things when they can be appropriate. Another example: parser generators. Also, using an IDE for C++ is the way to go, from the beginning. If OP ever needs to mess with the compiler toolchain directly, he will learn how to do so then.
&gt; As I said below, I love the language and I'll defend it to the death. Why? It is a horrible language. The only thing going for it is its prevalence. I wonder why there cannot be another language with similar goals/performance etc., with a sane feature set and not a million traps that could replace C++.
OH MY GOD! On the last page they scrap everything and turn the language into java. What a shocker: &gt;Effects: as if *this = packaged_task(std::move(f)), where f is the task stored in *this. [ Note: This constructs a new shared state for *this. Ah, fuck, that doesn't actually work.. screw it EVERYTHING IS A REFERENCE, NEW IS A NO-OP. FUCK STUTTER, FUCK STROUSTRUP, I'M OUT ] Edit: From page 1175!
I personally couldn't disagree with your more, but from your responses to others, I suspect that will carry little weight with you. Perhaps the creator of C++ could change your mind. savvycow meet Bjarne Stroustrup: http://www2.research.att.com/~bs/new_learning.pdf 
With those constraints, I'd say that read() and check return value. Better solution would be to use stat() though (or S_ISDIR() which uses stat internally).
Does read() return -1 when it is a directory? Because I know read() returns -1 when it cannot find the file, but I also need to be able to see if the directory exists. Is there anyway I can make it return a different value if it's a directory if it does just return a -1?
http://www.kernel.org/doc/man-pages/online/pages/man2/read.2.html
It is totally up to the STL library writer whether or not, or under what conditions, clear will release memory or not. It may decide that large memory blocks, for some definition of large, need to be cleaned up, but small ones are more efficient to leave allocated. But each of the major compilers each wrote their own standard library implementation, and may even change the details depending on version, debug vs release, or optimisation level.
RAII is one of the most important concepts in C++ programming. The idea is to let constructors and destructors manage the lifetime of all resources that must be set up and torn down including file pointers, allocation of heap memory, that sort of thing. This means that every resourse will typically be pinned to some lifetime of some object on the stack, which can make some operations a little trickier, like having a factory producing objects deep in your code, how do you get that object managed by something whose lifetime outlasts that memory call. auto_ptr confuses a lot of people, but it is supposed to be an easy template to give a pointer the behavior of being allocated on the stack, but with a couple of ways for it to survive being returned out of a function by being able to transfer it's lifetime by copying it into a new auto_ptr. People get confused by trying to think of it like a very limited shared pointer, but it is better to treat it like a shell of an RAII container for heap memory with a couple of bonus features. Also note that auto_ptr is being replaced by something in C++11 that can actually survive being stored in a vector (unique_ptr).
But if anyone finds Boost a bit much to digest, you can do fine without it and come back to it later.
One possibility is to open() the path with the O_DIRECTORY option. If the path is not a directory ENOTDIR will be returned. http://linux.die.net/man/2/open
I think this is my best option. Thank you.
Just remember that this is probably not a portable solution. From http://www.kernel.org/doc/man-pages/online/pages/man2/open.2.html: &gt;O_DIRECTORY &gt; If pathname is not a directory, cause the open to fail. This flag is Linux-specific, and was added in kernel version 2.1.126, to avoid denial-of-service problems if opendir(3) is called on a FIFO or tape device, but should not be used outside of the implementation of opendir(3). So it's probably better to use read, check if the return value equals -1, and if in that case ERRNO is set to EISDIR. See the link provided by zokier.
An IDE is useful if you already know what you're doing. If you're learning a language it actively inhibits your progress.
Explain.
Ok, Great thanks I'll check the documentations. EDIT: the documentations of MSVC 2010 doesn't say if it deletes or not. So I just tried it, pushed back a bunch of items into a vector and printed the the size and capacity, in debug it wont delete the buffer in release it will.
Oh wow, I did know that the 21 days thing (as a learning timeline) was a pile of bullshit but I wasn't aware that I might be learning bad habits from it. What are some of the bad habits that this/these book/s could be teaching me? And what are some better c++ books that don't teach us these bad habits. I currently have the C++ Primer, Accelerated C++ and The Pragmatic Programmer but I liked how the SAMS book went through things (but I don't want to pick up bad habits).
Great reference - Glad to see Microsoft Visual C++ and gcc support quite a large number of the features. It's actually called C++11 now, not C++0x :)
Great series. Keep it up! Thanks
"C++ Primer" is generally considered better than "C++ Primer Plus" (Different authors, not related other than they're both about C++)
So is there a way (beyond using `for` or `std::for_each`) to move things in bulk from one STL container to another? The code shown in this video went to significant pains to avoid unnecessary copies, and then just used `std::copy` to copy all the paths from the `Result` structs, which seems like a bit of a shame.
Because this is not a list of TR1 features. Furthermore I wouldn't use TR1, C++11 and boost have it covered.
Accelerated C++ gets you up and running pretty quickly.
It depends on the container. For example you can add a List to a another List in O(1) time.. but for things like a vector you need to copy them in (they need to be in memory with the other items, that is just the nature of a vector). Even using for_each you won't be able to change this. After watching again, List would have been a better data type for his list of files/dirs. List::splice should then be used ( I believe this is the O(1) operation)
I agree about using a `list`, but you can obviously move a `string` (or those `path`s) from one `vector` to another, just like you can move a string from one spot within a `vector` to another spot within the same `vector`. That's what I was interested in doing in bulk.
Does the move operation need to be atomic in order for this to work?
right right.. you're right he is copying the entire string like this. I guess you want a "move all" for a vector. Maybe copy is the right algorithm, but you just need some way of telling the copy that it is using rvalue references. I don't know :)
Bad idea man. C will teach habits not generally good for C++
Yeah I agree it has a lot of stuff that can be complex. But I think he can do well just learning some basics that he would need to write useful software. The beauty of c++ is that he can start out just using strings and vectors as opposed to c strings and writing his own linked lists. Once he gets comfortable he can then move on to the more complex features that the language provides.
Is it not necessary as itself. But, if another coder need to look at your code (or you in 6 months), it will be a lot easier to navigate the code. You will have the list of all the function and the main function at the start of the file.
Another point. Like that, it will be a lot easier to understand how header/source file work. Something really important in C++
By itself it's pretty unnecessary, esp if you have everything in one .cpp file. But if you want to use the function in multiple .cpp files the design of C++ forces you to declare function prototypes in header files (.h), and then implement them in a .cpp file. I suspect that your instructor just wants to get you into the habit of using function prototypes for when you'll start writing larger programs. It's a pretty unfortunate part of C++ that reflects its old age. Other languages that were influenced by C++ (Java, C#, etc) don't require header files and you don't need to (and often can't) use function prototypes.
I'm writing a fairly large program for my standards (10.000+ lines) and I have a single .cpp file, the rest is .h files with declaration and implementation in the same place. I'm sure it's a horrible practice for a number of reasons, but I think it kind of works for my way of thinking. I'm completely self-taught and I don't do this for a living, so that's why most of my practices probably suck. Sometimes I do wonder what I'd gain from declaring everything twice in cpp and h files respectively, feels like I might be missing out on something? I guess I just don't like to edit every declaration twice!
You have one 10,000+ line .cpp file and multiple .h files? What are you possibly doing?
There is one central purpose to functions, clases, libraries etc: **The interface should be simpler than the implementation** When calling a function, you should not have to consider all the tricky convoluted details required to garfunkle a crobstrom, you just pass in the crobstrom and get either a garfunk or an error. So each of these entities has three aspects: * **the contract:** what it promises to do. In our example that might be *"garfunkles a crobstrom. If the crobstrom is currently offline, a temporary one is created out of thin air. Throws an error on thursdays (GMT)."* * **the declaration:** the part of the contract that can be checked by the compiler. In our example: *receives an crobstrom, returns a garfunk.* * **the implementation:** That might involve illegal use of arcane magic, for all we care, as long as it's valid C++. **Putting the declaration first** means making up your mind about the contract - because that's all you need for calling the function. This is IMO the most important reason why this style may be beneficial, and "avoiding the need for the prototype" may be counterproductive. ---- There are other possible reasons: * If your code gets to big you will want to split it into multiple files; roughly, declarations go into headers and are included by the file holding main, and implementations go into other files. your prof's actually mimicking that, and already has declarations and implementaitons separated. * It's a poor man's top-down design: i.e. break the problem up into small chunks, then solve the small chunks. Now, the universality of "top down" is debatable, and you can't really crank out the code like your prof does if you haven't done it in your head before, but I can see how it leads to that way of organizing the code. * esthetic: main is most important, so it should go first. 
If you don't put the prototypes, then not only do you have to put main last, but you have to make sure all functions are before functions that depend on them. Reordering your code gets old fast.
This. Also, just to be pedantic, where you (the OP) say "function declaration" in your third bullet (after main), you mean "function definition". The declaration is where you state the function signature (declare the contract). The definition is where you define the actual mechanics of the implementation.
upboats for garfunkles and crobstrom
templates, edit : hopefully
Hey dude, the reason function prototypes exist is part of the way that compilation works. Putting main last is an acceptable solution...in very small code bases. It all has to do with how cpp files are compiled. Forget about the header for a second, and follow the compilation process. First of all, each cpp is compiled completely separately from all other cpp files in your project. That's what's being compiled. All the header files, inl files, resources, etc, they have nothing at all to do with actual code generation. They do, but we're taking baby steps here. We'll get back around to that in a bit. So, one cpp file is compiled. This leaves you with something called an obj file. This is true in the windows world. I think they're called something else in linux or macs. Whatever this intermediate step is called doesn't matter. It's just that. An intermediate step. It contains the machine code that the processor you selected during compilation will understand. Each cpp file is compiled all on it's own, and has absolutely no relation to other cpp files which are being compiled all on their own. No information is shared between cpp compilations. No headers are shared. Nothing is shared. Each stands on it's own during the entire compilation process. To make matters worse, while compiling, the compilation process goes one line at a time. Therefore, if it encounters a function call it doesn't know anything about, and can't find that function call in any of the previous lines of code, it doesn't know what to do. It won't know what to do with that function call until it gets to that bit of code. It goes line by line by line in order. After all the obj files are generated, all of these have to be stuck together inside of a single file (typically an exe, but it could also be a dll, or a lib, or some other file type). This is the job of the linker. The linker looks at all the obj files it's given, and tries to figure out where each function call is in each obj file. Then it fixes up memory locations so that each of the separate obj files can talk to each other. That's why it's called the linker, it "links" code pages together. And at the end of this final step, you get an executable. Now that we have this better understanding of how things actually compile, let's talk about header files. There's a ton of stuff that the compile won't know anything about while it's compiling. But it's the job of the compiler to set everything up in memory for the running executable. Each cpp file generates a code page. And those code pages, under the covers, need to set aside the right amount of memory for each variable you use. There is no guessing allowed. It *must* know at compile time what each variable, each function call, each declaration will require in terms of memory. Enter. Headers. Now, a header file's sole job in life is to tell the compile what each thing is and how it should look in memory. What goes on in a function that isn't on this code page is irrelevant. All the compiler needs to know is that some object is passed in, and some object is passed out. And it needs to know what those objects will look like in memory. Furthermore, sometimes header files include other headers. But it is the header file which links your entire code base together. Larger programs require more extensive and careful use of headers just to get all those cpp files compiling correctly. And the way header files are used is through something called a preprocessor stage. There are three different and distinct preprocessor stages. Each one does it's own thing, but we can jumble them together for the purposes of this discussion. The preprocessor stage takes your cpp, and every single time it encounters the word "#include" it will replace that line with whatever file you said to include. The preprocessor also goes through all your code and literally replaces all of your "#defines" with whatever they're supposed to be replaced with. Have a define for PI? It gets replaced with whatever you defined it as in some header file. Have a macro for text? The macro gets written in place of everywhere you called it. All of this work produces a new, unique cpp file, and that's what gets compiled in the end. Not your Some compilers will give you a command line option which will actually write out the entire cpp file after the preprocessor stage. That's awesome for troubleshooting picky header files. Not so much fun if you have to guess at what's going on. So, you have these cpp files that have no knowledge of each other. Furthermore, they don't even know what the next line in the cpp file is. But they know about the lines that have already been processed. But, we have header files which give definitions for things the compiler doesn't know about. Why not just stick all that stuff in the cpp file and stick main at the bottom? After all, this is what you said to do yourself. Well, what happens when you have more than one cpp file? You've got a bunch of functions in this other cpp file, but you want to use them in the same cpp file you've got your main function in? That's no problem for the compiler, provided you tell the compiler what each of those functions look like. And this is what the header file really does. It provides a way of offering continuity between the separate compilation processes for multiple cpp files. Sure, you can just put main at the bottom of your code page. No problem. It works. And it does what you want. No one will fault you for that. No one will say a word to you about it. But it limits you to a single code page. I don't think you can accomplish a great deal with just a single code page.
I've been a software engineer for 20 years, mostly working in C and C++ and, in my experience, this comes down to a matter of preference. I prefer it your way but I wouldn't try to get other people change their habits. That is, when the function definition occurs in the same file as the function call, I usually put the definition before the function call just because I don't want to maintain the parameter list in two different places of the file. Some people find that unnatural. However, if your instructor is having you write code in a single file (for convenience) but will eventually have you split it up into multiple files (header and source files), then I could see how their method is more appropriate. When you're talking about class methods, this won't be an issue because you have to put the prototype in the class definition. 
I'd usually rather reorder my code than maintain parameter lists in two different places.
It's not always possible. Consider a pair of mutually-recursive functions. Also, it's not usually too much work to match them up. If you're using an IDE, it may generate some code for you and have support for refactoring. Finally, think of the person reading your code. It's not nearly as important how easy it was to write as how easy it is to read. It's much better to have your functions arranged in some logical order (grouped by purpose, or at the very lease alphabetized). With function prototypes, you can put them in any order you like.
You can only put main() last in toy/beginner code. In real code, not all functions will be in the same source file, so to call them will require that their prototypes are available in a header. In fact, when you're using someone else's library you won't even have the code to the functions you're calling, so you couldn't put main() last even if you wanted to. 
Don't prototypes also avoid ordering problems? So if foobar() can be called by main but is all called in jerryrig542() you don't have a problem with ensuring foobar() is declared before jerryrig542()?
if you have two functions which call each other, then you MUST use prototyping. 
I did ask myself the same question. The answer it: use std::move in place of std::copy. It lets you move elements from one container to another. I'll include it in the next tutorial.
I just want to let you know, if I am *ever* in a situation where I would have to maintain your code, I'm going to kill one of us.
The main thing you're missing out on is the ability to change the code in one of your function implementations without having to recompile the entire program. The key is that .cpp files are compiled independently of each other (look up translation units), and then brought together by the linker to make a complete program. This independence means that if you change something in one of your .cpp files, only that file needs to be recompiled. Maybe with 10k lines of code the compilation time isn't too offensive, but with 100k, 500k, 1m+ lines of code compilation can take a very long time. Once you've come to the conclusion that having separate .cpp files in your project is a Good Thing, then the declarations in header files (.h files) are simply the way that your .cpp files are able to know about each others' functions.
Then don't program in C or C++. It comes with the territory. What is great fun is when in your header you have: runSomething( int numberOfSteps, int sizeOfSteps ) and in your source file you have runSomething( int sizeOfSteps, int numberOfSteps ) There is no obligation for the compiler to check the names of parameters (you can leave them out entirely in the header), so I'm not even sure at what warning level you will even get a warning for this one, since there is no type mismatch.
Do you know if the link times are much improved if you keep as much out of the headers as possible?
At worse, you'll get a warning from the compiler but the linker won't care.
The only problem is that you have to pay to look at these rules. Here I think (at least you can get them for free) better guidelines http://www.jsf.mil/downloads/documents/JSF_AV_C++_Coding_Standards_Rev_C.doc
No :-) I have one cpp file with a couple of hundred lines, which just holds the main() to launch the main loop and set some things up, everything else is #included from 40-50 .h files which contains their own modules and sub routines, everything is implemented directly in there.
Well that makes sense to me, nicely put. Compiling isn't that bad, still takes about 15-20 seconds so I guess that's still unnecessary waiting. What about Intellisense-type features in IDE's, would they get quicker? I've sort of been learning C++ along the way with this project so I started off having (presumably) awful practices, and 10.000 lines later I've learned a lot. If I'd do this project all over again, I'd make different choices. But maybe it's still worth moving all the implementations over to cpp files at this point, for maintainability by others and compile speed. Personally, I don't mind that the implementation and declaration is at the same place, but I hear your.
Isn't this subreddit for C++? what does guidelines for C have to do with C++? are they applicable in C++ as well? C has some differences from C++. C is not a proper subset of C++. 
It seems C++11 adds another embedded compile-time language -- a restricted version of C++ itself. At least it's more readable than template metaprogramming! 
you may want to look at / post the disassembly. 
That's for C++, not C. Also, it builds upon MISRA.
Using the same contains as in the post, this simpler program: double numbers[10*contains("hi", "h") + 20 * contains("jklas", "u")]; int main(void) { std::cout &lt;&lt; sizeof(numbers) &lt;&lt; "\n"; } includes this in the assembly file header: .globl numbers .lcomm numbers,80,8 .type numbers, @object which looks like a static size array. (I'm not particularly good at reading this.) 
There is a MISRA ruleset for C++ too.
The disassembly of the blog post program (unoptimized) includes one function ZNKSt5arrayIiLj10EE4sizeEv and one called ZNKSt5arrayIiLj0EE4sizeEv I think those are the inlined specializations of std::array&lt;int,10&gt;::size and std::array&lt;int,0&gt;::size respectively.
You'd never get a warning for that.
Pity they didn't go further with this.
Pointers **are** variables, but the value they hold is associated with the address of another variable. 
Firstly, lets define a pointer: a pointer is, like another variable, containing a value. This value has to be the address of another variable. Is this useful ? Of course ! You might know that when you create a variable in a function, like: void toto(int i) { int a; } the variables a and i are destroyed when you leave the function toto. But sometimes (in the real world, often) you need to modify one of the parameters of the function and you want the modification to take effect on the scope where you called the function. In C, the only way to do this is to use a pointer. What is a pointer ? A pointer is a variable containing a memory address. If you use a pointer, you can access this memory address like another variable, with the difference that any modification to the pointed address will be held in the memory. This is one of the most powerful feature of the C and C++ language, but WHY is this useful ? lets take a simple example: int main() { int a = 4; int b = 2; } If you want to swap the values of a and b, someone not knowing the pointers would write something like this: void my_swap(int a, int b) { int c = a; a = b; b = c; } But if you know about the calling convention of the function, you know that a and b are just copy of the originals value passed to my_swap, and that this function don't work at all. So if you write something like this: int main() { int a = 4; int b = 2; my_swap(a, b); } the values of a and b will be the same as earlier because when you call a function, the parameters are copied. Someone knowing the pointers would write my_swap like this: void my_swap(int *a, int *b) { int c = *a; *a = *b; *b = c; } With this one, the value are directly modified at their memory location, so if I call my_swap(&amp;a, &amp;b); the value of a and b will change. Knowing this, you can do anything you want ! Any function can change any variables if she has the addresses, and do every computations that you want ! If you don't understand the usefulness of the pointers, don't worry ! Everyone got troubles with this in the beginning. If you continue to learn C/C++ seriously, you will get used to this, and one day you will realize that this is the most powerful and dangerous feature of the C/C++ language ! Good luck !
Please read my question again, thoroughly. I state my understanding of what pointers are and how they work, but my question is when I should declare variables directly, when I should declare variables using pointers, and what the difference is when it comes to manipulating them.
Thank you so much, this helps me understand pointers a lot better!
To get demangled symbols, pipe the output through `c++filt` or use `-C` if you're using objdump.
As has been pointed out, pointers are useful if you want to manipulate a variable inside a function (references do that too but we won't get into that). But the real beauty of pointers is that they allow you to work with data where you don't know beforehand how many you will have. If you use standard variables you need to know at compile-time how many there will be, whereas if you use pointers that doesn't matter; you just allocate a new pointer for each (then use pointers to add them to what you already have). The simplest example is a linked list, where each entry consists of two parts: the data, and a pointer to the next one. You have a pointer to the start of the list and you can use the pointers to go through the list to the end.
That's not quite how .h files are supposed to work. H is for header; they're only supposed to hold stuff like #defines, function prototypes, classes, inline functions, and templates. Pretty much all the stuff that can't be compiled to any worthy binary on its own and also needs to be seen by other .cpp files too. Then all of the corresponding functions and class methods go into a similarly named .cpp file. Here's an example of how the split works: **main.cpp** #include &lt;iostream&gt; #include "stuff.h" int main(int argc, char *argv[]) { int x = foo(); std::cout &lt;&lt; "x = " &lt;&lt; x &lt;&lt; std::endl; Bar *b = new Bar; std::cout &lt;&lt; "b.message() = " &lt;&lt; b-&gt;message() &lt;&lt; std::endl; delete b; return 0; } **stuff.h** #ifndef __STUFF_H #define __STUFF_H #include &lt;string&gt; int foo(); class Bar { public: std::string message() const; } #endif **stuff.cpp** #include "stuff.h" int foo() { return 4; } std::string Bar::message() const { return "This is a message from Bar"; } Notice the first two lines and the last line of the stuff.h file. This checks whether the file has been #included already, and then it's only interpreted if it hasn't already been. This means it's completely safe to #include the .h file multiple times within the same .cpp file. (In a simple project like this, the need for safety isn't immediately obvious; more complex projects often have many .h files which may then #include each other possibly multiple times.) Note that you almost never want to #include a .cpp file, or any file with non-inline function definitions. Now you can compile main.cpp to main.o, stuff.cpp to stuff.o, and then combine main.o and stuff.o together into an executable "main" with the following commands. The benefit is that now if you change stuff.cpp, you only need to recompile stuff.o and then remake main, without needing to recompile main.o. (These commands are assuming you're using some terminal and GCC; if you're using an IDE like Visual Studio you can skip the rest as it should be able to do this stuff automatically once you put all of your .cpp and .h files into a project.) g++ -Wall -c -o main.o main.cpp g++ -Wall -c -o stuff.o stuff.cpp g++ -Wall -o main main.o stuff.o This can be automated with a Makefile: **Makefile** (NOTE: All the indents in this file have to be actual tabs.) CXXFLAGS=-Wall all: main main.o: main.cpp stuff.h stuff.o: stuff.cpp stuff.h main: main.o stuff.o $(CXX) $(CXXFLAGS) -o main main.o stuff.o clean: rm -f *.o rm -f main Now if you type "make", it will automatically figure out what it needs to compile and will do it. You can also type "make clean" to remove all the compiled stuff so you just have your source files left over. Note that the Makefile doesn't have explicit instructions for how to make main.o and stuff.o from their source files; the make utility already knows how to do that stuff implicitly.
thanks, that's useful
In case you haven't seen the [C++ FAQ](http://www.parashift.com/c++-faq-lite/index.html) it is extremely useful. The C++ FQA on the other hand is a collection of responses to the FAQ pointing out all the deficiencies in the C++ language.
I did, years ago, good laugh.
Not only can you check for substrings at compile time but you can check for grammatical constructs such as c++ integer literals (with all their suffixes) and do all sorts of compile time processing with strings - such as creating new strings, transforming them, upper-casing, lower-casing and other algorithsm. I partially implemented such a library at http://constexprstr.svn.sourceforge.net/viewvc/constexprstr/ (check out towards the end of main.cpp for a sample implementation of a C++ integer grammar checker). And yes it is certainly more readable than C++ template metaprogramming.
Yes. It would be great if the quality was better. In this edition it's just pile of crap.
Despite all the downvotes you're getting, the FQA has actually been a very good source of info for me. It points out the many ways that C++ can shoot you in the foot, and all the gotchas/surprises C++ is full of so that you can be mindful of them and avoid them.
Other big ways you'll see pointers getting used - Data structures - some data structures (like linked lists or trees) can't really be implemented *unless* you use pointers. Without pointers, you're restricted to a very simple set of data structures, a set that just isn't sufficient for modern development needs. Another big place you'll see pointers (and their nephews, references) getting used is that if you're passing around big objects, or objects that you can't copy, you have to pass them around as pointers or references. One other thing I'd note is that in a *lot* of cases, you won't be passing around built-in pointers, you'll use "smart pointer" objects. Those take care of a lot of the trickier aspects of dealing with pointers, like making sure what they point to gets destroyed properly when it's no longer needed. Smart pointers keep the benefits and usefulness (and if done right, the syntax) of built-in pointers without a lot of the nitty-gritty.
If someone is enthusiastic about an idea he will be always talking about it.
Occasionally the blonde guy reminded me of myself. I liked the ice cream pun. And I want to become more like the girl.
Absolutely.
Good to see someone is studying hard on C. Good for you, have an upvote.
Yes I did. I would not recommend it. The author overdramatized issues and even sees problems where there are none. Some things of what he writes seem terribly confused. 
So, you learn about pointers on your third day? Weird. I hope you are using a decent book. It would be a shame if you used a book that teaches you C with a bit of C++ sprinkled on top in later chapters. Get Stroustrup's new programming book or pick up "Accelerated C++". A prime example of pointer use are data structures like a linked list or a binary search tree. Try doing that without pointers. Basically, you need to use pointers (or something similar) to be able to refer to other things. To answer your question: If you have the choice, go without a pointer. But sometimes you don't have a choice.
When you're just starting it, it's generally not a good idea to use any pointers, as that implies that you're using arrays instead of vectors. Stick with STL containers and references if you need to modify values across functions. One of the main driving points behind C++ is to do things in a safer manner than C and that includes not managing memory manually, which means no pointers (at least, not until you get to a point where you really know what you're doing and need to do something like a heterogeneous list using base class pointers.) 
You really ought to. If you are going to supply a name, they should match.
This is the example they use in the book I am reading, to both explain pointers and references! Good stuff!
Unfortunately, for every deficiency he gets right, he gets three more completely wrong...
I tested on g++ here, and it set x[0] to 0. But afaik this is undefined behaviour, so each compiler can behave differently.
It's 0 due to the post increment. The increment operation is performed after j is evaluated, thus j's value has not changed (yet).
It's undefined behavior because the order of evaluation matters. Is *x[j]* evaluated before or after the increment operation? Well, C/C++ doesn't define which side of the assignment has to be evaluated first so you'll get different results depending on whatever the compiler implementors decided to do which is generally a bad thing.
A little digging indicates [undefined behaviour](http://stackoverflow.com/questions/2538562/in-what-order-does-evaluation-of-post-increment-operator-happen).
This thing reads like one big temper tantrum about C++.
Can you point those out?
&gt;C/C++ doesn't define which side of the assignment has to be evaluated first What!? j++ is post-increment so after that line x[0] is 0 and j is 1. This is all clearly defined. On the other hand ++j is pre-incrment and in that case x[0] would be unaffected. j would still be one and x[1] would also be 1. And this is all basic operator precedence stuff and it's not even C++ specific! 