&gt; ... stop this computer. Halting problem solved.
Not C++ but this might give you some ideas http://www.jsfuck.com/
My favorite is "far member access" a---&gt;b
Pretty sure conan satisfies the behaviour you describe, you can change what settings a package accepts. Like you mention, release/debug are nothing but convention. You could add more build types and have logic in your recipes to evaluate their values and toggle those build flags. Same for the arch setting, you can have a subsetting for the CPU family whenever the value is x86\_64, etc. But hell, in the end what you want is a different hash for every value / combination of values that result in a different binary package. You could add an option to your recipes (e.g. `extra_flags` that either accepts \`any\` value or a pre-defined set). You could pass those when creating the binaries, and they would result in different packages. if you keep the convention within your recipes there are ways of passing the same options to all packages etc so you know it's all consistent (if that's what you are after). &amp;#x200B;
QString::isNull() returns true for QString() and false for QString(""). It's a legacy thing, you use isEmpty() everywhere instead. The only case I know when it matters is QSqlQuery. When you bing an isNull() string for argument it creates null value instead of empty string value.
I've always found Qt to be easy to use. What problems were you having with it that caused difficulty?
The normal keyboard routines will be fast enough.
Qt is pretty easy to use. Yes it requires a lot of stuff, but that's the price for the convenience you get once it's running.
I've had good experiences with [wxWidgets](https://www.wxwidgets.org/) on Linux, and the Windows story is supposedly even better. I find it more straight forward and flexible to work with than Qt, partly because it's only solving the GUI problem.
Sounds like a solution in search of a problem
`_` could be a macro.
What are the benefits compared to [monotonic_buffer_resource](https://en.cppreference.com/w/cpp/memory/monotonic_buffer_resource/monotonic_buffer_resource) and [unsynchronized_pool_resource](https://en.cppreference.com/w/cpp/memory/unsynchronized_pool_resource) ?
in the underlying c library? No. But this is supposed to be provide c++ encapsulation. So it should be able to have any interface 
I don't know how easy it is to set up on nin-free systems, but API-wise gtkmm is the only GUI-library which embraces modern C++ that I am aware of. Qt on the other hand is an abomination and the counter-thesis to everything modern C++ is about.
I do not understand why you had any problems with wxWidgets, for me it worked right out of the box. It might not be the most modern interface, but it more or less works as advertised, has ok documentation and is not that bad on bugs. Their license is nice and you get really good support on the different forums.
But your claim was that it's C and not C++. It is both C and C++.
That is quite a non-realistic use-case, your thin air delivered. A more normal case could be perhaps top three out of 10000? And a little prechecking could actually help in that case as well: If you have a very small N (as 3 is), you could make partial sum run in O(n) (where n is the size of the input, not the big N which is of course smaller ;-)).
Kate Gregory has many good points, but I do not always agree with her either. It beats me your comment is downvoted - could anyone explain why? An [[not_reachable]] attribute would be nice to have here and preferred if available.
Things that exist for backwards compatibility are typically called C problems. Whether that is valid or not is an interesting discussion but it helps point to why it is a problem.
I have also considered trying Juce - it seems to be a good library.
Get 3 largest elements out of a set of 20 is unrealistic? O.o Get your head out of your ass.
I think an immediate mode GUI may be more your speed. https://github.com/ocornut/imgui 
I agree, there is not so much difference between both. We could argue that a reference might discourage pointer arithmetic. That the meaning of a pointer is not always obvious as it is part of the C heritage where everything was passed by pointer.
You can call it C and say it's in C++ due to backwards compatibility, but you would be incorrect to say it's not C++. It's similar to how we don't say header files are C and not C++. They're both C and C++.
&gt; The problem is that the borrow checker forms a directed acyclic graph of dependency and ripple propagation. Yeah, I can see how that could be a problem. Lifetime elision would help some, but if you're switching from owned stuff to non-owned stuff or vice versa, I can see how that could be pretty painful. &gt; I suspect that makes it as painful as it is in Ada to refactor, but without all the other benefits Ada comes with. What makes Ada painful to refactor? &gt; Perl and Ruby people just abandoned/are abandoning. I can see why people abandon Perl, given its reputation for being write-only, but I don't know as much about Ruby. Is it just too dynamic for maintainable codebases? &gt; It's literally shipping in compilers today. It's called `constexpr`. D'oh, can't believe I forgot about that. I was expecting something more like "traditional" formal verification, involving SMT solvers and whatnot. &gt; I'm actually currently arguing with WG14 that they ought to adopt the subset of C which is constexpr compatible formally as "safe C v3". What is "safe C v1/v2"?
&gt; What makes Ada painful to refactor? The whole point of Ada is that *is* painful to refactor. Nobody can deviate from the spec without a world of pain, and each component locks the spec of every other component. Don't get me wrong, Ada's great for safety critical, there you really *want* refactoring to be painful so people design and write the thing right first time. Quality software is not hard to make. It is however expensive, and tedious. &gt; What is "safe C v1/v2"? I believe C have checked C, and formally verifiable C. So a "v3" moniker seemed about right.
https://github.com/vurtun/nuklear I haven't ever used Nuklear, but it is another immediate mode GUI. This one is easily skinnable though.
This made me smile... (paraphrasing): &gt; "Undefined behaviour absolutely cannot happen in `constexpr` functions... it's really scary for compiler implementors, because there's no guarantee you'll get a valid program" But it's fine for the rest of us to deal with at runtime?
You want an easy GUI that's also simple? Yeah, just learn QT. It only takes a couple days of reading their phenomenal documentation to understand the architecture and write a decent app in QtWidgets. QtQuick and the designer also exist to make the frontend stuff look nicer and just hook into C++ for core logic.
\*\*Company:\*\* \[Carbon Black\]([https://www.carbonblack.com/](https://www.carbonblack.com/)) \*\*Type:\*\* Full Time \*\*Description:\*\* Our Carbon Black Response Sensor team is looking for Software Engineers with experience in macOS or \*nix development, computer security, and development of enterprise-grade endpoint software systems. Ideal candidates have experience developing code against posix on unix platforms writing code in C/C++ for endpoints as well as a passion to create a world class security product. If you love computer security and digging into complex engineering challenges, then we want you on our team! \*\*Location:\*\* Waltham &amp; Boston, MA, USA or Portland, OR, USA or Boulder, CO, USA \*\*Remote:\*\* Yes \*\*Visa Sponsorship:\*\* No \*\*Technologies:\*\* C++11, Xcode, Python \*\*Contact:\*\* Interested? Apply online [https://jobs.jobvite.com/carbonblack/job/oC0A8fw4?nl=1](https://jobs.jobvite.com/carbonblack/job/oC0A8fw4?nl=1) PM me or send email to [sfehser@carbonblack.com](mailto:sfehser@carbonblack.com) 
Conan looks interesting and I'm thinking about using it for a pet project. However, I was wondering if there is some sort of way to browse the available packages without installing it? I can't seem to find one on the main website.
[removed]
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9ninfw/_/e7n4ykt/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I wrote a compile time HTML templating engine that uses constexpr (documentation is sketchy, contributors and reviews welcome) https://github.com/rep-movsd/see-phit
Sure, let's move it to priv, to not spam here.
Gammaray has been a real game changer for Qt MVC programming. It makes it extremely easy to debug issues in models and proxy models.
I'm still trying to figure out how to build glibc with gold or lld. It *really* wants bfd. 
My favorite small lib is Nana. Builds on Windows/Linux simply, the API is reasonable.
Let's say that instead of `constexpr auto v = foo(42);` there's - `int bar;` `std::cin&gt;&gt;bar; //bar is 42` `constexpr auto v = foo(n);` In this case compile time evaluation won't happen, what happens when `foo()` is called now? Does it throw since there will be no compile time evaluation or will it error out on the basis of a throw being in a `constexpr` function? 
I am working on a small scale memcached clone , was looking into Boost::asio for all the networked code, I am tempted to use seastar instead. Also anyone here used FB's Wangle recently?
It is pretty good. 
An optimized qsort? Why should one use in C++? There is std::sort with a much simpler C++ interface!
Nuklear is terrible. I doesn't make much sense, is extremely difficult to get anything to work and has next to no documentation. I don't really know how anyone uses it - I wasn't able to make anything work, even after scouring the source. 
[godbolt](https://godbolt.org/z/iF-yS7) is perfect for testing things like this
Thanks a lot! I remember seeing this for some posts on the sub.
You probably want to try Java and coming back to Qt when you have the right experience and find it easier.
Well, the constexpr function still needs to follow certain limitations (prior to C++14 the function can only contain a single return statement, currently try/catch is not allowed, etc) if that is what you mean, because the same implementation needs to be valid in both the runtime and constexpr contexts. As far as I am aware the only change in behaviour between the contexts is the throw statement.
Yes, that is exactly what I meant.
It’s not easy to beat std::sort.
I put them immediately after the primary template’s class definition.
Yeah, in retrospect I didn’t emphasize that enough in the post (although it is briefly mentioned). My talk stressed it more.
WordPress has a habit of mangling my posts 😿
See no evil, hear no evil.
Our industry. Damn.
That price tag, though... (https://www1.qt.io/buy-product/)
I like qt, its free if you opensource (like i love) and qtcreator is awesome
I got to the "C++ is weakly typed" sentence and stopped reading. If C++ is weakly typed then what language is strongly typed? Haskell?
The part that surprised me was that `throw` is allowed as part of the ternary operator at all, even ignoring `constexpr`.
Yeah, I stumbled over that, too. I guess the author is making the claim that only a weakly typed language is allowed implicit conversion?
It's also licensed under LGPL.
Not all of it, and the present caretakers throw enough doubt in the mix to give pause to commercial users.
yes, though it has many more false positives, potentially.
&gt; * include/experimental/internet: New header. `#include &lt;internet&gt;`, here I come!
Adam and Eve are no GUI library. Adam is a DSL to describe the relationship between different UI elements. Eve is a layout system. For both, you need a binding to a UI framework. For older systems the adobe_platform_libraries are available. (But I have not tried it so far.)
Experimental internet =D \#include &lt;experimental/internet&gt;
I wouldn't say C++ is weakly typed, but it's not strongly typed either, there are much stronger typed languages out there. 
[https://www.youtube.com/watch?v=ygr5AHufBN4](https://www.youtube.com/watch?v=ygr5AHufBN4)
Do you plan to publish analysis anywhere? BTW: I participated in the survey
Your RSS is missing the published Date field, so I can't import it into the Meeting C++ tooling :/
strong and weak are relative terms. The article starts off with a tweet comparing it to JavaScript and then calls C++ weakly typed. If the article started comparing C++ to Haskell or something then it wouldn't be so jarring
From sidebar &gt; For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow. 
The analysis in the article is incorrect. The faux operator overloads `bool operator!(bool)` are only used in overload resolution where they are needed to form part of a user-defined conversion sequence. Applying an operator to an object of built-in type does not invoke overload resolution and cannot involve user-defined conversion sequences. This code is covered by C++17 [expr.unary.op]/9: &gt;The operand of the logical negation operator `!` is contextually converted to bool where *contextually converted to bool* is defined elsewhere. So the list of steps in the article summary is still correct.
don't post non-questions as questions, please. Make it clear what your post is from the title.
I don't really see anything wrong with those conversions though. Well, maybe the bool to int one. char[] to char* is required for anything using C strings (including std string constructors). T* to bool lets you do `if (ptr)` and `if (!ptr)` instead of explicitly comparing to nullptr. bool to int is probably for backwards compatibility from before it was a type (e.g. C code).
`bool` did not exist in C before C99. C is the one that could be making the "backwards compatibility" argument here.
[Wat](https://www.destroyallsoftware.com/talks/wat)
I get that they all have their purposes. I think most of the problem here resolves around an eagerness to interpret pointers as having meaning numeric meaning.
I usually prefer to explicitly compare to nullptr, because I'm checking a pointer concept, writing a few more characters doesn't impact productivity, and it can give more insight on the variable type (e.g. `if (banana)` vs `if (banana != nullptr)`).
No.
🎉 @stl. Is there any ongoing work on Network TS for MSVC STL? 
/u/BillyONeal is investigating right now.
The part that surprised me was that even though the type of a throw expression is void, it is allowed to appear in a ternary when the other operand is not void.
What doubt exactly? I mean the marketing department is obviously trying to sell commercial version for commercial projects, but apart from that I haven't seen anything out of ordinary regarding Qt licensing compared to other LGPL projects, am I missing something?
Please go ahead! :-)
&gt; Quite reduntant of you to say that at that point, there's been numerous hints about how rigid your mindset is. How you focus on less relevant details instead of the big picture, ignoring fully the essence of the problem. And even during criticizing the details you do it so sloppily: Blah blah blah, more nonsense. &gt; Indeed I stated what you replied to with bad English, it happens, was it unclear? Hardly. Wrong. Or else I'd not have asked for clarification. &gt; m_iWidth? Of course it is Hungarian notation; by the way, Star Citizen, one of the greatest undertaking in game development history uses this exect convention. Yes because one game using it suddenly makes it good, great logic. &gt; [A bunch of other nonsense here] I briefly glazed through the rest of the stuff and I realized responding to you is pointless. I think you are wrong, stupid, and you have no idea what you are talking about. You think I am wrong and some other mumbo jumbo, which is fine by me. If you did write anything of importance in the rest of it and I missed it, I would have read it if your noise to signal ratio wasn't all noise. No one cares about your opinions on stuff and certainly not me. I didn't mean to trigger you, and worse is that I feel slightly bad that I led you on to possibly thinking I care what you had to said at all. This is my bad.
1) The almost immediate 10x rise in price has all but killed Qt for indie and start-up development. $6000 per developer per year is just way too much considering the many good cross-platform alternatives - mostly free. Since this is really the only viable C++ framework (Juce is not quite there), it means very bad things for the long term health of the language. No indies, no startup == slow death. I don't know about you, but i don't want C++ side-lined to just the embedded world. 2) The switch to LGPL V3. With its patent killing clauses, its a non starter for startups.
I thought there was a dependency on executors that haven't been finalized yet?
What should you do? Try harder and do more. There isn't some magic bullet. Try to do something and look up what you don't know. The internet makes it easy if you are willing to put in the work.
Ok, dude. I didn't ask "what should I do?" I understand that perusing stack exchange and googling specific questions is helpful, but your response of "do more" comes across to me an insinuation of laziness on my part. On the other hand, if this isn't the appropriate forum for this query, I understand and apologize.
The coolest thing I did, so far, was a web server to serve 1 billion unique, state-full web sites on my laptop. The thing had an embedded DNS server as well. Some years ago I worked at one of the really big software shops. It drove me crazy to go on for days, may be even a week, to get a 3 line fix trough the build and verification process (usually because the CI process shoot itself in the foot). So I needed a side project that was just pure fun. At that time Microsoft IIS got a very high rating on a yearly "most popular http server" report, compared to nginx and apache. I suspected that they may run millions of instances of IIS on idle resources in their data-centers to manipulate the ratings. Once in a lunch break, I joked about writing a tiny web-server in the then new C++ 11 language, and climb to the top of that rating. According to the rating, there were about 1 billion distinct web sites at that time. After a few weeks of development in the mornings, before I went to work, it worked. I connected my laptop, with my new web-server to Internet, and added another 1 billion unique websites - effectively hosting 50% of the Internet. Everything running on my ThinkPad W520 laptop ;) When I tested it locally, the server handled around 170.000 http requests per second over the laptops gigabit nic. That was fun. Not at all useful, but definitely fun.
I don’t know. QTs licensing page (https://www1.qt.io/licensing/) does a pretty good job at sowing enough doubt to make it a hard sell in any commercial environment where a corporate attorney might actually review this. The LGPL has always been a bit murky, and reading the license text makes it worse. The QT folks go out of their way to instill enough fear and uncertainty in a blatant attempt to cough up $5k/yr. I wouldn’t be surprised if they were aggressive in enforcing terms. 
Why isn't it called "..../tcpip" or similar.. internet is just one specific network.
Real men have -Iexperimental in their CXXFLAGS
Because IP stands for Internet Protocol. That being said I agree, they should have named it sockets or something like that. My guess is that since the STD originally don't include specific implementations but rather abstract concepts, sockets wouldn't fit as it is too platform specific.
And parallel algorithms.
You are right i agree. There is udp as well and they both build on top of ip so maybe ip would be a proper namespace or internetprotocol. Everything under that namespace will be implementations that runs the internet protocol. If it was ftp the namespace would have been filetransferprotocol or ftp .. but never just filetransfer. Calling it just internet is misleading because there is a lot of tech stuff under internet. Smtp.. ftp http. Could also be implemented under the internet namespace. If that is the plan though I'm fine with that name. :-) 
`import std.experimental.internet;` // Only backwardness promotes #include
GCC is always the fore-front, 7 times out of 10
this is so dismissive and not helpful at all.
That didn't surprise me actually. It short circuits any function, since throw doesn't cause a return.
I a soooo hyped after Gabriel said that they made "fantastic progress on modules ... and ran out of work to do" at the special CppCon 2018 modules EWG meeting. Fingers crossed for San Diego C++20 feature freeze meeting. If they get modules in C++20 it would be easily be the most significant change in the structure of the language since C++ started.
Well, no, there is a lot of tech stuff *over* internet. Tcp, udp, dns, arp.... They're all descfibed in internet RFCs
The patent clause of the LGPL is only about the code of Qt itself. If you don't modify Qt and only link against it it does not concern you.
is the networking ts still a very high-level, very one-specific-style of doing things setup? 
thanks !
"It short circuits any expression" ? What does that mean? Should `if (foo || throw 0)` be valid then? (it's not) Ternary requires both alternatives to have a common type - except for this special case of throw. That's why it is unexpected. Also, Rakete1111 mentioned void. `int x = true ? 17 : (void)0;` isn't valid either. So it isn't because it is void, it is a special case for throw and ternary. 
Is that how much start-up plan is https://www.qt.io/start-up-plan/ ?
Qt is the only good cross platform UI when using C++. I really wonder what are those good alternatives, wxWidgets, JUCE, imGui with SDL, throw C++ under a truck and use Electron,.... 
LGPL was good enough for Apple to adopt Webkit. I'm pretty sure their lawyers wetted it thoroughly. Many other big projects like gstreamer are LGPL and routinely used in commercial environment. Any projects using Chromium (Steam, Spotify desktop client) links to LGPL library and nobody seem to bat an eye. Yes, the Qt licensing page is a big FUDy, they want to sell commercial licenses and I'm sure there are managers at Qt Group wish Nokia would never have licensed Qt under LGPL, but they did and there's no taking it back (they even have [agreement](https://www.kde.org/community/whatiskde/Software_License_Agreement_2015.pdf) with KDE Free Qt Foundation who could then release Qt under MIT). LGPL is perfectly viable license for commercial projects, many big companies are linking to LGPL code in their core projects, there is no reason to think Qt would be any different.
Nice! What are you referring to when stating "you do not want to define the qfunctions this way in production code"? 
Well, technically you can even link statically, as long as you provide object files for user to relink. 
 if (foo || []()-&gt;bool{ throw 0; }) is valid. The difference is just syntactic sugar.
I think you are fine; there isn't a way to loop using those constructs.
Wrong sub. Most likely belongs to r/ProgrammerHumor
I think it was QtCharts or something alike. I was not directly involved in the discussions. However, take a look at https://doc.qt.io/qt-5/licenses-used-in-qt.html. Even for commercial licenses you still have all that third-party code in your products and a single mistake can quickly jeopardize your products legal grounds. This is something that most small companies do not really have to worry about, but a big company presents a big target for law suits.
Okay , Thanks .
Some of the newer Qt modules (Qt Charts, Data Visualization and Virtual Keyboard) are not [LGPL licensed](http://doc.qt.io/qt-5/qtmodules.html), but they are very explicit about this and is very hard to overlook. I don't quite see the "very bad time separating the individual parts" you mentioned in your comments. I don't see any mandatory LGPL dependencies of Qt apart from WebKit in QtWebKit and QtWebEngine). QtScript is LGPL, but they have another javascript engine available under commercial license.
`&lt;regex&gt;` is still slow with either of the three most common compilers and multiline support simply doesn't exist.
Well I'm not sure I completely understood what you said , I think they are cool because it's fun to have your style out of the app , it's like building websites , you can just specify a css theme , and edit it anytime , but what you mean by older systems ? you mean old like Windows 98 or something ? :D
Okay , Let's give it another try , but I still don't think it's that easy , specially when building using QtCreator , I lost myself into it .
I'm confused , isn't Qt a c++ framework ? I mean I'm not new to programming , I used to be a web developer , and I already learned C lang , my issue with Qt , is more to compiler and components handling more to a understanding . 
Agree , easy and reliable but the truth , GUI isn't that good , maybe it's a personal feeling , but it doesn't looks good on windows , I liked it on Linux maybe because I like Ubuntu style I guess .
I'm giving it another try , but I used to made GUI using visual studio ([VB.NET](https://VB.NET)) it's very simple , I doesn't need to care about anything , I just put the design and do some logic code , while in c++ that's damn hard , every library or framework have a different code style , they are all C++ but looks different :\\ .
Great suggestion I like it , thank you .
Agree , I'ts a nuclear bomb ;d if we compared it to imgui , it's so hard to write a good app in it , but he has a nice GUI themes .
What platform you are using ? I tried to compile it on windows and failed , and tried to use the pre-compiled dlls with MSVC and CodeBlocks , but no luck too , I wonder how you did it .
well the problem not in the code , it's the way how I make it work , I had a headache trying to understand what should I download to make it run , after 30 mins I canceled the setup and downloaded the offline installer , 
Great suggestion , I will take a look at Juce , but I saw a weird text on their website : &gt;Leader for multiplatform audio applications &gt; &gt;Deliver music applications on all main platforms, with high performances and professional tools. &amp;#x200B; &amp;#x200B;
Hey, thanks! When you look at the template that's used ``` template &lt;class L, class R&gt; auto operator+(L&amp; l, R&amp; r) ``` Then it's a catch-all template. That means now you have a template that would match on ALL types in C++, e.g. you could suddenly add two custom types that are entirely unrelated (e.g. a std::time_point with an integer or something like that) and then you'll get a cryptic error message. A way to circumvent that (and how we do it in xtensor) is to define a CRTP base class (in xtensor it's `xexpression&lt;T&gt;`) that takes the derived class as template parameter. That allows you to create a function signature that looks like ``` template &lt;class L, class R&gt; auto operator(xexpression&lt;L&gt;&amp; l, xexpression&lt;R&gt;&amp; r) ``` This new signature will only match the classes for which it is valid. Inside of the operator, you can cast to the "original" class with something like `auto&amp; l_derived = *static_cast&lt;L*&gt;(&amp;l)` (in xtensor, this is accessed by calling `auto&amp; l_derived = l.derived_cast()`. Here is more information on CRTP https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern Hope that was clarifying a bit!
And once again: implicit conversions... one would think c++ has learned its lessons from its implicit conversion-C-heritage... 
Great article! It's kind of like an article that I read recently where one Julia developer claimed Julia was faster for reading some files with vertices and in the end his C++ version was only so slow because he was reading byte by byte with iostreams. The fixed C++ version was twice as fast in the end.
See also: [c++/oat++ service with Swagger-UI and auto-documented endpoints](https://medium.com/oatpp/c-oatpp-web-service-with-swagger-ui-and-auto-documented-endpoints-1d4bb7b82c21) [Github oatpp repo](https://github.com/oatpp/oatpp) &amp;#x200B; &amp;#x200B;
And C11 support.
Have you thought about submitting your framework to Techempower? I guess "submission" here means that you have to write the "fortunes" test yourself but it would provide a more independent benchmark and more visibility. With Techempower you will likely have to go with your async API but there is at least one high performance framework using pthreads and setjump/longjump style coroutines called Ur/web. 
Hey, thank you for the tip! I think I should try to do it
It really depends what your use case is, e.g. how expensive the comparison / move / copy of the type is. Even the different std::sort implementations vary quite a bit by use case.
Everything that would be a server application in Cpp
There's a very good library for that, known as [PAPI](http://icl.cs.utk.edu/papi/) for performance API. In the company I used to work for, they had something like this instrumentation built in the compiler. Very useful stuff. GCC has some instrumentation functions as well. You may want to look into that.
Do they include a separate header for Unix **stream** or **datagram** sockets? I looked that the paper and I don't see any mention of it. All this was all based on asio here, though it seems like a rather unaccomodating omission. C++ practically never acknowledges the existence of Posix. Hopefully asio or boost will pick up the pieces and rewrite that section of asio when the new standard finally comes out: http://think-async.com/Asio/asio-1.10.6/doc/asio/reference/local__stream_protocol.html http://think-async.com/Asio/asio-1.10.6/doc/asio/reference/local__datagram_protocol.html
on which OS are you ?
Reposting
Test it against fasthttp, net/http is easy mode and seeing your results against stdlib http implementation I would say fasthttp is faster than oat++.
And? They make audio tools and a gui library that started out being used for their audio tools.
Thanks for the comment, Think I should schedule this one
I'm looking for the same but I don't care if it's a video a tutorial, a book or something else.
One of my professors back in college put it this way: "Language benchmarks often show languages running a race with C++ when its shoes are tied together and then celebrate when C++ ends up being only twice as fast." (In that instance he was referring to benchmarks using a language's dictionary type compared to a C++ benchmark using `std::map`, but I think it's held mostly true for most benchmarks.)
Are you looking for something like live coding or just devlogs where they go over what they've done?
Here you just convert lambda to function pointer and then to bool. No relation to `throw`. If you add `()` invocation, then the type of the second expression would be `bool`, i.e. still no problem.
Native options: On linux I think you want to use perf_events.h in sampling mode (or just use the perf binary with -g). You can get the stack traces from the sampled instruction pointers. On os x instruments/dtrace is great. Not sure about windows. In terms of roll-your-own options, when I had to do something similar in the past, I used a single store of a unique-per-profiled-block integer token as my ACTION to some single memory location, and then ran a separate thread that polled that memory location at some short interval and tracked statistics. I made sure my application left one core free for that thread to run on. This gave me a roll-your-own sampling profiler that worked in a situation where I wanted something coarser-grained than instructions but finer-grained than the frame pointer, (and debugging symbols were not available for complex reasons).
honestly, both of them
Your best bet is probably twitch
Why don't you just read source code? There are [plenty](https://en.wikipedia.org/wiki/List_of_open-source_video_games) of available codebases. If you for whatever reason, still insist on a video format, there's [Handmade Hero](https://www.youtube.com/user/handmadeheroarchive/videos). Although many people here would consider that more C than C++ (compiled as C++, but restricted to C features), in case using modern C++ features is an important factor for you. &amp;#x200B;
**Company:** [Broadsign](https://broadsign.com) **Type:** Full time **Description:** As the leading SaaS company in digital signage, we’re a place for people who envision a better digital future and aren’t afraid to embark on ambitious challenges to change the status quo. We're looking for C++ developers to work on our Control suite consisting of a back-end, cross-platform media player and desktop administrative application. A more detailed description is available [here](https://broadsign.com/careers/software-developer/#view_job) and some of the reasons why Broadsign is a kick-ass place to work are [here](https://broadsign.com/careers/). **Location:** Montréal, QC. Speaking French is a plus, but not required. **Remote:** No **Visa Sponsorship:** No **Technologies:** C++11, Qt, PostgreSQL, SQLite, CMake, Jenkins. Both Windows and Linux. You're free to choose your tools. **Contact:** [Online form](https://broadsign.bamboohr.com/jobs/view.php?id=22). Feel free to PM me if you have any questions.
There is a pretty good series of [C++ in German](https://bytesnobjects.dev.geekbetrieb.de/cpp/).
I haven't streamed in a couple months, but you can watch me program a Vectrex emulator in C++ (17) here: https://www.twitch.tv/daroou2 YouTube videos of all streams archived here: https://www.youtube.com/channel/UCvGInSOEQnf2ms4n4Q9dXdQ Hope you find it useful, even though much of it is me figuring things out 😀
I‘m on mobile so here is just a quick gist of what you can do: Write the test case as a lambda instead of a function. Then store that lambda inside a global variable of some custom type whose constructor stores it in your global list of test cases. So the interface looks like this: test_case_list test_cases; class test_case { /* template ctor that takes a lambda and stores it inside test_cases */ }; test_case foo = []{ ... }; test_case bar = []{ ...}; int main() { return test_cases.run(); }
It's good being C++ dev now. So many changes can actually land on C++20. I hope it will be more of a revolution than C++11 was. Networking, coroutines, concepts, modules, ranges and plenty of other goodies (also waiting for Howard Hinnant date lib). Keeping fingers crossed too!
I like [Jason Turner's C++ Weekly](https://www.youtube.com/user/lefticus1) but the videos are a little short. I also enjoy [Bisqwit](https://www.youtube.com/user/Bisqwit).
&gt; Calling it just internet is misleading because there is a lot of tech stuff under internet. Smtp.. ftp http SMTP, FTP, HTTP, TCP, and UDP are part of the internet namespace in the same way "house" is part of the "bricks" namespace. I.e. it's not though commonly it will use bricks :).
Something something cherno bad something 
You can't go below raw IPv4/IPv6 BSD style sockets with it if that's what you are asking.
Maybe try ChilliTomatoNoodle. https://www.youtube.com/user/ChiliTomatoNoodle
is that how millennials study?
How did you conclude it's 34Gb? On the website if you download the offline installer it's around 800Mb including all source, all modules and QtCreator.
Bisqwit
Try also [Jonathan Blow's channel](https://www.youtube.com/user/jblow888/playlists) (of Braid and Witness fame), he has a playlist of Game Engine programming video clips.
Do people not like The Cherno here or something? Honestly asking because I think he has some good content.
I believe the majority of developers does not like him for choosing old-fashioned approaches or emphasizing the wrong things. (I like him anyway) 
404 Is it just not public yet?
Handmade hero's code is highly outdated and nobody should use that as an example when creating a bigger project. It's essentially C++ written as C.
Works for me.
I've got a few C++ videos on multithreading and template and class stuff. [https://www.youtube.com/srcmake](https://www.youtube.com/srcmake) I'll be making a couple of videos on move semantics and RAII (probably this week), and I plan to make a video on creating a vector class to show good fundamentals afterward. I'm not sure about a long-term C++ project. I've been looking into open source projects, but it's hard to break into good ones. Maybe I'll start a video series on it if I get a good idea.
Honestly, well-made educational videos are one of the best ways to study advanced topics. Mock millennials all you want but the fact that this exists and is used is freaking *amazing*. Unfortunately programming videos (outside of conference talks) seem to be almost exclusively terrible.
Lot's of interesting stuff. Very exciting. And looks like uniform erasure might finally move out of `experimental/` (P1209R0)!
Neat, this works: #include &lt;internet&gt; void foo(){ http://google.com std::cout &lt;&lt; "Yes, I am feeling lucky!\n"; } int main(){ foo(); } awesome; we can use URLs in code. See: https://coliru.stacked-crooked.com/a/edfeab8873d34855 it compiles!
Do the variables even need to be named?
I'm a millennial and also find this questionable.
Gonna let this thread live as we don't have such a list on the sidebar.
Cherno 
No I meant if it was just that one boost library. 
Pretty sure the entire point of Handmade Hero was to illustrate how viable these "old fashioned" ways could be. That said you'd be really missing out by ignoring all those videos and not finding something to learn from.
If you just testcase([]()) does it give that dumb lambda in unevaluated whatever error?
Oh, that’s what you mean. It doesn’t give the unevaluated context error but is wrong anyway because expression statements are not allowed in the global scope.
I updated https://www.reddit.com/r/cpppapers/
Benny does a fantastic engine dev channel. There is a full engine dev that is done in Java from 2014, but also has a mirror in C++ on his GitHub repo. He just started a new series a few months ago https://www.youtube.com/playlist?list=PLEETnX-uPtBUrfzE3Dxy3PWyApnW6YEMm
I don't really follow anyone, just browse occasionally, but there's usually someone doing C++ in the game development community https://www.twitch.tv/directory/all/tags/f588bd74-e496-4d11-9169-3597f38a5d25 There's also software development https://www.twitch.tv/directory/all/tags/6f86127d-6051-4a38-94bb-f7b475dde109
There are some C++ youtubers i watch: &amp;#x200B; [OneLoneCoder](https://www.youtube.com/channel/UC-yuWVUplUJZvieEligKBkA): This guy makes some videos based on game/graphic engines, algorithms and sometimes, low level concepts. He built most of his creations (2D and 3D game engine, racing game, First person shooter, etc.) for the command line. And (already suggested by others), [C++ weekly](https://www.youtube.com/user/lefticus1), explores modern C++ features &amp;#x200B;
Honestly, this makes me want to bench test StringIO. it's not optimized at all, and I'm sure I'd lose to most of those algorithms, but i'm still curious. Also, what's going on with LLVM's Unicode library?
I would look at the talks coming out of CppCon and other bigs ones. You will find a few talks by Chandler Carruth, John Lakos, Kate Gregory, Walter E. Brown to be particularly good.
As someone not familiar with web technologies, I would really like a rundown of what's going on here. WebAssembly is a bytecode VM currently available in all mainline browsers? There is also asm.js, which is a... subscript of Javascript that with proper annotations can be executed faster by browsers? There is also Emscripten, which compiles LLVM IR into JS... or is it the asm.js subset? And there is also nxxm, which... does what? And, how can `&lt;script type="text/c++"&gt;` even be possible at all? Is this the actual HTML that gets fed to the browser?
Benny has new videos... and they are in C++... def one of my favorite to watch.
Look at this graph, it's crazy: https://twitter.com/Cor3ntin/status/1051221855338676224?s=09
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/apolloapp] [URL bug? The link in this post 404s in Apollo, works in Safari. Seems to turn the # into %23](https://www.reddit.com/r/apolloapp/comments/9nyb4z/url_bug_the_link_in_this_post_404s_in_apollo/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
&gt; There are types that cannot provide an ordering, like std::complex. It just doesn’t make sense that they have an operator&lt;. That ship has unfortunately long sailed. There's tons of types for which `operator&lt;` doesn't make sense: any owning pointer (they can't point into the same array), optional, variant: these are all types for which in general the ordering is just silly, and should probably never be used directly (i.e. writing code that does `a &lt; b` with two values of these types, as opposed to using the ordering to do sorting, ordered container, etc).
You're not wrong.
Ok.
&gt; but the videos are a little short I think they are good in length. It's concise, focused and stays on point. Seen a few programming videos, and there is nothing more boring than watching some guy typing in real time and mumbling in a monotone voice for 30 minutes.
There isn't really a good reason to do old fashioned code these days anymore, especially on new projects. I get the nostalgy and people referring to the old days, but these kind of projecrs can have a bad effect on people learning to code. They pick up patterns they shouldn't use.
This is actually embarrassing. Did nobody notice this?
Remember the Vasa! and [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0939r0.pdf](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0939r0.pdf) 
I'm sure everyone is well aware of it, it's just that they wanted users to be able to easily be able to put things in `map`s and `sort` things, and at that point while attempts had been made at having a customization point that containers could use that wouldn't imply `&lt;` (e.g. `std::less`), there was apparently some issue with them (I've been told) so they decided to define all the operators directly. It's nice but in practical terms the fact that you can't hash tuples or std::array out of the box, let alone simple POD structs, is a much bigger issue.
A separate paper contain the changes to apply on Networking TS if/when Executors get in. Beware that it seems Executors will only partially gets in C++20, the part handling Executors returning futures is now separated and I'm worried it will not make it. I don't know if it's required by networking TS though.
Could someone report about what happened with Executors ? There was a meeting updating it and the result is splitting papers and probably no future-returning executors ready for C++20, which (like std::future/promise) drastically limited the utility. Except maybe for having fundations with the properties query system.
The easiest way to implement custom containers that are STL compatible is to take a look at [boost::iterator\_facade](https://www.boost.org/doc/libs/1_68_0/libs/iterator/doc/iterator_facade.html). Have a look at the [range v3](https://github.com/ericniebler/range-v3) library. It has many containers. Finally, and please excuse my shameless self promotion, have a look at [discreture](https://github.com/mraggi/discreture), which has some lazy on-the-fly combinatorial objects. If you don't care about combinatorics, just look at integer intervals and reversed. It uses boost::iterator\_facade for a lot of the boilerplate code.
Boost? No easier to follow, though. [CGAL](https://doc.cgal.org/latest/Manual/packages.html#PkgStlExtensionSummary) might be of some use. 
No, it won't be faster. PAPI doesn't have access to any additional magic and most tests show PAPI calls taking 100s or even 1000+ cycles. In my opinion rdtsc is fine: it's quite similar in performance to rdpmc, each in the range of 25 - 40 cycles, and you avoid all the problems with trying to get rdpmc programmed and working across all the platforms you want to support (eg it may not even be possible on Windows, and on Linux some distributions ship with user-mode rdpmc disabled, etc). 
There is still a fair amount of overhead there. You should try to get rid of the dynamic label creation check - after all, it should be known at compile-time, right? Try to reduce it to a fixed integer or string literal, and you can flesh it out during post-processing. You can use "unlikely" or "cold" annotations to move the alloc_chunk code totally out of line which will make the usual case straight-line. rdtsc isn't exactly fast, but it ideally executes "out of line" with the rest of the code so may have a smaller impact than it's 30-ish cycle latency would otherwise predict. Still, it's going to hurt for small functions. A faster approach is to build your own timer: a thread or signal which periodically updates a shared memory location which is read by your ACTION macro instead of rdtsc, so it becomes a single load. The choice between rdtsc and rdtscp is tough: the former is faster but less accurate in the sense that other instructions can more freely order around it: so if you have some small function incurring some slow cache misses, your profiling might easily report this cost in a subsequent function instead. rdtscp at least partly fixes that, but by partly slowing things down with a kind of "half fence" serialization. Personally I'd test both in your indended application and perhaps offer a compile-time switch to make it easy to change. Or you could even offer variants of ACTION which use one instruction or the other. 
Good luck. If it were easy everyone would do it. There are a lot of good resources online, but most will assume a significant understanding of how programming and computers works in general before they will make sense. C++ is a powerful language, but it remains in many respects a low level language that exposes a lot of hw and os specifics to the developer. My CS coursework started with Scheme (a lisp dialect). Looking back this was a great thing since we could focus on purely the language (also it is so different from what anyone had used before it helped break bad habits). 
This talk was amazing. The whole idea about using function return types (with no body), overload resolution and decltype to go through the parsing operations blew my mind.
I'd recommend learning C first. It's a smaller scope of a language and everything you learn will apply directly to C++. Learning C++ from there should be a lot easier to understand 
Keep working at it until you understand. Don't just read, experiment. Try things out. See the behavior in person, and try to understand it from that. Dig into the code with a debugger. Learning programming is hard, and C++ is kind of a bastard of a language. Lots of twists, turns, and things that seem illogical until you learn why they are the way that they are...and you might learn that years after learning the feature. For me, learning the patterns of C helped me see where C++ had come from, and the things it was trying to change. Learning assembly helped clear up how a lot of low-level features work, and the interaction between the language and OS.
This is how a number of engines do it. The main weakness is that it adds complication to the build pipeline and also is very confusing to the editor depending on what functionality you need to support. I am considering it for sure though.
[EASTL](https://github.com/electronicarts/EASTL/) is a fairly readable implementation, in my experience.
I feel this is a super convoluted way to implement a state machine. I feel that implemented with clean set of branches rather than a table lookup would not only be faster on the whole, but also cleaner code that would not require assembler whatsoever.
&gt; There are types that cannot provide an ordering, like std::complex. It just doesn’t make sense that they have an operator&amp;lt; Ordering items in a list is not the same as saying “less than” or “greater than” in mathematics. Complex numbers have no concept of “less than / greater than” comparison, but when plotted on a graph (as they often are), they’re clearly equivalent to two dimensional points, which, if I were to ask you to put those in an ordered vector, you could easily define ordering comparison operators for.
Stop teaching C =&gt; https://www.youtube.com/watch?v=YnWhqhNdYyk
We had a discussion in my company regarding the less operator of a 3d class. What does it mean? At the end, we just add a comment next to the declaration explaining the sort purpose and not the mathematical one. 
Thanks that was really good
It was indeed very cool, and inspiring
The topic here is learning C++. Learning C is certainly might be relevant in other fields, but as far as learning C++ is concerned, it only help in maintaining legacy codebases and understanding where some patterns come from.
Those who do not learn from the mistakes of history are doomed to repeat them. 
What are the pros and cons of doing so against running your server app on a linux?
Google's protobufs. 'repeated' fields of messages are stl and range-for compliant.
I for one have shifted to VS Code. 
Good point!
You could take a look at https://github.com/couchbase/phosphor It’s a cross-platform C++11 tracing library which we created to solve a similar problem to yourself. It was inspired by Google’s in-app tracing approach (Dan Luu has a good blog post on the approach here: https://danluu.com/perf-tracing/). It’s pretty damn fast, and outputs to the Chrome tracing format for easy rendering in Chrome. Even if you don’t want to use it as-is, it’s probably got some good ideas to look at. 
The name was supposed to be "Compile Time Regular Expressions" I hope they will fix it soon :)
I was excited about Labelled Parameters (http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1229r0.html) until I saw they went for a library solution instead of a fully language one. There is a language syntactic sugar for call sites, but the function declarations still look horrible and will clash with the DRY rule.
Thanks for the input! I thought about compile-time labels as well but I'm not sure how to "register" them (i.e. how to recover file, line, function information at the end). I think the overhead of checking label creation should be small: a single byte `mov`, a test-if-zero, and a conditional jump that the branch prediction will immediately learn to predict 100% of the time. If the byte is in the L1 cache this should not be more than 6 cycles latency (the influence is probably even less because the ALU ports should not get more than one or two u-ops). I've recently read that "unlikely" annotations for jumps are ineffective nowadays because the CPU branch prediction will overwrite that anyways. It's only interesting for code placement but that's the reason I explicitly marked `alloc_profile_chunk` as "noinline" (so that it wouldn't pollute the i-cache). 30-ish cycles per `rdtsc` doesn't sound too bad though. In total that should be 70-80 cycles latency per ACTION which is below half a RAM read. I've yet to measure that though because benchmarking at this level is ... tough. Your shared memory location approach sounds intriguing but I'm not sure how to keep it competitive. To get the same accuracy you basically have to write `rdtsc` to the shared location in an infinite blocking loop and each preemption will create jumps of 10k+ cycles. I'm also not entirely sure what happens if you read such a heavily contended shared memory section. I guess you have to do it atomically to prevent tearing? That sounds like more than 30 cycles per read. `rdtscp` per compile flag sounds good. Or maybe even just two separate `ACTION`s.
The Reddit link title unfortunately can't be updated (even if YouTube is), but I've edited the orange link flair in an attempt to draw attention to the correct name.
Thank you!
Yes, but maybe most future types will not get an operator&lt; once we have a different customization point.
Gross.
That’s exactly what the new `default_order()` customization point would do for you. Instead of overloading a point unless, you just do you customize the `default_order()`, no need for comment.
When I was learning C++ after Pascal in my teenage years. I was unfortunate enough to learn from books and articles with this “C first” philosophy and in my opinion it just wasted my time. Pointer arithmetic, weird casting, manual memory management, printf... all of this was completely unnecessary at learning phase. People should start with containers and algorithms first then slowly going down learning how those things are build.
test_case can be made a template function which &gt; that takes a lambda and stores it inside test_cases
Honestly, Google's c++ is not particularly readable
Yeah I definitely appreciate that so I am actually curious if PAPI or the GCC instrumentation can achieve sub-100 cycle overhead. Part of the motivation of this post was to get a feeling for how existing libs/tech perform.
Well, that's how learning works: sometimes you understand things and sometimes you don't. You just have to keep trying. Seek examples and different sources.
So if I understood it correctly we should be able to optimize std::regex the same way with relaxed constexpr (dynamic allocations)? Also is there a reason why std::regex generate so much assembly?
Windows 8.1 x64
So basically , they started to make their GUI becoming open-source .
I installed everything , and It's working now , thanks . 
every time I try to build anything gives me a lot of errors , designer hangs , seems the Qt installation was missing some stuff , I downloaded a fresh copy and everything works fine now , thank 
CTRE looks great. In my project I'm still using `boost::regex` because `std::regex` is so painfully slow. I tried using `std::regex` and, with gcc 4.9 the regex library blew the stack. Then we reverted to boost. I don't think we can switch to CTRE, because we still support C++11 compilers.
Ugh... &gt; 402 Plot twist! Payment required... I guess I won't be reading that.
No, there is no proposal. Yet.
!removehelp
Sorry for that. We will fix it ASAP
Strongly / weekly typed is a spectrum. I think C++ is quite weakly typed, considering its eagerness to do implicit conversion sequences.
This library is not supposed to be part of the next standard. Only the language features allowing it. I referenced Jeff Snyder's r/http://wg21.link/P0732 (P0732) which allows us to use Class Non-Type-Template-Parameters. I also referenced previous work from Louis Dionne u/http://wg21.link/P0424 (P0424) and Richard Smith r/http://wg21.link/N3599 (N3599) which started the discussion to add support for compile-time strings. And it all lead to my library :)
Suuuure, you probably *found* that on your desk with deadline tomorrow. ;)
https://github.com/hanickadot/compile-time-regular-expressions
&gt; C++17 with clang/gcc extension I missed that part. In other words, with C++17, there's no MSVC support, so we'd have to wait for C++20. Considering that we have migrated to C++11 two years ago, CTRE will have to wait.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Thanks for letting me know! I'll read up on this and update the article. 
That axiom is outright false in general. Let b and d be 0, and a and c be negatives.
For those interested in why OldWolf2 is right: I quoted `operator!` from \[over.built\]. But \[over.built\]¶1 says: &gt; These candidate functions participate in the operator overload resolution process as described in 16.3.1.2 and are used for no other purpose. And the description in 16.3.1.2 says: &gt; If no operand of an operator in an expression has a type that is a class or an enumeration, the operator is assumed to be a built-in operator and interpreted according to Clause 8. Indeed the operand is not a class or enumeration, so we need to instead refer to Clause 8, aka [expr]. Here we find [expr.unary.op]¶9 which he refers to.
TheChernoProject does OpenGL and game engine tutorials for C++
meson is probably the closest c++ has to what you want. The difference between C++ and other languages is that there is no centralized package repo that everyone has agreed to use, which has its advantages and disadvantages.
If you're somehow targeting Linux and Mac only, I recommend Nix. A Nix wizard will have no trouble producing Windows, Android, iOS etc binaries from Linux as well, but if those are current requirements, you'll have a bad start as a beginner.
CMake is not a dependency tool. It's a meta-buildsystem.
I have implemented a couple in https://github.com/foonathan/array
&gt; Cmake which is popular among others is the worst nightmare dependency tool I have ever worked with Cmake is mainly a buildsystem and not a dependency management tool. Although, its the only buildsystem that has a general-purpose way to tell the build script where the dependencies are installed, which makes it friendly for package managers. &gt; My question are : which tools are you folks using for dependency management that do work like other mainstream platforms like the JVM, Nodejs, ... I use [cget](https://github.com/pfultz2/cget) which lets me install packages directly from source tarballs or github, using cmake, meson, autotools or boost. There is no need for writing package scripts or a centralized repo. It is written in python but there is also a purely cmake implementation as well called [CMakeGet](https://github.com/pfultz2/cmake-get), which is nice if you dont want to use python or require someone to install a tool to install the dependencies. For example, I use it to create a cmake script(called `install_deps.cmake`) that will install the dependencies from a requirements.txt file(see [here](https://github.com/ROCmSoftwarePlatform/MIOpen/blob/master/install_deps.cmake)). Then someone can install the dependencies from cmake with `cmake -P install_deps.cmake` with no extra tools instead of doing `cget install` or `cget build`. 
I think that if you are really interested to measure a particular block of code, the overhead of the instrumentation is not that important meanwhile it does not pollute the measurements it has to take. Otherwise you would rather widen the scope to match the area you want to learn about. Overhead is important but so it is the quality and quantity of information you can provide.
Yes, as of now I think at least somemacros would be needed. Something like: ```` #define _ auto #define __(var, lbl) if (var != 0) goto lbl #define ___ int main() #define ____ putchar ```` And you're ready to roll.
Source level dependencies are adequately handled e.g. by git submodules. Binary (artifact) level dependencies are impractical because of a highly multidimensional build parameter space, you cannot pre-build a binary artifact for every possible build flag combination.
How can it take a decade to add executors? Especially when it's holding up other features.
&gt; And "If addresses a and b are in the same array, and z is in a different array, then a &lt; z is iirc undefined bahavior in c++ (you must only use the less than operator with pointers pointing into the same array (or was it same object/allocation? I forgot the details) 
Thanks for the replies everyone! This was really helpful.
I tried vcpkg on Windows platform and it worked for me. [https://blogs.msdn.microsoft.com/vcblog/2018/04/24/announcing-a-single-c-library-manager-for-linux-macos-and-windows-vcpkg/](https://blogs.msdn.microsoft.com/vcblog/2018/04/24/announcing-a-single-c-library-manager-for-linux-macos-and-windows-vcpkg/)
Ugh, nobody cares what cmake thinks it was or wasn't historically responsible for. It's 2018. This will only be viewed as a cop out for people who aren't already entrenched in C++ development. CMake currently provides half-assed dependency management and saying its not a dependency tool is delusional at best. We need to get real dep management in CMake either by adding it to CMake itself or packaging it and integrating it with a tool that provides such features.
&gt; NOTHING SEEMS TO WORK If you want a Cargo-like integrated build toolchain (build system and package/project dependency manager), take a look at [`build2`](https://build2.org). Specifically, to get a quick sense of what it offers, check the [Getting Started Guide](https://build2.org/build2-toolchain/doc/build2-toolchain-intro.xhtml#guide). And if you find that something doesn't work, I would definitely like to hear about it.
We need to destroy the preprocessor! :D
Yes. JavaScript has a tendency to coerce types in surprising ways.
You can check out this list of "awesome dev streamers" - wasn't going to post this since I'm on that list, and it felt like I'd be showing off, but since no one else has posted it: [https://github.com/bnb/awesome-developer-streams](https://github.com/bnb/awesome-developer-streams) &amp;#x200B;
Now I'm starting to feel like I'm pressuring you into creating a C++11 version of CTRE. This was not at all intended. I just wanted to say a nice word or two about CTRE, given my first impression.
I'll try it out. Thx
I know you're not being serious but... Do you want to destroy compiler flags, architecture flags, and linker flags too? Also, how do you plan on conditionally compiling anything if you remove the preprocessor completely
&gt; is iirc undefined bahavior in c++ Yeah, I'm saying the standard should instead say it's implementation-defined with some constraints.
Actually, what we really want is the order relation to be compatible with field axioms, which cannot be done for complex numbers. However, in computing other mathematical requirements aren't fulfilled either, for example the addition operation on machine numbers is not commutative. So thriving for mathematical correctness with complex numbers and reusing operators that are not correct in the mathematical sense is not reasonable. In fact the only requirement shall be for these operator overloadings is to not surprise the programmer, do what everyone expects to be. Mathematical correctness is not one of these things, programmers know that. 
Does Conan complement CMake in nice synergistic ways?
Yeah, integration with CMake is pretty seamless.
Nice feature! But c++17 only so not always suitable for a library. 
Yes, it definitely does! We (at our company) are using cmake+conan in a huge project with dozens of third party dependencies. I works quite well an I can definitely recommend it.
&gt;I have tried to set up a cmake project with openssl, gtest as a dependency libraries, it has taken me 2 entire days with no progress Setting up a CMake project with 2 dependencies shouldn't be **that** hard. &gt;Cmake which is popular among others is the worst nightmare dependency tool I have ever worked with : Care to elaborate?
I can't believe you can compare C++'s options with *gradle* and say we have it worse haha. I've never seen a cmake configuration worse than what gradle has to offer. Let's hypothesize what an NPM-like packager (because Yarn shouldn't be used these days with npm's new improvements imo) would need to do in c++: 1. Find every .c and .cpp/cxx file. These should be translation units so I should compile them 2. Well, in principal, each of those translation units could have been compiled with different compiler flags. OK we need to define some configuration that lets the dependency specify that. Many flags will need to be supplied to clusters of files. 3. Those files may be grouped in some odd way (overlapping sets possibly) to provide different targets that you should link to (as well as a set of linker flags per). Alternatively, some targets may be executables or logical transitive dependencies (a group of libraries that you link to all at once, a bunch of header paths you append to your include path) 4. All of the above may or may not be user configurable, on top of preprocessor directives you may have control over to control the final artifacts 5. Unlike node, there is no `index.js` which defines the main entry point. You need to know which targets you want built and linked to or copied out 6. If this dependency has other external dependencies, you'll need to figure that out yourself. Unlike in node, where you have some form of semantic versioning in place with possible dependency duplication, here, you have to be careful about providing the same symbol multiple times, lest you get a linker error or even worse, a runtime error if you mix static and dynamic linkage. 7. That means the configuration needs to specify what dependencies it requires, and know to let you provide them if it's being included transitively in another project In practice, C++ needs to do a lot more than the other options you're mentioning, and imo, CMake is honestly lightyears ahead of gradle's terribleness. Cmake + FetchContent gets you 99% of the way there, so I just recommend people use that. [Here's](https://cliutils.gitlab.io/modern-cmake/chapters/projects/fetch.html) a tutorial covering its usage, and you should probably read the whole thing if you aren't familiar with modern Cmake as a whole. Do I want something better than cmake? Sure. But Cmake gives me configurable toolchains, custom targets (code generation anyone?), logical dependencies (called interfaces), lots of real-world usage/adoption, and works with major tooling I care about (VSCode, emacs/vim, VS Studio). Improving it is just a matter of restricting its syntax/capabilities to a more reasonable subset (which is honestly a common theme with how I feel about C++ as well). Pragmatism wins though, and you choose the most productive thing.
what about just using the raw ATL? visual studio automatically writes the code for you
and they are assholes. we are just mean
since you used to be a web dev, why not use electron and call your c++ from the command line
Assuming you are taking about `-finstrument-functions`, the gcc instrumentation can certainly achieve less than 100 cycles overhead, because it just provides a hook to call a function on entry and exit, but the function itself is up to you. The cost of the call itself is in the "few cycles" range usually. Of course, you need to implement the call yourself to do something interesting, which then ends up being essentially the performance question you have now. So in that sense `-finstrument-functions` is mostly just compiler assistance in automatically putting your instrumentation hook in *every* function.
not a down voter but I think it's a very useful feature. you seem to already see that it's useful when returning objects and idk why void would be a special case 
https://repl.it/repls/NiftyFlawedProtocol Even most dynamically typed languages would have at least thrown some form of type error by that point... which is useful if you accidentally wrote something like `foo(bar)` instead of `foo(bar())`.
If a problem is using a O(n) algorithm when a O(1) would have worked in a highly generic case like vector, there isn't much need to benchmark.
It sure can be, especially if you want to link it in a certain way and provide a reusable solution in the open source world.
Well, I think void functions are very different from regular functions (and indeed other languages use different names for them). Void functions dont return any value, so they're not an expression when called, they're a statement. I guess associate 'return' with returning an expression to the caller, so an empty return looks strange to me. I wonder if this distinction is something that could be eliminated with the "Regular Void" proposal.
Looks like there are details related to two-way execution (basically returning futures) that might be problematic or maybe just incomplete but I see no public report on that except that line at the beginning of the last version of the splitted proposal.
&gt;I thought about compile-time labels as well but I'm not sure how to "register" them (i.e. how to recover file, line, function information at the end). Well it should work if you just make sure your "location" object is statically initialized, e.g., via an aggregate initializer of constant elements. In this case, even if the object is function-static it will get compiled directly into the data section of the object, and there is no runtime initialization. Here's an [example](https://godbolt.org/z/3672S) - note how the Location object is constructed, and in the resulting code there is no dynamic initialization, just a direct load of a pointer to the already constructed object. &gt; I think the overhead of checking label creation should be small: a single byte mov, a test-if-zero, and a conditional jump that the branch prediction will immediately learn to predict 100% of the time. If the byte is in the L1 cache this should not be more than 6 cycles latency (the influence is probably even less because the ALU ports should not get more than one or two u-ops). Sure, the overhead is "small" for some definition of "small" - but everything you are doing here has small overhead, so in a relative sense this is an important optimization. Sure maybe it's only a few cycles, but when you instrument a function which itself is only doing a few cycles of work, this really matters. About _that the branch prediction will immediately learn to predict 100% of the time_ - this is rarely true. The branch predictors have limited resources: think of them like a very small and precious cache of information. Even time you record information about one branch, it forces out information about an earlier branch. The info for this branch won't stay in the predictor forever, so the prediction rate won't stabilize at 100%, unless your entire process has a small number of branches. Yes, predictable branches are still much better than unpredictable ones, and are usually "cheap" in a relative sense - but they are not free and it definitely makes sense to get rid of unnecessary ones. &gt; I've recently read that "unlikely" annotations for jumps are ineffective nowadays because the CPU branch prediction will overwrite that anyways. It's only interesting for code placement but that's the reason I explicitly marked alloc_profile_chunk as "noinline" (so that it wouldn't pollute the i-cache). That they aren't useful in an often repeated myth. Yes, they are only interesting "for code placement" - but that has _always_ been the most important reason to use them, even in the brief period where static prediction hints were useful. Code that takes the straight line path is generally much more efficient than code that doesn't, and your code has an unnecessary `jmp .LBB5_7` in it that is taken *every time* (and BTW this also uses up branch target resources). Marking the `alloc` function `noinline` didn't fix this (but it's also a good idea) - you need a likely call (I recommend [Hedley's likely macros](https://nemequ.github.io/hedley/api-reference.html#HEDLEY_LIKELY) for cross-platform support) in there, or you need to annotate your `alloc` routine as "cold" to get that working. &gt; 30-ish cycles per rdtsc doesn't sound too bad though. In total that should be 70-80 cycles latency per ACTION which is below half a RAM read. I've yet to measure that though because benchmarking at this level is ... tough. If you are fine with ~100 cycle costs I think you are already done. It would limit a lot the type of function you can annotate with `ACTION` however, since an overwhelming majority of function calls in a typical process will take much less than that. &gt; Your shared memory location approach sounds intriguing but I'm not sure how to keep it competitive. To get the same accuracy you basically have to write rdtsc to the shared location in an infinite blocking loop and each preemption will create jumps of 10k+ cycles. I'm also not entirely sure what happens if you read such a heavily contended shared memory section. I guess you have to do it atomically to prevent tearing? That sounds like more than 30 cycles per read. Of course it is a tradeoff of precision versus performance. You don't write the value every 30 cycles or whatever! You choose some reasonable interval like anywhere from 1 us to 1 ms (or even slower). You will find that you generally get accurate results "in aggregrate anyways". For example, even if you set the frequency at 1 ms, you can still measure functions that take nanoseconds in a statistical way. That is, if the runtime of a function is 1 us and your clock has a resolution of 1 ms, you should see (approximately, and in expectation) 999 out of 1000 calls taking "0 ms" and 1 out of 1000 taking "1 ms", so it averages out to (approximately) the correct value. That's how you can get accurate aggregate timing with low-resolution-but-fast clocks. So there is no read of a heavily contented location (but yes, that would be slow). 
https://stackoverflow.com/questions/39162251/function-call-expression-statement-even-functions-of-type-void (can't speak for other languages tho) but regardless of that, I think it makes things more readable consider: void traversal(node*pn) { if (!pn) return; // other stuff } after the first line, I know if pn is 0, then I'm done! blam! no need to keep reading if that's what I care about. and if I care about other cases, then I know pn is nonzero. consider: void traversal(node*pn) { if (pn) { // other stuff } } obviously equivalent. however, - I have to read to the bottom to be sure about how the 0 case is handled - I now have to indent more (maybe not a huge issue but I personally don't like it)
Not **yet**, anyhow. Well, for some already.
I just spent the last two days doing the exact same thing with curl and openssl to write a tiny http client that grabs one url. It still doesn't work. took about 30 seconds to write in Go and about an hour to work out how to do it in rust and would now be about 5 mins to do once i learnt cargo. C++ dependency management is basically broken unless you want to spent a ridiculous amount of time bodging something together as a fair few people have already said in this thread. They really need to plan a c++21 that is just modules and proper dependency management story that works cross platform.
I'm not sure what you are saying, but yes their GUI library is open source.
I don't agree 100% with you, the situation is not ideal, maybe not good, but not thaaat bad. CMake, conan, other tools like vcpkg or build2... people are trying. The one scary thing indeed is that many big projects develop their own build/packaging system, so it is kind of scary that either these projects can't use anything existing (e.g. CMake), or they do and it's end result is really messy (e.g. OpenCV &amp; CMake).
VS Code is awesome. But Visual Studio (Community) still has so much more to offer and is the much richer C++ experience, at least out of the box.
https://www.npmjs.com/package/rili-hell
tbf, he's not using assembly, but compiler intrinsics. Not that there's much of a difference.
VS code is multi platform. That is a huge advantage. I primarily use Linux hence VS Code fits this use case.
The one I used last time I need PPCs was [this one](https://github.com/opcm/pcm) IIRC. It's pretty fast I think, but it's not super user-friendly.
&gt; you have to be careful about providing the same symbol multiple times, lest you get a [...] a runtime error if you mix static and dynamic linkage. Is there a way to catch this in the build process? I didn't realize this was a possibility. 
Showing as "video removed by user" on youtube
Yes, but it's not pleasant. You can use nm -D on each of your .so files to output their exported symbols, and check the list for duplicates as a post-build step. On windows you need dumpbin /exports. This only works if you get all of your files though, if your dependencies have dependencies, you need to check them too.
&gt; Also, how do you plan on conditionally compiling anything if you remove the preprocessor completely It's doable at a build system level. You can put all your platform specific code in platform specific directories, and have your build system include the correct folders. Similarly, if you have a debug implementation of a logger/allocator, the build system would just need to pick up the debug/Dev folders with the implementations in them. I suspect in practice that it wouldn't work too well though, if you have client and server code in the same file (or even in the same function) it would require large amounts of refactoring to make work.
I am not sure if it is just me but when I click Youtube says video is removed and I coulnd't find it on the CppCon channel. For those who are in similar situation there is the pdf: https://github.com/CppCon/CppCon2018/blob/master/Presentations/compile_time_regular_expressions/compile_time_regular_expressions__hana_dusikova__cppcon_2018.pdf and interactive slides https://www.hanicka.net/ctre/
There is no doubt that C++ is hugely intimidating these days, and there is a lot to get your head round. Thankfully I’ve had almost 15 years of learning it on and off, so these days I have a handle on most of it. If I brutally honest, whether it is worth sticking with it depends on your application. If you care about speed or resource usage, in my opinion it’s still the best game in town. Otherwise you might be better off with a different language.
By old I mean, - at least on Windows -, MFC interface.
SQLite probably not the best example, as that's just one big file.
&gt; Unlike node, there is no index.js which defines the main entry point. You need to know which targets you want built and linked to or copied out &gt; If this dependency has other external dependencies, you'll need to figure that out yourself. Unlike in node, where you have some form of semantic versioning in place with possible dependency duplication, here, you have to be careful about providing the same symbol multiple times, lest you get a linker error or even worse, a runtime error if you mix static and dynamic linkage. &gt; That means the configuration needs to specify what dependencies it requires, and know to let you provide them if it's being included transitively in another project No. You already indicate which headers you want to include or modules to import; that should be enough to find and use them.
Worked very well for me too but it only handles a handful of supported open-source packages. Their number is steadily growing, however.
&gt;you don't HAVE to use internet protocol to transport higher level protocols like UDP That is true, but the implementation of networking.ts only provides UDP support over IP (Internet Protocol). Therefore, it is appropriate for it to be in the \`ip\` namespace. If there was a templated implementation which worked on an abstracted protocol layer, then putting it in a higher level namespace would of course make sense.
Do you have any experience with cross compiling? I want to provide toolchain files in cmake which need to be used for dependencies too. Is there a way such that conan forwards the toolchain file to required packages?
Yes, it has disappeared from CppCon's youtube channel. I have no idea why.
It was put there with wrong title, it will be re-uploaded soon :)
Yes, just do `cget init -t &lt;toolchain-file&gt;` to set the toolchain file.
If I understand correctly that will only get you a generic matcher constructed a compile time. CTRE generates the code for the specified regex machine as it is part of the type system. So you potentially get an optimal parser for the regex specified with far less branching.
But maybe we want it to be
Since two years, nix https://nixos.org/nix/ solved the issue for me (and : - There is a lot of packages, I'd bet more than any other package manager I'm aware of. - Packages version pinning and sandboxed build make the builds reproducibles - It is composable. - Package rules can be easily overloaded to change anything you want - Binary cache for the default settings of the packages. So most of the time you don't need to build your dependencies. - Creating build environment are cheap and a lot is (correctly) shared, so you can easily create a build matrix with different compiler / library versions - Awesome cross compilation support. The drawback I'm seeing: - Linux and MacOSX support only. Windows 10 with the linux subsystem, but windows is clearly not a first class citizen. There is a support for cross compiling to windows, but I never tested it, I won't bet for a correct support. - Most libraries comes with a prebuild dynamic version, but no static one. It means that if you want to do static builds, you will have a bit of work. Most of the time you won't care about static build, so that's not an issue, except if you care about deployment in uncontrolled environment, then : - `nix` builds with a lot of supposition, for example, all libraries are in `/nix/store/name-of-the-package-hash/...`. It does not use "standard" paths such as `/usr/lib` on linux, and even `/usr/bin/bash` does not exists. This is great for hermetic and reproducible build, but it become an issue if you try to deploy your binaries. If you deploy them on a machine with nix (or if you deploy in a docker which contains nix), that's easy. If you want to sell a self containing package which will be deployed on an unknown configuration, it mostly sucks (but this configuration always sucks with other tools and I'm still looking for a robust solution). - `nix` only cares about the setup of your build environment, but it does not replace a building tool, such as `make` or `cmake`. I think it is a good choice, but many may have a different point of view. There are tools such as bazel / bucks / ... which aims at providing a solution for dependencies and build, but they actually does not come with a huge package database.
For a different take on the same problem, the D language has a new regex engine using compile time function evaluation. Unfortunately there is not a lot of information about it on the net, [but here's something](https://tour.dlang.org/tour/en/gems/compile-time-function-evaluation-ctfe). 
/What/ the .... ? &amp;#x200B; Oh, is joke. But I can't see how it compiles even so. 
it also fixed a nasty bug from the clang-5 days where in a constexpr context a temporary constructed in an argument to a function taking a const ref would have it's this pointer be const inside the constructor. This affected a bunch of my stuff and had to using forwarding references in the methods to get around it. So stuff like constexpr bool operator==( A const &amp; lhs, A const &amp; rhs ) { ... } would fail if you tried to call it like some_A == A{ ... } 
Maybe OOT, but ironically, the same problem also applies to D, which claims to be a \*better C++\*. D has three compilers - dmd, gdc and ldc, each of which has their highlights and defects - just as the fragment of compilers in C++. D does have a dependency management tool called dub, but it's interface is quite unstable and since many flags vary among compilers, you need to ensure compatibility by yourself. Moreover, many packages claim to support only one compiler, which makes it even harder to create a platform-agnostic project.
lol
Thanks for the detailed answer! &gt; Here's an example - note how the Location object is constructed, and in the resulting code there is no dynamic initialization, just a direct load of a pointer to the already constructed object. Unfortunately your godbolt link gives me a 404. I'd love to see the code (especially how I can iterate over all locations at the end). &gt; Code that takes the straight line path is generally much more efficient than code that doesn't, and your code has an unnecessary jmp .LBB5_7 in it that is taken every time I noticed the `jmp .LBB5_7` as well. Just changing the `if` order didn't help so thanks for the likely macro, I'll use that as well. &gt; If you are fine with ~100 cycle costs I think you are already done. It would limit a lot the type of function you can annotate with ACTION however, since an overwhelming majority of function calls in a typical process will take much less than that. I wonder if that's accurate. http://ithare.com/infographics-operation-costs-in-cpu-clock-cycles/ says function calls are 15-30 cycles. Functions below 100 cycles would have pretty high overhead and I would expect them to be inlined most of the time. But I agree that you need to be careful what to measure. My last attempt at profiling had a few 1000 cycles overhead. &gt; you can still measure functions that take nanoseconds in a statistical way. Nice approach! reading and writing aligned 32bit values should be atomic on modern CPUs right? If I choose a frequency where 32bit is sufficient I might be able to get away with 3x 32bit instead of 5x 32bit and replace `rdtsc` by a read to the shared memory location. I guess I have to profile how much faster I can actually get with that. 
perhaps because people think you aren't contributing to the conversation with your gross generalizations.
does vcpkg support versioning?
You can also watch the [teaser trailer](https://www.youtube.com/watch?v=3WGsN_Hp9QY) from CppCon 2017, though the library's syntax seems to have changed a bit since then.
nah
I agree that not all additions are good and I think it's good to keep focussing on key features. On the other hand the C++ standard library is still tiny compared to most other languages and is still lacking some quite basic features... Even simple vocabulary types like gsl::not_null, a string replace, container erase_if, make_visitor / overloaded to just list some very basic things that I had to write a few times or are overly verbose.
[Natively-supported](https://docs.conan.io/en/latest/systems_cross_building/cross_building.html#cross-building-with-conan). Their talks usually include a quick cross-compilation demo if you want to see it in action.
Not natively, AFAIK. What [they recommend](https://github.com/Microsoft/vcpkg/issues/1681) freezing the subfiles at specific SHA hashes, which is not very ergonomic. I'd say Conan might be a better choice for that.
Then at least quit your bitching.
There are other ways to handle things like that - you could put different profiling implementations in different libraries, and link against the one you actually want to use. It's almost certainly not worth the hassle though.
&gt; Edit: what I would like to add is that it feels like new additions are often focussed on library writers, while some basic features for the average programmer are still missing. Indeed. Or probably somewhat reflects the Komposition of the committee (more implementers than users), but that is just a guess (haven't checked, how the committee is composed nowerdays).
Hell. Yes.
Surely, not always OOP is the bet deal. But sometimes, generic or template meta-programming may perform better as the functions to be called are resolved at compile-time, thus eliminating the virtual function calls overhead. Another advantage, is that generic programming works with any type that conforms the template code regardless of class hierarchy.
'C is a strongly typed, weakly checked language.' &amp;mdash;Dennis Ritchie
Probably they will reupload with some fixes. They already did that for a bunch of videos.
But the standard doesn't say that. If it wants to say that then it should say it consistently. 
Maybe you, me, and /u/vector-of-bool can team up to tackle this once he's done with [Pitchfork](https://vector-of-bool.github.io/2018/09/16/layout-survey.html) and [How to Make CMake Good](https://vector-of-bool.github.io/2018/08/12/cmake-good.html).
I just noticed [p1149](http://wg21.link/p1149r0). Any comments on this?
&gt; Sure, you lose out on axioms like You lose out on &gt; If a &lt; b, and 0 &lt; z, then a*z &lt; b*z. Unless you are willing to have &gt; 1 &lt; 0 &lt; 1. I suppose multiplying complex numbers is not very likely, and expecting a sane result from the ordering, but it still alarms me.
I think it's pretty telling that a lot of modern C++ idioms, like the rule of zero, are intended to help us write code that more resembles a slightly-cleaned-up old fashioned C. This code exists everywhere, and sometimes it's written the way it is because you're interacting with a C library, or because somebody much smarter than you did the profiling work and chose to write in a certain style in order to meet performance requirements. Either way, you'll have to know the old idioms to be productive. Better to try out the "old fashioned" approach and develop a intuitive sense of the value we get from newer idioms and language features.
Why is cget written in Python? Doesn't that seem a bit ironic?
binary package distribution is like biting the apple from the tree of knowledge. all ABI incompatibility, compiler flag weirdness, static/dynamic linkage nightmares, come from binary packages.
What point are you trying to make?
Does GCC proper support modules, or only the branch? I'd love to use modules but support is mixed and confusing.
\&gt; *JVM has Maven and Gradle, Node has NPM and Yarn, ... etc they all work pretty easy - one line of instruction* : **you just set the name of the dependency you want and the version** : *Everything is handled by the tools*, .. &amp;#x200B; Those package managers works well, because those languages don't suffer from C++ ABI incompatibility problem among different compilers and even different version of the same compiler. So, while it is possible to add a library to Java project just by copying a jar file, it is not possible to add an object-code dependency like a static or shared library to a C++ project because the library author would have to compile to all possible compilers and versions of those compilers. So, most code reuse in C++ happens by adding the sources to the project and compiling them alongside the main source code. &amp;#x200B; Another problem is that C++ package managers only provide source code, but don't provide pre-compiled C-shared libraries like OpenCV, OpenGL, Gtk, GNU Scientific Library ... and so on. So, in this case there is no other solution than installing them manually or with Linux package manager in the case of Linux distribution. &amp;#x200B; \&gt; some projects are literally copying other project files : 😱, Decades old practice. &amp;#x200B; It may happen due to the lack of standardization about what package manager to use. As consensus in the C++ community is hard to achieve. &amp;#x200B;
Great concise talk! I really like the 30 minute talks when the presenter is well prepared and does not allow questions until the end
There are so many mistakes in the video. For example, see the first screen of `std::remove_if`.
The FAQ says that if you want different versions of a library installed at the same time, you should use different instances of vcpkg and be careful with integration.
I'm not sure, I know with clang it's just a matter of setting some flags. Not much support with build tools and IDEs though.
Well you can make it work with several instances. Keeping several versions in the same include path would be asking for trouble after all.
&gt; Unfortunately your godbolt link gives me a 404. I'd love to see the code (especially how I can iterate over all locations at the end). I fixed the link, sorry about that. I didn't check exactly how you are using the records, but I assume you can iterate over them after the fact, at least if you can get a handle into the thread local data from each thread (is it stashed away somewhere by the alloc function for that process?). &gt; I wonder if that's accurate. http://ithare.com/infographics-operation-costs-in-cpu-clock-cycles/ says function calls are 15-30 cycles. I have measured function calls at ~4.4 cycles on recent Intel, and AMD is similar. That's just the "latency" - you can get other work done in those 4.4 cycles, so in some cases the function call is nearly free (e.g., a function that has more than 4.4 cycles of "real" work and doesn't compete for the same execution ports the function call needs). &gt; I would expect them to be inlined most of the time. Sure, but inlining is neither here not there: once you've put your `ACTION` macro in a function, it's going to have the instrumentation, whether it gets inlined or not. A function that is inlined probably ends up faster which only exacerbates instrumentation overhead (and indeed, the instrumentation probably causes fewer functions to get inlined and also prevents some optimizations that would have otherwise occurred without instrumentation. &gt; Nice approach! reading and writing aligned 32bit values should be atomic on modern CPUs right? Yes, it is guaranteed to be atomic on all x86 CPUs (or at least since the 486 or whatever).
The struggle is real with boost. Looks like they are migrating towards CMake from what I heard.
I find myself using fewer dependencies in my c++ projects. I thought compiling dependencies would just get easier over the years, but nope. The dependencies require other dependencies which all have different ways to build them. Life is just better without a lot dependencies for what I want to do. 2 to 4 dependencies max is ideal for me. My new frontier is tackling build times. I cannot stand waiting 20 seconds after changing one file at work. It’s mentally exhausting.
Anyone tldw; version please?
Yes, cget creates a local environment to install the packages. For cmake it sets `CMAKE_INSTALL_PREFIX` and the build settings come directly from the cmake toolchain. For other build systems, it uses the appropriate flag to set the install location(ie `--prefix`) when it invokes the build system. It will also translate the build settings from the cmake toolchain file to the build system. For example, for boost it creates a `user-config.jam` file with the build settings from the cmake toolchain.
The point in this talk I appreciate the most is discouraging the usage of header-only code as a "selling point" for easier integration. If you just make a library and provide a sensible cmake frontend or equivalent, it makes different compilation options more discoverable and also means I can choose how to compile your library (static vs dynamic, debug vs release, O2 vs something else, etc). Furthermore, libraries that try to throw everything into a single giant header are a lot harder to navigate.
That's pretty cool. I'll have play around with this when I get the chance. Currently I'm caught up in a mess of shell scripts.
"Don't have dependencies" lol
if they add version control then it will be damn good for the visual Studio 
From my perspective is currently unimplementable. But after we make everything constexpr (allocations, destructors, exceptions catching) then it should be possible.
you're basically drawing 4 lines: - y = n/2 - y = x + n/2 - y = -x + n/2 - x = n/2 (if the top of your output image is y=n, and the bottom is y=0) Looping through the y values, it wouldn't be hard to determine which x positions would be on each of those lines and print a character there. It seems like there are a few ways you could decide how to draw the shape, and that maybe your assignment is open enough that you could just choose which one feels most "patterny" to you.
Is there an official Conan website where I can browse the full list of available packages?
While I agree with the general sentiment of letting maintainers choose the delivery type of a library, the real world just doesn't allow this flexibility: you cannot just build a library as DLL and expect it to work on Windows without code adaption (declspec extern). Therefore I usually enforce static libraries in CMake
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9oabcl/printing_patterns_in_c/e7snlav/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
airflow_matt, please, stop it. It's rubbish.
So you would definitely recommend using imgui instead? I’m asking since I was planning on using one of these two for a game options menu UI soon.
Does WG21 have procedures to triage, filter, or divert the proposals? With so many proposals, I start worrying about the shipyard.
Yeah, cmake is a paragon of simplicity and robustness when compared with gradle. I ported a relatively complex project over to it a couple of weeks back, and ran into horrendous overcomplexity, bugs in core plugins, and terrible documentation. I loath maven, but I'm a bit skeptical to call gradle an improvement after the initial experience.
I am sure Richard Stallman would have a different interpretation.
"[...] CMake via a new target property, WINDOWS_EXPORT_ALL_SYMBOLS. When enabled, this property causes CMake to automatically create a .def file with all symbols found in the input .obj files for a SHARED library on Windows. The .def file will be passed to the linker causing all symbols to be exported from the DLL." https://blog.kitware.com/create-dlls-on-windows-without-declspec-using-new-cmake-export-all-feature/
Agreed. I must stress that I haven't started reading the papers yet, but purely from the titles it looks awfully like people read the Vasa admonition, and literally went "let's write lots of cute isolated change-the-world proposals to turn C++ into something completely different", and we get this mailing. Or, put another way, about half the papers in this mailing are R0's i.e. new, not updated-after-feedback, submissions. BTW the Direction guidelines P0939 were substantially updated towards the end of that paper in particular. Lots more detail in there than before. Plus even more support for Graphics than was before. http://wg21.link/P0939
1. It's much harder than it looks from the outside. 2. We'd like it to work well with Heterogeneous compute, or rather, not wreck the usefulness on any heterogeneous compute.
But correct me if I'm wrong why can other newer languages (Rust) have these things but for C++ it takes 10-15 years just to spec? I know it's complicated, but when is good enough now better then perfect 5-10 years from now?
(LGPL 3.0)[https://opensource.org/licenses/lgpl-3.0.html] Section 4, Combined work: &gt;d) Do one of the following: &gt;&gt; 0) Convey the Minimal Corresponding Source under the terms of this License, and the Corresponding Application Code in a form suitable for, and under terms that permit, the user to *recombine or relink* the Application with a modified version of the Linked Version to produce a modified Combined Work, in the manner specified by section 6 of the GNU GPL for conveying Corresponding Source.
To be fair, quite a lot of header only libraries are navigable enough if you read the source code; The single-header version is often a compilation target rather than actual source.
&gt; When an exception is created, you’ll see some memory allocation - for the message string. That's not really an issue with string_view, but with exceptions in general. The worst case of this is when the exception is bad_alloc and the act of throwing the exception requires more memory.
Nobody is advocating for a C++-only build system. However, a C/C++ compiler is native (i.e., does not require another *system* as Python or Java would) to all the platforms out there. Which makes it a natural implementation language for a general build system and definitely the preferred language for C++-centric projects.
While it may seem complex, table-based DFAs are a very common technique for lexical analysis; recognizing UTF-8 is one such problem. Also, the UTF-8 decoders from Boost.Text and Alexey Vatchenko (for example) do indeed implement the clean set of branches that you describe. This talk was an effort to determine whether a DFA with some optimizations could have better performance.
Rust has a higher risk to stability ratio. So they'll ship features with less deliberation than C++ does. C++, incidentally, also has a higher risk to stability ratio than C. Over at WG14, they consider WG21 *far* too risk loving, and that C++ is full of rushed decisions to its detriment. And they're not wrong either - if you want correctness, sometimes it takes thirty years to decide on something e.g. http://wg21.link/P1095. So it's all relative in the end. And for Executors in particular, they specifically are trying to avoid causing problems for themselves down the line based on extrapolations of where technology will end up in the near future. This stuff is *hard*. Rust, meanwhile, isn't worried if its Executors design will work well on a million core compute cluster. That lets them iterate much quicker because they're not as concerned with how generic and scalable their design could be, but rather whether it works well on PC hardware today.
&gt; asm.js was like a stepping stone to wasm (WebAssembly). This was what was getting generated by Emscripten a couple years back when they were first demoing running UE4 games in Firefox. I don't think Chrome ever implemented it because they were trying to make their own NaCl (native client) a thing. The cool thing about asm.js is that any browser which supports JavaScript could use it. However, most non-trivial programs end up with a _lot_ of JavaScript when built for asm.js, so parsing it could be pretty time and memory consuming. All major browsers (Firefox, Chrome, Edge, Safari) now have optimized compilation pipelines for asm.js, but WebAssembly is still much faster to compile and smaller to send for the same code.
hi, im not a c++ dev, i just want to ask a (maybe) stupid question. will "modules" fix majority of these issues?
&gt; There is also Emscripten, which compiles LLVM IR into JS... or is it the asm.js subset? Emscripten can compile C and C++ code into either asm.js or WebAssembly via a collection of tools, namely a clang-based front-end. In addition to being a compiler, Emscripten, provides something like a complete platform for C and C++ in the browser. It provides implementations of the C runtime and standard library, as well as most of the POSIX API.
having used it, that's a terrible hack : - you may easily go over the 65535 symbol limit if you use templates a bit... hell, just a few dozen big multi-variant visitations can make it happen - it bloats the executable since the linker cannot remove unused symbols and symbol names (hello `boost::tuples::access_traits&lt;boost::tuples::element&lt;0, boost::tuples::cons&lt;unsigned long, boost::tuples::cons&lt;boost::multi_index::member&lt;word_counter_entry, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, &amp;word_counter_entry::word&gt;, boost::tuples::cons&lt;boost::hash&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, boost::tuples::cons&lt;std::equal_to&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, boost::tuples::null_type&gt; &gt; &gt; &gt; &gt;::type&gt;::const_type boost::tuples::get&lt;0, unsigned long, boost::tuples::cons&lt;boost::multi_index::member&lt;word_counter_entry, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, &amp;word_counter_entry::word&gt;, boost::tuples::cons&lt;boost::hash&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, boost::tuples::cons&lt;std::equal_to&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, boost::tuples::null_type&gt; &gt; &gt; &gt;(boost::tuples::cons&lt;unsigned long, boost::tuples::cons&lt;boost::multi_index::member&lt;word_counter_entry, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, &amp;word_counter_entry::word&gt;, boost::tuples::cons&lt;boost::hash&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, boost::tuples::cons&lt;std::equal_to&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, boost::tuples::null_type&gt; &gt; &gt; &gt; const&amp;): # @boost::tuples::access_traits&lt;boost::tuples::element&lt;0, boost::tuples::cons&lt;unsigned long, boost::tuples::cons&lt;boost::multi_index::member&lt;word_counter_entry, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, &amp;word_counter_entry::word&gt;, boost::tuples::cons&lt;boost::hash&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, boost::tuples::cons&lt;std::equal_to&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, boost::tuples::null_type&gt; &gt; &gt; &gt; &gt;::type&gt;::const_type boost::tuples::get&lt;0, unsigned long, boost::tuples::cons&lt;boost::multi_index::member&lt;word_counter_entry, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, &amp;word_counter_entry::word&gt;, boost::tuples::cons&lt;boost::hash&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, boost::tuples::cons&lt;std::equal_to&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, boost::tuples::null_type&gt; &gt; &gt; &gt;(boost::tuples::cons&lt;unsigned long, boost::tuples::cons&lt;boost::multi_index::member&lt;word_counter_entry, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, &amp;word_counter_entry::word&gt;, boost::tuples::cons&lt;boost::hash&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, boost::tuples::cons&lt;std::equal_to&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, boost::tuples::null_type&gt; &gt; &gt; &gt; const&amp;` my old friend) * it prevents the linker to perform some additional optimizations - symbols may not get inlined or be duplicated, identical code folding may not apply, etc etc
Yes, embedded devs would have to do something like that
Why are these problems prominent in the Microsoft world but not the Linux/Unix world?
I still don't see the point. You don't need to be able to build ON any platform, you need to be able to build FOR any platform. You don't build on an Arduino or a (Android|iOS) phone ( even if you could it's still a bad idea ). If my build system is fast and feature rich I personally don't care if I need to have installed some system dependencies. 
No problem!
Don't forget about https://bintray.com/conan/conan-center
After spending years becoming slightly more proficient in CMake than the average entry-level worker, I would like to retain my edge and justify all the time I spent be resisting any attempt to adopt a better system.
Totally agree. But with VS you can now compile, run, and debug on Linux, on the same machine, either via WSL or VM. So you don't need to "manually" switch to Linux anymore and use a second IDE. You can do everything from within VS in Windows. It's fantastic.
The struggles for Boost ultimately have nothing to do with the build system. And the potential support for CMake is not because of build struggles. It's because of providing user support. Currently many developers use CMake. Hence it makes sense for any library to provide support files for those users to interface with their build system of choice.
No support for packagekit? https://en.wikipedia.org/wiki/PackageKit#Back-ends It's a great choice if you want to distribute a package yourself that doesn't have to carry all its dependencies with it.
actually, the main problem (not speaking of the stupid 65k symbols limit of course) here is in the linux world (and I say this as a complete linux advocate). If you develop a DLL on windows, you *must* think of the API of your DLL, because no symbols are exported by default and you must export them explicitely (though this leads to another kind of hell: how do you export a template instantiation, e.g. `std::vector&lt;my_type&gt;`). On linux, the traditional linker behaviour is to mark all symbols visible by default. This is **bad** and if you develop on linux, you should always use `-fvisibility=hidden` and `-fvisibility-inlines-hidden` to get a sane behaviour and only export what you actually want to be exported and not $WORLD. But since so many C / C++ libs are developed for linux first and foremost, most libs are used to the default behaviour of the compiler toolchain here which means that they don't need to think about their public DLL API and thus don't mark their symbols as exported - then, when trying to port the lib on windows, nothing works because the DLL is technically empty since it does not export any symbol.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
You are approaching this from the "end-product" developer's point of view. That is, you are developing an application that only you need to build. What you don't consider, however, is the library/tooling developer's perspective: they need to make sure it is buildable on all the platforms out there. You can, of course, say that you don't care about them. But that is effectively saying you don't care about external libraries/tools that you can re-use instead of developing yourself from scratch.
I often see that author of build2 is promoting his build system on conferences and on this subreddit but it doesn't seem to be gaining any traction. I haven't heard about any open source project using it, there are almost no issues, no forks/pull request on github, etc. In comparison, another new build system - meson - is already used in quite a few open source projects (mostly linux related), has a lot of contributors, etc. So is there something wrong with build2? If it is so good why aren't people using it?
The only way to build it over "nothing" would be to distribute a binary or a bunch of platform specific scripts. Cmake exists, is widely adopted, and is specifically designed for doing the heavy loading of bootstrapping from sorce code to binary. Why _wouldn't_ you use it?
Yes, I forgot the `()`. But my point is, it is functionally identical; the lambda cannot return `bool` even if its type is `bool`. The part where `?:` can deal with `void` throw statements is because you cannot override `?:`, unlike `||`. You could permit `bool || throw statement` easily. #define THROW(...) [&amp;]()-&gt;bool{ throw __VA_ARGS__; }() gives us a `THROW` statement that acts as a `bool` expression. if (foo || THROW(0)) 
gcc has been doing that since 2.95 or so
Couldn't have said it better myself.
We have now opened the doors for EmojiScript... and CuneiCode.
We do and we are working on improving them.
&gt;If my build system is fast and feature rich I personally don't care if I need to have installed some system dependencies. Absence of dependencies is a feature.
&gt; The compiler was under the impression that the encoding was cp-1252 Use of a "codepage" is a bug, but to be fair, that compiler now has a way to fix it with /utf-8. Maybe it will be on by default one day.
I am not OP, so it's not my PMM. Also, how are you not just replacing cmake with build2 in this scenario? No, Cmake isn't universal, but as far as I can tell, it's at least the *most* universal. The more people build on to it and improve it the more adoption it's going to gain. If you think you have a better mousetrap, you're running out of time to get people to switch to it.
Thanks for answer. 
It may be a chicken-egg problem. Nobody is using it because nobody else is using it.
What mr mvonarx said: use smart pointers. void DoublyList::createNodeAtBeggining(int data) { Node* temp = new Node; temp-&gt;data = data; temp-&gt;next = head-&gt;next; temp-&gt;prev = NULL; head = temp; if(temp-&gt;next == NULL){ tail = temp; } cout &lt;&lt; "Node inserted!" &lt;&lt; endl; return; } Does this leak head? I don't see you free it. Also, is it possible that you wind up with head and tail equal to your temp node? does that make sense?
Disclaimer: I follow the evolution of most build/dependency systems. I decided to experiment with build2 because it's fundations are more sound that the alternatives (so "in theory" it's the best on the long run, which do not mean it will end up the best). I did a lot of experiments, gave feedback and bug reports and also participated in reviewing it's documentation. I am currently attempting to build gtest and gmock with it and I also have tried before to build Chaiscript with it (effort is paused until gtest is done). So I'm biased but I think I'm probably the closest to a power user of build2 around here (please other users, manifest yourself!) So to answer you general question: nothing particularly wrong with build2. It's not designed to "quickly replace" what you have now, so it's kind of slow to get to a fully complete state but it's totally usable today (although the API is not yet considered stable, but Boris said recently around here that they will try to not break it since 0.8.0). From my perspective, it seems to be targeting a long run, by having more solid fundation than it's current alternatives, which is what I am looking for. At my dayjob, we are looking for a dependency manager, and I recommend to use conan for example because it matches our use cases but also is working and complete today and have the libraries we need ready. However I still point regularly that it's probably like CMake: it works practically but it's not really ideal. I then point to build2 as a potential ideal. So depending on the timing of when and how we migrate, we might end up with either OR maybe one and then the other later. A few points: - It cannot gain traction easily right now because of some obvious things: 0) It's both a build system and a dependency manager (I think it's unusual and interesting but that might be scary for some today); 1) It does not have many libraries available yet (which is normal at it's development point); 2) It's documentation is incomplete, although it is now far more usable since 0.8.0; It also lacks "easy tutorials" (for people who don't like to read) but that will come with users I think. The introduction is nice in that it shows basically what you need to know, but it's still massive compared to what a very progressive set of tutorials would do. 3) Switching to it, kind of imply a change of mindset, like switching from svn to git (I like both by the way, I don't think every project should use git); 4) Lacks of IDE support might be something that people don't like too (it goes the other way around by letting IDEs drive it, and it should be easy to plug into VSCode or VS but there is a lack of people to experiment with it); - I have some reporitories using it but as said, it's mainly experiments to push where I have seen horrors (I worked on a wide variety of projects, open and closed source) - I am still exploring the impact of build2, how it feels porting a library already building with another build system, how it feels to evolve a new project with it etc. So far I'm pleased with the results, but I'm not yet in the target situation I want to explore: make a complex extensible game-or-graphic-tool with it; - It's the only build system that is natively designed to work with modules, current impls and incoming ones (which is when I started to experiment with it, though I couldnt use modules yet because impls were too buggy); - Alternatives teams are kind of super proactive in trying to propose their tool as solution for big open source projects. That's far less the case for Build2's team who often are super focused on the code and this reddit. For example the only case where I've seen Boris contact such project was Boost (and the main answer that "build2" and "b" are confusing because Boost.Build's binary is "b2" and that all kind of killed the purpose of the thread and nobody tried to see what was build2 at the time); - There are currently 2 people officially working on build2. All other alternatives (maybe not cget) have tons of people and sometime big companies behind them. - The github of build2 is a mirror of the real repositories. People trying it have historically been doing feedback on the mailinlg list (a bit like boost before it migrated to github) which is why you don't see issues on github. There are bugs sometime, but they are quickly fixed (currently there are less bugs report per week than people to answer to them). I believe build2 probably have the best model, therefore a more long-term tool, but it's not enough to make it "popular". It might become so with time, when some projects use it. As I work most of the time with all my dependencies as sources and I want to easily handle my dependencies, I invest time in looking at it for at least my own projects (from games to tools like montage tools). If you want to know something specific about it's current state, I can probably answer from my POV.
&gt; The idea of a standardized package descriptor isn’t getting much traction, we’re more likely headed towards a de-facto standard if one software manages to win the market &gt; Header-only libraries continue to be the “preferred” way to avoid the topic entirely :(
&gt; what I would like to add is that it feels like new additions are often focussed on library writers, while some basic features for the average programmer are still missing Agreed. There are some new features intended for "normal"/"final" users that I can see at a quick glance, though: * Pattern Matching * All the Unicode stuff * Networking TS * flat_set * find_backward * unique_val * secure_val 
I actually think this is a pretty great idea xD I will give it a try for my next project. I didn't quite understand if VCPKG is already supported or not ... The readme says: &gt; (As you are reading this, only Conan is supported.) But later on there is an API for VCPKG...
If you are requiring a scripting runtime to be installed to run it, it's just as universal as Ruby, Python, or any other scripting language. If you wanted to go with native code instead of a scripting language, somebody has to distribute and install binaries of CMake itself, etc. So doing that is obviously considered a reasonable thing to do. Many of the users of the PMM will be writing native C++ code, so it'd actually be odd if the PMM developers considered that an unreasonable use case. And it's really hard to argue that CMake is more pleasant than something like Python as a general purpose scripting language. That's just not what it was intended to be. CMake doesn't have any sort of spec or independent implementations of the scripting language, so you can't necessarily rely on stability/support going forward. Python and Ruby both have multiple implementations, so if the CPython devs go off the rails and end support for your platform, or deprecate features you need, you could use an alternate implementation of the language. There are lots of reasons why one wouldn't use it. I mean, if people like the result, it may see adoption. For a user, it doesn't necessarily matter what language a tool is written in. But acting like using CMake as the implementation language is a particularly obvious choice or a choice with no downsides is just weird. 
It sure doesn't help. I think only people who understand some flaws of the current alternatives and are looking for a solution that might not break in like 10 years will try build2 (maybe once 1.0 is out?). Or maybe just poeple who want to try modules today in a fresh project with a build system that handle them without hacks.
Absence of runtime dependencies is, development dependencies... well depends. Some can even add value ( think of static analysis tools, bound checkers ). I strongly believe in *choosing the right tool for the job*, and if you only use an hammer then everything looks like a needle to you. C++ is a great language for lot of purposes, but not everything has to be written in C++. 
I'm mentioning build2 just because it's an example of a tool that don't require you to install dependencies except a compiler. I'm not implying that it would replace this PMM (my understanding is that it Could be handled by a PMM). Boost.Build is another example (looks like most of these examples are build systems?). Yes CMake is used a lot. It does not make it universal at all. Anyway my point is that it seems that that specific dependency could be avoided too, and still work for projects using CMake.
So, Windows performance counters and ETW reinvented :)
Yes, building build2 itself. I'm now failing on the stage build: &gt; ... install /apps/build2/0.8.0/gcc-7.3.0/stage/share/doc/build2-toolchain/ install /apps/build2/0.8.0/gcc-7.3.0/stage/share/doc/build2-toolchain/ install /apps/build2/0.8.0/gcc-7.3.0/stage/share/doc/build2-toolchain/ info: failed to install dir{./} This is installing to a non-standard, no root required location
Does anyone know if there is a slidedeck available for this talk?
&gt; For vcpkg, you need to manually re-download and re-bootstrap the repository. Re-download? Not really. `git pull`. And re-bootstrapping means typing `.\bootstrap-vcpkg.bat`, and done. What's the issue here? PMM is intrusive, it requires me to modify my CMakeLists file(s), and everybody is then forced to use it for that project. vcpkg is completely non-intrusive, yet works perfectly well. Conan recently got improvements to its "non-intrusive mode" too. To me, the setting of which package manager to use, does **not** belong into the CMakeLists file. This is up to my users and there should be nothing in my project's CMakeLists files that ties them to any specific choices. 
This is probably not the best place for `build2`-specific troubleshooting. Could you file an issues on [github](https://github.com/build2/) or send an email to the users@build2.org mailing list (no subscription required). Also please include a bit more detail about your environment, what you have done, and the diagnostics your are observing. And thanks for giving `build2` a try!
Bazel, buck, pants, please.build, etc. Possibly gn, soong 
You need a deduction guide for it to work as shown.
Forgot to add - slides available at www.rrsd.com
APL says "Hi! Remember me?"
The Meson build system aims to provide exactly that. There was also \[a presentation about this at CppCon\]([https://www.youtube.com/watch?v=SCZLnopmYBM](https://www.youtube.com/watch?v=SCZLnopmYBM)) showing how to build a Python extension using C, C++, Fortran and Rust in one single module.
Aren't some of the talks' points related to issues with #include?
Maven and its plugins is a start. I routinely use Maven to: \- build Java apps \- build Docker containers \- build JavaScript apps using NPM Also, there is nar-maven-plugin and native-maven-plugin to compile C/C++ source files. But the plugin system enables devs to create plugins for any languages. Even if Maven is build with Java, it does not mean, it is only usable for Java.
How do you find the time to do such cool stuff? (Big fan of your VSCode plug-in here)
[CppCon Slidedecks should be here](https://github.com/CppCon/CppCon2018), but I don't see one yet for this presentation.
By not sleeping enough. :) No really, I need more sleep, and I wish I had more time. I don't have as much time to dedicate to the VSCode plugin as I want.
It's because the code in the article is C code, not C++. You're right, in C++ one should be using std::sort or other sort algorithms.
Have a look at qbs
!removehelp
Im running the synth on headless armbian orange pi zero. So no ui. I would like a non breaking keyboard read - like getkeyboardstate. Preferrable cross platform so I can develop on my win laptop before deploying to the linux board
Python does this, as far as I know. The interpreter allocates a `MemoryError` on startup so that it doesn't need to try to do one in case of OOM.
If you created a module in python that was designed to do the same job CMake currently does, it would be a bad idea to use python itself as the language in which to write up replacements for `CMakeLists.txt`. You'd want to build a (mostly declarative) domain specific language around the concept the concept of creating C/C++ projects. So essentially you'd be creating CMake but with different syntax. Might be a better cmake or it might be a worse one, or most likely, different groups would have different opinions on that matter, and now you've added yet another build system that some people use and some people don't, so you've made the problem worse. &gt; For a user, it doesn't necessarily matter what language a tool is written in. But acting like using CMake as the implementation language is a particularly obvious choice or a choice with no downsides is just weird. I didn't suggest it had no downsides. Every build tool has downsides, and I myself in the last quarter convinced my own company to add Python as a build system dependency because I was addressing a build toolchain problem for which CMake was not a suitable solution, and for which Python allowed me to create a much simpler solution. But you're also acting like Python doesn't have it's own downsides. Guess what, getting consensus to get Python on our build machines wasn't simple. First you have to deal with the Python2 vs Python3 mess. Then you have to deal with the fact that OSX has a built in version of Python2. You have to deal with the fact that Python3's Windows installer doesn't install Python for all users by default. Lots of people have legitimate reasons not to want Python installed, or to want a specific version of Python that isn't compatible with your hypothetical build system, because Python gets used for all sorts of different kinds of development. Because it's much more than a build tool, even if you can make a build tool out of it. 
Completely disagree with the article and the [P0973R0](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0973r0.pdf) is one of the best things that happed to coroutines debate. I don't see them pass in their current from - many use cases will feel like an afterthought (which they are), memory allocation uncertainty will hunt us forever and the extension points are as expert-only as possible and then some. I believe any delay will be for the better, if I am to compare what is happening to Modules and Concepts. The latter was "good enough" 5 years ago, yet the progress made since is undeniable. I am not saying the Core Coroutines is The Right Way - it is waaay too raw at the moment, but that experience will be accommodated, I am sure, and it will be for the better. 
&gt; If you created a module in python that was designed to do the same job CMake currently does, it would be a bad idea to use python itself as the language in which to write up replacements for CMakeLists.txt. I think that's debatable, but I don't have a strong opinion on it. It's certainly not the point I was making. I said it's not obvious that a "Package manager manager" should be written in CMake. I didn't say that somebody should write yet another thing like CMake in Python. &gt; But you're also acting like Python doesn't have it's own downsides. No, I said the downsides are equivalent to CMake. Everything you said about which version of Python to install on a build machine is equivalent to deciding which version of CMake to install on a build machine. Linux and OS-X machines at least come with some version of Python out of the box, which makes it a lot more common than CMake in a default OS install. 
I need more sleep too. There’s never enough time in the day. There’s a minor bug with the VSCode plugin (messes up an existing command-line configuration on first build) that I’ve been meaning to report, but seen as we both need more sleep...
Sorry, I will need a package manager manager manager before I can use this. Also: [mandatory xkcd](https://imgs.xkcd.com/comics/standards.png).
&gt; I could spend a good few posts just talking about everything wrong with this sentiment. It’s just wrong. I won’t even bother explaining it here, but maybe I’ll write another post if I get enough hate-mail. u/vector-of-bool, can you kindly consider that I send you a violent hate-mail about this subject. I'm sure the article you will write will be interesting ;)
Hum your compiler have to be setup anyway (just installed actually) for cmake to work. And a nativebootstrap only need to have the compiler installed, nothing have to be setup. My point is that I don't understand why it depends on CMake. It does not seem necessary to me nad could probably be made better by being independent. Whatever you find ok does not mean Cmake is necessary here.
&gt; if you only use a hammer then everything looks like a *thumb* to you FTFY
They should add Unicode codepoints for the old trigraphs, and for keywords. CPP2017_RETURN_OPERATOR
Hate-mail accepted :) I will probably write another post about package management in general. If I do, I will address this point.
Great! It feels quite good being a moron!
I mentioned cross compiling explicitly. Having a compiler working for your host machine does not mean you can compile for ps4 android etc
Can u elaborate?
And? That's something different entirely. `throw statement` is not the same as some lambda/function that return bool but could throw. It doesn't matter if you can achieve something with similar outcome if you really want, since it's not the same from the language perspective.
Sorry, original author. Fair cop, but it comes up frequently in sorting the issues. Well formed but absolutely not what you meant is not actually helpful if you want u8"" strings to mean something like what you say. 
It's a c++ 20 thing, meant to go with the 16 and 32 types. Latest version of it at http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0482r5.html Technically not landed yet, but I would be shocked if it doesn't. 
I would say yes. Allow them, but require a warning if they look invalid. I don't see what we gain by forcing them to be a hard error (and I don't even know how a compiler could keep up with the latest greatest Unicode revisions). And, please, force UTF-8 as the only allowed encoding for source files.
Ah but here's what you haven't considered: "I didn't read OP'S comment very closely"
Actually I did consider that!
then delete your unhelpful comment please.
Amen. I worked with C++ for a decade as my main (and nearly sole) language. I moved to a new job that is almost pure C#, and I was all ready to be grumbly and dismissive of it, but I'll be damned if it doesn't pain me when i have to go back to C++ and do package and build management on that side of things. With Core and Standard I'm finding it hard to find reasons to go back to C++, since none of my projects need that level of control.
The article is an update of: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0158r0.html
(I’ll admit I’m 100% biased in favour of the coroutines TS) I don’t think you’ve addressed any of the points of the article other than saying you disagree. Your comment seems written so as to dig up FUD. The article argues in a clear and easily understandable way why they think that we can do the coroutines TS now and pursue the additional optimization points from P0973R0 later. Did you not read it?
The main reason why functional style C++ is not very common is it's still impossible to write it easily. Ranges are pretty much needed for clean code, and that hasn't shipped yet. You can do functional code without ranges, but you still need C++11 in many cases, and C++17 for stronger guarantees (copy elision) and other nice features. For example, while in Python you can create a range from `x` to `x+n` in a functional way, in C++ you have to create a container, input this into `std::iota` and use the container again. So you have to write a functional wrapper over it. I want to be able to write something like `for(auto i:std::iota(1,10))`, or even `for (auto i=1:10)`
Why would you put a template instantiation as a visible symbol? That smells like insanity. You usually want template code to be inlined.
"I was lazy and I didn't read" isn't a "learning mistake" 
So we have to write a paper for Unicode and one for the C++ committee.
Just out of curiosity, how does this compare to the 10 year old (safeint)[https://archive.codeplex.com/?p=SafeInt] library?
Dunno, I always run into trouble with `bootstrap.sh` every time I update boost, or Xcode, or both, and fails to detect one or two dependencies. I'm hoping by "standardising" the build system with CMake will alleviate some of the aforementioned issues.
But lots of people are lazy and don't read. This will serve as a reminder that people are lazy and don't read.
&gt; People don’t use the package manager, and therefore their libraries will not appear in the package repositories, and downstream packages won’t use the package manager either since their dependency isn’t in the repository, and even further downstream packages won’t use the package manager… This seems to imply that package managers require a package in some central repository to use it, which is not the case for all package managers. Cget(and even pip) can install directly from source tarballs. &gt; Currently it supports Conan and vcpkg, but other packaging systems could also be supported in the future. What about supporting cget through the [CMakeGet](https://github.com/pfultz2/cmake-get) module. &gt; In particular, PMM is implemented as pure CMake script code that will automatically download, bootstrap, extract, and control package managers. I hope this can be disabled otherwise it makes it very package manager unfriendly. A package manager wants to install the dependencies and invoke the build script to use the dependencies it installed. It doesn't want to have another package manager installed and the dependencies installed a second time.
Not to lazy people who don't read... which would be the only people who would potentially benefit from it. :-\
I've worked on projects where we had to develop custom tools to get all of that information. There's a few reasons why, for example memory allocations come from all kinds of different places - the runtime, drivers, kernel, etc. Also, whatever tool you use has to be intimately familiar with the allocator you're using. It's a huge mess.
I believe Valgrind can help you. There are some GUIs like KCacheGrind that might make it easier.
Does your O/S support Dtrace? It tracks malloc’s &amp; free’s so you can get a good picture of what your app is doing at runtime. I haven’t used valgrind in years, but it was great too. 
Can we all agree on that the correct way is to ship a single header AND a single cpp file (pretty much what sqlite does)?
What do you mean? That `sfun` ends up returning a constant `1` instead of `a`? Why wouldn't it be? Is there a rule saying that optimized functions should behave the same if some code/symbol is generated for them? Without forcing the `noinline`, the symbols wouldn't be generated at all; and in this case, they aren't exported; so no one should be able to see the effect of this.
That link is not really applicable here. Loss of ability to do things in the future with less effort is a reasonable consideration. 
Suppose you start with a pointer to a `struct Foo { Bar* bar }`. How do you know whether that the value in `bar` points to a legit object? It's easy if it is a `nullptr`, but it could be uninitialized, or it could be initialized, but already deleted. One way is to ask the allocator (not an STL-style allocator, but `malloc`) if the object is valid. You'll have other problems, though. Suppose you have an `std::vector&lt;Bar*&gt;`. To follow the contained pointers, your tool would have to understand how vectors work, and how to use `.size()` to tell what pointers are followable. You could teach your tool about the STL, but any custom containers would have the same problem. 
but it means you need a JVM. That's really annoying.
I really like this idea. And using CMake avoids that you need to provide a bat script for Windows and a sh script for Linux. I have currently 3 valid or not reasons why I'm not using package managers so far (besides time to integrate one): - I want the possibility to choose the dependency version I want. vcpkg's approach to "fork" the repo seems like overcomplicating things. - I need a local repo for our own libraries. - our build server is not connected the internet for various reasons. So I need a local repo/mirror in our network.
I might be misunderstanding the purpose of this project, but Nix appears to solve the same problem. Nix is a purely-functional platform agnostic meta build system and package manager with reproducible builds. In particular, `nix-shell` seems to do the same thing as your tool. You write a declarative `shell.nix` expression and place it at the root of your existing project repository, and when you invoke `nix-shell`, it will fetch the latest version of your package manager of choice, fetch any native dependencies or external libraries you declare, and drops you into a shell with an isolated environment containing only your project's build system and other packages necessary to compile and test your project. Nothing you do in this shell affects the rest of your system, so any project which provides this file, regardless of programming language or toolchain, can be hacked on by anyone without any prior manual setup.
Conan supports all of these things as first-class features, so I'd recommend checking it out. You can run a local repository mirror in an intranet server, or even in the "local cache" pseudo-repository on a single machine.
GDB often knows about the dynamic type of an object, and it has plenty of frontends and/or you can write pretty-printers and other helper scripts.
!removehelp
Sorry, I'll post this in r/cpp_questions
Thanks for the info. So far I currently checked only vcpkg, because it seemed "native" (this project is VS only), but haven't checked Conan in detail.
Two very good commercial products are [Insure++](http://www.parasoft.com/products/insure) and [VTune](https://software.intel.com/en-us/vtune). I know you asked for open source, but this kind of tools do require lots of investment.
&gt; For Conan, this requires that you have a Python installation, and that you use Pip. C++ developers, in their stubbornness, don’t want to be required to learn another tool. Nah, just do the same as build tools in other languages do and use the same language everywhere. Ant, Maven, MSBuild, XCode, npm also require learning another tool, but they don't require installing another programming language.
Kcachegrind or heaptrack
The Instruments time profiler does what you said you want to do. 
If I understand correctly, Couroutine TS and Network TS (or just Asio) does not play nicely together in current form - you get two memory allocation for every single `async_x` call. Anyone knows if P1063 would make it any better or is it the same story.
Maybe you are lucky but personally I don't get "continual benefits" from knowing a massive lot about CMake. It's more like I know a lot about the "less worse" tool of the last 10years. I do believe I will totally forget about it if it get replaced by a better alternative. Like I totally forgot about php while I made merchant website 14years ago with it.
.dll -&gt; .so .lib -&gt;. a Header files are named the same. Note that under Linux files don't go into a program specific folder. Instead all library files usually belong into /usr/lib and all header files into /usr/include.
Being able to create and update your build without having to learn a new system is what you get from already knowing cmake. Just because you could learn something else and forget it doesn't mean your knowledge isn't beneficial moving forward if you don't switch.
&gt; Why would you put a template instantiation as a visible symbol? That smells like insanity. You usually want template code to be inlined. https://isocpp.org/wiki/faq/cpp11-language-templates#extern-templates if you use LTO there's actually good reasons to not inline: the linker will be able to inline anyways but you won't have 2000 additionnal needless instantiations
Facebook uses haskell in production.
vcpkg works on Linux as well.
&gt;implying for loops are functional
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/cpp_questions] [Looking for real-life C++ code written in functional style](https://www.reddit.com/r/cpp_questions/comments/9oll1r/looking_for_reallife_c_code_written_in_functional/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
For different UNIX like OS you can use massif tool from **Valgrind**: [http://valgrind.org/docs/manual/ms-manual.html](http://valgrind.org/docs/manual/ms-manual.html) and use **Massif Visualizer** [https://www.linux-apps.com/content/show.php?content=122409](https://www.linux-apps.com/content/show.php?content=122409) to visualize the output. or **heaptrack** [https://github.com/KDE/heaptrack](https://github.com/KDE/heaptrack) . For Windows you can use **Memory Usage** diagnostic tool : [https://docs.microsoft.com/en-us/visualstudio/profiling/memory-usage?view=vs-2017](https://docs.microsoft.com/en-us/visualstudio/profiling/memory-usage?view=vs-2017) 
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9ol65a/linux_dlllibheader/e7uy0eq/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Sorry but that's not my experience. CMake is working reasonably today but is full of issues as soon as you have to handle a complex project or a set of projects (where a dependency manager becomes important). What I'm saying is: we can do far better than CMake and having learned CMake before will become irrelevant and learning a new system will be effortless once we get there. It's what happen each time there is a major shift to a new language or tool. It's not new and I don't believe (based on my experience at least) in any benefits of any kind of status quo. Though that's my opinion of course ;)
Anything to do with streaming seems to be written in Scala these days for some reason
What happened here is that the compiler created specialized versions of \`fun\` and \`sfun\` for the particular call site with some constants hardcoded. You can see that because next to the function name you see things like \`\[clone .constprop.2\]\`. There is nothing illegal about this. You just don't see the general versions of those functions (that took actual parameters) because they are not needed here.
You can think that all you want, but it's nothing to do with sunk cost fallacy. 
If you can show that you will eventually save time/money/whatever by learning the new system and don't because you already know cmake, then sure, that's bad. But not just jumping at whatever shiny new thing is out there because you already know something that's serving you perfectly well isn't the sunk cost fallacy on its own.
Still fell short of establishing *why* something good enough to be the de facto standard in the Linux/Unix world needs to be a show stopper in the Microsoft world. Yeah, I get that they have symbol count limitations and different default visibilities, but the code obviously *worked* on Linux/Unix with a lot of symbols visible *and* Linux/Unix made it work while being compliant with the language standard.
Thanks; I've bookmarked it and will check later this week :)
It probably would not be too much effort write a GDB python script that prints the entire object graph reachable from globals and the stack. You could then further visualize the output with graphviz.
Seems like I can finally set link options that contains spaces? Link options like `-s DEMANGLE=1` (the space after `-s` is mandatory) cannot be used in `target_link_libraries`.
I am writing a comment not some sort of "respond letter". And to be honest almost all of the conclusions I degree on, so it is somewhat hard where to start, but the general the notion "it's good enough" and "well might be some better versions 2 years from, nothing wrong with that, we could have both" is something I strongly disagree. Seems the authors simply don't know how the standardization process in C++ works and/or draw parallels with other languages, developed at greater velocity. Ironically, the only part I agree is that both of the presented options have basically the same user facing API. But here is the thing, both (co_)await an [&lt;-] are not good (enough?)! Await is stuck in that mindset these are some remote resources, but it is questionable if [&lt;-] is an improvement. And both are not good as they don't support chaining - they are the operator* without operator-&gt;. Try writing code using pointers, using only operator*, just try it. If we agree we have much more fundamental concept then async operation, and at this point most agree (even the original await authors), then the design is destined to change (slightly), it is The Right Thing, or will be forced to evaluate more proposals like the [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0779r0.pdf](p0779r0) which is insane. Mind you am huge fan of coroutines and can't wait to use them, *but I was actually relieved reading P0973R0!* Even if just one of their (major) concerns is addressed, we all will win. 
Google-perftools includes performance and memory tools. The heap profiler works well without too much slowdown.
I recommend reading [P0973R0](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0973r0.pdf) which is the critique of await and outlines the problems. You can then read the alternative proposal [p1063r0](http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p1063r0.pdf), keeping it mind, *it is nowhere* *near* as matured - it was discussed just once. 
note that heaptrack is the successor of massif visualizer (and was made by the same person). In my experience it's as reliable but muuuch faster since it does not rely on valgrind.
Having used the Coroutines TS in my [gameboy emulator](https://github.com/TheThief/CoroGB), as well as coroutine-like fibers in a previous async networking project, I can speak from experience that short-lived coroutines are a huge performance issue, but a long coroutine awaiting on async functions (_not_ other coroutines) is fine. I don't see why awaiting on a Network TS async call would be any different.
I've studied the article, and in my opinion the reasoning of the authors is valid and the conclusion is sound. The gist of the article is to give the uncontroversially useful feature of coroutines to end users with a digestable syntax as early as possible, opening a opportunity to collect experience about using coroutines. In this regard, the difference between TS-Coroutines and P1063-ones is totally moot: the end-user semantics are totally the same, but TS-Coroutines offer the much nicer syntax (personally, I totally despice the special-character gobbledigook of much of C++'s current syntax, P1063 adding even more to it). Therefore TS-Coroutines are ready for inclusion and should be part of C++ 20. Endless discussions about possible, yet to-be-verified performance benefits of P1063-Coroutines offered by some future C++ compilers lead to nowhere and are just another means to delay the adoption into the standard and broad consumption by users. Rather than talking about optimizing the implementation of a non-existent language feature, the capacity of the standards body is better spent on delivering the language feature in the first place. To me, this sounds pretty much the same as the discussions about concepts and their syntax: a nice way to delay things endlessly.
This blog most reached into my soul. So perhaps my question is how did you manage that!! &amp;#x200B;
You can create an iterator to work like this
It's true that it's much faster, but has less functionality as discussed in readme. It cannot report stack allocation for example. 
I was looking for something similar recently and came across this: http://core-analyzer.sourceforge.net/ I haven't used it though--I would have had to invest time writing a backend for it to communicate with our memory manager, and priorities shifted. Visual studio also has a 
Nice release. Is anyone able to use newer cake releases with android studio, or the gradle external native build? Last time I tried there was a bug in the handling of cmake server api version.
- Compile time format string argument checker. - Compile time string parser for custom numeric types.
Does that track actual objects or just heap allocations?
It's quite easy to write a class `Iota` that enables exactly this. You dont even have to use a temporay container, the Iota::iterator can do all the work.
I haven't found much use for it, either. What I use most are the `constexpr` variables, as an annotation more than anything else. It is nice to have it, though. The fun stuff may come with `constexpr std::string`s and class types in templates. Even then, for most numerical stuff, and even code gen, I prefer to do it outside C++ and then import it (as C++ code or not, depends).
I wish there was examples with each jew feature and how it cane replace existing code. I have been trying to add some packages to my cmake project but I feel lost. I have a few libraries that are all cmake projects. Now I want to add these libraries to my high level project. I can copy these projects to a `lib` folder under the root of my high level project. But don't know how to integrate it with the main cmake project, should I use `add_subdirectory` or `find_package` or `find_library` or `target_link_library`. I didn't even know that there was a way to import library as you've mentioned. Can you please provide an example on how someone can do it prior to cmake 3.13 and after the release?
[Compile Time Regular Expressions](https://www.reddit.com/r/cpp/comments/9nxxe1/cppcon_2018_hana_dus%C3%ADkov%C3%A1_regular_expressions/)
Not sure if not off-topic, but compilers are surprisingly good in making constant things optimized out. I've been plating with a semi-static linear solver: [https://github.com/akalenuk/semi-static-linear-solver](https://github.com/akalenuk/semi-static-linear-solver) , and although it has no 'constexpr's in it, GCC makes best of what it gets efficiently optimizing out all the computations when all the data is de-facto constant. What's more interesting, if some of the data is constant and some not, it still manages to exploit that! You can feed it a triangular matrix, and it will generate a triangular matrix solver for it. It's amazing, It does algebra exactly like I would with pen and paper, but by doing optimizations. In practice, I rarely use 'constexpr'. Some exceptions are literally constant expressions like constexpr square\_of\_six\_and\_seven = six \* seven; But I do keep in mind that I can help the compiler do a great job by making sure it gets what's constant and what not. Data first, expressions - if it helps to make code more explicit.
That's foreach loop which can be perfectly functional.
There was a great talk at CppCon 2018 for compile time regex. The constexpr regex did better both in compilation time and runtime than std::regex.
For me, by far my biggest use case for `constexpr` is having the compiler check my code for UB and ambiguity, as code which could be constant executed cannot have either.
[A compile time format string argument checker](https://github.com/fmtlib/fmt) that compiles formats at compile time (but used to have to do everything at runtime).
It's hardly idiomatic usage for functional programming though, which typically relies much more heavily on recursion than loops. Indeed, many functional languages actually have no support for loops at all. In functional programming, it would be more usual to call a function that enumerates the list, calling a function on each element, and aggregates the results in some way.
&gt;Bloomberg Worked there and from my experience almost all code needs to be C++98/C++03 for Solaris and IBM compiler support. C++14 isn't the standard for the vast majority of teams.
I don't know what do you mean by tracking "objects" . This is kind of information you can from heaptrack : [https://www.kdab.com/heaptrack-v1-0-0-release/](https://www.kdab.com/heaptrack-v1-0-0-release/) You don't provide really enough information of what exactly you're looking for. What "similar tool" did you use for Java? What tools are you using for C++? 
The \`-S\` and \`-B\` options are slightly improved compared to the undocumented commands. The primary improvement is that you can have a space between the option and the path. Additionally they are not required to be used together, so you can do \`cmake -S ../src .\`
Your comparison to * and -&gt; sucks. If we had only * and not -&gt; in rev A then -&gt; could be added later. No issue here, in the meantime library authors could start writing libraries today. When -&gt; was added they could make them better. I think the authors of the article made a strong argument that syntactic differences are mostly irrelevant and just about anything would be fine. Whether gobbledygook or a keyword, you need something... The core argument is that the main potential improvements recommended in core coroutines could be added later and would only impact library authors, not user code (the changes would be in the coroutine interface classes, not the users business logic). 
To add a library in a cmake project choose one: 1. Compile the library from source, then link it to your application 2. Link to your application a pre-compiled binary If you choose 1) and your library is already a cmake project than it's simple. 1. `add_subdirectory(my_library_source_dir)` from a upper level cmake files This will add a target to your CMake build. Skip to point 3) If you choose 2) you need to: 2. `find_package(MyLibrary REQUIRED)` and hope that cmake can find your package ( it should if it is installed in a standard directory, otherwise you need to read documentation to provide the necessary hints ). MyLibrary needs a specific CMake Find Module to be able to integrate with CMake. This should be provided by the library maintainer. Finally, in both cases, you need to: 3. `target_link_library(MyAppTarget MyLibraryTarget)` Where `MyLibraryTarget` is defined either in your Library cmake with `add_library` or in the CMake Find Module by the library maintaner.
Compile time string obfuscation in a binary - de-obfuscated on demand at runtime.
One that hasn't been mentioned is mtuner: https://github.com/milostosic/MTuner But frankly nothing comes close to massif and heaptrack if you are able to build your application on Linux
&gt; On the contrary, Conan and vcpkg both support exactly what I am doing. Yes, it can work fine with conan and vcpkg, but if I want to use this to build a library with conda or some other package manager or a distro maintainer wants to build the library, this completely removes the capability for the package manager or distro maintainer to control the dependencies as it will have to have vcpkg or conan get the dependencies.
I see. Thanks for the explanation. I think I can go with either options. The good thing about `find_package` is that I don't have to have the library folder as a subdirectory of the current project. Right? I just have to provide that cmake find module file. In both cases if everything is setup properly, would CMake recognize changes in the library and rebuild/relink the project if necessary? I'm thinking of a scenario when I am debugging the library and I modify it. Do I have to manually first compile the library and then build the top level project or is it automatic? The IMPORT library you mentioned is not used in cases like this?
Our codebase is heavily relying on template to perform as much computation as possible at compile time I would say that constexpr was by far our favorite feature of C++17 as we were able to get rid of tons of complicated sfinae expressions, I think its not revolutionary for some, but it make the code/flow much more straightforward, and was proven to be easy to understand from people less experienced with metaprogramming
You know I'm not the OP right?
Now I do. 😁
No worries, but anyway, your limo answers my question. Thanks! 
In functional languages It's usually done as a function rather than a statement. The only significant difference.
The code bases I have worked on with C++11/14/17 support have increasingly as the constexpr world has become more powerful used it more and more. We didn't use it alot with C++11 because it was a bit harder to read with all the recursion needed. With C++14 it became much easier and with if constexpr in C++17 a lot of our code especially our template code has become much much easier to work with. &amp;#x200B; We use it extensively for attaching metadata to user defined types basically adding compile-time known data to data fields that can be read and used both for compile time calculations for example of min and max, but also for storing stuff like a constexpr string view along with the runtime variables. Much more constexpr stuff is coming up though it is not in the field yet.
Is the VTune memory analyzer any good (compared to heaptrack for instance)?
IIRC, Scala is used extensively in Spark.
Hi u/vector-of-bool, &amp;#x200B; &gt;then pass -DCMAKE\_TOOLCHAIN\_FILE=&lt;path-to-vcpkg.cmake&gt; &amp;#x200B; Do you know how vcpkg's requirement to hijack CMAKE\_TOOLCHAIN\_FILE plays with cross-compilation? Currently we pass a toolchain file to cmake via this variable that specifies the required cross compiler settings, so it sounds like a blocker to using vcpkg with cross compliation. If you have any experience with this I would be interested to hear about it.
I left in August 2017. Whatever initiatives were in place were mostly to migrate to Linux vs. migrate to C++11.
I wrote a function to generate \`D3D11\_INPUT\_ELEMENT\_DESC\` arrays ...
A [compile-time raytracer](https://github.com/tcbrindle/raytracer.hpp), of course.
https://github.com/Microsoft/vcpkg/blob/master/docs/users/integration.md#using-multiple-toolchain-files
Used in dangerous applications where it's life or death if a failure happens. Like IV pumps for neonatal, something my boss worked on. Here's the convention for FP users http://cufp.org/2017/ And here is a list of real world apps http://homepages.inf.ed.ac.uk/wadler/realworld/index.html 
Yes you can supply different cmake toolchain files to flexible cross compile to different targets from a given host. It’s another option you can set at configuration time, like the release type. Search for cmake ios toolchain as an example. 
Perfect! Thanks, good to know this is not an issue if we look into vcpkg as an option for our projects.
Thanks, I've made some formatting improvements.
Lots of good ones in this thread. One that I don't see listed: compile time check for constraints. For instance, if I have some data set that needs to be ordered (because I want to binary search it instead of linear lookup): constexpr bool IsSorted(int i) { return i &lt;= ARR_SIZE(...) || thing(i -1).attr &lt;= thing(i).attr; } static_assert(IsSorted(1), "thingy isn't sorted!");
It's probably to be consistent with the thread's URL!
Well, in my opinion the article tells us something different. If you have a different opinion I am co\_awaiting a substantiated counter-article where you layout your reasoning.
Memory profiling performance tools (https://github.com/MattPD/cpplinks/blob/master/performance.tools.md#memory---profiling) may be of interest; in particular: * MALT: a MALloc Tracker to find where and how your made your memory allocations in C/C++/Fortran applications + https://memtt.github.io/malt/ + https://github.com/memtt/malt * Memoro: A Detailed Heap Profiler + https://epfl-vlsc.github.io/memoro/ + https://github.com/epfl-vlsc/memoro * memtrail: A LD_PRELOAD based memory profiler and leak detector for Linux + ​https://github.com/jrfonseca/memtrail * MTuner - a C/C++ memory profiler and memory leak finder for Windows, PlayStation 4, PlayStation 3, etc. + https://milostosic.github.io/MTuner/ + https://github.com/milostosic/MTuner * Typegrind + a type preserving heap profiler for C++ - collects memory allocation information with type information + https://typegrind.github.io/ + https://github.com/typegrind/typegrind For general heap exploration: * heap_history_viewer: https://github.com/thomasdullien/heap_history_viewer - Example: https://twitter.com/halvarflake/status/1009086741242896386 - A Qt/OpenGL-based implementation of a heap history visualisation UI in along the lines of Gerardo Richarte's HeapDraw (for more details, check http://actes.sstic.org/SSTIC07/Rump_sessions/SSTIC07-rump-Richarte-Heap_Massaging.pdf) * Heapy - heap tracer and visualizer for glibc’s malloc implementation - https://github.com/degrigis/Heapy * Villoc: Visualization of heap operations - https://github.com/wapiflapi/villo 
I use `constexpr` to implement compile-time format string checks in [{fmt}](https://github.com/fmtlib/fmt). For example ```c++ // test.cc #define FMT_STRING_ALIAS 1 #include &lt;fmt/format.h&gt; std::string s = format(fmt("{2}"), 42); ``` ```c++ $ c++ -Iinclude -std=c++14 test.cc ... test.cc:4:17: note: in instantiation of function template specialization 'fmt::v5::format&lt;S, int&gt;' requested here std::string s = format(fmt("{2}"), 42); ^ include/fmt/core.h:778:19: note: non-constexpr function 'on_error' cannot be used in a constant expression ErrorHandler::on_error(message); ^ include/fmt/format.h:2226:16: note: in call to '&amp;checker.context_-&gt;on_error(&amp;"argument index out of range"[0])' context_.on_error("argument index out of range"); ^ ```
It's an absolute boon for embedded work. Let's you code symbolically, but end up with a small object file that has all the complile time knowledge about a particular device/project hard coded in. 
A couple of quick points: * It seems some graphs/images are missing, e.g. after " If you run this piece of code on an 8-core machine, the CPU load can look as follows." * The code style changes: some examples use `std::`, others import the namespace. Apart from that, it is an OK article; but I would prefer the vcblog is focused on Visual C++ stuff. I understand that the author is trying to promote his book and MS is trying to promote the support for C++17 support in their compiler, but...
&gt; Compile time format string argument checker. [absl::StrFormat(...)](https://github.com/abseil/abseil-cpp/blob/master/absl/strings/str_format.h#L16-L68) :D
[Valgrind](http://valgrind.org/) for Linux, [Deleaker](https://www.deleaker.com) for Windows. Also I've noticed that many people tend to use their own internal system to track objects because they need to track their objects only, not everything.
Can you elaborate how you go about doing it? :)
A very primary usecase is that they can massively simplify any meta-programming. `if constexpr` kills off a ton of SFINAE and tag type overloads, and it in turn is dependent on `constexpr` functions being a thing for any but the most trivial use cases. `constexpr` itself lets you avoid various functional-style recursive template meta-programming shenanigans in places where a more procedural-style flow makes the code easier to grok. All those string examples others have posted were often _possible_ with templates, but with a worse user-facing interface and a *significantly* worse implementation (that may run into implementation-defined limits re template instantiation recursion depth, not to mention massively bloating linker tables).
If I were a package maintainer and I saw https://github.com/vector-of-bool/pmm/tree/fd5c36e714a8c20bbe0a8072ce00dff8b9644512#how-do-i-change-the-download-location-for-pmm , I would notice that I could change the `PMM_URL` to a local URL and use this to replace the `pmm(...)` call to do whatever I want
Do you have any examples of specific cases? I do primarily embedded work and am always looking for ways to improve my libraries. 
Compile-time computing of probability distributions.
Last I look, the Ranges library isn't good for your stated purpose (in spite of all the hype). Happily it's easy to roll your own integer range for use in range based loops. When I've done that, without any special attention to speed, the loop code has been optimized to the same as with a simple counter loop.
Actual my formatting function also modify format string for logging purpose. Example: Log("hello {}, {}", "world", 111) ; The result of preprocessing format string: '"hello {s}, {i32}" It's done in compile time. Serialization will be in another process in runtime. Sadly but now it's impossible to write log funtion like above without macroses. Another useful usage of constexpr is "constexpr if": If constexpr (hasSecurityId&lt;T&gt;) {...} Save too much boilerplate code.
&gt; That more or less implies that my encoding for the source file will also be utf8 What? No. Writing u8"foo" means that the characters you write in the source, in whatever the source encoding is, will be converted to UTF-8. If the source encoding is EBCDIC then the EBCDIC string in source is converted to a UTF-8 representation that's available at execution. Forcing the compiler to ensure that the string contents is valid UTF-8 _before_ converting it would pretty much defeat the whole purpose of u8 literals.
I've started a generic low level library from scratch that `constexpr`'s everything so that I can also test the library at compile time. A good case study I use is Clang's implementation of `variant`. You can get quite complex things to be `constexpr`. &amp;#x200B; [https://bitbucket.org/guan-jing-ren/gut/raw/HEAD/functor.cpp](https://bitbucket.org/guan-jing-ren/gut/raw/HEAD/functor.cpp) eg, here's a `constexpr` function combinator I've been working on. As you can see, you can use lambdas to package up some non-trivial test code that's not `constexpr` on the face of it, to produce `constexpr` values for testing at compile time.
I do use a little FunctionalPlus ([FunctionalPlus](https://github.com/Dobiasd/FunctionalPlus)) a little in production code, but I restrict myself to writing very clear and understandable code with it (so that my fellow developers are not to scared). Presently, its usage is very limited in our code base. I hope to be able to teach some of the lead developers to use it more, but this will require time. I think its usage will be limited to the base libraries in our code base, not to the GUI / business code. One of my lead developer was favourably impressed when he saw that you can search for `((a-&gt;b),[a])-&gt;b` and get `transform_reduce` as a result (see [the api search site](http://www.editgym.com/fplus-api-search/)) It's API is clear, and it is unobtrusive (header only); and it is quite usable. Of course it does not provide lazy evaluation as rangeV3 will, but in my case performance is not an issue. &amp;#x200B;
You can use it for a compile-time integer power function: http://prosepoetrycode.potterpcs.net/2015/07/a-simple-constexpr-power-function-c/
'if constexpr' is all sorts of fun. Check out lines 39-76 [in this fragment of my GLM/Eigen wrapper](https://gist.github.com/jrandom/254c2f8bb7e6556f267d20a9f098d274).
Wow, how awesome! And I can't believe that you can generate images as large as 800x800!
https://www.youtube.com/watch?v=LfRLQ7IChtg
Says video has been removed by user.
A string literal is defined in source code which is input to a constexpr utility which applies an XOR on the string based on some buffer of pseudo-random data (this can be seeded by the current time at compile time). The resulting binary output is stored in a std::array of the same size as the input. In order to get the plaintext output at runtime simply repeat the XOR and you get back the original input string. You can of course perform all sorts of jumbling of the data and further obfuscation as you please, you just need to perform the inverse when you want to get the original back. This isn't secure encryption, as the key is also in the binary but it prevents someone being able to run strings and immeditely find your literal. This merely raises the bar so someone at least has to reverse engineer your scheme. 
&gt; The “target_link_options()” command was created to specify link options for targets and their dependents. Hooray👍👍
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9oqk02/templates_and_functions_question/e7vy0ay/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Note: Interestingly, Reddit's classic view doesn't interpret triple backslashes, while the new view does.
I use a combination of templates and `constexpr` to do two things in AVR/Atmel, at least: 1. Autogeneration of data tables for things like ADC lookup, including assistant variables (min/max/constant intervals between values, min/max values, and so forth). This is further used to help generate optimal code for *lookups* into these tables - if you know the properties of the tables, you can generate better code - if you know the interval is constant, you can avoid a progmem load. If you know the min/max values, or the min/max values *relevant to the input you have provided*, you can use smaller type sizes which are important on 8-bit chips. 2. Autoderivation of type sizes in algorithms and autogeneration of code around that. Almost everywhere in my AVR codebases uses templated types like uintsz_t&lt;min, max&gt;, and use similar template and `constexpr` constructs to generate minimal-size fixed-point types for various purposes. I basically have C++ generating *far* better AVR 8-bit code than C reasonably could.
I use a combination of templates and `constexpr` to do two things in AVR/Atmel, at least: 1. Autogeneration of data tables for things like ADC lookup, including assistant variables (min/max/constant intervals between values, min/max values, and so forth). This is further used to help generate optimal code for *lookups* into these tables - if you know the properties of the tables, you can generate better code - if you know the interval is constant, you can avoid a progmem load. If you know the min/max values, or the min/max values *relevant to the input you have provided*, you can use smaller type sizes which are important on 8-bit chips. 2. Autoderivation of type sizes in algorithms and autogeneration of code around that. Almost everywhere in my AVR codebases uses templated types like uintsz_t&lt;min, max&gt;, and use similar template and `constexpr` constructs to generate minimal-size fixed-point types for various purposes. I basically have C++ generating *far* better AVR 8-bit code than C reasonably could.
The problem impacts C++ codebases as well (I've run into it).
If you have an async operation that is simply calling a non-cancellable sync operation on a background thread then there's not a lot you can do. You still need to wait for that sync operation to complete before it's safe to release resources used by it. It's possible you could build a cancellable future/task such that you could co_await the future along with a cancellation_token so that the co_await may return early before the future has become ready. eg. ``` // Async operation, calls non-cancellable sync function task&lt;void&gt; async_read(char buf[]) { co_await thread_pool::schedule(); sync_read(buf); } cancellable_task&lt;void&gt; cancellable_async_read() { char buf[100]; co_await async_read(buf); } task&lt;&gt; coro(cancellation_token ct) { some_big_type big; co_await cancellable_async_read().detach_if_cancelled(ct); } ``` With this approach, the `coro()` function would be able to perform a cancellable co_await on the cancellable_async_read() task. If the cancellation_token is signalled before the operation completes then the co_await could return early and allow cleaning up the coro() coroutine and its resources, but would detach from the cancellable_async_read() and async_read() coroutines which would still need to remain allocated until the sync_read() function completes. I think that's the best we can do with regards to freeing up resources early if those resources are still being used by an uninterruptible synchronous operation. Note that I'm not necessarily advocating for this approach as it now means that you have some detached computation that you cannot now know when it completes and thus when you can safely reuse or shutdown/destroy resources it was using or whether it completed with an error. However, these tradeoffs may be acceptable for some use-cases. &gt; `weak_ptr` is a cancellation token While you can use a `weak_ptr` to query whether some object is still alive and thus whether to deliver a result to it, it doesn't allow me to receive active notification that the source object has been destroyed so that I can interrupt/cancel what I'm doing early. At least not without intrusively adding this support into the object so that the destructor notifies me.
your ide may do this already
yes &amp;#x200B;
We get it: you can do stuff at compile time
!removehelp
The program returns 1. After optimization, the program still returns 1. Therefore, the optimizations are perfectly legal. I have no idea what ODR has to do with this.
Why do you want them to switch?
[Here's](https://en.cppreference.com/w/cpp/compiler_support) a link to cppreference which shows compiler support for certain C++ features. GCC and Clang (the compiler you're referring to when you write LLVM) both support essentially equal features and both cover the entire current standard (C++17). I think your research thus far shows that swapping between current version of Clang or GCC will give little performance increase. Most likely, any headache of switching compilers will invalidate any of your pro-LLVM arguments. It seems like you're asking for reasons why you might suggest switching compilers but if your company sees no need, then why would you suggest a change. Why spend the time forming the argument if your current GCC build is fine? Why would you "like something more substantive?"
aninteger just craves more c++ action presented by Turner
Please see https://youtu.be/UL3TtTgt3oU?t=325 that describes an efficient way of integration of Coroutines and Networking TS. The concept of Awaitable allows describing any async OP without requiring any allocations. It is likely that cpu_read8() would need to return awaitable, but does not have to be a coroutine itself. For example, in nano-coroutine talk at CppCon 2018, it was shown how to use coroutines to mask memory latency by suspending the coroutine while prefetching a value from the main memory to the CPU. https://youtu.be/j9tlJAqMV7U?t=541 
But I don't have a button on my keyboard for a unicode trigraph character, so I'd need to be able to type it with some sequence of more common characters!
Please see https://youtu.be/UL3TtTgt3oU?t=325 that describes an efficient way of integration of Coroutines TS and Networking TS. Coroutines TS not only does not require a memory allocation for an await call, it also allows to eliminate an allocation done by networking TS by allowing to store the state as a local on the coroutine frame.
&gt; C++98/C++03 for Solaris and IBM compiler support &gt; migrate to Linux Can't say I'm seeing the problem here? But yeah, progress is mixed for some teams.
It's hard to sell the comparison points you are interested into without knowing the motivation behind the change. As far as I'm concerned, you shouldn't simply move from one to the other. You should strive for compatibility with both in order to maintain maximum flexibility, and at the same time, standard compliance.
Technically, I do everything before compile-time. The compiler does it at compile-time, I have nothing to do with it.
&gt;It is likely that cpu_read8() would need to return awaitable, but does not have to be a coroutine itself. In my case cpu_read8() contains an await for the appropriate cycle count for synchronisation and then the actual memory read - so was a miniature coroutine. It was grossly inefficient, making it into a macro moved the suspend point into the parent function and skipped the allocation of the coroutine frame. The alloc/free of the coroutine frame actually showed up on performance profiles O.o Thinking about it I could probably make it return a custom awaitable type which delegates to the cycle awaitable and then performs the memory read on resume, but it works fine as is (and the 16-bit reads contain two waits, so can't pull that trick). What I really need is the ability to _inline_ one coroutine function into another.
Lame
Those COW std::strings were from a time threads did not officially exist. Of course, everybody used thread anyway, so it was found that COW strings in that context is not a good idea. Now what can we deduce from that? Should std::string only have been designed after standard threads? I'm all for coroutine that don't allocate if they don't need to (and I'm even talking prior to any smart optimizer magic, because unoptimized C++ is already slow enough...) but I'm not sure there is any relation with COW or not strings.
I'm not sure I like that. I usually end up putting something in the makefile to spit out a C array in a namespace and another array of all the files so you can iterate over them. Sure, for something like that I use Ruby and erb so that encumbers the build process but it works on literally any C/C++ compiler. What I don't like about this is the inflexibility of the data generated and the fact that I have to define all the resources in the source code. I just want a big directory of files I want processed and for the packers to just dump it all into arrays for me. My source code shouldn't have to stay in sync with the resources. There's also no metadata here, is there? Accessing everything through an unsigned template parameter is too inflexible. You can't iterate over the resources, you can't call up a resource by original filename, you can't even get the original filename given a resource handle.
Yes, why do you want them to switch if you don't know why Clang is better than GCC?
If they are going to stop using old machines, great. But in my experience they weren't stopping.
Good talk, but nothing significant about uses of constexpr in there that I could see?
Haven't watched the talk yet. Was it the one with the LL parsing table in it (and probably more theory)? If she used theory and std::regex has to support non-regular languages, I would expect her implementation to blow away the standard's even if it wasn't constexpr.
You might be interested in the [`std::embed` proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1040r0.html)
Why switch when you can have both? 
I started out with Accelerated C++. At the end of the fifth chapter, I decided to step back and switched to C++ Primer fifth edition. Thanks.
Looks useful and shows nicely how to write a tool based on clang/LLVM Some minor things i noticed: https://github.com/nohajc/resman/blob/master/rescomp/main.cpp#L286 I would handle RTTI and Exception settings with a command line argument https://github.com/nohajc/resman/blob/master/common/objcompiler.cpp#L104 You only init the X86 Backend. To init all you can use this code: InitializeAllTargets(); InitializeAllTargetMCs(); InitializeAllAsmPrinters(); InitializeAllAsmParsers(); It would also be useful to handle options like TargetArch. You can look at the code of llc to see how to do this. Check also if you need to call InitLLVM. On thing that i do not understand is https://github.com/nohajc/resman/blob/master/rescomp/main.cpp#L175. Why do you init storage_size to 6? 
Well, for one the handle is not templated, so adding a container of all resources would be trivial. Since I use clang to parse the header I might also pass the filename as metadata. Why not. This is work in progress so I welcome any suggestions for improvement. The reason I use the non-type template parameter is purely technical. It allows me to generate unique extern static data members on demand which are then linked to the contents.
&gt; The only way to find out which produces better code for you is to benchmark. I am working on this, unfortunately, disk space appears to be a premium where I am because of an overly aggressive backup system we have. &gt; GCC has more backends for exotic hardware We use Intel CPUs only. The only real concern along these lines is a specific OS for some of the subsystems. I am trying to see if GPUs (CUDA) would be a fit and that uses LLVM. 
&gt;So you're trying convince your company to switch to a compiler even though you don't have arguments for that? Please quote where I say I am trying to convince them. The closest I come is: &gt; I would like to consider moving to LLVM but that is a statement that I want to consider it, not actually do it.
Yes i want to join.
6 is just an arbitrary constant (strlen of "dummy" in this case). The code is there just to generate the right AST node from which I can get mangled names for the static members I need to export. It doesn't matter what the value is since it won't be used. I use the mangled name to generate a variable containing the actual size later in the code.
Yeah, but why "consider moving to LLVM" if you don't have reasons to do so? Moving a project to a different compiler takes time and effort. I am just trying to understand you motives. Are you dissatisfied with gcc or what makes you think switching to LLVM is a good idea? Don't get me wrong clang and the LLVM ecosystem is great and insanely powerful, but is it really worth the effort? Ultimately gcc and clang have somewhat comparable optimizations/code generation: there are scenarios where clang excels and scenarios where gcc takes the lead. Unless you're interested in, say, some LLVM feature or tooling it's probably best to stick with gcc.
If you go that route just use Hunter - a native CMake package manager. 
&gt; Don't get me wrong clang and the LLVM ecosystem is great and insanely powerful, but is it really worth the effort? This is what I am trying to figure out and every single path I go down hits a deadend or I get nebulous statements like: &gt;Don't get me wrong clang and the LLVM ecosystem is great and insanely powerful &amp;#x200B; &amp;#x200B; &gt; Yeah, but why "consider moving to LLVM" if you don't have reasons to do so? Because we are looking at the next major iteration of out software in the next few years and I keep hearing great things about LLVM/Clang but when I try to find information on why, I just hit dead ends.
I don't know anything about tooling using LLVM and it looks like a good learning experience. Thanks
You keep hitting dead ends because you don't even know what you're looking for. LLVM is a complex ecosystem with rich tools and features, such as clang tidy, address sanitizers, static analysis tools, thin-LTO, cross-compiling to other languages (e.g. emscripten), libclang/libtooling etc.... 
I'm a little wary of tying it into `clang` and generating a binary. I have a pretty simple python script that generates binary source code from a list of files and provides a header with access to all of them. The output then compiles with only a C++ compiler. This code uses a string for item lookup. But it would be easy to output symbols in the namespace instead of string lookup if you want static references instead of dynamic. Could also be converted to `O(1)` lookup in the dynamic case, but I didn't need it. ``` #!/usr/bin/env python import argparse import os.path header_file = """ #include &lt;string&gt; #include &lt;cstdint&gt; namespace {namespace} {{ struct buffer {{ uint8_t const* data; size_t length; size_t cursor = 0; /// provided for client convenience buffer() : data(nullptr), length(0) {{}} buffer (uint8_t const* d, size_t l) : data(d), length(l) {{}} operator bool() const {{return data &amp;&amp; length;}} std::string stringCopy() {{ return std::string(reinterpret_cast&lt;char const*&gt;(data), length); }} uint8_t const&amp; operator[](size_t i) {{ return data[i]; }} operator char const*() const {{ return reinterpret_cast&lt;char const*&gt;(data); }} }}; /** Use this function to retrieve resources. */ buffer r(std::string const&amp; filename); }} """ buffer_block_start = """ static uint8_t {file_ptr} [] = """ buffer_block_end = """; """ r_func_start = """ namespace {namespace} {{ buffer r(std::string const&amp; filename) {{ """ r_func_block = """ if (filename == "{filename}") {{ return buffer({file_ptr}, {file_length}); }} """ r_func_end = """ return buffer(nullptr, 0); } } """ args_p = argparse.ArgumentParser(description = """ Make compileable resource package. Embeds every file argument as hex-encoded binary data in an object of your choice. To use the resouce file, add it to the list of source files for the compiler in your build system. Then call the resource fetch function with the file name you want to retrieve. By default, the function is `_r::r(std::string const&amp;)`. """) args_p.add_argument('--outdir', default="./", type=str, help="Directory to write the .h/.cpp files.") args_p.add_argument('--ns', default='_r', dest='namespace', type=str, help="Namespace used by resc.") args_p.add_argument('--basename', action='store_const', const=True, default=False, help="If set, file keys will be only the base part of the given filenames.") args_p.add_argument('output_base', type=str, help="Base for output file names.") args_p.add_argument('files', nargs="*", metavar='FILE', type=str, help="File(s) to resourcize") args = args_p.parse_args() header_file_name = os.path.join(args.outdir, args.output_base + ".h") source_file = os.path.join(args.outdir, args.output_base + ".cpp") if not os.path.exists(header_file_name): with open(header_file_name, 'w') as out: out.write(header_file.format(namespace=args.namespace)) file_pointers = [] file_id = 0 with open(source_file, 'w') as out: out.write('#include "{basename}.h"\n'.format(basename=args.output_base)) for filename in args.files: row_len = 25 with open(filename, 'r') as f: fp = "_buffer_" + str(file_id) file_id += 1 out.write(buffer_block_start.format(file_ptr=fp)) filelen = 0 while True: row = f.read(row_len) out.write('"' + "".join("\\x{:02x}".format(ord(c)) for c in row) + '"') filelen += len(row) if len(row) &lt; row_len: break out.write("\n") out.write(buffer_block_end) if args.basename: filename = os.path.basename(filename) file_pointers.append( (filename, fp, filelen) ) out.write(r_func_start.format(namespace=args.namespace)) for fp in file_pointers: out.write(r_func_block.format(filename=fp[0], file_ptr=fp[1], file_length=fp[2])) out.write(r_func_end) ```
Literally the first sentence of my post was: &gt;Are there any good comparisons of LLVM vs GCC? &amp;#x200B;
If you go reread my post I never stated I want them to switch. I stated I want to consider it, but have been unable to turn up useful information even though I keep hearing good things about LLVM/Clang.
You may consider these points: * generated binary performance: realistic tests show that even if LLVM improved, real code binaries generated by clang are still slower than those generated by GCC: [https://www.phoronix.com/scan.php?page=article&amp;item=gcclang-epyc-summer18&amp;num=4](https://www.phoronix.com/scan.php?page=article&amp;item=gcclang-epyc-summer18&amp;num=4) * language conformance: the conformance status shown on cpp reference or reported by on compiler's web pages does not take into account the open bugs. From my own experiment, GCC is clearly a winner here. If you want your code to compile with both gcc and clang, you will have to find work around the many clang bug that make the compiler silently crash. From my point of view, clang should not be use to compile generic code. * speed of compilation: clang is clearly a winner here, but it seems that gcc9 will improve drastically compilation speed.
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9oryt5/would_like_to_join_the_cppforbeginners_group/e7wec29/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Why not use both ? I would advise that you should start by using both in your continuous integration. You will quickly see that clang and gcc will emit different warnings at different places in your code base (with -Wall or more). All of them are interesting. The more compilers you use, the more you can increase your code quality. As a matter of fact, Visual Studio (with /W4) can also give some quite interesting warning in addition to those two. &amp;#x200B; Then, switching compiler for the final product is a question that can be answered later; after you benefited from having a double check on the quality of your code. &amp;#x200B;
Just a heads up, this build seems to either behave differently with Qt5. the QT\_UIC\_EXECUTABLE variable is **blank**, whilst the MOC equivalent is populated. There was nothing in the release notes about change in behaviour (only the verbosity flag).
&gt; Wow, how awesome! And I can't believe that you can generate images as large as 800x800! Not sure if this is sarcasm but hey, it's the fastest C++ compile-time raytracer I know of... &gt; May I ask whether you've reported the msvc ICE to MS? I didn't at the time, but this predates VS 2017 so it may work today if you set `/constexpr:steps` appropriately. I haven't tried it in quite some time.
I am saying internal implementation changes break user land frequently. A cow string would have left room for a non cow string later; but a maybe cow string meant half the world suffered breaks later. Plus, specs changed that nobody thought cared if the string was cow. Implementation matters, and abstractions leak. Saying it doesn't matter because it is behind an abstraction is risky.
&gt;I am working on this, unfortunately, disk space appears to be a premium where I am because of an overly aggressive backup system we have Can you elaborate, that sounds super weird? If compiler disk space is an issue for your company, then you have bigger issues than GCC vs LLVM.
What are you trying to compare? It's like asking chrome vs firefox. It depends. The solution at my company is the build with as many compiler as possible, and ship the binary built with the default toolchain for the system that the project needs to be deployed on. 
I noticed but decided to keep it this way to raise awareness that Markdown support needs more work.
or would I answer it this way, &amp;#x200B; cout &lt;&lt; "(" &lt;&lt; setw(4) &lt;&lt; intValue &lt;&lt; ")" &lt;&lt; endl; &amp;#x200B; ? 
I haven't found one yet. Suggestions are welcome.
What do you expect? Seriously, anything you find on the net will reflect personal biases. The other problem is that you are posting this at a very late date with respect to the existence of LLVM / CLang. That may indicate that compiler tools and code development tools don't mean much to you and your project. That could be good or bad, I don't know much about your project but I find it odd that any serious developer using C or C++ hasn't built his project against LLVM / Clang already. Actually it boggles the mind that somebody would be so out of touch. This especially when considering the tools beyond the compilers.
Yes and you still don't get what people are saying here. Screw the comparisons!!!!!!!!!!!! The question you are asking is simply of no use, you have to understand the tools before you can really say what value they may have against your current suite of tools. There is so much to the LLVM / CLang world that no comparison would be of use with your project. You need to consider the value of the whole suite. The analyzer tools are well regarded and have found many bugs in software that has been around for a long while much less new code.
I want ranges doesn't even allow you that, but not having to type `.begin()` and `.end()` is already a big win. Baby steps. For the integer range coroutines with generator can do it, so there's definitely work on it.
You should probably find the proper place to report that to Reddit's devs, since they aren't going to monitor the cpp subreddit. (Our stats show that most people are using the new view in the subreddit, but I'm one of the holdouts.)
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9otgfl/assume_the_following_variable_definition_appears/e7wmqld/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It's probably mingw-gcc or mingw_w64-gcc. Or did you install just g++?
Technically, everything was done even before before compile-time and put somewhere in the expression of pi. Someone just forgot to store the offsets.
Not sure. Just followed this tutorial [https://www.eclipse.org/4diac/documentation/html/installation/minGW.html](https://www.eclipse.org/4diac/documentation/html/installation/minGW.html)
no problem!
&gt;I am working on this, unfortunately, disk space appears to be a premium where I am because of an overly aggressive backup system we have. I don't know if you need serialization software, but my approach of on-line code generation minimizes the amount of code you have to download, build and maintain. Additionally I use a terse coding style. &amp;#x200B;
Well sometimes you need to write for loops because you need the actual indices to do something. I know there are ways to write `for(int i=0;i&lt;n;++i) total+=i*i;` with algorithms, but that requires a lot more code than the simple for loop. You need iterators that are actually ints to do this, and it just makes the code less obvious.
The compiler output you are referring to probably includes most of the library because headers =). Per-call code is actually tiny, comparable to that of \`printf\` and much smaller than what you'd get with iostreams: [https://godbolt.org/z/nCnhJL](https://godbolt.org/z/nCnhJL) . Note that constexpr is only used for compile-time checks at the moment, generation of optimal formatters at compile time is still in the works (and you wouldn't want to use them everywhere, only in perf critical code).
Is `1:10` that much better than `1, 10`?
Why do people like you criticize others for attempting to learn? He's heard good things about LLVM and he's asking for more information and you're being critical of his attempts to find this information. Just fuck off...
You mean replace the ugly `ADDRESS_OF_THISSTUFF` macro by a `constexpr` expression with an actual type?
When formatting memory buffers or directly to string is there a way to reduce the generated code size? constexpr auto f = fmt( "{}" ); auto s = fmt::format( f, 42 ); This results in 15-16kloc of asm on god bolt with v5.2
We find https://github.com/vmware/chap to be pretty indispensable. “chap analyzes un-instrumented ELF core files for leaks, memory growth, and corruption” glibc only.
Sorry for my misunderstanding
Safari doesn't have an optimized pipeline for asm.js, and never did.
CTRL-D is what we neeeeeeeddd
Isn’t that name already taken by something similar? https://en.m.wikipedia.org/wiki/Lex_(software) 
How's it different than the guy who posted the same thing here a month or two ago?
This might be a completely stupid question, in which case I apologise in advance: What's the gain from having a tokenizer be constexpr? I can't think of a case where the input would be known at compile time, which is the only case when constexpr matters (as far as I understand.)
I also have repositories called `array` and `memory`. I'm not good at naming, so the full name is `foonathan/lex`, `foonathan/array` and `foonathan/memory`.
I don't know to be honest. But with C+-14 constexpr, all I needed to do was put constexpr in front of the functions, so I just did that...
I haven't seen that / don't know which guy you're talking about.
no, PCH don't instantiate templates at all (afaik)
Do you know of [Hunter](https://github.com/ruslo/hunter)? A dependency manager written in CMake? How hard would it be to iclude it as a viable option?
IIRC it wasn't proven that pi is infinite?
A few people have mentioned it but the best thing you can do is get you code compiling on as many platforms as possible. So you are starting off with GCC. Next up would be getting it compiling with clang (and fixing errors / warnings that appear). If you want to you can then do some speed tests to see if it is worth changing your "release" compiler. But even if you don't you should keep the code compiling with clang. You should also look at getting you code running with things like: * clang analyzer / tidy * sanatizers * cppcheck * msvc The more things you can catch with your CI system, whether by compilers, static analysis , or dynamic analysis. The less chance of bugs reaching your customers. 
&gt; Not sure if this is sarcasm but hey, it's the fastest C++ compile-time raytracer I know of... I was completely serious, sorry it didn't come across :-) A very cool project, and I really wouldn't have thought that you can make it work for such "large" images (okay maybe that's not large anymore for nowadays measure, maybe that's why you thought my comment might be sarcasm!). If I had to guess I'd have said you could render maximum a 200x200 image or something along those lines.
You might. I know I care. C arrays take up unnecessary disk space and they're potentially slower to compile. There's even the std::embed proposal (mentioned in this thread) so it looks like people care.
Indeed it is an observation that is valid for a library I am working on, using heavily templatized code, and this observation may be more the consequence of this library coding convention than the expression of the intrinsic quality of these compilers. But still I am very disappointed because of the total cost of finding Clang bugs and of maintaining work around for them in this library.
Appropriately enough, me and Herb are presenting http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2289.pdf to WG14 C programming language standards committee later today 11am EDT. What WG14 thinks will greatly influence what happens at WG21 in a few weeks time. Before people start asking about prototype compilers, we need to decide the shape of a prototype first. That should be done by end of WG21 San Diego, so expect a prototype compiler sometime in 2019. If people would like to use this stuff today and now, Outcome as a library based solution is ready to go. Here is P0709's `throws` use case example written using Outcome and proposed `std::error` on godbolt: https://godbolt.org/z/nKpNZu. Note how well it optimises, already, with today's compilers. 
Good luck! Thanks for all your hard work on this.
All the answers so far haven't mentioned the single biggest reason why big multinationals love clang: if you're required to generate executables for RHEL6 or RHEL7 as most are, you can use clang trunk with as ancient as libstdc++ 4.4 and it works beautifully. That in turn means you can use C++ 20 features, the sanitisers, the optimisation, and the warnings but with a truly ancient STL, as RHEL6 binary compatibility would require. And that's exactly our big love for clang here at my current client, as we target no Linux newer than RHEL6 (and no, statically linked binaries are not permitted, else security fixes to libstdc++ require us to issue a new release, and we only do that once every two years). In terms of which is better, each has their strengths and weaknesses, but generally it does great favours to a codebase to compile cleanly on both with all warnings on max. In terms of codegen, clang does more really clever optimisations, but in aggregate GCC tends to still edge out. To be honest, most folk don't care about a &lt; 4% performance differential if there are other big compelling reasons to choose clang (like the above).
aren't static libraries exposed to other sort of problems on linux? The ones that come to mind: 1) the `.a` file was generated on a system that uses relocations not yet supported by the version of `binutils` installed on the current system 2) PIC / non-PIC issues, such as integrating the library into a shared object if the .a file was not generated with the PIC flag, or integrating the .a file into an executable where the compiler/linker will generate PIE executables 3) how the library was built w.r.t. `_GLIBCXX_USE_CXX11_ABI` No matter what, if one wants to maintain a library that targets a high degree of compatibility, certain things need to be taken into account anyway regardless of the platform. 
The linux ecosystem is opensource, whereas most of the Windows ecosystem has remained closed-source. It is not entirely unreasonable to make hiding symbols the default. Can also prevent people calling undocumented APIs (the second they depend on it, you have to support it one way or the other!). Like someone else has mentioned, having something force you to think "this function/class is part of my API, this other one isn't" is not the worst thing either. &amp;#x200B;
The stream starts in 2 hours.
yes, but the only compiler which does this in practice is zapcc (https://github.com/yrnkrn/zapcc). It would be very cool if this was to be merged in clang proper but it's sadly not the case.
The compilers are very different from beginning with their focus. GCC has much more backends and is more embedded oriented (extensions for Linux kernel, etc.) Clang is very extensible and created ground-up as a library. It also has much more better license for downstream extensions. So you have lot of tooling created on top of LibTooling (clang-format? Some parsers, clangd etc.). But because we have a competition, they are always making themselves better to comparison to the other. And getting closer and closer in that regards. To have some hard numbers, I am usually following [Phoronix GCC vs LLVM](https://www.phoronix.com/scan.php?page=article&amp;item=gcc-clang-eoy2017&amp;num=1), but best approach is as with C++ performance - experiment, measure, choose and improve.
That pi is irrational is proven since 1761...
Comments are good for unobvious cases like this one.
Good luck! Btw feels like a unique opportunity to create a proper universal ABI better suited for modern code with mutiple returns, function chaining, vector code etc. ;)
It is not a matter of "putting `constexpr` in front of functions". You are promising that you will always be able to keep it `constexpr`.
So, they basically added Rust style error handling with some weird C++ syntax or am i missing something? I'm not complaining since i think Rust's error handling is probably the most beautiful thing i have seen in programming, but my main problem with exceptions still remain: try/catch blocks. The new try keyword before function calls help a little, but it's still hard to follow the control flow of try blocks with multiple calls that can throw an exception. Still a big thumbs up for trying to make exceptions suck less in C++.
I'm fully aware. But it's compile time tokenization is a feature that cost me nothing, so I support it.
We've found quite some embarrassing bugs from warnings when we added different compilers to our CI, I can only recommend that.
Yes, they are adding "rust style" error handling to c++, in the sense that the error is part of the function signature and that you can only ever access the result if the error is not raised, and are forced to handle the error (assuming passing onto caller is a way of handling it, as well as explicitly opting to do nothing). The try-catch syntax is very familiar to a lot of developers. Calling it weird is at the very least subjective. 
&gt; Some may feel that the collision potential of these choices of naming is too high, however it is the same mechanism which C99 &lt;stdbool.h&gt; uses, which macro defines `bool` to `_Bool` if not in C++. Why `fails` and `failure` is outside `#ifdef __cplusplus` then?
Exceptionally good proposal.
`fails` and `failure` are C. `throw` and `catch` are C++.
I just did a quick google and this looks really promising (and interesting!) There is so much C++ stuff I have yet to learn, and that makes me excited and happy \^-\^
Do we need `fails` and `failure` in C++? I still don't get why these 2 are outside ifdef
I'm familiar with the try-catch syntax and i'm not calling that weird. I'm calling the "throws" keyword before the return type in the function declaration weird. Isn't it just syntactic sugar to tell that "this function will return a result&lt;OkType, error&gt;"? Maybe i'm just getting it wrong (i'm at work, so i haven't read/watched the whole proposal), that's why i'm asking. And yes, it's very subjective and I find the "-&gt; std::expected&lt;double, std::error&gt;" return signature more readable, because it tells me exactly what it does. Anyway, as I said, I really like the proposal and hope it goes through.
If you read the linked paper, a `fails` function in C++ does not have auto-propagation, whereas a `throws` function in C++ does have auto-propagation. `failure` in C++ equals `throw`, but only in `throws` or `fails` functions, otherwise it's a compile time error.
Quick plug for a project that has replay integrated fundamentally so it is always available: https://github.com/LiveAsynchronousVisualizedArchitecture/lava/blob/master/README.md This talk seems to be about recording function calls and serializing them into JSON to be able to replay the function calls, which makes a lot of sense to me. LAVA's approach is to always use serialized communication. Then any input can be written to files or sent to other processes and used visually in the same way the output that created them was used. This is easy with a single header file array+hash map that is always a flat single memory span (always 'serialized'). 
On the C side, I really don't like the catch mechanism. Having to declare your own struct to access the returned value is simply a no-go. At an absolute minimum, the `caught` macro needs to be standardized into the header, and I'm not even a fan of that. N2285 has a very interesting alternative syntax to get around this (though it has other problems, like function pointers, ambiguity, and there's no chance C++ could be backwards compatible). I'm interested in your thoughts on that proposal, and if there's some way to make N2289's C version more convenient.
How is it different from xxd? &amp;#x200B; $ echo hello world &gt; a $ xxd -i a outputs: unsigned char a[] = { 0x68, 0x65, 0x6c, 0x6c, 0x6f, 0x20, 0x77, 0x6f, 0x72, 0x6c, 0x64, 0x0a }; unsigned int a_len = 12;
&gt; On the C side, I really don't like the catch mechanism. Having to declare your own struct to access the returned value is simply a no-go. At an absolute minimum, the &gt; caught macro needs to be standardized into the header, and I'm not even a fan of that. It took a fair bit of WG14 reflector debate to land on the designated initialiser workaround in fact as a reasonable compromise between competing factors. In real world code, most C code has a library-peculiar error struct type with extra data about failures. They want to initialise one of those, and maybe fill in the remaining fields. Hence standardising any one error type does not suit existing C code bases, which tend to use macros calling an init function to initialise said custom error struct types as they have no constructors. The current proposal is a reasonably open ended, balanced, solution which does not impose too hard on whatever C programmers are already doing. It isn't perfect, but some are really opposed to any standard type, others really want a standard type. So we propose exactly in between, and satisfy nobody :) I personally think that if C wants a standard error object, it ought to be magical. Only then can they implement the polymorphism necessary to make such an object useful across any collection of possible C libraries. I think said magical object ought to gain its own paper, as it's orthogonal to any mechanism, and will involve a ton of bikeshedding. 
I'd say here the getInstance() returns some singleton stored as a static in IApplication. So someone inherited from IApplication and made an instance of itself, causing the IApplication constructor itself to store that as a singleton and returning it through getInstance()
In you code it looks like IApplication::getInstance() is a static method. The confusion probably comes from the fact that C++ does not have actual interfaces, only abstract classes. We just say that an abstract class with only pure virtual methods fulfills the role of an interface because there is no interface language feature. Likely the getInstance() function uses a local static variable and returns a reference to that to implement a singleton: class MySingleton { MySingleton&amp; getInstance() { static MySingleton i; return i; } } Here it’s just that MySingleton is an abstract class and the static constructed object is a concrete implementation “MyApplication”. 
You can almost smell the end goal: cmake_minimum_required(VERSION 3.10) project(cmaketest) # TODO: Put this in a library somewhere: add_library(MyWarnings_High INTERFACE) add_library(MyWarnings::High ALIAS MyWarnings_High) target_compile_options(MyWarnings_High INTERFACE $&lt;$&lt;OR:$&lt;CXX_COMPILER_ID:Clang&gt;,$&lt;CXX_COMPILER_ID:GNU&gt;&gt;:-Wall;-Wextra&gt; $&lt;$&lt;CXX_COMPILER_ID:MSVC&gt;:/W4&gt; ) add_library(MyWarnings_Low INTERFACE) add_library(MyWarnings::Low ALIAS MyWarnings_Low) target_compile_options(MyWarnings_Low INTERFACE $&lt;$&lt;OR:$&lt;CXX_COMPILER_ID:Clang&gt;,$&lt;CXX_COMPILER_ID:GNU&gt;&gt;:-w&gt; $&lt;$&lt;CXX_COMPILER_ID:MSVC&gt;:/W1&gt; ) add_library(MyWarnings_AsError INTERFACE) add_library(MyWarnings::AsError ALIAS MyWarnings_AsError) target_compile_options(MyWarnings_AsError INTERFACE $&lt;$&lt;OR:$&lt;CXX_COMPILER_ID:Clang&gt;,$&lt;CXX_COMPILER_ID:GNU&gt;&gt;:-Werror&gt; $&lt;$&lt;CXX_COMPILER_ID:MSVC&gt;:/WX&gt; ) add_executable(app1 main.cpp) target_link_libraries(app1 PRIVATE MyWarnings::High) add_executable(app2 main.cpp) target_link_libraries(app2 PRIVATE MyWarnings::Low) add_executable(app3 main.cpp) target_link_libraries(app3 PRIVATE MyWarnings::High MyWarnings::AsError ) 
The video is streamed now as he is speaking here at Avast in Prague.
It is interesting, but I think that the project could use a better name since lex is already a commonly used lexical analysis utility name.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
I find it very interesting. However, I wish there was an example showing off the best practices etc that utilize the tool. For examples, people may want to use enums instead of hard coded constants. People may have a spreadsheet (csv) that maintain the resource id (enum) and the corresponding file when there are a lot of resources. What would be the easier / painless way of integrating csv list with the tool?
I've considered doing something like that but warnings are too opinionated to make it really useful.
I need to finish my `__builtin_external` extension for GCC and Clang. `constexpr` builtin that calls an external program and injects code.
&gt; In the same way that we have to protect our code from comma operator overloads (something that should also be deprecated and removed), we now have to protect ourselves from one of the most common operations when working with a systems programming language: Getting an object’s address. While it might have made sense at one time to permit users to define their own memory model, this approach is no longer viable. the condescending tone here is incredible. Yes it still makes sense to permit users to define custom memory models, this is the kind of flexibility C++ is about.
So like every function call that can throw must be wrapped in `try()`? Is it not excessively verbose?
I expected the spanish inquisition.
I don't think the problem is whether or not the error object is standardized or not, but with how that object is accessed. Certainly standardizing it would make access easier, but surely there's another mechanism!?! Telling C programmers that every time they call a function that might have an error, they have to write code that looks like this: struct { union { double value; struct error_type error; }; _Bool failed; } result = _Catch(some_function(argument)); I mean ... come on. Really? And, yes, as your proposal shows, it's possible to write a `caught` macro make it more manageable. Of course, since `caught` isn't standardized it'll be called any number of things in different code. I would expect libraries to provide one for its users where the error type is baked-in ... and called by yet a different name. That's why I'm asking that this, at a minimum, be standardized into `&lt;stdfails.h&gt;`. If you have to use a macro to make your proposal usable in practice, that macro should really needs to be part of the proposal as well. I think it's bad form to point out problems without making at attempt at a solution ... so here's my try. Something that hasn't been talked about yet (that I've seen) is that the error information needs to be part of the function's type. What if we provide a compiler mechanism to create the appropriate error type from a function pointer? I'm going to use `_Catch` to do this (sorry for re-purposing your keyword). Basically, `_Catch(some_function)` would be boilerplate to create the appropriate error type similar to `caught`. The code would then look like: _Catch(some_function) result = some_function(argument); I didn't put the `_Catch` when calling the function -- instead, I would suggest that these functions automatically get the `[[nodiscard]]` attribute, which would have the same effect for ensuring the programmer doesn't ignore the result. `_Try` would satisfy the attribute's requirements as well. I've only been thinking about this for one day, though, so I'm sure there's multiple problems with this, especially when it comes to C++ compatibility. Feel free to poke holes in it ... but also please think about ways to make this mechanism more usable for C programmers.
WG14 were adamant that the call site for these dual channel functions must be annotated explicitly. That was a hard red line for them, and indeed it just received special mention during the committee discussion as to why this makes accepting "exceptions" into C tenable at all. Regarding the designated initialiser approach, again I must remind you that was where consensus arrived at on WG14. Nobody likes it, but far more importantly, everybody can live with it. And we in C++ can do something with that to implicitly construct `expected`, so we're covered too.
I'm not sure if it's moving *all* that fast. Everything is predicated on there being a satisfactory prototype compiler. That'll take at least six months to make happen, then several years of empirical experience will be needed, only then could standardisation become possible.
Or `catch()`. For C that was a hard red line for them. It is non-negotiable. For C++, if a function calls a `fails` function, any failure returned by C looks like an exception throw. C functions marked `fails_errno` in particular look like they throw exceptions, so no more losing failures from C accidentally!
I interpreted that passage as "While *overloading `operator&amp;`* may have made sense at one point ...", *i.e.* not saying that custom memory models don't make sense but that operator overloading is not a viable way to implement them.
I just want to write everything in c++.
I guess the tool could be extended to support this use case. I know it's pretty basic right now but I can imagine the header file being also generated from any other input format. My idea was that you write your resource list in code and then you can also use that code as an interface to access the files. I could introduce a lot of improvements based on all the feedback I've got here. E.g. resource lookup by string key, including whole directories at once, etc. I'll have to figure out what to do with the template parameters though. The implementation somewhat depends on them.
Good news, you can. 
If you're writing a desktop app, use Qt Widgets at least for menus, toolbars, and dialogs. Otherwise it doesn't integrate as well.
There is a lot to like about QML, but I think it is a bit early to say that it should always be used instead of widgets. With widgets you get: * Much better item views (tree/table/etc.) * Platform native theming for desktop platforms. * Additional controls that don't exist in QML * Better keyboard input support (by default.) As for the clean separation of logic, it is worth looking at QDataWidgetMapper, which allows widgets to be mapped from models similar to how data is mapped in QML.
QML does not completely separate logic from UI. It separates UI and UI logic from business logic. UI logic (how UI elements interact with each other) has to live with UI in QML files (moreover, it's written in JavaScript).
Qt Quick Controls 2 has gotten a lot better in the last few Qt releases. Also KDE devs created QQC2 style that uses QStyle for rendering. Though they are still aren't as feature complete as Qt Widgets (and will never be. Qt Quick is for "modern", simple interfaces).
&gt;* Better keyboard input support (by default.) Yep, what I like about classic GUI toolkits is they have working keyboard navigation out of the box. With "modern" toolkits (be it UWP, Qt Quick or Android) you have to do a lot of things by yourself, possibly with dirty hacks. Their developers focus primarily on how to implement flexible and easy to use animations and various graphical effects, but completely ignore how UI elements would be accessible from keyboard.
Is there any example of source code for a modern desktop application that behaves like QWidgets (e.g. fits in to Windows/macOS/the Qt theme) but uses Qt Quick underneath?
It still should have been worded differently. Throughout the paper, most of the time, I was wondering if they are deprecating *operator&amp;* or *overloading of operator&amp;*.
I agree. I never did it for the same reason. However, in a blog like that, where you're recommending use of `target_compile_options`to set compile options, it makes some sense to show how to avoid duplication. 
I'm not a big fan of QML, I wish there was a proper widget set written in C++ based on Qt Quick scene graph. That said, I'd not recommend starting a new desktop application using Qt Widgets if the app targets OS X and performance is a concern. Qt Widgets renders whole window in the backing store, which is in main memory. The changed parts are then copied to GPU memory for compositioning. The sad part is that on OS X there's no way to transfer large amount of pixels fast enough to update HiDPI fullscreen window 60 times a second. So no matter you do, on 4K or 5K display you don't get document scrolled smoothly enough. So in the end, you get worse GUI performance with Qt Widgets than electron. This is not a problem with QtQuick, as the scene graph is fully accelerated, but it still feels like desktop is a second class citizen. Last time I checked even basic things like context menus were missing in all Qt Quick examples.
&gt; WG14 were adamant that the call site for these dual channel functions must be annotated explicitly. That was a hard red line for them, and indeed it just received special mention during the committee discussion as to why this makes accepting "exceptions" into C tenable at all. Eh, fine. `_Caught(some_function) result = _Catch(some_function(argument));` is still a significant improvement in usability (though I think it sill annotates the call site just fine). (Also, `_Catch` should be `[[nodiscard]]` IMO.) &gt; Regarding the designated initialiser approach, again I must remind you that was where consensus arrived at on WG14. Nobody likes it, but far more importantly, everybody can live with it. Nah, that part is totally fine with me. The trouble comes here: &gt; It is up to the programmer to define some type suitably matching this designated aggregate initialiser. This requirement alone becomes a significant barrier to adoption, and there needs to be *something* to help programmers. Some way to create a default type that satisfies the initialization requirements, without preventing an library writer from creating their own type if they need. Can you imagine trying to teach a programmer how they're supposed to do error handing in C? Absolutely everything is just fine and easy to understand, right up until they want to actually do something about the error. And then the solution is literally going to be hand-typing a macro from their book or notes, or googling until they find the magic line they need to copy/paste. That's, quite simply, absurd. &gt; Simple things should be simple, complex things should be possible. You've solved the part about making the complex things possible, but the simple case has been left behind. ------ Another question came to mind while reading this -- what happens when the function has a return type of `void`? That a case that's not explored in the description of the initialization, and it wouldn't play well with the `union`.
thank you :)
&gt; It separates UI and UI logic from business logic. UI logic (how UI elements interact with each other) has to live with UI in QML files (moreover, it has to be written in JavaScript). Not really. As mentioned in the article, you can integrate C++ and QML fairly easily. The article only really touches on using this as a mechanism to expose the results of business logic to the UI, but you can just as easily write UI utility functionality in C++ and expose it to the QML context so that the latter can read variables and call methods that are backed by C++. Additionally, you can do some pretty cool things by extending classes like `QAbstractItemModel` and then offering them to QML so that you can have list views rendered with QML but with all the backing logic of sorting and selection implemented in C++. 
I'd add to this: * Easy customization on of UI on a per-platform basis with `QFileSelector` * Support for creating and interacting with user interfaces entirely offscreen with `QQuickRenderControl` I use the latter for developing UI for VR environments. `QQuickRenderControl` lets me translate the actions of the user in a 3D environment interacting with a "virtual tablet" via hand controllers into touch and or mouse events which I can feed into the offscreen UI. I can then render the UI directly to an OpenGL texture and composite it into my scene. It is _super fucking cool_ that you can do this. I know there are other tools that let you do similar things, like imgui, librocket and CEGUI... but those were all designed first as UI tools that were renderable to a GPU, not as general purpose UI's intended for a broad set of platforms. QML is designed as a first class UI, and it just happens to have as a feature the ability to do offscreen rendering. That means it will always have the advantage in terms of features and functionality, because its target audience wouldn't settle for anything less.
There's [qmlbook](http://qmlbook.github.io/) but that's more of a guide than a good example of best practices. My own company is open source and uses QML extensively, but unfortunately it's been worked on by tons of different developers at tons of different levels of skill and experience with QML, so it's more of a dumpster fire than a best practices guide. A lot of that's my fault as I'm the one that did a lot of the initial development of our QML usage, and I did it before I myself had my head fully wrapped around when it was best to use C++ and when to use pure QML. 
This is such a great Talk imo. I'm not sure if i understood the essence of Act2 correct. If we take out all the Functions from a Class and give it a reference to a Data Structure. Wouldn't we go back in Time to C with classes or starting of Object Oriented Programming? Since the compiler already adds the implicit "this" pointer. And the behaviour of the Functions rely heavily on the Object? Whats the Point then? Same with 2.1. Feels a bit like going back. I'd prefer taking a Point and a Radius for my Circle to construct and not double,double,double. Which could be another Constructor but even with Strong Types this feels weird (Coordinate(X), Coordinate(Y), Radius). For me it feels like the essence should be more in the direction of "We really should think about what belongs to the class". I think he referenced this later when he was answering question, but i couldn't understand it.
Some others - 1) Modern C++ Programming Cookbook by Marius Bancila 2) C++ High Performance by Viktor Sehr &amp;#x200B; 3) C++ Templates, 2nd edition by Josuttis, Vandervoode(forgot the name of the 3rd author) 4) Mastering the C++17 STL by Arthur O'Dwyer Upcoming &amp;#x200B; 1) 2nd Edition of C++ Concurrency in Action , releasing December(??) 2) A new volume for Large Scale C++ by John Lakos, no idea on the release date.
Yeah, your confusion is understandable. Before C++ had return type deduction, they added a feature in C++11 to allow trailing return types, and that's what you're seeing here. You still had to specify something, but it could be later so that writing generic functions is easier. Then they added return type deduction in C++14, so the trailing type isn't necessary if it can be deduced (though being explicit is a good idea). Some people prefer using trailing return types everywhere, just for consistency. And that's what other languages do. (Personally ... yuck. Please don't.)
spaces are overrated anyway /s
&gt;Are there any good comparisons of LLVM vs GCC? What would you consider to be a 'good comparison'? &gt;Currently, my company is on GCC and I would like to consider moving to LLVM. Why would you like to consider moving to LLVM?
`#include "https://raw.githubusercontent.com/..."`, wow, that works...
I use the terse style in computer generated code: [https://github.com/Ebenezer-group/onwards/blob/master/src/cmw/tiers/zz.middleBack.hh](https://github.com/Ebenezer-group/onwards/blob/master/src/cmw/tiers/zz.middleBack.hh) That helps in terms of being able to create the code efficiently.
You cannot do "fast iterations" in javascript because there is no API exposted to do even basic things like file editing which forces you to write your logic in C++ (which is good!). I've beed working on a large Qt/QML desktop app for quite some time now and never wrote more than some ifs or switch case statements in js for my UI. &amp;#x200B;
Hi guys, Thanks for all the feedback and discussions so far. I've updated the post to reflect some of the thoughts and experience that you've shared here. Cheers, much appreciated!
Bjarne revised his book, Tour of C++ 2nd edition
&gt; can be even faster and less bloat-y than the zero-overhead-est exceptions implementation, at least on some exceedingly common hardware architectures I am no expert (neither in this proposal nor in the nitty-gritty of exception handling implementations) but my understanding was that this style is actually slower than traditional exceptions in the success case. I thought the main benefit is that it gives a much more _predictable_ runtime.
I've been reading [C++17 - The Complete Guide](https://leanpub.com/cpp17) by Nicolai Josuttis. It's currently 85% complete, but already worth it in my opinion.
&gt; expect a prototype compiler sometime in 2019. That matches what I've been hoping for. &gt;Note how well it optimises, already, with today's compilers. Do you have an idea of how much it reduces code sizes? 
I need the principles book get revised. It is very direct and presented in a very clear manner.
I wish there's a C++17 version for C++ Primer out sometime.
On Mac, you can also use QtMacExtras to embed native Cocoa components in a QWidget application. (and vice-versa, qwidget into cocoa) IIRC there's no way to do that right now with QML. There is a way to do this on Windows too (non-UWP components, at least) but it is not as well supported: https://github.com/qtproject/qt-solutions/tree/master/qtwinmigrate
That's an awesome use case, thanks!
It's not as nice as having a native type system, but I've seen issues in their Jira that show they are investigating TypeScript support in QML. No guarantee yet, but they are looking into it at least.
You should never have `-Werror` enabled by default. It is fine to use in your own builds but never on code that you want other people to use. They will use compilers that you don't have and those compilers will produce warnings you have not fixed. When this happens people need to dive into your build setup to find and remove all uses of `-Werror`. &amp;#x200B; Compilers get new warnings all the time, so even code that is perfect and warning free today will produce warnings in the future.
Libraries using Modern CMake should provide a CMake package configuration in the upstream project. Find Modules that are intended to be provided by downstream projects are obsolete then. Read more about it here: https://cmake.org/cmake/help/latest/manual/cmake-packages.7.html Do not manually create Find Modules for projects using CMake. Instead try to submit a package configuration to the upstream project and use the CONFIG more of the find_package command.
I have been reading P0709 (Zero-overhead deterministic exceptions: Throwing values) and I still have no clue how one would use this to throw an exception that includes useful information like an error text or (for more advanced cases) other custom information (e.g. a localization key with format parameters, allowing the catch code to build a message for a given language). It seems completely blind to requirements of applications to propagate useful non-trivial information through exceptions. Only at the end does it glance at the idea to allow specifying a type of object that a function throws (instead of error), but does not consider it essential in any way. Am I missing something?
Or provide a clear way to opt-out of -Werror (with a CMake option for instance).
&gt;C++ High Performance by Viktor Sehr I'm liking the east const flavor to the title. Amazon says the book helps one "Use SIMD and STL containers for performance improvement". Other than vector, I'm skittish about STL containers. 
I think ea origin is qt quick based. 
You can (and probably should) use the \`state\` property of QML elements to express those kind of states. It also allows you to use transitions and animations. You can also bind those states to QObject/C++ models and so, make your UI react in relatively complex way without writing a single line of javascript. The point is, of you don't want to write JS, QML gives you a lot of way to not do it, and write logics and states to c++ or to QML element (State, Animation) instead.
If this continues in a clean build directory can you open an issue at [https://gitlab.kitware.com/cmake/cmake](https://gitlab.kitware.com/cmake/cmake) ( or send me a way to reproduce the problem).
Hell yeah, keyboard-as-a-service even sends across native keycode events as JSON. /s
C has a regular cadence, just like C++. Last two standards were C11 and C17 with various TCs in between. Next one is C2x, expected maybe around 2022 currently, but might slip.
WG21 recently asked me to provide a POC that arbitrary error information can be transmitted via a two CPU register `std::error`: https://github.com/ned14/status-code/blob/master/example/file_io_error.cpp#L160 In case you don't like the dynamic memory allocation, bear in mind that under N2289 with P0128, you can define any error type you like with any payload you like, so long as it can reduce itself into `std::error` on demand. So you'd not dynamically allocate memory in your custom error type, and only upon reduction do so. This lets you avoid all dynamic memory allocation in hot path code.
It's only one fairly common configuration of Linux which overallocates. I, for the record, tell my Linux to never overallocate. Makes it more like Windows and FreeBSD.
&gt; and no, statically linked binaries are not permitted, else security fixes to libstdc++ require us to issue a new release, and we only do that once every two years Do you really see libstdc++/libc++ requiring more frequent security fixes than your own code?
It's *definitely* slower on an in-order CPU. It *might* be slower on an out-of-order CPU. Principle gain is that failure path is no slower than success path. Remember type based exception throws aren't going anywhere. So people will use value based exception throws where they need balanced success vs failure complexities, and type based exception throws where success occurs 99.99% of the time.
Yes your missing that you can still do what you've always done by throwing dynamic exceptions. You can have a program that can do both static and dynamic exceptions. 
&gt; clang certainly had better static analysis than GCC, but GCC has largely caught up GCC has greatly improved but when it comes to static analysis it isn't even close unless you don't count clang --analyze or clang-tidy as part of Clang. That's OK though - GCC doesn't need to be a static analyzer as there are plenty of them (like Clang's) that can be used in addition to GCC.
First sing first, QML is NOT javascript. It comes with/use it for some, probably questionable, reasons, but you definitely can write near zero lines of javascript in your QML UI. You would use a lot of simple expression yes, but it could be any C like language that would not know it. &amp;#x200B; Second, there is a QML compiler. I haven't use it recently but it is almost mandatory to compile your QML code for performance and security reasons (mobile/embedded). It is a believe the way forward. &amp;#x200B; My experience with QML (not recent, probably Qt5.8), having write both huge QWidgets applications and large QML ones, is that UI debugging/iteration with QML is really faster and more friendly. Customization is easier and more powerful and it is, as a framework way easier to use and less find the 'delete after use widget/model' you forget somewhere randomly crashing your software.
This is hardly a fact. There are lots of use cases where you need to provide your own find modules or even cmake build files for upstream project. For example take a look at vcpkg. 
You mean C99, C11 and C18? That's slightly longer than C++'s current 3 year cadence, though there is a trend for speeding it up.
Can someone provide a "too long; migraine; don't like videos about programming" summation?
That is horrifying.
If there's only one guinea pig compiler, I hope it will be my primary compiler - gcc. For back-end services that don't need to be portable such a compiler would be *helpful* prior to all the standardization details being hashed out.
Regular point releases are made for security fixes. But we rely on the system provided libraries rather than issuing our own copies of them. This is what the customer wants, so that's what they get. Remember we only support exactly one RHEL, and a specific minor release of that too.
I don't know what is intended, but as a general rule, clang is much easier to modify than gcc, so I'd expect it to be clang. I wouldn't be surprised if MSVC gained a fork as well, they seem very keen on prototyping new language features in MSVC nowadays. I guess they have the resources to dedicate to that.
https://github.com/EbookFoundation/free-programming-books/blob/master/free-programming-books.md#c-1
&gt; The try/catch block is just as noisy or even noisier than using match on every rvalue but why would you do that ? the point of exceptions is that you don't have to catch them in every block, just in the block where you can handle them. Most of the time catching in the main or at the top of the event loop is enough - exceptions are always (at least in the codebases I know of) used for ... exceptional stuff, and this kind of stuff should just show an error message to the user and abort if it's a CLI or continue "normal" operation if possible if it's a GUI.
Depends really if you want you defaults to target users or developers. I tend to favor targeting users since there are more of them the less they need to deal with project-specific flags the better - `-Werror` should be opt-in if used at all (I personally don't find it useful).
&gt; if you can’t understand, please understand. This made me smile :)
It doesn't return std::expected, though. It uses a specialized calling convention and plumbs errors through without the program having to handle every call directly.
Yes, it was that one.
&gt; Remember C has no concept of `auto` types, so you're asking for a magical type in the compiler. Yeah, I might be flirting a bit too close to automatic type deduction. Though it's more like type generation, not deduction. The definition would be something like: `_Caught(ptr)` creates an implementation-defined type that can be initialized with `_Catch(ptr())`. &gt; Or if they do standardise `typeof()`, then it would be something like `ERROR_HANDLE(expr)` which is an extremely common idiom in C code. Could you elaborate on how you think this might work, how `ERROR_HANDLE` might be implemented? And what the thoughts are surrounding an Either type in C? You're right that we're early-on in this process still, and maybe some more language features are necessary to make this fully workable. &gt; Designated initialisers can initialise a struct just as well as a union. So for where the function returns `void`, no `.value` member is initialised. I'm more worried about this `ERROR(T)` macro. It's unlikely to be able to handle the case of `void` (see `caught` from the proposal), so a library has to provide `ERROR_VOID` as well.
Why not just use a compiler flag to mark the snippet of code that causes undefined behavior as an error? Or does such a flag not exist?
Then you must live in utopia. People misuse exceptions everywhere, including for control flow. I've seen hundreds of exceptions during normal program operation.
Awesome. Maybe in a couple years we can get `cos` that is actually pure and just uses `NaN` as intended.
Considering herb is the one doing most of the promoting, I wouldn't be surprised if MSVC implements it soon-ish. Gcc is much harder to modify indeed, and most people who still depend on gcc don't use the latest gcc because they get it from their packages.
A clang implementation might be helpful to me, but msvc wouldn't be of much use to me.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9p5hto/requesting_help_with_computational_methods/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Name collision with [this mio](https://github.com/carllerche/mio)
Suggestion: add a current "advice" property (settable) and call `madvise()` with this every time you call `mmap()` on Linux.
Just read Herb's paper on this subject?
Maybe it is just a question of where along the C &lt;---&gt; OOP spectrum we want to be. The functions I pulled out of `ViewPoint` were not essential to it. (You'll notice I put serialization and logging on the left side - they are _almost_ essential. They are very tied to the class. But they also entangle the logging and/or serialization codebase.) Many of the function I pulled out may instead belong on some other class. Like should `display(ViewPoint)` be part of ViewPoint, or part of the DisplayUI (or something like that). For the 2.1 part, it depends _how much_ of the class you need. If your function needs x,y,radius maybe it should take a Circle. But if it only needs x,y then take a Point. The examples are too simplistic though. In real code you end up with bigger objects, and they get passed around. And then it is very common to see a function where the first thing it does is call a single `thing.getFoo()` at the start, and only deal with Foo. Why did you pass `thing` then instead of Foo? There is a reason. You think about code at a certain level. You have a Projector object and a Camera object and you need to make something work. So you pass a Projector object to a function, asking it to do its part. From that point of view, it feels right to pass Projector. Like imagine for some crazy reason you need to know if the projector is facing north. Call `isFacingNorth(projector)`. That function answers the question at hand. But all that function did was call getOrientation and then answer it from that. And that function probably hardcoded a tolerance of "north within 5 degress". So now this function does exactly what you need right now, but is completely tied to projectors and completely tied to the situation at hand. This is somewhat fine, it gets the job done. But the tolerance part should have probably been foreseen as something that is better to pass in. `isFacingNorth(projector, tolerance)`. But that can be done later - it is easy to imagine someone simply refactoring that when needed. But instead someone later adds an if statement that is "if it is this type of projector, allow 10 degrees of tolerance". And then a switch statement that is per projector type... But hey, the function is doing what we _want_, it is smart, and gives the answer we really need, for any projector. (At this point maybe you should find a better name for the function that encapsulates why it is different per projector. Maybe the real question it answers is whether North is _within_ its projection view? Should it be called canSeeNorth() ? ) And now you realize you need to also know if the Camera is facing north. Hmmm. Maybe Camera and Projector should both derive from Device (in fact they already do) and maybe isFacingNorth() should take a Device instead. But wait, not all devices actually have a direction (or at least not one that we care about. Which way is the Network Switch facing?). So either create a DirectionalDevice so you now have Device -&gt; DirectionalDevice -&gt; Projector/Camera. And isFacingNorth takes a DirectionalDevice. Or you don't do DirectionalDevice, and isFacingNorth handles all Devices, and the Device API returns a default for NetworkSwitch orientation. (Wait it returns {0,0,0,0} for Orientation, which actually causes a divide by zero, which we never notice because no one actually calls isFacingNorth on NetworkSwitches until somewhere at the top of the program we decided to put all devices into a Device Tree in the UI...) Does any of this feel familiar? Now we can't predict how our code will change in the future. Maybe isFacingNorth will never change. Or maybe it will get refactored well as needed. But we can predict that the code will get worse over time, that is what code does :-( So rewind. Notice _as you write_ isFacingNorth() that it only needs Orientation. So pass that in. And tolerance (because its obvious). `isFacingNorth(proj.orientation, tolerance);` I suspect that this version will be less likely to devolve into chaos. The next programmer in is more likely to put the per-projector code closer to where it belongs. Maybe Projector gets a canSeeNorth() function, but at least the projector specific stuff is in Projector. And/or, back at the code where you started, you can still have an isFacingNorth(proj), but maybe it is now a lambda (calling the more general version) in the function where it does exactly what you want. So that code is still "thinking" at the projector level. Does that help? Examples are hard. 
Do you have any reference about C and C++ having different alignment rules? According to cppreference, C++ do have alignment constraints on objects. In the end, althought C and C++ are different languages, it could be interesting to figure out if they are the same on this matter. Moreover, I think the author do point the fact that the memcpy solution needs builtins..
While not true over-commit, I'd (weakly) argue that Windows is still over-allocating when it starts swapping things to the page file. Once that starts happening, it's sometimes faster to get the PC back into a usable state by rebooting than it is to wait for the OS to get everything back into memory and no longer doing disk IO for random memory reads. :p
Hence one of the many reasons a lot of us just disable them, and why this set of proposals is so nice. :) It doesn't necessarily stop folks from abusing errors for flow-control, but it makes that use case less catastrophically stupid, since missing a try/catch won't cause termination or higher-layer error handling to kick in.
Thanks for sharing this!
can we please get informative post titles please? 
Good point, it depends on your use case. I tend to enable it by default at work since the users are fellow developers, and that way new warnings (after clang/GCC updates) are quickly reported. Sure, most of them are not critical and I always filter some irrelevant ones, but it still allowed to catch stupid bugs in old code bases introduced by people who never cared to read any warning. For open source projects where you don't know who or how many people will end up using your code, the opt-in way makes sense indeed.
why? 
In our application, most of the time we want to catch them in higher level code. Because aside from logging and showing an error message to the user, we fallback to a branch which "will run without error" or try to continue. For example: we are parsing a PPTX file and an exception is thrown, we show an error and try to continue parsing. Maybe there will be a missing page or an object, but at least something is shown to the user. Well, at least that's our policy. Also, catching everything in the main loop will make tracking down the piece of code that thrown it nearly impossible. Java and C# at least provides the call stack in the exception, but C++ doesn't. And yes, you are right that exceptions should be thrown when exceptional stuff happens, but some third party library are very eager about throwing exception every time they can. Even for a warning! We personally avoid using exceptions in our codebase and only use exception handling for such libraries.
Such a flag does not exist. Toolchain vendors tend to address specific problems instead, so they come up with things like -fwrapv and the various sanitizers. To see why we don't have such a flag, ask yourself how that flag would actually work: You can't just tell the compiler to "just detect UB", because that's just not how it works. You have to bind the check against a specific combination of input function parameters at least, since otherwise you run into what's probably a variant of the halting problem. You'll most certainly need to restrict yourself to a subset of C++ because otherwise good luck on having anybody actually implement the thing in finite time. And then you outright need to implement an interpreter for that subset of C++, because that's the only way to reliably and comprehensibly detect all UB there could be. So in a nutshell, this thought experiment leads to reinventing what `constexpr` already looks like, just that constexpr has a lot more applications beyond UB checking.
Dies this include windows.h?
That's not Windows overcommitting. If you ask for more storage than the commit limit (physical memory size + page file size), you will get allocation failures. You're describing virtual memory, not overcommit.
C++11 had return type deduction. Trailing return type was added at the same time.
**C++ Reactive programming** : [https://www.amazon.com/Reactive-Programming-concurrent-asynchronous-applications/dp/1788629779/ref=sr\_1\_2\_sspa?ie=UTF8&amp;qid=1539844680&amp;sr=8-2-spons&amp;keywords=c%2B%2B+reactive+programming&amp;psc=1](https://www.amazon.com/Reactive-Programming-concurrent-asynchronous-applications/dp/1788629779/ref=sr_1_2_sspa?ie=UTF8&amp;qid=1539844680&amp;sr=8-2-spons&amp;keywords=c%2B%2B+reactive+programming&amp;psc=1)
You're gonna wanna set AverageGrade inside of main to equal the function call. `double AverageGrade = GetGrades();` Other than that everything looks good!
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9p6ne5/c_projects_for_job_seekers/e7zhvi3/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
it's the same language ofc
I have a question, not in particular about this lib, but in general about usage of memory mapped files cross-platform because of Windows. From the [docs](https://docs.microsoft.com/en-us/windows/desktop/Memory/reading-and-writing-from-a-file-view): &gt;To guard against exceptions due to input and output (I/O) errors, all attempts to access memory mapped files should be wrapped in structured exception handlers. When you receive EXCEPTION\_IN\_PAGE\_ERROR in your \_\_except filter, make sure that the address is within the mapping you are currently accessing. If so, recover or fail gracefully; otherwise, do not handle the exception. Now in C++ one could pass [some flags](https://docs.microsoft.com/en-us/cpp/cpp/mixing-c-structured-and-cpp-exceptions?view=vs-2017) to the compiler to be able to catch these structured exceptions, but I am not sure if this is healthy. Does someone have experience with this? 
Good speaker with good ideas on various topics. I liked it :)
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9p6orj/trying_to_return_variable_from_function_but/e7zifhs/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
At the moment, it's asking you to put all the grades in twice. Remove the first `GetGrades();` call (i.e. delete line 25) and try again?
Aside from the obvious encapsulation argument, if all symbols are visible, then you kill the potential for virtually any whole program optimizations, and prevent the linker from removing data and functions associated with unused symbols. Globals not explicitly marked const can't be constant-propagated. Globally, but not locally, dead code can't be removed from functions. Calling conventions can't be optimized, e.g. function parameters which are always the same constant value can't be removed. Functions inlined everywhere can't be removed from the final binary. Etc.
wow that was it! thank you so much!!!
This is not the right forum to ask questions how to use C++ - it is about the language itself. Also never post code as screen-capture. That being said, you never assign the value returned from GetGrades to the AverageGrade variable. In other words, remove the very first line that you call GetGrades and uncomment the line where you call GetGrades and do assign the return.
I don't know, I'd prefer to be able to do error handling the way rust does it, which apparently could be possible with coroutines, see the discussion on the google comments on coroutines earlier here. So basically propagating `optional` or `expected` easily by being able to do `auto var = try some_function_that_returns_optional(...);` which returns on failure or assigns the value on success. I realize that we can have both, I just wonder why one would prefer exceptions if we have return values on steroids?
&gt; People misuse exceptions everywhere, including for control flow. I have frankly never seen exceptions being used for control flow in C++. To which library / code are you referring ?
&gt; Also, catching everything in the main loop will make tracking down the piece of code that thrown it nearly impossible. Java and C# at least provides the call stack in the exception, but C++ doesn't. This is a problem in theory, in practice you can just `catch throw` in gdb and lldb (or do the equivalent magic with msvc's debugger, certainly in a UI somewhere)
I am so excited that it looks like we will get modules. From [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1103r1.pdf](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1103r1.pdf) \&gt; At the Bellevue 2018 ad-hoc Modules meeting, we answered all remaining known open design questions. This paper provides a description for the resulting design, as well as wording (based on the wording in P1103R0, which in turn is based on the wording of the Modules TS) to incorporate this design into the C++20 working draft. &amp;#x200B;
More precisely, C++ is a strict superset of C.
When is your proposition expected to ship? C++23 and C20? (I'm not sure about the release schedule of C).
(I wasn't being serious) (also is that really true? I think there are some valid c programs that wrong compile in cop... eg recursive main I think?)
We can't return NaN as there are implementations which don't have those. And it would be a huge breaking change. Best you can hope for is we stop setting errno.
Need a successful prototype compiler first.
I think you'll find value based exceptions just as rich as type based exceptions. More awkward to use to get richness in the current language (we need matchers!), but doable with investment of work. LLFIO is using this proposed `std::error` for some time now with a *very* rich payload. It's fully deterministic, excellent performance, works very well.
You may have noticed the proposals author wrote Boost.Outcome! So yes return values on steroids is covered!
This article talks about the problem but does not provide a suggestion on how to improve the feature to avoid it. I have not followed modules enough to understand what an alternative solution would do differently. Do you have any idea how the current proposal could be modified to address it?
No idea, I have to admit that I have stopped following what happened to modules a long time ago. I just stumbled upon "We feel that this is fundamentally the wrong solution" in the conclusion, which is a rather strong statement, and wondered what would be the end of the story for modules :p
I think that was true of Windows once. But those pathological performance corner cases have got a lot better in recent years. My biggest beef with them is their abysmal *average* filesystem performance. 80x slower to open a file for example than Linux, FreeBSD or OS X, and that's in the warm cache situation. That *heavily* impacts compile times on Windows no matter what a compiler team does. Closing files is very data loss safe on Windows, but it's slow, try closing a million open files for write in a directory and watch the poor kernel humble itself. Compare that to Linux or FreeBSD or OS X, and well ... I don't think anyone can claim FreeBSD doesn't treat power loss safety as strictly as Windows, but it just runs rings around Windows on this. My other big issue is with the scheduler. It's tuned for maximum SQL Server performance, and it penalises badly low QD single threaded i/o. They know about it, but maximum SQL Server performance is an internal business case. Rotten i/o latency distribution curves are not an internal business case :( Yet anybody who has ever deleted a lot of files sees 20% longer times just so SQL Server can max out synthetic benchmarks. That's a bad choice.
A fight I have coming with WG21 is that deterministic exceptions *are* flow control in every way. They are an `if` statement. WG21 needs to wake up and realise this. A long and tiring debate looms ...
I think even here you meant "maximum latency". So deterministic exceptions swap slightly worse average latency for dramatically improved worst case latencies.
Though, implicit conversion to any `ValueOrError` concept matching type e.g. `std::expected&lt;&gt;`, would "just work".
Yea my bad. I realized that after I posted. I have never been on this subreddit. I just googled c++ Reddit help and it brought me to this subreddit. Also again, im very unfimilar with the way people format codes when posting. I tried to copy paste the code and it didn’t come out clean in reddit text form. But yea I removed the first GetGrade call and it fixed the issue as someone else suggested. Appreciate your help!
For code pasting use the special formatting option - it is under the "..." button, then "Code Block". All forums have some sort of option for this, either called "code"(something) or "preformatted"(something). If there are no buttons, the there will be a link/button form "formatting help" to see formatting using textual hints
If you come around trying it out and have any questions just PM me or open an issue on github. Ruslo is normally very fast at responding to tickets
The one notable difference is that SFINAE mechanism can trigger with trailing return types when writing generic code, so using trailing return type instead of simple `auto` may affect compilation speed and can actually change which function is called from overload set in complex cases.
&gt; When this happens people need to dive into your build setup to find and remove all uses of -Werror. ​I disagree: I found out the hard way that compilers emiting new warnings means that the compiler is able to infer some kind of new information about the code, and **will** use this new information to perform additional optimizations. Hence the code may "compile" without -Werror, but then suddenly segfaults at runtime because for instance some code was optimized-out and removed by the compiler. The only proper (and safe) response is to not build code that your compiler tells you has a problem, do a bug report, and ask for binaries which are certified as working by the developer. 
It was invented because of namespaces. If the return type is defined in the namespace of the function, you don't have to repeat the namespace. For double it doesn't matter.
\&gt; I would prefer the vcblog is focused on Visual C++ stuff. .. like, the IDE? Managed pointers and other extensions? But how much has that changed? 
http://wg21.link/P1031 *Low level file i/o* is the WG21 standards paper you seek.
LLFIO traps segfaults during writes to `map_handle` via its `write()` function only. Otherwise users are expected to use the yet-to-be-proposed standard C++ mechanism for trapping signals which I currently have in testing, and just need to get around to writing up into a formal proposal paper.
[removed]
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9or8s1/llvm_vs_gcc/e7zn1gj/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Maybe he's new to this particular job and is an eager beaver. 
(I wasn't either. Poe's law :)
I had rather similar concerns when I first browsed about the modules TS quite some time ago. Haven't followed the modules story too closely, but it's a bit concerning that not too much seems to have changed on that front. And, yes, I've seen quite a few fortran projects rely on ad-hoc perl/bash code with a pile of regexps with manual fixups to resolve dependencies (and there doesn't seem to be anything much better). There's perhaps more incentive to produce good C++ tooling, but that also means moving away from some of the simpler tools (not exactly painless either). The parallel build issue is something I've also seen. Either it's difficult to saturate even a normal desktop at all or there is a lengthy almost-serial head/tail on the build. Did any of the proposals ever revisit the naming? Resolving conflicts from different codes that had identically named modules was not exactly a lot of fun. 
The 6th edition is [coming in January 2019](https://www.amazon.co.uk/dp/0135161797), by the looks of things.
[`madvise`](http://man7.org/linux/man-pages/man2/madvise.2.html) allows you to give performance hints to the operating system, which may allow you to 
It's fine. It uses the to-yet-be-proposed `std::signal_guard`. POSIX: https://github.com/ned14/llfio/blob/5f576c797bfbadfbcc9092ce7e1b98089156eebc/include/llfio/v2.0/detail/impl/posix/map_handle.ipp#L595 Windows: https://github.com/ned14/llfio/blob/5f576c797bfbadfbcc9092ce7e1b98089156eebc/include/llfio/v2.0/detail/impl/windows/map_handle.ipp#L909
which sanitizers are not supported by GCC?
`madvise()` is overrated. Setting random vs sequential has no measurable effect on any recent POSIX. Setting don't need or will need is completely ignored unless there is memory pressure, which isn't often on modern desktop PCs. Some proprietary extensions permit hole punching or unsetting the dirty bit, but you're getting into fairly niche use cases.
Call them like this: `(std::min)(x,y)`.
Totally agree. Great book. Section 1 - basic advice with pragmatic illustrations why your code looks simpler, clearer, more robust. Section 3 - new standard lib features (although particularly Filesystem chapter tends to get a bit more 'reference' and lose some of the brevity and punch I'd been hoping for.) I have an aversion to writing the sorts of libs/functions that require template metaprogramming. I don't mind using them but kind of don't care about the implementation detail that section 2 and 4 address.
I know the workaround and it's awful. Apart from the other caveats this comes with. e.g. what if you need the not LEAN_AND_MEAN parts in your code? It's just bad practice to leak your implementation details and pollute the global namespace like that.
Tell me what you think
Well, it was deprecated in the latest release, they just didn't update documentation yet. Also, I [found](https://lists.qt-project.org/pipermail/development/2018-February/032073.html) announcement of deprecation in Qt mailing list. So, current guidelines now look like this: * If you want to develop classic, native interfaces use Qt Widgets. * If you develop for mobile/embedded, or want to create "modern", highly animated interfaces, use Qt Quick and Qt Quick Controls 2.
Thanks for the effort. It makes the big picture clear. It's good for everyone, not only WG21 members, but also we the C++ community. But at the same time, it reveals quite some horror. Like: - So many proposal trying to fix spaceship operator. Should I rejoice to see so many people help polishing this important feature? Or should I worry this seemingly simple feature isn't good enough? - P0267 is still alive? - "Void Main"? "Unless"? Why waste committee time on those? - Please leave `$`, `?`, and `!` alone, P1274. Please don't complicate the lexical analysis. 
There are still mainframes on sale today with no implementation of IEEE754. Unisys ones if I remember rightly. Also, I vaguely remember the Cell processor in Playstations has no NaN. ARM NEON has a non-conforming NaN. And some DSPs definitely don't implement NaN. Many of the above send reps to WG21 meetings, and they would surely be instructed to vote down any such proposal. Indeed http://wg21.link/P0907, which is a much smaller ask than for IEEE754, may yet get defeated ...
The class is inspired by C#'s Random class. I used it very often so decided to implement it's functionality in C++. Let me know what you think.
Can you please tell more? I'm interested but I fear rxcpp is somewhat dead. Review of the book in few words would be nice. :)
Great feedback! Would you mind filing an issue to that effect?
&gt; Apart from the other caveats this comes with. e.g. what if you need the not LEAN_AND_MEAN parts in your code? In the short term, one could include `windows.h` before including `mio`, but your point's taken that failing to restore the lean and mean macro to it's previous state is rude. I was unaware of the MIN/MAX macros (I'm a unix programmer), but that should probably also be restored to it's previous state before returning from the library headers. I'll file a pull request to that effect.
FYI: I've also been trying to keep track of books that cover C++17 here: [https://github.com/BartVandewoestyne/Cpp/blob/master/C%2B%2B17/books.txt](https://github.com/BartVandewoestyne/Cpp/blob/master/C%2B%2B17/books.txt)
Thanks for replying, I'm keeping my fingers crossed : )
Firstly I'm not exactly sure I understand what the gain of wrapping `mt19937` into a class is, but maybe you prefer the C# API. I wouldn't use `mt19937` in new code. Poor choice compared to the alternatives. Better choice is JSF, see http://www.pcg-random.org/posts/bob-jenkins-small-prng-passes-practrand.html. If you'd like a ready to go C++ class edition of that, grab one from https://github.com/ned14/quickcpplib/blob/0c2e5dd3102d865e4728c4af0c54456e3ef27f14/include/algorithm/small_prng.hpp#L43
Nice list. Can you consider changing the format to .md instead of .txt maybe, it would render the links right away ?
I've looked at cppreference now and I should use uint_fast64_t, not sure why I I used strict unsigned long long, probably because i only checked the reference from visual studio. 
I'd use it often so it's easier that way. I'll check other alternatives. mt19937 was the first one i came into. Valid advice on the allocation, thanks.
And what mt19937 is poor choice for you?
I have an application which needs to read a single page of an 8 GiB file every few MiB, until the end of the file. Setting `MADV_RANDOM` makes this operation dramatically faster. Now I didn't notice any difference between `MADV_NORMAL` and `MADV_SEQUENTIAL`.
&gt; MSVC 17 Maybe you mean MSVC 19.15, which is the compiler currently on VS15.8 (aka VS2017.8)? FYI, I'm on the preview version and get the following: &gt;cl Microsoft (R) C/C++ Optimizing Compiler Version 19.16.26926 for x64 Copyright (C) Microsoft Corporation. All rights reserved. usage: cl [ option... ] filename... [ /link linkoption... ]
I don't see a problem with having the lib setting the flags as default, but with the option to not set any of those flags for users who want a full-fat windows API
What would you suggest?
Yeah, I don't agree with his advice. I think instead you should limit yourself to interactions that do not cause bus errors and a segfaults. For example, one common patter that I use is: memory map the whole file to a single mapping (using 64 bit support if necessary) and simply use pointer manipulation to change the parts you need.
I've always assumed such hinting flags just increased the likelihood that a prior memory page with mapped file contents would be dropped (or flagged as droppable) once you'd moved on to subsequent pages. Since these flags all date from an era when your system commit was more likely to actually be exceeding your physical memory, maybe in an era where much of RAM ends up effective being file cache anyway, it doesn't really matter. 
It's inferior to other choices. There was a thread on here about it a few months back.
Given the limited number of functions and structures you're actually using, it might not be unreasonable to simply declare them in an `#ifdef` block rather than including `Windows.h`. Alternatively, you could require that `Windows.h` have already been included prior to this header and emit an `#error` if you can't find a standard definition from that file.
RTTTL: Ring Tone Text Transfer Language
I've edited my answer above to say "for most data access patterns". It's possible that the default setting for clustered reads on your specific system, storage and configuration was a major slow down. But I wouldn't generalise that. For example, shingled HDDs would almost certainly load the entire track for any given 4Kb page, and keep that around in its ample 256Mb cache. Prefetching on those drives thus happens irrespective. Similarly, SSDs have no benefit at all to clustered data reads, so most recent kernels turn off prefetching entirely when talking to a SSD. But maybe your kernel is older, or doesn't realise it's talking to a SSD.
FreeBSD has a four level count attached to each page indicated how much priority there is to not kick it out of cache. `madvise(WILLNEED)` on that platform simply bumps the page count by one. On Linux `madvise(WILLNEED)` is much more powerful, it starts reading the pages in from storage immediately, but only under certain circumstances. On Windows, I'm not sure anybody outside of Microsoft knows for sure. Point is, `madvise` is overrated. It doesn't have consistent behaviour. I think you ought to tune your filing system algorithm for the defaults for more than one platform, that yields the most portable and consistent results.
There isn't really much of a point in using the `uint_fooN_t`s. Just use `uint_N_t`.
This paper is awesome. But the green line in figure 2 is clearly more of an article of faith than a reasonable data-based prediction given the small N.
I took some time to prep an STL-only version of tuple_vector that is available in a personal branch [here](https://github.com/CypherSignal/EASTL/blob/stl_tuple_vector/include/STL/tuple_vector.h). It should be possible to just grab that header, add "using namespace std_tuple_vector", and you're off to the races (ofc, if you're roping it into a redistributed repo, the EASTL license still applies, so check it). I've only tested it in the EASTL Test Suite, trying to minimize usages of EASTL stuff to make sure there isn't something slipping by, but this should work as-is. As well, I'll note that this is only tuple_vector: fixed_tuple_vector has more than a handful of other EASTL dependencies. Though, for whatever project you're on, if you're really left wanting for fixed_tuple_vector, I can't help but recommend incorporating EASTL, even in a limited capacity ;)
Mmmm ... you're not wrong, for sure. However, it is the correct extrapolation given currently available data until now. I've accumulated a fair few contacts within the Optane teams in Intel, and from everything I've heard, they want to ramp Optane up to price competitive with Flash as quickly as process will let them. I personally think they'll set the market price at slightly more expensive than Flash as the technology is better, and then reap as much profit as they can. For NV-DIMMS things are a bit more interesting. Intel have 64Tb RAM machines in the works so you can really load up on NV-DIMM Optane memory. I'm not sure where they'll pitch the price of those at. I suspect at whatever price Apple are happy to pay to put 100% Optane in for the RAM of a Mac Book Pro, but we'll see. 
Technically it's _paged_ virtual memory, since virtual memory by itself is just the difference between virtual and physical memory addresses. :p I very explicitly said that Windows doesn't over-commit. :)
Thank you very much for the explanation. It really helped me alot. And its amazing that you explained this to this detail :). For me personally i took the example of having a POD type(while doing refactoring) and trying to log it to the console. It was clear to me, that i don't add it inside since it should be still a POD. But I can't put it into std, so i started overloading &lt;&lt; on a stream with a function, which i didn't include inside the POD. I put it in a function due to being able to see the differences during different calls (and not copying code around while trying to understand). Confusing for me was that i didn't know how related functions generateWarp and generateBlend would've been and i misunderstood where you split them on left and right side creating a hierarchy of relevance to the class.
Putting them on the left vs right wasn't something I expected people to notice (nor did I explain it in the talk). But when I was separating things, I did consider leaving those functions inside the class, because they were "closer", so putting them closer on my slide felt right. P.S. one more thing to think about (and maybe I'll add to the talk), since it was kind of mentioned in our discussion: Circle doesn't have an x,y. It only has a radius. The x,y is an _extrinsic_ property of a circle, not _intrinsic_. A circle moved somewhere else is the same circle; 2 circles with the same radius, sitting side by side, are equal. Now, a CircularRegion would have an x,y. Or a GraphicalLayout might have a data structure that associates a position with a circle. But that position, and that association, is a property of the Layout, not the Circle. IMO, at least.
My fault, I didn't really think to mention what it is. Sorry :v
I made a demo: #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;fcntl.h&gt; #include &lt;unistd.h&gt; #include &lt;sys/mman.h&gt; #include &lt;assert.h&gt; #include &lt;stddef.h&gt; volatile int v; int main(int argc, char *argv[]) { int fd = open(argv[1], O_RDONLY); assert(fd &gt;= 0); const size_t size = 8ULL &lt;&lt; 30; char *addr = mmap(NULL, size, PROT_READ, MAP_PRIVATE, fd, 0); #ifdef ADVICE_RANDOM madvise(addr, size, MADV_RANDOM); #endif assert(addr); for (off_t offset = 0; offset &lt; size; offset += (128 * 1024)) { v = *((int *) (addr + offset)); } munmap(addr, size); close(fd); return 0; } Reading one `int` every 128 KiB (65536 times). Try it with a file having a size of at least 8 GiB on an SSD, clearing the caches before each test: sudo sh -c 'echo 3 &gt; /proc/sys/vm/drop_caches' I get about 23.11 s with no `madvise()` and 9.5 s with the random advice. Using Linux 4.17.5, a Samsung SSD 840 PRO, and an ext4 file system. `/sys/block/sda/queue/read_ahead_kb` is 128.
No, we can't!
I just find his questions strange, especially the insistence on a comparison. It hard to believe that a GCC developer doesn’t know what is going on in the LLVM world. 
I wrote most of that paper and what it is supposed to mean is that modules *themselves* are good, but the current syntax and file layout for expressing them is not
&gt; So you have to learn Japanese first. How hard can it be, compared to C++?
I think when we say "flow control" for errors we're usually talking about a non-error case and _implicit_ flow control changes, e.g. people using exceptions to signal end-of-data or the like and that unwinding through umpteem layers of non-annotated function invocations. The stuff you're working on is _explicit_ flow control and the supporting machinery thereof anyway, which is a rather different matter, and much more palatable. :) The other proposals in flight also help to unlock monadic error handling patterns that that actually do eliminate (user code) flow control, too, which has its own set of benefits of course. Proposals like [P0798](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0798r0.html) applied to `outcome`/`expected` would be one (kinda clunky) library-only approach to that end.
(I guess http://cpp.sh is just g++. I was looking for an alternative to Comeau, which seems broken.)
This is really leaning toward /r/cpp_questions material, but the ability to do this can help a bunch in generic code. Regular void would help more, but can't win 'em all.
 void f() {} void g() { return f(); } is well defined and correct. It works in order to enable generic code. Note that int f() { return 0; } void g() { return f(); } will not compile since you try to return non-void from a void function. An alternative online compiler with a lot of different implementation choices would be https://godbolt.org
Yes, that is correct. You can also simply `return void()`.
Those are interesting numbers. 23.11 / 9.5 = 2.43. If your kernel is doing the full 128Kb read ahead, that's 32 x 4Kb. The Samsung SSD 840 Pro delivers about 15x the IOPS at QD 32, so that looks plausible. I haven't tested on anything like that new a kernel as you. More like Linux 3.15. So it's possible that your Linux kernel is aware that your Samsung SSD can deliver 128Kb in one fifteenth the time of doing each 4Kb individually, and thus does do prefetch on that SSD model. I honestly don't know for sure, but I do know there are tables of well known SSDs in the Linux kernel with various custom settings for each. But I'm glad to learn I may have to refine my earlier claims that `madvise` wasn't of much use on SSDs. Thank you.
Some C++ features are easier to understand when you understand the evolution of how they came about and the previous C++ features they're related to. Lambda's in C++ are syntax sugar for function objects, and `auto` parameters on lambdas mean that the `operator()` on that function object is a template. Writing the equivalent of the global lambda without using a global lambda would be: struct { template &lt;typename Function&gt; auto operator()(Function function) const { return [function](auto... head) { return [function, head...](auto... tail) { return function(head..., tail...); }; }; } } curry; And then the exact code written to use the lambda would work using this `curry` variable. You could also avoid having a global variable at all by naming the class, not declaring a variable, and then just instantiate it as needed. That would change the usage syntax to: compose(curry(), curry())(printf)("%i %i\n")(1)(2);
&gt; I've accumulated a fair few contacts within the Optane teams in Intel, and from everything I've heard, they want to ramp Optane up to price competitive with Flash as quickly as process will let them. They want doesn't mean they could. They wanted (and drew a lot of similar optimistic graphs) to start producing 10nm chips in 2017, when in 2018, then in 2019 and now we are looking at 2020. Also, most of such "predictions" doesn't really consider that progress in other technologies (or just ramp up in production) might noticeably decrease competition's price (flash prices are rapidly dropping right now, but it's also still considerably cheaper to store data on HDDs while I saw numerous similar predictions that SSDs would "outprice" HDDs around this time). So yeah, I'd take all similar "projections" with a huuuuge grain of salt, especially since according to it, the SSD and XPoint prices should be almost the same, while in reality I see differences up to x10 (!).
It also prevents it from participating in ADL, which is probably a good thing.
That graph is actually my own creation, from my own data sampled by me over many years! I also performed the regression with my own fair hand. It is on a log scale though, so large linear differences today are small compared to forty years of history. I personally think for SSDs they'll match the projection, and the price parity point will be met. I would be surprised if they do for NV DIMMS, but we shall see.
I'm harsher on it than it deserves. It's an awkward API that depends too much on its representation for high-level semantics and conversions. It's probably a good choice for the C++ standard library in that it can be zero-to-low overhead in a wide variety of cases, but the end result isn't particularly user-friendly.
!removehelp
Overloading is too useful to discard like that. Instead I pass templates by wrapping them in lambdas at call sight: #define OVER(...) ([](auto&amp;&amp;... args){ \ __VA_ARGS__(::std::forward&lt;decltype(args)&gt;(args)...); \ }) int main() { compose(OVER(curry), OVER(curry))(printf)("%i %i\n")(1)(2); }
Putting clang and GCC together doesn't always work as you think. The common warnings like `-Wall` work on both but they don't [cover the same warnings](https://hopstorawpointers.blogspot.com/2018/10/warnings-series-hidden-overloads.html). And if you are enabling individual errors then you break your build as some errors are named differently depending on compiler.
Well, that just means there are more reasons to believe it for YOU ;P That's a real confusing way to create a graph then =) Unlike stuff like brightness/sound, people's wallet are generally really sensitive to even sub-linear changes =) Most wouldn't consider a technically superior (on paper) alternative at x2 cost as long as they have good enough (and regular/nvme SSDs are just that), they won't switch. Not to mention that it there is not enough data to extrapolate XPoint prices. There is one really pricey point, and a few in the similar somewhat lower prices range. It's unfounded to draw such an optimistic line from that. Anyway, we'll see in a year or two if it had any real ground.
Cool! This mailing list post is awesome! Thank you very much for sharing it here. Btw, it's from Feb 2018. And it contains REALLY, like REALLY important information, that is essential to the decision of using QtWidgets/QQC1/QQC2. It is a big fail in my opinion that this hasn't made it into the documentation, and more than 8 months have passed already!
Which other languages do you have in mind? There is a CUDA Fortran compiler.
AutoModerator has a trigger that looks for that text and checks if the poster is a mod, then does some magic and hacks.
I'd argue that with your example, you have hardware where 2's complement would not be what you want. Sometimes saturation makes more sense (for both unsigned and signed by the way). You could still make it an optional feature then. I don't like segmenting the language but it's still better than `errno`. Or you could even say stuff like "in case of invalid operation, the effect is implementation defined/undefined behaviour". You allow sane implementations to provide error checking with NaN, and others can do whatever they want.
If your strings are mostly using SSO it makes sense for many cases.
You have that backwards; I opt for the ones guaranteed to exist. ;-]
That is a bad idea because it would require to specify all conversion rules from all legacy encodings into UTF8 and make sure the compiler somehow always detects the right legacy encoding. There is no way to satisfy all people with one size fits all. I prefer to keep it simple and allow utf8 string literals only in utf8 source code and only allow valid utf8 code points. 
Why, tho?
Are you able to describe an example of a syntax and file layout that would be better (at least in terms of this specific concern)? It would make it easier for me to understand the issue if I could compare it with an alternative.
Good luck
There is no Xcode for iPad...
Bluetooth keyboard, ssh client, iPad pro. 
Don't forget to put the `inline` if you are in a header file: inline auto curry = [](auto function) { ... }; (this will make the variable inline, not the function) 
Her presentation at cppcon was great; definitely in my top 3, probably my favourite overall.
It also makes sense in many cases where strings are too big for SSO. In any case. My comment was not meant to promote or discourage pass by value. Just wanted top point out that this has indeed been a common advice.
From the sidebar: &gt; **For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow.** &gt; &gt; http://isocpp.org/get-started &gt; &gt; http://en.cppreference.com/w/ &gt; &gt; http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list
Rust and ada come to mind 
\&gt; store different instances of a base class in the same STL container I did not say, store them by value, but store a pointer to them or smart pointer. The benefit of OO, it is use the same client code to manipulate multiple implementations. But the cost is the virtual function calls overhead. If this overhead is significant, the better option is generic programming or generic + type erasure + CRTP and so on. Programming is a kind of art, there is always many solutions. &amp;#x200B; As far as I know, there is also no way to store the classes (pointers to instance) Circle and Rectangle implementing the methods computeArea or getLocation, setLocation with the same type signature in both classes in the same container if they don't the have the same base class. 
Ok, Thank you
You probably don’t want to do that. You want to code on a computer and cross compile for iPad 
Sounds like a good idea, but as I don't have much time right now and this list is free as in free beer: feel free to send me a pull request :-)
Why the video on Youtube has been removed?
This talk helped me to finally understands memory model guarantees.
I'd actually write `constexpr auto curry = [](auto) { ... };`. The non-capturing lambda is `constexpr`, and `constexpr` implies `inline`, or so I was told.
**Company:** [RaySearch Laboratories](https://www.raysearchlabs.com/) **Type:** Full time **Description** RaySearch develops state of the art software for radiation treatment and care. We are recruiting C++ developers to join our 150 person strong development department in central Stockholm, Sweden. We believe that candidates have * 3-10 years of experience in an academic or industry environment. * MSc in computational science, engineering physics, or similar. * An interest in high quality C++ development and architecture both at scale. For junior positions, also have [a look here](https://translate.google.com/translate?hl=sv?sl=sv&amp;tl=en&amp;u=https%3A//www.raysearchlabs.com/career/vacancies/last-datateknikit-fight-cancer-with-code/). We also have other positions (CM, IT, C#, WPF, TypeScript, ...) at [www.raysearchlabs.com/career](https://www.raysearchlabs.com/career) **Location:** Stockholm, Sweden. Fluency in English or Swedish is required. **Remote:** No **Visa Sponsorship:** No **Technologies:** * Parallel algorithms both on CPU and GPU (Cuda). * C++14, towards C++17. * Visual Studio, boost, google test, ReSharper C++. * The algorithms are implemented in C++ and the application layers in C#/.NET, under Windows, for Windows. **Contact:** If this sounds interesting, feel free to PM or contact us at [work@raysearchlabs.com](mailto:work@raysearchlabs.com), subject "reddit c++". &amp;#x200B; **About RaySearch laboratories:** RaySearch is a technology company with a difference - our software is a vital weapon in the ongoing battle against cancer. We help save lives through innovative software for radiation therapy, which is one of the most important forms of cancer treatment. You will work in a modern office environment with access to the latest hardware and tools. We encourage a healthy work-life balance and have created a strong social culture, with regular events and activities for employees. RaySearch is committed to equal opportunities. We value diversity and are dedicated to preventing discrimination. Our development department are made up of a mix of application developers, physicists, algorithm developers, specialists. More, [About RaySearch Laboratories](https://www.raysearchlabs.com/About-RaySearch).
there are many apps. I like this one C++ Programming Language Pro by Dmitry Kovba https://itunes.apple.com/us/app/c-programming-language-pro/id461327665?mt=8 because it is simple. you must pay after the trial though. the commenter who said to use ssh is correct if you want to actually make something
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9pgjfm/how_to_program_c_in_ipad_pro_129/e81to9n/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I implemented xorshift based on your suggestion, it's much faster! Almost twice as fast for generating bytes. Will do more tests for it and update my release.
There are many OSes where all resources (files, mutexes, network sockets, ...) are handled using URLs (Uniform Resource Locators), so the above just works because whether an URL points to a file in your hard drive or on the network does not really matter.
You can have a look at xoroshiro too
I was thinking of asan but it looks like GCC had that and others too.
Yeah they got supported a bit later but recent versions of gcc should support all of them afaik
I updated the code to use xorshift128+, it's twice as fast now. Investigating further.
Our project's backend, written in PHP (by another team mind you), uses exceptions as control flow. They basically never return bool from a function. Instead they throw an exception and catch it immediately in the caller code and well... do nothing with it. I have also seen codes like this: `try { if (!something) { throw Exception; } } catch { // do nothing }` It's really easy to misuse exceptions, especially by beginners. I haven't seen this kind of control flow in C++ so far, but it doesn't mean it doesn't exist somewhere out there in the wild.
...em...no. Really no. We have std::vector, that's more than enough. Bring more C madness to C++ is like asking for more trouble. 
**Company:** [Svenska kraftnät](https://www.svk.se) **Type:** Full time **Description:** Svenska kraftnät manages and operates the swedish high voltage transmission grid. Our real-time simulator (ARISTO) is primarily used to train grid operators at SvK and several other operators of power transmission networks. You will be part of the 4 person team responsible for the continuous improvements of ARISTO. You will have the opportunity to work with all aspects of software development ranging from design to performance and user interaction. Our current aim is to develop a new GUI in Qt/C++ but also to complement our library of models of power system components and adapting to CIM, a common standard for data exchange. Junior and senior developers may apply. **Location:** Stockholm, our main office in Sundbyberg. Workplace language is Swedish. **Remote:** No, you can work from home occasionally but most days you will be at the office. **Visa Sponsorship:** No, only swedish citizens are eligible. **Technologies:** Required: C++14 or above, Linux (CentOS) Optional: Qt, Boost, C, python, Fortran, postgreSQL, tcl **Contact:** Applications are welcome until October 31 at: [https://www.svk.se/jobba-har/lediga-tjanster/svenska-kraftnat-soker-en-systemutvecklare-som-vill-bredda-sin-kompetens](https://www.svk.se/jobba-har/lediga-tjanster/svenska-kraftnat-soker-en-systemutvecklare-som-vill-bredda-sin-kompetens) Questions can be sent to [linda.oppelstrup@svk.se](mailto:linda.oppelstrup@svk.se)
Slowly but steadily languages seem to converge to [my proposal](https://www.reddit.com/r/ProgrammingLanguages/comments/m0f1o/how_about_a_programming_language_in_which/), formulated about 6 years ago... 
The link doesn't work without javascript.
Don't be giving away the secret!
idk about this one fam
&gt; Our project's backend, written in PHP (by another team mind you), uses exceptions as control flow. yes, but that's PHP, and that's idiomatic use of exceptions in PHP. The first thing that comes up when looking up "PHP good practice exception" on google is exactly this : http://bestpractices.thecodingmachine.com/php/error_handling.html. Likewise, in Python, breaking from a for-loop with an exception is the idiomatic way to do it. Those are not misuses at all, and nobody cares about this in Python because Python is ~80x slower than C++ on average. The same would absolutely be a misuse in C++. The error here is trying to apply the same concepts to different languages. For instance, exceptions in PHP and Python don't bloat binaries because these languages don't even have binaries. You don't have to handle MinGW throwing exceptions which are incompatible with MSVC in PHP.
&gt; that's more than enough. well, no, else there wouldn't be the need for stuff like Boost.PolyCollection.
ಠ_ಠ &gt; Feature: FAMs can only be created with new This sounds highly unintuitive, as typically one would not expect new'd members to be allocated in-place. 
Boost.PolyCollection is a type of array that satisfies totally different array requirements from T[] and vector&lt;T&gt;. 
(Author here.) This proposal is still a draft and is not part of the San Diego mailing. It's also riddled with typos and other things I'm still fixing, but I wanted to get a version out in the hands of the people I'm working with.
This is probably poor wording on my part. The whole flexible array member \_type\_ can only be created with \`new the\_whole\_fam(std::fam\_size(24))\` or spun into life from a \`reinterpret\_cast\` or by the use of placement new on a segment of data.
Sorry! rawgit is dying so I needed to try out different services. It seems like I'm going to need to just open up my own github pages at that point.
I really appreciate this feature in C. I've used it high performance computing as well as in programming language interpreters for efficiency. I hope it will make it into C++.
The specific problem we are attempting to solve here is the #-of-allocations problem. For a fixed header plus some variable sized data after, C++ has no type-safe way to do this in exactly one allocation without the use of type punning "aligned\_storage" or just some random buffer. This allows you to allocate both a header and its data in one contiguous chunk without supreme gymnastics.
Ayyyyy! ^(Did you know that when I still had papers in separate repositories I called the repo \`family\` as an acronym for "fam, it's lit, yo" ahaa ah geez I'm a nerd aren't I?)
We are open to getting the best candidates, obviously we would be looking for strong distributed work behaviors. 
Then you are required to know \`N\` at compile-time, and at compile-time only. I am not wizard enough to know the size of my IP or UDP packets ahead of time.
It could be remote or in one of our offices as listed.
Sorry I assumed you had a Mac to connect to. I don't know of many on-eevice idea. I think I used something called Coda a while back but it was definitely not c++. Google around, maybe there's something that fits your needs
Ah, true. Don't mind then.
so you want something like std::array (fixed length) but where it's size if fixed at runtime? (unlike std::vector)
so you want something like std::array (fixed length) but where it's size if fixed at runtime? (unlike std::vector)
Huh, `/permissive-` could be just what we need to reduce the number of broken linux builds by windows devs.
Yes, the allocation size is fixed (as in it doesn't change), but it is only known at runtime. Primary example of this are packets on the network, but there are lots of other places where VLAs are stored (paper contains examples). The other core component of this is that it still participates in the type system. I can put a bunch of data laid out before the Flexible Array Member comes up. I can also have the guarantee that my destructor will properly destruct each element inside of the FAM in reverse-order just like a regular array, before destructing the rest of the members too. We want to promote FAMs into something that participates nicely with C++'s type system.
The correct solution for this, I believe, would be to have a vector with 'short vector optimisation'. That lets you allocate space for the common case on the stack, and still spill over to the heap if necessary. That wouldn't need language changes either.
No, that is the Variable Length Array problem. This is not variable length arrays. This is heterogeneous data -- in particlar, the Some Header + Different Tail Data case -- where the prefixed data is not the same as the data that comes after it. C++ arrays have elements all of the same type: you cannot stick different types at the beginning of an array and then use another type later (without just violating the type system).
@15:30 &lt;prepares for loss of karma&gt; `std::for_loop` is reminiscent of the way old-school Fortran, Kokkos, and Cuda kernels are written and runs contrary to the abstraction goals of As someone working in scientific computing and HPC constantly teaching that higher level abstraction are to be preferred, in my opinion, bringing this convention into the standard library (and thereby legitimize this style) would be a regression in the language, especially in light of the upcoming ranges proposal.
Oh god I just realized htmlpreview doesn't respect href links clicked.... DEFINITELY changing to my own github pages now if I can...!
&gt;making it’s usage unspecified Spell checking your prose makes you look more professional. &amp;#x200B;
Well, if I was to be honest I wasn't expecting the draft of this to be posted on reddit. It's not even in the San Diego mailing. ¯\\\_(ツ)\_/¯ 
Googletest, boost.test and catch2 are the most popular unit testing frameworks I guess. I would try automating the process with cmake, but if you have no experience with that, a batch script will do. 
Yeah ive got cmake set up to compile everything. Just needed somewhere to start looking for how to test them
Two types of tests will be used, 1) direct user input, where the output of the students program is tested. 2) The students will implement an interface that we have given them. Then we test the functionality of their implementation 
How are you a TA and not able to automate something so simple?
[removed]
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9pki45/best_way_to_test_hundreds_of_cpp_files/e82h6nc/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
My professor that did the most automation did this: 1. Specify the exact format of input and output 2. Specify location and filename, plus ACL for the files, on our shared drive on the school servers 3. He had a Perl script that did lookup of the username for each student, checked their file ACLs (only student and prof should have read access), copied their files locally, compiled, piped in test cases and redirected output to file, then compared the output with the output from his implementations. 4. Output of the script was a report detailing how the student's output differed, if it did. But that guy designed his assignments around being automatable, and keeping the testing as simple as possible.
It's a pretty valid question
do you also need to review their code to give feedback or just make sure that the output matches the expected result? ``` #!/bin/bash generate_input() { # put code to generate the user input here } SrcFolder=/path/to/folder for file in $SrcFolder/*; do g++ $file -o $file.bin &amp;&gt; $file.build if [ $? != 0 ]; then echo "$file couldn't compile, check $file.build for errors" continue do generate_input | $file.bin &gt; $file.out 2&gt; $file.err if diff /path/to/expected_output $file.out &gt; $file.diff; then echo "$file output matches the expected output" else echo "$file output doesn't match. Check $file.diff" fi done ``` something like this is how I would do it using bash 
Ta's are not processors, they are still students, and shockingly poorly paid/compensated ones at that considering the work they do. 
They have a specific format to turn in. Also, i have a zipped file (from the website they turn the assignment in on) that contains all their files with their name prepended. I already have my script setting up dir paths and all that. For the purpose of this question, i have all the students compiled code, and associated with their name. So i just need to test it
Thank you! Ive got the compilation down. I was trying to make this testing as modular as possible so that for any new projects/assignments i could swap out a portion instead of changing the script. Do you think it would be more viable to have a cpp generate input &amp; test output, so that in the future, only this file would be swapped out to test different assignments?
Wish they would've just unlised it until the fix instead of removing. Looking forward to watch it.