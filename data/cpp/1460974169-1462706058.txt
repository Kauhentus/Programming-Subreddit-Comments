No problem. I find that putting this stuff in writing clarifies my own thinking on the subject as well. As for raw loops, there are quite a few people who actively try to stay away from raw loops. You can try googling "no stinking loops" or "no raw loops" if you want to find code samples comparing raw loops with algorithms. Myself, I find [this talk by Sean Parent](https://channel9.msdn.com/Events/GoingNative/2013/Cpp-Seasoning) especially enlightening. It shows example code, and discusses the matter within the context of real codebases.
I haven't been callous you fucking douchebag. I joked that you should learn C++. I joked that you didn't know C++ because of fucking capitalisation. That's not callous. It's just a bit of very, very harmless teasing. You overreacted more than I've ever seen someone overreact before. You literally wished for my hands to be cut off in a chainsaw accident over a comment about a **programming language**. Jesus.
Well, that was a result of the development process :). When wrapping the `void*` I tried to avoid writing all special member functions while having a copyable handler. So I picked `std::shared_ptr`, with out of the box reference counting semantics. Actually the `MetaObject` of my implementation overloads assignment operator so assignment is by value. When doing reflection `MetaObject` instances act more like "bridges" from the API to the actual reflected value, so this trick was neccesary. For example: class Class { public: int i; }; Class c; auto field = cpp::reflection(c).field("i"); field = 3; assert(c.i == 3); In that example, `field` has a `MetaObject` wrapping a reference to the `i` field of `c`. Assignment of a value on a field calls `MetaObject::set&lt;T&gt;(assigned value)`. Now look at the following: class Class { public: int f(int i) { return i * 2; } int i; }; Class c; cpp::reflection(c).field("i") = cpp::reflection(c).function("f")(1); In that example the return value of member function `f()` is assigned to field `i`. Both the returned value and the field are `MetaObject`s (We've lost type info by using the dynamic reflection API), so we need value assignment to pass values between referenced entities. Was reference semantics worth it? Maybe you're right and I would have to support full value semantics, at least to be coherent.
The question of why RVO and NRVO optimizations are acceptable is an interesting one indeed. The copy or move may have observable side-effects in which case the optimization changes behavior. By definition an optimization doesn't change behavior. To my knowledge, this is the only acceptable optimization in C++ that can change observable behavior. For all intents and purposes you can assume that RVO/NRVO is the exception to the rule, and no new exceptions should be added. With that in mind, optimizing test1 the way you want it to be optimized can change observable behavior and is therefore unacceptable. This is probably not a very satisfying answer but that's the way the cookie crumbles :)
I've reported your post for threatening, harassing and inciting violence. You disgust me.
I don't want to sign up for a Disqus account to leave a comment on the post, but the benchmark has a bug. The first run (with std::endl) includes the time needed for the system to create the file, but the second run does not. Even when explicitly asking the std::ostream to truncate the file (which is the default behavior), it does not have to create the file.
Is there a way to say "first try resolving this as an r-value; if that fails, try again with an l-value"? It makes sense to `std::move` the last use of an object that is about to die, but if you're calling an unknown function, there's no guarantee it has an r-value overload.
So this will be PGO on steroids? That would be fantastic. I could see this being extended into a JIT system where an inefficiency is possibly detect and the compiler re-analyzes the source to try different optimization passes until it can decrease the runtime "sufficiently" (for whatever that means to the user).
You are correct - ish. I just reran the tests to check. Truncating the file first seems to actually be slightly slower. by .01s. Really it's in the noise of that simplistic of a test, in the margin of error. But starting with a no file at all seems to be consistently *slightly* faster.
Interesting. Thanks for checking!
I understood his point. I was asking a different question. What is the easy solution?
There's no way in the Core Language to request that on demand (although it's what happens for returning local variables). Any trickery (e.g. wrappers with conversion operators) would be detectable to templates. Fortunately, this isn't necessary for most functions. There are only a couple of kinds of functions that want to be given lvalues. The first kind is functions taking modifiable X&amp;, where they insist on modifiable lvalues. The second kind is functions taking X&amp; or const X&amp;, with deleted overloads for rvalues (ref()/cref(), regex_match()/regex_search(), and the regex iterators behave like this). Such functions really really want lvalues and forbid rvalues. You generally know when you're working with functions like that, so you generally know when you can't say move(). Otherwise, you can say move() and it makes the thing eligible for moving, when the compiler sees such an overload. It's not a big deal in practice.
Okay, it's a fair point that the particular way this optimization can be broken is potentially peculiar. But I would say the ways that RVO gets broken are sometimes not so obvious either, even if the specific case of following statements can't happen. For instance some compilers won't do NRVO when two branches return different named values, i.e. the following simple code can prevent NRVO depending on implementation return condition ? first : second; 
As C++ developers it's our duty not to use this product, it' written on Java script the language of sin and abomination!
There are many cases in the Standard where the implementation is allowed to select one of several valid behaviors with the choice being unspecified. Copy elision is special only in that it can observably skip calls to user-defined functions. There are no cases in the Standard where the addition of a statement can affect overload resolution for previous statements in the same function. (Yes, I am aware that member functions can be declared after use, that's different.)
&gt;PGO actually optimizes your code (i.e. makes it faster) I believe you are thinking of Whole Program Optimization (WPO) (aka, Link Time Optimization (LTO)). PGO is Profile-Guided Optimization which has two phases: 1. calculate timings based on hardware counters, cache hit ratio, branch prediction, virtual table lookup frequencies, etc., and 2. feed that information back into the compiler on the next compilation of the source files to produce code that (ideally) adjusts the data layout or reorders branches based on the data it collected. This first phase of PGO is exactly what esan is doing except that it can detect a larger class of problems.
&gt; That's not true, is it? It is true in the sense that you can just ignore missing dependencies target start with "api-ms-win-*", as generally that's not where your dependency problems are going to be.
At the end of the video, you say "let me know if you have any comments.". Below the video it says "Comments are disabled for this video.". 
RVO shouldn't be considered precedent for how things should work in C++. It was basically a performance hack developed by a compiler vendor that was too important for the standard to forbid.
The most problematic case is when you're both reading and writing from the stream. More commonly, if the application crashes before the buffer is flushed, you won't see the text output, which can confuse the programmer while debugging. This is especially bad for beginners using cout-based debugging.
I guess it's not very explicit, but: 1. I think all the other *Sanitizers are targetted at humans. 2. They mention one of the tools is for "providing basic direction for further effort by the developer". 3. I think a lot of the identified issues can't be optimized by the compiler. For example, I think clang or LLVM aren't allowed to change the layout of structs, that has to be done by the programmer.
Honestly, I see no reason not to do this. Both `vector` and `map` have additional template parameters (allocators, comparers), and they derive from base classes (or at least can). The base classes are implementation details, and IMO, so should the SOO size parameter/`base_any` be. I'm not arguing that the SOO size param should be a parameter of the `std::any` type, but there is no reason not to add it to `base_any`.
This makes no sense. You're seriously suggesting giving up the benefits of iostreams in favor of a C API with no type safety because one platform implements it with poor performance...
`std::flush` does not necessarily write anything to disk, I think you're confusing it with the `sync` command. What flushing does is writing the contents of the internal buffer to the output of the stream, which in case of `ofstream` means invoking the `write` syscall: $ strace ./endl 2&gt;&amp;1 | grep write | wc -l 1000000 Without explicitly flushing, the buffer will still be flushed once in a while, but significantly less often: $ strace ./newline 2&gt;&amp;1 | grep write | wc -l 1465 On my computer, the buffer is flushed after 8196 bytes. Explicitly flushing the buffer at the end has no effect at all (the buffer will be flushed automatically anyways): $ strace ./newline_flush 2&gt;&amp;1 | grep write | wc -l 1465 stringstream is so much faster because it doesn't invoke `write` when flushing it. In fact, while it consumes much more memory, it only needs one invocation of `write`: $ strace ./stringstream 2&gt;&amp;1 | grep write | wc -l 1 By the way, the GNU C Library will also flush stdout when it encounters a newline (at least if stdout is an interactive device): https://www.gnu.org/software/libc/manual/html_node/Flushing-Buffers.html `std::cout` will also do this regardless of using \n or endl: int main() { for (int i = 0; i &lt; 10000; ++i) { std::cout &lt;&lt; "Hello World" &lt;&lt; '\n'; } } $ strace ./hello 2&gt;&amp;1 | grep write | wc -l 10000 
First several comments on the mailing list: "we should instead name it ..."
If you want to deploy to Win 7 or Win 8.1, then unfortunately it is where dependency problems are. :\ (it's probably only true for Windows 7/8.1 installations that are not running all updates. But that's still a _LOT_ of systems.)
&gt; The first phase of PGO does some runtime analysis of the code and produces machine-readable information about how to compile it better. I always wondered why one couldn't generate human-actionable tasks from PGO. It would be rad to have PGO spit out information for obvious improvements like 'rearrange the order of this if-then-else'.
Not really. You can write code in any style in any language. That doesn't mean that language is that style.
I would say the use of std::endl with an update stream makes it harder to reason about. Is it a flush or is it just endline? As for logging, wouldn't it make a lot more sense for the beginner to learn what flush (and cerr/unitbuf while at it) is?
I'm the author of CallableTraits. Quickbooks documentation is linked in the README. However, the reference section is maybe half-full of stub pages. Still, I think there is more than enough substance here for the community to offer some feedback (and/or rip it to shreds). I'm displeased with the names of a few things, but I'm having a hard time thinking of better ones. I am well aware that many of the features in CallableTraits are not generally useful *at all*. However, the sheer amount of templates and preprocessor tricks it takes to achieve this is something that no law-abiding programmer should ever have to experience, so I decided to settle the matter once-and-for-all with a library solution. Have you ever used a template specialization that looks something like this? template&lt;typename Ret, typename T, typename... Args&gt; struct foo&lt;Ret(T::*)(Args...) const&gt; { //... } CallableTraits makes this code *absolutely* unnecessary... ...unless I missed something. Can you think of anything? 
Your post has been automatically removed because it appears to be help/homework related. If this has been in error please message the moderators. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
AMD's first C++ support in kernel dates back to 2011/2012 (as an extension).
This is *awesome*. Thank you for tackling this beast head-on, and here's hoping C++20 doesn't inflict more combinatorial specialization upon you!
Thank you for bringing `transaction_safe` to my attention -- N4000 looks very exciting. I will start looking into this once I've finished documenting what I've done so far, and once satisfactory test coverage is achieved. I briefly touch on C++17 `noexcept` in the documentation. The implementation of CallableTraits lends itself to the addition of new features like the ones you mention. Basically, I'll just have to add another layer of pre-processor/x-macro spam -- ugly, but effective. Optimization opportunities may arise as more features like these are added to function types, where certain layers of CallableTraits' internal specializations could be restructured into a binary search. It's hard to say when this point will be reached without benchmarks, though. Edit: for clarity
The C++ language has a `template` feature, which is *insane in every way*. Templates open up a whole new world of programming called "template metaprogramming," or TMP. TMP lets you *generate types at compile time* for the runtime code to use. For instance, TMP is used to bring us cool toys like `std::bind` and `std::tuple`. Metaprogramming libraries were written to make TMP easier, such as Boost.MPL and Boost.TypeTraits, some of which now exist in your standard C++ header `&lt;type_traits&gt;`. Type traits are the building blocks for metaprogramming. `std::remove_const`, for instance, lets you remove `const` from a type. The C++ language also happens to have complicated, insanely customizable function types. Until CallableTraits, we didn't *really* have any type traits that let you manipulate the guts of these types. The immense complexity of these types makes certain TMP scenarios very difficult to work around. The only way to manipulate these types is to write *partial template specializations*, which can be described as a form of switch statement, but for types instead of runtime values. A side note on template specializations: [This guy's tutorials are usually pretty good](http://www.cprogramming.com/tutorial/template_specialization.html), but really the only way to learn template specialization is to start using it, Googling as you go. I actually didn't know how to write a partial template specialization until fairly recently. Stack Overflow is your new best friend if you are interested in learning TMP -- that's how I learned, anyway. Back to the function types: Have you ever used `std::function`? `std::function` takes a *function type* argument as its template parameter. A function type looks like this: `ReturnType(ParameterType0, ParameterType1, ParameterType2, /* and so on... */)`. So, both `int` and `int(int)` are types - one is boring, and one is a function type. Consider this code: void print_number(int i) { std::cout &lt;&lt; i; } `print_number` is a function. Its type is `void(int)`. If you have a function type and pass it to a template, the template only knows that it is a type. A template doesn't know whether it's dealing with an `int` or a `void(int)`. The only way to distinguish one from the other is to write a *partial template specialization* to handle it. An ordinary class template looks like this: template&lt;typename T&gt; struct foo { /* T can be int or void(int) or a bazillion other things */ }; To expose the guts of a function type, you must write a partial template specialization like this: template&lt;typename Return, typename... Args&gt; struct foo&lt;Return(Args...)&gt; { /* ... */ }; Partial specializations use a weird syntax that many C++ programmers may never see in their life. However, this technique is the ONLY way to break down a function type, the parts of which can then participate in TMP type generation. That's only a couple more lines of code. Not too bad, right? Wrong. So far, we've only touched on the most basic case. If my new-found understanding of C++17 is correct, one would have to write a bare minimum of *192* different partial template specializations (yes, 3 digits) to account for all the variations of function types and *member function pointers*, all of which can only be broken down in this way. These specializations are a massive barrier that had no shortcut until CallableTraits. CallableTraits works like this: First, CallableTraits unrolls every one of those specializations (actually only 48 of them for now, because the C++17 function type additions haven't been addressed yet). Then, CallableTraits gathers all the information you could possibly want (and then some). Finally, CallableTraits packages it all back up in a clean little interface for you to take home to your kids. Additionally, CallableTraits does a few nifty things related to callable types that don't require all that heavy lifting. [Here](https://github.com/badair/callable_traits/blob/master/include/callable_traits/detail/function.hpp) is how CallableTraits solves this problem for function types in a relatively maintainable fashion. (Note: apparently some tab characters sneaked into my header files. I opened an issue for this.) I hope that makes sense. Also, after you learn what makes TMP work, you should *definitely* start using [Boost.Hana](https://www.youtube.com/watch?v=cg1wOINjV9U) if you want to build cool things with metaprogramming (and have the luxury of using a modern compiler). Hana will make things a lot easier for you. I plan to eventually write Hana extensions in CallableTraits to open these operations up to the Boost.Hana world (which would only take an hour to write, but much longer to document -- I think have enough on my plate for now). Edit: [Boost.FunctionTypes](http://www.boost.org/doc/libs/1_60_0/libs/function_types/doc/html/index.html) deals with these issues as well. I'm not yet familar enough with it to know exactly what it does, so I can't yet explain how CallableTraits differs. But it's looking like there will need to be a documentation section devoted entirely to this differentiation.
&gt;The showcase feature in this release is the introduction of ==, !=, &lt;, &gt;, &lt;=, &gt;= and in operators for the if tag. And according to GitHub this project exists since 2009. This creates a very bad gut feeling in me. Anyway I do have knowledge of the Django templating system (which grantlee apparently is based on) and it's fantastic. I don't use Qt so I don't know how feature rich it is at the moment but I'd recommend it because the Jinja templating style is pretty good (unless, of course, grantlee is missing important features such as filters, loops etc.). 
Probably 192, not 182 :) The latter doesn't factor correctly. It should be possible to write the partial specializations once for function types, and use them for pmfs/function pointers etc. Also, if you want to do calling conventions, at least in MSVC it's part of the function type, so there's e.g.,`int __cdecl (int)` and `int __stdcall (int)`, which are distinct types, with `int (int)` being whatever the default is (usually `__cdecl`).
Fixed, thanks. You are right about technically only needing to write them once for function types and member function pointers, since you can basically express member function pointers as member data pointers to functions. That brings the number down to 96. However, I ran into an obscure compiler bug or two that prohibited me from using that approach, [such as this one](http://stackoverflow.com/questions/36026352/compiler-attribute-stuck-on-a-function-type-is-there-a-workaround-for-this-cla), which earned me the Tumbleweed badge on StackOverflow. Thanks *a lot* for the note about calling conventions -- sounds like I need to add some options for that as well. My current implementation assumes calling conventions are exclusive to pointers. Those are tough to deal with for cross-platform development.
For me it's more about code clarity, since `std::endl` is almost never used as intended (in my experience). Performance is worth talking about too, but for me is not the killer reason to stay away from using/teaching `std::endl`. I wrote a little explanation/rant about this myself not long ago: http://chris-sharpe.blogspot.co.uk/2016/02/why-you-shouldnt-use-stdendl.html
Relax, man. It's all good. We've said the things we have wanted to say. Tempest in a teacup. Let's just leave it.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/macprogramming] [Peercoin OSX packager needed (qmake\/Qt4) : cpp](https://np.reddit.com/r/macprogramming/comments/4fhptj/peercoin_osx_packager_needed_qmakeqt4_cpp/) - [/r/peercoin] [OS X Ad Posted](https://np.reddit.com/r/peercoin/comments/4fhq2z/os_x_ad_posted/) - [/r/qt5] [Peercoin OSX packager needed (qmake\/Qt4) : cpp](https://np.reddit.com/r/Qt5/comments/4fhnrx/peercoin_osx_packager_needed_qmakeqt4_cpp/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
You will need a Qt 5 port, 4 should not be used for modern OS X. Also you'd ideally need a code signing certificate, to simplify launching and improve security. That costs money but I know nothing about PeerCoin's finances or structure.
The Qt5 port is here: https://github.com/hrobeers/Peershares/tree/ppcoin-master-qt5 (note the branch name "ppcoin-master-qt5"). Can you help? The community can raise funds in peercoins or bitcoins if needed.
I suppose you could produce something like that. But then again, if the compiler has that information, why not just let the compiler take care of it?
People should get in the habit of using cerr, not cout, when debugging and synchronicity are issues. It flushes on everything so whether or not you use endl is irrelevant.
std::sort()
thanks for nice list, we'll read on my way home :)
&gt; Is it a flush or is it just endline? But does it really matter? I just want that shit on my screen. 
But surely the CRT dependencies aren't in API-MS-WIN-* dlls, right? I thought they were inside ucrtbase.dll or others.
&gt; The most problematic case is when you're both reading and writing from the stream. If you mean writing to `cout` and reading from `cin` or writing to `cerr`, then by default `cin` and `cerr` are tied to `cout` and attempting to read from `cin` or write to `cerr` will flush `cout`'s buffer (this is controlled by [`tie`](http://en.cppreference.com/w/cpp/io/basic_ios/tie)). You can explicitly disable this synchronization with `std::cin.tie(0)` and `std::cerr.tie(0)`, but unless you do so it's on.
Sorry for the detour, but as a language user I would also like to know why the study group does not push *runtime* reflection.
No, it doesn't. Thanks, I didn't know that!
&gt; Both `std::ifstream` and `std::ofstream` are nice RAII classes and with two lines of code I can write or read a std::vector, which is neat. Except that if you actually care if data was written or not, you must manually close stream and check its state afterwards. And if there were an exception in some unrelated part, you have no way to determine if write to file was succesfull.
Right quicksort should be preferred, it is the very efficient sorting algorithm.
I can't speak for the others, but probably because C++ is a statically typed language, static reflection feels like it should be the foundation. And static reflection will allow reflection libraries to build on top of it. And that in turn will give us, the C++ community, the experience we need to glue runtime reflection on top of static reflection.
No one commented here, but I think this is a pretty neat idea!
&gt; Bubble sorting is the very commonly and widely used sorting technique in C++ programming. You are kidding, right?
Looks kinda cool! I skimmed through proposal and haven't found a way to list all enum class values. Is it possible with current proposal?
I agree :-) But I always comfort myself with the thought that here, we are really defining the /language/ of meta-C++. Only after we have that will we see a /standard library/ of meta-C++. And I expect that the latter will provide the simplicity we all want.
I would guess that: if your use-case can accept the cost of *runtime reflection*, the chances are you'd be ok with alternative languages that already have it.
I've seen some cool things done with their service bus, which is apparently a generic, scalable message-passing queue that lives in the dreaded "cloud". It looks pretty easy to program against, at least from .NET.
:) Yes
I've always found the 'visitor' pattern for double dispatch to be overly intrusive and maintenance intensive... but the alternative of manually switching on the derived type (from RTTI or by manually returning the type from a virtual method) and static_casting also feels like it is excessive effort for the problem. Is there a better solution in C++?
As mentioned in my other comment, this has to do with assemblies referenced in the manifest, so the dlls are not actually _named_ API-MS-WIN-\*; a given API set is named API-MS-WIN-\* and references specific versions of ucrtbase.dll or others.
It's still going to be template-based, so it still won't look anything like normal code.
I agree that this would be annoying to use. But I also think this was inevitable: C++ pretty much has one way to do compile-time programming: templates. And since reflection in C++ is supposed to be compile time (to make it efficient), the options are: 1. Reuse templates. They already can do support everything that's needed. They're also already annoying to use. 2. Invent a new, relatively simple, way to do compile-time programming just for reflection. 3. Invent a new general-purpose way to do compile-time programming. Both #2 and #3 don't really sound like viable approaches to me, so templates it is.
No, you apologise. Now.
This article prompted [some discussion](https://github.com/pfultz2/Fit/issues/162) about adding a solution to the Fit library.
I hear you. I feel your pain. I empathize with your frustration. I share all of it. I have a dozen projects that use it. It wasn't me that got it working initially, it was someone trying to convince me that CMake was better than Autotools (it is, oh god it is), and showing me how it would be better. It's better, but it's not exactly fun to work with, or easy to understand. In fact, here is how I think of it: You type "cmake .", and off it goes. It's a runaway train, it's going to gather speed, fuck up, and derail itself, causing plenty of carnage in the form of an unreadable makefile, which you cannot debug. Every statement in the collection of all CMakeLists.txt files (Lists? huh?) is a prayer, pleading with it to not fail. Is that CMakeLists.txt file executed in a linear fashion? No. At least I don't think so. It's just a bunch of arm-waving, but it all sort of, mostly, kinda has to be referentially intact by the end. I suspect the best way to concoct a correct CMakeLists.txt file is to grow one with a genetic algorithm, in a monkey/typewriter kind of way. But I admit it solves an ugly problem. You'd think it should be easy, but if you list out the steps you need to occur, it looks something like this: * Turn on warnings for GCC, and do the right thing for any other substitute. * Compile all this directory into a static lib. Or whatever it's called on Windows. * This file compiles into a binary, links to that lib, and is named this. * Oh, and install these man pages into the right place, wherever that is on this OS. * Oh, and yeah, make me a tarball on demand, but leave these files out. * This thing here is just baggage, but install it anyway. * Oh, yeah, and pull in a git submodule, I need that. * And I want to link to libfoo on BSD, but not on Linux, wherever that thing was installed. Might not be here at all in fact - find out. * Make that dependency over there optional. And so on. It's inherently non-linear - which step should occur first? I don't know. If I actually tried to create a toolkit/language that did all that, I suspect I'd end up with CMake or something a lot worse, and have a lot more respect for it. TL;DR: Trial and error, sweat, tears, a little help from friends. Beer.
Hmm... Number 3 already happened, it's constexpr, and compile time execution of code is quite the goal of this thing.
Proposal author here. You are right that the basic proposal is quite complex, but this stems from the complexity of the C++ language. We also want to cover as many cases and thus reflect as many things from the base-level language as possible. But. We are just beginning. This is just the foundation and a whole library consisting of several different interfaces (compile-time/run-time, objectish/functional/etc.) and facades (for the trivial cases) will be implemented later. For a few examples of what is possible once static reflection is available see the following (ignore the registration macros, they will not be required once we have compiler-assisted reflection): http://kifri.fri.uniza.sk/~chochlik/mirror-lib/html/doxygen/mirror/html/examples.html http://kifri.fri.uniza.sk/~chochlik/mirror-lib/html/doxygen/puddle/html/examples.html http://kifri.fri.uniza.sk/~chochlik/mirror-lib/html/doxygen/rubber/html/examples.html http://kifri.fri.uniza.sk/~chochlik/mirror-lib/html/doxygen/lagoon/html/examples.html EDIT: We started writing a paper trying to answer all the questions related to the 'static reflection' proposal. It's still an unfinished draft, but FWIW, you can find it here: http://kifri.fri.uniza.sk/~chochlik/reflexpr/DxxxxR0.pdf You don't need to read the whole thing just browse through the contents and look up the things you are interested in. EDIT2: Comments and new questions for the FAQ section are welcome. HTH
The last thing i want is my IoT devices connecting to the cloud.
[Meson](http://mesonbuild.com) is my proposal. [github](https://github.com/mesonbuild/meson) tl/dr: like CMake but with a sane syntax.
Don't lose hope and take small steps. Don't try to learn things from tutorials only, pick a small project to work on, use what you already know. As you become acustomed with that, try learning new things and apply them to the source code you already have - try rewriting parts to fit the newly learnt things - classes, templates, functional programming concepts... I started as a young teenager with Pascal (Borland Turbo Pascal to be precise) and learnt a lot of concepts on that language, but it was mostly procedural programming. Then I started programming in C++ at the end of high school as pascal became a burden to bear - it was too verbose, lacked expressivity. At first it was procedural C++, mostly C, then I used Borland Builder for a couple of months. Then I started working on my hobby project in full blown C++, using classes, templates, etc. Fast forward to now, I am employed as a C++ backend programmer.
Thanks for responding! I normally stay away from tutorials because I feel they leave out so much, and a lot of people also said what you just said. I have a book which is decent I guess, but my teacher doesn't teach so I'm on my own. Ah, that makes sense. I did make a small project (not my own idea) with Qt, maybe I can add to it. That's what I'm also nervous about. So many people that I'll be in University with ~next year will have a much further head start than me, and I wont be able to compete in the market. So pretty much working on a project taught you how to apply C++? sorry if that question is a little stupid. Thanks again for responding!
Yep, working on my own project and reading a lot of open source code. There are piles of well written source code out there to show you how things are usually done. Only trying to understand it will push you miles. If you're trying to understand a thing, try doing a few lines of code in a small file (I call it a.cc usually) and build it on it's own - this is also a good idea for debugging, if you can separate the problem into a small piece of code and a few lines in main(). Don't worry about the head start, it does not mean much in real life, many of my collegues started programming C++ on university, some of them had no big experience with programming before that. Did you try looking at rust? It has a very strict compiler and ownership rules, it could show you how to manage object ownership later on. Don't try learning it now if you know you'll be doing C++ on university though, but keep an eye on it, it teaches good habbits and removes a quite a few of the problems C++ now has (there's quite a few). 
The impression (from the Qt Creator guys feedback) I've got is that Kitware doesn't want [cmake-daemon](https://github.com/steveire/cmake/tree/cmake-daemon) in. Or at least they don't say anything about it. It would be great if somebody can prove me wrong.
It's seems the standard committee has decided to not move forward with N4447 (P0255R0 on the last iteration) in it's current form. I also don't totally agree with the design of the proposal described in the article (P0194R0) so I've started working on a proposal myself based on some ideas from the author of sqlpp11. Here's an early draft. Comments and questions are welcome: https://github.com/ricardofandrade/cpp-name-reflection/blob/master/README.md 
Yeah, this one seems to me like it's very low hanging fruit. 
Yeah on the mailing list the Kitware guys are staying purposefully silent. It sucks because the daemon would be great for every CMake user out there, but I guess Kitware does not want the additional maintenance burden. It's the same thing that happened when a language change was proposed (for Lua instead of the atrocity that is CmakeScript), they look like they don't want too much to change.
As a daily c++ user you (probably, depending on what your daily c++ looks like) won't use any of this _directly_. But you will use _all of this_ indirectly through libraries that use this directly: serialization libraries, data-layout libraries (seamless AoS to SoA), gui/signals libraries (Qt's moc), ... Compile-time reflection is mainly for library writers, so that they can build libraries that are easier to use and more powerful that what we currently have. You will use those libraries since they will be better than those that do not use reflection.
 Why do people use CMake anyway? I've tried reading various cmake build scripts and they are all unreadable piles of excrement. The docs are absolutely terrible. It uses a asinine custom language:| 
how does this compare to premake5? why do you not use an existing language like lua/python?
I started C++ about two decades ago, and at that time I simply viewed OOP as algorithms that own data. For starting, ignore inheritance, virtual functions, operators, templates and anything else that is not simply defining a class, instantiating objects and using them. Write some code that simply defines classes and instantiates objects (and consider classes to be simply structures of data, that also have functions associated with them). Then, tackle any of the above, one by one.
I agree, it's a pain, but it just works.
1. I would say that if this is a problem on some platforms, then the fix should be the same or similar as with the lambdas. 2. I'm not completely happy about the pointer-to-member syntax either. As a solution we would like to introduce "reversible reflection", from a metaobject you would be able to get back to the original declaration. The section "(5.3) Reversing reflection" of http://kifri.fri.uniza.sk/~chochlik/reflexpr/DxxxxR0.pdf discusses this. For data member pointers the syntax would be: `` using meta_member = reflexpr(myclass::data_member); myclass obj; obj.reflexpr(meta_member) = 123; `` we are still talking about if we should use the same operator (=reflexpr) or a different one. This thing would allow us to get rid of the `get_original_type`, `get_pointer`, and some other templates.
An approach suggested in SICP can be mirrored to C++: have a method which extracts typeinfo pointers from its arguments and uses them to look up method pointers in a table, and then invokes the methods with the original arguments. As is done in SICP, you still need to construct the table manually, but I feel it's cleaner than brute-force and it's not intrusive, unlike visitor.
/u/karies42 /u/k4rku14 I would really like to see a proof-of-concept implementation of a `soa_vector&lt;T&gt;` that takes e.g. a pod `T` (for simplicity), stores each of its member in a different `std::vector&lt;_&gt;`, and implements e.g. `push_back(T t)` and `proxy_ref&lt;T&gt; operator[](size_t)` where `proxy_ref&lt;T&gt;` implements the same interface as `T` (if `T` has a data member `int a` then `proxy_ref&lt;T&gt;` should have a data member `int&amp; a` that points to the element within a particular `std::vector&lt;_&gt;` inside the `soa_vector&lt;T&gt;`). AoS to SoA transformation was one of the main initial goals of SG7 and having that particular use case be addressed in the proposal would reassure me that the current proposal is in the good path for addressing all goals that SG7 has. 
It is more sane than autotools and works in non-POSIX OSes.
LOL. No more words than LOL. I'm still laughing after 5 minutes
Just don't learn OOP, it's complete bullshit. Also C++ may not be the best first language as it is overcomplicated.
Is the benchmark code available?
You are not alone. CMake is also immensely frustrating to me, and if you look around the community you'll quickly find a lot of people feeling the same way.
Yes, here: https://github.com/foonathan/memory/blob/master/test/benchmark.hpp https://github.com/foonathan/memory/blob/master/test/profiling.cpp (Boost Pool isn't in there, though. I've just added a tiny wrapper about the class and integrated it for the given results) The profiling isn't too advanced, just takes the minimum time of n iterations. And the point of the series is more to share how I optimized my code.
All my hobby projects are single headers after being exposed to CMake. Have you tried using premake? It uses Lua as it's scripting language.
Wow, reversible reflection looks super awesome. But isn't it conflicting with two-phase lookup, like how we need to write typename x::type or x.template f&lt;abc&gt; (), and reversible reflection allows much more complex expressions like namespaces to be determined during instantiation?
&gt; Am I right in assuming that the optimizations were driven by the benchmark results? Partly, I stopped doing optimizations when I've got the benchmark I wanted. But I didn't optimize by exploiting the benchmark patterns but by keeping the general usage scheme in mind. But the optimizations I did like ensuring better inlining and removing branches did make the code faster without disadvantages in a real-world scenario. So there isn't really a disadvantage in using the benchmark as indicator. &gt; And tbh, your benchmark is really bad because it doesn't reflect any real world usage pattern. Care to elaborate? I know that the patterns are artificial and will not occur in this pure form anywhere. But they will be occurring as part of the usage pattern.
What is Kitware's business model? Do they benefit directly from the complexity/difficulty in debugging?
I don't know. I guess they make money on trainings and support, since there is no monetization of CMake itself. So you could say they benefit from CMake being complex, but I don't honestly think that's it. 
We see the potential, but we are still thinking about the consequences. This is one of the things which we would like to discuss at the meeting in Oulu.
&gt;For those of you who use CMake, how did you guys learn it? Is there a better source? From my experience - you never truly "know" CMake. Every complicated build behavior forces you to stick with trial-and-error approach. Simple example - we have to pass some data to compiler with an environment variable. I spent ours finding a proper way to implement it, but ended up using horrible wrapper script which sets this variable before calling compiler. (There may be simpler solution, so feel free to enlighten me.)
For Lua, I think they were more worried about maintaining two projects. They are a company funded by consultation after all. Developing CMake is just a side project. That being said, I want the lua-based CMake. 
&gt; I always read about people doing stuff with open source code. Where can I find them, or what do I search for? The Architecture of Open Source Applications may be a nice resource: http://aosabook.org/ For instance, LLVM and Clang codebases use fairly readable C++; here's a write-up on LLVM: http://aosabook.org/en/llvm.html Another, performance oriented, example may be [pugixml](https://github.com/zeux/pugixml): http://aosabook.org/en/posa/parsing-xml-at-the-speed-of-light.html Other than that, I think the following two codebases are nice and readable: - Adobe Source Libraries: https://github.com/stlab/adobe_source_libraries - GAP Benchmark Suite: https://github.com/sbeamer/gapbs In particular, take a look at the source code files in https://github.com/stlab/adobe_source_libraries/tree/master/adobe/algorithm -- usually short and relatively self-contained, with brief explanatory comments: https://github.com/stlab/adobe_source_libraries/blob/master/adobe/algorithm/gather.hpp https://github.com/stlab/adobe_source_libraries/blob/master/adobe/algorithm/rotate.hpp As for the larger*, more advanced / performance-oriented projects, take a look at Seastar: https://github.com/scylladb/seastar *Although it also has some relatively self-contained source code examples, e.g., https://github.com/scylladb/seastar/blob/master/core/circular_buffer.hh Questions and answers at Code Review Stack Exchange can be another source : http://codereview.stackexchange.com/questions/tagged/c%2b%2b?sort=votes
&gt; Care to elaborate? &gt; I know that the patterns are artificial and will not occur in this pure form anywhere. But they will be occurring as part of the usage pattern. The problem with benchmarks like this is that they don't capture the side-effects arising from interactions with *other* code. For example... * cache-misses: very expensive, but your benchmark can't show that because there's nothing that can cause eviction of your data structures * branch-prediction: your benchmark is very predictable * concurrency: unexpected false-sharing issues might cause excessive cache-line bouncing between CPU cores * pipelining: latency-hiding is nice, but it can also artificially inflate the meassured throughput. Real world code might stall for arbitrary reasons, e.g. HyperThreading sometimes causes ordering violations that force the CPU to flush the pipeline.
I learned to like CMake even though it has many pitfalls. At first I was also constantly ranting about it but I tried to change it and that resulted in me developing a Cmake library which makes many tasks easier and through which I have become very good at it. https://github.com/toeb/cmakepp 
Just like you, I find it very frustrating. There is a copy of "Mastering CMake" on my desk, but that's one of the most pointless and poorly written technical books I've ever seen. Fortunately, there is a developer in my team who does understand CMake and everybody else just goes to him for anything non-trivial.
Recent CMake documentation is pretty decent and has plenty of examples. I'd start with https://cmake.org/cmake/help/v3.5/manual/cmake-buildsystem.7.html. Although CMake has a lot of features, you'll probably need a very small subset of them.
I don't think it would be two projects, CMake should support Lua scripts natively, and they would transition from supporting an in-house clusterfuck of a language (seriously, generator expressions ?) to just small bindings to Lua.
Uhm, what's bad about Azure?
screen is not an input device, so it is not relevant to what I'm responding to
&gt; No, they are not. They are bound to their types. There is no difference between a function bar() that requires a Foo* argument and a method Foo::bar(). The point is many functions use 2 (or more) types. e.g. we're talking about ```bar(Foo*, Baz*)``` vs ```Foo::bar(Baz*)``` The former is superior for decoupling (Foo doesn't depend on Baz, but bar depends on both; bar can go in separate source file). But The latter shows up in dot-autocomplete , reads &amp; writes better, so everyone wants to use that wherever possible.. leading to excessive coupling, messing up the project structure.. so you constantly have a battle between these two conflicting draws. With UFCS, you get the superior syntax and superior decoupling *simultaneously*. There's no ambiguity or conflict over which to use. It's 2016, other languages have this, *please please please* can we have this in C++. (and no, I can't just use another language, because we're stuck with the momentum of C++ in certain domains, and worse still, other languages usually use garbage collectors/JIT etc; I want native code &amp; deterministic allocation) &gt;&gt; What does that have to do with what we are discussing... The option of Virtual functions is another draw toward the ```Foo::bar(Baz*)``` option. A function might even start out as something virtual and you're the one who has to come in and clean it up. (I don't like them, but they do have their uses). &gt;&gt; Just move the method up the hierarchy. class 'hierarchies' are well known to be a *terrible* way of arranging source code. but most people like the method call syntax regardless (and you might try to fit classes to a heirarchy to try and workaround the decoupling issues, but it never works) . Free functions are superior in most situations.. but the syntax is inferior.. it's madness. newer languages use the traits or interfaces approach which works much better. Free functions are closer to that.(eventually C++ might get concept maps which are more like those too, and if you can just collect free functions into those, we'll have the ideal situation)
I've seen both longer and worse rants. Myself, I hate setting up build systems (too complicated to be easy to learn, too rarely interacted with for anything learned to sink in) and when I installed CLion, it straight-up refused to work with CMake.
I would urge you to use Qt instead. For one, it has a more long term viability.
I just looked at copperspice and it seems it is a refactoring of Qt to use modern C++ features. Have you run in to downsides of copperspice or just successfully used Qt?
Qt does make use of c++11 features, when available and there are discussions about dropping support for compiler not supporting c++11. Despite its age, Qt holds really well and is actively maintained ( hundreds of active maintainers) . and used in a lot of industries. Copperspice is maintained by a handful of people, based on Qt 4.8 ( so a relatively old version of Qt ). It only exists because "moc sucks" despite moc having a very small overhead and being supported by cmake ( + qmake + qbs + other of you take the time to set it up). So instead, they use ugly macros, and, lacking a proper meta object system, they can't do half of what Qt enables. I just don't get it.
Programmers make "above average" dough, that's some motivation maybe. Like someone else said in the comments: learning c++ as your first language is hard, try c#.
&gt; if he is to be flexible, then needs to learn oldskool C++98 and newskool C++14... if he does join a dev team which has oldskool code, etc... or new dev team with newskool code.. then OP will be more adaptable. I just can't agree with this. OP needs to learn how to program as a way to enable learning theory first and foremost. After that it's just a matter of getting familiar with the specific tech for a job. You will go crazy trying to make yourself adaptable enough for any job by learning languages. One of my biggest mistakes from college was not paying more attention to the theory in class and just focusing on using Python and C to try to bootstrap myself up to being functioning team member before I even knew what jobs I was applying for.
Agree. The documentation is precise. Who started that theme about fighting and hell?
copperspice is QT derived, right? Qt supports MSVC 2015 at least for 5.6. http://doc.qt.io/qt-5/supported-platforms.html Copperspice appears to be QT4 derived. I don't know if they support / test MSVC2015. I'd be interested in knowing what you find. - Steve the VC Dev Mgr
The basic problem (but I guess one could also consider it a feature) with CMake is that its too expressive as a language with multiple/infinite ways of how to achieve things. Like 95% of people are trying to solve the same issues, but there are no clear guidelines no conventions that tell you how to solve those issues. If you let two programmers design CMakefiles for the same (non-trivial) project, they'll look _completely_ different. I firmly believe it would be better to a build system that has _one_ good default way of doing things, where multiple people trying to solve the same thing end up with more or less the same thing...
AFAIK, copperspice rely on latest language features to avoid moc. This features (not sure which, perhaps extended constexpr or some case of sfinae) were not yet implemented in vc.. don't know if this apply also for 2015 update 2 as I'm not sure what is missing. 
Please, **please** use references where appropriate. It is C**++** FFS!
I said this before and completely agree...
declare != define void fun1(); // declare void fun2(); // declare void fun1() { fun2(); } // define
which 1 declare first if both call each other.thats my doubt?
Oh, that makes sense. How do I contribute? I searched KDE and went on the website but I don't get how to start contributing to the project.
&gt; Build small libs in subdirectories and then several apps in subdirs all in the same project dir. It seems to want everything as independent projects. I don't understand what you mean here. Having a single 'project' with subdirectories for libs and exes works just fine in CMake. What is it that's different about your style of building/linking?
Thanks for the response. Sorry about posting in the wrong section, I'll make a note of that and thank you for not down voting me. Thank you for the support and advice I really appreciate it.
That sounds like a question rather than a doubt.
But isn't OOP in high demand in the market? I would like to be competitive in the market and school as well. Yeah, I understand that but unfortunately it's the language that will be used in my University as well as my CC. =/
I blame C++'s terrible error messages. They're fucking awful. 
Thanks for the response! I'm currently reading Gaddis Starting Out With C++ and up to Ch 15, I've found quite a few mistakes in there (it is the 8th edition so I'm sure there was plenty more). Definitely will do that, I actually downloaded C++ Primer last night and hopefully put it to good use. Thanks for all your advice! I really appreciate it!
Wow, thank you for your resources! I really appreciate it!
Keep learning C++, I am. Today I realized how stupid it looks to write code on paper. Looks like the scribbles of a madman. Because normally i just write text, not symbols.
This post might be useful for x amount of people.
And the troll again demands an apology... Don't you ever get bored of your own tired bullshit?
Reading between the lines I'll assume the answer is the latter.
I don't understand, what distinguishes this exactly from `std::function`? You can pass around a `std::function` that's captured a pointer to an object (or not); it seems to provide exactly the same utility.
Last time I asked for modern CMake resources here on Reddit, multiple people gave me this link: http://purplekarrot.net/blog/cmake-introduction-and-best-practices.html I haven't yet followed up on reading through it, so I can't attest to its quality personally, but there you go.
The downside is that it's a fork of Qt 4.8 – if it were based on the 5.x codebase it would be _far_ more appealing... (One other downside is that Copperspice-based binaries are significantly larger than Qt-based binaries; not something _I_ care much about, but worth mentioning.)
yeah, that book is a joke - it's basically the website docs printed on paper.
I've been using C++ now since the early 90's. There was a time that I fashioned myself as an expert, but now the language has become so large that I find that I'm always learning something new. I accept that I'll never grok the entirety of the language again, but that's ok. To be honest, I enjoy that aspect. It makes me feel like a treasure hunter when I find some precious nugget buried in the standard. That, and it keeps me on my toes.
Ah! [Here](http://open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3601.html) is the original proposal and [this one](http://open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4469.html) modifies it. It [looks like](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/) there is no disposition yet.
Different people learn differently. For me, I love C++ for its complexity. I enjoy reading every bit and piece about things like the rule of three (now known as the rule of five or zero!), RAII, and various template tricks and so on. I've always been fascinated by all the tidbits and *magic* of the language. Now I don't think this approach will help you with programming all that much in general (it will certainly teach you everything about the language in due time, and once you're comfortable and confident with C++, everything else becomes easier). But yeah, I think an easier-to-use language might help you achieve that. For example Java might help you pick up the rudimentary OOP concept much more quickly than C++.
You started the hard way, learn first Java or C# and make with that lenguages the classic mistakes all did when starting like nullpointerexceptions or arrayboundofindex When you learned switch to C++ and it will be much more easy
What linkage issue?
I also noticed that, in the "vanilla C ABI", they have two overloaded versions of QuickSort.
&gt; Well, I did make that comment on the article I don't see the word 'linkage' in the article, nor any reference to UB. &gt; Also, if it is supported as an extension and it is documented then it is not undefined behavior for the compiler that officially support it. I agree, but I'm not aware of it being documented for any compiler, yet I know it "just works" with VC++, GCC, and Clang. VC++ documents that lambdas convert to function pointers of any calling convention, but no mention of linkage is made. EDIT: It's worth noting that in C++11 the standard did not specify the language linkage for captureless lambdas' implicit function pointers, so I assume that most compilers implemented support for C and C++ linkage from the beginning. DR1557 and C++14 then changed the wording such that the language linkage is explicitly 'C++', so this "extension" was likely grandfathered in for free but unfortunately remained undocumented (speculation on my part). EDIT2: I see in the comments you say "*It’s ABI portable. The call made is still a regular C function call – all the lambda guck stays at the call site*" but I don't really know what you mean here. In any case, it's the code `QuickSort(elems, elem_count, sizeof elems[0], compare_closure, &amp;f);` that would yield UB if `QuickCompareFuncReentrant` were correctly declared to have C linkage, since `compare_closure` can only convert to a function pointer with C++ linkage.
The article is not saying you should write your libraries this or that way; the point is that if you want to pass C++ closures through a C callback ABI, this is a way to achieve that that is type-safe and transparent to client code.
&gt; link to non-trivial examples of design patterns in open-source projects. There's [OpenSceneGraph](http://www.openscenegraph.org/), which makes use of a bunch of GoF patterns, including the visitor. Sources on [github](https://github.com/openscenegraph/OpenSceneGraph).
As far as I know, only Solaris actually uses a different ABI for `extern "C"`.
I just realized the comments I made to the article are awaiting moderation. In one of my comments I pointed out [defect report 1557]( http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_defects.html#1557) which clarified the linkage which was previously unspecified. 
I didn't pick up programming until I was 20, and I didn't really get serious until I was 21-22. I'm 23 now and I'll be graduating college in a year. I am by no means an expert, but compared to these students, I am. literally 2/3rds of the students in my classes don't have any sort of serious motivation to be programmers, which is fine, but this is what you are up against. If you like to program, then it will come to you over time through your own motivation. It's really all about your own drive. But life doesn't begin and end with programming. I am not trying to simply broadcast my projects, but if you are interested in learning about video game emulation and creating UI's with c++ and Qt, I could help ya with that. https://github.com/team-phoenix/Phoenix
Fair point. But it's a crappy language. Good thing is it will lay ground for binding other languages. 
Thanks for responding, Yeah, I guess I fail to understand that I'm still a noob and this is a discipline that takes time. It's just that I always see stories of people starting at such a young age, it's like trying to become an NBA player and never picked up a basketball until you were 21 (if that makes any sense at all lol). Oh, believe me, I've figured that out after the first grading session. I don't even show up to class, it's literally the most quietest room in the world. She does not teach, nobody asks questions there's seriously no help. I just use the book and forums whenever I run into serious trouble. I definitely do, but I must admit I have slacked on these last couple of chapters (structures - now OOP). I do extremely well, A in first intro class and I have a 99.21 at the moment for my second one, and she tries to ruin my grade because she can't have everyone have A's apparently that's what I've been told. Haha, yup, he's a teacher at the University I plan on going to, Texas A&amp;M. Thanks for your informative response, I really appreciate it!
What the fuck is your problem? How can you be this much on an aggressive cunt over a tiny bit of criticism? You used the language incorrectly. I, in a jovial manner, suggested you should learn the language a bit better. And what do you do? You fly off the handle at me and suggest I should get into a chainsaw accident and have my hands cut off. I mean holy shit, how do you think that is acceptable? How would that ever be an acceptable way to respond to criticism? 
I second the Emacs suggestion! However, I would always recommend going rtags instead of irony-mode. irony-mode is easier to setup, but focuses on completion, whilst rtags will give you completion and navigation. BTW, on a large Qt project I'm working on, I regularly use emacs+rtags instead of QtCreator. See https://vxlabs.com/2016/04/11/step-by-step-guide-to-c-navigation-and-completion-with-emacs-and-the-clang-based-rtags/ for a guide on setting up rtags with emacs.
The major obstacle here is that we currently cannot create identifiers "programmatically" (without the preprocessor). There are some partial workarounds for this (see for example N4111, section 2.6.4, p.20) or we need some mechanism for turning compile-time strings to identifiers (as discussed for example in N4452 appendix A.4 (p.27) and in several other proposals). I'll describe this in a more detail in the upcoming paper.
One of the requirements is the possibility to remove delegate. `std::function` doesn't have comparison operator.
The M. Smith comment says it all. http://imgur.com/06QrGuN
&gt; What is Kitware's business model? Do they benefit directly from the complexity/difficulty in debugging? As far as I understand, CMake is tangent to Kitware's main domain which is medical data visualization, with [VTK](http://www.vtk.org/), [ITK](http://www.itk.org/), [ParaView](http://www.paraview.org/)...
why not JS ? 
https://rix0r.nl/blog/2015/08/13/cmake-guide/
Bloomberg presented some extensive Allocator Benchmarks that aim to simmulate real world usage patterns at the last standardization meeting: [P0089](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0089r1.pdf) and [P0213](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0213r0.pdf)
I really like the new UI. I don't know about windows but on linux the clang model is really responsive. Make sure the sources are on a fast SSD drive. But for me the best of this release is the clang static analyser and the improved diagnostic you get without even have to build. Seems more stable too.
I started out learning C, then learned C++ four years on, and found OOP initially hard to grasp--it's a very different way of thinking about programming than purely procedural/imperative logic, and I had to "unlearn" some things to make progress. You also see the same thing from the opposite side with e.g. Java programmers who *only* understand OOP and can't think in any other terms. But I think it's OK to struggle with problems. Even nearly 20 years in, I'm always coming across problems, spending time to understand and solve them, and then once solved and implemented, moving on to the next. Some are mundane, some are interesting, and some are plain difficult. But the nature of programming is solving problems; if you enjoy that and retain your motivation, then you'll likely do just fine. I think you probably need to start worrying when there aren't any problems, because that's when boredom sets in and motivation drops (depending upon what motivates you). That's usually the point when you need to find a new position with new challenges!
Not sure why we're downvoted, but thanks for the rtags tip, I switched and will see how it works for me.
That's probably not true. The ApiSchemaSet redirection is at the OS level - re-routing linkage to dll's like KernelBase, ntdll, kernel32 etc. The C++ layers (ucrtbase and siblings) are high, high above that - and there is no API-set involved in resolving their linkage. 
Honestly, it's not *that bad*. I used the GNU autotools for 15 years. CMake replaces a minimum of five languages and many separate tools with a single language and a single tool that works everywhere. No matter how awful CMake might be, it's an order of magnitude simpler, robust, and better documented than the autotools ever were, and it's actively maintained and works for all contemporary platforms. I've also had the misfortune to use SCons. If you want a bucket of parts from which to assemble your own unique and nonportable build system, it might be OK. But CMake is again a significant improvement. This is not to underemphasise that: - The CMake scripting language is baroque - The initial tutorial documentation could be better - CMake best practices have changed over time; stuff like imported targets and configuration export which are fine to use for CMake &gt;= 3.2 but in 2.8 were unheard of, but are still not widely publicised as the recommended way to do things But the scripting language is perfectly serviceable for its intended use. Initially, I spent a few days converting a large autotools project to CMake; the autotools project made heavy use of most of its features and had lots of custom macros, and this was an intense learning experience. Later, I converted a couple of SCons projects. Once I'd read through a few CMake-using projects and tutorials to get the gist of how it basically operated and what was done in common practice, I found the docs perfectly usable as a *reference*. But over the next few months I found useful new bits to use to improve things. Today, I have large projects building on FreeBSD, Linux, MacOSX and Windows, including shared libraries, tools, programs, documentation. That's a significant achievement for a build system. While there might be other systems out there which improve upon CMake, learning and committing to using a build system is a large investment of time and effort. I made the switch 2.5 years back after researching all of the options. I still think it was the correct choice, and I expect I'll be using it for the next five at a minimum. To respond to the other comments about it being trial and error, if you're doing that then it's a sign that you don't understand the tool and need to read the documentation and/or ask some questions on the mailing list. I understand what every single line in my CMake scripts are for; if I didn't, I'd be worried.
I would still strive for a byte based approach, as [utf8everywhere](http://utf8everywhere.org/) proposes!
The primary documentation is reference material. It makes sense to refer to once you understand how the system as a whole works. So if I need to use e.g. `file(...)` or `execute_process`, then I can do straight to the `cmake-commands` manpage and read which arguments I need. But first I need to know which commands I want to use, and that part I found by - reading other projects `CMakeLists.txt` files - reading all the reference material to get a full overview of all the pieces - reading some of the CMake macros under `Modules/` to see how the macro language and features are used internally by CMake itself
sorry for spam, but recently I've written a post about microbenchmarking libraries: Nonius, Celero, Hayai... there is also a google benchmark lib. the post it located here: http://www.bfilipek.com/2016/01/micro-benchmarking-libraries-for-c.html so maybe you could use those frameworks in your benchmarks?
Why does my mouth taste like coffee after reading this?
I'm on the freenode server on irc, my channel is #phoenix-dev. I go by the same name as Druage and I go to Wayne state. It's a uni in Detroit. I thought the exact same thing as you, which is why I started a lot of side projects. On Reddit you may feel like everyone is doing side projects, but most uni students aren't. And ya we are a fun group, I actually had to learn c++ to do my project, and before that I didn't know anything.
if you want to be best and adaptable, then you can try learning oldskool and newskool C++ at the same time. it appears newskool... looks daunting at first, but I heard it's easier/better to program in the end. the only disadvantage I can think of is backwards compatibility. what if you needed to compile on an old linux box which only has C++98 tools, etc. also, I think all console/games companies use C/oldskool C++ at the moment (I haven't heard much big things about them using newskool C++... but it is possible for them). maybe you want to look into 1990-2000 open source games like Quake, Duke Nukem 3D, etc. as a hobby. but then again, if you land a job where they've already written everything in newskool C++.. .then be prepared. 
Their docs for OSX app bundles are pretty bad. I expect to have to read both CMake and Apple's docs to get it, but I don't even get a hint on what to cross-reference between CMake and Apple. The language guide for the CMake language was really good. It made me throw up in my mouth a little bit (quoting and conditionals...wow), but was clear.
How is removing a delegate not equivalent to just assigning a `std::function` to the default constructor? `std::function` does not have a comparison operator for good reasons as /u/cdglove mentioned. Your delegate does not try to use `==` for the underlying type in the functor case, so you do identity based comparison, which will typically be false, even if a user e.g. creates two delegates from the same stateless functor. If you want a comparison operator that is guaranteed to be correct for the function case, you can do it with `std::function` provided that RTTI is enabled. This delegate does not allow inlining any more or any less than `std::function`. The delegate is calling a function pointer which will not be inlined. `std::function` however will avoid one layer of indirection that your delegate will not; because of the small function optimization, small pieces of state will be stored inline with the `std::function`. Anyhow, I'm certainly not claiming that `std::function` is perfect for all use cases. But I think your post would have been better served by explicitly comparing to `std::function` from the get go and explaining the motivation. As it is, I was reading your post waiting for the "punch line" to see why you were rewriting `std::function` without mentioning it by name.
Your post has been automatically removed because it appears to be help/homework related. If this has been in error please message the moderators. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
You enable the clang code model in help&gt;About plugins and restart Creator.
##### Qt Charts &lt;- Killer feature? Previously commercial-only Qt Charts module is now included in Qt under also GPLv3 license for open source users ##### Qt Data Visualization Previously commercial-only Qt Data Visualization module is now included in Qt under also GPLv3 license for open source users ##### Qt Virtual Keyboard Previously commercial-only Qt Virtual Keyboard module is now included in Qt under also GPLv3 license for open source users 
&gt; This article confuses me insofar as it seems entirely predicated on the idea that qsort is superior to std::sort, other than type safety Generally games reimplement parts of the standard library like this to ensure that they remain consistent across multiple compilers. Historically, some consoles' standard libraries weren't that great; they'd have bugs, different performance profiles etc, and it'd mean the game's performance would be inconsistent. Reimplementing bits like algorithms and containers mean that you can get exactly the same results on every platform, as well as take advantage of more specific optimisations that the standard library might not be able to perform due to its need to work with an inspecific domain of application..
You just have to find some projects that you enjoy coding in. Game development is what got me to learn c++ originally. Music, art or useful utilities are other potential exciting things are great for learning. GUI libraries like Qt also use OOP extensively. Personally I find learning by experience much easier than theory. Once you have a project that benefits greatly from OOP you'll pick it up much quicker.
&gt;the optimization (from doing codeset conversion in bulk instead of a character at a time) is probably minimal The optimization is actually huge. &gt; Most of the virtual function calls involved are required to be "pure", so (for example) when you imbue a stream with a locale, the stream can walk through the possible values of a charT for that stream, and build a table of the translated value for each. That's totally impractical for most values of CharT. EDIT: And is also totally incorrect when you are considering unicode and combining characters. Not that iostreams gives you any way to handle those correctly anyway.
Clang code model should work better than it does on Windows, especially when you use Visual C++ to compile your code. Visual C++ system headers take more computational power from clang to parse them. Also you might want to do a PGO build of libclang, trained with your project code. You might get a [40% performance boost](https://cristianadam.eu/20160104/speeding-up-libclang-on-windows/)
I found it quite disappointing that N4447 is not likely to be accepted. I don't understand what's appealing with `std::thing&lt;1&gt;::nameof&lt;B&gt;::otherstuff` And the worse, you can't unpack it without indexes, which is less than bad to work with. What's wrong with something simple as `typename&lt;A, is_member_pointer&gt;...` ? Is there a reason this proposal hasn't got as much attention as the others?
&gt; there are discussions about dropping support for compiler not supporting c++11 This has actually progressed past discussions. Pre-C++11 compilers will no longer be supported as of Qt 5.7, which is currently in beta, and will be released soon. There won't be huge API changes immediately, but new work will likely be done in a more modern style moving forward.
I wonder how it performs compared to netty.. 
You have a **very** loose understanding of the word "full".
&gt;*Windows systems have been gradually shifting towards Unicode* but UTF-8 console output might still require a call to specify the code page to be used (SetConsoleOutputCP). The italics part is really false, Windows supports Unicode really well since a *long* time. The second part speaks of UTF-8 *encoding*, not about Unicode. &gt;Compilers by default document their binary encoding when storing string literals (gcc has the -fexec-charset option while MSVC uses the appropriate machine’s encoding). This setting is not affected in MSVC by the “multi-byte character set” or “unicode” in the project property pane that just switches headers to use wide APIs or not. I *think* that MSVC simply uses user-specified codepage for the text, so whatever you type (feel free to correct me, I might learn something!) The charset property, however, switches the use of the whole runtime library form the one with MBCS flavor to the one with UTF-16 flavor. (Yes, there's two of them, and you also get debug/retail, and you get 32/64 bit ones, and there's static/dynamic. So MS builds this in 16 flavors, whereas on Unix you only need 8 flavors :-)).
Firstly, this isn't a copy elision context. In general, the compiler may perform any optimization which does not change the observable behaviour of the program. (Copy elision is separate to that rule). In your program this suggested optimization *would* change the observable behaviour, because your program specifies that `"copy constructor\n";` be printed. However if you removed that output line, then theoretically the compiler could move the object. (But so far as I know, no compiler actively does this sort of optimization - perhaps that's an indication that there is not much demand for it). 
&gt; the following simple code can prevent NRVO depending on implementation In C++14 (and earlier) NRVO only happens when the return expression is exactly the name of an object (or that name parenthesized). It must not happen in your example; that would indicate a compiler bug. 
It's pretty useful though. 
I've added new subsection (4.9 "Structure data member transformations") to http://kifri.fri.uniza.sk/~chochlik/reflexpr/DxxxxR0.pdf discussing this use case.
Article author here. Thanks for pointing that out, I've edited the paragraph since I do care for correctness. I meant to have readers aware of [console code pages](https://msdn.microsoft.com/en-us/library/ms682064.aspx) on a windows system but I agree that the sentence was wrong (to be honest in the first unrelated part I was thinking of MSVC and *C++11+ unicode* support, sorry about that). Unfortunately some of the snippets provided in the article aren't working in MSVC 2015 Update 2 while they do in clang and gcc, I haven't double checked but if I recall correctly they should be related to known issues.
/u/foonathan this is nice, would it be possible to include these benchmarks? Some comments: - Is there a header only version of your library? - Not having a compile component lowers the barrier of entry: it makes it easier to integrate into an existing project and if compile-time turns out to be a problem one can invest into build-system changes after knowing that the library is useful. - It would also solve the inlining problems in compilers without LTO. - Second: you can try to assert your preconditions and post conditions in function entry and exit _in debug mode_, but instead of disabling them in _release mode_ you can replace the assertions by `__builtin_assume(expr)` to hint the optimizer that the `expr` is true, which might help the optimizer in the absence of good PGO. And well more assertions are always better. Like this they makes your code more robust in debug mode and faster in release mode :) - Third: you can try `__builtin_expect` to hint the compiler which branch is expected to be taken more often, mainly when handling errors if the error conditions should not happen often. - Fourth: you can try marking some code paths as `cold` to avoid them being inlined improving instruction cache usage. For example if you had a vector `push_back` implementation, growing the vector does not happen often and involves a lot of code. You can hint the compiler that the branch is not taken often using `__builtin_expect` and then wrap the call to `grow` in a lambda whose `operator()` is marked with the `[[cold]]` attribute to avoid inlining `grow`. If you want to try all these builtins you should obviously wrap them in macros, and allow users to enable disable them which would also help you with benchmarking the effects of all these builtins on your benchmarks. You can find some implementations of these macros [here](https://github.com/gnzlbg/hm3/tree/merge_old_fv/include/hm3/utility/config).
Thanks for the feedback! I edited the sentence and I *suppose* you're correct regarding the codepage used. More on the charset property can be [found here](https://msdn.microsoft.com/en-us/library/8x480de8.aspx) &gt; Character Set &gt; &gt; Defines whether _UNICODE or _MBCS should be set. Also affects the linker entry point where appropriate.
&gt; would it be possible to include these benchmarks? I'll see what I can do. But it will take some time. &gt; Is there a header only version of your library? Currently not. I might add it in the future. &gt; __builtin_assume(expr) Didn't know about the GCC version thought only MSVC had it. I'll add it for the next issue. &gt; __builtin_expect &gt; [[cold]] I once heard that these had almost no effect, will look it into it. &gt; If you want to try all these builtins you should obviously wrap them in macros, and allow users to enable disable them which would also help you with benchmarking the effects of all these builtins on your benchmarks. I will most likely add them to my compatiblity library: github.com/foonathan/compatibility 
&gt; Yep, but it's important. &gt; Profiling during real world usage :) I'll see what I can do.
I'll look it into it.
https://www.youtube.com/watch?v=pjkJY7qZy5k found by typing "qt5 beaglebone" on google.
Just curious. Why do you consider yet another set of template meta-funcs instead of utilizing constexpr funcs? The latter would provide us with a more convenient syntax, also allowing to reuse existing control flow constructs. Like, `reflexp(...)` would return some object which exists at compile-time only, and cannot be brought into run-time. Then, we can have some methods on that object, or free constexpr functions. Like: `constexpr auto type_name = reflexpr(T).get_full_name()` So basically we'd have extension atop constexpr functions which would introduce expression types at compile time - with ability to both analyze them and construct. Would be a direct mapping of meta-programming concept. What were the downsides of such approach so that you discarded it?
I mostly use trailing underscores, i.e. `name_`. &gt; I'd like to avoid having two separate names since those variables really mean the same thing In cases like `storeParams` I'd just make the variables public. Trivial getter/setter don't add any value.
As /u/dodheim says, one underscore prefix followed by a non-capital is perfectly fine to do, people who think it's reserved haven't read the standard. My personal preference is just that, non-public data members start with a single underscore. It's much easier for me to parse in my head that `_something` is an internal member, whereas `m_something` I initially interpret as "m something" before I arrive at "ah, *member* something". Also gives me horrible hungarian notation flashbacks where the variable name is more annotation than usable words. 
Witness me frowning upon it! I will never accept "m_", it's super annoying to read.
Where is the RSS?
I can't say I particularly like the m there, but it does its job of a short way to convey that this is a shared mutable variable, like g_ for globals. 
What you do doesn't matter too much - the most important thing is to stay consistent and to obey your style guide.
It isn’t popular, but I’ve always liked this convention... a_foo: local my_foo: member our_foo: static member the_foo: global or static local
I'd suggest to use the MFC naming convention since: 1. You have to use a naming convention to prevent bugs and make the code clear 2. I'd suggest to use a commonly-used convention (e.g.MFC) since it will be clear to another developer if you'll transfer your code to someone.
Depending to whom you talk that might be a good or bad thing. Which one is it for you?
I usually follow Google's rule. I find it intuitive. https://google.github.io/styleguide/cppguide.html#General_Naming_Rules
[nano-signal-slot](https://github.com/NoAvailableAlias/nano-signal-slot) is the library I'm currently using for this. Seems to utilise the same technique as the OP.
&gt; I'd just make the variables public. Trivial getter/setter don't add any value. Besides [Google](https://google.github.io/styleguide/cppguide.html#Access_Control), [WebKit](https://webkit.org/code-style-guidelines/#names-data-members), and [C++ Core Guidelines](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#c134-ensure-all-non-const-data-members-have-the-same-access-level) advertising making data members of a class private I would argue that the even trivial setters/getters are useful because having a trivial setter/getter in the first place allows for changing the implementation later down the road.
How about not mixing data and logic? With well defined structs as data objects and classes that only expose idiomatic methods you still have that benefit and avoid the problems of exposing your internals, even if that is done through accessors.
I'm not a fan of the Java way of doing things, so no thank you :)
If you're talking about [Anemic Model](https://en.wikipedia.org/wiki/Anemic_domain_model) vs [GRASP's Information Expert](https://en.wikipedia.org/wiki/GRASP_\(object-oriented_design\)#Information_expert) or procedural vs object oriented approach, let's just agree that with C++ being a multi-paradigm language there's more than one way to accomplish the same thing.
Am I the only one that doesn't think you need any prefix or suffix at all? Go ahead and give 'em the same name, I say.
Well, that was the intention - you created two different objects which can have different states.
MFC is pretty clear to me; That said, I'd never use it for new code. MFC has a few glaring problems: - the hungarian convention used for type names is really really bad, as it adds detail you will likely not use and that imposes extra effort on refactoring. - the adnotation of variables with a shortcut only makes sense for semantic (not syntactic) purpose: that is for an index of an array of `Person`, `nIndex` is terribly bad; `idxPerson` is much better (idx tells you it's an index, and the rest, where it will be used. - ItsBloodyDifficultToReadUntilYouGetUsedToIt. All in all, I prefer snake_case, with no prefixing of variables (because it matches the standard library and because its_much_much_easier_to_read_for_humans). I do postfix my members with an underscore though.
Rewriting the library has nothing to do with whether you use the C style (type erased with void*) or the C++ style (strongly typed with templates). On your point, I can imagine this had more truth historically, but it's pretty hard to imagine justifying it now. gcc and msvc between them cover almost every imaginable platform, and both have very high quality implementations of sort and various other algorithms. Domain specific optimizations are nice, but they're not going to make up for a trivial comparator function not being inlined.
If `std::any` were to support move-only types, what would its copy constructor look like? There's a few options, all of them bad: * not provided (= delete): this would penalize programmers who want to use it with copyable types * copy copyable types, throw/terminate on noncopyable types: this would be confusing and dangerous * copy copyable types, steal on noncopyable types: this is bad for the reasons the old auto_ptr was bad * copy copyable types, share (reference-count) noncopyable types: this is inconsistent. You're better off writing your own type with either a deleted copy constructor or shared semantics; this could be called `unique_any` or `shared_any` respectively.
Notably this document was edited by Stroustroup and Sutter. Long, but well worth a look through.
With underscore prefixes are are likely to step into reserved identifiers. Using underscore suffixes are OK though and that's what I use for class member names. I got an idea from [Google C++ style guide](https://google.github.io/styleguide/cppguide.html#Variable_Names).
&gt; The sets of rules have not been thoroughly checked for &gt; completeness, consistency, or enforceability. No kidding... &gt; Triple question marks (???) mark known missing information Oh, so it's TRIPLE question marks, eh? They should do an animation like the swirling stars and planets that cartoon characters have when they get bonked on the head. &gt; Update reference sections; many pre-C++11 sources are too old. Heh. Yep, those are the C++ *core guidelines* alright. An hilariously apropos introduction. 
**Company**: [TSS-Transport Simulation Systems](https://www.aimsun.com) **Type**: Full Time **Description**: Your job will be to work on the user interface and core services of the Aimsun traffic modelling software, used by traffic engineers in over 70 countries. **Location**: Barcelona **Remote**: No **Visa Sponsorship**: No **Technologies**: C++11 (a must) and Qt (nice to have). Windows, Mac or Linux, this is up to you. **Contact**: jobs@aimsun.com 
While not all necessarily applicable to this implementation, there are plenty of reasons that folks like me replace std::function: - support move-only functors (e.g. lambdas that capture move-only values) - predictable and controllable allocation or disabling allocation entirely - predictable overhead across all implementations for cross-platform projects - compatibility with pre-C++11 implementations - smaller, simpler, easier to read, and faster to compile header dependencies The delegate in our game engine, for instance, never ever allocates space for "large" functors (it takes the embedded buffer size in words as an optional template argument), is move-only and so supports move-only functors, takes only ~200 lines of very easy to read code, and meets our perf requirements on all target platforms and their respective vendor-supplied compilers. There's frequent discussion of supplementing std::function in the standard in the SG14 "Games &amp; Low Latency" study group for at least the reasons above.
Ok, I don't get your sense of "humor". To have core guidelines are long overdue, I'm glad they get written, collaborative that is. &gt; Yep, those are the C++ core guidelines alright. An hilariously apropos introduction. Yes, as everyone knows, your publications were 100% right, complete and up to date on the spot. Oh wait... do you even have any? 
Correct, guaranteed per `[expr.sizeof]/p1`. Fixed. Thanks!
Oh, I've never even heard of KDE =/. I have windows and Mac.
How is that a smart idea!? Say that you process international text and therefore use ICU. Every time you get something from it, you convert to UTF-8, and back to UTF-16 when you pass it stuff (not really, ICU does it for you, but the work is done). Goodbye performance (and hello busywork). Or, are you suggesting that everywhere where any of these line platforms can be or already are used, people should rewrite whatever they do from scratch? Utf8everywhere is a fools errand in so many situations.
&gt; Oh wait... do you even have any? Your comment doesn't need this ad hominem.
So it's a work in progress. I'm glad they posted it in its incomplete state.
I mean, isn't the point of it being on GitHub so that people can help finish it quicker? How is that not better than waiting for one or two busy people to finish it alone?
thank you!
please send us an email at itodirel at microsoft dot com
please send us a mail at itodirel at microsoft dot com
Converting **input** and **output** from one encoding into another is done within most languages with an internal unicode data type. That works perfectly fine! Where do you see performance issues **in general**? I always feel that lots of C++ guys prefer premature optimization because they always tend to have fear of lossing some cpu cycles... of cource you can always find some corner case, but hey, this is not abaout number crunching, right? ;-)
Who are you talking to? lol
`m_` is not Hungarian notation. Hungarian notation is prefixing a variable name with its type abbreviation, e.g. `char const ** pszFileName`, where `psz` means "pointer to a NULL-terminated string". Microsoft really took it to heart for their C++ code. However, Microsoft didn't continue to use or advocate Hungarian notation for C# code, which can be either viewed as their admission that statically typed languages don't need Hungarian notation, or perhaps it happened because Charles Simonyi wasn't around any longer.
&gt; Hungarian notation is prefixing a variable name with its type abbreviation That's 'Systems Hungarian'; IME 'Apps Hungarian', where the variable name is prefixed with its semantic/intended use rather than data type, is more widespread (likely because it's what MSFT uses). &gt; Microsoft didn't continue to use or advocate Hungarian notation for C# code, which can be either viewed as their admission that statically typed languages don't need Hungarian notation, or perhaps it happened because Charles Simonyi wasn't around any longer I think it had more to do with pushing the IDE and IntelliSense so hard as a fundamental part of the development experience (e.g. you can see all the type info and documentation in tooltips), and Hejlsberg's famously strong personal dislike.
* [Link to the actual guidelines](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md) * [Link to web version of the guidelines (slightly older, easier reading)](http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines)
 - [Link to the accompanying code, the Guidelines Support Library (GSL)](https://github.com/Microsoft/GSL)
No. setjmp/longjmp is as close as the Standard gets to this. As a question with a direct answer, this is more suited for /r/cpp_questions.
https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#Rl-name
&gt; NL.7: Make the length of a name roughly proportional to the length of its scope &gt; Rationale: ??? &gt; Example: ??? &gt; Enforcement: ??? A solid idea there... That being said it does kind of make sense. The more spread out the usage is the more explicit the name needs to be.
Yup, that's the difference between sys and apps Hungarian. 
Clickbait
"Names with long scopes should be descriptive and specific" Would be a more to the point recommendation as there is no major harm in having a long name for something with a short scope.
As the sidebar advises, this subreddit is not a good place to ask questions with specific answers, especially about non-Standard libraries. You should probably ask StackOverflow.
Package management would tie really well into it. But that's more about managing 3rd party dependencies and the like. I was talking more about `go build` and not `go get`. Sutter talked about some package management we where supposed to be getting based on nuget a few years back but I don't think anything happened with that... Plus I don't see it being really cross platform. Other than that there where a few attempts that didn't seem to really get traction.
Isn't one of the major things they say is "if you can use the GSL do these otherwise don't worry about it"?
There sometimes is, excessive verbosity can lead to reduced density which can make understanding the logic harder. That isn't to say that the length of the scope should be your only factor, just an easy starting point. Feel free to use a decent name when there is ambiguity but try to avoid being too wordy with a value that only exists for three lines of code otherwise. EDIT: I wrote this as kind of a pure counterpoint and realized it came off a bit too harsh against verbosity. It is a nuanced thought and length of scope is only one of the considerations in how long things are.
Actually you can use cmake like that (since 3.4.0) With options --config and --build
Can you recommend any in particular? 
Ian't the point of std::any that it doesn't behave differently for different contents? It's just std::any not std::any&lt;T&gt; once it's constructed.
I was expecting this response. From my experience programmers seem to be fairly evenly divided on whether verbose naming increases or decreases readability. It's really just a matter of personal preference. Not everyone reads and thinks in the same way. Much of the Core Guidelines are VERY subjective. However, that is OKAY!! They're just mainly loose rules for new programmers anyways. There are a few items I will be blatantly be violating. For instance, the benefit I get in readability from enums in all caps far outweighs the microscopic teeny tiny minuscule risk that one will conflict with a system macro. I have 1000s of enums in my code (no exageration) and only a single instance of a macro conflict, which text editor identified instantly. However, if you work in a domain that interfaces with enormous volumes of old c-style code you'll likely have a very different take on the matter.
The magic incantation involves `_O_U16TEXT`, see https://msdn.microsoft.com/en-us/library/tw4k6df8.aspx . This was implemented back in VS 2005 and I rediscovered it years ago, then got MSDN to properly document it.
Sorry, so not the CRT then - but the standard library stuff. I wrote CRT/STL. Whatever is in there! :-)
I mainly just want them to add this stuff to the STL. If these are such great, probably necessary features, they should give them to us.
Behave like the code around. If you don't have any, behave like the largest helper lib you use. If you don't have that, pick whatever and stick to it. Which one you choose is relevant only to deranged idiots. My personal preference: varName\_. But I would never defend it anywhere. I would also attack anyone who wants to bring their own against the team's will. Finally, if it was up to me to decide, I Would roll a dice between candidates.
If I remember correctly (I cannot find it in the notes), the study group was concerned about the cost for compilers; these aggregates (even if constexpr) have a different performance pattern for ASTs than a traits-based approach.
Also, note that Kate Gregory (author of the linked article) will have a two-day class on the Guidelines at this year's CppCon. You can register for the conference and the class here: https://www.eventbrite.com/e/cppcon-2016-registration-18889615348. Information on CppCon at http://cppcon.org
Effective Modern C++ by Scott Meyers and IMO the thing that sets C++ apart is the metaprogramming, i.e. templates.
They are adding this stuff the to STL. Much of the GSL was approved at the standards meeting in Kona: https://isocpp.org/blog/2015/11/kona-standards-meeting-trip-report. It was discussed at the next meeting in Jacksonville and will likely continue to be discussed in Oulu, Issaquah, etc. 
I am SO hoping that I can convince my job to send me there!
Copy that. Real world experience is dreadfully effective, when one comes to c++ (any language?)
_Manifests_ are handled at the OS level. I don't see how you're contradicting me, which you appear to be trying to do..?
&gt; Just remember that good code is simple, not complicated. So don't waste lots of time learning how to write complicated code Ironically, write simple code is complicated.
Wonderful advice. I'll add this: no need to be overly ambitious in your learning projects. You'll learn a ton from even a simple game done on a weekend.
Generic code ( templates without metaprogramming ), function overlaoding, RAII, a standard library that is actually useful, operator overloading, a type system that isn't mostly just throwing out type info at every opportunity, need I go on?
&gt; As far as I know there's no website to 'teach' the subject. http://www.learncpp.com/ Literally google "website to learn C++" and this is the second link. The first link is someone recommending this site.
??? That has nothing to do with the first answer, he was advocating C++ because he says there "is nothing going on behind the scenes" (no magic) while in fact there is. The examples you cited are "magic" and I would even dare to say that the concepts you are talking about are for people who have been programming for a while. C is so simple, the hardest thing about it is pointers. C++ is way more complex. I think the former is better for someone who wants to learn how code is treated by the machine.
&gt; C style casting does not do anything that you cannot do with a combination of static_cast, const_cast, and reinterpret_cast. Almost. N4582 5.4 [expr.cast]/4: "The conversions performed by - a const_cast (5.2.11), - a static_cast (5.2.9), - a static_cast followed by a const_cast, - a reinterpret_cast (5.2.10), or - a reinterpret_cast followed by a const_cast, can be performed using the cast notation of explicit type conversion. The same semantic restrictions and behaviors apply, with the exception that in performing a static_cast in the following situations the conversion is valid even if the base class is inaccessible: - a pointer to an object of derived class type or an lvalue or rvalue of derived class type may be explicitly converted to a pointer or reference to an unambiguous base class type, respectively; - a pointer to member of derived class type may be explicitly converted to a pointer to member of an unambiguous non-virtual base class type; - a pointer to an object of an unambiguous non-virtual base class type, a glvalue of an unambiguous non-virtual base class type, or a pointer to member of an unambiguous non-virtual base class type may be explicitly converted to a pointer, a reference, or a pointer to member of a derived class type, respectively. If a conversion can be interpreted in more than one of the ways listed above, the interpretation that appears first in the list is used, even if a cast resulting from that interpretation is ill-formed. If a conversion can be interpreted in more than one way as a static_cast followed by a const_cast, the conversion is ill-formed."
It seems to me that you're contradicting yourself..? In reality, metaprogramming is a lot less important _because_ of _`constexpr`_...
Shouldn't std::function have the same overhead as a function pointer? I guess there is one extra load out of the vtable?
I think we're talking past each other re streams. You write "can only be used in the simplest situations", I assume you are talking only about streams. My point is that if something is really performance critical, you should not call printf either. So a 50% performance difference doesn't matter much. What's bad in release? You lost me. Also, I'd be curious what implementation you're using where it's not very simple to disable bounds checking simply by changing a macro. I don't see much justification to ever use a C style array in modern C++ code. I'm curious why you say function pointers are too common. You see people use them when they should use a templated class taking a functor? Or you see people use them when they should use std::function?
&gt; My point is that if something is really performance critical, you should not call printf either Unless you really *do* need to print or format something. My story was that I had to format lots of floats and that I had to revert to arrays of chars and sprintf because ostringstream was too slow. &gt; What's bad in release? You lost me. I was in a situation where std::sin() was "too slow" in release (it wasn't really, it just was high up in the profiler's report and it was bothering me). I decided to use an array of 720 floats populated at startup instead. Since this was already a hot section, std::array or std::vector would have made things much worse with all their checks in debug, so I went for C arrays directly. &gt; Also, I'd be curious what implementation you're using where it's not very simple to disable bounds checking simply by changing a macro. Visual C++ 2015, g++ 4.9 and some clang with libstdc++. I'm not aware of any ways of temporarily disabling debug checks in a particular scope on any of these implementations. I'd be *very* happy to be proven wrong. &gt; I don't see much justification to ever use a C style array in modern C++ code. Agreed, in an optimized build. I usually run my stuff without optimizations in debug, so I sometimes have to adapt my code so it runs fast in both. &gt; I'm curious why you say function pointers are too common. I see people go through a lot of trouble with function pointers. A combination of std::function and lambdas could save them a lot of lines, time and effort. I have no specific example right now. 
&gt;char[] prefer std::string Consider `std::basic_string_view&lt;CharT&gt;`.
Rather than polluting member variable names with prefixes or suffixes, why not just prefix function arguments names instead? void storeParams(int newParam1, int newTheRightName) { param1 = newParam1; theRightName = newTheRightName; } Function argument names are basically throw-away and used only once within the scope of the function. Whereas member variable names are referenced often all over the place, so you'd want to keep their naming scheme nice and pristine. That's how I roll anyway.
&gt; process explorer I prefer Process Hacker. It is also open source so you can see where the numbers come from :) 
In practice, language is 10% or less, libraries are tbe rest. You might need (or rather, will be forced) to learn the "DSL" of any C (or C++) library you might come across and its idiosyncrasies. With that, you might need to learn all the "other" ways of dealing with whatever programming situation the library and its users have found themselves, and their "nonstandard" and imaginative :-) solution. But I think, by far the most relevant thing to do will be to work on discovering the "ownership protocols" of various API elements. I've seen this: "In C++, OOP means Object Ownership Protocols", and this is equally true for C, but can get much dirtier.
When you invoke undefined behavior, anything can happen. You can't have any expectations about what will happen. Appearing to work fine is one such outcome. The compiler is not letting you get away with anything, the code is still horribly broken, as it overwrites some area of the stack. It's just that by pure luck that part of the stack wasn't used by anything. But that could easily change at any point for a number of reasons. Maybe you add a new local variable and the function crashes horribly, for example. Edit: also you have an off-by-one error in your thinking. An array of length 1 cannot store a string of length 1 because a null terminator is required. So even if you only enter a single character, this invokes undefined behavior.
Reading data into an array that is too small to hold the data is undefined behavior. Undefined behavior is like dividing by zero, there just simply isn't an answer. The program appearing to work is like saying "1/0 = 0". The program crashing is like saying "1/0 = apple". 
&gt; A commercial application captures air traffic data and stores it in MS SQL severs... &gt; Believe me converting all strings from utf-16 to utf-8 is very slow no matter what. I have tried it So where does the data come from? You have to convert it into utf-16 at minimum. Java (and JVM applications) could be considered to be the most used technology concerning business server applications as you have described here: how would they manage such a scenario? In those languages you have no choice to **not** convert a string for IO operations. And they work fine... Nothing comes for free and of course conversion almost always *cost*, but the question ist, whether this is critical or not. The benefits of a reliable internal string representation should overcome those drawback for most cases.
You should learn all of those things. It shouldn't take you more than a couple hours to run through sample source code for them all (PM me and I can send you some examples), so it would be a good investment of your time. Even if you don't ever write code using, say, a malloc (and you never know, you might - I've been stuck doing development on many systems with poor compiler support) there's so much legacy code floating around that you should be familiar with it. And it's not crazy complicated, it just returns a pointer to a block of memory. How big a block of memory? That's the parameter you pass to it. But if you've never written code using these other idioms, you'll probably screw it up when you work with their code.
This was not in any published standard; but is currently on track for inclusion in C++17.
`boost::string_ref` is equivalent I think
We use ccache and distcc to speed up the building process. So we need to set CCACHE_PREFIX: https://ccache.samba.org/manual.html#_using_ccache_with_other_compiler_wrappers
Both gcc and clang [allow](http://melpon.org/wandbox/permlink/jyMoEFvC2RaMixmS) that conversion with `reinterpret_cast`. I don't see why they shouldn't, but if I'm wrong I'd love to know why.
That's a different conversion. `reinterpret_cast` gives the same address with different type (aliasing), but casting to base class may change the address, in the multiple inheritance case (and in that case, reinterpret_cast would lead to undefined behaviour)
Oh, so C-style cast in this case will give `static_cast`-like result, except for not caring about accessibility? edit: [right](http://melpon.org/wandbox/permlink/o8Qb5c51rmq9ACfm) Thanks a lot for explaining this!
Yes that's right
&gt; The answer is most likely: You should not use a linked list. This is absolutely not the answer that you need if you're into a programming course. Every programming course that I know of starts by introducing all the traditional data structures, and the teacher will certainly not like to hear "/u/sumo952 on reddit told me that I shouldn't use linked list so I won't answer your question about the space complexity of insert on my final exam". This is because the courses are completely abstract of the hardware, they operate on a pure theoretic level where a LL might give better result than a vector. The practical stuff like this comes in the group projects &amp; the likes.
From the description: &gt; pybind11 is a lightweight header-only library that exposes C++ types in Python and vice versa, mainly to create Python bindings of existing C++ code. Its goals and syntax are similar to the excellent Boost.Python library by David Abrahams: to minimize boilerplate code in traditional extension modules by inferring type information using compile-time introspection. &gt; &gt; The main issue with Boost.Python—and the reason for creating such a similar project—is Boost. Boost is an enormously large and complex suite of utility libraries that works with almost every C++ compiler in existence. This compatibility has its cost: arcane template tricks and workarounds are necessary to support the oldest and buggiest of compiler specimens. I bring this statement up because there is some truth to it. The problem with it though, is that a lot of libraries are surfacing that are taking a similar stance and it can be more difficult to use those libraries in a commercial setting. One of the great benefits of boost is that one basically only needs to get approval for one library and license to get access to a huge amount of incredibly useful stuff. This trend makes me wonder if it's time for a C++11 fork of boost that simplifies a bunch of the machinery, removes support for old compilers, etc. 
There's boost::string_ref which can be useful in avoiding copying of strings if you have access to boost and a dislike of char[]. Of course I am sure you know this better than I do, but I wanted to emphasize that most problems like this have already been solved and it is, in most circumstances, unnecessary for one to write a custom string class oneself.
Looking at the suggestions in e.g. http://stackoverflow.com/questions/1815688/how-to-use-ccache-with-cmake there are a few different approaches you could take here. The simples and least invasive being to create wrappers so that CC and CXX work transparently, but there are others mentioned there as well. Regards, Roger
Any plans for support alternate python VMs, such as PyPy?
Intel Parallel Studio and MSVC15 both compile this, but why not just use a std::string then substring the first character?
I looked at the source for your TinyWindow library and it looked pretty good (although very spread out but that's inconsequential). Having used IMGui before and recently learned about nuklear I think what would be really substantial would be putting your TinyWindow together with an immediate mode GUI. Both IMGui and nuklear require quite a bit of boiler plate to bind them to a drawing and input library. In the case of IMGui at least, once that is done it is fantastic to use and very fast. If you put the window creation, gui and boilerplate together, it would mean a one header file gui library which would be amazing.
I started a cffi version of this a long time ago. The problem is that there's no (easy) C(++) cross Python implementation way of reading non-trivial Python data in C(++) and vice versa. If you're interested, it's on my gitlab.com account. I'll send you the link when I'm on non-mobile. EDIT: https://gitlab.com/rubdos/cffipp/
This second layer of indirection for a function pointer shouldn't be necessary if the std:: function is created in a block of code where a particular function is hard coded. Note that the user can also solve this themselves by wrapping the function call in a lambda. 
You don't spawn a thread, the thread is already running. This is how low latency, high performance loggers are generally written. I guess I don't really follow your use case, if you need to display floats as formatted strings its easy to do this fast enough; how many strings can a human being process per second? No idea why this is "trouble". And you are already asking for different code paths in debug and release, so its weird you're mentioning this now. 
You're right but... &gt; The practical stuff like this comes in the group projects &amp; the likes. unfortunately this part is most often not part of group projects. Most lecturers and class helpers are not aware of these things.
I don't use MSVC much. Does it catch writing outside of the bounds of C style arrays and not just library types?
If you just want to make games, and aren't doing anything super special, I'd highly recommend looking into an engine with a higher-level language like Unity or Unreal. Unreal in particular basically uses a simpler subset of c++ along with a highly-polished visual scripting language.
Not necessarily a good thing. static_cast *does* give the same result as the c-style cast, if used within a member function that has access to the privately inherited class: struct D: B&lt;1&gt;, private B&lt;2&gt; { void castMe(){ B&lt;2&gt; * ptr = static_cast&lt;B&lt;2&gt;*&gt;(this); DBG(&amp;ptr); DBG(this); } }; Similarly, the static_cast works if a friend function attempts the cast: struct D: B&lt;1&gt;, private B&lt;2&gt; { friend void externalCast(D&amp;); }; void externalCast(D&amp; foo) { B&lt;2&gt; * cast = static_cast&lt;B&lt;2&gt;*&gt;(&amp;foo); DBG(cast); } If you are using a c-style cast while violating access, you are probably doing something bad and you should feel bad. NB: static_cast only helps you. There is no good reason to use c-style casts. 
Out of the loop. I haven't used Borland C++ since around 1998(?). What's wrong with it? BTW, OWL used to be a cool framework *way* back in the day.
C is not a portable assembler. That's always said by people who have never written assembler. There is nothing assembler-y about C. Portable assembler would be something like LLVM IR.
I've written (real) compilers (I'm a contributor to LLVM). There's very little relation to what goes on in your code, and what goes on in the assembly, except that the assembly and your code do the same thing (assuming you rely on no undefined behavior, etc. etc). Optimizations are crazy.
Actually, the Magic I was referring to was runtime magic, whereas a lot of C++'s features are compile-time. I would agree though that there's a lot of overlap or maybe perceived overlap. A new person might regard constructors and destructors as magic, yes. The kind of magic I was referring to, out of langs like JS or Python, are things like function closures (and associated variable capture) and the fact that without pointers and memory references, we just have "objects" that somehow float in memory. Due to the pains of mem mgmt in C/C++, you'll never avoid the concrete reality of what an allocated object really is (otherwise, you just segfaulted or leaked memory). 
I usually tell people that they should read that section if they want to get nightmares.
*Borland* C++ Builder was last released in 2006. It doesn't have any C++11/14/17 features. That's why you shouldn't learn C++ with Borland C++ Builder. *Embarcadero* C++ Builder (the successor to Borland C++ Builder) is based off clang and should be just fine for learning C++.
True, but that doesn't invalidate /u/jurniss's point.
&gt; I was thinking arrays were 0 indexed They are. But sizes and indices are different things. If you declare array with size 10 such as `int arr[10]` the valid indices are `arr[0]` through `arr[9]`. 
I have a Licence for Embarcadero C++ Builder XE7 and with this licence you get a licence to use their products back to Borland Builder C++ V6.0. I compiled the code above with XE7 and it crashed like it should. 
Thanks - declarations are not zero based, however indexing the array is.
Ok I understand why that phrase would be annoying if you work on C compilers, but the phrase was really tangential to the main point I was trying to make.
Yeah. Sorry for going off on you like that, the phrase just... really, really annoys me, because people take it, and then generalize it to mean things that it doesn't. You make a really good point with: &gt; most of the things that seem scary / confusing about C to newcomers are not specific to the C language, they would exist in any language that gives similar access to the hardware. So it's better to learn the underlying ideas without necessarily filtering them through the C language. I couldn't have said it better myself :)
Why not `std::string_view`?
Are you compiling on multiple different systems? If not, you might think about ignoring CMake and just using a simple build system. CMake is a way to generate builds for multiple different build systems. Sure, sometimes CMake just works and in those cases a lot of people use it just generate for a single target system, but there is a lot of complexity behind it and if it isn't working for you and you don't need that extra complexity, why bother? Do yourself a favour and just use a simple build tool for your target system. As an aside, in my experience, the majority of problems people have with builds stems from not actually knowing what they're doing. Not in a derogatory sense, but in the sense that they've lose the knowledge of what actions actually need to be taken in what order. If you know your code well enough to know what's building, in what order, and what links with what when, banging together a makefile in your chosen system really isn't difficult. The problems come when people don't really know, and the build kind of just works and people keep bodging new bits onto it without quite knowing what's going on, and eventually it's a horrific fragile mess.
I do agree with you though, that the point can really be taken too far. Nowadays, I feel like we're living in a world of abstraction, so encouraging someone to learn how a machine works relative to C is probably the most useful perspective you can ask for. I've had even more frustrating conversations with people that see Python as the hammer for every nail in the universe. 
Yea I agree. The "problem" with boost is that it's serving kind of two purposes: * A playground for new stuff that will eventually land in the standard (some of it only of course) * Allowing to use this new stuff on older compilers. I would really love to see what you propose regarding a "C++11 boost" but I don't see how this would happen.
it's not released yet :p
[removed]
Noted, but that doesn't seem like a make-or-break issue like remote work and visa issues. The template is already pretty crowded.
Your post has been automatically removed because it appears to be help/homework related. If this has been in error please message the moderators. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
How good is the GSL? Is it as proven in the field as the STL implementations?
Hmm, first thoughts: * Minimalistic code. * Needs some fixes: - Remove `&lt;windows.h&gt;` etc. from the headers and do a real PIMPL. - Split headers in supported OpenGL versions to reduce include size. - Single out the OpenGL ES subsets? Not sure if people need/want that though. - Remove stupid namespace or make it short and snake_case. Why not `gl`? - Why do we need a `gl_` prefix for enums when we have namespaces for that? - Use `&lt;cstdint&gt;` instead of `__int32` etc. - Source code formatting can be easily fixed with *clang-format*. - Add error checking for `FetchProcAddress` since performance should not be an issue there. * Good license. * Nice window example, but ... - Could be split up into one file per backend. - XCB and Wayland support would be interesting though. - OS X and mobile examples if a long term acceptance and widespread adoption are goals. * `error_code` support. Yaaaay! But not for normal OpenGL errors, correct? - Rename `errorCategory_t` to something like `error_category`. It has it's own namespace after all. * Enums as snake_case - very pleasant to work with as long as you have proper syntax highlighting. * Does not mention OpenGL 4.5 in the header. No idea if this is supposed to be the case. * Is optional *glm* support something worth considering? Would make the library more interesting. In the end, I like it.
I'm using Microsoft's implementation on gcc-5.3.1. I don't know of any other implementations yet. It seems to work okay, despite a whole load of #pragmas in the code. But I've only been using it for a couple of weeks. Since it's just a few useful utility types to support the guidelines, it's not comparable in complexity to the STL. When and if it becomes part of the standard there are bound to be changes. But the point is that it is useful now and its just a header. 
&gt; `Comp comp = compare_closure;` This is not legal, except as an extension, because the standard only calls for a conversion to a function pointer with C++ linkage, which is an altogether different type than a function pointer with C linkage.
&gt; &gt; &gt; This trend makes me wonder if it's time for a C++11 fork of boost that simplifies a bunch of the machinery, removes support for old compilers, etc. But you aren't paying for it, are you ? (unless you're a boost dev)
The priority queue uses log n time to get each new element, not log k, so it's much slower for small k. I will probably update the post with a comparison, because this question has come up a lot.
It's very sad that usability is sacrificed in favor of phantom performance. The problem is, trait-based analysis results in horrendous, unreadable syntax for any non-trivial case. No one requires to compute those meta-objects eagerly in case of constexpr.
Paying for what? The cost of that all of that machinery? As users, we most certainly are in terms of compile times, complex error messages, and deep call stacks. For me, these things are not a deal breaker. But for some projects they are. Even on my project, which uses quite a bit of boost, many of my co-workers complain about these things often. 
For years and years of learning: http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list
&gt; As users, we most certainly are in terms of compile times, complex error messages, and deep call stacks. Isn't this the case only if you're on a "complicated / legacy" code path ? I think that most workarounds in boost are implemented using the preprocessor so it should really not matter wrt compile time and error messages since from the point of view of the actual compiler, the workarounds won't even exist and only the "clean" codepath will be here.
Old stuff also affects the design of boost. Things have to be implemented in a way that has interfaces for workarounds. Also, designing things without modern C++ features in mind is a disservice to people using modern C++. That's why hana is so different. So yes, everyone pays for the cruft, but the boost developers are not interested in removing it, and the majority of boost libraries do not have an active maintainer.
What about an any-like class with fixed capacity that never does heap allocation, like `static_any&lt;N&gt;`? Kinda a hybrid between `variant` and `any` (or a high-level API for `aligned_storage`).
University of Waterloo
Makes sense, hope it doesn't discourage people who may not be 'expert level' from applying. As long as they have a decent grasp of C++ and some experience they have a good chance. 
That's EXACTLY the kind of thing that will put off otherwise suitable candidates from applying. Would you ask that they also be brain surgeons but not actually require it? EDIT: just realised you are contingent recruitment consultants, and therefore a) would specify brain surgery and b) do not know what the hell you are on about. 
Incorrect, we have no oversight over the job description that is the prerogative of the company looking to hire. We simply match users with the job if their A. Skills B. Experience and C. Preferences make it appropriate to do so. 
Job offers in this field are ridiculous more often than not. People want juniors with 3-5 years experience (???), expert in 1-2 languages, familiar with ${insertEveryOtherLanguages}. Also, you need to spend all of your free time working on open source projects on GitHub (who needs a life, right). Then maybe you have a chance. Unless you ask for more than 65k. Yet in reality, you show up for an interview, most likely noone else applied in weeks, they are so happy someone is finally interested in the position they make an offer at the end of the meeting. Strange way to go about finding people for software dev positions.
I was talking about job offers in general, the example you posted looks reasonable to me.
Not here. From the monthly jobs thread: &gt; You must be hiring directly. No third-party recruiters. Removed for this reason and the fact that your account appears to be used only for self-promotion.
I'm not sure that it's appropriate to keep open source code in the same repo with art that is commercial property of a company that hasn't released it for this. I'll check it out though. 
Legit question. I can understand how a bot might make money in something like WoW but CS:GO? Someone explain how that works, what's the profitable part?
If I am not wrong , Tower hires only from top schools in all the countries it has offices in?(like IIT in India, target schools for US jobs)
I noticed the bit about the vector and working its data pointer the other day, in release mode it was just fine, but in debug it was killing me, it was extremely slow, so I did exactly what you said, got a pointer to its data and poked around myself and it was just as fast in debug mode as it was in release. The whole idea of avoiding raw pointers and using pointer math seems wrong to me, I desperately want to like writing C++ code but I often feel like I am "doing it wrong" when I fall back on C style thinking. I am not a professional and am self taught and I've always preferred C, it just feels right.
I would like to mention that cheating online is largely based on the permissions and calculations done on the host computer instead of the server. For example, if the host server only took mouse and keyboard inputs from the host and calculated everything else, the game would be nearly unhackable, Assuming that the player only got his own player data back. However, most games do not due this, in order to reduce lag, lousy programming, or necessity. Instead, games may have the host hold the local player position, money, health, etc... and a hacker can exploit that data. Wall hacking obviously exploits the server's ability to give you the position of other players, and uses that to see them even though you shouldn't. We could just have the server not give the player the enemy position data, but how would we see the enemy players? 
Yup! I've written those exact types in fact. Since you don't have to implement the type-erasure yourself, they're pretty simple!
How is this different from nth element?
I'm actually not sure - I heard it's not possible, but from an unreliable source. I googled a bit and it's hard to find information... some vague posts say it's possible... others say it [isn't](http://forums.codeguru.com/showthread.php?258540-About-STL-in-Kernel-Mode). I would be really interested in knowing this for sure.
&gt; could be avoided through a proper inheritance tree with an abstract base class at the top You appear to be missing the _entire point_ of using CRTP...
Bjarne Stroustrup is an expert. So are kernel programmers. Good luck. 
Note, we can find material from Olve Maudal's talks including past Pub Quiz's [here](https://olvemaudal.com/talks/).
My main problem with C is that it requires discipline because it has no support for any sort of RAII. After that comes containers and utilities, most of which can be checked at runtime. It's basically like unit testing: it gives you more confidence in your code if you're not tripping any asserts. As for higher level stuff like design and object-oriented programming, really, that's up to you. I've seen horrible designs in C++ and very clean ones in C. My experience is that languages have very little impact on the quality of design. C++ is not the answer to everything. You don't have to "desperately" want to like it. It's just a tool. If you prefer another one, go for it.
Your idea is very sound, just not new. 
I know I don't have to like it, but there are some bits of it I really do like, but the language is overwhelming for someone who is an average programmer without any formal education at best. I'm no prodigy :P
From the sidebar ------&gt; &gt; There is a useful list of books on [Stack Overflow](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list).
/me debates if I should get this working on linux..
seconded reading it for a while now good layout, good examples, has some nice tables for references, covers a lot of topics and at least gets you familiar in c++
1. I've never done a PIMPL implementation before but I'll give it a crack if you think it helps. 2. the gl_ prefix is sadly necessary as enums such as GL_BOOL (becomes bool) give alot of issues. keeping it uppercase is also an issue in Linux as GL_* has already been defined unlike in windows where they are not defined. also removing the prefix and keeping the enum uppercase also gives issues in windows with some enums being defined in WIN32. other opengl extension libraries like GLEW #define over existing definitions. I'm trying to use as few #defines as possible 3. I will add error checking to FetchProcAddress 4. XCB and wayland support are on the backburner right now. Apple products are further back in the burner 5. OpenGL 4.5 is coming up 6. I try to make my libraries as self-reliant as possible. also changing the function pointers to use glm will not work as OpenGL does not support glm. I do use glm in my engine so I know the pain
Hmm this could be a final exam, not a pub quiz :) Here are my answers, before checking the answer key... I think I'll be happy if I get 50% 1. 1234567 2. 01246018137481333 (Assuming copy-elision from `tmp` to return-value-object for postfix-++ call) 3. 233444566 4. 133 5. 1a2b3c4a5b6c1 6. soledaa (IIRC, g++ uses nullptr for NULL; if not then "solleda" is the answer) 7. (no idea but there's some trigraphs in there) 8. 101024 9. 24124 (Assuming empty-base-class optimization is on by default) 10. 1223 (The 3 might be a 4, IDK whether the rule about named members of rvalues being xvalues also applies to lambda captures) 11. 42133124 (Assuming copy-elision applied to `static X c = 1;`) 12. 42 
&gt;I can estimate roughly what instructions my compiler will emit. That must be very roughly these days ;-). I am generally surprised when I look at the generated code. Optimizers do crazy stuff.
Thank you for the references! I will start learning these new concepts and watch the videos. One thing the older coders I work with tell me that the new cpp features just make the language bloated and I shouldn't waste time learning any of it because it isn't needed. They say you can write the same code without all the bells and whistles and keep your code as close to C as you can get and you end up with code that runs faster than the new cpp features. Are they just set in their ways, or do you think there is some merit in their thinking?
Are there any similar techniques for performing an incremental stable sort?
OK, watch [Kate Gregory's video](https://www.youtube.com/watch?v=YnWhqhNdYyk) right now!!! But if you don't have time to watch the video, the answer is there is no merit in your co-workers' thinking. The only reason to stay close to C is not upset co-workers (or managers, etc...) that won't bother to learn C++11 (or because you are stuck with a legacy project While C++11 offers more features (some of which do take a long time to understand and master), C++11 code can be simpler, easier to make safe, and usually is faster than just plain C code. C++11 is actually pretty easy to learn for a 'consumer developer' -- easier than even C++98. C++11 is more difficult to master as a library developer. I think a parallel would be looking at C# compared to C. C# is a much more complex language, has many nuances, and takes a lot longer to master than plain C. But is C# a bad language? By no means. It does many things better than C. C++ is similar. There are more features, but those features actually help programmers write more concise, meaningful, less error-prone code.
I hope OP read your post. BTW, why Horde3d and not Ogre3d? 
That page is good, thanks for the link. Yes, too bad it doesn't talk about the STL.
Happy to answer any questions... For CMake users there is now [How is this better than CMake?](https://build2.org/faq.xhtml#cmake) FAQ entry.
sounds like your colleagues want to write C... which is no problem, but they should be honest about it. C++11 is a HUGE improvement over c++0x, and even more so over c++98. There are occasional areas where I have found compile times to be quite a lot longer when using a lot of c++11 features, but runtime I actually in general find performance gains, not losses, due to things like auto and rvalue refs. Allow me to explain: if you use auto to specify types for e.g. derived iterator classes, you can often avoid accidental copies from using the copy constructor when you didn't mean to. Move constructors and rvalue references allow you to maintain high level abstraction whilst reducing memory copies. And, finally, the now automatic return value optimization incrementally helps every time you return a heavy type from a function.
Someone just posted this question and while I am busy replying to it, deleted it. Not cool. Here it is seeing that I've already answered it and I think it is a good question: &gt; I read your FAQ. To the question: "What makes you think you will succeed when so many have failed?" it seems to me your only reason to bring this tool is (I quote) "The biggest problem is the lack of out of the box Windows support. Or, more precisely, the lack of a POSIX shell on Windows.". Now that windows can run Ubuntu's binaries, I think this is about to change, don't you? This is a big problem but only one of them. Even given a POSIX shell, it is very hard to implement complex logic in it. Say, automatic header extraction: the stuff we need to do (extract headers, hit an auto-generated one, re-generated it if necessary, if changed, restart the extraction process) is just not possible with `sed`. I am also not convinced that running Linux userland on Windows will solve all the problems. For example, how will you invoke a native binary like `cl.exe` and pass it (POSIX) paths? I doubt this will work out of the box: $ cl.exe -I/home/boris/work ... 
Quite a lot of Windows utilities do allow / in paths to work as \, so relative pathnames may work. But when I was using Cygwin make and cl.exe, we did have to use cygpath to convert paths with annoying frequency.
probably some stupid mistake on my side, but I wasn't able to install C++ extension - "ext install cpptools" couldn't find any matches 
Is this about migrating from Matlab? Are you specifically looking to solve (non)linear algebra problems or to organize datasets?
There is also the [Fit](https://github.com/pfultz2/Fit) library. It only supports `constexpr` initialization of functions by using workarounds in MSVC, however, `constexpr` evaluation of functions are not fully supported(although it may work in some simple cases).
Thanks, /u/pfultz2! 
FYI, we are now pushing daily updates of these tools. More info (and the caveats!) here: https://blogs.msdn.microsoft.com/vcblog/2016/04/26/stay-up-to-date-with-the-visual-c-tools-on-nuget/
Oh and while you are at it: add C++17 `constexpr` lambdas as well :)
Please avoid the three year unfixed bug in clang wherein calls to constant expression functions are not considered noexcept (which they should be, regardless of their exception specification). See link: https://llvm.org/bugs/show_bug.cgi?id=15481
This is dumb. The most common reason to cast away const is to use C-style libraries such as libtiff.
This is great, and I wouldn't have thought of it. Thanks! Can you explain why I have to go back to `adeklos`+2945 and can't just do the same calculation with `oldsake` and 3862? I tried, and it doesn't work (even the first letter, 5*6! would be k which is already wrong), but it seems like it should.
You are right, I remembered the passage from the standard incorrectly. I would still argue that the approach you showed has a downside. If the instance of CGoodClass is non-const, then the object referred to by DoWorkAndReturnAThing() has to be non-const as well. If this is changed later during development, i.e. the attribute is made permanently const, the code will invoke UB but not cause any errors.
Yeah I guess you have to weigh the chance of that happening vs. the chance of changing the work the function does and either carrying forward a lot of code duplication or, worst-case, getting the work they do out of sync accidentally.
I'm not very familiar with the subject of system automation, and a company by the same name is polluting my search results. Can someone give me an example of what this is/could being/be used for?
Now what you _could_ do these days is add something like static_assert(!std::is_const(decltype(m_hasMyThing)), "Remove my non-const override!"); to the const version. You could also argue that you should put it in the non-const version, but I guess if you want basically 0 code in the non-const one you might choose not to do that.
There's a proposal to fix this: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0187r0.pdf &gt;Why does C++ always have these pointless limitations? This particular case has some parsing ambiguities and the process for language changes in general is pretty slow and bureaucratic. 
This library has a lot of use cases. But you could use it to simulate keyboard and mouse input, write basic key loggers, take screenshots of the system, read and write the memory of another process, etc. It gives you the ability to write software for simulating a real human using a computer. So you could write a basic remote desktop application, a bot for playing a game, etc.
It's still in the works, but this is a very decent tutorial for C++. http://www.learncpp.com/ Of course, it's not perfect nor complete, but reading that should give you some notion about what C++ offers you. Note: It doesn't teach you programming. It teaches you C++. As for videos, I don't know any good videos tutorials. I was considering maybe doing some with the help of some users from here, but that's out of the question for now.
Bit fields are themselves an awkward corner best avoided. A lot of aspects of C++ don't work with bit fields. They are sort of the `vector&lt;bool&gt;` of the core language.
The API documentation for C++ can be found here: http://getrobot.net/api/global.html. The node interface is largely identical except for a couple differences which are outlined here: http://getrobot.net/docs/node.html.
Also standardized functions like iconv where the input text should be const but iconv has a char\*\* parameter: size_t iconv(iconv_t cd, char \*\*inbuf, size_t \*inbytesleft, char \*\*outbuf, size_t \*outbytesleft); http://man7.org/linux/man-pages/man3/iconv.3.html
&gt; # Replace older compilers &gt; $ cd /usr/bin &gt; $ [sudo] rm gcc g++ cpp &gt; $ [sudo] ln -s gcc-[ver] gcc &gt; $ [sudo] ln -s g++-[ver] g++ &gt; $ [sudo] ln -s cpp-[ver] cpp *shudder*. Hint: `sudo update-alternatives` Also you're using loads of globals and macros. Is that necessary? And it supports MSVC2010 - for me, that's a red flag, and not something I'd usually want from a codebase. In most of the cases it means the code is horribly old and/or bad and/or goes through lots of hoops to make MSVC2010 happen, and possibly even has something like XP support. Please, move on. :-) And too bad for you if you're stuck on MSVC2010. I don't feel for you. Quit your job ;-) (Awaiting the downvotes ;-) ) Otherwise it actually seems really useful and the application code quite pleasant! (apart from the globals &amp; macros that is).
The point is that starting from `adeklos`, the first 6! permutations all start with `a` (and the first 5! of those 6! always start with `ad`, etc.), the next 6! all start with `d`, etc. That property doesn't hold when you start with `oldsake`.
Ah I see now, thanks!
I don't know what you expect this library to be doing that would require jumping through hoops for older compilers. It seems like it could be written in C++98 for all anyone cares - no need to force all the modern C++ stuff be supported. Unless I am misunderstanding you?
Cool, I'll just tell people who work on certain game consoles to quit since they don't have language support even as good as VS2010. /s I mean, I get what you're saying, but that's a little harsh. No downvote though.
Perhaps you can try this one: http://www.ece.uvic.ca/~frodo/cppbook/ Slides: http://www.ece.uvic.ca/~frodo/cppbook/#obtain Videos: - http://www.ece.uvic.ca/~frodo/cppbook/#videos - https://www.youtube.com/playlist?list=PLbHYdvrWBMxY9onUxT2l7-ZyuFEEI8Qpv Note: I'd probably jump straight to "C++ Lecture Series --- Standard Library --- Part 1 of N --- Introduction" right after "C++ Lecture Series --- Classes --- Part 1 of N --- Introduction", and then go back for the rest (my reasoning: better to start using containers like std::vector before going into classes and inheritance). 
If you know the answer, then please, share it. If you don't know the answer, then you're not in a position to say an opinion different than your own "isn't very helpful".
Yes, it works exactly as shown in the gif screenshots. They were recorded from gameplay :) Just pushed more updates -- Item drops.
You totally should start a port to linux! Would be GREAT! Especially OpenGL. xD
Robot uses some C++11 types (std::regex, std::unordered_map, etc.). Unless people want boost as a requirement, I think the compiler choices are pretty generous. You're right! why deprecate something for no reason.
Because some people realized that was how it should have been defined. Having both forms possible made things even more fun. Here is some discussion including C++ adapters that handled either: http://stackoverflow.com/questions/11421439/how-can-i-portably-call-a-c-function-that-takes-a-char-on-some-platforms-and
This library seems really nice and the documentation is pretty good. Good job on that! Concerning the Mac implementation, I skimmed it and the main suggestion I got to improve your code base would be to use a RAII Wrapper for the CoreFoundation types so you can get rid of the explicit and error-prone calls to CFRelease.
If you are already familiar with some programming language (MATLAB, python, Ruby, etc.), then I recommend STL's [Core C++ series](https://www.youtube.com/watch?v=3Yg3QnGXxHM&amp;list=PL9QAu9zhcKhGEDZpDtk33mz1kRV9o1vfa).
Thanks for the suggestion! The main reason I didn't use RAII was because I originally thought I could just write the whole thing with C calls, like in Linux and Windows. But then I realized I actually had to use Objective-C++ for some things (I'm not exactly a huge Mac developer). As such I sorta just left the old code in there because it worked. That being said I'm not entirely sure that changing it now would be a good idea. That code was very carefully written and tested and I'm afraid that changing it for the sake of changing it could cause more problems than it fixes. But I digress, I'm certainly open to improving the code base when the time is right!
I should have some time this weekend to play around with this.. Do you hang out on IRC? 
As long as you write your RAII wrapper in a sane way, unit-test it, and then deliver it in a future release, you'll only gain stability. I haven't checked whether or not there are APIs which you've used that might throw, but if that's the case, RAII can save the day!
You create that firewall with casts. Nothing insane about writing an API in C, such as the Linux or Windows APIs. The dumb thing here is the article making a big deal out of something that doesn't happen often, on the other hand interfacing with c style libraries is common.
You don't have to, you could (and I would) create that firewall with a wrapper API and copies of the input variables. I disagree that c-style APIs are sane (sure, let's pollute the global namespace, who gives a shit!), but if you have to use them you have to. It's not dumb to discourage using a feature that basically renders a more fundamental feature pointless. I think you should make perversions of the type system as ugly as humanly possible so that they're easy to find, easy to see, and hard to follow as examples to future developers.
This is AMAZING! I started a research today project to add native support to an automation project.
So, you would deep copy a 10 megabyte tiff file to avoid a cast? Sounds like Python!
&gt; Replace older compilers Where did you see this? Edit, nevermind I am not thinking clearly, it is right there one the usage page. Yeah, for a second I thought it might have been in some script or something.
Your link to github directs me to a search ( https://github.com/robot ) instead of your repo, which I presume is https://github.com/Robot/robot .
I wouldn't have a 10 megabyte tiff file in a const char*, that's for sure.
I don't but been looking for a good IRC room to join for gamedev. You have any recommendations ? :D
Yes, we all pay for it. As an extreme example, I use Xalan and Xerces for XML and XSL processing. These libraries date back to the mid-late '90s and they never adopted even C++98; hell, even namespaces are optional. The APIs are awful and barely usable, they are fragile, leak memory if you don't write your own RAII wrappers, and are not thread safe. They could have chosen to break compatibility and use C++98, but chose to stay stuck in the past, to their long term detriment. They are awful libraries, and their remaining maintainers, even today, are sticking to their guns, actively preventing new major versions that would clean up the awfulness. The point of the above is that Boost is in a similar position. They can choose to remain compatible with C++98 forever, leaving C++11/14 features as optional extras, or they can choose to break with the past and remove all the compatibility hacks and workarounds. That would obviously be a major break, and the question would be when? Right now, all the compilers from the major vendors are "good enough" to allow this, with a limited set of portability hacks, where a year or so back this was definitely not the case. Deciding to have such a large break would be hard in the short term, but might well be a positive for the long-term health of the project. And it must have done so for pre-C++98 compilers back in the distant past--while it originated post-standardisation, it took several years for good support by all the vendors, so they must have made the choice to mandate C++98 at some point, and they could do so for C++11/14 when they feel the time is right. It will soon be *half a decade* since C++11 was formally ratified, and most of the individual features have been implemented well before this. I think that is a more than generous period to transition, and I would welcome Boost mandating it.
It should really say "OS" or maybe "end-user OS" instead of "system". It's much too general like this; I actually expected something targeted at large businesses based on the name.
I don't believe you can learn C++ with online courses. Online courses, by their nature, tend to focus on saving your time which unfortunately doesn't work for C++. Get yourself a good book such as &lt;The C++ Programming Language&gt; then just write a lot of code. Use it everyday, read other people's code, learn from your mistakes. That's how every decent C++ programmer has been through. There's simply no shortcut.
I had been programming in very limited forms since the mid 90's by myself with my first graphing calculator then screwing off with MegaZeux to scripting with level editors and eventually taking an online Java class. But it wasn't until I was in class with other students and the teacher was having us behave as if we were bytes in memory that it all *clicked*. If you have options please don't limit yourself to learning only through online sources.
Hmm, interesting. Say you want to make a robot that should "go through" some screens of an application and takes some screenshots. From the API I can't see how one saves those grabbed screens. But perhaps I should "automate" (code) that using MS Paint via the clipboard?
&gt; So, you would deep copy a 10 megabyte tiff file to avoid a cast? Sounds like Python! Depends on how critical it is that the library must under no circumstances modify your input data. With const char* you get some kind of promise in the interface in regards to that. But still, if you really must be sure input data is kept the same either a copy is necessary, or preferably mark the pages the data resides in as read-only before calling (win/win for sanity/performance) and clear the flags after function returns.
Love how the diagnostics are finally approaching clang levels of useful.
I'm sorry for the confusion, I didn't think of that.
Try telling that to corporations stuck supporting legacy code. Again why deprecate something for no reason when it doesn't affect the end product?
The power of competition :)
Yes it's because Robot is currently comprised of two libraries, the C++ version and the Node.js version. More languages will probably be supported in the future.
Ah, they added [`std::invoke`](http://en.cppreference.com/w/cpp/utility/functional/invoke) support to libstdc++ - great!
Agreed. The only reason I'm a bit reluctant to change it is because I don't fully understand the platform. I'm actually hoping somebody more experienced can get involved to help out since it's becoming hard to manage on my own.
Actually I'm doing that right now. I'm using learncpp.com, TheNewBoston's C++ tutorials on YouTube, and MIT has free 2011 courseware that is listed as being equivalent to their official online classes (http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-096-introduction-to-c-january-iap-2011/index.htm). You should also look into courses on Edx.
**CONCEPTS!!**
Note that the changes confusingly list the changes of 6.0 and 6.1 combined. C++14 default was already the case for 6.0 (they would never make such a major change in a minor version update).
You make a point out of const-correctness being valuable. I know a lot of people who would rather say "it can be helpful for some documentation/optimization but is usually not worth the trouble". Do you have more background on the value of const-correctness? Eg. how much does it really help in optimization (in numbers)?
Yes, that is a good side note. My main points were: 1. gcc "changes" documents always list the changes from all versions combined since the last x.0 version. See [this page](https://gcc.gnu.org/gcc-5/), with three "changes" links that all point to the same document. ~~You would have a hard time to find the list of changes between 6.0 and 6.1 or any other subsequent minor versions (I guess you could diff the archive.org version of that page from before 6.1 to the current version of the page, if archive.org would have that page, which it doesn't)~~ Edit: actually the changes of minor versions are at the end of the changes documents, thanks adrian17. 2. Changing something big like the default language version is something that is done on x.0 versions in general. 
MIT should be ashamed of itself for putting that OCW online.
It can get even messier if you then use multithreading :) The best approach is to use a custom allocator for data like this and just not use the extra page memory in each allocation. At worst you are wasting 4kB of data per allocation, which is not bad as long as your data is big enough. If the data is smaller than a few pages you could just make a copy, since the copy cost would be rather low.
Thanks for the comment. I will update the documentation to include some info on this. The library is compiled and tested with both Clang and Visual C++ (I'll look for the exact versions of the compilers we use). The implementations of optional and variant are not 100% compliant with the C++ TS, but they are close. There is no support for types that throw during move (which makes it easy to provide a never-empty guarantee for the variant), and there are unfortunate syntactic differences that I will work on smoothing out. Certain features are also not supported, for example applying a visitor on multiple variants. Because there are basically no system calls in the library, the UTF8/UTF16/UTF32 distinction doesn't matter as much. For the JSON part of the library, Goldfish currently only speaks UTF8 and assumes "char" strings (std::string/const char*/const char[N]) are UTF8 encoded.
Could you give further explanation as to why you say that?
Oh dear, this is so confusing. Whoever came up with this...
I know someone that refused to move past c++98 until something else was default. I need to tell him to switch now. The best part is he was dealing with problems C++11 would solve just a few days ago.
Screw all this C++17 stuff, that's all I wanted: spellcheck-fields.cc:52:13: error: 'struct s' has no member named 'colour'; did you mean 'color'? return ptr-&gt;colour; ^~~~~~
Use Clang ;) Back in the days (6 years ago now??) I was following the heroic advances of the one lone ranger who implemented most of the code correction in Clang. And it was epic! At first, you would think it's easy. Compute the edit distance between the identifier you get and whatever it could be, pick the shortest, done. But in Clang the suggestion is a "FIXME" note, and there is special logic for "FIXME" notes: in order to prevent cascading errors the rest of the compilation proceeds as if the FIXME had been applied. This is great, because cascading errors are a nightmare, but it also means that a *wrong* FIXME is apocalyptic as the compiler starts complaining about issues who cannot be mapped to the source code. Very, very, confusing. What this meant for identifier suggestions, therefore, was that multiple culling strategies were put in place to avoid suggesting something that's not callable if it's called, a variable where a type is expected (or vice versa), ... The refinements went on for years, and I would not be surprised they are still going on.
Calling a member function on a null pointer is assumed to never happen, so null pointer checks on `this` are assumed to always pass. This lets the compiler optimize away null pointer checks from functions that get inlined. The existing code bases that have problems with this optimization are relying on undefined behaviour when they expect calls to member functions on null pointers to work.
I suspect something like this: void fun(foo* ptr) { if (ptr) {use(*ptr);} } class foo { void bar() { fun(this);} }; You can inline it and remove the check. Since it requires a high level of stupidity to belive that `if (this == nullptr)` is a valid thing to do under any circumstances, the GCC-team made the right decision and didn't punish those of us who are not that incompetent for the actions of those who are.
{} on freenode You are welcome to join, there are a few of us in there working on stuff related to SDL2 and opengl.... we all have full time jobs and suck at game development but we all share a passion for software development. Currently I'm usually on later at night ( EST ) ... I'm currently working on a solution to keep me connect 24/7.... feel free to come on in and chat with us... I'd totally be willing to help ya out.. 
That's precious.
I'm confused - what the hell *are* those code bases doing that would break this assumption?
I really love them though. If just the not-really-specified-but-the-same-everywhere behavior could be removed, I would replace all shitty enum flag things instantly.
I still am reserved about compiler assuming a correction to be correct even if it's just for continued error checking. misinformation is sometimes a greater cost than not saying anything at all.
&gt; Actually, 5.2 and 5.3 release notes are separate and at the very bottom of the document. Wow thats crazy. I am looking at those changes documents for gcc for many years now and was always confused by the fact that they had multiple links for different minor versions to the same document. This is the first time I see that they in fact always added the changes of the minor versions at the end. You have to scroll through all the changes for more or less obscure platforms to find those sections. &gt; You can't find them, as "6.0" was a name for all in-developement builds, so there isn't even a specific commit tagged "6.0" you could compare 6.1 with (at least AFAIK). I guess this is partly right. If I understand their timeline correct, the main development branch was named 6.0 as soon as the gcc 5 release branch was created (i.e. development leading up to gcc 5.1 was done). The thing is that each compiler can self-identify its own version with the --version flag, and that gives a valid version number even for the development versions long before their release. My guess would be that the gcc 5 branch for example in the whole time between the gcc 5.2 and 5.3 releases self identified as 5.3.
 % gcc --version gcc (GCC) 5.3.0 Damn you, Arch.
Your post has been automatically removed because it appears to be help/homework related. If this has been in error please message the moderators. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Especially because [this is all a ploy from the government](http://stackoverflow.com/a/36894819/4885801).
Why not just put your comparison criteria directly in the enable_if like this #include &lt;type_traits&gt; #include &lt;iostream&gt; template&lt;class T, std::enable_if_t&lt; (sizeof(T) &lt; 4) &gt;* = nullptr&gt; void func(T&amp;) { std::cout &lt;&lt; "Less than 4\n"; } template&lt;class T, std::enable_if_t&lt; (sizeof(T) &gt;= 4 &amp;&amp; sizeof(T) &lt; 8) &gt;* = nullptr&gt; void func(T&amp;) { std::cout &lt;&lt; "Greater than or equal to 4 and less than 8\n"; } template&lt;class T, std::enable_if_t&lt; (sizeof(T) &gt;= 8) &gt;* = nullptr&gt; void func(T&amp;) { std::cout &lt;&lt; "Greater than or equal to 8\n"; } int main() { short s; int i; double d; func(s); func(i); func(d); }
Yea. I made the algorithms one. Can we add boost libraries as a search criteria? The !cpp goes to cppreference.com when both !cppr and !cppreference already go there. Can we get !cpp for cplusplus.com? I much prefer it.
It is a very low quality brief tutorial, mostly about C with classes, which just happened to be written by MIT undegrads (as a UROP I guess?) rather than any other enthusiastic beginners. People seem to mistake it for a useful course.
Inlining the function inherently results in multiple copies of it.
It goes both ways of course. How many times have you seen cascades that are just nonsensical just because you didn't think to look at the first error first?
Check the [GCC Development Plan](https://gcc.gnu.org/develop.html), there is a section 'Version Numbering Scheme for GCC 5 and Up' and also a expected release schedule. So yeah, they changed the numbering scheme. Edit: &gt; The change also takes advantage of the fact that previously the GCC major number carried little to no useful information. That might be one of the important parts, it seems the major number previously had no real meaning.
Thanks.
This looks fantastic. I have to ask though, if it is an IDE for C++11 and above, why does it have so many boost dependencies that aren't necessary with C++11 and above?
There are embedded systems that use byte 0 as normal memory (someone said)
Gentoo is still using 4.9.3.
The reason behind for instance the boost-regex dependency is to support older compilers like g++ 4.8. This dependency will be removed in a few months most likely though. 
Quick grep only shows one (boost::regex)? It's possible there may be a reason for this too.
boost-thread might not be needed anymore actually.
Probably because cppreference is considered more detailed and accurate overall. There were (are?) some issues with cplusplus.com materials. I was also used to cplusplus.com, but switched recently.
Actually, you could. It makes it harder to debug once you get to much larger constructs that could be re-used multiple places. If you break them out of the template into separate constructs you can have test cases just for the conditionals. Then you can use the conditionals over and over...without re-typing. Much easier, more compartmentalized, easier to debug/test and well...easier to read. It becomes a jumbled mess once you start adding things like std::is_array&lt; T &gt;::value || XXX || XXX || XXX which these things often turn into for complex tasks.
that someone is stupid.
&gt; The change also takes advantage of the fact that previously the GCC major number carried little to no useful information. To be fair, there *was* a huge difference between GCC 2, GCC 3, and GCC 4.
Time to make Ubuntu snap package )))
So... Competition! 
Makes sense. Why put what is essentially a lambda somewhere it can't be tested outside of the template where you're using it. Especially if you're re-using it in multiple places.
Can you explain "`const_cast&lt;&gt;` away the const for the memory"? Where is the `const`?
That has nothing to do with null pointers. Null pointers and 0 are different concepts and the compiler treats them differently.
I just googled juCi++ and arch looking for the AUR. Only got this thread as a result. Haha Thanks!
I think one of the issues I have is that modern C++ can rely on the compiler to do so much for us. RVO for example. I really don't feel like checking every compiler toolchain from every microcontroller manufacturer out there to make sure they've implemented it correctly for every permutation and subtle instance of when RVO is and isn't applied.
I'm not sure if I was using juCi++ correctly or not but it doesn't seem like it has any sort of automatic build system.
Either work with an existing CMake build project, or create a new C++ project in the File menu. At the moment, only CMake is supported. 
&lt;3
I default to template&lt;class Function&gt; double optimize(Function f). Concise, easy to understand, inlineable.
Looks nice. I think you should post in /r/debian, /r/Ubuntu and /r/Fedora to ask if someone is willing to maintain it as a package and get it into the official repositories.
The stackoverflow thread suggested that this was a common pattern for traversing a tree: void Tree::do_something() { head-&gt;do_something(); } void TreeNode::do_something() { if ( !this ) return; bla(); left-&gt;do_something(); right-&gt;do_something(); } The explanation given was that in C a similar pattern does work: void do_tree(TreeNode *p) { if ( !p ) return; bla(); do_tree(p-&gt;left); do_tree(p-&gt;right); } and C coders have "translated to C++" ending up with this code, presumably not realizing the problem. A corrected version was suggested: void Tree::do_something() { if ( head ) head-&gt;do_something(); } void TreeNode::do_something() { bla(); if ( left ) left-&gt;do_something(); if ( right ) right-&gt;do_something(); } Someone objected that "having to code this way" is worse because you write the null pointer check in 3 places instead of 1. (Although at runtime it is the same number of checks). Of course there are many ways to solve this "problem", e.g. use a non-member visitor.
I will! C++14 by default sounds amazing :)
As for Qt, most were already fixed long ago. The remainding ones comes from third party code such as webkit: http://lists.qt-project.org/pipermail/development/2016-March/025166.html
Not really! If you can demonstrate character and capability that is better(or atleast on par) with the top graduates from the said schools, no reason why we wouldn't hire you.
Thats the portage/system GCC, because the new abi is difficult to apply system wide - especially on an existing install.
`ext install c++` autocompleted for me 
Good lord, that first code snippet makes me feel dirty. Call a member function on a non-existent object? Even if it worked, it makes me deeply uncomfortable just seeing it. ... Now I have to try it. 
I just tried it and let's be entirely honest, it's nowhere near as good as VS. If you want a good non-Windows C++ IDE try CLion. It's the closest you'll get. This is still a fantastic project and I'll continue to try it out.
'Fast' really depends on the context. You mention getting a performance increase with flat_map. This almost certainly because you're looking things up, or in-order traversing far more often than inserting. If your usage was different, where you are altering the container frequently, a std::map might be better. My point is that there are no magic 'fast' containers, but there are containers that are optimized for different use cases. The boost flat* containers are one example of these, the Google hash containers are another. Further consideration also needs to be given to iterator and reference stability. For example, it's not valid to cache pointers to objects that live in a boost flat_map (because it's an array, so it might reallocate). For a std::map this is ok though, so here again the flat_map might be faster to look things up, but you might need to look things up more frequently because you can't cache pointers. 
I've been using Qt Creator as Visual Studio surrogate since 2012 (with Visual C++ / Visual Assist [keyboard bindings](http://cristianadam.blogspot.de/2012/08/qt-creator-visual-c-keyboard-shortcuts.html)) Qt Creator works fine for my workflow: edit code, compile, debug, submit in source repository.
Ya, it was published like a standard course. Honestly, I've only looked at the first two lecture notes, but I found it to teach stuff similar to that of (learncpp.com). I'm not saying you can necessarily learn everything online either, but you can at least get good enough to give yourself a head start and build something.
Change isn't always bad... :)
Yes, `std::regex` was badly broken in GCC until IIRC 5.1, when it stopped throwing exceptionsj when trying to compile a regex. Quite why it was included when it wasn't functional I don't know. It made feature testing and fallback to `boost::regex` harder than it needed to be.
Awesome! I'm under a deadline right now, but when I have a spare moment, I'll be sure to check it out. We have a pretty good code base for testing things like this against. Thanks!
It's advertised as having only C++14 as a dependency, but the examples use boost::asio. Why not just [standalone asio](http://think-async.com/Asio/AsioStandalone)?
Good points. I generally have lots of insertions and deletions (millions per second) of small objects either to a single big hash table or spread over thousands of maps. My hash table and flat_map is much faster since they reduce cache misses and they don't do any allocs if sized properly. You are right open addressing hash tables with inplace storage invalidate all iterators on any modifying operation, but if you are fine with the alloc overhead you can store std::unique_ptr to the values instead and get iterators that don't invalidate (traversal would still be an issue). I think using btrees might be faster than the red-black trees of std::map in almost all use cases where std:map is used. It would be interesting to see benchmarks on that.
Early C++ compilers actually just translated to C, so when you wrote: void Foo::bar() { it might be translated to void Foo_bar(struct Foo *this) { and an invocation that looked like this: Foo *f = 0; f-&gt;bar(); might get translated into struct Foo *f = 0; Foo_bar(f); hth
Devtoolset-2 has rpms built for you so its as easy as adding the extra yum repo and installing. Its not quite gcc 5 but you get access to a lot of the new features
The library itself (stackless_coroutine.hpp) has no dependencies other than C++14. The goal is for a person to be able to easily drop it into any project where you deal with async callbacks. For the example, I wanted to use something that people would be familiar with and for that I used boost::asio. If you want I can make examples that also use standalone asio. 
Is there another async library you use that you would like to see an example for?
Great!
I'd love to see examples that don't use async libraries. What about a function that walks a directory tree and returns file names (using std::experimental::filesystem)? Or how about a string-splitting algorithm that returns const-iterators to the ranges of returned values (or use gsl::span)? There are many uses for coroutines besides just asynchronous I/O.
It's a heuristic. When it works (most of the times), it makes your life much better. In the rate cases where it doesn't, it may make your life worse briefly... but since compilers emit errors in order you just have to fix the first one and try again. From personal experience, in Clang it was a real time saver.
Currently, the library is optimized for async io uses as opposed to generators mainly because I personally use async a lot more than generators. I will provide more support and examples of generators in the near future. 
It isn't, but fixing all (real) errors in one fell swoop is for me more efficient... then again I mostly work on big projects where just checking which file needs be rebuilt takes a few seconds.
**Company:** [Susquehanna International Group, LLP](http://www.sig.com) (aka SIG) **Type:** Full-time **Description:** At SIG, we build some of the most powerful trading systems in the financial markets. Our developers work on low-latency applications that drive our trading. We focus on performance and optimization, while bringing our ideas into production quickly. **Location:** Philadelphia, PA **Remote:** No **Visa Sponsorship:** Yes **Technologies:** We look for the best technology to build optimal solutions. We work with C++11 (Clang, GCC) C++14, Linux, Python, and high performance data structures, along with new technologies we investigate. **Contact:** Zanaya.Wagner@sig.com You can learn more about our technology [here](http://www.sig.com/technology/technology/). 
Pay attention also to [stx-btree](https://panthema.net/2007/stx-btree/). It is a well-implemented B+ tree mostly compatible with `std::map`
Almost, identifiers starting with an underscore followed by an uppercase letter or another underscore are reserved to the implementation for any use.
.
That is good to hear! New apps like this don't need to be so backwards compatible. 
6.1 *is* a major version. In the current GCC versioning scheme, there is no such a release as 6.0.
&gt; I think using btrees might be faster than the red-black trees of std::map in almost all use cases where std:map is used. It would be interesting to see benchmarks on that. This is true (don't have any benchmarks off the top of my head though). It's difficult to meet the iterator invalidation guarantees of `std::map` with a B-tree though, so it's not quite a drop-in replacement.
I realize C++14 is a *relatively* minor update to the language, but it still seems strange that he skips over it *completely*, and writes as if the progression is directly from C++11 to C++17, with nothing in between at all.
&gt; `auto result = FindMinima&lt;Square&gt;(f, initial_value);` This should be `auto result = FindMinima(f, initial_value);` – there's no reason to tell the compiler what it already knows, and some good reasons not to.
Thanks for your feedback! Do you have any specific aspect of the website in mind as a candidate for first improvements? (; As for the sample applications, do you think about sth like "real applications" (I don't know... a temperature sensor with logging to SD card and some display, mp3 player with graphic display, ...) or just some tiny examples? There's a repository with example applications ( https://github.com/DISTORTEC/distortosExamples ), but these will be trivial usage examples of the functionalities provided by the project (currently there are just examples of creating threads), nothing more. I guess you mean something "real" (so the former), but to be honest I would prefer that to be something simple to maintain but - at the same time - quite "fancy" to be interesting for the viewers. These two requirements are usually contradictory and that's the problem... I would like it to be easy to maintain just to focus on the main project (RTOS) instead of playing with "other" projects... Maybe you have some good suggestion for such application? I'd be really grateful for any suggestion!
There are some typos, and also some real errors and omissions here. First of all, while you obviously can't use exactly `make_shared` with a custom deleter, you can use `std::allocate_shared`, all you have to do is write a simple custom allocator (about 10 lines of code). In fact, `make_shared` just calls `allocate_shared` with the standard allocator. This should be mentioned, because the article makes it seem like having two separate memory blocks is insurmountable where custom deleters are involved. Secondly, the article writes: &gt; Fortunately, make_unique is only for convenience That's not true, and it's a topic that has already been beaten to death in previous articles about `unique_ptr`. `make_unique` is important for exception safety; it guarantees that nothing happens in between performing the heap allocation and constructing the `unique_ptr`. Also, as a nitpick: the author writes in the answer to the "puzzle" about the size of `unique_ptr` that it's surprising/tricky that a stateless functor/lambda does not bloat the size of `unique_ptr`. This shouldn't be surprising! As the article notes, the deleter is part of the type of `unique_ptr`. And since the functor/lambda is stateless, its type fully encodes everything there is to know about this. The surprising thing (naively) is that EBO is necessary at all; indeed it is only necessary because the standard stipulates that every member of a class must have a distinct address, which rules out the possibility of having zero size members. Thus, stateless types, when members of a class, will generally take one byte.
Standalone Asio works only with a C++11 compiler and it's headed to a C++17 TS. Boost.Asio, has dependencies. I know of `bcp`, but I doubt it has a smaller footprint as Standalone Asio.
I don't deny it. I have seen a few posts from the guy in the issues on the sparsehash github, and he seemed legit enough. Plus there are tests and whatnot for it in the zip download.
The reason you need examples is so that people can get a jump start on a project without digging through many pages of documentation. Look at the example projects other RTOSs are offering and just offer similar things.
Yes, that's also an issue with open addressing hash tables. It's a shame really that the spec constrains the design so much.
Most of the projects I know either provide nothing, provide some dummy examples (like what I [will &lt;: ] have in the distortosExamples repository linked above) or provide full applications (like webserver or some gizmo with graphic LCD). I cannot really say which is the most popular...
If you don't care about the keys, a slot map might benefit you. It has O(1) random access, insert, and remove, at the cost of dictating what your values key will be instead of letting you choose.
I don't recall, I only remember Sean telling me something along those lines.
well, I think he refers to the image, which does not really contain specifics for multi threading.
That's not really true, there is a "recommended way", it's the way used all over the standard library, and it's the 3rd way. The third way has all of the advantages of the first two ways. You can pass it a function pointer if you need to be dynamic. If you want a pre-written function to get inlined, you can trivially wrap that function in a lambda and pass the lambda. You can pass it a lambda inline. You can pass it `std::function` if it has state. There's no reason to consider 1) or 2), unless you're in a very particular case where you cannot use a template; for instance if you really need to implement this in a .cpp file.
Just speaking on editors: On windows I use either visual studio for smaller projects or notepad++ for larger projects. I also sometimes use kate from the (seemingly abandoned) kde port for windows for searching very large projects. On linux I use KDevelop (https://www.kdevelop.org/screenshots) or Kate/KWrite.
I'm primarily on Qt Creator because I hop between different OS's enough that I like to stay consistent. Visual studio would probably be my #1 choice if I stayed on a single platform. I still will use Kwrite/Xcode/Notepad++ once in a while if I just want to consult some other header files or examples.
IMO, this information should be made a bit clearer in the first paragraph on your 'About' page. I kind of think of what you're doing more along the lines of "IT Automation" rather than system. The word system by itself makes me think of something more along the lines of enterprise architecture than a single workstation.
Emacs with irony-mode is pretty nice. I was using CLion, but got annoyed by the bad parser and general slowness. https://github.com/Sarcasm/company-irony
I saw ya.. :D 
emacs.
Yes and no. No, there wasn't much else that was really *specific* to multithreading. But yes, there were other things that were *useful* for multithreading. For example, generalized lambda captures make it easy to explicitly transfer ownership to a lambda expression. When you're running a thread, you frequently use a lambda expression to specify what it does. Combine the two, and C++14 makes it easy to explicitly transfer ownership to a child thread, which was non-trivial in C++11.
You're absolutely right, there are certainly better ways to approach this and I will try to improve the wording as time goes by. I just needed to get something out the door to gather feedback.
Those who use command line editors, how do you create header and source file pairs quickly? This is one thing that I struggle with, like if it's Python and you want to refactor something out to a class it's easy enough, just a single new file and import it, but I find it a little harder in C++, made header source pair, add includes, edit makefile etc. Is there some command line tool to automate this stuff ?
Thanks. Why do you have to use placement new over existing memory to read the data?
I use Linux as my development platform with Qt Creator, CMake, ninja, ccache. Everything works smoothly and very fast. CLion is nice too but slower (or faster if you are used to Visual Studio).
PluralSight and Infiniteskills both have some good learning material for Cpp.
Currently for my medium-sized research project I use (g)vim + ctags + YouCompleteMe. YCM has been kind of flaky the past few months, but I still haven't found an IDE that works to my liking that works across OSX and Linux. I've tried CLion, and it's mostly okay, but I just can't give up the raw development speed I've built up with vim across both platforms.
vim, lots of xterms (urxvt to be exact). We still use jam for builds, kind of something set up back in the mid 90's that we keep on reusing for new projects. Works fine through cygwin via ssh so I can do a lot of windows cross compilation work without having to deal with remote desktop.
I've actually always had a really easy time working with Netbeans, even though I'm the only c++ developer I know to actually use it. The c++ support is very full featured, it runs on just about any OS, and projects are generally simple to set up. Plus it's been the least painful when I need to set something up with local source code and remote compile/run/debug. Plus like most IDE's it's got a decent vim mode plugin if you want the best of both worlds.
We have to support several platforms so a bit of everything ... Xcode on host machine for iOS/MacOS and common code if I'm working on host, for android platform code I've really been liking visual studio code, builds are all command line scripts on host. I have a couple different vms for Windows builds and here I always use visual studio. Vim or SlickEdit used to be enough, but when the projects got big enough it was just easier to stick with what the others on my team were using because the projects were well maintained. 
Well, you don't know what kind of lambda you'll be receiving when you define that function signature. You may actually not even receive a lambda to begin with. Maybe your user will call it with a std::function, and you definitely don't want to copy that unless you have to.
I have been using vim as my primary editor for years and I'm really satistified with it. If you write simple projects (namely, fast to compile), you can use youcompleteme, syntastic and color_coded for an awesome C++ experience, but this won't work with complex projets or header-only libraries. As for build, I only use GNU Make, I have tried other systems such as CMake, but in the end, Make is really the way to go. 
PS4 uses clang, although I'm not sure how up to date it is (for all I know Sony releases every time clang does, I genuinely don't know.). I don't know anything about the Xbox One except that it's some somewhat recent version of MSVC (as you said &gt;= to 2012). I can't speak to the actual consoles that I was referring to though, NDA, sorry.
Rebuilding/installing juCi++ from scratch for Ubuntu 16 will fix this issue most likely. Not sure why it was linked to a specific boost thread version on Ubuntu, but either way it is a good idea to rebuild after upgrading to a system that is 2 years newer. 
I don't do that stuff often so I just do it by hand. I spend much more time thinking about my code than I do coding so it doesn't make sense for me to optimise the actual writing part. Note I write simulations which are smaller than typical programs (&lt;10kloc).
My linux setup with QtCreator, i3, the software I develop. http://i.imgur.com/oPUcXVZ.png Same tooling as /u/aearphen : CMake, ninja, use of clang while developing (and a CI server, Travis CI, with GCC, and clang on OS X, and MinGW on win32 with appveyor, checked at each push)
I use Eclipse CDT. Initially, I gave it a go out of curiosity. I didn't expect much but I was surprised how well it actually works. It parses modern C++ and it is quite fast at it. CLion is extremelly sluggish comparing to Eclipse (I don't really get the CLion hype). GDB debugging is great as well, you can debug more than one process at a time. For example debugging client / server applications is easy. The only drawback is configuration. It is not intuitive at all and quality C++ parsing unfortunatelly depends on project / workspace configuration a lot. In particular on Eclipse's discovery options. It can parse the build output to find out include directories, macros, etc ... and more, but this is not turned on by default. On a messy codebase, I use vim with ectags for navigation.
I'm on Linux and use Sublime Text for editing C++ with CMake I need to build on multiple servers so normally keep my code hosted on an nfs share but do my compilation on the disk of the physical server using an out-of-source build. Over the last few weeks instead of SSHing to each server for the build I've started to use Docker to have local containers for each server type. This seems to work well and means that I can now have my code and build directories locally on my workstation, while still being able to target multiple Linux versions
Do you use any Vim plugins for auto completion?
My beef with CMake projects in Qt Creator that sometimes it causes the app to freeze for a good part of a minute, even in a relatively small project, when I try to open a file. I'm intending to debug the issue, 4.0 is somewhat better than previous releases, but it is still there. As for the pop ups for variable values in debug mode, they are available for long time in Qt Creator. There are issues with them, sometimes the tend to stay without pinning them down, and sometime, when trying to expand a field, it only does it in the Locals and Expression window, while repositions the pop-up window to the top, and that's it. In general, I hope that it's going to give a better experience in the locals/expression stuff. Would be amazing to have auto-completion, better views for gdb, better support for return value. I'm going to have a go too.
Unfortunately, these approaches use ccache only, not ccache + distcc. CMake environment issue manifests when you try to add distcc to the mix.
It does. It is macro based using a switch statement. In my opinion, it has not achieved widespread adoption due to many people in C++ being wary of macro magic. One of goals for this library was not to use any macros.
 foo *bar = nullptr; bar-&gt;baz(); where baz is not virtual.
Multiple implementations exist. I'll list them in no particular order: [The Boost Statechart Library](http://www.boost.org/doc/libs/release/libs/statechart/doc/index.html), Qt's [QStateMachine](http://doc.qt.io/qt-5/qstatemachine.html), [Machine Objects](http://ehiti.de/machine_objects/), [Yet Another Hierarchical State Machine](http://accu.org/index.php/journals/252), [QP framework](http://www.state-machine.com/doc/concepts.html). They all do very similar things and I'm somewhat familiar with all of them. The fact of life is that communications of any sort can only be sensibly expressed as a hierarchical state machine. Over the last 20 years I've tried all other kinds of more linear ways of expressing it, and they don't scale. They give an appearance of being adequate when you start out, but as your system evolves, it turns into spaghetti code. Of course, you shouldn't have to spell out every little substate by hand. E.g. if you're abstracting your system as a master that sends requests to a slave, you should have a way of automatically creating the scaffolding for the sequence of commands that you wish to execute. Usually some combination of code generation and generic programming provides a balance between maintainability and productivity. I can't overstress how important the FSM/HSM formalism is for reasoning about correctness of the code. Bugs usually pop out at the concept stage when you're designing your states and writing out pre/post conditions and invariants for each.
I occasionally take time off from teaching and working on compiler stuff to write papers. http://accu.org/index.php/journals/2157 http://accu.org/index.php/journals/2198
If you're strapped for ideas, maybe try re-implementing other RTOS's examples using yours. That would give people an easy apples to apples comparison of what you are offering. (More compact code? Better error handling? etc) This seems like a fairly large effort. Are you or anyone else using this in a real application?
I was just about to add a little bit about "required" meaning "what features will I refuse to re-implement to develop this library", but you beat me to it. I don't have numbers on compilers in the wild, but I would start narrowing down the list using criteria such as "latest gcc/boost release in Ubuntu 14.04 LTS". Are you writing this library for fun or profit? Is there a specific industry you're targeting? Those will also factor in to how much effort you want to put into supporting older setups.
Kakoune (http://github.com/mawww/kakoune) integrated with clang for completion/linting, universal-ctags to move around in the code base, and the_silver_searcher for text searches. At work where I am on windows, I run all that in cygwin, and use VisualStudioController to control visual studio from inside Kakoune (to run builds / add breakpoints mostly)
With Visual Studio, 2015 Update 2 is really decent and although there are still some quirks I strongly suggest supporting it. I think it really depends on your library's purpose and target audience. If only people who are working with new language features will find use of your library, then just support the last couple major releases of most compilers and libraries. For example, I wrote a metaprogramming library that requires some C++17 support even though C++17 isn't even out yet. GCC and VC++2015 both support it just fine. If your library will be more general purpose then you should definitely try to stick to bare-bones C++11 and outdated minimum library versions. For example, look at the versions of compilers and libraries used on the long-term support versions of various linux distros. For Windows, try to pick library versions that are easy to build on Windows without needing convoluted setups like cygwin or msys. Consider supporting both MinGW and MSVC. You'll also want to use the same logic as above for your build system - if you're using CMake, I think 2.8.8 is a pretty commonly supported version. But if you can require a newer version I'd say go for CMake 3.1 since you can use [`CXX_STANDARD`](https://cmake.org/cmake/help/latest/prop_tgt/CXX_STANDARD.html) and the likes. (CMake 3 is really a lot better than 2 for multiple reasons, but a lot of distros still ship with 2)
This was the link which helped me when I start working at project that used asio: http://theboostcpplibraries.com/boost.asio 
Go for it. It can be greatly extended as well using metaprogramming to derive different tags. Tags can inherit to simplify operations, etc... So you can create a general metafunction to find the right tag, and then use function overloading rules to match the best algorithm for whatever you need to do.
Myself and coworkers break C1XX all the time, but I can't remember the cause being variadic templates....
It's not *really* dereferencing the pointer. Its just syntax sugar for: baz(bar);
YMMV, but for me, Visual Studio is a complete no-go, at least because of this: [https://www.visualstudio.com/support/legal/mt171547](https://www.visualstudio.com/support/legal/mt171547) &gt; DATA. The software may collect information about you and your use of the software, and send that to Microsoft. Microsoft may use this information to provide services and improve our products and services. You may opt-out of many of these scenarios, but not all, as described in the product documentation. [...] edit: corrected enumeration 
I cannot speak for anyone else, but I'm using this RTOS in a few applications that I was contracted to write. I didn't wrote it just for the act of writing - I wrote it so it could be used in real-life projects. I was really disappointed with other RTOSes that I used and the fact that something was always missing or was always broken (especially with regard to C++ or C++11), so I had no other option than to write my own (; I'm a bit reluctant to making such comparisons (reimplementing the example, showing what changed and what's better) myself, on the projects website... This somehow feels wrong (; I don't have anything against such comparisons, but if I'll be making them, they may be considered untrustworthy or unreliable - after all, my opinion is biased. That's why I would prefer to avoid such direct comparisons and maybe stay with functionally similar, but not identical, examples.
This is a great resource, but the best thing is to just get your hands dirty and use it. I started with one of the simple/blocking examples to write the app I wanted and then evolved it into one of the complex/asynchronous ones. ASIO seemed really overwhelming to me at first, and it's honestly a fairly different way of thinking about things, but doing that made me finally realize how ASIO really works and understand how simple it really easy once you figure out how to "speak its language" (i.e. you're writing a state machine).
What does that have to do with OP's question? What does that have to do with supporting code being compiled under MSVC? Nobody said you have to use the IDE to compile code.
I would really urge you to go with CMake &gt;=3, even if it's a hassle that some distros are still on 2.8.x. A newer CMake can just be downloaded and unzipped from cmake.org, no need to compile anything, so it's really easy for anybody to set up in `/home`. As for VS, go with Visual Studio 2015 Update 2, the C++11/14 support is getting really decent. Don't exclude it if you want your library to be used by people. If I see that a library doesn't support VS2015U2, I'm not going to use it.
You can set up AppVeyor, then, you don't have to have VS installed by yourself. There's also the new VS Build Tools, check them out. I think they're still in beta.
My rule is roughly: support any compiler released in the past 3 years (possibly rounding for important stable distro releases), *once my project is stable*. If my project is expected to have a long development time, that means initially it might only support the latest release.
You are right, but I'm interested in an offline solution. VS Build Tools? Thanks for the hint! However it seems to be an online installer. I maybe will have a look at it. 
Emacs with evil mode which emulates vim. I compile in an xterm running tmux, as we are highly distributed and I need a window for each remote machine I am running on.
Getting a file not found error on that. 
You can also check the source code of the STL2 which is implemented using the Concepts TS (and only works with gcc 6.1): https://github.com/CaseyCarter/cmcstl2
C++ was my first language. I started teaching myself it when I was 17, 17 years ago. I remember being enchanted by the buzz words surrounding the language at the time (*powerful, expressive*). I remember my thinking was, "I wanted **absolute** control over things I was going to make. Today, I think I asked for more power and responsibility than I could possibly care for. Nowadays, I'm burying my head in Swift. I do not think C++ is a great first language, but I would say if you have an interest in the language, go for it. It was the first language for many people, and I imagine many of them are successful (programming is just a hobby for me). If you do go ahead with learning C++, know that you're learning process will probably be more involved compared to learning other languages. There's quite a bit of nuances you have to be aware of that other languages just shield you from (like Inheritance and slicing). Unfortunately I can't recommend any books, but you can't go wrong with Bjarne's Programming and Principles, I guess?
I thought it's [this](https://www.microsoft.com/en-us/download/details.aspx?id=49983) but it's from 2015 and I thought there was a never version. I'm a bit confused, there seem to be multiple versions of this, as MS is trying out different things. They're working hard on it though. It may have an "uncomfortable" EULA too though.
**Company** Phi Optics **Type** Full Time **Description** Our software platform employs device synchronization and fast parallelized image processing algorithms to: 1. capture images with a camera 2. send them into a computational algorithm 3. send the computed output to the UI See it in action at: https://www.youtube.com/watch?v=ymJgcvQjXkc You will implement a production-quality system (development, testing, maintenance) for existing software. **Location** Champaign-Urbana, IL **Remote** maybe - depends on the skill set **Visa sponsorship** no **Miscellaneous** For more info: http://phioptics.com/company/careers/ We are located in the U of I Research Park EnterpriseWorks Incubator - next door to Yahoo, Sony Biotechnology, Raytheon, Dow Chemical, Citrix, Caterpillar, Anheuser-Busch's Bud Lab, and Abbott Labs.
I want to be able to make simple games.Nothing too complex like Call of Duty.More like Pac-Man,Minesweeper,or my own Minecraft rip off.Also simple programs like calculators,passwords,and stuff like that.
Right, that's why GCC now assumes that it never happens and assumes`this != nullptr` is always true.
Even though most of our stuff on Windows is still built with Visual Studio 2010, I use VS2015 for reading and writing code and debugging. I sometimes drop into WinDbg for advanced debugging. I use Notepad++ for editing non C++/C# files and as a temporary snippet board. I use Windows Performance Analyzer for profiling code. I also use a custom tool I wrote to search file system as I couldn't find any decent tools that do what I needed (extension filtering, ignoring files larger than certain size, ignoring case, searching both in utf8 and utf16, simple GUI, good performance). We use Mercurial for our source control so I use TortoiseHG for committing, diffing and viewing history (for pushing/pulling/merging I use command line). I also sometimes use command line to invoke compiler directly if I want to test something quickly without making a VS project.
No. bar-&gt;baz(); is equivalent to (*bar).baz(); [expr.ref]/2 &gt; [...] The expression E1-&gt;E2 is converted to the equivalent form (*(E1)).E2; [...]
Seems so, mixed it up with LUA :) Certainly explains why it is UB then. Only seems to be so for raw pointer types. For class types E1-&gt;E2 with non nested operator-&gt; it should resolve to *((*E1).operator-&gt;()).E2 for a single nested overload *(*((*E1).operator-&gt;()).operator-&gt;()).E2 and so on. Or?
It's essentially impossible to make a meaningful recommendation without knowing quite a bit about you, such as how you think, how you learn, what makes you [un]comfortable, and what sorts of things you want to accomplish. Without knowing at least some of that, almost any recommendation is almost entirely a reflection of how I think, how I learn, what makes me [un]comfortable, and the kinds of things I want to accomplish. If those happen to match your situation extremely closely, my recommendation is likely to be relevant to you. If they don't, it probably won't be. Unfortunately, you know just about as little about most of us as we do about you, so it's just about as difficult for you to evaluate our recommendations and figure out which ones to heed/ignore as it is for us to give recommendations that are really relevant to start with. So, rather than trying to answer "yes", "no" or "maybe", I'll try to outline a set of guidelines for you to consider in evaluating how well C++ is likely to suit you: 1. One of the biggest things to consider is the levels of abstraction at which you're comfortable thinking. Most languages have a fairly narrow range of levels of abstraction at which they're aimed. Assembly languages are extremely concrete. Many functional languages are extremely abstract. Most typical languages (e.g., Java) occupy fairly limited ranges in between. C++ is fairly unusual in covering a much wider range of abstractions than most, all the way from almost as concrete as assembly language to almost as abstract as, say, Haskell (in fact, Bartosz Milewski frequently points out that C++ template meta-programming is fundamentally similar to Haskell, but with much worse syntax). 2. Valuing flexibility over specialization. Some languages specialize in a small range of problems for which they work extremely well. Others generalize a little more, so they're not quite as nice to use for one particular thing, but can be applied reasonably well to a wider range of tasks. C++ takes the latter trend to an extreme. 3. Hierarchical thinking. For example, C++ has what I'd think of as a few "meta-rules" that govern the basic direction of nearly all the rules. At the "bottom" level, there are a lot of actual rules--but if you know the meta-rules and understand the situation well, you can usually just about guess the vast majority of the actual rules (but you really do need to understand the situation--in a lot of cases there's a lot more to understand than is initially obvious). 4. An interest in how things work. As noted above, knowing the rules of C++ requires either memorizing a gargantuan number of rules that may not initially make much sense, and often even seem mutually contradictory, or else having a really deep understanding of how the system (both the compiler, and to a lesser extent, your hardware) works. Most people who think primarily in terms of memorization rather than understanding, find that C++ simply exceeds anybody's memory capacity. Their reaction is usually to retreat to some degree or other--either run to a language that fits the memorization mindset better (e.g., Java) or, if they have no other choice, use C++, but think of it as a dark cave full of monsters, and huddle around their little camp-fire, hoping that if they don't wander off into the dark, they won't encounter the monsters. As far as books go: I think the recommendations in the Stack Overflow [C++ books list](http://stackoverflow.com/q/388242/179910), also linked in the sidebar, is quite good (but I may be biased--I've edited it a number of times, so I wrote quite a bit of what it contains). Edit: a number of people have (more or less) recommended C as a better first language. I have to disagree *vehemently* with this, as a general rule. As previously noted, C is at the "extremely concrete" end of the spectrum. For somebody like an solid-state physicist who started from things like how electrons travel through semiconductors, then progressed through gates, and how wants to move to the next step higher than assembly language, it might make some sense as a first higher-level language. For almost anybody else, C is a spectacularly horrible choice (much worse than C++). The problem with C is extremely simple: it's so close to the machine that even tasks that a reasonable person would see as trivial become serious chores to do at all well in C. Worse, doing them well at all is so difficult that the vast majority of people who think of themselves as C programmers never actually bother. For the obvious example, C's standard library doesn't offer any sort of buffer or string that can/will expand itself at need. This has been the source of *countless* buffer overflows over the years, and countless programmers who write code in ways that are subject to the same. The few (and they really are few) who make a serious attempt at dealing with that still only take a tiny baby-step, and actually enforce the arbitrary limits they impose on buffer sizes. The number who even try to do the job well by creating a self-expanding buffer to handle arbitrary-sized input is so minuscule they're nearly impossible to find. To paraphrase Dijkstra, C is the language of the past for the coding techniques of the past: it creates a new generation of coding bums.
In practice, that's something like what the compiler does when there's no need for a vtable lookup. Not something that should be relied on, though.
Right, that's an old release; the current release is here: https://www.visualstudio.com/downloads/download-visual-studio-vs#d-build-tools EDIT: On the left named 'Microsoft Visual C++ Build Tools 2015'; I couldn't figure out how to link to it directly.
This episode seemed to end somewhat abruptly. The hosts usually ask the guest whether there's anything left he or she'd like to talk about before letting him/her go and it hasn't happened here. Left me wondering why that was!
Pretty much, you only got a few too many dereferences in your code. The pseudo code for `LHS-&gt;RHS` is: while (LHS is NOT a pointer): replace LHS with the result of calling operator-&gt; replace the expression with (*LHS).RHS An overloaded `operator-&gt;` always has to return either a Pointer or an object with overloaded `operator-&gt;`, so no matter how deep the class hierarchy and `operator-&gt;` call chain there is a single pointer returned at the end. One overloaded `operator-&gt;` gets resolved to: (*( LHS.operator-&gt;() )).RHS With two overloaded `operator-&gt;` it gets resolved to: (*( LHS.operator-&gt;().operator-&gt;() )).RHS With three it is: (*( LHS.operator().operator-&gt;().operator() )).RHS and so on.
Thanks. Yes, 'over-engineering' is the word.
Thanks for the link. I have gone through the link and it's pretty good for covering the basics. I kind of know the high level working of Asio. It's just that I get lost in its details. Maybe I should try harder.
it is pretty irrelevant whether baz is virtual. In practice, what happens with bugs like this is that a member function accesses class members. They are normally at some positive offset from this. nullptr is normally 0 (maybe always, didn't look), and memory close to 0 normally does not belong to neither process stack nor heap. So accessing those member ends up in segmentation faults on systems with virtual memory, or in overwriting memory belonging to the system (or reading system data thinking it isyour own), or in invalid instruction traps being generated by hardware, or... Virtual calls are only "interesting" because in typical C++ implementations, they are implemented through a hidden object field usually at offset 0 from this. On systems with virtual memory, this leads to segmentation faults even before a function is called (because code tried to read this hidden member first).
&gt; "That is the C++ preprocessor. Pretty cool. I wish Java had something like that - it would make it so much better." :D And the obligatory `system("PAUSE")` is in the mix as well. The guy uses way too many raw `new` and `delete`s where it is completely unnecessary. Empty destructors, manually setting library paths in VS, ... It's a shame, the vids are really good apart from that! The guy can explain quite well. But he is really not up to speed regarding C++.
These are fantastically written, thank you!
What I really want is a tutorial on autoconf and automake. 
Initially: I have personally found understanding how ASIO works under the hood to be an extremely rewarding intellectual task. That being said, the following video and associated slides are a really good introduction: https://www.youtube.com/watch?v=D-lTwGJRx0o https://raw.githubusercontent.com/boostcon/2011_presentations/master/mon/thinking_asynchronously.pdf Perusing the ASIO examples will give you a much better understanding of how the author generally intends it to be used. Other great examples/uses of ASIO are: https://github.com/vinniefalco/Beast https://github.com/arvidn/libtorrent In fact it's beginning to look like in the next 2-3 years most *"application developers"* may not need to use ASIO directly as most pieces of functionality they require will have been developed as a layer atop of ASIO - which is a good thing, but like all things, any astute C++ developer would endeavour to at the very least have a general idea of what is going on under the hood. 
Cmake is largely considered a superior alternative to autotools these days
If you haven't read them yet I'd recommend it as well. 
To be fairly honest, NO, I would not recommend C++ as a first language; I may be swayed if you had a good mentor at hand, but even then I would not recommend it. The language is gigantic, and much abused. You may find some quality books, but most of the code you'll find on Internet is embarrassing. Furthermore, it is notoriously plagued with large swaths of "undefined behavior"; while they might spur your debugging abilities, they can be *very* frustrating to chase down, and even good tooling might not help much. For a first language, I absolutely recommend an "undefined-behavior-free" language. One where a careless mistake does not lead to a mysterious crash. --- If you consider learning C or C++, I advise you to learn Rust instead first. Any issue that could lead to a crash in C or C++ will instead lead to either a compiler error or a panic in Rust, and in both case you'll be pointed toward the offending line of code with some degree of explanation. Once you rarely make mistake in Rust, you'll find C and C++ much easier, because you will have internalized the rules.
Huge thanks for mentioning AD! I never heard of it before.
Thing is, I'm new to C++ myself and have been trying to learn how to do it on my own for some time. I guess I'm going the 'handmade' approach to it, since I was trying to figure out how to eliminate the IDE and do everything from the command prompt and compiling with batch files and all that. I then discovered the 'handmade hero' project and immediately fell in love with it because the guy had a setup that was pretty fucking close to mine (I've not made anything large enough to make debugging a serious issue, so I've not attempted that yet). I was also taking less of a C++ approach and more of a 'C-style coding with some C++ features to simplify and organize a bit' method. I have no idea if that's a good idea, but that's how I'm doing it. For now. I have, however, considered doing some kind of video series where instead of showing the actual coding going on, I would just post videos where I describe the thing I want to implement, attempt to implement that thing and then document my various frustrations / successes in implementing that thing. I think it could be useful to other newbies who may be watching this sort of tutorial or reading things on the internet and are thinking "how the fuck does someone figure this shit out?" In a lot of ways, the hardest part of learning how to program is that there are like 9 billion ways to do something, but some of the ways are going to get some very negative reactions from experienced programmers because you're using some newbie method or whatever, but you frequently don't get a suggestion for what to do *instead* of that. And then it becomes hard to figure out which of these people are talking directly out of their buttholes. Some people get annoyed because you don't do things the way *they'd* do it, even if your method is fine, or maybe requires a few extra lines of code. We're new. We don't know all of the things that some experienced person knows. Many of us are learning on our own, so we don't have multiple hours of lectures and coursework under our belts. I've been looking for the exact same thing that OP is looking for. I think watching someone else solve these common problems or more uncommon problems would be like taking a virtual internship or something. That's how a lot of people end up learning this stuff, right? They get a job and they end up learning the real-world application of the stuff they learned in classes. It would be nice as well to see how a program - a complicated and fully-featured program - evolves. But I dunno. And games are nice and everything, but some of us don't just want to make games :P
Okay, a clean install did fix the issue. I then did just try making a new project and there was an automatically generated CMakeLists.txt file. So I guess everything is working now. I'd like to formally apologize for being kind of a c*** before. The fact that you responded so level-headed and usefully speaks volumes about the quality of your character.
&gt; Publisher: Addison Wesley Publishing Company (June 1, 2001) While I'm sure this book probably teaches some great programming ideas, I am looking for something that will teach modern C++, i.e. C++11.
&gt; Many of us are learning on our own, so we don't have multiple hours of lectures and coursework under our belts. Most "C++" lectures (note the quotes) at Unis are garbage. Learn from GoingNative &amp; CppCon videos. And, as you mention, alternate that with practical work. I pretty much agree with your post. &gt; Some people get annoyed because you don't do things the way they'd do it, even if your method is fine, or maybe requires a few extra lines of code. Yea, that's a very valid problem. But again, there are enough awesome resources out there, _and_ dozens of link collections of pointing to them, this gets asked here like every couple of weeks.
When I was working on Windows, we were using Visual Studio, I keep using VS 2015 for my personal project, it's my favorite editor by far On Linux most of us are using Eclipse (few are only using VIM or Emacs), but I don't quite like it, the search is slow (when you have a huge project), and the IDE is not that responsible and lack of customization I wanted to use CLion, but we are using Makefile so you can't get too far (i.e. you can forget go to definiton) except having a clean and customizable IDE, I felt it was a bit too slow for huge projects So nowadays I still use mostly Eclipse, but I keep tabbing to use vim for faster code browsing (we have tons of little sub projects)
The guy doesnt ascribe to all things c++ but handmadehero.org is a pretty substantial archive of building a game from the ground up (still in progress). Currently almost 300 (~90min) videos are on his youtube channel, and he streams on weeknights.
This looks like a great guide. I either missed this or it didn't show in my searches at all.
I had a style guide recommending `and`, `or` and `not` instead of `&amp;&amp;`, `||` and `!` at my previous job. Looked pretty nice, actually (albeit unconventional), especially `not`. Gave some "pythonic" feeling to the code.
Given your list of "most advanced" topics, I'd recommend hitting that **books** link in the side bar and look under "Intermediate" or "Best Practices". Your experience seems to mirror someone who has completed a beginner-level book.
`v and_eq compl 0xFF` doesn't look that bad. Is `compl` an immediate word? *...um, wait... this isn't /r/Forth?! er... in that case...* What /u/STL said. 
After some consideration, I'd estimate your level as 2. You need to go and grind some pigs before proceeding to reading scrolls.
Best guess it's something to do with directly accessing/changing memory and Kaspersky doesn't like that. Could be that the address chosen by the linker, to store your variables, is monitored by Kaspersky as well.
If you want to learn all the weirdness, you could try reading the actual language specification. It's written in standardese so it might be tough to read, but it's definitely the most detailed reading you can do on C++.
It's all mentally translated in my head, so it reads the same anyways. I think the reason it was shot down at my workplace was lack of default MSVC support (special flag or something?).
Coming from a primarily python background, I slipped some ands, ors, and nots in by accident and never even realized it until code review when the senior devs were scratching their heads about why it would compile.
I always use symbols, but I can see the value of `not` over `!`, since the latter can be harder to spot visually. I'd never use `or` over `||` because humans tend to mentally parse it as `xor`.
Let's try to see if I can add some questions that you should be able to answer at a given skill level: 1: What's an if statement, what's a while statement. How can you convert a for loop into a while loop? What does break do? What does continue do? Have you ever seen a pointer? What is the function of a pointer to a pointer? 2: What's a class, what's an object, what are operators, why do we want to overload them? What's the difference between a struct and a class? 3: Why do we use multiple inheritance? How do you declare an interface in c++? What goes wrong when you delete an array of objects without [] on the delete? 4: What's the difference between C-style casts, static_cast and dynamic_cast? When should you use dynamic_cast in a well-designed program, and can you accept it in normal development? 5: when exactly do you need an include for another type? What happens when you add a first virtual function to a class in terms of its object layout, memory consumption and so on? How much are virtual functions slower than normal member functions? 6: Can you show an example of a template metaprogram that calculates 5! ? What is template metaprogramming used for? When should you not use templates? 7: What does your class contain when you derive from an interface (as defined above, with virtual destructor)? Why are there three different constructors and destructors in your object file (C1, C2, C3, D0, D1, D2) ? What is empty-base-class-optimization and when does it not apply? 8: Give an example of use of operator comma. Explain how to implement a smart pointer. Explain the concepts behind a shared and a weak pointer. Explain when you would not use standard container classes and why. 9: Give an example of the most vexing parse. What's placement new and when do you use it? Given a class that inherits from two bases that both declare the same function, how would you call either of them from the user of that class' perspective? 10: What's placement delete and when is it called? I have a stack trace that shows an impossible virtual function call from one side of my code base to another; what happened here and where do I look for fixing it? (... open space here for things I don't know about). Open for additions, of course :-) I'm mostly hoping this list gives you names and things to search for to expand your own knowledge.
I use them pretty consistently because I think they really enhance readability. One advantage that you haven't mentioned is that your editor is more likely to highlight them, which helps to mentally separate different parts of a complex expression.
That is what I use (quite extensively) in my personal projects, and that is what I used to teach in a previous life. I think Francis Glassborrow's book also uses them.
Do note that `a &amp; b` differs from `a &amp;&amp; b`, the latter is short-circuiting while the former is not since it's a bitwise operation.
I suggest to use the newest stable compilers, especially if it's a non-commercial product where you don't have to meet requirements set by customers with hopelessly outdated operating systems. * Clang 3.8 * GCC 6.1 * Visual Studio 2015 Update 2 Building statically linked applications in Visual Studio 2015 is easy and legal even for commercial products. You have to be careful with GCC and Clang when using glibc or libstdc++ and possibly revert to a compiler that is available on your target OS. Then there is the clang/libc++/musl path that I'm experimenting with right now. Very difficult to set up. A partially working example is the ELLCC project but they don't care about C++ and don't support exceptions.
At first I had to look if **or** behaves like | or like || . Then I saw this on cppreference: | bitor || or |= or_eq So standalone or behaves like || and not like | as in vb.net. However or_eq behaves like |= instead of ||= . What where they smoking?
There isn't a `||=` operator (presumably because short-circuting due to the LHS would be confusing).
Your short and sweet statement totally ignores the OP. 
I guess maybe I just write unusual code, but VS2015u2 still can't handle most of the C++11 code I wrote four years ago. In fact this very library I'm concerned about has been around for four years and hasn't compiled properly in any VS version since. On the other hand it compiles fine in any GCC or clang since 2012. I'm not really talking about using features they don't officially support. I'm talking about using features they claim to support but every time I do anything nontrivial with them, the compiler crashes on me. Common offenders are variadic templates, SFINAE, and template aliases. I really want to support some version of VC++, but it's always horribly painful when I try it.
Fedora 22: gcc-5.3.1-6.fc22 CentOS: Build from sources or use a Fedora repo. OpenSUSE: https://software.opensuse.org/package/gcc5 RHEL: Red Hat Developer Toolset 4 Bottom line: Still "NO!".
 - [Modern C++ Design: Generic Programming and Design Patterns Applied](http://www.amazon.com/dp/0201704315/) - [C++ Template Metaprogramming: Concepts, Tools, and Techniques from Boost and Beyond](http://www.amazon.com/dp/0321227255/) Both act as great introductions to the static side of C++, but both also push the boundaries of the language as much as possible with C++98. Much of the code can be rewritten with C++11/14 much more neatly, but the ideas presented are still all 100% relevant, and fundamental if one hopes to understand the use of `&lt;type_traits&gt;`, `&lt;ratio&gt;`, etc., or especially the implementation of the standard library.
To be honest I asked because my first reaction was "this doesn't compile". After seeing it compile, I thought "then this isn't standard code". After seeing it was standard, I couldn't come up with any major point against it other than "others will go through the same thought process and see my code as crap". Now, if I want people to think of me as a knowledgeable programmer just by looking at my code, then I guess the correct option is to write it the way they expect it to be written. I'll start using `and` when people see my name and say "oh, this guy is good" *a la u/GabrielDosReis*.
Mathematical equations used to be written in full english. Before the 1700s most people didn't even use `=` to represent 'is equal to'. If we were to take away all symbols from your example, it would end up as: distance is equal to acceleration multiplied by time to the power of two.
Here are some slides from a presentation by Michael Caisse at BoostCon 2010: [Getting Started with ASIO][1] Here is the video of Michael giving that presentation, although the slides are easy to follow without watching the video: [Michael Caisse: An Asio Based Flash XML Server][2] For more general information on the design, read up on the [Proactor pattern][3]. [1]: http://dl.dropbox.com/u/10282384/asio_presentation_with_story.pdf [2]: https://www.youtube.com/watch?v=9X45eBYkBv4 [3]: http://en.wikipedia.org/wiki/Proactor_pattern
Good because you can write a video game in it, which is among the typical motivations for starting computer programming. 
Frankly, the template will just complicate everything. There are only two real types which are `float` and `double` which can be handled by the same algorithm (complex and fix point require different algorithms). You go 'a la Fortran and just have a #define that changes the precision of a `real` type. 
The only way this would be related to this discussion is if you wrote out the operators. So no astrix or equal signs or brackets for that matter. This is a discussion about operators not variable names. 
Just because something is possible doesn't mean it is the best path to take. A lot of people getting in to programming now are in high school or younger. They aren't trying to make a full commitment to EE or CompSci they are just trying to figure out if they would like programming or not and a scripting language is much better for that than C.
They're mostly intended for use on systems that don't have full ascii-equivalent character sets. See also digraphs and trigraphs. %:include &lt;iostream&gt; int main(int argc, char *argv&lt;::&gt;) &lt;% if (argc &gt; 1 and argv&lt;:1:&gt; not_eq NULL) &lt;% std::cout &lt;&lt; "Hello, " &lt;&lt; argv&lt;:1:&gt; &lt;&lt; '\n'; %&gt; %&gt; Has a charming HTML template feel, doesn't it? 
I wasn't trying to pretend that I'm not a beginner, I'm just here looking for some insight/advice.
I am all for fully written out variable names. But I think it does not create additional mental burden using the operator-symbols, nor does it help to write them out. Just avoid the exotic ones.
Handmade hero is basically c though 
Devil's advocate: bool err = false; err |= (seek(fd, 0, SEEK_SET) &lt; 0); err |= (read(fd, buf, size) &lt; 0); 
 I might use them, but they don't work in VS2015--soo.. Or more specifically, when I enable /Za to turn them on, everything else breaks. Suddenly "_vectorcall" doesn't exist etc. I think they should be on by default, and shouldn't have anything to do with _vectorcall 
And let's not forget Effective STL. It's a shame how people are led to think that Meyer's older books are outdated, as if C++ somehow stopped having its older features, when in fact Meyers pretty much assumes in his later books that everyone's up to date with his writings. EMC++ only covers C++14 features, but C++ still has pointers, templates, inheritance, overloads of all kinds, and exceptions, among other things. Also, Herb Sutter's GotW blog posts are great reads for anyone who truly wants to grok C++.
The word 'and' would be a sensible alias for logical (&amp;&amp;), but would be nonsense if used to mean a bitwise operation. (I don't know how the standard was written though.)
That's COBOL. 
Kind of. It does if you're looking at the file in your favorite editor (I'm not even sure they all support this, since I wasn't aware of it) and not something else like a raw git diff or something that's _not_ your favorite editor. That happens a lot to me. I have my IDE setup exactly the way I want, then I use a diff tool which is OK but doesn't support some things or our online code review tool which is also OK but supports even fewer things. My biggest beef right now is with our code review tool not supporting visualized whitespace, but it highlights so few things I wouldn't be at all surprised to learn it didn't support highlighting alternative operators. Edit: Then there's the all-too-common workflow of looking at code on another developer's machine that was apparently configured by satan.
That is the silliest comparison I've ever read. In programming you only put the final equation. In mathematics we usually have to describe what we're doing, and go through several steps. For this reason, repeating the 'variable names' every time is extremely repetitive. Additionally, I've really never had much trouble knowing which variable is which in maths. If something is ambiguous, it's defined somewhere close. And then everything else is much easier to read.
http://imgur.com/Sdwf4oO VS 2013 + Resharper (if relevant) supports it, provided you include the headers for it. http://imgur.com/pNjWhZ5 Git does not parse it though, and you're right, it does sort of making it hard to read properly. 
I'm playing the devil's advocate here, but that's just a convention.
I'm playing the devil's advocate here, but that's just a convention.
I have literally never seen these alternative operators used "in the wild" so I wouldn't be surprised if lots of otherwise very decent IDEs didn't recognize them. Or they all could. Lemme check VS2015+VisualAssistX right quick... [Here.](http://i.imgur.com/Lw6GMp8.jpg) They're colored like operators but it whines about the first one. YMMV.
`and` looks too much like the conditions/variables. `&amp;&amp;` stands out way more. I've read some codebases with word logical operators and they were really confusing and hard to read. Like /u/TemplateRex, the only one I'd consider is `not`. But I've tried that for about a week, and it honestly felt even more confusing than `!`. I switch to a different font and now I don't think I ever missed a `!`. If it's still a problem you can always do `== false` or `== nullptr` instead.
It doesn't solve it, it only partially helps it.
Aren't those just defines anyway? Meaning they'd look like other macros in color as well. Edit: They are.
That would be one of the few cases where I'd write `if((a &amp; b) != 0)`, to make the intention clear, unless b is named something like `bitmask`, then it should be obvious.
From my other comment in this tree, [this](http://i.imgur.com/Lw6GMp8.jpg) is VS2015+VisualAssistX. The highlighting is correct but it does intellisense-whine about the first one.
Did you include the header? http://www.cplusplus.com/reference/ciso646/ Mine threw [an error](http://imgur.com/nwUfKv5) until I did too. Actually that makes sense, purple is macro for me. It just recognizes it as a macro instead of an operator.
I didn't realize there was a header for the operators, I assumed you meant a header for resharper. Of course on actually thinking about it that doesn't make any sense, so yeah probably whatever header it is would fix the intellisense error.
I've been moving beginning C++ programmers away from &amp;&amp; to and, simply because so many of them do bitwise ands by accident. They still learn the ampersands, but it helps cut down on inexplicable (to them) runtime behaviour. For older programmers, well, it doesn't matter. You do appreciate it, though, when you get stuck on foreign keyboards. (And VIM is a surprise a minute...)
Fair point. You might want to edit your original post to make this requirement clear.
I've been using them exclusively for the past 17 years. On the plus side, it makes it easy for me to recognise code that I wrote. On the down side it makes it easy for others to recognise code that I wrote :-)
All other operators in C++ are composed of non-alphabetic characters. 'and', at a glance, looks like the name of a variable or class or something.
&gt; whereas an if would only check once The equivalent would be if (!err) { err = (seek(fd, 0, SEEK_SET) &lt; 0); } if (!err) { err = (read(fd, buf, size) &lt; 0); } which would also check each branch. And if you have 20 statements to execute, you wouldn't make 20 nested `if`s, right? This style is pretty common in certain areas, for example, where MISRA rules are in force. And that's precisely why I'd expect compilers to optimize it.
Its a good challange for the reader: implement the ideas in moder C++ manner
Any news on when the slides will be available?
You need the template specifically to handle automatic differentiation. To evaluate the derivatives of a function, you use a special AD type which will track derivatives for each operation in the function. For a concrete example look at the AD type used in [Ceres](https://github.com/ceres-solver/ceres-solver/blob/master/include/ceres/jet.h). More generally, tempting mathematical functions like this allows access to higher-level tools, which are ruled out if you specify `double` as the type. For example, you could pass in an interval type, which will generate rigorous bounds on the function over a region.
+1 for CMake: I spend almost a day recently to figuring out how the automake system works in a specific project because I have to integrate a new module for that. I dont have enough time for that so I remove the whole buildsystem from the project and started to read the CMake documentation. The result: I learned the basics of CMake about 2 hours and created a well working CMake buildsystem for that project which does everything what autotools done.
I use them exclusively in C++, both at home and work; the only exception being when doing "mercenary" work on another team's code base. I have never had any IDE issue (both Eclipse and Notepad++ clearly distinguish them) and I have found that the slight increase in verbosity is largely offset by the gain in clarity: - `&amp;&amp;` and `||` are too close to `&amp;` and `|` for comfort, just a typo away - `!` is nigh indistinguishable from `l` or `i`, especially when written without a space: `!imbo` vs `limbo` the keywords do not suffer from this, you cannot mistakenly write `bitand` instead of `and` or `not imbo` instead of `limbo`. At first my coworkers were scratching their heads a bit, but after a few code reviews pointing out mistakes they would not have made had they been using keywords, they all switched over.
If you don't put it in the tutorials and beginner documentation (i.e. "A tour of C++") - you won't see it in code. I didn't know about this - and it is not in beginner books as far as I can tell. People would rather only hold one set of rules in their heads and probably don't want to learn how to parse old and new c++ code. 
On linux, I used a small bash script with the class name as argument to bring the template .cpp/.h files and replace the necessary include guards etc. If you're using vim, you can drop into the shell, call the script and come back. Pretty convenient. 
Coming up next: "A cache miss is not a cache miss: the OP discovers branch (mis)prediction" ... :D
Definitely more likely to be a beginner's mistake. I actually started considering these operators because I was asked to give a small C++ intro to two 16yo guys with only PASCAL experience. In PASCAL the equals logical operator is only `=` (instead of `==`), so they would confuse them pretty often. Same happened with `&amp;`, it would compile and run, so they wouldn't think that part of the code was wrong. I realize this is a very particular case, but some advantages of the alternative operators are still valid to more experienced programmers, I think.
Using the name of the short-circuting operator or for the non short circuting or_eq instead of calling it bitor_eq seems just as confusing to me.
Thank you for the positive feedback. For future readers: we now got a currently open issue on this marked with help wanted: https://github.com/cppit/jucipp/issues/204.
Removed - not related to C++.
that's a completely fair point! I never use &lt;regex&gt; so didn't notice...
C (not C++) as the first programming language; the only problem is that you will have to program in console. If you wish to program in GUI, you might have a look as Delphi. P.S. All this if you are working in Windows.
Sure, for many people the results in the post are obvious. Meanwhile, I frequently hear discussions on the performance of various data structures where data dependency of cache misses is completely ignored. Therefore, I think a few people will find the results interesting.
I find the conclusion/title to be misleading. The cache miss is still the cache miss. That you have to wait one cache line to come in before missing on the next (the data dependency of which you speak) is a somewhat orthogonal problem, not necessarily related to cache performance.
Your shell font is awful :(
1st thing that comes to mind for me is to prefer inheritance to switch statements that call functions. This speeds up ruby considerably, I suspect a C++ compiler can handle individual language built-ins better than things composed of multiple language primitives. I suppose a benchmark is in order. Then there is this this stack overflow showing using an if in a CPU bound loop on sorted vs unsorted data: http://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-an-unsorted-array So I guess prefer sorted data. But then you might just move your branch mis-predictions into your sorting algorithm. 
I don't see any results in any of my browsers.
if they are proven to be a burden in a critical path, you can benchmark and try the following: - reorder your code so you don't need that branch (if applicable) - static branching (e.g. constexpr_if) - reorder your code to make the most likely condition first - use compiler specific built in for likely/unlikely (e.g. __builtin_expect) - loop unrolling (best way is to hint your compiler or to have a static condition so the compiler can unroll for you) If you want more details, you can have a look at: - [What Every Programmer Should Know About Memory ](https://www.akkadia.org/drepper/cpumemory.pdf) (must read material!) - [Intel article about branch mis-predict](https://software.intel.com/en-us/articles/branch-and-loop-reorganization-to-prevent-mispredicts) (small article)
I've felt like for the most part I would be interested in reordering my code so that branch prediction is not needed. Although when I think of such cases like if based movement vs just adding and subtracting based of keys pressed it results in additional addition and assignments but I get rid of the branches. I'm not a fan of compile time things so I will probably be avoiding that. I've seen likely/unlikely but I feel like most of the time I would be using a if statement what is likely and unlikely would switch depending on the player's input and would flip ( like a player holding a key ). At that point I feel not using likely and unlikely would result in a more predictable branch. I like the idea of loop unrolling but not sure of how to trigger it. As for most likely first, would the cpu not notice a pattern of which one is more or less likely and figure it out on its own? ( yep dynamic branch prediction seems to follow this idea ) but it's good to know that static branch prediction defaults to the true case.
It seems naive to dismiss a person entirely because of their opinion on a very specific topic. The "person" who posted this link (I'm assuming that's what you mean by the submitter) I believe is the reddit account for Meeting C++, a C++ conference based in Europe.
I'm talking about the shell on the right
There is a fair amount of people who dislike auto and the almost always auto style. I wouldn't call someone a moron for this...
I've started reading *Generic Programming* and it's very interesting --- the idea of "policy classes" doesn't resemble anything else I've learned about yet. Thanks for the pointer!
&gt; for a nullable non-owning reference use T* reference_wrapper seems safer and worked for me.
The Design and Evolution of C++ The Design and Evolution of C++ 
Is this library compatible with MSVC? The compilation instructions say it requires an ISO compliant compiler and a "Posix compliant shell" to build. On the other hand the release notes of v1.6.0 say "Fixed compilation issues with VC++".
There is the [Nash embedding theorem](https://en.wikipedia.org/wiki/Nash_embedding_theorem), which roughly speaking states that a curved `M`-dimensional surface can be mapped to an `N`-dimensional grid with `N &gt;= M+1` while preserving some nice properties. That does not mean that any non-linear system is easily solvable, just that it can be interpreted as a lower-dimensional projection from a linear system. Relatedly, the [manifold hypothesis](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/) posits that natural data forms lower-dimensional manifolds in its embedding space. Neural networks are a way unfold such data into the embedding space and detect patterns that are not easily visible in its original form. So "tacking on extra dimensions" is only the beginning, you then need to find the nonlinear mapping (e.g. fit a neural network) that actually transforms the original problem into linear form.
Stepanov. thank me later. https://www.youtube.com/playlist?list=PLHxtyCq_WDLXryyw91lahwdtpZsmo4BGD https://www.youtube.com/playlist?list=PLHxtyCq_WDLXFAEA-lYoRNQIezL_vaSX-
NeoVim seems to be the best approach. Just commented on this in https://github.com/cppit/jucipp/issues/163. Thank you. 
You can also try getting the compiler to emit conditional moves instead of jumps. That way you never pay for a misprediction, but you might slow things down with false data dependencies.
&lt;ciso646&gt; looks really great. #define and &amp;&amp;
Also Intel compiler do NOT support this too.
Yes, with the proviso that it is hierarchical, and that's at (or very close to) the root of the hierarchy. It leads to quite a few lower-level meta-rules, such as: "garbage collection is optional", "you can decide how to allocate objects", and so on.
Any reason to not embrace C++14, since it's the fixed version of C++11?
The "moron" stems from his argument why he hates it, so much more than his conclusion that he does. Luckily, comments on his blog are decent :-) Harsh word though :-)
Headline is pandering to the wrong crowd. As you point out, there's very little reason to stay on 11. 
No CPU will guess the jump target of a cold virtual call, there are too many possibilities. It could literally be _any_ address. Branch target prediction only applies when the cache is hot, and fails if there are many different functions resolved by the virtual call.
The header `&lt;ciso646&gt;` is actually specified to have no effect, but MSVC uses it to define macros in place of supporting the operators as keywords. Actually they do support them as keywords, but only in the ["enable obscure compiler bugs"][1] /Za mode, which cannot be used. [1]: http://clang-developers.42468.n3.nabble.com/MSVC-Za-considered-harmful-td4024306.html
Sounds like nice material to blog about!
Branch target cache, it's another one :) The big issue with vtable calls is it can't be predicted from the code or current registers where the call is going, because it's too indirect
&gt; "Math people" use a symbol which looks similar to \^. ∧
The source of cmcstl2 is a far worse concepts tutorial than even the TS itself; cmcstl2 does some really horrible things to avoid concept bugs in GCC. That said, cmcstl2 source is a decent tutorial for how to implement concept libraries that don't trigger the bugs in GCC ;)
yea but at that point you could write if(!err) and it makes more sense than arbitrary ||=
I have now added tables of data for viewing with js disabled.
Come on... you ask this in a c++ place - what answers do you expect? Of course lots of people here love c++ and will promote it, which is totally understandable! Better inform yourself in a more neutral place...
The Seattle one says it's on April 20. Is there a link that needs to be updated or something?
Ah, thanks for catching this one. not sure, but they should meet, usually 3rd Wednesday like my own user group.
Okay I'll look into that, thanks!
You might want to look at unreal engine. It's a full source commercial C++ engine that has one of the cleanest code bases around.
You are going to want to start off learning a graphics library. I'd recommend OpenGL. I used this tutorial when I got started, and prefer it to a lot of the others that are out there. Its simple, and the progression that he goes though is very appropriate, I think: http://ogldev.atspace.co.uk/ Another thing to look into is SDL (https://www.libsdl.org/), a library that makes it easy to do cross-platform window management, I/O and events. Once you get the hang of those two, plus lots of trial and error, you should be on the right track.
I can now see the results... Thanks! :-]
You might check out Handmade Hero: https://handmadehero.org/. Everything built from scratch, no libraries, done in real-time video episodes. Admittedly mostly C, but it'll help answer the "how it fits together" questions you have.
It frequently does not, however. Profile-guided optimisation is amazing though, as it can convert virtual calls to a comparison of the vtable pointer and a direct call, skipping the memory read and removing the stall in the common case, even for cases where the compiler can't normally predict the call (most of them). I would highly recommend PGO. EDIT: I believe LLVM (used by clang) has _just_ gained this feature! http://reviews.llvm.org/rL267815
If it's your first game, I highly suggest you to start with [SFML](http://www.sfml-dev.org/), it's a light multi-os library that is easy to use, with a lot of useful documentation, and very easy to learn from 
That's pretty cool! I really like the PerfCounter class you implemented, very practical. Snapshot has too much dependency for my taste. If I were to use it, I would actually create a Snapshot light class just printing the results for difference counters. And any reason why Snapshot takes a FILE* as input rather than an std::ostream&amp; ?
&gt; For eg, when calling this function in MSVC(VS 2015) and g++(4.8) like this &gt; &gt; vector&lt;int&gt; v(50, 0);// 50 elements each filled with 0 &gt; sortReverse(v); &gt; &gt; caused an access violation/segmentation fault. Needless to say how giving a wrong implementation of the comparator function can not only lead to wrong behavior it can also leave security loopholes in your code.!!! If they do really introduce a security vulnerability I would like to know which performance optimization makes this worth it. If the performance is not worth it I'd rather have the implementation `assert`/`throw`/`abort`/`terminate`/... During the stabilization of Rust's `PartialEq` and `PartialOrd` traits the question of making them unsafe to implement came up. The motivation behind this discussion was actually `std::sort` but nobody could come up with an optimization of a sorting algorithm where this optimization provided any performance improvement. And well they don't introduce memory unsafety per se and unsafe code cannot rely on them returning meaningful results for memory or thread safety anyways. EDIT: it seems that MSVC actually asserts that the compare function meets the ordering condition, maybe /u/STL has some insights.
Check SDL/SFML &amp; OpenGL. [Lazyfoo SDL Tutorial](http://lazyfoo.net/tutorials/SDL/index.php).
Recording is hard, the Seattle Group does it some times, most other groups don't. Its already hard enough to get people present, recording the talks would make this even harder.
.
What is video about? About resizing the editor window? :-))
Yup, mostly showing the text wrap (a threadpool actually does the job by splitting workload into chunks) and some textures being mapped over. I didn't plan to write YACE - *YetAnotherCodeEditor*, also because there's plenty of great ones out there.
In addition to ogldev great tutorials, http://www.learnopengl.com/ is another awesome series It has more intermediary images, and is a little nicer on the eye (imho) but doesn't cover some of ogl topics Those two are definitely my favorite opengl tutorials
[removed]
Good follow up. &gt; The results are interesting and unexpected for me. Delegate version I wrote is incredibly slow but std::function is pretty fast though 50% slower than the raw function call. For me the choice is obvious - I can live with managing unique identifiers for std::function, the speed for me (as a game developer) is much more important. I'm glad you were still willing to post a follow up. Not everyone would be so humble. It's also good information for others to know. A sincere thank you for doing the measurements.
This looks great! (sent you a pm)
/u/stl help! You're ~~our only hope~~ the only MSVC ~~compiler~~ dev. whose username I know off the top of my head!
I've been on the vim + plugins train for about 10 years now. When developing on windows I even have the vim plugin for Visual Studio. I can't live without it. As far as compilers, I would recommend Clang family since it has productivity tools as well, e.g. clang-format (which can be vim plugin). My preferences for build systems are cmake and the make family. My two cents. I can explain my reasoning if you want. My background is almost exclusively c++.
I think /u/stl is an MSVC library dev, not compiler dev. Which is also exactly the kind of dev we need.
Reckless logging is a high-performance, asynchronous logging library akin to spdlog or g2log. This version adds rigorous error handling both for errors in the back-end writer and during string formatting.
Submission titles on reddit are final.
Are you a visual studio user? There are plenty of IDEs out there, it is just a matter of trying them on to see which one fits you the best. However, I would recommend not tying yourself to an IDE. Find an editor that suits you. Sublime, CLion, Geany, QtCreator, Emacs, Vim, whatever suits your preference. Then familiarize yourself with gcc and clang usage from the command line. Lastly, try out a few build systems, make, cmake, qmake, autotools. Most likely you'll encounter several, so unless you plan on working exclusively solo, you will need to have at least a little bit of a broad base of understanding.
QtCreator will provide a VS-like experience with compiler (&amp; cross-compile for Android &amp; friends) toolchain and GDB / LLDB / Valgrind / cppcheck / clang-analyze integration
Hm, probably. In any case I know for sure `std::mutex` has always been very slow in MSVC, so I use wrapped `std::atomic_flag`.
For build system, I recommend CMake and the Ninja generator. I always miss Ninja when I start a build with MSVC.
That's fair. I mean more that until I need one or become one, they're both doctors :)
As the blog post says, `std::mutex` wraps a Win32 `CriticalSection`, not a Win32 `Mutex`.
Well, this was on the topic of games (as that's what both I and OP do), so that's not a problem. I've usually only had 2-3 threads on spinlock, so I've never encountered the spinlock threads being higher than number CPU threads, but that's certainly a valid concern.
Honestly, at this point you can use any of: QtCreator, Netbeans, Eclipse, Visual Studio Code, Clion. Each of them has small niches that they do better than other. I would personally recommend Netbeans due to the build based scanner that correctly detects macros used during the compilation. Plus Netbeans and Eclipse are the only ones that support call graphs for data elements (extremely useful tool). Remote development using Netbeans is also very straightforward.
&gt; Thought stl provides a great way to store functions and call them later it simply not fulfils my requirement - function callbacks should be added and removed runtime. Also the same function shouldn’t be added twice. This is very unclear. The target of `std::function` can be added and removed at runtime. Also, the same function not being added makes sense in terms of your dispatcher, but not in terms of `std::function`. But you haven't even mentioned dispatcher in this article yet, and it was not the main focus of your last article. So this completely confused me when I read it. Even after reading the whole thing it's not wholly clear. &gt; Recall that in order to create a wrapper around a member function we need to bind it with `std::bind()` No, we don't. We can just use a lambda. Just say [no](https://www.youtube.com/watch?v=zt7ThwVfap0) to bind. Specifically, you can create a wrapper for a member function pointer with the following one liner: template &lt;class T, class R, class ... Args&gt; auto make_function(T t, R(T::*mem_fn)(Args...)) { return [t, mem_fn] (Args ... args) mutable -&gt; R { return ((t).*(mem_fn))(args...); }; } This is much simpler than all of the placeholder shenanigans. I'm copying around the type instead of using a shared_ptr but you get the idea. I'd suggest maybe asking a friend to read over your post to give you feedback, I find that your posts jumped around a lot and weren't sufficiently pedagogical to be easily read.
Visual Studio Code cmake C++11 or greater Advanced Programming in the Unix Environment Effective C++ &amp; Effective C++11
We were able to implement almost every occurrence of constexpr in the C++17 STL, shipping right now. mutex's ctor is indeed one of the few exceptions.
Gcc, llvm/clang and clion
Oh, so it does. It's a SRW lock on Vista+ and a CS on XP, and I assume the author only cares about 7+.
Is your handwriting better?
What threading architecture are you using?
Just a tip: it's probably worth putting a couple of screenshots on the Github "front page" for your project so people can get an idea of what the project is about without having to download and install.
On XP, we're powered by ConcRT, not the WinAPI, because ConcRT did the hard work to implement condition variables.
&gt; However, I would recommend not tying yourself to an IDE. IDE makes development a lot easier on larger projects (go to definition, declaration, call graph, etc.).
I've used Netbeans for the past year and I can say it's very usable. Even setting up LLVM is straightforward. BTW, how do you set up remote development with Eclipse?
No, I mean, what threading model are you using? A threadpool shared between systems, a threadpool per system, *etc*?
Was Sublime Text user, then switched to Atom, now switched to Visual Studio Code because I dev on VS on Windows. VSC is pretty new and has some issues but it also has lots of potential (big company, fast-growing community). Has many features of VS but is much more lightweight. To build, I recommend scons. It's a very easy build script thingy that uses Python. Very convenient.
A very interesting approach. For the right case this would be awesome. The extended lifetime of the arguments would be tough though. Good addition to the logging world.
No, they are not. std::mutex in C++ is a process-only mutex, the article explains that in MSVC it's implemented with a SRWLOCK, libc++ also uses lightweight locking as well as all other STL implementations I know of. We have some mutexes hit 1-2 times per-frame that are almost contention-less. This is one of the reasons I noticed the odd behavior on Windows - the call was significantly slower (relatively) than the same call on other platforms.
My favorite setup: IDE: QtCreator or Eclipse (vim is great for almost anything, but you may enjoy better autocompletion, automatic refactoring, integration with other tools); Automatic documentation: Doxygen; Build system: cmake 3.0 or qmake; Unit testing: GoogleTest; Static code checks: cppcheck; Version control: git; Memory checks: Valgrind; Graphics: Qt libraries; Libraries: Googletest, Boost, Qt. 
1-2 mutex hits per frame seems extremely little.
Thank you. This is a reaction that I've seen before but I don't think it is an issue in practice. If you worry about the lifetime of the arguments then you can just pass them by value. Other logging libraries are basically doing this already, except they pass the value encoded as a string. Unless your object is noncopyable or its state is much larger than its string representation, you will still benefit from this approach. Another benefit from sending the log arguments verbatim is that your formatter doesn't have to produce a string at all. It could encode the data as ODBC parameters or similar for passing to a database, or some binary structured format, or gzip compress the data directly, or whatever you can imagine.
Here's a good book on real-time rendering: http://www.realtimerendering.com/ There aren't any books/forums that contain C++ projects that teach you everything from beginner to expert because computer graphics is a huge domain with many sub-domains. Many of these sub-domains are large ( ex: anti-aliasing, optics, physics, optimization ) and are populated with their own experts. Thus, being an expert in C++ does not make you an expert in computer graphics or any of its sub-domains. I think a lot of people would say that, no matter how book smart you are about C++, algorithms, and data structures, you need to put in 5-10 years to become an expert. Further, a large part of being a well-rounded expert in C++ has a lot to do with systems design, people skills ( being an expert isn't much use if you're an asshole to whom no one will listen ), and knowing what not to do - being able to see certain pitfalls in advance, and being able to say when certain pitfalls are acceptable / nicely aligned with the realities of commercial software development. Write code. Find a mentor. Fare thee well.
Here's an approach: * Practice. Practice. Practice. * Get your work reviewed by other developers and really think about the feedback you get. * Get a mentor to guide and challenge you.
Hmmm.... Ok.
Picking a project to learn/practice C++ with is probably the least important choice you need to make. Find a mentor, and the mentor will suggest projects for you. Wax on. Wax off. Don't expect your early projects to have value to the world. Focus on learning. I would suggest treating C++ and Graphics to be separate topics, and learn them individually. You'll need mastery in one, in order to focus clearly on the second. Then again, I'm not your mentor, ymmv.
Here is a good and rather easy to understand book about [design patterns for games](http://gameprogrammingpatterns.com/) which I recommend. Knowing C++ in detail does not imply being a good software architect. However, the latter is utterly required, otherwise all that comes out is a big mess of crappy code no one will understand :-)
Participate in an open source project that encourages code reviews.
From everything you've said there is one book above all others that you want - physically based rendering by Matt pharr and Greg Humphreys. That is your Bible. It explains in detail how to implement a full production quality renderer. A 3rd edition of the book will come out soon to complement the 3rd version of the renderer which is already on github. To compile it you need a recent C++ compiler since it uses alignof. An older book that is still amazing is advanced renderman. Renderman is free and you can write plugins for it. Pbrt is on github and 100% open source under the bsd license. A program called touch designer is amazing for writing shaders in real time. I wouldn't spend time on an obj loader, just use the tinyobj loader library and move on to something more interesting. There is also a tinyexr library out there for saving exr images as well as the main exr library. Renderman comes with a good image viewer. 
This actually isn't bad advice, except that Linux is written in C if I'm not mistaken. Most of programming is actually debugging, and you would certainly learn a lot about debugging whilst working on drivers and kernel bugs.
Thanks for all the replies. I was hoping for more of a consensus. :) Now I'll have to try everything out. 
Kk
Sounds cool.U guys are really being very helpful.
Actually not a bad idea.I am always afraid to try cuz I think my code will be laughed at..Hahaha.
In MSYS2: pacman -S mingw-w64-x86_64-sfml will solve this I think, that is using MSYS2's sfml libraries. Have not tried juCi++ with non-MSYS2 libraries on Windows actually, but you can try hardcode the linking maybe, as Find_SFML.cmake is probably looking for MSYS2 libraries. Feedback on this is welcome though! 
i almost googled 'overdad' to see what it meant
Sadly I think you need a change of attitude here. The reality is that some book learning often away from the computer is required to get to where you want to go. Being an expert in this field implies being able to implement new techniques and approaches in C++ code. Knowing C++ itself is nothing in context as C++ is just a way to implement new technology. In other word ea great programmer in this niche world requires you to understand the underlying graphics technology.. 
Your post has been automatically removed because it appears to be help/homework related. If this has been in error please message the moderators. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Having had worked with UE3-&gt;UE4 professionally for some time, I'd hardly call it state-of-the-art in regards to its usage of C++ or even modern programming principles.
You're right sir, will put some when updating for the next release
You can throw something and catch it in main...?
what if I'm a library - I don't know if the user will catch everything in main - and if an exception is not caught anywhere - there is no stack cleanup.
That would be nice. Until that day happens, you can use `__cxa_atexit` (part of the Itanium c++ ABI). If it's not available, you can write your own `__cxa_atexit` and register your destructors with `atexit()`.
Because once you start passing around a reference to a thread local variable you need to be *extremely* careful about making sure it doesn't escape the thread.
Why? That's totally defined. It's like passing around a reference to any variable. If you modify any variable from other threads without synchronization, you're going to have a bad time. What's unique about thread-local variables?
&gt; It’d be great if Microsoft provided more versions of the runtime libraries – especially “fast” ones without the security features. No it would not. It would be batshit crazy and borderline criminal. The author wants a faster mutex (how can a 30% slowdown on such a primitive can impact your code so much remains a mystery, but whatever, all other things being equal it would be great to have a faster mutex) and then jumps to the conclusion that he could disable some *security features* to achieve that. So MS should especially NOT provide MSVC redistributable .dll with security features disabled, for the very simple reason that some people like the author would use them, especially if they are advertised as "faster". Exactly like MS should not provide e.g. a faster kernel with all security features disabled, or anything insane in the same theme. I'm a little desperate that developers still have that kind of thought in 2016, even if it is for a video game. I don't see why it should be ok to increase the risk of gamers more than non-gamers, by denying them useful mitigations. So forbidding than kind of devs to do that kind of shit is the only way. You can't prevent them to rewrite rewritable parts in a way that will allow their users to be hacked faster, but at least don't make it easier to do that kind of shit. 
&gt; Get your work reviewed by other developers and really think about the feedback you get. I can't stress this part enough. 
I cut my teeth in an HPC Linux environment and what I first worked with was gdb and ddd. Those tools are simple (some might say under-featured) and straightforward to use. With a robust set of unit and integration tests I found that they met my needs. Good luck. Edit: I forgot about valgrind for memory debugging
I haven't watched the entire video yet, but is there a particular reason to use c++ filt over the --demangle nm flag? edit: Ah it seems it was because he was more interested in the type names than the symbol names.
&gt; If you detect something that makes you "panic", use abort(). Almost. Use `std::terminate`: It has a similar effect but allows the user to set a handler, while still being a very clear message that things went extremely bad.
Could you explain with an example? I don't understand the inconsistency. I'm interested in understanding your point of view, though. The way I see it: every variable could be said to be owned by a thread, whether or not the definition of the variable is prefaced with a thread_local. So why does it matter that the reference to the thread local variable does not have a "thread_local" on it? &gt; but thread local introduces a non-consistency to what different threads see Are you saying that a reference to a thread local variable will refer to the variable local to the thread operating on the reference? Because I'm pretty sure that the reference will refer to the variable in the thread that originally took the reference. Edit: I kind of see what you're saying. If you expect that a reference taken of a thread-local variable will propogate its thread-localness, you'll be sad to find out that it didn't behave in the way you expected. This is a trivial misunderstanding of the language, though. It's easier to reconcile by actually reading how to use thread_local rather than have code review tell you that you can't do that. If you take a reference to a thread_local variable, expect that the reference is not thread_local. It's so easy to understand that, especially given that the reference definition doesn't have "thread_local" on it exactly as you said. It's like caching the thread ID in a local variable and passing it to another thread and wondering why the TID you passed in isn't the same as TID of the thread you passed it into. It sounds silly to me to worry about that.
Hi, what is the address of your NYC location? Google maps mentions Jersey City, which is a big commute difference for me. Thanks,
The issue isn't with code like this: thread_local int foo; int &amp;bar = foo; use(bar); It's more things like // in header: thread_local int foo; // in impl int &amp;bar = foo; // ... // 100 lines of code later: use(bar); It's going to be easy to forget that bar is actually a thread local variable and that you should be careful where you store it. The non-consistency I mean is not in the code, but when debugging. If some bit of code with a cached thread_local variable is run on the wrong thread, imagine this debug: printf("%d %d\n", foo_ref, foo); 42 0 WTF? Disconnecting the fact that a variable is thread local from its usages is just asking for someone who tries to change the code later to not know that it's local and pass it around the wrong place. Even if your cached version is "only local to a function", what happens when someone refactors that code into a function object that keeps that cached reference inside it? The reference is like casting away the `thread_local`. That qualifier is no longer attached to the variable and it's going to get forgotten about eventually.
Yeah, sadly forced to use UE4 at current consulting gig. It's an incredibly shitty piece of software from the coding end of things. Most of the engineers loathe it with a passion. It took 8 previews of 4.11 until they deemed it release worthy, 2 hot fixes later of bug fixes and it's still a buggy mess. If you take a look at their bug reporting site a large number of bugs gets submitted each day, a lot of which I'd say are class A bugs. Sadly it seems there won't be a 4.11.3 as they're moving onto 4.12 quickly cramming more untested features in.
It's also very slow. This was more of an issue for me as my job was to make sure the games ran quickly.
Hey folks, I have been working on this Result&lt;T, E&gt; type inspired by Rust std::result module for non-throwing C++ interfaces. Let me know what you think.
Why would you want to cleanup after exit? What recovery can your program handle once it has a fatal error? The OS closes all handles and sockets, and any allocated memory is taken back when a process terminates. There is really nothing to cleanup. If you say that you need time to flush your persistent data, what can you do if there is a power outage? 
They'd still have an equivalent of kill -9. I think it's TerminateProcess() on Windows, or just pulling the power cable out of the machine. Or hibernating the machine and throwing the hard drive in the trash, or...
want to exchange my prompts for programs.. ^ _ ^
You could still want to clean up temporary files, for example caches of data structures you wrote to disk. One of my classes does exactly this in its destructor.
Solved it! Thank you so much for pointing me to the right direction. If anyone is interested: It is simple enough. Just add "VC\crt\src\linkopts\notelemetry.cpp" to your project to disable the thing and remove all associated code. There are other *goodies* there too :)
I'm... not really sure what you guys mean by "mutex hit". Locking a mutex that isn't unlocked is a very inexpensive operation (relatively). If there is heavy contention, then it's certainly wrongly engineered. In most of my games I usually have some kind of mutexed queue. I lock it, swap it with an empty queue, then unlock it. This means I spend very little time with the mutex.
Have you checked out Alexandrescu's Expected? 
If you are heavily making syscalls for allocating memory (aside from committing to already-reserved pages via page fault) or you are writing to console in a release build, you're also probably doing something wrong. I have seen many poorly-designed codebases which handle concurrent programming very incorrectly, and bottleneck on locks substantially. I write my code with the express intent of eliminating that.
If people are rude, don't focus on that and try to see what their actual feedback is instead. Sometimes rude people giving you feedback is all you got.
I agree. It's just something not everyone knows or thinks about. Writing to a console for game servers is very common though. Some dynamic objects do still allocate stuff that isn't always easy to control (eg. running DB queries on a separate thread). Anyway, my point was that threaded applications generally incur loads of mutex hits behind the scenes, unless you're very careful.
For console output on a server, there are good ways to mitigate that. Buffered multithreaded output (give each worker thread an output thread which operates as a single consumer of the worker thread's output) which requires either a very brief lock of an atomic commit to push a string over, for instance. Anything that can have an external lock should generally be mitigated. Isn't being 'very careful' what game optimization is? :)
Unlinking the file requires keeping the file descriptor open, which is not an option if there are many files. Using /tmp is nice for small files, but does not necessarily work the same for large files. Regarding atexit(), does this not behave the same way as a destructor deleting the file? That is, is there a valid way for a C++ program to exit (from within, i.e. not SIGKILL or unhandled other signals) without calling the relevant destructors?
Ooh, I'll have to take a look at that. The last time I ran across flycheck, I was running emacs 23, so I think I need to give it another try.
Looks interesting, the only thing I'm not a massive fan of is the call to ```std::terminate```, by default it will call ```std::abort```. &gt; Destructors of variables with automatic, thread local and static storage durations are **not** called. Something that potential users should probably be aware of, no RAII or flushing files/streams etc. I guess there aren't really any other options though. Would it be possible to return another Result&lt;&gt;, so the error can propagate up in a similar fashion to an exception? It could then go all the way up to main and exit more cleanly
There are ways around all that stuff, of course. It's just a question of how much work it is in contrast to how much benefit it all has. I've never bothered much with writing to console as my servers generally aren't very verbose on release (and they're also very unlikely for 2+ threads to be spitting out a lot of text at the same time). Other than using a mutex per log line, it's generally not very beneficial. &gt; Isn't being 'very careful' what game optimization is? :) Indeed. But you know what they say. Premature optimization is the root of all evil. This is certainly not the kind of thing that you would absolutely need to do right away since it doesn't generally need such a large rewrite to overcome if it ever becomes a problem. Again, my point was really that mutexes with low contention are faster than what most people think. You just need to make sure you spend as little time as possible with the lock.
&gt; I play a lot of Go. When I was in the early levels, I lost almost every game for a long time... That's missing the point though, unless some significant percentage of your opponents mocked the way you placed stones or gave you condescending explanations on why your last move was so horrible. That said, it's the internet, go ahead and make an anonymous account on SO/blog to get code snippets reviewed if you are bothered with it being attached to your name. 
thanks, it worked! After installing sfml with the "pacman -S mingw-w64-x86_64-sfml" command, the libs were linked successfully. The only difference to using normal windows toolchain is that after closing the SFML generated window there is a warning message: "Warning: Detected "Microsoft Corporation GDI Generic" OpenGL implementation The current OpenGL implementation is not hardware-accelerated Setting vertical sync not supported." 
No one is going to care if you post something bad as long as you learn from the experience. I doubt they'll rate you on code randomly located on the internet unless you link it directly. However it is valuable to get private feedback. I always send my code to friends and mentors. If you don't have any, you should work on getting some. Having no one to vouch for you is far worse than having bad code in the Internet archives.
Hey I tried to implement a similar object for my own needs as I too am a game dev with various mutex protected vectors... I am confused how you get it to unlock when a reference goes out of scope... Did you mean? MutexedObject&lt;std::vector&lt;int&gt;&gt; vec; auto&amp;&amp; v = vec.Lock(); vec.push_back(42); // automatically unlocked when v gets out of scope
Instead of a compound statement, you could probably just use a lambda in your TRY-macro.
Be skeptical of anyone who says that you should *never* do such-and-such, or that you should *always* do such-and-such -- especially if they don't say why. On the other hand, reviewers who prefer adverbs such as *rarely* and *usually* might be offering some real wisdom.
So what exactly does this telemetry do? Does it bring any benefits to us developers?
If somebody actually mocks you on CodeReview.SE, flag them/their reply (or comment, etc.) The moderators there are unlikely to tolerate it. As long as you follow the basic rules (primarily that the code really does seem to work, and you do include it in the question), substantial down-voting seems unlikely to me too (though there isn't much anybody can do if it happens, as long as they don't do something like serial downvoting).
I *never* trust people who...sorry, just too obvious to resist. I'll try to act like a grown-up now, I promise.
What a great point. I feel this way all the time when considering if I should post some code or not.... half the time it prevents me from getting help. I usually reach out to close friends that I respect in the industry to look over things. Just my personal point of view.
What incorrect usage pattern are you concerned for? 
His talk is brilliant, but the implementation is poor; if I recall correctly it calls make exception_ptr which throws and immediately catches an exception on error. So you are paying the cost of throwing on an error even if the contained exception is never thrown. 
The fact that you can easily attempt to use the value even if it's an error. It's the same problem with std::experimental::optional and how anyone can trivially *my_optional and get a run-time exception because they forgot to test it. The Result type popular in functional languages is paired with pattern matching and a native algebraic type system that makes it impossible to accidentally cast T|E to T but makes it easy to destructure T|E into either T or E.
No. There's no way to inject a return call into a function in C++ from an expression. The only options you have in C++ for exiting from a function are (a) reaching the end of the function, (b) the return _statement_, or (c) throwing an exception. There's also longjmp but that skips unwinding.
According to my vague understanding, there are people on the VC team who use that telemetry to make decisions. (I don't know very much about it because the Standard tells me what to do.)
Ah, yeah, then it'd actually be legal real C++. :)
I've worked on VC's STL (licensed from Dinkumware) since Jan 2007.
Leave your ego at the door. If you're doing something stupid, wouldn't you rather find out about it?
You can inject a return, but you have to use a macro instead of a function, so it's not really "pure C++"
Not really. I think it's safe to assume that a function as small as template&lt;typename F, typename G&gt; void either(F f, G f) { if (this-&gt;is_ok()) { f(this-&gt;ok()); } else { g(this-&gt;err()); } } will be inlined, and template specialization will mean that `f` and `g` are inlined too. If those are all inlined, then the second piece of code becomes identical to the first, aside from the messiness with `retval` instead of an early return. You're right that the `this-&gt;is_ok()` check will be slower than exceptions when the `ok` variant is present, but the speed difference is usually pretty small.
It's faster because exceptions have overhead and compilers treat them as unexpected cases and pessimize them. They're not appropriate for errors that are just part of normal operation.
I would love to see a "try or" syntax so you could do this without half your code being macros. I've made small projects based around this sort of result handling and it's so nice to work with. And if you don't care about error data, only propagating failure, you can make TRY just return {} and it works for a bunch of types.
This is already proposed for a future standard, and types like this are in common use. https://github.com/ptal/expected
Pessimize them? Do you have a source for that? I understand not optimizing it (or rather, normal code takes precedence over exceptional code), but 'pessimize' would mean making it intentionally slower, which makes no sense. That being said, exceptions are still really fast, at least in the non-throwing case.
I thought this code was pretty strange: template&lt;typename T&gt; struct EqualityComparable&lt;T, typename std::enable_if&lt; true, decltype(std::declval&lt;T&gt;() == std::declval&lt;T&gt;(), void()) &gt;::type &gt; : std::true_type And you then complain about gcc's warning. A much cleaner way to write this is with `void_t`: template&lt;typename T&gt; struct EqualityComparable&lt;T, void_t&lt;decltype(std::declval&lt;T&gt;() == std::declval&lt;T&gt;())&gt; &gt; : std::true_type You can also use `std::aligned_union` instead of bothering to compute the size/alignment yourself for your aligned storage. I couldn't figure out the purpose of Map, AndThen from a quick inspection (though I can roughly guess from the names), a few lines of comments (pref with a usage example) would go a long way there.
Consider the following code: void expensive_function(); struct foo { int i; ~foo(){ if (i==0) expensive_function(); } }; void bar() { foo f{0}; try { throw 1; } catch (...) { f.i=1; } } In `bar`, both clang and gcc will emit calls to the internal throw function, even though determining where the exception is caught is trivial. I know they both know this information, because they perform constant propagation to eliminate the call to `expensive_function`, which means they know the catch block is always executed. It's not a matter of preferring non-exceptional code, they literally refuse to simplify try-catch blocks, even when they know they can. 
Exceptions have no runtime cost if no exception is thrown there Error-Code checking always has an impact on performance. Yes, throwing an exception is slower than error-code checking, but exceptions are an exceptional occurance and should rarely occur.
The point is that your mechanism is incomplete if you can _accidentally_ raising a runtime error when it could and should be a compile-time error. I don't feel your concerns with pattern-matching and ignoring errors is well rooted in experience. If literally all you do is support Result&lt;T,E&gt;, sure, but that's long behind the state of the art. :)
This is more like a variant. 
Ah thanks ! I always forget about that neat void_t trick, I'll try that. I also tried `std::aligned_union&lt;T, E&gt;` but got compiler errors at the beginning so I did not bother figuring out why. I included descriptions of map and andThen in the README file, let me know if it is not clear
Believe me, I tried, again and again and failed, again and again. The thing is: how do you short-circuit a function call (i.e returning an Err Result if the thing you're applying the macro to returns an error) while still allowing users to write `auto val = TRY(write(sockFd, "hello"));`. I did not find how other than using a compound statement
Yeah, basically they share similar features but different semantics. For example, you can not really encode an error with an `Optional&lt;T&gt;`, you are just returning "no value" aka `None`. `Optional&lt;T&gt;` would best suite interfaces like finding a value in a map where the map can either contain the value you're looking for `Some(T)` or not `None`. You don't really need to encode an error in such interfaces. `Result&lt;T, E&gt;` best suites interfaces like writing a socket fd: `Result&lt;size_t, NetworkError&gt; write(const char* data, size_t len)` that can fail with many possible errors and you want to know exactly the error if it did.
You are also imposing a lot of overhead for the *expected* cases... I wouldn't presume this necessarily improves performance.
That has nothing to do with optimization. Compilers are not allowed to optimize out throws. A debugger could be attach to break on a specific exception. See [this](http://stackoverflow.com/a/19381261) SO answer, which also states that exception _are_ optimized.
Exactly, and it also happened to me that people couldn't care less for (or didn't notice errors in) a code snippet and I was fooled around for publishing it without realizing it. So the "friends &amp; reviewers" must be chosen carefully.. lazy or incompetent ones will only do bad to you.
+1 Visitors work fine in a lot of situations but not all of them and without destructuring these types are a bit awkward to use in some cases.
&gt; Be skeptical of anyone who says that you should never do such-and-such, Well, in C++ there are quite a few things, where telling someone to “never” use them is legit: Never use `NULL` if you have at least a C++11-compiler. Never implement manual resource-managment in classes that also contains business-logic. Never implement a new library so that your users are forced to use `new`…
If you're writing a buggy library that segfaults, cleaning up your automatic variables on exit shouldn't be a high priority.
&gt; A debugger could be attach to break on a specific exception. A debugger could also be set to break on the `if (i==0)` line; that doesn't stop the compiler from removing it. You can argue that they don't optimize out throws to help with debugging, but I would argue that intentionally not optimizing code is pessimization. Also, the link seems to agree with me: &gt; Throughout it, it shows that at the current time they are not stripped at compile-time but optimizations are made to them.
Maybe for a single player game it would be somehow acceptable, well, except if a community develops around the game with e.g. levels created by the users. Other caveats may apply. I beg to differ about a video player: all security features are absolutely essential for this kind of program, and anyway current CPU are largely powerful enough to play videos, the hard work is performed by graphic chips anyway, and to come back to the specific issue you should not be impacted by the perf of std::mutex (especially in cases where it is *only* 40% slower and not a insane value like 10x slower) too much to begin with, otherwise that means you have a broader design issue. So yes, I maintain that as long as some devs continue to consider that security features are not essentials in games or video players, it makes me want even *more* that main OS/library vendors force those features, if possible as non-optional. 
AFAIK that wasn't always the case though. GCC even still has -fno-exceptions and MSVC can also disable exceptions. I guess maybe it's only for executable size at this point, whereas performance is unaffected.
Branch prediction on modern processors makes rarely-executed error code checks pretty cheap as well. Though I wonder if exceptions have benefits in terms of code locality, which could make a significant difference in some cases.
Not currently, but something I've thought about. What exactly would you be interested in? For example: slides of ever step along the way or just the final source pushed up to a github repo?
Yes, but it's certainly still valid to be skeptical! Even if the advice is incidentally correct.
Are you sure you want to teach them c++? If they have no prior coding experience, it can be quite daunting and off-putting. Ie getting compilers up and running, learning all the concepts that c++ tends to throw right at you. And then if they run different operating systems at home, it would be even harder to get them motivated to practice because they'd have to learn how to set up build systems on each OS or learn cmake or something too. Why not use something simpler like python? The syntax is much lighter, the lack of type declaration etc make it quick to write. It's basically the same install everywhere and same way to run it everywhere. It will be much easier to teach them the logic of programming rather than all the overhead associated with the implementation of the language itself etc.. 
There are benchmarks showing that 0-cost exceptions beat conditional logic wrt performance in happy case.
Aren't exceptions supposed to be unexpected? On x64 using exceptions allows for zero overhead for the non-exceptional code path by the way (vs error code which will incur some branching unless you discard them)
Sure so basically, both operations are a way to *compose* results. If you take a `Result&lt;T, E&gt;`. `map()`-ing it to a functor that returns a value of type `U` will produce a `Result&lt;U, E&gt;`, that is to say `map` will apply the functor to Result containing an `Ok(T)` value and will return a `Result&lt;U, E&gt;`. std::string stringify(int val) { return std::to_string(val); } Result&lt;uint32_t, uint32_t&gt; r1 = Ok(3u); auto r2 = r1.map(stringify); ^-- here r2 becomes a Result&lt;std::string, uint32_t&gt; Now, supposed that you want to apply a function to your result that also returns a `Result&lt;U, E&gt;`. With `map`, you would end-up with a `Result&lt;Result&lt;U, E&gt;, E&gt;` which is not very convenient. Instead, you can call `andThen` and the second `Result&lt;U, E&gt;` will be automatically **unwrapped** and you will get a `Result&lt;U, E&gt;` instead: Result&lt;uint32_t, uint32_t&gt; square(uint32_t val) { return Ok(val * val); } Result&lt;uint32_t, uint32_t&gt; r1 = Ok(3u); auto r2 = r1.andThen(square); ^-- Here r2 becomes a Result&lt;uint32_t, uint32_t&gt; and is equal to Ok(9u) I'm not an expert in category theory nor functional programming, but basically, in the monadic world, `map` corresponds to `map` and `andThen` corresponds to `bind` (I know that `bind` has a complete different meaning in C++). At first, `map` and `andThen` were a single function (`map` would understand functors returning Result) but then I decided to split it.
I'm trying to avoid any preconcieved ideas, but this doesn't sound too great. I can't find any references to it on MSDN either. Perhaps /u/spongo2 could chip in?
This file is already built, and it is included in the same folder as the runtime libraries, so the linker is able to find it by just including notelemetry.obj as one of the input files. i.e: cl test.cpp -link notelemetry.obj But really, we shouldn't have to be doing this in the first place. Is there anything from MS these days that doesn't have this telemetry bullshit.
That's just great news! Someone from Microsoft must have been on last meetingcpp and listened to Chandler's talk about SSA optimizations in clang :). Maybe next release of Visual Studio will include really modern compiler with this and full AST generation. I'd really like to look on performance tests for this new optimizer, did someone already test it?
So true! But the posters point is very important, there are no absolutes, there are good practices but that doesn't mean you can implement them all the time. 
There is also the problem of perception here. This poster seems to be excessively sensitive over what other have to say about his code. The problem is that isn't going to go over well out in the work world. In fact it is a bigger issue than having poor programming pointed out. In a nut shell this person has to get over their sensitivity to criticism if the expect to survive corporate employment. 
I'm sure we can look forward to those upon the actual release
This explains the cryptic SSA comment in update 2's mfc/atl source changes!
Often enough I will comment a section of code with "here's the reason why this is done in a way that seems counter to best practices"
&gt; What about dealing with a decades old legacy code base even though you may now be using a C++11 compiler to build it? You can't rewrite the whole damn thing overnight Well, in a couple of seconds: for FILE in $(find src -iname '*.[hc]pp'); do sed 's/NULL/nullptr/g' "$FILE" | sponge "$FILE"; done But that aside: Not changing old code is not “using NULL”
I think it is a good idea to allow the process to switch of the death-laser before dying.
Destroying local variables (i.e., those with automatic storage) requires finding those variables. In the typical case, those are created on the stack, so finding them means walking the stack, and destroying the variables local to each stack frame. That's pretty much the nutshell description of what happens when you throw an exception (with one minor...exception--it would always proceed through the whole stack instead of only until it found a handler for the type of exception that was thrown). In other words, what you're asking for would require essentially all the "machinery" necessary to implement exception handling, and add essentially all the same overhead, but without most of the functionality that goes with. Given that C++ compilers have exception handling anyway, the obvious way to implement it would be to add a `try` and `catch` into `crt0` (or whatever name your implementation uses for its startup code), and have `exit` throw some type of exception that isn't visible in user code, so no intervening exception handler could possibly match it. As for being a library: supporting libraries was most of the reason for inventing exception handling to start with. It's almost certainly what you should be doing here. It will exit the program if the user doesn't install a handler (after cleaning up locals, as you want), but it also allows the user to at least make some minimal attempt at recovering as well, if he chooses to do so (even if this is basically just an infinite loop to start over when/if it dies). Bottom line: yes, it could be done, but also yes, what we already have is better.
I think the bottom line is that "virtual" is nothing but syntactic sugar which bundles many things you might or might not want. You can implement any combination of C++'s OOP features with generic code in a way that makes perfect trade-offs for your problem.
Generally input validation is done at the stage where the input enters. For example Qt has: http://doc.qt.io/qt-5.6/qvalidator.html wxWidgets has: http://docs.wxwidgets.org/trunk/overview_validator.html These are designed to validate user input at the point of input, and then pass only correct input to your business logic. It depends on what you're doing and using, but if you're using a GUI library chances are there might be something in there.
Same here, good IDE. To start also Atom + terminal is good.
I tried the new optimizer on a 350K line code base and didn't notice a significant change in performance or code size. Spot checks only revealed minor changes in assembly, mainly about a dozen places where some of the tricks listed in the blog were applicable. Didn't see anything earth-shattering. The build had LTCG enabled but not PGO. Some of this is probably due to my coding style, which is best described as "C+-11" due to preferring straightforward constructs. On the other hand, nothing seemed to break, which is an accomplishment for a big optimizer change. I can see the compiler team being able to put more aggressive optimizations in later with this in place. 
validate your input and transform most things into strongly-typed constructs
This seems to be missing in the VS14 preview (at least with the new installer). 
What comment was this? I don't really use MFC/ATL so I didn't see this.
How are you using inheritance?
I doubt there will be any noticeable difference in performance at this stage in real-life code. Even reductions in actual code size they present are on the order of 0.1%. For now, it's mainly an architectural improvement.
How does it do against [these](https://chadaustin.me/2013/01/json-parser-benchmarking/)?
I don't like it: char* serialized = src.json_pack(true, 2); // ... free(serialized); Edit: it seems to be a duplicate from [this](https://www.reddit.com/r/cpp/comments/3s563w/json_serialization_library_for_c_11/). 
In my case I learnt futures exposing a rest api with Casablanca. The process had an embedded web server that casablanca implements as a listener running in its own thread pool. For consistency I needed to do the work of request answering in the main thread, so I needed something like remote procedure call but inter-thread, not inter-process/machine. The part of calling was easy, a prosumer queue polled in the main thread. But to get the caller on-hold, I first thought of queueing win32 events to signal when the call work is done, in the main thread, and to wait for completion in the request handing thread. The problem was portability, and then futures came to the rescue. Upon http request, instead of creating a win32 event, I created a future in the request handling thread, and obtained an associated promise. I pack the request params and promise and queue it up. Here I call future's wait(), blocking. In the main thread loop I poll the queue, dequeue the request, do the work, and then call the promise's set_value(), waking the wait()ing thread and safely also transferring a result value. Exceptions handled in the main thread. All people happy. 
Just started using Conan in a personal project of mine, it's pretty good even though it could provide small, mostly artificial improvements. like the web UI could give a basic command to install the package locally, the user has to copy paste the various options and then modify them in and editor then paste in the terminal. as i said artificial, the system itself is pretty nice to work with.
Have you tried YouCompleteMe ? There's a layer to use ycmd in Spacemacs: https://github.com/syl20bnr/spacemacs/tree/master/layers/%2Btools/ycmd
Rtags has worked well for me in the past. 
I just don't understand it either... there are so many options to choose from, and this is just the worst possible...
Indeed. BTW, this comparison is probably well known, but for the sake of completeness: [https://github.com/miloyip/nativejson-benchmark](https://github.com/miloyip/nativejson-benchmark)
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rust] [X-Post from r\/cpp: Locking in WebKit](https://np.reddit.com/r/rust/comments/4i5zpb/xpost_from_rcpp_locking_in_webkit/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Binding a documentation engine to a bona fide c++ parser/compiler is brilliant. I hope this effort succeeds.
Ycm is definitely fast (with vim where I tried out). Handled, e.g., boost much better than eclipse. Biggest pain is setting it up. Also make sure you have a lot of memory available. In addition, hotkeys are hard to learn. Vim-like basically. 
Thanks! As a relatively new c++ programmer this is exactly what I want from c++ tutorials / instructions. Please do some c++17 stuff!
Sounds like a great idea and I wish you luck. I wonder how close the generated output could match the ISO standard documents. For example, could it be possible to generate a perfect match for the documentation of the standard library from appropriately marked up C++ header files? I think that would be a huge boon to standard maintainers and proposal authors.
Oh, great. But problems with the parser wasn't my main motivation as mentioned.
YCM is sadly missing a ton of useful features that Eclipse provides (which rtags mostly does as well). The last I looked it did not support find references, nor other useful things that Eclipse has like type hierarchies. I'd consider spacemacs if rtags didn't seem like such a pain to set up.
There is an open [pull request](https://github.com/syl20bnr/spacemacs/pull/2834/files) which adds rtags support to spacemacs. It's currently got some merge conflicts which will need to be sorted out first though. I'm an emacs noob, so don't really know enough to help on that front. /u/TheBB said it's getting a bit of interest, so I'm hopeful it'll be merged sooner rather than later. 
I'll try to remember to get it done. I'm not sure how useful that PR is since it's fairly old and I have no idea how serious the conflicts are.
I'm wondering why you left Eclipse to an EMACS derivative? I'm not trying to troll here because there are lots of things to hate about Eclipse. I currently use it for a modest amount of Python development because I haven't found anything cross platform that is really better. I guess the question is what was the last straw that caused you to dump Eclipse? Also why this version of EMACS? 
I didn't write this, but recently I've ended up using [dollar](https://github.com/r-lyeh/dollar) when profiling small things. It probably has overhead and whatnot but it gives me decent insight and all you need to do is: 1. Add an include 2. add "$"'s at the start of scopes you want to profile 3. output the results
well, translated auto-return type for non-template code would already be nice to have
Have you ever had a look at [DoxyS](http://www.doxys.dk/doxys_homepage/index.html)? I think it’s abandoned, but I do like its feature set. It looks better within the source code itself, for one thing. It produces output similar to that home page.
Except for quicknir's comment, which I have to go investigate, it is free of exception in the sense of throwing them and catching them. It merely uses them as the classes that carry the errors. It _does_ end up throwing them if you try to get the value without checking if its an error, but thats fine. I dont care what style of Option/Maybe we end up with, but I just hope we get a nice one. I like how it carries the error up by default, rather than leaving it to implementations like Option and Maybe in other languages often do. 
I definitely aim for a very similar kind of documentation.
No `std::literals` support either. :-[
Stock emacs CEDET with projectile and helm isn't bad... I can't imagine code navigation being much faster, if you like keyboard shortcuts.
The WTF framework??? http://martinfowler.com/bliki/TwoHardThings.html
I'll definitely focus on other things first. One of those is entity synthesis which will allow to at least manually specify the return type.
Very cool, was actually searching for a documentation tool based on libclang. Markdown output allows for easy integration in existing docs. Looking forward to seeing this mature.
I'm curious, why do people use ICC over other free compilers? What are the benefits? I know people used to say ICC had much better performance, but it seems that this isn't as true nowadays.
I like what Python does, having "catchable" exceptions deriving from `Exception`, while others, like `SystemExit` or `KeyboardInterrupt` deriving from `BaseException`. In C++, you could consider that all "catchable" exceptions derive from `std::exception`, while special exceptions meant to abort the program don't. In fact, this is the only clean and portable to really unwind your stack and be able to exit the program properly. I recall that Boost.Thread does that with its thread interruption mechanism, throwing an exception that the user is not supposed to catch to interrupt and clean the user function. Of course this won't work if you catch everything, but I think it is considered best practice to *almost*[1] never `catch (...)`, except at the beginning of a thread (be it the main or a `std::thread` entry point). [1]: IMO, the only acceptable other use case for `catch (...)` is to re-throw the exception immediately after some cleanup operation.
Sure. But that's cumbersome and you have to do that twice (with some extra work) to also support return. :) There's a difference between saying that you _can_ make it work and saying that you _should_ make it work. Using lambdas for control structures falls into the first case. :p Note that you can in this particular example also simulate simplistic destructuring using the for-range syntax and a little elbow grease so you'd get: for (auto x : my_result) { // my_result would return a 0- or 1- element range // x is a value, return works, but break and continue are still problematic } You can also simulate it with an if statement in a more explicit but still possibly misused way, e.g.: if (some&lt;X&gt; x = my_result) { // *x is a value, return break and continue all work } else if (none _ = my_result { // no value, return break and continue all work } *my_result // make this a compile error, require converting to some or none first some&lt;X&gt;(my_result) // this can still be misused, though at least it's more obvious in reviews There's nothing _too_ fancy really required here. Just a few small additions/tweaks to C++ could give us simple matching/destructing with a high degree of safety against accidental misuse, which should be the desired goal. Being 100% safe is not really in scope for C++, but protecting against accidents should be a very high priority. Or as Bjarne says, we need to protect against Murphy but not try to protect against Machiavelli. :)
What makes my reasoning irrational? Other people are agreeing with my point of view so you're either considering all of us irrational or we're all wrong (unlikely).
Why not clang? It's cross platform.
clang is hardly cross platform - the Windows support is seriously lacking. libc++ isn't even ported to Windows yet. To use clang on Windows you need either Visual Studio or MinGW and for the latter it takes some elbow grease to get clang working. It has always been a nightmare every time I have tried it. I really want to use it but they just can't make the Windows experience as seamless as the *nix and Apple experiences.
ACK. I've been cringing everytime I happened to see another commit that added "MSVC compatibility" to clang, meaning it'd understand the command line flags or behave just as quirky. I'd really wish for a gcc compatible clang on windows, along with a proper port of libc++. As I see it, mingw usage in non-open software is low due to the dependency on non-standard dlls for exception handling and gnulibc++
I do agree with much of the sentiment but if you do need to support windows mingw isnt really a high performance option particularly with multithreaded code. MS is trying to improve its optimiser too. In general you should ideally write code supporting many compilers and then measure. Different compilers have different strengths.
I compiled a simple program with only main(). When looking at the compiled binary in Ida, I see a calls for ```telemetry_main_invoke_trigger``` and ```telemetry_main_return_trigger```. I can not find documentation for these calls, either on the web or in the options page. I compiled this in Visual Studio 2015 Update 2. **edit: you can remove the telemetry calls**. Thanks for all the replies, guys. As /u/adzm points out, you can link ```notelemetry.obj``` and the calls are removed. I verified that this works. [This comment further explains it](https://www.reddit.com/r/cpp/comments/4hoyzr/msvc_mutex_is_slower_than_you_might_expect/d2thalz) **edit 2: this may be a local logging feature**. When I initially saw the word "telemetry", I though it might have something to do with [Windows Telemetry, a "feature" that sends private information to Microsoft's home base.](http://www.techpowerup.com/forums/threads/script-to-block-all-windows-telemetry-and-windows-10-upgrade-components.216611/). However, as several users have pointed out, this may be separate from that and only store local logging information. [see here](https://np.reddit.com/r/cpp/comments/4ibauu/visual_studio_adding_telemetry_function_calls_to/d2x6dau), or [here](https://np.reddit.com/r/cpp/comments/4ibauu/visual_studio_adding_telemetry_function_calls_to/d2wvnej) **edit 3: Visual Studio team responded [here](https://www.reddit.com/r/cpp/comments/4ibauu/visual_studio_adding_telemetry_function_calls_to/d30dmvu)**
Yeah I saw this mentioned before in a blog post (http://levicki.net/articles/2015/12/03/RANT_Microsoft_Visual_Studio_2015.php). Not heard anything else about it and that post is almost 6 months old now.
if this is what it seems to be it is pretty nasty stuff :|
What software have you used for dis-assembly and plotting the execution flow?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/coderradio] [VS15 adding telemetry to compiled code? Would love to hear hosts thoughts](https://np.reddit.com/r/CoderRadio/comments/4ie1nh/vs15_adding_telemetry_to_compiled_code_would_love/) - [/r/linuxmasterrace] [Compiling C++ with Visual Studio 2015 automatically adds telemetry to the binary](https://np.reddit.com/r/linuxmasterrace/comments/4ibhjk/compiling_c_with_visual_studio_2015_automatically/) - [/r/privacy] [This is why you should NEVER use a proprietary compiler.](https://np.reddit.com/r/privacy/comments/4nc8ic/this_is_why_you_should_never_use_a_proprietary/) - [/r/privacy] [\[X-post \/r\/LinuxMasterRace and \/r\/CPP\] Compiling C++ with Visual Studio 2015 automatically adds telemetry to the binary](https://np.reddit.com/r/privacy/comments/4idb7j/xpost_rlinuxmasterrace_and_rcpp_compiling_c_with/) - [/r/programming] [Visual Studio adding telemetry function calls to binary? (\/r\/cpp)](https://np.reddit.com/r/programming/comments/4id4xo/visual_studio_adding_telemetry_function_calls_to/) - [/r/stallmanwasright] [Thank you stallman for giving us GCC so we don't have to rely on proprietary compilers!](https://np.reddit.com/r/StallmanWasRight/comments/4ncdra/thank_you_stallman_for_giving_us_gcc_so_we_dont/) - [/r/technology] [Visual Studio adding telemetry function calls to compiled binaries (r\/cpp xpost)](https://np.reddit.com/r/technology/comments/4nh6i3/visual_studio_adding_telemetry_function_calls_to/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Intel's auto-vectorizer is still miles ahead of everyone else; and for code that uses BLAS/LAPACK/etc, Intel MKL is also the quickest implementation I've come across. I don't think it offers much for normal apps, but if you fall into its (maybe niche) demographic then it can do some pretty crazy optimization.
Lets see whats /u/spongo2 has to say once he gather some ["details".](https://www.reddit.com/r/cpp/comments/4hoyzr/msvc_mutex_is_slower_than_you_might_expect/d2uwxng)
I'm still seeing the **"identifier __is_assignable is undefined"** when building against the msvc standard libraries. :( https://software.intel.com/en-us/forums/intel-c-compiler/topic/623368 
It appears to be calls to undocumented black box routines which do who knows what. Since they are called 'telemetry...' this compounds the level suspicion of what the purpose might be. Since 'stdafx.h' is included though I wonder if it was compiled as managed code and has something to do with that. I don't know enough about windows land to really comment beyond that.
Help me understand what's going on here. Is MS's compiler adding some sort of spyware? Is it possible this is debugger type calls? Could switching to release fix this? (I'm pretty sure VS doesn't use -O3 style options. it's "debug" or "release" right?)
/u/xon_xoff [summarized things pretty well](https://www.reddit.com/r/cpp/comments/4hoyzr/msvc_mutex_is_slower_than_you_might_expect/d2thalz) in a recent thread about mutex performance. Apparently you can disable this by also linking with notelemetry.obj which is included with msvc. The source for that obj is also in the CRT source's linkopts folder. Edit: can also put this in one of your compilation units: extern "C" { void _cdecl __vcrt_initialize_telemetry_provider() {} void _cdecl __telemetry_main_invoke_trigger() {} void _cdecl __telemetry_main_return_trigger() {} void _cdecl __vcrt_uninitialize_telemetry_provider() {} }; 
you know what he means you silly goose!
recompiled with a barebones application (no includes, no commands). [the telemetry calls are still there](http://i.imgur.com/A8mXFGj.png) edit: link to ```notelemetry.obj``` to get rid of the calls.
Seems to be that way. At least right now they only keep main invoked/returned, exit/abort called and such. Nothing serious. The suggested way to disable it is adding this to your project: extern "C" { void _cdecl __vcrt_initialize_telemetry_provider() {} void _cdecl __telemetry_main_invoke_trigger() {} void _cdecl __telemetry_main_return_trigger() {} void _cdecl __vcrt_uninitialize_telemetry_provider() {} };
It would be really interesting to see these results about efficiency &amp; fairness reproduced on Linux because the author draws conclusions about this on OS X which has a sub-optimal POSIX mutex implementation (so all the claims that efficiency is hampered by fairness is suspect when you could explain a lot of the discrepancy on having a more efficient lock in the first place). See http://stackoverflow.com/questions/22899053/why-is-stdmutex-so-slow-on-osx where it's 10x slower than a simple spinlock with only 4 threads. I can't recall if this has changed on more recent versions of OSX, but traditionally a contended mutex requires IPC calls to the kernel rather than the futex approach favoured by Linux &amp; what WTF::Lock is basically accomplishing here. The other point about the size of POSIX mutexes is super interesting &amp; a fair point about why it's the right choice for WebKit. Would be interesting to investigate a way to improve this for POSIX mutexes on OS X/std::mutex if relevant across platforms.
It must be an installation problem – I can't repro with ICL update 3 running on VS2015 update 2. Can you post a specific SSCCE? **EDIT:** That post reports the version as 2016.2.180; mine is 2016.3.207. Clearly an installation problem.
 #include &lt;vector&gt; int main() { return 0; } Output: 1&gt;------ Build started: Project: test, Configuration: Debug Win32 ------ 1&gt; test.cpp 1&gt;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\type_traits(550): error : identifier "__is_assignable" is undefined 1&gt; : integral_constant&lt;bool, __is_assignable(_To, _From)&gt; 1&gt; ^ 1&gt; 1&gt;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\type_traits(550): error : type name is not allowed 1&gt; : integral_constant&lt;bool, __is_assignable(_To, _From)&gt; 1&gt; ^ 1&gt; 1&gt;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\type_traits(550): error : type name is not allowed 1&gt; : integral_constant&lt;bool, __is_assignable(_To, _From)&gt; 1&gt; ^ 1&gt; 1&gt; compilation aborted for ..\test.cpp (code 2) ========== Build: 0 succeeded, 1 failed, 0 up-to-date, 0 skipped ========== 
`icl` shows me `Intel(R) C++ Intel(R) 64 Compiler for applications running on Intel(R) 64, Version 16.0.3.207 Build 20160415`; and you?
The existence of those kinds of types *at all* is completely implementation-dependent. The standard doesn't actually mandate that the `(u)intN_t` typedefs exist. It just requires that *if* the platform provides 8-, 16-, 32-, and/or 64-bit integer types, with no padding, *and* the signed types are two's complement, then the implementation must provide the corresponding fixed-width typedefs. The only types that are actually required to be present are `(u)int_fastN_t`, `(u)int_leastN_t`, and `(u)intmax_t`, for N ∈ {8,16,32,64}. I agree that 128-bit integers and quad-precision floats are useful; but don't all of the major implementations already provide them? Either way, given the way floating-point types and integer typedefs are defined by the standards, I'm not sure what could be done there to make them more widely available, beyond simply adding 128 bits to the set of integer types explicitly mentioned in the standard, as noted above.
We fell into the same trap as well... Sadly, we are stuck on an older ICC/VC combo as the newer ICC versions haven't worked well with vs2015. I have attempted multiple updates of icc2016 to work with our code base, but there has always been complications with the STL (particularly shared_ptr). 
same - that said I did the u3 upgrade via ISM 
If you can make an SSCCE/MVCE then I don't mind testing with the latest VS/Intel combo.
I can see this being useful, but it is a strange thing to add ~~in an update~~ with neither warning nor documentation. And enabled by default!
&gt; but was annoyed by the hack to get things to work on amd Wait, what? 
&gt; I agree that 128-bit integers and quad-precision floats are useful; but don't all of the major implementations already provide them? Visual C++ doesn't, and has publicly said they don't plan to for the foreseeable future.
I'm completely done with Microsoft. I'm formatting my windows drive to FreeBSD.
I was practicing doing reverse engineering today, so I compiled an application to which I had the source code and loaded it into Ida, a disassembler. I compiled the code in full Release mode. No pdb or debug symbols, etc. If you were distributing a binary to a customer, this is how you'd do it. Ida finishes doing the analysis. The [side by side comparison](http://imgur.com/TiVrXyf) shows the code vs. decompilation. On the left is the source code within Visual Studio. On the right is the assembly in Ida. Strangely, I found a call to "__telemetry_main_invoke_trigger". I definitely did *not* have that call in my source code (I only had a main() function that returns 0!). I try to find it within Microsoft's documentation, it's nowhere to be found. The source code for this function from Microsoft is unavailable. I look more online; it seems Microsoft has [implemented new telemetry "features" in Microsoft 10.](http://www.techpowerup.com/forums/threads/script-to-block-all-windows-telemetry-and-windows-10-upgrade-components.216611/) The OS phones home with personal app usage data. But, Microsoft gives no information about how to use Visual Studio to remove this feature from your code. Eventually, some guys here (on /r/cpp) told me how to get rid of it (by linking ```notelemetry.obj```), but if I hadn't been taking a day off today to play around with Ida I would not have even known it was being added. Here's the main problem: 1. I did not know that this was being added to my application. 2. There is no explicit option within the Visual Studio project options page to enable or disable. (Search for telemetry -- nothing comes up, either within the compiler or linker options). 3. ~~We do NOT know what it does. The source code is not provided.~~ It may do nothing 4. ~~If you walk through your code using Visual Studio's provided disassembly view, you will NOT see these function calls. Only when you use a third-party application like Ida do the call become visible.~~ edit: if you set a breakpoint at ```mainCRTStartup``` rather than ```main``` you can see the calls
Guess I'm sticking with CLion and MSYS2...
I would concede a game but definitely not a video player or editor (not sure what kind of editor we're talking about here). Applications with the potential to handle untrusted input should definitely be using these security features.
&gt; c# too? Oh, boy. c# doesn't even need to do that. Whole .NET on windows is a black box of gazillion unnecessary things that waste your CPU time. (even if you never run any .NET apps)
They wanted to avoid the embarrassment of having to call it "long long long" ;)
As far as I can tell (at least on my machine) this is only in Debug builds (not the builds that get shipped to customers). Maybe it hooks into some tools for helping you debug stuff during development? (seems like it might *just* fire some ETW events, so unless you're actually running a profiler that records the ETW events they wouldn't do anything).
This was a Release mode build. I didn't build with debug symbols at all
Just because the symbols are there doesn't mean the functions get called. From the other investigations (in the other thread about this), this appears to be just ETW events that fire (if the ETW profiles are enabled, e.g. by running WPR), so it makes perfect sense that the code is never run in a straight Release build. I really don't think there's anything to see here. Apps fire tons of ETW events all the time (when a profiler is running), and the reason is to help the developer debug the application (by capturing an ETL file using e.g. WPR which will turn on these ETW and store them to a file, that you can then view in e.g. WPA). I don't know what these specific events are for (sounds like it's just to show you markers for when main gets called/exited), but I think it's a bit premature to speculate that this is somehow unique or malicious. 
Anyone here can take a stab at seeing if Intel is trying this as well?
You are a shill.
Nearly everything I've said is a verifiable fact, I don't see how that's shilling
well Microsoft wants to know what user runs... whether benign or bad..
Honestly I'm more into the stability, familiarity, and frankly LLVM/Clang is a bigger selling point than it would be to most others. But, of course security is a main issue as well. I'll check out Security Onions/Qubes though, I've never heard of those.
I suppose we should assume the etw logs are being collected and submitted to Microsoft as part of their telemetry. This is a very disturbing realization. 
My vague understanding is that it emits information into the PDB for use with memory profiling. I was just told to mark various STL functions with it. We can probably get you more information if you're interested in implementing it in Clang.
I noticed these subroutine calls right after updating to VS15 after it came out but ignore it as I didn't know what 'telemetry' meant at the time. After taking a glance over the subroutines prefixed with ___telemetry_ it looks to be simple logging using Microsoft's EWT[1] ___telemetry_main_invoke_trigger simply fills out a data structure named _EVENT_DATA_DESCRIPTOR[2] (with a size of 4) with some metadata (which I haven't looked into) and a string "Main Invoked" and the path to the current module (process in this case). ___telemetry_main_return_trigger does something similar but with a logging entry containing the string "Main Returned.". So from a quick glance it looks to be simple tracing used for debugging purposes by Microsoft but I'll look into it more when I get the time. http://puu.sh/oKdTZ/2e8f1a269f.png While this could potentially be something malicious note that no one has determined what it does so far so don't go assuming that it's stealing your code without reason (albeit Microsoft not being the best provider to trust). NOTE: You can get something close to the source code which is the PDB file. IDA will connect to Microsoft debug servers to obtain debug info and in this case it exists so you can use that. But just in case here's a copy of the PDB file: https://up1.ca/#4TLX04iCzedH6emBF6J2mw [1] https://msdn.microsoft.com/en-us/library/ms751538(v=vs.110).aspx [2] https://msdn.microsoft.com/en-us/library/windows/hardware/ff545673(v=vs.85).aspx Edit: Note that VCRUNTIME140.dll is located under "C:\Program Files (x86)\Microsoft Visual Studio 14.0\Common7\IDE\Remote Debugger\x86" so when referring to telemetry it could be referring to collecting/sending data over to the remote PC you're using for debugging. Edit(2) - Microsoft has already written an article stating what telemetry means to them and how they believe it should be used[3]. I'm not saying that they're using it for the wrong reasons but given the fact that they have already published an article stating what they're using telemetry for it's easier to see now why it could possibly be there in the first place. [3] https://msdn.microsoft.com/en-us/library/dn589775.aspx
There's no telemetry.cpp in the sources shipped with VS2015 Update 2, only notelemetry.cpp. If you search for "__telemetry_main_invoke_trigger" in the source folder there will be only one occurrence, in the notelemetry.cpp file, which has only empty functions.
If you're interested in higher floating point precision and portability, check out [quad doubles](http://web.mit.edu/tabbott/Public/quaddouble-debian/qd-2.3.4-old/docs/qd.pdf) (pdf).
I might be interested in implementing it in Clang. It looks like a S_HEAPALLOCSITE CodeView record should be emitted, doesn't sound too tricky. Could you ask folks in the know if the optimizer uses this declspec?
Man that's sketchy as heck.
VS Code is far from ready for serious C++ development.
What I really wonder is 2 things: 1. Why for removing the call you need to explicitely link notelemetry.obj (instead of the other way around)? 2. Why this changed and users were not informed? I think this is a quite sensitive topic and it is not nice to have a change like that without informing users... On top of that it seems that telemetry.cpp is a "black box" for what I see in the comments: no telemetry.cpp shipped, just the deactivation code. I do not know if this is bad or not, I just know that it does not look nice indeed... 
You're being highly misleading. ETW is a general mechanism to log any kind of event, not just performance events, and is used throughout Windows for more than just profiling. Furthermore, it supports both multiple simultaneous consumers and storage in .etl files for later processing. Any program with sufficient privilege can enable tracing of specific event types throughout the system, and user intervention is not required to do so. An example is an automatically generated file called ExplorerStartupLog.etl in the AppData\Local\Microsoft\Windows\Explorer folder. These files being generated locally doesn't mean they can't be transmitted later, and some problem reporting tools use ETW+ETL files to efficiently capture telemetry for upload. 
Has anybody tried using Wireshark, to see if something gets transmitted?!
&gt; The code size increase alone can start to slow your program. (wrt exceptions) a source is needed for this. [Benchmarks](http://nibblestew.blogspot.fr/2015/12/are-exceptions-slower-than-error-objects.html) showed that the same code with error-code handling was slower than the version converted to exceptions.
What about Release using a different CRT dll? You sure the breakpoint went there as well?
Can't you dig into the telemetry function to hazard a guess as to what it might be doing, or is it too complex?