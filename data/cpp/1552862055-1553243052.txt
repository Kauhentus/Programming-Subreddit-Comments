&gt; One big reason is being stuck on old build infrastructure that makes switching to compilers that support C++11/14/17 hard. This is the biggest one in my experience. The further back in time you go, there are more systems that can support it in a predictable manner.
You're missing my point. I think both API examples you provided are terrible. Transfer of ownership is something you should be trying to avoid. FooHandle Thumbnail::CreateFoo() const; If `Thumbnail` is responsible for creating `Foo` then it owns `Foo`. If `Thumbnail` is destroyed it takes `Foo` with it and whatever handles that existed to either are now invalid. Even better, try to not have external handles at all. Does `Thumbnail` really need to hand out `Foo` objects or could it be an implementation detail?
If all you are doing is allocating something in the ctor and deleting in the dtor, there's nothing really gained, and in the process you lose the ability to catch any errors when the thing gets cleaned up and log them. 
Well truth be told, a large portion of the statements you write in C++ would probably be valid C. They are different languages, but they share a lot. It's not uncommon in older and larger code bases that the same project contains both C and C++ and is compiled by the same compiler. 
[removed]
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/b0uyg6/how_long_have_you_worked_with_cc/eirixq1/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I don‘t think so. Rather, a large portion of the statements you can write in *C* would probably be valid *C++*, but not the other way around, if you‘re writing modern, idiomatic C++. Despite some pieces of C heritage in C++, both language have completely different paradigms and best practices, especially given the developments in the C++11/14/17 and later standards. They *are* completely different languages.
What are you offering for compensation? Good C++ guys aren't cheap. Think (not positive) that it was Code Complete that called out that a good dev can be 10x as productive as an average dev. Are you offering 10x market pay? 2x market pay? 1.5x market pay...?
If you're near Munich, you're competing with Google, Microsoft, Lyft, Siemens, and others. So you'll need to be offering a good salary, and the North American companies tend to pay SW engineers quite a bit better than German ones.
&gt;and in the process you lose the ability to catch any errors when the thing gets cleaned up and log them. Huh? Just instrument the destructor of the object being destructed by the smart pointer. Your destructors shouldn't be throwing exceptions anyway. 
&gt;And 90% of people can't answer that? Ouch. I can imagine lots of good answers, including, "Not much."
The dtor of the smart pointer doesn't help you. You want to know the context in which failed, not just that it failed. That requires catching it on the way out of the dtor of the class that created the smart pointer. You can't do that unless you do the cleanup yourself and catch the error. In my case that would mean adding where it failed to the stack trace of the exception and re-throwing. And of course they shouldn't be throwing, hence why it's extremely important to know exactly what sequence of events caused the failure if it should happen in the field. And the most important aspect of that is the sequence of calls that it took to get to the failure point. 
Probably about 28k
I used to keep my C++ knowledge bleeding edge. I loved the language and wanted a high paying job with it, but I found higher paying jobs in C#, so I ended the pursuit. :(
The context is not lost. Here's an example: #include &lt;stdexcept&gt; #include &lt;memory&gt; class Klass { public: ~Klass() { throw std::runtime_error(""); } }; int main() { std::shared_ptr&lt;Klass&gt; k = std::make_shared&lt;Klass&gt;(); } If you compile (I used: g++ -std=c++11 -g test.cpp) and run under gdb, you get a backtrace like: terminate called after throwing an instance of 'std::runtime_error' what(): Program received signal SIGABRT, Aborted. 0x00007ffff74aa428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54 54 ../sysdeps/unix/sysv/linux/raise.c: No such file or directory. (gdb) bt #0 0x00007ffff74aa428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54 #1 0x00007ffff74ac02a in __GI_abort () at abort.c:89 #2 0x00007ffff7ae484d in __gnu_cxx::__verbose_terminate_handler() () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6 #3 0x00007ffff7ae26b6 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6 #4 0x00007ffff7ae16a9 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6 #5 0x00007ffff7ae2005 in __gxx_personality_v0 () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6 #6 0x00007ffff784ef83 in _Unwind_RaiseException_Phase2 (exc=exc@entry=0x615ca0, context=context@entry=0x7fffffffdaa0) at ../../../src/libgcc/unwind.inc:62 #7 0x00007ffff784f2eb in _Unwind_RaiseException (exc=0x615ca0) at ../../../src/libgcc/unwind.inc:131 #8 0x00007ffff7ae290c in __cxa_throw () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6 #9 0x0000000000400d09 in Klass::~Klass (this=0x615c30, __in_chrg=&lt;optimized out&gt;) at test.cpp:7 #10 0x000000000040190e in __gnu_cxx::new_allocator&lt;Klass&gt;::destroy&lt;Klass&gt; (this=0x615c30, __p=0x615c30) at /usr/include/c++/5/ext/new_allocator.h:124 #11 0x00000000004018e1 in std::allocator_traits&lt;std::allocator&lt;Klass&gt; &gt;::destroy&lt;Klass&gt; (__a=..., __p=0x615c30) at /usr/include/c++/5/bits/alloc_traits.h:542 #12 0x00000000004017d1 in std::_Sp_counted_ptr_inplace&lt;Klass, std::allocator&lt;Klass&gt;, (__gnu_cxx::_Lock_policy)2&gt;::_M_dispose (this=0x615c20) at /usr/include/c++/5/bits/shared_ptr_base.h:531 #13 0x0000000000400ec0 in std::_Sp_counted_base&lt;(__gnu_cxx::_Lock_policy)2&gt;::_M_release (this=0x615c20) at /usr/include/c++/5/bits/shared_ptr_base.h:150 #14 0x0000000000400def in std::__shared_count&lt;(__gnu_cxx::_Lock_policy)2&gt;::~__shared_count (this=0x7fffffffdea8, __in_chrg=&lt;optimized out&gt;) at /usr/include/c++/5/bits/shared_ptr_base.h:659 #15 0x0000000000400d26 in std::__shared_ptr&lt;Klass, (__gnu_cxx::_Lock_policy)2&gt;::~__shared_ptr (this=0x7fffffffdea0, __in_chrg=&lt;optimized out&gt;) at /usr/include/c++/5/bits/shared_ptr_base.h:925 #16 0x0000000000400d42 in std::shared_ptr&lt;Klass&gt;::~shared_ptr (this=0x7fffffffdea0, __in_chrg=&lt;optimized out&gt;) at /usr/include/c++/5/bits/shared_ptr.h:93 #17 0x0000000000400c32 in main () at test.cpp:12 (gdb) where frames #9 and #17 are what you're after. 
That type of stack trace isn't always available in a production build in the field. 
What kind of stack traces are you using then? I'm not too familiar with Windows error handling. Regardless, there's nothing magic about smart pointers that would mask invocation of the destructor in a stack trace.
They are built into the exception mechanism. So they don't depend on any platform specific functionality or on symbolic information being available in production builds, which it may not be. Each catcher along the way can just add his/her location to the stack trace. I also wouldn't be surprised if some smart pointer stuff (given that it's specifically designed to be extremely small foot print and all is generated directly into the calling code) would not be seen as a separate call in some production builds even if you did use some sort of native stack trace. 
Using a temporary string is the best way to avoid lines being mixed up. You don't have sync issues when writing to a string, and when you write the whole string at once nothing will interrupt it (unless you disabled the sync).
I doubt they'd be using boost in the game industry.
Really? Why not? I've never worked on games before. 
It depends a lot on what the objective of the lecture is. But if you want to reach people how to write good code, don't put the more recent constructs in an advanced class. If people were teaching how to use `unique_ptr` before `malloc` and `new`, we'd get a lot less programs with memory leaks and various errors. No need to give a rocket launcher to people who just started, they'll just blow themselves off. Start with safer things and move from that.
Really, you require strong C++17 knowledge that is "needed for the job" when MSVC only added full support for it less than a year ago? Good luck with your almost always auto code base in 10 years when everybody has realized that was a terrible idea. 
Is there any (stand alone compilable) example with the task\_system? I'd like to play with it but I even don't see any test cases. 
&gt;They are built into the exception mechanism. If you're using your own homespun exception mechanism then clearly it won't be compatible with shared_ptr, so you probably should have led with that. &gt;I also wouldn't be surprised if some smart pointer stuff (given that it's specifically designed to be extremely small foot print and all is generated directly into the calling code) would not be seen as a separate call in some production builds even if you did use some sort of native stack trace. I don't think this is a legitimate worry. If you have examples of this happening I'd like to see it.
Agreed. Modern C++ features are easy enough to learn in a few weeks, graphics is not.
If they're good, experienced programmer, they should be able to adapt to the new paradigms and idioms of modern C++ on the job. Why is it critical that they come in already with those knowledge? 
Don't you have a code review culture? Nothing should be committed to the central code repository without at least one other engineer in the project reviewing it. And since the new hire's code will be reviewed by in-company veterans who are already steeped in modern C++, that's how you ramp up the newbie engineer and have him acclimate to the styles of your codebase.
Just to be clear here, while you do break the invariant of the multiset, the algorithm does work for the intended purpose right? The main issue is it's not sorted any more, so further operations on the set may lead to dubious results.
I bet you can get even better performance by adding some multi-threading to that. Especially when there's no filter, you know the size in advance so no need for a `back_inserter`, a regular iterator works. Also allows SIMD operations.
I used this exact approach to filter through a list of template parameters that could be unordered. the call signature was something like `f&lt;P1&lt;1,2&gt;, P2&lt;2,3&gt;, P1&lt;0,0&gt;, ...&gt;(A, B)`. Unfortunately, if the template parameters are not classes, one must speficy the proper template signature, so instead of `template&lt;template &lt;typename...&gt; class Template&gt;`, i had to use something like `template&lt;template &lt;size_t...&gt; class Template&gt;`. I think one could unify this approach by using std::`integral_constant`s, but that would clutter too much my call syntax...
Hey there I trying using this but gcc complains. You can check it out if you like. https://gitlab.com/LIONant/properties Is currently comment out. I have not yet investigated. 
Boost is going to make your compile times go up a lot, and is also quite slow in debug. Most game companies would avoid boost at all costs or limit it's influence to a very small part of the game.
Check out the answers on https://gamedev.stackexchange.com/questions/8980/why-dont-c-game-developers-use-the-boost-library I remember a post-mortum on a gameboy game. (I think it was DS?) They had to write a custom `std::vector` in order to work well on limited resources. Technical debt in their engine, and tool chains have a lot of inertia. Knowledge is an issue too. If your company has 10 years of expertise on DirectX for games -- why would they change to a competing API? 
It really depends on the level that I'm interviewing for. Junior level engineers are generally hired out of universities or with minimal work experience and it's hard to fault them for not learning everything, also ... They often do the interview in Python, which is fine. A senior engineer who has been working with c++ for more than a couple of years is likely to be questioned on some amount of their understanding. Sometimes they're working in code bases or technology stacks that have made it difficult to move, and sometimes they're not fully in control of those choices, but I do like to see that they're still growing. Above that, people are often domain experts. I still want to see that they're growing technically, and maybe that they've given some thought to new features, but I'm really focusing on their areas of expertise. The deeper in the stack someone is operating or expected to operate, the more I care about their skills toward things like API design which is where the big impacts of modern c++ start to show. Someone operating at the leaves to solve a problem using those apis doesn't need as much of that skill.
Canonical's kernel team unofficial moto was at one point "we're a drinking team with a kernel problem".
 &gt;I love python and use it all the time but holy shit do I still VASTLY prefer statically typed languages. God forbid I have to dig through someone's monolithic code base where the types for function parameters change based on who called the function.. If I write any serious python again it'll be with type annotations. https://medium.com/@ageitgey/learn-how-to-use-static-type-checking-in-python-3-6-in-10-minutes-12c86d72677b 
I always find eigen's API really non-intuitive. Up till now it doesn't even have a simple way for advanced indexing or even reshaping/slicing. So basically even if I have to use Eigen (a lot of other libs depend on it), i fucking hate it. The closest I found that have numpy api is [https://github.com/QuantStack/xtensor](https://github.com/QuantStack/xtensor). 
I suppose one could check if you can invoke it first and then check if the tuple types can be invoked
thanks, I've had this on my todo list for a while
Not only do doctors hate win32 api
Or it's a recursive factorial.
The main two differences are that pointers are an optional type and are considered scary. 
Damn, thanks. You learn something new every day.
&gt; Why should someone have to have significant experience in more than one language if their problem domain doesn't use more than one language? It's not a strict rule, I really only meant 'telling'. I wouldn't pass judgement right away, but this would be the first thing I would want to focus on in an interview, do they have good reasons for really only using one language. &gt; Take embedded systems, for example. The languages of choice are C and C++ along with a bit of Python for tooling. I'm not familiar w/ embedded systems per say, but I would be curious what issues Rust or Go or any other nativly compiled language had that they went with C or C++ instead? I understand there could be good reasons, I would just want to hear the candidate say them because that's really the point. In GameDev it's super common to hear people spouse the same things they were told and never looking into it any deeper than that. I just want someone who cares to learn more. Maybe that person had good reason to use C++ all the time, because he knew it, it does the job and he was good at it. Maybe, he had opportunities to branch into other areas of development and grow there but decided not too. Maybe he has a bias against the new features and just doesn't bother to learn them because he can already do the job with the tools he has. This sort of attitude is fine for some situations but in general, I don't like it. I feel like these engineers play the hot potato game, where only issues within their domain of 'expertise' are what they should be working on. And really, is it that realistic this day in age to assume someone has been working in such a narrow field that they legitimately had no better options then their own language for a decade? &gt; You could easily have worked 20 years in the field in many different projects without needing any other languages. I find this too hard to believe. Without needing? Sure, technically you can build websites in C. If you spent 20 years programming on many different projects while feeling like C or C++ has been the best choice every time then you'd have my condolences but I'd need a pretty damn good explanation why, otherwise I'd just assume you gave up years ago.
Interesting., but I usually do control stuff... In that context Eigen Api is not terrible except from. The surprises. You have mixing auto and expression templates. 
I'm sorry for you if you're stick with C++11 in 2019 ;/
This is actually one of the first things you are told when learning multi threading. The best option is using a dedicated buffer per thread and then using a lock for flush.
So, I was eager to try this out. I installed the latest version of VS2019 and tried the 10.1 installer. The installer installed CUDA build tools for MSVC 2015, VS2015 but not VS2019. No dice. I can't figure out if whatever changes were necessary to fix up STL compatibility are in VS 2017. Setting up the build environment for CUDA is completely dysfunctional for other reasons, for example, on a majority of my systems when upgrading, the CUDA installer will get stuck at various weird places "checking compatibility" or fail when installing the build tools. The best solution is to wipe the system and reinstall everything from scratch. In an ideal world, part of GPU code generation would be part of the compiler like with llvm. You guys got some of that C++AMP code lying around?.
I believe boost filesystem comes pretty close though.
I am grateful for your involvement. But I think perspective was immediately lost. Here we have few kb of C++ code that does the matrices for what it is worth. We can not compare this to gigabytes of Intel C++ matrix suite. I can't think of some killer use case, but I can say I would use this in all the use cases which are \*not\* gaming or graphics or simulations or some such endeavor. I might use this in quantitative mathematics for Value At Risk (VAR) long running calculations. For example. 
Yes. A better approach for this particular use-case would be to use `std::is_invocable` before trying `std::invoke`.
&gt; Nothing. And thank God! The standard specifies this behaviour as pseudo destructor. Well, there is a part of the committee who want to change that so it ends the lifetime of the object just like in the regular class object case. ``` using Int = int; struct Class {}; Int a{}; a.~Int(); std::cout &lt;&lt; a; // ok, no UB Class b; b.~Class(); auto c = b; // UB, b was destroyed ```
Try again. I've removed a macro from one of the examples and replaced with a proper code.
True. Fortunately, I don't have to deal with non-type template parameters. I haven't given a proper look to Hana, so I can't answer this.
Thanks I will check it out.
I would not expect to get a competent C++ programmer in the UK for that amount of money. Anyway with the willingness to do so is going to be able to get far, far more elsewhere in the country if that’s the local pay level.
Here it is on Godbolt: https://godbolt.org/z/q87Kge
The killer use-case evolves around speed and correctness. Once one has dissected the overly complicated API (i.e. make a wrapper), it's use is simple.
Exactly! And that's the bad thing about it, it's legal and works correclty.
For practical real world usage most C libraries can be considered to inherently contain C++ ”binding”, even if it looks a bit ugly. Unless you ask the ”modern C++” zealots, of course.
And `std::placeholders`, IMO.
PhysicsFS sounds like it was written by physicists... so use std::? Just kidding ((mostly) I'm an ex-physicist).
Here was the situation... this is not OK `template&lt; template&lt; typename... &gt; typename T_BASE, typename T_DERIVED &gt; struct is_specialized : std::false_type {};` `template&lt; template&lt; typename... &gt; typename T_BASE, typename... T_ARGS &gt; struct is_specialized&lt;T_BASE, T_BASE&lt;T_ARGS...&gt;&gt; : std::true_type {};` `template&lt; template&lt; typename... &gt; typename T_BASE, typename T_DERIVED &gt; constexpr static bool is_specialized_v = is_specialized&lt;T_BASE, T_DERIVED&gt;::value;` This is not OK &amp;#x200B; `template&lt; template&lt; typename... &gt; typename T_BASE, typename T_DERIVED &gt; struct is_specialized : std::false_type {};` `template&lt; template&lt; typename... &gt; typename T_BASE, typename... T_ARGS &gt; struct is_specialized&lt;T_BASE, T_BASE&lt;T_ARGS...&gt;&gt; : std::true_type {};` `template&lt; template&lt; typename... &gt; typename T_BASE, typename T_DERIVED &gt; constexpr static auto is_specialized_v = is_specialized&lt;T_BASE, T_DERIVED&gt;::value;` &amp;#x200B; The difference is the auto in the last line. I am not sure what is gcc thinking... Man creating cross compiling code is killing me. Cheers! 
And thats why we don't have nice things in c++. Things like manual resource management are not just "looks a bit ugly", they make the API inherently more difficult to use than necessary and may even increase the likely hood to introduce bugs. C++ is so much more than writing `foo.bar()` instead of `bar(&amp;foo)`. This was already true in c++98 and is true today even more.
Here is the code if you want to play around. Bad GCC! [https://godbolt.org/z/dRaJ9r](https://godbolt.org/z/dRaJ9r) Line 149 like I said change the auto to bool and it will get fixed Cheers
std::filesystem is for navigating files and directories, not for accessing zip files or archives. PhysFS is used to access zip files or other archives that contain files and directories. If you have a lot of files that need accessing then it can be faster (depending on the compression of the archive) than having to open every single file manually, as there will only be one file to open. If you want a cool use case for PhysFS, which the Love2D game framework utilises, is that if you concatenate a zip file to the end of an executable ($cat myapp res.zip &gt; myapp) and use PhysFS to mount its own binary then you can easily embed resources within the executable without having to use anything specific to Windows or Linux.
You explain the code praising how "simple and great" it is while it is a huge source of bugs. What exactly will "make the compiler [stop] you from even trying to move it in the “standard” way"? You can easily make a copy or a move of such a container and you WILL have a bug. Also if the "code shouldn’t work in the real world", then please put this LARGE AND BOLD next to it or beginners will happily use it for the advantages you described (and which don't exist IMO)
&gt; In general yes, a double free is possible but the trick is to use a container that does not free the memory in a way that invokes the destructor of the stuff being moved from (aka a relocation). Where is this "trick" used in your class? Your destructor destroys the objects by calling their destructors hence double free and double destruction on a copy or move. 
The if is not required and self move is completely fine: `x = std::move(x)` is valid. After the move `x` is in undefined state but the assignment makes it a defined state again. Why if is not required: The code boils down to `std::exchange(this-&gt;x, other.x)`. Think about it and you'll see that this is a no-op for self-moves
If never said that the `if` was mandatory.
&gt; there is a cost to separating everything out into independently managed objects Nope. Only if those objects heap-allocate. If you use a RAII wrapper for file objects etc. instead of writing the same code in your class you end up with the same locality. &gt; Move assignment must ensure that an object is not moved to itself for exception safe guarantees to be met. Nope. Especially for containers move is a swapping of pointers. No self-checks required.
No need for the delete. You have the destructor for that so DRY! (dont repeat yourself). An exchange/swap is the right way and is even self-assignment safe
Without deleting the copy and move constructors and operators this is not an optimization but a bug source.
 int main() { void *p = &amp;p; std::cout &lt;&lt; bool(p); } Hey, I submitted that example to CppQuiz. Funny to see it back.
There isn't any swap happening: The code does a simple memcpy. No destructors a called.
However, why would you insert everything in a set rather than sorting a vector in the first place? Memory locality is terrible with a set, vector are better than almost everything else in the vast majority of cases, and your data wouldn't be stored as a set in the first place anyway.
'Using namespace' works inside a namespace. We don't need a scoped 'using namespace'.
Maybe you, haven't seen but Eigen can do reshaping and slicing. :) [https://eigen.tuxfamily.org/dox/group\_\_TutorialReshapeSlicing.html](https://eigen.tuxfamily.org/dox/group__TutorialReshapeSlicing.html) &amp;#x200B; And for indexing, you can use the Coefficient Accessors [https://eigen.tuxfamily.org/dox/group\_\_TutorialMatrixClass.html](https://eigen.tuxfamily.org/dox/group__TutorialMatrixClass.html) &amp;#x200B; Its not perfect (i've seen some horrible template errors when it can't figure out the right types from complex expressions), but its used heavily in the Computer Graphics Simulation world (industry and academia). &amp;#x200B;
If it was fixed as a defect report (DR) then the fix is often applied retroactively. So it will be fixed for all versions that support the core feature.
 using MySomeGadgiMathing = LibBar::GadgetHelper::SomeGadgiMathing; Would that cause any actual problems? It should transparently accept the canonical name while also saving you typing. I guess the ugly alternative is a define too. 
That in fact is what I suggested as a solution to the inital problem. The export/insert approach was for the next problem, the one with the map, without a loop.
That's a no-no in header files.
`using namespace` is a no-no inside headers.
They don't think they can adapt so they'd rather drag you down to the status quo or drive you away screaming. You can't change people's minds that are made up like that. The best you can do is carve off part of the project or start a new project in modern c++, don't advertise it, and just outpace them. It's hard for management to ignore results like that, but you also put the relationship with your colleagues and job at risk. Be careful and good luck.
I originally did [this](http://mariobadr.com/using-clang-format-to-enforce-style.html) (warning, the post is quite dated), which creates a target-per-project in CMake for applying clang-format. But since then I've simply integrated it with my IDE instead of my build system. This works because I work on the majority of my repos alone... I doubt it would scale very well to a team unless everyone is as pedantic about style as the other.
By "optional type," you mean they can be null? So can references. They're not *supposed* to be, but they absolutely can be null.
I think formatting (I.e. changing the source code) as part of your build process is a very, very bad idea. You should integrate it into your editor and maybe to your per-commit check.
I don't think you should integrate that into build system. Think about it - someone commits code that has wrong formatting, people pull the changes, build them and now everyone has changes in their source trees. Should they commit those changes? Why? &amp;#x200B; Reformat should be triggered before the commit, like most IDEs do (Clion has that option), not during the build. 
I do [this](https://github.com/ttroy50/cmake-examples/blob/master/04-static-analysis/clang-format/README.adoc) which generates format and check-format targets
 How do you integrate/use clang format ? Not at all. Formatting is part of the editing process (i.e. format on save). Bilds are never allowed to change any artifacts authored by developers.
**Company:** [Gritworld](https://www.gritworld.com/) **Type:** Full time **Description:** Gritworld pushes the boundaries of real-time graphics and computer vision and develops key technologies in graphic visualisation applications for the industry. Our focus is to improve the productivity of our clients in real-time Film and TV production, as much as real-time industry data simulation and visualization. We strongly believe in creating a work environment where people, ideas and results are more important than regulations and time sheets. Every human ticks a bit different, but we still share our laughs together. If you want to learn, create and grow with us, join us today. As a growing start-up Gritworld offers excellent opportunities for personal career development. *What you need for this position:* * You have 4 or more years of experience as developer in at least one professional environment * You finished a degree in computer science, programming or similar * You have a passion for clean coding and creative thinking * You have solid English language skills, both verbal and written *Required skills:* * Strong programming skills in C++ and modern standards 11/14/17 * Data-driven design and software architecture * Excellent debugging and optimization skills * Knowledge about common game engine systems, such as asset pipelines, entity component systems * Good understanding of multithreaded software architecture * Ability to work with an existing codebase, and eager to further improve it **Location:** Frankfurt am Main, Germany **Remote:** No **Visa Sponsorship:** Yes **Technologies:** Modern C++ (11/14/17) **Contact:** Apply [here](https://gritworldhr.bamboohr.co.uk/jobs/view.php?id=48)
I freely admit, I should have had no idea that the example with the three-argument operator would have been a problem. Wonder if I've ever written code like that somewhere. 
&gt; `"ABC"` is nothing else than `const char *` not true, though I suppose explaining what type it has would break the flow
Perhaps the question should be "How do you integrate clang format in your build system so that it report potential format failures?"
This is what happens when you post code, everyone checks if_pokable_v to find all the little things not about the main topic :)
We use something like this as a CMake target: [GitHub Link](https://github.com/felixguendling/cista/blob/910ceb1d2d460f77f378a916ee3c2273638ad6e6/CMakeLists.txt#L38-L58) (`CMakeLists.txt`) We also check this in the CI build: [GitHub Link](https://github.com/felixguendling/cista/blob/910ceb1d2d460f77f378a916ee3c2273638ad6e6/.travis.yml#L33) (`.travis.yml`) &amp;#x200B; And of course every developer should have this on a keyboard short cut in their IDE/editor. I have configured (and recommend doing so) my editor(s) to format on save.
Question here regarding the detection idiom: will it be needed after lambdas in unevaluated contexts are added in C++20?
Hmm I think you are correct. I will reconsider my approach. Thanks.
Ow my eyes!
Just create a .clang-format file and put it in your projects root directory and enforce clang-format on pull requests.
Didn't know that subreddit! Thank you.
Pre-commit hook is the answer.
I know eigen can do all these stuff, all I said is that there is no simple intuitive way of doing it, like bumpy.
That’s awesome. Bet you’re going to find some more #define’d monstrosities.
This was my initial thought.
Use case I've seen: interpret input as date, try to parse it with one format, not working? Throw exception, repeat after catch with other format...
Loop macros (or macros that behave like a loop) are fairly common in C, specially for complex data structures. It is not that uncommon :)
So I have a template version of this I have used to unroll things namespace algorithm_impl { template&lt;typename Function, typename... Args, size_t... Is&gt; constexpr void do_n( Function &amp;&amp;func, Args &amp;&amp;... args, std::index_sequence&lt;Is...&gt; ) noexcept( std::is_nothrow_invocable_v&lt;Function, Args...&gt; ) { if constexpr( sizeof...( Is ) &gt; 0 ) { (void)( ( daw::invoke( func, args... ), Is ) + ... ); } } template&lt;typename Function, size_t... Is&gt; constexpr void do_n_arg( Function &amp;&amp;func, std::index_sequence&lt;Is...&gt; ) noexcept( std::is_nothrow_invocable_v&lt;Function, size_t&gt; ) { if constexpr( sizeof...( Is ) &gt; 0 ) { (void)( ( daw::invoke( func, Is ), 0 ) + ... ); } } } // namespace algorithm_impl template&lt;size_t count, typename Function, typename... Args&gt; constexpr void do_n( Function &amp;&amp;func, Args &amp;&amp;... args ) noexcept( std::is_nothrow_invocable_v&lt;Function, Args...&gt; ) { algorithm_impl::do_n( std::forward&lt;Function&gt;( func ), std::forward&lt;Args&gt;( args )..., std::make_index_sequence&lt;count&gt;{} ); } template&lt;typename Function, typename... Args&gt; constexpr void do_n( size_t count, Function &amp;&amp;func, Args &amp;&amp;... args ) noexcept( std::is_nothrow_invocable_v&lt;Function, Args...&gt; ) { while( count-- &gt; 0 ) { daw::invoke( func, args... ); } } template&lt;typename Function, typename... Args&gt; constexpr void do_n_arg( size_t count, Function &amp;&amp;func ) noexcept( std::is_nothrow_invocable_v&lt;Function, size_t&gt; ) { size_t n = 0; while( n &lt; count ) { daw::invoke( func, n++ ); } } template&lt;size_t count, typename Function, typename... Args&gt; constexpr void do_n_arg( Function &amp;&amp;func ) noexcept( std::is_nothrow_invocable_v&lt;Function, size_t&gt; ) { algorithm_impl::do_n_arg( std::forward&lt;Function&gt;( func ), std::make_index_sequence&lt;count&gt;{} ); } 
Quite interesting part on optimizing the compiler by building it with PGO &amp; LTO. Anyone else here used this technique? What kind of speed ups one can expect? (Presentation only mentions hello-world example with a boost header include)
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b2gdhi/cmake_resources/eit4ffm/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Why?
Well, it's like c++ doesn't have nice way to loop over iterators or anything.
I wish I could find a tool that would auto-refactor this. 
There's a surprising number of IMO bad answers in this thread. Folks seem to think that "integrating clang-format in builds" means that you want to \_apply\_ formatting fixes automatically during a build. A lot of us use clang-format in builds in a more linter-like fashion. e.g., fail the builds on format violations. Combined with clang-tidy to do the same. There can then be an additional optional build target or CI project to apply changes. The neat version of that turning into a CI failure reported on your GitHub/GitLab/etc. server with a handy "click this link to apply format/tidy" fixes. Which commits a new change into your PR's branch. So far as setting all that up, there's a ton of articles available if you Google "CMake clang-format." I never integrate it into the main CMake builds because clang-format has an unstable config file (e.g. the files that work in clang-format 6 don't work in 7 and vice versa... sigh) and I'm not interested in forcing other developers to install exact specific versions of things, especially for open source projects. So I keep it all in CI scripts, where I just use CMake to generate a compilation database and then feed that into clang-format via a script.
I'll take the C version :p
Yeah we went back and forth early on, I was planning on adding multiple callbacks, to follow the Javascript API, but eventually I was wisely convinced (IMHO) to only use one callback.
For me it looks like code from competitive programming (not for production ! ) More complete version below (taken from shared solution of one contest) :) `#define REP(i,x,v)for(int i=x;i&lt;=v;i++)` `#define REPD(i,x,v)for(int i=x;i&gt;=v;i--)` `#define FOR(i,v)for(int i=0;i&lt;v;i++)` `#define FORE(i,t) for (typeof(t.begin()) i=t.begin(); i!=t.end(); i++)` `#define REMIN(x,y) (x)=min((x),(y))` `#define REMAX(x,y) (x)=max((x),(y))` `#define pb push_back` `#define sz size()` `#define mp make_pair` `#define fi first` `#define se second` `#define ll long long` `#define IN(x,y) ((y).find((x))!=(y).end())` `#define un(v) v.erase(unique(ALL(v)),v.end())` `#define LOLDBG` `#ifdef LOLDBG` `#define DBG(vari) cerr&lt;&lt;#vari&lt;&lt;" = "&lt;&lt;vari&lt;&lt;endl;` `#define DBG2(v1,v2) cerr&lt;&lt;(v1)&lt;&lt;" - "&lt;&lt;(v2)&lt;&lt;endl;` `#else` `#define DBG(vari)` `#define DBG2(v1,v2)` `#endif` `#define CZ(x) scanf("%d",&amp;(x));` `#define CZ2(x,y) scanf("%d%d",&amp;(x),&amp;(y));` `#define CZ3(x,y,z) scanf("%d%d%d",&amp;(x),&amp;(y),&amp;(z));` `#define ALL(x) (x).begin(),(x).end()` `#define tests int dsdsf;cin&gt;&gt;dsdsf;while(dsdsf--)` `#define testss int dsdsf;CZ(dsdsf);while(dsdsf--)`
You must be looking forward to `for...`.
ReSharper C++ ([https://www.jetbrains.com/resharper-cpp/](https://www.jetbrains.com/resharper-cpp/)) can do it.
Not sure if that helps you, but there is actually a quite nice blog by Stephen Kelly. [https://devblogs.microsoft.com/cppblog/exploring-clang-tooling-using-build-tools-with-clang-tidy/](https://devblogs.microsoft.com/cppblog/exploring-clang-tooling-using-build-tools-with-clang-tidy/) &amp;#x200B; If I understand it correctly he basically build his own cmake / clang-tidy build system which invokes a python script to achieve what you want... [https://github.com/steveire/codedive2018/tree/master/0005-ninja-build](https://github.com/steveire/codedive2018/tree/master/0005-ninja-build) &amp;#x200B;
I see this all the time in the legacy codebases I maintain. They are mostly from the late 1980s up to the late 1990s. The original coders came from a FORTRAN background and were thinking in terms of performance, for the type of algorithms they would normally write. &amp;#x200B; There was a time where function calls could be slow, and people didn't really trust the optimizers.
I dont. I use a githook instead. Here is the [pre-commit](https://github.com/ROCmSoftwarePlatform/AMDMIGraphX/blob/develop/.githooks/pre-commit) hook that I use. It goes into a `.githook` directory in the repo and has an [install](https://github.com/ROCmSoftwarePlatform/AMDMIGraphX/blob/develop/.githooks/install) people can run to enable it.
you are free to, but the code gen is the same and mine breaks nicely(until you get to about 1000 or so reps).
Right, but this is neither of those things (C or specific data structure)
-E \s
The trouble is git hooks is people can not run them. It's also worth having a check as part of the ci process. 
You need to use `-export-fixes` which will write them out to a yaml file. And then you can apply the fixes with `clang-apply-replacements &lt;directory-to-fixit-yamls&gt;` to apply all the fixits at once. We use a cmake module to setup clang-tidy [here](https://github.com/RadeonOpenCompute/rocm-cmake/blob/master/share/rocm/cmake/ROCMClangTidy.cmake) that will run with `make analyze` or `make tidy`. It writes out each yaml file to a `fixits` directory in the build directory [here](https://github.com/RadeonOpenCompute/rocm-cmake/blob/master/share/rocm/cmake/ROCMClangTidy.cmake#L133). So fixits can easily be applied with `make -j$(nproc) analyze &amp;&amp; clang-apply-replacements fixits/`.
Last I tested (and it's been a few years), clang built bootstrapped PGO+LTO was about the same as clang built with gcc. Optimizations in clang have gotten better, so it's probably worth trying again. It also wasn't very easy getting it working, requiring me to define obscure cmake variables like `BOOTSTRAP_BOOTSTRAP_COMPILER_RT_CMAKE_C_FLAGS`. That tells me probably either I was doing it wrong, or I was working in uncharted territory. I do know it didn't work out of the box, and I spent a lot of time looking at the Apple cache configurations to figure out why the PGO cache configuration wasn't working.
That does look bad, but I must confess, I do use a HOF for nested multidimension loops I call [`dfor`](https://github.com/ROCmSoftwarePlatform/AMDMIGraphX/blob/develop/src/include/migraphx/dfor.hpp#L16): double product(std::vector&lt;float&gt; x, std::vector&lt;float&gt; y) { double acc = 0; dfor(x.size(), y.size())([&amp;](std::size_t i, std::size_t j) { acc += x[i] * y[j]; }); return acc; } The main reason is that I almost always mess up the variables in the different loops. I also have a parallel version called [`par_dfor`](https://github.com/ROCmSoftwarePlatform/AMDMIGraphX/blob/develop/src/include/migraphx/par_dfor.hpp#L13) so it makes it nice when I want to make the loop parallel.
Ah yes, for CI I run: find . -iname \'*.h\' \ -o -iname \'*.hpp\' \ -o -iname \'*.cpp\' \ -o -iname \'*.h.in\' \ -o -iname \'*.hpp.in\' \ -o -iname \'*.cpp.in\' \ -o -iname \'*.cl\' \ | grep -v 'build/' \ | xargs -n 1 -P 1 -I{} -t sh -c 'clang-format-5.0 -style=file {} | diff - {}' Which will flag any files that aren't formatted, but it doesn't help the developers format the code unless they install the githook.
I think `/bin/rm` would do a good job.
I don't think ``` works on reddit You need to indent by four spaces instead. #define REP(i,x,v)for(int i=x;i&lt;=v;i++) #define REPD(i,x,v)for(int i=x;i&gt;=v;i--) #define FOR(i,v)for(int i=0;i&lt;v;i++) #define FORE(i,t) for (typeof(t.begin()) i=t.begin(); i!=t.end(); i++) #define REMIN(x,y) (x)=min((x),(y)) #define REMAX(x,y) (x)=max((x),(y)) #define pb push_back #define sz size() #define mp make_pair #define fi first #define se second #define ll long long #define IN(x,y) ((y).find((x))!=(y).end()) #define un(v) v.erase(unique(ALL(v)),v.end()) #define LOLDBG #ifdef LOLDBG #define DBG(vari) cerr&lt;&lt;#vari&lt;&lt;" = "&lt;&lt;vari&lt;&lt;endl; #define DBG2(v1,v2) cerr&lt;&lt;(v1)&lt;&lt;" - "&lt;&lt;(v2)&lt;&lt;endl; #else #define DBG(vari) #define DBG2(v1,v2) #endif #define CZ(x) scanf("%d",&amp;(x)); #define CZ2(x,y) scanf("%d%d",&amp;(x),&amp;(y)); #define CZ3(x,y,z) scanf("%d%d%d",&amp;(x),&amp;(y),&amp;(z)); #define ALL(x) (x).begin(),(x).end() #define tests int dsdsf;cin&gt;&gt;dsdsf;while(dsdsf--) #define testss int dsdsf;CZ(dsdsf);while(dsdsf--) 
If someone is lazy to write std in small files, an alternative to import the whole namespace is to use: &amp;#x200B; namespace s = std; namespace b = boost; namespace bi = boost::interprocess; s::string; s::bind(...); &amp;#x200B;
I grew a distaste for ASIO years ago (maybe 2008) when I was trying to write a networking application and got a long error message. I waited a few minutes for the screen to stop scrolling, but it kept going. I went to lunch, came back, and the compiler was still spewing error messages. No idea what I did wrong, as I didn't try to reduce it to a small test case. I find ASIO challenging, but I have no problem writing programs that do BSD sockets or reading template-meta-heavy code. It's something about the mixture of the two that makes it confusing.
Would you accept someone with a year's experience but fulfill the other criterias? 
I do wish C++ had some syntax sugar to allow custom `for_each_something(...) { ... } ` without resorting to macros or nesting the block inside the call as a lambda.
It does. It's called a range-for loop.
You can just run the preprocessor, or if you really want to, write a simple parser that does it. Can't imagine it'd take more than an hour.
Same codegen. Abysmal compile time.
You can make this saner... #define LOOP_IT( IT, START, END, CMP, STEP ) \ for( int IT=START; IT CMP END; STEP IT ) #define LOOP_UP( IT, LEN ) \ LOOP_IT( IT, 0, LEN, &lt;, ++ ) #define LOOP_DOWN( IT, LEN ) \ LOOP_IT( IT, LEN-1, 0, &gt;, -- ) #define FORWARD_LOOP(IT, CONTAINER) \ LOOP_UP( IT, CONTAINER.length() ) #define BACKWARD_LOOP(IT, CONTAINER) \ LOOP_DOWN( IT, CONTAINER.length() ) add some extra ()s. Better than raw fenceposting errors. 
The range-for loop comes pretty close, but it doesn't play well with SoA setups. The form with init statement in C++20 comes even closer, but who knows when we'll be able to use it reliably in CUDA 8-/.
Not necessarily a discovery but still surprised you can get away with this: ```cpp void DoSomething(Data&amp; myRef) { ... } ... DoSomething(*(new Data())); // instantiate and deref ```
it can, a thousand different types kills things
With C++17, you could potentially rewrite this to be: for (auto [i, j] : dfor(x.size(), y.size())) { // loop body } Which is a little nicer.
The fact that there is `loopl` means there's at least one piece of code with `O(n^4)` complexity.
&gt; I don't think ``` works on reddit You need to indent by four spaces instead. I know it doesn't make sense but I think this is browser/platform-specific and possibly a reddit bug. It works on my end. Probably someone should report that bug to reddit, it has been around for a while.
Resharper C++ is great for this task, but it brings in an assumption that the code is compilable with Visual Studio. A less restrictive solution would be to integrate clang-tidy in your build process. (Resharper leverages on clang-tidy for these suggestions) Keep in mind that some of the cases won't be recognized, i.e. variable is declared and initialized in the first line, but then reassigned immediately on the next line. Joining the declaration with assingnment will be reported after you remove the initializer. So you have to repeat the process atleast twice. Source: I've been doing exactly the same thing last week with Resharper
This is very common in legacy C code bases. I'm working on one right now like this, and we're leaning into it. I'm currently trying to figure out ways of implementing GPU offloading code using macros that abstract loops.
I see! Thank you for elaborating! And thank you so much for your CMake book and the continuous updates. You set the bar on a whole new level for other authors.
Sometimes you have a complex structure where you want to do iterate over all the elements and do some work at each element. Using macros, you can define the basic looping methods, and the macro then accepts a body of code (as an argument) which is performed when it reaches an element in the structure. This simplifies the code necessary to iterate over Now you might ask "Why not just define a function that iterates over the structure, and also accepts a function argument and args struct that does the work", which is a totally valid idea. But you might have lots of shared state in between invocations of these structure iterations that you dont want to keep passing between the many different work-functions. &amp;#x200B; For example, you might have an octree representing some non-rectangular region of space with many cubes. Then, you want to apply a series of +20 operations to all the elements in those cubes. With the function-pointer pattern, we'd need a function for each operation, with its own struct for arguments, and pass the stared state (there could be literally hundreds of variables), and all of that around. With the macros, its like writing normal looping code (where normal looping code might be \`for( auto element : struct ){ body; }\` ) You don't need dozens of functions and structs to make it all work, it just kinda does. It's not great today, but back in the day this is arguably good design for what was available at the time.
Indeed. And shifting from boost::filesystem to std::filesystem was quite easy. Had to change a few things but otherwise painless. 
&gt; How anyone thought this could be a good idea? BOOST_FOREACH 
&gt; Be careful and good luck. I thank you, but I'm actually unemployed right now and working on a game! In C++!!
Literally copy pasting for each #define would be the fastest solution IMO (if you don't want to run the preprocessor only)... Start your copy pasting from the bottom macro and it will all work fine with the recursive macros
I am quicker to give up nowadays, too. One problem I've noticed in open source projects is that they are specifying their dependencies too tightly. Assuming a library uses a major.minor.rev versioning scheme, and further assuming major=API-breaking changes, minor=new features and possibly API issues, and rev=bug fixes, there is no reason for a client project to require exactly version 1.2.3. They should be dependent on major.minor, with a recommendation to use rev &gt;= 3 or whatever. I can't remember what I was building, but it required very specific .rev versions of cairo and pango, while I already had matching major.minor versions installed. There's no need for that. Readers: Don't get hung up on my major.minor.rev definitions, my point is not that, it's about overly-constrained versioning in general.
What's your end? I'd guess that it's an app that uses a non-standard parser. ``` isn't [standard Markdown](https://daringfireball.net/projects/markdown/syntax). It's a very common extension (it is in [CommonMark](https://commonmark.org/help/)), but since it's [not used on the Reddit webpage](https://www.reddit.com/wiki/commenting) I'd avoid using it here.
I believe this is part of the redesign
I don't integrate tools like clang-tidy or clang-format with the build-system directly. Enabling this during all compilation would make iterating on the code slower, and it's non-trivial to know on which file to run it (all files might be costly). Doing it on-demand is only partially useful if external casual contributors don't think about it. &amp;#x200B; I created [`run-clang-format.py`](https://run-clang-format.py) so that formatting can be checked using CI, e.g. on Github this runs on pull requests, before code enters the repository: * [https://github.com/Sarcasm/run-clang-format/](https://github.com/Sarcasm/run-clang-format/) &amp;#x200B; Also, I configure my text editor so I can format the lines I'm changing. I use `git clang-format` when I know I made a lot of changes and probably missed up some formatting. Pre-commit hook is interesting, but external contributors won't necessarily have them.
Is it possible to run the preprocessor, but not resolve any includes in the output?
It works on `www.reddit.com`, but doesn't on `old.reddit.com`. 
It's a good one. But I think the (traditional) choice of whitespace maybe contributes a little. I think the disturbing aspect of this example is that C++ is (casually) permitting (full) access to the object before construction. So for example ```cpp std::vector&lt;int&gt; v{ v.at(0), v.at(1) }; ``` seems to compile (and sometimes run) just [fine](http://coliru.stacked-crooked.com/a/2173b6a18cb27f61). This has implications for the question "Is it possible(/practical) to ensure memory/UB safety in C++ by simply sticking to a (safe) subset of its elements (as opposed to imposing restrictions on how the elements are used)?". The answer appears to be mostly yes (if, for example, you accept that the implicit `this` pointer qualifies as a C++ "element"), but this example is a thorny, if uncommon, exception. 
I'd say building a small game is a pretty solid way to learn OO and C++ in general, and also about the limits of OOP (which is why most people in game dev use data-oriented design and ECS nowadays).
Yeah it doesn't seem like code for production. I also do competitive programming and sincerely there are things from my template I would never use for a real application
what container has `length` in stead of `size`?
I'm using QtCreator with clang format support built in (I think it's a bundled plugin), so I bound it to a hotkey to allow for easy access formatting when required. You can also define several clang-format config files directly in the program to allow for switching depending on your project's needs. As others say, I think it is better suited in the editor.
This is *not* a good idea. This is, however, a good cause for immediate termination :P
That sounds like a very straightforward case for [`std::inner_product`](https://en.cppreference.com/w/cpp/algorithm/inner_product): return std::inner_product(x.begin(), x.end(), y.begin(), y.end(), 0.0); And even in general, you'd be much better of with writing zipped iterators.
Ah, you seem to be correct. Despite the help link on [the new submit page](https://new.reddit.com/submit) leading to the same commenting wiki page, there is a [new markdown wiki page](https://www.reddit.com/wiki/markdown#wiki_new_features_inherited_from_commonmark) that says they're using CommonMark, which has ``` (and ~~~) code blocks. 
&gt;Resharper C++ is great for this task, but it brings in an assumption that the code is compilable with Visual Studio. It's true, it is closely related to Visual Studio (and MSBuild), but it's possible to use command line tool ([https://blog.jetbrains.com/dotnet/2018/03/01/code-cleanup-resharper-command-line-tools/](https://blog.jetbrains.com/dotnet/2018/03/01/code-cleanup-resharper-command-line-tools/)). &gt;A less restrictive solution would be to integrate clang-tidy in your build process. (Resharper leverages on clang-tidy for these suggestions) No, ReSharper doesn't leverage on clang-tidy for these suggestions. &gt;Keep in mind that some of the cases won't be recognized, i.e. variable is declared and initialized in the first line, but then reassigned immediately on the next line. Joining the declaration with assingnment will be reported after you remove the initializer. &gt; &gt;So you have to repeat the process atleast twice. Unfortunately it's true right now. &amp;#x200B; Source: I'm working in ReSharper C++ team.
Not understanding why they have loopi,j,k,l... It's like what? They thought that it'd make separate iterator variables when nested? That's really scary to think about -- especially if they got the thing working XFD
Meson will create a `clang-format` target that you can run manually and it will reformat all code in the source tree using as many parallel processes as your machine has CPUs. The target is only created if: - the repo has a `.clang-format` file - clang-format binary is in path - the project does not define `clang-format` target by itself 
Don't know about these things. If anything, I'd replace the includes with dummy char strings or something similar before running the preprocessor and put the include statements back afterwards. 
I think I understand the problems you're bringing up if fancy pointers were not default constructible. Are you saying that fancy pointers don't need to be default constructible because nowhere in \[allocator.requirements\] does it mention allocator::pointer must be default constructible, or is there another part of the standard that governs this? &amp;#x200B; It seems like these issues with default constructibility could apply to a lot of places in the STL, what is the scope of the patch that you were previously working on for this?
Oh, sorry, then I was confused, every time when these suggestions appeared to me they were associated with the clang-tidy suggestion, I didn't know they are recognized separately. Anyways, thank you for amazing work!
Who needs raw owning pointers when we can have raw owning references? /s
No problem, and thank you for the kind words!
Strictly speaking it means there's at least one piece of code with `O(i * j * k * l)` complexity - there's no necessity that the terms are proportional to each other. 
That's my usual workaround, but under `std::ios_base::sync_with_stdio(false)` that can still cause full strings to be printed more than once.
Or a dedicated logging thread that you send your messages to, which also avoids holding up all your processing threads logging to the output stream (especially if it's a file). Of course if things are getting this serious, you should use an existing logging library rather than rolling your own.
Oh fair enough :) I've been meaning to give [https://github.com/QuantStack/xtensor](https://github.com/QuantStack/xtensor) a go which looks like it has numpy like syntax. 
&gt;because nowhere in [allocator.requirements] does it mention allocator::pointer must be default constructible Right. It only really affects the containers. The scope of the problem is to ensure all our containers support fancy pointers. 
string?
Just compare this (from Eigen 3.3.7) ```code Map&lt;MatrixXf,0,OuterStride&lt;&gt; &gt; M2(M1.data(), M1.rows(), (M1.cols()+2)/3, OuterStride&lt;&gt;(M1.outerStride()\*3)); ``` to xtensor ```code auto v1 = xt::view(a, xt::range(1, 3), xt::all(), xt::range(1, 3)); ``` I would pick the second one on any day.
Out of curiosity, how do these macros help in competitive programming?
At the beginning they are mostly confusing. But once you dive more and more and you are very skilled, the difference between getting more points is just a matter of typing faster than others. When you abstract some tools as macros or aliases, you gain a little time against others and that can be the difference between being first or second in a contest. In ACM-ICPC and some CodeForces rounds it matters because the first to solve a problem in World Finals gets a check for doing so, and in CodeForces rounds you might get a t-shirt by being among the top 50. For lower rankings, as I said, is mostly confusing and won't help that much, the templates generally are personal and won't help you that much unless you understand it and use thoroughly.
Smells like a python programmer
oh I would pay good money, but really time, to seeing this. Yes to the blogs easing developers into it.
I have edited the answer multiple times during creating this post. I suppose it is displayed fine now (checked on reddit and old reddit). "Preview" option would be great.
Yes :)
C++11 and later provide much better facilities to help produce readable error diagnostics. The situation is much better now than it was in 2008! Beast is designed with diagnostics in mind, by doing as much type-checking as possible to prevent the "error wall of doom", for example: https://github.com/boostorg/beast/blob/0c3ca62590e7d31dbd9ac5823ea52a95b9a5967d/include/boost/beast/http/impl/read.hpp#L450
I'd say that the dection idiom is more threatened by concepts and `reuires` than lambdas in unevaluated contect.
Yeah, it works now. Preview would be god sent. We'll never get it. At least not on old.reddit.com and I refuse to use the "redesign".
In my previous job I'd teach people about move semantics on a weekly basis, then next week I'd have to teach them about it all over again. Part of the problem is that people never saw the need to learn about it. They can write the logic using the old C++98 structures and can't even wrap their head around the idea that using the new stuff could make their code safer, faster, and more maintainable. Oh well, at least I was able to push the use of unique_ptr to some degree...
There's also no necessity that the terms have linear complexity either. I just assumed linear complexity throughout the 4 nested loops.
&gt;First of all, in some languages, such as Java, “type erasure” means something completely different. In Java, it means the procedure applied by the compiler when you write a “generic” function — which looks deceptively similar to a C++ template, but is not a template! The issue is not that in "some languages" it means something different than from C++, it's that in every other language type-erasure has a well defined and formal meaning, namely it is the reverse of type inference. C++ for some reason took that term and used it to mean something else. This confusion seems to arise often with C++, where we borrow terms from other languages and use them in entirely different ways... functor is another term that means something in every other language, but in C++ basically means a function like object.
```cpp delete &amp;ref; ``` C++ is great because if you really wanted to, you can break anything
Since I roll all my own, I can do this kind of thing from the inside out, so: tCIDLib::TVector&lt;String&gt; colBunchaStrings(); colBunchaStrings.ForEach([](const TString&amp; strCur) { // do whatever;} ); And a nice side effect is that the collections also support thread safety. Since the foreach is done from the inside, it will be thread safe if the collection is thread safe, no need to lock from the outside. You can still directly iterate with an index or via a cursor of course, but for small stuff that's a pretty compact way to do it. And similarly for enumerations: tCIDLib::ForEachE&lt;tMyStuff:ESomeEnum&gt; ( [](const tMyStuff::ESomeEnum eCur) { // do whatever; } ); ); That can be convenient since directly enumerating enums that are in namespaces can be sort of wordy. &amp;#x200B;
Would love some syntax highlighting on these blocks. The code text looks samey after a line or two without it, IMO.
From your description, it sounds like C macros have been doing the same thing that people have been using lamdas for in more recent code. Fun one I like tell people about doing is object oriented C. I.E. make a struct, add function pointers, and have each function something like void function(structType *obj, other args). So, it goes back to there is always a way to anything in C.
That was a simple example. Usually its for operations over multi-dimension arrays, like [convolution here](https://github.com/ROCmSoftwarePlatform/AMDMIGraphX/blob/develop/src/targets/cpu/lowering.cpp#L163). Also, `inner_product` is not equivalent(which can be done with a zipped iterators). `inner_product` you have `x[0]*y[0] + x[1]*y[1] + ... + x[n]*y[n]`, whereas this is a cross-product which does `x[0]*y[0] + x[0]*y[1] + ... + x[0]*y[n] + x[1]*y[0] + x[1]*y[1] + ... x[m]*y[n]`.
Yes, but without ranges(like `view::for_each`) a lot more code would be needed to write that. 
&gt; it sounds like C macros have been doing the same thing that people have been using lamdas for Yes. The lambda in the macro example would be the bodies, and macros themselves are the loops or the mapping function of lambdas to data. &gt; doing object oriented C, make a struct, add function pointers Ya I've heard of this, but I still dont really understand why its better than just a collection of `TypeFame_FunctionName( TypeName* this, /* more args */ )`, since you still have to pass the instance as a function argument in both cases, and the function pointer thing brings makes me go "Oofa Doofa" in a major way. 
But there's almost no reason you'd want to use that ever from what I've seen.
I use built-in Visual Studio integration of clang format. 
You explained it much better than I did in my blog post. Thanks for that article!
Nice, I was actually mentally working out something similar while looking over the initial code. ALL\_CAPS to indicate it's a macro, reasonable function and parameter names, no hard-coded variable names in the macros, and good reuse between the macros... While I'm not sure I'd support using these macros over just typing out the loops, they're certainly a far superior improvement over the original.
`LOOP_DOWN` looks wrong to me. It ends at 1. Should use `&gt;=`.
&gt; functor is another term that in C++ basically means a function like object, which is not at all what it means in every other language that uses the term. Actually, functor has totally different meanings across languages. A C++ functor is not a Prolog functor, a Haskell functor is something completely different, and SML has also different functors.
You are absolutely right, thanks.
Wait until you see: \#define BEGIN { \#define END } So fortran programmers can feel right at home: if(x&lt;0) BEGIN do\_stuff; END
Imho, a search-replace would be the better solution then
I've made an issue for this, I'll try to support this. [https://github.com/machinezone/IXWebSocket/issues/21](https://github.com/machinezone/IXWebSocket/issues/21)
Bog standard polymorphism is type eradure. Java generics are type erasure. std function is type erasure. Go interfaces are type erasure. In all of these cases, we are writing an operation that does not need to know the full type information of the thing it is operating on. The specific type is "erased", forgotten, and we operate on this projection of the original type. It is `*-&gt;T`, where `*` is some category of types, for the purpose of converting an operation `T-&gt;X` into `*-&gt;X`. Now, how this is implemented in different languages differs. But they are all, in essence, the same operation. 
I've worked on a fair bit of C where the structs were defined and all the associated functions were defined as you indicated. And I do consider that to be (partially) objected oriented. The big reason for function pointers is then you bring in polymorphic behavior. But that, as always, requires a fair bit of forethought when designing the code. If polymorphic behavior is not being used at all, then I would really question why any function pointers would be associated with the struct. As I recall from [The design and Evolution of C++](http://www.stroustrup.com/dne.html), one of the big features of C++ was to abstract away all of what we are discussing. (The original C++ was only a frontend that translated the C++ code into C.) I think it is an interesting to learn this type of background, since it gives us a better understanding of what languages are doing underneath the hood. 
If you do need indexes, you can make a `iota_it` (and now you have a proper range for it). It is a integer with a dereference operator to satisfy the constraints of iterators. So you can use it in algorithms in some cases like when you need to use two values of an array at the same time and you can't make it work with `adjacent_difference` or something like it.
Adding an `-f`, just to be safe. You know, burn it with fire.
What's wrong with lambdas? I use them everywhere. `std::transform` works in many cases and when your compiler is modern enough it does the parallelization for you.
If it's not a constant reference, then you have a dangling reference. Lifetime checkers can detect this pattern (it was one example afaik).
I wouldn't know of any clang-tidy check that does this.
&gt; What's wrong with lambdas? I use them everywhere. Nothing is wrong with lambdas, but the syntax is yucky. I find `for_each_something(...) { ...}` considerably more readable than `for_each_something(..., [...]{ ...})`. &gt; `std::transform` works in many cases Again, it's a matter of syntax: using `transform`, `for_each`, range-for loops etc with SoA gives some very ugly code.
Like I said, fenceposting sucks.
"Functor" is borrowed from formal logic and the philosophy of language, where it essentially means "function-like sign".
Thanks, this is great! I wanted to launch it under Python3 and discovered that I need to rebuild lldb. Heavy path. I hope some Linux distros will start to provide builds with Python3.
I think the proposal to make `new` a `[[nodiscard]]` will fix that.
Why not? You can easily have an iterator over an SoA setup.
&gt; `find&lt;Object&gt;` is not real Java code, by the way. Java has no syntax to refer to “a particular specialization” of a generic method I believe it [sort of does](https://stackoverflow.com/questions/3012781/java-syntax-for-explicitly-specifying-generic-arguments-in-method-calls).
There's a definition of functor in the space of category theory that relates to a transformation mapping one category to another, which would generally be some sort of mapping of the values in one category to the values in another category and the operations in one category to operations in the other (obeying a few restrictions). There's a definition of functor in the space of logic that is essentially a function taking a tuple of size n in some domain and returning a value in the result domain. (Ex: an N-ary function \`R f(T\_1, T\_2, ..., T\_n)\` ) 
This article is a bit baffling. I wouldn't recommend it to somebody learning C++. - It uses a non-obvious datatype (std::multiset) for sorting instead of something obvious like std::sort and doesn't explain the choice at all. - It uses a sorted list from min to max and fails to break out of the loop once all further iterations will fail - It uses a language construct (const_cast) of which the most common advice is simply "don't use it" - which seems about right. - The Employee class is not as simple as can be, despite the article's statement. If that was the goal, just write: class Employee { public: bool operator== (const Employee&amp; rhs) const = default; std::string m_name; int m_salary; int m_balance; }; The encapsulation here doesn't serve any purpose. - The lambda is justified by the lack of operator&lt; on Employee, but other approaches (like defining a class EmployeePaycheckRef with a ref to the employee and a operator&lt;) are not discussed The article then goes on the explain that multiset has a const iterator type in addition to a const const_iterator which is fine, but then it delves into a bunch of implementation details, failing to mention that well, they are just that - implementation details, that might vary from one implementation to another. &gt; what if we don’t have the authority to change the whole container? Authority is a very strange word here - I can imagine situations where I would be reluctant to change the type of a container because it would be a lot of work or because the type was chosen for optimizing another part of the code (again, would have been nice if the author motivated the choice of container) - but I don't really code in code-bases where I don't have the authority to make basic decisions. Why am I not equally worried about having the authority to remove the const_cast? - Not sure I agree with the comments in the epilogue that it's weird for an Employee to have operator== but not the other cooperators. Employees are unique, hash-able, but not sort-able, seems to make sense to me. Overall - if you're learning C++ - please read something else, not this.
How not? * It is done exactly that way in C (the fact that they are using a member function is irrelevant). * It is done for a specific data structure (in particular, has a `.length()` member function).
Isn't the first example of WrappingCallback just a hand-written vtable with one slot in a sense?
Your formatting is wrong. it doesn't work on good reddit.
Interesting! I wasn't sure if it would work with python3, did you get it to work?
But also not everyone at the very top uses such stuff (and not only java people) so it's not like you necessarily have to use it. Personally - if writing loops is such a huge hassle I would rather use some text templates for faster typing rather than macro.
You can do it, but I'm talking about how amenable the syntax is. The more recent versions of the standard do make it nicer (C++17 with structured binding, C++20 with the init statements), but it's still not fully there.
Yeah, it's a matter of taste. Though I think substituting loops is just a little part of the templates because sometimes you find complex things made simple like checking (naively) if something is inside a container or a range, something like: `#define isIn( a, b, x ) ((a) &lt;= (x) &amp;&amp; (x) &lt;= (b) )` I made some aliases for the common use of tuples and vector of tuples, and some templated functions and aliases relating data structures (like __gnu_pbds priority queues or trees) and they've come handy some times as well as a wrapper to move through grids with ease, either in 4 or 8 directions because it was always taking a lot of code and with that it's just a simple call to an array of tuples which made it a little easier when I was practising graph problems. But I also have a friend who dislikes templates and does everything without them and it's ok too, and we have similar times and rankings in CodeForces so, as you say, it's just a matter of taste and it's not worth it only for loops or something that simple.
I agree. Somehow I always thought it would make switching back and forth between normal/competitive programming not easy for me, I even abstained from `using namespace std;` which is considered very uncommon for sure :)
When I first started I was stubborn enough to not use anything more than pure C (God it was hard sometimes) and when I met C++ it was just C with classes for me. Little by little I began to study the language and fell in love with it, and I feel kind of bad using `using namespace std` but reading the standard helped me switch with ease between "competitive" and "software engineering" coding styles. Now for some school projects it helps a lot switching from one to another in some cases where you need a quick test or when you need something more robust. It's awesome but at the same time I'm grateful of Internet and seeing how people used a lot of things I wasn't aware of made me realize how little I knew (and still) to the point I was able to follow good programming practices without being told to.
I agree that 17 makes it slightly nicer, but even in 14 the syntax is ok if you are willing to write a struct (this isn't a bad idea anyway because it's easy to mix up structured bindings if you have a struct with several fields and repeated types). I'm not sure though how C++20 init statements help at all?
If it is not a constant reference, it shouldn't even compile or am I mistaken?
Sorry to the author, but I have to say that is imho a shorter and better description of type erasure than the one given in the blog post.
Consider passing `std::integral_constant&lt;std::size_t, Is&gt;{}` instead of `Is` in `do_n_arg`. It permits the index to be treated as a compile time value. So: do_n_arg&lt;7&gt;( [&amp;](auto I){ std::cout &lt;&lt; std::get&lt;I&gt;( some_tuple ) &lt;&lt;"\n"; }); becomes legal.
Locking a mutex then run unaudited code (client-provided) within the lock scares me. 
No, offsetof_base has to be a constant expression, i.e. has to be `constexpr int offsetof_base()`, but a `constexpr` function cannot [as in not allowed] have a static function member variable.
Amazing improvements, kudos! I'm especially eager to try SIMD related changes. BTW Is there a release date for VS 2019 yet? 
I'm not sure how to feel knowing there's a real term for the phenomenon I experienced. :)
[April 2.](https://visualstudio.microsoft.com/vs2019-launch/)
Interesting that you've had such a rough experience with it. I recently switched most of my projects over to Ninja from MSBuild and have seen pretty significant speedups, even for non-incremental builds (though especially for incremental). Very, very happy with it so far.
Yes it is inside other namespaces. Using the 'using namespace' declaration inside a namespace only affects that specific namespace.
But... why? What does that get you in this case aside from an additional indirection?
Hmm it's tempting not to wait. But in the past it wasn't a good idea to install a preview (side-by-side with the older VS).
The new Visual installer since 2017 means you can rather safely install multiple varied copies of Visual side by side. I don't think it'll be a problem here anymore.
In the last 2 years (since shortly after they launched the new installer), I haven't encountered any problems with having two VS installations, including one of them being Preview. They happily co-exist side-by-side, cleanly separated. You get a different set of command-prompts, can choose which one to use with CMake, etc. Works great. With that being said, there was one exception: Unreal Engine, with its horrible build system, just chooses whichever toolset it pleases. But you also run into that trouble if you have a single VS version installed with multiple toolsets. And it's certainly UE4 that's to blame here.
And yet trying learn to implement type erasure from this comment would be futile. It's almost like this commentator and the author are trying to do different things...
So how well does VC++ optimize compared to other compilers and Clang in particular?
A comparison with [LLD](https://lld.llvm.org/windows_support.html) for link times would be great. We have a project that just moved to lld and the difference with VS 2017's linker is drastic: from minutes to less than 30 seconds (sub 10s for small changes). Would also nice to know what they are doing to prevent linker OOM, something that's also big reason why we moved to lld.
import &lt;iostream&gt;; is c++20.
Again, it's not a matter of shortcomings, it's a matter of aesthetics, but maybe it's just a matter of taste (my first experience with these kind of construct was 10 years ago with the yield/block construction in Ruby).
Hi annyeonghello. Sure, feel free to apply even when you're not 100% sure about meeting the criteria. We will still consider and evaluate your application. 
There is a `reinterpret_cast` so that won't work without additional work :).
Like he says. :-) Plus this additional work as far as I can tell is impossible. Which really makes my code a nightmare, for not reason at all.
Apparently enough that [Qt](https://doc.qt.io/qt-5/qlist.html#length) needed to implement it in 4.5
This is the website you are looking for: &amp;#x200B; [https://govnokod.ru/](https://govnokod.ru/)
 This is the website you are looking for: [https://govnokod.ru/](https://govnokod.ru/) ("govno" means "shit" and "kod" is "code" in russian)
I was referring to the part, where the blog author tries to define type erasure.
Especially with /DEBUG:GHASH: http://blog.llvm.org/2018/01/improving-link-time-on-windows-with.html
That would appear to be the whole article... the definition is mixed with code examples that show things that are and aren't type erasure. Type erasure in C++ has a very specific meaning, and the article captures and demonstrates it much better than NotAYakk's comment.
I was laying-out the minimum, what at least needs to change [without looking that was even possible or makes sense]. 
Is the linker still a 32 bit process or are we really talking out of physical memory on dev machines?
32 bit process memory limit likely.
Just need to make sure you use the x64 tools. `setx PreferredToolArchitecture=x64`
I believe that's been fixed.
There is no additional indirection and it gives you far better exception safety. 
That's not true. If you import that namespace in a source file, you also import any `using namespace` from it, which is not good. Furthermore, the header file in this specific example declares functions outside of any namespace.
I have similar experience. I'm too afraid to uninstall VS 2015 from my primary computer, even though I don't need it for anything anymore, because the last time I tried that (on other PC), it broke VS 2017 so bad that I had to reinstall Windows.
All widgets is a rectangle area, if you need display as a circle, just make a transparent background widget and draw a filled circle in it. I think is easiest way to do this. Ps. Or you can using qss to set border-radius to half of value of widget's width, height. e.g. QWidegt { width:10px; height:10px; border-radius:5px; }
Performance, C++'s IO is outperformed by Python IIRC without it.
Yea, and just choosing the latest is not really any better - particularly if you've got a VS Preview version installed.
Qt provides also count(), which IMO is a better name than size() for containers, generally speaking. Because 'size' is more generic.
Let me leave this here for discussion. https://developercommunity.visualstudio.com/content/problem/457819/vs2019-generates-inefficient-code-compared-to-clan.html I have another one about inlining but thats a different issue.
I wonder how they pinned the frequency of the AMD Ryzen CPU to 3.4GHz. &amp;#x200B; I tried two things in [https://cristianadam.eu/20190318/speeding-up-libclang-on-windows/](https://cristianadam.eu/20190318/speeding-up-libclang-on-windows/) 1. Disabling in BIOS the AMD PowerNow! feature 2. Setting in AMD Power Slider the value to "Best performance" &amp;#x200B; This way I could do better future benchmarkings :)
You may find my bug fixed run-clang-tidy.py script useful: https://github.com/ned14/quickcpplib/blob/master/scripts/run-clang-tidy.py. You might integrate it into your cmake as follows: ``` if(DEFINED MAKE_LINT_TARGETS_INCLUDED) return() endif() set(MAKE_LINT_TARGETS_INCLUDED 1) # The compilation database is only generated by these generators if(CMAKE_GENERATOR MATCHES "Ninja|.*Makefiles" AND NOT DISABLE_CLANG_TIDY) set(MAKE_LINT_TARGETS_RUN_CLANG_TIDY_SCRIPT "${CMAKE_CURRENT_SOURCE_DIR}/scripts/run-clang-tidy.py") if(NOT EXISTS "${MAKE_LINT_TARGETS_RUN_CLANG_TIDY_SCRIPT}") message(FATAL_ERROR "FATAL: run-clang-tidy script not found at ${MAKE_LINT_TARGETS_RUN_CLANG_TIDY_SCRIPT}") endif() include(FindPythonInterp) if(NOT PYTHONINTERP_FOUND) message(WARNING "WARNING: Python interpreter not found, lint targets cannot be built!") endif() endif() # Args are: # - clang_tidy_path: Path to the clang-tidy executable to use (find_program) # - target_filter: Regex to say which targets to lint and which to ignore # - header_filter: Regex to say which headers to lint and which to ignore function(make_lint_targets clang_tidy_path target_filter header_filter) if(CMAKE_GENERATOR MATCHES "Ninja|.*Makefiles" AND NOT DISABLE_CLANG_TIDY) # Turn on the generation of the compilation database file(MAKE_DIRECTORY "${CMAKE_BINARY_DIR}/${PROJECT_NAME}_fixes") add_custom_target(${PROJECT_NAME}-lint "${CMAKE_COMMAND}" -E make_directory ${PROJECT_NAME}_fixes COMMAND "${PYTHON_EXECUTABLE}" "${MAKE_LINT_TARGETS_RUN_CLANG_TIDY_SCRIPT}" -clang-tidy-binary="${clang_tidy_path}" -target-filter="${target_filter}" -header-filter="${header_filter}" -export-fixes=${PROJECT_NAME}_fixes/fixes.yaml COMMAND echo clang-tidy fixes have been written to ${PROJECT_NAME}_fixes, use 'clang-apply-replacements ${PROJECT_NAME}_fixes' to apply. COMMENT "Running clang-tidy on ${PROJECT_NAME} ..." ) add_custom_target(${PROJECT_NAME}-lint-fix "${PYTHON_EXECUTABLE}" "${MAKE_LINT_TARGETS_RUN_CLANG_TIDY_SCRIPT}" -clang-tidy-binary="${clang_tidy_path}" -target-filter="${target_filter}" -header-filter="${header_filter}" -fix -format COMMENT "Running clang-tidy -fix -format on ${PROJECT_NAME} ..." ) endif() endfunction() ``` So, to run, do `make PROJECT-lint` and apply the fixes using `clang-apply-replacements` later, or `make PROJECT-lint-fix` to do it all at once. The script runs using all CPU cores for maximum performance. Be aware your machine is fairly unusable while it runs.
I think it specifically avoids previews now unless you ask it to use them.
I know, I never had this problem. I was just wondering what exactly the problem of the previous poster was.
1) Yes I know. But my point is this is C++, so you'd normally use a range-based loop. 2) True.
I've seen these lately. Compiler optimization flags, right? If you're on a compiler that doesn't support them, do they get ignored?
Just two words - Awesome Work.
You should be happy, it means that C++ is evolving!
These are also good articles and talks on this: * Mathieu Ropert + Polymorphic ducks - https://mropert.github.io/2017/11/30/polymorphic_ducks/ + Better polymorphic ducks - https://mropert.github.io/2017/12/17/better_polymorphic_ducks/ + Follow-up to 'Better polymorphic ducks' - https://mropert.github.io/2017/12/23/undefined_ducks/ * On the Tension Between Object-Oriented and Generic Programming in C++ and What Type Erasure Can Do About It + Thomas Becker, C++ Source - October 15, 2007 + https://www.artima.com/cppsource/type_erasure.html * Practical Type Erasure + CppCon 2014; Cheinan Marks + https://www.youtube.com/watch?v=5PZVuUzP34g * Sean Parent + Small Object Optimization for Polymorphic Types - http://stlab.cc/tips/small-object-optimizations.html * Tales of C++, Episode Nine: Erasing the Concrete - http://talesofcpp.fusionfenix.com/post-16/episode-nine-erasing-the-concrete * Type erasure - Andrzej's C++ blog + https://akrzemi1.wordpress.com/2013/11/18/type-erasure-part-i/ + https://akrzemi1.wordpress.com/2013/12/06/type-erasure-part-ii/ + https://akrzemi1.wordpress.com/2013/12/11/type-erasure-part-iii/ + https://akrzemi1.wordpress.com/2014/01/13/type-erasure-part-iv/ * Type erasure in C++, and some details + Gothenburg C++ Meetup 2018; Harald Achitz + https://www.youtube.com/watch?v=9X9JzSO00oY 
Are you sure you're not supposed to write it in C? Calls to pthread are unnecessary in C++ now.
It reduces the amount of time required to implement the solution once you've found it, first by reducing the actual amount of typing and second by eliminating a lot of decision points about e.g. how to name your variables or how to structure the code. These many little time saves add up, and if you can implement the solution for an easy task in say 5 instead of 10 minutes, you have more time to spend analysing the harder tasks.
https://thecppzoo.blogspot.com/2016/10/constexpr-offsetof-practical-way-to.html this is a dumb way that works (apparently) https://en.cppreference.com/w/cpp/types/offsetof Note: &gt;offsetof cannot be implemented in standard C++ and requires compiler support: GCC, LLVM AKA you really can't do that, and just use a compiler that supports it. All c++ compilers that are recent support it. Including the ones that are really "out there" and no one uses, except for those not updated (e.g. Digital Mars C++)
Last week u/TemplateRex lamented that (unlike LLVM) there are no nightly builds of GCC usable in Travis CI etc. &amp;#x200B; So I made some. &amp;#x200B; Feedback welcome (here, or in github).
This probably does not belong in /r/cpp? Maybe ask in /r/androiddev
I bet that they’re using 32bit but I can’t say for certain. I’ve certainly only ever seen OOM with 32bit linker. x64 should really be the default in this day and age for everything but a lot of things still choose x86.
I put the blame on Microsoft and particularly the msvc team. No one says, they should suddenly drop x86 support, but at least the defaults should have changed long ago. Instead, vcpkg decided to go down the same route. And why they still ship a 32 bit version of Win10 desktop is anyone's guess.
Make your program never end without using any loop. 
&gt; Finding the min and max of 2 numbers without using any loop or condition. How 'bout find the average of two `int`s? The easiest way to do that is to cast to a larger int size, so then the extension is to average two `int64_t`s on a system with no `int128_t`.
I am with you on the sentiment but I feel like the msvc team may not have had as much say about defaults and the like until the last few years. VS in general has been loathe to make major changes to defaults in my experience. vcpkg being 32bit feels like confirmation bias (or whatever is the appropriate logical fallacy) where they have data saying 32bit is used more often but that’s because the default was 32bit. 
Do gotos count as loops?
&gt;• Finding the min and max of 2 numbers without using any loop or condition. You could extend this to any set of numbers of which the size is known at compile-time.
Yup
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
This fails to compile on both GCC and MSVC.
&gt; The CI service now includes [lots of cool new compilers] Nice! &gt; Now the build/*.build and buildfile filesystem entries in a project can alternatively (but consistently) be called build2/*.build2 and build2file. This is really good. &gt; The project dependency manager's bdep-new(1) command now supports the --subdirectory mode that can be used to create a new source subdirectory, normally an executable or a library, in an already existing project. Another great new. &gt; Another improvement to the new command is support for more granular C++ source file extension specification. Dammit, you really want to make build2 nice and easy to use :)))
You could use a text editor, normally IDEs have features to help you write code more efficiently it’s about finding an environment that helps you go faster with out getting in your way too much. It might be worth checking out visual studio code with plugins, I don’t like a lot of the ways MS “helps out” but vs code is pretty minimal. I normally use vim and Ive also heard good things about clion(free for students and open source contributors I believe). None of these are android specific but there are probably plenty android tools for all of these platforms.
Well, with vcpkg at least, they explicitly wanted to align the defaults with the defaults in VS, which kind of makes sense, but imho they're just digging deeper into the hole from which they eventually have to crawl out anyway. 
write a fully working application, whith just an empty ```int main() { return 0; }```
It's their code. It's no different from them locking a mutex and running the loop. And they can of course lock it from the outside if they want using a lock janitor to lock it on scoped basis. And that's not uncommon. But if they just needed to, say, search to see if some element was present or to update an element or something, it's convenient. &amp;#x200B;
32 bit often performs better for applications that don't need more than 2GB of RAM because pointers are half the size.
I was thinking about mutexes ^^
I appreciate you've put some work into this, but you solved the "problem" of having to declare the enum outside the function, and in exchange all the call sites look like we're passing string literals, in some cases apparently only triggering errors at runtime where before they would have been at compile time? I feel like the cure is substantially worse than the disease. While sometimes giving the enum a name can be annoying, in most cases I find a way to give the enum class a name so that readability at the call site is improved. All your examples are with foo and bar so I can't use one of your examples, but usually I find something reasonable (it could just be a CamelCase version of whatever you named the argument itself, which presumably is a good name as well). I'm not yet sure whether I think it is more cool, or more frightening, that this can be done in C++20 (without a single macro). On the one hand, we can solve more problems in better ways. On the other hand, people are going to abuse this and really over-complicate things. 
Thanks! And, yes, pleasant to use is definitely the goal.
Every major compiler has support for offsetof as a constexpr. But that can't be use to determine a particular offset from a base class which is what I am looking for, specially a constexpr.
You could do [this](https://i.imgur.com/1hdpYb6.png). Set minimum processor state to 100%, maximum processor state to 100%, and then disable core performance boost. That'll avoid transitioning between any other P-states. It's possible that "Processor performance boost mode" will be hidden in the Power Options panel, and you'll have to enable it in the registry: Windows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Power\PowerSettings\54533251-82be-4824-96c1-47b60b740d00\be337238-0d82-4146-a960-4f3749d470c7] "Attributes"=dword:00000002
Implement an authentication system without security vulnerabilities.
Yeah, I tried that, but as I'd like to automate, it doesn't work with the use-override rules. &amp;#x200B;
Thanks for the link! I wasn't aware that ninja can create such nice trace logs.
Awesome! One of the issues I had with the run-... script was that I could not exclude targets without work, your script fixes that :) I shall test it later. Thanks!
External locking is also scary. Lock based concurrency does not compose. All code using it has to be checked *as a whole* for deadlocks and other incorrectness. When the locking code is local and bounded and final, correctness is plausible to assert. When it is *open to extension* correctness is impossible to assert. It is convenient to permit arbitrary code to be injected into a lock, but if you do so your code will have deadlocks and other concurrency errors with near 100% certainty over time. 
A `int main() { return 0; }` is a fully working application :P On a serious note, I assume this would require either executing all of your application's code within the constructor of a global object, or setting the entry point of the application to something else that then calls main?
Small tip: instead of rolling your own *static\_strcmp*, you can use std::char\_traits::compare/length/... They are constexpr since C++17 &amp;#x200B;
Your point about runtime errors is a good one, and quite an annoying one at that since in many cases the compiler has (in theory at least) all the information it needs to be able to catch them statically. I probably should emphasise that the main use case I'm advocating for is to replace bool parameters in function signatures, rather than existing places where enums are already used. i.e. replacing `f(true, false)` with `f("Cheese", "Vegan")`, but you might counter than `f(Dairy::Cheese, Diet::Vegan)` is better than both, and you'd be right, but it does mean substantially more boilerplate, and exposing types in places where it doesn't make sense for them to be available. I guess another way to solve the bool problem would be to create a "NamedBool" type that enforces naming its purpose at the call site, ala Obj-C messaging (`[object useCheese:true andVeganDiet:false]`). I think it should be possible to do something like `f(NamedBool&lt;{"useCheese"}&gt;::True, NamedBool&lt;{"andVeganDiet"}&gt;::False)`. That is quite verbose, but I suppose that's the point really. Anyway, I'm getting off track. Really I'm just playing with C++20 features and thought this was more cool rather than frightening :). I am quite pleased with StringPack as a thing, and I guess it's conceivably useful in other template non-type parameter contexts.
Nice!
We have a test that verifies that clang-format doesn't recommend changes and then people can voluntarily set up a git hook to do it on commit (a script for that is provided). 
There's a legacy component in my codebase that does this on purpose. It "works" because the objects are internally refcounted and the way they use our smart pointer type ends up freeing stuff at the correct time, but it's tremendously fragile.
I'm hearing that over and over, but I haven't seen any real-world benchmarks that would really show a significant impact (more than let's say 10%-15% difference). Maybe that is because most performance critical code I've seen doesn't use pointer-heavy datastructures to begin with, maybe the x86 exception handling mechanism has too much overhead and maybe some projects didn't activate SSE when compiling for x86. I don't know why I mean, have you folks actually tried to compile e.g. Visual Studio in 64 bit mode and decided that it runs too slow? But this is not about which is faster, it is about having less heterogeneity in the c++ eco system. x86 should be the exception, when you have very specific needs, not the rule (and yes if windows had a m32-like abi I would complain much less, although there are a lot of other advantages in having 64 bit address space).
Could you elaborate please? Or you mean its const char[3] which decays to const char * ?
I have never heard that usage before, and I've worked with multiple languages that support type inference. Conversely, I *have* heard it applied in the context of Java, the usage of which is accurately described in the article.
 constexpr bool static_strcmp(char const* a, char const* b) { - return (*a != 0 &amp;&amp; *b != 0) ? - (*a == *b &amp;&amp; static_strcmp(a + 1, b + 1)) : // NOLINT - (*a == 0 &amp;&amp; *b == 0); + return std::char_traits&lt;char&gt;::length(a) == std::char_traits&lt;char&gt;::length(b) &amp;&amp; + std::char_traits&lt;char&gt;::compare(a, b, std::char_traits&lt;char&gt;::length(a)) == 0; } It's a shame there isn't a version of compare that doesn't need a count parameter though. Granted this is a readability improvement in the implementation, but I can't just get rid of static\_strcmp altogether, as far as I can see.
The most reliable way is to do this using an "overclocking" approach, although in this case it's mostly downclocking. You can use either Ryzen Master, or what I did here for the testing- force the CPU frequency and voltage in BIOS, most motherboards have these options. And also make sure you have "High performance" selected in Windows power options. But in general, unless you really want stable results for benchmarking, let the CPU scale frequency freely, new CPUs like this Ryzen automatically clock between 3.7Ghz when all cores are used to 4.2Ghz when only 1-2 are used.
It's `const char[4)`
I think it's name is Attributes It can be compiler optimizations like [[gnu:inline]] (which msvc ignores). But this one gives you a warning if you dont use the return of a function marked as nodiscard.
I'm going to look at this, it certainly made me curious seeing such a big difference. In most applications there's usually plus/minus a few percent difference at most, there is no "best compiler" for everything, depends on a case by case basis.
32 bit can perform better sometimes, but I advise to use x64 as a default for everything unless some benchmark proves that your app is faster in 32 bit mode. The x64 code generator is overall better at optimizing, register allocation, lowering of intrinsics, plus most optimizations efforts are tested internally mostly on x64, including performance tests such as SPEC, Geekbench and others. Combine with /LTCG to get much better inlining behavior and some extra optimizations.
Interestingly, &lt;charconv&gt; shows a significant impact in x64's favor - x64 is 1.79x, 2.30x, 3.59x, and 2.75x faster than x86 in the cases I'm looking at. (This is triggered by the wide multiplications that Ryu needs; x64's umul128 instruction really helps.)
Have you tried [BOLT](https://github.com/facebookincubator/BOLT)?
I've head of it, but never use it. I will give it try someday. Thank you for the heads-up!
[http://plplot.sourceforge.net/](http://plplot.sourceforge.net/) &amp;#x200B;
Sadly this has the same issues in the end, where multiple fixes collide :( I've made a small fix to the target-filter regex ( [https://pastebin.com/B7UBi7rB](https://pastebin.com/B7UBi7rB) ). Now you can add multiple targets at once like so: `-target-filter "first|second|third"`
That's hardly the case. It takes two lockable things to create a deadlock, right? If a class has a thread safe collection, and that's the only lockable thing in the class, and it is the one that is doing the locking internally, then there's zero chance of a deadlock. Or there's no more chance of a deadlock than in any other use of synchronization mechanisms. Or, if it does have other things that need sync but it uses the collection's mutex to do that as well, which I commonly do. It's not like any coherent code just randomly creates thread safe collections without being as safe with them as they are with any other locking scheme. 
You surprise me. As you'll see in the bug fix bottom of https://github.com/ned14/quickcpplib/commit/7f3df03d2e927815fffbf74b6dd69cd660f32b0a#diff-39deac21a9332154efbe334dc0c1d660, it eliminates duplicate fixes.
 Hi, My name is Brian Zhang. I am an experienced C++ developer with over 12 years professional experience. I live in the Greater Toronto Area in Canada. I have a full time job and I want to use my spare time to do some freelancer work. My main interest is in server side programming, especially interfacing with databases. I have experience in MFC and Qt4 as well. I am familiar with C++11. I am also good at implementing numerical algorithms because I have a Master's Degree in Electrical Engineering specializing in Control Theory and DSP and I developed programs for Geophysics Applications for eight years. I am open to part time opportunities either in GTA locally or remote ones that need online collaboration. Please feel free to message me here if you are interested in my service.
`template &lt;class IntType&gt;` `IntType average(IntType a, IntType b)` `{` `return (a &gt;&gt; 1) + (b &gt;&gt; 1) + (a &amp; b &amp; 1);` `}` &amp;#x200B;
Recursive function?
\&gt; Dividing an integer by 4 without using the '/' operator. That's not tricky at all. `x&gt;&gt;2`
&gt;more than let's say 10%-15% difference 10-15% difference in real-world program-wide benchmarks is *huge*.
It will end prematurely with a stack overflow error.
Are you certain the mutex doesn't have a loop in the implementation? Or does that just not count as using a loop because it's buried?
That looks very similar (or maybe even originates) from code I wrote starting almost 20 years ago: [https://github.com/inexorgame/sauerbraten/blob/master/src/shared/tools.h#L103-L112](https://github.com/inexorgame/sauerbraten/blob/master/src/shared/tools.h#L103-L112) I have since removed them :)
http://www.keil.com/support/man/docs/armcc/armcc_chr1359124255545.htm otherwise AFAIK... well... you're out of luck
Depends on the kind of program. If autocomplete is 10% faster or a website opens 10% faster I won't notice. 10% compilation speed or scientific number crunching would indeed be a lot, but in such applications 64 will most likely improve performance, not degrade it. What I do definitely notice though is if VS runs out of memory.
llvm/clang codebase is not bad https://github.com/llvm-mirror/clang
It's been too long since I have looked into the various possibilities so I forget if I had one that I like better, but I think that *may* be my favorite. Nevertheless, it still has a caveat -- `a &gt;&gt; 1` has an implementation defined result for negative `a`. (That appears true even in the C++20 draft.) That's relying on it sign extending. I think the most *satisfying* answer is `a/2 + (a%2 + b%2)/2 + b/2`, but optimizers aren't good enough. :-) 
That is pretty much my experience too (although I'm talking more about application level performance (like how fast can you parse json). If there is a big difference, it is usually in favor of x64 due to the new vector instructions and generally bigger registers. Have you checked what happens if you activate arch:avx2 for x86? Or is that hand-optimized assembler?
[Catmother](http://catmother.sourceforge.net/) is some of the cleanest C++ code you can find on the internet.
[About that](https://gcc.godbolt.org/z/zchjiL)
[fmtlib](https://github.com/fmtlib/fmt) [google benchmark](https://github.com/google/benchmark) [Catch2](https://github.com/catchorg/Catch2)
There's also [this variant](https://gcc.godbolt.org/z/-uqzVM) if you go back to the original "run forever" requirement and don't count recursion as a loop.
[github ](https://github.com/google/sandboxed-api) direct link
Looks like you don't even follow your own conventions, the majority of your methods are in pascal case but then there is \`app\_-&gt;set\_window\`, and I hate the Qt-esque API with everything allocated on the heap: \`platform.set\_gpu\_driver(new GPUDriverD3D(new D3DRenderer()));\`.
Cool! What other language bindings are you working on? And when do you expect to have them ready?
Fair enough. I could replace "&gt;&gt; 1" by "/2" and it would then not rely on bit shifting.
That'd require a different "fixup" than `(a &amp; b &amp; 1)` though. `-3/2` gives -1 as a result, so averaging -3 and -3 with `a/2 + b/2 + (a &amp; b &amp; 1)` would give `-1 + -1 + 1`, which is -1. Part of why I say that the last thing is the most satisfying is it not only works now but it's also guaranteed (I think...) to work on older revisions of C and C++ that didn't entirely guarantee what negative division and modulus results were. For example, in C++98, `-3/2` could be either -1 or -2, but then `%` had to be consistent with it -- so: * If `-3/2` evaluated to -1, then `-3%2` had to (per the standard) evaluate to -1. So then, averaging two negative odd values would result in a middle term of (-1 + -1)/2 = -1. * If `-3/2` evaluated to -2, then `-3%2` had to evaluate to 1. Then, averaging -3 and -3 would result in -2 + (1 + 1)/2 + -2, which works. The standard now guarantees the first result, but that means that the fixup needs to change sign as appropriate. (Lots of little subtleties, which is why I think this is actually kind of a neat problem! For example, I originally typed `a/2 + b/2 + (a%2 + b%2)/2`, but I *think* that is *not* actually guaranteed correct! Not until C++20 guarantees 2's complement.)
This is a nice resource!
Actually on a closer reading, I think I'm going to go back and disagree with myself that fancy pointers don't necessarily need to be default constructible. From \[allocator.requirements\]: &gt;The `X::pointer`, `X::const_pointer`, `X::void_pointer`, and `X::const_void_pointer` types shall satisfy the requirements of NullablePointer (20.5.3.3). And according to \[nullablepointer.requirements\] in order to satisfy NullablePointer, a type must satisfy DefaultConstructible. Am I misinterpreting this?
You're right. I've misremembered the details then.
How do you print output without using a semicolon?
Any plans to change buildfile syntax before hitting stable?
If I'm interested in picking up where you left off working on that patch, should I send you an email?
Yes please.
What's the use case? Does it have to be interactive? Do you just need to plot some points or a curve?
What problem were you trying to solve?
Not nightly, and not entirely what people mean by binary packages, but Conan guys have [Docker images with a lot of compilers](https://github.com/conan-io/conan-docker-tools?files=1) that are used to automate package building on Travis.
Holy guacamole! 
I loved reading through https://github.com/scylladb/seastar and https://github.com/scylladb/scylla. Some great async code in those as well.
I'm just tripping this is going to be possible now. I've implemented similar constructs in C++11-14 and they were much more difficult. You had to recursively build what you pass in as a template parameter directly. Great possibilities.
yet another seccomp wrapper?
Thanks Jonathan, this is really awesome. The 3/17 build already had a bug fixed compared to the 3/10 build that generated an ICE on one of my repos. I would have reported that otherwise (since it was a regression w.r.t. gcc-8).
&gt; character encodings Like with everything, if we ignore the mentally handicapped child that is Microsoft Windows, we’re pretty much on par that it’s Unicode and usually, if not specified otherwise, UTF-8 that is used for encoding.
It seems like some duplicates are fixed, but I still get: \`\`\` #include &lt;utility&gt; #include &lt;utility&gt;\`\`\` for instance, or: \`\`\` autooldView = (NSView \*)oldViewObject;\`\`\` Sometimes the random \`\`\`}\`\`\` dissappears and so on. &amp;#x200B; In my opinion this is not fixable aside from limiting it to a single thread and fixing immediately after each file :( I'll work on a script tomorrow thats going to re-run clang-tidy, if fixes were found in between to hopefully get full multi core performance if nothing has changed, and no issues if something did.
Feel free to make your own from svn if the weekly snapshot is too stale for you, but given that there are no GCC trunk images at the link you gave, what are you complaining about?
&gt;Enspects/Exsures
No significant change (for either x86 or x64); Ryu doesn't contain loops that are amenable to autovectorization. There's no asm, just direct use of x64 intrinsics when available. There may be opportunities to use handcrafted SSE* or AVX* intrinsics, but I haven't tried to do so yet.
Shameless self-plug: [https://github.com/nlohmann/json](https://github.com/nlohmann/json)
I do not complain. I note that if someone is interested in a variety of different compilers with Travis, there is one more option.
My lamenting will stop now, all my wishes from 2 years ago are fulfilled: https://www.reddit.com/r/cpp/comments/5sxrun/what_are_some_examples_of_new_modern_c_projects/ddjlney/ All my Travis/AppVeyor C++ projects can now test gcc-7/8/trunk, clang-6/7/8/trunk (libstdc++ and libc++) and VS2017 (soon 2019), all with the latest Boost. 
I'd still appreciate it if you'd remove the build2 dependency that build2 has for building.
Just to hop in here, where did you find instructions on setting up std lib 20 on Microsoft visual studio 2019? Are there any that anyone can point too?
Isn't gcc's official docker image enough though? https://hub.docker.com/_/gcc
I found bsnes (now called higan) to be very beautiful. Haven't taken a look in a while though.
Yes if there is only one blocking operation within all of the scope of all of the code that locks the mutex you are safe. Which is exactly why the code that locks the mutex or has it locked should be a closed set of code. Because then you can ensure some hope of correctness. Once that set of code is an extendible one, every time new code is added you have to prove again that the code has no threading errors. Better to keep the code that is under the lock bounded. Then you can be convinced it is correct. Only in extreme situations should you be invoking callbacks while the lock is held, as that commits you to either repeating all thread/lock safety whenever that method is used or the callback modified, or leaves you open to threading bugs. Threading bugs are expensive to find and fix and generally lead to complete program failure. It takes a really good excuse to say "fuck it, we can afford expensive hugs here for the next 10 years everytime someone makes a mistake with this API." Now, static rarely changing code, small code bases, or short term projects change the calculus. As do method names like `DangerousMutexLockingOperation` to a lesser degree. 
UTF-16 is good enough for anybody
I think that's Docker's official GCC image, not the other way around. And as you realised, that's not GCC trunk.
Again, you are making it into more than it is. If I have a class that has a collection and operations on that collection need to be atomic, then one way or another I have to lock around operations on that collection. If the particular operation is that I need to iterate the collection and do something, then there's two ways to do that, I can lock outside the collection, and do the loop. Or, in my case, I can just ask it to call a lambda back that will do whatever it is want to do. One of these things must be done, and they are both completely equivalent in this case, but the callback is actually safer because the collection is fundamental and well tested code. So it's not like this is some kind of cowboy move. The class that contains the collection as a member is a closed environment. It knows what the locking requirements are for it's own members. This is no different than a class that has to sync any other of its members. As I said, in some cases if the collection itself must be atomic, but there are a couple other things here and there that the class has to protect, it will typically use the collection's mutex for that as well, so there's still only one lockable thing involved. Beyond that it will typically just create a separate mutex to use for sync of the collection(s) and anything else in the class. But, one place where the lockable collections are always used is in queues, because they are inherently used for multi-threaded scenarios where threads are putting stuff into the queue and getting them out (with the ability to block for a given length of time for something to show up. That always need to be lockable, because the queue has to manage a wait list and signal waiting threads and all that. Of course there wouldn't be likely to be any scenario where you need to iterate that queue, though for debugging you might use that to dump the contents or something. In that case, the locked callback would insure that the contents can't change while iterating the queue. I have a million lines of code in my code base and only once can I remember having a deadlock scenario and it was nothing related to this issue, it was something far more obscure and indirect. 
Ah sorry, I thought you were pointing out *my* packages are not nightly (which is true) rather than pointing to some other also-not-nightly images. Sorry for the misunderstanding. I think Travis already supports a variety of GCC releases out of the box, but not as many versions as are available from Conan. https://docs.travis-ci.com/user/languages/cpp/#c11c11-and-beyond-and-toolchain-versioning
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b2vruo/android_ide_without_training_wheels/eiwzj0m/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It has the main drawback of UTF-8: it is a variable length encoding. It does not have the main advantage of UTF-8: it is compatible with ASCII. It's a clear cut case of bad compromise.
It says its aiming for most of HTML5, but I can't find where support currently is.
This looks..... awesome. Do you have any performance numbers?
Yet UTF-8 is a mechanism to maintain Anglo-centric dominance of CS.
I believe nanogui can do what qt-charts can do: https://github.com/wjakob/nanogui
Where else could it be allocated? You need to give it to the platform thingie to use, so it can't be on the stack. If you mean put it in a pointer wrapper it's still allocated on the heap. &amp;#x200B;
By using cout as the condition for a if statement.
Did you mean to put some punctuation in your title?
How so?
Getters and setters are `snake_case`, everything else is `PascalCase`. Not my cup of tea personally, but just because you didn't recognize the convention, doesn't mean it isn't one. Also, way to demonstrate your fundamental lack of knowledge of basic c++ concepts. Next time just say nothing.
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0811r3.html#integers
A lot of people seem to dislike the greatest feature of contracts: That compilers are allowed to optimize based on them if they are disabled. Some go as far as wanting to remove that ability. Personally I think that notion is terrifying because it would almost put the feature back to plain old `assert`. Math-Constants are coming, except that [τ](https://tauday.com/tau-manifesto)(τ = 2π) is missing. Now I know that a lot of people will say that its pointless because it can be trivially defined relative to pi, which I find very unconvincing in the face of several of the proposed constants that are FAR less useful, among them pi/2, pi/4 several logarithms (→`std::log`) and roots (→`std::sqrt`). There is of course to be debated whether `tau`would be the best name, but given that `2_pi` is both practically impossible and wouldn't conform with the naming-scheme as well as that tau is somewhat established and for example used in python makes it a pretty clear case in my opinion. To quote the `std::exchange`-paper: “The benefit isn't huge, but neither is the specification-cost”. [`polymorphic_value`](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0201r5.html) looks quite nice and useful. The [bit operations](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0201r5.html)-paper looks nice for someone who is into cryptography and is annoyed by having to define `lrot` all the time. 
I honestly don't really see the point of replacing `Expects` and `Ensures`: In my opinion they are pretty clear and intuitive and to extend on the quote from Feyman's book: I am one of those non-native speakers and I still think it's fine.
Somehow I just can't get past them capitalizing the names of variables. Otherwise yes it's great code.
It sounds like you could just write it yourself, but take a look at eigen.
You can turn those runtime errors into compile errors by wrapping the strings in lambdas that return them and forcing them to be evaluated in a constexpr context: [https://godbolt.org/z/NGsghx](https://godbolt.org/z/NGsghx)
English characters get the coveted single-byte characters while especially eastern languages have to settle for 3 or 4.
Windows is great; The religious dedication to backwards compatibility is less than great.
I agree that optimise based on disabled contracts is a good thing (and frankly, if you care so much about it just give your compiler vendor a call and tell them to add an option to disable the behavior, it's not like the standard mandates anything about optimisation), but even if they didn't do it it's not like there's no benefit to having a unified way to specify function pre and postconditions.
If you make this into a socio-political (possibly racial) issue, nobody will take you seriously. Serious programmer is thinking "how can i make this efficient and conformant with standards?", not "How can i make this about me?".
\&gt; fmtlib Particularly after removing this workaround (extreme portability is a PITA): namespace std { // Standard permits specialization of std::numeric_limits. This specialization // is used to resolve ambiguity between isinf and std::isinf in glibc: // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=48891 // and the same for isnan. template &lt;&gt; class numeric_limits&lt;fmt::internal::dummy_int&gt; : public std::numeric_limits&lt;int&gt; { public: // Portable version of isinf. template &lt;typename T&gt; static bool isinfinity(T x) { using namespace fmt::internal; // The resolution "priority" is: // isinf macro &gt; std::isinf &gt; ::isinf &gt; fmt::internal::isinf if (const_check(sizeof(isinf(x)) != sizeof(fmt::internal::dummy_int))) return isinf(x) != 0; return !_finite(static_cast&lt;double&gt;(x)); } // Portable version of isnan. template &lt;typename T&gt; static bool isnotanumber(T x) { using namespace fmt::internal; if (const_check(sizeof(isnan(x)) != sizeof(fmt::internal::dummy_int))) return isnan(x) != 0; return _isnan(static_cast&lt;double&gt;(x)) != 0; } }; } // namespace std &amp;#x200B;
It will compile, because there is one branch that results in defined behaviour. The compiler is allowed to remove the branch entirely and say the other can't happen because it would be UB. A good compiler will give you warnings for this.
I highly doubt that considering how Python is slow at everything.
I propose `two_pi` and `co_pi` (because two pi together makes two pi).
&gt;Written by the author of Awesomium [insert chain of red flag emojis] It'll be a miracle if this sees any kind of long term support
Can't agree more. 
Thank you for this package.
Those Eastern languages (China) in one character (3 or 4 byte) describe an entire word. While Russian and Greeks uses 2 bytes characters exclusively. In any case, who cares. Text is not what take space. Forget about text size! Compression algorithm (like arithmetic coding or Huffman trees) will compress all that to the same size, up to a few bits, trivially. It's a non issue.
I've been [working on this](https://github.com/Ebenezer-group/onwards) for years: Believe it or not the naming has gotten a little more consistent over the last year. Some may try to bash me for the terse format. Joaquin M López Muñoz may have inspired me in that. There's a library and some executables: [https://github.com/Ebenezer-group/onwards/blob/master/src/cmw/tiers/genz.cc](https://github.com/Ebenezer-group/onwards/blob/master/src/cmw/tiers/genz.cc) [https://github.com/Ebenezer-group/onwards/blob/master/src/cmw/tiers/cmwA.cc](https://github.com/Ebenezer-group/onwards/blob/master/src/cmw/tiers/cmwA.cc) . The first program above is a command line program that sends a request to the second program. The second program is a UDP server and it holds a TCP connection with a third program that is closed source. 
&gt; What I do definitely notice though is if VS runs out of memory. That seems like a problem with VS, the IDE, itself, not a problem with the defaults it uses.
Just started using your library! Happy with it so far! I'm using it in conjunction with Clang to serialize the AST.
P1614 is amazing. I imagine all the hidden friends will bring a substantial improvement in compile times. It seems so ambitious though. Can it really make C++20?
SoA?
&gt; 2019 &gt; Not using `BOOST_OPEN_CURLY_BRACKET` and `BOOST_CLOSE_CURLY_BRACKET` for portability
How did a symbol that looks like pi cut in half come to mean two pi?
p1441r1 is quite alarming: It basically means that module doesn't scale with DAG dependencies. The CPU graph shows that there is 0 parallelism in modules based builds while the non-module variant didn't suffer from this problem. Though the compiler used didn't implement the latest Modules features, the fundamental issues remain. Fix possible?
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b34yf9/a_simple_library_to_solve_a_system_of_nonlinear/eixfe90/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I did yeah! I liked the course I did. Have you checked on there recently?
It would have been more clear for sure. 
Thanks that interesting. But I need it a compilation time. I know the language and compilers don't have. I am trying to bring the issue some attention to help us all.
Quite similar to RHEL afaik. The issue was with built binaries. 
Just curious why not qt charts? We are considering adopting it. 
Such a great library!
The choice of τ for `2π` was popularized originally in [the Tau Manifesto](https://tauday.com/tau-manifesto), I believe; that document outlines some prior art of the use of τ along with the author's reasoning for proposing that particular symbol (see section 4.1 and thereabouts).
In my experience, reasonably but not as well as GCC and Clang. For many questions of the form "is X optimized by the compiler?", the answer is often yes for GCC and Clang and no for MSVC. This includes heap allocation elision, auto-vectorization patterns, intrinsics support, converting common idioms to optimized forms, skipping unnecessary null checks, optimizing library calls with constants, etc. This hurts the most in programs that have highly concentrated performance hotspots. It also lags behind in useful extensions such as `__builtin_constant_p()` and x64 inline assembly. OTOH, this also makes MSVC fairly predictable, such that if you do something slightly naughty like type punning it is more likely to do something reasonable rather than the optimizer coming to a crazy conclusion and removing half your code. 
Doesn't gcc have compiler farms?
I do not find it concerning mainly because of the problem space it's focusing on. The extremes do no represent real projects. As it says in the paper, when you have 128 dag depth and 150 tasks, you end up with a mostly linear dependency chain, so you can only do one thing at a time anyway and then you pay for the overhead of generating modules without any reuse benefits. This paper also doesn't look at the incremental build time. If you modify something near the leafs of the dependency chain the header build will need to do a full rebuild of any source which depends on it, but a modular build only needs to rebuild up to that module. The other difference that isn't really dug into is that the modular build uses drastically less resource, and so the rest of the machine is free for other things. Regardless of the above, there's nothing in the spec that you could change that would "fix" this problem. First, it is a valid implementation to not actually build module BMIs; thus ending up with the same performance characteristics as a header build. Second, it is a fundamental property of any modules system that allows reuse of module artifacts that there are dependencies between modules, and you can only stretch a graph so wide and compress it so short.
Easily the best json library. Thanks for the effort. I know doing it is significant. &amp;#x200B;
&gt; or a website opens 10% faster I won't notice You might be surprised how important that 10% is to users. Marissa Mayer talked about a test they ran at Google where they increased the number of results / page to 30 (after users asked for it), which took the page load time from .4 to .9 seconds. The 1/2 second difference correlated with a 20% drop in traffic. I can't find the number at the moment, but Amazon found a similarly surprising stat about conversions when A/B testing a 100ms delay to page loads.
There was [a very long thread](http://lists.llvm.org/pipermail/llvm-dev/2019-February/130083.html) on the llvm-dev list last month about changing that naming rule. The author is taking all of the feedback from that thread [and writing up a proposal and transition plan](https://reviews.llvm.org/D59251).
Safe topic choice. For a second there I thought this was going to be on modules. There's a dumpster fire.
Dude, I love Windows. I only use Linux if necessary. But try to open a UTF-8 encoded CSV on Windows and report back. Spoiler: It’s not great.
It's not ruled out but a change like this will need to be well motivated. And nobody proposed anything concrete yet. I've also asked on the [`#build2`](https://cpplang.slack.com/app_redirect?channel=build2) slack channel about this. Overall, the sentiment from those who've used `build2` in non-toy projects is that the syntax is fine though some names (such as variables and target types) are a bit cryptic (and which, BTW, are a lot easier to change than syntax). I do realize there is an inherent survivorship bias in this, though. If anyone wants to take a stab at a new syntax and/or names, I think it will be a good idea to use some real-world `buildfile` for the before/after (aka Tony's tables) comparison. For example, one [from `libmysqlclient`](https://git.build2.org/cgit/packaging/mysql/libmysqlclient/tree/mysql/buildfile). Again, I am not dismissing the need for a good first impression on a "Hello, World" example. I think a new person joining a team and being able to more or less understand what's going on in `buildfiles` is a valid concern. But, on the other hand, we have real world projects and if the new syntax/names make their `buildfiles` less managable, I don't think that's a win either.
Structure of Arrays. A typical example, instead of having a `struct Particle { float2 pos; float2 vel; };` and then an array of `Particle`s, you'd have a `struct ParticleSystem { float2 *pos; float2 *vel };` (or any other container. (In both cases `struct float2 { float x, y};`). Better approach for HPC.
LLVM source is really clean, it's large, but takes all of 10-15m to find your way around because things are logically laid out and named correctly.
I think your remark is with tongue in cheek, but in case it's serious (and for others who think it is), `build2` can bootstrap itself using GNU `make` or with shell script/batch files. So all you really need is a C++ compiler and there are nice [install script/batch files](https://build2.org/install.xhtml) that automate the whole thing. If, however, you already have the previous version of the toolchain, then you can easily upgrade via the `build2` package manager (or using the install script's `--upgrade` option for the automated experience). 
&gt; 0 comments &gt; 0 spaces Yeah, no.
SUSE does the same here - all GCC versions are perfectly ABI compatible.
Last time I tried, it had a dependency on a library that only could be built with build2 - I instead had to use a script that set up a tiny build environment, and I *really* didn't like that.
Can this be targeted for 32-bit systems and if so are integers still 64-bit?
I don't think I follow what exactly the problem is/was. If you could try the latest version and describe how to reproduce the issue (probably best not in this thread though; slack, github, mailing lists, and PM will all work), I would be happy to take a look. Thanks!
 template &lt;…, class NumberIntegerType = std::int64_t, class NumberUnsignedType = std::uint64_t, …&gt; https://github.com/nlohmann/json/blob/8d6c033f80461123cbfba5e7a3027a9c35ea2eef/include/nlohmann/json_fwd.hpp#L32 You can override the defaults, of course, but by default 64bit integers are used for all platforms.
Just switched from jsoncpp to this, won't be going back.
Ah and `co_pi` is obviously short for "couple o' pi's"! /s
That too, but I was mostly thinking about the meaning of the "co" prefix (together), so if they are together that means there's 2 of them. The resemblance with coroutines syntax is obviously intended.
vpckg itself does very little work and needs just a bit of memory, the compilation is offloaded to the actual compiler/linker that can be 64 bits (different process). No need to make it 64 bits.
Same experience here, it just becomes a horrible mess.
100ms relative to what? I think I've heard about those studies but can't remember the numbers. 100ms is certainly perceptible by humans, but a one second autocomplete delay (as in 100%) is anyway far too large and I'd guess the same is true about page load times(I.e. 1.1s wouldn'tbe any more problematic than 1.0s). But I mean all of this is hypocritical anyways. I've switched a couple of applications from x86 to x64 and I never had the feeling that it should suddenly become sluggish i.e some such. It's not A/B testing, but I'm at a point where I want to se hard and impressive numbers when someone claims "we should not switch to 64 bit because it would make our application slow".
yes, a global initialization does the trick :)
Sorry, I meant the default in vcpkg being 32bit instead of 64bit. The actual bitness of the vcpkg executable is irrelevant for exactly the reason you stated. It does very little work and needs only a small amount of memory. No need to make it 64bit but also no need to make it 32bit either. I feel like defaulting to 32bit because pointers will be bigger and potentially slower falls under the heading of premature optimization. Start with the least restrictive default (64bit) and if you find that your particular workload is suited to the constraints of 32bit and has observable performance gains, use 32bit. 
The problem /annoying thing is that vcpkg installs 32 bit packages by default on windows. And yes, I know I can change the default, but that doesn't change the fact that the deafault is (imho) wrong.
Relative to their average page load speed. IIRC it was serving the same content with a 100ms delay. I'm totally on your side when it comes to x86 vs x64. I've been shipping apps primarily for x64 and 64-bit ARM for years and have had exactly 0 performance complaints. I don't work for Microsoft, but I can't imagine why VS processes themselves are still 32-bit
Still doesn't support comments.
I just mentioned VS as an example of an application that should have switched to x64 long ago despite the repeated claims by some people (afaik without any proof so far) that this would slow down the application too much. So yes I have two problems with VS in that regard: The defaults (I think currently it generates both a x86 and a x64 configuration for new projects) and the fact that the app itself is x86. 
&gt;Relative to their average page load speed. IIRC it was serving the same content with a 100ms delay. Sure, but what was the base line? 400ms, 700ms, 1s? &gt;I don't work for Microsoft, but I can't imagine why VS processes themselves are still 32-bit My guess is that there are some ancient parts in the codebase that would need to be rewritten to run with 64bit correctly and whoever is in charge of such decisions didn't want to spend the money. 
Have you actually tried that? (Currently on my mobile)
Because it's a [JSON](https://tools.ietf.org/html/rfc8259) library, not [JSON5](https://json5.org/).
Beauty lies in the eyes of the beholder (I hope this saying exists in English?) And this is especially true for source code, imho. 
&gt; How did a symbol that looks like pi cut in half come to mean two pi? If you look at pi like a fraction, the denominator of tau is halve that of pi. It really is intuitive after a while. &gt; also polymorphic_value and bit operations link to the same paper oops, fixed now
Sure, that's part of what makes this worth doing. I think the fact that it means as an example to follow for a beginner should dissuade anything too wild. Beauty may be subjective but we have coding styles.
What's the problem with tau? The name is certainly reasonably established, especially among those who will probably end up using that version of the circle-constant. Furthermore `two_pi` is inconsistent with the naming-conventions of the other constants.
&gt; That's not true. If you import that namespace in a source file, you also import any using namespace from it, which is not good. That's actually a desired feature. &gt; Furthermore, the header file in this specific example declares functions outside of any namespace. Which is a very bad practice, because you never know when you will have collision of symbols.
&gt; if you care so much about it just give your compiler vendor a call and tell them to add an option to disable the behavior If we look at option one of [p1607](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1607r0.pdf), that would arguably be at least a non-standard extension if not an outright violation of the standard. &gt; but even if they didn't do it it's not like there's no benefit to having a unified way to specify function pre and postconditions, so it's still better than `assert` in that respect. Yes, but compared to the UB-version that “better” goes from “great advantages” down to “minor improvement”. Arguably it would also be a violation of the “don't pay for what you don't use”-principle: I don't use the code-path that is only there if bugs are present, but the compiler would still have to check for it.
Wt?
I hadn't thought about it before but I like the new words `pre` and `post` because my brain has to work less. I think this will probably mean I will do less mistakes.
That's bad code and whoever posted it as tutorial should feel bad for doing so.
And that makes it less of an inconvenience?
So your question is "why does a JSON library only read JSON"?
No, I'm saying it would be a nice feature to allow them regardless of whether they are in the json standard or not. It's not as if it where a proprietary extension that no one else uses. 
I think it is definitely cool as is, and I can appreciate the language features making it possible. However, if I came across this as-is in production code, I would be horrified. Just adding a ton of complexity for dubious value. Sometimes its the greatest samurai who lets his sword rust in its scabbard. 
&gt; A lot of people seem to dislike the greatest feature of contracts: That compilers are allowed to optimize based on them if they are disabled. That property is very useful, specially if the behaviour can be chosen. For instance, in NDEBUG, let the optimizer assume them and optimize; and in !NDEBUG always check them. However, I have seen discussions about how easy it is to introduce UB with contracts, and I don't like the sound of that at all.
No, I'm saying it would be a nice feature to allow them regardless of whether they are in the json standard or not. It's not as if it where a proprietary extension that no one else uses. 
I did not try it, but I could work by just defining `NumberIntegerType` and `NumberUnsignedType` to 32 bit types. If not, please open an issue at https://github.com/nlohmann/json/issues and we have a look.
The library does not support them for several reasons: - They are not part of RFC 8259. - I agree with Douglas Crockford's thoughts on this: https://plus.google.com/118095276221607585885/posts/RK8qyGVaGSr - I agree with "The Harmful Consequences of the Robustness Principle" https://tools.ietf.org/html/draft-iab-protocol-maintenance-01
I think msvc deliberately doesn't use type based alias analysis for exactly that reason. 
Personally I've never really seen tau used to mean this outside of the memes, though most of my exposure is graphics programming
As pointed out by /u/nlohmann, it's not a good idea to make a JSON parser accept input that does not strictly conform to the standard. That said, there is always the possibility of implementing additional parsers for extended specifications like we did for our library, to be found at https://github.com/taocpp/json. While the JSON parser is again strictly standards compliant, it also supports our form of extended JSON that we call JAXN, to be found at https://github.com/stand-art/jaxn. JAXN extends JSON with, among other things, comments, however comments are ignored by the parser and not included in the data model, in case that's what you need. You can even use the glue code included with taocpp/json to parse JSON-with-comments with the taocpp/json JAXN parser and let it directly create an `nlohmann::json` value object (instead of a `tao::json::value`).
&gt; given that 2_pi is ... practically impossible constexpr double operator "" _pi (unsigned long long int value) { return value * 3.1415729; } Works for me...
I am a noob at this but what are the differences between this and QJson? Can it do the same QJson does (for example support arrays)?I am looking to ditch Qt (since it's too cumbersome i think, but maybe I'm doing it wrong). 
That is the reason for why I added in that “practically”: Yes, it works, but it really is ugly to do it that way. Also it provides no advantage over `2 * pi`.
So you *did* see it.
When I think of `co_`, the last thing that comes to mind is for it to mean times two. My first instinct is to interpret it as something being complementary. Tau doesn't complement pi, if anything it is the complete version of it.
Please have a look at https://github.com/nlohmann/json/blob/develop/README.md - there are a lot of examples. (And yes, it also supports arrays).
Do you mind me asking: How do you get started doing this? I would love to do this.
why not use the already established and used conventions of boost ? https://www.boost.org/doc/libs/1_62_0/libs/math/doc/html/math_toolkit/constants.html
Thank god
That's cool. Not the best syntax though :/
Oh it's definitely not production, not least because it's all structs.
I always need to remember there is _ensures_ to know what _expects_ is about. Because at the end of a function, I also have expectations. I have less troubles with _pre_ and _post_ that I already use with Doxygen.
Amazing work, congrats!! Currently using the Poco/JSON library but might consider switch to this one. 
I have nothing to contribute here, but thanks :-)
On NamedBool: [https://godbolt.org/z/Q0j1bs](https://godbolt.org/z/Q0j1bs)
Serious question: I thought the issues with multi-byte character length was complexity and buggy implementations, not size? 
There are various posts about UB optimized away, the most famous being the solving some impossible problem because an infinite loop without side effects is UB, making a function that should not return, return right away. In the general case, if you have a branch where one side would cause UB, the compiler is allowed to assume this branch will not happen.
I disagree. You could still provide an optional parser that ignores them. Right now, the majority of your users who use JSON for configs or even debugging/testing comments have to write their own wrapper - possibly broken and insecure. 
I've been working on [this](https://github.com/DeveloperPaul123/rayray) for quite some time. It's been a fun side project and has allowed me to practice using modern C++. It's also relatively small so it should be easy to follow. 
As I understand the reason to why Structured Bindings were done that way (not tie-like at all, magic entity that is a name only) is the required support bitfields (Aside from the "feature creep" argument mentioned in the original paper)? It's really frustrating that so many interesting discussions about features are locked behind the committee curtains. Considering the number of problems arising from the feature I wonder would it make more sense to forbid them at all in Structured Bindings in the first place and make the feature more sound with prior standard instead (references route at least). 
Very interesting that "the JIT-generated code is significantly faster than the ahead-of-time-generated code for small matrix sizes". Is there a specific reason for this?
Quick question: how does it compare to cling? It's it the same goal or can it achieve similar things? By the way, the non type template parameter twisted my mind.
Maybe the JIT can be compiled with **-march=native** instead of a general x86/x86_64 target. 
You're absolutely right. Disregard /u/gvargh misplaced complaints. As for UTF formats, even UTF-32 would be better than UTF-16. Also UTF-16 isn't even a thing, since you have UTF-16LE (little endian) and UTF-16BE (big endian). Then you have incompatibility with ASCII and you still have variable length characters - either 2 or 4 bytes. UTF-16 solves none of the UTF-8 problems, but creates new ones.
As expected, the code would not compile on clang, gcc and msvc: [https://godbolt.org/z/VLmBDE](https://godbolt.org/z/VLmBDE). &amp;#x200B; I don't have time to dig through the standard, but my guess is that the program is ill formed, which requires the compiler to emit an error, so runtime UB isn't relevant at all. In anz case, this seems like a theoretical question, given that all major compilers generate a compilation error.
&gt; That's actually a desired feature. Doesn't look like a desired feature to me. If I do `using namespace libfoo`, I don't expect an implicit `using namespace std` and possible others to come with it, dumping all these namespaces into my scope. &gt; Which is a very bad practice, because you never know when you will have collision of symbols. For libraries. For applications, that's not an issue.
It would be pretty easy to write a JSON5 to JSON translator
Well ... you could [fork this library](https://github.com/nlohmann/json/) and add the missing features to make it support JSON5.
I think it's because this one is too obvious, but there are some cases (with example in the lifetime checker) where wrong things compile because of UB.
clang fails with error: use of class template 'String' requires template arguments; argument deduction not allowed in template parameter template &lt;String string&gt; class NamedBool { ^~~~~~ Would gcc be wrong to accept this code ?
No, it's using a C++20 feature (non-type template parameters) that clang doesn't yet implement.
To calculate the length of a char* char_traits::length is going to have to dereference the pointer for every character in the array until a null terminator is found. As such, your length comparison prior to calling char_traits::compare is both redundant and inefficient
Please show me a concrete snippet of code where the standard says it is ill-formed (not just UB and not "ill-formed, no diagnostic required" but actually "ill formed"), but due to UB somewhere close to it still compiles. I think you are attributing more power to UB than it actually has.
Since G+ is going away: &gt; **Comments in JSON** &gt; &gt; I removed comments from JSON because I saw people were using them to hold parsing directives, a practice which would have destroyed interoperability. I know that the lack of comments makes some people sad, but it shouldn't. &gt; &gt;Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser. -Douglas Crockford &gt; Public _Apr 30, 2012_ 
This one is very easy to use (and to integrate into your project) - it certainly is the best (used to be the only) 'modern' C++ JSON implementation. It is not the fastest, if that matters.
Unless I'm misreading it, removing the length check appears to call `memcmp("abcdefghijklmnopqrstuvwxyz", "abc", 26)`, in the non constexpr case (see below). Looking at the implementation of char\_traits::compare that I have, it appears not to do any bounds checking if you pass it a count that is too large... as you would expect. [https://godbolt.org/z/0jOmjR](https://godbolt.org/z/0jOmjR)
[https://stackoverflow.com/questions/9371238/why-is-reading-lines-from-stdin-much-slower-in-c-than-python](https://stackoverflow.com/questions/9371238/why-is-reading-lines-from-stdin-much-slower-in-c-than-python) enjoy
This is because AOT version uses dynamic matrix sizes, while JIT and 'Single specialization' versions know the matrix size at codegen time.
[https://github.com/ReactiveX/RxCpp](https://github.com/ReactiveX/RxCpp)
I do get your point here, I'm not well versed in the standard enough for any ill-formed example. But [here](https://kukuruku.co/post/undefined-behavior-and-fermats-last-theorem/) are some nice examples of crazy things UB can do.
That's some diabolical shit. 
TIL - serves me right to make assumptions rather than actually test! 
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b3aujg/having_trouble_understanding_vg_team_github/eiylrmh/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
IMO, if you're going to store these or pass them through more than one function call, you might as well use a normal enum, and if you're not, then using any kind of enum smells bad, and you should probably have multiple functions, possibly with a common helper to do most of the work: \`MungeFoo(); MungeBar();\` vs \`Munge("Foo"); Munge("Bar");\`.
#3 annoys me terribly (along with similar suggestions in other static analysis tools). If you're going to suggest a replacement function (in this case memset), make sure it is one that is part of required-to-implement part of the standard. memset_s is in Annex K which is unsupported by many compilers. Additionally in this case, the function memset_s isn't just a "not omittable memset", it comes with a ton of baggage, including some runtime checks.
&gt;[P1391R1](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1391r1.pdf) Range constructor for std::string\_view &gt; &gt;[P1394R1](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1394r1.pdf) Range constructor for std::span Yes please. This had bugged me when using string\_view and span. &gt;[P1423R1](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1423r1.html) char8\_t backward compatibility remediation This seem reasonable. I've dealt with code using `std::u8path` to cope with Windows/Linux differences. Being able to specify *please utf-8 only* is great. &gt;[P1604R0](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1604r0.html) The inline keyword is not in line with the design of modules. This. I want to put function implementation in my interface (when I see fit) without causing runaway recompilation. I think discouraging vendor to apply implicit inline is a okay short term solution, but the first solution proposed seem right. Maybe someday also put everything in the BMI in a realease build for free LTO? &gt;[P1381R1](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1381r1.html) Reference capture of structured bindings Yes. Thank you for removing the small annoyances we have! &gt;[P1452R1](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1452r1.html) On the non-uniform semantics of return-type-requirements Is this not a similar problem than what the terse template function syntax is causing? For example: void stuff(auto Integral&amp;&amp;) {} int main() { int i; stuff(i); // error, int&amp; is not an integral type } Or maybe I don't understand the problem correctly?
I can promise you, that there are a lot of c++ programmers who won't know what tau means when seeing it in a cpp program . E.g. in many applications that interact with or simulate physical systems, tau is related to time.
That's a good point as well.
Believe me, it's nothing like as rosy as you might dream. One lurches from contract to contract, no idea if or when the next income is going to turn up, often doing bottom-basement coding and build system refactoring because none of the permies wants to do "the boring stuff". As much as getting paid $500/day to copy and paste code all day every day for three weeks might sound fine, it really starts to get to you about day four onwards. Also, refactoring build systems always makes you the enemy of everybody, even if you reduce build times from hours to minutes. People hate the ground being pulled from underneath them, no matter the rationale. But to answer your question, get a library into Boost, and present at at least two global C++ conferences per year for three to five years, and you should be able to pick up remote work without too many months in between without income. You need to make sure that you always float to the top of any pile of resumes, better again if you have widespread name recognition. But even with all that, remote C++ contracting is a very brittle realm, when compared to remote Rust or Python contracting. It's not how C++ is done, you'll always be at a major disadvantage in pay and work quality compared to working onsite at one of the tech multinationals. Still, if you hate living in cities and having non-family physically near you, it can be worth it on balance. And the time freedom between contracts is amazing, though annoyingly unpredictable. Good luck! 
Maybe I don't see this because I regularly delint my code? The other approach is to emit all the fixes, dedupe, then `clang-apply-replacements`. I wouldn't want to lose the multiprocess approach, clang tidy is very slow.
Does the clang package provide a full toolchain yet? Or do you still need Visual Studio tooling installed?
&gt; Clang has new options to initialize automatic variables with a pattern. If long been wondering if/how much impact it would have on the performance of real-world c++ programs if this was mandated by the standard. Would be nice to see some benchmarks for this.
I thought LLVM and Clang is released is too frequently and don't have more differences between each major version.
The toolchain is complete, but you still need the header files and libraries from the Windows SDK, which comes with Visual Studio. But you do not need to buy or install Visual Studio, you can also install the SDK via the free Build Tools (also includes the command line VS compilers and the linker, but you don't strictly need them &amp;#x200B; If you don't have LINK.EXE, you need to tell clang to use LLD instead: -fuse-ld=lld-link &amp;#x200B; If you find a way to access the Windows SDK header files on a case insensitive file system, you can even use clang-cl from a full LLVM+clang install on Linux to cross compile Windows binaries.
I disagree. Frequent releases are a welcome change, even if the differences feel minor. Incrementing the major version number is what feels strange about all this, but what ends up happening with frequent releases is the major number never changes anyway. So I get why various projects are going this way.
During my studies (many eons ago) I was taught: - pre-conditions - post-conditions
This looks fantastic, does anyone know how well it works on Windows and/or how well it works with libc++ instead of visual studio's std lib?
[P1492](https://wg21.link/p1492) is a brilliant paper which explains the different tradeoffs involved in the various coroutine proposals. It is very readable for someone who did not follow the coroutine controversy closely. In fact, I suspect if such a paper was released a few meetings earlier, there wouldn't be much of a controversy regarding coroutines!
Why not designated initializers? struct Args { bool whenFalse; bool andWhenTrue; }; int return42(Args); return42({.whenFalse = false, .andWhenTrue = true});
Does this version integrates itself as a visual studio toolset or still I need [stuff like that](https://github.com/arves100/llvm-vs2017-integration)?
I have updated unofficial linux binary packages for Debian/Ubuntu and CentOs/Fedora (CentOs packages can be used for RedHat too). Packages have repositories to install and auto update packages. More info here: [https://masterspline.gitlab.io/build2-linux-packages/](https://masterspline.gitlab.io/build2-linux-packages/) 
That's insane
You can use build2-toolchain (packaged with all required libraries) [https://build2.org/download.xhtml](https://build2.org/download.xhtml) .
My first instinct is to think of C++ `co_`routines.
I routinely worked with such CSV's and never encountered a problem. Perhaps it was a problem with the program you were using.
P1391 and P1394 were approved by LEWG it's just a matter of getting the wording through. As for P1604... I'm curious to see what the committee will say... Don't expect too much to come out of it though. 
Excel. The CSV is fine for parsing in a program, but you can’t use it to send data to tech-illiterate people, because Microsoft tries to parse it with Windows-1252.
It was meant as a reply to both you ("self-move may cause trouble") and @SadisticPenguin ("the if ... is required"). Sorry for the confusion
Thanks!
They're similar, but built for different purposes. &amp;#x200B; Cling is primarily a REPL and always JIT compiles the whole program with minimal optimization, while cxxjit is a C++ language extension to allow JIT compilation of specifically-annotated functions with user-supplied run-time constants for maximal optimizations not even possible at build time.
That sucks. Seems to work with BOM though. Nevertheless, it's Excel issue. I barely use it nowadays.
There were some numbers in the mailing list. 
Interesting idea. It does mean disconnecting the arguments from the function, which I'm not a fan of.
You don't happen to have a link handy do you?
Do existing implementations even guarantee that memset\_s isn't optimized away just as memset?
Yeah indeed, it's not enforced. In the case for bools, I usually end up using enums decribing the behaviour of the function. It's much clearer at call site and use simple and familliar syntax.
See this thread for example: http://lists.llvm.org/pipermail/cfe-dev/2019-January/060878.html (reformatted for clarity) Stack Init Method -O1 -O2 -O3 -O2, ThinLTO -O2, ThinLTO, FDO zero-init Size Regression 0.5% 0.6% 0.6% 0.4% 0.3% Perf Regression 0.7% -0.9% 1.1% 1.0% 1.7% pattern-init Size Regression 1.6% 1.6% 1.6% 1.4% 1.6% Perf Regression 1.1% 1.2% 1.2% 0.8% 1.1% 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/b3f5kx/as_a_new_c_developer_which_book_do_you_recommend/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt;0 comments Another poster in this thread [has a program](https://github.com/DeveloperPaul123/rayray) in their readme with one comment. I think it would be better without the comment: // initialize the sampler and generate the samples rayray::multijittered_sampler sampler(25); sampler.generate_samples(); &gt;0 spaces There are some spaces. 
&gt; If you find a way to access the Windows SDK header files on a case insensitive file system http://www.brain-dump.org/projects/ciopfs/
It does not, but it can be [installed separately](https://marketplace.visualstudio.com/items?itemName=LLVMExtensions.llvm-toolchain).
yeah works, but I bet there's some impact on compile times. 
Is like those asking for stuff didn't know how it works in the first place, therefore they expect the impossible. 
Many people have a general aversion against qt. Probably nothing too specific.
Obviously. 🤷‍♂️
There's something wrong with that array: `-O2` appears twice in headers, and there are 7 columns in the header for only 6 measurements.... Regardless, &gt; 1% performance regression across the board is pretty significant.
Optimisations aren't within the purview of the standard, so enabling or disabling them can't violate the standard. What would violate the standard is an optimisation that causes code to behave not as specified, which isn't the case here.
&gt; It is not the fastest, if that matters. This is a bit of a naive question, but the performance numbers I've typically seen focus on *parsing*, which I take to mean reading in a JSON file, creating the types, and having it resident in an object. But once in memory, are there libraries that are markedly better or worse in terms of *accessing* elements of the JSON? Is that a common benchmark? Eg, if I'm using this library and have an nlohmann::json object that I've read in (slowly, perhaps) 10K lines of JSON into, is something like: int x = json_object["foo"]["bar"]; .. going to be measurably slower than using a different library but maintaining that same JSON structure (eg, "{ "foo" : { "bar" : 12 }} )? My guess is I just incur the std::map cost for finding 'foo' and 'bar', which is probably similar to other libraries, unless they switch to other types - unordered_map if I have a lot of entries, maybe? Just curious to hear any experiences; the initial read/parse from a text file to an in-memory object isn't my concern, but maybe I'm misunderstanding how 'parse' is used in some benchmarks I've seen. Thanks!
What about the standard library? Is it possible to get binaries for Windows that have std::filesystem without compiling?
looks quite similar to https://github.com/jmmartinez/easy-just-in-time
you can use clang with msys's mingw headers. 
The headers are `-O1`; `-O2`; `-O3`; `-O2, ThinLTO`; `-O2, ThinLTO, FDO`
I use a `tau` constant everywhere in my game engine. It just makes it easier to think about transformation, sine, etc.
Can somebody explain to me/point me in the direction of the right examples/docs on how the fancy constructor: json j2 = { {"pi", 3.141}, {"happy", true}, {"name", "Niels"}, {"nothing", nullptr}, {"answer", { {"everything", 42} }}, {"list", {1, 0, 2}}, {"object", { {"currency", "USD"}, {"value", 42.99} }} }; works?
Facebook's folly - [https://github.com/facebook/folly](https://github.com/facebook/folly) At my last job we had a few PhD's who were great at C++ and a lot of the codebase's design was influenced by folly. 
It is a little weird/concerning that it apparently works in the constexpr case. Does this mean the compiler is reading memory past where ever it allocates "abc"? What am I missing? More generally, what does the compiler do when constexpr code does "bad things"?
The LaTeX-code of my masters thesis contains 127 lines that contain `\pi` (some of them multiple times) and exactly zero of those refer to the circle-constant. The same variable can refer to different things in different contexts and that really is not a problem.
If a pre-condition-violation is not undefined behavior as some people demand, then any optimization based on the assumption that it never happens could very easily be a violation of the standard.
They aren't documented because you aren't allowed to name `__ugly` things, much less call into them and expect consistent results. If libc++ wanted to remove those entirely tomorrow, they should be allowed to do that.
https://nlohmann.github.io/json/classnlohmann_1_1basic__json_ab5dfd9a2b2663b219641cb7fe59b6da2.html#ab5dfd9a2b2663b219641cb7fe59b6da2
http://blog.llvm.org/2018/01/improving-link-time-on-windows-with.html - hey, can I copy your homework? - sure, just change it a bit so it is not obvious
Dang man I love your library!
Can you recommend an XML library anywhere near the quality of this one?
I feel like number 5 could be avoided entirely by using enum class, which has been around since C++11
This is basic stuff, I found all bugs easily. And they just can't stop reiterating the "modifying container during iteration" cases.
Sure, you can always define any symbol to mean anything, but by default (sampling across people with various backgrounds) people will assume that pi refers to the circle constant and other than two_pi, most people will not have an intuition about what std::tau is without looking up the definition. Similar problem with iota.
It complicates my entire build process. :(
Right, I'm not trying to use them, just get some insight into how they work. I sort of expected there to be some kind of internal notes/documentation, but couldn't find anything after googling around. They must be documented somewhere, right?
Definitely, but there are not built-in charts. I would be better off writing my own charts stuff with NanoVG, which NanoGUI uses. I was just trying to avoid that hassle because I find drawing widgets very boring.
No need to be interactive, just dynamic. Use case: in-game stats.
Nope. You can use a macro to make the lambda syntax less noisy but then you've got macros so it might not be an improvement...
https://www.webtoolkit.eu/widgets/graphics-charts this?
Ah. Hm no that’s a fair point.
I completely disagree, and quite frankly think the arguments against it are pretty lackluster. Have anyone ever heard of complaints about either of the competing formats actual support for comments? I would guess not. Douglas comment about 'just pipe it through JSMin' actually goes against the whole interopability argument, 'nah, this particular JSON source has to be minimized first, otherwise it will fail'. Now we instead have a situation with some JSON libs supporting comments and some not. Besides, if someone thought slapping parsing directives in their comments was the best course of action, good for them, that's hardly the fault of comments. Imagine c++20: "We removed comments from the standard, doxygen &amp; derivatives abused them, download this other preprocessor here and just pipe all your source through it first". Thing is JSON is used for a very wide range of use cases, and for a lot of them having no comment support is a huge drawback. Otherwise I can only concur with the majority of posters, your library looks terrific.
Yeah sure, because you knew there was a bug in the code. Would you have noticed the bug in code review?
Good point. In the constexpr case it has to evaluate the function at compile time, whereas in the non constexpr case it doesn't *have* to (although may choose to) So for the constexpr case, I had a look at gcc-7.3.0 source and found the following: static constexpr int compare(const char_type* __s1, const char_type* __s2, size_t __n) { // check if the inputs are constexpr, and if so, use char_traits::compare if (__builtin_constant_p(__n) &amp;&amp; __constant_char_array_p(__s1, __n) &amp;&amp; __constant_char_array_p(__s2, __n)) return __gnu_cxx::char_traits&lt;char_type&gt;::compare(__s1, __s2, __n); // if we're comparing nothing they clearly are the same if (__n == 0) return 0; // otherwise fall back to memcmp return __builtin_memcmp(__s1, __s2, __n); } The constant checks are comprised of: - `__builtin_constant_p` - `__constant_char_array_p` `__builtin_constant_p` is a gcc built in, with the following excerpt from the gcc manual: &gt; Built-in Function: `int __builtin_constant_p (exp)` &gt; You can use the built-in function `__builtin_constant_p` to determine if a value is known to be constant at compile time and hence that GCC can perform constant-folding on expressions involving that value. `__constant_char_array_p` is a constexpr function in `char_traits`: template&lt;typename _CharT&gt; static constexpr bool __constant_char_array_p(const _CharT* __a, size_t __n) { size_t __i = 0; while (__builtin_constant_p(__a[__i]) &amp;&amp; __i &lt; __n) __i++; return __i == __n; } Presumably when evaluating `__constant_char_array_p` for `"abc"`, once `__i` runs off the end of the input array `__a`, `__builtin_constant_p` returns false. Since `__builtin_constant_p` is a built-in, presumably it is able to evaluate the result without triggering undefined behaviour? I'm not sure... Moreover, changing the 2nd string's length to be the same as the 1st (so the program becomes well-defined), the optimisation can be applied. https://godbolt.org/z/tbJpl1 
Nearly all examples use it. This executor is named default_executor in our library.
Wow! I'd be very interested in a blog post going into more detail on these topics! A docker container with clang-cl, the SDK headers, and a userspace case-insensitive file system all bundled up would be amazing. 
I use nlohmann::json and [pugixml](https://pugixml.org/) and I find both very good. Sometimes, I wish some features from one library could be in the other but overall, they are both very good.
If read as a joke this is pretty amusing.
It is possible to set MSVC vtab layout in clang?
Sure, because you can see what it does. But if the only line in your function is if(::pread(fd,t,sizeof(T),0)==-1)raise("preadW",preserveError(fd)); then a comment maybe wouldn’t be a bad idea.
Using tons of highly advanced cryptography¹ to create some form of privacy preserving targeted advertising for physical shops. Regarding the topic at hand, I use π for non-interactive zero-knowledge (NIZK) proofs (so it usually comes with an index since there are often several of them around). From what I've seen in other works this is by no means unusual and in fact the most common identifier for those. [1] Most notably Groth-Sahai proofs for the NIZK proofs, structure preserving signatures by Abe et al. for my signatures and Groth-Sahai commitments for my commitments. (Great trio, works well together, would use again, 8/10 because it is pre-quantum.)
I was going to recommend clang as well. It's been years, but I looked over it fairly early in it's life and thought the code was very clean and well architected. I feel the same way about KDE too, but that back in version 3 or 4 days.
&gt;From what I've seen in other works this is by no means unusual and in fact the most common identifier for those. Sounds quite interesting, but that seems to be a highly specialized field and probably not a classic c++ domain. I also know fields, where pi is commonly used with a different meaning, but that's again very domain specific and not at all common knowledge for people not active in that domain, whereas every child knows pi a a constant related to circles.
Yeah, because I know there are bugs in the code.
Still on rapidjson
Who do you feel is harmed by this?
Does this have any new c++ syntax features? Was hoping to see the concepts changes in here that were demoed on godbolt months ago. Even if they aren’t final. 
I can understand that people may want comments in JSON. I quoted the sources above to make my case: 1. JSON does not support comments. 2. This is not an oversight, but was designed like this. 3. Adding comments without a specification, but just because it would be nice is dangerous.
Does it have to be embedded in something then? It has to support streaming data? I ask because if it's just simple plotting, even streaming plotting, I would delegate it to something else outside your program entirely. I often just have my C++ programs write output to stdout or a file and pipe that (or `tail -f`) it to [feedgnuplot](https://github.com/dkogan/feedgnuplot).
You can use Qt with CMake btw. Not sure if that helps you. But you don't need qmake.
 /usr/local/include/xl/log/log_status_file.h:110:13: error: call to unavailable function 'get': introduced in macOS 10.14 Is this what they were talking about for it looking for headers in different places? *sigh*
Is this too basic? https://nanogui.readthedocs.io/en/latest/api/class_nanogui__Graph.html Or did you mean something else by 'builtin'?
That's C with some C++ features thrown in, not a beautiful C++ codebase. 
You can use an enum class with underlying type bool: enum class whenFalse : bool; enum class andWhenTrue : bool; constexpr auto return42(whenFalse b, andWhenTrue c) { if (!bool(b) &amp;&amp; bool(c)) return 42; return 0; } int main() { return return42(whenFalse{false}, andWhenTrue{true}); } The downsides are the declaration of the enum outside the function and the required explicit casts in the `if` expression.
&gt; I instead had to use a script that set up a tiny build environment, and **I really didn't like that**.
There are 5 measurements. And there are 5 headers.
&gt; Pattern matching A match-like facility for C++ Under active development, targeting C++23 Yay!
If you have ideas on how to improve it, I'm happy to hear them.
Just curious, how would one know to supply "fuse-ld=lld-link", is there a tutorial or a guide for this somewhere? Also do you know if libc++ is included in the windows version?
libcxx has experimental (last I checked) support for Windows.
Agreed that would be nice but I believe the Windows sdk is non-redistributable. Though I guess you could have a script which mounts a volume and "installs" the sdk there. 
I found the llvm docs a bit sparse personally, libcxx has experimental support for Windows last I checked. 
Still not always entirely safe, unfortunately. Had good luck with parallel preview and non-preview VS2017 from 15.0-15.9, but the first couple of VS2019 previews completely reset my VS2017 settings. 
This plugin also allows you to use lld, from the IDE, in other words, it allows [makes it possible] you to use ThinLTO [without leaving the IDE].
If only Microsoft could have had a time machine to know how to implement UTF-8 when writing Windows. 
Use the [plugin](https://marketplace.visualstudio.com/items?itemName=LLVMExtensions.llvm-toolchain). And to get the compiler options, just type `clang++ --help` or `clang-cl /?`, depending. 
Only another 4 years until it hits debian stable.
auto pa = std::make_shared&lt;int*[]&gt;(3); // C++17 
std::array&lt;std::unique\_ptr&lt;**T**\&gt;, N&gt; might be an option.
yoh might want vector of shared pointer, like this: std::vector&lt;std::shared_ptr&lt;int&gt;&gt; pa;
Annex K says memset_s must not be optimized away (either the overall call or the individual writes). I'm not sure what the point of bothering to implement it would be if that basic guarantee can't be met. I do not know of a compiler that implements memset_s so maybe the "why bother" side won.
`std::shared_ptr&lt;int*[]&gt; pa{new int*[3]}; // C++11`
Thank you very much!
The code speaks for itself, if you’re at a level needed for a standard library implementer – I guess. 
Disappointingly, test frameworks are still using macros for assertions, and the justification is quite obvious and legit. I really hope someone can tell us what to do to eventually replace assertion macros.
For the developers' sake, I really hope the whole class works together than separately. Surely sharing the quality and not reimplementing is the best way to go. In fact, I hope you develop cpp in a similar fashion. 
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
I'd love to be able to use it in my VS, but every time I install Clang it corrupts all my VS instances in such way, that they work if I open them manually, but neither CMake nor VS Installer sees them. What's eveen weirder, even after reinstalling VS it would loose track of the instance after ~a week.
In new code, yes you can write it that way. But old and existing code often doesn't get updated, which leaves std authors in the awkward position where adding names to their own std namespace can nonetheless break existing code due, because that existing code had used `using namespace std`.
C++20 Contracts may be a first step to replace assertion macros. 
&gt;Maybe I don't see this because I regularly delint my code? That could very well be it. Another mistake I made in the beginning was to not set the header filter, so It never touched my headers. &gt;The other approach is to emit all the fixes, dedupe, then clang-apply-replacements. I wouldn't want to lose the multiprocess approach, clang tidy is very slow. Thats what I tried with and without your fixes. Both failed to varying degrees.
Not to mention the fact that Unicode has over 87,000 Chinese characters. Even if you started allocating those from 0 over 95% would be 3 or 4 byte characters.
&gt; Just curious, how would one know to supply "fuse-ld=lld-link", is there a tutorial or a guide for this somewhere? Not sure what you mean by this question.
I haven't tbh, because it still doesn't fully support my formatting style.
I would guess that's caused by using the (outdated) system libc++? Did you also build libc++ as part of your LLVM/Clang build?
At the 3rd place, the compiler might eliminate the call to memset because it sees 'hash' and 'passwd_buf' are not used anywhere. If they are truly not used anywhere, then the compiler is right. But is this true? if these are variables are actually used, then the compiler shouldn't remove the calls. 
Yes.
&gt; Doesn't look like a desired feature to me. You may not desire it, but it's no more different than not liking the API offered by a library. If the author did so intentionally, then it's a desired feature, because the author might anticipate heavy usage of said namespace. &gt; For libraries. For applications, that's not an issue. Applications shall be written as libraries put together. 
&gt; Another notable procedural development is that the committee started to track proposals in front of the committee in GitHub. If you’re interested in the status of a proposal, you can find its issue on GitHub by searching for its title or paper number, and see its status — such as which subgroups it has been reviewed by and what the outcome of the reviews were — there. Nice!
 &gt; Most build systems already support parallel compilation, and even if they don’t cl.exe supports it natively via the /MP compiler switch, so there is no roadblock to anyone taking advantage of parallel compilation. Nice, someone in clang team has finally noticed that /MP is useful. Maybe now there's a chance to see it working in clang-cl, instead of ["it's a build system task"-like excuses](http://clang-developers.42468.n3.nabble.com/clang-windows-clang-cl-support-for-MP-td4045651.html)?
I really wish we could have gotten synchronous networking in c++20.
Would it be OK, if I quote you on this when I get into a similar discussion next time?
The thing is, you do. 20 FPS vs 18 FPS could easily feed smooth vs choppy. Or 1.0 vs 1.1 secobds could be the gap it takes for you to cancel the operation. Not always. But *some* 10% slowdown is going to be the difference in perception/response by a user. 
does it mean that we'll have unique\_function in C++20?
&gt; You may not desire it, but it's no more different than not liking the API offered by a library. If the author did so intentionally, then it's a desired feature, because the author might anticipate heavy usage of said namespace. I struggle to make sense out of this. &gt; Applications shall be written as libraries put together. You forgot to raise your sceptre :-/
&gt; This does mean that the wildcard pattern in C++23 pattern matching will (very likely) have to be spelt some other way than _. :sad panda: Other than that: awesome!
I didn't build anything - I just downloaded, untar'd and ran it - just like I did with 7.0.
Not sure for libc++, but libstdc++ has such things, including documentation: https://gcc.gnu.org/onlinedocs/libstdc++/ https://gcc.gnu.org/onlinedocs/libstdc++/latest-doxygen/
Thank you for marking this as an announcement :)
or if Qt used standard library coding style - you would not have problems with accidental capitalization if everything was snake_case
Thanks for the tip!
Why in the fuck was the `at` method voted down for [P1024](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1024r3.pdf)? This makes bounds-checking in `std::span` entirely up to the implementation, which we all know how that usually goes...
`new`s on the main page example scare me
I expected nonsense but found a good explanation of observer_ptr&lt;&gt; That being said the advantages of this seem extremely minimal and not worth using something fairly trivial that isn't in the standard. On top of that, the main premise seems to be that the name is better because the observer_ptr doesn't observe (I disagree) while object_ptr makes it easier to use function pointers (which confuses the name object). 
Excellent.
I like these write-ups and their book. Sometimes it’s really helpful to look at how not to do things.
Her [talk on CTRE at CppCon 2018](https://youtu.be/QM3W36COnE4) was pretty incredible and I'd recommend people watch it.
Thanks. Should have read the complete cppreference page
XML is not to be encouraged
&gt; (Approved) Adding the constinit keyword. Soon we will have an entire constness family - `const` - `constexpr` - `consteval` - `constinit`
Another useful one is `echo | clang -dM -E -`, which will give you all the macros defined by the compiler (this is Windows, though, there's a similar command on Linux, but I'm not an expert on that, nor do I need it, so best to search for it). 
I still dislike the idea of observer_ptr. By developing library replacements for things that are usually fundamental parts of a language (pointer,array,tuple,variant) we are effectively saying: The languages is broken beyond repare, but that is fine, because we can build a new language on top of it that is completely implemented as a library - and if we can't implement a feature as a library type, we make the language even more complicated until we can implement it as a library type.
That's quite neat. It would be so much nicer if there was syntax such that you could declare the enums inside the parameter list.
Yes. I was a bit against merging coroutines because of their non-determinist allocations, but with that paper I'm convienced it's okay. It shows the situation and the problem perfectly. It would take a decade merging coroutine if we want to introduce deferred layout types.
&gt;It is but you need the windows c++ runtime to compile it. Which was working fine for me on 7.0, but now with the upgrade seems to conflict with various items in libc++.
The point of static analysis tools is to give you a free and unbaised second opinion. It's not gonna catch everything obviously, but it helps immensely in at least squashing some of the more subtle ones. Even the most careful and experienced of programmes can put in bugs without noticing, or simply be forced to inherit an existing codebase of unknown quality. Having to review hundreds of thousands, maybe millions of lines of code can get fatiguing fast. Besides if programmers were perfect why are we still finding bugs years later in open source programs, especially really nasty ones? Clearly some properly experienced coder would have spotted it by now :P
Thanks for investigating. There is perhaps some unobvious reason, but I would have expected undefined constexpr behaviour to be a compile failure, but apparently not: [https://godbolt.org/z/vxHHny](https://godbolt.org/z/vxHHny)
There was a proposal for \`\_\_\` (two underscores) for something that has no name. Like, you could declare multiple variable named \`\_\_\` without them colliding.
Ah thanks for letting me know!
I can't wait enough for `declconst`
[GLM](https://glm.g-truc.net)? [Eigen](https://eigen.tuxfamily.org)?
&gt;Eigen is elegant. &gt;The API is extremely clean and expressive while feeling natural to C++ programmers, thanks to expression templates. Yeah... about that. 
"make me a module" link is 404
GLM is probably what you are looking for. It's convenient, extremely usable and the extensions even have some cool template stuff (just check how the swizzling is implemented for instance). &amp;#x200B; Although, I must ask - why is "cool C++11" stuff essential for you in a 3d vector class? I'd imagine there are a lot of use cases that are \_vastly\_ better showcases of modern C++ functionality than something that's practically been functionally the same since the 80's. There's no need to put complexity where it's not needed. 
I see expression template as ranges but for mathematical expressions. The confusing thing is that a view must be returned by these expression, so it's easy to mess up lifetimes, and it's not explicit that you use them.
I understand the advantages of using smart pointers whenever they're applicable (owning resources etc), but I still can't quite fathom the allergy to raw pointers that many people seem to have, or the wisdom in building wrappers around a simple language feature that's been there for decades.
one (big) benefit of c loop macros is you can name them LOOP(outer, vecstring, str, LOOP(inner, str, ch, BREAK(outer); ); ); you can also make CONTINUE or SKIP etc... that's a lot harder with a template. highly recommend this if you like macro error messages
&gt;initializer_list Is not a library type. It normally exists in a header as an implementation detail, but you couldn't go and make your own version because it requires compiler cooperation to function. &gt;pointer,array The main limiting factor here is maintaining C and older C++ compatibility. Unless we introduce entirely new syntax (like Microsoft's `Thing^` managed handles) it's simpler to implement them as library types, unfortunately. &gt;tuple,variant Do actually have some language cooperation - between uniform initialisation and structured bindings you get things that look an awful lot like language-level tuples. Variants would benefit significantly from the language-level pattern matching proposal. This "hybrid" language/library approach seems to be a hallmark of C++ - and it has the added benefit of allowing people to implement their own versions of these types if they need additional functionality/constraints.
On the contrary, I find it amazing that the language provides us tool that let us reimplement privitives in a way that makes programming more expressive and easier.
Since clang-7.0, the installer does f-all to the VS-install and you have to use the [plugin](https://marketplace.visualstudio.com/items?itemName=LLVMExtensions.llvm-toolchain) to integrate clang with VS (or/and nothing will happen auto-magically).
Its nice that it is possible, I'm annoyed that it is necessary.
This makes it finally bearable to use large C++ codebases with VSCode for me.
&gt; Although, I must ask - why is "cool C++11" stuff essential for you in a 3d vector class? Some sort of orthodoxy that's probably a byproduct part of the "modern" adjective, and part because it's trendy.
People who like observer_ptr (like me) don't like it as part of some attempt to make a grand statement about the language being "broken". It's for very simple practical reasons like: 1. It's great if you're working with a transitioning codebase where raw pointers are still sometimes used for ownership. 2. It prevents comparisons to 0, or pointer arithmetic, at compile time, for no cost. I used to work in a library where `*x == 0` was fairly common where `x` was a raw pointer; forgetting the * caused everything to quietly compile and run with totally incorrect logic.
voting for `constrefl`
There isn't much reason to use things like move semantics for 3d or 4d vectors. Really it is about making a union and making sure you have operators defined. Intel's embree library actually has a really good vector library. Better than that is operating on arrays, which ISPC is great at.
I think I’d rather use strong typing to avoid problems than trying on not making typos
What does this tool do?
ofc, strong typing is better
Short Vector Math libraries rarely need/do deep copies so move semantics wouldn't do anything useful. Template meta programming isn't exactly very modern anymore nor add anything substantial when the back-end is using hardware SIMD registers so the lanes don't need to be evaluated separately. If you want *modern* graphics code, you should look into memory layout of your data rather than syntactic sugar coating from latest language features. 
sorry about the format. dunno how to fix it.
pPlayerBuffs is an array or a vector that's indexed with an enum.
The swizzling implementation looks overly complicated (I tested and it adds more than 200% to compilation times when enabled). Here's a bit more light-weight alternative: https://t0rakka.silvrback.com/simd-scalar-accessor 
Put four spaces before each line &lt;Space&gt;&lt;Space&gt;&lt;Space&gt;&lt;Space&gt;like this
Man that’s great documentation, explains the behavior and at a high level “why” it behaves that way, with examples!
Or go the opposite direction from cache centric designs and investigate sean parents scene graph stuff via type erasure. Or possibly a combination of the two
ever played might and magic?
It's microsoft's implementation of C++ LSP. It can provide auto complete, error detection, and debugging support for C++.
Out of curiousity, are there any other articles / principles that really guide your thinking on library / api design? Your json library is pretty widely loved (for good reason), so I’d be interested if there’s any princples or guidelines that come to mind that have been particularly helpful in deciding what to include / not to include, philosophy on error handling, what to expose to users etc
comming from average c# here, "vector of strings"? let's stick to an array. but how ? if PLAYER_BUFF_BLESS is enum.
std::vector is basically an array you can edit after creation. Enums work like numbers. PLAYER_BUFF_BLESS is basically 12 or whatever.
yes lets say 12, but how can then it be a class with .Apply()?
Not just cache centric, but also SIMD -friendly; it's best to eliminate all the shuffling and juggling bytes around the registers if you can do a full-register width loads, processing and stores. This approach scales to any register width the hardware vendors will come up with (some architectures have "unlimited" width vector registers!) and Intel is up to 512 bits on consumer/prosumer level hardware. Of course, if these large chunks can be loaded from cache aligned chunks even better. If you think "vec3 is three floats" you are stuck to using a fraction of what your CPU can do. Of course, at end of the day, it doesn't matter much as the CPU side vector math code should be just for setting stuff up and for convenience. The action is on the GPU side.
If you’re using it for something like a config, where file size usually isn’t a constraint, can you just add json fields for comments? What I’ve seen is often: { “enums”: [ { “key”: ... “value”: ... “comment”: ... }, ... ] } IME anything that has size constraints (for example, to be sent over the network) usually has a corresponding class in whatever language is doing the sending, which is where documentation for the fields would live.
I've edited [my original comment](https://www.reddit.com/r/cpp/comments/b3rolm/can_someone_explain_this_snippet_thank_you/ej1l8vp/) with more explanation, you might just need to learn more about how arrays work with regards to what can be contained inside. It works the same in any language, C#, C++, Python, JS. An array can contain anything, and so if it contains a class instance, you can call that class's member functions.
https://github.com/gp-alex/world-of-might-and-magic/tree/master/Engine/Objects and go to Player.cpp ctrl F and its the second find.
I understand that you can put anything to array the thing is, in the source code , i can't even find definition for Apply(). mainly because c++.
So, it still does not compile anything, and I [and the rest of the world individually] need to learn [to write] JSON to be able to actually compile even a cpp-single file. Rust had this [and much more] working over a year ago.
Yes, there are many instances where I have seen libraries take a long namespace and shorten it because it is going to be frequently used. That short name usually resembles the name of that library so that it's less likely to accidentally be used. &amp;#x200B; My comment was geared more toward avoiding namespace use in every single header. Maintaining all of these initialed namespaces would be a nightmare compared to using human-readable classes.
&gt; i don't think [PLAYER_BUFF_BLESS] is a class What is the full type of array? If the array is `PlayerBuffs[99]` or whatever, just go look at the definition of PlayerBuffs. FWIW `[PLAYER_BUFF_BLESS]` on its own is meaningless, so I'm assuming you mean 'the object in the array at index PLAYER_BUFF_BLESS'.
&gt; Disappointingly, test frameworks are still using macros for assertions, and the justification is quite obvious and legit. Not to mention test registration. And loads of other stuff.
i am trying to be as polite as i can. but can you please take a look for me? What is the definition of PlayerBuff[]. i been sitting here for a while and i still don't know. and mainly, thats what i want to know.
Sure, send me the github link
The before/after code for `std::any` is not a good example of the feature, even ignoring the typos and formatting.
It doesn’t compile anything because that’s not its job. For historical reasons, build management is the job of other tools - these days CMake is a common choice. CMake tools exist for VSCode. Note that the situation is actually the same for Rust, as Cargo manages the build. Sensibly the Rust team put a lot of effort into Cargo early on to avoid these issues.
&gt; https://github.com/gp-alex/world-of-might-and-magic/tree/master/Engine/Objects https://github.com/gp-alex/world-of-might-and-magic/tree/master/Engine/Objects and go to Player.cpp ctrl F search "apply" and its the second find basically any .apply thingie
&gt; Note that the situation is actually the same for Rust, as Cargo manages the build. Yes, but the whole thing works auto-magically. 
 std::array&lt;SpellBuff, 24&gt; pPlayerBuffs; That's the definition of the array, so you need to find the definition of SpellBuff and it, or its parent class, will have Apply defined
Why would someone choose libuv instead of asio / networking TS which is destined to become part of the standard library?
I really think your best bet is still Qt. Have you heard of Qt QUIC? Bonus points for Qt being multiplatform, working on Windows, Linux and Macs.
where did you pull this out of?
The flame libuv vs asio is quite alive online. A search is enough to find out the motivations of the supporters of both parties.
I am rigth now dealing with it with https://ultralig.ht/, Adam, the guy who is developing this answer any questions so feel free to ask him any doubt I think it cant be better, HTML + CSS is how the webs are done and it looks like as you like so you can do the program as you want not as you are able to do it because of some limits 
I'm also curious to hear the motivation. Not that I'm going to use it but it would make sense for consistency with other containers.
`constrofl`
Ikr
Their C++ status page hasn't been updated, but the features marked "SVN" [here][1] are in this release. [1]: https://clang.llvm.org/cxx_status.html
https://github.com/gp-alex/world-of-might-and-magic/blob/master/Engine/Spells/Spells.cpp Line 363,. so SpellBuff::Apply() is a class? (i really dunno c++ syntax) 
\`at\` would make it necessary for span to draw in exception headers, this way span can stay relatively lightweight. &amp;#x200B; &amp;#x200B;
OHH i found it its a struct
Sadly this extension still do not work with VS2019.
So I guess That's Two Steps,...they say one step at a time though, hope i didn't rush too much.... :)) TY
I have tested a solution like this and the problem is that you have to redefine all basic arithmetic operations for your scalar accessor (accessor op accessor, accessor op scalar, scalar op accessor), which is quite annoying. 
Glad you worked it out. Most c++ definitions are found in the header, and the implementation is in the CPP file. That's how I found the definition so fast
Building a languge in the library is not necessarily a bad thing. It often comes from the underlying language being powerful enough that the library is the best way to build things. LISP macros for example are so powerful that the actual LISP language is tiny and almost all of what other languages have is implemented in LISP code.
Nice name!
As /u/spinicist notes, with CMake the whole Intellisense setup is just working immediately with no hassle for me as CMakeTools provides the proper setup for launching stuff for debugging or just running the program. Works great for me.
I use VSCode for C++, with CMake, every day. I think it’s an utter joy to use. Your mileage clearly differs. I don’t think anyone would claim VSCode is fast - we all know it’s an Electron app. But it is fast *enough* for me. Start up time is a bit poor, but not enough to be annoying.
&gt;Qt Quick I don't like Qt because there are features you need to pay for... I also dislike it because it lacks of features I need
If its so windows specific, why not just use C# with .NET for Ui.
This one looks pretty cool. Thanks for sharing!!
&gt; ... with CMake the whole Intellisense setup ... Do these things have anything to do with each other?
You don't need to configure anything if you use CMake, it'll handle it automatically.
So do I need to learn CMake as well, to get it to work?
Yes.
This uses clangd right? So it doesn't support project wide references yet but will when llvm9 comes out?
I simply don't work with C# because I dislike the way its written
If they're not used after the `memset` then the compiler can optimise away the `memset`. The intent is to remove the plain text password memory but it won't.
But I do think I will work with C# in the future if I work on a project is for windows only
It feels very clean and expressive if you've never used Fortran, Matlab, or numpy.
There is a free community edition of C++ Builder (formerly by Borland, now by Embarcadero). It supports C++17 (including some lesser-known headers like &lt;latch&gt; and &lt;barrier&gt;), and has an easy-to-use GUI builder that has an extensive array of controls. It's all native code — no .NET, no HTML/CSS, no Qt, etc. The standard library is written by Dinkumware, who I believe used to provide Microsoft's implementation, too. The compiler is a modified version of clang. It isn't perfect, but if you're looking to quickly build a native Windows GUI application, it is worth a try.
You may run the application like a server: you write a C++ application with an embedded web server, then open on your browser of choice a html page on your local machine that is served by the application itself. From there it's just plain HTML and CSS but instead of having a remote web server you have a local one. It's messy and complicated to setup, but it works and only uses opensource / free software (100% C++ / HTML / CSS / JS).
It's not free for commercial use though, worth noting. Not that I mind, coders have got to make money :-)
Given that `__anything` is reserved, it can safely be used by the standard if I'm not mistaken. That's a good alternate idea.
Well, you can use Gtk/Gtkmm, it's fully opensource, if that's your problem. Either way, from the other comments, you will probably need to write what you want by hand, or use something based on OpenGL/Vulkan.
const string of length?
Do you happen to have a good reference, book or otherwise, on all this?
Thank you! That's what I've been looking for.
&gt; there are features you need to pay for The only commercial-only features are for embedded devices, like car and medical equipment UIs. You've already stated that's not your environment, so what features *doesn't* Qt have that you need?
From experience: writing UI C++ is half as productive as doing it in Java or C#.
Couldn't a valid implementation of vector::erase just destroy and move construct each element one by one? I believe using move assignment is in itself an optimization, not a requirement. There are downsides to the proposed requirement for all special member functions. std::polymorphic_allocator would not be trivially relocatable without specifically marking it as such.
&gt; I still can't quite fathom the allergy to raw pointers that many people seem to have They can cause headaches when you mix and match, especially when you're on medium sized and larger teams/legacy code. I've burned an annoying number of hours tracking down memory issues because a new person managed to get their hands on a raw pointer, delete the object out from underneath a smart pointer, and it snuck through code review. That being said, as long as you're marrying yourself to either smart or raw pointers I agree and don't see an inherent problem with raw pointers.
I know why you would say that; been there, done all that. I have implementation that doesn't need that. Here's the whole accessor, literally: template &lt;typename ScalarType, typename VectorType, int X, int Y, int Z, int W&gt; struct ShuffleAccessor4 { VectorType m; operator Vector&lt;ScalarType, 4&gt; () const { return simd::shuffle&lt;X, Y, Z, W&gt;(m); } }; This code survives the transformation just using the operators, functions and member functions for the Vector&lt;T,S&gt;: float32x4 v = a.xyzz + b.xxxw * 2.0f * dot(c.wwwz, a.xxzz * b.yyww)); You can shuffle, swizzle, mix the sub-expressions with native intrinsic code and stuff like that w/o any hassles. It "just works", but sure, getting there has been quite a bit of work. I wrote first version of this math library in 1990's, can you believe that shit? The trick here is to know which overloads to provide so that the compiler's pattern matcher can do it's job properly. If you try to micro-manage and provide every possible variation explicitly you open a can of worms that then you have to do everything yourself. Example of micro managing, you provide: - vec * scalar - scalar * vec - vec * vec - vec * accessor - accessor * vec - accessor * scalar - oh shit… we're in the deep end now! The number of permutations just blows up, I get it. The better approach is to make accessor and scalar to implicitly convert into a vector, when needed. This means carefully using the explicit keyword with constructors.. also, you don't want accidental type promotions so it can get tricky as the C++ isn't the most intuitive language out there but it is very, very expressive.. 
.NET has no direct relation to UI! So I am wondering what you meant?! WPF? WinForms? Some kind of Web based approach via electron (which wouldn't be C# anymore of course, at least not for the UI itself) 
Give xtensor a try?
\&gt; Couldn't a valid implementation of vector::erase just destroy and move construct each element one by one? Not in all cases. If the move constructor throws, the \`vector\` would be left with a "hole" where the destructed-value lives. In order to avoid UB when a user later tries to access elements in the container, \`vector\` cannot destruct elements during \`.erase\` if the contained type has throwing moves. Exceptions and throwing moves: 1, obviousness: 0. \&gt; There are downsides to the proposed requirement for all special member functions to be defaulted. That's why you're \_able\_ to mark types as trivially relocatable in the proposal. :) As the proposal outlines, if trivial relocatable were applied to types that have those special member functions defined, you'd easily end up with false-positives on the relocatable trait for real types that exist today in standard library implementations (not to mention user code), which would be a \_very bad thing\_.
Please don't. Enough with this html/js/electron thing. Making a desktop app should not require a local server! 
What does **adopted** mean? I'm asking in the context of scope guards paper (P0052). 
Never came across this, looks reasonable. The real issue for me isn't the API as it relates to using a single instance of an object, but how you deal with passing that around in and out of functions. In Fortran and Matlab, multidimensional arrays are very much intrinsic datatypes, and you can cleanly pass slices, with and without strides, or with any kind of masking. Nothing in the c++ world comes remotely close to the code niceties of other languages. 
The above is related to the ShuffleAccessor; since it can convert itself into a Vector that's all we need to do. The redefinition is required for the ScalarAccessor since it is much less work to give it a few operators than make everything else aware that it even exists. Of course we want to choose the path of least resistance and smallest amount of work. :) It's not really a big deal; there are 4 member operators that we care about: +=, -=, *= and /=. Global operators: +, -, * and / with 3 variants of each, making it grand total of 16 redefinitions which are mostly template boiler-plate like this: template &lt;typename ScalarType, typename VectorType, int Index0, int Index1&gt; ScalarType operator + (const ScalarAccessor&lt;ScalarType, VectorType, Index0&gt;&amp; a, const ScalarAccessor&lt;ScalarType, VectorType, Index1&gt;&amp; b) { return ScalarType(a) + ScalarType(b); } This can be avoided by casting explicitly, but I hate that so we're not promoting this (although it works, of course): float s = float(a.x) * float(b.y); Preferred: float s = a.x * b.y; But these are of course syntactic preferences and vary from person to the next. I aim to please myself first, if I cannot do that then it is unrealistic to expect that anyone else would be, right? =) 
I have worked with WinForms and WPF in my past. Also Java is my main programming language which I mainly use for backend developemt. The reason I don't like C# is because it becomes cross platofrm only if you work with xamarin or mono or whatever there is. If we talk about productivity in gui creation then Java is far more easier. In fact, I dont use both of them because I need low level access.
Googling for SoA vs. AoS should give starting points into the right direction. I wrote a blog post along these lines of thinking about a year ago. While it is about software rasterization it is heavily leaning on these premises: https://t0rakka.silvrback.com/software-rasterizer The performance is result from data layout in memory more than anything else. The access is cache friendly and the data can directly be consumed in CPU registers in the same layout it is stored in memory, regardless of the SIMD width used so there is no cycles "wasted" shuffling data as it is already organized to minimize any extra work. 
Much appreciated.
Yeah that's usually what one has to resort to, but it really irks me the wrong way. I mean C++ &amp; C doesn't really need comments either, just go for const char* _UNUSED12354 = "This function overe here does X"; Although it's a bit silly I actually find the JSON comment situation to be the same. Also it's a mess when you have some portion of the JSON file which you currently don't want for whatever reason, but don't want to remove permanently. If there were comments you'd just comment it out, now you have to rely on either source control or redo / undo in your editor.
That's also my experience, unless it's the type of thing I can make with Dearimgui.
&gt; Not in all cases. If the move constructor throws, the vector would be left with a "hole" where the destructed-value lives. In order to avoid UB when a user later tries to access elements in the container, vector cannot destruct elements during .erase if the contained type has throwing moves. Exceptions and throwing moves: 1, obviousness: 0. Point taken. But for optimization purposes, we are interested in the case were the type is trivially move constructible. If the type is also trivially destructible, I don't see why trivial relocation by memmove would be invalid for erase and insert.
Something that might not jump right out of the blog post is that the code is essentially "scalar" code, which is just executed simultaneously for N pixels (4, 8 or 16 pixels per iteration, depending on the CPU architecture). This means crafting the code is straightforward as writing the code is nearly identical to processing one pixel at a time. The complexity comes from how dynamic branching is handled; it is handled by conditionally choosing the output with select. We used the same approach in microcode in G40 microarchitecture back in early 2000's and even then it was already well established technique from decades old work. The point here is that GPUs generally have to execute the same code for all fragments the slowest fragment would dictate how fast a group of fragments are processed (this architecture called the group a "quad" (=2x2 array of fragments)). I am diverting a bit from the main topic so I cut it short for now. 
To be honest this solution sounds just too complicated. I think running a special server for UI is pretty much overkill
People ask why FORTRAN is still used in new projects,.. this and namelists is why. 
At least in the case of c++, the problem is that a) library implementations rarely quite live up to the expecations you have for a given feature and b) they also come with a lot of overhead (compile-time, debug performance, clumsy interface). 
Ah!, I had seen the comma as a separator between measurements; not as a separator between options of a single measurement... (and I managed to get the measurements off by one :p)
Thanks!
The enum variant is really useful, could it be used to auto generate EnumToString and StringToEnum ?
I’ve also had good luck with (Blaze)[https://bitbucket.org/blaze-lib/blaze]. I find the API a bit nicer than Eigen, and handles non-trivial scalar types well (e.g can do arithmetic on dynamic vector of vector3’s).
Just saying: The fact that I can compare a pointer against 0 is imho a broken part of c++ that should be deprecated. And no, it is not zero cost. It adds compiletime overhead, it adds overhead during debugging, it is yet another feature you have to teach programmers, it potentially adds overloads to your APIs - even worse, it will most likely lead to even more ifdefs (use std::observer\_ptr when compiled in c++20 and raw pointer otherwise) etc.. &amp;#x200B; I have no problem if a project/company decides to use observer\_ptr - I just don't think it carries its weight as a vocabulary/ stdandard interface type (which is the only reason, why you'd want to have a trivial type like that in the standard library at all).
I thought Winforms and WPF are both part of the .NET Framework. Admittedly I'm not quite up to date with the windows environment. 
Nice! I am super interested in using the type system to describe a parser and reduce the amount of code paths available and offer better optimizations.
Can you link me to it please?
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b3tmay/what_should_be_filled_in_the_blank_to_pass_the/ej21xui/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; As the proposal outlines, if trivial relocatable were applied to types that have those special member functions defined, you'd easily end up with false-positives on the relocatable trait for real types that exist today in standard library implementations (not to mention user code) We would? Can you give an example? Both move constructor and destructor would of course have to be trivial.
Yes they are. But it's not helpfull just to name a complete framework that is not specifically tailored to UI. None of them are "modern" (even if I dislike this word) btw. MS is going more in direction of UWP or electron based web apps. They have a hard work in order to let *classic* .NET die - they just announced they will port WinForms support to .NETCore... I bet they wouldn't do it first, but got too much feedback of customers that are still relying on those technologies.... 
Can't you say all the same things about C++ language features? In my experience the language itself is just as clumsy as the standard library.
In case Nameof work only to EnumToString 
And to also answer the question about compiler, the C++ language service in Microsoft's VSCode extension uses the same mix of C++ parsers that Visual Studio IDE uses, the primary one being a EDG-based frontend compiler. The language services can emulate both MSVC or Clang modes. Give it a try and let us know how it works for you /u/quicknir
How's the HTML5 support? It said it was planned but I never got a clear idea of what is and isnt supported. If you wanted to use Bootstrap4, would it work?
I played with dear imgui and I enjoyed it. What I did was mostly 2d and 3d visualization stuff. I don't know if it is considered "modern".
If you only need to target Windows you could give C++ WinRT a try https://docs.microsoft.com/en-us/windows/uwp/cpp-and-winrt-apis/intro-to-using-cpp-with-winrt The only downside might be that without any WPF knowledge the learning curve might be a bit high and since C++/WinRT is quite new the documentation is as good as with C#.
can't try add a construct_cast or something? Also std::bless is not a very descriptive name
For me it is the guaranteed copy elision.
 NAMEOF(somevar.foo() -&gt; "foo" NAMEOF(somevar.boo&lt;int&gt;() -&gt; "boo&lt;int&gt;" I think you are missing closing parens there.
Explain please
Yes I will fix it, thanks! 
Anybody mind explaining difference between VSCode and VS IDE?
I think there is no such an exact thing that you are looking for. The closest thing that I can imagine is the SKIA ( [https://skia.org/](https://skia.org/) ) the graphics engine under the Sublime Text, Chrome (and Android and Flutter, ...) combined with Yoga Layout ( [https://yogalayout.com/](https://yogalayout.com/) [https://github.com/facebook/yoga/tree/master/yoga](https://github.com/facebook/yoga/tree/master/yoga) ) the layout engine under React and you need an SDL2 [https://www.libsdl.org/index.php](https://www.libsdl.org/index.php) for cross platform OpenGl and eventloop and you can export widgets (with JavaScript plugins) and User interface design elements from Adobe XD and there are many UI kits on the net: [https://www.xdguru.com/free-xd-ui-kits/](https://www.xdguru.com/free-xd-ui-kits/) or from [https://www.sketch.com/](https://www.sketch.com/) ( Sketch only works on Mac). &amp;#x200B; But these require really a lot of work to deal with! It think really a challenge to write such a thing!
Without MFC and Qt, you can use WxWidgets. This is worse than MFC. Look and feel is not modern and you will have a feelings of MFC style programming. &amp;#x200B; I also had similar problem. I chose Juce. It's lightweight and portable. The biggest advantage is the smooth learning curve and dependency free binaries. &amp;#x200B; I think you should give it a try. 
I have the same problem. I am surprised that anybody mentioned Sciter. It's a very very nice desktop gui toolkit. A real alternative to QT.
\&gt; Allows the initialization of an aggregate with multiple values through curly braces You could always do that, the word "base" is missing
Can use data hack: &amp;#x200B; `// EnumToString` `auto c = Color::RED;` `std::cout &lt;&lt; nameof::nameof_enum(c) &lt;&lt; std::endl; // RED` &amp;#x200B; `//StringToEnum` `std::string_view s{ "RED" };` `Color color;` `for (int i = 0; i &lt; 100; ++i) {` `if (nameof::nameof_enum((Color)i) == s) {` `color = (Color)i;` `break;` `}` `}` `std::cout &lt;&lt; nameof::nameof_enum(color) &lt;&lt; std::endl; // RED`
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
How about `...`? Not sure if that could introduce ambiguity.
It's look interesting idea, later i implement this hack.
Try Juce. https://docs.juce.com/master/tutorial_main_component.html
Thanks for pointing that out, fixed now.
The networking TS is not perfect in its current incarnation for many use cases: [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1269r0.html](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1269r0.html) Some users needing higher perf, more control, or who just have a better idea of a usable API (relying on their own framework) will be better off building that on top of libuv than in trying to shoehorn Asio into their project.
What about Nana? http://nanapro.org/en-us/
That's the intention, yes. It still needs to undergo wording review in the Library Working Group; the deadline for that is the end of the next meeting, and there are many proposals that need such review, so there's always the possibility of something slipping, but with some luck it should make C++20.
In addition to the concerns about exception headers mentioned by Fabio, I think the committee considers the existing containers' \`at()\` methods a mistake these days. The reason is as follows: if the purpose of the check is more of a "sanity check", then contract preconditions are the appropriate mechanism for it. If the purpose of the check is to handle cases where the index is legitimate out of bounds (e.g. because it comes from user input), then that's ordinary control flow, and exceptions should not be used for ordinary control flow.
100% agreed, Optimization on disabled contracts was the selling feature for me.
2. is quite like "the core language is broken, let's workaround it" anyway. But well, it can't really change because of compat. So maybe this is useful. But maybe more stuff should be phased-in in the core language, instead of in the STL, because of usual shortcomings of the STL solution (long compile times, over-reliance on the optimizer to obtain decent speed) 
Didn't realize you said "all" special member functions and not "any" special member functions, so my prior comment was inaccurate for your point. Oops. :)
That paper's been debunked twice now
Code is a cross platform editor with a very large amount of plugins and language support, similar to VIM/Emacs/Sublime ect. It can be made into a pretty nice IDE, although with some unfortunate amount of effort to get it working. VS is a full blown IDE that pretty much does everything out of the box, but it is Windows only (and not free outside of the community edition).
Not 100% but I think the C++ extension uses the same engine that Visual Studio uses for intellisense/tag parsing.
My implementation: https://github.com/bravikov/nameof
Thanks!
I am(was) working on something alike, https://github.com/integricho/bdm/tree/develop but due to recent work obligations I haven't had much time to wrap it up completely, some core features are still missing.
Check out JUCE!
&gt;&gt; initializer\_list &gt; Is not a library type. It normally exists in a header as an implementation detail, but you couldn't go and make your own version because it requires compiler cooperation to function. The compiler knows about it and creates in inplicitly under the proper circumstances, but it absolutely is a regular, (fairly trivial and somewhat broken) library type. I even need to include the corresponding header to use it. &gt; &gt; pointer,array &gt; The main limiting factor here is maintaining C and older C++ compatibility. Unless we introduce entirely new syntax (like Microsoft's Thing^ managed handles) it's simpler to implement them as library types, unfortunately. I'm aware where the problem comes from (although I still believe, array could have been fixed instead of introducing a library type that is almost but not quite as powerfull as native arrays). But it is exactly as I said: The language is broken and we can't fix it, so we implmenet a "new language" by means of the standard library. &gt; &gt; tuple,variant &gt; Do actually have some language cooperation And still require a whole lot of template meta programming to be implemented correctly (AFAIK, msvc has an intrinsic for it, that at least solves part of the pain) &gt; - between uniform initialisation and structured bindings you get things that look an awful lot like language-level tuples. The former being an example of what I meant with "and if we can't implement a feature as a library type, we make the language even more complicated until we can implement it as a library type." Regarding the topic itself: I simply think that raw pointer are good enough and the additional complexity that comes from introducing another pointer like type that will never fully replace raw pointers is not worth it. I'd rather see improvements to raw pointers (e.g. only assignable/comparable to nullptr, not `0`) even if they break backwards compatibility. If you want an observer pointer in your codebase, implementing one yourself is trivial. 
Xaml + c++/winrt? Haven't tried that yet though.
&gt; as long as you're marrying yourself to either smart or raw pointers I disagree. I really hate this phrase because it usually communicates nothing, but you need to use the right tool for the job. Fortunately in this case I can be extremely specific: In a codebase that is heavily bought-in to modern smart pointer usage raw pointers should be used for parameters, reseatable optional references, and *occasionally* longer-term references to objects that have easy-to-reason-about scope (usually globals). Being obsessive about smart pointers is a debug performance pessimization and eliminates useful function signatures from your API design toolbelt.
Isn't the union stuff UB in c++?
Thanks! Those are helpful for libstdc++
I implemented a templated vector2/3/4 back in the day that could perform all swizzles using template fun: vector2::x, vector2::y, vector2::xx, vector2::yy, vector2::xy, vector2::yx, vector2:xxx. vector2::xzyy, vector2::..., vector3::..., vector3::... Umm... the static library size (before the executable was built) in release was... 3 GiB. 
That's very clever to use the function name macro to get the name. :)
You don't need return 0; 
Wouldn't a simple #define Nameof(x) #x do the trick?!
2 years professionally.
I didn't see this in a quick browse of the documentation: how does this handle type aliases?
Making a macro that is not ALLCAPS is a mortal sin...
#include &lt;iostream&gt; struct Executor { Executor() { std::cout &lt;&lt; "Hello world!" &lt;&lt; std::endl; } }; static Executor executor_instance; int main() {}
Nice! :) Not sure if this post is appropriate here, but here are some things.w $ clang++ -std=c++17 -Wall -Wextra -pedantic -pedantic-errors -o main main.cpp main.cpp:11:20: warning: unused variable 'BASE_TEN' [-Wunused-const-variable] const unsigned int BASE_TEN = 0; ^ 1 warning generated. You are using a lot of C stuff :(. Instead of using a `char[255]`, use a `std::string` (which you seem to be already using, not sure why you choose to use it in one place only). That way you can also remove your `Length` function since it's not needed anymore. `to_digit` really shouldn't be a macro. Sorry but IMO your constants are horribly named and upper case is normally used for macros. Here's your code with the few improvements. If you want you can use std::transform_reduce instead of that loop. Also consider dropping the intermediate printing. As seen by the last cout statement, you expect that `Per` returns just a number but it actually also prints something, so your output looks broken. That's a reason why computation and printing is done separately. unsigned int Per(string num, unsigned int steps = 0) { if (num.length() == 1) { return steps; } unsigned long long new_num = 1; for (char c : num) { new_num *= c - '0'; } ++steps; num = to_string(new_num); cout &lt;&lt; "Iteration " &lt;&lt; steps &lt;&lt; ": " &lt;&lt; num &lt;&lt; endl; return Per(num, steps); } int main() { string num; cout &lt;&lt; "Multiplicitive Persistance of: "; cin &gt;&gt; num; cout &lt;&lt; "Steps: " &lt;&lt; Per(num); return 0; }
Hey thanks for the feedback, this will be super useful in the future! I didn't know about a lot of those tips, hopefully my school can be more clear on industry standards, and such in the future. We've been doing a lot of C in class, but I honestly enjoy using c++ the most right now.
all caps constants are not uncommon at all. There are real reasons to use arrays instead of std::string (though I didn't look in this case). 
Please link said debunkings; the timer issue is just one point brought up in that paper; and it's not clear how what you linked is even related to the paper's points (about callbacks, not socket expiration).
I have done that forever. Wouldn't mind an official operator still.
main.cpp : int main() {} other_file.cpp : #include &lt;iostream&gt; static struct MyMain { MyMain() { std::cout &lt;&lt; "Hello there!" &lt;&lt; std::endl; } } myMainInstance; some_other_file.cpp : #include &lt;iostream&gt; static struct MyMain { MyMain() { std::cout &lt;&lt; "General Kenobi" &lt;&lt; std::endl; } } myMainInstance; Not in order? Then is static initialization fiasco.
Your `is_lexeme` function is not technically portable, as it assumes characters from 'a' to 'z' or 'A' to 'Z' are contiguous, which is true for ASCII but not for EBCDIC for example.
Author here. Last weekend, I've read an article about error handling in OCaml, and thought to myself: That must be somehow possible in C++. After playing around a bit, I had a semi-working version ready, and I thought I write about it. The post exploded a bit, and now contains a rather lengthy section about error handling in C++, too... By the way, if anyone knows how to report an MSVC ICE from godbolt.org, please tell me.
This post is missing a question.
That doesn't handle member variables and template instantiations as nicely as this does.
&gt; Feedback is also welcome :)! Feedback incoming! #define to_digit(x)(x - '0') You should define a function to do this instead of making it a macro, because there's so much that can go wrong unexpectedly. For those times that you do need a macro, there's no such thing as too many parentheses, just in case: `#define to_digit(x) ((x) - '0')` using std::string; using std::to_string; using std::cin; using std::cout; using std::endl; I'm pleased to see you don't have `using namespace std;`! I still prefer to use the namespace when things are used, but this is acceptable. const unsigned int INIT_STEPS = 0; const unsigned int BASE_TEN = 0; const unsigned int OFFSET = 1; const unsigned int MIN_INT = 1; Again, I'm pleased you're being aware of "magic numbers" and giving them names in your program. That's a good sign. However, I think you've gone too far here, and these names don't actually add value and understanding to your program. Not all literals are bad (especially -1, 0, 1, and 2). unsigned int Length(const char * str) This function exists for you in `&lt;cstring&gt;`, and is called `std::strlen`. Don't write functions that already exist. unsigned int Per(const char * num, unsigned int steps) I wouldn't use `const char*` here. C style strings come with so many caveats and oddities. And you're already using `std::string` elsewhere. Pass a `const std::string&amp;` instead. Even better, use `std::string_view` if you have C++17. An alternative idea is to pass an integer type instead of a string for this parameter. You'll need to grab each digit individually instead of allowing `to_string` to do that for you, of course, but that's pretty easy. A slightly more controversial suggestion is to give `steps` a default parameter, or provide an overload with only one parameter. That way the caller doesn't need to know they need to pass a 0 for that value. unsigned long long new_num = to_digit(*(num)); for (unsigned int i = OFFSET; i &lt; Length(num); ++i) { new_num *= to_digit(*(num + i)); } I think there are some more clear ways to do this loop. First, you can access digits with array notation (`num[i]`) instead of pointer arithmetic. Even better is to use a ranged for loop, which you could have done had you started with a `std::string` or `std::string_view`. And possibly even better than that would be to use `std::accumulate` (again, why write a function when one exists already?). string new_str; new_str = to_string(new_num); When possible, declare an use a variable in one step. steps += 1; I prefer to use the increment operator here (`steps++;`). cout &lt;&lt; "Iteration " &lt;&lt; steps &lt;&lt; ": " &lt;&lt; new_str &lt;&lt; endl; In general you don't want to use `endl`. This doesn't just end the line, it also flushes the output buffer. You want to just use `'\n'` instead. Sadly, teaching materials haven't caught up in this regard. char num[255]; This especially should be a `std::string` instead of a C-style string. You might want to do some error handling to make sure the user entered in all digits, that the input can't overflow your intermediate values, etc.
Reflection with compile time mutables and expression statements, which we will probably not have for another 4 years in the standard.
Left to right, one line at a time. (The question is a bit vague) 
Not loosing your time asking such questions would be enough. Just spend it trying to understand c++ code.
Top to bottom... uh no go back to top, no, no, no too much ! now straight to the end ! No ! let's go back to include section again... hum maybe in this file...
This is absolutely fantastic feedback, i will definitely be attempting to utilize what you've suggested! I'm always looking to better myself for when i get into the job market! Our teachers dont seem to care about our exact use of functions, classes, templates, and inheritance, as long as the program covers what they asked us to do. Which is a shame in my oppinion.
See lib-ext post from me, titled "[P1269R0] Three Years with the Networking TS (feedback)"
Use WinRT, It's the C++17 wrapper around Windows (UWP) APIs. User interfaces (XAML) can be designed with Visual Studio, written by hand or use some third-party apps to design UI. The most similar cross-platform tools would be Xamarin (also owned by Microsoft) , which does not have the same level of support for C++ but focuses more on C#. Although you could make a UI app in Xamarin C#, and the actual bulk of your code could be a dynamic library written in C++.
For example, from the paper \&gt; "I have strong reservations about the usability of any async framework in C++ built only on top of callbacks. " &amp;#x200B; Statements like this highlight a misunderstanding. The \*only\* possible primitive is callbacks, unless a new technology I don't know about has been invented which allows code to be executed without being invoked. Even Coroutines TS objects must be invoked to execute (by calling .resume()) . I'm sure the author meant well, but the blame is misplaced on Networking TS. The shortcomings of epoll on certain Linux versions are well known, and it is similarly unfair to place the blame on asio's implementation when the underlying operating system support is itself faulty. &amp;#x200B;
Instead of Switch, since you already have a variant, couldn't you just use std::visit with the overload helper. Switch(result) .Case&lt;SyntaxError&gt;(\[\](**auto** err){report\_error("Invalid syntax at line", e.line, ":", e.column);}) .Case&lt;GrammarError&gt;(\[\](**auto** err){report\_error(e.explanation, "at ", e.line, ":", e.column);}) .Case&lt;LengthError&gt;(\[\](**auto** err){report\_errror("illegal length: ", e.length);}) .Case&lt;DisplayError&gt;(\[\](**auto** err){report\_error(e.explanation);}) | ESAC } &amp;#x200B; std::visit(overload{ \[\](auto&amp; SyntaxError){}, \[\](auto&amp; GrammarError){} }); &amp;#x200B; If you potentially forget one of the types of the variant, visit will cause a compile time error.
The benefits of using a type like this are the annotation of (intended) "ownership", and the compile-time restrictions. I'll note that you can take those benefits even further by using a variety of such pointer types to more precisely annotate the intended use case. Specifically you could have: i) [`scope_ptr`](https://github.com/duneroadrunner/SaferCPlusPlus#scope-pointers) \- The pointer itself has scope lifetime (basically is declared on the stack) and the target object is known (at compile-time) to outlive the scope. (So there's intrinsically no chance of a dangling reference.) ii) [`norad_ptr`](https://github.com/duneroadrunner/SaferCPlusPlus#norad-pointers) \- Doesn't satisfy the requirements to be a `scope_ptr`, but the programmer intends that it will never point to a deallocated object. (Which is stronger than saying it will never be *dereferenced* while pointing to a deallocated object.) iii) [`unrestricted_ptr`](https://github.com/duneroadrunner/SaferCPlusPlus#registered-pointers) \- Doesn't qualify to be a `scope_ptr` or `norad_ptr`. I suggest that if you annotate all your pointers with these, you are essentially providing sufficient annotation to enable the assured memory safety of your pointers (with a minimum of overhead). So if you're considering using this type of `object_ptr`, I recommend creating aliases that correspond to the three use cases I listed, and use those aliases instead.
This will generate worse code I believe. Honestly std::visit should just be considered an antipattern at this point
You're right, that should also work, and once we have overload in std it would even be nice to write. However, I think the static_assert creates better error messages, which is important from an ergonomic point of view.
What would be the point of using this macro vs. simply writing the string in place ? It's not like the parameter has to be a valid expression.
Most obvious use is refactoring. Visual Studio support automated renaming etc., and thus it is just good practice.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b3w8qb/accessor_and_mutator_c_method_in_class_arrray_33/ej2txu8/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I dont really know, i guess what you are asking is about the new video embeded features or webassembly or something more complex that a new tag name, what i cared what about the CSS support so i did my tests, CSS grid for example worked so it has some new feautres. Because i am not one of the developers i dont know how deep it is the support but try for your self, i discovered that JS dont work for me but isnt that big deal since you have C/C++ to do whatever you need and CSS to add the efects you want to the UI I was using Electron (which has complete support for all HTML5 + CSS 3) but i has to left it beside, the moment you try to do something a little more complex that expected brace yourself for errors and problems, thinks without that many solutions, in my case i wanted SQLite in my project and Electron need to compile but always failed (i tried with Linux and some compilers and later with Windows), i never get working, what was more rare is that without Electron, Node could compile it without a problem. That error and others things that i was having left me no choice and has to say good bye So try for your self and if you dont get what you need ask Adam about it, i asked him a few times and always get an answer, an honest one so 5/5 in that aspect
Please report ICEs through [Developer Community](https://developercommunity.visualstudio.com/spaces/62/index.html) with minimal test cases (or preprocessed).
Thanks for the deeper context, I appreciate your time taken. :)
It's fairly easy to use the Windows API directly, creating light-weight wrappers as you go. The problem is that it will be really really Windows-specific. But it's a nice exercise and leads you into some interesting C++ problem. I guess the most obvious is the mismatch between the Windows view of object creation, and C++ RAII. Essentially, a Windows widget (more commonly known as a "window" in Windows programming, but e.g. a button is a "window") receives and handles messages, corresponding to virtual method calls, during creation. In the 1990s C++ frameworks this mismatch was solved by accommodating Windows and ditching the safety of the C++ way, by using two-phase construction. One way to avoid two-phase construction in your wrappers is to pass a polymorphic factory object up the constructor call chain. 
You can just target UWP. You can use C++17 to write pretty modern code nowadays: https://docs.microsoft.com/en-us/windows/uwp/cpp-and-winrt-apis/intro-to-using-cpp-with-winrt No .NET overhead, modern C++ syntax, modern Windows look-and-feel - what's not to like?
You are welcome, and I appreciate the dialogue!
Thanks!
as another option: electron front-end with your c++ backend for the heavier stuff
I don't know much about this topic, but wonder why a local server is complicated to setup. I use a local server in my approach to middleware/serialization. So far I don't think setting it up is messy or complicated.
It uses the EDG compiler and takes those errors and uses them, so that would be a yes. The debugger also seems loosely based on their own debugger, but slightly different, mostly the same, though.
Would this be another example of backwards compatibility preventing the addition of new features? /s
It is explicitly called out by the language definition as *dynamic initialization* because it isn’t static initialization. 
[removed]
Like `max`?
Matlab can't mess up lifetimes of your objects because no proxy objects are ever returned. Also indexing syntax is nicer but you can't implement it in C++ for various reasons.
for some of these, you could go `#define nameof(x) \"x\"` I am not sure, I haven't done too many macros
Example of a machine using EBCDIC with a modern C++ compiler?
to be fair, his code would still work, just would let through these characters [±](https://en.wikipedia.org/wiki/%C2%B1) [\~](https://en.wikipedia.org/wiki/~) [{](https://en.wikipedia.org/wiki/Brace_(punctuation)) [}](https://en.wikipedia.org/wiki/Brace_(punctuation)) [\\](https://en.wikipedia.org/wiki/%5C) Which shouldn't be TOO much of a problem, and if you use EBCDIC, you deserve to fix these errors yourself. 
You forgot `co_const`
This is an exaggeration. Yes, it's not implemented well at the moment but that will change.
This would not work at all if your type is a template. For example: template&lt;typename T&gt; void foo() { std::string name_of_T = NAMEOF(T); } Yours would just product "T".
It probably requires only minor changes for VS2019, so if you can get the code it should be easy enough to fix it. Not sure if the extension itself is open source though.
uwu what's this?
This is eerily similar to something I've been working on in my spare time.
I mean you could probably find most type errors from carefully reading code, but you would still want the compiler to double check...
Microsoft's unit testing doesn't use macros for their assert (at least from the user point of view, they use some inside the code). `Assert::AreEqual` and `Assert::IsTrue` are templated functions, so they won't do some funny business with your expressions full of side effects. They do use them for registering test functions and classes, but not sure you could have a sane syntax without with the current state of C++, you need reflection for that.
Or by not redefining the almost same enum twice. If you have only three states, make one enum that works for flags and the different states and you won't get hurt by this. This would save the problem for even old school C without the fancy enum class protections.
&gt; you can't implement it in C++ for various reasons I'm aware of that from a high level, but can you elaborate on any of the specifics of why it can never happen?
Might be an actual legit use of `volatile` right here. The compiler can't remove your changes even if it doesn't see you do anything with it.
Not having built-in EnumToString and StringToEnum in C++ in 2019 really rustles my jimmies.
Matlab syntax uses the colon for indexing. You could actually write containers to accept a range with `operator()` (OpenCV does this), but then you have to write it with braces so you get something like MyMat({1,5},{2,4}) So it is much more annoying that Matlab's `MyMat(1:5,2:4)`. Matlab also has a few special ranges that can be invoked, like `:` for everything in this dimension, and `end` that refers to the end of the array (you could use -1 for the latter so it is implementable at least). Now you have things like `1:3:end` which takes one third of the elements. You have filter in ranges that can do that, but the syntax is much more verbose. You can see how the colon gets used in many different ways, so standardizing all of this is no easy task, because it would require massive core language changes.
&gt; You can see how the colon gets used in many different ways, so standardizing all of this is no easy task, because it would require massive core language changes. For sure. It'd definitely take core language changes. It doesn't seem intractable at all, considering this is stuff from fortran90, I guess just no one is sufficiently interested in doing it. 
The MeetingC++ one has some updates.
It's possible, but I can already see the bikeshedding that is going to happen. If the operator simply spawned an iota range it'd be easy, but then people will want to customize it and this is going to be hell. There'd be an argument for the iota range to be a core language feature instead of the library, but that battle has been lost with tuple, variant, any and optional already.
/u/VinnieFalco thanks for mentioning this, I recently came across the improved universal model and I thought the `initiate` function is a step into the right direction. However it still requires a `return_type` which is not dependent on the initiating function itself which makes it impossible to stored the initiating function without a type erasure. Do you know whether there are any plans in improving this?
Yes, exactly like max! http://www.suodenjoki.dk/us/archive/2010/min-max.htm
Was just about to ask a similar question. For those who are familiar with Qt, how flexible is it in terms of design? I'm wondering whether Qt can do UI like VSC (like the custom window frame designs and such). For people who just want to get some modern design up and running fast, is Qt desirable than say, Electron?
For C++11 over WinAPI, there's [WinLamb](https://github.com/rodrigocfd/winlamb), which is just a thin layer over raw WinAPI.
&gt; Assert::AreEqual and Assert::IsTrue are templated functions, so they won't do some funny business with your expressions full of side effects. Of course you *can* do that, but of course this comes with a couple compromises that IMO are substantial. I'm not sure how much this matters in the context of VS test integration so maybe it's a good decision in this context, but my initial reaction is that going with a function means that the failure message can't capture the relevant expression. You also can't do fancy catch-style `assert(a == b)` trickery without *really* compromising on the messages. In something that *used* to matter to me but doesn't more recently, but would for others, you can't do a GTest-style `return` on failure, for if you `-fno-exceptions`. (That of course has plusses and minuses.) (There were actually a couple other shortcomings I was going to mention... but I think they're obviated by lambdas now!)
Wasn’t this the reasoning used to remove trigraphs? No one could find such a system?
Well in this case you also supply a string for custom error if you want, and it will also print "expected x, got y". Yes it's not perfect, but it works pretty well. The only problem is you have to provide a custom `ToString` function for non-standard types for the printing. I'm not sure why you'd care about disabling the exceptions in the Unit Test code itself, you can call code without exceptions from a code with exceptions just fine.
Is there an issue with this algorithm: [https://en.cppreference.com/w/cpp/algorithm/find](https://en.cppreference.com/w/cpp/algorithm/find)
Look into Eigen
No, was just curious that’s all. It just strange cus that method is in almost every other container. Thanks tho 
Finding a single element that compares equal is relatively simple. `std::string::find` searches for a sub-sequence, and may be implemented with something like a rolling hash, which would be difficult to implement for any generic `T` in `vector&lt;T&gt;`. That `T` may contain bits witch do not contribute to equality. Some `T`'s may not have a means to compare them at all. It doesn't really make sense to have a generic find attached to a container that will sometimes do nothing.
Also, this returns an iterator not an unsigned integer like find() does.
I've mostly used a macro like this for reflection or doing things with automatic data loading. When you can declare and register a variable in one step (without repetition) it makes the code cleaner and easier to read.
No, in your case NAMEOF(person.address.zip\_code) -&gt; "person.address.zip\_code)" My: NAMEOF(person.address.zip\_code) -&gt; "zip\_code" 
There's `std::search` for finding subsequences, which you can also now customize with algorithms that are better than just comparing each element individually.
Use NAMEOF\_TYPE\_T(T) or nameof::nameof\_type&lt;T&gt; 
I remember your realization, and when you decided to do it. &amp;#x200B; But my library supports * Compile-time * Nameof type * Name of enum
Unfortunately, aliyas are not supported. Only compiler specific type
I was inspired Nameof() from c# ;)
Did not quite understand what your question is?)
Other containers have non-generic find algorithms. `vector`, like `array` and arrays, don't have a single find algorithm, as they could be unsorted, sorted, or partitioned.
С++17: Removal of [trigraphs](https://en.wikipedia.org/wiki/Digraphs_and_trigraphs)
As noted below, it is needed to handle names in c++17 (no [trigraphs](https://en.wikipedia.org/wiki/Digraphs_and_trigraphs)), so i can rename ithis function) like is\_not\_naming\_character 
I use this fot logs, serializable. This macro will generate a compilation error if the variable does not exist.
&gt; Well in this case you also supply a string for custom error if you want, and it will also print "expected x, got y". &gt; &gt; Yes it's not perfect, but it works pretty well. But at the same time, given a choice between that reduced functionality and using macros for assertions? I'll take the latter in a heartbeat. If I were writing tests using the MS framework, I'd likely write some wrapper macros (plus functions) to build those custom error strings out of the stringized expressions. (Or maybe not; like I said, maybe that's less important in the VS/WinDev context than the way I'm used to working.) &gt; I'm not sure why you'd care about disabling the exceptions in the Unit Test code itself, *you can call code without exceptions from a code with exceptions just fine*. Depends what you mean by that. If you mean I could compile tested code twice, once with `-fno-exceptions` for production and once without for test, that'd work but add a crapton of compiler overhead. But what I expect you mean is that you suggest that production code be compiled with `-fno-exceptions` and test code with exceptions and those be linked together for tests -- that's playing with fire. In a world where templated and inline function definitions in headers is extremely common, this (i) at best means you'll often not be testing your code as it's built in production and (ii) is begging your linker to screw you from ODR violations. Remember how I said that I don't personally care about `-fno-exceptions` *recently*? We *used* to do this for production code. Most things were built with exceptions disabled, but some select components (usually using third party code) had them enabled. Substantial engineering effort was spent tracking down what turned out to be ODR violations. We no longer build with exceptions disabled.
Good work, some very useful comments as well, please integrate those! I like the nameof nameof: _ _ __ _____ | \ | | / _| / ____|_ _ | \| | __ _ _ __ ___ ___ ___ | |_ | | _| |_ _| |_ | . ` |/ _` | '_ ` _ \ / _ \/ _ \| _| | | |_ _|_ _| | |\ | (_| | | | | | | __/ (_) | | | |____|_| |_| |_| \_|\__,_|_| |_| |_|\___|\___/|_| \_____| 
Also emulates GCC. I'm using it for a C project right now. The team behind it does a great job. If there is a way to let them know, they are one of the most enjoyable open source maintainer teams I've come across.
find() returns an index, which for a contiguous buffer is the same as an iterator
&gt; (including some lesser-known headers like &lt;latch&gt; and &lt;barrier&gt;) ... The Concurrency TS, not C++17. 
Good point about potential issues from ODR violations, but if you are writing and testing an API, it should be able to link dynamically and be lenient about compiler flags and work fine as long as you don't throw across the boundary. Obviously it can create issues with internals so it's not a silver bullet either. Everything that ships a DLL cannot ensure that the code using it will use the same flags, so they make an interface that isn't full of potential ODR violations.
&gt; what's not to like? Don't know yet, but I'm going to work through the link you posted, thanks. 
Yes..and no. Try assigning an integer directly to an iterator. Not gonna happen. You can make it work but the point is that there’s more work involved as opposed to directly evaluating the unsigned int. Just feel like the STL should be more uniform.
I have yet to see good example of std::any - and I say this as someone who uses std::any :p
Interesting, I like the "a thin layer over raw WinAPI", and the results look, what can I say, "the way they should, basically".
Being unsorted, sorted, or partitioned would not matter as underlying implementation would be a for loop which would traverse every element anyway. 
I get that finding a single element is simple, but this could easily cutdown some verbose code. I guess I was just more curious why they decided to leave out find() as it seems like a lack of uniformity across the containers. 
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b3zbby/is_there_any_way_to_read_the_timezone_info_from/ej3jvg8/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Why would you traverse every element of a sorted vector? 
Well yea binary search..you right. But that’s besides the point of my post 
The C++ standard library gives you a bunch of tools you can use as building blocks. It'll be be maybe 4-5 lines of code making your own generic find_in_vector function, that works on every vector and has the exact interface *you* want. The C++ standard library does not include every possible interface for the exact same functionality. That would be an enormous waste in a library that is already rather large. So, just use the provided tools and wrap them the way *you* prefer, then I'll wrap them the way *I* prefer, and none of us has to deal with each others different preferences.
I hear you, just was more curious why it was left out of vector among the other containers. Ima get to wrappin 
For that `memset` needs to take volatile pointer though, which isn't the case.
C++ is all about the strange. Just look at `std::vector&lt;bool&gt;`.
Mistakes were made...
No, it's not. The containers that *do* have a find have so because they are implicitly ordered (e.g. map, set) in some way that makes searching them specialized, or because they have specialized search usage (string). The containers that *do not* have a member find are the ones that can contain data in any order (e.g. list, vector, deque) and where there are *differing* correct ways of searching depending on the content. These different ways of searching are provided as free functions that work identically for *every* iterable collection of data. The same function works for vector, deque, raw array, your own array wrapper etc. So the fact that you have to choose between linear and binary search of a vector is very relevant for why vector doesn't have member find, whereas map and set which have an internal mechanism that should be used for search *do* have a member find.
how about conditional const? (i.e. const( bool ))
Well you'd get a compile error then.
std::distance(vec.begin(),std::find(vec.begin(),vec.end(),thing)); does the same thing but it's a bit verbose. std::find returning an iterator plays nicely with #include &lt;algorithm&gt; algorithms are free functions so they can be used for any container that has the iterator interface. Theoretically, if we have n algorithms and m containers, you'd need to create n*m functions. but if they're free functions, you'd only need n functions and write an iterator for m containers. (n+m) Also, if std::find returned size_t, it wouldn't work with std::list or std::deque 
Insightful, thanks 
I fail to see any example on their site of "beautiful". Also, aside from the automatic layout they offer, I fail to see any "modern" in it. I have written UIs with this style of code back in 1993.
My 8gb laptop cannot survive one more electron based bullshit. please, already stop with this madness.
The problem of creating good looking and modern UI is not the underlying technical implementation. You can use anything under the world for drawing pixels on the screen. But if you are going windows only, just use the UWP. The problem is actually understanding how to *design* the interface. What must be surfaced and visible at every moment, and what must be hidden? I am doing usability studies for my product the last 3 weeks, and no one of my subjects complained that my app is using Electron (I am on the business side, not a programmer so this is not my decision, and trust me, I hate it with passion). However, no one of the subjects could find a critical piece of functionality of the product and they were blocked from using it effectively. That in my opinion is much larger problem with the UI than whether what library was used to create it.
&gt; i haven't used Java for UI in nearly a decade so idk what the situation is there. JavaFX is the new shiny thing. Based on scene-graph and declarative UIs (FXML). Just doing a project with it now and I quite like it. I shudder when I think what I'd have to do with Qt Widgets. Qt also has QtQuick (declarative UIs, etc.), but its documentation is not nearly as half as good as that of JavaFX. Plus all the deployment troubles with Qt(Quick), esp. if you're going to deploy it on osx.
I don't know about uwu, but the title says that uvw is a C++ libuv wrapper. 
Meh you can implement observer_ptr with always inline methods; realistically it is so simple it has trivial impact on compile times (and with force inline will not impact debug performance). So these downsides, again while they sound nice in "general principle" are not very applicable here. It seems hard to believe that raw pointers could disable arithmetic; maybe comparison to 0 but it seems unlikely as well. When that happens I won't be a fan of observer_ptr any more but that day isn't here yet and it may never be. Engineering wise I think observer_ptr is a very clear win.
I really like strong types but here with Object\_ptr advantages seems minimal and personally the name object\_ptr is as good/bad as observer\_ptr, Not sure how many people uses delete calls on raw pointers (except inside abstractions or containers), Anyways we can express our intent directly with object\_ptr here so i think it will be good to have inside library
Comparing to 0, maybe, but even if that were eliminated, you can't remove pointer arithmetic. Raw pointers were overloaded to perform several tasks: owning heap objects, providing views of contiguous memory, and providing views of individual objects. We already have constructed abstractions that do the first 2 and provide some benefits. The benefits for the third case are smaller overall but that doesn't mean it's not worth doing. There are compile time and debug costs but they are extremely tiny (much smaller than something like unique_ptr even, comparable to say std::array). For most of the community those small costs are well worth paying in exchange for increased correctness. Use observer_ptr if compiled in 20 and something else otherwise, is no argument. Types are constantly being added in new standards. Usually the way this is handled (pretty obviously) is simply to get an implementation that works with the older version, and have a conditional type alias (this is what I do for variant, optional, any, ...). What you're suggesting by comparison makes little sense. Again I think you are trying to be too sweeping and general about this instead of focusing on engineering specifics. The desired changes in raw pointers are not likely to happen for backwards compatibility reasons. So if we want to get slightly improved correctness benefits, observer_ptr is the only way it's going to happen. C++ has always prioritized backwards compatibility quite heavily; and surely has never balked at introducing a library type to fix up the shortcomings of a built in feature (e.g. std::array). If you interpret this is as a broken language its your prerogative but that's realistically the approach of the language and that discussion has very little to do with observer_ptr.
There is a financial application made with juce : https://www.youtube.com/watch?v=rVSOvPOqE7w
The first example should probably use \`std::variant\` and \`std::visit\` instead of \`std::any\`. Seems like a better way to demonstrate it.
It's well known that `std::basic_string&lt;T&gt;` is a better vector than `std::vector` itself \^\^ [https://www.youtube.com/watch?v=SDJImePyftY](https://www.youtube.com/watch?v=SDJImePyftY)
libuv has been battle-tested as part of NodeJS for a long time, I guess. Are there any comparable projects using ASIO? 
Testing and development activities runs parallel in this model - [https://www.technolush.com/blog/verification-validation-model](https://www.technolush.com/blog/verification-validation-model) &amp;#x200B; Anyways the post does not say anywhere to test after finding bug. You can always prepare a test plan for complete testing before starting the actual testing depending on project requirements.
std::find could help you here...
The answer is that containers only contain algorithms when it needs some special knowledge of the container's implementation. Otherwise, generic algorithms are preferred. Since the implementation of find on a vector is the exact same as the generic implementation of find, it's not needed.
Until networking is standard and available generally for my target architectures that's a no go for me personally. And using Boost in general is a big no thank you for me as well. Asio on its own without boost *maybe*. Libuv has some enormous pitfalls of api design where failure modes require intense source spelunking as the docs are light at best. For my current work I built all networking systems using Rust and Tokio as a simple c library instead. Could not be happier with that choice.
You can use lower_bound to binary search on a sorted vector
Sounds neat, and the code seems readable enough :) I was used to Java Swing before trying out Qt, so I wouldn't know how easy it would be to use a platform-specific framework, but it seems doable anyway! Do you think the API is so ugly it can't be used with modern best practices (I'm mostly interested in dependency inversion and template patterns) or with a bit of wrapping and headaches it would be feasible?