Do you have any specific project in mind? Also there are hundreds of -dev packages on Ubuntu, do you want us to install all of them? 
there is [OUTCOME_TRYX](https://ned14.github.io/outcome/reference/macros/tryx/)
In simulation (in my specific case, robot simulation), the clock depends on the simulation step and on the time required to apply physics and evaluate the next position of the objects in the world. The simulation clock is completely independent from the system clock, it usually starts at zero when the simulation begins, and it can be faster or slower than the real clock. For example, if the simulation step is 1 ms and it takes only 0.5 ms to simulate it, the simulation clock will be twice as fast as the real clock. The ratio between the simulation clock and the real clock is usually called real time factor (in this example you have a real time factor = 2). In the mean time, in robotics you usually have a control loop (that read the encoders and the sensors and controls the motors) that must run every n ms (in the simulation world, not in the real world). Control loops are usually calibrated on the period. If the control loop does not resume in time, it runs slower than it is supposed to run, and this can lead to instability. Also the result is that you don't have an accurate simulation of what will happen on a real robot.
1. LLVM is a ridiculously common dependency. 2. You can determine what package a file belongs to with Aptitude.
Amen brother, welcome to the fold.
Have a list of common packages, or use the system's package manager to query what package contains it.
You want to introduce into your build system either a redundant list of package names/contents by OS (and the maintenance nightmare therein) or dependencies on the various package managers (and the slightly smaller maintenance nightmare of that)? Lennart? Is that you?
[removed]
Does the "King LEWGI" title come with a fancy hat?
Maybe they've lost theirs already? :-D
Hi! Thanks for the informative and entertaining report! I noticed that you forgot one of the closing angle brackets in this line: auto b = ranges::to&lt;std::vector&lt;int, Alloc&gt;(l, alloc); 
Please stay objective. This kind of comment isn't helpful. Can you provide a technical reason why continuing on contract violation is the wrong approach?
I actually feel that it's a problem, because it effectively means, you are lying to me: I want to find out, i'f the function exists and base some (e.g. overload ) decision on it. So you tell me yes, the function exists, but when I want to call it due to that knowledge, I get an error.
Does aggregate construction via parentheses mean we’ll now be able to use `emplace_back` to instantiate `struct`s in a `vector`?
Others might disagree, but this was roughly my impression: 1) Lots of FUD 2) differing opinions on how modules should work exactly (most of it around the actual implementation rather than the language side) 3) concern that we don't have an actual implementation yet.
Why would messaging and serialization need an account? Especially one where the password is sent over email.
That's a valid criticism, and one that was raised during the meeting. It's one option that allows a program to act the same in freestanding and hosted (a requirement), but to ensure that in freestanding if you actually used anything that relies on exceptions to function the program will be effectively ill-formed. Note that I'm only the one that formulated the possibility, I'm not personally responsible. Can you find a nicer word than "lying" for that case?
If only I'd have known before the meeting; I had an actual crown in the back of my car going to the airport and sufficient space in my luggage.
The build system having to be clairvoyant on modules, some things needing global effect at the build system level, and modules themselves bringing much less than the expected benefit. Plus making it much harder to do distributed builds and creating a much deeper dependency graph due to BMI-to-BMI dependencies.
Yes. That. That's exactly the main motivation of P0960.
Let's turn the question on its head: can you provide an example in where it is the right approach? If a contract has been violated either * everything is fine and the contract is, therefore, lying / useless * something went wrong and continuing is pretending nothing went wrong. Which is never the right thing to do? 
&gt;Considering rust has the same target audience as C++ I don't think so...from what I've seen of Rust it generally works on a much lower level than C++
I agree with you both that I would prefer contract violations to terminate (possibly after invoking some violation handler), and never continue, at least in my code. So I am not a fan of Bloomberg's newest proposal. I wasn't objecting to check_maybe_continue being a bad idea. I was merely objecting to Dragdu's comments suggesting this idea would be the result of brain damage (if I understood them correctly).
Let's not forget this one, 'with exceptions': int get_num(); int add_nums() { return get_num() + get_num(); } 
It sounds like if you want to do check_maybe_continue, you may be better off using some kind of logging facility instead of a Contract.
The one example that I can think of would be unit-tests that verify that certain invalid inputs are indeed caught by the preconditions. Other than that I agree with you though: Actual code continuing after a violation is, politely put, insane.
You can cover terminations with unit tests as well, can't you? GoogleTest even has a death test!
It would still be nicer to have it properly integrated in the framework.
I reserve my right to be flippant, especially in reddit comments ¯\_(ツ)_/¯ Anyway, you were already given the _technical_ reasons why continuing after a precondition failure is a bad idea (hell, it is called "precondition", not "this function works better if"), so I'll expand upon what I honestly think of the suggestion. I genuinely believe that the proposal is serious and well motivated. At least, if you've spent multiple years at Bloomberg, using their homegrown contracts, and have went through [normalization of deviance](https://danluu.com/wat/) for Bloomberg. And I also genuinely believe that it is the duty of the rest of the community to call them out on it.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/ax5xum/help_new_to_c_and_need_some_advice_asap/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Reading his blog. Its very good and easy written
Maybe then we will finally get a complete compile time Candy Crush. https://jguegant.github.io/blogs/tech/meta-crush-saga.html
I forgive you.
I’m glad it will become standardized. It’s a pain having to maintain my own internal branch of libc++…
Here, “you’re lying to me” means that the compiler is doing it, and personally I find “lying” to be too mild of a term. Fucking useless is more like it: it’s silly to expect same behavior between hosted and freestanding implementations. Overload sets will be different: great!
Their working on it.
&gt; Reflect on whether we can design a better networking library with the tools and knowledge we discovered over the past decade. asio was created in a world without lambda, executors, coroutines... And wait another 10 years? That seems pointless. And it too will be out of date by the time it's ready for C++30. The standard library components are not supposed to be these perfect libraries that cannot be improved upon, they should be high-quality general purpose building blocks that fits most use cases. If you have very specific needs you'll use an external library or roll your own anyway.
Yes, his blog is great. Lots of content.
If I were you I wouldn't worry about this too much, but rather put a static\_assert in my code to ensure the requirements. Something along the lines of `static_assert(-1 == 0xffffffff, "not two's complement")`.
Nope https://wg21.link/p0907r4
It's for C++21, right? So for C++17 and below, it's not standardized.
C++20 - but it's in practice not an issue in earlier version either
For C++20 there is a proposal to support only signed 2's complement, [P0907](https://wg21.link/p0907). Here's a sentence from it, but you might want to read it for more context: &gt; To the author's knowledge no modern machine uses both C++ and a signed integer representation other than two's complement. None of MSVC, GCC, and LLVM support other representations.
It's about the hardware, not the compiler. 
The... Burger King crown?!
&gt; Is there any C++ compiler that doesn't use two's complement? The sign representation is property of a CPU architecture. If you target a CPU that uses one's complement, then your compiler has to support one's complement. I don't know any C++ compilers that support CPU architectures that use one's complement, but that doesn't guarantee that no such compiler exists. &gt; So, to do `int32 -&gt; int24` I can just "crop" the int32 and only encode the three low bytes. To convert the 24 bits value back to 32 bits, I can do sign extension (`int32_t(value &lt;&lt; 8) &gt;&gt; 8`). Is this correct? That's not quite sufficient. The behaviour of left shifting a signed integer is undefined if any overflowing bit was set. You can fix this by first masking the top eight bits before left shift. &gt; Or are they so rare that it's not worth worrying about that? They're quite rare. Whether they're so rare that it's not worth worrying about depends on how rare they have to be for you to worry about it. But, "yes" would be a decent guess.
Doing the encoding yourself seems unnecessary. Use a bitfield, and allow the compiler to generate optimal code to extract the components. nb - doing this and playing around with the layout allows to demonstrate that having op in the lower 8 bits gives simpler code.
If you search the subreddit for beginner projects (or the likes), there are plenty of previous threads with ideas. 
Thanks Personally what would you suggest for a 1st time project?
Number guessing game, it's pretty straight forward. 
Make a few polished, to completion projects. Try making a tic-tac-toe game, that not only "works" but is polished and isnt extremely buggy. Bringing projects to completion is an extremely important skill to learn. 
Thank you i will start with that and search reddit for future ones
At the moment, as far as the language is concerned it is not correct to assume two's complement but you can _generally_ expect it to be there in practice (or at least I can't think of a counterexample). [C++20 will guarantee two's complement](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0907r1.html). Note that as of _now_, signed bit shift is UB, so you should probably avoid it. As an alternative, you can always just do the encoding yourself, or use a tagged union of sorts to represent your opcodes internally: ``` struct My_Opcode_1 { uint8_t code; int32_t arg:24; }; static_assert(sizeof(My_Opcode_1) == 4, "that's what we're trying to do I guess?"); struct My_Opcode_2 { uint8_t code; uint8_t args[3]; }; static_assert(sizeof(My_Opcode_2) == 4, "same"); union My_Opcodes { uint8_t code; My_Opcode_1 code_1; My_Opcode_2 code_2; }; ``` Also note that unless your interpreter is supposed to support self-modifying code (in which case the union approach wouldn't work unfortunately, as you'd run into UB) there is no particular reason why your runtime representation of programs necessarily needs to match the "on-disk" format (if you will) of your instructions, so depending on what exactly you're trying to achieve all this worrying about bit shifting may be unnecessary anyway. Ah, also note that just because your instruction size is 32 bit that doesn't mean you're limited to 32 for opcode + args total. You can totally have instructions that say "interpret the next two 'instructions' as arguments to this opcode and increment the IP by 3 instead of 1 when I'm done".
Thanks for the suggestion Do you think that staring with projects is the right thing to do when learning a programming language?
It would have a hat, but the titles associated with the Tooling group voided all hat claims.
I haven't yet audited the library to see where confusing overload / SFINAE decisions may happen. I can imagine someone SFINAE'ing on the get&lt;&gt; extension points for optional and variant. I don't see people getting confused with the various parallel algorithm overloads. There is likely something that I missed. &amp;#x200B; If I find a place with a difficult overload set, it becomes a real choice of damnations. Either you get silent behavior changes when switching between implementations, or you get build errors even when a candidate function would have been fine.
That was one batch of suggestions. &amp;#x200B; Another batch of suggestions was to standardize existing practice and turn throws into something abort-like via the preprocessor. My concern with abort-like behavior at the time was that it was that I didn't want to allow a function to have different semantics based on whether it is freestanding of hosted. However, the weasel wording I posted suggests that, in some situations, the semantics are the same, so long as the implementation can prove that no catch statements would catch the thrown exception.
It could be a bad idea for your hello-world sized application, but it's not for a larger application written by a team of some 100 people. Contracts get broken all the time. It's a fact of life. Deal with it.
Something like a tic-tac-toe playing program ([Min-Max Algortihmus](https://en.wikipedia.org/wiki/Minimax#Combinatorial_game_theory)). It is maybe not the easiest thing as a first project but when you finished this you can maybe start programming a chess playing program which is very much fun.
Thank you 
No, one that my 6-year old daughter forgot in the car.
&gt;Bringing projects to completion is an extremely important skill to learn. 2011 C++ was pretty immature. Every version since then has been, to some extent, completing 2011 C++ in my opinion. Sometimes the best that can be said is: "Better late than never."
Making it a deterministic terminate instead of a throw, when there is no exception mechanisms is "the same" as far as I can judge. The intent of no definition is so that the program and any metaprograms are guaranteed to do the same thing on hosted and freestanding, and if your program anywhere uses exception-throwing functions to not compile for freestanding. Your build server is then able to tell you when you mess up. Especially nice if you also have some hosted tools in the repo that do use exceptions - they can freely keep using them, as long as you don't build them freestanding.
Yeah, I'm a student and the majority of my modules are project based. In my opinion it's best to start a project and if you don't know how to do something you want, Google it and figure it out that way. 
Good to know 
This sounds like one of those rare cases where you might want to use `unsigned int`. Shifting and bit twiddling is what `unsigned` is for. Or, use signed ints, just don't shift negative numbers. Signed shift - for non-negatives - is defined as integer multiply or divide by 2^N, regardless of how the bits are stored underneath. Bit shifting is done on the _value bits_ not on the _object bits_. The value bits are defined by math. 1024 has the 10th bit set, regardless of how it is represented underneath. C++ doesn't actually care how integers are represented, as long as you get the same answer when reading it back as an integer.
I could not agree with you any more, dear sir. OpenCV's api is just horrible.
I am a bit fan of almost-always-auto, even in the case of int foo = 1; which is clearly shorted than the AAA approach, BUT, by just typing a bit more you avoid uninitialized variables and make it crystal clear where variables are declared and initialized: auto foo = int{1}; 
Not sure what you're going for here. All the other approaches listed here require explicit handling of an error somewhere, whereas exceptions invisibly propagate as much as they want to. Quite different circumstance.
Those are legitimate optimizations which happen to expose subtle programming bugs. Can't have it all. And even so, crank up warnings and the compiler should let you know. 
&gt; constraint #2 must work with the existing ecosystem. &gt; =&gt; eliminates: bazel, b2 This is incorrect. You can call any buildsystem from bazel. Similar to Conan - where you have to write a python script to wrap the underlying build system, you can do the same in Bazel. I've seen that most projects are quite simple and can be ported using a handful of globs in Buck and Bazel. In order to port packages to [Buckaroo](https://github.com/loopperfect/buckaroo) we had promising results in transpiling arbitrary build systems to (more or less) idiomatic Buck builds (read: Bazel) by performing semantic analysis using [buildinfer](buildinfer.loopperfect.com). I think maintaining multiple build systems and glueing them together is suboptimal. It may seem like a good solution in short-term but in long-term you are dealing with a lot of complexity and are losing out on many opportunities. Although I don't believe that CMake is a good solution, Vcpkg at least embraces the idea of only having one build-system. ps. why is vcpkg not excluded due to #2? - It only works with CMake
Wut?
[YouCompleteMe](https://www.reddit.com/r/cpp/comments/awlxqu/why_is_cmake_so_popular_and_what_do_you_have_to/) plugin for VIM builds with CMake and I don't recall having any issue with it. Ever.
This is clearly a problem in C++. It actually took me less time to learn a bit of Rust for my microservice than to write everything myself on top of Beast. Some people enjoy that kind of programming (me too!) but sometimes I just need to get something working, and right now C++ doesn't feel like the language for that. 
&gt;We have module **dog** defined in **meow.cpp**! That’s crazy, but completely allowed by the IS! The TR can’t declare the code itself broken, but can request that implementations and tools not support such use cases. Why the hell? That's completely legal, if you want write it, why someone should try to stop you?
An ecosystem built entirely around CMake sounds like the 9th circle of hell!
I would build something on top of SFML. It will be a much more rewarding learning experience! :)
Nobody addresses the question: Are there any C++ compilers that don't use two's complement for signed integers? The answer is either no, or yes: these ... 
That seems pretty arbitrary. Normally you start by imagining something you want to do, not by how you want to do it.
how about using std::bitset ?
Its tutor's requirement so... 
Recently I watched a talk about modern Cmake where the presenter had old and modern cmake code side by side and I thought to myself "it still has the same problems, but there's 30% less typing". I was in the midst of reorganizing a cmake project to have a multi dir hierarchy [like this](https://stackoverflow.com/questions/6352123/multiple-directories-under-cmake) and pulling my hair out to get it right. I switched to meson in an afternoon and couldn't be happier. The current project is now meson + conan and have been delighted with the experience. It gets out of the way, the build is fast by default, the syntax is lite, and code coverage was trivial to setup. Once I found out that meson can integrate cmake libs and everything else I was sold. Try it.
Then I seem to like the 9th circle of hell, cause that's exactly what I'd want, and require from a healthy C++ ecosystem.
As I understand it, the issue is how to locate the definition of `dog` if it is not simply in dog.cpp. If any file can define any module, the system has to scan all the source. Since module source is susceptible to macro replacement, it can't just do a shallow **grep** for the word `module`. It has to do a fairly deep parse, with all the #defines that will be used for the build, and do macro replacement as well as understand quoted strings etc. This is a performance issue that doesn't arise with the #include system. I'm a bit surprised that it's an issue myself, since I'd have thought that even with macros, the parsing would be fairly quick and the real compile-time bottlenecks are things like templates and optimising.
Because there are 2 ways to handle providing module **dog** to users. 1) Have the user provide a list of module &lt; -- &gt; files mapping as part of the build 2) Scan all .cpp files for modules Both of these are terrible for obvious reasons.
Because the tool writers want a simpler problem to solve, and I’m all for it if it means I don’t have to manually define those things. It’s all about what are you willing to give up to make life easier.
I'm surprised by this response since my experience with CMake has been very negative (poor syntax, not reproducible, no proper data structures, inconsistent conventions). What do you like about it? I'm genuinely curious. 
As I understand it, the problem becomes an issue of how easily this can be made to run in parallel. It sounds “simple” when you think about it for one file but what happens when you have 32 independent compiles going on where they all import dog and they all need to do that parsing? Caching? That’s not a hard problem to solve /s
You could use CMake instead. It’s not perfect, but a much more sane way to describe a C++ project.
As someone who doesn't write computationally-intensive code so I don't care much about performance in my use cases, I wonder if virtual call overhead of std::polymorphic\_allocator is still relevant to people who do care about performance.
Use Cmake. Add a CMakealists.txt with add_executable(app1 app1.cpp) add_executable(app2 app2.cpp) ... 
It's quite simple: CMake has become the *de-facto standard* build system for C++. Some might try to argue that there are N build systems out there, and consolidaton still has to happen. No; it has already happened. CMake is what most C++ projects support, and thus all new projects *should* support. This way, it brings consistency to building. If there's one thing that needs to be avoided is a whole bunch of build systems that all try to compete, but all together utterly befuddle end users. No one wants to build a complex project by having to integrate N different build systems. CMake is the answer, due to the reasons outlined above. Also, "modern" CMake is actually really, really nice. Not without its warts and issues, but lots of inconsistencies and ugly parts are being cleaned up (mainly by adding new functionality, but that's how C++ does it, too). I strongly suggest to take a look at the "modern" subset of CMake, and *only* use that, ever. Also see [this](https://crascit.com/professional-cmake/) excellent book.
Have you tried Hunter?
As an addendum: I really like *vcpkg*, and think it's by far the best package management system out there, currently. Wins over Conan hands-down in my opinion, also because it avoids the public federation mess that you get when you let a "community" have lots of potentially competing packages of highly varying quality.
Isn't the layout of bitfields terribly underspecified?
I am aware of modern CMake, and it does not fix the fundamental issues. I agree that it is the most common build system. I use CMake _despite_ the issues when I need to write something for people committed to CMake. In my experience though, the major libraries all have build scripts for other, better build systems. For my own projects, I can just use those and side-step the madness! We also need to think about how CMake impacts C++ as a whole. It is much easier to get started in other languages, in part due to the issues around CMake, and that has to be hurting C++ long term. 
Just because you're used to it doesn't mean it's good for you. I swear I become a cmake expert for like a month, move on with life for a while, and then come back to the same thing I wrote and find myself struggling to add to it. I've had enough and switched to meson and I couldn't be happier.
&gt; The behaviour of left shifting a signed integer is undefined if any overflowing bit was set. In `int32_t(value &lt;&lt; 8) &gt;&gt; 8`, value is a unsigned int. Thanks for the information! 
The best practice is contributing to an open source project
That was why I always avoided it, thinking its not the best at anything, but maybe its actually the best at mixing high and low level.
&gt; C++ is really ideal for learning canonical CS I don't think so, at least not usually. I'm a big fan of C++, but if you're trying to use it to teach canonical CS concepts, you're going to spend a lot of time explaining things like why the only pointer types that `ostream.operator&lt;&lt;()` is specialised for are char and void. Or what argument dependent lookup is. Or, (soon) what the relationship between a namespace and a module is. Or (taking a recent question from this sub, IIRC) what `std::endl` actually does and why you shouldn't use it. My basic point is that C++ is a great language but it's too large to use as a vehicle for teaching CS basics, as it would force you to divide the students' attention between CS basics and the C++ language itself.
Pretty much. There's two issues: the ordering of the fields and the possibility of unwanted padding. In end, you wind up with the same problem as before, that you can't guarantee your code will work on all compilers and platforms.
First of all, you're _definitely_ not clear on _all_ C++ concepts. There are people who can say that, but none of them could accurately self describe as lacking practice. Now, if you want practice there are two good ways to go about that: Either try building real things from scratch, or try participating in some existing project. There are advantages and downsides to both approaches, so you should probably do a mixture of both. Basically, the way to "practice" is "praxis".
This reminds me of the "export" keyword that was introduced too quickly, without really thinking about how it would be implemented. It was not supported by many compilers, and then dropped. Clearly, not enough thoughts were put into Modules. 
By this argument we never should have moved off of autotools. It was the de-facto standard build system after all, pretty much everything used to use it.
Thanks , yes I think you are right I maybe not clear in all concepts....can you suggest how do I participate in projects I mean resources.
Cool thanks can you suggest some resources to contribute in projects
macOS primarily. For anything that is specific to Linux I use Ubuntu
1. Find something you're interested in. Maybe it's even some tool you're already using. Should be open source, otherwise this doesn't work. 2. Find out where it's hosted (most likely GitHub nowadays, but can be other places like sourceforge, gitlab self-hosted depending on the circumstances) 3. Find open issues (GitHub and Gitlab have integrated issue trackers, some projects run with their own 4. Find something on there, ideally something where some contributor said something along the lines of "this should be easy enough to do, but I don't have the time to do this at the moment" 5. Do that thing (most projects will have contributing guidelines and things like that, follow them. Also look at things like recently closed pull requests to see what the project owners expect contributions to look like). 6. Submit your contribution 7. Get rejected for reasons X, Y and Z 8. Fix X, Y and Z 9. Resubmit 10. Go to either 1. or 4. depending on your personal preference
Google "modules dead on arrival"
Why, precisely that! Don't you find the lack of verbosity and sheer clarity of this solution incredibly appealing? Of all solutions presented, this is the only one that stresses the business logic (_such as it is_), rather than dedicating the majority of its code to something that might very well never happen. It is also the only solution that uses zero cycles for error handling on the non-error path. If you are comparing so many error handling solutions, surely this one should be there as well? 
I don't buy this argument - if a project doesn't have an adequate warning level turned on or doesn't treat warnings as errors, you have a much bigger set of problems. Better train muscle memory to use \`const\` where possible.
If *value* is 24 bits unsigned data, it fits into int32 without any conversion, no? Or do you mean it is *24 signed bits* stored in an unsigned variable? Why not represent the instruction like: struct instr{ int32_t opcode : 8, arg : 24; } Then the compiler knows it is 24 bit signed and will handle sign extension for you.
Correct me if I'm wrong, but as far as I know, the issue is deeper than that. \*There is no mapping specified in the IS\*. This means that an implementation could only allow the \`dog\` module inside a \`dog.ipp\`, and it would be completely valid. I'm thinking about the default GCC mapper there, which try to stay simple. &amp;#x200B; However, this may differ from what is recommended in the TR. I think build2 supports the arbitrary mapping.
Considering that nobody here isn't aware that exceptions exist, and the use case for explicit encoding of potential failures include cases like "failure to handle this is catastrophic" or "predictable performance is needed on all code paths". Also, it's quite often an error to assume that error handling is _not_ part of the business logic. 
I hope it should be eventually be the case. AllocT is just devirtualization for the poor.
&gt; Why the hell? That's completely legal, if you want write it, why someone should try to stop you? Because now modules have to accommodate an incredibly rare and senseless use case that has consequential performance implications.
Oh sure! But there's no need to worry about that if the values are internal, or if you're targeting a single platform. You can wait until you need to read data serialized under one ABI under another ABI. 
To be fair there are other parts of the language that have the same issues. Singling our modules is a bit sensationalist. 
Create a project and do stuff
You should've stated it in the original post... but still.
Completely agree. I recently switched company going from a C++ code base to Java. I wish there was C++ with gradle / maven! &amp;#x200B; C++ feels better in terms of language features but falls behind on the tooling -&gt; productivity.
Never tried to mangle anything to be honest; does it have to do with the choices of substitutions?
I've yet to ship production code in Rust, but so far my experience has been that it's not so terrible to learn as people say it is. The borrow system takes a bit to get used to, but it took us all a bit to get used to pointers at some point, right? 
When you want to be your life easier, just don't write such a thing -&gt; ta-da your life is easier. Really, don't expect compiler to "navigate" you what is good is and what is wrong, it's not a coach, teacher or something as is, neither static analyzers. Programmer should "think" that's one of its main purpose. 
Look, this group is filled with postings about the presumed evils of exception handling, and methods that we are supposed to believe are 'better'. If you told me that the majority of people here would rip exception support out of the language today if they could, I would believe you. In fact the committee is in favor of removing exception handling from STL, even if that comes at the incredibly steep price of having an automatic abort on OOM. So please, do forgive me for occasionally saying something positive about it. Just so we are all aware that some people actually _like_ exception handling. Let me be perfectly clear: all the solution presented in the first post, in my humble opinion, are *crap*. They obfuscate, blow up your source size, and add to your runtime overhead. The solution with exceptions is none of these things: it is perfectly clear what is happening, there is no code beyond what is needed to do the actual work that is necessary, and there is no cost on the non-exceptional path. &gt;predictable performance is needed on all code paths The standard does not make any kind of predictability guarantee. Your compiler might generate code that is somewhat similar in its performance characteristics between runs (unless your code got swapped out under a heavy load, in which case you can say goodbye to that as well) - but it would do that for exceptions as well, you know. 
I was feelin' it, then I saw the nonsense that is split_at_mut and noped the fuck out
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/axa0ia/what_is_the_best_c_book/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Then maybe you buy the consistency argument ``` using myint = int; // actual type on the right auto a = myint{42}; auto b = std::unique_ptr&lt;int&gt;{42}; // could have used make_unique but this was to show how types align ```
&gt; The current project is now meson + conan I couldn't find any examples of integrating conan and meson. Do you know of any? The conan doc describes only how to build a conan package with meson. But how do you use a conan package in your meson build?
meson + conan pretty much gets you to gradle/maven experience. Would you say your application is more web/control plane focused vs data plane?
Because it's not the only instruction in my VM, it's just one of them. Most instructions require one or more `uint8`(for register), while some will use a single `uint8` + a `uint16`. etc. I'm trying to find a struct representation that I like and that would work just as well (=be just as fast) as bitwise operations, but it's not easy. For a starter, I don't think I can use methods too much in the core loop of the interpreter (unless I can guarantee that they are inlined) to avoid calls when executing instructions, so that severely limits my choice.
Ouch.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/axa6zd/i_need_some_help_with_hackerrank_problem/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
/r/cpp_questions is a better place for questions like this. Also, it's hard to read your Makefile -- use the "code block" button instead of inline code, or in markdown add four spaces before each line. Then it would look like this: SRC_DIR := ./src CC = g++ CXX_FLAGS = -Wall OUTPUT_DIR := ./bin SRC_FILES := $(wildcard $(SRC_DIR)/*.cpp) BIN_FILES := $(patsubst $(SRC_DIR)/%.cpp, $(OUTPUT_DIR)/%.o, $(SRC_FILES)) all : $(SRC_FILES) $(CC) -o $@ $^ $(OUTPUT_DIR)/%: $(SRC_DIR)/%.cpp $(CC) -$(CXX_FLAGS) -o $@ $&lt; I think the problem comes down to those last two rules. Normally you'd write something like this: # The "all" command (default since it's first) is to build "program_name" in the output directory all : $(OUTPUT_DIR)/program_name # How to build any given object file from a specific source file: $(OUTPUT_DIR)/%.o : $(SRC_DIR)/%.cpp $(CC) $(CXXFLAGS) -c $&lt; -o $@ # How to Link the executable from the object files: $(OUTPUT_DIR)/program_name : $(BIN_FILES) $(CC) $^ -o $@ That's a good start, at least. Your Makefile didn't specify the executable name, so I assumed one. `$(CC)` is actually the C compiler, you should be using the `$(CXX)` variable instead. And you probably want to generate the header dependencies using the `-M` family of switches to g++. And there's other improvements that could be made along the way. If you have any troubles, `make -n` will show you what commands it would run, which is very handy.
Why do you use conan, instead of using wrap?
Thanks! I'll adjust the example following your suggestion.
Oh, you are right! Both \`format\_to\` and \`format\_to\_n\` are included - which is nice.
:o Nice, well I guess I didn't find anything new :')
KDE has a lot of interesting C++ projects
I don't remember using autotools under Visual Studio.
How so? No doubt you are right but I see the `format_to` in proposed wording in [P0645R0](http://wg21.link/P0645R0).
That's no reason to make the problem worse.
Yes, it has to do with namespace "shortcuts". E.g., if you are defining function "func" in namespace "namespace" (i.e., namespace::func()) and the first argument to the function is of a type that also belongs to the namespace, e.g. "namespace::type", then the namespace portion of that type is not encoded as a string, but as a reference to the same namespace that func belongs to. But nothing prevents you to encode it as a string like all other symbols. So, if you are particularly perverse, you could totally generate mangled symbols that demangle correctly but don't match what g++ produces.
Last time I tried meson the VS integration was very poor. Did something change in that matter? I don't want to desert the IDE and all the goodies that come with it. Also, I did not like the defaults meson provided such as build types - release did not generate symbols and debugoptimized (or something like that) was only -O1. Is it still the same?
Isn't it mostly aesthetic?
Wouldn't you end up with all those problems regardless, of how modules where specified? Also regarding dependencies and parallel builds, I don't seethe situation is worse than today: With today's `#include` mechanism, the compilation of my source code depends on the compilation of all the other source code I copy pasted in front of my code. The only difference is that the results of compiling the code can now be reused, but no one is actually forcing you to do that.
Agreed, very good documentation and approachable tutorials
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ax98gc/what_to_practice/ehs8v06/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
here you go. You need meson-0.49.0 and conan-1.10. &amp;#x200B; I should make an example build repo. &amp;#x200B; \`\`\` tabs=4 **ppetraki@vanguard**:**\~/Sandbox/krillia**$ cat conanfile.py from conans import ConanFile, Meson class KrilliaConan(ConanFile): settings = "os", "compiler", "build\_type", "arch" \# ("", "") requires = "gtest/1.8.1@bincrafters/stable" generators = "pkg\_config", "ycm" default\_options = {"gtest:shared": True} def imports(self): self.copy("\*.dll", dst="bin", src="bin") # From bin to bin self.copy("\*.dylib\*", dst="bin", src="lib") # From lib to bin def build(self): meson = Meson(self) \# conan is shadowing these meson parameters... args = \['-Db\_coverage=true'\] options={ 'warning\_level': 3, 'cpp\_std': 'c++1z'} meson.configure(args=args, defs=options) meson.build() \# XXX probably move all makefile magic to here meson.test() meson.test(targets=\['coverage'\]) \`\`\` &amp;#x200B; \`\`\`tabs=4 **ppetraki@vanguard**:**\~/Sandbox/krillia**$ cat meson.build \# vim:ft=meson project('kbs', 'cpp', version : '0.1.0', \# these are overriden by conan so make sure you make changes \# in both places or you will be "surprised" when you run meson \# without conan harnessing it. default\_options : \['warning\_level=3', 'cpp\_std=c++1z'\] ) libopenssl = dependency('openssl', version : '&gt;= 1.1.0', required : true) \# provided by conan libgtest = dependency('gtest', version :'&gt;= 1.8.1', method : 'pkg-config', required: true) include\_dirs = \[\] include\_dirs += include\_directories('kbs/src') link\_flags = \[\] cpp\_flags = \[ '-Wall', '-Wextra', '-Wshadow', '-Wnon-virtual-dtor', '-Wold-style-cast', '-Wcast-align', '-Wunused', '-Woverloaded-virtual', '-Wpedantic', '-Wconversion', '-Wsign-conversion', '-Wmisleading-indentation', '-Wduplicated-cond', '-Wduplicated-branches', '-Wlogical-op', '-Wnull-dereference', '-Wuseless-cast', '-Wdouble-promotion', '-Wformat=2' \] cpp = meson.get\_compiler('cpp') add\_project\_arguments(cpp.get\_supported\_arguments(cpp\_flags), language : 'cpp') add\_project\_link\_arguments(cpp.get\_supported\_link\_arguments(link\_flags), language : 'cpp') &amp;#x200B; \#... and the rest is standard meson stuff \`\`\` I drive it with this makefile. Oh, I just found a bug with my compile\_commands.json symlink :) Thanks! \`\`\`tabs=4 **ppetraki@vanguard**:**\~/Sandbox/krillia**$ cat Makefile TOP=$(shell pwd) CURRENT\_BUILD=${TOP}/current-build \# the release profile is named 'default' for conan, probably should change that. BUILD\_PROFILE= BUILD\_TYPE= \# map build types to conan build profiles ifeq ($(MAKECMDGOALS), debug) BUILD\_PROFILE = debug BUILD\_TYPE = debug endif ifeq ($(MAKECMDGOALS), release) BUILD\_PROFILE = default BUILD\_TYPE = release endif BUILD\_DIR := build-$(shell echo $(BUILD\_TYPE) | tr A-Z a-z) \# just describe the project and exit if we don't target a build ifeq ($(BUILD\_PROFILE),) all: info endif .PHONY: header header: @echo "BUILD\_DIR $(BUILD\_DIR)" @echo "BUILD\_TYPE $(BUILD\_TYPE)" .PHONY: info info: conan info . clean: rm -rf build-\* tags current-build compile\_commands.json .PHONY: tags tags: ctags -R kbs .PHONY: build\_dispatch build\_dispatch: mkdir ${BUILD\_DIR} || : rm -f current-build &amp;&amp; ln -sf ${BUILD\_DIR} current-build conan install . -pr ${BUILD\_PROFILE} --install-folder ${BUILD\_DIR} ln -sf current-build/build/compile\_commands.json ln -sf ${BUILD\_DIR}/compile\_commands.json conan build . --build-folder ${BUILD\_DIR} .PHONY: debug debug: header build\_dispatch tags .PHONY: release release: header build\_dispatch tags .PHONY: check check: clean make debug make release .PHONY: coverage coverage: cd current-build &amp;&amp; ninja coverage .PHONY: coverage-html coverage-html: coverage xdg-open file://${CURRENT\_BUILD}/meson-logs/coveragereport/index.html .PHONY: coverage-report coverage-report: coverage gcovr ${CURRENT\_BUILD} \`\`\` 
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ax8hiv/question_about_makefiles_how_to_compile_multiple/ehs8x2t/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ax8mu5/project_with_6_classes/ehs8xsq/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The following will do what you want: SRC_DIR := ./src OUTPUT_DIR := ./bin CC = g++ CXX_FLAGS = -Wall SRC_FILES := $(wildcard $(SRC_DIR)/*.cpp) BIN_FILES := $(patsubst $(SRC_DIR)/%.cpp,$(OUTPUT_DIR)/%,$(SRC_FILES)) all: $(BIN_FILES) $(OUTPUT_DIR)/%: $(SRC_DIR)/%.cpp $(CC) $(CXX_FLAGS) -o $@ $&lt;
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ax7bfb/suggest_projects_for_noobs/ehs92vw/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I don't hack on Windows so I can't speak to it at all. They might plan it some day but if this bug report is any indicator it isn't very high on their todo list. https://github.com/mesonbuild/meson/issues/668 Does VS have an API where we can do this as a plugin. "It can't be that hard" :-p 
This does not look very ergonomic... I don't think this is a serious equivalent to Cargo. 
 I never even heard of it wrap until now. Can you please give us the elevator pitch?
If you dump my makefile driver and all my compile flags the only work that's left is file lists and targets, and that's pretty trivial.
Given that it's been in development for 10 years and there are two implementations of closely related variations at Microsoft and Google, I'm pretty sure plenty of thought has gone into it. Maybe, just maybe, it's actually a really hard problem ...
Not having a wall of text may let you see this kind of stuff: &gt; genz.exe 14 /Users/brian/onwards/example/example.mdl &gt; 14 is an account number. Substitute your account number there. Code generators are the devil. But code generators that requires an account to use, will break when there is no network and will let you down when the guys goes out of business? Makes absolutely zero sense. 
I've only seen Conan before, will give them both a more thorough check. Tbh part of my productivity increase might be from moving from Vim to IntelliJ as well. This is my first time Javaing professionally so the code completion / inspection hints from IntelliJ has been invaluable. Both applications are algorithmic trading system but the former had a significant low latency focus while the later does not. So yeah you could say a data plan to control plan. Not sure what impact it has though, I still write message based event sourcing code because the performant code is also clean code.
MSVC's product documentation is quite extensive but can be found here: https://opdhsblobprod01.blob.core.windows.net/contents/8ee155eb21834b65814ae67f4da97bf3/8bba2b6b8495c8ea06dd809170531dc5?sv=2015-04-05&amp;sr=b&amp;sig=mxUWZQSr5uLe5zmolZ7Ho9M7mOmn3jIpcpE7Hz%2FPP%2BM%3D&amp;st=2019-03-04T18%3A47%3A08Z&amp;se=2019-03-05T18%3A57%3A08Z&amp;sp=r You will want to reference page 752 which outlines how registers can be used in a way that avoids conflicts between the compiler and inline assembly blocks. There's a lot of stuff to go over in there but some tidbits include MSVC allowing the use of the following registers without the need to preserve or restore their values before/after an inline assembly block so long as they are used within a function that isn't marked as ```__fastcall```: EAX, EBX,ECX, EDX, ESI, or ED Lambda expressions in C++ use ```__thiscall```. In effect what this means is that if you have an inline assembly block that makes use of those registers, the MSVC compiler will ensure that by the time you enter that block those registers do not contain any data that needs to be preserved when the inline assembly block completes.
Having a GPS for code is helpful and something to be encouraged these days. I've gone to great pains to script my entire vim configuration + YCM so I'm not stuck with just ctags when I'm on a foreign machine. The reason I asked is I was trying to gauge whether the easy availability of that enormous library java has available at your finger tips was the over ridding factor. It doesn't appear to be. I admit I haven't built enormous software with meson yet but seeing that it's at the core of RH with systemd, parts of gnome, and meson works in Eclipse, where IBM owns both. I think it has legs.
The reason why include model works is that it has been standardized _de-facto_, even though it isn't standardized _de-jure_. 
upvoting because thanks for the report! (personally i'm in the "no no no no, please just standardize the package manager" fraction)
I don't know what you mean by a static package. Anyway, as I cannot investigate the problem by touching your machine, it's hard to give an efficient piece of advice. Likely a seasoned CMake user around you can solve this issue rather quickly. If it's hard for people around you, I would first contact the dev team who wrote the software you are installing, then the Ubuntu dev (or Debian dev if you are using it). Some more technical suggestion I can give is to install LLVM (that's what's missing, right?) on your own. See [here](https://llvm.org/docs/CMake.html) on how to. Then you can pass LLVM's CMake config file or perhaps the build dir to the software you are trying to install. The danger is that the software is naively written, and then there can be a conflict with the system llvm... Therefore, I'd install the LLVM with the exact same version found on the system. Anything else requires much more information.
This has been carefully measured as neglectable by John Lakos's team (recalled from one of his conference about polymorphic memory allocators). 
&gt; 1) Have the user provide a list of module &lt; -- &gt; files mapping as part of the build This doesn't sound terrible at all. Plenty of languages have worked this way for a long time, even to the point that they use this mapping *instead of* C++'s `import`s. I strongly suspect that the conventional wisdom for modules will eventually follow that for listing files for the build system- just maintain a list, don't try to glob or otherwise do anything fancy.
Is C++20's [`clock_cast`](https://en.cppreference.com/w/cpp/chrono/clock_cast) possibly helpful here?
Gonna install this and start using it as soon as i get home tonight
It's called INTERFACE in CMake. You do add_library with the INTERFACE keyword and then add_include_dirs the installation directory (again with the INTERFACE keyword). This registers a header-only library target. Then you expose the target in the CMake config file that you will install using whatever command I never manage to remember. Many first timers need big effort to do it right. It's a pity Kitware is not known for perfection on documentation...
Which c++ library have you used to build the Twitter bot?
&gt;The reason I asked is I was trying to gauge whether the easy availability of that enormous library java has available at your finger tips was the over ridding factor. It doesn't appear to be. Ah yes a very good point. Maybe I am missing out, I feel like I need a good reason to include something though and understand that library before using it. I think there has been a few instances when it has helped but not by much.
None. It's written in Go [https://github.com/therocode/CppCompilerCompliance](https://github.com/therocode/CppCompilerCompliance)
https://stackoverflow.com/questions/12276957/are-there-any-non-twos-complement-implementations-of-c
Paraphrased: "Now that Modules has been merged, I'm excited to see that there is interest in figuring out how to use them!" This \*really\* seems backwards. There should have been some effort put into "how to use" during the implementation phase, or even during the design-sketch phase. Assuming you can shoehorn "useability" into a completed design at the last minute sounds like a fast path to failure.
It's not our own lives that we want to be easier. It's the lives of the tool developers which have to consume the module's feature. The harder their life is, the less awesome our tools are.
In the '80s and '90s that was probably true. Since the mid-2000s, but definitely the 2010s, that's no longer the case. I'm not saying nothing could ever succeed CMake, and CMake will stay dominant for all eternity. I'm just saying that in this day and age it's rude *not* to offer CMake support. Being "hip" with some alternative niche build system just inflicts pain onto a user base accustomed to using what's the common and sensible thing to use.
What languages?
Singling out a feature that, until very recently, was not part of any upcoming standard, which has the potential to make everyone who deals with build system's lives worse, is not sensationalist.
Then you're certainly doing CMake wrong. At least for 95+ percent of use cases (adding source files, dependencies, and compiler options for a target, in a cross platform manner), using CMake is a breeze.
&gt; transition to containers without an allocator template parameter? Genuine question. Why? You don't even have to know that it exists unless you want to use custom allocation scheme. &gt; custom memory allocation in terms of being more reusable and compatible with STL containers due to a standardized interface `std::allocator_traits` has pretty much all of this. IIUC `pmr` is built for different purpose. E.g. dynamic dispatch (type-erased allocator) that it uses allows to have a container of containers with each using different memory allocation scheme. With an allocator being a template parameter that isn't possible (maybe possible with type-erasing the container?).
the fact that you can do it wrong is a red flag for me.
&gt;the major libraries all have build scripts for other, better build systems "Other" and "better" is always in the eye of the beholder, and I would disagree. The real pain, however, starts when you want to put some dependencies together in a "one command builds all" from-source build, and your dependencies use build systems A, B, C, and D. Good luck! Then you wish everything just used CMake, and it just works(TM)! &gt;We also need to think about how CMake impacts C++ as a whole. I think about that. In particular, I think it's improving the ecosystem significantly.
While TR gives some hope we won't see module cthulhu in pajamas.cpp, I'm still worried about standartization process where standard only defines "rectangle with rounded edges" and all the real stuff happens in non-mandatory papers.
Well, then you shouldn't write C++ code either. Heck, you shouldn't program in any language, cause I'm sure regardless which language it is, you can certainly do it wrong.
Or: 3. Find out during the build which file provides `dog` and make it Just Work™. This is what CMake does for Fortran and how C++ modules are going to work.
Scanning is embarrasingly parallel. The compiles might not be anymore, but accurate scanning means it is no more contentious than your actual code complexity.
I think I have about five years in cmake and have never really found it intuitive to use and more expense to debug than it's worth. I want to debug my code, not the build. Cmake has a lot of complexity and it's "best practices" are a off by one character away from an empty variable and no error message until you're half way through the build, if you're lucky. I've had enough.
The TR won't require that at all. For build systems which won't support `export module cthulhu;` in `pajamas.cpp` right away, this might be a reasonable restriction. But it isn't required (and CMake will work just fine with the `cthulhu`/`pajamas.cpp` case).
It's funny -- I almost(\*) never had issues debugging CMake files (that I wrote); using `message()` judiciously takes care of most of your debugging desires. (\*) I can think of one exception in the last few years (actually, just a few weeks ago), but I've made peace with CMake again quite quickly. For the most part, I do find it intuitive.
I think one thing missing here is that the TR will likely have a "gold standard" to strive for from build systems for module support. The bulk of the document will likely include a "transition" guide. Build tools, however, should *not* be complacent with the transition support from compilers. Things like "module name == base file name" and: &gt; The Ecosystem TR can specify exactly how that import is resolved. are not easy for the compiler implementors. The bits needed for "gold standard" is *much* lower on compilers and likely to be available first. Yes, build tools may need to be more complicated, but compared to a compiler doing forks of itself for shadow BMI compilation and caching, it's *way* simpler (e.g., POSIX `make` has the facilities and we have a patchset for `ninja`). &gt; The TR can’t declare the code itself broken, but can request that implementations and tools not support such use cases. I'd say absolutely not. Tools might declare that they don't support it, but I expect such tools which don't get with the times to be dropped in the long run. Compilers should certainly support this (in fact, they already do).
eh, I expect that it doesn't hurt performance in any direct sense, but there's still a cost there on terms of space (since it makes every container bigger in order to store the pointer) and that might lead to worse performance due to reduced locality, etc. I think it's probably very small but there are people who care about that.
Now that says a lot about C++ doesn't it? 😄
Fixing problems in the standard which existing code relies on is very hard. Fixing problems in brand new features which nothing relies on yet is much easier.
I'm currently trying something along thoses lines. It looks like this for now: struct UnaryInstr { std::uint32_t value : 24; }; LLVM_PACKED_START struct BinaryInstr { std::uint8_t a; std::uint16_t d; }; LLVM_PACKED_END struct TernaryInstr { std::uint8_t a, b, c; }; struct StructuredInstr { // Opcode common to all instructions std::uint8_t opcode; // Representation of the last 24 bits dependent on // the kind of the instruction union { TernaryInstr ternary; BinaryInstr binary; UnaryInstr unary; }; }; static_assert(sizeof(StructuredInstr) == 4, "StructuredInstr not 32 bits"); static_assert(sizeof(UnaryInstr) == 3, "UnaryInstr not 24 bits"); static_assert(sizeof(BinaryInstr) == 3, "BinaryInstr not 24 bits"); static_assert(sizeof(TernaryInstr) == 3, "TernaryInstr not 24 bits"); union Instruction { // Raw representation std::uint32_t raw; // Structured representation StructuredInstr instr; }; But it doesn't work, UnaryInstr isn't 24 bits, it gets padded to 4 bits directly. Even if I put the bitfield directly in the union, it won't work. Is there any way to force UnaryInstr to be 24 bits/3 bytes?
That it's not the appropriate tool for small twitter bots/web scrapers? Yeah sure, Go can have that one
Probably not. *Maybe* some compiler extension. And that construct is likely to give you endian problems as well. Bitfields suck when you have different endians
Yes, but only if you grow the appropriate mustache. [Luigi Hat](https://www.halloweencostumes.com/child-luigi-hat.html)
It's only been alive for a couple of hours and it's already got a bigger Twitter following than me :(
&gt; And that construct is likely to give you endian problems as well. The 24 bit bitfield? Is there any way to solve this problem or will I have to live with it?
This is such a common misconception, and a bit of a cheap point. C++ is error prone because it must give you low level control for performance and integration reasons. There is no reason for a build system to be error prone or unsafe like this. 
The [hackathon environment](https://hackumass.com/) really shows how hobbled C++ is out of the gate. I've mentored here... for a while now. They get really excited over C++... and then they get to the "I want to find and use stuff" phase and then fall flat on their face, even with IDEs like VS and Eclipse. They then switch gears into golang, rust, node, or Java and start chugging. It's a real problem. This year I'm thinking about doing a workshop on how to get started with C++ using "a package manager" (probably conan) and "a build system" (meson or evoke if it gets library discovery) that is something they can grok and make use of in an hour. Prepackage it in a docker image so they can just go. The sample set is over 500 kids now so it'll be interesting to see how many take up the challenge. If we want to stay expert only I fear we may end up in the same boat as "I need to find a Vxworks engineer" 10-20 years from now. Concerning "message()" yeah sure, just like linux kernel. You would think by now with this whole "object model" that IDEs would actually be able to inspect all of these cmake "objects" and tell us what's in them or where they live by now? There's also this universe of cmake scriptlets to enable all these amazing features that only a google search away, depending on the time of day or your google fu. Vim has better plugin management than cmake! Those paper cuts add up into real losses in productivity and that kills value. In a startup, I'm not wasting my time on that.
Well there are objective measures we can use. For example, speed of incremental builds, ability to cache across a network, sanity of the build script DSL. This is not just "in the eye of the beholder". I'm willing to bet your entire project tree is not CMake by default either (just an example, OpenSSL https://github.com/openssl/openssl). So you are hunting for build scripts or manually gluing things together either way. 
Semi-related: are there any systems out there (with C++ compilers) with non-8-bit bytes?
Not having any anonymous fields makes it easier to think about what happens, I think. The usual approach to handle endianness, I think is to create mirrored structs and byte swap the data if you are on the wrong platform. And that is not only bitfields. If *d* in your BinaryInstr is written in Big Endian in your binary blob and your platform is Little Endian it will have the wrong value, unless you byte swap it.
We were worried about clairvoyancy and global effects being hard to implement in some build systems from the 70's that we want to keep working for various people and reasons. Part of the resolution is indeed having a compiler with support for not precompiling modules, and the assertion from a second that such support would be likely to be added. That makes it possible for old build systems to keep working. And no; this is not independent of how modules are specified. - If a header being included as a regular header in one place and imported as a module in another is ill-formed, then the build system does not need to care about the global effects. It still might, but at least it's the user's problem if it doesn't. As specified, your build system is responsible for making sure you don't accidentally create ODR violations by virtue of making one include into an import. As far as I am aware (correct me if I'm wrong Boris) no current build system handles this for you at this moment. - Modules need to be found before they can be used. How do you even find a module, given that finding it may be dependent on your compiler version and settings (think macros) ? This could easily have been resolved, but I'm fairly sure this is outside of the purview of the IS and not resolved for that reason. This is why I have a paper for the post-Kona mailing addressing this exact issue for the TR in the hope that we can get some kind of usable mapping out of it. Modules actually do have more differences than the #include and reuse that you mention in your second paragraph. I suggest reading wg21.link/p1103 with respect to parsing contexts to see how modules are actually helping much more than just that.
This would probably never be written to a file. If it's written to a file, it's a local one generated by the interpreter for that machine. It's never going to be passed to another computer. Is this still a problem?
Some languages offer type systems and well designed APIs to enforce correctness. &gt; Well, then you shouldn't write C++ code either. I'm tired of this type of aggressive comments. This just pushes people away that could have made a valuable contribution to the C++ community.
Some languages offer type systems and well designed APIs to enforce correctness. Well, then you shouldn't write C++ code either. I'm tired of this type of aggressive comments. This just pushes people away that could have made a valuable contribution to the C++ community.
Probably not then.
The (relatively recent) one I'm most familiar with is Rust. Dependencies are listed as command-line arguments to the compiler as `--extern library_name=library/path.rlib`, and then the program can use `library_name::item_name`. In practice the user actually specifies this in a `Cargo.toml` build system file as `library_name = "library_version"`. As I understand it, C# also does this as `csc.exe /reference:LibraryName=LibraryPath.dll`, enabling the program to use `LibraryName.ItemName`. Further, unlike Rust and like C++, C# libraries are responsible for namespacing their own contents and so the `library_name=` part is often left out, and you just use `csc.exe /r:LibraryPath.dll`. It's also notable that Rust used to be closer to C++ modules- dependencies had to be imported in the program text as `extern crate library_name`, analogous to `import library_name`. However, because this is redundant with the mapping described above, it was later made optional. C++ could also take this path, if compilers were to introduce a similar compiler option for "auto-`import` this module at the start of the TU."
Modules are strongly based on existing implementations Sure, and if it turns out implementors need to tweak things to make modules work, well then the standard will be updated to reflect that
just because you have to learn how to use something does not mean that it is not made with usability in mind. Modules has been in design phase for years; why on earth would it be an unusable design?
Modules are not analogous to crates, as we can have dotted names in modules, but crates cannot. We then go a step further and have module partitions, which are a whole problem on their own. Additionally, rust's modules are also their namespaces. Cargo takes an rlib, that contains however many modules stored inside. The nice thing that the rust developers do is provide their own rust library format so they can store additional metadata. It would be nice if this can happen for C++, but that would require us to standardize Gaby + Bjarne's IPR format, and then get every vendor to be ok with moving away from the time tested "I put all my object files into another file" format. Which *would* be nice, if I'm being honest.
What? My tongue-in-cheek comment? Should I explicitly add &lt;irony&gt; tags next time? I thought that was pretty clear.
I did a survey of the various build / package management options and I think Buckaroo is the closest to a Cargo experience for C++. It is very opinionated (but so is Cargo)... but if that's what your looking for, definitely check it out: https://buckaroo.pm/
Again, if the proper CMake subset is used, it's not overly unsafe or error prone. The main problem with CMake is not its usability. It's the pretty terrible documentation (at least for *learning* it), and its inability to cleanly break with its past. (I wish it had a backwards compatibility mode that has to be explicitly enabled.)
I do maintain that getting started with using external libraries in C++ is *exceedingly* easy these days. Clone vcpkg, bootstrap it, and bang, you have an easy-to-use, full-blown package manager. It's also pretty well documented. Integration into CMake isn't difficult eiher. You have to be able to follow a few instructions, and learn less than five commands (install, remove, list, ...?). That can be expected from a software engineer, or even a motivated kid. What else do you want? Honest question. (It's probably much more difficult to find the right headers to include, API documentation for a library, etc.) Another remark: For 95+ percent of use cases, you *do not need* any weird CMake scriptlets, or plugins, or whatever. I don't know why I'd really want any of these. In many cases, you just need `add_project`, `add_executable`, `add_library` and the `target_*` commands. OK, and a bit more boilerplate for installation.
Actually, I *am* only using libraries that provide CMake integration. Or, alternatively, maybe installation via *vcpkg*, which provides exactly this.
Referring to the following state end from the linear algebra paper "every rank-2 tensor can be represented by a square matrix, but not every square matrix represents a tensor": Which square matrix would not represent any rank-2 tensor?
These are things you can change fyi
Appreciate the irony tags :) I still think that CMake is error-prone though, whereas I actually found the documentation quite good. A few examples: * Knowing what is a variable name, what is a string and what is a variable substitution. This trips up newcomers and occasionally CMake veterans. * The lack of return values makes even simple manipulations verbose, where they might be a one-liner in a real language. * CMake lists are actually strings, so CMake will let you do list operations on strings. Sometimes, this is what you want, other times it is by mistake. CMake will just keep going! * Managing configuration folders. If you tweak your configuration but build into the wrong build-folder, artefacts won't match up to what you expect, which is very confusing. Modern build systems manage the configuration folders automatically. I am not aware of any CMake linters to prevent people from sticking to the better subset. Most of these issues (and there are more) seem to me to be fundamental to the design. A clean break from the past would be for the community to begin adopting a better system, rather than sticking to a limited subset of a lesser system. 
Modules *are* analogous to crates. Dotted names are purely syntactic, the key here is that modules and crates are both translation units. Rust modules are analogous to C++ namespaces, *not* C++ modules.
There are like four major package managers in use, and it's not hard to figure out which one to use. You're blowing the difficulty and complexity of this *way* out of proportion. 
two of the three oldest comments say 'no'
Sure, there are some remaining issues. CMake is not perfect, but none of these are a dealbreaker for me, by far; if you know a bit what you're dealing with, you're going to be fine. Really. I fully agree that "everything is a string type" was not such a good idea in CMake's design. It rarely constrains me, though, since I have learned this fact once. Lack of return values: yep, CMake commands are not composable -- too bad. I wonder, however, if you really *need* that composability too often in what should be a very simple, declarative language, if used for its main purpose: listing translation units, and matching the right compiler instructions to them. Managing configuration folders: I feel that putting the build into a folder of *my own choice* actually gives me more control and makes everything a lot *less* confusing, compared to some build system deciding itself on where to put things. That's some "magic" I don't really want, and I'm sure lots of subtle issues would arise as a result of that.
Is it core language features only or library features as well? I initially thought this table was (unfortunately) core language features only but it seems it's now library as well, as I can see `&lt;optional&gt;` and stuff on the list?
You should not need to look for -Wall and -Wextra, you can get those automatically by setting Meson's warning level option. The default is 1 that gives you -Wall. It also works automatically converts it to the equivalent arg in Visual Studio.
Don't worry, it will be a great success like the Itanium. The compiler and build process tools will solve all the problems automagically. /s
&gt; Being "hip" with some alternative niche build system just inflicts pain onto a user base accustomed to using what's the common and sensible thing to use. This is the exact same thing people said about CMake when it first came out. Word for word.
&gt; These are trivial UX issues. One, no, they aren’t. We’re just going to have to agree to disagree here. Two, then maybe it’s worth asking why nobody’s done them yet.
Using [outcome::result&lt;T&gt; instead of exceptions and a static factory function](https://wandbox.org/permlink/85ac4TqGIPgvmzZz) makes the code remind me even more about rust.
For getting started, cmake is pretty simple. 3 lines for a hello world project. Adding a 3rd party library (doesn't matter if hear only, shared or static) adds two more lines Where it gets complicated is when you add warning flags for every possible compiler or if you provide dozens of different build options. 
What was the problem when using cmake? Sounds like a two liner could do it (recursively glob for all source files and create an executable from it). I think many people over engineer their cmake files and then complain how difficult it is. That isn't to say, that meson isn't even easier.
What I mean is, for example: printf("Full name: %80s\n", u8"Frédéric François Chopin"); since printf uses the string length as the width, it would print that sample with three padding spaces less than one would like. It would be better to have the width as the number of codepoints. &amp;#x200B;
Excellent report. The notion of std::audio is intriguing, but my general reaction is basically the same as I had to 2D graphics. A vocabulary type to an audio buffer that understands sample rate and format and such makes sense. Putting an API for talking to the hardware, enumerating devices, etc., probably doesn't need to be a part of the language. And sort of playback library could just use a standard audio buffer type. Actually playing the audio doesn't seem like a part of the core language to me. I can only imagine that I'd start playing with it, run into some weird non-portable complexity that arises from dumb ALSA details when trying to pipe samples between an obscure combination like a Bluetooth headset to an AJA SDI card, with an FPGA in the middle. It'd work fine on one OS, but not another, and I'd be stuck with being unable to write portable code using only the core language. OTOH, if there's a simple audio buffer vocabulary type, I can imagine using some platform specific libraries in an eventual ecosystem that work with it to do some of the heavy lifting on the wacky edge case setups.
You should reroll to MonsterRange or something like that :p
I hope MSVC will fill the gap soon. 
Probably both as the library is part of the standard 
C++ modules *aren’t* translation units. They can represent the interface to any number of translation units. There can also be an implementation module separate from the interface, which is used to then create the object file, as otherwise everything would be inlined. The standard does not discuss to what level of granularity a module should represent. A file? A class? Several of these? A whole library or section of an overall library? There is also no relation to these names. `slim.shady` could be either placed in a file adjacent to `the.real.slim.shady` or in another library. They act as a separation mechanism for names to be unique. Rust crates imply that `slim.shady` MUST exist under a module named `slim`. There is a guaranteed hierarchy with rust crates. There is none for C++ modules. Rust modules are a superset if C++ namespaces, but do not have things like ADL attached to them.
The funniest part is also how you have to be careful what functions reallocate and what functions don't. You might think you're copying data to a view but you are actually allocating new data. No difference between owner and view types will also be the source of many mistakes. I'm not saying they needed the bikeshedding `std::span` got, but it could have helped. The lack of functional API I can forgive, that not as much.
The main reason it passed is nobody cares about supporting platforms that have been dead since C++ was invented.
You're still conflating C++ modules with Rust modules. There are of course differences between C++ modules and Rust crates, but none that undermine the sort of mapping I described above.
Agreed. A lot of harm has been done with incomplete understandings or misunderstandings presented was flaws in the modules design. Somewhere else, someone claims with certainty that named modules were not used at all, contrary to evidence. I would like to encourage everybody interested in the intricate details of modules to get in touch to modules implementers to verify things before scraming wolf.
Indeed. I would like to exhort the C++ community to be willing to take a hard look at its existing practice, and strongly resist taking the familiar for simpler. We have a huge opportunity to update our practice.
I am still hopeful that as practice of modules become widespread the resistance to shared format to describe module metadata will significantly lower. For now, the idea is new, so the resistance is understandable. I saw worse with `constexpr` - it was deemed unsound, unimplementable, and you should be scared because it required an interpreter. These days, if your functions aren’t constexpr, they are uncool ;-)
I would be curious to see how all this is relevant to modules.
Actually, cpp as it used to work in the Steve Johnson’s compiler is different from what was eventually standardized in C89.
Contrary to the urban myth, the scan does not need to do to “deep” parse.
Please, do also keep in mind that a lot of internet FUD is being generated and spread about the nature of the issue and how severe it is.
Yes, I was trying to confirm that although unclearly =).
We fully agree that contract violations in new code should never continue and doing so is potentially disastrous. The problem is that turning on contract checking in a large system where the contracts were not previously checked is potentially equally disastrous - your system that was breaking contracts continuously yesterday without noticable downsides is suddenly crashing continuously, costing money and jobs. The big problem is that when contracts enter the language ALMOST ALL contracts are going to be new contracts in old code - and those are the hardest to add and turn on. This applies equally when adding contracts to a library for the first time, or simply changing the 'build level' your production code runs at. None of this is specific to us at bloomberg - every large library and large enterprise is going to have to figure out how to deal with this, or choose not to use contracts at all because of the risk involved.
&gt;Somewhere else, someone claims with certainty that named modules were not used at all, contrary to evidence. Could you point to the evidence you speak of? I'm honestly curious to read real life use cases of modules, as a scientist.
What does "deep parse" even mean? Scanning will require an accurate processing step ( can't wing it ), nothing more - nothing less
I do not believe qualifying the raised concerns of "internet fud" to be the best way to address them...
That's slightly disappointing. I hoped it was compiling from trunk and testing against code samples for each feature.
On Ubuntu and Debian, all the CMake modules (yes, I mean the scripts) in the entire distro are in a single package: `cmake-data`. The dependencies themselves do not ship with CMake modules within Debian or Ubuntu. Some packages have their CMake modules included in `cmake-data`, while others don't. If you try to build something with a dependency in the "don't" category, it simply won't build, full stop. 
On Ubuntu and Debian, all the CMake modules (yes, I mean the scripts) in the entire distro are in a single package: `cmake-data`. The dependencies themselves do not ship with CMake modules within Debian or Ubuntu. Some packages have their CMake modules included in `cmake-data`, while others don't. If you try to build something with a dependency in the "don't" category, it simply won't build, full stop. 
As far as I know, no current C++ compiler compiles to a platform that uses anything other than two's complement. More importantly, the fixed-width integer types from `&lt;cstdint&gt;` (`Int8/16/32/64_t`) are required to be two's-complement if they exist[^1](https://en.cppreference.com/w/cpp/types/integer). So if you use those you'll be golden (or get a compile-time error if your system doesn't support 32-bit 2's complement integers).
&gt; Some more technical suggestion I can give is to install LLVM (that's what's missing, right?) on your own. See here on how to. &gt; &gt; LLVM is *not* missing. Only its `,cmake` config file is missing. 
Nothing that depends on Qt5 will build on Debian (although Qt4 will work). This is in spite of the fact that Qt5 is in Debian, along with its dev packages. 
you can use offscreen mode when run qt app in container. Just set QT_QPA_PLATFORM=offscreen.
That seems like a pretty serious oversight for the distro. I'm not entirely sure, because I have never encountered that. In my experience, including projects that I am working on, the project also provides some CMake modules in the source directory. I'm on Gentoo and have never had this kind of problem. A Google search brings up the following package: **extra-cmake-modules**. Have you tried to install this?
Nothing that depends on Qt5 and uses CMake will build on Debian or Ubuntu. 
&gt; Well then you are probably not doing the correct things. "The correct things" seem to be building everything from source, from libc up. 
There may be a reasonable argument that libraries should provide a module to make them easy to include from CMake. There is absolutely no reason that anything in particular needs to use it as a build system though.
I've never heard of that package. It *still* doesn't come with `FindQt5.cmake`, though, and that's a source of a big swath of projects that I can't build. 
Oh that's not cool
With libcurl I'm pretty sure you can do it
Also, I see **cmake-extras**. Maybe try that. Qt5 is such a widely used library that it's hard to imagine that its cmake module is so hard to find. You mentioned that you are on Ubuntu? What version are you using? Also what version of CMake do you have installed?
https://blog.kitware.com/cmake-finding-qt5-the-right-way/
`Qt5Config.cmake` is every bit as absent from Debian/Ubuntu as `FindQt5.cmake`. 
What happens if you try this: &gt;In order for find_package to be successful, Qt 5 must be found below the CMAKE_PREFIX_PATH, or the Qt5&lt;Module&gt;_DIR must be set in the CMake cache to the location of the Qt5WidgetsConfig.cmake file. The easiest way to use CMake is to set the CMAKE_PREFIX_PATH environment variable to the install prefix of Qt 5. Quoted from https://doc.qt.io/qt-5/cmake-manual.html
If you install the Debian development packages for Qt5 and then run `find / -name Qt*.cmake`, you'll find nothing. I've been there before. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/axh39w/any_other_book_recommendations_you_all_want_to/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Try adding the Qt5 install directory prefix to the CMAKE_PREFIX_PATH variable. Would you mind copy pasting the relevant CMake error message here as well?
It's been years since I tried building a Qt5 project, but I know that changing `CMAKE_PREFIX_PATH` can't help CMake find a file that literally isn't present on the filesystem. Setting environment variables does not create files, let alone fill them with the right data. 
Then you must not have it then. What Qt5 developement packages do you have installed? qtbase5-dev?
That's mean we could not get UI on screen?
That, along with `qt5base-dev-tools`, `qt5-qmake-bin`, `qt5-qmake`, and `libqt5opengl5-dev`. Unless there's one they decided to name `QueueTeeFive-Programmers-Edition`, I think I found them all. Just for shits and giggles, I threw `pyqt5-dev` into the mix to see if it would pull in any dependencies I didn't find by searching for packages with `qt5` in their name. 
That seems like a whole lot of complexity to avoid getting your hands slightly dirty &amp; doing some basic bit math.
Again not on debian or ubuntu, but it appears that qtbase5-dev is supposed to provide Qt5CoreConfig.cmake. Weird. Try reinstalling the aforementioned package. Also remember to delete CMake build files after failed cmake configure run. Otherwise if that doesn't work, I'm stumped.
Look at Corentin’s blog post.
As public codebase, you may want to look at build2.
I am not qualifying raised concerns as internet FUD. I do however want to alert the public about misrepresentations and FUD being spread.
Well, having single module:file 1:1 is indeed simpler. For both humans and software. Simple rules, and no potential preprocessor influence. Could you please point to some reasoning behind not adopting that approach? I saw only phrases about some marginal decades old FSes limited to no extensions or single level of directory hierarchy.
Consider: printf("Screen name: %80s\n", u8"chopin🇮🇩"); This will also have the wrong number of padding spaces if you use code points for width.
Thanks for the tip on the code block, I've made the Makefile more readable (I'm really sorry about posting in the wrong sub, I'll take care from next time. It's fixed now
Yes, that worked! I hadn't realized that I was trying to create the same executable from two files!
I'll stick to GNU Make for now as not all users have cmake (I know it's easy to install, but still) bundled in their distro
That's what I'm trying to avoid, I don't want to manually add all of them and instead use wildcard to quickly compile all of them
Preprocessing 100k files to start a build does not seem like happy funtime to me.
You also left out the value of convention over configuration.
I think there is a *very* strong reason. I just finished watching Mathieu Ropert's talk, and he nails it (see around [1:05](https://youtu.be/C1m-Uy4nuQA?t=3900)). He's also not the first one to say it: Not using CMake will only isolate your library from the rest of the ecosystem. If you want package maintainers to *not* hate you, just use CMake throughout. (And I argue the same holds for most users!)
So? That may be, and I'm not saying no one shouldn't write another build system, ever. But let's be realistic: anything new here has a very small market share, and it would be terrible for any library *today* to only support a niche build system. Think of both users as well as package maintainers. It's probably OK, but utterly optional, to support additional systems.
Turning on contracts is not automatic in my understanding. It requires code to be written (specifically the require clauses). As such, if there is no require clause, turning on contracts switch should not affect the current code in any way. And then, contracts can be gradually introduced into the code to maintain the correctness everywhere. Why is this approach not the preferred one?
I'm sorry, but that's just madness, and it's not quite nice to add that requirement to the design of C++ contracts - which will be used over many decades. Either add more test, add contracts more slowly or don't use contracts in production at all? Which doesn't preclude using them in test environments, and if everything breaks it's a sign that either the contract or the code is wrong? 
I'm already using my build system to specify which source file should produce what output artifact. If I stick to a simple pattern, the build script is similarly simple (*.cpp-&gt;*.o), if I want something special, the script becomes more complicated. Why is the same not acceptible for modules?
Strange, I have a project that requires them and it builds correctly. Moreover, the compilation worked for years. There must be something wrong with your installation. 
If contracts for some particular function gets broken, you don't have to write contract for that. Contracts are not something that will be forced on the code anyhow. So, why not rather have contracts that cannot be broken that have contracts that can be broken. Imagine the pain of debugging when you could not trust the code that is written in the contract part. Its not just useless from the point of view of compilers but also useless from the point of view of future code readers. 
&gt; Point #2 is the real kicker here: Proposals to “fix” Modules for tooling have rarely focused on changing the C++ language itself. Instead, they focus on specifying what is implementation defined behavior in the language standard. This more than anything was the reason I felt that people were grossly overdramatizing the situation. Sure, common guidelines on how to implement modules are important and I'm very happy about the decision to write a TR, but unless something in the standard actually prevents sane and efficient implementations, the lack of specification for implementation details doesn't mean there won't be good implementations. And other than with the Language, where it can be highly annoying that one compiler implements implementation defined aspects in a different way than the next, my build script will never run with a different build system anyway, so implementation divergence is much less of a problem. Again, that is not to say that a good initial set of guidelines or a reference implementation (instead of everyone coming up with their own solution) isn't very valuable. 
Could you elaborate on the build systems from the 70s?
The argument given there seemed to be "don't roll your own" (which I completely agree with) rather than "don't use better systems that currently exist. I don't really see how using a different build system isolates my library from the rest of the ecosystem. It is still easy to grab non-cmake libraries using package managers, and of really needed it can ship a find module that sets up linking it. As for people building the library, is typing "cmake &amp;&amp; make" really that much harder than "meson &amp;&amp; ninja"? The command to build the thing is usually in the readme anyway, so users can just copy/paste this.
For example Make. In order to compile modularized code you either have to know ahead of time which BMI depends on which BMI, you have to be able to handle failed commands based on dependencies missing, you have to be able to compile BMIs in any order, or you have to be able to pause the compiler when it is missing one. Let's call those options 1-4. 1. This is copying your whole BMI dependency graph into the makefile manually. Not very maintainable. 2. This is what many tools handling Fortran modules do. It's a specific error code handling and a sort of yucky backtracking method of handling missing dependencies in retrospect, basically making your build a non-deterministic hope-this-finishes kind of thing. 3. This is the alternative that Clang supports, which we wanted to know would be possible and actually implemented somewhere. It's not faster than includes. 4. This is what Nathan Sidwell (from GCC) implemented in a fork of Make. It works and is faster than the 3rd option. The problem with options 2, 3 and 4 is that if you import a header somewhere and include it elsewhere, those two may compile differently leading to an ODR violation. At the very least, you're using two separate code paths in the compiler to generate them / load them. Note that the main concern is large companies that have big code bases set up with these kinds of build systems, without manpower on such a system to do big changes to the build system (but enough man power to keep up with functional changes). These would be left out cold in such a case. Also note that the beginning developer use case is pretty similar. Options 1, 2 and 4 are not very friendly to new users.
&gt;It is still easy to grab non-cmake libraries using package managers \*If\* they are maintained, or packaged in the first place; see my comment above. Also: What if you want/have to build *all* dependencies from source (except maybe the C++ runtime), in a true "one-command-builds-all" fashion (i.e. `cmake &amp;&amp; ninja`)? A heterogeneous set of build systems is a massive hindrance, since it cannot seamlessly support this use case. Thanks, but no, thanks.
Narrowing prevention is a very weak argument for brace initialization. When it comes to overflowing literals, the compiler will warn you, and if you're just passing a normal variable, the conversion will still happen for \*\*all functions\*\* except constructors. There's also the initializer\_list trap, which makes brace-init a negative sum IMO. &amp;#x200B; I don't think order of evaluation should affect teaching. You should in general not rely on non-obvious mechanisms, especially so when teaching.
That's what I meant with "this table". The cppreference table used to be core language features only, IIRC.
I just answered your question: &gt; What Linux distro do you guys use where CMake actually works? There was no qt context in your first post. You may be right, but I have not experience with qt cmake combination. Last qt project I had to build was [OpenBoard](https://github.com/OpenBoard-org/OpenBoard) and had no problem with it on debian, but it uses qmake. &amp;#x200B; &amp;#x200B;
What gap? MSVC has the most complaint C++17 support
You weren't trying to do that. I think the original/top reply submitter didn't read your question and presumed you were trying to do what they would expect you to be trying to do - ie make a single executable from multiple sources. You were falling into the usual trap with make, in that you appeared to be trying to direct every step and had got confused as to what you were trying to accomplish. make already knows how to do most things C/C++ build related and it just needs a pointing in the right direction. I could probably take out a couple more lines of the working instructions and make will still do the right thing. Examine the diff between your version and mine to get a better idea what is and isn't required.
I was talking about C++20 features.
Oops, you are right. But still I give you the same set of suggestions as I did in my previous comment.
The only thing I don't understand is why the for\_each\_args function has to return a copy of the callable? Wouldn't it make more sense to use perfect forwaring for the callable? Maybe I'm overlooking something.
I don't understand what you expect the standard library to do. The underlying kernel sleep calls don't understand anything but system_clock. Even if they did, there's no guarantee that the thread is even scheduled (e.g. if all the CPUs are held by threads of higher priority). Putting threads to sleep is not a synchronization mechanism.
The compiler and library ship as part of the same package.
Try mac Linux or Windows. I've had great success on all these platforms.
The virtual call is already on an expensive path people optimize away from -- memory allocation -- so I'd expect that to not matter. The bigger deal is increasing the size of every vector by 25%.
If you write a library interface that takes a `std::vector`, it has to be templated, or your users can't provide their own allocator. Even if you aren't using your own allocator, you may need to care.
Because of the lifetime of temporary objects passed in https://gcc.godbolt.org/z/5egVgC
One is extending the lifetime of a temporary return value https://gcc.godbolt.org/z/H2ayMe
That's also how you link in libraries in C++. I think modules are supposed to replace headers, not libraries.
&gt;I saw only phrases about some marginal decades old FSes limited to no extensions or single level of directory hierarchy. AFAIK thats at least one of the reasons. The Filesystems in question seem to be still in use in cars. 
 One notable gotcha of inline functions is that they can violate the ODR even if they are *textually* identical. In other words, even if put the definition in a header file and only define the function via that, you are not quite safe. Consider the following: // In myfn.h: inline int myfn(int x) { return static_cast&lt;int&gt;(otherfn(x)); } // In foo.h: double otherfn(double x); int otherfn(int x); #include "myfn.h" // In bar.h: double otherfn(double x); #include "myfn.h" If you use `foo.h` then the definition of `myfn` uses the `otherfn(int)` overload, while if you use `bar.h` (and don't first include `foo.h`) then `myfn()` uses the `otherfn(double)` overload. If you do these two different things in two different translation units then you have violated the one definition rule, even though the text of `myfn()` is identical in the different places, and you have undefined behaviour. 
Sure but I mean, if you get it right, what's the main concern with templated version of such an interface? Is it binary size increase, usage ergonomics or sth else which I currently can't think of? Let alone that polymorphic allocator and template-parameter allocator are not quite the same things. 
Having to write a conanfile.py with boilerplate to get conan to play nice with meson is unfortunate indeed. That being said, with ~15 lines of boilerplate you now have a meson + conan build system that just works. I have a project I'm building on windows and linux, the former was a bit of a pita to set up because I had to manually download pkg-config and ninja, but once that was settled it was just glorious to see my dependencies being automatically downloaded and everything being neatly compiled.
&gt; and methods that we are supposed to believe are 'better'. I think that it is an error to think of any error handling (or not handling) mechanism as 'objectively superior'. C++ gives us the choice of using whatever fits our usage best unlike Java or Rust. &gt; So please, do forgive me for occasionally saying something positive about it. Just so we are all aware that some people actually like exception handling. This isn't a discussion about whenever exceptions are better or worst than outcomes (or whatever), and nobody here made the assumption than outcomes are better or worst than exceptions. 
You write a contract and a year later it gets broken. What can you do about that?
For numbers, `=` like a formula: `= 123`. For structs, `{}`, like in C: `= { 123, 456 }`. For classes, `()`, i.e. call the constructor: `Widget(123, "asd")`. In generic code, you may need something more generic, though :)
I know this is old. I tried to use KDevelop but it felt somewhat lacking and not as mature as other IDEs (or even text editors with plugins such as VS Code). Just as an example, I want my editor to have a nice color scheme *that I like*, and KDevelop doesn't have many of those. There aren't many on the internet made by the community either so you're kinda stuck with what the IDE offers. Also, I found the autocompletion a tad "bloated". Like, when I start typing it pulls out all sorts of symbols and macros which I know nothing about (I'm guessing from the standard library). I switched to QtCreator after literally 3 minutes of use :/
I know that, I meant that it's easier to ship something that's just a couple files that don't change behaviour of 99% of code compared to things that may introduce bugs because they are more complex features.
You need to put an empty line between text and lists for marrkdown to recognise them: * For numbers (arithmetics), `=` like an equation (and like in C): `int i = 123;`. * For structs (PODs), `{}` like in C: `S s = { 123, 456 };`. * For classes, `()`: `Widget w(123, "asd");`.
But do they need the car itself to compile it's C++ code? oO
Good explanation, especially thanks to the color-coded diagrams. I gave a talk about `for_each_arg` and possible uses back in 2015: [CppCon 2015: Vittorio Romeo “`for_each_argument` explained and expanded"](https://www.youtube.com/watch?v=2l83JlqkzBk)
I had some fun during a programming contest debugging a `std::vector&lt;int&gt; v{n, 0}` that I wanted initialized with `n` copies of the value `0`. When I found out that `()` and `{}` have slightly different semantics, it was the top of the BS for me... But I never forgot that after that episode.
Ok forget what I said about perfect forwarding - I think for this example it actually doesn't matter. &amp;#x200B; I still think that the function should simply return void. At least that is my gut feeling... I just wanted to say that the STL also doesn't do that... but I just checked std::for\_each and discovered - to my surprise - that it actually also returns the callable o.O So what is the design rationale behind that? I mean I have worked with some pretty big codebases at work and have also worked with some big open source projects like LLVM and never once saw a usage of the return value of std::for\_each
so you can accumulate state in the callable
There was a bug in MSVC. But it's fixed in the latest Preview. So now it works fine
Windows debugger is under development. It's not CDB (we've tried but it worked poorly). Hope to get it in the preview for 2019.2 or .3
Please upvote this if you feel it's important [https://youtrack.jetbrains.com/issue/CPP-9678](https://youtrack.jetbrains.com/issue/CPP-9678)
Would you apply a similar principle to tests? You write a test today and a year later it fails and you do nothing about it? Especially a unit test? 
yes, but assuming that when one uses width formatting the output is probably displayed in a mono-space font, and since most of code points are half-width characters, it is more accurate to use code points count than string size. Not 100% accurate though. &amp;#x200B;
Ask the committee to fix it for you? Surely, that isn't be the intended answer
A unit test doesn't crash my application in production.
If we're talking C++20, I think it's worth to remember designated initializers struct some_integers { int x; int y; int z; }; some_integers one{.x = 5, .y = 7, .c = 11}; //fine in C++20 some_integers two{.y = 7, .x = 5, .c = 11}; //won't compile This is good, because it makes you certain that exact fields of your struct will be initialized, if someone decides to redefine 'some_integers' and swap order of x and y, you'll get compile error, it may prevent some nasty bugs.
/u/meetingcpp It seems like the title for Dresden was messed up. &gt;René Richter "A view of infinite `&lt;ranges&gt;` in C++20's kitchen" Probably the &lt; and &gt; signs are not properly escaped.
If you allow contracts to be off in production you're allowing code to continue past violations without knowing about it (and suffering whatever consequences you might get for that). How is that better than being able to deploy a build in a mode where you can detect is this happening (but run just the same otherwise)? Testing would be a great solution. The time it would take to fully unit test our codebase to find all contract misuses is something that is likely going to be measured in decades (and the effort probably measured in centuries or millenia). The time it takes to detect contract violations in our thousands of different applications can be measured in weeks. The cost, however, of crashing on all of those violations is more than we can afford - some contract violations happen so frequently and are compensated for by other bugs/misuses that it will take years to fix them. Only having the option to make contracts terminate would be effectively useless to us. 
We don't even know what the jobs are. how are we supposed to give you advices? &amp;#x200B;
The Modern C++ Challenge is a nice book for that.
You'll probably have better luck asking on /r/cpp_questions 
So that sounds like my previous contract. Given the language, location and salary, sounds you're being hired by Amadeus. 1) if you're being hired through a contracting company, back off now. If you're hired directly, continue to point 2 2) I've worked there before. What I can tell is is the code quality depends massively on the department. I met some people working with decent C++, but I myself was stuck with 98 for reasons that no one could explain but no one could change either (we tried, of we tried). Do you know for which department you're going to work? Airline? Rail? Hotel?
Although, not exactly what you are looking for, you can try [http://cppquiz.org](http://cppquiz.org). It has some quick problems with various difficulty. I have picked up some knowledge starting from these questions and recommend it.
You think that both his Debian and Ubuntu fresh installs are broken in exactly the same way? Really?
 bool connected = true; ... while (connected){} There are at least two UBs here. First, you need a Data Race for this to "work". Second, an infinite loop is also UB. Welcome to C++.
&gt; initialized with n copies of the value 0 using namespace ranges::v3; auto v = view::repeat(0) | view::take(n) | to_&lt;std::vector&gt;(); Now forget about those constructors.
&gt; Try literally any platform Have you read any part of this thread?
Or, much better, `std::vector&lt;int&gt;(n, 0)`.
I have no idea what you just said, but don't forget `wscb-&gt;options.callbacks.onClose = [&amp;connected]() -&gt; void{` `cout &lt;&lt; "[WS] Session closed: &lt;reason&gt; \n";` `connected = false;` `};` The purposes is to keep the program open until the WS client closes as the code previewed is just for demo purposes. It's up to the programmer to figure out how to prevent their program from closing.
The thing you are looking for is called logging.
So, basically, you are looking for a way to log violations. Just develop a logging library for the purpose. Why use contracts for this purpose? Contracts are not out yet, why spend time adding contract based code when you could be writing a logging code instead? 
Yeah, it also works, though it requires some knowledge of `std::vector`'s constructors in order to understand what it does. And, though all containers (except `std::array`) this pattern, one can't expect it to work the same for all classes. E.g. `std::valarray` accept the arguments in the opposite order. These aren't really big problems, but I'd rather avoid these problems if the code is to be read and maintained by others.
Yes, this is indeed quite dangerous. According to the standard, however, the One Definition Rule is not just constrained to the function body but also includes the clause: &gt; name lookup from within each definition finds the same entities (after overload-resolution), ... Hence it's off course, as your example shows, not enough to have identical function definitions if the name lookup, e.g. function calls, finds different entities in different translation units. Great point though!!
I think I have a rather unpopular opinion. I use explicit type auto and braces: auto vec = my::pod{}; auto dd = double{1.7}; auto obj = my::person{non_obvious_name()}; I wish there was a warning for using a constructor taking a `std::initializer_list`. I do not use them and I could simply make the code not compiling when using them by mistake. Brace initialization is not broken, but initializer list is. It should have been a language level tuple instead of a magic list and no ambiguity should have been allowed between constructors.
You can check the disassembly
&gt; Is it true that C++ **really** has no way to check for optimisations at compile time? There are two questions here: 1) are optimizations standardized in C++, i.e: are they described in the language? Some are, like return value optimization, but not many. 2) Are there tools in the C++ eco-system that allow you to enable certain optimizations in a more dependable way? Yes: just google "c++ simd" to get an idea of what you could find.
I quite enjoyed [Timurs talk on Meeting C++ 2018](https://www.youtube.com/watch?v=ZfP4VAK21zc) on this exact topic. It gave a nice overview on initialization throught C++'s history and concluded with a proposal of best practices for C++20 (use parens per default, use braces if you need initializer lists). &amp;#x200B; Regarding the initialization order: you are right. My opinion on this is, that a temporary variable and a separate statement should be used, whenever the order of evaluation has to be specific. This also documents the requirement and prevents future code changes accidentially changing the order, in which expresseions are evaluated. Also keep in mind, that paren and brace initialization behave differently when a move-referenced is passed.
Of course, but thats an extra step that might inappropriate to check by hand. It can't be eadily unit tested, and the cause of the optimization failure is unknown.
It's a compiler QOI issue. I work on compilers for Cray and our optimization messages give pretty detailed information. For example, the compiler won't just tell you something didn't vectorize, we've gone to great lengths to tell the user the most important reason *why* it won't vectorize.
Than if the tech is there on the compiler end that just jumps out at me as room for standardization
Some other reasons off the top of my head: Modules might consist of partitions as well which would be additional files too. Forcing file name correspondence also means that you cannot do *nix-y things like `gensrc | g++ /dev/stdin` ever. The source file might be in a faraway directory anyways, so knowing the filename doesn't necessarily help without a module map either.
It's part of the build, so the scans are scheduled just like any other build node in parallel with everything else. Preprocessing before the build starts means that generated sources are not supported. It has to be in the build graph.
Theoretically, one does not need to expand every macro. If the preprocessor knows it is in a context where a macro expansion cannot expand to an import, it can skip expanding that. No preprocessor exists with such smarts yet. I do know there may be a few points in the spec which can make this harder, but I'll have an email for that to the modules list some time in the next week or so.
Basically contracts won't be largely used in production because why would I add a potential crash into my app.
If you ask me, we could simply preclude macro expansion to split out imports. We would still have to deal with macro expansions in #if statement, unfortunately
In my view, you should (you have to, no if, buts, or maybes) learn French (a 2 week immersion course at Berlitz, it's $$$, but it works), and move to the south of France and get the 40k job. I did the same moving to Paris (as an ex-pat). You will never ever regret it, your QoL will go up unlimited-less, consider the weather, the relaxed life-stile, beautiful people (just to keep it gender neutral), some social context (iff you speak French) and great food. And, some can even code.
I like that, it’s easy to understand, but Hot damn is that verbose. Is that valid as of the c++20 spec? Also the `|` operator is for piping now too?
I'll give a totally different type of answer here: 1. Are you mid-twenties and without responsibilities? 2. Do you think you would not hate living in France for a few years? French work hours, French holidays, French food, French weather. Plus in the south of France, women always seem to look classier than elsewhere in Europe. If the answer is yes to both of those, then that's your best choice. I did a few years in Spain back at the turn of century when I was young and carefree. Knew zero Spanish before I arrived, and few in Madrid back then spoke English. And I'd definitely recommend doing that, before you get too encumbered. You'll be a better person for it after, and that's *lifelong learning* stuff nothing to do with computers. All that said, would I raise a family in Southern Europe? If I had the choice, probably not. Southern Europe has a fetish for the old, enormous economic resources are ring fenced for them. So great place to retire, lousy place to raise children in compared to elsewhere in Northern Europe. 
The C++ standard is compiler agnostic and for a good reason.
It's the job of the compiler to do this kind of optimization so that is where it belongs. Putting it in the language creates a dependence on platform when the language is meant to run anywhere.
You are calling it with a float, but the operator takes a pointer to a float 
&gt;auto v = view::repeat(0) | view::take(n) | to\_&lt;std::vector&gt;(); This line requires no knowledge? If I had not know what its supposed to to, I would be completly clueless. The whole pipeline thing is going to make the most ugly code ever, worse than all the template-programming stuff
I stand by what I wrote in an eralier post: Use braces if you are putting values into a data structure, use parenthesis if you parametrize the construction of an object (and use assignment for copies (like \`int i = 5\`).
No, the thing i'm looking for is a way to enable contracts in a very large production codebase without inevitably crashing that system repeatedly. I'm also looking to make language level contracts something people can widely and safely use in libraries across our organization. The person writing the contract, who could conceivable alter it (and possibly need to move it into a function from a declaration) into calling into a logging framework, isn't the one who needs to be making the decision to continue or not. Only the person deploying a complete application can know how new any of the contracts they want to enable in that codebase are and whether they should continue or abort. A library with contracts might be deployed to thousands of applications with those contracts on and checked - but if another application decides it wants to test if those contracts are being violated without crashing then we shouldn't be asking that application to rewrite that library to log instead. 
Niall, we agree, see https://www.reddit.com/r/cpp/comments/axkcfe/france_riviera_vs_a_remote_jobgermany/ehub2mr/, it's a no-brainer.
&gt; Is it true that C++ **really** has no way to check for optimisations at compile time? Sure, maybe, for a given definition of “check”. But of course you can do exactly the same thing in C++ that they did with C#: only use low-level language features, without abstraction. That way you can control — to a large extent — what machine code output will be produced. Is this what we want? Of course not! We *want* to write high-level code and let the optimiser do its work. Ideally it would be obvious and reliable, but it turns out this is hard. The “subset of C#” approach makes code generation obvious and reliable, but it’s not a (sophisticated) optimiser. It’s mostly simple translation. And it forces you to write low-level code.
It would be even better if the constructor accepted named arguments, like `std::vector&lt;int&gt;(num: n, value: 0)`
Exactly, but a programmer relying on proprietary compiler output for feedback about language behaviour could be seen as problematic. Not to mention that C++ **is not compiler agnostic**, several existing headers that compilers must provide as per the STL translate compiler implementation details into a standardised format. You **can use C++ in an agnostic manner**, but it is not unprecedented to query compiler implementation details via a standard format.
&gt;It's the job of the compiler to do this kind of optimization so that is where it belongs. Putting it in the language creates a dependence on platform when the language is meant to run anywhere. It's also the job of the compiler to pick the sizes of the various data types provided (byte, short, int, long, float, &amp; double) but it's still required to provide size information to the code at compile time.
I have used cmake on these three platforms and encountered no problems.
`const float*` instead of `const float&amp;` or even just `float`
I feel the point is kind of moot. These days you can't even get predictable performance out of computers if you write in what's _ostensibly_ machine code, because it turns out current machines are perfectly willing and able to do - or not to do - certain optimisations on their own as well.
&gt;I feel the point is kind of moot. These days you can't even get predictable performance out of computers if you write in what's ostensibly machine code, because it turns out current machines are perfectly willing and able to do - or not to do - certain optimisations on their own as well. I disagree, yes I wish I had a more predictable way to design around cache line misses without profiling, but that doesn't mean I have to give up the ghost entirely. I'd rather be 2 steps behind instead of 3.
&gt; yes I wish I had a more predictable way to design around cache line misses I'm not even talking about the cache here. Processors are under no obligation to execute code exactly as you write it down, as long as you don't notice the difference, in the same way the C++ compiler has no obligation to lay out code the way you'd expect as long as it respects the semantics laid out by the standard.
I would prefer a profiler that can be given constraints and report which were met/unmet. It would probably require test vectors for each profiled function (including initial state for non-pure functions), as flow control logic may be too complex for a static timing analysis model. Such a tool could be run by CI after functional unit tests. This would directly test whether certain functions execute fast enough, instead of checking for weak proxies such as whether certain optimizations were used.
&gt;Sure, maybe, for a given definition of “check”1. But of course you can do exactly the same thing in C++ that they did with C#: only use low-level language features, without abstraction. That way you can control — to a large extent — what machine code output will be produced. Is this what we want? Of course not! We want to write high-level code and let the optimiser do its work, for two reasons: This is what what I'm thinking of would effectively force, a bracketed area where only the subset of C++ that supports the optimisation is allowed. &gt;Is this what we want? Of course not! We *want* to write high-level code and let the optimiser do its work, for two reasons: No it's not what we want, I want to be able to mark particular critical areas of code where I know what the machine behaviour is I want. Yes the compiler is smarter 98% of the time, but those last 2% can be a pain to manage. The solution adopted by the unity team, of creating an **entirely new compiler &amp; language subset** just to deal with these particular parts of code seems ridiculous to me, when (as other posters mentioned) the information is readily available to many compilers compiling C/C++ code already, but no language facility exists to interact with it. Leaving it to convoluted proprietary warning systems to be built around the compiler output.
My point is that you can *already* do this in C++ by restricting yourself to a subset of the language in parts of your code. Modern optimisers aren’t geared towards this scenario (because high-level code optimisation is much more attractive, and gives more return on investment) but I think they generally deal well with it. Primitive code is (relatively) simple to optimise reliably.
How do they behave different in move-referenced?
This is why when I use C++ in programming contests I use only a small subset of it (for example vectors, better to avoid them, I use only for building adjacent lists of graphs, the rest you static allocate).
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
&gt;My point is that you can already do this in C++ by restricting yourself to a subset of the language in parts of your code. Modern optimisers aren’t geared towards this scenario (because high-level code optimisation is much more attractive, and gives more return on investment) but I think they generally deal well with it. Primitive code is (relatively) simple to optimise reliably. Exactly, it is already a common pattern, but those rules cannot be enforced at compile time with the tools provided by the current standard without some *very* creative solutions, that I have yet to see implemented.
&gt; Putting an API for talking to the hardware, enumerating devices, etc., probably doesn't need to be a part of the language. The same could be said for threads, network, atomics, filesystem, date and time, ... They all need to talk to hardware in a similar way, they all have to deal with different OS, different architectures, different configurations. But the role of a standard library is also to offer a common interface to the hardware, not just vocabulary types. A programming language that can not talk with the outside world is not worth it. 
&gt;2 I don’t think they provided enough details to tell but I suspect that their C# subset can outperform C++ in many situations due to cheap heap allocations (GCs do have an overhead but under certain situations they perform very well, compared against manual memory management, because allocations can be made to be effectively zero-cost, unless there’s memory pressure). But of course this is entirely solvable in C++. I'm not asking the compiler to do what I want, I'm asking the compiler to give me an error if it can't do what I want with the code I've written, instead of substituting what I want for far less performant code.
Whoever wrote that is clueless It's easier to presage the performance of c++ than any other highly compiled language in practice Would you rather have a machine that makes five dollars a day, or one that makes 50, but that occasionally drops to 25 and it takes you a week to figure out why? 
"Everything in the C++ ecosystem should work the way this one compiler works! Let's standardize!" "what do you mean these aren't language topics and you already have a five year roadmap?" 
&gt;Would you rather have a machine that makes five dollars a day, or one that makes 50, but that occasionally drops to 25 and it takes you a week to figure out why? I don't agree with many of the points he made in that article, but the basic concept of "Performance is Correctness" does seem interesting. I'm no fan of the solution presented in the article by a long shot, which is why I was curious to see if the idea had any existing implementation in C++.
You seem to be repeating yourself with bold emphasis and someone else's words used incorrectly, so that you don't have to understand what was said to you C++ definitely is compiler agnostic, even if you can name a few tools that choose to do otherwise 
Well go ahead and write it then
Those not very creative rules are common and easy to find
Not the rules, but a solution that would enforce them as errors in a cross-platform manner.
No it isn't. Sure you're not required to be provided it's name, but it is required to provide you with implementation details.
Ok you can drop the cynicism. My whole entire schtick here is to understand if this is something that interests other people, get feedback, see if maybe I'm reinventing the wheel here proposing something like this for C++ (in a manner that goes beyond Unity literally inventing a new compiler and language subset), and gauge if there was enough interest for me to actually got through the process of putting together a proposal. I'm not asking anyone to "put this in C++ now plz", I'm well aware of how long it takes for anything to go into the standard, and that everything has to be approved and move through several committees (that aren't just the people here).
First of all, one thing about the title: There is not a single program on earth for which performance isn't correctness. A program is only useful, if it provides results within a certain time frame. Where they differ is how strict that time limit is and how hard it is to achieve. &amp;#x200B; Now, at least one problem with C++ (and most other programming languages) is that the programming model is focusing on the sequential executions of simple instructions (load, store,basic arithmetic like +,-,\*,/ and branching) and a uniform memory model. However, the bulk of the processing power on a modern computing device lies (by at least an order of magnitude) in vectorized instructions, pipelining, specialized instructions, multithreading and accelerators like GPUs. And if you only consider simple sequential part of the hardware, you only come anywhere near the full potential if your program takes the memory hierarchy into account . Also, al that generic code c++ people like to write usually relies heavily on layers and layers of abstraction, that are only efficient thanks to inlining. Within standard c++ (and again almost any other programming language), you are completely dependent on the optimizer to bridge that gap between the sequential math program you are writing and the functionality the hardware is providing. As c++ has only very limited introspection and no notion of the concepts for all those low level details that are so tremendously important for performance, no, there is (mostly) no way to check if certain optimizations are happening or not - there is just no way to ask thos questions from within c++. &amp;#x200B; All that being said: There are dozens of c++ libraries and compiler extensions out there that let you write e.g. SIMD code and/or use the power of a GPU, so it is not like you don't have control over this at all and this situation will (hopefully) become somewhat better with c++23.
There's no cynicism involved in explaining to. you that these tooling teams have existing priorities and plans that do not include imitating other teams because you decided to take over the c++ standard and have it cover things that the language has explicitly refused to cover for decades, on the observation of portability needs I'm just trying to help a junior developer understand why their flight of fancy isn't ever going to happen This is the exact opposite of what that standard is. You've never read the standard that you think this fits 
It's weird how you're insisting a language isn't something the language's standard says it is because you can name one tool that does something different 
Yes, those exist too. I would tell you where but you seem to be blindly arguing, making claims without evidence, insulting, and downvoting That's probably why nobody else has told you where to find them either 
Many
What are those C++23 plans?
You need to tell the compiler what you want for it to know what you want.
That's one of the two public samples I was aware of using modules. For reference this is the library in questions: [https://git.build2.org/cgit/libbutl/tree/libbutl](https://git.build2.org/cgit/libbutl/tree/libbutl) \-- It's a hybrid in that it can be consumed both as regular header TU library or as modules. The other use case being the partial use in the LLVM code base. What I could never figure out is if the modular version of \`libbutl\` is used externally. It's certainly a minimal example of the Clang and MS modules.
What does this have to do with the way you specify to the compiler which files to read from? Modules are built before they are used (thus "modules are translation units," forgive my imprecision if that's not how the term is used). The fact that they can represent anything from just an interface, to multiple implementation TUs, or a file/class/library/etc, doesn't change anything here. The names thing doesn't really matter either. Separating `slim.shady` from `the.real.slim.shady` is *exactly* what I mean by "dotted names are purely syntactic." Rust crates are the same- they have no hierarchy at all, since that's all provided by modules (i.e. namespaces) inside a crate. This is how Java packages work too- `com.reddit.cpp` has no relation to `com.reddit`. And even if that weren't the case... I still don't see how it affects the way you specify them to the compiler.
C++ syntax is mostly compiler agnostic but its semantics are absolutely not compiler agnostic. The standard has many fundamental semantics that are implementation specific behavior or unspecified behavior, both of which depend on the compiler in order to reason about C++'s behavior.
Yes, I'm aware. How does that change anything?
Let us say that piping is the poor man's lack of UFCS in C++.
Many features in C++, including optimizations are the result of how a single and specific compiler worked, including RVO/NRVO which was part of Digital Mars C++ implementation and then standardized based on it and which evolved into the mandatory C++17 copy elision.
That's currently not spec-valid. Only the `;` for header unit imports cannot be expanded from a macro. I'd like to know why non-header-unit imports can have the `;` expanded from a macro. If we can add that restriction, if you see a macro that doesn't have a literal `;` following, it cannot be an import (or `#include`) and can be trivially skipped.
If you want the (IMHO) canonical example of this, consider RVO. Especially back in the days before moves. In C++03, a lot of the experts would still recommend (at least, from what I recall) that if you had a function that say built a vector, it should return the vector by value. RVO will kick in, so everything will be good! The problem is, in line with what you're saying, there's no way to enforce that RVO is actually happening. There's no way to make the code fail to compile when RVO isn't happening. And RVO is actually quite fragile, you can imagine someone coming and modifying the function in question and breaking RVO. So while return by value was (again, AFAIK) the "official" recommendation from many sources, most people in real life strongly preferred using out parameters for this sort of thing. I don't typically find this to be nearly as much of an issue per se now; while I do still sometimes see examples of bad codegen, most examples aren't as dramatic. You can also get a general sense of what kind of code enables which kind of optimizations (I gave a talk on this at cppcon); using that for the initial design combined with looking at assembly and benchmarking is pretty good IMHO.
If you are especially looking for iterators I suggest https://github.com/nemtrif/utfcpp. I use them in a project of mine and find it very good. It allows iterating over UTF8 sequences by 32bit code points and handles invalid and incomplete sequences. Plus it's header-only and C++98 compatible
I mean, we could change the spec - it's not too late
Isn't C++ explicitly specified "as-if" it is running on an abstract machine called the "C++ abstract machine", which is explicitly compiler agnostic, barring undefined and unspecified behavior, which is explicitly NOT in the purview of the language specification (e.g. "the language"?
You seem to have this picture of me as some naive young developer who wants everyone to do his work for him, up to and including compiler implementors. I'm not some wizened developer whose been writing code since the early days of "C with objects" either, I'm just me. As for claims without evidence, I assume you mean that as to compilers providing implementation details in a standardised manner? Yes it's rare, but it exists. It's usually very trivial things such as being required to provide the sizes of types, IE I can write a compile time assert to trigger if a struct is larger then I expect it to be because the padding used by this particular compiler with these particular settings is larger then an arbitrary value I state in my code. As this is relatively trivial I didn't think I had to bring it up specifically. I guess that endianness is another example, though that is new to C++20, and although a compiler could be intentionally flippant and go against the architecture, that's usually more of a question about architecture than the compiler. I haven't intended to insult anybody, PM me examples if I have that's far from my intention and I apologise if I have you personally. As for downvoting, I only downvoted 2 of your comments that I didn't think were constructive, the rest of those aren't from me.
&gt;You need to tell the compiler what you want for it to know what you want. I just feel like I can't tell it some things I'd like to be able to.
Well, that is a compiler-specific question, not a C++ standards question. There is -Wdisabled-optimization and -Winline for gcc, for example. Some of the compiler-specific pragmas and options could have been standardized, of course, but I'm not really sure if they would solve more problems than they would create. A number of standardized 'helpful' hints to the compiler eventually end up counter-productive, as the compiler can figure out these things better than you in almost all cases anyway ('register' and 'inline' comes to mind).
The as-if rule is not universal in applicability. In particular it doesn't apply to the sections that are undefined, implementation or unspecified behavior. Those three types of behavior are left to the compiler.
Yes, this is what I was referring to with "I do know there may be a few points in the spec which can make this harder, but I'll have an email for that to the modules list some time in the next week or so.". :)
&gt; cross platform work &gt; optimisations Pick one. The kind of optimisations we're talking about here are fundamentally platform specific.
The second one works with an already existing object.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Modules are about software architecture, and as such do not require a 1:1 correspondance with containing files. There are shops where the architect mandates a 1:1 correspondance between a header file and an implementation file per component. Yet, there are shops where a component spans several header files and implementation files. Furthermore, you can have a library comprised if several modules. We build the tools to serve us, not the other way around. I don’t know anything about “marginal decades old FSes limited to no extensions” that have influenced the design choices for modules.
&gt; I think modules are supposed to replace headers, not libraries. Who said that?
That might just be an oversight in the wording - I don’t recall a discussion where we made a conscious decision to differentiate here.
The hard part is (1) installer interaction, and (2) users being confused about dot-dot updates (since due to branding there won’t be a 15.10). The size of the feature or number of edited files are irrelevant.
I was mainly referring to executors and I've heard some rumors about a simd library. It's a small step, but at least something. 
&gt; What I could never figure out is if the modular version of `libbutl` is used externally. It's certainly a minimal example of the Clang and MS modules. Now, the goal post has moved: see my specific comment you originally quoted and asked evidence for. For those following at home: named modules (as defined in the Modules TS and the Merged Modules) have been used at Microsoft in shipping products. For reasons I still cannot fully understand, some people insist on discounting that as usage.
&gt; You seem to have this picture of me as some naive young developer Well, not the young part, but otherwise yes . &gt; who wants everyone to do his work for him, up to and including compiler implementors. What? This isn't your work. This is you rambling about things you don't understand and saying "this thing that's completely unrelated to what the standard does should be standardized." . &gt; I'm not some wizened developer We know. . &gt; As for claims without evidence, I assume oy . &gt; As for claims without evidence, I assume you mean that as to compilers providing implementation details in a standardised manner? Nope. . &gt; It's usually very trivial things such as being required to provide the sizes of types This being part of the C87 standard, and something basically every language does. So interesting. Do go on. Or, you know. Don't. . &gt; As this is relatively trivial I didn't think I had to bring it up specifically. You don't. It's just that, as a junior dev, you don't actually recognize the things you're discussing to be irrelevant. Wow. ***Endianness***. You're ready to replace the C++ standard and dictate to all compiler implementors. 🙄 ---- If you seemed trustworthy, I'd ask a couple leading questions, to help you understand just how out of your depth you are. Unfortunately, you strike me as someone who would google answers, then provide them and pretend they were your own, so, I won't
Thanks
Now, all that said, some people e.g. me do not get on well in France, mainly due to their irritating culture and annoying habits. I can put up with it for a few days whilst grinding my teeth and suppressing rage, and it is a beautiful country well worth visiting, but I couldn't imagine living there. Not ever. Anything great in France you'll find in other Continental European countries without the annoying culture factor. Spain is great, as is the Netherlands, Germany, Belgium, Sweden, Norway, Denmark. I could see myself living in any of those no problem. Still not sure if I'd raise children in them. I returned to Ireland to do that after much careful thought and consideration.
Well, there are rules to C++. Your program broke them and causes undefined behavior. I works for you until it doesn't. For example, I'd expect the while loop to simply disappear when enabling optimizations. Introducing a data race and an infinite loop without side effects both cause undefined behavior. There are better ways to do this kind of stuff that actually work. Search for them and upgrade your code.
&gt;Now, the goal post has moved: see my specific comment you originally quoted and asked evidence for. I never said I agreed or not with your or the "someone claims" statement of wether modules was or wasn't used. I.e. I didn't place a goal post anywhere. I was only curious as to what evidence you where referring to. As I'm always eager to acquire data. &gt;For those following at home: named modules (as defined in the Modules TS and the Merged Modules) have been used at Microsoft in shipping products. For reasons I still cannot fully understand, some people insist on discounting that as usage. I didn't mention the MS use case because it was my understanding that the use in Edge was removed and never shipped. Is that an incorrect understanding? Is it still in use in Edge? Or is there some other MS use case you are referring to? &amp;#x200B;
&gt; Many features in C++, including optimizations are the result of how a single and specific compiler worked, including RVO/NRVO which was originally part of Digital Mars C++ implementation This isn't actually correct. The C++ standard requires competing implementations before anything will be considered. A great number of production grade boost libraries haven't been standardized because they didn't have a competing implementation. This is why concepts didn't make it in. Etc. Digital Mars was quite late to the RVO/NRVO game, and is not generally a cutting edge compiler. You're probably trying to talk about Zortech, because Wikipedia recites Stanley Lippman's incorrect claim that Walter Bright implemented RVO first. Walter Bright is like RMS, or Shiva Ayyadurai: he tells that story so often because he wants people to believe it, despite that the evidence says otherwise. Besides, Zortech C++ isn't Digital Mars C++ in any realistic way. You might as well say that C# is actually Turbo Pascal, on grounds that TP becomes BP, which becomes Delphi, which becomes C#, on grounds that they all have the same author. In the meantime, the Hewlett Packard C++ compiler had shipped an NRVO under what GCC called the NRVO syntax for almost two years at that point. What Zortech did was ship the first ***automatic implicit*** RVO, which while the important step, is very different than being the first to do it at all. It's really weird that you tried to fold NRVO, a competing standard proposal by different people that works in a different way, in as part of Bright's work. Bright was actually (appropriately) very critical of NRVO, and NRVO is ***not*** a part of modern C++. You give the strong impression of copy pasting trivia rather than speaking from personal knowledge. . &gt; and then became incorporated into the C++03 standard and then evolved into the mandatory C++17 copy elision. I'm not sure why you believe that it happened this way. The real story was far more complicated. This was one of the biggest mudslinging events in the history of C++. ---- In the meantime, none of this has anything to do with my commentary. What TomerJ is discussing is entirely unrelated to a small, well defined, well constrained language optimization. TomerJ is talking about completely changing what the standard is and does, in a way that is directly opposed to machine and compiler agnosticism choices the language explicitly made decades ago and has stood resolutely for ever since.
I see, now I’ve learned another thing. Thank you. Feel free to fork and contribute with improvements if you want to.
&gt; The standard has many fundamental semantics that are implementation specific behavior or unspecified behavior, This is called "being agnostic" If the language shrugs, then it's agnostic. Saying "but that means the compiler has to choose, so it's not agnostic" is a whoosh of the third order.
There's a proposal to add a workflow operator `&lt;|` and `|&gt;` https://wg21.link/p1282
If the syntax and semantics of a language depends on an implementation then it's not agnostic. If you disagree with that then we will agree to disagree on this issue.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/axktgu/c_exercises/ehup0cz/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It seems to me like they could have saved a lot of time and added a custom pragma to GCC or clang. I mean, I know why they switched to C# (their game code is in C#), but it's kind of silly for them to pretend their solution was optimal. 
&gt; If the syntax and semantics of a language depends on an implementation this is the opposite of correct if a language punts on defining something, the language is agnostic to that topic. that an implementation still needs to make a choice doesn't change that. . &gt; If you disagree with that then we will agree to disagree on this issue. no, we won't. you are simply incorrect. this is not a matter of opinion. this is how language design at large uses the word, what you will find in every compiler textbook, and how the c++ standard explicitly defines its use of the word. i don't have to agree to anything, even if you said so. that you decline to admit that you're wrong doesn't change that you're wrong.
Why an error if re-ordered though? When you're initializing by name, isn't it because you don't care about the exact order?
The author is right that, for most compilers, there will be no diagnostic if a specific optimization is missed. Shunning C++ for this seems, however, rather misguided. When performance matters to the degree that vectorization or unrolling *have* to be used, then this needs to be reflected in the code. And there is no better way to reflect it in the code than to use code: types and functions. C++ is perfectly capable, with its generic programming facilities and its access to platform instrinsics, to have high-level abstractions that map efficiently to CPU instructions. It's just a matter of creating the library for it^1 . The main advantage of leveraging types and functions is that they are *universally understood*: all the regular C++ tooling works as expected! IDE will auto-complete, highlight unknown method calls, etc... This makes programming vastly more efficient as the feedback is instantaneous, and it's also likely the feedback is more easily understood: it's just types/functions as usual! ^1 *I only know of a Rust library for this, [faster](https://github.com/AdamNiederer/faster), but there's nothing there that cannot be applied to C++.*
That's certainly the impression I get from the way the conversation has been mostly about things like macros. I've heard nothing about the technicalities of modules replacing libraries, such as how modules would be dynamically linked.
isn't unity core written in c++? c# is unity's script api.
&gt;The C++ standard requires competing implementations before anything will be considered. A lot of what you're arguing is simply false. What competing implementations existed for ```constexpr```? GCC was the only compiler to have a working implementation of it prior to formal standardization on September 2nd 2011. Clang, MSVC and all the other compilers didn't even have experimental support or otherwise for it until **after** standardization. Same is true for much of what eventually got included in C++11. With C++2a there are similarly numerous features being proposed or that have been approved for which no competing implementation exists, such as the following: contracts, optional typename, explicit bool, constexpr virtual functions, ```std::calendar```, ```std::span```, and a whole host of features. &gt;Zortech C++ isn't Digital Mars C++ Yes it is, just like Microsoft's C++ compiler is MSVC. Digital Mars is the name of the company, Zortech was the name of the C++ compiler. &gt;TomerJ is talking about completely changing what the standard is and does, in a way that is directly opposed to machine and compiler agnosticism choices the language explicitly made decades ago and has stood resolutely for ever since. Someone is trying to have a discussion on an issue and asking questions about whether it would be useful to treat optimizations as part of the correctness of a program and you're basically ranting and exploding over it for absolutely no real reason.
That's a very good list of solutions paired with your complaints 🤔
That understanding is incorrect. The product that came out of that usage was shipping - as I reported a year or 18 months ago - until the recent decision to change codebase.
Oh, cool. We should work on a paper to mod the "merged modules" proposal as CWG approved it then I guess. Do we wait for the updated status quo document post-Kona or write it as a mod on P1103r2?
GCC has -fopt-info (and family that narrow results) that reports optimization info including missed vectorization.
Please name one single compiler textbook that uses the term "compiler agnostic" in the manner you're using it. &gt;how the c++ standard explicitly defines its use of the word. Please find me a single reference in the C++ standard that defines the term "agnostic", be it compiler or otherwise. To make it easier for you, here is a link to the C++17 standard for your own reference: http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2017/n4659.pdf To make it even easier for you... I'll give you a hint... the term agnostic isn't found anywhere in the C++ standard, explicit or otherwise.
There are a some things in c++ where the compiler is required to pick on of several alternatives (e.g. size of int) so it is not a compiler agnostic language. And if you talk about compiler + standard library there are even more things left to the implementation.
Are compilers even mentioned in the standard?
That sounds awful. Don’t limit compiler writers. 
Compilers don’t have to provide anything. Are you sure you know what a compiler is?
&gt; Please name a compiler textbook that uses the term "compiler agnostic" in the manner you're using it. As I already said, the C++ standard, which is the relevant authority here. Alternately, dragon book. Weird how I have to give evidence even though it's your claim originally. . &gt; To make it even easier for you... I'll give you a hint... the term agnostic isn't found anywhere in the C++ standard, explicit or otherwise Gasp. They used different phrasing? Cut the "even easier for you" attitude. It's not my fault you haven't read this standard, used control f, didn't find this word, and gave up. . &gt; You seem to think that just making an unsourced claim You're the one making claims, dear heart. I'm rejecting them. You made the claim that something which is ignored by the compiler, and has to be defined by the implementor, "isn't agnostic." Everyone else in the thread is resisting you, so you're demanding evidence from them instead of giving it of your claim on your own, and climbing the "I'm going to follow the rules of argument" tree to pretend that you have a point. . &gt; your condescending attitude Lol.
What complaints did I make? What solutions would you like?
&gt;Gasp. They used different phrasing? You made a claim that the C++ Standard **explicitly** defines the term agnostic, you used the word **explicitly***, yet you can't actually point out where in the standard it **explicitly** defines that... how bizare. Similarly the dragon book contains no reference to that term nor does it define any similar term either. Anyone with a PDF of that book, which can be Google'd can confirm this. https://en.wikipedia.org/wiki/Compilers:_Principles,_Techniques,_and_Tools
Performance is Correctness, sure. But the C++ compiler doesn't check for correctness. Tests do. ie a C++ compiler will gladly compile: int sqrt(int x) { return 17; } Only tests will tell you whether it is correct. Using TDD, it seems good so far: bool test1() { return sqrt(289) == 17; } Anyhow, write tests that check whether your code is as fast as it needs to be. At my work, if something goes slower, a test fails. 
Complaints was a poor word, but you didn't provide anything constructive while calling the author clueless and making an analogy without backing it up. And your follow up response to "existing implementations in C++" was a single word, useless response. If there are so many, it would be great to point out those examples or reference other comments which may have done the same. I just started using C++ a few weeks ago, I'm not someone who could remotely provide an answer. 
How about you give some concrete examples of what kind of checks you want to make in code? And in particular plecify exactly what you mean by it. "Vectorize that loop" isn't nearly specific enough to base compile time checks on it.
Every damn `llvm-*-dev` package since `trusty` on Ubuntu and `jessie` for debian contains `AddLLVM.cmake`. So, maybe, before telling all the people here that this is all broken, and all helping answers here are wrong, you should inform yourself and learn how to use your system. If you don't believe me: - https://packages.debian.org/search?suite=jessie&amp;arch=any&amp;mode=path&amp;searchon=contents&amp;keywords=AddLLVM.cmake - https://packages.ubuntu.com/search?suite=xenial&amp;arch=any&amp;mode=exactfilename&amp;searchon=contents&amp;keywords=AddLLVM.cmake
&gt; What competing implementations existed for constexpr? GCC was the only compiler to have a working implementation of it I have no time to go digging through historic trivia to satisfy your curiosity. This is the explicit reason that many things, including the given example `concepts`, were rejected. . &gt; you're basically ranting and exploding over it for absolutely no real reason. I'm ... doing neither of these things. I'm making no personal attacks or accusations, I'm sticking to the facts, and I'm remaining polite. Given the way you're acting in other threads, I'm also done interacting with you.
Could you elaborate or point to a source that describes the build sequence CMake use to support modules? Are imports discovered at configuration phase or as part of the build?
It's described in D1483R1. I have a copy hosted [here](https://mathstuf.fedorapeople.org/fortran-modules/fortran-modules.html). Currently this is using the strategy described in §6.2.1 there ("Scan sources independently then collate") because a scan tool smart enough for §6.2.2 doesn't exist right now (that strategy would likely be preferred on Windows due to process launch overhead costs).
This has all been done many times before and it introduces so many new constraints and qualifiers that you end up with a different language - e.g. https://ispc.github.io/. Would it be possible to embed this language as a DSL in C++? Sure but you'd hate the syntax. A specialized language and compiler with C bindings is a better solution all the way around.
\[Yes\]([https://superuser.com/questions/1137182/is-there-any-existing-cpu-implementation-which-uses-ones-complement](https://superuser.com/questions/1137182/is-there-any-existing-cpu-implementation-which-uses-ones-complement))
&gt; Every IDE will tell you what the contructor above does. I don't think visual studio does.
And here I thought you were being sarcastic with your previous post. It looked more like one of those jokes, where you blow up a simple mathematical equation to make it look as complicated as possible (like `1 == 1` becoming `i^2*-1 == sqrt((3+3)/-2/3 +2`).
Maybe because constructors can have side effects and throw exceptions.
I think most of the folks in this thread are misconstruing the OP's question. What that blog post talks about (and what would be the C++ equivalent) is *not* a guaranteed optimization! All arguments about QoI, architecture, compiler flexibility, etc. are irrelevant, because nobody's asking for the impossible. Instead, what Unity's work provides is a way to declare an intent for data-independence in loops with a way to get errors if those rules are broken. An unoptimized debug build, a build for a target that doesn't even *have* SIMD instructions, and so on would all still be allowed! The feature is "if the code compiles, *and* ***if*** the compiler supports the optimizations, you will get them." Unity further has only a single compiler and an easier time guaranteeing a certain QoI, but even then it's not 100% guarantees (e.g., compile to WASM without SIMD support and... well, obviously the generated code won't be vectorizing the loop). What the Unity folks - and the OP - would be seeking is providing a way to say, "I intend this loop to be optimized *to the fullest extent of what the compiler's QoI will allow* and I want to be told up front if I inadvertently wrote code that would defeat even naive optimizations." There's no architecture dependence there. There's no mandatory QoI there. There's no loss of flexibility in implementation there. All those arguments are completely missing the point. This isn't even a new problem for C++. Right now, in C++14, I can use the parallel algorithms library and request code that is vectorized or parallelized (which may not *actually* be optimized that way, of course; QoI) but can provide code to those algorithms which is fundamentally broken (e.g., it's not just "not optimized," but rather "will trigger undefined behavior or incorrect results"). It is then a QoI as to whether the compiler emits a diagnostic or not.language designed by experts for experts but used primarily by intermediates.") That's pretty much it.
I have some concerns about `polymorphic_allocator`. Mainly, it seems that the design decisions and intended usage of polymorphic allocators are known only to a select few people, mostly those who have worked at Bloomberg. I don't think the wider C++ community has really been given any help to understand how containers with polymorphic allocators should be used; nor has there been any serious discussion about the drawbacks of the design decisions that have been made. A `polymorphic_allocator` contains a raw pointer to a `memory_resource`. Who owns this `memory_resource`? That's not specified - it's left up to the person who constructs the allocator. So, suppose you have a function which returns a container which uses a `polymorphic_allocator`. Is that safe? How can we ensure that the memory resource outlives the container? It's not at all clear how this is supposed to be achieved. Perhaps we aren't supposed to return containers from functions at all? Do we go back to using output parameters, like we did before move semantics came along? What's the value of `propagate_on_container_move_assignment` and friends? It's `false`, right? So, if you `move` or `swap` a container which uses this allocator, then that *might* not be a constant-time operation, and theoretically it can throw. Is everyone OK with this? Ever since C++11 people have been used to being able to move containers cheaply - do they realise that this will not be guaranteed if they use a polymorphic allocator? I genuinely do not understand how this is all supposed to work. The idea of a type-erased allocator seems really useful, but it does not appear to be a drop-in replacement for the standard allocator. It looks to me like, if you wanted to switch to use polymorphic allocators throughout your code, that would fundamentally change the way that your interfaces would have to be written. If so, then I think that would put a lot of people off the idea completely.
&gt; Complaints was a poor word, but you didn't provide anything constructive while calling the author clueless I provided supporting examples. I also don't provide constructive things when pointing out that Andrew Wakefield is clueless. Valid criticism is of value and does not need to be paired with constructive offerings. . &gt; If there are so many, it would be great to point out those examples It's too late to make requests. You've started a false criticism train that has buried what I want to say.
Time to switch 
Can't you guess?
&gt; Every IDE will tell you what the constructor above does. What IDE does this? I've used several and have never seen such a feature. At best go to definition and hope your standard library implementation has comments.
Certainly not. But that is beside the point.
As others have said, I think the narrowing conversion protection is not all that useful -- compilers will usually warn about this anyway. I also don't think that beginners need concern themselves with order-of-evaluation differences. My personal style goes like this: * Use copy-init style in simple cases where this makes sense. For example: int i = 4; std::string str = "Hello world"; std::string other = str; * Use list-init style where you are (conceptually) doing "component-wise" initialisation, for example: std::array&lt;int, 3&gt; arr{1, 2, 3}; std::pair&lt;int, std::string&gt; p{1, "two"}; std::vector&lt;int&gt; vec{1, 2, 3}; * Otherwise use direct-init style when you are (conceptually) calling a "construction function" Of course, this all goes out of the window in generic code, but that's "uniform initialisation" for you. I think parens-for-aggregate-init will mostly be helpful for this case.
No. The standard library still needs to translate to something the platform/kernel understand.
I don't see example anywhere in the thread, and you then tell me it's too late to request examples. The first response asked what examples there were and your only response was that they existed. That's the best time to give them, which you didn't, and is definitely not too late. I hadn't even gotten here by then. Critisism is great when it has some base. You just called the author clueless, dismissed the whole thing, and provided no basis for why when asked. That was the whole point of the OP. 
&gt; it seems that the design decisions and intended usage of polymorphic allocators are known only to a select few people Wrong. The popular EASTL has a rather similar memory allocation system. The original design of STL allocators is mentioned as one of the main reasons for the creation of EASTL (cf. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html). "Among game developers the most fundamental weakness is the std allocator design, and it is this weakness that was the largest contributing factor to the creation of EASTL" 
&gt; surprisingly, developers const-annotate 46% of methods In what way is that surprising?
I agree, but this is not a thread synchronization issue, it's a timing issue. There are derivatives and integrals with respect to time involved. The control loop should not run again before a certain time point in the future (in the simulation clock). Also the control loop usually runs on a high priority thread, that will help with the scheduler. Nonetheless, even if there are no other threads running, and the time point is passed, the system will not wake up the thread. As I explained in the bug report, I don't know if this should be considered a bug, and there is an easy workaround (i.e. specialize `std::this_thread::sleep_until` for the simulation clock), but this is suboptimal. If the Clock concept had a "real time factor" (that would be 1 for most clocks), the `sleep_for` inside the `sleep_until` call could take this factor into consideration.
So basically there is almost 0 evidence of this working at large scale except if we trust you? I still think that the charge of proof is on the one making claims (here:it works) and not the one doubting claim
It's the job of the platform to define the ABI. Compiler just follows it.
Undefined Behavior IS compiler agnostic because the program that relies on it is not a valid C++ program.
When does C++ syntax depend on an implementation?
&gt;I agree, but this is not a thread synchronization issue, it's a timing issue. The scenario described is synchronization with some external hardware. Synchronizing with hardware and synchronizing with threads are both synchronization. &gt;Nonetheless, even if there are no other threads running, and the time point is passed, the system will not wake up the thread. All real systems I know of do this, for power management if nothing else. &gt; i.e. specialize std::this_thread::sleep_until for the simulation clock You don't get to specialize function templates. http://eel.is/c++draft/constraints#namespace.std-5 &gt; If the Clock concept had a "real time factor" (that would be 1 for most clocks) I wouldn't be in support of such a proposal, but I wouldn't be against it either.
You can use the direct initialization rules (en.cppreference.com/w/cpp/language/direct_initialization) to bind a temporary to a `&amp;&amp;` member. Then the temporary values lifetime is extended only when using braces. See the "If T is a class type" bullet point in the C++20 box under above link
It is a complex matter, sometime small change triggers permutation of instruction which can result in a big performance hit (popcnt issue see: https://stackoverflow.com/questions/25078285/replacing-a-32-bit-loop-counter-with-64-bit-introduces-crazy-performance-deviati ) In case of clang, there are some compiler flags that you can use to see optimization reports - see: http://clang.llvm.org/docs/UsersManual.html#options-to-emit-optimization-reports . I assume similar flags can be found for other compilers. But I am not aware of anything aside of DIY own performance tests as part of CI to ensure performance is right. BTW does anyone knows if it is possible to make a clang report to be localized for a single hot loop/function? (like diagnostic push/pop ?) It would be helpful to find out compiler did not unroll a loop after its upgrade..
&gt; But the C++ compiler doesn't check for correctness. Tests do. And that seems to be one of the point made in the article. C++ doesn't, doesn't mean no one should. Otherwise you can easily make the similar argument regarding "some weakly dynamically typed language doesn't check for type correctness. Tests do".
&gt;Actually, I was referring to the "it was added per committee feedback" part. &amp;#x200B;
&gt;It can't be easily unit tested It can be. See llvm test-suite.
Irritating culture and annoying habits? Care to elaborate?
Thanks I will!
&gt; It can't be easily unit tested You _could_ automate a test on `c++ -S` output if you like.
1. Do you guys use exceptions and `noexcept` in production? Exceptions and destructors without `noexcept (false)`? That are "potential crashes". Do you check pointers for `nullptr` every time before dereferencing? Do you call functions with narrow contract without checking preconditions? ;) 2. Contracts is not a form of warning. It is a specification of expected conditions. If function expects something it can be implemented with strong reliance on such thing. Look for example at `std::vector`. Failed precondition on `front()` or indexing operator leads to UB. It makes no sense to talk about resuming execution after UB. Or do you propose some sort of catch-fix-and-continue contract handlers? As many others pointed out: if you want something else from contracts maybe you actually don't need to use contracts for it - use logging.
&gt; I don't see example anywhere in the thread Well keep looking, you'll find it soon enough . &gt; Critisism is great when it has some base. Yep. Mine does. When you're done complaining, feel free to go back to looking for it.
This is great to see. Thanks for the hard work!
That is certainly not how the design presented them. Also see my public presentations, especially the CppCon 2015 talk. Macro isolation is just one of the four criteria I put forward. I do acknowledge that discussions of modules here and elsewhere tend to focus on one specific aspect.
Yes, we should work on a paper to clarify that. I would wait for the post-Kona Working Draft to appear since that is what we would be diffing against for this specific point.
As an embedded developer, I tend to disagree. Vocabulary types are great, but when I want to communicate with actual hardware, there's hardware/platform specific reference documentation.
As I mentioned previously, C++ syntax is almost entirely agnostic but C++11 introduced attributes as a way to introduce implementation specific syntax of the form ```[[attribute_name]]```. Attributes are said to "appertain" to a statement identified by the syntactic context in which it appears and an implementation may treat that syntactic context as ill-formed due to the presence of an attribute. Generally implementations that do not recognize an attribute simply ignore it entirely.
The penalty is negligible compared to the gain you get by having custom tailored allocators.
Your comment is incorrect but even if it were correct it has no relevance to this discussion. The C++17 standard can be found here: http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2017/n4659.pdf Page 6 of that document defines what constitutes a valid C++ program and it specifically defines it as follows: &gt;C++program constructed according to the syntax rules, diagnosable semantic rules, and the one-definition rule. Undefined behavior does not violate any of C++'s syntax rules as it's a run time property of a program. Diagnosable semantic rules are quite complex to define but we don't need a full definition of it because the Standard specifically states that undefined behavior is not a diagnosable semantic rule on the first sentence of page 7. That leaves only the one definition rule. Violating the one definition rule does result in an ill-formed C++ program and also results in undefined behavior so in that specific case yes it would be ill-formed. But any other programs that engender undefined behavior are well-formed as far as the standard's explicit definition for what constitutes a well-formed program.
What's implementation specific about the attribute syntax? You've given non-specific example. C++ language only specifies a handful of attributes, others - are not it's concern. They are no different than some implementation-provided macro, library or extension.
It's tough to discuss this in layman's terms which is why I don't care to make a big deal about the syntax. If we wish to be formal then the C++ standard states that implementations may define their own attributes and for those attributes they are welcome to take the syntactic context that said attribute appertains to and treat that syntactic context as ill-formed even if it would have otherwise been well-formed. In other words, a compiler can take an attribute and reject a snippet of C++ code on the basis of that attribute whereas another compiler can take that same attribute and accept that snippet of C++ code.
If function have precondition it is usually not an empty demand but something that is relied upon in function body. For example `std::sort` can result in out of bound access when used with wrong comparator. So contract violation leading to UB is not uncommon. It makes no sense to continue execution after UB. Even if your current compiled executable would appear to do what you want any change in source code, environment or tools can lead to unexpected behavior changes. 
Where? I'd be interested to know too.
A didn't write the program that contains UB is not well-formed. I wrote that the program that relies on particular implementation of UB. UB is by definition is undefined and International Standard provides no guarantee that it won't format your hard drive or do anything else, as such if you rely on it you program is not only invalid C++ but invalid program in general.
Well with regards to polymorphic_allocator containing a non-owning pointer to a memory_resource, I personally tend to agree with what John Lakos (Bloomberg) said with regards to constructors taking pointers vs. a reference (Can't remember which talk). He stated that constructors/functions that take pointers make it clear that the lifetime of the object to which the pointer points to is not managed by the object/function to which it was passed and that it is up to the programmer to manage the lifetime him/herself and ensure that the pointer remains valid while the new object is in use. With regards to a function that returns a container that uses a polymorphic allocator: I primarily view pmr::memory_resource as a customization point and therefore a function should only ever return a container that doesn't use the default resource, if a pointer to a specific memory_resource was passed in by as an argument by the caller. Furthermore, the fact that "polymorphic_allocator does not propagate on container copy assignment, move assignment, or swap. As a result, move assignment of a polymorphic_allocator-using container can throw, and swapping two polymorphic_allocator-using containers whose allocators do not compare equal results in undefined behavior. " can be problematic, but once again since this is more of a customization point for users who understand the costs of move/copy operations and how un-intrusive containers broadly work, I think it's manageable but I also don't see how it could work any other way since propagation has to be a compile time property but the polymorphic-allocator can be given at runtime, so the worst-case has to be assumed. 
It's fine if you have your own private definition of what a valid C++ program is or isn't, people are entitled to their own opinions after all... but without providing a formal definition that can be agreed upon then that's all your definition is, a personal opinion. Undefined behavior is explicitly and consciously used by many C++ programs and libraries including boost, Qt, cryptographic libraries, Facebook's folly, and almost any non-trivial C++ program. In situations where the decision to engender undefined behavior is consciously made to satisfy a narrow use-case, it's perfectly legitimate to use it. You are welcome to call it invalid in spirit, just like perhaps you have moral objections to the use of other aspects of C++, like maybe you are so opposed to the use of macros you consider any program that uses macros to be invalid C++. That's fine too... none of this is remotely relevant to this discussion.
"Filesystem" in C++ doesn't have to deal with details for implementing filesystems, or how to allocate blocks to specific block devices in an array, or what the allocation unit size is. The threading library doesn't let you schedule threads on specific CPU's, or know enough about the CPU to implement a C++ eval() so you can generate machine code for the CPU. All of that lives outside the language, in the OS. I would say talking to specific block devices to implement your own filesystem is analogous to pumping buffers that have to be in a hardware-specific format into specific audio devices. And it's something that can comfortably be handled outside the score of the language itself. If you want to add hardware interaction on top of the vocabulary types later on, it's always gonna be easy to add to the language compared to trying to deprecate it and take away something that existing code might have started to depend on. I used to work in post production, and I had to deal with stuff like writing control UI for big SDI video routers, and keeping the right config for Flame systems that had multiple audio outputs, some of which would go to the router, and some of which would go to an extender, and all of which needed to stay in sync with some video... Audio is a complex fiddly pain is the ass of a bastard when you get to actually depending on it, and it's easier to get something narrow in scope right and build on it later. Since C++ doesn't generally have standard idioms for dealing with hardware, I think starting with a minimal std::audio, and then something external like boost::audio_hardware that uses the std::audio types would be the way to go. Since the current draft of std::audio exists as an external library on github, it's clearly not something that *needs* to be in the language to function correctly. 
&gt; C++ is error prone because it must give you low level control for performance and integration reasons. I feel like the bigger reason that C++ is error prone is that it aims to be mostly compatible with C, which is just a terribly designed language.
If you want to do multiplatform code, you only hope for the language and/or the standard library to provide everything in a single interface, whatever the underlying system. We are in the 21st century! 
This. I think the jist of it was that the gains in locality far outweigh the cost of virtual allocation. Here are some benchmarks that the above poster is referring to: [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0089r0.pdf](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0089r0.pdf)
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/axkcfe/france_riviera_vs_a_remote_jobgermany/ehvdpzv/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
For a specific example, whether the sequence of lexical tokens below adheres to the C++ syntax rules is implementation defined: [[gnu::visibility("")]] int main() {} In GCC, the above sequence of lexical tokens does not constitute a well formed C++ program. In MSVC and Clang, that sequence of tokens is well formed. The ISO C++ Standard leaves it up to the implementation to decide whether the above sequence of lexical tokens adheres to the C++ syntax rules or not.
Everyone in this thread is hereby warned against spiraling into increasing hostility.
Implementation's own attributes are non-standard, they are language extensions. So implementation that would make well-formed program ill-formed would be treated as non-conforming. I'd also argue that it still doesn't affect the C++ syntax in any way.
&gt; Since the current draft of std::audio exists as an external library on github, it's clearly not something that needs to be in the language to function correctly. The problem with the standard library is that it is tied to a compiler vendor, not a system. In the C ecosystem, there is the standard library and there is POSIX. POSIX provides some features that deals with the system, not the language (message queues, sockets, shared memory, etc). C++ lacks this kind of standard extension. 
&gt;Implementation's own attributes are non-standard, they are language extensions. As a matter of opinion you can refer to it as a language extension or come up with whatever wording you'd like, but that's not particularly relevant. The point is that the C++ Standard explicitly states that whether a sequence of lexical tokens represents a well formed C++ program is in some cases left up to the implementation to decide. If we can't agree that allowing an implementation to decide whether a sequence of lexical tokens constitutes a valid C++ program implies that **some** C++ syntax is implementation specific, then that's fine but we can no longer proceed to have a conversation on this issue as that would be too fundamental of a disagreement.
With the added complexity that Make is not a build system, it's a language for writing rule based expert systems for implementing build systems. It was typical to have a pre-build scan step to determine header deps until the late 90s. It didn't work well then, but the tools weren't coming from the compiler vendors. Rebuilding the make files as dependencies were re-calculated also led to n\^2 build times, as each dependency check would start the build over from the beginning, or scanning everything every time, which is a large constant for a particular build. Neither was very popular. 
how else will it become sentient?
Do you use `assert`? Do you enable it in release builds?
Could you point to some documentation about how those declarations look like in HPC#? I didn't find anything about that in the article (but I only skimmed some parts)
Good work! I couldn’t dream of putting something like this together when I was starting out in C++. A gentle suggestion: I would ditch the *RubberArray* dependency. Its implementation looks confusing at best. You could just use a plain old `std::vector` or `std::list` in its place.
I've been searching for a solution to this as well. With the number of `assert`s in my code, clang-tidy has become unusable with warnings about array decay and something in `__PRETTY_FUNCTION`. Seems like a configuration to ignore macros, or specific macros, would be useful, but I haven't found it.
Fair enough.
Structs/Classes must be initialised in the member order. By enforcing the order they avoid the multitude of bugs that people encounter with constructor initializer lists.
In fairness, this API made infinitely more sense when the typical thing to get passed into for_each was an actual struct that you had to write out. In modern code if you want to accumulate state you would just initialize the accumulating variable locally, and then pass in a lambda that captures by reference and performs the update.
They list many issues with allocators, but I don't think that polymorphic allocators address (or can address) many of these issues (many of these issues are boiled into the container-allocator interface boundary). I'd also be very surprised if game devs would like the virtual function call and extra container size called by polymorphic allocators, but maybe I'm wrong.
Are you able to provide some further ? Not all of us have your depth of knowledge of the subject :(
I'm just getting constant flak, so, no. 
The pmr stuff is a bit weird insofar as its been heavily pushed by people from a very specific company. Outside of that specific group of people, I've rarely seen much interest or usage of it. Because it's library only and doesn't modify existing types in any way, the bar to have it accepted is not as high as it would otherwise be, so I think despite not necessarily appealing to a broad audience, it was able to get through. You've already been able to write your own allocator forever, though I agree pmr does make it significantly less intimidating, which is good. One issue with it is that it makes types larger by one word. This could be a total non-issue or a really big deal, depending on your use case. I think it's unlikely that future containers accepted to the standard will not have an allocator template parameter. Another issue is this: while its true in general that virtual function costs are dwarfed by the cost of actually asking the OS for memory, one of the actual points of allocators is to avoid that cost in various ways. The more straightforward your setup is, the simpler your allocator can be, the lower the cost of performing an allocation with it. Of course, if your setup isn't straightforward then your allocator will perhaps not be very simple, and it won't be as big a win for you. This is all a long-winded way of saying that some of the biggest wins you can achieve with using custom allocators is with really dead simple ones, like arena allocators. Where an "allocation" is just bumping an integer. In this case, the virtual function cost looks pretty bad.
Well, up to you, though if the very idea is as wrong-headed as you appear to think, these tools will surely make your case for you.
&gt; There is not a single program on earth for which performance isn't correctness while (true) { ::usleep(1000); } Where are my sunglasses when I need them?
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/axsb4t/intel_compiler_does_it_support_compilation_for/ehvs1nm/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Hey guys, you move fast as hell!
I saw the paper and do not remember well but anything that requires additional boilerplate is a waste in my opinion.
Two things to note: one, their approach is as a pure subset of C# with no additions to the original language so they rely on "tricks" to trigger their behaviour; two, they aren't actually done yet so it's all kinda in flux. In their example at https://lucasmeijer.com/posts/cpp_unity/ most of the magic happens at line 214: [ComputeJobOptimization] struct TraceRowJob : IJobParallelFor A job derived from `IJobParallelFor` automatically triggers various compiler behaviour; their compiler doesn't allow code in a Job to contain data races. Which implicitly means the class is barred from using anything but PODs, built-in arrays, and certain library data structures (e.g. `NativeArray`). For loop optimization they're still working out the bits with how iteration of `NativeArray` is special-cased and what annotations (like the `[NativeDisableParallelForRestriction]` in that sample) would work. From that article: &gt;Data races, nondeterminism and deadlocks are all challenges that make shipping multi threading code difficult. What we want is features like “make sure that this function and everything that it calls never read or write global state”. We want violations of that rule to be compiler errors, not “guidelines we hope all programmers adhere to”. Burst gives a compiler error. &gt; &gt; We encourage users (and ourselves) to write “jobified” code: splitting up all data transformations that need to happen in jobs. Each job is “functional”, as in side-effect free. It explicitely specifies its readonly buffers and read/write buffers it operates on. Any other attempt to access other data results in a compiler error. In C++ land, this would more likely take the form of a something like `pure` function annotations, which would play directly into lambdas for parallel algorithms, for heterogenous computing (e.g. writing OpenCL/SYCL kernels directly in C++), OpenMP extensions, and so on. Unlike HPC#, C++ can also generalize this from magic types in proper annotations, a la the GSL-style annotations in Herb's recent paper on lifetime bounds analysis. Which incidentally is the _original_ reason that Rust added lifetime annotation (the memory safety without GC was a just a nice knock-on effect from their original goal of fearless-and-efficient parallelism).
Yes, but contract violations that lead to hard UB are also much less likely to be the violations that are happening in your production system - they would have already been leading to crashes and hopefully been fixed. It's the violations that lead to wrong results but not crashes that make adding terminated contract checks hazardous. A binary search on an unordered list will just return the wrong result - but still one in the list, and still one that can be operated on. Enforcing that contract in many applications turns poor behavior into a crash, potentially bringing down essential systems with little or no warning (even more likely if the bad data is a corruption in production state that isn't replicated in its entirety in testing environments). Again, continuing after contract violations in new code is never the right answer. Continuing after newly introduced or activated contracts is the only safe route to turning those contracts on in a production system --- as a step towards making those contracts terminate when it becomes clear they are not being violated by the current system.
Oh, I see. Originally \`format\_to\` was something quite different, using a buffer instead of an iterator. The Library Evolution Working Group asked to change that which was quite a nice improvement.
In this example, you could still get a warning for unsigned-&gt;signed conversion (assuming your `n` was unsigned). If you don't use integers, code is less likely to compile so it usually saves you from trouble for this specific case. It is very tricky, not going to deny that, but hard to change at this point now.
Only took a few years to lift this from C.
You provided nothing of value and can't even pretend to have done so, evidently. I'm not here complaining or looking for an argument, though yes that's exactly what I expected. You simply did not provide any substance in response to OP twice and I'm content to waste your time here. I'm enjoying myself, I really am. 
In his CppCon 2018 talk, Odin talks about situations about situations where a correct implementation must deliver performance within a particular bound. This is different from a static assert on the presence of an optimization, but seems related to me. Clang has -Rpass-missed, and I've used that before to tune a routine which I felt should be inlined until it was small enough to be inlined by the model. If there's a particular optimization that you require for a particular routine, it seems straightforward to verify that optimization pass succeeds for that particular routine. With respect to vectorization, some algorithms are more readable when expressed directly with intrinsics than trying to write equivalent scalar code provided that portability isn't a concern. (vpmovmskb comes to mind) Given that most forms of optimization are features of the compiler rather than the language, I don't think that coupling optimization passes with the language is consistent with the rest of C++.
&gt; How C++ Developers Use Immutability Declarations: an Empirical Study When I see "immutability" in C++ context, my first recall is `constexpr`, and the second is what-I-call data encoded in type e.g. `std::integral_constant`. So I Ctrl-F-ed, and the results were "no matches." &gt; This work investigates how C++ developers use immutability by analyzing their use of the C++ immutability qualifier, `const` It turns out this paper is about `const`. But doesn't `const` merely mean logically unchange, which allow underlying, unexposed changes? Isn't "immutability" a far stronger word with stricter meaning compared to "constness" in C++ jargons? Reading on the abstract, there are more disconnection in terminology. - "non-trivial" class means class with "more than 3 methods" in this paper. It has nothing to do with "trivially copy-constructible" etc. - What is "immutable methods"? Can functions be immutable? I always think data can be immutable and functions can be *pure*. - "`const` annotations", "`const`-annotate", instead of "const-qualifier", "const-qualify". - Similarly, "label", "annotation", "annotate", etc. instead of "qualifier", "qualify" etc. I don't think this is inherently wrong, but I don't find it necessary either. I wonder why the authors make these terminological decisions.
I understand the use case. But if you say, continuing after contract violations in new code is never the right answer (which I agree with), then we really shouldn't allow them to do that. It sounds like for this use case you don't want C++20 contracts. You want something else. Like a logger that you can perhaps hide under a macro that can later be switched to become a contract instead. But please don't break contracts themselves for everyone else.
If you're willing to let people turn your checks off (a feature most people consider implicit in contract checking) then why would you want to prevent people from checking and continuing? Both are equally dangerous, but one lets you actually diagnose what might have gone wrong instead of being left clueless as to where a problem occurred - without turning that mistake into a forced hard crash. I'll turn around what you guys keep saying - it sounds like you just want to check something and call std::abort, not have a checking facility with failure modes configurable by your users. Please don't break contracts because you want to have a draconian enforcement of contracts that are likely being broken today without you knowing. Using macros to make something magically log instead removes many of the features of contracts being in the language - you can't put logging statements on a function declaration, or pure virtual functions, or before contructors create member variables. Similarly, every use case i've mentioned is something that is going to apply equally when dealing with contracts on code delivered in other people's libraries - don't make me rewrite those whenever I need to change he contract checking levels in those libraries.
A tensor is a special mathematical object that represents a linear transformation of coordinates therefore it has special rules about how it rotates and transforms. There is a representation theorem that says rank 2 tensors can be represented as a square matrix (which makes using them much easier as we can use the standard linear algebra tools e.g. multiplication, eigen decomposition etc). However, a matrix is essentially just a "box of numbers", so there are no rules about what those numbers represent, or how they transform. So, a rank 2 tensor can be represented as a matrix, but a matrix is not necessarily a rank 2 tensor.
&gt; these tools will surely make your case for you. you would think, but i've posted them, they didn't, and i'm getting inboxed about once every 20 minutes by people who want to insult me, and a mod told me to drop it, so, i'm following instructions this is why i've mostly stopped participating in this sub, honestly. i used to be a regular.
Well, looks like we will have contracts in C++20, so let the correctness checking begin!
I do not see why you cannot implement on top of Meson or CMake a reasonable, user-defined module mapping, even if it is implementation-defined, that can avoid this scannig stuff that raises so many concerns. Having a mapping can speed up scanning algod a lot.
This reminds me of all the why do you love windows 8 videos, and I was shouting about the amazingness of network kernel debugging.
Who uses direct initialization for references to begin with? Use `=` like a normal person.
&gt; but I just checked std::for_each and discovered - to my surprise - that it actually also returns the callable o.O Stateful function objects are _the entire point_ of the algorithm.
Gamedev here. We've been using polymorphic_allocator for years now. Don't generally care about object size or virtual calls in this context. Sometimes it might matter, but then you'd probably wouldn't use a dynamically growing container anyway.
You could argue that is the program is so slow that it never reaches the sleep call, then it would be also useless, because it would not be actually idle, but spinning. ;) Even with `int main(){}` you could say the same if if your only output, the return code, is never returned.
&gt; Cmake developer How do you live with yourself? ^(^i'm^kidding)
Thank you 👏🏼 I will do that.
And what is the purpose of the program?
Exactly
Maybe the authors aren't c++ experts or they don't expect the readers to be. It seems they rather chose colloquial meanings for certain terms rather than language definitions. I haven't read the paper. What was their datasets?
The compiler would be entirely free to rewrite this as `return 0;` - infinite loops like this are UB
So, here are two fun examples of "poor behaviour that was better to have than to crash" * http://heartbleed.com * https://bugs.chromium.org/p/project-zero/issues/detail?id=1139 Sorry, I meant "that should've absolutely, positively and assuredly hard crash instead of keeping going". Arguing that it is better to keep going on inconsistent state for anything accessing the internet in the year 2019 is mindboggling. Mind, I am not against having contracts throw a specific exception, so if you have exception safe code, you avoid the problems of inconsistent state without killing the process, but keeping execution going is just wrong.
Thank you for making CMake great again! Nice to see that you don't have to change (that much, just the versions probably) your CMake files to have modules support in CMake. You "just" need to modularize your C++ code. Making changes to the build system in a large project is a pain. You take this pain away. Thank you.
Whether audio should be in the standard aside, my main issue with the current std::audio proposal is that it requires the program to adapt to an arbitrary sampling rate chosen by the mixer without exposing the system facilities to do sample rate conversion. This requires SRC to be done by the program with potentially a pretty wide range, at least 22KHz-192KHz. Any program that has a reasonable SRC routine probably already has the required interface to the low-level playback API, which makes the minimal layer in the initial proposal of dubious use by itself. 
&gt; Enforcing that contract in many applications turns poor behavior into a crash, potentially bringing down essential systems with little or no warning (even more likely if the bad data is a corruption in production state that isn't replicated in its entirety in testing environments). Good. That means the bug will be quickly noticed and fixed.
... Unless they contain side effects, like calls to `extern` functions like `usleep`.
&gt;You don't get to specialize function templates. [http://eel.is/c++draft/constraints#namespace.std-5](http://eel.is/c++draft/constraints#namespace.std-5) Is this invalid c++ code according to the standard? [https://gcc.godbolt.org/z/-ELNWB](https://gcc.godbolt.org/z/-ELNWB) My understanding on the matter is very limited (I usually trust the compilers, and this code compiles with gcc, clang, MSVC and icc), but if I interpret it correctly: * it depends on the name of at least one program-defined type (`my_clock`) * the instantiation meets the standard library requirements for the original template (implements the [`Clock` named requirement](https://en.cppreference.com/w/cpp/named_req/Clock)) Also I think that the linked paragraph refers to class templates only, not function templates. &amp;#x200B; Running this code takes 2 seconds (as I would expect). If you comment out the \`sleep\_until\` implementation, it takes 6 seconds (tested with gcc and clang only). &amp;#x200B; &gt;I wouldn't be in support of such a proposal, but I wouldn't be against it either. Cool, that's something, thanks! :-) I wouldn't know where to start to make such a proposal, though...
&gt; Is this invalid c++ code according to the standard? https://gcc.godbolt.org/z/-ELNWB It's UB, yes. I'm not sure why /5 was cited, as it only pertains to class templates, but /7 is relevant and `sleep_until` is not a customization point AFAIK.
you are indeed right, I thought that the compilers would see through the deception
One module which spans multiple files is easily solvable with hierarchical sub-modules. One of the issues here is that it's not clear what is module semantically. A translation unit? Seems no. A linkage/delivery unit? Nope. Was it designed to span from former to latter? Not clear.
The usual answer to such "multipart" modules are hierarchical modules. Module "foo" consists of modules "foo/bar", "foo/baz", "foo/ugh" etc. and then reexports eithercontents of its submodules or subomdules themselves, as necessary.
literally nothing
I think the post you responded to was asking "which matrix, using standard linear algebra interpritation of the numbers, and bog standard orthanormal basis, is not a tensor". And you restated the quote he was asking about instead. 
Agree! But just the fact that the language allows both but treats it differently is horrible. Especially when both versions compile but only one is actually valid. 
&gt; The whole pipeline thing is going to make the most ugly code ever, worse than all the template-programming stuff I never heard this kind of opinion before. I'll remember this.
Thanks, I think I'm starting to understand the reason for this being UB, even though I don't see a real problem if the class and the specialization are defined in the same file. Or maybe I'm missing something? Anyway, in this case I think that my proposal to add a real time factor to the \`Clock\` requirement makes even more sense now, since I cannot find a legal way to fix this.
Gradle actually has support for C++(can't remember if it was plugin or part of itself tho), but I haven't used that yet
Ok that makes sense and is a really good point. I haven't thought about that this API makes more sense without having access to lambdas. 
Do you have a github account? I’d like to credit you for the advice you’ve given.
It says it's 21EUR
No, it means that people with large, complicated systems written by developers of many skill levels will turn contract checking on once in production, crash horribly, lose customers and money, and never again turn contract checks in production on again. This leaves them significantly worse off than they would be if they had a way to safely turn on their checks without otherwise crashing their systems. This insistencee on not providing continuation gives people just 2 choices - a shotgun and a blindfold. Worse, with the draft as it stands today, unchecked contracts are treated as language-level UB, so your choices are a shotgun and a shotgun pointed at the back of your own head while blindfolded. Continuation at least lets you open your eyes to see where the shotgun is pointed before you pull the trigger.
[removed]
How is loop in here UB?
I see a band *"Time is running out to access this title for free11:04:11"*, counting down. 
Thanks!
I guess the point I was trying to make is that a tensor is a fundamentally different object from a matrix, and is only representable in matrix form once a coordinate system is chosen. A matrix just holds numbers and has no concept of coordinate systems. So, If the question is essentially when mapping the set of arbitrary tensors under an arbitrary coordinate system to a matrix, does the matrix have the range of all real numbers, then the answer is yes. I hope this clarifies.
To see that one needs to register. - Ok fine. - Oh, noscript is blocking captcha, alright, let's allow all domains on the page to run js. - Oh, the registration failed, because there's now a new domain that needs to be allowed. - OH! Ooooh... Now you think my username has been registrered due to previous attempt and won't let me use it? Greeeat... Note: By "you" I mean whoever is behind PacktStaff.
Thanks
C++ sort of has that with partitions, but you only get one level. Still, it isn't as simple as a `modname -&gt; filename` function; you really need `modname -&gt; [filename]` and the content of that array depends on the contents of the file…
&gt;Something went wrong please try again...
Right now, it's keyed on "are you using C++20" and "does the compiler support extracting module dep information". There will probably be a target property to say "nope, no modules here" to skip the extra build logic too. Note that header unit modules and external modules will almost certainly need some extra CMake code, but if patterns show up, the details can probably be hidden behind convenience APIs.
Same here :/
It's still will be the most compliant Check out @GorNishanov’s Tweet: https://twitter.com/GorNishanov/status/1100485900755062784?s=09
Sorry, but I object to this advertising. There is no free e-book. Iff one opens an account at packtpub.com and one 'claims' the book (whatever that means) one can read the contents of 'the book' in a browser, that's it, one can only read this 'book' online, while logged in, which makes it a collection of some web-pages with restricted access.
Server has problems it seems.
I think STL containers should still have a template parameter for allocator, but it should be `polymorphic_allocator&lt;&gt;` by default. The additional template parameter for the allocator has no downside, especially since C++17.
I'd say it's [EUR 26.04](https://imgur.com/a/HGnfBlo), free is not what it used to be!
Clion... No, thanks
Thanks for sharing the document. It was an interesting read. I really hope ninja + CMake will support modules on time when implementations come out
Thanks for the info, I guess you guys do not make use of ultra simple allocators like arena allocators?
Why do I see EUR21.00? https://imgur.com/dLmxowN
They like you better?
Maybe I'm prettier... I doubt it, but who knows...
This must be a thing for only southerners. I got my engineering degree in Sweden. Not in computer engineering, though I had my basic classes together with them. If they paid attention, they should know the basic parts of everything from embedded compilers to building speakers to physics and linear algebra. These are just things anyone with an engineering degree should be aware of. Why do people title them engineers elsewise, and not technician or scientist depending on depth of knowledge?
I'm a student and got it free, what's wrong with it if I may ask?
Well, that's easy, I'm ugly! :-)
I noticed one difference, I'm logged in, while you weren't.
[removed]
Prices work on a country basis with local taxes applied ;)
So the tax on a free e-book in my country is EUR 26.04, how does that work?
[removed]
Reality: Debugging a program on another machine Expectation: How to program from exotic locations 
Nice! I'd like to point out that this program is using the \*\*master\*\* branch of Boost.Beast which has support for built-in websocket timeouts (and many other things). Bravo!
It would be really nice to stop using shared\_ptr where unique\_ptr is far from enough... And [Nlohmann JSON](https://github.com/nlohmann/json) is really really slow honestly
&gt; I'd expect the while loop to simply disappear when enabling optimizations. [It'll depend on the compiler.](https://blog.regehr.org/archives/140)
Well well well. Isn’t it the boost man himself?! 😂 Love your library. Thank you for the recognition 👏🏼
I'm not sure. On the other hand I'm not sure why thermodynamics, 3D kinematics, surveying, material deformation, and fluids, were required for my undergraduate studies.
I am willing to optimize as time goes on. I am still very new to C++ as I started out with C++ ~3 weeks ago. I decided to go with Nlohmann JSON because it was the only library that Worked for me at the time. I have some ideas of how to create my own JSON library with a different coding fashion that resembles JS a little bit more. I’m all for ease of use. Performance might take a hit due to my thought process.
Remote debugging is all about setting up gdb-server. Once it's done, you don't really need a GUI (like CLion or any other) for successful debugging.
We use a bunch of different allocators. Those include arena allocators for specific systems and super simple bump-allocators for scratch memory. The virtual function call to acquire memory isn't really an issue regardless of the simplicity of the underlying allocators. The biggest gain from pmr IMO is passing around allocators to functions without having to make everything a template. 
I suspect the issue is that you're calling "start", and the argument is getting de-quoted by start. Try: system("powershell.exe \\"C:\\\\spaces are bad\\\\example.ps1\\"");
I've been through the thread again and can't find where you may have posted them. I am now officially finding this whole affair somewhat mysterious! Somebody else posted a link to llvm test-files, and looking at that is now on my to do list (I don't have high hopes as it appears to be for testing llvm itself, suggesting that some self-assembly may well be required for making it work with random code). (There was only so far back through anybody's comment history I am willing to trawl, so went I went to see whether you perhaps meant you'd posted this stuff in the past, I didn't find anything obvious.)
It requires the JDK (or is it just the JRE?) to work. To some people that's the 8th deadly sin.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/ay0tia/transforming_from_beginner_to_advanced_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Packt = no thanks, regardless. They have *some* good books, but mostly they're just blasting the market with crap and seeing what sticks.
it's really hard to just say no on reddit without someone saying "omg i find this mysterious, i went snooping, i'm trying to call you out without being explicit about it" the mods said to stop. i stopped.
&gt; Do you use assert? Yes, but rarely. &gt; Do you enable it in release builds? No. Failed assertion crashes the application and does not call destructors. I prefer using exceptions in such cases. In my line of work usually one failed subsystem should not bring down entire application (but I know some applications that are fine with terminating on failure). And you know that violation handlers should be able to throw exceptions, right? Letting failed application with inconsistent state to run and wreak havoc is far worse. IMO when you encounter failed precondition you should stop the execution of that piece of code - by aborting whole application or throwing an exception. Either way: 1. "potential crash" of `noexcept` doesn't stop it from being "largely used in production". 2. "check contract but ignore it" mode brings nothing good over throwing violation handlers. Except for potential UB in production code.
My experience with free things is you generally have to open an account. Taking your word for it about the rest of it, I agree with you.
The problem is not in quotes, you cannot start powershell as is, check Win docs when you started not from shell.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ay09x8/calling_powershell_script_with_spaces/ehxinpc/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I'm assuming you're referring to https://www.modernescpp.com ? (Just want to be sure I've got the right one.)
Link is dead.
Correct, though im reading the german version. Ive read every article, theyre great 
Fair enough, thanks for the info.
Having used IBM Aix extensively in the early 2000's, it surely allows for multiple directory levels like any UNIX.
Also contrary to Conan, Microsoft is able to prove that C++ build tools are perfectly fine to be written in C++, as they should.
Any actual reason or just "haven't tried it, must be shit"?
Depends pretty much on the country. My Portuguese Informatics Engineering degree (5 years duration), was pretty broad. Maths, physics, electronic, data structures, systems programming, distributed computing, information theory, compilers, 3D graphics, artificial intelligence and so forth. Basically level I lectures were compulsory, while level II were optional, and we were required to choose enough level II to reach minimum amount of credits, but we could have more if we so wished. After Bologna, the 5 years degree (Licentiate) was made into one that gives a Master title at the end.
Thank you. It should be fixed now. I moved that directory recently and forgot about this link.
On Portugal they are required because any Engineer should know them, and the profession is regulated. You cannot legally just do a 6 months bootcamp like in US and call yourself engineer. Although the title usage is usually only enforced for those legally signing projects as such.
Wouldn't the employer be paying for it anyway? So, what does it matter if it's not "affordable"? At the end of the day they have to decide what's the cost of continuing with the existing bugs vs buying the tools to fix them.
I encountered some projects in the past that were using some unfamiliar systems. When trying to do something with them, I simply came up with a naïve replacement based on cmake. It seems cmake is also somewhat supported: http://docwiki.embarcadero.com/RADStudio/Rio/en/Using_CMake_with_C%2B%2B_Builder Perhaps that might be an option you could consider.
Of course, my employer should've provided me with all required software, but as i understand, its one time task, and we're planing to build future projects using Qt. But you right, it shouldn't be my concern. 
Thanks, i hope it will work 
Neither worked :(
Well it works for other commands
Dude, come on.
Just joking. =)
Just repost on r/cpp_questions
Would alignas(uint8_t) help? Otherwise, possibly move the opcode into the three structs? Accessing a common prefix of structs in a union is allowed, so you'd still be able to read it.
I never got why some people think they shouldn't be. I mean, ultimately it doesn't matter what language they're written in, but installing another compiler/interpreter/runtime for a package manager or build system is just another dependency. Which comes with a cost.
I love it, it's worth every penny, and it's as buggy as other IDEs
I cited it because that's the place that gives users permission to specialize stuff in std at all, and that place only gives class templates permission.
The reason for it being UB is to allow the standard library to change signatures without being considered breakage (as happened to swap in C++17), and to allow implementations to optimize things assuming the user isn't doing something odd. For example, this allows us to engage our handwritten vectorized std::reverse for trivially swappable things, even though the spec says that reverse calls iter_swap rather than swap. Even the permission to specialize structs arbitrarily is probably excessive; for example, this makes implementing optimizations on the basis that a supplied allocator is std::allocator hard, since the user can explicitly specialize that.
You’re actually supposed to use dllimport if you have client code that’s using an interface exported by a dll. Additionally, dllimport/dllexport is normally hidden behind a macro so that it can be used (or rather, not used) on platforms that don’t have an equivalent. While likely not applicable to a game engine, using STL types in an exported interface can get a little dicey in certain scenarios (eg executable and DLL using different CRT).
Great work, thanks for allowing us to easily test out C++20 modules (and, I guess, other C++20 features, as this has gcc-head) before they become the norm.
The Unisys UCPP compiler for OS2200 compiles to one's complement because the underlying hardware architecture (which dates back to the 1950's UNIVACs) is one's complement. I don't know how recently it's been updated, however. I've never used the Unisys C++ compiler though. I used their C compiler back around 2000 and 2001, however, and it was all one's complement.
Unisys OS2200 again. 9 bit bytes (36 bit words).
Thank you for that. I have made the modification to the code and put in a thank you at the bottom of the post with your comments.
I mean, yeah, if you're never going to enforce contracts until you deploy to production, you'll deservedly lose your job. But that doesn't mean that code should keep running in the face of contract violations. It means that code should actually be tested before deployment. Continuation also means that instead of a nice, safe crash, your system will get confused, corrupt its own memory, and end up sending bogus billion dollar payments to people who weren't meant to receive them.
&gt; You’re actually supposed to use dllimport if you have client code that’s using an interface exported by a dll. There's no _need_ to use `dllimport` for functions in any even-somewhat-modern versions of Microsoft's toolchain (e.g., VC6 or later). There's some codegen differences when using `dllimport` that can be advantageous for many scenarios, but it's questionable whether it matters on modern PC or game console projects (especially as final products will typically be statically-linked). `dllimport` is required for exported variables, though, otherwise it won't link. 
Yes, I’ve also read the MSDN page on the matter. I never said *need*. I said *you’re supposed to*. It’ll still work if you omit dllimport.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ay24ta/borlan_crad_studio/ehy48zg/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Sorry, but the "traditional" pattern example is much more cleaner and simpler. &amp;#x200B; * The factory stuff is outside of the food stuff. Separation of concerns and all that. * If you're going to use a macro, you may as well have used a macro to simplify the "traditional" factory. * In fact, if you hate the "traditional" factory so much, you could have simplified the registration with one variadic macro if you so wanted. * The factory stuff is all in one place, instead strewn about under some singleton hidden by a macro. * It's not as if the "traditional" factory is error prone. It's a very small piece of tedium. In fact, it's less error prone than the proposed solution, and only feels more productive because you have to write more advanced feeling code. The proposed solution is more tedious compared to the "traditional". &amp;#x200B; So actually, the "traditional" factory is actually quite modern, while your pattern is actually quite an old one, and one they teach in university Java courses for over a decade. I have worked with lots of Java source that used such patterns, and they were always worse for it.
Did I suggest not enforcing contracts before production? I don't believe I ever did. The problem is that many of us have to live with systems that are not fully tested prior to production. Large, complicated systems with highly varied and customized configurations and very complicated deployments that excercise countless permutations of those setups. I'd love to be able to comfortably say that we can test our systems with contracts checked and then know that those contracts won't be violated by some other common permutation of inputs in our production environment. I don't live in such a world, and it will be years before I could even consider being close to such a world. No amount of testing done in the near future will protect against contract violations already happening in just production, and causing those violations to be hard failures will mean losing those customers quickly and expensively. Yes, continuation might expose us to corruption or UB. However, turning off contract checking exposes us to exactly the same UB, and provides no way to actually diagnose what might be going wrong. Most importantly, continuation as a temporary measure when deploying a new set of contracts lets you go from having contracts ignored to having them enforced without unbearable risk. Not having continuation as an option means many companies will never take that risk and never be able to have the protection of any contracts in their production environments (and possibly anywhere if burned badly enough by misdeployment of contracts). 
I've never said that I hated the traditional pattern. In fact, I specifically mention that it isn't ideal for all cases. I never even made the case for this pattern being less error prone than the traditional factory pattern so I am not sure where that is coming from. Maybe I should have been more clear on my real-world application of this code. I am using this in my game engine to automatically register component types. I use the name of each component type in my serialized scene data which uses the string literals of the class names. Since I am adding many game components very frequently in the codebase, this pattern enables me to be much more efficient rather than having to manually register the type in the factory's code or next to the creation of the factory. The use for this pattern is much more niche than the traditional factory pattern and is not a candidate in many scenarios, however it is very useful in some.
For a correctly written class, a const instance of that class is immutable.
OMG!!! What's the problem? Very old-school. JRE is a framework like any other framework. Don't you install python or node just to keep your machine clean? In this segment Java is almost as fast as native if that's your problem
Ditto. Been re-learning it after 10+ years away. New stuff is quite nice!
Is the cmake the latest release or head? Or a branch. I have gcc_modules built already.
And I'm saying you're ceratinly not _supposed to_ be using it. Omitting `dllimport` isn't some deprecated or ill-advised approach. `dllimport` is a trade-off, not a free optimization. Use `dllimport` if you need to, or if you really want the minor codegen improvement (... and don't mind the costs, e.g. inability to delay-load, hot-patch, or shim those DLLs).
If your use of DLLs is fairly vanilla and dllimport gives you an optimization (albeit a small one), then why wouldn’t you just use dllimport by default? It really just sounds like you’re being a pedant for the sake of being a pedant.
Good article. As personal preference I like classes to contain only what they are meant to use. The static Boolean in each specialization of food does not have anything to do with food. What about having a dedicated class that calls the method on the constructor? Your taco.cpp would be something like: namespace { FoodFactory::Registration&lt;Taco&gt; registration; } The registration object can contain the Boolean *is registered* and everything would keep being the same, despite now your food is clean (that is important in a restaurant haha).
Thanks for the suggestion! That sounds like a great idea. I will implement this in my code to see how it works in practice and if it works (I don't see why it wouldn't) I will update the repo and bog as well as leave a thank you at the bottom. Better yet, if you want to create a pull request with your changes some time today, I would like to merge your code in to give you credit on the repo.
Not AIX in general, some specific FS. I remember even finding it on IBM site.
Crashing gives you a nice crash dump to load into your debugger, to make it even _easier_ to figure out the problem. That beats some message in an error log any day of the week. 
That would imply `mutable` doesn't have a single valid use case and is a systematic code smell, wouldn't it?
&gt; In this segment Java is almost as fast as native That hasn't been my experience. Not for general "fastness", not for latency (which makes coding feel sluggish even if it's "fast", though it's likely general Idea issue, rather than Java/JIT-ed languages. I didn't experience it in VS Code, for example) and especially not for memory consumption (simple hello-world type project could easily consume several GBs of ram).
Do note that changing printf to std::cout on the 'vanilla C++' example takes it closer to the 2 second mark
that's not what "real time" means in systems. I would suggest not using that term. 
This is actually the version of this pattern that I have in my hobby engine.
I outlined reasons you wouldn't want to limit your DLL arbitrarily via `dllimport`. The further cost of `dllimport` is increased complexity in shipping and building libraries that can be used as static or dynamic libraries. Your build system need to export arbitrarily-named inconsistent target properties (e.g. compiler defines) that every single client must use just-so to denote whether it's turning the `dllimport` macro "on" or not; failure to do so (or the client forgetting to use/enable the right flags) results in obscure linker errors in the "good" case (that can only be resolved by reading your library's documentation) and results in the exact same performance degradation you were trying to avoid via `dllimport` in the worst case (because misplaced `dllimport` causes the compiler to generate the thunk and indirection table "just in case"). The use of `dllimport` is a massive pain in the ass for little to no benefit for most libraries, and further incurs the limitations I outlined previously. Premature optimization is... well, you know the quote. :)
I think each line in your sample code here: Register("Burrito", []() { return std::make_shared&lt;Burrito&gt;(); }; is missing a closing parenthesis
You are right! Thanks for pointing that out. I wrote that code in my blog and not an IDE so I half expected there to be something wrong. And as for thread safety, the singleton pattern I use here should be thread safe if you are compiling with the C++ 11 standard or greater from what I have read since I believe that is when static members in the scope of a method was guaranteed to be thread safe. Someone else can correct me here if I am wrong. However, the inserting into the map is not thread safe from what I understand. Since all insertions in this example are done during static initialization it would be a problem if static variables are initialized in parallel. I don't believe that is how they work, but is certainly something I should look into.
No, not at all. mutable is supposed to be an implementation detail of the class. The whole point is that const methods are still not supposed to mutate *observable* state. Immutable in this context is not about the low level bits; immutable data structures in GC languages may well have bits they own change as part of reference counts for the GC for example. It's about behavior/semantics. If you write const methods that don't preserve const semantics, that *is* code smell.
&gt; If your use of DLLs is fairly vanilla and dllimport gives you an optimization (albeit a small one), then why wouldn’t you just use dllimport by default? Is 'vanilla' a good default for native code on Windows? I suspect most people doing vanilla things are using more vanilla languages to begin with...
I wrote: &gt; But doesn't const merely mean **logically unchange, which allow underlying, unexposed changes**? And you wrote: &gt; The whole point is that const methods are still **not supposed to mutate observable state**. I wrote: &gt; Isn't "immutability" a far stronger word with stricter meaning compared to "constness" **in C++ jargons**? &gt; [...] &gt; Reading on the abstract, there are more **disconnections in terminology**. &gt; [...] &gt; **I don't think this is inherently wrong**, but I don't find it necessary either. I wonder why the authors make these terminological decisions. You wrote: &gt; Immutable **in this context** is not about the low level bits; So... Are you disagreeing with me or what? I'm confused.
I didn't see this particular offer in time. But, I have downloaded several free PDFs from similar offers from Packt. No future logins required.
Not when you lose the customer for crashing on them in the middle of a busy trading day.
And if crashing continuously on a new release isn't going to lose you customers then by all means never use continuing contract checks - but don't demand the feature be unusable when there's a soundly proposed alternative that lets the rest of us deploy contracts sanely.
&gt; Iff one opens an account ... I did write that. 
&gt; especially as final products will typically be statically-linked I guess you mean the game components, not the third-party dependencies?
- Infinite loops without side-effects are UB - This must necessarily be an infinitely loop because `connected` is not atomic and the loop body does not modify it.
I have a free offer also. It's free forever, but there's still a benefit to signing up sooner than later. By signing up sooner you get a smaller account number. I use a variable-length integer for account numbers, so if your account number is less than 128, it will be marshalled as one byte, rather than two, three, four or five bytes for larger account numbers. It's not a huge deal, but the account number is part of every request to my service.
I don't understand, why do you think immutable can't allow unexposed changes? If they're unexposed, the user can't access them anyway, by definition. Immutable data structure is just one where the contract guarantees it can't be mutated observably. It doesn't say anything about the underlying bits and that's not even a concept that exists in most languages that have immutable data structures.
So, you briefly touched on the fact that static initialization is frowned upon, but I'd like to explain a bit more *why* it's frowned upon. Specifically, the C++ specification requires that all static initialization must be done before the start of `main`. That means that these functions are being called before any possible other code can be executed. So, for example: (1) They are used in a command line utility, I call "foo -h" to see the usage. Now all the static initializers run before it even gets to the "-h" and notices that it doesn't need them because literally all the user wanted was to spit out a (probably static compile time) string. (2) They are used in a library, somebody links this library from their GUI application. Now the static initializers must run before the very first window can be drawn. The user might not even click on the Food Factory widget, they might want to click on some other part. But time and memory are spent on initializing this factory. So for a small or single-purpose application, sure, go ahead and use them as a matter of convenience. But for reusable code or any kind of module in a larger application, be a good citizen and only do work and allocate memory at the moment it's needed. A static initializer at global scope is basically your way of saying "this code is soooo important, it's always first in line even before any request (e.g. user, network, IPC) is serviced.". 
Thanks for giving more info on the negatives of this pattern. In my case, I am using this in my game engine editor for all game component types so it is important in this project. I am planning on having compiled game executables use either a traditional factory and have the engine determine which types are necessary, or keep this pattern but strip out all component classes that are not referenced at all. I will plan on updating the tutorial tomorrow with the notes you brought up. I will credit you on the post as well.
Sure, if you know that you are the only holder of it. Otherwise, you could have a const instances of a class that is mutable or has mutable members. For example, this is perfectly compliant C++ class T { void Mutate(); }; static T * secretCopyOfT = nullptr; T Factory() { auto t= T(); secretCopyOfT = &amp;t; // Maybe I will be needing this later std::async([&amp;t]() { sercretCopyOfT-&gt;Mutate(); }); // Evil Laugh return t; } void MyFunc() { auto const t = Factory(); // Nothing can mutate my t, nope nope nope } 
Or here's another one class U { static std::string&amp; hahahaha; std::string myString; U(std::string s) : myString(s) { hahahaha = myString; } }; Maybe these are "poorly written classes" (obviously these are just malicious), but the point is that const is really only an access qualifier -- it says "the holder may read but not write to this object", it doesn't mean "nobody anywhere in the program may write to it". In more complicated cases where a few intervening layers sit between the callers, it can be non-trivial to figure out whether all references/pointers to a given object are const qualifier. 
I didn't start until my mid-20s. It's never too late, and you are never too big a loser, of which I'm proof. I was a completely lost boy just flailing around and doing a lot of drugs and working menial jobs (not that there's anything wrong with that if it's what you like.) My mom was going to a local community college at night. I decided to take some electronics courses. Since I didn't have a car, I had to hang around and wait for her. I wondered into the computer lab and started playing around. Those were the says of DOS on a floppy, so there was no worry about people using the computers. Just reboot and put your disk in and you have a clean machine to yourself. I ended up getting bitten really badly and pretty soon sold one of my electric guitars (to the eternal loss of the Emo-Polka music world) and bought one of the newly arrived IBM clones, a Leading Edge if memory serves. And that was it. Not long after that I got a job doing late night tape backups at a company, and used all the slack time between tapes to teach myself to program using the much nicer machines there. The rest is hysteria, as the saying goes.
since macros are evil, I wrote a template to auto-register classes. I like to think it minimizes the need for too much boilerplate: `namespace { auto r = Register&lt;Taco&gt;::withId("Taco"); }`
nice! I was just posting mine (below), but I think yours is more succinct. namespace { auto r = Register&lt;Taco&gt;::withId(L"Taco"); } &amp;#x200B;
My parents offered me a Timex 2068 as a gift after finishing primary school, alongside a bunch of programming books. So while initially I only played games, after an year or so I started to actually going through the books and having a glimpse of what Basic and Z80 Assembly were all about. Also got to know some friends with Amiga 500, doing some demoscene parties. So by the 10th grade I started informatics technical apprenticeship school, followed by an university degree years later. Just get a couple of programming books, preferably with exercises at the end and do really make them, while it may seem slow at the beginning, you will eventually get it. Good luck.
I really hate functions with output parameters. It's often unclear from reading the declaration that it's an output parameter, it complicates the call site by forcing you to declare the variable to be used as an output from the function separately, you can't skip declaring the output variable in the cases you want to call the function but don't care about the result. And it's not consistent (ints are returned from functions, but Foos are output parameters? Wtf... I find it better then to return a unique_ptr to a Foo allocated on the heap, or better yet writing the code in such a way that (N)RVO is used. Unfortunately I often dobt know for sure if the compiler used (N)RVO without inspecting the assembly, and you also have to argue with the 95 % of your colleagues that don't know about (N)RVO and/or want 100 % optimal code but don't trust the compiler...
I don't understand what you are saying. I've never written what you claim I've written. Or... maybe... Either you don't understand or I've misunderstood rhetorical question in negative assertion form? I believe the sentence "Doesn't const merely mean logically unchange, which allow underlying, unexposed changes?" actually means "const merely means logically unchange, which allow underlying, unexposed changes." Also, I've never tried to assign a single absolute meaning to the word "immutable". My original comment is always about the paper's terminological decisions, and one of those decisions is the [pragmatic](https://en.wikipedia.org/wiki/Pragmatics) contrasts (and lack of contrasts) between words, in the particular context of discussions about C++.
A lot of dependencies would be, yeah. From the small OSS stuff like zlib and libpng up to the big commercial middlewares like Havok or Scaleform, my experience at least has been that we don't tend to use DLLs where we don't have to (in the AAA sphere, at least). It's a performance loss (*far* greater than the lack of `dllinline`; it's the lack of IPO!) and it's just a vector for players to insert custom hacked DLLs which is a problem for competitive multiplayer titles. Sometimes we have libraries that we're legally obligated to ship as DLLs or the odd middleware that only provides DLLs, and of course not all games are the same and certainly there have been AAA games that have shipped a pile of DLLs.
I kinda believe the existence of `mutable` specifier is one of several things that make the terms "constness" and "immutability" different.
Then do better testing. The very idea that you should just keep on trucking even after you have definitively proven that the application is in an incoherent, unpredictable, unexpected state is just absurd. There is literally no safe way for the application to proceed in this context. It should crash. Or to turn it around: if your application can actually keep on running in this situation *then it isn't part of your contract in the first place*. 
It's the same thing. I think the difference here comes to taste mostly.
Very good point. I tend to like using free functions that return the singleton value as a static local variable to the function, so the construction never happens until the first call. The tricky thing here is that probably this needs some linker magic to arrange all the registration functors in a specific section to be called later by someone else. I've seen projects using this and works well, but it is hell of readable.
I actually tried it... 
for that connected needs to be constant as far as i know, isn’t it?
But it's not more efficient. You have to derive from AutoRegister. Then you have to write that macro. That's still manual registration. I'd argue you're doing just as much work as the "traditional" pattern - there's absolutely nothing automatic about it.
I was asking because many Steam games come with DLL, and SDL itself recommends *not* statically linking (and actually nowadays has an indirection layer inside it to allow for patching even if statically linked), so I was surprised. As for the performance loss, there is indeed a small difference due to the indirection, but IPO is not the cause, i.e. static linking does not enable IPO by itself. You are probably referring to adding IL representations to the static libraries and enabling LTO/WPO; but that is not really static linking anymore than adding the code to your own. As for the competitive multiplayer, if it is a AAA game with millions of players, I bet people will do it anyway, DLL hooking available or not. Specially versus the alternative of simple static linking (instead of actual source code being available + optimizations + obfuscation etc.).
I started with around 12 years, one day I left my legos aside and I tried to start building software with an old computer. I was fascinated by being a hacker, building .bat viruses and doing malicious stuff. My father had to reinstall windows a couple times, since I was always breaking it or deleting system files. &amp;#x200B;
It's almost ridiculous just how much simpler and easier to read and understand the vanilla version is. And it's also ridiculous that std::cout adds so much compilation time. &amp;#x200B; Of course this is a contrived example, but it makes you wonder just how much benefit these modern techniques actually bring to your day-to-day bread and butter code that just needs to get stuff done. 
&gt; Don't you install python or node just to keep your machine clean? actually, if I can avoid it...
I really like this pattern a lot also but I sometime have issues when the types registering themselves in the factory are part of shared libraries. I found that it's possible, probably due to compiler/linker optimizations, that the static initialization is removed from the final executable since these types are not referenced directly by any part of the program. This happens with GCC and Clang. I couldn't find a proper solution so far so I end up registering what I need manually... &amp;#x200B; Have you ever faced a similar issue or do you have any idea on how to avoid this?
&gt;Don't you install python or node just to keep your machine clean? With JetBrains stuff i think it comes bundled so you don't need to install it separately and no i don't install Python or Node in computers i wont need them.
I don't understand what you are trying to do here. Could you provide an example? 
I don't have enough experience with deduction guides to comment on the usefulness of this, but shouldn't it be template&lt;typename Explicit, typename Deducible&gt; some_type&lt;Explicit&gt;(Deducible&amp;&amp;) -&gt; some_type&lt;Explicit, typename Deducible::type&gt;; ?
He expects compiler to deduce second type in `some_type` in the following code: struct X {typedef type = size_t}; some_type&lt;X&gt; x; 
I really don't understand why Eric used such an artificial example to demonstrate ranges code, but neither do I understand why people are still talking about it. &amp;#x200B; And yes, more or less deliberately skewing the results by changing the io method between the examples is just not good style. &amp;#x200B; I recently had the problem that I needed to transform something akin to a \`std::vector&lt;std::set&lt;Foo&gt;&gt;\` to a \`std::vector&lt;std::vector&lt;std::string&gt;&gt;\`, where each string being created from a Foo object and the strings in each std::vector had to be sorted. I think stuff like that is a much better showcase for ranges. &amp;#x200B; Btw.: For most of my code, the rangified algorithms with built-in slots for projections are much more interesting than the algorithm chaining via the pipe operator. Now we only need to get an abbreviated lambda syntax and c++ code might actually become readable ;) &amp;#x200B; &amp;#x200B;
It's not atomic and is never modified by the current thread – the memory model supersedes constness at this point.
Just because you use NVRO doesn't make your code 100% optimal. There are occasions, especially if you're constructing something such as a URL, where passing the url as a reference to a string will be far faster than NVRO. &amp;#x200B; So... there are times and places for output parameters. 
NRVO is not guaranteed, so the `t` in `MyFunc` could be a completely different one.
But there is no `const` in that example, what do you mean?
There was a proposal to add partial CTAD to C++ but that part of it didn't get too far; [P1021](https://wg21.link/p1021).
I'm not 100% up to speed with PMR but if classes that use it need a vtable then they can't be stored in shared memory.
What about the real important software? Pinball! 
I have interesting and useful info about C/C++ developers. You can get to now how to [hire C++ developer](https://mobilunity.com/blog/cost-of-c-developer-in-ukraine/), cost of this development, examples of C++ projects. You will find all necessary info about employment on a page. Enjoy reading!
I think they bought that one. And because of some serious hardcoding was dropped from Windows 7. Maybe someone has more details.
Not interested until they opensource the standard library and the compiler.
Also using namespace std; I mean, come on ...
&gt; Just because you use NVRO doesn't make your code 100% optimal. There are occasions, especially if you're constructing something such as a URL, where passing the url as a reference to a string will be far faster than NVRO. Can you motivate this and show an example? Because I have a hard time believing that, everything else being equal, passing a reference to something as an out parameter will be faster than (N)RVO, considering (N)RVO is basically the compiler transforming your code (which is written in such a way that it looks like you construct a local variable and returns by value (NRVO) or just return a temporary (RVO)) into a version where the object is actually never constructed inside your function, but rather the function is using the variable constructed in the call site to receive the result of your function directly. My guess is that the speed difference you experience is either because you write your code in such a way that (N)RVO is not possible (which is easy to do, and why I say you need to inspect the assembly to be 100 % sure you get (N)RVO), or you have some other difference in your code (such as pre-allocate the necessary space in the version that uses an out parameter but not in the version that uses (N)RVO).
Coz you're gonna fix it, I presume?
If only half the issues that are already posted get implemented, it will be a much better app (like f.e. bigint/bigfloat). Time to open-source the Photos, Paint3D, and Skype as well (maybe they can get fixed as well).
I found myself often enough looking at Wine's source code, become MS' documentation is sometimes a little shitty. 
&gt; https://github.com/Microsoft/calculator/blob/master/src/Calculator/Converters/ExpressionItemTemplateSelector.cpp EnterpriseFizzBuzz strikes again
 DisplayExpressionToken^ token; What does the circumflex mean? 
https://en.wikipedia.org/wiki/C%2B%2B/CX
Have you ever reported a bug to GCC or Clang? The discussion about the bug is right in front of you. With Microsoft? The best you will get is "we have opened an internal ticked, move on". So, yes, I want my tools to be opensource and I want to know what's going on. If you don't see any benefit in being able to look at the code of the standard library, doesn't mean the rest of us don't.
https://blogs.msdn.microsoft.com/oldnewthing/20121218-00/?p=5803
I don't know about that. It's nice to be clear that it's a template selector and it's selecting the template for expression items.
not C++, so it's off-topic
Ridiculous. 
so, for 16 lines of clear, concise, comprehensible code that does the job, with ranges....we get a ton of boilerplate? that was a motivational examples for ranges??
Microsoft library source code is published and has been for decades.
Wow. Microsoft inserted the telemetry for the calculator app...
I was asking about a specific counter-example. In my understanding, every square matrix consisting of numbers can be thought of as representing a tensor. The rules of how a (1,1) tensor transforms simply correspond to a change of basis for a matrix. However, that view requires that a matrix is really just numbers without intrinsic meaning. A Hessian matrix would be a good example of something that would not transform like a tensor, as it's entries are not simply numbers, even if explicitly evaluated to their numeric values.
While cool, this relies on undefined behavior: https://stackoverflow.com/questions/1421671/when-are-static-c-class-members-initialized Specialty, the static initialization registration code is only gauranteed to happen before main if it is in the same translation unit as main. Works if you have a monolithic build, can be problematic otherwise. I learned this bit of c++ trivia using the exact same pattern and discovering some initialization didn't happen before main depending on linking order. That wasn't fun to debug.
I guess you are not compiling with C++17? Because with C++17 (N)RVO should be guaranteed (for nearly all cases)... [https://en.cppreference.com/w/cpp/language/copy\_elision](https://en.cppreference.com/w/cpp/language/copy_elision)
I'm a little confused. In this pattern, `withId` would be a static method of the class `Register` (templated on the class to register). Is it correct that `withId` would call the `registerGenerator` function called in [this template](https://github.com/Derydoca/factory-auto-registration/blob/master/FactoryAutoRegistration.Logic/src/AutoRegister.h#L11)? Thanks for this great discussion. I'm learning a lot!
Was thinking that too. I wonder what's so interesting (or useful) about what people type in a calculator.
&gt;Specifically, the C++ specification requires that all static initialization must be done before the start of main. Not true: The standard requires that static initialization happens before any code in the same **translation unit** is used. The compiler/linker may choose how to combine static initialization across separate translation units. [static storage initialization in the c++17 draft standard](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4713.pdf) &gt;Dynamic initialization of non-local variables V and W with static storage duration are ordered as follows: &gt;(2.1) — If V and W have ordered initialization and V is defined before W within a single translation unit, the initialization of V is sequenced before the initialization of W. &gt;(2.2) — If V has partially-ordered initialization, W does not have unordered initialization, and V is defined before W in every translation unit in which W is defined, then &gt;(2.2.1) — if the program starts a thread (6.8.2) other than the main thread (6.8.3.1), the initialization of V strongly happens before the initialization of W; &gt;(2.2.2) — otherwise, the initialization of V is sequenced before the initialization of W. &gt;(2.3) — Otherwise, if the program starts a thread other than the main thread before either V or W is initialized, it is unspecified in which threads the initializations of V and W occur; the initializations are unsequenced if they occur in the same thread. &gt;(2.4) — Otherwise, the initializations of V and W are indeterminately sequenced. I've actually been bitten by this in real life, and debugging/working around it is more fiddly than just having a manual `register_everything()` function in a cpp file somewhere that avoids undefined behavior.
[C++Weekly ep 2](https://www.youtube.com/watch?v=B3WWsKFePiM&amp;list=PLs3KjaCtOwSZ2tbuV1hx8Xz-rFZTan2J1) had an interesting discussion about this.
John Lakos mentioned, I think in this talk that save for clang 2 years ago, most compilers manage to de-virtualize this call anyway. https://www.youtube.com/watch?v=nZNd5FjSquk
Also a game dev and our move to pmr containers, even sticking with the default memory_resource show no measurable performance penalties.
What did you end up doing to get around this?
Yes, I did (Clang), no feedback.
The more used features are the ones to make more streamlined? Looking at mistakes might show what is wrong with the UI? Etc.
Virtually all of MS native code libraries is published, it ships with debug symbols (can be debugged through) - since forever.
In a header?
Those are actually good points. Thank you!
We just enabled C++17 at work this week, thanks for asking! :D However, my understanding is that (N)RVO is now a required optimization in the cases where it used to not be required but almost always used anyway. And the cases where it was not used before is mostly the cases where it is still not required (because various reasons). So basically, not much has changed afaik.
NO. A contract is not "These are the requirements for me to execute without crashing". It is "These are the requirements for me to behave as I promise". Contracts can be much narrower than absolutely required for many reasons that are not language UB - performance requirements, unimplemented code paths, inaccurate results, etc. Assuming that contracts are only protected against language level UB and crashes is ridiculous. Again I ask, for those people who cannot afford to have their production applications crash when the only change being deployed is a new contract check, why is it better to say "just don't check your contracts at all and don't be aware of them being violated in production" than to provide a way to choose to check but not enforce those contracts? And yes, testing would be great. Billions of lines of code exist and are being maintained and would like to be improved but are not written in a way that submits itself to easy thorough testing, or simply do not have those tests implemented yet and are years away from having thorough tests. Even then, very few testing methodologies on large, complex systems are thorough enough to guarantee that no bugs will ever get through. To not provide a way for contracts to help those systems at all is a disservice to a significant majority of the existing c++ userbase.
I honestly love that they write the requirements for a merge so clearly. Every project should have this as I often don't feel like contributing because who knows what the maintainer wants.
And that is the most upvoted comment here? c++ community reallike likes nitpicking about low level code details.
You are absolutely correct. I will amend my statement with the relevant quote &gt; It is implementation-defined whether or not the dynamic initialization (dcl.init, class.static, class.ctor, class.expl.init) of an object of namespace scope is done before the first statement of main. If the initialization is deferred to some point in time after the first statement of main, it shall occur before the first use of any function or object defined in the same translation unit as the object to be initialized. That said, both clang and gcc seem in practice to emit these before `main`. Even if they didn't, a future version could change that and you would be stuck with the startup time and memory hit. Thanks for the correction!
Speculation, but if you output values that you're about to use in the same scope, compilers can optimize it so it puts them into registers and be ready to use for next operations - this avoids allocating the object on the stack. Of course, this'd only work for small types. I don't have ability to check it right now, so I'll edit the post later with a test.
Microsoft is kinda a big company. I expected better from them. 
And why did you not enjoy it? What was it missing? 
It requires extra patches applied to gcc_modules so that gcc writes out the information needed by CMake. On the CMake side you need the branch gcc-modules from https://gitlab.kitware.com/ben.boeckel/cmake The docker image contains all the necessary scripts to bootstrap each component indepently ( cmake, gcc, and kitware-ninja )
Except they did write it in C++
It’s a converter used in the XAML code. Very familiar if you’ve written any c# MVVM code. 
Would like to see that ported to winrt.
Really? MS used to have a 5 volume set of books for win32 that documented it all pretty well, I thought (not that I read the whole thing)
&gt; abbreviated lambda syntax I would like to know how much terser your abbreviated lambda syntax is compared to what we have today...
It *could* be. Or it could be the same one. The point is that the standard does not guarantee that all pointers and references to 't' are immutable.
So not for a string containing a URL, as you used as an example in your previous post...? Small types (8 bytes or smaller on x64) is most likely already returned in a register (rax) when you return them from functions.
 auto widget = std::shared_ptr&lt;Widget&gt;(); \&gt;The above is well-formed and valid C++ code. It gives widget the exact same static type. The only difference is that instead of setting widget to a new heap-allocated Widget, it sets widget to nullptr! Uhhhh yeah? a shared ptr's default ctor should not create anything. shared\_ptr is not an instance of a pointer, it's an instance of shared memory ownership....
Well, um, yeah?
I wasn't the previous poster - it was my first comment on the post. Yeah, the small types, but there are also vector registers, so it might be better for code that uses vectorization.
&gt; Yeah, the small types, but there are also vector registers, so it might be better for code that uses vectorization. But will those be used in arbitrary function calls to functions in other translation units though? For functions in the same TU, you can probably depend on the compiler to do The Right Thing and just inline the entire function most of the time.
Well, I don't know what is realistic, but I find the following very desirable: Current: [](auto&amp;&amp; x, auto&amp;&amp; y){ return x*y; } ) Terse: [](x, y) =&gt; x*y ) 
&gt; ! Manually specifying the linker argument in the build script and changing the object file argument order until it worked. Auto-registration had been working for about a week, then an unrelated new source file in the build changed when initialization happened. Debugging revealed that only about half the classes I expected were registered by `main()`. Googling lead me to several discussions that pointed out my false assumption about static initialization.
why not all the way to `[] x, y =&gt; x * y;`
I can see all kinds of problems trying to write a parser for your terse syntax. But they managed to fix the double angle bracket ("&gt;&gt;") in templates, so who knows. I suggest you write a proposal. :)
I took another route for my engine. I wanted two things out of my factories: creation of an object and unserialization. I needed like a creator of object that needed to do small logic to get parameters from the json value. What I ended up with is these functions are the point where the polymorphism is. Instead of implementing a class and glue it to the factory, my builder functions became where the implementation is. The registration is the implementation, instead of the implementation is the registration.
This may be pretty obvious to most readers, but it's good to have some more beginner-friendly content in this subreddit too. Noob programmers can also be C++ enthusiasts.
Not exactly, it's [C++/CX](https://en.wikipedia.org/wiki/C%2B%2B/CX).
There have been several proposals to that end. I didn't follow them, but I doubt I could contribute something new to it. 
I think there was even a proposal that suggested `[].name`
So given that argument, are we only allowing standard c++? I hope no one posts anything about gcc or clang nonstandard extensions. 
I didn't say it was offtopic, only that's "not exactly" C++.
Fair enough
`using namespace std;` in source files is not uniformely considered a bad thing (but lets not get into that). ALso, when I think about microsoft, then well written c++ code is not necesarily the main thing that comes to mind (legacy, c-style code does however). In any case there are really much more interesting things about the code - but of course they don't provide so nice one-liners.
I don't think so (from casually browsing the code).
Only part of it. 
There is absolutely nothing wrong with ```using namespace std;``` in a source file. In a header file there is something objectively wrong with it when it's used at the global scope because that statement will end up affecting all translation units that include the header file. But in a source file... absolutely nothing wrong with it. You may not like it as a matter of preference and that's fine, but bike shedding over such minutia is petty.
It's not in a header, only in source files.
I mean this entire discussion contains very low-effort comments. &gt; "This is not C++!" &gt; &gt; "They have a using namespace std!" &gt; &gt; "Microsoft should open source the entire compiler!" &gt; &gt; "Rediculous!"
You have a point there
You're saying that `const` and "immutable" are very different. `const` applied to an instance is not different from immutable at all, provided the class is correctly written. I don't know how to put it more clearly than that. `const vector&lt;double&gt; x{1.0, 2.0, 3.0};` // an immutable array
&gt; For example, this is perfectly compliant C++ Not even close. You're keeping a reference to a function local variable after its lifetime ends, that's just UB pure and simple. &gt; but the point is that const is really only an access qualifier No, it's not. `const T&amp;` is only an access qualifier. `const T` means that the T is really const; any attempt to modify it is UB. I'd suggest (re) reading some pages on cppreference, e.g. https://en.cppreference.com/w/cpp/language/cv.
With construction/copy elision, the function local variable may be the same object as in the calling function. That said, if you object, here's another example that's perhaps clearer and doesn't involve any kind of construct/copy elision. struct T { std::vector&lt;int&gt; vec; }; void MyFunc(void) { auto first = T(); first.vec.push_back(1); int * dataPtr = first.vec.data(); T const second = std::move(first); printf("second contains %d\n", second.vec.at(0)); dataPtr[0] = 66; printf("second contains %d\n", second.vec.at(0)); } 
Whether it's cleaner and simpler, depends on how many classes you have. If you have a few classes, then sure. If you have a huge number of derived implementations, then at some point it's going to feel pretty crazy that every single time you add/remove a class, you're going to have to go to this centralized file and add/remove lines. As opposed to each class being a self-contained unit, that can be added/removed without affecting anything else. "Separation of concerns" in this case, depends a lot on perspective. Not to mention the really fundamental problem with the traditional pattern for some use cases: the factory has to know about all of the derived implementations. Usually, the whole point of even using registration for a factory at all is that the factory doesn't need to know about the derived at all. After all, if the factory needs to know about all the derived, why bother with registration at all? Just have a series of if statements and directly construct the requested-for class. The point of having classes register themselves is that the factory no longer needs to know the derived classes; the derived classes instead know the factory. This is simply critical if the base class and factory are in a library and the user is writing implementations of the base they need registered in the factory. If you experienced that such patterns "always" made source code worse, then you just have either always seen the pattern misapplied, or you have never encountered any use cases (which are quite broad).
C++/CX is not C++, it is a proprietary C++-like language, non-standardized and Windows only
On what platform, and what kind of program? I've never seen such code fail to run before main in practice. I have seen such code fail to run entirely, when doing static linking and the linker decides to eliminate the variable completely, and I've seen many issues related to ordering, but that's all.
C++/CX is not C++, it is a proprietary C++-like language, non-standardized and Windows only
&gt; But for reusable code or any kind of module in a larger application Meh, this is taking it too far. There are whole domains where you are writing servers that are typically launched automatically and run for long periods of time, and where startup time is totally irrelevant. E.g. in HFT we use a library that uses such techniques to automatically register various things; it's a perfectly reasonable choice for a reusable library in this context. Very little code is as generic as `vector`. Even most library C++ code in the world is ultimately various internal libraries targeting a specific domain; for many of these libraries using static initialization is fine and well worth it if its less error prone.
Something similar, where you a) don't need a macro, and b) it's impossible to forget to register, because derived classes are forced to inherit from the base class indirectly via a CRTP class, which performs the registration: http://www.nirfriedman.com/2018/04/29/unforgettable-factory/.
It may end up being the same but the program is still UB. For this example, yes this is valid, but only because vector's contract explicitly guarantees that the pointer returned by data is unchanged after move construction. The person writing a container doesn't have to make such guarantees; in general you can't assume that it's allowed to cache references from the container prior to a move and use them again on a move constructed object. There still is no legal way to mutate a const object, unless either the class author writes it in such a way that it allows you to do so, or you cheat and look inside. If you have a lot of problems in your codebase assuming that const objects cannot be mutated because of cached non-const references from move constructed sources, or const cast, you have very serious issues.
If you throw or handle exceptions you’re doing it wrong. Exception programming is the biggest mistake ever created. 
Nobody tell him about Java.
You can buy the source code from them if you'd like to ;) 
Hate can be a strong motivator.. 
Here are some actual [measurements](http://nibblestew.blogspot.com/2017/01/measuring-execution-performance-of-c.html) regarding exception handling, for your enlightenment. 
The original poster said it was off topic
That's completely missing the point of everything I tried to say.
Retry sure it’s a language extension much like those available in gcc and clang but maybe we’re just arguing semantics. 
Everyone wants modules. But no one agrees on what they are. That’s the problem. 
Be careful, only RVO is mandatory, not NRVO yet
&gt; If you have a lot of problems in your codebase assuming that const objects cannot be mutated because of cached non-const references from move constructed sources, or const cast, you have very serious issues. Agreed, it's a fair point. And to be honest, almost all false-constness issues are due to `T const &amp;`, `T const *` or `shared_ptr&lt;T const&gt;` and not bizarre corner cases of `T const`. Sadly, there is no grammar for "pointer/reference to an object that is really const underneath". 
I reported the same bug to GCC and MSVC. GCC rather quickly, MSVC, like I said, the last thing I know is that they have opened an internal ticket - whatever that means.
Okay, maybe I was a bit sarcastic there but you very well know that Microsoft is a for-profit company that sells commercial software including compilers. But who knows, maybe if they get enough people subscribed to their cloud crap they might opensource the compiler too.. 
Java is exactly what I’m talking about.
Are the libraries available in a public repository where users can inspect the commit history? I usually compile clang from source and use the latest trunk so I can confirm that a bug in some LLVM tool (lately that's been `clangd`) is still present before I open a bug report. Can I do the same with MS STL? If I can, please show me the link to the repo. If not, then my point still stands - the development process is too closed and one has no idea what's going on behind the scenes.
&gt;I really don't understand why Eric used such a bad and artificial example to demonstrate ranges code, but neither do I understand why people are still talking about it. I think it's a great example. It's way too easy to pick an example which is selected to make things look easy. This example illustrates a real weak point of the ranges library which needs real work. I spent a few days trying to "fix" this and learned a lot about the library. I started with the idea that a natural way to address this example would be to add a custom range type. But it turns out that making one's own range type is not easy. This is a major weakness of the library as it stands. I don't think adding it to the standard is going to be helpful to its usage and development.
The containers aren’t intended to be used from shared memory anyway.
I would be so categorical about that. Using exceptions for error handling is fine even in performance sensitive code. In my code, for example, exceptions are never thrown on the hot code path, so the latency stays low. But if an error condition resulting in the exception does happen, the latency of error handing doesn't matter very much.
Yes, I know MS is for-profit organization. Without getting political and talking about my ideals, I'd gladly contribute money to MS if that would result in them opensourcing the compiler.
I said nothing about the sources being open nor do I care about it. I said that you can see and debug through, virtually all of it. You have a point, but you're drowning it with insistence. Also, you're mixing compiling the compiler and the standard library, what's that about?!
I'd love to see a similar binary size breakdown for exception handling code and data for GCC.
As those new types are an addition to the standard library they don't have to make everything better or easier to write. There just need to be enough common usecases, where they shine to warrant the overhead in terms of library and standard maintenance. If I can solve that particular problem easily with existing techniques, I don't care how good or bad ranges fit it. What I do care is if ranges simplify tasks that are currently difficult to write (or at least result in very verbose code). If you saw it as a challenging teaching example to improve the code that's fine, but it was still a bad example for demonstrating what ranges are good for.
Of course I'm not claiming, that there isn't room for improvement. 
This is a C++ forum
&gt; Also, you're mixing compiling the compiler and the standard library, what's that about?! That's because of the way LLVM/Clang repository layout. You need to clone and compile everything at once.
&gt; Bike shedding over such minutia is petty. For my taste, there was overuse of `auto`. In my opinion, doing so just obfuscates things. It should be used only when the type really is impractically long. Not sprinkled around to get brownie points for using this fancy new thing. But as the saying goes: some people rant about academic things in the code... other people ship applications.
Open sourcing would be great, but I hope they continue to pay their developers to work on the compiler. But if that means they have to remain closedsource then too bad.
They don't always emit it before `main()`--I've had a project that only worked when object files were linked in a particular order. Sure, you can make it work with compiler behavior *now*, but as you point out: &gt; A future version could change that and you would be stuck So, I would recommend avoiding using this particular sort of UB. Maybe the c++ will add a storage specifier that aids with robust initialization order across TUs?
You're pulling my tongue, but once again, I'll stay away from ideology/preaching. Anyway, I completely agree - developers need to be payed appropriately for the work they do. There are developers that are paid to work on open source projects.
I would strongly disagree. Nothing enterprise going on here. It's definitely WPF slang, but just from the name I know the class is responsible for switching the (template/) visualisation of an item in a collection based on a certain information (e.g. type, enum). 
The new https://docs.microsoft.com/ website has been serving me well.
TL;DR: If exceptions happy often, then they are slow, otherwise they are fast. Use exceptions if their case is "exceptional".
Yes, it would be nice, though I'm not sure how practical it would be. If it were part of the type system, then if you wrote say `void foo(immutable Bar&amp;);`, you could only call it with const objects. In D you have both const and immutable, but it makes more sense because it's a GC language so you are typically working with things that are actually references to objects. I've also heard that const/immutable in D is a fairly major pain point but I don't really know the details.
You don't think a file for what is essentially a single switch statement is too much overhead? I hate these kind of programs where you have to wade through dozens of hollow wrapper classes and files to find where *anything* happens.
I don't think there's anything wrong with having a coding standard you use and if that coding standard doesn't allow ```using namespace XYZ;``` or restricts the use of ```auto``` then that's fine. But you won't find me disparaging other codebases for their coding standard except for in some very exceptional circumstances where there is a measurable cost to productivity. I bought into the hype of "always use auto" and truth be told when I was first put into a "leadership" position I took the easy route and just listened to what the big name thought leaders said about C++ and blindly adopted it. Some of that advice was good, most of it was kind of neutral and some of it was bad. I am a lot more critical when it comes to advice about C++, regardless of who expresses that advice. Bjarne says always use vector! Herb says always use auto! This C++ master says always do XYZ! That C++ master says never do ABC! I am happy to listen to their advice and be mindful of their opinions and think it's good to know what various leaders in the community believe or are pursuing, but I no longer accept it with the same degree of prestige or authority as I used to. For my company's codebase we adopted the always use auto and are kind of stuck with it for the time being. In retrospect it was a mistake and at some point in the future I'd like to switch to using ```auto``` only when the type can not immediately and obviously be determined by the initializing expression. It makes code a lot harder to review because now to determine the type of a variable you have to hover over it with the mouse in an IDE meaning reviews on Github or basic text editors or even a casual perusal of the code on a mobile device are basically not possible to conduct in a thorough and meaningful way. I have to load up a heavyweight IDE like Visual Studio to do code reviews and then I have to hover over individual variables to see their type which reduces the visual bandwidth enormously. I think with the introduction of concepts, always use auto will be revised so that you can declare a variable whose type is a concept like: Iterator&lt;int&gt; i = some_function(); Collection&lt;std::string&gt; c = ...; It will give most of the benefits of ```auto``` without sacrificing readability.
Check mate
Most Java exceptions generate a stack trace by default, which has a gigantic time cost and does not generally apply to c++ exceptions. Even modern Java runtimes started cheating and stop generating new stack traces for builtin exceptions after reaching a threshold. 
&gt; Combined, switching to __CxxFrameHandler4 dropped the overall size of Microsoft.UI.Xaml.dll from 4.4 MB down to 3.6 MB. Can someone tell me why I would care about such a change in size?
Because it's huge. Check how large your `c:/windows/system32` is. Then take 20% away. That's not taking into account all the dlls and executables scattered around other parts of your system.
Thats cool, do you have any specific book recommendations?
Until one day in the future your service/daemon is changed from launch-and-stay-resident to launch-on-demand. Then the time to respond to the first request is delayed needlessly. You're right though, I should be clear that this is a domain-specific concern. For HFT, you have a single-purpose application with huge runtimes and so it's surely OK.
It would be interesting to compare this to ["throwing values"](http://wg21.link/p0709r0), at some point.
Thats a pretty cool background, thanks for sharing!
Smaller binaries fit in cache better.
Smaller binaries size means smaller installers, faster to download, faster to load in memory / your app load faster. 0.8 MB may be ridiculous here for you. But for some companies, every small optimizations combined together may start to cost a lot. 
&gt; `Iterator&lt;int&gt; i = some_function();` It's actually `Iterator&lt;int&gt; auto i = some_function();` to clearly differentiate type constraints and variable declarations.
Bit isn't that meta data usually put into a separate section anyway, which doesn't get loaded into cache unless used?
I pointed out an example. If you provide an output parameter, if that method is being called in a loop or just called multiple times with the same object, which is not uncommon, it means that the called code can often reuse content and not reallocate anything at all, or use most of it and prune off some trailing elements, or just lower the used bytes count and leave the buffer intact as is. That's guaranteed to be faster than gen'ing up and object, filling it in, and returning it every time. &amp;#x200B;
If it's a non-const reference, it should be an output parameter. I would think that anyone would use that convention. If it's an input parameter, it's a const reference. That's pretty simple. Of course it would be even better still if C++ allowed for parameter direction indications. I can't believe it's not even offered yet as an option. &amp;#x200B;
&gt;If you saw it as a challenging teaching example to improve the code that's fine, but it was still a bad example for demonstrating what ranges are good for. To me, the whole motivation for ranges is to make easier to write expressive, demonstrably correct and efficient code. To me, this is an example which should be easy to illustrate this. But it's not. This example illustrates that this goal has not been reached.
Well, it is a much more extensive language extension than what clang and gcc offer. I'd almost say c++/cc is to c++ what c++98 is to c, but that would probably be exaggerated (don't know c, so I can't fully quantify it)
&gt; As for the performance loss, there is indeed a small difference due to the indirection, but IPO is not the cause, i.e. static linking does not enable IPO by itself. Ah, yes, wrong acronym - I meant LTO/WPO as you say. :) &gt; As for the competitive multiplayer, if it is a AAA game with millions of players, I bet people will do it anyway, DLL hooking available or not Complicated topic. There's a buttload of things some games do to prevent cheat mods. Blocking trivial DLL hooking is just one teensy tiny itty bitty part of the puzzle, but a necessary one nonetheless. :)
Well, it is a much more extensive language extension than what clang and gcc offer. I'd almost say c++/cc is to c++ what c++98 is to c, but that would probably be exaggerated (don't know cx well, so I can't fully quantify it)
As I said it is a bad example.
I found the Google engineer!
It's still not all that much. Binary size is rarely the dominating factor when it comes to memory/hard drive usage.
No, contracts defend against user-level UB, some of which may cause language-level UB. If it's part of your contract, it's mandatory, and failure to fulfil the contract is a logical error. It's a bug. How can your program perform reasonably in the face of known misuse? It cannot. Just look at what you've written! It's OK for your program to go down "unimplemented code paths" and produce "inaccurate results" in violation of a contract? No way! What a ridiculous thing to allow.
[removed]
The thing is that the controls are very generic and if you need a different visualisation for certain types in a collection the custimization point is simply a template selector. You need a wrapper class somehow and it's not necessarily bad it's only responsible for a single simple thing. 
I don't think you really can: Throwing battles requires modifications in the source code. This here is an optimization for existing code. In theory, throwing values should be much more efficient thougj
Those 20% apply to anything written in C++ and system32 is full of dlls.
 Foo foo; // ... process(foo); Is foo an input to process or an output I.e. the result of some processing? Or both?
If this was 1998, then you'd sort of have a point. But given that a modern IDE will show you the comments for the method very easily, it's not too hard to figure out. And of course if there were actual coding conventions involved, the name wouldn't be foo, nor would the method be called process. Obviously doing almost anything has its pros and cons. But if there was a big difference in performance, clearly it's worth it. And the ability to reuse the content of the object, if it's a heavy one, could be enormously more more efficient. And of course if you need to get back three things, not just one, that's another reason for output parameters. I'm hoping that the modernist position wouldn't be to create a class to hold the three things by value and return that by value? 
No it doesn't. It depends on the code and as you can see from the blog, average savings are more around 10%.
Are you saying you should be using exceptions for their intended purpose? I find your ideas intriguing, and would like to subscribe to your newsletter ;-)
Do you know the reason it was removed from the proposal?
Meh, I'm the opposite. People are way too scared of `auto`; Most of the time the return type of an expression shouldn't be a surprise (and if it is, make your expression simpler) so it's really just mindlessly repeating what both the reader and the compiler already know.
^(Thank you for submitting to "mildly useful programming tips" by u/plistig. Each tip is provided to you for a small fee of only 3.99$ per message.) C++11 has four different types of loops: `for`, `while`, `do…while` and range `for` loop. Learn how they work, and you the appropriate loop for your specific use case.
Tangentially, it is quite useful to have a non-nullable shared pointer type, to avoid the need to test for null at every usage of a shared pointer. A lot of times it's not a big deal if the returned object isn't actually valid. For instance, I ask for ListBox::selected(), get a shared_ptr&lt;ListBox::Item&gt;, then ask for the text() of the item. A default-constructed ListBox::Item::text() would return "", which ends up being what we'd want in that case anyway. So we can go from: string text; if(auto item = listBox.selected()) text = item.text(); To: auto text = listBox.selected().text(); In that case, the default constructor would allocate the object for you, and assignment of a nullptr to it would throw. Maybe call it shared_ref&lt;T&gt;.
Yes, but if the exceptions get thrown often (they shouldn't), then the data has to get loaded often, or they loaded.
yes, my bad.
Gcc and clang often extend in ways that don't necessarily break parsing, though not always. This one introduces new syntax, especially use of ^ for something tied to .net. some extensions in gcc/clang will break parsing though. Like the extension that allows using strings as non type template parameters.
I did provide an example. The idea is a [user-defined deduction guide](https://en.cppreference.com/w/cpp/language/class_template_argument_deduction#User-defined_deduction_guides) that allows you to specify some arguments instead of deducing all of them for you.
Love it!
I don't only read code in the IDE, I also read code in review tools like Gerrit. Out codebase is also very large, very old, support many different configurations controlled using #ifdefs, and probably a few other things that I don't know about, with the end result that our IDE very easily gets confused. Maybe you work on a simpler code base or with better tools. If so, good for you. What's the problem with returning multiple values? The standard does it in a bunch of places such as map::insert. C++17 even got structured bindings to better support multiple return values. Or are you seriously suggesting that any construct more complicated than a int should be returned as an out parameter?
do u maek gaems?
These are clang/gcc, and AFAIK they (may) implement exceptions quite differently than MSVC's compilers.
no this is not accurate. you can somewhat ignore the `typename Deducible::type` this is just placeholder code for the kinds of things people usually do with deduction guides. See my comment above...
Yikes, that's a nightmare. But as I understand, you are talking about static initialization *order* right -- there was some dependencies. That's a very good reason not to use them, but it's orthogonal to my point that even if all goes well, you will have wasted precious initialization time.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/ayhvui/help_with_c_array/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
One week C++ holiday. Its only 150 folks attending, so you'll get the best out of your time with lots of debate on C++ topics. Get an impression on how the setting is: https://www.panowalks.com/embed/4Esbf7KlEldVHsjM9jAqwBvPHTNi/
Unrelated, but C++ is also used a lot on embedded systems. It could be de difference between the firmware fitting tightly in ROM space and not fitting at all.
So what if you have to go edit the factory source for every class? Is switching to a different file really that difficult? Is switching to a different file so rare when doing any kind of development? If I have a huge number of derived implementations, that's even better, because I can look at the file, and at a glance, see all of the implementations the system knows about, and also see when someone has done something wrong. Or I can have one localized macro to cut out the remaining boiler plate. If a design changes, which they do, I can fix it all in that one registration. Can't have that when the implementations are strewn about the place. The class is not self contained at all because it contains part of a system that is not actually it's single responsibility. What's wrong with the factory having to know all about the implementations? The only thing that matters is that users of the factory don't have to know all about the implementations. That's what a factory is for, to create the appropriate object appropriately on behalf of the user. If you look at the "traditional" example given in the blog post, it uses lambdas. So the factory class doesn't actually know about the type. It obviously just stores some type-erasing function wrapper. So in that example, you actually have a much cleaner design because you can plug anything into the factory without forcing them to have to inherit some class. They didn't make the source code worse. They made the design worse. The pattern can't be misapplied, because it's an anti-pattern. All it did was give the programmer a sense of accomplishment, while it actually caused really high coupling to everything underneath the covers.
This is exactly what I hear high traders saying in talks. I recall hearing they like exceptions because it leaves error checks out of the hot path and let's them reduce latency the maximum amount, then when an exception does happen their trade isn't happening so they don't care about the performance, but even then it is pretty good.
Find out during the build which file provides dog and make it Just Work™. And how do you do this? That requires CPP expansion.
There were lots of reason but here's a big one: You get placeholder types where you don't expect them. Now true, this is already a problem for normal CTAD, although not as big. What this means is that: tuple&lt;int&gt; a(1, 2); Will *not* give you a `tuple&lt;int&gt;`, and that can be very surprising. Normally when you write `Type&lt;something&gt;` you know what types you're getting, but with placeholder CTAD, you can't be sure since it could be a placeholder and deduce another different type. There is also the problem that it breaks existing code when you have templates with default arguments. With partial CTAD their default template argument can be deducted and you'll possibly get a different type, which is a breaking change.
If an exception gets thrown, the performance lies anyway on the floor.
only RVO is guaranteed by 17, but both have been allowed for much longer and you can't compete as a compiler if you don't... 
Another major problem is it's hard to test the individual classes. You have to link in the factory stuff just for compiling a unit test.
You laugh but he's right. People abuse them a lot in the real world, even for control flow.
I think the vast difference in GCC performance was due to moving the unwind part of the functions to a different section.
Awesome!
The shit I've seen...
Not sure, what the downvote is for, but it is a fact that can and has been measured. Dynamic exception handling is slow - really slow - but on the plus side it costs almost nothing as long as nothing gets thrown. 
Most likely you won't be using exceptions on such devices anyway. 
The issue is that it is unintuitive. That's a valid way to assign things elsewhere in the language.
When you create a vector, you don't expect it to have any data do you? It is an ownership wrapper just like shared ptr
It's not just the metadata, it reduces the number of catch funclets also, which are actual functions in the executable.
- easy mistake to made - compiler doesn't help with warnings - runtime errors are super ugly - it can happen in some side branch that gets executed pretty rarely. Nobody says that after noticing the constructor call and thinking for a second, you wouldn't notice what's up. The problem is that mistakes happen and this one leaves programs defenseless. It's similar scale to forgetting to allocate s memory in a c/c++ before modern c++ and we don't want this.
I wouldn't go so far as an int, but I think it's madness to throw a bunch of objects into another object and return them by value just to avoid an output parameter. 
&gt; Is switching to a different file really that difficult? Is switching to a different file so rare when doing any kind of development? It's not about it being difficult, it's about what is modular, which I entirely would agree is a matter of perspective here. One perspective is that the factory is a separate unit of code; you should be able to add/remove the factory without touching the classes. Another perspective is that the factory is as much "built in" to the system as the base class itself; this is often the case when the library provides the base class + factory, and the user is providing derived classes. In this case, the factory is simply a given, and what needs to be modular is adding/removing a class (because the person adding/removing a class doesn't own the factory, and can't even touch it, for example). &gt; What's wrong with the factory having to know all about the implementations? The only thing that matters is that users of the factory don't have to know all about the implementations. I actually already explained exactly what is wrong with having the factory know about the implementations: in many cases the base class and the factory are part of the *library*. And the implementations (or at least additional implementations) are written in *user* code. So it's not possible for the factory to know about the implementations. &gt; If you look at the "traditional" example given in the blog post, it uses lambdas. So the factory class doesn't actually know about the type. Yes, it absolutely does. In the traditional example, you have to name the derived types you are registering. You'll notice that the food factory obviously includes Burrito.h, etc. If someone shipped the traditional example, I would not be able to produce ice cream from that factory ever, unless `Register` were a public method (in which case, we are exactly back to allowing classes to register themselves, so now the original library has one approach to registration for its own food, and a different one for users). What you probably meant is that the factory does not include the derived types in its *API*, i.e. the derived types are private dependencies of the factory and not public dependencies (which you alluded to earlier). In some cases, this is good enough, in others, it is not. &gt; The pattern can't be misapplied, because it's an anti-pattern. All it did was give the programmer a sense of accomplishment, while it actually caused really high coupling to everything underneath the covers and made everything difficult to change. The fact that you haven't understood the use case for it, does not make something an anti-pattern. I've encountered the use case many times and seen this pattern very successfully applied (by excellent programmers); the code is clear and as a user it's simple to use and hard to misuse. I've also seen situations where it would definitely not be appropriate, and avoided it then. I'm willing to give you the benefit of the doubt that when you saw this pattern it was misapplied and made the code worse; people often learn patterns without learning the motivating use cases for them and then misapply them. This is bad but no worse then failing to understand the motivating use cases for a pattern and then simply generalizing and saying that it is "bad".
We just had a discussion at work about exceptions, since we don't use them in our codebase. It's video software that can't crash, and was built over a decade ago using error codes. It seems like exceptions are easier to deal with nowadays due to RAII, etc, but it's still tricky to take an old codebase and make it exception safe. Plus, it's nice having local error handling to catch problems near the place that caused them. A very promising solutions seems to be the std::expected proposal.
Qt has it. It's almost like a variant of C++.
They always taught C++ to new programmers when I started, and it helped me out tremendously. It seems like Java, Javascript, and Python are the go-to beginner languages w.
"some people rant about academic things in the code... other people ship applications." I really despise this mentality. Ranting about academic things and shipping applications are not mutually exclusive. All too often this mantra is used by insecure SW engineers who are not open to learning from their own mistakes and use it as a way to deflect valid criticism.
&gt; it sets widget to nullptr! Actually, that's incorrectly stated. It sets `widget` to an empty `shared_ptr`. `widget` is not a pointer; `nullptr` is. Not that knowledgeable people don't grasp the real meaning immediately. But if this is aimed at people who are just learned about smart pointers, the incorrect terminology is going to confuse them.
But you might as well make them faster right? There's no reason to make a feature of c++ slower than it needs to be, and like it or not a lot of applications use exceptions fairly heavily (eg see nlohmann or boost)
As I understand it, yes. I have gone with an implementation similar to xurxoham's. I have a branch "tasks/reddit-improvements" that I have committed this change, along with others if you want to see it in my example. I will be updating the blog post once I am happy with all of the changes.
Thanks for sharing. That was a good video. &amp;#x200B;
I haven't come across this issue yet, but I use the MS compiler primarily. If you are to try to compile this example in GCC or Clang, do you get an issues with it?
The classic example is std::getline processing a whole file. If it returned a new string via NRVO, that would still be a separate allocation for each line, whereas with the out parameter it can reuse the space allocated each line.
I only know how it's for Linux. Windows has its own ABI and handles exceptions very differently. On a 32bit i386 platform every try-block is costly, if there is a thrown exception or not. On x64 due to some magic try-block are essentially for free if there is no exception. And there are many automagically generated try-block to do the unwinding, so even is you don't actively use exceptions, essentially very RAII variable is costly unless the compiles knows that there can't be any exceptions (→ noexcept).
"I was told never to use `goto`, but does should I leave this 4-times nested for-loop unless I use `goto`? I know! I simply throw an exception!"
This makes me want to go
Not him, but for me it is _way_ too slow. I like a lot of the features (I used Intellij and ResharperC++ in Visual Studio), but it just chokes on our code base. Currently I've been using VS Code with some plugins, and while it doesn't have all of the features of CLion, it at least can handle our codebase. Also, another sticking point for me is that it costs. There are so many great &amp; free IDEs out there, that it ends up being a con. Not that I mind paying money for good tools, but its a mark against it for me.
Non-null pointers are fairly common, dropbox has a good implementation.
They thought so much if they could, they didn't stop to consider if they *should*. Frankly, calculator should be immutable between major updates. Last month, I was giving a talk before a medium-sized audience and pulled up calculator. Calculator informed me it wouldn't launch until it updated. So it proceeded to laboriously update (a 10MB update!) while the crowd laughed at how preposterous Microsoft was. Then, to top it off, the update failed. So I couldn't use calculator at all. 
&gt;I'm a little confused. In this pattern, withId would be a static method of the class Register Yep, my code \*slightly\* different, but hopefully you can glean the rough idea template&lt; class moduleClass &gt; class Register { static bool withId(const char* moduleIdentifier) { RegisterPlugin(subType((moduleClass*) nullptr), moduleIdentifier, -&gt; gmpi::IMpUnknown* { return toUnknown(new moduleClass()); } ); return false; // value not used, but required. } }; &amp;#x200B;
tldr silently ignoring errors
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/aylom1/help_understanding_output/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
* that's one dll. this is a compiler change, so it will make all the dlls shrink (eventually) * faster download * faster installation * smaller disk size required * less ram required * faster loading from disk to memory * more cache hits, therefore running faster when it actually runs The goal of a compiler is to turn the code humans writes into code machines read. The goal of an optimizing compiler is to produce code that machines read faster. Smaller code gets read faster. That's it. (this is not an atypical post for a blog on compilers)
The amusing part is that leaving a nested loop is often cited as the only good use of goto, and this use is actually called out as being good in the core guidelines.
It appears [from answers below] this apears in (an) implementation-file(s). I don't see there to be anything wrong with that, stylistically, maybe.
To add to that (and this does not only apply to calculator), they change the name (version named) of the executable, so now my firewall rule(s) is(are) f'ed every bloody time.
AFAIK, they are on their way to fix it.
Windows uses table-based EH for x64 and a singly-linked list of frame handlers pointed to by fs:[0] for x86. The problem with noexcept is that if the compiler can't determine that there are no possible throw paths, it'll just emit the implicit try-block inside of the noexcept function instead. In the case where the calling function already had an implicit try-block for other reasons, adding noexcept can regress performance on x86 as now there will be two such scopes on the call path. I really wish Visual C++ had a mitigation flag to disable the noexcept terminate() scopes, as they make it difficult to recommend noexcept when x86 builds are still being maintained. 
Pfff, too fancy for `LOOP: if(x) goto LOOP;` now are we?
I had the exact same problem with my method a couple days ago. I tried screwing around with linker options but it wasn't robust or portable. Since I'm using code generation that understands the relationships between modules, I just bundled up all my registration into a function and call it inside an auto-register instance in the final executable.
I thought the advantage would be more predictable performance, not better. In fact I'd expect performance to take a hit
If you throw an exception? I can almost guarantee you that that will be faster with throwing values than throwing types. On the non-throwing path you may me right, because the compiler has to insert more branches. But I was talking about the overhead in binary size, not performance. 
But they are also not loaded into cache, as they don't get executed under normal operations. 
Sure. I'm certainly not complaining (on the contrary, I'm very happy that some work is being done in that area), but the original question was "why should I care?" and after thinking a bit about it, my answer is: you probably shouldn't (at least not too much). Note that the guy has made performance measurements (for the throwing case) and the improvement is nice but not dramatic. Doesn't mean that it isn't important for someone out there, but I think for the average application it is simply yet another optimization that improves your binary a bit. Of course, in total those optimizations become really, really noticeable. 
Where does bist make henry user of exceptions (remember, this optimization is only relevant for the performance of the throwing case)
Ah yes, this makes sense now. Thank you!
Because this is one of several optimizations.
Sort-of related: is there a reason to use lldb on Linux, as opposed to gdb?
This is a good point.
&gt;in many cases the base class and the factory are part of the *library*. And the implementations (or at least additional implementations) are written in *user* code. So it's not possible for the factory to know about the implementations. So what? Those library factories will have registration methods with some kind of type erasure anyway. &gt;Yes, it absolutely does. In the traditional example, you have to name the derived types you are registering. You'll notice that the food factory obviously includes Burrito.h, etc. That's just incidental. The actual registration of the actual factory is done via a lambda, which are most likely shoved away into some type-erasing function wrapper. The type is not known the the factory. Just the function. The factory can't even touch the type. Just because it includes the header doesn't mean the factory itself actually reaches in and manipulates the types directly. &gt;What you probably meant is that the factory does not include the derived types in its *API*, Yes, that is what I "probably" meant, because I specifically mentioned type erasure. Not sure why you spent half a paragraph arguing something else and then only get around to "probably" addressing the point I actually made. &gt;In some cases, this is good enough, in others, it is not. Both implementations of the factory pattern hide the derived types from the public interface, and those are the only two that are being considered here. &gt;The fact that you haven't understood the use case for it, does not make something an anti-pattern. Just because you lack the imagination to figure out an alternative doesn't make it a good pattern. &gt;This is bad but no worse then failing to understand the motivating use cases for a pattern and then simply generalizing and saying that it is "bad". Yet you continue to fail to even come up with a good motivating use case for it. Meaning, not only do you not understand the pattern, but unable to see that your "expert" programmers may not be as expert as you think and you've mislearned to accept bad design as good design.
AFAIK, there are no outstanding features that lldb has and gdb misses. But I find the handling of commands, subcomands and their options more consistent within lldb. I keep forgetting how to do and/or tweak x in gdb, the lldb counterpart is often more sticky.
FYI, here's the talk Abstract C++ has been undergoing quite a lot of change in the last several years - C++11, C++14, and even C++17. These changes present opportunities for new designs and behaviors. But, how do these new opportunities actually pan out when the project is non-trivial, extremely performance sensitive, and has to interoperate with other languages? Aeron is a high performance messaging transport that provides a C++ API that transparently interoperates with its Java API. In this session, we will talk about the challenges faced with the use of C++11 in Aeron and the lessons learned. Whether you are just curious about modern C++ or are an experienced C/C++ developer, this session will provide some new information.
&gt; If you throw an exception? I mean as a whole, you get predictable (deterministic) performance with "throwing values" but in general it's going to be slower for the reason you state &gt; On the non-throwing path you may me right, because the compiler has to insert more branches. Yep I agree, throwing values will be slower on average but more deterministic
One nice use case is leveraging the python API to for non-interactive debugging. For some function calls, it's a bit tedious to figure out the appropriate function parameters (lots of zero or \`Null\` parameters), but once you have set up a script that loads an executable and sets breakpoints with python callbacks, you can easily customize it from this point on. \[Here\]([https://stackoverflow.com/a/54399711/9593596](https://stackoverflow.com/a/54399711/9593596)) is a simple example to collect function parameter data.
My 2 cents... The examples in the README don’t show which headers to include, nor any namespace aliasing. Add a cmake option to build a static lib (and make it the default for easier packageability). The option to build tests should be off by default, especially if it was going to download online packages. 
I have very limited knowledge of C++ but according to my tests, bool connected still causes the while loop to exit once it's changed to FALSE, even if connected is modified by a different thread. What I fail to understand is why this is an issue &gt;over all&lt;. If it's not causing any Unexpected Behaviour such as a crash, why is this a problem? I'm talking about logics, not C++ rules. Please explain because Googling didn't do me any good in this case.
Since I usually don't need return values for tuples I just use fold expressions: &amp;#x200B; | template &lt;typename T, typename F&gt; | auto for\_each(T&amp;&amp; tup, F&amp;&amp; func) { | return std::apply(\[func\] (auto&amp;&amp; ...el) { (func(el), ...); }, std::forward&lt;T&gt;(tup)); | } &amp;#x200B; Note that this also works with member functions: &amp;#x200B; | template &lt;typename T&gt; | auto for\_each(T&amp;&amp; tup) { | return std::apply(\[func\] (auto&amp;&amp; ...el) { (el.func(), ...); }, std::forward&lt;T&gt;(tup)); | } &amp;#x200B; And don't forget we probably get expansion statements in C++20.
boost::hana definitely has a \`find\_if\`, and I'm not sure why the author says \`find\_if\` on tuples would be out of scope for it
It's a shame code isn't very readable without proper indentation.
&gt; Discussions, articles, and news about the C++ programming language or programming in C++. Should be asked in /r/cpp_questions. I don't think that there is a cross compiler for Mac.
I reposted the same questions to /r/cpp_questions, sorry. As for cross compiler for Mac Cygwin cross compilers build (the link I've poated) includes one, so it is definitely possible to build one. Also Go, FreePascal, Red and Zig compilers can cross compile from Windows to Mac.
Feels rust-y.
I hope that's a good thing. I definitely took some inspiration from Rust when implementing this (and Elm, which is where I believe Rust took theirs from).
I think the standard should provide portable access to different low-level facilities (like `std::thread`, `std::socket`, etc. and leave high-level libraries outside. That way we could have got networking already in C++11...
As long as we can get the safety of Rust.
UB isn't about crashes, it is about code that simply has no defined rules on how it will behave. Advanced optimizers may or may not end up generating the code you expect, because they may or may not assume some situation is impossible.
Ues const is very different than immutable. For concrete cades: int foo(int const&amp; x, int&amp; y) x is const but not immutable; foo promises not to modify x, but x can change whenever it wants to: foo just isn't supposed to do it. Nobody would think int foo(int immutable&amp; x, int&amp; y) would permit that. 
I have migrated my codebase and workflow to clang and llvm versus gcc. I'm still maintaining gcc support, but I find all the clang tools and libs to be extremely useful. Maybe it's just subjective, but I really prefer clang. While not necessary, it makes sense to use LLDB since I'm already using the LLVM framework through clang++.
I completely agree about clang vs gcc, I also compile with it at work and it's easily 40% faster on our codebase (on both small incremental build and full rebuilds). However I still use gdb for debgugging since I have some tooling for it
Here is a more creative solution for the find\_if, which is stateless and should even be a bit more efficient, since it doesn't have to visit every element of the tuple. That being said... it's not necessarily easier to read. template&lt;typename Tuple, typename Predicate, typename Indices = std::make_index_sequence&lt;std::tuple_size_v&lt;std::remove_reference_t&lt;Tuple&gt;&gt;&gt;&gt; constexpr size_t find_if(Tuple&amp;&amp; tuple, Predicate pred) { return find_if_impl(tuple, pred, Indices{}); } template &lt;class Tuple, class F, std::size_t... I&gt; constexpr size_t find_if_impl(Tuple&amp;&amp; t, F&amp;&amp; f, std::index_sequence&lt;I...&gt;) { size_t currentIndex; bool found = false; ((currentIndex = I, found = std::forward&lt;F&gt;(f)(std::get&lt;I&gt;(t))) || ...); return found ? currentIndex : std::tuple_size_v&lt;std::remove_reference_t&lt;Tuple&gt;&gt;; } &amp;#x200B;
The JSON output with nesting looks like an excellent tool to improve IDEs. I would really like foldable error messages for nested substitution failure diagnostics in the future :)