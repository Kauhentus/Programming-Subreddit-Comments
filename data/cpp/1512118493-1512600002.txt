&gt; looks intriguing to me, think I'm one step closer to using c++ as a pseudo scripting language `self(x, "abc"s);` looks very obfuscated to me, think you're one step closer to using C++ in the wrong way (for some definition of "wrong")
If only "auto" was allowed here, it could've been auto x = "abc"s; which couldn't be any clearer 
Host processor in a network device used by ISPs. Used mainly for management of the device so one of the interfaces is REST through the cpprest. 
So just use auto?
So, what do you want to discuss, present, ask, know, solve? Other than showing a 18+ year old feature of c++?
If u let go of the exact type names and just focus on what each variable, or object for a custom type could do for u, coding would be just a million times easier (there are exceptions like if u wanna implicit type conversation)
Yes, it's all **implemented by** the old templates, but like I said earlier, I'm not here to discuss templates, a lot of coders like, Java (which does not have templates) coders or similar would limit "polymorphism" to function polymorphism, and I just think polymorphism should be more than that
Is it x86, arm, mips? Just curious.
Auto is not allowed for member variables
There's a reason why auto is not allowed there. Having the class layout depend on the type of an expression, which may in turn depend on the class layout, is troublesome to say the least. The fact that you can achieve a similar result with `decltype` doesn't mean it's a good thing to do.
It wouldn't be a problem for maybe 90% of the time, I prefer to use it by default and deal with the shitty 10% manually if necessary 
I started using Qt Creator when I needed Qt for a project, because like you said it has the best integration. But I haven’t used Qt for quite sometime, yet Qt Creator is still the best C++ IDE for me, and I’m using it daily for all my (non-Qt) projects. 
It's complete with regards to my needs, but pull requests are welcome if there are bits and pieces one feels is missing. At the very least we have achieved a fast, stable and easy to use IDE for C/C++ based on libclang. I also think jucipp is the only IDE mentioned here that is extensively programmed using C++14. 
I guarantee you will have to look at cmake and proceed to install vs back immediately and make a post about how easy project managment in it is.
1) use clang as C++ compiler 2) use ctags to generate a code project file $ ctags -R -V &lt;projectfolder&gt; 2) use neovim (newer successor of vi(m)) with the following plugins: - deoplete // code completion - deoplete-clang // code completion support with the help of clang - vim-clang-format // code formatting with the help of clang - Yggdroot/indentLine // see indentlines - tomtom/tcomment_vim // toggle comment lines/selected sections - craigemery/vim-autotag // searches for a tags file on save to update so you dont have to run ctags manually after every change The setup in vim for the plugins to make it all work is just a few lines, most work out of the box (you can always pm for more information)
I really like the approach, but the GUI was sluggish since I used the Linux version on Windows (WSL + Xming). As long as it's GTK based, I'll stay with Visual Studio. Would love to help, but my private schedule is full for the next 4-6 months.
mips
It is not just the amount of files if I remember. A real compiler like libclang is not really good at handling half-written code, which is often the case (unless you write block of code at once).
The best Visual Studio version is 2008, which is a pleasure to work with. After that, they migrated to WPF crap, and since then everything became slow, unresponsive and bloated.
&gt; libclang isn't very good with working on many files at once. what does that even mean? YCM and rtags are living proof that libclang can do code completion just fine. The only real argument for the in-house parser is more error tolerance.
Upvote for conan.io as next integration in Clion
There's no special integration, but it uses CMake as its project model so developing Qt code is painless.
PIMPL isn't really complicated, and I think it's a good idea to stick with a pretty standard implementation. The template issues you describe are a good start at painting yourself into a pretty nasty corner. You can usually make something like this work in a few cases, but it will become uglier and uglier as you scale the system up.
But where would I design my GUI? 
Make is for CMake like C is for C++. Of course, it is harder to debug CMake, but it is easier to understand and write. 
Ahh, now I know what `std::decay` is for.
Same when read the article. The problem was to remove virtual calls but it ended up in type erasure + boilerplate code + hidden pointer + still virtual calls, which doesn't solve the problem and even introduced more complications. AFAIK the only solution to these virtual calls would be CRTP.
A colleague complained that Beast (client-side) is a bit too low-level when coming from things like libcurl, or even the equivalent in Go/JavaScript. I think he's right, but also, this is c++, so...
Nah, it works ok with many files at once. The reason for in-house parser is mostly that they've already written shitload of their own infra around parsing files and providing suggestions, etc, and they have been writing C++ parser (VS plugins) when libclang hasn't been that much of a thing... now its kind of a sunk-cost thing\* \* And their own parser is likely easier to extend for them to include specific suggestions
&gt; AFAIK the only solution to these virtual calls would be CRTP. I don't think the point is to remove virtual calls altogether (sometimes you really need that run-time polymorphism, eg with plug-ins), but instead to hide them behind value semantics.
From the article: &lt;&lt; It’s no secret C++ favours static polymorphism. But sometimes, runtime polymorphism is needed and suddenly we find ourselves down the virtual rabbit hole. Do not despair, for there are ways to avoid this madness. Okay, but using type erasure (nothing against type erasure) to solve this problem sounds like fucking madness to me! The way to actually avoid this type of madness, and to solve this problem cleanly, is to *use the decorator pattern*. It's sort of my go-to when static polymorphism isn't enough. Yeah, it is a bit more work than using inheritance/virtual functions but it scales far better across problem domains with higher uncertainty. To this point: Polymorphism via inheritance/virtual functions is a super amazing tool, but the main issue is that it's basically only good for problems with low uncertainty and/or situations where you have a pretty good understanding of the problem you want to solve. You also need to have a pretty good idea that users of your class will be able to solve the problem using the same base class and function signature(s). There are many situations where this is just perfect. For situations where the set of use cases is poorly defined / highly-uncertain, you need to consider things like objects that can be decorated with other objects that contain the plug-in behavior, and your virtual functions just activate the behavior in the plug-in. That makes it much easier to to apply such a system to higher uncertainty problems because, with careful design, the user isn't strictly limited to solving their problem via a subclass and a specific function signature.
&gt; &gt; &gt; template &lt;class T&gt; static constexpr type_size&lt;vector&lt;T&gt;&gt; = sizeof(void*) * 3; would fail for instance with -D_GLIBCXX_DEBUG or MSVC debug mode if I am not mistaken
&gt; "just because you can, doesn't mean you should". What an nice summary of : Modern C++ Design: Generic Programming and Design Patterns Applied By Andrei Alexandrescu
I find autogenerating all the sln/vcxproj junk with cmake vastly more maintainable and flexible.
Works from Poland for me.
So far the most boilerplate comes from defining operators; `if constexpr` shortens SFINAE a lot, but the code would benefit great from `operator&lt;=&gt;`.
Yeah, value semantics are better.
Ooh. It has bazel support now? I'll have to give it another look. Anything funky I should keep in mind?
So do you get the All Products pack? Should be cheaper than individual licenses at that point.
By the as-if rule, you the compiler can remove member variable if it's not used. Unless you pass it to a function, this concrere instantiation could have reduced size. It's probbaly one of these funny optimizations that only happens if you don't use something.
libclang is getting better at this all the time - and with the new server architecture is becoming increasingly viable. That wasn't the case when CLion started, so using our own parser was really the only option that made sense for us. There are quite big pros and cons to switching now - so it's not something we're doing imminently, but I wouldn't rule it out.
It's basic, but usable, but I've just used the CrtDbg stuff before. It's even built in to Catch now (https://github.com/catchorg/Catch2/blob/46c7c9d3a0cb975dabf5970cc65fd8fc72d4c5b5/docs/configuration.md#other-toggles)
!RedditSilver
Can C++ get actual sum types first before adding more and more monstrosities like `std::optional` or `std::expected` to the standard?
I would be surprised if it didn't work. In the end compiler will generate a bunch of subroutines and only member functions of the class with FwdMember&lt;&gt; are allowed to touch it. Please have a look at FwdMemberMockup template in [fwd_member.h](https://github.com/nadult/libfwk/blob/master/include/fwk/fwd_member.h). You simply cannot do anything useful with it (like generate invalid code).
I wasn't suggesting to do it for std:: types, only for your own.
No it can't because they can be easly implemented with current language features.
static_asserts are not necessary, FwdMember does the checking for you. Also I found FwdMember to be much smaller PITA in maintainance than PIMPL.
Understood - that would be a welcome change, maybe even optionally if the completer is decoupled enough. I work with template-heavy library code and the CLion parser is regularly choking on it. 
Yeah, I get the full suite. 
No, I said actual sum types. Just because it *can* be implemented as a library feature, doesn't mean it *should* be. 
I use makefile for building golang projects or cooking Docker containers, not for building C++ projects. Makefile is awful for such complex jobs.
Initially I was hesitant to implement it and use it because I too consider it ugly. But I gave it a try and after a month of testing I'm sticking with it (not using it everywhere I can, but only there where it provides some benefit). What do you mean by 'template issues'?
Don't cast. get `const char*` from `std::string` and save it somewhere, then pass it. extern void foo(const char* const* arrs, size_t size); // want to call this std::vector&lt;std::string&gt; pages = { "Apple", "Orange" }; std::vector&lt;const char*&gt; pages_cstr; pages_cstr.reserve(pages.size()); for (auto&amp; item: pages) { pages_cstr.push_back(item.c_str()); } foo(pages_cstr.data(), pages_cstr.size()); 
No casting a std string like that is undefined behavior and , in fact, doesn’t work. (Because SSO etc) Why not storing const char* inside the vector?
&gt; It would be great if the ODR could be adjusted to allow this somehow. Instead I would prefer a new compilation model for C++. What we have now is simple but also quite 'dumb': it causes a lot of redundant computations. Recompiling Client using SomeType when SomeType implementation changes but interface &amp; size remain unchanged is only one of many examples.
That's a lot to ask for a feature that has pretty low usage outside of functional languages. And it should stay like that because it's more of a workaround in functional languages than what imperative languages lack.
I disagree, sum types are used a lot in Rust and Swift and they augment the usual facilities which languages like C++ provide. I would really like to see a language variant in C++. Something like `std::expected` could then be implemented on top of this rather than all the ridiculousness we have to go through to implement it today.
PC-lint *Plus* is considered a new product so there is no standard "upgrade" pricing but we are currently offering a discount to current PC-lint/FlexeLint customers.
I usually do PIMPL by declaring an abstract interface in the header file, and derive from it in C++. Like this struct Something { static std::unique_ptr&lt;Something&gt; Make(); virtual ~Something() = default; virtual Do1() = 0; };
&gt; I seriously do not understand the hate for inheritance. because I hate Java style programming and its whole crew, moreover, I hate the entire nominal type system, its extremely verbose, a more elegant solution should be duck typing, which does not need inheritance to achieve runtime polymorphism, and is how OOP is implemented in dynamic languages including smalltalk
The man page is [here](https://kristaps.bsd.lv/kcgi/khttp_parse.3.html) It uses it as look up table. As it is `const char* const*` it will now change them and also no free them. I assume no transfer of ownership.
That looks like a way. I might try also try a `std::array&lt;const char*, n&gt;` as the list of strings is pretty much fixed.
I understand this but then C++ is the wrong language for you. (I do not mean that as an insult)
Why not both?
What is CRTP?
I've used the cpprestsdk for a small, cross-platform (macOS, Windows, Linux), hobby app with great success. I appreciate the CMake support!
It also plays very nicely with CMake.
I wish C++ could have something like the "dynamic" keyword in C# someday, it grants the power to do occasional duck typing in a static language, its not very performance friendly but it offers a choice if ur willing to pay the price
https://stackoverflow.com/questions/4173254/what-is-the-curiously-recurring-template-pattern-crtp 3rd example is the simplest. Note "seemingly recursive" inheritance.
https://stackoverflow.com/questions/4173254/what-is-the-curiously-recurring-template-pattern-crtp 3rd example is the simplest. Note "seemingly recursive" inheritance.
The bazel plugin may not work with the latest CLion, so you may have to go back a version (but this needs to be checked again). I got hooked on CLion/bazel while I was working at Google, since I could not stand Eclipse (which was also used for C++), but with dart, flutter, Java, Python and go support the JetBrains products are leading the way
I'm unfamilliar with the installer or the IDE we ship (I've actually never used either!), but I wouldn't have been surprised if it was a 'checked by default' checkbox. 
Sounds like you need concepts + terse syntax
I think you're missing the point here. There's a difference between compile time duck typing and runtime duck typing. I love compile time duck typing. I can write a function and put an `if` there if my variable has a particular member and use it if it exist. It makes variable names more important than type names. Both are important but when you're forced to use a good variable name, it's better. I can concentrate on what a variable do instead of what the base class of that can make or not. Compose an interface not just with AND but with OR too (required to implement that function OR that function). With duck typing I can focus on writing behavior with things I give names. I don't have to care how that thing is implemented. I just need to know that when I implement y, I will be able to do x with it. And the best thing about it: The compiler tests it all for you. If there's a place where you do something invalid with a type, you don't have to run the function. Simply hit compile and the compiler tells you what is wrong and where. The compiler is such a powerful tool. If your data structure is done right, you can catch most programming error at compile time. However, I *hate* runtime duck typing. It's so error prone. You never know if you really can do that thing with that variable. You can't validate it. You can't even go see what you can really do with it before you actually RUN the function. And what you can actually do with that variable can change depending on what is done before. This is so awful, I worked a lot with that and it's really painful. If an error can happen, it will. You can call a non existent function? You will do it. And you will ship it, and your client will call you for it.
Qt designer can be run as standalone application so you can still use it to generate ui files
And they are only usable because rust has pattern matching.
When a class need a particular instance of something, it all make sense you specify the type. Because majority of time, there would be nothing to place after `auto a =`. I receive those values from somewhere else that I cannot obtain without a prior state. For example, struct KeyboardEvent { KeyCode code; bool repetition; }; There is no place for auto there.
I would recommend taking responsibility for a smallish and popular open source project. This keeps one engaged with C++, it's modern enhancements and it's community without making a huge time commitment. If you don't have time to actually make such a project, you might want to take on the maintenance of an existing one. Boost has a number of projects which need someone such as yourself.
It's low-level, and the docs admit that. It's intended to be a building-block in the development of higher-level libraries, and is just a first-step in ongoing efforts. That said, it's great for what it does.
Yes, some kind of pattern matching would be integral to a good sum type feature.
what I would do auto f(std::vector&lt;std::string&gt; &amp;pages) { auto size = pages.size(); auto pages_vla = reinterpret_cast&lt;const char **&gt;(alloca(size * sizeof(const char *))); for (auto &amp;[x, y] : view::zip(view::iota(0), pages)) pages_vla[x] = y.data(); khttp_parse(pages_vla, size); }
unlike malloc() which allocates on heap, alloca() allocates dynamically on the current stack frame (similar to VLA in C99), it has the performance of std::array but also allows allocations with runtime determined sizes
Fair enough, thanks for checking into it. I'll look forward to the switch then!
The philosophy of C++ is the opposite. If it can be implemented as a library, it should be. String is a library. Vector is a library. What do you want from your sum type that you're not getting and that you think a library can't provide?
It holds github passwords and server info if you tell it to save. Is that what you mean by security? Otherwise I'm not sure what could happen in a breatch
what...? struct KeyboardEvent { auto code = KeyCode{}; auto repetition = false; //or true, doesn't really matter KeyboardEvent() = default; KeyboardEvent(const KeyCode &amp;x) { code = x; } KeyboardEvent(KeyCode &amp;&amp;x, bool y) { code = std::move(x); repetition = y; } ... };
&gt; 's a lot to ask for a feature that has pretty low usage outside of functional languages For the sole reason that it’s badly supported. Otherwise its use would be pretty m
I'd recommend my own editor, [Kakoune](http://kakoune.org) which is itself written in C++14, Vim-like but much modernised (both in design and implementation), with very expressive text edition support (its easy to express complex semantic changes), and good C++ support including intelligent completion through clang.
If you want duck typing in C++, just use hash tables and "any" everywhere. Honest to god, [that's how dynamic languages work](https://github.com/Jeff-Mott-OR/javascript-cpp-rosetta-stone#objects).
That sort of philosophy is what led to the abomination that is `std::initializer_list`. I don't see why you even bring up string and vector. If `enum class` was added, I don't see why something like `union class` can't be added to make working with sum types not a pain in the ass. As for bashing `std::variant` and `std::visit`, [this article comes to mind, which probably spells it out better than I ever could.] (https://bitbashing.io/std-visit.html) Don't even try and convince me this is acceptable just because of an obsession to unnecessarily make everything a library feature.
If by "why not both?" you mean adding actual sum types and THEN implementing `std::optional` and `std::expected` using those, yes, that's exactly what I want.
I don't know much Functional Programming, so by actual sum types do you mean pattern matching instead of std::visit or are there other features std::variant doesn't have?
Now there is a branch after every call, which wouldn't be there if you used exceptions. 
FYI, there is already a C++ project for command line interface parsing called [CLI](https://codesynthesis.com/projects/cli/).
What if keycode is not default constructible? What if I don't want my class to be default constructible either? Why did you added copy and move constructor when default one are just fine? &gt; //or true, doesn't really matter It's that don't really matter that annoys me. If you have a thing that should not be default constructible, and you put initial value that don't make sense, you will end up with runtime bugs instead of compile time error. Invalid states should not be able to exist, unless you explicitly made something that represent an invalid state.
Qt uses PIMPL extensively to help remain backward and forward compatible between its library versions. Your alternative with strict size requirement would make it very hard to support that case.
This is true, but in the event where errors are somewhat common, this is no problem at all: the cost of the exeptions is probably much higher.
Indeed, if you want binary compatibility in your API then you definitely need additional layer of indirection which PIMPL provides.
C++ is a multi-paradigm language which means its not like Java that would force u to do things the way u dislike, everyone has his own way of writing C++, there's no such thing as default unconstructible in scripting languages, as someone that writes modern C++ as a pseudo scripting language, I would never create types with weird constructors (private constructors/somehow unconstructible/unmovable/cannot be copied/...) so it won't be a problem to me, we are writing the same language but with very different style preferences, and it's why our code looks weird to each other
Exceptions make sense when you actually *need* to unwind the call stack, because the only reasonable course of action is to ditch what you're working on and have something far up the call stack handle the failure. They do not make sense when there is a reasonable way to recover, and the failure is likely to happen in normal usage. Besides, while exceptions don't have an actual branch after every call, they *do* add essentially the same edges to the control flow graph, inhibiting the optimizer (which is part of why `noexcept` is valuable).
No. Adding sum types and product type is a mistake. We should add the tools that enables creating sum types. Then with that tool we can create much more powerful things instead of just that specific sum type. I'm talking about coroutines: https://github.com/toby-allsopp/coroutine_monad
`return crop_to_cat(img) .and_then(add_bow_tie) .and_then(make_eyes_sparkle) .map(make_smaller) .map(add_rainbow);` Compared to `crop_to_cat(img) add_bow_tie(img) make_eyes_sparkle(img) make_smaller(img) add_rainbow(img)` ? It's just cute. Also, if there's any memory allocation needed anywhere, it's either lying about not throwing or each such function is wrapped in a try/catch. (And no, you can't rig operator new to return nullptr because std lib needs it to throw). In practice, this is only usable in the lowest level code. Which is funny because it tries to play on a high level of abstraction.
Isn't that a similar setup to what Jason Turner uses? On this subject, did he ever publish his settings/plugin selection?
I can't wait to drink fanboys tears when it will fail like the Itanium after people realize it can't be faster than precompiled headers, will break tons of tools, and it will not fix magically code with high coupling. 
The author of that blog seems entirely unaware that std::variant has get_if() and index(). Which provide the tools necessary to deal with a a variant in the way that he wants. No Lamdas, no visitor pattern...
why would someone use COM for IPC when they map shared memory with only a few lines and build on that? 
use `string_view`
Actual IPC Support for various multithreading models Cross-language integration Easy switch to RPC should thst be needed Declarative, role based security (Component Services a.k.a COM+) Shared memory, pipes, mailslots etc. really are from the stone age comparatively. (Yes I did all of them at least once :-)).
Sorry, my mistake - schould have had a proper Lok at where it was used.
Ok, my mistake then for not thinking from the perspective of a non-c++ programmer. BTW: you can even have type polymorphism (e.g. `&lt;type_trait&gt;::type`)
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7guyx4/how_to_wrap_a_cstyle_string_array_in_c/dqmivc3/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I guess the question is what those other threading/parallel solutions are. Or how complicated it is to recreate them in libstdc++ (I haven't had a look at the code, it might be totally trivial).
Actually, if you watch the talk of Louis Dionne about his library dyno and runtime polyphormism, you will see that you can remove both of these indirections. Also, one of the best feature that you get out of this pattern is that you can "extend" types that you don't own (like STL types) by writing a free function that handles the desired behavior for that type. Ideally all of this could be done as a language feature. Haskell does it with higher-kind types and Rust with traits. The difference being that you explicitly implement a trait for a type.
You can actually embedded the vtable within your object as demonstrated by Louis Dionne Dyno library.
IMHO, the trade-off with "Sean Parent style" polymorphism is very simple: you add lots of boilerplate and repetition (or complexity, if you use some library that uses macro to try to eliminate these), and you eliminate coupling. That's pretty much it. The derived doesn't have any dependency on base any more, only the end user depends on both base and derived. Derived doesn't even have to directly implement the interface of base. In the article, the free functions implementing base' interface were friends, but the much more interesting case is when they aren't friends, i.e. you are implementing free functions that satisfy Base' interface for a Derived you don't even own. Basically, this approach kind of gives you the Adapter pattern for free. The thing is that much/most of the time, base and derived are owned by the same person, that person is the same as the user, and derived's only purpose in life is to satisfy the interface laid out by base. In other words, a situation where the coupling just isn't a big deal, and adding all this on top of simple but imperfect inheritance, just isn't worth it. All the other pros/cons are mostly agnostic of using traditional inheritance. I think it's just fashionable nowadays to have some kind of vendetta against traditional inheritance and member functions.
Example link pls?
https://youtu.be/gVGtNFg4ay0?t=2444
Ahh didn't know that, thanks! 
Exceptions are supposed to be free unless they happen. So as long as throwing is not part of your normal code path, you're fine.
EDG's real compiler which powers MSVC's Intellisense is a counterexample.
That's a myth. Un-thrown exceptions are only free in the sense that they don't *directly* use any additional instructions. They still have a cost in the sense that they add extra edges to the control flow graph, which inhibits the optimizer. If you have a `catch` block in scope it's even worse, because the `catch` can touch arbitrary state and resume normal execution, which inhibits the optimizer even further.
Except in practice, the compiler understands what you're doing and doesn't actually generate a branch after every call. This isn't hypothetical, I rely on this.
Yet `lambda` is not a library function, because the implementation was horrendous. While it's not as bad with optional/variant, it could definitely be a lot better.
Yes. And Pattern matching is possible because Sum types are part of the language. Nothing prevents same efficient pattern matching in C++ if sum types were a language feature and not a library one.
Is it possible to read C++17 standard for free? If yes, why would anyone pay for that version?
This is indeed a great great talk from Louis Dionne, highly recommended.
&gt; Actual IPC &gt; Support for various multithreading models &gt; Cross-language integration I think it's a pretty bold claim that those things can't be done, done quickly and done elegantly with shared memory. You didn't really back up what you are saying or even mention what 'real' IPC is supposed to be. 
It is possible to read the draft for free and in my experience the draft is identical to the final version except for minor editorial corrections (spelling, grammar etc..). The money goes to the ISO for maintaining and publishing the official standard. I pay for the official version (through my corporation) for the same reason I pay for open-source software, to contribute to things that I (and my company) benefit from so that we can continue to benefit from it. But it is perfectly acceptable to download draft copies of the standard to learn from it, and if you're an individual the official version certainly is expensive.
You can access the previous version before the final fixes for free, but not this one. ISO always makes people pay retarded sums for the standards and realistically only companies buy them to make sure they are compliant.
It's easy to see why. If you use your object a lot, the vtable will be in cache so the access will be fast. But putting it inside your object increase its size, so the memory overhead can definitely hurt more than one indirection that never ends up in a cache miss anyway.
Now you're making me worried because I used some Intel products under non-commercial licenses for my research and I do get paid for my research by my university. 
In an imperative language, return type-based error handling makes more sense with an early-return macro or operator, IMO. For example some of the macros used with COM, which uses `HRESULT` return codes instead of exceptions, either return or throw on errors. It's unfortunate that the stdlib containers rely exclusively on exceptions for allocation failure, because it would sometimes be useful to get an error return instead, but at the same time most allocation failure isn't really actionable beyond cancelling the operation at a high level to reclaim some resources.
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4659.pdf Should be nearly identical
How does ISO maintain the standard? As I understand it is a separate entity from C++ standard committee, so how does paying ISO benefits the creators of the standard?
Ooh, its available as a paper copy! I'm REALLY tempted, this is the first standard I worked on, so sentimental-me wants a copy... If only I can convince myself its worth $200!
Nice article! I'm glad someone else also wants to put why-something-failed somewhere, which is what I thought as well after playing around with std::optional for a bit...
I don't know Jason Turner, I"ve tried various plugins and these seemed to work best for me.
PIMPL requires dynamic memory allocation unless your class is a singleton. I've worked on embedded projects where there was no heap, this would've been a useful compromise. 
Branch prediction, maybe likely/unlikely hint. Cost of that vs exceptions existing is hard to judge.
Great stuff, especially happy to see Louis and Hana's paper moving forward. There was supposed to be a new revision of my `function_ref` proposal, but it was left out by accident. You can find it here: https://vittorioromeo.info/Misc/p0792r1.html I am looking for and appreciate feedback :)
Wouldn't Intel just buy it for you? :)
I'll have to see! Might be hard to justify...
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7gzsbv/help_please/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Write a C++ program that outputs the time since your last medical checkup in years, months, weeks and days. 
It sounds like a scam to me, to be honest. In this day and age it costs exactly zero dollars to publish something. Zero. You can put it all over the internet, for free, instantly, no maintenance required. Now, for publishing it in a book, that takes money and materials. But only for the book version. A PDF costs them nothing, but is somehow the same price as a paper version? Definition of a scam, right there.
&gt; The money goes to the ISO for maintaining and publishing the official standard. Doesn't make much sense to me considering in this day and age it's free to publish anything, because of the internet. It costs nothing to publish or maintain, whatever that means in this context. 
There's a joke about standards compliance in there somewhere..
Some would say that being an ISO-affiliated org lends prestige to the committee. Its probably helpful for anyone who is an academic who serves on the committee. Its like tier 1 journals vs. lower tier, im sure being on iso or acm associated committee counts for tenure points somehow at most places. I dont know if there are any industry jobs that particularly care in that sense. Probably there are a lot who see it as the reverse - the c++ standards committee being affiliated to ISO lends prestige to ISO.
Doesn’t std::variant solve most of these problems?
I have been told that a big part of standards organizations like ECMA and ISO is that they handle legal mumbo jumbo that lets big competing companies come together to work on standards without triggering cartel / antitrust laws. But I Am Not A Lawyer, so I may have misunderstood.
I dont think this is really true... using switch over index, with get_if, defeats the type safety mechanism of visitation. With visitation, and with rust pattern matching, if some one adds a new type to the variant and every match/visitor is not updated, you get a compile time error. With index and get id, you dont, you get a runtime error. That really sucks.
Would it really be that much worse for the optimizer than something like auto error = some_error(); if (error) handle(); else continu();
The author said he wanted something like the following: match (theSetting) { Setting::Str(s) =&gt; println!("A string: {}", s), Setting::Int(n) =&gt; println!("An integer: {}", n), Setting::Bool(b) =&gt; println!("A boolean: {}", b), }; using get_if, we can write something pretty similar: if(auto s = theSetting.get_if&lt;std::string&gt;()) { std::cout &lt;&lt; *s &lt;&lt; '\n'; } else if(auto n = theSetting.get_if&lt;int&gt;()) { std::cout &lt;&lt; *n &lt;&lt; '\n'; } else if(auto b = theSetting.get_if&lt;bool&gt;()) { std::cout &lt;&lt; *b &lt;&lt; '\n'; } The difference seems mostly cosmetic to me... Sure, the C++ variant is a bit more verbose, but it providing what appears to be essentially identical functionality. Including the type safety. Unless I'm missing something?
Also see the Stackoverflow question [Where do I find the current C or C++ standard documents?](https://stackoverflow.com/q/81656/1708801) which also covers where to get the C documents as well.
Not much, probably worse in some cases and better in others. The point is that merely compiling with exceptions enabled has a cost, not just throwing one.
`get_if` won't trigger a compiler error if you don't cover all the cases. Rust does exhaustiveness checking on every match so that you can't leave cases out.
Sure, fair enough. That one particular feature has no equivalent when using std::variant.
With this you're paying for unnecessary virtual function overhead.
The price is ridiculous.
I mean stuff like [this](https://www.cvedetails.com/cve/CVE-2014-10036/)
This is how I got hooked on JetBrains
Agreed. BTW, allocation failure is not much different from other failures with regards to "actionability". It is **exceedingly** rare, in practice, that the code does something *right after* a failure (beyond cleanup of temporary state/resources, which is the job of destructors). Rather, cleanup is performed and normal processing resumes several stack levels higher. Indeed, the whole purpose of `expected, map, and_then` (or the `try!` macro in Rust) is to make that easy. But if that's the case, exceptions fill the need better, because they are purpose-made just for that. From that standpoint, the purpose of the article is... well, flawed. It starts with "there are problems with exceptions", but then goes on to pretty much reimplement them. I think, this is useful only to * incompetent people who can work exceptions, which would be weird because they need to work template magic which isn't trivial at all * **extreme** high-performance parts of the system (we have seen from cppcon that HFT industry is fine with exceptions, so for those who need even more) * **extreme** low level stuff, where there's no environment support for exceptions.
I did not say they can't be done. I was answering you question "why do it when there's shared memory". We can elaborate of course, but we are both biased and the argument would revolve around *what* is quick and/or elegant and how much, compared to the other approach. By 'real' IPC, I simply mean: I call a function that tells the other process what to do. Because if you think about it, you want the same with shared memory. You don't want to write something to it, that's an implementation detail in a large picture. Yes, I can e.g. take a lock, write, release a lock, set an event, and the other side can wait for the event, take a lock, read data, execute. But COM takes all that away, caller only needs to... well, execute. So you are right that it **can** be done. But my argument is "just because I can, doesn't mean I should".
One of the primary benefits of PIMPL is that it maintains ABI compatibility no matter what goes on in the private type. With your code, if you change the size of the implementation, it breaks ABI. 
Several links here: https://isocpp.org/std/the-standard I'm a fan of this copy: https://timsong-cpp.github.io/cppwp/
For C and C++ code, in my experience, [CodeSonar](https://www.grammatech.com/products/codesonar) and Coverity are in a league of their own, with the next rung down being occupied by Klocwork and lesser known ones like Fortify, Polyspace, etc. If I could travel back in time and give myself -- who was in your position some years ago -- just two tips that aren't already mentioned here, they would be: * When selecting one of these tools, it's VERY important to keep in mind what their licensing model is -- typically they determine the price based on the amount of LOC (Lines of Code) that gets "scanned", which can make managing the tool a nightmare. In every case I've seen, the static analyzers stupidly over count the amount of LOC that has been "scanned" in various ways; for example, it might count all the LOC for third-party dependencies against you, unless you spend the next 1000 man-years sweating bullets while fighting with configuration/settings/rules to ignore them. And finally, if you have a library/component that is re-used in N products, it will count that code N times. What you don't want to happen here, is ending up having to create a new fiefdom that controls/polices access to the tool because you're afraid of going over your licensed LOC limit. IME, vendors may not reveal other models to you unless you ask about it; ideally, push for an unlimited license based on some other reasonable "sizing" criteria, e.g. the number of developers that will be using it day-to-day. * After evaluating the tools on as much of your code as possible (N products or M platforms or whatever is representative), narrow it down to (at least) two contenders, and be ready to point out all the cases where contender A failed to find something important that contender B did. Repeat this process prior to your license expiring, so when you get a visit from their sales people for renewal and they suddenly want to double the price, you can (again) point out that their tool isn't perfect, they don't walk on water, and are prepared to drop them entirely in favor of their competitor if they try to price gouge you. 
Are you saying those code snippets should be equivalent? That would only be the case if those functions took a `optional`/`expected` and checked for failure themselves, which is even worse than the versions with mixed in checking I showed.
I'm really excited to see compile-time strings making progress too! This is a sorely needed feature.
I just followed the steps listed on the github repo and was able to install without a hitch.
Yes error handling adds overhead. And exceptions are lower overhead than branchy if-else code checking for error codes everywhere.
QtCreator had this feature for year (and also integrates with callgrind to show you pretty percentages near to your code) : * http://doc.qt.io/qtcreator/creator-analyzer.html * http://doc.qt.io/qtcreator/creator-cache-profiler.html 
I disagree on theoretical grounds (it's much more powerful to have a base meta-language able to express many things) but agree on practical grounds: the compilation model of C++ makes usage of base templates like this way too slow. If it was fixed so that templates were guaranteed a single instantiation in the compilation of a whole program, there wouldn't be any problems with std::whatever. Also, the compiler writers always have the possibility to optimize a library class, but you wouldn't be able to write an alternative "language-level" variant.
uh ? of course it does. std::variant&lt;int, std::string, std::vector&lt;int&gt;&gt; var; struct { void operator()(int); void operator()(std::string); } vis; std::visit(vis, var); // fails at compile time. 
You can have library-level pattern matching though : https://github.com/solodon4/Mach7
can you show me on godbolt?
Even with practice getting insight out of optimized C++ perf traces can be arduous. This will bring a measurable increase in legibility, especially so for those attempting to use perf for the first time. It is much appreciated.
That and modules, despite their big differences in the problems they solve and the scale of the features, are at the top of my list.
&gt; It costs nothing to publish or maintain, whatever that means in this context. It costs manhours. Those aren't free.
&gt; Maybe someone else can enlighten me to the costs of ctrl-c and ctrl-v'ing the pdf they get from the committee. Are you serious? Are you one of those who just downloads illegally and justifies it as "it's digital so it costs them nothing"?
&gt; branchy if-else code checking for error codes everywhere. That's not the comparison. Not every function can fail, and not every call needs to immediately check and branch. And for that matter, whatever happened to benchmarking? These approaches both have different performance characteristics.
Exactly. One feature I would like it to have is exporting Qt Creator project (.pro) to CMake. I usually create .pro for developing but then manually convert it to CMake when publishing the code. 
if your code only works in PGI or embarcadero you have bigger problems than running the sanitizers
Define a mission for the tool first. What do you want to do with it, and how do you want to deal with its findings? Project managers tend to think "cool, now we have this tool. Turn on all warnings, force devs to get down to zero warnings, and our code will magically get good". My experience is that on a moderately tested codebase, such tools find 99% false positives (unless you count simple syntactic issues like a "the body of an if must be a braced block" rule). I have been using Klocwork, QA-C++, cppcheck, and previously cl /analyze. Real problems those tools found: * cppcheck and cl /analyze know some APIs and will tell you about lost resources (e.g. forgot to close a handle) * klocwork finds missing initializers in constructors, which makes me wonder why this is not a standard compiler warning * I think both cppcheck and klocwork find unintentional fallthrough in switch/case; again, I wonder why this is not a standard warning False positives these tools recently annoyed me with: * klocwork claims to be able to prove that the result of `std::string::c_str` is not null-terminated * klocwork claims I'm leaking resources if I have a function called `open` * klocwork often tells me to remove error checks or null-pointer checks because it thinks it can prove they never happen and I have written dead code * klocwork claims `1&lt;&lt;8` overflows (because that's what MISRA-C++'s special type system says) * cppcheck warns if I access a `std::unique_ptr` I have moved away from (which is well-defined for unique_ptr) * cppcheck wants me to pass everything by reference, which I often refuse to do to avoid aliasing problems TL;DR: I think using the free / available tools (cppcheck, cl /analyze, warnings, valgrind) will make a good jump forward if you were using none before. I wouldn't miss anything if I had none of the commercial tools. In any case, be aware that it is pretty normal to ignore a tool finding. When evaluating, the tool's handling of ignored findings should be an important point (i.e. does it pop up again if the code moves a line down?).
I'm not sure exceptions are necessarily better than `try!`- they're probably better if you want to unwind the stack all the way to, say, the event loop, but probably worse for anything that's only going to return once or twice and/or is less rare than allocation failure. And *catching* exceptions is just plain bad, IMO. It makes exception safety much harder without much benefit. I'd much rather just stop their propagation without any ability to touch anything they left behind. (Again, at something like an event loop or 
Every benchmark I've seen always showed no error handling the fastest, exceptions middle, and return codes the slowest. If you need to propagate your return codes you end up with very branchy code.
Microbenchmarking of the error handling techniques themselves is not comparable to benchmarking actual programs that use them, and misses the "not every function can fail or needs to branch" point.
But now we're back to the problems from the article linked by /u/whocouldwinaportal. `std::variant` gives you *either* the ability to `return`/`break`/`continue` across matching *or* exhaustiveness checking, but not both at once like a language feature could.
And in all these discussions no one ever shows any benchmarks showing return codes being faster than exceptions. If they try to, it's always the same code but with and without exceptions enabled, which as you say is not at all the same thing.
Look, all I'm getting at here is exceptions impose a cost at every call site (unless you opt out with `noexcept`), while error returns isolate their (yes, higher) cost to only the call sites that can error. It's nice to let the optimizer run freely on the part of your function that's already checked all its preconditions, without having to manage `noexcept` on its callees (which may e.g. be in libraries that don't throw but aren't annotated). If nothing else, it's a nice tradeoff to have available.
Yes, of course. You have some Rust code, yes? It’s really simple: go to a center of whatever code you might have, lowest level, count the number of times you just do ‘try!’ versus actually acting upon the error emanating from there. Because the code is, by and large, just a bunch of tries, with an occasional ‘real’ processing, isn’t it? Either that, or you’re purposefully ignoring errors :-)
My current Rust project is a scripting language compiler and interpreter. Every single use of `?` (new-ish operator replacement for `try!`) falls in one of these two cases: * in implementations of `fmt::Debug` (not the hot path at all) * propagating errors in the interpreted program across zero or one stack frames The second case is mainly useful for inlined helper functions, but also has some of this: registers[t].value = match a.data() { vm::Data::Real(a) =&gt; Ok(vm::Value::from(/* do the op */)), a =&gt; { let kind = ErrorKind::TypeUnary(op, a.ty()); Err(Error { symbol, instruction, kind }) } }?; In this case I could have written the second match arm with `return Err` instead, but went this way for stylistic reasons. --- In projects where I do more IO or other fallible operations, I appreciate `?`/`try!` because it makes it easier to tell where the errors might come from. For example, that way I can do things like move all those calls to the start of a function and do all the real processing after, and it's obvious that that's what's happening, so unfamiliar contributors and distracted code reviewers can maintain that property. If I ever get to the point where "the code is just a bunch of tries with an occasional 'real' processing," I feel like something's gone wrong, regardless of whether I'm using exceptions or `Result`. :)
As you can have library-level lambdas. But the problems are similar: cumbersome syntax (often relying on matrices), long compilations times and very hard to debug resulting generated boilerplate code (also, where are most likely numerous cases where something doesn't really work as expected), which is totally unnecessary for something very simple in concept.
Did you try 2017? We recently switched and for me it's a lot faster (also better intellisense) and the debugger is just great.
I don't think VSCode is bloated at all and with the right plugins (cpptools, cmake tools, .. ) it's really good. 
I've added it to the list of other known parsers. Its last release was in 2009, and it is a whole new language, and in many ways is not nearly as powerful as CLI11. But the manpage and html generation look useful and easy to add to CLI11...
There are many others on that list.
Well... what is an "error" for your parser? Invalid code from the input? That's a bit of a grey area, surely a parser expects invalid code as a matter of fact? But let's go with that... Having said that... you say that ypu handle errors where they happen. How? If i presume a common case where a scripting language interpreter stops everything at a parsing error, I see this code: somewhere deep in the AST processing, input is found to be bad, processing stops, meaning, you climb way up the stack. So code can *report* the error (which is not handling, isn't it?) at the place where it happened, but then, it will climb up the stack and stop (or, if you're interactive, wait for the user input and [enter]. So what I see is: upon an error, you do stop processing and climb up the stack. No?
&gt; In this day and age it costs exactly zero dollars to publish something. Zero. You can put it all over the internet, for free, instantly, no maintenance required. Absolutely not. Hosting, domain registration, maintenance, a website (for publishing news, announcements and download links)... Every one of these things costs money and may be expensive depending on how much visits you get.
Waouh if the distribution and pricing is so ridiculous that even Intel does not buy a copy, nevermind the smaller actors... Maybe publishing an ISO standard is not a so good idea after all. I mean tons of other languages are fine going through other (and open!) distributions channels. We all know about the last (or next) draft trick, but still...
&gt; By 'real' IPC, I simply mean: I call a function that tells the other process what to do. Because if you think about it, you want the same with shared memory. You don't want to write something to it, that's an implementation detail in a large picture. Either way you are dealing with data being transferred. What you are talking about is using a complex and non-portable RPC mechanism instead of wrapping a few lines of synchronization in something that is generic. Shared memory can be built upon in a lightweight and portable way, and no matter what you do you still have to transfer data. Calling another processes' functions doesn't get around that, I don't think it even makes it easier. &gt; Yes, I can e.g. take a lock, write, release a lock, set an event, and the other side can wait for the event, take a lock, read data, execute. But COM takes all that away, caller only needs to... well, execute. I usually compare and swap atomically, which is a few lines in a 'do while' loop. I don't know why events and execution even enter into it. 
Maybe, because the loop object doesn't keep them alive indefinetly? 
And how do you know, when you can delete a Node?
Oh, I had not seen that yet. I can already envision a `printf`-like function taking the format string as template parameter.
I don't dispute that, but compilers have a history of breaking code that was written under the assumption that UB "will work in practice". As I said, I wouldn't feel comfortable with it - that doesn't necessarily mean it doesn't work or you shouldn't do it. 
Having nodes with no connections is perfectly fine in a graph, so they would be deleted when the logically need to be deleted.
!remove
OP, A human moderator (u/blelbach) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7h31vo/im_really_hoping_to_get_your_input_on_online/dqnrin6/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
VS2017 is my current IDE, but it's still WPF, and very slow. It's surely better than VS2010, which was the worst of all, but light years away from VS2008, the last one before WPF.
You need more than a swap and compare as soon as you want more data than what fits into an address. You want events because otherwise you need polling. Execution comes right after. Change in data means that he who read the change will do something. To be honest, what you just wrote shows incompetence and the inability to think about things in a slightly more abstract manner.
Wait, you say no branching, which means the compiler removes a branch .. that means, he removes the error handling path or the normal path - and thus the checking for an error, the whole reason behind this. Your comment makes zero sense.
I've tried to compile some code, but got compilation error literally saying: &gt; "X does not have a desired interface" What do I do? How do I fix the problem? 
That's not even close to what I said.
Agreed, though union types are a better primitive than sum types. (`std::variant` is a sum type that pretends to be a union type, which is the worst of both worlds.)
&gt; You need more than a swap and compare as soon as you want more data than what fits into an address. Not really, since the swap and compare can be an address (or an index). Those indices can be create atomically. &gt; Execution comes right after. Change in data means that he who read the change will do something. Data that is shared by two processes is completely disconnected from those two processes' execution. &gt; To be honest, what you just wrote shows incompetence and the inability to think about things in a slightly more abstract manner. I'm sure to a mediocre programmer, dealing with things a simple and direct manner using the fundamental principles of what really needs to happen, seems like incompetence. 
Man, data is shared exactly so that something can be done with it in another process. I can't believe I am reading you here. Why *else* are you sharing it?!
&gt; I can't believe I am reading you here. I'm not surprised you are confused if you don't understand what I wrote. I said that data sharing and execution are disconnected, you said "Execution comes right after", which is somewhere between a design choice and nonsense. 
you said, he does not generate a branch. When please explain to me, how he cannot generate a branch and still check whether there is an error.
&gt; I am finding this conversation frustrating. Imagine what it would be if you had been working on this for two decades (or more) and people are making various sorts of assertions to you with no factual basis, except to complain that they are finding the conversion frustrating. &gt; Either my quotes from P0800R0 are contextually appropriate excerpts of an honest, informative assessment, or you should be telling me how either I've misunderstood the text or how the author has made an incorrect judgement. Your quotes do not provide factual basis for your assertion that I hi lighted earlier. &gt; Either my analogy to my direct observations of people's use of traits in Rust to solve the same problem as I see concepts being used for is accurate and fair, or you should be telling me why I have misunderstood the goals of C++'s concepts or otherwise been inaccurate in my assessment. You know "proof my analogy is fraud" and all that. I asked for measurable evidence. You didn't provide any.
The parser works more like an AOT compiler's- I parse the entire program and produce bytecode before interpreting it. When the parser encounters an error, it reports it first, adds an error node to the AST, and then attempts to recover and continue parsing. This means more errors can be reported, the parser can be used for editor support, etc. So no, I do not stop processing and I do not climb up the stack. --- My point is, there are a lot of (parts of) domains where error handling *does* occur immediately or only a very small number of stack frames up. When an error is actionable like that, which is not as rare as you claimed IMO, exceptions are a poor tool because they have such high overhead and obscure the control flow. This also isn't really determined solely on a per-error basis, because it depends on the use case as well. Which is why it would be nice for the stdlib containers to provide an optional error return-based allocation path for those instances where allocation failure *is* actionable.
Fair enough. Execution can come later, but that doesn't change the crux of the point: the reason you're putting data in shared memory is that something will pick it up.
Ok, but then the invalid input is not an error at all and the whole discussion is moot.
Very well explained, although there are some typos here and there. For me, it clarified what `void_t` means in the sense of "validity mappings".
How on earth is it not? Does everything that you can handle immediately become "not an error" to you??
Because it isn't something you would exceptions for in C++, which is the basis of the comparison, no?
I mean, *I* wouldn't use exceptions for almost anything in C++. The whole context of the discussion is which things someone would or wouldn't use exceptions for in C++.
Don't be fatuous -- _no one_ would use exceptions for errors meant to be handled a single frame up. Pretending you don't understand the discussion you're participating in doesn't strengthen your argument, nor does downvoting a bystander's observation/request for clarification. In fact, they do pretty much the opposite. ;-]
I'm not pretending anything, or downvoting for that matter...?
Or the fresh-out-of-the-oven http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4713.pdf
Still no structured bindings? It's one of my favorite C++17 feature but it's completely unusable in Clion, it breaks code completion in the entire scope
Here's a [simple demo](https://godbolt.org/g/CQZtNK). See that if `foo()` fails, we're done. We don't do any more branches for `bar`, `baz` or the two `op`s since we know we don't need to. Likewise, there's no branch or comparison between the two calls to `op` - because if we call the first, we know we have to call the second. 
No, I didn't. What I said was that you don't need to generate a branch for **each** call, because you can propagate the state throughout, avoiding all but the strictly necessary ones. I did not say you don't need **any** branches. See my comment [here](https://www.reddit.com/r/cpp/comments/7gua48/functional_exceptionless_errorhandling_with/dqo9knr/?st=japvmdt6&amp;sh=acf405d4) with demo. 
Any direct comparison to boost PO?
You're going to have to elaborate on what exactly you regard as the difference, and what is wrong with `variant`.
The article is really weak. Basically, he doesn't express any problem (and there are still some issues) that isn't solved by the `overloaded` class, which is a two liner in C++17. Yes, it should have been provided. It's not. If I had a nickel for every seemingly obvious thing missing in every language that I had to write not only my own 2 liner, but 20 liner for... The more interesting problems are: 1. When you have the same type twice in the variant 2. Wanting to early return out of a function if the variant holds a certain type. 3. More complicated recursive and such pattern matching. How important you regard each of these 3 depends what kind of code you write. 1/2 are warts to be sure but they are relatively small ones in my practical usage.
If you use `overloaded` and `visit`, then you indeed get a compiler error exactly the same. So /u/eteran, there is an equivalent.
Uhm, it's not that hard to judge. If the exception is not thrown, even successful branches have cost, and in particular tax the branch predictor which will always hurt you in the grand scheme of things in a real-life sized program. If the exception is thrown, it will be way slower than error'ing out via a branch.
The reason `get_if` came up in the first place is that it gives you the ability to do things like `return`/`break`/`continue` from within the match branches. The `visit` interface gives you exhaustiveness checking, but takes away that ability; vice versa for `get_if`.
Can anyone comment on the `expected` vs `outcome` proposals? It's pretty clear that both of these are going after exactly the same niche. I thought that the former had mostly died out and been replaced with the latter but I see from the date that the `expected` proposal is alive and well.
OTOH I have a file that successfully compiles with both MSVC and Clang that is one huge red squiggly line.
Dr. Memory is a pretty nice Valgrind-alike.
you should look at line 14, 23 and 29 of the output. There are the needed branches for bar(int) and baz(double) checking whether it is ok, or not.
For me, the compiler is a "he", as he is one in my mother tongue. Whatever it is in english, i dont relly care, anyone is going to understand me anyways.
Agreed, but the concern was about having that AND having non visit style syntax. Seems we can't have both.
&gt; the reason you're putting data in shared memory is that something will pick it up. Of course, but that isn't what you said at first and I didn't say anything that contradicts that. I said that the data and execution are disconnected.
Yes, I agree with that. Along with issues with storing two of the same type, it's probably one of the biggest issues with the C++ variant. That said, for very common use cases like ADT error handling, e.g. `outcome` defines a `TRY` macro that handles exiting for you. For other use cases you can do: auto x = visit(v, overload([] (int x) { cerr &lt;&lt; x &lt;&lt; " exit early"; return true; } [] (double x) { cerr &lt;&lt; x &lt;&lt; " no exit early"; return false; } if (x) return; I'm not saying this is a thing of beauty, just that it's not really a big deal. It's not stopping anyone from using ADT's where appropriate. Certainly it doesn't constitute a bullet proof case for making sum types first class.
[Here](http://voices.canonical.com/jussi.pakkanen/2013/08/20/zero-overhead-pimpl/) is an alternative approach for doing the same thing with a char array and placement new.
This is basically exactly the same concern that people have with `string_view`, btw. If you are not familiar, as the name implies its intended to be a view of a string, and gets implicitly constructed from both `std::string` and a c string. Before `string_view`, things could get a bit awkward: if you take c style strings, it can be less efficient, and annoying to call `c_str` everywhere. But if you take `const std::string&amp;`, then if the client has a c string, they have to do a heap allocation unnecessarily. It's really only intended to be used for function arguments, but obviously that's not enforced in any way. Meanwhile, it has reference-like semantics (it doesn't own its own data), but it doesn't have the reference temporary extension mechanism: std::string foo(); string_view x = foo(); // instantly dangling pointers in string_view `c_str()` is a function that returns a pointer to internal data, so it also has reference like semantics, and is subject to the same kind of issues. Unfortunately it seems like C++ is mostly stuck with this. For me the take away is that you should be very conservative with writing new reference-like types; write objects that own their own data and are well encapsulated and stick to a small number of well understood reference-like types (mostly references themselves of course which are slightly safer). And yes, I think that if you do have a member function that returns a reference to internal data (I'm not a fan of this anyway; even a const ref is bad for encapsulation, but it might be the best choice sometime), you should ref qualify as you are suggesting. Yes, some code that would be ok will not work, but in that situation the user just needs to write an extra line. It also works better when you are working with references to types, then you can do: struct MyData { std::array&lt;char, 42&gt; buffer; const std::array&lt;char, 42&gt;&amp; get() const &amp; { return buffer; } std::array&lt;char, 42&gt; get() &amp;&amp; { return buffer; } }; This is safe and performant and convenient. If you are noticing stuff like this right after learning about ref-qualifiers, that's really good stuff!
I guess that is a question of memory efficiency. Just to be clear, I'm not necessarily talking about std::shared_ptr, which is often much heavier than what you need, but shared ownership in general.
Ceylon and Crystal both have union types. You can think of union types as representing a tagged\*, disjoint union of *types*, so `int | float` represents either an integer or a float. A Rust style enum, enum Enum { Case1, Case2(i64, i64), Case3 { x: i64, y: i64 }, } can be thought of as the composition of the type declarations struct Case1; struct Case2(i64, i64); struct Case3 { x: i64, y: i64 }; and the union type type Enum = Case1 | Case2 | Case3; The power of a union type comes about through a mix of things: they are composable (you can pass a `Case2` to a function, or have a hierarchy of more specific enums), they are truly algebraic (eg. *[The signature of reduce() in Ceylon](https://ceylon-lang.org/blog/2013/12/23/reduce/)*), and in some more complex sense they "complete" the types ([`mlsub` made the rounds](https://news.ycombinator.com/item?id=13781467) because it "solves" a challenging problem, which was only made possible with the help of union types). Given union types are strictly more expressive than sum types, there's little reason not to prefer them. The one issue I can think of is that deciding on the tag can be less trivial, but that's far from a blocker. As to what makes `std::variant` a mixed breed, it discriminates internally like a sum type, in that `std::variant&lt;int, int&gt;` ≢ `std::variant&lt;int&gt;`, but you construct and match on it as if it was a union type, so a generic `std::variant&lt;T, U&gt;` is liable to break should `T` and `U` be equivalent. Neither union nor sum types share this issue. \* Ceylon is Java-based, so its unions use the dynamic type tag, whereas Crystal has value types and a union needs an explicit tag.
Why not `std::array&lt;char, 42&gt;&amp;&amp; get() &amp;&amp; { return std::move(buffer); }` and leave the decaying to the caller?
As a function author, you often don't know if the errors you report will be handled a single frame up, or way later.
I missed the `std::move` on the inside, whoops. In the case of `std::array` a move and a copy are equivalent so it won't matter, but e.g. with a vector it's a better example. The standard library can't usually build in slower behavior, so std::get returns an rvalue reference because in certain case it will be faster than returning by value. This really only happens when you are chaining function returns; in a typical situation where you would assign the result of `get` to a local or a function parameter they'll optimize to the same thing. On the other hand, return by rvalue reference can cause dangles very easily: MyData foo(); const auto&amp; x = foo().get(); `x` dangles iff you return an rvalue reference; if you return a value then it's safe. So while making the choice that is strictly slightly more optimal but less safe is probably right for the standard library, it's usually not the right choice for user code where you can evaluate the contet in which `get` is used directly.
It sounds nice in theory, but there's a really big issue. You can't redefine classes or functions. This is usually half the point of working interactively in jupyter with python. You might code some helper functions or toy classes, try to use them for something, then edit the cell in which they are defined and rerun it which redefines the function/class. Being a dynamic language this is doable and works quite well. In C++ you can't; without this the utility of such a workflow is hugely diminished.
That makes literally no sense. They didnt create the standard, and the draft is free. The only thing they're doing here is copying and pasting it to a file host and slapping a price tag on it. This is a completely different situation than an actual paid product, and it's a pretty impressive leap to suggest that means i download stuff illegally. Incredibly impressive, insulting, and disrespectful, i might add.
What manhours are involved in copying a pdf to google drive/their preferred host? This isnt a thing that takes manhours.
All of those only apply if you ignore the fact that you can publish anything on the internet anywhere for free instantly. You don't *need* a host if you use one of the dozens of free ones, you don't *need* a domain, or a website. You *want* those things. And even then, those things are incredibly cheap. a domain is like 10 dollars a year. You dont need $200 to afford that. Besides, those arent even relevant to what we're talking about. Those are general costs, not specific to publishing standard. I asked about the cost of that. They arent the standard committee, so they didn't make the standard, so afaik basically all they're doing is being sent a finished work and then charging a bunch of money to download it. There are no costs involved in that, it could just as well be put on google drive or something for free. Anyone could do that in under 5 minutes.
I'm not in a courtroom. If I say I saw a pub down the road, I shouldn't have to take photos before we can go get a drink. If I say I have observed inexperienced users using traits without undue difficulty, I shouldn't need to have documented every case before my opinion becomes valid. If you're curious about precise measures, I'd be happy to point you to specific places I think would give you good numbers. If you have good reason to expect my judgement was incorrect, or just want verification, I'd be glad to help you out. But to disingenuously suggest that the evidence I've observed isn't real before I've laboriously proven it to you or to question my reason to be speaking at all is downright rude, and if you don't start treating this like a two-way conversation I'm not interested in taking it any further.
&gt; Incredibly impressive, insulting, and disrespectful, i might add. Just like assuming ISO is a scam organisation because of your ignorance? Yeah.
There you go again, assuming and saying nonsense! I said it sounds like one, not that it was one. Idk about you, but a group of people taking a free work, changing a few words, and then selling it for $200 dollars, sounds like a scam to me. As is said higher up in this very thread, the only difference is minor editorial corrections. Nothing super important or special. Sure as hell seems overpriced to me, especially for a PDF. For the paper version, sure, you have to print those, and their probably arent enough people buying paper versions to justify printing a bunch early and lowering the cost, so i can understand a high cost for it. But the same price for a PDF, which is free to "make"?
which C++17 feature do you mean?
that's what I'm trying to do - a compile time SQLite (not SQL)
1) nothing about multithreading yet 2) yes. Call `sync_schema` and get your db created. Nothing happens if you already have one. Schema will be altered if db exists with a different schema 3) yes. Foreign keys and indexes are fully supported. Please check out this example https://github.com/fnc12/sqlite_orm/blob/master/examples/foreign_key.cpp and this https://github.com/fnc12/sqlite_orm/blob/master/examples/index.cpp Thanks for the opinion
`std::experimental::optional` has runtime bug in `has_value` function. This is the main reason I don't use it. But you can map it on your own as a nullable type to `sqlite_orm` if you wish - it's easy
&gt; typos what do you mean `make typos in plain queries`?
what do you expect to use instead of exceptions?
You had me at const bool twin_peaks_is_perfection = true;
I tried using that one but it said it didn't work with applications compiled with g++.
There has never been an `outcome` proposal, as far as I'm aware.
 &amp;nbsp; *There has never been* &amp;nbsp; *an outcome proposal as* &amp;nbsp; *far as I'm aware* &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;*^-sphere991* ----- ^^^^I ^^^^do ^^^^not ^^^^see ^^^^all ^^^^comments, ^^^^so ^^^^I ^^^^cannot ^^^^detect ^^^^all ^^^^haikus ^^^^| ^^^^[blacklistme](https://np.reddit.com/message/compose/?to=haiku-bot1&amp;subject=blacklistme&amp;message=blacklistme) ^^^^| ^^^^[info](https://github.com/frostyfan109/haiku-bot/blob/master/Info) 
XD
The real shame seems to be that noexcept isn't automatically inferred (I appreciate the general case is undeciadable but i'm sure modern compilers could do a good job).
How on earth it is? Just because it has a word "error" in it? A bad parse is obviously normal processing to you: it merely results in inserting a different kind of node in your parse tree (and some I/O, to inform your user, which can fail, but you're conveniently ignoring that error, don't you? Or perhaps Rust does a `panic` then, in which case, you do have exceptions?). Come to think of it, your other failure mode is OOM, which, in rust, ... terminates? Does a `panic`? The latter is exceptions, and the former is really a bug in Rust, the language, if you ask me... If you will believe me, we had a compiler at my old job. A compile error was not a compiler error, it was his day-to day job. The result of the compilation was a tuple(success flag, compiled code(if any)), and the side effect was sending syntax errors to some queue, for display (compiler was running async, it was in a GUI). I presumed that your interpreter is simpler than than that, my bad. So in the end, this discussion is a mess, isn't it? I wrongly guessed (initially, see mention of OOM and I/O) where your failure modes will be.
Yes, I was discussing from the standpoint of "IPC", which I took to be "one process tells the other what to do". I agree, it doesn't have to be an "immediate" action. But we diverged a lot from the initial discussion, where I claim that COM is better for IPC than shared memory. So if we continue with your idea that you just bump some index in a well-known place... where does that index point to? To some circular buffer of data items in shared memory? If yes, another advantage of COM is the so called "marshalling", which is an inherent part of IPC. You need to have code to read/write your data items, and you need to have the so-called POD types in them, and then elaborate a scheme with pointers and whatnot for collections. Alternatively, you can use your language/library serialization support - but with COM (or any other.. ahem... non-stone-age 😀 IPC), this is dealt with by the said IPC. With COM, this is done in a language-agnostic manner, and there is a decent support, in COM, for UDTs and collections, which makes for a lot of firepower.
I think he is referring to the new c++ core guidelines checker in vs2017 which is similar to that option but technically different. The standard code analyzer (which is what I think you are referring to) is great but you have to understand it works off of SAL annotations. SAL annotations are very well suited to C and C-like C++ but aren't super well suited to modern C++.
On the same topic, this conference from Zach Laine is good: https://www.youtube.com/watch?v=0I0FD3N5cgM
I use the one from VS2017, and as far as I know it does include the C++ guidelines rules with it.
&gt; In C++ you can't can't you ? IIRC cling has no problem with this
&gt; Given union types are strictly more expressive than sum types, there's little reason not to prefer them. Calling a function expecting a union type `Enum` with a `Case1`, how is this internally handled? I can only see either copying `Case1` into `Enum` or having an indirection from `Enum` pointing to `Case1`. Both might involve some performance issues. 
There should be an alignas specifier on the char array to give the internal class the correct alignment. In the example, alignof(PimplDemo) is 1 but alignof(priv) is possibly 8 (depending on architecture and the implementation of std::vector).
How does cheerp achieve "no overhead calling DOM/HTML5/WebGL", if webassembly has overhead calling javascript functions? Or does it mean that there's no additional overhead? 
Have you tried visual studio code with cquery? I switched from clion to it. And clion is free for me.
&gt;I'm not in a courtroom. Right; only in courtroom are verifiable evidence expected; that would never occur in technical discussions to establish facts. Right? &gt; If I say I have observed inexperienced users using traits without undue difficulty, I shouldn't need to have documented every case before my opinion becomes valid. Actually, for the record, here is the assertion I was asking verifiable evidence for &gt;&gt; when the bar is placed an order of magnitude higher than other languages &gt; If you're curious about precise measures, I'd be happy to point you to specific places I think would give you good numbers. You made an assertion that suggested you have the data, just provide them. That is all I have been asking. &gt; questioning my reason or right to be speaking at all. Nope. I didn't. Absolutely not. I just asked you to provide verifiable evidence for an assertion you made. I am perfectly OK with you saying it was just your opinion not fact. &gt;I am not comfortable with this way you are acting. Asking for verifiable evidence about an assertion presented for as a fact isn't acting. That should be expected in technical discussions. 
I am done here.
Assessed CLion for work and it was dead slow, completely useless with our code base, while Visual Studio manages well. :-(
Or a move, yes. But this is no worse than passing a `Case1` to a `std::variant&lt;Case1, ...&gt;`. There are cases where a union might need less work than a sum type, like passing a `union1` to a `union1 | union2`. Sum types will either need two layers of indirection or a manual (likely inefficient) remapping, whereas well-optimised union types could just make the tags disjoint most of the time.
Can someone explain to me why [having split containers for keys and values for a flat_map gives a performance benefit](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0429r3.pdf)?
 int main() { char n; while (cin &gt;&gt; n) cout &lt;&lt; n; } Your `cin &gt;&gt; n` doesn't change n when it detects the EOF, so it prints the last character twice. Looping until cin becomes false is the solution.
[`using namespace std;` is a bad practice](https://stackoverflow.com/q/1452721/2176813), never use it.
Could you please give the correct code? 
For a five line example it's fine. Obviously don't slam it in some common header.
Thanks a lot
Did you also just seriously post the same question both here and [on SO](https://stackoverflow.com/questions/47619531/the-last-character-is-printed-twice-while-reading-till-eof)?
 #include &lt;algorithm&gt; #include &lt;iostream&gt; #include &lt;iterator&gt; int main(int argc, char* argv[]) { std::copy(std::istream_iterator&lt;int&gt;{std::cin}, {}, std::ostream_iterator&lt;int&gt;{std::cout, " "}); } 
Dude tried getting the solution from stack overflow but I couldn't understand it. So I tried my hand on Reddit.
The point is OP likely doesn't know the difference. It makes more sense to just tell people not to do it. There's enough complexity and ambiguity when using C++; let's not add any more.
I was solving questions on codechef, it would be useless to write std:: in front of everyone cout.
No, you're doing SQL string parsing/formatting at compile time. I was suggesting something fundamentally different be supported by most relational databases.
You're welcome!
My naive guess would be improved cache locality. Most of the CPU time when working with a map is probably spent searching the keys for a single value. So it'd be more efficient if when a key was loaded into a CPU cache line, it brought along more keys rather than waste space with key/value pairs, since the values are less likely to be immediately used.
I'm just giving more context.
Been trying to solve this problem from morning and I am not able to read the input. That's why i posted. [question]:https://www.codechef.com/DEC17/problems/CPLAY
https://github.com/vgvassilev/cling/issues/125
Rumble, rumble, rumble, rust a language with no segfaults and fearless concurrent, rumble, rumble, rumble. Pattern matching is fine, but so is Expected. Some people cannot use exceptions for a variety of reasons, and it is good for them to have an alternative that is as robust as exceptions. Having said that, I have seen people that want pattern matching calling expected a monstrosity. This looks quite like mob mentality.
Now that's it's been solved, NEVER use "using namespace std;" as if you are using a different lib that may have a function with the same name, it may use the wrong one if the parameters can be implicitly casted.
I'll keep that in mind
Maybe I misunderstand something, but I thought a sum type and a tagged union were the same thing. Could you elaborate a bit more on what you're calling a sum type or maybe what the difference is?
At this point in my career I am starting to believe that the main issue with exceptions is that nobody can agree when they should be used. Not the performance aspect, or the code clarity aspect, just, which situations are exceptional. 
There is some truth in that. From a C++ perspective, and I think also from a good practices perspective, exceptions should not be used for validating input. The reason is that stack unwinding for expected situations will have a performance hit and, anyway, normal code should handle that. On the other side, I like this discussion, and I tend to agree mostly with /u/WalterBright opinion on the topic of how to use them: http://forum.dlang.org/thread/m8tkfm$ret$1@digitalmars.com
This article is describing the method for writing code using exceptions that [exceptionsafecode.com][1] calls "The hard way" or "the wrong way." Maybe optional/expected is still preferable, but it's not really worth comparing that to doing something the wrong way. It'd be more convincing to compare the option you're promoting against the right way of using the alternative. [1]: http://exceptionsafecode.com
Not wanting to blow one's own trumpet too loudly here, but the Outcome V2 tutorial covers all this subject matter and then some, except with out of the box solutions to the problems raised including many problems but yet discussed in any blog. https://ned14.github.io/outcome/tutorial/ Boost peer review is scheduled for 17th January after which I hope it enters Boost.
I think your basic premise is wrong. The fact the user is not aware of the failure modes is not a bug, it's a feature. It's a feature that allows you to write code that completely ignores the possibility of failure when it's not that code's responsibility to handle the error. It can just not care. Why do people keep trying to make it sound like this is a problem?
If each function/operator/member had a specifier which exception(s) it may throw, then the compiler would catch right away - if the said exception should've been handled, and/or re-thrown. For example checked exceptions in Java - http://www.geeksforgeeks.org/checked-vs-unchecked-exceptions-in-java/ and for true programming errors, you can leave it the old way ("unchecked" exceptions) - runtime error, out of bounds, null ptr, etc. But the one you may be able to handle, report, or do something meaningful (e.g. check) then adopt it from java. 
Part of the problem is their name. The name implies they're supposed to be rare, but that's not really the case at all. &gt; Given that there is nothing particularly exceptional about a part of a program being unable to perform its given task, the word “exception” may be considered a bit misleading. Can an event that happens most times a program is run be considered exceptional? Can an event that is planned for and handled be considered an error? The answer to both questions is “yes.” “Exceptional” does not mean “almost never happens” or “disastrous.” Think of an exception as meaning “some part of the system couldn’t do what it was asked to do”. --Stroustrup Exceptions are an error handling mechanism, plain and simple. We're meant to use them anywhere we need to communicate an error.
As I understand the article the main complaint in it seems to be that there is no way to know what exceptions may be thrown through the type system. Well there is a feature like that in other languages such as the so-called checked exceptions of Java and there was the beginnings of the same in C++ with throw clauses, which have now been replaced with noexcept instead as I understand general C++11/14/17 guidance where you have to expect exceptions except if noexcept. What is the right and wrong way here seems to be to up in the air and as always purity looks enticing but in either style it breaks down eventually. I work with the following algorithm in my head for API design (for C++14/17 and feel free to tell me where I am wrong): Can this function or method fail due to unexpected conditions? If yes, are these conditions uncommon or common? If common and I can have a meaningful reaction to the error, then I use either a variant capable of returning the result or an error. Or I use an optional. Both result and error may be simple or complex objects. If uncommon and I can have a meaningful reaction to the error, then I choose between throwing an exception or returning as above and usually I lean towards the exception. No matter the frequency if I cannot handle the problem at the callsite I use exceptions always. Because I can usually do something meaningful at a higher level or allow it to kill my thread/program in some useful way (core dumps or minidumps in Windows can be very useful in such cases). Finally I consider the performance and memory considerations of all solution. Say if I am in a tight loop with a high frequency of calls, middle to low chance of errors and high performance is key I would always use exceptions because the check on the optional might actually matter in terms of microseconds and in case of a failure I usually then want to leave the loop anyway. So for me sum types are a tool like exceptions are really. Maybe exceptions could use more type system support to allow objects and functions to declare that they can throw something, but it has been discussed many times before and there is definitely not perfect consensus on what is the way. Maybe we could also really use Sum types and pattern matching in the language but it comes up so much these days that I think the committee is well aware. And I seem to remember some proposals on pattern matching at least being mention so maybe something could move forward.
True, but it is quite possible to introduce a policy within a team and then stick to it. For instance, at a previous workplace we had a policy that an exception that gets thrown indicates a bug - either in the code or in the infrastructure. The QA people would look in the logs for exceptions and file bugs if they found any.
One nice thing about exceptions is that if you don't catch them you have a backtrace basically for free. By contrast, if you're returning a sum your error type needs to reify enough of the surrounding context to allow debugging. So any error caused by a defect in the software itself should be handled by an exception so the programmer can easily get at where the bug is.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Why would any human look at this, and not automate it right away? Even coalesce, combine similar ones, then even "blame" looking at the history of their submission back to whoever introduced them?
I like the idea, but first time user of this API the names "and_this" and "map" mean some other things to me, It didn't click with me right away. Surely after some use it would. (There is Map Reduce, there is std::map, there is lisp's map, also some future/promise implementations of .then() which I thought of and_this())
`std::variant` is not a sum type. E.g. you can't put the same type twice in it while real sum types don't have such issue.
I think his point was that there’s no good way to figure out what errors CAN occur. You can write your error handling code elsewhere, but you still need to know what to handle.
Been using ST and PlatformIO for all my embedded projects lately and it’s really comfortable. 
Because if I'm writing code that uses your library in a customer facing application I need to either be confident that your code will not fail or be able to handle the failure appropriately, which usually involves telling the customer what went wrong (or fixing it myself in the code), both of which involve knowing how your code might fail. 
For all I know it may have been automated, but that's really not the point of my post :)
&gt; What do these signatures tell us about potential failures or error cases? Nothing. With this design, the user is not aware that these functions might fail/throw an exception They're not marked noexcept, so yes, the signature tells you whether these functions might fail/throw an exception. &gt; Should (0) be wrapped in a try...catch block? No. Not because the expression can't throw, but because there's nothing to do here to handle the error. Just let it propagate. &gt; Can I safely invoke send(cropped) on (2) without checking if an exception has been thrown? Yes. Because if an exception is thrown, then send(cropped) will never execute. Not trying to be mean, but... this part genuinely makes me wonder if you know how exceptions work.
I don't know whether std::variant is a sum type or not, but &gt; you can't put the same type twice in it That's wrong: https://wandbox.org/permlink/YrJFNoyQNUwbCFx6
Sure. But that's what documentation is for, plus a more central place to actually do the handling. When I write code outside of that central handling, I usually just want to ignore the errors completely. You can always have a higher level catch all and yell at the vendor for misdocumenting things. Expected *is* useful. I am just completely disagreeing with the premise that it should *replace* exceptions.
Ah, yeah, sorry for not being clear. "[Tagged union](https://en.wikipedia.org/wiki/Tagged_union)" means sum type, because a union type where each option is disjointly tagged is a sum type. A union type can also (optionally) have tags, and they are also a disjoint union of some principal types, but you tag the types rather than the explicitly enumerated possibilities. To [quote myself](https://www.reddit.com/r/fsharp/comments/51u0zn/managing_complexity_or_why_do_you_code_in_f/d7i3uxd/), &gt; Ever wondered why they're called "sum" or "product" types when they have don't obviously correlate with traditional addition or summation? &gt; &gt; Type theorists normally consider a type to be a set of permissible values (`T: U ⇔ T ∈ U`). A product type is the product of the two sets, a sum type is the sum of two sets and thus a union type, unsurprisingly, should be union of two sets. This has existed in the literature for ages, and [you can even do crazy stuff like differentiate](https://codewords.recurse.com/issues/three/algebra-and-calculus-of-algebraic-data-types). &gt; &gt; It's worth noting that though Ceylon takes unions very seriously, eg. `X|X == X`, `(X|Y)|(Y|Z) == X|Y|Z`, C's union types do not collapse because the type itself is nominal, even though the values of each branch aren't. This holds even when used "anonymously", since `union { int i } != union { int j }`. Note that it looks like the value is the nominal part, but that's misleading syntax; the value is what's stored, which is still just an `int`. &gt; &gt; So although I can't say when "union type" was first used for Ceylon-style unions, the meaning of the name was pretty much set in stone once "sum type" and "product type" were. (NB: It might not always be valid to call a type a set, though the difference doesn't matter here.) A `T | U` doesn't necessarily have a tag for `T` and a tag for `U`, because if `T` ≡ `U` then `T | U` is just `T`. If `T` is `X | Y` and `U` is `Y | Z`, then `T | U` is `X | Y | Z`, which is the same type as `T | Z` or `U | Y | X`. 
&gt; They're not marked noexcept, so yes, the signature tells you these functions might fail/throw an exception. This doesn't help much in practice. Every function that allocated memory with `new` cannot be marked `noexcept`. Does that mean that every usage of those functions should be wrapped around a `try...catch` block? If a function is not marked `noexcept`, what exceptions can it throw?Should I handle them as much as possible as they are "basic error handling", or should I let some higher-level function deal with it (i.e. they actually are exceptional cases, like `std::bad_alloc`)? With ADTs you know that something can go wrong and exactly how, and you cannot "forget" to handle the failure cases. --- &gt; Not because the expression can't throw, but because there's nothing to do here to handle the error. Just let it propagate. That might be completely true. Similarly, the person implementing `just_crop` might have forgotten to catch the exception and provide some default behavior *(e.g. do not crop)*. There's no way to tell, because error handling is not explicit. --- &gt; Because if an exception is thrown, then send(cropped) will never execute. Not trying to be mean, but... this part genuinely makes me wonder if you know how exceptions work. I do know how exceptions work - this is unfortunately poor phrasing on my part. I wanted to express: *"Should I even bother writing `send(cropped)` without a `try...catch` nearby? Does it make sense to propagate the exception to a higher level?"* --- &gt; Basic error handling is exactly what exceptions are meant for. Using them for basic error handling can work, but it has drawbacks as I have shown in the article. I find ADTs easier to reason about and to read *(e.g. for code reviewers)* than exceptions.
Author of the reddit comment that TFA refutes here... I see already that the good people here help me already, which is good 😀. First off, the article starts with what I believe is an **exceedingly** naive view of whether mentioned functions can fail ("it's not visible in the function signature"). Nowadays C++ offers `noexcept` for that. But IMNSHO much more importantly, even before `noexcept`, the good way of thinking about exceptions in C++ was:: **everything throws**, except a **very** small set of well-known things: primitive type assignments, C API calls, non-throwing swap and a couple of purpose-made functions with a no-fail exception-safety guarantee (e.g. smart pointer assignments, last-ditch logging). From that, it is really easy to design every single function, locally, using an analysis based on exception-safety guarantees as explained by Dave A. Otherwise... One aspect that I didn't see mentioned here yet, is: the proposed solution gives a yes/no answer to the "success?" question. *U wot m8?* That is useless in real life. What real programs really need is a rich description of the error, that can be * reported clearly to the user; "function blah failed" is not a report worth mentioning; it must say how and why, for what values of relevant inputs etc. * selected among a multitude of failure modes to deal with it programmatically; for example, I am putting an item in a DB and it's already there; I need to weed out network, resource shortage, other DB errors and act on that one small item (well, it's not small to me). I see that u/ned14 chimed in with the stuff he's usually pushing. That's leaps and bounds better to provide decent error reporting than what TFA gave (but still not better than exceptions, hi ned14! 😁). tl;dr: quite unimpressed by the refutation.
Author of the article here. --- &gt; First off, the article starts with what I believe is an exceedingly naive view of whether mentioned functions can fail ("it's not visible in the function signature"). [...] As I said in a comment below, [this doesn't help in practice](https://www.reddit.com/r/cpp/comments/7ha64y/why_choose_sum_types_over_exceptions/dqpjvh3/). If you see a function that is not marked `noexcept`, all you know is that it can throw an exception. You do not know which one, you do not know if it should be handled as soon as possible *(i.e. it's a "basic error case", unexceptional)* or if you should just let it propagate *(i.e. it's an exceptional case that can't be really handled at the call site)*. --- &gt; One aspect that I didn't see mentioned here yet, is: the proposed solution gives a yes/no answer to the "success?" question. U wot m8? That is useless in real life. [...] I'll begin by saying that `std::optional` for error handling is not useless in real life. Sometimes operations have a single very obvious failure state. Sometimes `std::optional` is good starting point before refining the return type to something more fine-grained. Regardless, my article used `std::optional` as an example, and kept mentioning *sum types* and *ADTs*. I even mentioned `std::variant` in the beginning. It is obvious that `std::optional` is not always the right tool for the job - `std::variant`, `std::expected`, and `outcome` are valid alternatives. You knew that my "proposed solution" was an example to demonstrate some key differences between *exception handling* and *ADTs* for basic error handling - I never claimed that `std::optional` was the be–all and end–all of error handling. U wot m8? 
The backtrace is indeed helpful in exceptional cases. What I am arguing for in the article is the following: if you used ADTs instead of exceptions for *basic error handling*, you wouldn't have a backtrace in the first place because the compiler would prevent you from forgetting to handle an error.
I really like Jon Kalb's work, but I have to mention that those slides/talks were created with C++11 in mind. We didn't have *generic lambdas*, `std::optional`, `std::variant`, and many other features that make working with ADT-based error handling easier. Working with ADTs is way better in C++17 compared to C++11.
I suggest using vim + plugins. I do it myself and mostly it is cool. The greatest challange for me is debugging using gdb, but there are also gdb wrappers that simplify it. With plugins vim can be as powerful as any IDE without 1GB memory footprint ;)
*(emphasis mine)* &gt; What I'm pretty sure is happening is those **programs use error codes for error reporting, and then don't check the error codes**. This is common practice for C code. I'm a little surprised that with Windows' long history, it still has problems detecting when it runs out of disk space. This is exactly what ADTs prevent. You cannot access the result value unless you **explicitly** check that it's in a good state. ADTs are not the same thing as C-like error return codes! --- &gt; However, if exceptions are thrown for errors instead, the programmer has to deliberately add code if he wishes to ignore the error. This is not true, at least not for C++. You need to explicitly provide a `try...catch` block if you want to handle exception, otherwise it will propagate to god knows where. If it was a "regular error case" and not an exceptional situation, you probably want the `try...catch` in the call site. If you forget it, you're going to have a bad time...
&gt; The fact the user is not aware of the failure modes is not a bug, it's a feature. It's a feature that allows you to write code that completely ignores the possibility of failure when it's not that code's responsibility to handle the error. It can just not care. I agree with you when we're talking about **exceptional** failure modes, but I completely disagree when referring to basic error handling that the client can reasonably react to. Sure, if my function `foo` allocates some memory, I do not want to force clients to deal with some ADT that can represent that exceptional condition. An exception is the right choice here. On the other hand, if my function `bar` can fail because it reaches out to a service on the network, I do want to represent that as part of the type system so that clients can react to it accordingly. Makes sense?
The article doesn't even mention constructors or RAII.
&gt; However, if exceptions are thrown for errors instead, the programmer has to deliberately add code if he wishes to ignore the error. I think the point is that unhandled exceptions usually lead to crashes, so you have to explicitly do something to make your program keep running after the exception happened
Author of the article here. Not sure why RAII should be mentioned in this article - can you elaborate? Regarding constructors, I assume that you meant *"How can I deal with constructors that might fail without exceptions?"* This has been covered in the past, but the idea is that your constructor should not throw, and that the logic which might fail should be moved to a separate helper function. Using exceptions: struct foo { foo(const path&amp; p) { this-&gt;something = read_file(p); // might throw } }; Without exceptions: struct foo { foo(const contents&amp; p) { this-&gt;something = contents; // cannot throw } }; std::optional&lt;foo&gt; create_foo_from_file(const path&amp; p) { try { auto contents = read_file(p); return foo{contents}; } catch(...) { return nullopt; } } In a real life scenario you might want something more informative than `std::optional`.
I see the point now, thanks. I cannot help but think that a state where *"your program keep running after the exception happened"* would be prevented from compiling when using ADTs, though.
Slight modification: Make the constructor private and make the function returning std::optional&lt;foo&gt; a static method.
&gt; your constructor should not throw You are inventing an entirely new language here. No C++ standard library, no existing C++ third-party libraries, no C++ idioms. Your new language may or may not be better than C++, but it is very very far from C++ by look and by feel. If I want a language that is not C++ I'll use Haskell or Rust, thank you. 
&gt; Does that mean that every usage of those functions should be wrapped around a try...catch block? Again, no. If there's nothing to do at your callsite to handle the error, then just let it propagate. &gt; If a function is not marked noexcept, what exceptions can it throw? Your alternative is to reduce all error information to a mere success/fail flag. That's not better. &gt; Should I handle them as soon as possible since they are "basic errors", or should I let some higher-level function deal with it (i.e. they actually are exceptional cases, like std::bad_alloc)? You should handle an exception in the exact same spot you would have handled an optional. Sometimes you just let an optional propagate, such as with `return result.and_then(...)`, but eventually, at appropriate level, you do handle the error. That appropriate level to handle an error is the same regardless if you're using exceptions or optionals. &gt; I wanted to express: "Should I even bother writing send(cropped) without a try...catch nearby? Does it make sense to propagate the exception to a higher level?" The answer to this is the same as my last point. The appropriate level to handle an error is the same regardless if you're using exceptions or optionals. If you would choose to let an optional propagate, then you would also choose to let an exception propagate.
One great thing about C++ is it's flexibility. You do don't do something just because everyone else does it, do you? Idioms change over time, practices that were considered good 5 years ago might be considered bad now. If concepts from Haskell and Rust bring benefits to C++, why shouldn't people use them? Your argument is meaningless.
&gt; Finally I consider the performance and memory considerations of all solution. Say if I am in a tight loop with a high frequency of calls, middle to low chance of errors and high performance is key I would always use exceptions because the check on the optional might actually matter in terms of microseconds and in case of a failure I usually then want to leave the loop anyway. Actually, in a tight loop where performance matters, I'd advise to try both. Zero-cost exceptions are not necessarily as zero-cost as they appear, and the mere presence of exceptions might prevent some optimizations. Notably, like destructors, I am unsure of their effects on tail-call optimization. If performance matters, don't assume, measure.
&gt; This doesn't help much in practice. Every function that allocates memory with `new` cannot be marked `noexcept`. It can, actually. The only effect of `noexcept` is to terminate the program should an exception attempt to pass through. 
No, I do stuff **exactly** because everyone else is doing the same thing. This is called standardisation and interoperability. I don't see any benefit in rebuilding/wrapping the entire standard library and all the third party libraries I depend upon to conform to the new paradigm. As I said, at this point I'm better off using a different language that supports the paradigm out of the box. If you demonstrate me a new standard library that is as good as the old one, then I'll reconsider this. Otherwise, nope.
Don't they have an academic licence too? I remember signing up for one.
&gt; I don't see any benefit in rebuilding/wrapping the entire standard library and all the third party libraries I depend upon to conform to the new paradigm. No one ever said you should do that. What I am suggesting is that new code that you write *might* benefit from this approach.
What's the point if anything that calls the standard library still can throw? Are you saying that we should wrap every "old paradigm" call in a try block?
So first, a key part is splitting exceptional cases from mere failure. Out of memory, for example, is a case so exceptional that failing to handle it resultijg in program immediately ceasing operation is reasonable. And honestly, that is almost the only exception the std library throws. Every other exception is exceedingly rare and corner cased. Second, C++ as a language exists as a way to take C and extend it into a new way of programming. This was both useful and successful. Doing the same to itself is both expected, and reasonable. Reflection and Metaclasses will be doing the same again in 6 years. Get used to it. 
Does it expect the service to be reachable? Because if it does, then an exception is generally *the* way to express this. Does it do validation of the service's availability *as part of its core behavior* (this part is important)? Exceptions are probably worse than expected for this case. But not because "it's not in the type system" - it's because *the failure state is a part of the codomain of the function*, unlike in the other case. 
IMO, it is much simpler to just crash on memory allocation error. Makes the rest of the program much more robust. Yes, there are places where you know that you might run out of memory, and you can can provide a function like try_allocate for that. However plain old new should just crash on OOM. And as /u/matthieum mentions, marking allocating functions with noexcept ensures that it crashes on OOM
So there are still exceptions, and then there's another mechanism for error reporting, alongside exceptions. That's fine with me. No significant change in the grand scheme of things.
Which is good advice. I still think that there needs to be room for "designing with performance in mind" which I think is not "Premature optimization" even if it is a mantra in our world.
I prefer VS as well :-)
I really don't see, how this blog posts demonstrates that one techique is better/more readable than the other: I find the version with exceptions more readable, because it is less to boilerplate and I also really don't understand, why you chose to put the result into the return value in one version, whereas you use an input/output parameter in the other. And of course the the function signature tells us if an operation might fail when using exceptions: That's what noexcept(true/false) is for. Also the question of where to put a try/catch block does usually not depend on whether or not a function could fail, but whether or not you can do something meaningful to recover from a failure - why should I put a try/catch block somewhere, if all I can do is bubble up the error further, which is what the exception would do anyway for me? Which brings be to my most important quarrel with this post: As seems to be common with many other posts about error handling, there is no actual error handling here. If you want to claim, that one mechanism for reporting errors is better than the other, then please include a realistic example for both cases, of how the actual handling code would look like and where you would place it then we can have a meaningful discussion about which version is more readable. I'm emphasising this, because most of the time, actual error handling I'm seeing happens on a pretty high level in a very generic manner: We display an error message, possibly try to save some Userdata and restart the module or terminate the program and this is exactly where exceptions shine. Of course there are lots of counterexamples and I certainly don't want to advocate the use of exceptions everywhere. But what I am saying is that you cannot make a general argument for or against an error reporting mechanism, because it heavily depends on the specific context of what error you want to report and how you want to handle that error.
Actually, I'm quite happy with the fact, that the specific reasons for why a function may fall remain an implementation detail the code between the throw and the catch doesn't have to care about.
Why are people so anxious about running out of memory? Does that ever happen? Why go to such lengths to defend against it?
Why did you offer to give specifics then..? What a pointless subthread.
In general, agreed, but not in the context of this conversation – it has already been stated "*I do not stop processing and I do not climb up the stack.*" That being the case, indeed _no one_ would use exceptions there, and the attempts at socratic irony are painfully transparent.
"The compiler can not help in this situation." Sure it can, it just won't. ;)
Well I'll have to check about that. It's been a while since I used it since what I'm doing now isn't as performance-sensitive and I don't need it so much.
The optional is a bool check. Even if the branch predictor fails it isn't going to be microseconds. If the cost of the book checks were really too much wouldn't inlining and a go-to work better?
My largest problem with this approach(beside FP buzzwords in articles) is that std::optional is not as informative as article claims. in find_cat(image) nullopt may be no cats in picture, or FindCats RPC failed. Nothing wrong with optional but there is only so much information bool can carry :) So problem is that you would need something like expected of optional or expected of vector or optional of vector. Here empty vector means nothing found... But I find it disgusting. Also since I see Vitorrio reads some of the comments: Even ideas that fail to get positive feedback are useful. You may be right and 90% of r/ cpp wrong, and even if you are wrong feedback is useful info. So I hope mixed reactions do not stop you from writing more.
&gt; I see that u/ned14 chimed in with the stuff he's usually pushing. That's leaps and bounds better to provide decent error reporting than what TFA gave (but still not better than exceptions, hi ned14! 😁). I have actually been listening. You can return custom payload with your disappointment, and have that auto-convert itself into any arbitrary exception throw if the programmer doesn't specially handle it: https://ned14.github.io/outcome/tutorial/payload/. And yes, stack backtraces can be captured too, there is a worked example in the tutorial. You can also intercept every time an Outcome gets translated, converted, copies, moved plus know when it traverses a namespace boundary. This allows for a decent amount of customisation.
`std::optional` was chosen as an example to show the key difference between exception-based and ADT-based error handling. You can carry additional information with `std::variant` or something like `expected` or `outcome`. --- &gt; So I hope mixed reactions do not stop you from writing more. No way that would happen. I really like healthy debate and discussing about controversial topics. Everyone's point of view, no matter how "wrong" they are, can be a source of inspiration/further research. I welcome feedback, even if negative. :) 
A single if practically doesn't cost anything. We had a scenario where approximately 99% of the time the if would be true and I was running this test let's say several million times a second. Now that is 1 million times almost nothing. This added up at least in that project. Instead a design was chosen the scope of a try {} catch {} section was wrapped around the loop, and the hot path changed to the assumption that no errors occur unless it is an exception. Then when one of these rare exceptions occur we escape the loop (with proper life cycle handling of stack allocated objects and lock) then we try to mitigate the error. Maybe we can reenter the loop or do something else (report an error, switch algorithms and so on). But our situation does involve a world where we have to make every effort to keep running even if hardware fails in the field. We try to keep running in the face of rough environments, bad physical systems, bad electrical supply and bad input data. Error mitigation is a major research subject for us.
Most of these points have been discussed in other comments already. Regardless... &gt; why you chose to put the result into the return value in one version, whereas you use an input/output parameter in the other I was replying to the comment made on Simon's article, which required that kind of interface. Why would it change anything anyway? --- &gt; And of course the the function signature tells us if an operation might fail when using exceptions: That's what noexcept(true/false) is for. This is not useful in practice for unexceptional error handling. You do not know **what** exceptions might be thrown, and if it makes more sense to catch them ASAP or let them propagate. Additionally, `noexcept` functions **can** throw - that will call `std::terminate`. --- &gt; why should I put a try/catch block somewhere, if all I can do is bubble up the error further That's not all you can do. Clients often can (and should) react to error cases immediately. --- &gt; then please include a realistic example for both cases This is a good suggestion - the goal of this article was covering the topic in general using Simon's example (and the comment from someone on reddit) as the key example. Here's a slightly more realistic example for now: https://github.com/SuperV1234/scelta/blob/master/example/error_handling.cpp --- &gt; We display an error message, possibly try to save some Userdata and restart the module or terminate the program and this is exactly where exceptions shine. Good, because these sound like unrecoverable errors. The point of the article is that ADTs are superior to exceptions for usual/common errors that the client should handle. --- &gt; I am saying is that you cannot make a general argument for or against an error reporting mechanism I am not. I am focusing on Simon's example and generalizing the idea to "unexceptional error handling". I am not suggesting to handle all possible failure cases with ADTs - I'm saying that ADTs are superior to exceptions for cases where the client can meaningfully recover from the errors.
&gt; If there's nothing to do at your callsite to handle the error, then just let it propagate. Sure. This depends on the nature of the error. Unexceptional errors can often be handled at the call site. --- &gt; Your alternative is to reduce all error information to a mere success/fail flag. That's not better. `std::optional` was chosen as an example to show the key difference between exception-based and ADT-based error handling. You can carry additional information with `std::variant` or something like `expected` or `outcome`. --- &gt; You should handle an exception in the exact same spot you would have handled an optional. Yes - the point is that I can forget to handle the exception or don't even know what kind of exception is going to be thrown. The ADT *(`optional`, in this case)*, prevents my program from compiling if I forget to handle the error and tells me what error can occur thanks to the type system. --- &gt; If you would choose to let an optional propagate, then you would also choose to let an exception propagate. Agreed. Exceptions are inferior when I do not want to propagate for the reasons I mentioned in the paragraph above. 
`map` is very commonly used - it's in Rust, Haskell, Java, and many more languages. Rust uses both `map` and `and_then`: https://doc.rust-lang.org/std/option/enum.Option.html
So scientific computing which doesn't do any low level optimizations of the kind I listed. Makes sense then, your performance profile is a bit weird since you aren't real time but have tight loops still.
As with exceptions, the main overhead probably comes from optimizations that might not fire anymore - I really wouldn't dara guessing which of the two strategies produces worse code. In my experience however, `std::variant` code often looks much worse than I would have expected - far from zero overhead, but this might get better with furture standard llibrary and compiler versions. `std::optional`should be much less of a problem for the optimizer. 
Because I was open to the possibility that Gabriel would change tact on how he's approaching this conversation. Since he has not, I see little reason to spend my time.
&gt; If I want a language that is not C++ I'll use Haskell or Rust, thank you. We wouldn’t ever have C++11 with this attitude. As yourself, I don’t like haskell/rust fanboys derailing every technical discussion either. Having said that, I do want C++ to plunder what these languages have to offer.
&gt; You can carry additional information with std::variant or something like expected or outcome. `variant&lt;Image, NoImage, ErrCode&gt;` Sure, but then how does your code look? How does your map, and_then code knows that NoImage and Image are ok values, ErrCode is the bad one? I think it looks horrible, but maybe I am wrong. note: I have used std::variant once for cached_value_ whose computation may fail(as in permanent fail) and in that case it was cool. it was variant&lt;Result, CalculationNotPerformedTag, CalculationFailedTag&gt;; 
We have a big codebase at work written mostly in modern C++, with a few caveats: no RTTI and no exceptions. The alternative is return types.
It does not. Well I am being dramatic. It does sometimes. It depends on the usage pattern like the other comment says. Also It could be that for some types of keys and pairs storing them together would waste space because alignment requirements. https://godbolt.org/g/d2VHXB I hope somebody smart can confirm this. 
You can do something like this. I will be using utilities from [my library **scelta**](https://github.com/SuperV1234/scelta). Firstly, you define your error types and variant: namespace readfile_status { struct success { std::string _contents; }; struct io_error { int _code; }; struct file_not_found { }; struct unknown_error { }; using outcome = std::variant&lt; success, io_error, file_not_found, unknown_error &gt;; } Then, you can pattern-match on the call site: readfile_status::outcome readfile(const path&amp;); void foo() { auto result = readfile(some_path); namespace rfs = readfile_status; scelta::match( [](success s) { do_something(s._contents); }, [](io_error e) { log_error(e._code); }, [](file_not_found e){ log_error("File not found"); }, [](unknown_error e) { log_error("Unknown error"); } )(std::move(result)); } Here are a few more examples: * https://github.com/SuperV1234/scelta/blob/master/example/error_handling.cpp * https://github.com/SuperV1234/scelta/blob/master/example/expression.cpp
Nice.
If I'm not missing something here, the exception based code would look almost identical. Now, how would that code look like if do_something can fail and/or if I want to propagate an error to the caller of foo?
Fair, I was assuming optional. Variant is a different can of worms.
&gt; happliy programatic divise Typos. &gt; #include &lt;cstdlib&gt; &gt; #include &lt;iostream&gt; &gt; #include &lt;math.h&gt; Including both the &lt;cmeow&gt; and the &lt;meow.h&gt; family isn't very consistent. Pick one. &gt; const double epsilon = 1e-6; // Maximum Allowed Error. You're paying for the cost of a non-static data member, when you just need a compile-time constant. &gt; g++ ./callbacks.cxx Not compiling with at least `-Wall -Wextra` is poor form. &gt; our callbacks will take the iteration index and to the intermediate guess Spurious "to". &gt; using TCallback = std::function&lt;void(const size_t, const double)&gt;; You shouldn't depict const value parameters in `std::function` signatures or function declarations, where they have no meaning and are immediately ignored. Only function definitions should have const value parameters. &gt; void add_callback(TCallback cb) { &gt; m_callbacks.push_back(cb); &gt; } Inefficient, because you're copying a `std::function` unnecessarily. Moving `cb`, or perfect forwarding with `emplace_back()`, would be more efficient. &gt; for (const auto &amp;cb : m_callbacks) { Good! Omitting the `&amp;` would have been a mistake. (Never let it be said that I'm all criticism and no praise...) &gt; At this point, we have added the structure necessary to allow the user to add callbacks; but we haven’t actually added any. This is an incorrect use of a semicolon, because these two parts don't form complete-but-related sentences. A comma would be correct. &gt; auto *cb_a = FunctionPointerCallback; &gt; p.add_callback(cb_a); This is doubly unnecessary. First, the `*` is unnecessary (auto will decay). Second, you can just say `add_callback(FunctionPointerCallback)`. &gt; Defining a pointer to a member function is simple using auto: I have found that people have significant difficulty understanding PMFs, and that they should be presented as a topic by themselves. Knowing how to manually declare them is useful, even if this is avoided later. &gt; Luckily, this can be dealt with painlessly by using std::bind `std::bind` is the opposite of painless and should be avoided in new code. As a Standard Library maintainer, I rarely tell people to avoid the Standard Library. This is one of those few times. &gt; &amp;cb_b_tmp, // First argument (*this) Note that there is a lifetime dependency on `cb_b_tmp` being created here, which is less than obvious in the code. &gt; Although using std::bind is an elegant and quite readable *laughter* &gt; In this post, we’ve discussed a motivating problem which callbacks address; constructed a toy example for experimenting with their implementation; defined a simple callback mechanism; and shown four types of callables compatible with this mechanism. Incorrect semicolons. &gt; return EXIT_SUCCESS; Note that `main()` doesn't need this, as a special case. &gt; I hope that this post provide a simple starting point Provides. Overall good post, although I would recommend spending some time talking about the efficiency implications of each approach, notably `std::function`'s inherently nonzero space and time costs.
Yes, this is nice compared to manual if else code, I like std::visit(I know your match is superior, but I forgot why...). My problem is now that your function call chaining does not work nicely. Like I said glue code knows that empty optional means do not call next function, it does not know what file_not_found in variant "means".
I had this happen again. Windows Update was hanging. I finally realized disk space was low - deleted some files, and WU worked again.
How many people check the return value of `printf`? Pretty much nobody, so ADTs won't prevent that problem.
&gt; I am looking for and appreciate feedback :) [clang is magic, clang is life :) ](https://godbolt.org/g/frukZ4) GCC fails to inline, so in general your paper is right. If you are bored try to explain the bizarre behavior of compiler in fwtfa vs fwtfb Both are functions with one unused std::function, but only one gets dead code generated. Note: this is not important feedback wrt your paper, and I would not bother to test it just to confirm it, but paper motivated me to finally try to see if I can give helping hand to compiler by creating function struct that knows if it owns complex std::function or just captureless function ptr(so the compiler could inline for captureless). I was all happy when I got it to inline because you know it could be applied to std::function... But then I saw it is because clang is so good at inlining, and my struct did not help. :) So another failed experiment, but you know failed experiments are still sources of data. :) 
&gt; Does that mean that every usage of those functions should be wrapped around a try...catch block? &gt; If a function is not marked noexcept, what exceptions can it throw? Should I handle them as soon as possible since they are "basic errors", or should I let some higher-level function deal with it (i.e. they actually are exceptional cases, like std::bad_alloc)? I think all these questions are premised on writing exception code "the wrong way," as mentioned in my [other post][1]. [1]: https://www.reddit.com/r/cpp/comments/7ha64y/why_choose_sum_types_over_exceptions/dqpfgba/
&gt; This has been covered in the past, but the idea is that your constructor should not throw, and that the logic which might fail should be moved to a separate helper function. &gt; I feel like we're moving backward in time. 
&gt; everything throws, except a very small set of well-known things: [...] C API calls [...] Actually even C API calls can throw, and I think writing your code to be exception safe even there is good. As a specific example: Linux's default model for POSIX thread cancelation points is implemented with exceptions. That means all the C API functions that POSIX specifies as thread cancellation points can and do throw exceptions.
I think you could implement sum types and pattern matching in a way, that would make error handling more terse, explicit and faster than error codes or exception, if it would be a language feature, not a library implementation. Take for example an imaginary `operator|`, that matches on a value if it is an error and executes its right hand side and a function `func`, that returns an error or an int. Then let's imagine the following cases: int i = func() | pass_error(); int i = func() | 0; int i = func() | func2() | pass_error(); int i = func(); The first case would either assign a value to i, or in the error case pass the error up the call stack. `pass_error` would probably need to be a macro function (code that gets expanded in the calling context), so it can return from the calling function, but you could also implement logging of errors that way, etc. The second case would assign i to 0 in the error case. The third case would first try `func`, then `func2`, then pass the error up, if all fails. The fourth case would fail to compile, as the error case is not handled. This is more verbose, than exceptions, but also makes the control flow more visible and you can't leave out error handling, like you can with error codes. Now, why could this be more efficient than straight checking of error codes? I believe, if this was a language feature, you could just pass multiple return adresses to a function returning a sum type. That way you would incur the penalty for the branch predictor in the place, where you already need to have a branch, because you want to throw an exception or return an error code. In a way you would jump up to the error handling in a very similiar way, that exceptions do, but in a more explicit way and probably more performant and easier to optimize, as the compiler knows, where sonething will jump to and can factor that in for possible optimizations. But maybe I'm to optimistic. Note that I said `pass_error` is a macro function and probably `operator|` too. If you assume a macro function is code, that gets expanded in the calling function, so a return is like a return statement in the calling function. Then you could probably implement `operator|` like the following: tenplate&lt;class T&gt; void $operator|(sum&lt;T, error&gt; e, expression$ expr) { switch(e) { case error err: inject -&gt; expr(err); break; case T t: inject -&gt; t; break } }; The compiler would see the pattern matching (here as a case statement, syntax can be debated) and jump to the code of the matching pattern. In this case this is code, that gets injected into the calling context and in the error case executes the right hand side argument `expr` and in the normal case just evaluates to the value, so it sets i to the return value and continues execution after that `pass_error` could then be: void $pass_error(error e){ inject -&gt; return e; } Which injects a return statement. You could probably just have written return directly, but you can also do different things in the error case, like reopening a file or whatever, this is just an example. In the end, I think this would make error handling easier, maybe as fast as exceptions and at least for me, much less annoying.
First of all, there is some argument about putting error info into the function signature. This was done in C++ (`throws`) and in Java (checked exceptions). It is/was a failure in both. I think there may be an argument that putting the error into half of the return value might somehow be better than in an exception spec, but I'm not sure if that argument has been made anywhere, or whether we had enough experience with ADTs (in C++ at least) to know the answer (or whether C++ is still missing some helper mechanisms (pattern matching, etc) to show that ADTs could be better). So error-info-in-signature is either a bad idea, or still up in the air. Next I see this idea that a criteria for when to use ADT vs exceptions is "exceptional cases" vs "handle by caller". I've never been a fan of "exceptions are for exceptional cases". Here's the thing: as a function author (and thus decider of how it will report errors), how am I suppose to know whether a caller will want to handle the error right away or pass it on? For example: `string read_file(string_view filename) // read file contents, return as a string` Is file-not-found an exceptional error, or expected? If the filename is coming from the User (ie a File Open dialog), shouldn't the file picker always give you a valid file? But if you are reloading a project (ie a video editor, and the file is "some_movie.avi", which is part of your project) you shouldn't be too surprised if the file has gone missing. Or if the calling code is `string config = read_file("hard-coded-config.txt")`. That is _probably_ a programmer error (or install error), and maybe shouldn't be handled by _any_ code (not immediate, not higher up). etc. As a function author, I don't think using "the caller _probably_ will handle this" is a valid way to choose an error strategy. Does anyone have any idea how often the immediate caller handles an error? I've have 25+ years programming experience. In a variety of scenarios (embedded, server-side, desktop, mobile,... User-facing apps, process-driven apps, ..., ...). I think you typically handle errors locally 5% of the time. Actually 0%, but let's just say 5%. If you are doing transaction-based programming (ie financial trades), go back to where the transaction started. If you are doing user-facing apps, go back to where the user initiate the action (ie clicked File-Open or Edit-Paste, etc). ie go back to where the transaction started. Take your "document" - or whatever data/state exists - and protect it well. Bundle up a change-of-state into an action. Apply that action or fail. And look, save that change-of-state action thingy - you can get Undo almost for free!
&gt; You can carry additional information with std::variant or something like expected or outcome. And when you do, then you'll encounter exactly the same "problem" that you have with exceptions. Let's say your unexpected type is an int or an enum, then instead of asking what exceptions can be thrown, you'll be asking which return codes to expect.
Here's the real problem - programmers don't want to deal with errors. Even worse: Programmers don't want to deal with any caller except the "current" caller. The "current caller" is either the imagined ideal caller when you are writing the function - which if often you and some other function you just wrote, or the current caller during the debugging session when you "just need to fix this stupid bug!". Programmers are fixated on the current state and their current state of mind. So ADTs put errors "in your face". Exceptions let you ignore errors - for a while. It is really a social and psychological problem - We need to think differently when programming. We need to think "wider" when writing a function. Do ADTs force that? Or do exceptions mitigate it and minimize that thing you don't want to think about? 
Sounds like you want [exception specifications](http://en.cppreference.com/w/cpp/language/except_spec). string readfile(string some_path) throw(io_error, file_not_found, unknown_error); There you have an enforceable list of all the possible exceptions that could be thrown. But this turned out to be a bad idea. That's why you'll see exception specifications marked deprecated.
Just `goto fail`. What could go wrong? /s The cost of exceptions is very hard to estimate because it can vary a lot depending on the system. The only thing you can safely assume is that if your exception is thrown only a couple times through the life of your program in the worst case and not in a performance-critical part, it's probably not worth changing your API to make it `noexcept` because of the bugs you might introduce.
Something you usually don't want unless you are Google but you might want to Kernel panic instead.
If you are concerned about the possibility of throwing an exception that is never caught you can use your static analyzer to look for uncaught exceptions. It is also worth noting that in many cases simply logging "Operation failed: unknown exception" is completely reasonable.
I'm not familiar with Jon Kalb's work so I don't know what "the right/easy way" version of the same code looks like. Can you provide an example? Without one your arguments sounds a bit like a "no true Scotsman".
`double` also uses the same size as `char`, so we're looking at some serious space wastage. You can optimize this by adjusting the size of the small string optimization so that you end up filling the whole 32 bytes.
It can happen in things like image processing if you request a massive block of memory. In general you know which allocations will be big though, and can assume that your small allocations will never fail.
I haven't seen Kalb's talks either, but one thing I've noticed from the article author, both in the article and in comments here, is that he thinks non-disastrous errors need to be handled absolutely immediately. If a function can throw, then he seems to think it needs to be wrapped in a try-catch. Convincing him to simply let the error propagate has been an uphill battle.
My experience is the same with regards to callers handling errors. The only cases I have seen were doing some bad logging that could have been done better at a higher level (but with more work due to not using exceptions.)
Sure, I wrote this post in response: https://iscinumpy.gitlab.io/post/comparing-cli11-and-boostpo/ (If the comparisons are not side-by-side, you might need to do a forced reload to get the new CSS file)
To add one small point to the first comment, a lot of instances of std::bind can be replaced with lambdas (either pure or using captures). I believe the general consensus is that they're a bit easier to read and to work with. I personally prefer them in my projects at least.
Yes but you can only detect that after a crash is found and properly reported. If it's a rare edge case, you likely won't find it until, e.g., you hit scale in production. The algebraic types: 1. Catch these cases at compile time 2. Make it obvious where you must handle edge cases. With exceptions, you have to read the code or docs to know 3. If you write some valid code, but then later someone else modifies the function you call to throw an exception, it's super easy to forget to update all of the calling code with try/catch. With the optional approach, all calling code will be required to be updated by the compiler. The only obvious downside is that it can be more cumbersome
There's nothing interesting about the code. It could look like the example given at the beginning. It's more instructive to answer the points in the article for exceptions. &gt; 1. Function signatures do not expose possible failure states. &gt; Thanks to ADTs, it is obvious when a function might or might not fail. Glancing at the signature is enough to understand whether or not a possible failure must be handled. With exceptions failure is assumed. We know the answer even before we glance at the signature, and we know that we must write exception safe code. &gt; 2. It is not immediately obvious whether or not an operation can fail and how. &gt; By using monadic operations such as map and and_then, the code becomes self-explanatory in regard to possible failures. Instead of guessing whether or not an exception will be thrown, possible failure states become explicit. With exceptions it's obvious because we assume failure is always possible and always write exception safe code. The explicit signal that a function can fail is that the function exists\*. And how doesn't matter because we're not handling individual error cases for individual function calls. &gt; 3. The compiler cannot help us prevent mistakes. &gt; The type system will prevent us from writing code that doesn't properly check failure states. We simply cannot write `send(cropped)` without checking the state of cropped beforehand - the program will fail to compile. With exceptions we're not handling the cases individually, so this is a mistake that doesn't need preventing because it can't happen. Having the compiler help you remember to do something isn't better than not needing to do it. E.g. the article says the compiler won't compile `send(cropped)` in the ADT design because the types won't match up, and so you'll be reminded that you need to write `cropped.map(send)` instead. With exceptions `send(cropped)` compiles and also works correctly (i.e. if an exception occurred in creating `cropped` then the exception is propagated and the code never tries to execute `send(cropped)` on an invalid `cropped` object). You don't need to be reminded of anything. \* with specific exceptions to that rule such as that `swap` and destruction don't fail.
Ah great post, very informative! I'm already quite integrated on Boost PO for my current project, but will definitely keep an eye on this for my next project, especially if I'm working somewhere where I have to ask for the boost dependency.
&gt; believe the general consensus is that they're a bit easier to read and to work with They also compile to much better code and much easier to debug. There were a lot of talks about deprecating `std::bind`, don't remember why it still not done.
Yes. This is a real shortcoming for cling and makes things quite frustrating. 
Stroustrup is clear in his book: a method should throw and exception if it cannot do the job it was supposed to do. Of course, it requires that you *think* about class and method invariants and detect when they can't be fulfilled. It's OK to return -1 from `string::find` to notify non-existence, but throw `range_error` from `operator[]` if the index is out of range. You could also have chosen that `operator[]` returns an `int` and returns -1 if you ask for a non-existent index, otherwise it returns the character (like `fgetc` in stdio). IOW, to use exceptions at least somewhat effectively, you MUST define class and method invariants. If you cannot fulfill the invariant(s) =&gt; throw. But people get stuck on questions "should I throw upon a failure to open a file?". You need larger context to answer that, i.e., why is the file being opened. Programs don't exist in a vacuum. If the file is expected to be there (e.g., config file without which the program cannot function), I'd say the answer is YES. Otherwise, it depends on the following question: Can the program meaningfully continue after an error has occurred? If no (e.g., config file missing), throw an exception. If yes, don't. The chapters on RAII and exceptions in TC++PL alone are worth buying the book.
I recall a few years ago really looking into C++ exceptions and refactoring some code I’ve written to use them… then discovering that unlike Java, there’s no “throws” declaration in the method / function signatures to indicate whether a throw would happen for a particular method, then doing more research online and essentially thinking that the design of C++ exceptions were fundamentally wrong / broken and just giving up on them. I guess considering you can turn off exceptions completely for compiled code was the real nail in the coffin for this… you can’t really guarantee a programmer-user would even want them let alone would expect your library to have them. Funny thing is, I started using `std::optional` in its place, without really realizing that I was “doing exceptions differently” like OP’s article suggests. Very happy with this. Never used `std::variant` or `std::expected`, I should probably check those out too.
About exception type not being visible in the signature... I don't know on what kind of software people work, but what I work on is **choke full** of diverse failure modes (quite a bit of I/O 😁). (And I posit, the higher one is up the stack, the number of failure modes is exponentially bigger.) This very quickly turns into a complete mess[1]. What you're asking for is akin to Java checked exceptions, and I firmly believe that it is a **bad** idea. It is not by accident that the old-style C++ exceptions spec never took any traction. It is also not an accident that Java (IMNSHO stupidly) splits all failure modes in "runtime" and the rest, and that . What I, the caller, need, in a *vast* majority if cases, is just an exception (and I let it propagate, by and large). For a *small* number of failure modes, I, the caller, need to know they exist and want to do something about them. It is *this, common* case that exceptions cater for. Cramming all failure modes into things like sum types is, IMNSHO, a bad idea at a scale. Just like checked exceptions resulted in pokemon exception handling. [1] Alternatively, one can turn to things like `error_code`, but then, they hide the actual failure modes behind codes and categories and achieve diddly squat. About sum types and ADTs... Yes, I did know that there is more to it, fair enough, my sarcasm was uncalled for. But you didn't go the full length, so... I kinda disagree that optional is *any* good as a return type for error situations. Well, maybe for "out of memory" 😁.When stuff fails, I need to know why did it fail, what parameters was it called with and occasionally some caller parameters. I have seen *way* too many `bool f(params)`, where the "failed" `return false` retval is a (sic!) a sum type for a handful of possible different failures, and the info about them is zilch. So perhaps I overreacted with that.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7hffmk/help_understanding_the_use_of_the_function_to/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I was always interested to learn about the problem with the addition of std::string::split function. Where is this one in the draft?
C functions can **never** throw exceptions because C, the language, does not know them - at all. As for POSIX thread cancellation... no. You misunderstood, this is not implemented with exceptions. How can it be when the C language knows nothing about them? How do you think can a C client interface with this functionality? Are you saying that C++ exceptions are called? If so, how can other languages who do not understand your C++ compiler's exception implementation use this part of POSIX? The way cancellation points work is pure C, no exceptions. There is a *stack* of thread cancellation actions (functions) that each thread who wants to play ball must register/unregister with POSIX, and POSIX calls these when a thread is cancelled. Yes, it looks like an exception and stack unwinding, but it's merely an exceptions look-alike 😁. .
According to [this](), the average single-bed apartment rent in Moutain View is $2,688. Take 12 of those off of $126,000 and you're left with $93,744. I can only imagine other living costs are high as well. It's still a good salary, but living expenses can cut deep.
C++17 added [[nodiscard]] which could be used there. Then you need to do some trickery to suppress a warning at least.
IMO you shouldn't use exceptions for preconditions or invarints, use assertions for that.
Every time I think I've become a "good" C++ programmer, I read something that makes me think I am an utter moron. E.g. TIL that you don't have to match parameter constness between function declarations and definitions...
&gt; C functions can never throw exceptions because C, the language, does not know them - at all. [Here's][1] some C++ code calling a C function and catching an exception thrown out of the C function. The object file for the C code is produced by compiling the C code as C with a C compiler. [1]: http://coliru.stacked-crooked.com/a/d4dd0aac5cad8c51 &gt; As for POSIX thread cancellation... no. You misunderstood, this is not implemented with exceptions. [Here's][2] what Ulrich Drepper has to say on the topic: "In NPTL thread cancellation is implemented using exceptions." (NPTL is the "Native POSIX Thread Library", the implementation of POSIX threads used on GNU/Linux. Ulrich Drepper is one of its implementers and a maintainer of glibc.) [2]: https://udrepper.livejournal.com/21541.html &gt; How can it be when the C language knows nothing about them? The C language doesn't need to know anything about them. How thread cancellation is implemented is an implementation detail that doesn't get exposed in the language. &gt; Are you saying that C++ exceptions are called? Yes. Or at least the same underlying exception mechanisms are used. You can `catch()` the exception in C++. &gt; If so, how can other languages who do not understand your C++ compiler's exception implementation use this part of POSIX? Via the POSIX specified interface, which hides the implementation details so other languages don't need to know how its done.
The name usually depends on the defining principle. If optional/expected are considered a container with one element, "map" makes sense. If you consider it a m monad, the other ones for (haskell's "bind" is arguably confusing for beginners). Iirc it had already been decided not consider std::optional a container of one.
&gt; Let's say your unexpected type is an int or an enum Let's not. How about we say they're a `std::error_code`, because those carry exactly the kind of information we're after, and are built to support user-defined error categories and values.
Those statistics are also often comparing apples to oranges. They take so many factors not into account... like how old / how much experience those devs have, how much the living costs are or what the average salary is (in other compareable companies is). If anything this tells me that google just hires really good devs and it has to pay them that much to keep them in the long run (Because other companies are willing to pay in that range as well).
You should probably do so anyway for documentation purposes though.
The $120k-140k band is basically unchanged 2011-2017. Given the hefty 12% annual living cost inflation in the Mountain View area, that's a hefty cut in pay in fact over time. Of course, that graph is for all of the US, plenty of roles heading to other large cities with less living cost inflation, but all in all that data really shows *a pay cut* in real terms, which is actually pretty interesting. Less exciting stuff happens at Google nowadays, I think it's actually more interesting around Microsoft recently and the cost of living in Seattle is far lower than California, plus the quality of life is higher is you have/want kids.
I'd argue with the exception of const value parameters. Useful in the definition, but not in the declaration.
Actually not, because food, commute, laundry, trips are mostly benefits/perks, so you end up really only paying for rent.
I'm all for having (real, core language supported) sum types in C++. Using them for error handling? Sure, no problem. Making this the only or the predominant error reporting mechanism? Rewriting my constructors so that they don't throw, which means there is a special "unconstructed" null state in every object? No thanks. At this point the language stops being C++. 
&gt; documentation is for what is this thing documentation that you mention? I do not believe I have ever seen such a wondrous thing before
I have an assert macro that throws `std::logic_error` for that and rely on exception hierarchy (derived from `std::runtime_error` -&gt; meant to be handled; derived from `std::logic_error` -&gt; log and exit the thread or rethrow or just let it crash the program like an assertion would). More flexible and robust than having an assert that can do just one thing (or not, if compiled out).
Agreed there.
OK...? Your statement is correct, but that doesn't mean that ADTs do not solve any problem. When you need to use the result value, ADTs will prevent you from using mistakes. As Jonathan suggested, `[[nodiscard]]` would be helpful here. The real solution would be a type system that supports *linear types*: * https://en.wikipedia.org/wiki/Substructural_type_system#Linear_type_systems * https://gankro.github.io/blah/linear-rust/ Since we don't have that, I think that exceptions are a reasonable choice here.
assertions are not always enabled, assertions kill the process. Both are bad if the program could otherwise recover from the error. A violated precondition may be the result of a corrupted file, for example just imagine the fun if someone could kill every browser by uploading a corrupted jpeg to reddit. 
Thanks for the feedback! While performance and easier inlining are one of the key benefits of `function_ref`, do not forget that it's also a valuable vocabulary type that represents a "non-nullable non-owning reference to a `Callable`" - even if compiler get smart enough to always inline `std::function`, I would still encourage the standardization and use of `function_ref` due to its semantic value.
Enjoy your ban.
!remove
OP, A human moderator (u/blelbach) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7hfq6m/google_c_engineers_are_so_rich_check_out_how_much/dqqr24k/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Taxes first, my friend :)
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7hg4q0/question_on_relearning_c/dqqr4yz/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I am a C++ newbie and I found this [Stackoverflow list](https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) useful about books.
&gt; Let's say your unexpected type is an int or an enum, then instead of asking what exceptions can be thrown, you'll be asking which return codes to expect. There's an easy solution to that - do not have `int` or an enum as your unexpected type. You can define a set of types that represent the errors and have a variant of those as your "failure" case. 
&gt; the exception based code would look almost identical It probably would **look** almost identical. The key differences are the ones I mentioned in my article: &gt; 1. Function signatures do not expose possible failure states. &gt; &gt; 2. It is not immediately obvious whether or not an operation can fail and how. &gt; &gt; 3. The compiler cannot help us prevent mistakes. --- &gt; if do_something can fail and/or if I want to propagate an error to the caller of foo? You would have to either chain `match(...)` calls, which is not nice, or use a better abstraction such as `expected&lt;Success, Failure&gt;`, where `Failure` itself can be a `variant`/`enum class`. Rust's `Result` is a nice starting point.
Security patches are always done to all affected versions. So you can get them with the perpetual licenses w/o upgrading to a newer version, which you don't have a license for.
There is a plugin, not an official JB one, but a 3rd party (Google) - https://plugins.jetbrains.com/plugin/9554-bazel. It can be unstable as it uses non-stable API, but at least you can check.
It doesn't allow implementing refactorings on the whole project out of the box. You still have to implement some caching mechanism. There are also architecture reasons (definitely our own solution is easier to fit in). But that doesn't mean we are closed to the clang-tooling idea. We are currently thinking on how to get goodies ob both solutions and incorporate for better user experience.
With this release false warnings should mostly be off in case of C++17 features. And the true support for C++17 is coming in 2018.x 
Avoiding leaks is relatively easy in C++: Use RAII, avoid reference cycles by reviewing code using shared_ptr etc very carefully. Use a leak checker like valgrind to run your tests. Avoid data races by not sharing mutable data between threads. No hidden "worker" threads in god classes. No global variables. Use the Clang thread, address and memory sanitizers to run your tests. You will still encounter plenty of use-after-free bugs. Use valgrind and address sanitizer to run your tests. You can get many of the benefits of Rust by having tests and running them with the sanitizers. Also, run your tests with the undefined behaviour sanitizer. You *will* find a lot of misuse of integer arithmetic.
In many cases it's better (faster) if the caller ensures callee's preconditions. There are some cases when checking preconditions is too expensive to do in the callee.
Resource leaks are actually easily possible and considered memory safe, any safe code could call `std::mem::forget` and destructors would never run, or you could create cycles for a less obvious leak. 
Perhaps give (`Yavide`)[https://github.com/JBakamovic/yavide] a try ... I've just released a major update :) It implements a mixture of `libclang`-based services and integrates them into the Vim editor (even though architecture is editor agnostic and is possible to integrate it with any other editor). Some of the features which have been implemented are: (`indexing`)[https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#indexing], (`find-all-references`)[https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#find-all-references], (`go-to-definition`)[https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#go-to-definition], (`go-to-include`)[https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#go-to-include], (`type-deduction`)[https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#type-deduction], (`fixits-and-diagnostics`)[https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#fixits-and-diagnostics], (`semantic-syntax-highlighting`)[https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#semantic-syntax-highlighting], (`clang-format-integration`)[https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#clang-format], (`clang-tidy-integration`)[https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#clang-tidy], (`json-compilation-databases`)[https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#json-compilation-database] Cheers, Adi
&gt; std::bind is the opposite of painless and should be avoided in new code. Why?
&gt; Assertions are not present in non-debug builds. And it's a feature. Widely known computer scientists disagree, but I don't have the time to find a reference right now. Not the least because 1) your in-house testing is unable to come up with all possible uses/inputs/scenarios that customers will (if you have enough of them), 2) because testing debug and non-debug builds is not testing the same program. &gt; If someone violates the precondition on the call site then it shouldn't be anything less than UB. Are you serious? With all people bitching against UB in C and C++ and wanting to define it in some way, you're actually advocating UB for programs where it can be cheaply reported? 
If you look at the cppreference page you see how unwieldy in can be. You often don't need to use it. http://en.cppreference.com/w/cpp/utility/functional/bind For example in the case of callbacks you probably don't care about placeholders.
&gt; Here's the thing: as a function author (and thus decider of how it will report errors), how am I suppose to know whether a caller will want to handle the error right away or pass it on? That's the problem with exceptions: the function author will change the control flow without having any information about the caller. For example let's say that I want to write: auto elem = cont.pop_back(); Should the the author of the container throw (it may be empty, or the copy constructor may fail) and change the control flow without having any information about the caller? Isn't better to return a std::optional and let the *caller* decide if and when to throw an exception?
&gt; Are you serious? With all people bitching against UB in C and C++ and wanting to define it in some way, you're actually advocating UB for programs where it can be cheaply reported? For places where it cannot
I have always used exceptions only for recoverable runtime errors. For programming errors (such as function precondition violation) I use asserts. I am not supposed to recover from programming error, that is a bug and it should be fixed. Continuing to run buggy program can cause more bugs, data corruption, etc. I would consider exception only for some kind of critical program that really needs to keep running to prevent even greater problems. But such cases are rare. My 2 main reason for not using using exceptions for preconditions are: * Checks are not removed from release builds, leading to worse optimization of code (example is checking if index is out of bounds or whether a key is present in a large map, or even worse, if a large array is sorted in O(N)). * Debugging. Debugging exceptions is a real issue, at least for me.
I'm really glad you wrote a follow up article! Good measuring is key to performance improvements (I guess we all know that). The article was a good reminder that if you are not measuring the right thing (e.g. too simplistic input data), you can easily come to the "wrong" conclusions. That was also one of the key takeaways from the CppCon talk “When a Microsecond Is an Eternity: High Performance Trading Systems in C++” https://www.youtube.com/watch?v=NH1Tta7purM. They did go trough great lengths so that their perfomance testing platform is as close to the production system as possible. I have one little critique - for me it would maybe have been nice to have a comparison between the results from in order evaluation vs. random order evaluation in some kind of overview (table) at the end of each paragraph.
I thought that was /u/STL's point
Ah ok, I'll have to wait then. Hope it makes it to one of the early access releases soon
Sure, but I wasn't replying to him.
Whoops I meant to reply to /u/1-05457. Though wondering why this thread exists. &gt;You should probably do so anyway for documentation purposes though. .. &gt;exception of const value parameters -- agreed. It only works for value parameters if I'm not mistaken.
What was a recursion joke?
The standard suggests limits on the order of 1000, but leaves it up to the implemtation.
No, assertions run only in development and testing. You shouldn't ship your releases with assertions on.
&gt; Can the program meaningfully continue after an error has occurred? If no (e.g., config file missing), throw an exception. If yes (e.g., create a default empty config), don't. The problem is when an exception is thrown in a library or in the platform which have no way to know if the client program can meaningfully continue or not. Particularly in Java it leads to the ugly pattern of defensive try-catch blocks when interfacing with third-party code just to make sure that a NullPointerException thrown from deep within their implementation does not bring down your entire application.
&gt; Widely known computer scientists disagree, but I don't have the time to find a reference right now. Clang and LLVM (and anything related) use assertions on debugging and ship without them.
&gt;Here's some C++ code calling a C function and catching an exception thrown out of the C function. The object file for the C code is produced by compiling the C code as C with a C compiler. Well now... If you do this, good luck to you. What you have done is: you **lied** to the compiler and your user that you have a C interface, and then you threw a C++ exception from there. Doing so squarely falls under the "just because you can, doesn't mean you should". Let me give you another example: say that your `bar()` is in fact C++ code that can throw, and that `foo` is this C code: void foo() { char* x = malloc(1); bar(); free(x); } See what you are doing? &gt;Here's what Ulrich Drepper has to say on the topic... Fair enough, I did not know that. However, does not matter. The thread cancellation has a purely a C interface to its users, and it has to, because otherwise it is only usable from C++. This is what I meant when I wrote the above.
That's impressive, good work! (Well, by the looks of it, didn't try).
&gt; A single if practically doesn't cost anything. That's not the problem. A function that throws an exception introduce a sequence point that the compiler and the processor cannot ignore. That can hurt performance because modern CPU execute instructions in parallel even in a single thread. I wrote a stupid example: https://godbolt.org/g/6u4YLt 
Best guess: people don't want to force a specific container type as the return type of such a function, and having an interface that takes an output iterator probably doesn't feel simple enough for such a function. Basically design issues.
&gt; You can get many of the benefits of Rust by having tests and running them with the sanitizers. But you need them - in Rust you don't. So there is less overhead if you do it good, but also less error prone, if you do it less responsible ;-)
Sometimes I feel like cv params in declarations would help me infer a little more about the definitions, but it's not a strong feeling.
&gt; When people skilled at performance analysis tell you to measure, they are not telling you to fire and forget. Measuring is not the method with which you gradient descent to your solution, it’s how you verify and expand your understanding. Only with a working model are you able to act with purpose. Thank you for this
It should be pointed out that calls on a std::function object will compile to worse code than if a lambda was passed via a template parameter (although this isn't always possible/desirable). It would nice if you mentioned that a lambda that captures anything cannot be used as a function pointer.
thanks for clarification. out of curiosity, would caching mechanism make sense to implement in clang server?
This +100. Rust uses [must_use] for its Result type, it’s not linear types but works good enough in practice.
&gt; Though wondering why this thread exists. Probably because I missed the word "value" in /u/STL's post and got very confused as to why he would advocate leaving the `const` out in the declaration.
Because there are some things that can be done with bind that cannot be done with lambdas.
Defining `&lt;=&gt;` by using `&lt;=&gt;`. ie they could define the result of `&lt;=&gt;` as a type that is then compared against 0 - using `&lt;=&gt;`.
But then the caller can't decide either, as it doesn't know about its caller, ad infinitum. So just get rid of exceptions then? Alternatively, just assume everything throws. What's the problem?
I know like and I said it is not a big thing, but I though to share about std function inlining, since it was above what I thought is currently possible with compilers. Either clang is super smart it has some hardcoded knowledge of what std::funciton is. I support your proposal, my actual concern with it is that it makes it easier to keep reference to dead objects, for example async callback can try to invoke statefull lambda whose state was destroyed. But ISO knows about this so if they are ok with this I am ok with this. :)
&gt;And you can argue about UBs how much you want, but they still are the most reasonable thing we can do. No, the most reasonable thing we can do is throw an exception. There is a whole set of predefined exceptions available (under logic_error and under runtime_error, depending on what happened) for precisely this purpose. The exception will then unwind the stack until it reaches a place where it _can_ be reasonably reported, so "most places" are actually covered by this mechanism. I'm not even sure how you would be able to make a precondition violation UB, given that we have no way to express preconditions in the language to begin with. We would have to add new syntax to express preconditions, and then add additional cases of UB where none existed before. And for what, exactly? I seriously don't get the hatred some people seem to have for exceptions. It's an incredibly convenient way to deal with error conditions, and in C++, in many cases it is the _only_ way to deal with them (constructors cannot fail in any other way, for example, and STL does not have error returns either). All these desperate attempts to come up with alternative mechanisms require masses of extra code and result in completely unreadable messes, and when asked to defend such mechanisms we don't hear more than "but I think the optimizer could perhaps, maybe, do a better job this way." - typically offered with much handwaving and very little in the way of evidence. do_something.and_then (do_something_else).and_then (something_else_again) I was taught in toddler school that when you tell a story, you shouldn't start each sentence with "and then". 
You can also use a school Id if ur in highschool
On which planet is there any point to checking the return value of printf? What are you going to do with that information? How will you know if it is right or wrong, and if it is wrong, how will you recover from that? 
The Boost peer review can be very effective for fundamental library designs. They're less common nowadays unfortunately, but I certainly came away awed.
So basically you throw sanity checking out of the window and let the program exhibit UB for the user.. yay, hundreds if not thousands of CVEs are due to exactly that. Missing/disabled sanity checking.
There is no sequence point (for one thing, the division and the throw are in different expressions entirely!). Try gcc, it has only one write to side_effect. It's a mystery to me why clang feels the need for a second write. The most straightforward way to write this code involves just one division and one write to side_effect, rather than two. It's also a mystery to me why you would believe the spagetti in the right-hand pane to be the better alternative. All those conditional jumps surely add up to lesser performance.
One thing that in a lot of cases is necessary is being able to unregister callbacks. This can be a bit tricky with std::function as it's hard to tell which callback to remove - I'm now returning opaque tokens from the add callback fn but I'm wondering if there's a better way.
Examples for learning? I've only ever seen `forget` used where an FFI assumes ownership of something.
Yet another article attempting to "write C in any language" (only the "C" in this case in monadic error handling). _Please stop!_ &gt; What do these signatures tell us about potential failures or error cases? **Nothing.** No, not nothing - they tell us those functions _may throw_. &gt; Can I safely invoke send(cropped) on (2) without checking if an exception has been thrown? &gt; In my opinion, these are the major pain points with an exception-based solution This pain-point seems to come from incomplete understanding of the exception handling mechanism. Here's what I mean: operation1(); // may throw operation2(); // may also throw In this code, if `operation1` throws an exception, operation2 _will not get called_. It will not get called if the try-catch block is wrapped around both operations, not if it is wrapped around the calling function (up the stack somewhere), not if it is missing completely. _You do not have to check anything_ to ensure that - the compiler does so for you. Here's another problem that your solution simply does not address (shown with a straw-man example): void process_file(file&amp; x) { your_errorcode_result y = get_file(x); prepare_environment(); // doesn't use file contents actual_processing(y.file); // uses file contents } If `y` contains an error prepare_environment will execute when it shouldn't. The correct code should have been: void process_file(file&amp; x) { your_errorcode_result y = get_file(x); if(y.success) prepare_environment(); // doesn't use file contents actual_processing(y.file); // uses file contents } but _there is nothing in the API of `prepare_environment()` that forces you to check `y`_. This is a non-issue with exceptions, and a silent failure with error codes (because the user forgot to add an explicit if in client code).
I think you could do that with ranges. I'm not sure though. But the advantage of adding this feature with ranges is that the functionality is not tied to strings, but any containers, and no container of strings are enforced, because views don't need to allocate or mutate a container.
Ah I see, fair enough.
The problem is that "everything throws" make things complicated, and complex code leads to bugs: https://youtu.be/QGcVXgEVMJg?t=335 
My best advice is watch talks from cppcon. Alot of great modern-oriented material there :) Also, you can follow the changes and Google each subject: https://github.com/AnthonyCalandra/modern-cpp-features/blob/master/README.md (This like includes code samples)
But that's more of the same: a big, overwhelming list of theoretical topics. I want something more organic, more practical. 
&gt; It's a mystery to me why clang feels the need for a second write. Because the logic of the code is different. In the first example if the first *dummy()* fails *side_effect* cannot be modified: that's the sequence point, the second dummy() call depend on the success of the first. In the second example the functions are independent: if the first *dummy()* fails *side_effect* can be modified by the second *dummy()*. That's why clang write *side_effect* only ones at the end. 
IMO that's kind of the point of Meyers' books. Start from an existing codebase, then work your way through the book and implement the tips/changes one by one.
Just pick a feature, implement it in your sandbox codebase (don't rush into production yet). Learn the details, then repeat
The big things with modern C++ are: * No manual memory management - use `unique_ptr` / `shared_ptr` and `make_unique` / `make_shared` instead of `new` * ranged for loops: `for (auto&amp; x : container)` so much cleaner than using iterators or manual iteration (e.g. indices) * lambdas: these make using std::algorithms _practical_. * `std::move` - passing containers (e.g. `std::vector`, `std::string`) need no longer be expensive If you research those you'll go a long way towards understanding modern C++.
&gt; No manual memory management - use unique_ptr / shared_ptr and make_unique / make_shared instead of new This is half truth. The new smart pointers are very nice, however, dont give up on new and delete! They still ahve their uses. I'd say, use new and delete as usual, and only when you actually find a need for smart pointers should you use them!
The unexpected type could also be, for example, a polymorphic base, `expected&lt;Result, Error_base_type*&gt;`, then a function could return any derived error type. But I'm quite sure you'll be unhappy with that as well. After all these conversations, I have a better idea what you're after. ADT were always a means to an end. The real goal you've been after is a statically checkable list of error conditions, and you believed ADT were the way to achieve that. But actually there's a way we could have a statically checkable list of exceptions (exception specifications), and there's lots of ways we could *not* have a statically checkable list of ADT errors, such as when the unexpected type is an int or an enum or a std::error_code or a polymorphic base.... basically anything except a variant.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7hhva2/modern_c_from_c03/dqr5k03/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The whole scoped thread thing that was removed from the standard library because unsound comes to mind. The point I was trying to make is that Rust doesn't have any sort of protection from resource leaks, since they're considered safe by design, and you should never trust `Drop` to always be called. 
When do you think there is no need for smart pointers? 
Just mentioning "container" and it already clicked with me. Thanks!
You are asking the wrong question. Smart pointers come with overhead, and are designed for specific purposes. Regular pointers is the core C++ feature that everyone should use by default, unless specific demands arise that smart pointers can fulfill.
We are talking about different things. I know about the costs of throw and that noexcept allows for different optimizations. I have seen the assembly outputs in both x86 and ARM to know this. I am not worried about it. In my case (and since code is often very different maybe only in my case) the sequence point at least in my measurements matters less than restructuring our code path to have less branches. The total effect at least has been to improve our performance in terms of managing to get code fast enough. You are entirely right about your points, what I am saying is that the structuring of your code to have fewer checks (especially as we have to do these in our situation) works out to a benefit that in our case was bigger than the costs of the exception. The inner loop also code looks simpler without the large number of error checks in our case and I think it would be the same in many other cases so I made my suggestion.
What overhead does a unique_pointer have?
It's better than an int, yes, but I don't think it's what the OP is after. [I think what he's after](https://www.reddit.com/r/cpp/comments/7ha64y/why_choose_sum_types_over_exceptions/dqr597b/) is a statically checkable list of possible error conditions -- effectively checked exceptions.
*Effective Modern C++* (like pretty much all Scott Meyers books) is exceptionally well-written and practical. It is the topic itself that is overwhelming, there is no way around that. My advice for you is to **be patient**. Because if you worked 20+ years with C++ (congrats!) then you will have some things to un-learn. Modern C++, to a great extent, aims to replace some old habits with less error-prone ones. This won't happen overnight. If you are a hands-on learner, it might be good approach to take a look at the C++11/14/17 wikipedia pages. They list the notable additions for each revision of the standar. Pick a feature that's interesting, research it and try it out in a fun project. Implement something in oldschool C++, then implement the same in modern C++. This is a long road (but a fun one!).
Potentially memory and always cpu cycles. But not only in regards of performance, it clutters the code for no reason at all. C++ pointers are still a thing. Smart pointers are a very good tool and complement to them. But completely disregarding actual real pointers is just silly.
IMO there's rarely a good reason for using `new` over make_unique - unique_ptr is zero-overhead, and using it also makes the chain of ownership very clear. Raw pointers still have their uses, but not as owners of memory - more as references to it or iterators into it.
How should unique_pointer consume memory or cpu cycles? 
What purpose does ctags serve in this setup? Isn’t it completely superseded by clang-based plugins? (I don’t know exactly what deoplete provides, never could get it set up. But if it’s anything like YouCompleteMe or [clang_complete](https://github.com/Rip-Rip/clang_complete), then ctags isn’t necessary.)
Ah, wait, now I see: because dummy gets inlined, you do indeed get two invocations, one for each call. Ok, great. But you have not demonstrated that there's anything wrong with two writes in a row. Certainly the second write is guaranteed to hit L1 cache. Moreover, the assembly of the `optional` version looks much, much worse. Even if we accept the inferiority of a two-write solution, I'd like to point out that this is not a language fundamental in any way. The optimizer could easily delay the write until it is ready to leave the function, by whatever method. Have a look at gcc, which does this (if the second dummy() throws, execution continues with a write to side_effect and fallthrough to the exception). Either clang doesn't realize this is an option, or it believes this is the faster solution. But anyway, performance... Shall we just give this a quick go, see how well it runs? I put both functions in a loop with a cool 100,000,000 iterations, and added both the result of `f` and the value of side_effect to a global counter, and printed that, just to make sure the optimizer was not removing the entire calculation. I did not cause any exceptions to be thrown, since your claim was that the mere presence of exceptions, _even if not taken_, is enough to cause trouble for the optimizer. Then I measured how long it took to run through both loops. For the version with exceptions, 100,000,000 iterations completes in 0.000000s. That seems a bit fishy, really - maybe the compiler has figured out a way to do this without actually iterating? If so, I will still accept that result: the claim was that the simple presence of an exception causes the optimizer to fail, and if it optimizes it out of existence than I'd say that claim is debunked. For the version with optional, 100,000,000 iterations completes in 8.83s. I'd like to point out that 8.83s is a lot longer than 0.00s, and that apparently the optimizer hasn't done nearly as well as with the first version. In fact it has done much, MUCH worse. Both versions return the same result, so we have no reason to suspect foul play in that sense. Oh, and I was using Visual Studio 2017 (15.4.5), obviously with the optimizer on. I then did a second test: what if I cause an exception to be thrown? Well, that's a bit more tricky to test - mostly because the version with optional is not actually behaving very well, returning int instead of optional&lt;int&gt;. Trying to call value() when there is no value... throws an exception. I'm not even sure what that proves anymore, but hey, let's run with it. 1,000,000 iterations this time, because exceptions are painfully, mindbogglingly slow: First version, with exceptions: 2.42s Second version, with optional: 2.46s Well, it doesn't really mean much - both versions have (literally) a million exceptions in their loop, and we are spending around ~2.4 usec for each exception. That's so slow I feel I should be posting at least 4 articles per day to reddit to convince people that exceptions are pointless, slow, difficult, complex, hard, slow, and that writing page after page after page of templates is a much better solution. But I'll try to contain myself. And so this once again demonstrates the value of actually measuring, instead of making vague claims based on feelings and a broken understanding of assembly listings... 
afaik unique_ptr doesnt have zero overhead. It also clutters code.
Right, it's a bit of an optimistic estimation, though maybe not as optimistic as I thought with the other expenses being benefits. 
https://youtu.be/2EWejmkKlxs?t=2161
It is absolutely zero overhead: https://godbolt.org/g/bB9FfL Literally identical assembly code generated for both new/delete and make_unique - the difference is you can't forget to delete a unique_ptr! The most common cause of memory leaks in C++ is people simply forgetting to delete allocations, and that entire class of bugs simply goes away with unique_ptrs. If you need to explicitly delete, simply null the pointer!
&gt; No, the most reasonable thing we can do is throw an exception. But you first have to determine that something is not right. And that may not be reasonable. &gt; I'm not even sure how you would be able to make a precondition violation UB, given that we have no way to express preconditions in the language to begin with. By specifing (or not) in the documentation. Just like you say what the function does, you also should say what the parameters should be. And the undefinedness follows from that. It's as simple as that. UBs are not needed to be enforced by language (compiler). They are just a way to communicate with other programmers, not the compiler. (Though compilers are getting better at understanding it and can optimize conde based on some UBs). &gt; I seriously don't get the hatred some people seem to have for exceptions. It's an incredibly convenient way to deal with error conditions, and in C++, in many cases it is the only way to deal with them (constructors cannot fail in any other way, for example, and STL does not have error returns either). You're right. But earlier points in the discussion still stand. Mainly that they should not be used to handle preconditions. &gt; I was taught in toddler school that when you tell a story, you shouldn't start each sentence with "and then". That I will leave without a comment. 
The Premature Optimization quote is oft-abused: 1. Big O matters, so even without optimizing, you should at least check it... to avoid premature pessimization, 2. The quote is generally truncated, the full quote includes a "in 97% of the cases" which is crucial, because... that leaves 3% of cases where squeezing all the performance is worth it.
That's with -O3, try -O0. Also, it's easy to see the overhead when you read up on it. Hiding shitty memory handling with unique_ptr's isnt a pretty solution imo. And it is by no means any excuse to completely never handle pointers manually either. I dont know if you are lazy or just ignorant.
- assertions slow things down. if you assert that a pointer is not null, then the optimizer cannot use the assumption that it is not null to make the code faster. undefined behavior is there for a reason. - from the user's point of view, exhitibing UB vs. calling std::abort and losing all their work, are both very very bad. you aren't getting any brownie points with the user for leaving the assertions in. - it makes sense to ship beta-quality software with assertions in, because the best testing is user testing. but it really doesn't make any sense to ship the final release with assertions on, unless performance really doesn't matter
That's not even remotely close to what assertions are used for in the **described** case. It's for the developer to check contracts (preconditions, postconditions etc), and not for the user.
&gt; Rust doesn't have any sort of protection from resource leaks, since they're considered safe by design I think that this corroborates what I've heard elsewhere -- which makes sense, since Rust's focus is safety. &gt; you should never trust `Drop` to always be called Why is this? I'm also curious.
&gt;I dont know if you are lazy or just ignorant. Personal attacks are not generally a good way to make your point. What you're proposing is the equivalent to "git gud" - avoid memory leaks etc by not being a bad programmer. But that's the thing, bugs will always happen - there isn't a person on earth who has written any program that hasn't written at least one bug. Unless you take advantage of the language to avoid the _possibility_ of the bug happening, it always will.
Yeah. His argument was as crazy as the one this Uncle Bob used to say that TDD "deprecated" static typing.
Just because C++ can be used pretty much like Java can be used, doesnt mean it should. 
Just because you can manually manage everything, doesn't mean you should...
I'd say your advice is entirely the wrong way round. Prefer to use unique_ptr (through make_unique) and only where there turns out to be a good reason drop to using new/delete. If you need shared references, default to using shared_ptr, only change if there is a good reason. Most modern standard libraries provide implementations of these where the overhead of unique_ptr is negligible in release builds, and the safety gained is well worth the price.
Returning a token is the best way to do it. A far more inferior way of doing it, if for whatever reason you really needed one, would be to pass in a pointer to a callback and the pointer would effectively serve as a token.
The cost in memory CPU cycles is normally negligible - generally equivalent to what you'd have to do by hand to safely manage memory. The reason is obvious - RAII helps eliminate a whole class of bugs. But I guess you know better than the entire C++ committee, acknowledged experts and most of the community - and you have the audacity to accuse other commenters of ignorance.
That's because "exceptional" means pretty much diddly squat and people should not think in these terms in the first place. I have no idea why this persist to this day. "Can't do what you ask me to? Exception!" is the default answer. What people refuse to realize is: in a **vast** majority of cases, code consists of "do x, use result to do y, use result to do z" etc. If one "do" fails, what follows is dead in the water. Similar situation when going into whatever calls there are on the call stack. Exceptions cater for that common case, simple as that. There are ecosystems where this question isn't asked at all (java, .net. python...) and nobody bats an eye.
Such as?
... which is why assertions cannot replace exceptions.
Well of course if you avoid optimisation there is a run time cost. But you'd be an idiot to release code without optimisation.
 Don't poke your eyes with a stick, it hurts? std::stack has `T top() const` and `void pop()` and **not** `T pop()` for exactly that reason. 
**In what situations** is that completely reasonable?!?!
Yes it does. 32bit processes tend to get run over by some software and not everything is in 64 bit, plus address space fragmentation is a bitch.
.. In this specific scenario, yes. But how can yo ube so sure that the compiler will catch and optimize every single possible usecase ? Answer: You cant. Also, my point still stands, there _is_ potential overhead, so I dont get why youre barking up this tree
No one said about replacing. &gt; u/foonathan &gt; &gt; you shouldn't use exceptions for preconditions or invarints, use assertions for that.
Try the company mode with rtags for better autocompletion.
&gt; It's for the developer to check contracts (preconditions, postconditions etc), and not for the user. So, users get the program with some bugs remaining, pre/postcondition checks are compiled out and.. voila, UB. Let the program do whatever it wants. Good? I don't think so.
VS Code is actually pretty decent. VS Code has nothing to do with Visual Studio that has a reputation for being extremely bloated. VS Code is less bloated than Atom, and thanks to JavaScript it's also cross-platform. I used it successfully for C++ on both Windows and Linux. There are plugins that make VS Code quite productive for C++ development. However, on Linux I eventually abandoned it for Emacs, because nothing can emulate Emacs better than Emacs itself.
dangling references are very easy to make, for example. "shared_ptr" is a good prevention.
&gt; exhitibing UB vs. calling std::abort and losing all their work, are both very very bad. If I throw an exception, I can catch it at top-level and save the user's work before exiting. Can't do that with assert. &gt; if your code is only secure with the assertions on, then it is not secure. Nonsense. Your "assertion" is my check for buffer size and throwing an exception if the operation wrt buffer size would access invalid memory. Secure code is built with layers upon layers of checks. &gt; assertions slow things down. In the rare cases it happened, the customers I worked with were happy that my code "crashed" and left their data intact instead of corrupting it by running slightly faster. Performance was never mentioned. So.. 
"Safety" in Rust refers to memory safety. Leaking memory isn't unsafe by that definition. The function `mem::forget`, which makes the destructor for an object not run, is therefore not marked `unsafe`. Another non-`unsafe` way to leak memory is reference cycles with `Rc`. This means you can never be sure the destructor will actually run. You have to safeguard against this sometimes when writing `unsafe` code, as you can't rely on the destructor to clean up any unsafe state.
afaik, in Rust you can't handle/survive lack of memory
Scott Meyers' Effective Modern C++ covers this (which arose out of his attempts to use bind() and my reviews of how that was wrong), but a quick summary of what I can immediately think of is: * bind() use a mini-language that must be learned in order to properly read and write bind expressions. This language is Not C++ and contains many traps for the unwary. In contrast, lambdas are written in normal C++, with a bit of extra syntax that doesn't fundamentally change how things work. Captures are the most novel thing, but: * With bind(), bound arguments are passed as lvalues (so the bind expression can be repeatedly called). This is invisible and surprises many people, who see rvalues being bound. Lambda captures make it clearer what's going on (admittedly not 100% clear, but this is C++, stuff always involves thinking). * Everyone in this day and age has to learn how lambdas work, because they're common. Having to additionally learn bind expressions is extra, unnecessary work. * It is unclear to programmers when things are called - bound arguments are evaluated at the point of binding, so if you do something like bind `system_clock::now()`, that behaves differently compared to calling it in a lambda body. * Nested bind expressions are really complicated for programmers to reason about. * bind is potentially less efficient because optimizers have difficulty seeing through function pointer data members. In contrast, lambdas calling functions permit ordinary inlining. * bind requires programmers to know about PMFs when you want to bind a member function, whereas lambdas don't. Yeah, programmers should probably know about PMFs, but only when they're necessary, and lambdas make them unnecessary.
The code _looks_ simpler, but what is going on is more complicated. Does it really lead to lots of bugs, or just edge cases like Sean's example? ie only when not using RAII? (which I agree is sometimes subtle) I find it interesting that people want errors more "in your face", but then want "monad style" to hide the error handling. Are we just trying to find the sweet spot - not too intrusive, but not too hidden? Does the sweet spot actually exist? Or is the ideal error handling a set of contradictory desires?
Now, how do you make that interface work atomically - ie on a thread-safe container? The committee is kinda sad about the current interface.
Actually any lambda that captures cannot be used as a function pointer - because it's operator() is no longer static!
I should have specified that you should never trust `Drop` *to ensure invariants in unsafe code*. 
When in doubt, add a layer of abstraction! Have the `RegisterCallback` return a `Callable` that the user invokes to unregister the callback. This has for benefit that the implementation details are entirely hidden within your code and can change whenever you need to (i.e., you're not beholden to use a token-based solution). e.g.: // By using &lt;list&gt; I'm not afraid of modifying it and iterators getting invalidated. list&lt;function&lt;void (int)&gt;&gt; callbacks; function&lt;void ()&gt; register_callback(function&lt;void (int)&gt; callback) { callbacks.push_back(callback); return [i = --callbacks.end()]{ callbacks.erase(i); }; } void do_work(int i) { for(auto const&amp; callback : callbacks) { callback(i); } } int main() { auto unregister_1 = register_callback([](int i){ cout &lt;&lt; "callback 1: " &lt;&lt; i &lt;&lt; endl; }); do_work(1); auto unregister_2 = register_callback([](int i){ cout &lt;&lt; "callback 2: " &lt;&lt; i &lt;&lt; endl; }); do_work(2); unregister_1(); do_work(3); unregister_2(); do_work(4); return 0; }
I have absolutely no clue what point you are trying to make. 
&gt;&gt; No, the most reasonable thing we can do is throw an exception. &gt; But you first have to determine that something is not right. And that may not be reasonable. ... If you can't detect a particular error, you can't employ any error handling strategy (whether throwing an exception, or returning an error code / optional / variant / etc), so this just doesn't follow from the discussion.
I never said you should only use assertions. This is one area you can cover (preconditions and invariants). Other kinds of errors are treated and handled differently. I'm not trying to be mean, but I don't think you understand the purpose of assertions at this point.
Criticising lack of `-Wall -Werror` seems a bit nitpicky IMO...I understand the significance, but this was also an example code block inside a blog post, not an actual project build script...
You can detect it. It may just be orders of magnitude slower than the operation you actually want to perform. And I call that check unreasonable.
&gt; Yet another article attempting to "write C in any language" (only the "C" in this case is monadic error handling). What? --- &gt; This pain-point seems to come from incomplete understanding of the exception handling mechanism. Poor phrasing on my part. See [this comment](https://www.reddit.com/r/cpp/comments/7ha64y/why_choose_sum_types_over_exceptions/dqpjvh3/). --- &gt; but there is nothing in the API of `prepare_environment()` that forces you to check `y`. That's because it's a poorly designed API. If `prepare_environment` can only be executed when `y.success == true`, then `y` should be passed as an argument. get_file(x) .and_then(prepare_environment) .and_then(actual_processing); --- &gt; and a silent failure with error codes Yes. My article is not about error codes. --- &gt; but the solution using exceptions addresses this issue without writing any code for it Maybe it addresses this particular issue, but it still hits the three pain points I mentioned: &gt; 1. Function signatures do not expose possible failure states. &gt; &gt; 2. It is not immediately obvious whether or not an operation can fail and how. &gt; &gt; 3. The compiler cannot help us prevent mistakes. --- &gt; You do not have to check anything to ensure that - the compiler does so for you. The compiler does nothing here to **prevent misuse of the API**. An exception might be thrown because you called two functions in the wrong order. With ADTs, you will not be able to write code that calls functions in the wrong order and compiles!
&gt; But you first have to determine that something is not right. And that may not be reasonable. The context was _conditions that were detectable in the first place_. &gt; By specifing (or not) in the documentation. Just like you say what the function does, you also should say what the parameters should be. One can express lots of tests on parameters in code: whether a value is within a specific range, whether a string is valid utf8, whether a pointer is not-null, whether a buffer is sufficiently large, etc. Are you saying you would write all of that in the documentation and just hope for the best? 
&gt; The context was conditions that were detectable in the first place. And I'm not saying they aren't. &gt; One can express lots of tests on parameters in code: whether a value is within a specific range, whether a string is valid utf8, whether a pointer is not-null, whether a buffer is sufficiently large, etc. Are you saying you would write all of that in the documentation and just hope for the best? And would you check everything in the code?
[The issue](https://github.com/rust-lang/rust/issues/24292). Previously, `forget` was marked as `unsafe` because you really shouldn't be doing it outside of unsafe contexts like FFI. However, someone found a way to write a "safe" version of it by making and then leaking a cycle of reference-counted pointers. There are two solutions to that: 1. Make it impossible to leak memory using ref-counted pointers. 2. Accept that it is possible to leak memory using safe code. Since there was no reasonable way to achieve the first, they decided to mark `forget` as safe and add "must not cause memory errors if leaks happen" to the requirements that need to be verified manually on any unsafe code. The old scoped threading API didn't satisfy this condition, since it relied on the destructor of the thread handle to join the thread in order to ensure that it didn't outlive the stack frame that spawned it. There was also the "drain" iterator, which mangles the internals of a container and then only cleans it up at the end, in order to allow for faster performance. The threading issue was addressed by changing the API. It used to be like auto _guard = thread::scoped([&amp;]() { code code code; }); and now (in an [external library](https://aturon.github.io/crossbeam-doc/crossbeam/struct.Scope.html)), it's like thread::scoped([](auto&amp; scope) { scope.spawn([&amp;]() { code code code; }); }); in order to ensure that the threads can be joined in `scoped` after it executes the closure, with no reliance on destructors. The "drain" issue is solved by temporarily marking the container as "empty", and marking it back to normal during cleanup. That way, there's no way to access freed memory if the iterator's destructor fails to run, but the entire container's contents will then be leaked. Since it's not something that happens in normal code, the leak isn't really a problem in practice. Again, not running the destructor is an exceptional circumstance. It will only happen if you have a memory leak (which you should be fixing anyways), when you explicitly call `forget` (which you should *only* do in FFI or other unsafe code), or when there's a double panic (in which case the process is fucked). 
The only common thing that can be done with bind but not lambdas are polymorphic lambdas in c++11. As of 14, I think there are only really obscure corner cases, which might be further diminished by 17. /u/STL gave a whole talk on this at cppcon once and I think he actually goes over this there.
Okay, so in simpler language: storing multiple of the same type is awkward in `variant`. Yes, this is a pretty big wart in principle, though I can't say it's one that comes up often for me. Strong typedefs are very often a good idea independently and obviate this issue completely.
I'd disagree that it's _the_ single best way to do it. Cancellation tokens are another approach that have a good set of benefits, though obviously also some drawbacks. Even signals-slots have their their pros and cons. Different use cases are sometimes best served by different solutions. :)
I don't see a difference, but ok, I'll use your word. If you can't ~~detect~~ determine a particular error (because it is too slow, say), you can't employ any error handling strategy (whether throwing an exception, or returning an error code / optional / variant / etc), so this still doesn't follow from the discussion. If you don't want to suck up the performance hit, you either refactor your code to make error discovery faster (and then we can talk about what error handling strategy is most appropriate), or write a bunch of slow sanity check code that gets thrown out in a release build and prey it never actually happens in the real world (forgoing the error handling).
Pulling the power cord is the typical example.
&gt;How many people check the return value of printf()? Every 100x developer checks it.
&gt; In Swift, when you have a function that may throw an exception, you have to specify the function as throw: well, Java has this too and this led to gigabytes of slashdot comments of people complaining
While I respect disagreement and would be happy to know of alternatives, I'm not really sure what you're disagreeing with or proposing. Cancellation tokens are **tokens**. All the signal-slot implementations I've seen including Qt's and boosts also use tokens as well. I know the mantra that different use cases have different solutions, pros/cons yaddi yadda, but it's usually helpful to actually specify what those use cases are and be explicit about the pros and cons in order to further discussion.
IIUC, Swift has `throws`, but you don't say what you throw, whereas in Java, you have to say exactly what checked exceptions you throw. Furthermore, Java also has unchecked exceptions, which is a big disadvantage over Swift. And Java also requires you to duplicate the exception boilerplate in multiple locations.
I did, its too slow and brittle for practical use for me.
I think you lost track of the context here: thlst wrote: &gt; No, assertions run only in development and testing. You shouldn't ship your releases with assertions on. And zvrba seems to disagree with that, suggesting that assertions = sanity checking, assertion failure is better than "exhibit UB for the user", and that hundreds of thousands of CVE's are due to not shipping with assertions on. &gt; So basically you throw sanity checking out of the window and let the program exhibit UB for the user.. yay, hundreds if not thousands of CVEs are due to exactly that. Missing/disabled sanity checking. I agree, assertions cannot replace exceptions. That has nothing to do with anything else that was said. 
&gt; Nonsense. Your "assertion" is my check for buffer size and throwing an exception if the operation wrt buffer size would access invalid memory. Okay... when you throw an exception, that is called "throwing an exception", and when you call `assert`, from the header `&lt;cassert&gt;`, that is called throwing an assertion. Please use standard terminology when discussing technical topics. And if you think constantly checking for buffer size is required for "security" or safety or anything other than making your program run slow as a dog, you should be programming in Java.
Generally, yes. Putting that burden on the caller makes very little sense: there is only one callee, but potentially hundreds of callers. And it is information that properly belongs with the callee in the first place. 
While I haven't seen an assertion in Clang specifically I can say the compiler is the absolute last place I want undefined behavior or even a straight segfault. Compilers sometimes get fixed in place on certain target environments and then developers are forced to permanently work around bugs in them. 
IMHO this is how it need to be done in C++. Here is some info about Go way to handle errors [Why Go gets exceptions right](https://dave.cheney.net/2012/01/18/why-go-gets-exceptions-right)
&gt; C++17 added [[nodiscard]], which is great but can easily be suppressed. I propose something like an assert(!unhandled_error) in the destructor of result that terminates the program, if you destroy a result without handling the error. That way you must not forget handling it or call something explicit like .ignore_error(). I'm not a fan. We have a library that does this, albeit without `[[nodiscard]]` yet. We find the approach error-prone and difficult to use correctly. A large percentage of our crashes and test failures come from code using that pattern; the rest are null-pointer problems that proper language ADTs would help us eliminate entirely. **Don't make run-time errors out of something that should be a compile-time error.** The major problem is that exceptions and ADTs both place the burden of broken error handling on the run-time realm. Adding yet another form of run-time error detection isn't an improvement to the status quo.
They still pay rent, it's the other stuff they don't pay as much on. 
It means that big salary loses a big % to taxes before they get to spend it on their super high rent.
I was primarily responding in context of foonathan comment &gt; IMO you shouldn't use exceptions for preconditions or invarints, use assertions for that But you're right that reading your post in a slightly different context than originally my comment seems redundant.
One issue with Java exceptions is that generic methods cannot handle them. So you end up with code that only throws unchecked exceptions, in which case thrown exceptions are either dropped by the user or wrapped in a opaque RuntimeException. Alternatively it throws Exception which tells you nothing usefull. The result is a lot of brittle user code just to tell the compiler to shut up. 
On the contrary, company mode and rtags work like a charm for me.
I have long wondered if the best way to handle errors would not have been to mark functions as potentially returning an error or not (as part of the return value or as separate syntax, not important which) and have errors returned essentially be expected with [[nodiscard]] (though impossible to suppress) with some special syntax to simply propagate the error upwards (ideally with just a single operator) when you cannot handle it locally. This makes it impossible to miss functions returning errors, but also makes it easy to say "I cannot handle this, maybe something above me can?" like exceptions. The downside might be generic interfaces (ie. virtual functions and other generic constructs) cannot return errors if they could not before, but honestly that makes the contract explicit which I think is an advantage.
&gt; Don't make run-time errors out of something that should be a compile-time error. it doesn't get truer than that 
&gt; I'm not really sure what you're disagreeing with or proposing. from your original comment: &gt; Returning a token Returning a token (which I'll call a "deregistration token" for clarity) creates a new token for every registered callback. Passing in an existing cancellation token allows using one token for multiple registrations. &gt; it's usually helpful to actually specify what those use cases are Fair. :) I originally wrote up just that but decided it was unsolicited and pointless noise. Returning deregistration tokens for long-lived registrations can result in some cases in code that tends to be filled with `vector&lt;token&gt;` variables. Our game engine was built on that pattern and the result is a significant sum of time and memory spent allocating and storing those collections. Cancellation tokens can be reused, meaning the caller only needs to store one token (or one-per-"lifetime"). Cancellation tokens involve overhead that could be avoided if one needs to optimize for the fastest-possible callback invocation and doesn't care about registration/cancellation speed as much. Signals-slots are simple and work well with code-generation approaches owning to all state being localized to the signals or slots, unlike deregistration tokens or cancellation tokens which introduce a piece of state to be managed.
i think the biggest boon to the language would be typed exceptions. it's crazy to me to think that what errors a function has is not part of it's type signature.. at least `std::expected` solves that problem. needless to say any function that calls a function that can throw but doesn't propagate it's exception type or handle it inside is a compile time failure. the obvious issue that typed exceptions introduces is the same one that java suffers from: namely `std::bad_alloc` and it being a nightmare to have to handle every single memory allocation. i'd solve this by introducing a `std::allocator` that doens't throw, and will terminate the problem on failure... this i think would be to the go-to allocator to use and the throwing allocator be useful in more specific, constrained problem spaces. i think all of this can be applied to `std::out_of_range` too, in my opinion logic errors shouldn't be exceptions, only runtime errors that can't be statically checked. a `try` keyword can be added for the common case of "call a function that may throw and terminate if it fails", something like: `auto x = try my_method();`. this can be generalised to rebind exceptions or provide a default value: `auto x = try my_method() else throw my_exception{}` or `auto x = try my_method else 1`. most of my opinions on this subject are based on [this article](http://joeduffyblog.com/2016/02/07/the-error-model/) which i love.
I've yet to find something that is actually useful and does need more than 20.
Java probably isn't the last word in statically typed exceptions. It's got all kinds of limitations around when they can be used, they're pretty verbose to handle, and people pretty much gave up on them rather than try to fix those problems.
If I understood it right GO just has no exceptions?
Yes Go uses something like ADTs but realized as multiple return values. There is also panic() that can be compared to std::terminate().
Not without a custom allocator.
People imitate what they see. For an actual build, I enable lots of warnings beyond those two, but for everyday "let's compile a file", using those two easy-to-type warnings is still important. I would equally hiss at an example with MSVC that didn't depict `/W4`.
I see now :)
&gt; auto first_result = try calculate_foo1(); auto second_result = try calculate_foo2(first_result); The good part, I guess, is this is as little boilerplate as you can get without being entirely implicit. *But*, considering faaaar more functions than not can fail in some way, we're going to end up writing this operator try an awful damn lot. And not just for ordinary functions, but also for operator functions, such as `try some_string + "!"`. &gt; The problems with exceptions: Writing exception safe code is hard I think this is another case where exceptions suffer from poor naming. "Exception safety" should probably be renamed "error safety". Let's say we abandon exceptions. Our code encounters a problem and we're about to return an error value of some sort, but before we do, should we do some cleanup to release resources and maintain the invariant? Should we undo any previous, half-finished work? The issues we need to deal with don't go away even if we stop using exceptions. These aren't problems with exceptions; these are problems for errors of all kinds.
Panics are just exceptions. You can throw them, you can catch them, and they propagate up the stack.
Panics are just exceptions. You can throw them, you can catch them, and they propagate up the stack.
a godbolted question is the best question.
Nice post, but I don't really see why you call this a compromise. If I understood you correctly, your suggestion is to plain and simple encode errors in returned ADTs. Not that I'm particularly against that but again I don't see where the compromise is. And btw. `std::optional` already has a value_or_throw - it's called `value` the same is true for `std::variant` with `get`. I'd love to see a operator try in c++ though. Imho, the problem with mixing return values and exceptions on different layers across the call stack is that you easily end up with the worst - not the best - of both worlds: If parts of your program use exceptions, you have to assume that any function can throw (if it is not marked noexcept) so you loose many advantages of using ADTs: Your code still had to be exception safe and you still don't know which functions can fail and which not. At the same time, translating all exceptions into some error part of an ADL requires writing try catch blocks all over the place, which makes exceptions less appealing and robb's them off their main benefit - the ability to transparently transport error information from the failing function to a point where something can be done about it without littering each intermediate function with error checking code.
When the output of the program is redirected to a file. If it fails, your program could exit with a non-zero exit code to tell the caller that it failed. (`printf` returns a negative number when it fails.)
Has it been added to `printf`?
Thank you, I'm glad you liked it. I'll see about adding summaries, though I might have to wait until Friday to get around to it.
I'm tempted to post *so* that /u/STL can critique the everloving hell out of my attempt at programming. He's so educational in all of his comments!
Violation of a precondition is manifestation of a logic bug, 100% of the time — you want to save data in a scenario where the code is known to be in a broken state? No thanks! I'll take a crash dump that helps fix the bug over possibly-corrupt data.
&gt; Exceptions still have a runtime overhead when thrown, so they shouldn’t be used for non-exceptional cases. If he is talking about swift, he's flat out wrong. 
How many functions (environment gives you) uses custom allocator?
Right... (err != null)... no, thanks.
"You" would refer to whoever owns the copyright, which in this case would be your employer.
Naive `std::integer_sequence` implementations that shipped with real stdlib implementations ran into this limit all the time; it was circumvented with compiler intrinsics.
Solved. Run: module show yourmodule then it should give you the directory to the /include folder. Mine was: /opt/apps/intel17/boost/1.64/include Then, when you compile do: g++ -I/opt/apps/intel17/boost/1.64/include yourcode.cpp -o yourcode That's a capital i, btw. -I
&gt;IIUC, Swift has `throws`, but you don't say what you throw Isn't that basically what modern C++ has, just with inverted logic (functions effectively have `throws` by default, and use `noexcept` to opt out)? If so, this might just be an example of C++ having the wrong default. 
Exactly, this is bad, so C++ need a better way to handle such cases.
By nested bind do you mean passing the result of bind to bind? It isn't just complicated, it is surprising to anyone who doesn't know about the arcane exception to how bind works. 
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7hm9qy/how_do_you_include_a_loaded_module_on_linux/dqs57lb/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It is useful, but the recursive implementation must have been really slow.
Ok, dismiss me for being someone who has never programmed professionally, also dismiss me because I have never programmed with a team. And while we're at it, dismiss me because I really don't test enough. All those things are true and I do not mean to think I am the upstart who is here to shake things up with his salt of the earthness But... I've been managing a *personal* 15+ years code base which is basically a GUI to a fantastic, expertly written, library which has undergone maybe a dozen incompatible updates. And the fact that it uses exceptions is why my app can continue to get multiple week^1 uptime while still reporting new errors without work from me. Thanks to a few a few top level exception catches which log everything they see, the app can keep functioning **and** report issues to the user with basically no effort from me. Yeah you might argue that the type systems should enforce I manually deal with those errors, but in the end of the day all I'd do is catch and log them anyway. But still... maybe relying on the library error message is me passing the book, also I'm giving up any chance of localisation. That's true, but here's a different sort of anecdote I was working recently on a research project and deep within it I was using Chaiscript. Things were going well and then, with what I thought was a small innocent change, everything crashed. Well actually it didn't crash, and that's my point, instead my top level exception catch caught and reported the error in the GUI . You could argue that, with forced error handling, the same reporting would have happened. Also you could argue that with better static verification the code would never have compiled. But for me, as a user, all I could see was that with **zero** effort the error was **identified, propagated to to the relevant handler, and dealt with appropriately**, i.e. logged. Like I started off with, dismiss me for being a bad programmer, but for me, exceptions making dealing with the vast majority of errors so very easy: just report them and either mosey on if possible, or die. There's a lot of new languages which tempt me, but any which force me to manually propagate errors start off on a [big negative](https://blogs.msdn.microsoft.com/ericgu/2004/01/12/minus-100-points/). To repeat once more, I'm total amateur here, but I love exceptions. ^1 It could probably get more but it's not the type of app which is run that long. 
Yep. I felt that I truly understood bind only after completely reimplementing it.
:-) I'll critique your first post, sure.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7hmjgq/happy_prime_numbers/dqs5ptn/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I feel slightly bad for strictly enforcing the subreddit's rules here (this is not a beginner forum - nothing's wrong with beginner questions but they tend to drown everything else out), so here's some quick advice: Write successively more complicated programs that get you to your code. For example, start by writing a program that can test whether a given number is prime, then write a program that prints out all the primes from 1 to 100. Write a program that can test whether a number is happy, then write a program that prints out all the happy numbers from 1 to 100. Finally, combine them to simultaneously test for happiness and primality. 
&gt; See what you are doing? Yes, I'm well aware of the issues with throwing through C code. My point is that the rule for writing C++ code that says 'assume everything throws except for...' can have the exception for C functions removed, because C functions actually can throw. There are implementations of POSIX where POSIX C functions actually do throw. And if you look at the exceptionsafecode.com guidelines for what should guarantee that it doesn't throw you'll see it lists: destructors, move/swap, and "_nowhere else!_". That's simpler than the longer list you gave. If you're writing C you don't care because you can't do anything about exceptions anyway and writing cancellation safe C code is like writing exception safe code without RAII (although there is the GNU C extension `__attribute__((cleanup))`). If you write the code you show in C then you already know that code is vulnerable to POSIX cancelation points, regardless of whether they're implemented with exceptions or not, because `bar()` might contain a cancelation point.
This is nonsense, C++ can do "multiple return values" as well via std::tuple. The syntax is very nice after c++17. Go hasn't brought anything new to the table.
&gt; i think the biggest boon to the language would be typed exceptions I think one of the big improvements Rust does for declaring the type you throw is that `?` will call the coversion "operator" to the expected error type. &gt; i'd solve this by introducing a std::allocator that doens't throw, and will terminate the problem on failure... Rust's containers don't communicate allocation failure. There is an RFC for failable collections but I'm not familiar with it.
http://coliru.stacked-crooked.com/a/049a441bee89d102
&gt; The good part, I guess, is this is as little boilerplate as you can get without being entirely implicit. I prefer having a ? to `try` since it reduces boiler plate more and composes better. I have been finding I like the explicitness of ? over the implicitness of exceptions. In my mind, I keep going back to http://www.gotw.ca/gotw/020.htm
For example: int read_and_parse_file(MyType&amp; output) { FILE* file = fopen("some_path", "r"); if (file == NULL) return -1; //fine void* buffer = malloc(100); if (buffer == NULL) return -1; //ooops fread(buffer, 1, 100, file); output = parse_file(buffer); // Assume it does not throw. fclose(file); free(buffer); } Challenge question: Can you make it error safe? Assuming your bigot manager forbid you using `std::ifstream`, `std::vector`, `std::string` and stuffs.
How does this apply to contracts that may be violated based on input from users? For example, imagine a text-processing function with a precondition that the text passed in is in ASCII. The text passed to this function is received from a user-provided file. If an assertion is used to check the precondition, then the release version has the potential for UB if a UTF-8 file is passed in.
On one hand, this is absolutely the wrong sub for a post like this. And **there are** correct subs. Every post like this comes from someone who doesn't strive to read directions. Which is a bad sign for any programmer. On the other hand, the rules for this sub are squished between ads, far off to the side. And I think they're not shown at all on mobile devices. Directing people to the best place for their question really is the best advice you can give, I think.
I have had good experiences with [ThreadPool](https://github.com/progschj/ThreadPool).
[QThreadpool](http://doc.qt.io/qt-5/qthreadpool.html)
&gt; In my mind, I keep going back to http://www.gotw.ca/gotw/020.htm Though, even if use ? instead of exceptions, there are still just as many error paths. If we take Herb Sutter's code, and we put in the ? syntax you like, it comes out like this: String EvaluateSalaryAndReturnName( Employee e ) { if( ((e.Title()? == "CEO")? || (e.Salary()? &gt; 100000)?)? ) { (((((cout &lt;&lt; e.First()?)? &lt;&lt; " ")? &lt;&lt; e.Last()?)? &lt;&lt; " is overpaid")? &lt;&lt; endl)?; } return ((e.First()? + " ")? + e.Last()?)?; } And, just as a reminder, with exceptions the code instead looks like this: String EvaluateSalaryAndReturnName( Employee e ) { if( e.Title() == "CEO" || e.Salary() &gt; 100000 ) { cout &lt;&lt; e.First() &lt;&lt; " " &lt;&lt; e.Last() &lt;&lt; " is overpaid" &lt;&lt; endl; } return e.First() + " " + e.Last(); }
What if `Employee`'s copy (move) constructor throws? Would you change the signature to String EvaluateSalaryAndReturnName( Employee? e )
&gt; Violation of a precondition is manifestation of a logic bug, 100% of the time &gt; you want to save data in a scenario where the code is known to be in a broken state? Yes, to a temporary file. &gt; if you have fundamental logic errors There's no bug-free program, and I guess you have 100% coverage testing in-house? 
No, because it will create so much noise as nobody checks the value currently....
[removed]
Your comment has been automatically removed because it appears to contain profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7ha64y/why_choose_sum_types_over_exceptions/dqseiab/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
So there's a prior art to this, starting with the Alexandrescu's Expected&lt;T&gt; from a decade or so ago. Changes to the C++ standard make the `std::expected` and `outcome` a worthy successors, I suppose. I completely agree that a flexible library author should offer both mechanisms - in some APIs. There is a certain then-major library from some 15-20 years ago that has both error-throwing and error-reporting "open file" (create a 'file' object) operation. This library is now known as... well, "yuck". What we should look at, too, is how other people did it. In .NET world, for example throwing an exception to express failure is the norm. For a large library like .NET has, **never** using something else would be amazing. So indeed, there is a handful of APIs that have an error-return form (e.g. TryParse for numbers and TryGet for dictionaries). What people should note, however, is: the percentage of such APIs is **exceedingly** small. (One can't open a file (stream) with an error-return API, there isn't one 😀). I think, indeed, "just do everything" is justified - sometimes. The real question is - how often, what situations for? I firmly side on the "almost never". BTW... **can we please stop with "exceptions are for exceptional situations"**? It's a bona-fide pointless hand-waving. We can't agree whether something as mundane as opening a file is exceptional , FFS! And I think, we shouldn't. This is a matter of context, people...
&gt; constantly checking You're putting words in my mouth. I never said that. And I did measure performance impact: (almost none), the program performs well within the specs. Classes have their invariants, public methods check preconditions, private methods assume invariants and preconditions are in place. &gt; and it will save you a lot of typing I have a macro called assert that checks the condition and throws a `std::logic_error` on failure. No more typing than assert. Plus, I have not yet had the need to compile it out in "Release" builds. And I'm willingly not putting performance above debuggable reliability; if most C++ programmers equal this with "Java", then well... I can see why Java and C# are more popular with corporate managers... 
&gt; There's no bug-free program, and I guess you have 100% coverage testing in-house? What does that matter? If you throw for precondition violation and catch it, then you are in a code path that _only exists_ because a bug exists. Lack of code coverage, aside from being a strawman for the purposes of this conversation, only introduces the possibility of logic errors — meanwhile, you've already embraced them. You have a lot of rhetoric about "secure code" for someone who has obviously never worked in an industry that required such, or you would have some concept of data auditing and the fact that due to liability concerns, possibly-bad-data is infinitely worse than useless/no data. Since you're not speaking from experience, at least apply some critical thinking, please.
He has expanded the definition for preconditions to apparently also include detection of every possible UB condition. For example, where most people would be satisfied with an `assert (ptr);` to ensure that at least _something_ is there, he apparently also wants validation that this is a valid pointer, which is of course very expensive. And you know the old adagio: if you cannot detect 100% of all possible problems, there is also no point in attempting to detect the 99% that represent common cases. If it is not perfect, it cannot possibly be used for anything. I wish this were a sad joke, but I've had to deal with people who think like this... 
Yes, this is how the cleanup problem is approached with pthreads thread cancellation. Note the following: * I was discussing your first example which had no pthreads; if no pthreads, what then? * the original sin you are making is the attempt to mix C and C++ in way that **does not work** for C code * related to the rest of our discussion : the pthreads thread cancellation cleanup is **pure C**, nothing to do with C++ or exceptions; you seem to think that, because it is implemented with C++ exceptions, it does; you fabricated an elaborated, but partial and quite fankly wrong, model of how C and C++ can be mixed; in particular, what does not work in your model is what happens when C code calls something that might have C++ in it.
&gt; If you throw for precondition violation and catch it, then you are in a code path that only exists because a bug exists. Yes, exactly: it allows me to log the bug with more information possibly encapsulated in the exception. And the "new" code path consists of try/catch around main or some thread's entry point. &gt; unreliable data When did I say anything about using unreliable data for anything else than logging the failure?
I'd say C++ has exactly the right default. Like it or not, exceptions are the norm. Not having them is a special case that must be specifically marked. 
&gt; log the bug with more information possibly encapsulated in the exception The bug was already executed; what do you really think you know about the state of your process?; And "encapsulated in the exception", as opposed to a crash dump, which has the exact state of your _entire process_? No. Just, no. &gt; When did I say anything about using unreliable data for anything else than logging the failure? Really? &gt; &gt; If I throw an exception, I can catch it at top-level and save the user's work before exiting. (Of course, no mention of letting the user know their data was saved in a code path that only exists because the code was known to have already run buggy code...) I'm sorry, but you can't actually hope to be taken seriously, right? Put some modicum of effort into your bullshit.
&gt; Performance was never mentioned There are many categories of C++ programs where during development you want assertions to catch programming bugs quickly, but you absolutely cannot have layers upon layers of assertions in stack at deploy time.
I don't know if you're speaking generally or just about C++, but [Midori](http://joeduffyblog.com/2016/02/07/the-error-model/) seemed to find that different results were very possible: &gt; First thing’s first: although Midori had exceptions, a method that wasn’t annotated as throws could never throw one. Never ever ever. There were no sneaky RuntimeExceptions like in Java, for instance. We didn’t need them anyway, because the same situations Java used runtime exceptions for were instead using abandonment in Midori. &gt; This led to a magical property of the result system. 90-something% of the functions in our system could not throw exceptions! 
Probably yep, that too.
Wrap the FILE\* in an unique ptr with a `fclose` deleter, wrap the retval of malloc in a unique ptr with a `free` deleter, job done?
Thanks, I'll have to check out his other responses. &gt; And you know the old adagio: if you cannot detect 100% of all possible problems, there is also no point in attempting to detect the 99% that represent common cases. If it is not perfect, it cannot possibly be used for anything. I wish this were a sad joke, but I've had to deal with people who think like this... Heh. Yeah, that is sadly common in this field. I see it a lot with typesystem discussions; types can't detect all problems statically, so just throw out the benefit they do give and use a dynamic language. Or closer to home, proposed standard library X doesn't help my specialized domain, therefore it shouldn't be in the C++ standard.
I agree. This approach would just be an extra safety net in addition to nodiscard which is a compile-time warning.
Regarding we need to write try a lot: As I said, this isn't for all kinds of errors. Most notably, it isn't for out of memory, which get rid of most exceptions. I think it's main use is system_error and some related exceptions. Regarding exception safety: Yes, this is also an issue with return codes (I forgot to mention it in the post). But with return codes thinks are more explicit which makes it easier to reason (IMO).
Code Examples: https://github.com/t0rakka/mango-examples/blob/master/misc/concurrency.cpp Performance use case: http://codrspace.com/t0rakka/holysh-t/ 
&gt; the assembly of the optional version looks much, much worse. I tried with GCC instead of clang, and turning on -fno-exceptions for the `std:optional` version, and they are close. Both for Os and O3
You may want to update it's constructor to properly handle worker thread creation failure
Can you suggest a way to handle that?
Having a choice between multiple non-ideal strategies depending on situation is really important. I'm not going to use C++ exceptions in a real-time critical piece of bare metal code, ever, so alternate options are very much needed.
Exactly my point :-)
Yes
It depends on which version of bigot boss you assume. Some versions may say, "RAII is expensive, you stupid" or "unique ptr? Must be a bad idea because I've never heard of it." Then, no. But seriously, this is a good technique to handle legacy or C API.
It is useful for future APIs though.
Ever heard of temporary files?
Of course. 
Intel tbb
I use QThreadPool and like its easiness. But it is not performant enough for very short tasks. I don't have figures in mind, but if your task times are 10 ms (?), then the thread pool overhead reduces its benefits. Certainly not a bad QThreadPool design though, as I tested other implementations with similar results. But I am pretty sure there must be some better solutions for small tasks parallelization.
I feel like you're not understanding the proposition I'm defending. What I'm saying is that the following is not correct: // C++ code ... int *x = malloc(10); printf("Hello, World!"); // guaranteed not to throw, because printf() is a C function. free(x); // no need to use RAII, because the code between here and the allocation is all guaranteed nothrow ... The point is that that guarantee _is not correct_, and we have actual, real world counter examples. If you try to write exception safe C++ code assuming that incorrect guarantee, you may well be surprised when your supposedly exception safe C++ code has problems with exceptions. And furthermore, not making that incorrect assumption _is simpler_ than making it. You have fewer exceptions to the rule to remember and deal with. &gt; I was discussing your first example which had no pthreads; if no pthreads, what then? Well if you want to you can write your C code to be exception safe. You don't generally need to and I'm not suggesting that people should always do that. That's not what I've been saying. And I'm definitely not suggesting that people should use C libraries under the assumption that they can throw exceptions through them. I'm not saying anything like that, so if you think that's what we're discussing just get that idea right out of your head. &gt; the original sin you are making is the attempt to mix C and C++ in way that does not work for C code I absolutely can write my C code so that it works just fine. &gt; the pthreads thread cancellation cleanup is pure C, nothing to do with C++ or exceptions; I'm not saying that the portable interface has anything to do with C++ exceptions. &gt; you seem to think that, because it is implemented with C++ exceptions, it does; No, that's not what I've said. See my clarifications above as to the proposition I'm actually defending. &gt; you fabricated an elaborated, but partial and quite fankly wrong, model of how C and C++ can be mixed; in particular, what does not work in your model is what happens when C code calls something that might have C++ in it. I'm giving you existence proofs that this code actually can and does exist. Any assertions to the contrary, that C functions can never throw are incorrect.
It is the developeres responsibility to ensure that contracts are upheld prior calling a function. Using contracts for checking user supplied data is wrong, a mistake the company I work for did in the past which caused quite a lot of pain. If you run into a contract it is nothing else but a bug in your code. Contracts are useful because you can explicitly state the expectations and the guarantees you get in return, making it much clearer whom's responsibility it is to check data, a caller or a callee. 
Isn't an introduction to callbacks in C++ without a mention of delegates somewhat incomplete? 
If you are planning to do IO tasks as well, you could use a Boost.Asio io_service (io_context) and make X threads run it and use io_service::post to post tasks to the thread pool.
I started my post with "I'd say _C++_ has...", so let's pretend I was speaking about C++. 
Close in what? Assembly or measured performance? 
Thanks - looks very nice!
Generally you don't need to check anything because it follows logically from earlier code. By having check on the callee side you are doing redundant work
&gt; They are implicit: When looking at some code it isn’t obvious which things can throw exceptions and which can’t. [...] so you have to refer to a function documentation. This is only a concern when using exceptions incorrectly. Instead of referring to the documentation, you just assume everything throws. &gt; They are difficult to use correctly: Writing exception safe code is hard, especially in generic code where you don’t know the type you’re dealing with. Well as David Abrahams says “Exception-handling isn’t hard. Error-handling is hard. Exceptions make it easier!” &gt; You have to assume that everything can throw, Yes! &gt; which makes the strong exception safety impossible to achieve, or you have to put additional requirements on your types (i.e. this function must not throw), but it is currently impossible to statically verify them. exceptionsafecode.com lays out how to do strong exception safety, and it does depend on ensuring a small number of operations make the nowthrow guarantee. You can also statically check that certain things are marked `noexcept` which means they will never throw, but that simply means that if something inside them does throw then the program terminates. Yes, statically guaranteeing that something won't throw and also won't terminate due to trying is difficult. But in practice I don't think this is really a significant problem. &gt; They are not easily composable: There is only one current exception, you can’t have multiple ones. This was a problem, for example, for the C++17 parallel algorithms. What if an exception is thrown in multiple of the worker threads? How to report all of them back to the caller? The implementation gave up on solving that problem and just decided to terminate the program if any exception is thrown. And that's the right choice, because there's no one right way to compose them and so I get to choose how to compose them: if the worker tasks can produce exceptions then the top of the worker task is one of those boundaries locations where try/catch is okay (as laid out by exceptionsafecode.com) and that's where I write my code to catch the exception, transport them somewhere, and handle them appropriately. E.g. maybe I want a `std::vector&lt;std::exception_ptr&gt;` after the threads are all done. &gt; They are explicit: In Swift, when you have a function that may throw an exception, you have to specify the function as throw: This is actually one of the things I don't like about swift. Exceptions are nice because, far from being invisible `goto`s, they are structured error handling: Code gets to focus on the successful path without the noise dealing with propagating errors to the right place, making it more readable and writable. And there are also clearly defined places where the error handling goes, without metastasizing over every level of the call hierarchy. Swift's `try` isn't too bad, but it's also not good. &gt; But unlike noexcept, this is statically enforced. Swift does at least do better than some other languages in that I can use `try!` to call a function marked as throwing, but say "I know I've called this in a way that it won't throw even though the type system says it might." This is a good thing, and much better than Java's checked exceptions, and not really that much worse than C++ exceptions. --- In all these articles about C++ exceptions, it really seems to me that the biggest problem is that people don't use them correctly. Improvements people suggest are things that would make using exceptions worse than using them correctly now, even if they'd make people's currently-incorrect usage better. Maybe on average it's an improvement, but it still seems bad to me. I'd rather just make everyone use them correctly, and then maybe we can get articles that actually make improvements over using C++ exceptions correctly.
Assembly, see here https://godbolt.org/g/hUyqAE
Imho the problem with tuple is that you can't name the elements and even with structured binding you can get the names wrong if the involved types are similar. Structs are much better.
&gt; The good part, I guess, is this is as little boilerplate as you can get without being entirely implicit. But, considering faaaar more functions than not can fail in some way, we're going to end up writing this operator try an awful damn lot. Yep. This is one of the things I don't like about Swift, although it's not as much a problem in Swift as it would be in C++, because Swift encourages less use of exceptions. Frankly I think C++'s system is better. auto first_result = calculate_foo1(); auto second_result = calculate_foo2(first_result); This looks fine, it's readable, it's correct. C++ exceptions give me structured error handling and don't sprinkle boilerplate everywhere. This is what I want and I'm glad this is what C++ gives me.
Thanks for the comments! As for your suggestion, actually you can already do something similar by selecting events on top of the instrumented functions in the capture view (events are the vertical white lines in the event track). These are sampling events collected from ETW (Event Tracing for Windows). When you select them, a sampling report of your selection will be generated. From there, you can hook into the functions that interest you.
There's four amazing things about Rust which I'd love to see being done in C++: 1) Everything is constant by default, having to declare things mutable instead of having to declare things constant is an amazing design choice. It heavily reduces the amount of errors. In theory one could always use const and constexpr whenever they can in C++ but in practice things slip and sometimes they cause error (not to mention they cause code to be less efficient). I thought this may be solvable with metaclasses, but playing around with the idea I saw it's not as easy as it may seem at first :( 2) The package&amp;build system. Having a package system is quite valuable, it means there's a centralized place and a standardized way for people to share libraries. It's much more minimalistic and concise than the monstrosity that is Cmake and since most libraries support being built statically and are oss, it means you can compile stand alone binaries as the default, even for large projects, rather than having shared libraries as the "default" and having to struggle if you want a build that statically links everything. 3) The compiler is more strict in places it can be strict. I'd love for the default behavior of clang and gcc to be compiling with `-Werror -Wall` and the "unsafe" builds to be done with a flag along the lines of `-IgnorError` 4) The way it handles move and copy/clone. I'm not saying it's perfect, but it's much better than C++ where some basic optimizations that could easily be compiler implemented instead force you to explicitly use std::move. This, however, would require having a better resource ownership mapping at compile time. The big problem with the points you mentioned are: &gt; compiler enforced RAII See the discussion thread started by /u/meh_or_maybe_not &gt; you can have either as many "non-mutating" handles to a piece of data as you'd like, or one "mutating" handle. This is where, in my opinion, rust oversteps it's boundries. Since a lot of time having two mutating handles makes sense, it's not impossible to have a two mutating handles, you can have mutexes (which in rust will wrap a type), atomics and other concurrent objects... but the implementation feels like a hack and the code that implements them will actually benefit less from compile time checks than the equivalent C++ code. If in the future architectures will implement mechanisms for synchronization (or mechanisms as to not require synchronization), better than the ones we currently have, Rust's thread-safety may become even more of a nuisance. 
&gt;They are implicit: When looking at some code it isn’t obvious which things can throw exceptions and which can’t. I believe the fundamental problem is this sentence. Somehow the author believes that exceptions are rare beasts that are almost never used, and if used should be approached with extreme caution and possibly a warning in the manual. The reality is this: _all functions can throw exceptions, except when marked as noexcept_. Stop thinking of exceptions as being exceptional, and instead treat every function like it may throw. &gt;They are difficult to use correctly: Writing exception safe code is hard That's a value judgement that I find questionable. Once you get in the habit of RAII, exceptions just stop being a problem. So does early return, and resource management in general. RAII is not 'overhead' (as claimed in the article), it's _the_ fundamental design pattern of C++. &gt;They are not easily composable: There is only one current exception, you can’t have multiple ones. You solve that the exact same way as return codes solve it. It's a bit of a straw man, isn't it? Nobody is complaining that you can only have one error return code for something that can fail in multiple simultaneous ways, but somehow for exceptions it is considered to be a problem. &gt;So what are you supposed to do? Do what others do. It sounds smart, but it makes no sense. You cannot take a language that uses exceptions pervasively and then somehow excise them. A language is not just a collection of disparate features, it all hangs together. Moreover, the author could just as easily take his own advise and wonder why so many people are perfectly happy with exceptions. Maybe they have some habit or use some code pattern that eliminates the problem for them? Wrt. the Swift example, the only difference is that C++ chooses to mark functions that do not throw. That makes sense, because they are in a very small minority, thus removing the burden of having to mark every single function out there with 'throws'. Similarly, it lacks the burdensome need to mark function calls with 'try' - _every_ function call is implicitly 'try', so why spell it out? And how would you compose that, anyway? Any given expression may be composed of operators that may or may not throw. Is there a single 'try' at the beginning of the expression? Or is there one per operator? That will be ugly... The Rust example claims that testing for an error return after every function call is somehow ergonomic. No, it isn't! You now need three lines of code per function call instead of just one. And apparently the Rust designers agree, adding shorthand to avoid having to write those three lines every time. The author finally reaches a compromise, which is apparently to return a type that can be easily converted into an exception when desired. This seems worst of all worlds: you always pay the price for error handling using return codes even if you don't have errors, you always get extra boilerplate on any function call, and you still cannot return errors from constructors or overloaded operators. &gt;Conclusion Error handling is difficult. I completely disagree with that. What the author is doing is not error handling, what he is doing is fighting the language to make it do something it was never supposed to do. _That_ is what makes it difficult. 
Now do a performance check as well. I did the last one, you get to do this one. 
&gt; instead using abandonment in Midori. That is such a fancy name for crashing. However I agree, no need to use exceptions if all you want to do is crash. Why aren't those guys working on the windows kernel, its been ages since I had a proper blue screen.
All source follows logically from earlier source, so by that logic no errors ever happen. Yet somehow they do. 
I agree. Often we already use an ad-hoc form of `std::optional` when returning a pointer that could be nullptr, with the difference that the compiler does not warn you when you start using the pointer as-is. I've been using `boost::optional` in return values for some time now and I really like it. It's explicit and easy to handle. Having `map`/`and_then` would be awesome.
This is something I've been working on for quite some time now. As I've just pushed a major update, I would love to get some feedback. I.e. Does it work for you as expected? Experienced some issues? What else would you be missing from it? Installation went fine? Too slow or fast enough? Would you love to see it integrated into other editors? Etc. Cheers, Adi 
Just to make a short recap what is it about and what does it implement as of now. `Yavide` implements a mixture of `libclang`-based services and integrates them into the Vim editor (even though architecture is editor agnostic and is possible to integrate it with any other editor). Everything is implemented on top of the asynchronous API. Some of the features which have been implemented are: [`indexing`](https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#indexing), [`find-all-references`](https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#find-all-references), [`go-to-definition`](https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#go-to-definition), [`go-to-include`](https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#go-to-include), [`type-deduction`](https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#type-deduction), [`fixits-and-diagnostics`](https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#fixits-and-diagnostics), [`semantic-syntax-highlighting`](https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#semantic-syntax-highlighting), [`clang-format-integration`](https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#clang-format), [`clang-tidy-integration`](https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#clang-tidy), [`json-compilation-databases`](https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#json-compilation-database).
What im saing is that fynctions have postconditions. And those postconditions may be compatibile with preconditions of the next function
This does sound like a good idea
While the other poster isn’t being helpful, he is right. Error handling in constructors is something I would expect a production ready c++ library to get right, although their attitude isn’t helpful. For how to handle it, according to [the documentstion](http://en.cppreference.com/w/cpp/thread/thread/thread), threads constructor can throw a std::system_error, so you have to catch the exception, and handle it in your chosen method of error handling. It’s also perfectly reasonable to say that the threadpool might throw a std::system_error on failure to create
&gt; you want to save data in a scenario where the code is known to be in a broken state? Smart programs offer you the choice to restore from the crash state or from the last clean save. Worst case the data is corrupt and crashes again, resulting in the same choice. Best case you didn't loose the last hour of work. 
I agree with this. It’s mature, has a friendly license and doesn’t pull in all of QT (if you’re not already using it). Works great as a [task library](https://www.threadingbuildingblocks.org/tutorial-intel-tbb-task-based-programming), or at a higher level contains all the normal goodies like parallel for, along with giving you thread safe containers and allocators 
To be fair, I’m not sure much of my code in c++ could ever survive running OOM. 
Im aware this is a stupid question because I'm ignorant of vim but anyway: This seems to be vim based, how tied to the vim style of input is it? IE can I use it like a 'normal' IDE/text editor (from a mouse/keyboard perspective), or is it more akin to vim + extensions?
&gt; decltype(*first) init{}; What about proxy iterators, like `vector&lt;bool&gt;::iterator`?
It is not tied to Vim at all. It is only a proof-of-concept integration that I have done with the editor I am personally using. That's all. But as I said this whole (framework)[https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#framework] is totally editor-agnostic and given that it is implemented on top of asynchronous API which doesn't have anything Vim specific, with some small code refactoring it would be possible to implement the integration into any other decent editor out there. It is very similar to what `clangd` is actually doing but I've made this framework way before `clangd` came along :/
My take: the problem is that we can't access all the information that the compiler has. We have to decide if the user wants exceptions (probably doesn't want to handle at caller level) or an ADT so that they can handle it right away. But we do know this information in the caller! `noexcept` is already part of the type system, so why not make it something like `const`? Currently, you can call a function that throws from `noexcept` function, which will terminate if it throws. What if you could have an overload for your possibly-erroring-function, so that it has throwing as the behaviour if you are calling it from a non-`noexcept` context (eg. in a `try` block or non-`noexcept` function) and returning an ADT / error_code if you are calling it from a `noexcept` context? (Probably you need the inverse of a `try` block for this, eg. a `noexcept` block too)
I mean just in your tiny toy example you forget to close the file in case the malloc fails. I think there is no good excuse (given that C++11 is available) to write: std::unique_ptr&lt;FILE, decltype(&amp;fclose)&gt; file(std::fopen("some_path", "r"), &amp;fclose); if (!file) return -1; std::unique_ptr&lt;void*, decltype(&amp;free)&gt; buffer(malloc(100), &amp;free); if (!buffer) return -1; output = parse_file(buffer);
It would be nice not to be forced to pass an initial value to accumulate indeed! Did you consider the overloads of std::reduce that take no initial value? You don't find them optimal because it does `std::iterator_traits&lt;inputIt&gt;::value_type` and not `decltype(*first)`?
You have to join the threads you have already created, since calling a [destructor](http://en.cppreference.com/w/cpp/thread/thread/%7Ethread) on a running thread leads to `std::terminate`
IIRC they're only crashing for things like array out of bounds or nullptr dereference which is what you should do.
My take: the problem is that we can't access all the information that the compiler has. We have to decide if the user wants exceptions (probably doesn't want to handle at caller level) or an ADT so that they can handle it right away. But we do know this information in the caller! `noexcept` is already part of the type system, so why not make it something like `const`? Currently, you can call a function that throws from `noexcept` function, which will terminate if it throws. What if you could have an overload for your possibly-erroring-function, so that it has throwing as the behaviour if you are calling it from a non-noexcept context (eg. in a `try` block or non-noexcept function) and returning an ADT / error_code if you are calling it from a `noexcept` context? (Probably you need the inverse of a `try` block for this, eg. a `noexcept` block too)
For those who are already in Qt land, there is a task library called [tasks](https://github.com/mhogomchungu/tasks/)
Checked exceptions is probably the most useless and confusing feature in Java. The only thing that you can infer from the "throws" clause is what types of checked exceptions a method can throw. Any method can throw anything that is instanceof RuntimeException or Error without declaration. Which means simply that any method can throw no matter what, defeating the purpose of exception declaration.
First, I like exceptions. The disadvantages expressed in my post aren't my opinion but opinions I've heard. So when I write a library I try to appeal to both people, those that want to use exceptions and those that don't. This is what I meant with compromise. &gt; Somehow the author believes that exceptions are rare beasts that are almost never used, And in my experience this is true. If you ignore `std::bad_alloc` (which cannot be handled in most applications anyway), most functions don't throw exceptions. &gt; That's a value judgement that I find questionable. It isn't questionable. It is harder to write generic container if you assume that every operation throws. Writing a container of ints is trivial compared to a container of Ts. &gt; RAII is not 'overhead' (as claimed in the article) I've never claimed that RAII has overhead. RAII is great. (If you meant my defer comment: RAII has a certain verbosity if all you want is "execute this particular function at scope exit") &gt; You cannot take a language that uses exceptions pervasively and then somehow excise them. See above: I don't think C++ uses exceptions a lot if you don't consider std::bad_alloc an exception. &gt; Moreover, the author could just as easily take his own advise and wonder why so many people are perfectly happy with exceptions. As said at the start: I'm happy with exceptions. Other people don't. I want to appeal to those as well. &gt; This seems worst of all worlds: you always pay the price for error handling using return codes even if you don't have errors, you always get extra boilerplate on any function call, and you still cannot return errors from constructors or overloaded operators. No, this is better compared to the alternative you need when trying a compromise: Writing two versions of every function. &gt; I completely disagree with that. What the author is doing is not error handling, what he is doing is fighting the language to make it do something it was never supposed to do. That is what makes it difficult. I'm not fighting the language. Return types aren't fighting the language. 
I am curious, what are you using as a project description and/or build system and what is the motivation for this?
&gt; It isn't questionable. It is harder to write generic container if you assume that every operation throws. At least it is possible. How can you make a generic container with all those fancy return codes for some type which can fail to move or copy but not allowed to throw from move/copy constructor? 
Thank you :-) That's the info I was looking for!
Yep
If you ignore out of memory, move constructors are nothrow. And for copy constructors you have to use a .copy() member functions. It isn't how C++ intends to do it, but it is definitely possible.
After reading multiple examples, I realized the whole task requires RandomAccessIterators, but you did not specify it clearly: &gt; You have 2 sorted ranges and you need to find the element that would be median after merging 2 sorted ranges. If we have trees (which are sorted by default), can it be O(log n)?
&gt;Swift has `throws`, but you don't say what you throw In Java, that's `throws Exception`. It has the same effect because all exceptions including checked exceptions derive from `Exception`. This shouldn't be used lightly. &gt;Java also requires you to duplicate the exception boilerplate in multiple locations. ?
I understand you fine. The crux of our disagreement is this: you say that anything wrapped in an `extern "C" {}` block is a C function, even something that can throw a C++ exception, can be called a C function. I claim that this is a stupid thing to do. To take you down a slippery slope, consider this: from a function declared as `extern "C"`, using FFI of language λ (who throws λ-style exceptions), I call λ code, and that throws a λ exception. This is the root of your folly.
You changed the challenge to "make it error safe while complying with an unspecified bigot boss". :-)
&gt; The crux of our disagreement is this: you say that anything wrapped in an extern "C" {} block is a C function, You misunderstand. I used `extern "C"` in my code just as an example. I literally mean _C functions_ can exit due to exceptions, so that in C++, if you call a C function you cannot assume it never exits via exceptions. &gt; I claim that this is a stupid thing to do. ... Uh, well who cares whether it's stupid or not? My point is that it's something that happens. Whether it's stupid or not is entirely irrelevant. &gt; To take you down a slippery slope, consider this: from a function declared as extern "C", using FFI of language λ (who throws λ-style exceptions), I call λ code, and that throws a λ exception. Yeah, okay. And? 
&gt; If we have trees (which are sorted by default), can it be O(log n)? I think trees here do not change complexity. Sorted array is like a frozen tree(you can not modify it easily as tree). So for example lookup in the sorter array is O(log n), tree traversal for lookup in tree is O(log n). 
So what's the total complexity of the task? You stated it can be O(log n) for 2 sorted ranges of continuous memory, but can it be still logarithmic when we have 2 tress (unable to jump arbitrary distances over nodes)? 
Whoops... if you don’t understand the ‘lambda’ slippery slope, then nothing, you are right on all accounts:-).
Not localising ‘technical’ errors is perfectly fine :-)
&gt; So what's the total complexity of the task? You stated it can be O(log n) for 2 sorted ranges of continuous memory, but can it be still logarithmic when we have 2 tress (unable to jump arbitrary distances over nodes)? 2 sorted arrays are given as input. See the link here: https://leetcode.com/problems/median-of-two-sorted-arrays/description/
&gt; I think a lesson to draw out of this analysis is that it is useful to provide at least one minimal interface, that perfectly satisfies the most basic need. I was surprised when I saw that `std::basic_string::replace` has [10 overloads](http://en.cppreference.com/w/cpp/string/basic_string/replace) but none allows thing such as: std::string str = "foo bar foo bar foo bar"; str.replace("foo", "baz"); `std::regex_replace(str, "foo", "baz")` can be used instead, but I predict it has much worse complexity
`vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2` no `const`?
Well, while it may seem nice (and may be nice), I find that I rarely use fold/accumulate/reduce/etc. function with some "default" value (usually the zero). More often than not you need to have something more meaningful there. For example even in the simple case with multiplication, `0` won't do.
&gt; If you ignore `std::bad_alloc` (**which cannot be handled in most applications anyway**)... (emphasis mine) Eh, I have to take issue with that. What is meant by "handled"? Reported to the user/some log? What is meant by "cannot be handled"? Program must crash? I think not. Merely abandoning the current operation is *just fine* in a fair number of situations. Consider the following situations: * code is an editor of some fashion; user pastes something big into it, that encounters OOM; should the program... crash? (and lose any unsaved work?) * a multi-threaded server of some fashion; a series of big requests come in (or perhaps just one, similar to the first bullet point; say that it's some XML and creating the DOM fails; should the sever... crash? * a batch of some sort, with a series of independent steps; one of them is a calculation so big that it hits an OOM; should the batch... crash, and abandon any next steps? The actual reality of these situations is that there can be plenty of memory, just not for the action needed right there, right then. Saying "can't be handled" makes it sound more drastic than necessary. In all of the above situations, upon abandoning the operation, there is a **big** chance that other things can be done; more importantly, a nice error can be reported to the user. If you consider building the DOM or that calculation from the second/third bullet point, abandoning the operation means climbing up the stack and freeing memory ass we go - so there is in fact *plenty* of memory left. People are throwing "can't do anything upon an OOM" around *way* to lightly... Finally... he who is writing a *library* can't *possibly* presume anything about what happens after an OOM. That would be like entering someone's house and taking a crap on the carpet. They have to react to an error, give up, clean up and report the problem to the caller.
Asking measurable evidence regarding the specific assertion you made has nothing to do with being "polite" or not. It is about establishing facts. You can change your assertion to opinion, and that is fine.
vim + YouCompleteMe + vim-clang-format does it for me.
So are you going to write C++ code in the future making the false assumptions that C functions will never throw or not?
Thats why there is no overload with custom function but without an initial value in the proposal.
Excellent work on the measurement! I have a request: could you maybe also add a case for just a simple for loop? for (auto i : v) results.insert (i); I guess I'm just not such a big fan of those rather imposing looking algorithms that seem to replace much shorter, and at least to my eyes simpler, for-loops... Just curious if the performance actually makes a difference or not. 
Have you checked out Qt? https://www.qt.io/
What you want to create is java checked exception syntax. It look nice on paper, but it's horrible to use in practice because you can't modify your code without updating the whole call tree (especially annoying for library) to handle a new error case.
The only thing that bother me in c++, is that you must write `try` to handle exception, in a world where everything may throw. Why can't we just have implicit try from the beginning of the current code block? void foo() { foo0(); if(foo1()) { bar(); baz(); catch(Exception e) { // exception caugh from bar or baz but not foo0 } foo2(); } foo3(); }
I appreciate that it isn't clear to you why I am not comfortable with the way you are acting, but I have already left this conversation. If you're genuinely interested in the data, I'm sure other Rustaceans over at /r/rust would be happy to help discuss their experience.
Isn't Qt just for making GUI applications?
Did the python lib come from C? 
Well, I see it being useful for `std::accumulate` but why not just use `reduce`? It has overload without an initial value.
no clue, i do imagine though
It has a lot of modules, you don't have to use the GUI ones. I have used it for a headless server before.
It couldn't have been written in python of course, so it might be worth checking to see if it is usable directly from C.
No its not impossible, ive heard and seen C and Cpp files being downloaded and compiled in certain libraries so i imagined that it was initially C because basically everything awesome is written in C
Does it work well with VS 2017? I've tried to use it had no luck. What is your experience with it?
&gt; project description and/or build system [JSON compilation databases](https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#json-compilation-database) are used to configure the 'project' paths and to extract the appropriate compiler flags. This is de-facto a standard way of interfacing with any of the `Clang`-based tools so it is the same with this one as well. &gt; what is the motivation for this? Curiosity. (Much) Fun. Expanding horizons. Building something which does not exist in such a form (or at least that I am not aware of). Not a fan of IDE's :) 
I have not used it with Visual Studio, I used Qt Creator with MSVC2013, sorry. But if there is a C version of that lib, that would of course be better to use. 
I assume the person writing the problem skeleton just forgot const.
*time for some rvalue binding errors!*
Does ConcurrentQueue not have a non-blocking enqueue function?
Qt Creator and Qt is written in C++, but I don't know need to check
This looks fantastic! How long has this project been going? It looks like it must have taken an enormous amount of work.
deoplete is for auto completion, deoplete-clang provides clang support for the autocompletion. ctags makes sure that vim understands the code and my own code so I could use goto definition, goto source, etc with the vim commands and hotkeys. I should check (and will now :) ), but I dont think deoplete or clang_complete and such offer that. Deoplete is really easy to set up btw: just pull it in with vim-plug, add 5 or so configuration lines in your init.vim and you are all set...
Out of my own curiosity, does this code compile? You return a lambda capturing the iterator in register_callback() which then calls erase on the list. You never captures the list itself. Is this allowed? I ask because I wasn't sure if there was something I didn't know about using lambdas. I would have expected the following: return [i = --callbacks.end(), &amp;callbacks]{ callbacks.erase(i); };
I am actually writing a text editor as a hobbyist project [ETME](https://github.com/azy2/ETME) and I'm almost at the point where I want to start implementing things like syntactic/semantic groups for smarter navigation, syntactic/semantic highlighting, linting, and autocompletion and I've been thinking about where to start. Would your project be suitable for these goals? If not where would you suggest I start looking? You seem to have for more experience with clang than I do.
I meant if there is a C version of PyAutoGui
If you want me to read what you have to say, have the common decency to write in halfway-decent English. This was just painful.
If it is considered bad to link to your own writings I apologize, I assume it is ok, but if not I just want to disclose. :)
Contracts don't handle user input. That doens't make sense.
&gt; This looks fantastic! How long has this project been going? It looks like it must have taken an enormous amount of work. Thank you. The whole project is around 3-years old but the main idea (`libclang`-based implementation) started around mid-2016. &gt; I just saw the list of requirements, is there a way to put it all in one directory so that it is wrapped up into something modular? It might be an option but I am not sure how would I wrap C &amp; C++ toolchain into the installation directory, or Python2 or Git ... :) So more or less all the requirements are the ones which are expected to be installed on most developer machines. The ones which are not expected to be installed are handled by the installation script. &gt; My experience with setting up complex vim environments hasn't been great so far. Install script will make sure that you get a sand-boxed Vim environment which is not going to mess up with the configuration of your default one. So in other words, (ideally) everything should be set-up after you run an installation. In case of any problems, please open an issue.
Yes, this, with a warning: I used its flow graph feature and couldn't figure out from the docs how to make it *not* use aggressive work-stealing. A story: an embedded 2-core machine with HT (4 threads in total) didn't have the capacity to do all processing I needed when I used TBB. So I threw it out, replaced with `std::thread` and TBBs blocking concurrent queue and shaved off 30% of CPU utilization -- ca 1 core. Suddenly, the machine was more than capable of doing what it was supposed to.
I agree. I think it would be nice to have version 4, but I don't like version 2 and 3 for the reason you mentioned.
Ooohh
No, no need. If some monkey writes something that looks like a C function, but is in fact a C++ function that throws, we (I) will take that change back. We have code reviews and we have **a lot** of `extern "C"` code written in C++. We know how to do that.
1. For some reasons the article was incredible hard to read. 2. I still don't understand what's the main problem with flat_map is. 3. Your criticism of unordered_map is that it is much to type. Seriously? Are you also against namespaces because it is more to type? 
Some like it painful. PS: I'm French and doing my best. Feel free to correct me, it will be more productive
enqueue is always non-blocking; it just enqueues the task (std::function) into a queue and the worker threads eventually dequeue and run the task. The task might be blocked on the worker if it's time-stamp is smaller than the queue's barrier time-stamp but this happens on the other end of the queue.
Note about the algorithm: - I would return `NaN` for an input below 0, - and I would either deal explicitly for the case `input == 0.` or add a comment. Because in this case `std::fabs(guess - input/guess)` is `NaN`, and we're relying on `NaN &gt; epsilon` being always `false`.
&gt;What about proxy iterators, like vector&lt;bool&gt;::iterator Ah, yes, I always seem to forget about that one. &gt;Update: you probably want std::iterator_traits&lt;inputIt&gt;::value_type Agreed.
&gt; how many execution paths **could there be** in the following code? One of the problems is you don't know how many execution paths there are. Without reading the docs, you don't know what might intentionally throw or not. Even with the docs, unintentional exceptions might leak through because the the "not throwing" function you are calling might accidentally call a function that throws. Now, getting back to the worst case example, some things that help - In Rust, the signature for operators don't allow failure - Getters, in Rust, rarely fail - As I mentioned, Rust doesn't have failable collections atm So with those in mind, the worst case for this would be Result&lt;String&gt; EvaluateSalaryAndReturnName( Employee e ) { if( e.Title() == "CEO" || e.Salary() &gt; 100000 ) { println("{} {} is overpaid", e.First(), e.Last())?; } return e.First() + " " + e.Last(); } (I took the liberty of changing out `cout`to a variadic function since I'm taking the assumption that operators can't fail). This leaves only one failure point (3 for the cout version).
&gt; However, T may or may not be the same as typename Iter::value_type which can lead to surprising results and/or unnecessary type conversions. I always thought this was a feature. For example, `T` could be a `Point` type et the container could have values of type `Vector` (like mathematical vector). A `Point` added to a `Vector` makes another `Point`. Et you could use `std::accumulate` event if the two types are totally different. Moreover, in this case, the initial value is important and may not be the origin. An example: ``` #include &lt;iostream&gt; #include &lt;numeric&gt; #include &lt;vector&gt; struct Point { int x; int y; }; struct Vector { int dx; int dy; }; Point operator+(Point p, Vector v) { return { p.x + v.dx, p.y +v.dy }; } int main() { std::vector&lt;Vector&gt; vecs = { { 1, 0 }, { 0, -1 }, { -1, 0 }, { 0, 1 } }; Point init = { 2, 2 }; auto end = std::accumulate(vecs.begin(), vecs.end(), init); std::cout &lt;&lt; end.x &lt;&lt; ',' &lt;&lt; end.y &lt;&lt; '\n'; } ``` Prints `2,2` as expected. 
Isn't begin()==end() for an empty set?
The code went through some revisions and a lot of different strategies for queuing the work. The first version was a simple mutex-protected queue. The mutex was a critical bottleneck so wrote a version where each worked had it's own queue and the work was distributed in round-robin fashion on the enqueue side. This created unbalanced queues so had to implement work stealing; but this brought us back to having mutex bottleneck. Then I experimented advancing the round-robing so that each worker/feeder advanced &lt;prime number, different for each queue&gt; number of slots which reduced collisions. Some variations later I wrote a lock-free queue and internally distributed the work again across multiple queues. This worked "OK" but it was difficult to enforce strict ordering for the tasks when wanted serial behaviour. Then I found Moodycamel's ConcurrentQueue and plugged it in. It has internally multiple lock-free queues and does really good job on muxing and demuxing the objects you push and pop into it so that externally it looks like one logical queue. The next step was to take the time-stamp based barrier code from older version and use it for serialisation; it is virtually free when not used. The barriers come at a cost as they stall a worker so had to implement cooperative wait so that when a worker is "waiting" it will help consuming work on other queues but only when the ordering (time-stamp compare) passes. This also solved the deadlock problem I experienced with Grand Central Dispatch. GDC also creates more threads and then deletes them. The new Microsoft thread pool implementation has heuristics to avoid thread explosion but I don't deal with any of that. The design I chose has a fixed number of workers and designed the queuing work around that instead. Let's put it this way: I have explored the problem in more detail that I should practically have, I slightly went overboard couple of years ago. I literally hunted down microseconds. Then I realised that the bottleneck had shifted to the std::function ; this is very expensive primitive to construct (in relative terms). I tested with custom solution where the task object was a class but the problem with those is that they are really awkward to use. The performance nearly doubled but it's not worth it in my opinion because if the API is annoying to use you won't use it and it does no good to anyone. This is the root for my recommendation that don't enqueue too light tasks so that the overhead won't matter too much. Currently relatively old 3770K can do ~10M tasks per second so for graphics programming use where I use this code the most this translates into 100K tasks per frame at 100 fps which is already very fine granularity. YMMV so I cannot recommend this to every possible use, as usual I am trying to please myself foremost (this is the disclaimer). The design accidentally took the shape of GCD due to the process the coding effort went through as outlined above. Any questions or criticism are both welcome. :) 
Looks like it is Linux only? Probably worth to note somewhere..
&gt;Did you consider the overloads of std::reduce that take no initial value? I glanced at them, but I should look again in more detail. &gt;You don't find them optimal because they do std::iterator_traits&lt;inputIt&gt;::value_type and not decltype(*first)? No, I should have used the iterator_traits.
&gt;I find that I rarely use fold/accumulate/reduce/etc. I work in scientific computing, so I have a tendency to use them often. That's probably why I was bothered by it. &gt;More often than not you need to have something more meaningful there. For example even in the simple case with multiplication, 0 won't do. Indeed. The interface I have would still allow a non-default `init` value. I just don't want to have to specify one for the basic case of using the built-in addition accumulator.
That's a good point. In my version, my_std::accumulate(begin, end, std::multiplies&lt;&gt;()); would be perfectly valid (i.e., it compiles), but definitely wrong. Perhaps I should scale back the change to just adding an overload for the simple built-in additive accumulator version. This would also get rid of most of the items in the "issues" that I don't like about the proposed changes. And adding a single overload would probably be more amenable to getting approved by the LEWG.
Indeed. I'm not suggesting we should take away the ability to specify a default value. Rather, I want to avoid incorrectness in the simple case (from the cited std-proposals mailing list) of double x[] = {...}; std::accumulate(x, x + N, 0); // truncates my_std::accumulate(x, x+N); // "Does the right thing"
For the record, all that has been consistently ask is evidence to establish a specific assertion as a fact.
Right now it is, although there are no bigger obstacles to port it to another OS. But easier to be said than done ...
&gt; Does it work well with VS 2017? yes, without problems. What didn't work for you ? 
ADTs also need some language support that makes checking the return types transparent. For example, the Maybe monad in Haskell is much easier to use because of Haskell’s ‘do’ syntax that hides all of the implicit checking.
Note to self: Start using std::unordered_map by default instead of std::map.
everything from installing to actually making it work within VS2017 Is there some documentation or step by step guide or even a youtube tutorial
Also thanks for the link
&gt;&gt; std::binary_search because when you need an iterator, you use std::lower_bound
Well, then in some cases you might have to start worrying about the hashing and collisions. std::map is rather fool-proof.
And now your generic container must include facilities for detecting if a type has .copy() and .construct() methods and some workarounds for types which didn't. Looks like this approach isn't much easier compared to containers for throwing types.
Are you familiar with rtags? If so could you contrast their approach with yours?
I got the 7th edition of "Sams Teach Yourself C++ in One Hour a Day", I really enjoyed it. They have the [8th Edition](https://www.amazon.com/One-Hour-Sams-Teach-Yourself/dp/0789757745) out now, which covers C++17.
It only worked because that toy example declared `callbacks` as a global. If it wasn't, then, yes, you'd have to capture it somehow.
This is even more complicated, because some chips have fused multiply and add SIMD instructions I would start with godbolt.org
Unless you know what you're doing or you're willing to go in and edit the assembly directly the general rule of thumb is write everything as simply and straightforward as possible. If you make your loops as obvious in implementation as you can the compiler is more likely to recognize what you're doing and be able to preform massive optimizations to your code. The only exceptions to this rule are a) if you can prove the compiler is not optimizing where it should and b) in order to improve cache performance. Always consider your memory layout and try to always maximize spacial locality (reorder your loops to use stride 1 access, etc) Clang and GCC both produce very fast code. You may also be interested in openMP for parallelization.
This should give you all the info you need. https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list
https://fbb-git.github.io/cppannotations/ Free and regularly updated. Frank (the author) has just added the c++17 filesystem functionality!
Please put a note in the article where you say that, apart from experimenting, the normal and right way to do that is: results.insert(begin(v), end(v)); Which is obviously faster because you allocate all the memory at the start, instead of pushing one element at the time, reallocate, move the old elements, etc...
&gt; Your criticism of unordered_map is that it is much to type. Seriously? Are you also against namespaces because it is more to type? Yes, but it is mostly about readability, excessively long names are hard to read. Yes if they are too long. My good friend :P Titus (agrees)[https://www.youtube.com/watch?v=xu7q8dGvuwk#t=26m14s].
&gt; std::map is rather fool-proof. Funny you say that since one of my arguments against flat_map is that it exposes linear insert to users. Also wrt collisions - I have never heard this being a real problem except when your user is intentionally malicious.
I grepped my trips, found 44 occurrences of std::accumulate and in 2(!) cases iterator::value_type and the accumulator type were the same. I call that a pretty useless default. But then 0 of those used std::plus...
I grepped my repos, found 44 occurrences of std::accumulate and in 2(!) cases iterator::value_type and the accumulator type were the same. I call that a pretty useless default. But then 0 of those used std::plus...
uughhh why is your editor not implemented as a plugin ontop of the editor uuhghh
The main problem with `flat_map` is the big O of insertion and deletion. `flat_map` is proposed as a drop-in replacement for `map`, and therefore boasts O(log N) number of comparisons for insertion and deletion. However, once again the implementation is over-constrained (requires contiguous storage) and this results in a hidden penalty: while there are only O(log N) comparisons for inserting or deleting, **there are also ϴ(n/2) moves!** This completely changes the complexity of algorithms using the `map`! --- Also, while the requirement of having the elements sorted and contiguously stored makes for lightning fast iteration, it makes for sub-par look-up performance. See, binary-search is NOT cache-friendly, or specifically, it's not *prefetch*-friendly: - whether to go left or right is random, trumping the branch predictor, - whether to go left or right changes which cache-line should be prefetched... and prefetching both may well be worse than wait on the comparison. --- Personally, I wish that `flat_map` would drop the contiguous storage requirement. If someone wants fast iteration on a sorted collection, they can very easily use a sorted vector by themselves, all the algorithms are there in the standard library. Droping this requirement opens up the usage of *more complicated* data-structures, which provide: - true O(log N) insertion/deletion/look-up, - better cache behavior. A "simple candidate" is to layout a binary search tree in the array "breadth-first". Take you red-black tree, put the root at 0, the next level at 1 and 2, the next at 3-6, the next at 7-13, ...: - it's less trivial because you again have to deal with rebalancing, - no parent pointer/child pointers, the relationship is embedded in the index (parent_index is child_index / 2), - excellent pre-fetching behavior, the "left" and "right" children are adjacent. This would be my "bare-minimum" implementation of `flat_map`. Afterwards, you can get fancy: - separate keys and values (drop the `pair`), and you have much better caching behavior on look-ups, - consider the [Eyzinger and van Emde Boas layouts](https://arxiv.org/abs/1509.05053). --- The C++ Standard has made the mistake already of *deriving the specifications from the implementation* when it standardized `map` and later `unordered_map`, to the point that despite only specifying an interface, the actual implementation is nearly imposed by the standard. If it's to get a new container, I wish for once the committee would pare down the requirements so that we do not get stuck with low-performance implementations.
Or equal_range, or whatever it's called.
As an aside, I strongly recommend upgrading to VS **2017** 15.5 Community, which was released yesterday. The optimizer team shipped significant improvements in 15.3 and 15.5, with a VCBlog post coming in the near future. (And of course, 2017 contains many C++14/17 conformance improvements in the compiler and libraries.)
I am afraid that any discussion of foregoing exceptions needs to address the elephant in the room: **What do you do with `std::bad_alloc`?** As long as allocating memory can fail, most C++ functions can fail, giving rise to a LOT of boilerplate. The simple solution is to consider that `new` cannot throw: it either returns a valid pointer or aborts. This solves 99% of the problem really, and suddenly your function zoo is sane again. However, some people do use C++ because it allows their program to recover from memory allocation failures gracefully. And keeping `bad_alloc` is not really possible if 3rd party code fails hard when it occurs.
This is not too difficult. You just need to write a free `copy()` function that invokes `obj.copy()` if that's available, else uses the copy constructor and is marked noexcept.
That's a nice list, but it's also getting somewhat dated. I don't know of better ones yet, though. 
&gt; People are throwing "can't do anything upon an OOM" around way to lightly... Well, maybe, because the exception itself is rarely thrown (IIRC allocation under Linux will never fail). I've never encountered it in my code and I've never had a (non-Java) program run out of memory (OS swapped itself to death well before that). Sure, you can do something graciously. Or you can just invoke a handler function, report the error, save if possible, and terminate. &gt; Finally... he who is writing a library can't possibly presume anything about what happens after an OOM. That would be like entering someone's house and taking a crap on the carpet. They have to react to an error, give up, clean up and report the problem to the caller. Well, I'm not. I'm invoking a handler function the caller can set. I don't allow the caller to recover from it though. (To be more precise: I throw an exception if they are available, else invoke the handler)
&gt; &gt; So are you going to write C++ code in the future [assuming] that C functions will never throw? &gt; No, no need. If some monkey writes something that looks like a C function, but is in fact a C++ function that throws, we (I) will take that change back. There's no need for you to ever assume that a C function doesn't throw? So you write code as if C functions can throw?
My over used C++98 AddressBook class maintains a list of heap allocated Contacts in a std::vector. Let's just assume it's better if they're heap allocated. The AddressBook owns the Contacts. In its destructor, it goes through the vector and deletes them. It provides various methods to query the contacts (e.g. find by name) and provide non-owning raw pointers to Contacts as needed. It even provides const/non-const iterators so a user of the AddressBook can iterate over all the Contacts as it pleases. Now my amazing C++ 11 AddressBook is trying to use a vector of unique_ptr to store the Contacts. All my query methods that return non-owning raw pointers work OK, since no transfer of ownership is desired and participation in ownership semantics is not required, I can just return a raw pointer using get(). This is consistent with Herb Sutter's advice for example. But now my iterators are returning unique_ptrs, which I don't want. Because that enables for example iterating clients to reset my pointers, which I don't want. I didn't have this problem before. What should I do? 
Thank you, I didn't catch that.
It is. All standard containers have `c.empty() =&gt; begin(c) == end(c)`.
I've heard the new "C++ Templates" book is good (Vandevoorde, Josuttis, and Gregor). It has C++17 stuff. Also the old one was amaaaazing.
Have you tried comparing to rtags? It seems very similar in spirit.
A tangent, but as I understand, `std::fma` is primarily about _correctness_ and not efficiency. `std::fma` guarantees mathematical qualities about the precision and amount of rounding in the multiply and accumulate operations, independent of compiler optimizations or hardware support for FMAC. The simple arithmetic _may_ be computed as fused-multiply-add or as non-fused MAC as it's entirely up to the implementation to decide. If you need FMAC for correctness on all platforms, compilers, and configurations, use `std::fma`, even though it may not optimize as well on all implementations. Of course, when targeting hardware with FMAC, a good optimizer should produce correct _and_ fast code using `std::fma`. :)
&gt; Start using std::unordered_map by default instead of std::map. Just remember it is unordered :) 
I believe there is already an `init`-less overload of `std::reduce` that has this behavior. If I understand the suggestion, this proposal would simply make the other reduction algorithms consistent with this feature.
Eh... there's myths built around overcommit and the OOM killer. It is just not true that allocation will never fail. The default Linux mode (`overcommit_memory`) is "heuristics", and that will refuse allocations without reaching for `kill`. Address space fragmentation can result in allocation failures (albeit realistically only for 32-bit processes). There is overcommit mode 2, which is "no overcommit". It is possible to take "valuable" processes out of the overcommit game. Outside of UNIX... Implementations of the C library on the other relevant platform, Windows, do not use overcommit for malloc. There are systems without virtual memory. But probably most importantly, `malloc` is specified to return null and `new` to throw (with the possibility to be rigged using `set_new_handler`), and *nothing* is specified to kill the program when reading/writing the memory that the program 'legally' obtained. *We should program to the specification.* &gt; you can... terminate Terminate the whole process? That's rather harsh, don't you think? (see examples above). I would rather say termination is only appropriate for "simple" processes who take some input, do stuff and exit. For anything else, much less so. (Albeit the system can be made to use multiprocessing to recover from OOM). 
You basically have two options. The first, and simpler option, is instead of exposing iterators, you can instead have a function `for_each` that takes a lambda and applies the lambda to each element in the vector, passing it in by reference (i.e. dereferencing the unique_ptr). In this way the method of ownership is an implementation detail. The second approach is to write your own iterator. A relatively less verbose way to do this than writing it from scratch, where we just piggy back on an existing iterator: template &lt;class T&gt; struct deref_iterator : T { deref_iterator(T t) : T(t) {} auto&amp; operator*() { return *T::operator*(); } }; struct my_wrapper { using my_list = std::vector&lt;std::unique_ptr&lt;int&gt;&gt;; using iterator = deref_iterator&lt;my_list::iterator&gt;; auto begin() { return iterator(m_l.begin()); } auto end() { return iterator(m_l.end()); } my_list m_l; }; int main() { my_wrapper x; x.m_l.push_back(std::make_unique&lt;int&gt;(3)); x.m_l.push_back(std::make_unique&lt;int&gt;(5)); x.m_l.push_back(std::make_unique&lt;int&gt;(7)); for (auto&amp; y : x) { std::cerr &lt;&lt; y; } } This prints out the integers themselves (not their addresses). Note that I prefer to work with something that dereferences to a reference, rather than a pointer, assuming you keep the invariant that none of the unique pointers in the vector are ever null (which makes sense IMHO). Also you probably should handle operator -&gt;.
&gt; However, once again the implementation is over-constrained I think design (for very narrow window where flat_map is good (think 10-30 elements)) is OK. And more importantly it needs to be fixed. Because game/HFT people will just stick to boost::flat_map if there is a chance gcc/clang implementation may not be like boost::flat_map. But to me this is again argument to avoid standardizing it. It is a container targeted at specific usage. And that is fine, just IDK why it should be in std:: &gt;parent_index is child_index / 2 I tried once to implement flat_map as a binary tree, where index 0 is root, 1,2 children, 3,4 are children of 1... It was not faster. I was surprised and frustrated and quit that experiment :), but if you ever try it out feel free to post results here, I would be interested if you got different results. 
365 days, about 20 years, 1 hour/day = 7300 hours. Seems lacking in time investment required.
&gt; because you allocate all the memory at the start Assuming, of course, that `begin(v)` is a random access iterator ;-). 
I'd aim for a good C++14 book at this point. C++17 compilers don't quite exist yet, and best practices are still being ironed out. You could do worse than Scott Meyers' Effective Modern C++
Everyone else is wrong, not you, never you. 
https://github.com/google/or-tools/blob/master/ortools/base/threadpool.{h,cc} 
Here is a toy one. template&lt;class T&gt; struct mutexed_queue { T pop() { auto l = lock(); cv.wait( l, [&amp;]{ return !data.empty(); } ); auto r = data.front(); data.pop_front(); return r; } std::size_t queued() const { auto l = lock(); return data.size(); } void flush() { auto l = lock(); data = {}; } void push( T in ) { { auto l = lock(); data.push_back( std::forward&lt;T&gt;(in) ); } cv.notify_one(); } private: std::condition_variable cv; mutable std::mutex m; std::deque&lt;T&gt; data; auto lock() const { return std::unique_lock&lt;std::mutex&gt;(m); } }; struct thread_pool { template&lt;class F, class R=std::decay_t&lt;std::result_of_t&lt;F&amp;()&gt;&gt; &gt; std::future&lt;R&gt; add_task( F&amp;&amp; fin ) { std::packaged_task&lt;R&gt; task = std::forward&lt;F&gt;(fin); auto r = task.get_future(); queue.push( std::move(task) ); return r; } std::size_t waiting_tasks() const { return queue.queued(); } void abandon_waiting_tasks() { queue.flush(); } thread_pool( std::size_t count = 0 ) { if (count) start_thread(count); } void end_thread( std::size_t count=1 ) { while(count) { queue.push({}); --count; } } void start_thread( std::size_t count=1 ) { while(count) { threads.emplace_back( [this]{ while( auto task = queue.pop() ) { task(); } }); --count; } } ~thread_pool() { end_thread(threads.size()); for( auto&amp;&amp; t:threads ) t.join(); } private: mutexed_queue&lt; std::packaged_task&lt;void&gt; &gt; queue; std::vector&lt;std::thread&gt; threads; }; 
http://quick-bench.com/uDO8pO9U8DCUeb0L0sJwV9x1sI8 I put that together a comparision of using the set constructor vs. insert with begin/end vs. using a loop ... It seems like the loop is the fastest version (not by much though). What surprised me though is that the constructor version is as slow as using the std::inserter.
I enjoyed: C++17 STL Cookbook Book and Modern C++ Programming Cookbook review on my blog: http://www.bfilipek.com/2017/08/cpp17stl-review.html and http://www.bfilipek.com/2017/06/modern-c-programming-cookbook-review.html
&gt; What surprised me is that the constructor version is as slow as using the std::inserter And you did not noticed the bug?
Just a question( as I have very little knowledge about those functions): Do the semantics of std::fma actually allow the use of hardware fma on x64 or is there some requirement in the standard that is not satisfied by them. Wouldn't be the first time that standard functions aren't as fast as they could be, because they have to guarantee certain behavior in edge cases that you don't care about 99% of the time, but a really happy about during that remaining 1%.
I suspect sorted inserter works on an unordered map. So really it is associative container inserter, not sorted inserter.
Disclaimer: Most of this is guesswork based on things I vaguely remember about msvc, SIMD,, and x86 implementations in general. I might be completely wrong but two things I'd check: Are you compiling for avx2? Does the performance change under ` /fp:fast`? Afaik, hardware FMA is not part of the basic x64 instruction set and I believe, that is what msvc 2015 generates code for by default. As normal SIMD instructions generally have lower precision than classic x87 floating point operations, they might not be allowed inside of std::fma. The other possibility is of course, that the optimizer can't inline std::fma for some reason and hence fails vectorize the code.
That is what i wrote
&gt; One of the problems is you don't know how many execution paths there are. That's true. To the point that counting the number of execution paths is used as a puzzle question. But the alternative is ?'s and ()'s littered everywhere, as demoed above. I think that alternative is worse. Further, I'd also argue that the vast majority of the time -- if not always -- we don't *need* to know the number of possible execution paths. It's easy and simple enough to just assume everything can fail, and rely on RAII to do the right thing when we do. For the uncommon cases where we must not fail, such as destructors or atomic mutations, only then do we need to check that we're using noexcept operations. &gt; Without reading the docs, you don't know what might intentionally throw or not. Use noexcept. &gt; Even with the docs, unintentional exceptions might leak through because the the "not throwing" function you are calling might accidentally call a function that throws. Noexcept will prevent a "not throwing" function from accidentally throwing. &gt; In Rust, the signature for operators don't allow failure I presume then that using "+" for string concatenation is no longer an option? And operator[] with bounds checking would also be forbidden? Seems like this rule would effectively disallow an awful lot of operator functions. &gt; In Rust, the signature for operators don't allow failure - Getters, in Rust, rarely fail This is a very different sort of proposal. So far we've all been quibbling over the right way to report failures, but this suggestion simply says... don't fail.
Which bug?
No mention of `is_detected` or `can_apply`? namespace details { template&lt;template&lt;class...&gt;class, class, class...&gt; struct can_apply:std::false_type{}; template&lt;template&lt;class...&gt;class Z, class...Ts&gt; struct can_apply&lt;Z, std::void_t&lt;Z&lt;Ts...&gt;&gt;, Ts...&gt;:std::true_type{} } template&lt;template&lt;class...&gt;class Z, class...Ts&gt; using can_apply=details::can_apply&lt;Z,void,Ts...&gt;; Now, simply write a template expression that is conditionally valid: template&lt;class T&gt; using dot_size_r = decltype( std::declval&lt;T&gt;().size() ); and ask: template&lt;class T&gt; using can_dot_size = can_apply&lt; dot_size_r, T &gt;; and bob is your uncle. Or is there an equivalent technique in that long article I missed while skimming? 
Somewhat date. Also literally not book on C++17 (not saying there is a good one yet, but it seems to be what OP asked for)
Personally I'd recommend this book (which is especially good if you are used to an old C++ version): http://shop.oreilly.com/product/0636920033707.do Well written, concise, does a good way presenting the language thorough the prism of a few simple features. The other one I'd recommend is this (second edition coming in Feburary if you can wait, otherwise get the first edition, the second will likely contain some stuff on coroutines and some better examples): https://www.manning.com/books/c-plus-plus-concurrency-in-action-second-edition
 std::set&lt;int&gt; results; while (state.KeepRunning()) results.insert(begin(v), end(v)); What's the state of the set after the first iteration?
I'd start with Stroustrup's "A Tour of C++" as a good concise overview of the language and concepts, then move on to deeper dives like the Meyers' Effective series.
I see flatmap as a sorted vector. It is useful in cases where iterating entire collection is is more common than inserting new elements and looking up of elements.
I have my own flatmap which stores its data in a vector, and uses explicit parent/left child/right child/next value fields (implemented as an offset into the vector). Inserts are O(1) (amortized - if the vector has to resize it has to copy the whole thing, obviously), as are deletes, but there is no guarantee that data in the vector will be in key order. The next value field is not strictly necessary, but allows forward iteration without tree walking. It's excellent for storing measurement data, which I need to store rather a lot of, and where I frequently care a great deal about the next timestamp in the sequence. Anyway, this is also a road a design for flatmaps could take... I'm quite happy with it: it lets me manipulate significant amounts of data without requiring an allocation for each value. It needs more memory than the standards version (17 bytes of extra housekeeping per node), but drops the requirement for the vector to be sorted. I tried that too, but for my usecase it was painfully slow... 
I will get downvoted for truth but C++17 is not that big of a update. Scott Meters EMC++ is a good book on C++11/14. After you learn stuff from it you can focus on minor upgrade that is C++17. 
I've stumbled upon it several times but never really tried to use it. It is a bit hard for me to point out the differences just by looking at their documentation. It would be unfair as well :) But definitely looks something on the same track (they implement some stuff which I don't have, and vice versa).
That's basically arguing that because different containers have different behavior and properties, they should not be standardized. That's the main reason we need flat_map and other alternatives to map to be available. So the article's point make no sense to me.
I've got the same question above and I tried to provide an [answer](https://www.reddit.com/r/cpp/comments/7hoix6/clangbased_integrated_development_environment/dqtl1ei/?st=jau5pinv&amp;sh=e2dc0292) for it there. But yeah, it is very similar but still different in some implementation details and features provided.
&gt; which is obviously faster because you allocate all the memory at the start IDK who gave you 5 upvotes but std::set has no reserve. 
Well this project definitely tackles (almost) all of the stuff you've mentioned but you would need means to make the integration possible into your editor. I can't tell what features you have anticipated for your editor and what is already implemented, but I can tell you that to make the integration possible from the Vim editor I have used two of its features: [Python interface](http://vimdoc.sourceforge.net/htmldoc/if_pyth.html) &amp; [client-server](http://vimdoc.sourceforge.net/htmldoc/remote.html), former being used to communicate with the server and latter to be able to communicate the results back to the client (editor).
If I understand you correctly you have a tree but instead of allocating per node everything lives inside a vector until that vector becomes too small and then you reallocate?
&gt;What surprised me is that the constructor version is as slow as using the std::inserter It's doing something else. The others take a fairly small vector, and then insert that same vector over and over into the set. All memory allocation happens on the first round through the vector though; afterwards inserts fizzle out because the inserted element already exists. The constructor version is different: on each round it allocates memory for all elements in the set, and then moves that set over the original set, causing all of its elements to be deallocated. In other words, this version, unlike the others, is drowning in memory management. Anyway, thanks for your excellent work! 
Even if your comment about reserve and the other one about random access are correct, they both missed my point. One of the great quality of the STL is the incredible level of abstraction. Insert a range of elements into a container, that's all what the code says. It does not say anything about the container and it works with a vector, a set, a map, etc.. both as a source or as a destination, and the STL will select the most efficient way to implement that. 
&gt; That's basically arguing that because different containers have different behavior and properties, they should not be standardized. std:: is a general use library. std:: already has a map. Like with vector or string if you really need it to be different(small_vector, different growth factor, different SSO [capacity](https://www.youtube.com/watch?v=kPR8h4-qZdk)) you can implement your own specialized flat_map, small_vector, fbstring... 
For forward and stronger iterators, vector range-construction and range-insertion allocates at most once, because we figure out the distance ahead of time. This is of course an extra O(N) iterator traversal for forward-only and bidi-only iterators, but that's a lot cheaper than multiple reallocations.
any plans for auto-completion? that is an area where rtags is weak
&gt; and the STL will select the most efficient way to implement that. Actually for years(maybe still?) back_inserter was pathetically slow compared to raw loop. So STL is not always that great wrt performance. Additionally .insert with range can not be used with for example copy_if/transform since you do not know elements you are inserting. And IDK if you follow the blog extensively but author is a huge fan of &lt;algorithm&gt;
How does it compare to qtcreator's clang integration?
Its pretty easy to find cheap hashing algorithms at this point, though. Or to use the one already defined for standard library types. I've had a hard time making slow hash algorithms for most custom types, to be honest.
Going this way, why standardize vector? You already have arrays in the language, you can write a "simple" wrapper around it. Also note that flat_map and other proposed associative containers are actually better default choices than map (unordered map is a good default in different contexts). So it is basically a "general use" container (actually a double container adapter, as per the last version of the proposal, which make your point even more moot IMO), except it should have been provided before map. Also, "general use" argument have been discussed to great lengths in several groups, nobody completely agree on what is or not general enough. What get standardized is simply what can be useful to most people and have been asked in a lot of different domains (see SG14 which is the source of the proposal). It is needed a lot, it's well understood and everybody have one probably slightly buggy. Excellent standardization material.
Make a docker file and distribute it.
It's not that minor. Just take the extensions to constexpr as an example. And then there is any, optional, variant, ...
I _believe_ `std::fma` (derived from C99's `fma`) was intentionally specified to be implementable as intrinsics to hardware FMAC implementations on major ISAs. According to [Wikipedia's FMA article](https://en.wikipedia.org/wiki/Multiply%E2%80%93accumulate_operation), IEEE 754 actually makes some of the same requirements on FMAC that the C/C++ library functions make, so any IEEE754 hardware FMAC implementations should satisfy `std::fma`'s requirements. I'm hardly an expert on this topic, though, so you'd be wise to assume I'm probably wrong. :)
Sean Parent discusses the thread pool libraries in his talk(s) on concurrency. He mentions Intel's TBB, Apple's `libdispatch`or his own which he intended to serve as a reference C++14 futures/tasking library https://github.com/stlab/libraries/tree/develop 
Do you have any link for cache optimization? I was wstching a talk about loop optimization and some of his benchmark was looking at cache misses and the intrigued me
&gt; . I would rather say termination is only appropriate for "simple" processes who take some input, do stuff and exit If you hit OOM, you won't even be able to render text in a gui to inform the user that OOM was reached
&gt; The only thing that bother me in c++, is that you must write try to handle exception, in a world where everything may throw. Why can't we just have implicit try from the beginning of the current code block? because you don't want to catch on every code block ? I generally just have a big catch in my main or thread root.
like Xcode?
You might also want to look at CUDA or whatever the equivalent is if you have an AMD card. GPUs are rather good at image processing.
I think you should add “in vim” to the end of the description...
I don't see where he mentions c++17's new filesystem support anywhere.
Haha! That's true, this book is in no way a resource to *completely* learn C++, but it sure helped me get up &amp; running!
structured binding declarations, initializers in if and switch, constexpr if ...
Another thing to note is std:fma is portable, if you're targeting x86 then using Intel's Intrinsics would give you the best performance for FMA since each intrinsic is directly translated into SIMD assembly.
&gt; Going this way, why standardize vector? Because it is useful to almost everybody. &gt;Also note that flat_map and other proposed associative containers are actually better default choices than map flat_map is not a better default than map 
For somebody coming from C++98 EMC++ is the best starting point. Compare C++98 to C++14 changes to 14 to 17 and you may see they are not that big. 
[removed]
sthing is not a wordl
Seconded, VS 2017 15.5 has an amazing array of improvements.
There will never be a std::hash_map for the reasons laid out in the [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2003/n1456.html](proposal). std::unordered_map wasn't chosen to wear out your poor typing fingers, or tax your reading abilities. 
This one looks nice too: tmplbook.com/ Bit more focus on template metaprogramming, I'm ordering in a few days
Actually this discussion is missing an important bit: Good luck summing 1M random integers using int accumulator. Aka in this case (although it is weak signal)0 without LL suffix is at least a bit more obvious than nothing... 
&gt; There will never be a std::hash_map for the reasons I know, I do not claim that C++ will do the right thing, just that it should. 
https://github.com/Eelis/cxxdraft-htmlgen/issues/33 He forgot to pay for the domain lol
I was pair programming with an emacs user, and I really got annoyed by the default emacs key bindings. Ctrl-X + Y for undo? I mean come on, why is it 2 keys, you can't keep pressing two keys at the same time, so it's impossible to undo a long chain of actions. Also other things like Ctrl-S for search, Ctrl-W for cut etc. Now I'm sure if I were to setup my own emacs environment I could find a way to switch to somewhat saner keybindings, but the the ways in which emacs differed from everything else in the world arbitrarily and for the worse made me have flashbacks of how much I hate Apple...
You don't seem to be written in C though, so I guess it's not the base of everything awesome :)
And fold expressions, class template type deduction, guaranteed copy elision...
Oof
11 was revolutionary. 14 and 17 are more evolutionary. 20 might be revolutionary. Right now coroutines look like they can change a lot of things, in ways that concepts and modules will not. A change in the expressiveness of the language. 
would that not just be a map with a custom allocator?
&gt; a real problem except when your user is intentionally malicious This winds up happening, ya know.
Your types might have members of std types.
Unfortunately, from my experience, I'd recommend holding off a bit. I got: fatal error C1001: An internal error has occurred in the compiler. 1&gt; (compiler file 'f:\dd\vctools\compiler\cxxfe\sl\p1\c\toil.c', line 5844) on a lambda call and d:\vs2017\vc\tools\msvc\14.12.25827\include\numeric(65): error C3199: invalid use of floating-point pragmas: exceptions are not supported in non-precise mode in Debug with code that complied perfectly with 15.4...
It works well for small sets. It'll fails badly for large sets. A lot of times a N≈20 set per object comes up and flat_map would make a ton of sense there. Saving on memory alone makes it worth it. The alternative is to restructure some externally managed lookup structure, but why bother? Sure, it's almost syntactic sugar over vector and the STL algos, but I'd appreciate it.
This is not the first time I see you voicing rather strong opinions about C++ proposals or directions taken by C++. I would like to humbly suggest that you write an official paper that can be included in a mailing, or even better, that you show up in person at a committee meeting to defend your point. I believe either of these approaches would be more efficient than merely posting an article (or comment) to Reddit, since that may not reach the audience you intend to reach if you truly want to change something. That being said, while I respect your opinion, I personally disagree with it. I am looking forward to using `std::flat_map` in my code and teaching my coworkers how to use it effectively, which means not all the time.
Can you provide self-contained repros for both of those (source files and command lines)?
OK, I'll do my best to extract them out.
I implemented this thing in MSVC++, so if you have problems let me know :)
Considering std::reduce added overloads that supply defaults this seems sane.
//Using https://github.com/joboccara/namedtype #include "strongTypes/named_type.hpp" using Nxxx = fluent::NamedType&lt;bool, struct XXXTag&gt;; int main() { auto ccm = [&amp;](auto&amp; m, Nxxx z = Nxxx(false)) {}; //Changing auto&amp; to Tf&amp; fixes the bug int tff = 0; ccm(tff); ccm(tff); //Second call causes the bug return 0; } 
Yes, that's correct. And since there are no pointers (only array offsets), resizing the vector doesn't require any work to patch up the tree. I'll see if I can share some code, although note that I've only implemented the API as far as I needed it. 
TIL `printf` returns something (I assumed it was `void`)
https://gist.github.com/anonymous/05aa955f58ddaf07fadd1dfad12bdf26 
Second bug: #include &lt;numeric&gt; int main() { return 0; } /permissive- /GS /analyze- /W3 /Zc:wchar_t /ZI /Gm /Od /sdl /Fd"Debug\vc141.pdb" /Zc:inline /fp:precise /D "_MBCS" /fp:except /errorReport:prompt /WX- /Zc:forScope /RTC1 /Gd /Oy- /MDd /std:c++latest /Fa"Debug\" /EHsc /nologo /Fo"Debug\" /Fp"Debug\bugR.pch" /diagnostics:classic (I've enabled /std:c++latest and /fp:except as compared to deafult empty app settings)
I think I will just propose Version 4 (but using iterator_traits instead of decltype) so that most of the concerns about the funky overload of 2 and 3 aren't a problem.
I was browsing reddit in class earlier today when I came across your link to that page. I saved it with the intention of checking it out when I got done with everything I needed to today. I have to say , thank you for posting that! I really like the way he explains aspects of C++! 
Take a look at this: www.agner.org/optimize/optimizing_cpp.pdf
&gt; I don't think C++ uses exceptions a lot i `std::function` will throw if called when empty. I some `bad_weak_ptr` exceptions when I tried to used `shared_from_this()` in a ctor. Promises and futures will throw in certain states (e.g., a future will throw if you call `set_value` if it already has a value). Yesterday I had `mutex::lock` throw a system error.. which made me notice the failure extremely quickly and fix it. (I was trying to lock an already locked mutex on the same thread, so it would have deadlocked otherwise.) Guess what? All of these are precondition violations. And guess what? They help *immensely* with debugging. Pre-C++11 didn't use exceptions (`bad_alloc` and you could turn on exceptions on a `iostream`). C++11 has increased their usage. 
+1 for effective modern c++. Was given a copy of when I started my current job, and it immediately changed the way I write and think about the language. The prose is amusing and conversational, too. Good stuff.
Hmmm putting that block in fp:fast mode is necessary to get std::reduce to be vectorized; but apparently /fp:except doesn't like that.
On 32bit it is common to hit std::bad_alloc due to the absence of continuous big chunk of address space. But small allocations will still work fine. And 32bit is still with us: emscripten and WebAssembly have 32bit address space.
If you’re looking at doing image processing in C++ you could look at (Halide)[http://halide-lang.org/]. It lets you separate the operation you’re doing from how it’s executed. It can generate vectorised or CUDA versions of your operation. 
It's in the STL section, chapter 18 paragraph 9.
Oh, stop it You... 
All of those are precondition violations. They shouldn't throw exceptions, they should assert. logic_error shouldn't exist.
I have many plans but unfortunately not enough time ... But my wish is to end up with a clang-based engine implementing more or less all functionalities found in IDE's but with the difference of being able to plug it in into any other frontend/editor (i.e. being portable). Refactoring, auto-completion, debugging facilities, cmake integration are just some that I would like to implement support for.
Never used it so I can't really tell but it is probably also Clang-based given the fact that Clang is the default compiler for Mac OS X.
Most of them are just syntactic sugar - they don't change the way you write code.- the exception being constexpr if.
I haven't used it lately. I remember it had support for clang source code model few years back but not in a very good shape. That has been probably changed ...
To be more clear, I don't see the added value of the `try` keyword in c++. If I create a `catch` block, this means that I want to catch something, otherwise I don't want to catch here (but probably at a higher level). And oftentimes, when I want to catch is the whole current block. Is situations like this something common: { foo(); // throw an exception of type Terror, but I don't want to catch it here try { bar(); // throw an exception of type Terror, I want to catch it } catch (Terror e) { // handle e } } Using my proposition it could still be written like this: { foo(); // throw an exception of type Terror, but I don't want to catch it here catch (Terror e) { throw e; } bar(); // throw an exception of type Terror, I want to catch it catch (Terror e) { // handle e } } And the default { foo(); // throw an exception of type Terror bar(); // throw an exception of type Terror baz(); // throw an exception of type TotherError that I don't want to catch here catch (Terror e) { // catch Terror from foo and bar // handle e } // TotherError exceptions are catched at a higher level }
OpenCL works for both but has a steeper learning curve.
O2 is optimizing for size. Depending on your machine it may be slower or faster than 03 (due to size of L1 instruction cache etc). that’s something you should benchmark and find out. Also on GCC you have the -march flag, which essentially tells the compiler to use the machine-specific instruction set e.g SIMD extensions. Ofast is also something to consider, however you should be careful as it disregards Standard compliance. Also take a look at PGO (Profile-guided optimizations) and LTO (link-time optimization) if you really want to get that last bits of performance.
LTO should be considered essential for good performance. When not using LTO you'll get "OK" performance, but with it you'll get "good" performance.
So much but the website is so ugly
With compilation database you need to (remember) to regenerate it every time you add a new source file to the project or change/add an option (say `-I`). Have you thought about how to best handle this? Specifically, what kind of interface/support would you need from the build system? We are thinking about this in the context of `build2` and it would be useful to hear from the "consumer" side, so to speak. For example, what would be the ideal workflow of updating the compilation database from your IDE's point of view?
&gt; &gt; &gt; &gt; &gt; Personally, I wish that flat_map would drop the contiguous storage requirement. Couldn't we instead just have a `std::sorted_associative_container&lt;T&gt;` adapter that one could apply to std::vector&lt;pair&lt;foo, bar&gt;&gt;, std::deque, boost::small_vector or boost::static_vector ? e.g. like `std::stack` and `std::queue`
MSVC is still unbearably slow when configuring a cmake-based project. It takes 7 minutes 30 seconds to configure a project with 15.4, it is down to 5 minutes 50 seconds with 15.5 on AppVeyor. The same project takes ~4 minutes to configure on my desktop in MSVC VM and a hair over 4 seconds on my native desktop (Arch + GCC). Is there any chance this step can be optimised further? The project in question: https://github.com/nih-at/libzip
he meant "something" 
I eventually gathered that.. but why people think it's appropriate to write like that in a semi-technical large block of text like this is beyond me.
Afaik, O3 doesn't exist on MSVC.
&gt; I would like to humbly suggest that you write an official paper that can be included in a mailing I suggest you learn what is a barrier to entry in economics and why it is bad. &gt;I am looking forward to using std::flat_map in my code and teaching my coworkers how to use it effectively, which means not all the time. I am so happy to learn that every programmer working in C++ has Louis Dionne to teach them how to use flat_map. Also I am thrilled to learn that every C++ user is at the level of A9 ones. /sarc
I'm not totally proficient in these things, but isn't the aggressive optimization a bug? Why would I not want to be able to find out if a pointer is null?
Just to add one thing. Here is where STL design with iterators show weakness. If you could insert entire container you could just use: reserve(dest.size()+src.size()) except in cases when src is std::forward_list :P 
It doesn't stop you from checking whether a pointer is null. The point of the example is to show that clang sees the `*i` which is only defined for when `i` is not null and therefore assumes that `i` must always be not null and can make optimizations around that (in this case, removing the conditional). The real bug is the example itself dereferencing a null pointer.
I guess you haven't invented time travel yet ? ( https://static.fjcdn.com/pictures/Learn+c+in+21+days_7ee339_3181601.jpg )
https://imgur.com/hNCw8We Sorted by date, Reddit seems to have issues.. Correct link https://www.youtube.com/watch?v=LNXkPh3Z418
Yeah my comment was referring to GCC mostly. I am not really familiar with the MSVC optimization backend
I predict this change is going to expose a lot of problems.
good
Regarding std::fma on MSVC: as far as I know, MSVC doesn't generate FMA instructions for std::fma, but always calls an external function. See [this example on godbolt](https://godbolt.org/g/gDt1UY). So, in the example above GCC emits a *vfmadd132ss* for both std::fma and for just manually typing out the multiplication. MSVC calls an external function *fmaf* for std::fma, and somewhat depending on your flags, produces either an add + a mul (without fp:fast) or a *vfmadd213ss* and a few garbage moves (with fp:fast). I've had trouble with this before, and never found a reliable way to get MSVC to emit FMAs (without reaching for the SSE/AVX intrinsics).
It's a reddit post not a blog post. That said, "sthing" is the only potentially objectionable thing about his original post, and given its innocuousness, your post is just ridiculous. We use abbreviations all the time, "sth" is maybe more common than "sthing", but you wouldn't object to "e.g." or "i.e." (or other things). Deal with it that the internet is used by people from non-English speaking countries (who still speak better English than most native speakers). Now go play LOL, English monoglot.
Rule number 0: don't pessimize Rule number 1: don't optimize either Rule number 2: mesure Then optimize ;)
CONFIRMED. It's awesome. I wish Josuttis would do the next edition of the runtime library reference. 
So how should I check if a pointer is null? I was under the impression that if(*p) is at the very least the C-way to do it.
No, you don't if(*p), you should do if(p).
You mock, meanwhile your thread gets downvoted and ignored. Great job!
The biggest question I have is what C++ library I can use on windows. Both clang 5.0 and gcc 7.2 (through msys) work on windows, but clang 5.0 doesn't come with a standard C++ lib and libstdc++ from msys doesn't come with filesystem even though it supports c++17. It would be very nice to have a solid open compiler on windows and not have to wait for the longer compile times from msvc.
The standard library of the llvm/clang project is libc++ . It has experimental support for Windows. https://libcxx.llvm.org/docs/BuildingLibcxx.html#experimental-support-for-windows
Love the merry Christmas demo.
&gt; a mixture of libclang-based services Is this using libclang itself, or the clangd language server? I ask because using the language server seems more robust / speedy than libclang... some developers I work with have done something along these lines before clangd existed, and now think clangd is the way to go forward.
Thanks, I'll check that out. I couldn't see any way that didn't involve compiling from scratch with specific flags.
Was it written for c++17 or did they just add some c++17 stuff here and there?
This is still not a big problem: constexpr int alignTo(int value, int align) { return ((value + align - 1) / align) * align; } template &lt;class T&gt; constexpr int type_size&lt;StrangeType&lt;T&gt;&gt; = alignTo(type_size&lt;T&gt;, 8) + 16; If you didn't specialize type_size&lt;&gt; for vector&lt;T&gt; then it's equal to sizeof(vector&lt;T&gt;). In such a case to use FwdMember&lt;StrangeType&lt;vector&lt;T&gt;&gt;&gt; you would have to have vector defined.
Absolutely! I've added a note to clarify that, thanks.
This blogpost by Regehr explains the optimization: https://blog.regehr.org/archives/970
&gt; They shouldn't throw exceptions, they should assert. Says you. The standard committee disagrees. And what's your authority again on the matter? 
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7hpjyg/c_gui_control/dquspe8/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Just use C++17's `std::reduce`, which has an overload with a default value for init.
The value of the pointer is likely still 42 in reality (well, we're in undefined behaviour territory so technically C++ itself has nothing to say on the topic). However, clang has effectively transformed the code to: void f(int* i) { f_unused_parameter(*i); std::cout &lt;&lt; "i is not nullptr" &lt;&lt; std::endl; } It doesn't matter at all what the value of `i` is because the conditional has been removed. Why has it been removed? Because the previous line had `*i` which only makes sense if `i` is not null, therefore the condition can, as far as clang is concerned, be optimised away.
&gt;I mean just in your tiny toy example you forget to close the file in case the malloc fails. Considering that he marked it with "ooops", I'm inclined to believe he did that on purpose.
Thanks for the responses! 
Thanks!
Are they planning to support the new directory structure of vs2017? That would be great. It's quite annoying having to install 2015 toolset only to use llvm with visual studio.
clang can be used with Microsoft's standard library implementation, for ABI compatibility. Unless you have a particular reason for using something else that's probably what you should use.
I don't get the point of the article, also - what's the actual problem with `std::unordered_map`? Too long name? And what about language philosophy - we should not not implement a feature just because someone can use it wrong.
Do you then disagree with my previous comment about why, in many situations this is simply false? Consider bullet point from there. I rather think yours is a blanket statement not based in reality.
Correct me if I am wrong, but: Currently, it is not possible to use Clang or GCC, atleast on Linux, as both libstdc++ &amp; libc++ have not implemented the parallelism TS, right?
it's already like this in GCC iirc.
Intel has a proposal for contribution: https://gcc.gnu.org/ml/libstdc++/2017-11/msg00112.html But beyond that, it seems like implementations are not included at the moment.
Yes, it would be nice to have that included. You can send your pull request when you are done.
It certainly seems possible, yes, and I much prefer your idea to the proposed `flat_map`... though I do think a good `flat_map` (without pathological insertion/deletion complexity) would be a good container to have.
As mentioned by /u/doom_Oo7 [here](https://www.reddit.com/r/cpp/comments/7hqcid/why_standardizing_flat_map_is_a_bad_idea/dquhd0s/) in this case I'd favor an adapter over a generic random-access container. This would it could work on top of `std::vector` but also `std::deque` or some `small_vector&lt;T, 42&gt;`, ...
&gt; but if you ever try it out feel free to post results here, I would be interested if you got different results. Well... the conclusion of the paper I linked is exactly: &gt; After extensive testing and tuning on a wide variety of modern hardware, we arrive at the conclusion that, for small values of n, sorted order, combined with a good implementation of binary search is best. For larger values of n, we arrive at the surprising conclusion that the Eytzinger layout is usually the fastest. The question then is "what is a good implementation of binary search"?
std::async ?
That would risk quadratic performance when reserve() is called in a loop. There's nothing wrong with iterators here.
Can you use Report A Problem in the IDE to submit that bug? I am not sure who needs to take a look at that, and Report A Problem gathers various important IDE information (which is usually irrelevant to compiler/library bugs when we can extract self-contained repros).
It was written for C++11/14/17. They discuss things starting with C++11 and then will explain how 14 and 17 improve things inline. Reading the book, you can see first the C+11 way and then see how the next two improve and how to use them. If there is an instance where the code would be written differently in C++17 they do it. I highly recommend the book, it's one of the best written C++ books I've read.
I will try next time I fire up MSVC, I don't do that very often and only rely on appveyor.
ROT13 is unsafe, we need ROT47!
Well you can either trust me or watch the video I linked in the article and decide if you trust Google developers or not. Regarding language philosophy: why did Herb push to give semantics to i=(i++) + (i++); that was UB before C++17 Language should offer reasonable defaults for general purpose containers. Linear insert is not reasonable default.
The std::min/max improvements look nice. I recently replaced every usage of std::min/max in our code base with by-value versions to work around that particular issue. It was actually a simple find-replace operation because not one place in our code did we use the fact it would return a reference.
&gt; That would risk quadratic performance when reserve() is called in a loop. There's nothing wrong with iterators here. I know that argument, I am not talking about end user calling reserve, but insert that internally calls reserve(and you know the behavior of reserve since you are the implementer). Like this: `auto v = give_me_nonemtpy_vector();` `const auto s = give_me_nonempy_set();` `v.insert(s.begin(), s.end())` is slower than `v.insert_container(s.begin(),s.end()); //diff name because no concepts` If you agree please comment, I am sick and tired of people downvoting me and then ignoring when I explain why I said Java is great :P . If you thought I am saying the end user should call reserve then I apologize for not being clear.
man, this may prove unpopular but i gotta say all these discussions on exceptions are getting to be a bit of a drag.. it just doesn't seem to end!
Interesting. It hadn't occurred to me to inherit from the iterator like that, it's certainly much simpler than writing a wrapper from scratch! I guess the problem with for_each is that you'd also have to have a way to supply a condition so iteration can stop early, as well as a const version. Perhaps that is still simpler, but the iterators are more flexible.
First of all, let me applaud the effort for getting actual data. Especially since even for people who did benchmark years ago, the actual costs may have changed as compilers evolved. Beyond the *cost* of using exceptions versus ADTs, however, there's a reasoning/usability issue. I'm pretty sure that a lot of C++ code doesn't care that much about 1% penalty if it gains significant robustness in exchange. Therefore, what I'd really like to know, is which of exceptions or ADTs lead to more robust error handling. And while my intuition leads me to *believe* that one is better, I've got no idea how infirm or confirm it.
I see your point now. Yes, the Ranges TS solves this by having sized ranges - a range that is a whole set has constant time size even though its iterators are bidi.
Well, you have some boilerplate to write with const either way. And `for-each` is a one liner basically so I don't think that's a big factor. I agree, of course iterators are more flexible. Another big factor is that with iterators you can actually apply other algorithms; after all `for_each` itself is just one algo. If you want to use e.g. `find_if` you can do it with iterators but not with a member function `for_each`. You can solve this problem as well with inversion of control but it starts to get ugly.
Use VS's integrated memory profiling tools? I always use those when working on Windows. Allows you to make easy snapshots and compare them and such.
man that is shocking
STL agreed with me, everything I now do in life will pale in comparison. :) BTW I learned long long time ago about reserve for loop quadratic performance from you, I think you mentioned it once in one video, like GCC had this bizarre but legal reserve behavior where it was calling exact what you requested(assuming it was bigger than capacity).
I've seen this issue thrown around many times. Let me try to carve out two relatively consensus items, and then jump into controversy: 1. Exception handling requires at least some form of RTTI. On most compilers, binaries can be quite a bit smaller if you disable both exceptions and RTTI, compare to both enabled. I've heard 15% thrown around, though it's hard to say, that seems on the high end to me. 2. Exceptions are really, really expensive when thrown. I did this benchmark a while ago, I vaguely remember the number "100", whether it was cycles or nanos I can't recall. Honestly, it doesn't exactly matter: if you are throwing a lot of exceptions things are going to be slow. 3. Controversial (to some) ahead: exception cost when not thrown is within noise in the vast majority of cases. Within noise I mean both measurement noise, as well as systemic noise: different codebases, different alternate error handling techniques (or absence of them), different compilers, etc. You may measure a slight cost vs the alternative in one case, a slight negative cost (e.g. faster than error code and subsequent branching), it just depends. Now to get more controversial: I think the debate on exceptions is clearly heavily influenced by technical culture. And I will pick on the two industries primarily represented on SG14. If you have a game developer and an HFT developer in a room and you are told that one likes exceptions and one doesn't, you can bet with relatively high confidence that the game developer doesn't like them, and the HFT developer does. The obvious response is that: the technical considerations are such that game devs may care more about the costs of exceptions. This is true in some cases: binary bloat is definitely a total, complete, 100% non-issue in HFT. In game dev it may depend a lot what platform(s) you are targeting (I don't have the experience to say). But there's also a lot of disagreement on the pure performance aspects of it. And in this domain it's fairly clear to me that HFT code is more likely to be sensitive to costs of exceptions than game code. Game code is usually doing a *lot* of work in an aggressive timescale. HFT is doing much less work, on an even more aggressive timescale. The number of error checks doesn't scale up proportionally whether you are updating a few hundred coefficients in a model, versus recalculating millions of numbers in a game engine. Despite the theoretical sensitivity of HFT code to any extra costs, if they were associated with unthrown exceptions, very few people in the industry see an issue with this. Carl Cook, IIRC, mentioned this briefly during his CppCon talk. My perspective is that you have to remember: within reason, it is always possible to convert human time back into performance. Anyone that tries to make it like modern video games, or modern trading systems, are celestials palaces of optimization throughout, are wrong. They are highly optimized, yes, especially some parts, but you can always do more. If exceptions work better for your error handling and thereby save you time, even if they had some tiny perf penalty, that doesn't automatically mean you shouldn't use them. It's a trade off. There's a few characteristics of exceptions that mesh well together to use them for certain use cases: - because of their performance asymmetry, you should only use them for rare, severe failures - Because the failures are severe, you are usually going to be out of the critical path: trading has stopped, the game is not rendering, the machine is displaying an error message, etc. So perf is not that important. - It's more severe, and typically more global in scope. So it needs to penetrate more levels up the call stack. This is precisely the case where error codes or even ADT's get annoying. - Because it penetrates more levels, you are less likely to do detailed error handling. You may have a handful of error types, and simply want to log, either retry the application, or exit, or wait, or trigger an alert, or switch modes, etc. - Because it penetrates more levels, and its less detailed, it fits in very well with the fact that emitted exceptions are not part of a function's signature. If you add an error code or ADT to a function, you not only have to refactor that function and its immediate calls, but all functions upstream now have to *combine* another error into what they return. Exceptions save you all this high effort, and (IMHO) low value refactoring. Static types are great generally but I don't think one should be dogmatic.
And how do you define "robust"?
I like your list. One nuance (that you mentioned, but then lost in the list): &gt; - because of their performance asymmetry, you should only use them for rare, severe failures That's only if you care about performance (in that part of the code). Is "user tried to open the wrong file" a rare, severe failure? No, users do that all the time. But loading a file is often not performance critical either. So exceptions are fine there. And, similar to what you mentioned, _most_ code is actually not performance critical.
So much of this debate revolves around what kind of business problems you have. In our case, we don't really do mission critical / lives-or-property-at-stake stuff, so Our customers are okay with asserts and crashes. I suppose "fail early and hard" sums up our philosophy. That said, exceptions can definitely make software much nicer to use for an end user. It also almost goes with saying that exceptions are likely essential for some use cases. I feel like a problem with exceptions, certainly in a large scale codebase of &gt; 500k loc is that they can be a lot of work to implement correctly. How much guard code do you want to write? How much engineering effort can you devote to the what ifs, and does this benefit your end users? You could literally expend thousands of engineering hours for possibly very little benefit.
quite amusing to see a code example that uses memset, seeing as how compilers have deduced that the can throw away this call
"I don’t think anyone promised C99 anything." Best reply ever :) Ignoring that does anybody knows if MSVC performs optimization for moves? like this `MyClass::MyClass(string s): s_(std::move(s){}` `string lval; `MyClass mc(lval);` This involves construction temporary for argument to constructor, then moving it into s_. While in theory you could directly construct s_ with from lval and skip the middleman. I know this sounds trivial, but it is quite complicated since string logic is quite nontrivial so it is hard for compiler to prove asif. 
My feeling is that if your container contains more than 100 elements hash map that allocates nodes in a vector(so you do not malloc for every new insert) should be faster. So if you share code I hope you provide some input data you want to optimize so if I get bored and try to optimize it I can see if I succeeded or not. :) 
&gt; How much guard code do you want to write? Trick question: use of exceptions removes code that would otherwise be there to check and forward error codes/optionals/expecteds/etc.