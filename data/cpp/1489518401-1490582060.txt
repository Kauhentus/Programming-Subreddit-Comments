The quirks are that `reference`, `pointer` and `iterator_category` are not obviously types. Why not add to `iterator_traits` an alias `using reference_type = reference` (and similarly for `pointer` and `iterator_category`) so that you can consistently use the convention `xxx_t&lt;T&gt;` to be equivalent to `typename T::xxx_type`? Then one can simply deprecate the old typedefs `pointer`, `reference` etc. and remove them around C++26. Then all `iterator_traits` nested types are consistently named. 
Alternatively, if the convention in the standard library is going to be that `xxx_v&lt;T&gt;` means `xxx&lt;T&gt;::value` and `xxx_t&lt;T&gt;` is going to mean `typename T::xxx` rather than `typename T::xxx_type`, then it would maybe a good idea to add aliases `value = value_type` and `difference = difference_type` to `iterator_traits`, so that we get `value_t&lt;It&gt;` and `difference_t&lt;It&gt;` Anything to get rid of the `type_t` stutter.
No, I spend most of my time these days trying to push the Ranges TS through committee. On the plus side, http://en.cppreference.com/w/cpp/experimental/ranges is coming along. EDIT: Volunteers are welcome to help beat range-v3's docs into shape.
1. there is a subreddit for that kind of questions 2. code in english pls 3. in your cpp file your function is declared and defined as a free function, so its not part of the struct "Students" (i asume this was your attempt). to do it, you have to define it like this: `void Students::izvadit(vector &lt;Students&gt; saraksts)` 4. you declared your izvadit function so that it takes a vector of students as arguments. so call it with a vector of students 
&gt; That doesn't make good C++ code. That's purely subjective. Also depends on on the definition of good code and good C++ code. If good C++ code means that it's not compilable by C compiler, then the "naive" solution is indeed not a good C++ code. &gt; That makes C code. What's wrong with that. I use the best tool for the job. I am not using C++ features just for the sake of using C++ features. &gt; In the wrong context, you can shoot yourself in the foot. Not in this one. It's definitely necessary for templates. And it might be useful for objects, although I can remember the last time I caught an error with static_cast or need to search for cast, especially casting from one primitive type to another. &gt; It's generally nicer Subjective foo(static_cast&lt;int&gt;(p.x), static_cast&lt;int&gt;(p.y)) vs foo(int(p.x), int(p.y)) I personally find the latter much nicer
I try it and it wont work , get the error that member function not defined in class students.
In my opinion, const and move are contradictory - if I move an object, I modify it. So it can't be const... However, C++ allows to define this concept and achieve these semantics nevertheless, e.g. like this: template &lt;typename T&gt; class MoveableConst { public: template &lt;typename... Args&gt; MoveableConst(Args&amp;&amp;... args) : m_value(std::forward&lt;Args&gt;(args)...) {} ~MoveableConst() = default; // disallow copy MoveableConst(const MoveableConst&amp;) = delete; MoveableConst&amp; operator=(const MoveableConst&amp;) = delete; // default move MoveableConst(MoveableConst&amp;&amp;) = default; MoveableConst&amp; operator=(MoveableConst&amp;&amp;) = default; const T&amp; value() const { return m_value; } const T* operator-&gt;() const { return &amp;m_value; } const T&amp; operator*() const { return m_value; } private: T m_value; }; 
Yes, my bad. The point is still the same.
No, it's not the same as soon as you leave primitive land. There is nothing wrong with functional casts when combined with brace-initialization instead of parentheses.
vcpkg compiles ranges-v3 for vs2017
but seems it still uses old fork
"clang with ms codegen" fails with ICE for rather simple code which uses a pair `boost::filesystem::recursive_directory_iterator` to make a range, applies a simple `view::filter` to it and converts to a vector with `to_vector`. This was a week ago with a master branch, though. Did not check if it has been fixed. BTW, the same code does not compile with cl.exe and MSVC fork, but no ICE.
Because I'm used to interchanging array, pair, and tuple and std::get is my de facto go-to for these three types.
Absolutely agree. Listened to it today, and could hardly tell the difference between the main content and the Incredibuild ad portion. 
then it should be an error message, not ICE.
&gt; emacs ../range-v3/doc/index.md &gt; **emacs** *I knew it* I also might help with documentation in my spare time. I'm relatively new to ranges, but can definitely help flush out documentation.
Implementing your own is a good exercise, in my opinion. If you make use of `std::aligned_storage`, it's not especially difficult. The key insight is that you can achieve type erasure without virtual methods using function pointers: template &lt;std::size_t Size, std::size_t Align&gt; class inplace_function { private: using storage_type = typename std::aligned_storage&lt;Size, Align&gt;::type; using function_type = void(storage_type*); storage_type m_storage; function_type* m_function; public: void operator()() { m_function(&amp;m_storage); } template &lt;typename Function&gt; inplace_function(Function _function) { static_assert(sizeof(Function) &lt;= Size, "Function too large to fit in storage"); static_assert(alignof(Function) &lt;= Aligh, "Function has too strict alignment"); new (static_cast&lt;void*&gt;(&amp;m_storage)) Function(std::move(_function)); m_function = [](storage_type* _storage) { reinterpret_cast&lt;Function*&gt;(_storage)-&gt;operator()(); } } }; This obviously assumes a function returning `void` and taking no parameters, and it ignores copying, moving, destruction, and a bunch of other things. However, I think the key idea is illustrated.
/u/Morwenn, consider using flair to identify yourself a bit more. Note that "as a direction poll" is shorthand for "are we even interested in considering the direction that this proposal is taking"? So the votes don't reflect the exact syntax or semantics of the poll. The votes reflect the idea of trying to solve this problem in a fashion even remotely resembling the one proposed. And so this has been taken back to the community, as stated :)
Everything aside, isn't it possible to write a move constructor yourself that const-casts members to work around this issue?
Did it work at all? 
And in my world, some day we might want more than 64 bits! (For global addressing on a cluster where you want to each node to have a full 64 bit address space for interoperability, but the native word and pointer size is larger so you can add a node ID to local addresses)
UB vs ID I think is solely due to pragmatism: implementation-defined behavior forces the compiler author to do something about it and document it. Undefined doesn't mean it must crash or can't be supported. The compiler writer is free to turn *each and every* UB into ID. So the standard leaves the way open, but doesn't force it. Furthermore, ID can also mean that if you do it, it abort()s. All it needs is to be consistent about it, not necessarily for the behavior itself to be useful.
&gt; C++ is not Python with its benevolent dictator nor is it Rust with its open republic-ish design process nor is it C# with its team of chief populist designers. C++ is 100% bureaucratic bullshit and that's just how it is. :) What I meant is that with a popular uprising this could change. If tomorrow enough people started saying "it's not the current commitee who decides what C++ is, but a new commitee composed of Mr. Foo and Mrs. Bar and ...", then by matter of facts the balance of power would change.
Yeah, you're right. Darn. Oh well. Blame that on posting concurrent with having the first coffee of the day.
Might be an old C-thing. Without bools you write `while (1)`which can happen by accident when editing. I think the main idea was that a `for(;;)` stands out and clearly signals your intend.
&gt; C++ const is not restrictive enough to ensure that the data managed by an object is actually unchanged One needs to distinguish between modifying a non-const-declared object via a const reference (valid) and modifying a const-declared object (undefined behavior). Accessing a const-declared object from multiple threads without synchronization is thread-safe provided that all these threads have *observed* its initialization (for example, by being started after such initializaion).
There's probably a reason Rust has `loop`: it avoids such discussions and clearly signals intent. 
Frankly I don't think anyone would follow the second lot C++ might be awkward and confusing in places, but its still obviously the best language in a lot of respects (for particular tasks), I'd prefer to stick with the people who seem to steering it in aggressively the right direction recently!
And if your approach to problems is to wait for other people to fix them, you should not work on build2 but instead do nothing and wait for CMake to get better by itself.
But _you can_: the standard library might invoke undefined behavior if you violate the precondition that every const method should be thread-safe, but this is neither required nor enforced by C++ _the language_. In particular, if you don't use the standard library at all, const only means thread-safety if your code, and the libraries that you use, _as a convention_, give it that meaning, and stick to it. But if there is a bug in any of the code or libraries that you use, and a method that isn't thread-safe ends up being marked const, just because it is const doesn't mean that your program is magically threadsafe. Worth remarking is that _this is only a convention_, you could have a different convention like "all functions that end in `_thread_safe` must be thread safe, and that would be as reliable as `const` is. BTW: are you still in Aachen? PM.
Yes, but technically it is still UB. It shouldn't be a problem if you use, let's say, `std::vector` with it, but it isn't guaranteed to work.
I guess it's the number of connections
This should be really interesting. I have often heard that Rust is more focussed on providing zero cost abstractions than C++. Would be nice to hear something on that.
I don't understand the conclusions.
Am I the only one who found the layout of the bar charts to be with no sense at all? I would expect to either group each section by message size, or group by asio/evpp. Instead it's some completely random order. 
&gt; When concurrency is less than 10,000 in the test, asio is better, the average is higher than evpp 5%~10% &gt; When concurrency is 1,10,100,1000 in the test, evpp performance is better, the average is higher than asio 10%~20% Aren't these mutually exclusive? &gt; When the number of concurrency is 100, asio than the evpp overall more dominant, throughput higher than 10% I'm guessing English is not your native language; the way this reads to me is that asio is better performing to 10% in this case. 
That's cool! Niko Matsakis has a great blog [here](http://smallcultfollowing.com/babysteps/). I think his posts on [Rayon](http://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) (a library for parallel iterators in Rust) could be interesting to non-Rust developers as well. 
You're right, the literal answer to the question in the title is ([as always](https://en.wikipedia.org/wiki/Betteridge%27s_law_of_headlines)) no, when coming from a "what does the standard declare about the language" perspective. But that's not what the article is about. It's about what level of thread-safety is implied by `const` when it comes to the standard library. It also gives an actionable recommendation for how to design your own classes' const methods vis-à-vis thread-safety.
You _might_ be able to pull off a WHAT-WG style coup but then you need buy-in from the folks that actually write the compilers, not an online poll about some individual feature. You need to go talk to the developers for GCC and LLVM and MSC and EDG and so on. You can go gather a huge collection of experts and get them to agree on a new standard but that'll mean diddly squat if the compiler vendors don't listen to them. Or of course you could go write a new fork of C++ with your own production-grade multi-platform IDE-integrated compiler implementation that users can switch to, which is a ginormous undertaking that is approximately 10,000,000,000,000 times harder than making an online poll. :)
Sorry, I should have read the article before opening my pie hole
&gt; gcc version 4.8.2 20140120 (Red Hat 4.8.2-15) (GCC) what about testing with latest GCC (and CLang), and with link-time optimizations ? 
For boost asio, which implementation of the server was used ? I can see server-1, server-2 and server-3. I think it is important/nice to mention how the `io_service` was used in multi threaded test. Was it `1-to-1` or `1-to-N` (`io_service` instance-to-thread).
I don't think this topic is as clear-cut as you present it, but that's okay. :) for example: &gt; it's focusing on providing more safety and you pay for those safety at runtime unless you use unsafe. Many of Rust's safety checks are compile time, not runtime. Lifetimes, most famously. http://blog.burntsushi.net/ripgrep/ is another interesting case study people may want to read about "production" Rust. (Technically, not quite yet, but it's looking like ripgrep is going to be used for Visual Studio: Code's search, so production gets some quotes for now.) EDIT: oh look https://github.com/Microsoft/vscode/pull/22722
I understand you try to do marketing here as someone behind Rust but... &gt; Many of Rust's safety checks are compile time, not runtime. Lifetimes, most famously. Many doesn't mean all. I wrote some examples in my post which requires runtime overhead. ripgrep doesn't support a lot of things that grep support that's why it's fast, not because it's written in Rust, I've tested ripgrep some time ago. Last time I've read Visual Studio ripgrep integration issue on github it didn't support all requirements needed and there were no plans to support them. Brotli is the only real world production example that I know in which someone converted C/C++ performance critical code without changing underlying algorithms (mostly one to one). 
&gt; I understand you try to do marketing here as someone behind Rust but... It's not that; I think it's important to keep abrest of C++'s evolution, like many other languages, since I work on a language. I'm just usually a lurker since I don't have much to say. &gt; Many doesn't mean all. That's true, but like I said, it's not that simple. Some of these checks let you do stuff that you'd need dynamic checks for in C++, for example. It's not just "Rust has some bounds checks and so is inherently always slower." &gt; ripgrep doesn't support a lot of things that grep support that's why it's fast, Like the above, this is an oversimplification. &gt; Last time I've read Visual Studio ripgrep integration issue on github it didn't support all requirements needed This is true, but... &gt; and there were no plans to support them. This is false, in fact, a new release of ripgrep just came out with the largest one (UTF-16 support).
&gt; ripgrep doesn't support a lot of things that grep support that's why it's fast Neither are even remotely true. Please see my blog post, which explains in great detail why it's faster. And no, it's not because it's written in Rust. Nobody has ever claimed otherwise. &gt; not because it's written in Rust, I've tested ripgrep some time ago. I wouldn't have been able to write it if it weren't for Rust. It would take too much time. &gt; Last time I've read Visual Studio ripgrep integration issue on github it didn't support all requirements needed and there were no plans to support them. I'm in contact with the Visual Studio people. I am hopeful. (***None*** of the available search tools fit all requirements, including their own.) &gt; Brotli is the only real world production example that I know in which someone converted C/C++ performance critical code without changing underlying algorithms (mostly one to one). ripgrep (grep/C), [Rust's regex crate](https://github.com/rust-lang/regex/blob/master/bench/log/05/re2-vs-rust) (RE2/C++) and [Rust's `snap` crate](https://github.com/BurntSushi/rust-snappy#performance) (reference snappy impl, C++) are all comparable in terms of performance and implement similar (ripgrep), very similar (regex) and exact (snap) algorithms.
I uuh... I actually thought this whole article and the code was a satirical joke taking the piss out of 'expressive' code until I read this
&gt; And where I wrote that? You are manipulating what I wrote. That is how I read your first post; if I'm misunderstanding your position, no biggie. &gt; Again you are manipulating reality, utf-16 was not the only requirement so it's NOT false. I said "largest one", not only. And, the bit that you said was "and there were no plans to support them", but plans were made and UTF-16 support was added, hence why I said that was false. There are more issues than just that, but a counter-example to your blanket statement means the blanket statement is incorrect.
His blanket statement also started with "*Last time I've read &amp;hellip;*", so he's not necessarily incorrect, just mis/under-informed. ;-]
You can be incorrect because you're mis/under-informed. ;) That is, I'm not ascribing any malice here, just trying to lay out the facts. Anyway, it's pretty clear that this line of comments isn't gonna really go anywhere, so I'll cut it out :)
&gt; abstractions that do more than you would think (like validating if buffer is valid utf8 when converting to str unless you use unsafe). This isn't true. Rust has both `from_utf8`, which converts bytes into strings and checks for valid encoding (which you should do in most cases, if you are going to handle external data). Then there's https://doc.rust-lang.org/std/str/fn.from_utf8_unchecked.html, which is perfectly memory-safe, it just might lead to panics later on.
I really wish that it had a standard library like go, when I am writing go it already has most things I am going to need, like http, compression, templating, **crypto**. I know it's all going to be patched and supported.
&gt; I've wrote "like validating if buffer is valid utf8 when converting to str unless you use unsafe" - unless you use unsafe which means what it always means = unsafe block = in which you use utf8_unchecked. So you need to use unsafe... Gah, too late here and I misread my own docs :). &gt; If you handle user date then yes but yo don't need to utf8 validate files that for example your own software generated etc. Sure, and that's precisely the point where "I can guarantee all invariants hold, just do it" is the right thing (and that's what unsafe tells the compiler). unsafe is not at all a bad word in Rust, it is a fundamental feature to be used.
&gt; Neither are even remotely true. What about PCRE support in ripgrep? Not remotely true that it doesn't support it and grep does? &gt; ripgrep (grep/C), Rust's regex crate (RE2/C++) and Rust's snap crate (reference snappy impl, C++) are all comparable in terms of performance and implement similar (ripgrep), very similar (regex) and exact (snap) algorithms. So do you have any other example that was not written by you/rust language developer/for rust language? 
&gt; What about PCRE support in ripgrep? Not remotely true that it doesn't support it and grep does? So that's one feature. What else? I can give you one: backreferences. Anything else? &gt; ripgrep doesn't support a lot of things that grep support **that's why it's fast** So what does the lack of PCRE support have to do with ripgrep being faster than egrep? &gt; So do you have any other example that was not written by you/rust language developer/for rust language? Those are the ones I did, so those are the ones I know. Is there a problem with that?
&gt; Gah, too late here and I misread my own docs :). No problem :) &gt; Sure, and that's precisely the point where "I can guarantee all invariants hold, just do it" is the right thing (and that's what unsafe tells the compiler). unsafe is not at all a bad word in Rust, it is a fundamental feature to be used. Yeah, I just like to point out that some of those abstractions are not free and they cost runtime performance unless you use unsafe. It would be great if Rust-docs included "not so free abstractions" or similar document explaining which abstractions in std include additional runtime costs because of safety and what language itself is doing under the covers to provide safety (ex bound checking).
&gt; Then there's https://doc.rust-lang.org/std/str/fn.from_utf8_unchecked.html, which is perfectly memory-safe, it just might lead to panics later on. I think you're understating it here; doing this incorrectly is UB, not just "might lead to panics". Safe methods on `String`/`str` assume proper UTF-8 encoding, arbitrary bad things can happen if that's violated.
&gt; So what does the lack of PCRE support have to do with ripgrep being faster than egrep? You wrote 'neither is true' but it isn't the case, is it? I was obviously replying to that. &gt; Is there a problem with that? I just wanted example similar to brotli, I don't see any problem with that, do you?
&gt; You wrote 'neither is true' but it isn't the case, is it? It is true. Two features isn't "a lot." You still haven't told me why any missing features are related to performance. &gt; I just wanted example similar to brotli And I gave you some.
Ok I know this thread is 3 months old but I just found it via google and have been trying to get a good GUI framework for months now. There is none. There isn't a single GUI framework that simply works and is easy to use in computer graphics applications. If you can go with a multi-window setup (like gimp) then just use any C++ framwork. If you can't, you have two options. You can fight with ImGui and hope you get something going that at least works. Or you can write your own library. 
Really? I would think that the standard library provides you that for the classes it gives you. But if it really requires that your const method are thread safe in order to interact with them behind your back (the only reason I see would be to try to attempt auto parallelization), then it could cause all kind of problems both if you use mutable stuff or if you simply call non thread safe functions from your const methods... So that would probably be a huge defect of the language, given it would be a regression from previous C++ versions... so I don't believe it. Edit: just anticipating potential remarks about previous versions of the language not specifying threads, in practice we could use them on virtually all the platforms where they are available, with virtually all the compilers that exists, and without that defect of requirement of absolute thread safety for our const methods, so I would not find that very convincing either...
&gt; And I gave you some. No, you didn't. My question exactly points out what kind of examples I was looking for.
OK, this is getting ridiculous. I hope that this is my last comment to you. As I said before... The [`snap`](https://github.com/BurntSushi/rust-snappy) crate implements the same algorithm as the reference C++ snappy implementation, and its test suite checks that the implementations yield *byte for byte* equivalent output given the same input. Rust's [`regex`](https://github.com/rust-lang/regex) was implemented by following the strategies laid out by the [author of RE2](https://swtch.com/~rsc/regexp/). There are various differences in details, but the core of the regex engine is the same (Pike VM, bitstate backtracker, lazy DFA). GNU grep and [`ripgrep`](https://github.com/BurntSushi/ripgrep) have a similar architecture for searching single files. It's single threaded, uses aggressive literal optimizations and uses a lazy DFA to implement the regex engine. All of these things have benchmarks to support my claim that they are all similar in performance.
&gt; I hope that this is my last comment to you. You hope? Then why you are replying at all? Too much emotions my friend. I think you are smart enough to deduce what I was implying in my question (which is pretty obvious) but it seems emotions got better of you so lets just finish it here. 
&gt; Yeah, I just like to point out that some of those abstractions are not free and they cost runtime performance unless you use unsafe. I'm by no means fluent in rust, but given a signature like this: pub fn from_utf8(v: &amp;[u8]) -&gt; Result&lt;&amp;str, Utf8Error&gt; I can immediately see that this is by no means zero cost. It's not even abstracting anything away, the signature is pretty explicit on what is going to happen.
&gt; Yeah, I notice your tag on here as embedded developer. Completely understand your point of view. I'm trying so hard to keep ahead of things, but there's so much to learn and stay up-to-date with. It doesn't help that on most code I write for work that I'm limited to GCC 4.4. Thankfully my work has enabled the `-std=c++0x` flag. We use the GSL where possible and use as many modern techniques as we are allowed. Lambdas can only be used on certain projects since GCC 4.4 didn't support them. :(
It's abstracting away manually implementing the loop/state machine required to check for validity. It's not a groundbreaking abstraction, but it still is one. In any case, zero-cost abstraction doesn't mean literally has no cost (that'd mean one couldn't write zero-cost abstractions for anything non-trivial): it means "has no cost compared to not using the abstraction". That is, `from_utf8` is zero cost if it's as cheap as manually writing the validation loop (which it is). A non-zero cost abstraction might be something `from_utf8(v: &amp;[u8]) -&gt; Result&lt;String, Utf8Error&gt;`, which allocates a buffer and copies into it, rather than just returning a view into the original buffer. In C++ parlance, this is the same as the difference between `std::experimental::string_view from_utf8(char *, size_t)` and `std::string from_utf8(char *, size_t)`.
&gt; It's abstracting away manually implementing the loop/state machine required to check for validity. It's not a groundbreaking abstraction, but it still is one. In this sense every function call is an abstraction of whatever the function actually does. &gt; That is, from_utf8 is zero cost if it's as cheap as manually writing the validation loop (which it is). Yes, if you define zero cost that way. But kl0nos is claiming that rust has "abstractions that do more than you would think" like this from_utf8. And I don't agree in this particular case, because from_utf8 is pretty explicit on what it does.
I don't think "What Other Languages Can Do That Rust Can't*" is in the spirit of what the parent meant by a response. *https://lifthrasiir.github.io/rustlog/why-is-a-rust-executable-large.html
On Windows you need to statically link or at least distribute the C++ stdlib as well. And, Rust uses the equivalent of `--gc-sections` by default.
Thanks for your advices. I haved changed the doc. What's `mutually exclusive` meaning?
OK, We have updated the bar charts with for every asio/evpp group. Please look at it again. Is that clear now? https://github.com/Qihoo360/evpp/blob/master/docs/benchmark_throughput_vs_asio.md
There are all N-to-N. There are N threads for client and N threads for server. The test script is https://github.com/Qihoo360/evpp/blob/master/benchmark/throughput/asio/multiple_thread.sh 
I've seen exceptions disabled for "performance reasons", which mostly means "we haven't investigated" or "we've always done it this way". There was a time (20 years ago) when exception _were_ expensive, but it is not the case today. However, I've also seen projects that had either realtime or hard deterministic requirements. Those had exception disabled, but also most sorts of dynamic memory allocation. You had to be able to prove your program used at most N bytes of memory in _total_ while it ran.
It is if you use iostreams rather than `printf`.
OK, We have update the benchmark report. Please look at it, does it look clearly now?
We described at the benchmark report : we use `client2/server2`. And the test script also shows that. ./asio_test.exe **server2** 127.0.0.1 33333 $nothreads $bufsize &amp; srvpid=$! ./asio_test.exe **client2** 127.0.0.1 33333 $nothreads $bufsize $nosessions $timeou server1,server2,server3 and other codes in repo https://github.com/huyuguang/ are all pertinent and will be taken to do other benchmark test in few days. We will post more reports later. 
&gt; Yeah, I just like to point out that some of those abstractions are not free and they cost runtime performance unless you use unsafe. I wouldn't agree here. Making the default APIs safe and conservative is no abstraction. Strings in Rust are UTF-8, with everything that comes along with it.
Is there a convenient shebang to interpret Rust?
&gt; Specialized roles decay while full stack engineers are on the rise. I kinda disagree with this premise.
I really don't like the inexact terminology used in this discussion and Herb is guilty of this. 'const' does not *mean* thread-safe. But const *implies* thread-safe ("if I'm not changing the object, why is this this operation not safe?"), which means you should honor this when writing a class. That said, this is not a hard rule and there might be legitimate use cases for a class that is const and non-thread-safe, such as a cache that is only used from one thread.
D:
so many things
Yeah, the whole intro reads like a marketing copy written by an MBA. 
Maybe not specifically in C/C++, in which specialized roles are almost by definition, but in SW development in general, and in important areas like web it seems a trend [StackOverflow survey](http://stackoverflow.com/insights/survey/2016) and according to [CodingDojo](http://www.codingdojo.com/blog/web-developer-salaries-2016/), it seems that full-stack salaries are higher, which imo is driven by the growth of the market. From what I know, it also seems that even in C/C++, agile keeps getting adoption, and developers are more in charge today of the full lifecycle, testing, building, deploys than they were years ago, which forces them to be more "full stack" than in the past.
Is `restrict` still a thing in C++ ? I remember getting a compiler error for using that keyword.
It's one of those valid-C-but-not-C++ things.
Convenient may be a bit of an overstatement, but [cargo-script](https://github.com/DanielKeep/cargo-script) can be used to shebang Rust scripts. A nicety is that it can extract Cargo manifests from the script, so you can use external dependencies.
nope, there is also the scope resolution operator "::".
But very easy to set up. http://www.bitsnbites.eu/faster-c-builds/
True enough, which is why I'll often use argument structs in C: SetDimensions((struct dim){.height=h, .width=w, .depth=d}); Not that much additional ceremony, and solves the problem. Honestly, though, in the case you show of strings used for a name, I might consider it fine as is, depending upon the situation (culture, audience, etc.). OTOH, given all the [Falsehoods Programmers Believe About Names](http://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/), it's usually best to have a struct for names, as well.
OK, I will. Are you willing to champion / present it for me?
What is the bug? You can also send me mail: firstname.lastname@microsoft.com. 
Rust standard library aims to be "minimal" as opposed to "batteries included". Rust has a _great_ package manager / build system that just works (and cross compiles and everything), so if you need something, it is typically one line of code away. The standard library only contains the most basic building blocks, and vocabulary types (and traits/concepts) to build interoperable libraries.
It's giving a warning to use `_strdup` instead of `_strdup`.
&gt; for other areas, though, it can often feel like a real roll of the dice finding one to rely on. FYI, this is a problem the Rust designers know about. There's been a few debates about exactly this but unfortunately there's no easy solutions :-/
See https://github.com/brson/stdx, https://github.com/llogiq/stdx-dev, ... These "boost-like" things exists (e.g. stdx), but they only help newcomers which don't know how to navigate the ecosystem (e.g. there are 10 json libraries available, "which one do I use?"). These "boost-like" packages give you just one so that you can get started. Once you have a bit more of Rust experience and know your way through crates.io it's pretty easy to discover which libraries are widely used for a particular task. For example, crates.io tells you for each library, the number of reverse dependencies, that is, how many other libraries and projects depend on a particular library. "Separating the wheat from the chaff" is trivial when you have this information: "oh, from 10 json libraries, only 1 is widely used, i'll use that one". So developers beyond the "very-beginner" level just include the dependencies they need. Instead of including huge collections of libraries (like boost) for parsing json, they just include the json parser they want. For this reason, these "boost-like" collections of libraries are not "that popular" in the Rust ecosystem, people who use Rust for more than 2 weeks just don't need them. They are still very important for beginners though. This is why they exist, and why some members of the core team maintain them. But IMO, the main reason these "boost-like" frameworks exist in C++ is because adding dependencies to a C++ project _is hard_ (compared to Rust, insanely hard), and organizations sometimes forbid dependencies tangentially due to this, so it is more worth it in C++ to just get "Boost approved" and obtain 30 libraries, than have to go through the approval process of an organization for 10 different libraries that you might need. One thing that is actually successful (to some extent) in Rust is `stdx-dev`. It is not a "boost-like" collection of libraries, but a collection of "useful infrastructure" (CI, linting, fuzzing, sanitizers, benchmarking, quickcheck, code coverage, publishing docs...). Basically, stuff that you should be doing on every project. Setting each of these up is trivial and takes 1 minute, but when you need to set them all up it adds up, so this package is arguably more popular than `stdx` itself, because it is still useful for "beyond beginner" devs. 
Should the first one say ASIO is better when it's at least 10k, not less than 10k? I think that matches the figures and clears up the inconsistency. EVPP looks to have higher throughout under 10k in the early figures. 
&gt; Of course, there's degrees of abstractions and some functions are thinner abstractions than others—just like some types are thinner abstractions than others—but they still fit somewhere on the abstraction continuum. If you call a function that just converts from type A to type B and returns an error if this is not possible (which entails that there is some checking logic inside the function) a zero-cost abstraction, you water down the semantics of this term to a level where it no longer bears any meaning. A string_clone would a zero-cost abstraction in that sense, since it abstracts away the malloc and memcpy and it has no overhead on top of what is has to do anyway. But no one would call it a zero-cost abstraction. To be more constructive, rusts from_utf8 does indeed contains a zero-const abstraction: Rust guarantees that the lifetime of the return value does not outlive the lifetime of the parameter. This is something that C++ does not guarantee. It's also hard to abstract it and probably impossible to do it with zero-cost without language extensions.
**Company:** [Gameloft] (http://www.gameloft.com/corporate/jobs/view-all-opportunities/ ) **Type:** Full-time **Description:** Gameloft is a leading mobile-game publisher in term of number of app store and Google play downloads. We are looking for C++ programmers, for the following positions: Senior Games Programmer (designing and implementing 3D engines and technologies on various gaming devices, developing tools for 3D videogames creation and actively participating in the game creation process along with the game designer and art teams) and Online Multiplayer Developer (working on large-scale online systems that will impact the experience of millions of users and they are implementing online multiplayer features (gameplay, leaderboards, matchmaking, tournaments, social networks) using our current SDK/library/tools) **Location:** [Cluj-Napoca, Romania] (http://clujbusiness.ro/#), we are a multinational team in Cluj and everybody speaks English **Remote:** No **Visa Sponsorship:** Negotiable **Technologies:** We use C++11/14 for the bulk of the work with some additional Objective-C and Python on the side. The main development happens on Windows and additionally on Mac or Linux depending on position. We use the STL extensively so experience is highly recommended but Boost experience is also appreciated. For the graphics roles, OpenGLES ES 2.0+/Metal and shader programming knowledge is required. **Contact:** Either submit your application [here]( https://www.smartrecruiters.com/Gameloft/110545878-senior-c-games-programmer ) for the Senior Game Programmer role or [here]( https://www.smartrecruiters.com/Gameloft/110545722-online-multiplayer-developer-c- ) for the Online Multiplayer Developer role. Or send me an email: ioana.marcu@gameloft.com.
&gt; Yes, if you define zero cost that way. Actually, C++ defines zero cost this way (Rust just copied this definition), and we are in /r/cpp after all.
Can't you already do this though? It won't be as seamless as this, but you can make rust wrappers and tell to use c calling convention/name mangling and such for them, basically creating a C compatible interface.
IMO Boost is a collection of libraries because organizations have a hard time "process-wise" approving dependencies for C++ projects, so it makes sense to put high-quality libraries together into a collection. - In Rust it is trivially easy (and robust) to have _a lot_ of small single-purpose dependencies in Rust projects. It obviously also helps that these libraries are peer-reviewed, that some of the reviewers are involved in the standardization committee, and that because standardization was a _very slow_ process, it also made sense to put these things somewhere "close" to the standard. - Rust standard library evolves way faster (and is more flexible) than an ISO standard (for better or worse) Note also that the parts from Boost that have been moved into the standard were "fundamental" (shared/unique ptr, threads, futures, some containers, chrono, filesystem...). Nobody has proposed moving Boost.Spirit into the C++ standard, nor will they do so for the time being. Also, big new changes in the C++ standard library like the Ranges TS, never went through Boost. - All these "fundamental" bateries (and more, networking, processes, ...) are already part of Rust's standard library. So I think that Boost appeared in the C++ ecosystem to solve problems that Rust projects do not have in the first place. The only problem shared by both Rust ecosystem and Boost is that of "peer-reviewing key libraries". The process for this in both Boost and Rust are very similar. 
And in the classic political compromise, the implementation will be something that nobody likes.
Yes! And a few additions: &gt; I haven't been able to find a properly working ccache solution for cl.exe. Have you tried the newer versions of clcache and similar projects? I know older ones had issues with cache corruption, but I haven't had the opportunity to try the newer versions yet. &gt; You can build windows artifacts on linux with mingw64 which works great You can probably also use clang to target Windows from any platform, the cross compilation scenario is becoming better and better! &gt; Currently I think you need several engineers to have something like breakpad/socorro in your pipeline One good engineer is enough, I did it at my company. But it makes more sense when you have more than one developer or you'll never have the bandwidth to fix bugs. &gt; In all, you probably need to have more build engineers in your team than actual developers. Yes! Good build engineers have an expertise, can optimize and increase the reliability of a pipeline much better than regular developers. They know how to debug build issues properly. I have seen good Linux developers who didn't know about ccache or proper build tools and had been developing for many years with a classic "make clean all" loop. So much time was wasted :( 
Those are all sensible tweaks to your build pipeline. 
I don't really strongly disagree. It was indeed a personal statement. But it is an important one. Ignoring it because it's subjective seems silly, especially if it's an experience that a lot of other folks share. Hell, this is directly related to the OP title: hack without fear. And I wasn't only referring to initially writing it, but maintaining it as well. There are other line oriented searchers written in C and C++ (that I won't call out specifically because it would be rude). From looking at their issue trackers, I don't envy their maintenance burden, especially when it comes to supporting Windows, Mac and Linux. But maybe they are just bad C or C++ programmers? I don't know, but that's the data I have.
That's how I originally learned it, and they were still teaching it this way for that reason when I was still in school 4-5 years ago (although a lot of the DS &amp; algorithms professors were middle aged to older and still teaching in C++98), But that's how it's done in existing code here at work, so it's still how I do it.
 &gt; Have you tried the newer versions of clcache and similar projects? I know older ones had issues with cache corruption, but I haven't had the opportunity to try the newer versions yet. I must say I haven't. Last time I check was probably 3 years ago and it was very much unstable. &gt; You can probably also use clang to target Windows from any platform, the cross compilation scenario is becoming better and better! There is a cross platform linker compatible with the windows abi ? &gt; I have seen good Linux developers who didn't know about ccache or proper build tools and had been developing for many years with a classic "make clean all" loop. I think all developers should have a relatively deep understanding of the tooling involved and of the underlying systems. However, this rarely get taught ( or poorly) and it can be so cumbersome that most developers try to minimize their involvement with the BS* *Build System
Well, we probably agree about the C part. No line oriented searcher that has picked up major traction though (major = [rip-grep (congrats!), ag, ack, pt, grep, git grep) has been written in C++ though. And even then, a lot of C++ code written in the wild is written as pseudo C. If people are not comfortable moving out of their C-bubbled-C++ into better C++, why would they be comfortable moving into Rust? It just shows how tricky it is comparing mainstream and cutting edge languages, I feel. Just conditioning on wanting to learn something new like Rust that is relatively challenging, puts you in the top 10% of developers most likely.
Yeah, because that's worked out so well so far... :\^)
Oh, you were talking about the production of safe programs (or maybe correct programs). I've always been under the impression that c++ was among those languages that is bad at formal correctness and safety. You're right in that conventions aren't very good at preventing complicated bugs, data races and the like. I guess I thought you were talking about something else.
I write infinite loops all the time! It can make control flow in a loop a lot easier to reason about, rather then trying to force all your loop conditions/iteration logic into the `for`.
Meaning that both things cannot be true. 
Fair enough. &gt; You partially confronted the issue by talking about the linux side but windows is important. Unfortunately, Windows XP is the newest Windows I've used in any significant way and I haven't yet gotten around to experimenting with Rust for my WinXP retro-gaming PC, so I'm not qualified to talk about Rust on Windows. I'd actually be quite interested in seeing someone re-running the comparisons shown in [Why is a Rust executable large?](https://lifthrasiir.github.io/rustlog/why-is-a-rust-executable-large.html) for Windows and then blogging about the results. &gt; Firefox is a very large program that can ship the rust standard library without making a large percentage difference. I assumed being big enough to ship the Rust standard library without it being a large percentage of the total application size went hand-in-hand with being "[a project] that [is] already up and running". &gt; I'm trying to tell you why I can't use rust even though I've invested plenty of time into it. Comment voting on reddit doesn't change the technical issues. I suspect people are downvoting you, not because of what you say, but because of how you're saying it. (The way you phrase your posts is very reminiscent of people who have invested themselves in a conclusion and will ignore or twist facts to avoid challenging it.) For example, you say that Rust produces consistently larger binaries than C++. The blog post I linked says that, once you get the compile flags matched up, the Hello World! binary being used for demonstration is actually a bit *smaller* when written in Rust. You'd come across as a lot more credible if you either qualified your statements with "in my experience" or, to borrow a phrase from high-school math class, if you were to "show your work" like that blog post did.
Hey, I believe you. I'm just trying to explain why you're probably getting downvotes. &gt; I can make a hello world that is a few kilobytes with C++ or Rust, but only if it doesn't statically link in anything, just like that blog post. &gt; This is how it worked on windows with Rust nightly 1.17 That sort of thing is why I suggested writing a blog post like the one I linked to. If you can point to a "show your work" blog post with actual numbers, people will be less likely to downvote you. (Often, even if what you post is wrong, because it's the show of effort that convinces people of your sincerity and willingness to change in response to new information.)
Not a problem. I'm already planning to do something similar purely to minimize compile times when I learn Free Pascal to write some tooling for my older 133MHz P1 retro-PC. (My most powerful PC runs Linux only and VMs are a hassle to develop inside.) (In addition to things like the default string representation, which give a little more bug-insulation than C, Free Pascal has a [Turbo Vision](https://en.wikipedia.org/wiki/Turbo_Vision) port and, while I suspect [Free Vision](http://wiki.freepascal.org/Free%20Vision) is no longer capable of running in real mode like its ancestors, Free Pascal itself can target both the [GO32v2 DOS extender](http://wiki.freepascal.org/GO32V2) and [real-mode 8086](http://wiki.freepascal.org/DOS).)
I get that. I dislike it. I would be far more inclined to use rust if it had all that stuff. I want to know that these things are solid and I am not importing random buggy insecure code for basic use cases. It also encourages standard design patterns and provides a very good example for developers to work with.
\&gt; 2017 \&gt; writing Pascal on svn like a boss
I thought of cool lambda stuff or variadic templates, but in the end, nothing for me will ever beat RAII. class resource { public: resource() : v_(acquire()) { } ~resource() { release(v_); } resource(const resource&amp;) = delete; resource&amp; operator=(const resource&amp;) = delete; private: void* v_; }; void f() { resource r; // ... } There is something so satisfying in wrapping a C API into a couple of RAII classes and cleaning up acquire/release calls, I could do it all day for the rest of my life. [edit: alright, alright, I deleted the copy ctor and assignment operator]
 if (something) { bracketOnNewLineForLyfe(); } 
At work we are using a minor modification of Google C++ Style Guide. Mainly with the following exceptions: * `#pragma once` instead of define guards (we don't want to support compilers not capable of dealing with `#pragma once`) * file extensions (header: h, source: cpp) * interface are prefixed with `I` instead of `Interface` suffix (we try to keep it short wherever it feels appropriate) * member variables are prefixed with `m_` instead of the postfix `_` (we find it easier to search for when browsing the class/member tree in the IDE) * no legal info at the top of each file (we don't need that bloat) * line length of 100 (80 leads to very vertical code) To enforce and ease the plain formatting (i.e. indentation, line breaks, alignment, etc.) we are using a clang-format configuration based on Google C++ Style Guide and a few modifications. We haven't fully automated clang-format as a SCM hook, but are using it basically the in same frequency as [Ctrl]+[S] with the help of the VS plugin. For private projects, I mostly use that pattern as well. Except for pure (or mostly) Qt projects, where the Qt style is more appropriate.
This: template&lt;class T, T v&gt; struct integral_constant { static constexpr T value = v; // [...] }; I find it to be really elegant, and I like elegant code ! More info and code on [cppreference !](http://en.cppreference.com/w/cpp/types/integral_constant)
There was a small [survey](https://www.reddit.com/r/cpp/comments/51f3od/short_c_coding_style_survey/) and [results](http://imgur.com/a/gEvgB). I'd say the goal in general should be a balance between not wasting space while keeping it from being cluttered. And not being weird or antithetical to the general style of a language. It's C++, not Pascal++ or Java++ and vice versa.
Neither C nor C++ have these things either, maybe its a low-level language thing. The more things they have the higher the chances something cannot be made to work in some platform.
you should probably delete your copy constructor and copy assignment operator
Man what should I do. I got the time to read up on any book, that isnt an issue. I just want to avoid confusion while im learning. Is Stroustrup's book my best path?
The fast inverse square root.
The key here is `constexpr`. Rather than the classical `static const`, it means that the variable (or more) is/can be "computed" at compile time and not run time ! [cppreference on constexpr](http://en.cppreference.com/w/cpp/language/constexpr)
My personal favorite is WTF operator: !error_occured() ??!??! handle_error();
&gt; I've always been under the impression that c++ was among those languages that is bad at formal correctness and safety. I think that the cppguidelines team is doing great progress here. Backwards compatibility with C makes this hard, but hey, MISRA C exists so there is hope that we might in the future be very confident that some parts of C++ programs are formally correct, which is great because there are gazillions of lines of C++ code that everybody relies on every single day of our lives. Rust has this arguably way easier. There are some verification tools already that can prove the correctness of not so trivial algorithms like quicksort even when the implementations use unsafe code, and dynamic memory and such. There is also one mostly solid rust interpreter that also can deal with most of the unsafe code and undefined behavior (and diagnose it sometimes). Finally, Rust is still far away from a specification for what is and what isn't undefined behavior in unsafe code, but the current models for this aim to be easily implementable as run-time verification tools (e.g. in the spirit of clang's undefined behavior sanitizer, but with 100% undefined behavior coverage). 
Literally all of your posts are about Embarcadero, and you've never participated in this community by commenting. This is spam by Reddit's definition. You're welcome to submit content from your employer (as I do) if it's only a fraction of your community participation (often considered to be 1 in 10).
This is my experience as well.
No, they aren't.
I just wish you could have anonymous objects that respected scope :(
On Windows `-list-checks -checks='*'` does not work for some reason - not all checks are listed. You should use `-list-checks -checks=*` to see all of them (`*` without quotes).
Something is just nice about this... template&lt;class... Types&gt; constexpr auto avg(Types... t) { auto sum = (t + ...); return sum / decltype(sum){sizeof...(t)}; }
That makes sense. I have seen this before then, just didn't think of the same question. Thanks a lot.
My experience may not apply to you, because I began programming with Pascal in 1982, moved to C in 1987, and started C++ in 1994, so I was never a beginning programmer with C++. Also, C++ in 1994 was a much smaller language than it is now, and like many people I used it as "a better C" for a time. In short, I eased into C++ gradually. I haven't read PPPC++, but I have owned the 2nd, 3rd, and 4th editions of "The C++ Programming Language" book, also by Stroustrup. The 2nd edition was rather tutorial in nature, and I felt that Stroustrup exhibited much wisdom in his advice. I presume he takes the same attitude in PPPC++. By the 4th edition of C++PL (not suited for beginners), the language had grown so large that the book turned into primarily a reference manual. Even with 1346 pages, it has room only for introductions to feature after feature, with the understanding that once you know what to look for, you can find the details on the web, for instance [cppreference.com](http://en.cppreference.com/w/Main_Page), which is a fine site, but possibly scary for beginners. I haven't looked at online tutorials much, so I can't say how good they might be. 
I hope you are not using functions then, they are not zero cost, horrible horrible things!
Nothing to do with your code, I'm just saying that I would like to be able to have unnamed objects when they are used as "guards", that is, when only their constructor and destructor are relevant. Something like: void f() { std::lock_guard&lt;std::mutex&gt;(m); } But this, of course, creates a temporary `lock_guard` that dies at the end of the statement, so you have to give it a name: void f() { std::lock_guard&lt;std::mutex&gt; lg(m); } But `lg` is not used anywhere, it's a useless name introduced in the scope just to have the object stay alive. I wish there was a way of creating an "anonymous" object: an object that has no name, but behaves as if it had one. Maybe with a keyword? void f() { inline std::lock_guard&lt;std::mutex&gt;(m); } 
I like using the type-erased pointer for interfaces. Basically, instead of doing this: class my_iface { virtual void foo(); virtual void bar(int); virtual void baz(double); }; and deriving from `my_iface`, you make a single `my_iface_ptr` class, with a template constructor: class my_iface_ptr { using foo_ptr_t = void(*)(void*); using bar_ptr_t = void(*)(void*, int); using baz_ptr_t = void(*)(void*, double); void * obj_ptr_; foo_ptr_t foo_ptr_; bar_ptr_t bar_ptr_; baz_ptr_t baz_ptr_; public: template &lt;typename T&gt; my_iface_ptr(T * t) : obj_ptr_(static_cast&lt;void*&gt;(t)) , foo_ptr_([](void * obj) { static_cast&lt;T*&gt;(obj)-&gt;foo(); }) , bar_ptr_([](void * obj, int i) { static_cast&lt;T*&gt;(obj)-&gt;bar(i); }) , baz_ptr_([](void * obj, double d) { static_cast&lt;T*&gt;(obj)-&gt;baz(d); }) {} void foo() const { foo_ptr_(obj_ptr_); } void bar(int i) const { bar_ptr_(obj_ptr_, i); } void baz(double d) const { baz_ptr_(obj_ptr_, d); } }; This is basically just a (somewhat more succinct, C++11) way of writing the "impossibly fast delegates" from this article: https://www.codeproject.com/articles/11015/the-impossibly-fast-c-delegates Sadly, MSVC won't always allow you to implicitly convert the lambdas to function pointers above, it thinks there is ambiguity because of several possible calling conventions. So you may have to futz with it very slightly if you need it to work with MSVC 2015. (I didn't try MSVC 2017 yet). But it works as written on gcc and clang. I like doing it this way sometimes because - this way doesn't use virtual dispatch, and doesn't require RTTI, which is sometimes an issue - sometimes you are using an abstract interface in order to "future-proof" the code or make it more easily extensible later, but in real programs, there is only actually one type that will be using this interface. In that case the compiler may be able to figure out that there is only one possible value for `foo_ptr_` etc. above, then make them constant and inline all of the calls. I think this is less challenging than "devirtualization" which is still considered pretty hard as I understand, and still a "frontier" in compiler development. - While it may look somewhat "unsafe" with the void * casts, it's actually fairly safe in that if T doesn't actually meet the interface, it's going to fail at compile-time while instantiating the ctor. - It allows somewhat looser coupling between your compilation units. If `A` is a class that implements this interface, but the interface is one of these "type erased pointers", then `A` doesn't actually inherit from the interface, and people that use `A` don't need to include the definition of the interface. `A` could in fact implement tons of interfaces this way and most users of `A` wouldn't need to know about it. This can reduce compile times. Overall it feels a bit closer to traits in the Rust language, but in C++ - IDK man I just find it very elegant. It's like a smaller, simpler C++ closer to just "C with classes and templates ( and lambdas...)". Also I guess I should hype the `eraserface` project, which tries to automate the construction of such interfaces and develops the idea in various directions: https://github.com/badair/eraserface As to why I think it's beautiful: It seems very strange the first time you see it, like, what is going on here, how can I have a pointer to untyped data and recover it and use it correctly without some major overhead. But after you understand how it works, it all fits together very well IMO. It's nice the way that the class is not a template (which would make this much less useful) but the constructor is.
Now that I'm old, I don't have time for more newlines. I need more context in view, not glaringly more separation of stuff that's already separated. Brackets are either invisible or just irritating noise to me. At home, I've been writing such blasphemies as if (foo) { auto baz = nexBaz(); for(;;) { auto bar = nextBar(baz); if (bar) break; }} I don't do this at work! I don't inflict this on other people. The goal is to minimize pointless empty lines and get the damn brackets out of the way as much as possible. Basically, trying to make my C++ look like Python. Indentation conventions are all I need to parse my code. I find code that's 1/2 or more empty lines harder to keep track off. In 20+ years I can count the number of bugs attributed to a lack of brackets on one hand. I don't need brackets. They are there for the machine.
Aaah rule of five fail!
Ugh. Typos.
Everything in here: [Sean Parent : C++ Seasoning](https://www.youtube.com/watch?v=qH6sSOr-yk8) edit: Short text with examples from that talk: http://www.bfilipek.com/2014/12/top-5-beautiful-c-std-algorithms.html
I'm getting clang-tidy crash `Support for this Decl not implemented. UNREACHABLE executed at llvm\tools\clang\lib\StaticAnalyzer\Core\ExprEngine.cpp:2025!` What exactly is not implemented? 
I know. I checked his posts. Attends C++ Standardization Committee meetings. I was just joking. :)
Use the formatting style that is being used in an existing project. Hopefully, clang-format is hooked into the VCS. If creating a new project, use the same style as other projects. If no other projects exists, use the same style as the library you are pulling from (`std`, `boost`, `folly`). For personal projects, just use whatever you feel comfortable with, just be consistent. For language and compiler issues, we use a guideline tailored from the [LLVM coding standard](http://llvm.org/docs/CodingStandards.html) and [CppCoreGuidelines](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md).
I have some different styles depending on whether I'm at work or working on personal stuff: ### Class Names * At work: `MyClass` * At home: `my_class` Work enforces Java-esque PascalCase class names, which is fine and common. Personally, I prefer to match the C++ style because it is less jarring when standard code and my code are mixed. ### Function Names * At work: `FunctionName();` * At home: `function_name();` Same rationale as above. Worth noting that matching the C++ stdlib coding style can be beneficial when writing functions. For example, the range-based `for` loop uses `begin()` and `end()` for iterable containers. If you declare your container iterator methods as `Begin()` and `End()`, you cannot use range-based `for` loops. ### Variable naming I use the same style for personal code and work code: * Standard variables: `int myInt;` * Pointers: `int *pMyInt;` * Class member variables: `int m_myInt;` ### Variable modifiers: * The `const` modifier is always declared *before* the type name: * `const int myInt;` * Pointer and reference symbols are always aligned next to the variable name, instead of the type name. This is good for avoiding subtle errors when declaring multiple variables on the same line: * `int *pMyInt;` * `int &amp;myInt;` * `int *pInt1, *pInt2;` ### File naming * Header Files: `*.h` * Source Files: `*.cpp` * Header/Source combined files (e.g. headers for templates): `*.hpp` ### Newlines and Indentation * Newline between expression and braces. * Tabs to indent spaces to align. The following example uses hashes to indicate tabs, and dots to indicate spaces: - class foo { public: # //! Default Constructor. # foo(); private: # int.............m_myInt;......//&lt; My integer. # std::string.....m_myString;...//&lt; My string. }; ### Line Width 80 characters is to narrow for code, I use 132 character line limits and rarely go beyond that. Functions that require more than 132 characters for all parameters get broken down as follows: myClassInstance.CallFunctionWithLongName( myInt, myString, myOtherParameter); ### Comments At home and work, I stick to the [Doxygen comment style](http://www.stack.nl/~dimitri/doxygen/manual/docblocks.html). Autogenerated documentation FTW! Inline comments in functions are used infrequently, and rarely used to describe what code does (the code should do that), but rather to explain WHY a piece of code is the way it is. Inline comments always use `//` syntax and never `/*...*/` syntax. ### Namespaces Used infrequently, never causes indentation: namespace foo { // Do not indent here! class my_class { }; } ### Other Miscellaneous * I favour many small functions over a few larger functions. The main exception to this is for optimization, where keeping a lot of data in scope can improve performance in specific scenarios. * Unsigned integral values are suffixed with `u` (e.g. `1000u`). I'm pretty inconsistent with this though, so can't say that it's part of my style. * Only use raw pointers as a last resort. Modern C++ has an huge collection of smart pointers for handling pointers in a safe manner: `unique_ptr&lt;&gt;`, `shared_ptr&lt;&gt;/weak_ptr&lt;&gt;`, `observer_ptr&lt;&gt;`, etc.
Why would you use tag dispatch instead of SFINAE here? Smth like this: #include &lt;string&gt; #include &lt;iostream&gt; #include &lt;type_traits&gt; using std::cout; template&lt;class T&gt; constexpr bool is_pointer = std::is_pointer&lt;T&gt;::value; template&lt;bool B, class T = void&gt; using enable_if = std::enable_if_t&lt;B, T&gt;; template&lt;class T, enable_if&lt;is_pointer&lt;T&gt;&gt;...&gt; void meow(T t) { cout &lt;&lt; "Pointer: "; if (t) { cout &lt;&lt; *t &lt;&lt; "\n"; } else { cout &lt;&lt; "(null)" &lt;&lt; "\n"; } } template &lt;typename T, enable_if&lt;!is_pointer&lt;T&gt;&gt;...&gt; void meow(T const&amp; t) { cout &lt;&lt; "Non-pointer: " &lt;&lt; t &lt;&lt; "\n"; } int main() { int x = 1729; int * p = &amp;x; meow(p); p = nullptr; meow(p); const std::string s("KITTY"); meow(s); } 
(ripgrep landed in Visual Studio Code on nightly, I know it's different than Visual Studio but your "no plans to support" is a bit too strong :p)
Something like this: struct AlwaysUseStructs { void someFunction() { if (cond) { // small if } } double publicData; private: int _privateData; }; Also, I use tabs. 
*whispers* clang-query *whispers*
Okay, thanks for putting together these benchmarks they look great and they are quite informative! Now looking at the numbers, it seems to me that the performance is very close. Both implementations look great! If it was up to me, I would simply choose the implementation that makes my code the easiest to write, maintain, and understand (in case a new person has to improve or fix it).
Crouching banana, hidden monkey.
Easier to read. The bracket at the end of the line can easily be overlooked. If I wanted to be queued by indentation that a new block was beginning then I'd work in Python. To each their own, of course. I'm just glad every C++ job I've had agrees with me. :) I do find it odd that Google doesn't like a bracket on a new line but even Google isn't perfect. 
There is an up to date list of books [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list).
You see a lot of Python influence in the Rust community and one of the big viewpoints the Python world has is "modules in the standard library have one foot in the grave". (eg. Because of the stricter backwards-compatibility requirements of locking down your API for an entire major version of the language itself, Python 2.x stdlib has `urllib`and `urllib2`... but everyone uses `requests` and its underlying `urllib3`, developed by people who intentionally keep it out of stdlib, for everything but trivial scripts which don't install via `pip`... and even then, many of those use `requests`. It's not the only example.) Having a blessed set of packages outside stdlib allows them to do things like a "1.x long-term support vs. 2.x current" version split without having to clutter up stdlib, so people with that mindset favor a reliable, easy-to-use, semver-friendly package system over a fat standard library.
I disagree it separates context that's really important to preserve imho. It's like breaking every sentence into a new paragraph. Sure paragraphs are great, but if every sentence is one then you lose the benefit. Also that space in front of the curly brace is something I don't think I could tolerate. It looks like wasted time.
&gt; It's like breaking every sentence into a new paragraph. Sure paragraphs are great, but if every sentence is one then you lose the benefit. To use your analogy, I would equate lines/statements to sentences and blocks to paragraphs. 
The entirety of `&lt;algorithm&gt;` and `&lt;numeric&gt;`.
I think boost::any is good candidate. It is amazingly short considering that it can give you runtime generic support. http://www.boost.org/doc/libs/1_55_0/boost/any.hpp
&gt; What do you mean by this? I think it accepts the same command line parameters. It does, but if you try building a project that has PCH set up conventionally you get this: 1&gt;clang-cl.exe : warning : support for '/Yc' without a corresponding /FI flag not implemented yet; flag ignored [-Wclang-cl-pch] It only works with the PCH reference injected by forced include, which is not the way VC++ projects are conventionally set up. &gt; Yes, I've only encountered a few cases where intrinsics were not implemented yet, but filing bugs about them got them implemented quite quickly. I would if it were a fire-and-forget form, but apparently you have to email to get an account on Bugzilla. That's more effort than I can spare right now. That having been said, it works better than Clang/C2 in this regard (non-functional intrinsics + no inline asm support = impossible). The main issue I had to deal with was that Clang requires you to segregate your ISA-specific code paths into separate functions and tag them with target attributes. Not too bad, but definitely requires rework of existing VC++-based code. 
No `camelCase`ing. Just `int m_foo`. `CamelCase`ing only for classes and template parameters, which we usually give a postfix `T`.
Also `z` for `std::size_t` literals please. There was a proposal somewhere IIRC?
We don't have the env, maybe in the future we will have a try.
s is taken for seconds and string IIRC… i might work, overall I think it's a nice idea. Post it to the committee group isocpp.
Duff's Device: send(to, from, count) register short *to, *from; register count; { register n = (count + 7) / 8; switch (count % 8) { case 0: do { *to = *from++; case 7: *to = *from++; case 6: *to = *from++; case 5: *to = *from++; case 4: *to = *from++; case 3: *to = *from++; case 2: *to = *from++; case 1: *to = *from++; } while (--n &gt; 0); } } Now perhaps this could use some improvement, but I've always found it hilarious that you can just mix a switch and loop together like that. Note that the lack of ++ on to is not a mistake, but is specific to the problem Duff was solving (a memory mapped register). Normally you wouldn't do things like that.
The same style as Bjarne does on his books, favoring using the best features of C++'a type system and libraries for writing safe code. This includes never turning language features off. Usually with all warnings configured as errors. Old C style coding only when confirmed by a profiler that is actually an improvement.
I thought that too, but sadly.. That won't work.. if you want integers as parameters to UDL's you'll need to use *unsigned* long long. The unary minus will be applied after the UDL, which means the result for std::int8/16/.._t is promoted to int. Maybe I'm wrong (I hope so!) but [I tried](http://coliru.stacked-crooked.com/a/a7556f693ff6ec73), and failed.
I'd just like to point out I realized this was your comment before ever reading the username because of the usage of meows.
shit style
I am doing a metaprogramming project right now, and it relies heavily on std::index_sequence, but for the love of me I can't figure out the syntax. I know what it does, and I know how it works, but the syntax escapes me. Do you know of any resources besides cppreference which might explain this? I am using it on structs and cppreference only provides function examples. Here's the code I find confusing: template&lt;typename T&gt; struct my_struct; template&lt;size_t... idx&gt; struct my_struct&lt;std::index_sequence&lt;idx...&gt;&gt; { do_stuff()... }; How is a &lt;size_t... idx&gt; a specialization of a &lt;typename T&gt;? Why do we have to specialize it? If it's a specialization shouldn't the angular brackets after template be empty? What does std::index_sequence&lt;i...&gt; *inside* of the angular braces even do?
instance initializes 1 time, the first time the function is called Edit: static memory != Stack memory
On the stack, you say? I'm think you're a little fuzzy on how stacks work. Also you didn't answer my question.
You are right, it does check every time object is accessed and object is initialized in `.data` (?) section or similar.
Yes, it does. When I want something in the language I go to meetings and advocate strongly for it. It has worked pretty well so far. You just have to know how to collaborate with people and be willing to compromise.
Would it be possible to use delegating constructors to enable the use of tag dispatching for constructors as well?
These alternative but "incomplete" solutions are my exact issue really. You can't use auto a = unsigned short{0U}; because it doesn't support that format. Using uint16_t is "kinda" one solution, but unsigned short and uint16_t aren't guaranteed to be the same and it also doesn't fix the hole that the standard leaves with this outlier type. As you mentioned, UDLs don't work here (though arguably that's a problem in and of itself?) and I don't think using typedefs is a good solution either for all the reasons typedefs are a bad idea in the first place. The only solution I can think of specifically for unsigned short would be to use static_cast: auto a = static_cast&lt;unsigned short&gt;(0U); which isn't really a solution at all. Additionally, for embedded programming, it might be nice to have explicit literals for specific sizes (ala, the ui8 style formatting in the main post). To me it feels very much a "legacy C" situation, where they haven't really thought to add this additional functionality - so I'm mostly gauging interest before writing something up more thoroughly and posting it to the committee, or at least someone that can do it on my behalf.
completely forgot about that one actually. I'll take a look and see if I can find this proposal! Edit: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0330r0.pdf here it is
Heya. Blog author here. I've never seen this error myself, but that's definitely an issue originating from LLVM. I've found this report which has a similar backtrace: https://bugs.llvm.org//show_bug.cgi?id=28454 Please try to isolate which file is causing this and create a minimal working example which you can attach to the bug report.
"handy" 
&gt; Here's the code I find confusing: I assume you mean template&lt;typename T&gt; struct my_struct; template&lt;size_t... idx&gt; struct my_struct&lt;std::index_sequence&lt;idx...&gt;&gt; { /* ... */ }; &gt; How is a &lt;size_t... idx&gt; a specialization of a &lt;typename T&gt;? It's not, `std::index_sequence&lt;idx...&gt;` is `T` there. `template&lt;size_t... idx&gt;` has nothing to do with `template&lt;typename T&gt;`, it's just the "variables" you can use in specifying the family of types you are specializing for. &gt; Why do we have to specialize it? To access the arguments to `std::index_sequence` as`idx`. For example, if you have template&lt;size_t... idx&gt; struct my_struct&lt;std::index_sequence&lt;idx...&gt;&gt; { static void f() { (std::cout &lt;&lt; ... &lt;&lt; idx) &lt;&lt; "\n"; } }; then `my_struct&lt;std::index_sequence&lt;1, 2, 3&gt;&gt;::f();` would print "123". &gt; If it's a specialization shouldn't the angular brackets after template be empty? If it's a full specialization then yes, e.g. `template&lt;&gt; struct my_struct&lt;std::vector&lt;int&gt;&gt;` would specialize `my_struct` for the case where `T` is exactly `std::vector&lt;int&gt;`. But suppose you wanted to specialize `my_struct` for any kind of `std::vector`, then you would want something like `template&lt;typename T, typename Alloc&gt; struct my_struct&lt;std::vector&lt;T, Alloc&gt;&gt;` instead.
What is the point here? Auto is great, and I use it as much as possible, but I fail to see what is gained in this instance. This is exactly a case where you just want to name the type explicitly instead.
Also easy to select the block, copy and paste it somewhere. Copy-Paste! The best way to generate ridiculous amount of code in no time!!!11
&gt;Using uint16_t is "kinda" one solution, but unsigned short and uint16_t aren't guaranteed to be the same Yep, also specifying the amount of bits in the variable is bad whenever it isn't necessary. &gt;and it also doesn't fix the hole that the standard leaves with this outlier type. &gt;As you mentioned, UDLs don't work here (though arguably that's a problem in and of itself?) They **are** outliers. Arithmetic operators in C++ cast types smaller than `int` **to** `int`. You don't have this problem with `long` and `long long`, because they are larger or equal to `int`, this is why their literals just work. The problem is with int types smaller than `int`, and how literals work. `auto v = -1LL` is the same as `auto v = -(1LL)` the unary minus is separate. You'll probably also see the problem when using the Microsoft's literals extension, I don't use MSVC, so I can't test it, but could you try and see what happens when you use code like this?: auto v = -1i8; std::cout &lt;&lt; sizeof(v); I suspect you'll see 4 instead of the *expected* 1, because unary minus converts to an int in this case. &gt;You can't use `auto a = unsigned short{0U};` Wow, I just assumed you could, I should've tested it :/. I don't use auto in these situations, which leads me to a question I have.. Why do you want to use auto everywhere? Don't get me wrong, I understand why AAA is useful, but don't forget what the first A stands for, here you want a *specific* type, AFAIK `auto` is then useless so why not just use the old method in cases like these? I guess it could look a bit strange when the rest of your code uses `auto`, but I don't see that as a *big* problem. In another comment you say it's because you like consistency, I get that, but sadly I think you'll have to move on. It sucks that this is a problem, but there's no easy fix other than writing code that you might think looks a little less pleasing, in this case I think it wouldn't make the code any harder to understand. &gt;To me it feels very much a "legacy C" situation It definitely is, which sucks. We're stuck with it though, but there's one more thing you could try, find or create a safeint class, that prevents and improves casts. But I'm unsure that's a good idea.
You'll have a hard time avoiding that check, particularly in thread-safe code. But singletons are evil anyhow.
Right, it makes more of a difference when the code should never be run from more than a single thread. I suppose `thread_local` would probably fix that.
Of course, I even said as much in the opening post - but that doesn't mean there can't be a discussion of an alternative syntax (a shame really, because 's' / 'us' is the most logical) if the feature is deemed worthwhile.
It is worth noting the C++ standard looks at it the same way. `-100` is unary-minus applied to the integer literal 100, and this leads into some strange behaviour: `-0x80000000` is an `unsigned int`, `-2147483648` is a `long`/`long long` depending on `sizeof(long)`, and on MSVC you get `unsigned long`, so yay consistency. Basically integer literals are fucked.
The link to the const-correctness article is broken - the right link is https://blogs.msdn.microsoft.com/vcblog/2017/03/07/check-for-const-correctness-with-the-c-core-guidelines-checker/ Edit: Link is now fixed. p.s. CppCast is awesome.
For a demonstration of the power and elegance of the standard library, it's hard to beat /u/TemplateRex's [implementations of various sorting algorithms](https://stackoverflow.com/questions/24650626/how-to-implement-classic-sorting-algorithms-in-modern-c). Here is merge sort for example: template&lt;class BiDirIt, class Compare = std::less&lt;&gt;&gt; void merge_sort(BiDirIt first, BiDirIt last, Compare cmp = Compare{}) { auto const N = std::distance(first, last); if (N &lt;= 1) return; auto const middle = std::next(first, N / 2); merge_sort(first, middle, cmp); // assert(std::is_sorted(first, middle, cmp)); merge_sort(middle, last, cmp); // assert(std::is_sorted(middle, last, cmp)); std::inplace_merge(first, middle, last, cmp); // assert(std::is_sorted(first, last, cmp)); } 
Very interesting! I wonder if I could get this to give me polymorphism-through-dispatch for objects in shared memory. Hmm.
Others already explained it, but I think it might be also helpful to explain it in a step-by-step manner: You know you can specialize a template: template&lt; typename T &gt; struct foo { ... }; template&lt;&gt; struct foo&lt; int &gt; { ... }; // ^^^ the type you specialize for Now you can also specialize not just for `int`, but also for types like `std::vector&lt; int &gt;`: template&lt;&gt; struct foo&lt; std::vector&lt; int &gt; &gt; { ... }; // ^^^^^^^^^^^^^^^^^^ the type you specialize for Since you specialize for one specific type, this is called a full specialization. What if you want to specialize for all vectors? This is what is called a *partial specialization*. Instead of giving it one specific type, you make it a template itself by extending the `template&lt;&gt;`: template&lt; typename U &gt; struct foo&lt; std::vector&lt; U &gt; &gt; { ... }; // ^^^^^^^^^^^^^^^^ the types you specialize for Note that I used `U` as it has nothing to do with the `T` from the base template. In practice, you will often see `T` in such a case, but it is still an independent `T`. The above is not complete, since `std::vector` also has an allocator. What you would really need is: template&lt; typename U, typename A &gt; struct foo&lt; std::vector&lt; U, A &gt; &gt; { ... }; Or even simpler and more generic: template&lt; typename... Us &gt; struct foo&lt; std::vector&lt; Us... &gt; &gt; { ... }; In the latter case, `Us...` is deduced to the value type and the allocator, for example if you instantiate `foo&lt; std::vector&lt; int &gt; &gt;`, the type pack `Us...` is `int, std::allocator&lt;int&gt;`. This, of course, also works when you deduce integral values instead of types. `std::index_sequence&lt;0, 1, 2&gt;` is a type (suitable for the `T` in the base template, and if you specialize for template&lt; std::size_t... Ns &gt; struct foo&lt; std::index_sequence&lt; Ns... &gt; &gt; { ... }; you get the indices as `Ns...` when you instantiate `foo&lt;std::index_sequence&lt;0, 1, 2&gt;&gt;`. Additionally, you could create the index sequence at the point of instantiation, for example `foo&lt;std::make_index_sequence&lt;3&gt;&gt;` as `std::make_index_sequence&lt;3&gt;` simply is a type alias for `std::index_sequence&lt;0, 1, 2&gt;`. Each step is simple, but all of them together might not be easy to understand when you are not familiar with it. I hope this helped to get started on how those integer/index sequences work.
I am well aware of the existence of ranged for loops. Not sure what I would be doing on /r/cpp if I didn't :D
For issue 1 the way literals work with unary minus should change before they get useful, and they then wouldn't be consistent with how variables work with unary minus. I don't know how much code would be impacted by such a change, but because of this it might not be worth it. I'm not sure what you mean with issue 2, I think you're saying that `auto a = unsigned short{-48};` should be made to work. I agree, I don't see any problems with that. Maybe there's a good reason why it doesn't work like that that I can't think of, it's such strange oversight that I seriously doubt it hasn't been done on purpose. If I've understood you correctly I'd say the fixing second issue is a lot more realistic than the first, but the second issue is fixable with a simple typedef or by doing `auto a = (unsigned short)-48`, it's not ideal, but it's not that much of an issue to me either.. This problem won't keep me up all night until 4am. ;)
 if (something) { fooBar(); } else { iHateWhenThisHappens(); } I hate when the ending braces align like that.. the braces just become a random soup for my eyes. But this is subjective, isn't it? For all purposes my subjective view on this considers relevant makes this a trade-off between readability and condensing more information into smaller number of lines of code. YMMV, but I am coding on large terminals and/or retina / hi-dpi screens so I got more than enough screen estate so trading off readability for more of something I already have more than enough is not one that I choose. Each to his own. :) 
That's exactly my thinking - that there's an "issue" to resolve (the inability to use the format `auto a = unsigned short{b}`) and a feature to be added (the use of iN and uiN as cstdint literals). Don't worry, I'm not *that* pedantic! I was just upgrading some old personal C/C++ code to take advantage of C++11/14/17 and came across that issue is all :)
The trailing underscore trend seems to be spreading like wildfire; I hate it almost more because it makes code accessing members look like cancer: int bar = foo_.bar; On the other hand a lot of people really love that so there must be something super obvious I am missing. p.s. I know you wrote leading, but trailing is even worse and I had to take advantage of this therapy session. :)
Theoretically there should be nothing stopping this, since there is hardly any runtime for Rust, just like C++ (no GC). Maybe it can even be done by just using LLVM asm. But yeah, I don't think there is some easy `extern "Rust" {}` way yet (it'd require cooperation from both languages).
[s](http://en.cppreference.com/w/cpp/chrono/operator%22%22s) and [us](http://en.cppreference.com/w/cpp/chrono/operator%22%22us) are already taken and I don't think they should be reused. That's just going to make it impossible to figure out if `auto x = 0us;` is declaring an unsigned short or a microsecond time duration without looking at the entire file to check for using directives. I would be alright with introducing the explicitly sized Microsoft literals as long as they were put into their own literal namespace in &lt;cstdint&gt;, but they would have to map to the fixed size integer types rather than short/long/etc.
That's more about math than any programming language.
&gt; The u/STL's dispatch version looks clearer to me. Didn't you just confirmed my "just a matter of taste" comment? ;-)
What else would you expect when averaging ints?
B, A when line gets too long. &gt;what's the StyleX that trumps the all others? None. It's a bikeshedding question.
I use `UpperCamelCase` for just about everything (I use `snake_case` for types and `UPPER_SNAKE_CASE` for macros). I don't have collisions between variable names and functions because function usually the form of verbs (`Render`, `GetFoo`, `DoBar`, `WriteLog`) or questions (`IsFoo`) whereas variables are nouns (`Renderer`, `Foo`, `Log`). I also don't care if parameters shadow member-variables, I can just write `this-&gt;`, and for setters I consider it added clarity (`void SetFoo(int Foo){ this-&gt;Foo = Foo; }`) and if two variables have nothing to do with each other there is usually better ways of differentiating them than an underscore in my experience.
I hate that as well. I think the only advantage is trailing underscore is allowed anywhere in the language, whereas leading underscore is only allowed in non-global scopes (so basically inside classes since you can drag stuff out of namespaces).
He has a point, as it would be overly verbose to cast each one to float individually, so I made [this](https://www.reddit.com/r/cpp/comments/5ztihq/what_is_the_one_piece_of_c_code_algorithm_snippet/df2396t/) which helps. 
So, is something like if (something) { foo(); } else { bar() } Better from your perspective?
Yes. However, there are situations in which delegating constructors with tag dispatch are insufficient - e.g. when constructors (like pair and tuple) need to be conditionally explicit. There are other situations in which SFINAE is superior. For example, disambiguating `vector(InIt, InIt)` from `vector(size_t, const T&amp;)`. In C++03, this was specified to work without SFINAE, allowing `vector&lt;vector&lt;int&gt;&gt; v(11, 22);` to compile. While convenient, this essentially allowed `22` to be implicitly converted to `vector&lt;int&gt;`, breaking the usual rules. (The reason is that the non-SFINAE approach selected the `(InIt, InIt)` constructor, then the second arg was `static_cast` to the element type.) In C++11, SFINAE is used to disable the `(InIt, InIt)` constructor for `InIt = int` which is bogus. That leaves the ctor taking (in this example) `(size_t, const vector&lt;int&gt;&amp;)`, and `22` can't be implicitly converted to `vector&lt;int&gt;`.
yeah, I've more or less come to the conclusion that s/us can't be sold. I still think the cstdint literals are worth considering separately though (and size_t already has a proposal, so I don't need to worry about that). Instead, I'm not more interested in the potential for making `auto a = unsigned short{b};` legitimate code. What would be your thoughts on that? (Considering your credentials, you're probably the best person to ask in here :P)
Looking at all the implicit int conversions I don't consider it type-safe.
That syntax seems like it would either be confusing or be of limited use depending on how it was implemented. Narrowing conversions are generally prohibited for list initialization, so if `b` were of type `int` I would expect that example to cause a compilation error. If narrowing conversions are allowed, then it's inconsistent and leaves me wondering why `unsigned short{b}` is any better than `(unsigned short)b`. If narrowing conversions aren't allowed then this will probably only get used for constants for the most part. Literals would provide some utility by being much shorter than writing out a full integer type, but why is `auto a = unsigned short{b};` any better than `unsigned short a = b;`? Using `auto` is great, but in this case the new syntax would make using `auto` even longer than just writing it normally.
User defined literals and lambdas: 20_ms.Later([]{ cout &lt;&lt; "Hello "; }); 40_ms.Later([]{ cout &lt;&lt; "World!"; }); Sure you have to implement .Later yourself.
&gt; in important areas like web it seems a trend StackOverflow survey and according to CodingDojo, it seems that full-stack salaries are higher In web it's not really full-stack. It's more like random-stuff.
Aha, that makes sense.
Which version of clang-tidy do you have? If it comes from your distribution, you may want to contact the package maintainers. Otherwise, grab the LLVM 4.0 release made recently and try to use that instead!
the return type could have been `decltype(sum / 1.0)` by default. Note sum / 1.0 is not necessarily double; A vector3d class that implements +, - and / by real number can be calculated average, and the result should have type (vector3d / double) == vector3d.
`avg&lt;Complex&gt;(complex1, complex2, complex3)` would not compile, but neither will `avg&lt;double&gt;(complex1, complex2, complex3)`
It's still beautiful!
Ranges started in Boost. There is a reason Eric calls it ranges-v3.
meows should become standard placeholders for cop speak
I prefer not prefixing my accessor names with "Get" because it's shorter and more resembles the STL.
I don't understand. If you want to comment out the whole if-block, then you need to comment out the if-expression anyway, and I don't see why you'd want to leave the if-expression but comment out its body. Can you give an example?
I'll just share one style rule that I think is uncommon but that I've found useful. I like breaking long lists of parameters/arguments onto multiple lines this way: foo ( arg1 , arg2 , arg3 ); rather than the more common way: foo( arg1, arg2, arg3); I do it this way because I find it harder to mess up the commas while refactoring when they occur at the beginning of the line rather than the end. Also, I put the closing parenthesis/brace on its own line to make reordering/removing/adding things easier.
The construction of the pointer is thread safe. ie there is a "lock" (of some kind) protecting the `singleton_vec = some_value`. That doesn't mean all the other work that happens "before" the `return` in the lambda actually _happens before_ the `return` in the lambda. Remember, the compiler or the CPU or the memory subsystem can reorder your instructions (if it doesn't make any difference from a single threaded point of view). This probably works now, but once optimizers get "better" at optimizing atomics, I'm not so sure.
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/601b4p/help_on_a_school_project/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Derp, I messed up the casting, that's what I get for coding in a rush, fixed it. `avg&lt;double&gt;(complex1, complex2, complex3)` still won't compile because there's no way to get a complex to a double without using `.real`
&gt; I'm a professional metaprogrammer, so I like to think that my opinions about metaprogramming carry some weight. O_O I'll just leave the room...
Never omit the `constexpr`s for array-like types, even if you're going for minimalism.
Thanks for the feedback. I like your first point, because it is clearer and less redundant. You're right about the stack overflow example. The stack building part or the whole recursive call could be optimized out. Clang optimizes the whole thing out. I think the recursive call needs to change global state.
I use Cool::Cool(int a, int b) : m_a(a) , m_b(b) { } so a slight variation on A to preserve vertical space.
I have near exact same style, only that I indent namespaces.
Wait, so int const &amp;f(int const &amp;a) { return a; } int r = f(3); is undefined (or more accurately, implementation-defined)? Wow my C++ sure is rusty. Does any compiler give any kind of warning about the definition of f()?
This is an interesting question. I can't say that I know for sure, but I suspect that what you're talking about does fall into the "compiler-specific behavior" area. That being said, if you're not using RTTI, virtual functions, or inheritance, and you can guarantee that there's no additional padding between data members, I think you could probably get this to work via a reinterpret_cast (or by using a void pointer). I would make absolutely sure sizeof(MyData) == sizeof(MyClass) first. It would also be wise to test under several different compilers. More importantly, I would suggest careful profiling to discover if this particular code segment really is a bottleneck that merits an optimization like this. I suspect in many cases, the compiler may be able to use a direct memory access if the proper flags are set, which would effectively cancel out any potential gains. I'd very much like to see a benchmark (assuming of course that this operation works as expected under some standard compiler). If you decide to run one, please share what you discover! Cheers! :-) Edit: Fixed a typo
Not compiler-specific, it's pure UB.
I can ensure sizeof(MyData) == sizeof(MyClass) by some static assert. However, I don't want it be compiler specific behavior, I want to ensure it's standard behavior, though to be honest I doubt that.
You are correct that usually a forced include can be added safely if the precompiled header is written properly, but in my experience this is not how projects are typically set up on Windows. If you create a new Win32 project in Visual Studio with precompiled headers enabled, it will be set up to create/use a PCH through /Yc and /Yu compiler options but no forced include option (/FI). This is therefore something that has to be fixed up on every project when attempting to switch the toolchain from MSVC to Clang. I have my solution set up so that all projects can be gang-switched to a different toolchain through a single .props file, so any additional needed per-project fixup is noticeable. I've also worked on projects where the fixup would be more annoying, such as PCH exclusions for individual files scattered throughout projects. Clang on Windows has made a lot of progress toward being a drop-in replacement for MSVC and it would be nice if the need for this change could be lifted as well. 
Both sides of this are shitty code. I don't mean this to be an ass, but that code is unreadable garbage. That is the sort of code that makes for bugs and maintainable garbage. The only purpose of it is to show off. Who gives a shit about L Pr or X outside of a CS course? This guide might be of use to someone studying for a code obfuscation contest. 
&gt; If you create a new Win32 project in Visual Studio with precompiled headers enabled, it will be set up to create/use a PCH through /Yc and /Yu compiler options but no forced include option (/FI). This is therefore something that has to be fixed up on every project when attempting to switch the toolchain from MSVC to Clang. Yes, but you fix this in one place (the project file) and the change is 100% harmless &amp;ndash; every source file compiled with `/Yu` _must necessarily_ include the pch at the top of the file. Adding `/FI` to those source files just makes them include the pch twice, which given `#pragma once` and/or include guards is completely benign. What am I missing?
I think this person's use of it is about as wrong as possible as far as being good code. 
It's not one project file, it's every project file. Some of which come from external libs, which are set up differently and don't use the same precompiled header name, which you have to copy manually from the PCH setting to the /FI setting. Which is one more thing I have to fix up on every project just to try Clang. I just wanted to call out that this is still something you need to fix up on most projects. If you have the benefit of having projects set up this way already or a surplus of time to manually twiddle settings on existing projects to try Clang, good for you. 
That wouldn't help for treating it as an array of `MyData`.
Why not just say: MyData* someDataPointer = &amp;someArray[0].data; and then wherever this code is make it a friend of MyClass. Or else provide some member access or something. Otherwise if you try to use someDataPointer you might have undefined behavior if your compiler doesn't have relaxed pointer safety. (Note that strictly speaking the last line is never UB until you use the pointer. You can convert pointers any which way however you want in completely nonsensical ways, you don't have any trouble unless you try to use the pointer. We obviously assume you are going to use the pointer)
Shared pointers have a runtime cost, so using them automatically is out if the question. Unique pointers by default could work in theory, but that would probably change the semantics too much. 
(+1) Of course a real implementation which wanted to work with bidits would be better to avoid the distance/next.
Having used both Boost.Range v2 and range-v3 extensively, there isn't _anything_ in range-v3 that even remotely similar looks like anything in Boost.Range v2. So... sure, Boost.Range v2 is prior art (so are many other range libraries btw), but my point stands, the Range TS is directly the outcome of range-v3, and range-v3 has never gone through a Boost review, and probably never will.
You know what's shorter than both and better than both? Not using any prefixes or suffixes at all.
Holy shit you have cancer.
You must be incredibly bad at writing code if you don't just automatically write the spaces in the right place.
The correct style is this: Cool::Cool(int a, int b) : a(a), b(b) {} It's never, ever correct to prefix `m_` to variable names.
That code is illegal. If you declare something `const` then it *must* be thread-safe.
**Here's a sneak peek of [/r/rust](https://np.reddit.com/r/rust) using the [top posts](https://np.reddit.com/r/rust/top/?sort=top&amp;t=year) of the year!** \#1: [Announcing Rust Language Server Alpha Release](http://www.jonathanturner.org/2017/01/rls-alpha-release.html) | [49 comments](https://np.reddit.com/r/rust/comments/5olcan/announcing_rust_language_server_alpha_release/) \#2: [ripgrep is faster than {grep, ag, git grep, ucg, pt, sift}](http://blog.burntsushi.net/ripgrep/) | [144 comments](https://np.reddit.com/r/rust/comments/544hnk/ripgrep_is_faster_than_grep_ag_git_grep_ucg_pt/) \#3: [Introducing MIR](http://blog.rust-lang.org/2016/04/19/MIR.html) | [46 comments](https://np.reddit.com/r/rust/comments/4gp6ex/introducing_mir/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/5lveo6/blacklist/)
[cppreference says](http://en.cppreference.com/w/cpp/algorithm/max): &gt; Capturing the result of std::max by reference if one of the parameters is rvalue produces a dangling reference if that parameter is returned So this is bad: const int&amp; r = std::max(1, 2); And this is ok: const int r = std::max(1, 2); 
&gt; Nope, undefined. Would you happen to have a citation for that in the standard? Just saying it is undefined isn't particularly convincing.
Good work! I see a lot of interesting libraries here, but this one satisfies an actual need I have all the time. (A shame that I don't have any projects that can use C++17 right now, but this will come.) Some comments. * _You must put this into a namespace!_ Having a global symbol called `flag`is just asking for trouble and collisions. * Bravo for having no external dependencies! * There are no C++17 compilers that don't support `#pragma once`. Perhaps consider replacing the `#ifdef` guards with this construction. * Strongly consider having also a "single file" version of this project with the main .h and the three `details/` .h files glued together into one file. That last one needs a bit more comment. It makes it so much easier to use a library when you can just drop a single .h into your project. For example, I switched from using Googletest to [Catch](https://github.com/philsquared/Catch) on new projects, precisely because it was a much easier sell to collaborators and management to say, "Add one file and go," than it is to say, "Introduce this new dependency and a bunch of subdirectories. I personally prefer a git subtree or submodule - I think it's more elegant. But the single file version will help your adoption dramatically IMHO, and at very little cost to you. 
You should probably target a newer version of CMake (2.8 is a VERY broad version range) and create an interface library, propagating the include directory with "target_include_directories()". 
Not a book but you could have a look at Boost.Hana's documentation: http://www.boost.org/doc/libs/1_63_0/libs/hana/doc/html/index.html#tutorial-introduction It's the way to go for metaprogramming these days.
Why not? 
Could you please explain why? The constructor is not being called though the reinterpreted pointer, neither is the destructor. He is merely reading/writing to the member variables. As /u/wqking says, as long as sizeof(MyData) == sizeof(MyClass) this should work just dandily. And it should be the same since the compiler is not injecting any data padding, vtables or inheriting from multiple classes. 
In clang-format terms: BasedOnStyle: LLVM IndentWidth: 4 Standard: Cpp11 UseTab: Never ColumnLimit: 80 AccessModifierOffset: -4 ConstructorInitializerAllOnOneLineOrOnePerLine: true However, I often find myself just using the default config of clang-format, which is similar, but with 2-indents. It was weird at first, but now I find it easy to read and it's better with the 80 ColumnLimit. At work, I finally convinced the team to use clang-format. On the other hand, the majority voted to use 160 chars ColumnLimit which drives me crazy.
You are maybe messing with aliasing rules and alignment rules, although for the last ones you are using implementation specific stuff anyway. I would not expect that to work *portably* today, and I would expect it to risk to break with your next compiler update if it happens to work for now because of some kind of miracle.
&gt; I would not expect that to work portably today That's why I want to check if it's well defined behavior. If it's UB, I won't do it any way even current compilers give correct result.
&gt; you should be fine. Or not. I find the aliasing rules particularly difficult to master in all their details, so I tend to ere on the safe side, and think this will *probably* break some, depending on how someArray and someDataPointer are otherwise used. Plus here you might also have alignment issues.
But who cares if the space is to the left or to the right. Does it really ruin your concentration that much?
I think this is a little dangerous way to approach the problem, if you don't have an already very clear view of how compiler authors "leverage" UB to get some "optimizations". For the example programs the authors used, the presented results were obtained. However, for the very same UB in a different program, even marginally so, the behavior can very well differ. So you can't make any a-priori practical rules of the presented "pass" results, because you have no proof some of them will fail in other contexts (and I know that some actually will) 
Well, thats what the static_assert and assert are for, guarding yourself for when the compiler decides to "mess up" your hacks :D
If you truly believe this, the right thing to do is to go to the admins, not the mods. Brigading is a serious offense that gets subreddits banned. Mods can't do anything other than lock a thread.
The columns of Debug and RelWithDebInfo show how the compilers trade off showing the issue to the user and optimizing the program. To get more strictly functioning code across platforms, the program should halt and emit a different error code so that someone could eliminate the behavior. Runtime observed behavior means dynamic analysis (i.e. running the program with some instrumentation). Static analysis in these cases means compiler warnings.
I second that, even though it doesn't really cover C++11/14. It's an excellent book and I learnt a lot from it!
Just few things I noticed. Address of referenced object can never be `nullptr` in C++. Dereferencing a null pointer to pass the object by reference, is undefined behavior. Int32 Int32::CompareTo(const Object&amp; other) const { if (&amp;other == nullptr) { return 1; } Your Array class is flawed by bugs. Your ArrayLength is unsigned int. Size of std::array is of type std::size_t. Then you later return the size as either Int32 or Int64. There may be many more issues, but I don't have time to read the rest of the code.
Yup. Easiest thing to do is feed in an initializer list. Read the documentation on `std::max` and you'll see many return references so you shouldn't be using temporaries with them. Instead, you want the by-copy return which is the initializer list overload.
"Address of referenced object can never be nullptr in C++. Dereferencing a null pointer to pass the object by reference, is undefined behavior." This is simply not true. References can be null. The *should* never be null, and seldom enough are that no one bothers checking against null.
Unless someone does a bunch of dumb stuff in an unsafe code block. Yes, it is nice that that would help you track it down but your point doesn't really stand. Yes, Rust can also be used to have quite a bit of static analysis done on it but the programmer can eschew it so it is just as much a convention in C++ as it is in Rust. No language wars!
&gt; 8.3.2/1: &gt; A reference shall be initialized to refer to a valid object or function. [Note: in particular, a null reference cannot exist in a well-defined program, because the only way to create such a reference would be to bind it to the “object” obtained by dereferencing a null pointer, which causes undefined behavior. As described in 9.6, a reference cannot be bound directly to a bit-field. ] Specifically, the compiler usually assumes that your program is well defined, so it will most likely assume `if (&amp;other == nullptr)` is always false in that context. 
This is essentially the same as converting to a (void*) and then converting to some other pointer type. As long as you convert back to the original type before using the pointer, you should be ok. Off the top of my head I can't think of any pointer conversion that would itself be undefined behavior (and not just ill-formed) unless the conversion calls some member function or something. You're even allowed to convert pointers to integer values and back and the standard says it's legal and safe (as long as the integer is big enough and as long as you convert back to the original type before using it). Edit: Actually, you're right, I just thought of one: I think if you try to convert a pointer to a base class that inherits ambiguously through multiple inheritance that is UB. Edit Again: Wait no, I just looked it up, that's ill-formed not UB. Edit: Also, you have to worry about alignment issues, but only if you actually use the pointer. Like, really you should never actually do this. And when you do it, you should use (void*) and avoid converting to the wrong pointer types.
DON'T use a `#define`. The entire history of C++ has been a methodical march away from the awful preprocessor.
I don't think this is a good project to begin learning modern C++ with: by trying to closely follow the .NET Standard Library's interface and idioms you aren't learning with any of the features that make C++ great: *value semantics*, *RAII*, *templates*, and so on. I briefly skimmed through your code and it's full of red flags. As an example, this is how you're defining `Char`: struct Char final : public Object, IComparable&lt;&gt;, IComparable&lt;Char&gt;, IEquatable&lt;Char&gt; { public: ~Char() override; private: char value; }; You're creating a polymorphic class hierarchy for a `char`. This is horribly unnecessary and inefficient. The idea of having everything derive from `Object` is also in my opinion a very flawed one, which doesn't make sense at all in a language like C++. Also, all your interfaces such as `IEnumerable` could be compile-time concepts. If you need a type-erased concept, there are solutions for that like Louis Dionne's [dyno](https://github.com/ldionne/dyno) library - but it shouldn't be the default, as it incurs a performance hit. C++'s philosophy is **"pay only for what you use"**.
It is though. You can talk about anything and deconstruct it in as much details as you want. the problem with C++ is the details are taught first. Everything is a rabbit hole, you just don't think about it https://xkcd.com/1741/ You may argue that some language are simpler. I would answer they are either less flexible, less performance oriented, or badly standardized. There are no free meal.
[Image](https://imgs.xkcd.com/comics/work.png) [Mobile](https://m.xkcd.com/1741/) **Title:** Work **Title-text:** Despite it being imaginary, I already have SUCH a strong opinion on the cord\-switch firing incident\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/1741#Explanation) **Stats:** This comic has been referenced 43 times, representing 0.0282% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_df3mdpj)
&gt; What's wrong with using C++/CLI? multiplatform support ? &gt; Qt, while not modern C++, is what you're looking for ? I agree, a more worthwhile and less complicated task would be to make a "modern-c++" header-only zero-cost abstraction facade to Qt
&gt; any more tedious than having to write an interface class definition and then an implementation of it That's a very low bar. Not to mention that most of us avoid that entirely by coding in the headers. 
It wasn't criticism! Let me explain, as you say, the use case. I have an application. Some data has to be stored in shared memory, to allow for inter-process communication. This is in the form of objects stored in a pool in shared memory. Communication is done through single-produce-single-consumer queues that hold offsets of items in the pools. Because of how virtual tables are handled in C++ implementation, they can't be used across shared memory boundaries. The virtual table pointer points to a location in the memory space of the program that constructed the object. When this is read by another process, it's unlikely to point to the right location. This forced us to flatten our object hierarchy. Instead of having a tree of classes, we have a single class that implements all the functions, hidden behind a pimpl-style "wall". The sub-classes are replaced by thin non-inheriting classes that call functions in the pimpl class. This also means that shared behavior isn't always easy to share between similar subclasses. Such a failure to express our intent in the language makes me sad as an architect :( So... My original musing was whether I could take advantage of **dyno** to implement a shared-memory queue that would allow having different types of objects in the same queue. I haven't reviewed the implementation details, so I don't know yet. The other concern was how much work would it be to convert the existing code to use dyno. After having read the README.md, I came to the conclusion that it would only require changes in the interface, and only in a few of the usage instances. That's good to know :) 
Maybe I read Modern C++ too late but I wouldn't recommend it. I understand how it might have been a disruptive book in the late 1990s, but in a post C++11 world the techniques shown there are first of all already well known, and have been improved a lot. Those interested in that kind of stuff are probably better of reading their standard library implementation of tuple, functional, ... or modern libraries like Hana, FIT or range-v3.
Thing is, "C++ has these defects, let's learn from them and make something better" is what led to - Java - C# - Rust - D And yet C++ is still around because it's good at what it does. I think if C++11 never came about we'd be in a different situation, but C++ is around to stay, as is.
To be fair, .NET does include value semantics. For example, `DateTime` is a value type, so a method-local `var dt = DateTime.Now;` is allocated on the stack and copied around and whatnot. Another example is `Char`, so in actuality, .NET doesn't have a whole polymorphic class hierarchy for `Char`.
Thanks. Fixed that part in my post. Java and C# are very similar... except where they aren't. This is one of those places where they aren't.
Const operations are logically equivalent to read-only operations which are supposed to be thread safe.
Long term with reuse in mind, qt is trying to accomplish this, does a decent job and has years of testing. I personally do not program c++ with out qt.
While it certainly is a good book, it has nothing in common with Modern C++ Design. It is not even about meta programming.
```template &lt;typename T&gt; using void_t = void;``` When I first saw Walter Browns talk that introduced this I was blown away, and with C++17 we'll even have it in the standard.
Great article, keep them coming!
What drives me crazy is tall, narrow columns of code on high-res screens. ;-]
This is why I hate those "bit hacks" type sites (and questions). It's fine as a curiosity but many people come away thinking that using any of that stuff in real code makes them a good programmer.
I don't think it's a book where you read it (at least in 2017) with the intent of hammering out code exactly like that. At this point, I think it's more of value for showing the power of C++, conceptually, how to think about leveraging the language to solve problems, etc. The first couple of chapters on policy-oriented design are still, for me, one of the top shorter pieces of reading I'd recommend to anyone who is trying to step up their C++. I understand your concern about code obfuscation, but big teams need good code review anyhow. Senior devs should know better than to over-use powerful tools, and junior devs should get guidance and code review from seniors to prevent their getting carried away. Reading stuff like this is what turns juniors with potential into really top notch devs.
I would gladly give $50 USD to a GoFundMe for Andrei to write a modern version of that book (and another $50 to get a paper version). There is so much great knowledge in that book and the implementations would be drastically simpler and more expressive in C++14.
With the proviso that he doesn't really even try to define a dividing line between "simple" and excessively complex beyond a "I know it when I see it", so even that little bit isn't written in a way from which any real meaning can be drawn. 
I'm a going to be frank, this blog post gave me cancer. I'm genuinely shocked by the number of up votes.
Getters and setters are an antipattern.
Well, I do that for a living. But thanks for the advice.
Lol good luck being a software developer in the real world if you are so unbelievably retarded that you don't know how to write code in a clean way without putting effort into it. You probably don't even touch type. What a waste of space.
lol
maybe there is, but why not just install some linux distribution in a VM? you'll learn much faster if you get to play with the compiler the way you want to.
http://coliru.stacked-crooked.com/
Use [default member initialization](http://en.cppreference.com/w/cpp/language/data_members#Member_initialization) for `foo`.
There sure is! [Compiler Explorer](https://godbolt.org/), a.k.a. Godbolt, is what you're looking for.
Is the conversion from unsigned to signed for numbers greater than signed max defined by the standard? And should that cast even be happening here? The answers to those should answer this. I think it's most likely Clang's right here too, then maybe GCC. Not sure what MSVC is up to here.
Further to that, if you're on Windows 10 then you can install the "Windows subsystem for Linux" which lets you install and run linux within Windows. It's a really awesome new feature. My understanding is that it translates Linux system calls to windows ones natively at the kernel level so isn't doing emulation like cygwin et al. Currently cmd let's it down a little but it'll be getting major updates in the creator edition update later this year or if you join the fast ring updates are fairly regular. Edit: It's a full Ubuntu 14.04/16.04 installation by the way, not just bash.
There's also no such thing as a `const` function; way to correct someone about "methods" and be more wrong than they were. ;-] As to the standard's requirements: as you just said, that's for types used with the standard library &amp;ndash; it is not a requirement of the _language_, and use of the standard library is hardly mandatory.
Providing both a getter and a setter that don't do anything special may be. But providing only a getter or providing a setter that validates input is certainly not.
I suppose, although I can't think of a time I've ever needed to comment out only the if-block and not the else-block.
&gt;GoFundMe NotSureIfAdvert... As for Andrei, he's all about D now, I doubt he'll ever again write a book about C++ that can't be summed up as "Use D instead".
&gt; I have to acquire dedicated hardware for linux though Why? Why in the world pick the significantly more complicated option of getting another machine to install it on when you have a machine that is perfectly capable, and installing it through VirtualBox is free, incredibly easy and convenient? You can also get Clang on Windows by the way.
I was in this program last year and can only recommend it if you're a student and interested in C++.
&gt; It is not the same on VM as when you know you can't alt-tab and get back into Windows. Yes, when you want to do some work or learn it's better. Even on Linux you should still use Linux VMs (or just Docker) as part of your development workflow).
Yes
I never understood if this is a volunteer program for students or if it is a program for volunteers and students. Do you know?
When a friend started learning C++ ~1 month ago his first code he proudly showed to me was `#define ever (;;)`.
I think they also take people that aren't officially students but in a similar situation (short on funds. etc.). But you should ask Lelbach for a definitive answer (or just apply directly).
I've created a Microsoft Connect issue here: https://connect.microsoft.com/VisualStudio/feedback/details/3129614/ambiguity-when-distinguishing-signed-ness-for-constant-template-value-specialisation /u/STL (I know this isn't your area, but I don't know who to ping otherwise)
My point is that future expansions are not that common. Sometimes we over engineer stuff. 
I have to do internships during that time and my resume isn't anywhere near impressive enough to be considered anyway(even though my knowledge of the standard is pretty adequate I'd say) ;_;
I use: Cool(int vara, int varb) : m_vara(vara), m_varb(varb) {} Cool(int vara, int varb) : m_vara(vara), m_varb(varb) { do_stuff_here(); }
You can apply if you are not a student. 
More high-level. Just send a request, get it back, single call. Do not build up things from low-level pieces. I used beast before (it works great by the way) for websockets. In my library you just issue a call and get the results, nothing else, not even setting up an asio loop (the library will do it for you if you do not provide one explicitly). 
Definitely agree. The original plan was to go through boost, but that changed along the way. 
What do I put in the fields then? 
Also, I should be able to include *both* the integer literals and the chrono literals at the same time.
One thing I'm strongly rooting for is for the OpenCL C vector types and syntax to get merged into standard C and C++, possibly together with the associated library of built-ins. I think it's about time these languages got proper support for hardware-agnostic and compiler-independent vectorization.
Removed
Did you click on "image post" instead of "text post"? PS: Im taking down the image link to protect your identity
Just a habit. I disable strict aliasing in most of my programs as a matter of principle, it's too dangerous. For example in the specific case of hashing, there's going to be tons of type punning between non-character types. Nobody wants to process data 8 bits at a time, they're going to cast the data to chunks of 64 bits or more. Normally it's not a big deal since the hash functions are defined in a separate file. But my implementations were inlineable, so it feels like there's a real risk of a compiler exploiting the undefined behavior. 
&gt; Warning: Unpopular opinion ahead. I am of the opinion that strict aliasing is a crutch to prop up a language with insufficient aliasing information in the type system/annotation, so there's at least two of us :) Still... I prefer sticking with standard-compliant code; otherwise we're back to an age of dialects.
I think I submitted a text post... thanks for that, yes, please, remove it. Thank you very much.
For all intents since they are the same size it should be fine? I just can't see any UB behavior here, but I could be shortsighted... 
The same argument could be made for #pragma once. Disabling strict aliasing and 'restrict' are equally well supported so I don't see a reason not to fix this language defect using compiler switches.
I could add int_least, int_fast for selecting from these types
Max value is first to allow default 0 min value for unsigned value ranges, so you can skip typing 0 for min. Tho different function signature can be used for &lt;max&gt; and &lt;min,max&gt;, instead of just &lt;max,min=0&gt;. I wonder if it can be done without duplicating the types parameter list. integer&lt;&gt; prioritizes unsigned types first, so if you define a range that doesn't have negative values, unsigned int will be used. To mix things up you'll have to explicitly mix signed and unsigned ranges, so it would be your own fault, just like mixing regular int types.
Being able to write `int_least&lt;12&gt;` would be awesome.
Added. Kinda cool to see int_fast&lt;1000&gt; picking unsigned int over unsigned short on my machine.
What's the point of having them optional? Would it be because of theoretical 16 bit arches or some non-binary arch? 
&gt; I wonder if it can be done without duplicating the types parameter list. Sounds like doable since the range is defined by values but the possible choices are types. They should be distinguishable. &gt; To mix things up you'll have to explicitly mix signed and unsigned ranges, so it would be your own fault, just like mixing regular int types. Sure but my point is that when using ranges to define the types you aren't explicitly using signed and unsigned types anymore, rather they'll be deduced by internal logic. There are cases where both the signed and unsigned type of the same size contain the same range taking the same amount of space. Suddenly the library user must know the internal choices of the library to know which version of the type is deduced to ensure the correct behavior of the program code. Looking at such range it's not intuitive which one is used and the choice is completely arbitrary. I feel like it'd be better if this choice was in the hands of the library user so they can clearly know what they can and cannot do with such type.
Computers with native word lengths of 9, 18, 36 and 39 bits have existed, so it's entirely possible to have a computer where there is no instruction support for operating on integers with multiples of 8 bits.
&gt; The idea of having everything derive from Object is also in my opinion a very flawed one, which doesn't make sense at all in a language like C++. It's flawed in C# as well (especially since `GetHashCode`/`Equals`/`ToString` exist on the base type!) 
Unless you're doing something like embedded work on DSP chips that only support 64 bit types, they're going to exist. But people do write code for such platforms, thus the fixed width types are optional in the standard. 
We actually use chromium as a kind of C++ runtime for most of our projects. It has a base library that does all kinds of common operations that you do in general... threading, task-based models, files, metrics, etc. They also have a networking stack that is incredible, and it can be really useful to get a project done in a short time where the requirements are pretty demanding.
Two unrelated smart pointers like that should not both hold the same address. (Also, std::shared_ptr for a better, standard implementation). 
std::shared_ptr would have the same issue. Basically what you've written is incorrect usage. There implementation isn't wrong. You're meant to create one handle and then COPY that handle. edit: check out #5 http://www.acodersjourney.com/2016/05/top-10-dumb-mistakes-avoid-c-11-smart-pointers/ 
Makes sense. Niche, but not enough to force the standard. 
Always returning by value is bad though. You can invoke unnecessary copies that are non-trivial. Instead, don't reference temporaries and use the by-value overload.
See [core issue 1809](http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_defects.html#1809).
Image some of the systems I have to maintain that I'm happy when I have to debug them and not to write new code... :(
And compared to SFML's HTTP client? https://www.sfml-dev.org/documentation/2.4.2/classsf_1_1Http.php
Nice code, I enjoyed reading it.
&gt; Unpopular opinion ahead. &gt; &gt; [...] strict aliasing hurts How? &gt; It doesn't do anything for you [...] "But optimizations!", you say. Strict aliasing doesn't help with optimization whatsoever. When you actually care about performance, the same information can be conveyed using 'restrict' So if you are writing C or C++, _strict aliasing is actually doing something for you_ then. Ok. &gt; [...] preventing you from doing things that should be easy to do The standard compliant way of viewing and manipulating raw bits is using a `char*`, which is the only non-strict aliasing allowed by the standard. Fixed-width integer types are optional, and the size of char is guaranteed by `CHAR_BITS`. &gt; I expect a systems programming language to let me access integers as floats That is guaranteed to break since the fixed-width integer types are optional (so an `int` in a 64 bit platform is not of the same size as a `float`). &gt; Memory is memory is memory. Hence why the standard allows type punning and non-strict aliasing via `char*`, that's the standard way of manipulating raw bits. &gt; Also, strict aliasing forces you to memcpy, which could be more expensive than accessing values directly. Not in C (which supports type punning via unions without memcpy), only in C++. If your C++ compiler cannot elide `memcpy`s, you have bigger problems (GCC, Clang, Intel, Cray, IBM, MSVC, PGI, NVCC, they all do this, which is trivial if your IR is in SSA form). &gt; And let's not forget that strict aliasing is an unintuitive, arbitrary rule. "The only way to break type-safety is to use a `char*`, which is useful for doing bit manipulations." That seems pretty easy intuitive to me. &gt; Nobody would expect it to be a thing unless specifically told about it. Anybody that knows a bit about type systems and type safety actually wouldn't even expect the `char*` workaround to be there in the first place. That is, anybody who takes programming a bit seriously, or has studied computer science, expects this behavior. Non-strict aliasing is actually the insane thing from a programming language perspective if you have a bit of a type system, which both C and C++ have. &gt; Time and time again do beginners fall into the trap of thinking that their casts are fine `static_cast` in C++ gives you an error, most compilers emit warnings. Any C++ linter warns about C-style casts... For a beginner to fall into this traps it must be ignoring / disabling warnings, be learning from an uneducated teacher / mentor, or a malicious source, but if any of these applies the beginner has way bigger problems since "ways of shooting yourself in the foot" are not scarce in C and C++. &gt; The Linux kernel and Chrome are two examples of large projects that (to my knowledge) are compiled using -fno-strict-aliasing, with good reason Chromium depends on so many C libraries whose code is broken that they cannot compile in any other way. They actually do not allow implicit casts in their own code and have lints against no strict aliasing (both via clang-tidy, and they take this seriously, because Chromium developers actually implemented the lints in clang for this). The Linux kernel is a C project and C does not provide type-safe casts like C++ does, so they have no way of actually enforcing that people don't make mistakes. At some point GCC's optimizer got good enough to start using strict aliasing information, but the kernel developers realized that they had so many bugs in the kernel they couldn't actually fix them, so they _bullied_ GCC into adding `-fno-strict-aliasing` so that the kernel could compile on newer GCC version. Thanks to them, any compiler that wants to be compatible with GCC has to implement this as well... So the reason both projects use `-fno-strict-aliasing` is that modern compilers take advantage of it to optimize valid C and C++ programs, but their code has so many bugs that its impossible for them to fix them. This is a reason, an engineering one actually, but I don't think its a good reason. &gt; Unpopular opinion ahead. IMO your opinion is not unpopular, lots of people share it. And if one: - doesn't know that the standards (C and C++) support type punning and non-strict aliasing via `char*`, - doesn't care about standard compliance, - doesn't care about type-safety, - doesn't care about enabling all present _and future_ compiler optimizations, - doesn't care about future compiler optimizations altering your program's behavior, then it is easy to see how some certain types of people come to this opinion. However, most professional C and C++ developers know and care about these things. The _only_ reason why they use `-fno-strict-aliasing` is because "I have to use this library which is utterly broken, so I cannot do anything else". While in both situations the results might be the same, there is a huge difference in knowledge and reasoning about how they arrived there.
Any chance to know when vs2017 will support constexpr if?
Seems that the client is synchronous in the case of SFML. This call is async. My library will try to remove the boost dependency when it is feasible and only depend on standard things, but for that the Network TS must be in. 
I once inherited a project that had a dependency on YACC and LEX. I did not understand why, until I found out how it parsed a simple INI file for configuration :-(
+1, it is the page i may suggest, works really well and you can choose the version you want
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/60g7yr/cpp_and_c_aimbot_help_wanted/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
he actually wants the code to be easy. Something being easy is whole different from being simple.
BTW, another example of a "non-trivial GCC plugin" is [ODB](http://codesynthesis.com/products/odb/), an ORM for C++. It uses GCC to parse C++. While these days it is fashionable to do such things with Clang, GCC also works pretty well (and in some areas even better).
If you have a Mac, Xcode is pretty alright. It has some nice profiling tools too. That being said, it's hard to beat sublime text or vim and g++. Learning how to use cmake can be really useful
Not really an ide but the unreal engine is open source and is absolutely stunning. [unreal](unrealengine.com) 
thanks! because my book said they would use C::B but i thought there would be something better, like visual Studio!
ye i know. but at my first attempts i will likely just put down a 2d sidescroller rpg ;) 
Yes, of course - a "broken up" version for reading and development, and an "all in one" version for simplicity.
It's my top feature request for the compiler team, but we can't share an ETA yet.
Visual Studio, or Unreal Engine (last one not really being an IDE). If your main goal is to learn about game engine development, and do more dirty work by yourself, I'd say go with SFML, very good choice. If your main goal is a game, go with Unreal Engine.
He was asking if you are a student because then you can get it for free.
Edit: CLion is great, but note that VS is also free for students (and more). Visual Studio is free for individuals, students, and small groups (see below). There are some features in Enterprise that aren't in Professional or Community but I honestly don't know what they are. I run Community on my box (because my employer is too cheap to buy me software.) https://www.visualstudio.com/vs/community/ "Any individual developer can use Visual Studio Community to create their own free or paid apps. An unlimited number of users within an organization can use Visual Studio Community for the following scenarios: in a classroom learning environment, for academic research, or for contributing to open source projects. For all other usage scenarios: In non-enterprise organizations, up to five users can use Visual Studio Community. In enterprise organizations (meaning those with &gt;250 PCs or &gt;$1 Million US Dollars in annual revenue), no use is permitted beyond the open source, academic research, and classroom learning environment scenarios described above." 
Although I gave Visual Studio a +1, I also think CLion's a great choice for C++ in general. It's what I use if I'm dealing with any moderate/large codebase that isn't for games or graphics or Windows (whereas I feel Visual Studio + Windows have more to offer in these remaining scenarios, since the tooling environment has been more advanced for some time IMO).
VS has quite a toolset for game development, integration with engines like Unreal and Unity, and cross-platform targeting for mobile apps/games on iOS &amp; Android. And as pointed out below, it's free for individuals.
OP said clion not VS. But great input either way! 
Am I the only who thinks that learning a language with game programming is a bad idea?
[This](https://www.reddit.com/r/cpp/comments/603gi6/learn_c_from_scratch_how_to_make_your_first_video/) [is](https://www.reddit.com/user/FasterBust) [spam](https://www.reddit.com/user/MarkLee101).
Unreal is NOT open source, nor is it free software. You're confusing open source with source available, you still need to pay royalties and abide by their license.
Years ago I worked on a project that had zillions of lines of ini configuration. Except it wasn't really ini, just something that slightly resembled ini. It had C++-style `// comments`, lists and I think also an obscure sort of conditional sections. It was terrible.
Visual Studio is pretty much the standard when it comes to "non mobile" development and it's also arguably awesome (and free unless you start making money with it). So I'd definitely start there, you'll get your project done and learn the industry standard.. win win. 
Its spam.
Only problem is that the graphics debugging stuff is DirectX alone (which is unsurprising, but a bummer) and that there's still not even something simple like native GLSL syntax support. RenderDoc works excellently for OpenGL debugging though.
Unity still uses it for many things, AFAIK. CryEngine, Autodesk Stingray, Godot, Lumberyard, Frostbyte - these are just the huge, quadruple A, 3D game engines. Should I continue?
The really funny thing is that when you get to actual metrics of "complexity" you'll often find that what is "simple" is actually inherently complex beyond necessity. What they mean is "easier" and this profession is anything BUT easy.
Hope it's not butt cancer. That's the worst!
&gt; Too many programers like to demonstrate how smart they are just because they can. Really? That's what is going on in their heads when they write code? "I want to look smart so I'm going to make this really fucking hard to understand." I dare say there's a lot fewer of such developers than you are asserting.
A hammer is simple. Try using it to turn a screw.
Thank you. I was not aware that a reference always has a value. I will change the code asap :) As for the Array class, yes it's littered with bugs and design flaws. I honestly haven't given much attention really.
&gt; What's wrong with using C++/CLI? I wanted to do basically two thing with this project: * Continue learning and practising my C++ skills in a large project; * Explore how the .NET STL works "from the inside". Using something that already exists didn't really fullfil any of those. Another reason is that MS has been increasingly silent about C++/CLI, and the fact that I could make something similar, open source and multiplatform at the same time increase my excitment about this project. &gt; Qt, while not modern C++, is what you're looking for ? As for Qt, it's the first time I heard of it. But I'll be sure to take a peak. Looks like a very interesting and usefull framework :)
What's in hello.cpp? Does it use printf or cout? I assume the former; Rust would certainly win vs the latter. ;-]
Since it seems almost assured that your program will construct the instance of the singleton, eager initialization seems to be a performance *gain*, not penalty. With lazy initialization, you are checking at each usage if it has been initialized but can avoid construction if you never use it. For singletons that are not used all that often, that's probably a worthy tradeoff: a null check per access in exchange for not initializing it if you don't use it. In your case, since your application is focused on interfacing with the JVM, it seems like you will always construct the singleton and probably use it fairly often. I think that eager initialization probably your best bet. The only issue is figuring out when to delete it
Funny you mention deletion. I implemented getInstance() to increment a static counter, and the destructor to decrement it. When it reaches 0 the object is released. 
I'm not sure I follow you. Is `getInstance` returning some sort of reference counting class that you use to control access to the singleton instance? If not, what destructor are you referring to? Also, this seems like it could pose problems. Are you calling `getInstance` only at startup? If not, couldn't you end up releasing the instance before you're done using it?
Don't they serve VS through ProductsWeb? Or are you making a silly joke here?
I can easily write asynchronous I/O software that makes your computer feel frozen until it completes. I long ago realized that maximizing I/O isn't a valid goal on desktop systems. Aim for good I/O that doesn't cripple the system.
It's a silly joke. I'm installing VS so frequently that I never get past the trial periods anyway. But I usually do use Community. No reason, really. 
We also did throughput benchmark. Please see https://github.com/Qihoo360/evpp/blob/master/readme.md#benchmark
Apparently I've been downvoted to oblivion so thank you for the comment despite my low status. I agree with you, I was speaking to OP's intent where he said "also to make a more accesible gateway to C++ newcomers with a background in other popular languages (such as C# and Java)." Looking at OP's code they are clearly implementing the C# interface. My comment was mostly a Qt PSA. Qt was clearly influenced by Java or a common ancestor and is "somewhat" comfortable for a Java person. 
Show the code?
If you are using nvidia hardware on your developer machine, you can use Nsight (Nvidia's graphics debugger), it supports OpenGl and Vulkan as well as DirectX.
I doubt very much you can extract a reasonably complete C++ AST from debug info. And a reasonably complete C++ AST is what ODB needs (if you looks inside you will quickly realize it is by no means a "trivial tasks involving data structure"). But I am willing to be proven wrong...
Yes, I think there is quite a bit of truth in what you said. But there is also this side of the story: when GCC added plugin support (in GCC 5.0), Clang still could not compile half of C++ codebases out there. In fact, I remember I was investigating their plugin support vs GCC's (no, I didn't want to link to a custom-built libclang, I wanted to use the system-default toolchain) and their implementation was non-functional (with the explanation being that "it is just a placeholder"). In the end this was the main reason ODB went with GCC. Still no regrets, BTW. But, look, in the end everyone won: we now have two mature C++ compilers that can be used for parsing C++ code in third-party tools.
&gt; As discussed in the post, the hash functions developed in the last few years rely on 64-bit multiplies and thus can't be vectorized with AVX2. // untested AVX2 code for z=mul_u64(u64 x, u64 y) // on Skylake: ~10c latency, every ~2c VPMULUDQ z, x, y // z = mul_u32-&gt;u64(x[31:0], y[31:0]) VPSHUFD y_hi, y, 0b11110101 // _hi = copy [63:31] into [31:0] VPSHUFD x_hi, x, 0b11110101 // VPMULUDQ lo_hi, x, y_hi // lo_hi = mul_u32-&gt;u64(x[31: 0], y[63:32]) VPMULUDQ hi_lo, x_hi, y // hi_lo = mul_u32-&gt;u64(x[63:32], y[31: 0]) VPADDD lo_hi, lo_hi, hi_lo // VPSLLQ lo_hi, lo_hi, 32 // VPADDD z, z, lo_hi // z += (lo_hi + hi_lo) &lt;&lt; 32 
I appreciate the effort to do all this benchmarking. However, I'm not sure of the relevance. For 99% of users doing network i/o, using ASIO versus anything else is unmeasurable. For those doing many small bits of i/o, ASIO on Linux has historically always had scalability problems relative to ASIO on BSD or on Windows because Chris has stuck a giant mutex around the epoll reactor on Linux which isn't necessary with kqueues or IOCP, and the spin count on that standard pthread mutex is about 10x too small for ASIO's epoll reactor implementation. Replacing it with a mutex with a 10x bigger spin count closed the scalability gap between ASIO on Linux with many small i/o and ASIO on Windows to within 10% if memory serves. My knowledge of ASIO internals is stale, but my point is that Chris targets ASIO at what 99% of users do balanced against reasonable maintenance costs for him. He does provide hooks for more bespoke customisation, I know of low latency hedge funds which change the allocator ASIO uses and do some other customisations to get the max latency in ASIO really pared down. And they're very happy with the results, and I would expect they've done lots of testing to make sure it's a good job. So sure, you can build an ASIO replacement which is 50% faster at doing single byte i/o out of the box. However, if you're benchmarking on Linux and if ASIO still is using a giant mutex which almost everybody in that situation replaces, it's of no difference. And single byte i/o is hardly representative, most people deploying ASIO onto 10Gbps NICs are going to be aiming for at least 4Kb i/o chunks aligned to 4Kb pages (and more likely 1Mb i/o chunks in huge TLB mapped pages). The performance of the core reactor becomes considerably less important as i/o chunk size rises. None of this is to take away from the work you've done, and for the record I agree that ASIO needs to do better with small i/o on Linux out of the box, but other Networking TS implementations won't make the same design mistakes. Building your C++ network application to use the Networking TS is **far** more future proof than using evpp or anything else.
Do what sqlite does, and have a script that will concatinate everything together?
Does anyone know what the stability is like? That is always my worry with stuff from KDE. It is very cool that is is packaged as a single stand alone binary. I think that is an idea whos time had come a long time ago for major programs like this. Unfortunately it segfaults trying to run it on Ubuntu in virtual box. -Looks like turning off 3d acceleration in virtual box fixes it enough that it can run, though this isn't a real solution unfortunately. 
The language has grown so big that I wonder if anybody can be fluent in all of it.
Just another C vs C++ article. Feel free to remove if it's not appropriate for the sub. /r/programming discussion: https://np.reddit.com/r/programming/comments/41ij6s/c_or_c_for_my_game_engine/ HN thread: https://news.ycombinator.com/item?id=10919634
Makes sense, let me rephrase it then. What are essentials I should know to land a dev job?
I can't say, because I use C++ for mathematical research. But it depends on what you're developing. For instance, you'll need one kind of background for games, and another kind for telecommunication systems.
Even considering the conclusion where the author states he spent a good time learning good C++ practices, this article feels like a long list of what happened in what order and feel very anecdotal, but there isn't much analysis or understanding as to why things would have performed differently between your C++ and C implementations. The author keeps mentioning slow compile times but does not provide any information as to what makes it slow. Unity builds aren't a good solution to reduce build times for the kind of iterations described in the article. Some of the conclusions are very brittle, such as rolling out your own containers requiring more work in C++ than in C. Basically, if a home made C container is satisfactory, the same can be accomplished using C++ and there's no reason it would require more work unless additional requirements are thrown in, such as compatibility with &lt;algorithm&gt;. Another important thing is that C++ doesn't force OOP design on anyone, class hierarchies aren't required to be writing idiomatic C++. Also, I'm surprised there aren't any steps to remove some of the debugging features of Visual Studio's STL to reduce the debugging overhead considering the author seems to be using Windows for development. Also, I just looked at the other discussion in /r/programming and this article has already been discussed a lot over there and is over a year old…
I use NSight for all my CUDA work, but have been generally dissatisfied with its performance as a graphics debugger. RenderDoc has more useful features, and generally feels better. The mesh viewer in RenderDoc is especially useful. I keep both around though, because its always useful to have more debugging tools in the strange world of graphics/GPU programming. 
I love it. Thanks 
We have several repos, currently kdevplatform, kdevelop, kdev-python and kdev-php. "kdevelop" is sort of a collection of plugins considered mainline (only =&gt; implication, not &lt;=). Some analyzer plugins have their own repos still, and those could be moved into kdevelop.git. Memory leaks? Where, what? Please report on bugs.kde.org. Regarding cmake/git integration, yes, it could be prettier. The IMO important thing though is that it retrieves your compiler settings from cmake -- and that works just fine. You don't want to know how much you have to configure by hand if that doesn't work. Also, the "git blame" feature is awesome, so there's that! ;)
Nothing I'm allowed to talk about publicly (finance makes you sign NDAs). But i can tell you that you aren't making a mistake choosing ASIO (not Boost ASIO). It's been very battle tested. There are good reasons it's entering the standard. And there are ample resources on the internet to help you, plus a farm of expert consultants like me to hire if needed. Basically ASIO comes with a support ecosystem. Alternatives don't.
Hello, i am sure there are many expert programmers in this subreddit, if i can improve anything with my code please let me know, am always happy to learn new things! Thank you :) and enjoy!
As others stated , and some cents from me: Basic: * RAII idiom * Global or static variables lifetime (are they initialized on runtime?) * Special member functions (c-tors, d-tors, assigment operator) * How to achieve type conversion ( by operator , by c-tor ) also explicit keyword * Move semantics * Exceptions - 3 stages of exception safety , why not to throw in d-tor, what is stack unwinding * Lambda syntax, how to use in STL algos Templates: * SFINAE - concept, basic usage ( std::enable_if ) * CRTP - the same ( struct Derived : public Base&lt;Derived&gt; ) Libraries: * STL ( vector, map, unordered_ , algorithms ) * STL ( threading, chrono ) Bonus Points: * Boost::Asio * Boost::Filesystem ( will be part of STL ) * Qt5 
Check this presentation on C and C++ [Deep C](https://www.slideshare.net/olvemaudal/deep-c)
 class Jni_Connector { public: static JNIEnv* GetInstance(JvmMem args); virtual ~Jni_Connector(); static long GetPID(); private: JavaVM* m_java; static JNIEnv* m_env; static Jni_Connector* m_pInstance; static long m_jvmPID; Jni_Connector(); Jni_Connector(const Jni_Connector&amp;); Jni_Connector&amp; operator=(const Jni_Connector&amp;); }; JNIEnv* GetInstance(JvmMem jargs) { if (0 == m_pInstance) { // test 1 mtx_.lock(); if (0 == m_pInstance) { //test 2 sArgs = jargs; m_pInstance = new Jni_Connector(); } mtx_.unlock(); } return m_env; } Jni_Connector() { std::stringstream sstm; if(sArgs.min &gt; 1 &amp;&amp; sArgs.max &gt; 1) { sstm &lt;&lt;"-Djava.class.path=. " &lt;&lt; "-Xms="&lt;&lt; sArgs.min &lt;&lt; "M -Xmx" &lt;&lt; sArgs.max &lt;&lt; "M"; } else { sstm &lt;&lt; "-Djava.class.path=."; } string newArgs = sstm.str().c_str(); JavaVMInitArgs vm_args; JavaVMOption options[1]; long jvmStatus; //================== prepare loading of Java VM ============================ options[0].optionString = const_cast&lt;char *&gt; (sstm.str().c_str()); vm_args.version = JNI_VERSION_1_8; // minimum Java version vm_args.nOptions = 1; // number of options vm_args.options = options; //=============== load and initialize Java VM and JNI interface ============= jvmStatus = JNI_CreateJavaVM(&amp;m_java, (void**) &amp;m_env, &amp;vm_args); if (jvmStatus != JNI_ERR) { jint ver = m_env-&gt;GetVersion(); std::ostringstream le_msg; le_msg &lt;&lt; ((ver &gt;&gt; 16)&amp;0x0f) &lt;&lt; "." &lt;&lt; (ver &amp; 0x0f); m_javaVersion = le_msg.str(); } assert(m_env); //fetch and set the PID jclass localCls2 = m_env-&gt;FindClass("mil/c2i/ul/common/Util"); jmethodID getJvmPID = m_env-&gt;GetStaticMethodID(localCls2, "getPID", "()J"); m_jvmPID = m_env-&gt;CallStaticLongMethod(localCls2, getJvmPID); } ~Jni_Connector() { m_java-&gt;DestroyJavaVM(); }
http://melpon.org/wandbox/permlink/UQ9fxvSiy0dsERkC
Here's a suggestion. You can trigger linker errors by adding the following comment in one of your cpp files. The trick is that the ending of the comment uses a unicode symbol that looks like an asterisk but will not actually end the comment so that it runs to the end of the file. You can use U+2217 or U+FE61 that look close to the original one and might not raise suspicion at first sight. ``` /* Insert innocent comment here ﹡/ ```
NuDB provides a very specific set of functions. But if those functions happen to meet your use case, it is absolutely the perfect tool. Specifically if you: 1) Are using SSDs for storage 2) Have data with fixed-sized keys 3) Only need to fetch a value based on its key (or traverse), and 4) Don't need to modify the data Then NuDB's performance will blow you away. Reads per second is roughly one half the IOPS level. So a 100K IOPS SSD will read 50,000 keys per second. No memory buffering (except to group writes for flushing as a unit) is needed. The inability to modify or delete keys certainly limits the arenas in which you can use NuDB. But it's *so* fast, that often working with those limits (even where that takes some effort) is worth doing. For example, if you can create a new database every so often and copy any old keys you still need, it's probably worth doing because NuDB is that solid. Another plus: It stores the database in two files, one for data and one for index. The data file is append only. So you can copy it while it's in use and reconstruct the index from the data if needed. It's a true work of art.
I can't take all this credit, u/sjoelkatz offered considerable assistance during the design and code review of this library!!!
As I'm posting this, the highest comment is at 0, and it's the one with the least contribution. What's with all the downvotes? 
Exceptions are what makes RAII really work. Alone, exceptions are a nifty control flow mechanism that allows you to focus on the primary logic of your code and avoid interspersing conditions to handle all the myriad ways it could fail, and RAII is a convenient way to declare ownership and prevent you from forgetting to free your memory or whatever. Together, and in combination with lifetime semantics, they form a powerful invariant: `MyClass x` *declares* that `x` is a valid object of type `MyClass`, and you can do `MyClass` sorts of things with it. If the constructor for `MyClass` encounters some failure condition — e.g. inability to allocate memory or lock a file or connect to a networked resource — first, that's probably not a problem the constructor can handle; and second, that constructor might now be unable to create an object that supports all of its canonical operations. It can't return an error code! What can it do? It can *throw an exception*, which results in the automatic tear-down of any RAIIed resources it had previously set up, the error being kicked back to you, the caller, where it can be handled or forwarded up, and, most importantly, no `x` — because the constructor never completed, the object's lifetime never began!
Templates, and easy distribution. But mostly templates.
The most common one is certainly on error handling. Countless time, I see people dealing with exceptions for functions or objects which may end in an "invalid state" (i.e. ifstream in a deleted file) by following them with a *if(somethingbadhappens)* instead of try-catch at initialization by a constructor. To me, the main advantage of RAII is the absolute certitude that no matter what happens -even the worst-, everything will remain under control, and only what's necessary will be called. Plus, no need to deal with all the hassle of resources management (variables, pointers, etc.), RAII itself ensures your resources are correctly managed. Hope that helps.
50,000 reads per second is a 'true work of art' for immutable database with static key lengths? Let's not get too carried away.
you mostly need to perform a daily sacrifice of seven executables to the dark god of substitution failures and make a pact with the devil to trade 12.75% of your remaining life time with error-less, bug-free compilations of your software.
Header-only libraries are much easier to integrate into projects - no messy build scripts! And also, the choice of hash function and "File" type are template parameters.
Maybe your intuition differs from mine, but my intuition says that this is the best you can possibly do. Here's why: We are not buffering anything in RAM and we have no idea whether or not the key exists. There is no way we can magically know where on the disk the data is. At best, our first read can tell us where the data is and then our second read can read the data. So 1/2 the IOPS is the theoretical best possible. We tried numerous other data stores and none came anywhere close to this. NuDB hits 92% of this ... easily. This was not an accident. After seeing performance drop offs with data size increases in many databases that we tried, Vinnie and I pondered what the best we thought was possible if we insist RAM usage not scale with database size. We then came up with a design that could come as close as possible to that. I definitely agree that we traded off a lot of functionality for this performance. This database is not going to be a good fit for a large number of problem sets. But if it happens to be a good fit for yours, you're going to be very happy with its performance, stability, and quality.
&gt; Strict aliasing doesn't help with optimization whatsoever. Oh of course it does. With -fno-strict-aliasing the optimizer has to assume that any write through any pointer could potentially overwrite any piece of memory. So it can't keep things in registers, can't hoist constants, etc. Here's a quick example: https://godbolt.org/g/RG6TyV Explanation: with strict aliasing the compiler can assume `pi[0]` is a constant and puts it in xmm0 and vectorizes the loop. With -fno-strict-aliasing the write to `pf[i]` can potentially stomp on `pi[0]` so it has to load it from memory each time around the loop and cannot vectorize in the same way. Also yes the contrived example is contrived, but this happens all the time in real code, and no "restrict" can't save you as in reality this code could be a template insantiation that was then inlined, reordered, etc. and is far distant from the as-written code.
You can obtain a pointer to the JVM (JavaVM*) with JNIEnv-&gt;GetJavaVM. You can safely store that pointer as a global variable. Later, in the new thread, you can use AttachCurrentThread to attach the new thread to the JVM. 
Where can I find resources to learn about this? I'm going through Stroustrup's intro book to C++ and I've never heard of RAII till now!
Yes. What I was meaning to point out is that the code you posted appears to always give out the same JNIEnv (m_env) and it looks like you're expecting it to be used from different threads, so it looks like you have a problem where the JNIEnv will be used from multiple threads.
Are you the author? If so you could also talk about when to use class vs. typename.
I pronounce this "Nude Bee"
I checked some C libraries, such as Allegro game engine, all of them simulate virtual functions with function pointers. The overall idea behind the C and C++ libraries are not that much different.
I've seen a crash somewhere in `std::string` that was due to a binary built with g++ 6.2 linked with a binary built with g++ 4.9. `std::string` is ABI-incompatible between these two versions (and I have no idea how it managed to link). Not really a horror story *per se* as it wasn't particularly difficult to pinpoint.
I had some issues once with a library that could switch its implementation between different backends and you could use a preprocessor define to pick which one you wanted. The library API would stay the same and was header only. Thus, linking together 2 pieces of code using that library and 2 different backends produced weird results and illegal states when objects were created in one compilation unit and passed to the other one. We tried to inspect variables in a debugger and it took us a while to figure out what happened. It got fixed by choosing the implementation on the library target in CMake and getting the flag propagated properly to all its users instead of having that one user library specifying the implementation locally.
Sure,that's great. It just seems like a warped perspective for people to think 50,000 reads per second is good performance in a general sense.
Unless you assume that you're reading related objects (and we're assuming totally random reads) you will necessarily need at least one read for each object's data. You can't somehow magically arrange them to already be close together on the disk when you had no idea what order they'd need to be read in. As I argued above, it grows to 2 IOPS because there is no known way to know where the data is on disk without doing at least one read to an index of some kind. Such an index will necessarily grow with some function of the size of the data it indexes, so you can't expect the entire thing to fit in a fixed size cache or buffer. We believe that for random reads with an O(1) buffer, you cannot do better than 2 IOPS per read. NuDB comes very, very close to this performance level. You could, theoretically, try to get the data and index to be read in the same operation. This might theoretically be doable. I don't have a clean, simple proof that it's impossible. But it seems, at best, completely impractical. Perhaps somebody will dream up a way in the future.
Thanks for the explanation! How do I go about reporting the issue? Sometimes I will come back to my computer and KDevelop is suddenly using something like 6GB of RAM (for a pretty simple project). What's the step next step that I should take? "The IMO important thing though is that it retrieves your compiler settings from cmake -- and that works just fine" Can you explain what that means? As far as I can see it seems to uses the build configuration to set the build type and build destination and then it runs cmake on some pseudo-terminal
Horror stories? Not especially. Took us a while to figure out an issue with Havok in our Linux server build with SIMD (popular C++ library for rigid body physics in games) but that was as much the macro definition flags as anything else.
This looks interesting. Don't need it now, but surely I'll like to not forget it. Few questions: What if I'm not using SSDs? What are the performance hits on a normal spinning disk? What's better than NuDB then? How much RAM do you need to store 1 million keys+values ? 
I had a problem where my system version of boost was compiled as C++98, while I wanted to compile everything as C++11. Most things worked fine, but there was a static or something that did not work. Not a big deal. It just meant that I could not use that variable.
That's actually not gcc, that's libstdc++. It uses ABI tagging, so it really shouldn't have linked.
Maybe this wasn't clear in my comment, I know those exist, I'm suprised there aren't any such steps outlined in the solutions the author has tried.
You can draw inspiration from this classic: http://m.imgur.com/gallery/lunecj3
Boost. Test does mocking too. Boost. Di for dependency injection. The only lint tool worth bothering with is clang tidy. Period. It's head and shoulders above all other free tooling and beats many commercial tools. Plus recent cmake can auto call it for you.
As far as the essentials go you must understand int, std::vector and the virtual destructor (really well).
Thanks for sharing your opinion :) but remember not everyone can learn so easily just by books, some people also needs examples!
what are you saying? qtcreator runs natively on windows
For unit tests I find [doctest](https://github.com/onqtam/doctest) strikes a great balance between being useful and being unobtrusive. I switched to it after running into ["One Definition Rule" violations with the `gtest` package in RHEL 7](https://github.com/google/googletest/blob/master/googletest/docs/FAQ.md#why-is-it-not-recommended-to-install-a-pre-compiled-copy-of-google-test-for-example-into-usrlocal) and a personal disdain for doing a source tree inclusion with something that is non-header-only. I use [CMake](https://cmake.org/) as a configuration system so I like registering tests (i.e. [`add_test()`](https://cmake.org/cmake/help/v3.7/command/add_test.html)) with CMake and invoking all registered tests with CTest (i.e. `ctest -V`). That includes the unit test executable as well as tests for any built executables (like input/output checks). Mocks and stubs aren't really a part of my workflow at the moment. If I need one I usually write a dumb specialization and make it a part of the library. For most of my work I'm stuck in RHEL 7 which doesn't have `clang-tidy` packaged yet so I just add [`cppcheck`](http://cppcheck.sourceforge.net/) and [`cppclean`](https://github.com/myint/cppclean) to my automated workflow.
I always recommend [Catch](https://github.com/philsquared/Catch) as unit testing framework and clang-tidy or CppCheck as linter.
That's just "when ever you feel like using one or the other".
It looks like it might be useful for producing records of state changes in simulations (like games records for replay and debugging). &gt; Specifically if you: &gt; 1) Are using SSDs for storage Could you clarify what should be expected if the program does not run with access to a SSD drive? I mean, what's the impact if it's: - a classic disc hard drive; - a usb key (the slowest I guess); Will it only be a speed performance reduction or are there other potential issues?
Returning a pointer to local data happens all the time for performance reason. You just have to be careful that the returned pointer is not used beyond the scope of the owning object. The only safety you can have is if your object is contained in a shared pointer and you have a special "member_ptr" that increment the ref count of the parent object.
Author here! It's been over a year since I made that post, and after writing a lot of C game code it still remains my choice. Some details presented in the post have turned out to be non-ideal (e.g. the array thing). Every now and then I'll face more or less idiomatic C++ and the conceptual complexity overhead almost always reduces my happiness level. Naturally this is a subjective experience.
Something which can be incrementally implemented to help with the situation - I believe this document http://www.stroustrup.com/resource-model.pdf covers it better than I ever could. For example here - I think it may be possible to see that std::string owns the pointer in question, and string_view does not. So if the string is temporary, it is possible to conclude the pointer stored in the string_view will get invalidated upon return from the function.
Indeed, but... Stealing would need copying and heap. So has a performance consideration and incurs exception safety change (from no-throw to can-throw).
&gt; I do hope C++ will get some basic pointer ownership specification features in the future There are already, unique_ptr, shared_ptr etc. If you're using a raw pointer you should be able to demonstrate that it either won't dangle or if it dangles, it won't be dereferenced. It is not even always possible to decide if a function returns a reference or pointer to a local variable at compile time: int* x(bool b) { int i = 1; static int j = 2; int* r = b ? &amp;i : &amp;j; return r; }
If you run this on a spinning disk, you're going to experience a lot of pain! It will be incredibly slow. If you need a key/value store to run on a spinning disk you'll have to use a library that implements some variation of "log-structured merge", like LevelDB or RocksDB. The amount of memory NuDB uses is proportional to the rate of inserts. It does not use any RAM to buffer fetches! That means no matter how big your database gets, it still uses the same amount of memory. Less than 100MB usually (with a sustained insert workload). The whole point of this database is to recognize that for incredibly large data sets with a random access pattern, RAM doesn't help.
rippled (https://github.com/ripple/rippled) was using LevelDB, and then RocksDB. But we noticed that as the database got bigger those libraries get slower due to increasing RAM usage and building more bloom filters and tables. Thus we created NuDB to address that problem. NuDB doesn't "use" anything, its all custom code built on top of the POSIX or Win32 file APIs.
No idea, you'd have to try it and let me know how it performs!
In this case you can conclude it may return a pointer to local variable and issue a warning. Some more sophisticated things would be impossible to detect, though - for example over a dynamic library boundary, or obscure pointer arithmetics and casts.
And by glorified you're just saying that the data representation + its semantics have a name and type we can use now. This should be programming as usual and nothing suspect.
Yes, but the type adds a layer of opacity which might lead into thinking this data structure has magic properties like lifetime extension, while conceptually it is just a pointer with a size attached to it.
You may want to read this one: http://www.bailopan.net/blog/?p=7 This blog has some more stories of this kind.
I am well aware of strict aliasing works. My point is that there's nothing stopping you from slapping on 'restrict' when performace is relevant and you are going to optimize anyway. When performance doesn't matter, strict aliasing doesn't matter either. In your example, restrict works just as well as strict aliasing. I don't like working with hypotheticals, but I'm happy to be proven wrong if you can show an example where restrict is not sufficient.
Thanks. Yeah, I guess I was browsing through the rippled codebase when I saw LevelDB mentioned somewhere.
What do you suggest?
It lets you register tests that are not unit tests like running some built utility executable, piping a known input to it, and checking that the MD5 sum of the output matches what I expect. If you look at [`add_test()`](https://cmake.org/cmake/help/v3.7/command/add_test.html) you'll see it just takes a command and determines success from the exit code. I also use it to configure the working directory of the test in a way that is robust to wherever the out-of-source build is placed. Sure most people put their out-of-source build in `./build` but it could technically be anywhere so relative paths are brittle. With `add_test()` I can specify the working directory to be [`${CMAKE_CURRENT_SOURCE_DIR}/test`](https://cmake.org/cmake/help/v3.7/variable/CMAKE_CURRENT_SOURCE_DIR.html) or something similar and always have it run where I have my test data.
&gt; In object orientation, there is a code smell named “Data Class”. It says that having a class that does not contain any logic is a hint at a violation of design principles. What is wrong with structs? If all you have is some related data and no invariants, why overcomplicate things?
It bothers me far more than it should that @op is talking about C++17 but still uses parenthesis instead of brace-initializers. 
The garbage collector will take care of that ;)
I fully agree with the poor naming. I believe std::pair is designed to be used in generic programming and not for everyday use case. Sometimes I find in my company code with std::pair or std::tuple and I usually lose plenty of time figuring out what is each field. This code would be very simple to understand if instead of a pair or tuple, a structure with proper fields names was used. Therefore in most situations I prefer the structure or class approach over the lazy std::pair or std::tuple one.
And rippled still fully supports RocksDB. It works much better than NuDB for small datasets and on spinning disks. The problem with RocksDB, and the main reason we created NuDB, is that if you don't use bloom filters, the performance gets truly awful very quickly. But if you do, the size of the bloom filters is proportional to the number of keys, and if the bloom filters don't stay in RAM, performance nosedives. A lot of rippled servers run on virtual machines where RAM is at a premium. The ability to provide consistent performance with minimal, and consistent RAM consumption is important.
Does your find_first signature imply that you will be returning a string_view into that 'source' argument? If so, you have the same problem as op. The following is broken: find_first(MethodThatReturnsAStringOrView(), "data to find"); You will be returning a string_view into a temporary for what amounts to a very natural invocation of your function here. I use type-traits to exclude r-value references being used for similar methods of mine.
The problem is not with `string_view`, but with your class. You should have &amp; and &amp;&amp; overloads for your accessor and delete the &amp;&amp; ones. This will make it perfectly safe. This is a very common thing to need to do if you are writing classes that have functions that lead to bad behavior on temporaries. I've discussed this point before on my blog: http://www.nirfriedman.com/2016/01/18/writing-good-cpp-by-default-in-the-stl/. I don't mention `string_view` specifically but it's no different than a reference or a pointer.
&gt; You should have &amp; and &amp;&amp; overloads for your accessor and delete the &amp;&amp; ones. This will make it perfectly safe. How? My `substr()` example is broken because `substr()` has the "wrong" return type and the compilier can't remind me.
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/60wlwi/need_help_with_errors_in_code/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Not using ScopeGuard! A lot of people have code they want called on exit that is not part of any class' destructor, and its understandable that you are not going to write a wrapper class for every single thing you need to do on exit. That's what ScopeGuard is for. Really if you understand ScopeGuard well, you know a lot of C++ essentials right there: RAII, lambdas, templates, special member functions.
Reading and writing memory in loops happens all over, it's kind of how most code works (particularly after inlining). And 99.9% of the time you are not reading/writing over the same memory locations, particularly if your pointers/references are to different types. Further, reloading registers from memory every time around a loop just in case, or turning loop constants into maybe-mutables, is a pervasive and significant cost. C++ compilers have great optimisers, and -fno-strict-aliasing ties their hands across large amounts of typical codegen - it's a global slowdown caused by an accumulation of many pessimisations. Yes you can scatter 'restrict' all over you code, and hope you don't get it wrong as that would lead to incorrect codegen, or you can let the compiler do it automatically. And in the rare case you do need e.g. type punning, that's where you have to be explicit. 'restrict' is still useful, but in the case where the strict aliasing rules are too conservative, e.g. when you have a char* pointer that you know doesn't read/write the same memory as another pointer in the same scope. Having the vastly more common case be automated and run faster, and the rare case need explicit idiomatic handling, is just the more sensible choice IMHO (and I guess the standards committee agreed). Here's an old but good article, in particular the section on "benefits of strict aliasing": http://cellperformance.beyond3d.com/articles/2006/06/understanding-strict-aliasing.html
My mistake, you're right, I read a bit too quickly and thought you were referring to a situation where `foo` itself is a temporary and someone calls `get_str` on the temporary to get a string view. Note that that issue is still present.
I don't believe there is any competitor that can provide that level of performance predictably. They all rely on a cache that can grow as data set sizes increase. With RocksDB, for example, you can get initial performance much higher than that. But as soon as your O(N) bloom filters don't fit in memory, performance drops to levels much, much lower than that.
These classes do provide *some* logic, e.g., comparison, but I do agree that they should be used sparingly. Nobody likes to open up code full of things like "return i-&gt;first-&gt;second.second;" It would be great to have "named tuples," for that small grey area of simple cases where a full-blown class isn't really necessary, but "first" and "get&lt;0&gt;()" are unsightly. Of course you can do something with [type "tags"](http://stackoverflow.com/a/13066078/135138) but at that point you might as well make a class, the only benefit I can see is that the members are iterable, which is rarely very useful in my experience.
You have to explicitly define a struct type, while you can make pairs and tuples on the fly with std::make_pair and std::make_tuple respectively, automatically deducing their types from the arguments. C++ has compile-time duck typing with templates and "auto", and that's where pairs and tuples and other generalized concepts are useful.
Is there anything wrong with just adding another override for ULL? template &lt;unsigned long long val, std::enable_if_t&lt;val != 0&gt;* = nullptr&gt; auto constexpr foo() { return 1; } template &lt;unsigned long long val, std::enable_if_t&lt;val == 0&gt;* = nullptr&gt; auto constexpr foo() { return 2; }
by "local data" I mean automatic variables or temporary objects created in the scope of the function. They stop existing when the function returns.
Doesn't std::tie replace the need for named tuples?
You've been looking at some really bad code then.
What does this solve? The compiler can't discern between the unsigned and signed versions of the function at instantiation and I need to handle values between signed_min and unsigned_max. This is the simplest example showing what I need. It doesn't currently compile because the compiler thinks the call is ambiguous. #include &lt;utility&gt; #include &lt;limits&gt; template &lt;int val&gt; auto bar() {} template &lt;unsigned val, std::enable_if_t&lt;(val &gt; std::numeric_limits&lt;int&gt;::max())&gt;* = nullptr&gt; auto bar() {} int main() { bar&lt;4294967295u&gt;(); }
The problem I have with `std::tie` is that I have to declare a mutable variable somewhere to use it, which interferes with a functional/immutable style. If I could do something like this I would use it more: (auto const key, auto const&amp; value) = std::tie(...); 
Thanks. I knew I saw that somewhere but couldn't find it.
Oh, yeah, makes sense now.
What's the advantage to this over a struct?
It *is* a struct! The advantage is you get strongly-named fields while not having to duplicate all the constructors (value, copy, move, etc) and [std::pair&lt;&gt; public methods](http://en.cppreference.com/w/cpp/utility/pair), and can pass it to anything taking a `std::pair&lt;&gt;` of the same field types. A more complete example would return references to `first` and `second` for setting values via strong field names: struct CoordXY : public std::pair&lt;int, int&gt; { using Pair_t = std::pair&lt;int, int&gt;; // Type alias for grumpy compilers / IDEs using Pair_t::Pair_t; // Inherited constructors int X() const { return first; } int Y() const { return second; } int &amp; X() { return first; } int &amp; Y() { return second; } } CoordXY my_coord { 1, 7 }; my_coord.X() = 3; if( my_coord.X() == my_coord.Y() ) { // things and stuff } CoordXY my_other_coord{ my_coord }; MethodTakingStdPair( my_other_coord );
&gt; I think the only reason that various insert() methods return std::pair&lt;Iter, bool&gt; is that std::optional&lt;Iter&gt; didn't exist at the time map etc were standardised. Why would that be a case for optional? The iterator returned is always valid and points to the entry corresponding to the given key. The bool only indicates if the new value was inserted. Sometimes you require the iterator in either case. 
+1 grokking the implementation of ScopeGuard is a great start to all those !
std::pair generic member names are, in my opinion, very close to unnamed boolean parameter sequences. Both have the problem of losing important information.
Does inheriting from std::pair get you much benefit over declaring the fields yourself?
That's much cleaner!
That's not what swap does.
Oh! You're right, I had forgotten that you use it like x.swap(y), not x.swap(). Nevermind. :-)
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/60ypzv/help_writing_a_whileelse_while_statement/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I use something like this: struct Size { int width; int height; }; Size getSize() { return {1,1}; } int main() { auto size = getSize(); std::cout &lt;&lt; size.width &lt;&lt; " " &lt;&lt; size.height &lt;&lt; std::endl; } 
You get `swap` without having to inherit `std::pair`, and actually now that you mention it I'd say getting things like `operator &lt;` is a bad thing. Coordinates do not have an ordering to them.
Have you ever needed to store coordinates in a map? Ordering is useful. And equality, obviously...
Sees the previous comment on how he has the same problem, provides a reassuring answer to the question, and then in terror, runs back to the code to review every occurrence of the case above because had never thought of the aforementioned case.
You should consider Boost's strong typedef mechanism.
I'd say it's much better to use a hash to store coordinates in a map rather than giving the coordinate class an `operator &lt;`. But for the sake of argument if I really had to store it in an `std::map` then in my opinion the proper approach is to declare a custom comparator and use it on a case by case basis rather than canonically declare that all coordinates are ordered first by their x value and then by their y value.
That's a lot of trouble when you already have an operator&lt; available.
So much trouble it took me all of 30 seconds to type out: struct CoordinateComparator { bool operator &lt;(const XYCord&amp; lhs, const XYCord&amp; rhs) const { return std::tie(lhs.x, lhs.y) &lt; std::tie(rhs.x, rhs.y); } }; My God the horror!
Versus no lines or time at all. Laziness is a virtue. Edit: And no bugs unlike yours? 
Can't say I've ever had a single issue using a pair as coordinates.
&gt; Thank you for proving my point actually. You think you're getting equality and ordering for free, but actually what you're doing is introducing subtle bugs into your program. I could make just as strong an argument that lexographical order is a good default such that it *avoids* bugs because it at least guarantees all of the fields are compared. &gt; Finally, neither std::pair or std::tuple provide a way to write to ostream nor is it clear what that would even do, should it write it separated by commas?. Oops my bad. There are iostream overloads for tuple in boost, which is what I'm used to. http://www.boost.org/doc/libs/1_63_0/libs/tuple/doc/tuple_users_guide.html#streaming
But the example is valid for things like `find()`.
Where did anyone mention inheritance as a vehicle for code reuse here? (I don't even agree with your point, or rather think it's exaggerated, but I don't even know why you brought it up).
If it's not obvious how `std::pair` is being inherited with the stated advantage being the reuse of constructors, comparison operators, and other code that works with `std::pair` (and apparently even code that doesn't work with `std::pair` such as the stream operators) then I'm not sure how much more constructive this conversation is going to be.
Yes, absolutely. I had some craziness a while back because some of my dependencies were compiled with 14, some with 11. Both of them depending on some boost library (maybe regex). So those headers are being included in two different places but with different C++ versions; that means that the header files could be different after preprocessing, leading to ODR violations. It took a while to figure out as there was some global variable that was segfaulting either before or after main. Those tend to be a pain.
But `find()` does not return a `std::pair` or a `std::tuple`, so it's off-topic.
Whoops you're exactly right there. But it's still an interface that would benefit from using optional in the return type. 
So if I'm reading this correctly, [N4659](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4659.pdf) is the draft international standard that has been sent out for voting to become C++17, and barring any unexpected votes, will be the final version.
Like others have mentioned, I've had issues with boost being built with different flags. I was building my project with the c++11 flag, and was also linked against some boost library. I had indeed also built boost with c++11, however I wasnt aware that at runtime, the linker was picking up the boost libraries from a different location (where boost wasnt built with the c++ flag). So after some debugging, I realised what was happening was that a static variable was being initialised one way by the non-c++11 build of the particular boost library. Someone describes the problem to detail here: http://lists.llvm.org/pipermail/cfe-dev/2014-April/036260.html It was interesting to learn, and also eventually learned about the install name tool on mac and how the install name of the libraries determines the linker decision. In a nutshell: its aways better that thr install name es "@rpath/libname.dylib" and not just the library name, otherwise it can be pulles from unsuspected places (macports/homebrew!) 
Is P0630R0 serious?
I'm sorry I can't attend this year. But I'm looking forward to watching this great program on Youtube soon :) 
Exciting. Many of these could be implemented as clang-tidy checks.
Stopped to read that guy after reading fabulous link https://arne-mertz.de/2015/07/c-is-not-an-object-oriented-language/ : &gt; Comparing C++ with object oriented languages &gt; With that in mind, we may be able to understand some people who come from Java or C# and consider C++ a bad language: They expect an object oriented language with all its cozy features like e.g. a garbage collector and are disappointed because they don’t get what the brochure promised. .... I do not think that person that confuses oo paradigms with garbage collection - is reliable source... 
Of course, but we were talking about pairs. And you've removed the type safety that newtype brought you to avoid accidentally using a width as a height. The next step would be: using Width = newtype&lt;struct Width_, int&gt;; using Height = newtype&lt;struct Height_, int&gt;; struct Size { Width width; Height height; } 
Yes, Cppcheck can implement all of them now!
yeah that works in a pinch, although i do think the using newtype declaration is prettier than the macro. boost's solution does have an additional issue that it requires the underlying types to have the equality and less-than operators to be defined for your type. this, for example, doesn't compile: struct foo{}; BOOST_STRONG_TYPEDEF(foo, myfoo);
Looking at [More Better Operators](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0611r0.html) by Lawrence Crowl. AFAIK, parsing left to right, it is ambiguous if the same token is both infix and postfix operator. An operator can either be prefix and infix (e.g. +,-,*), or prefix and postfix (e.g. ++,--). The table at the end of the paper demonstrates this. However, the paper talks about extending the fixity of operators and says: &gt; While all such 'fixity' extensions will yield parsable expressions, such expression may not be easily written or read. To avoid confusion, it is probably best that any given operator have at most two of the three fixities. I am not sure how this works. Can you have an operator with all 3 fixities and still parse an expression unambiguously? The paper goes on to suggest ^ as postfix dereference operator. So how do you parse a ^ b or a ^ + b unambiguously?
[Concepts are ready.](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0606r0.pdf) But if [P0464R2](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0464r2.html) is not approved then I'll be *very* sad. Also looking forward to [P0624R0](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0624r0.pdf) and to the discussions that [P0633R0](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0633r0.pdf) will start.
Hurray! Updates for C++17! I've been waiting for this! My thoughts on the [Kona minutes](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4654.pdf) and [N4661 Editors' Report](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4661.html) that interested me: * [Core Issue 426 (Identically-named variables, one internally and one externally linked, allowed?)](http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_active.html#426): I remember playing around with this and being mildly surprised it compiled. I have a feeling this might break some people's code if they were not careful with their naming and linkage. There's a frustratingly large number of documents that are inaccessible (need to be committee member or invited to view). I want to be informed! I'm interested! :( Edit: Nevermind, a lot of them are available as part of the mailing list update! Guess wg21.link just hasn't caught up yet. Updated links! * [P0257R1 (A `byte` type for increased type safety)](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0298r3.pdf): This should reduce the confusion with regards to using `unsigned char` for byte representations (which struck me as odd from the first time I learned of it), made even more confusing by many interfaces using `char` as the type for byte representation (C API's in particular). * [P0615R0 (Rename to "structured bindings")](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0615r0.html): I still think "decomposition declaration" sounds better than "structured binding declaration," but if anyone can explain to me why the latter is the better choice, I'd be glad to listen. * [P0620R0 (Drafting for class template argument deduction issues)](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0620r0.html): Looks like template argument deduction for class templates will work with direct list initialization as well. Nice, but I'd like to know more about the specifics, e.g. how it might interact with regular direct list initialization rules for aggregate types, `std::initializer_list` constructors, etc. By the way, can anyone explain or link to an explanation of all these cryptic acronyms such as CA, CH, CR, DR, FI, GB, NB, US, and whatnot? I know DR stands for "Defect Report", but I haven't a clue what the others might mean. * [P0604R0 (Resolving GB 55, US 84, US 85, US 86)](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0604r0.html): "US 86: Rename `is_callable` to `is_invocable`." Makes sense, given that it's really checking if it can be used with `INVOKE`, not whether it can be used in a function call syntax. * [P0433R1 (Integrating template deduction for class templates into the standard library)](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0433r2.html): Hurray! This makes me [very happy](https://redd.it/5o1cah). Probably my favorite news among everything else, and the one that will have the most impact on me personally. I'm sure many will be appreciating this one once C++17 is released! * [LWG Issue 2872 (Add definition for "direct-non-list-initialization)](https://cplusplus.github.io/LWG/lwg-defects.html#2872): Not a very elegant name or anything, but I suppose we now have standard-supported disambiguation of `T(a, b, c)` as "direct-non-list-initialization" and `T{a, b, c}` as usual "direct-list-initialization". As direct list initialization is becoming more popular, it's good that this is properly defined, especially in the context of [emplace-constructors](https://cplusplus.github.io/LWG/lwg-defects.html#2903). Speaking of emplace-constructors, I really wish `emplace_*`or `make_*` functions used direct list initialization instead of direct non-list initialization so one could aggregate-initialize elements. For example: struct S { int x; }; int main() { // Aggregate initialization please? :( std::vector&lt;S&gt;{}.emplace_back(1); // error. } However, it looks like there's [some work being done](https://cplusplus.github.io/LWG/lwg-defects.html#2911) on that front (whatever "accepted as Immediate to resolve NB comment" is supposed to mean), so there's hope! And, finally: * "`__cplusplus` macro value updated from 201402L to 201703L, resolving NB comments CA 15 and US 83." C++17 is just around the corner! \o/
The writer says in the next paragraph that C++ isn't necessarily object-oriented...
Concerning other papers on the mailing list: * [P0511R1 (Deduction guide for `std::array`)](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0511r1.html): A good read if you are interested in or expect to write your own deduction guides. Writing them is not as simple or straightforward as it may initially seem. * [P0599R1 (`noexcept` for Hash Functions)](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0599r1.pdf): This should make some library maintainers a bit happier! * [P0611R0 (More Better Operators)](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0611r0.html): ... Really?! Is this really suggesting deprecating and eventually *removing* the dereference operator as we know it in favor of a *postfix* `operator^`, for the sake of introducing `operator**` as an exponentiation operator?! Am I reading this right? `int p^ = &amp;x;` just looks horrible: I thought we're trying to avoid syntax such as `T arr[]` or `T (*fp)(A, B)` where the identifier is tucked in the middle of the type somewhere. * [P0614R0 (Range-based for statements with initializer)](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0614r0.html): Ooh, I like this! Initializers for conditional statements was very nice. This should help with the common indexing problem when using range-based for loops. * [P0623R0 (Final C++17 Parallel Algorithms Fixes)](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0623r0.html): I had wondered why the multi-range overload was missing for `transform_reduce`, despite [the CppCon talk](https://youtu.be/Vck6kzWjY88?t=25m42s) mentioning it. Good to see it back in. * [P0630R0 (To boldly suggest a pub crawl for C++ Toronto)](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0630r0.html): LOL! Pub crawling is serious business, folks. XD * [P0634R0 (Down with `typename`!)](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0634r0.pdf): Yes! The less places I need to write `typename`, the happier I am. I would very much welcome these changes if they are as simple to apply as the paper makes it out to be. Compilers already seem to be comfortable with parsing types without `typename`, even where `typename` should probably be used according to the current standard.
&gt; I could make just as strong an argument that lexographical order is a good default such that it avoids bugs because it at least guarantees all of the fields are compared. :-o Sorry, no. To have an automatic, invisible facility that _might sometimes_ be correct is a trap. If you need a comparison operator with your struct, write it yourself. Nine times of out ten, you don't need it.
:-o I see zero advantage to this inheritance scheme and many disadvantages - you really haven't explained why this is better than the simpler and completely explicit: struct CoordXY { int x, y; } 
Won't make it into C++17(?), but the range-based for with initializer is a very good idea! Super useful.
with precedence (like with all operators) and type. Same as * ("a * b" or "a + *b")
And also in many of the same situations. 😕
That is not the same. * is prefix or infix. As I mentioned in my post, an operator can be simultaneously infix and prefix. But an operator cannot be simultaneously infix and postfix. Say you are parsing a * b. You first see a. Then you see *. You know * has to be infix since any operator after you see a has to be either postfix or infix. But if ^ is allowed to be postfix, and you parse a ^ b, when you see ^ you don't know which ^ it is - postfix or infix.
That's a bit melodramatic. Every default is only sometimes correct and we count on defaults all the time, all over the place, because it's convenient. Otherwise, we couldn't have defaults for anything and would need to be explicit all the time. Some people think that's a good thing, but for me it gets overly verbose fast. 
Far more commonly, only the use of `typename` and not "class" is supported for dependent types: template&lt;class T&gt; ... typename T::dependent_type x; Some compilers do not complain (e.g. gcc), but others will (msvc), if you use "class" instead of `typename` there.
Thanks for the insights. Would you happen to remember which talk by Jonathan Blow discusses this? Out of curiosity, considering some codebase of size 6M LOC in Rust, could you, perhaps elaborate on the kind of stuff that you think might drive the compiler crazy? Thanks! 
return accumulate(s, s + size, char(), (_1 ^ _2)); Boost lambdas FTW :D
Depending on what you use of C++, it can be as fast as C. What you gain with C++ is some additional tools to help maintainability and hopefully reduce bugs. Most if not all AAA video games are written in C++ because the code base is large and there's a lot of programmers working on it.
&gt; What's the value in using CTest as opposed to just running the compiled unit test executable? automatic submission to a dashboard, parallel running of the executables...
Those two letter acronyms are national body names. "NB Comment CA 15" means that this was the 15th comment on the draft standard from Canada. NB --&gt; National Body DR --&gt; Defect Report CA --&gt; Canada CH --&gt; Switzerland FI --&gt; Finland GB --&gt; Great Britain RU --&gt; Russia US --&gt; United States 
&gt; Is this really suggesting deprecating and eventually removing the dereference operator as we know it in favor of a postfix operator^, for the sake of introducing operator** as an exponentiation operator?! Wouldn't it be better to make `operator^` the exponentiation operator? Isn't this the usual sign for exponentiation anyways?
Programming languages are typically written in English, with maybe a few (dozen) pages of BNF. A language is not a program. Compilers and interpreters are programs and can be written in any general-purpose programming language, though it's often considered worthwhile to implement them in the source language: https://en.wikipedia.org/wiki/Bootstrapping_(compilers)
My experience so far (admittedly not on projects so large) is that various Rust features actually improve my confidence of correctness when refactoring and modifying programs. It is a frequently measured pleasure point on r/rust as well, so I guess I am not alone.
Hey, fellow Rustacean here. Look up Jonathan Blow's first videos on "a new programming language for games" I believe he explains his problems with Rust and other languages there. 
It seems that Rust is not neutral. It is sponsored( or controled?) by mozilla. Will it be adopted by other tech giants in the future? 
Neutral compared to what? golang doesn't even have a steering committee.
To C++ ? This is C++ subreddit, you forgot?
I would go with #define true false
Is [this]( http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0611r0.html#Examples) satire?
Rust core team member and Mozilla employee here. We have a federated governance structure https://www.rust-lang.org/en-US/team.html A _ton_ of these people are not Mozilla employees. We think of Rust as a community project Mozilla works on heavily, rather than as a Mozilla project. &gt; Will it be adopted by other tech giants in the future? https://www.rust-lang.org/friends.html is a list of production users; Dropbox is probably one of the bigger ones you might know. There's some stuff in the works, but I can't talk about it :)
After typing out four or five responses trying to justify my lack of usage of unsafe blocks, the only reason I don't use them is because I personally frown upon myself using them. It's nothing logical, I just feel like I *should* be able to solve all programming problems using their programming model unless I'm going to be calling into foreign functions. Gotta love the human brain. Maybe I'll start using them more often - generally when I run into a place where I can't do the thing I want because of lifetimes, I find another way to do it in a more idiomatic Rust fashion.
Just my thought: What happened in the very beginning was that a programming language instead of machine language was created. That gets translated into machine code later. Then with that language another language. And with that another. You see? The level of translation and abstraction gets higher and higher. So if possible I would write another programming language (the compiler/interpreter for it) in C instead of C++. Don't get wrong though I like C++ better than C.
I use Rust (since ~9-10months) and C++ (since ~7 years) at work, both in the same project (modern generic header-only C++ using almost all of C++17 already...). My time is spent like this: ~40% Rust, and 60% C++, implementing new features in both (the C++ part is not "legacy" code or anything, it is just that new modules are written in Rust, but the "old" ones are still being developed). The jump from C++ to Rust is qualitatively larger and better in benefits than the jump from C to C++. Still, trying to sell Rust to C++ programmers is as hard as trying to sell C++ to C programmers. To me, the best way to sell it is attacking the following question: When you are developing in C++, what do you spend time on? - **writing new features?** - **build system**: portability across compilers, setting up CMake, configuring CI/sanitizers/clang format/tidy/linters, adding/upgrading dependencies, adding new unit/regression test files (and updating the build rules)... - **compiling**: C++ modules is a ~2x speed-up (we use clang-modules), but that is sometimes not enough. - **boilerplate code**: lots of C++ code is "boilerplate": RAII, rule of 5, NVI, noexcept, enable if, tag dispatching, wrapping functions in function objects, type trait kind of stuff, ... This adds a lot of mental overhead, because C++ has lots of pitfalls, and there are lots of idioms to defend yourself against these pitfalls, but they all require "boilerplate". - **APIs**: there are tons of ways of doing APIs in C++, but you need to think about const functions, constexpr, constructors, explicit constructors, SFINAE, tag dispatching, constraining generic functions (are your constraints correct? who knows..), what goes in the header file, what goes in the cpp file, ODR issues, ... - **refactoring**: if you have lots of unit tests and assertions, the compiler will mostly guide you through refactoring in C++, but when you have variant, and switches, and lack of exhaustiveness checks (e.g. say you are updating a compiler's AST), refatoring can be quite time consuming (e.g. trying to debug why some overloads are being picked or not at compile-time due to a large SFINAE chain). You should answer this question for yourself. For us, we spend some time implementing new features, but we spend a lot of time with the rest of the cruft. What does Rust bring to the table? It eliminates _all that cruft_: - It has a build system, package manager, and module system, that _just works_ on all platforms that LLVM can target (not all platforms, but still a lot of platforms). Adding new dependencies is trivial and never breaks anything. Sharing modules with the community is _trivial_. Being able to reuse all the collective's hive mind code makes you instantaneously more productive. So does not having to think about build system, dependencies, linting, sanitizers, portability, .... - Adding new tests and benchmarks is trivial. Testing everything is trivial. Automatically generating test (quick-check like) and fuzzing is trivial too. Want to add a test? add it inline with your code if you want to. - Boilerplate/APIs: Rust solves all problems that a large set of features in C++ solves, with a minimal set of features that really works well together: affine types (move semantics by default), lack of constructors/copy/move assignment/.., and Traits. I cannot really state how great traits are. Think of concepts + definition checking + concept maps + virtual concepts, all of these solved by a single language feature. You just declare a concept, and can use it to constrain generics at compile time (for static dispatch), or you can create an object of that concept, that can refer to any type that implements it (and type erases it with the concept). It is just infinitely _more ergonomic_ than all of the features C++ has for this (templates, SFINAE, tag dispatching, inheritance, virtual inheritance, virtual functions, overriding, final, NVI, concept-based run-time polymorphism, any, etc etc etc). - refactoring: is trivial in Rust, the type-system and the compiler guide you through everything (e.g. updating variant fields and switch statements), run-time bugs are always logic bugs because _in Rust there are no segfaults, no data-races, no uses after free, no double frees, no accidental reads of uninitialized memory, no iterator invalidation errors, etc etc etc_. If you are debugging and get an error, _it is always a logic error_, which means that you don't need to think about _anything else_ while looking for it. It is hard to state how big of a productivity boom this is. The other day I spent ~1.5h tracking down a segfault in C++ due to alignment issues of a SIMD type in some struct (the fix was to overalign the struct member and overload operator new for that struct). I am still pissed, 1.5 mentally exhausting hours! I am still pissed! In Rust, my _editor_ would have started blinking the second after hitting return while defining that struct member. I wouldn't have even needed to compile the thing to get an error. And I guess this is the reason I am so pissed. Two years ago I would have thought "life sucks, shit happens", but now instead I am pissed because I know there is something better. Its like being forced to write C code as a hardcore C++ dev and spending 2 hours debugging a memory leak because of a missing `free`. You would be pissed as well because with the smart pointers that just couldn't have happened in the first place. That's basically how I feel every time I hit a segfault in C++ or run into any kind of undefined behavior. I mean, Rust has many other great things (like Ranges, which they call iterators for whatever reason), really good lambdas (no need for capture clauses, they are always correctly deduced), pattern matching and destructuring (like structured bindings but not only for tuples but also for variants, structs, and nested combinations thereof), really great type inference (`let` is like `auto` on steroids). It is also trivial to parallelize something because the compiler will tell you when you make a mistake. It is also hard to really emphasize how powerful this is. In Rust, I spawn a bunch of threads, that work and mutate variables that live in each other stack frames without using the heap, and I don't even think about safety. In C++ I would be terrified of somebody spawning a thread and passing it a `std::ref` to a variable in some other thread stack frame, in particular when using `std::async` and `std::future`s. In Rust, I don't even think about it while doing it because if I screw up I know the compiler will just tell me exactly what I did wrong. Also, error handling in Rust is _trivial_, you just cannot get it wrong. Its like C error codes, which are really simple to explain, but with the compiler telling you exactly what you missed to handle and where. Did you ever wanted to know exactly what a function can throw in C++? In Rust, you just look at the return type, it tells you exactly this. Rust lacks a lot of things (e.g. template template parameters, integer generics, variadics, ...). These hurt when coming from C++. Really, variadics and integer generics in C++ are actually pretty great. Not many languages have these. But at everything else Rust is so much better. I don't know. I feel like telling a C programmer "why C++ is better than C". I hope I at least got you interested enough in the language by mentioning things "beyond memory safety" so that you will try it. Rust does have a learning curve. Learning Rust in a week (and by that i mean ~40h) is not possible. In a week you can learn the language, and you will be able to use it to write C++ like code in Rust. But it takes 2-3 weeks (~120h) to "forget" C++ and learn to write Rust in Rust. Its an investment, a way to justify it is that integrating Rust with an existing C++ code base is really easy via C FFI.
&gt; we use C++17 already, mostly **constexpr lambdas**, **if constexpr**, structured bindings, and all of C++14/11. It is mostly header only **heavy generic / template kind of code** (STL like) Interesting. When trying out Rust I came to the conclusion that these features/idioms do not have a direct counterpart in it. Did you use macros in Rust as a replacement? I'm talking about the things I've highlighted in bold and stuff like type computations done via metaprogramming or heterogeneous computations a la Boost.Hana.
Practically the only thing that I miss from Rust is its powerful pattern matching. That is a sore point not only in C++, but also in Java, D, and other ALGOL-based languages.
^ is already used for bitwise XOR.
Deadly serious.
I see, that sounds really useful. Would still need to compile it for each platform but it would make life a lot easier.
I dabble in rust every so often; however, I've been using C++ for over 18 years now and rust does not have enough to get me to switch over to it. I do not prefer rust over modern C++.
&gt; But if P0464R2 is not approved then I'll be very sad. I agree. &gt; ... and to the discussions that P0633R0 will start. I have not checked the the value proposals but anything that actually requires an object (i.e. memory) at runtime will probably encounter resistance in the embedded world. While the syntax is nicer one should only pay a runtime cost for reflection if that is wanted and necessary.
We use `if constexpr` a lot to do SFINAE/tag-dispatching "in a nicer way" and also to match on variants. This is a problem that you just don't need to solve in Rust (the variant part is solved with `match` and `if let` and destructuring/pattern matching). We use constexpr and constexpr lambdas in C++ to compute things at compile time. In Rust a project can have a `build.rs` file that runs arbitrary Rust code before building your project. Do you want to connect to a data-base at compile time and fetch a data-base scheme to generate structs and what not? Just write _normal_ Rust code that does exactly that and run it as a build step. The other solution is procedural macros (e.g. semi-stable via the `syn`crate). These are also normal rust code that can get invoked by the compiler on arbitrary code. The procedural macros get a stream of tokens (the input source code), use a library (e.g. the `syn` library) to parse them into an AST, and then you can manipulate the AST at will, generate/change/delete code, and finally write it back to tokens, that get compiled by the rust compiler (potentially invoking new procedural macros). This is _way_ more powerful than constexpr, and a big part of this system works on stable already. We have some in use since ~january, and... are kind of happy with them, but they are not perfect. They are a really big hammer, and the error messages one get could be better. A pre-build step that runs at run-time is easier to debug on a logic error than a procedural macro. In C++ a pre-build step (like Qt's MOC) is frowned upon, but in Rust they are part of the build system, and Rust really emphasizes that you shouldn't need to learn "a compile-time language" to do meta-programming. Meta-programming in Rust is not perfect, but most of the problems one would solve in C++ using meta-programming are solved with Traits without meta-programming. For the rest, you have textual macros, procedural macros, build steps, and full compiler plugins.
Point. It was awhile back so I'm probably misremembering and was just storing them in a regular map. I don't remember why, as it was just one of many little experiment projects I do continuously.
Sorry, I couldn't follow any of that. Could you elaborate on 1. What was the long division error? 2. How was it solved? (Bonus, since the formula is a bit of a mess can you explain it without code?) 3. What does an array or specific digits have to do with it? 4. Why does the humble period "." make an appearance? 
I wasn't aware of that new feature. Cool!
I think that the objects will be empty, and just provide a value interface to type computations a la Boost.Hana.
Just curious, what's the problem with it? 
Oh yeah right.
&gt; Everything I read about Rust is more or less positive This is indeed one of the problems I have with Rust; not so much the language, but rather the community. There is a definite subset of Rust users who are rather, um... *enthusiastic*, shall we say. I certainly don't want to tar everyone with the same brush, but there do seem to be a lot of very excitable Rust users out there who appear to view it as the single greatest advancement in the history of computer programming. If I see one more blog post about how "revolutionary" Rust's use of RAII or zero-overhead abstractions are... Let's see Rust for what it is: the latest attempt at a C++ replacement. These have come and gone over the years, and it's by no means clear that Rust will succeed. As an example, Rust is currently [43rd of the 50 languages monitored in the Tiobe index](https://www.tiobe.com/tiobe-index/). For comparison with languages of a similar vintage, Swift and Go are 10th and 17th respectively. C++ is 3rd. To put it bluntly: almost nobody is using Rust in the real world yet. So please, ease up on the hype, Rust users. Have a little humility. You've got a nice little language with some really good ideas, and having a static analyser built into your compiler is cool. But there's a long way to go yet.
As [n-gete.com](http://n-gate.com/hackernews/) calls them, The Rust Evangelism Strikeforce.
Maybe it would be also worth mentioning vaiven (https://github.com/MichaelRFairhurst/vaiven), which is another project using asmjit for JIT compilation of a dynamically typed language.
Every time I try to build a base, some naked guy pulls a shotgun out of his ass and shoots me in the face.
Do other compilers count? If so... We build openssl and zlib ourselves, against MSVC runtime of our choosing. For zlib, we use "contrib" files (VS projects). That builds it with "pascal" calling convention for exports, as Windows does (apparently, because that convention is/was faster than cdecl, on x86, due to ret [bytes off the stack] instruction). OpenSSL presumes the make-based build of zlib, which does the cdecl. Nice runtime crash :-). OpenSSL has a flag to align with that, `ZLIB_WINAPI` or some such. So we fixed it.
I've been loving Rust so far. - It has a lot of the philosophical benefits of C++. - The safety value might not be as high for C++ as compared to C but it works in more environments, like in a kernel, without crippling the language into a C with classes. - The build, dependency management, and release aspects of Rust are amazing. Last week, I saw people here encouraging a library author to take his headers-only library and make it a single header. We shouldn't have to make compromises like that. As for the warts: - Too much magic, compared to C++. Specifically auto-deref and type inference from how a variable will be used. I have mixed feelings about the language ergonomic initiative adding more. - Result/try!/? get you close to the ergonomics of exceptions except in when using closures, like with iter.map.
&gt; also i can't imagine how hard it must be to dive into a big source base (for example 6M loc) and try to add new features without the compiler going nuts.. I would expect it to be complete opposite. I only have experience with **much** smaller codebases, but I think extrapolation works here. Because of rigour enforced by compiler, the existing Rust code base has to be decently-structured already. No wonky patterns or code working by chance. Everything fits well, and is enforced by compiler. There might be quite a bit of modifying signatures and other "mechanical" work, but overall the experience would be best described as "fearless". Refactoring in C++ is usually "couple of hours of work, and a week of ironing out all the bugs". In Rust it's "couple of hours of trying to make compiler happy". Also, because of how thoughtful the tooling is and how well integrated ecosystem (I love `cargo`) it is effortless to have well-abstracted and separated code with crates (libraries). From my practice, C++ codebases tends to be bunch of stuff dumped next to each other and glued together with some `Makefile`. 
"There is one good reason not to use doubles but we chose to ignore it. Therefore there are *no* good reasons not to use doubles"
IIRC from your talks, you were interested in entity component systems. There are a couple of them in Rust. Some of them abuse textual macros a lot (but macros in Rust are "mostly" hygienic, and way safer and nicer than C++ macros). I would recommend playing with [`specs`](https://github.com/slide-rs/specs), which also shows how to do parallelism in rust using rayon, and then trying to maybe implement your own. This will be frustrating at first, because its a hard thing to do in a safe language (safely concurrently mutating a data-structure in Rust is [FUN](http://dwarffortresswiki.org/index.php/v0.34:Losing)), but it will teach you all the gory details about the "darkest" corners of the language: lifetimes, unsafe, traits, macros, ... (which are way brighter than the "darkest" corners of C++). It is also quite a good fit for Rust, because Rust is not an object-oriented language, but a data-oriented one. So an entity component system following data-oriented design is just a good match that will teach you Rust idioms. Still, you will soon find out, that Rust abstraction capabilities when it comes to, e.g., data-layout, are not really more powerful than the C++ ones, and very far from the state of the art (e.g. [Halide](http://halide-lang.org/), and to a much lesser extent, Jai), which is what basically is going to force you to learn all the meta-programming hammers in Rust to get it done (textual and procedural macros, and maybe even full compiler plugins). Anyhow, only those who have gone too far can really tell you how far you can go. Overdoit with traits, overdoit with macros, overdoit with lifetimes, have a lot of fun, and with experience in overdoing it you will learn how to use the hammers judiciously.
But the performance overhead is a big deal. You would double your memory bandwidth and cut your SIMD lanes in half, thus likely cutting your performance in half for no noticeable visual gain. If this is really the case with the proposal, it suggests an alarming unfamiliarity with real world image manipulation. 
If you're sticking to x87 instructions, sure. SIMD instruction sets (like SSE or NEON) can benefit from floats over doubles by doubling the number of elements they can operate on.
Any image library that uses double should be looked at with skepticism since 32 bit floats per channel give an enormous amount of accuracy above and beyond what people can see visually. 8 bit integers almost work, 10 bit integers work well, 10 bit integers in log space work even better. Most films in the 90s had their digital shots delivered in 10 bit log (I think). 
I think the intent of the API is to provide graphics features to non-graphics people. Anybody who really cares about performance will make use of solutions that already exist.
I don't think writing any piece of software in C makes sense if there is a good modern C++ compiler available. Very brave and bold opinion, I know, but the fact that modern C++ now has ownership semantics is a real game changer. 
You can also give rustwin points in all the c++ or c threads that invariably tend to reach a point where a Rust missionary comes and saves us, from the dreaded deep web hackers, using lifetime annotations to fight these infamous dangling pointers.
If you really care *that* much about the performance, then perhaps you are not the target audience for the 2D graphics API. I was curious why double was chosen, though, and I think it's pretty clear now. If you read N3888, you'll see that there's a lot of talk about using Cairo. Cairo uses double-precision floats for *everything*. I don't think that, if this is approved (and that's a *big* if), anybody that actually cares about performance will be using it. It'll be a good stop for showing beginners how to paint stuff on screen with C++, though.
Try D! (okay, only half-joking).
Finally someone adressed that, also I am seeing that in a lot of places in where you touch Rust, not constructive comments like "Rust is a great language" get shower of upvotes and comments that are fairly looking at the language with a lot of depth and content getting downvoted to hell becasue someone dared to have different opinion about the language. I've seen that many times on HN and Reddit. Maybe Rust community leaders should address that in their own community. 
Upon reading N3888, it's pretty clear why they chose it. The proposed implementation is to make use of Cairo, which uses doubles for *everything*.
Ya, ownership semantics was a big thing, still getting to grips with it totally 
&gt; Yes, but can the compiler completely elide them? Yes, just play around with Hana on [gcc.godbolt.org](http://gcc.godbolt.org) and you'll see that everything gets optimized away. This is also "mandatory" when you want a *constant expression*, as it has to be known at compile-time.
&gt; requires that a new programmer to join the team to have to learn a LOT more of the application design before hes able to dive in, since he has to see the big picture so he can continue that design and make the compiler happy. Wait, is the new programmer not being able to add crap a *problem*? I would say that it's up to the existing programmers of the team to point the new programmer in the right direction; if the compiler further enforces it, then it's always better than finally having a change to commit and getting rejected during the code review because it's not how it should be done.
Yes, I'm a big fan of Andrei's, and IMHO D has no doubt done a better job concrete learning from C++ (not surprising, given Andrei). However, D has unfortunately other issues. Primarily, the standard library and many third party libraries are (afaik) mostly dependent on running a GC. Also, just in general the language just doesn't seem to have any momentum, sadly. I think it's quite likely that some unholy union of Rust and D might be perfect. I think almost every single thing I can think of, at least one of those two languages gets right.
If you don't really care that much about the performance, perhaps you aren't the _target_ audience for C++. &gt; If you read N3888, you'll see that there's a lot of talk about using Cairo. Cairo uses double-precision floats for everything. That would be cairo's mistake, and destroying an image library's performance just to interface with a vector drawing library a little bit better is devastatingly bad design. 
What would be the good reason to avoid single-precision floats?
&gt; If you don't really care that much about the performance, perhaps you aren't the target audience for C++. That's kindof what I'm feeling about this proposal, to be honest. I think it's a neat idea, and it certainly helps the book-writers with their "Teach yourself * in 24 seconds" type stuff, but i just don't see any real value being offered with this library. If you care about performance, you're using the platform-specific stuff. &gt; That would be cairo's mistake, and destroying an image library's performance just to interface with a vector drawing library a little bit better is devastatingly bad design. I don't disagree with you. I'm not defending the choices, I'm just letting you know what I found.
&gt; There is a definite subset of Rust users who are rather, um... enthusiastic, shall we say. I think that new users are the most enthusiastic (those that make it past the borrow-checker hurdle, there's a steep slope). I think that a combination of (1) having finally managed to get a reasonably-sized program to compile and (2) for many of them, having finally dabbed their toes into a systems programming language (without it blowing up in their face at runtime) leaves them "high". --- However... internet rankings, really? Well, Rust is [26 on RedMonk (2017-01)](http://redmonk.com/sogrady/2017/03/17/language-rankings-1-17/) and [22 on PYPL (2017-03)](http://pypl.github.io/PYPL.html); so under-represented in Tiobe for some reasons. I don't care, personally. While popularity may matter, I'd rather judge a language on what it offers, and not on how hype it is (otherwise we would all be using JavaScript on NodeJS). &gt; But there's a long way to go yet. Indeed. Rust is really cool, but beyond the papercuts, it's still relatively feature-light especially in the meta-programming area: the lack of equivalent to `constexpr`, non-type generic parameters, type constructors and variadic generic parameters are keenly felt. The mess that are the trait implementations for fixed-size arrays and tuples reflect these issues pretty well. --- Still, I look at the speed at which both C++ and Rust evolve and one looks like it's dragging feet, while the other is progressing by leaps and bounds. In the last 10 years, I've seen C++11, C++14 and now C++17. And I'm not that impressed. There were cool features, don't get me wrong, but...: - C++ got lambdas! Yeah, well, Rust has them too... - C++ got type inference! Yeah, well, Rust has better type inference... - C++ got move semantics! Yeah, well, Rust has better move semantics... - C++ got multi-threading! Yeah, well, Rust has better support for multi-threading... - C++ will get ranges! Yeah, well, Rust already has slick iterators... - C++ will get modules! Yeah, well, Rust already has modules... - C++ will get `variant`! Yeah, well, Rust already has sum-types... - C++ may get safer! Yeah, well, Rust already is safe... So, really, the one key advantage of C++ is its meta-programming story. It might be clunky and haphazard, but it is powerful and flexible. Rust is catching up though. Quickly. Of course, it's always easier with hindsight. And when not having to maintain backward compatibility. And when building on the shoulders of giants (LLVM!). But I don't pick a language based on the effort that was put in its development; I pick a language based on its features (or lack, thereof). And while I'll stick with C++ for a while because of legacy reasons (existing codebase), I've stopped tinkering with C++ at home and switched to Rust. It's been a bumpy ride (especially pre-1.0), but the language just has way less papercuts. And it's never crashed on me, either. 
The case where you actually needed the precision would be the big one. Most applications don't, but some do.
The Cineon format (more recently known as DPX), on which film scans were usually delivered to visual effects houses in the 90s, used 10-bit log because that represented well the dynamic range of a color film negative. The reason to use double-precision for 2D imaging today is that a number of common techniques capture very high dynamic range images of scenes and use them as 3D illumination maps or filter them to mimic a camera's color space as a post-process. I'm a little surprised if the proposals in question don't offer a lower dynamic range option, since as you say 16-bits-per-pixel is fine for most images captured with ordinary cameras, but I'm pretty sure that accommodating HDR images is what the designers had in mind in choosing double precision.
There was discussion on the Core Guidelines, and the consensus is that "override" means "overrides the base version" (as in the meaning of "replace", "clobber", "annul"), whereas destructors never do that. They always chain (you can't stop the base version from running), therefore destructors do not "override" anything. Therefore the Core Guidelines suggest "If a base class destructor is declared virtual, derived class destructors should neither be declared virtual nor override.". (https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#Rh-override)
&gt; I think that new users are the most enthusiastic (those that make it past the borrow-checker hurdle, there's a steep slope). I think that a combination of (1) having finally managed to get a reasonably-sized program to compile and (2) for many of them, having finally dabbed their toes into a systems programming language (without it blowing up in their face at runtime) leaves them "high". I've seen people that use Rust for a long time beeing "oveer enthusiastic" in comments on HN, for example arguing that Rust is so great that it does no allocations in certain siutation that other x language did. This was not a new user, one of rust core team member told him himself in comment that what he wrote is not true and this is just one example.
I haven't browsed the proposal, but if I had to take a guess, it's because performance isn't the critical use case for a 2D drawing API. After all, if you actually wanted performance, you'd be using OpenGL/DirectX11/Vulkan/DirectX12, and if it were a GUI-based program, you'd be using an API like QT, GTK, WinRT, etc. The use case for an API like this is pretty likely newer, less experienced programmers. For many newer programmers, `double` is a more natural data type for storing floating point values. Newer programmers often balk at the mention of `float`'s more limited precision (even if in practice it doesn't really matter) and get scared (unjustly) into choosing `double`, even when they don't need it. So when they're trying to use a drawing API, being suddenly told "`double` is too large, you need to narrow-cast to a `float`", they're not going to react well. Even if they do, their code will suddenly become littered with casts, which will make their code very smelly (`setPoint(float(x), float(y), std::draw::color{float(red), float(green), float(blue)});`). Forcing everything to use `double`s means that whether you use either, you don't need to cast everything, and it'll be a less intimidating API for newbies. You and I, as experienced programmers, can stand and look at this and say "well that's *ridiculous*! That doesn't make any sense!". And we'd be right. But oftentimes, in situations like these, how things are *perceived* is a lot more important than how they *are*.
Shame I don't see [File Literals](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0373r0.pdf) made a part of this. What would it take to get that proposal taken more seriously? Does it have defects that are too significant at this time?
Yes, I worked with HDR images. Those had single precision color values. It allows a range up to values &gt;10^38 , which seems enough to me. Can you give an example where double precision is used? edit: also important is that in the proposal no HDR is considered: allower values are [0.0, 1.0] For position values: how do you get the 32k value? In terms of consecutive integers single precision can address 2^24 .
This isn't really on topic for /r/cpp as this is a general topic. Consider asking /r/programming.
I don't know. I guess some gcc configure or build flags disabled it?
\^^ then? Although I've seen arguments that that should be logical xor
&gt; requires that a new programmer to join the team to have to learn a LOT more of the application design before hes able to dive in I wish I had a business, real-life experience of new people joining to work on Rust code. I only have my open source experiences so far, and I've playing with Rust since like 0.3... It's been a while now. IMO, because of explicitness it should be easier to dive into existing codebase for a newcomer. A lot of stuff is just plainly there in type system. This is shared, this can send to a thread, this is reference counted and so on. That is at least my experience, reading and submitting fixes to other codebases. Same fearlessness applies: if it compiles, there's probably no trickery that you might have missed. Also, testing is much more pleasant so there's usually more unit simple tests. Having said that, I can totally see how Rust overall can be a challenge for new hires. A lot of devs know C++, while Rust will dump on them a lot of new concepts, all at once. Borrow checking, FP, new patterns, new abstractions.
Are there people regularly looking over compiler generated instructions? The C++ code doesn't seem to be very complex at all, so it's surprising to see a whole blog post on how most compilers suck at generating instructions for that piece of code.
&gt; What would it take to get that proposal taken more seriously? Personal opinion: provide some code samples and comparisons (e.g., what code looks like with and without) instead of just a flimsy bullet list of hypothetical use cases. Preferably with a compiler implementation in GCC or Clang that people can play. The author would have any feedback from the committee if it's already been reviewed. It may simply have not been reviewed yet since the meetings have been pretty fully with C++17 NB comment reviews and fixed, so new stuff is hard to get scheduled in for a proper review.
This thing supports fastcgi. The point of the frameworks is routing and templating, and making sessions and authorization easier, and handling stuff like large file uploads. Doing that stuff yourself from scratch is kind of silly. As best I can tell it's not a good idea to do web stuff in C++ at the moment. There's nothing sufficiently supported and you're probably going to wind up bashing your head against the wall.
I regularly look at assembler output of hot spot loops, when I want to verify that the compiler sees my code the way I do, in terms of possible optimizations.
&gt; The de facto standard for graphics has been floats If I'm not mistaken all 64-bit Apple devices use doubles.
&gt; It seems rather excessive to add so much precision "just to be future proof", when the float data type has enough surplus precision especially for color and 2D coordinates. One case where single might be not enough is a Pythagoras calculation on a 8K display: sqrt(k * k) + 1) - k is 6.1e-5 if calculated with double and 0 with single precision. So the triangle hypotenuse and cathetus would be the same. But then: Why not use a template for the type?
I definitely understand that. But the size of the representation and the performance of the calculations in my program matters, too. It just does not seem like the C++ way to take a datatype that is too big by orders of magnitude. And I am forced to use it if I don't want to convert back and forth all the time.
Apart from performance, another reason for looking at disassembled compiler output is when your code had undefined behaviour, and you need to understand what damage it's done and how to fix it.
&gt; placement new, allocator support Very important features for game development / performance reasons.
I write a debugger in C++ that I quite regularly use to debug itself and look at the generated assembly, it's great fun!
I almost always have it in the background when debugging, even if I'm not actively looking at it.
This looks kinda neat. Hope it makes it to my editor of choice (Sublime) in the near future.
64 bit floats instead of 32 bit floats per audio sample? Do you have an example where that is necessary? It seems to me from some quick and dirty research that the loudest sound on earth would be 180db and would be about 524,288 the 'threshold of human hearing'. Wouldn't this mean that even 32 bit floats would be able to represent samples in that range with plenty of accuracy, even when dealt with and store linearly?
&gt; I don't know that you can credibly assert that across all possible applications. Perhaps someone has one in mind that you haven't thought of? I can credibly assert that it is not an issue in practice for visual images. &gt; Ok here's one. Suppose you're using this image library to manipulate complex-valued images, where you maintain an imaginary-component image and real-component image. You want to calculate the magnitude of the complex vector for a pixel. Doing so requires squaring each pixel value and adding the results, then calculating the square root, and you'll likely need all that precision if you don't want to lose too much in your result. Not an issue in entertainment applications but it does come up in observational astronomy, for example. That sounds like it isn't necessarily a visual image any more. Also it sounds like you are talking about two images, not a single pixel with higher precision. Also in your scenario it seems like you would only need higher precision to do the calculation, not to store the data. I think we've been pretty thorough on the idea of double precision for a standard C++ image library. 
If you control the language, you control the developer stay within your platform, framework, Eco system. Then developer will help you to develop products to control the market. That is why every tech Giants develop their own language. The main product of Mozilla is Firefox. Its competitors are Chrome(Google), IE/Edge(Microsoft), safari(Apple). Browser is the arena of Internet. Every tech giant want to control it. As a company, their purpose is to make a profit. I don't think it will keep neutral. At least, Google/MS/Apple will not think so! 
People who use such techniques certainly consider their data to be "images." My point is simple: some applications benefit from all that precision. I agree that many do not and if the proposal doesn't include a choice (via a template or whatever) that seems like an odd move.
&gt; So it involves writing a compiler in a general purpose language then use that compiler to create the source language implementation, or can you skip that step? Nope, there always needs to be a compiler or interpreter written in another language before you can start bootstrapping. You can make it easier by only implementing some of the language features in your initial compiler, and then use those features to write a compiler for the full language.
&gt; if you actually wanted performance, you'd be using I certain hope the standard committee doesn't take the view of make something standard, if anyone wants to use it outside of a hobbyist they can find something else.
This is an interesting post. I think the issue is that you are doing a lot of the optimizations that the compiler is trying to find. The compiler has a hard time recognizing the invariants that you are enforcing (as evidenced by the unrolling of the tail loop). I think one thing that can help with that is use of `__builtin_unreachable()`. For example, you could have added: if (length % 2 != 0) __builtin_unreachable(); Not to imply that would generate different assembly here, just that the comments indicate that there will always be an even number of entries, so you can indicate that to the compiler using something like that. MSVC actually has a better tool here in `__assume`, which can exactly replicate `__builtin_unreachable` with `__assume(false)`. It's also nice in that it won't evaluate the arguments even if it can't inline them. E.g. if `int foo(int)` is defined in another translation unit, you can still do `__assume(foo(10) &gt; 0)` and know that `foo(10)` will not be evaluated. The equivalent in Clang/GCC would be `if (foo(10) &gt; 0) __builtin_unreachable()`, but `foo(10)` would definitely be evaluated. Anyway, I think efficient use of this can help with some of this situations. You could even define some macros if you need to be cross platform: #ifdef _MSVC # define assume_true(c) __assume(c) # define assume_false(c) __assume(!(c)) # define assume_unreachable() __assume(0) #elif defined(__clang__) || defined(__GNUC__) # define assume_true(c) if (!(c)) __builtin_unreachable() # define assume_false(c) if (c) __builtin_unreachable() # define assume_unreachable() __builtin_unreachable() #else # define assume_true(c) ((void)0) # define assume_false(c) ((void)0) # define assume_unreachable() ((void)0) #endif Again, I'm not suggesting this would overcome the issues here, just that it can help the compiler understand what you are assuming. Also, it's a pet peeve of mine when I see code such as `length &gt;&gt; 2` or `length &amp; 3`. If you need to divide or mod by a power of 2 only known at runtime, then yes, the best way to do it is `length &gt;&gt; n` and `length &amp; ((1ULL &lt;&lt; n) - 1)`. But in this case, it's known at compile time that it will be `length / 4` and `length % 4`. So just do that. The compiler can certainly make the optimization and it makes the code much cleaner (especially considering that bitwise operators are low precedence, so you end up adding extra parentheses in more complicated expressions). It also has a nice symetery, since you change from `length &gt;&gt; 2`, `length &amp; 3`, and `src += 4` to `length / 4`, `length % 4`, and `src += 4`. Obviously the compiler doesn't need to generate static data for integer constants like it does with floating point constants, but it's still more visually pleasing to see the `4` repeated like that, at least in my opinion.
&gt; Unfortunately, as far as I can tell (correct me if I'm wrong) the standard does not allow doing it. {{citation needed}}.
What's the status of &gt; Despite being the the resolution to a Defect Report, this feature is disabled by default in all language versions, and can be enabled explicitly with the flag -frelaxed-template-template-args in Clang 4. The change to the standard lacks a corresponding change for template partial ordering, resulting in ambiguity errors for reasonable and previously-valid code. This issue is expected to be rectified soon. ? https://clang.llvm.org/cxx_status.html
"My C++ code is safe." I'm not /u/Selbstdenker, but I have felt the same as he does. I think the idea is, with idiomatic C++, compiler warnings, static analysis etc., developers can move pretty far up the safety scale in C++. But I agree with you that other people's code is buggy.
It should be a template type, so that its user has the flexibility to choose during compile time. For float type, it should be normalized [0.0 to 1.0] and int type should be 0 to int_max.
I do serious cad type work, high precision measurement and display of pixels. Having the double precision is convenient for positonal data becuase it is *very easy* to overflow 32bit floats especially when zooming into a model. Transforming the end points of a line to draw into a virtual canvas can go haywire when those end points overflow. Double precision effectively can make this problem just go away, although it can be solved in a PITA way by detemining clipped end points that will fit in a float friendly sub canvas of a full virtual canvas. Ugh all this sub pixel correctness crap can make my head hurt at times.
I don't think signed_min is as clear a concept as it seems to you. What is it, as an algebraic expression?
So you agree some other type should be used for colors ;) The standard proposition isn't for CAD rendering or gaming (my industry). It is a base-line intended to build UI solutions on top. Your CAD application, though interesting, is best served by true graphic APIs. I doubt you would even get close to manageable performance. Especially since they use doubles :P Displaying complex (and often ginormous) CAD drawings is a big task. For small stuff I guess it should be fine, but then again C++ was never intended "for small stuff".
I find it's plenty easy to add crap with Rust, but it's a lot easier to search for `unwrap` afterwards than to figure out everywhere with a potential null pointer dereference or exception.
I could say the exact same thing about C++ users toward C users. I work in embedded firmware, and it's the C++ people who are going door to door asking, "Why are you still using C??? Don't you know that C++ is like totally way super better in every way?" Rust programmers doing this to C++ programmers is just the chickens coming home to roost. &gt; C++ is 3rd. And C is 2nd. TIOBE is a mostly useless metric anyway, but if you want to use it then there you have it.
Thanks for finding the discussion, but ugh, that doesn't look like a consensus to me, that looks like one guy (gdr-at-ms) strong arming the discussion to meet his preference. After being shown from the standard that his explanation of overriding destructors was deficient, he comes back with "Again, I strongly encourage people to take a step back and not get too hung on details of standards wording." This just reads too much to me like, "shut up and stop disagreeing with me! Who cares what the standard says, my color for the bike shed is obviously best!" Worse, I didn't see anyone address the safely concern raised by MikeGitb, which is my main reason for using override. I'm glad clang tidy [held their ground](http://bugs.llvm.org//show_bug.cgi?id=30397).
Cool! now do the opposite!
Not standard, but cppreference says: &gt; Specifies that a virtual function overrides another virtual function. I read that as "if it's not virtual, no cookie".
This is not the problem: even 16 bit ints are sufficient for human hearing. And most music can fit in 13-14 bits in terms of dynamic. But when you produce music, if you start using a lot of effects &amp; filter, especially distortion, your noise floor will go through the roof if you don't do the filtering with an high enough bit depth.
Inlining everything is now a refactoring technique?
Yeah occasionally people post stuff to /r/rust instead of /r/playrust
It is not clear that being object-oriented is a benefit – that very much depends on the use case. IDEA is also supporting Rust, btw. I agree on the other points.
&gt; I was under the impression that it's not frowned upon if you keep them small and contained into safe abstractions. They're still not encouraged, because it can be surprisingly hard to write a correct safe abstraction. Many projects posted to /r/rust that use `unsafe` end up with a comment along the lines of "the unsafe block on line N seems incorrect ... ". Hopefully it will become easier and easier as the tooling around `unsafe` develops e.g. rustc recently gained support for Address- and ThreadSanitizer, [cargo-fuzz](https://github.com/rust-fuzz/cargo-fuzz) makes fuzzing (including with asan enabled) trivial, and there's both [academic](http://plv.mpi-sws.org/rustbelt/) and ["engineering"](http://smallcultfollowing.com/babysteps/blog/2017/01/22/assigning-blame-to-unsafe-code/) interest in formalizing and validating the rules in `unsafe` code.
I put the disclaimer there for a reason. Because I'm not entirely sure. My reasoning is as follows (based on the Nov 2014 [working draft](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4296.pdf), which is essentially C++14): The standard puts both override and final in the grammar construct *virt-specifier*. The definition of the destructor (p275, s12.4) is: *ptr-declarator ( parameter-declaration-clause ) exception-specification_{opt} attribute-specifier-seq_{opt}* Which doesn't have a virt-specifier. 
Enforcement across a team is the huge problem with any of the "If you opt into X, Y, and Z then C/C++ is safe" type of approaches. Because they are opt in and the language does little to help you do that. I spent a good part of the last year working to up the safety of the legacy c++ codebase, and I found that with current, widely supported c++ I could restrict a fair bit of bad behavior, but nowhere near as much as I wanted... and it was always a dive into some very deep and murky waters. There is lots of room for a "more safe" language, whether it is rust or something else. I do not believe c++ is anywhere close to where I want/need it to be on that front. (fwiw rust isn't either... their view of safety is too narrow.)
&gt; 8 bit integers almost work They almost work if you are using non-linear color space such as sRGB. To perform operations on colors such as alpha-blending colors need to be converted to linear color space first. In this case 8-bit is completely inadequate. 
&gt; "Rust is a great language" get shower of upvotes and comments that are fairly looking at the language with a lot of depth and content getting downvoted to hell becasue someone dared to have different opinion about the language. Well, yes. But for a different reason. Much of the time, the criticisms of Rust are flat out wrong. So somebody corrects them as being such, and the shower of up/down-votes from the Rust community ensues. When the criticism is fair (factually correct and relevant), I have seen much humility from the community. 
It's for reading code, not for changing the code.
That's the description of the *declarator*. A *virt-specifier-seq* is not part of a *declarator*. (Another consequence of this: the order is `auto f() const &amp; noexcept -&gt; void override final;`)
While things are improving for rust, RLS looks awesome, and the idea plugin is great, the IDE experience still lags behind C++. Intellij-rust is good, but nowhere near as good as CLion. Hopefully, things will improve considerably this year.
In my personal experience, use of std::pair and std::tuple should only be limited to within two levels only (i.e. two functions, one producing the pair/tuple and one consuming it). Beyond that, the meaning of the pair/tuple is lost, and the code becomes seriously unreadable.
But it changes it too so you have to undo everything again.
Oh, you're the guy writing this gem? I yearn for a Linux equivalent, congrats for your work :)
Never put parenthesis in return expressions, it some compilers it prevents RVO and with `decltype(auto)` you get some side effects.
Thanks :) I tried edb a few times on Linux and it's pretty good!
Obfuscator?
modern 2d graphics use lots of pipelined process, where double can be applied most widely and easily. Check the good old AGG [introduction](http://www.antigrain.com/doc/introduction/introduction.agdoc.html).
At some stage the draft is sent to all the national bodies (NBs) for comments. Every national body sends back a list of comments. So, UK 53 for example, would mean comment number 53 by United Kingdom national body. Then the committee processes all the comments and decides if and how they should be resolved. List of national body comments for the C++2017 committee draft is here: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0488r0.pdf
Note that Clang has `__builtin_assume`: https://clang.llvm.org/docs/LanguageExtensions.html#builtin-functions 
&gt; the amount of attrition that is imposed by the compiler is enormous What about the amount of bugs not caught by C++ compiler? I was big fan of C++ but after years of trying to create high-quality software (that means software that wouldn't crash or leak memory) with multiple threads I desired language that would statically check more things. I found Rust to be exactly what I wanted. Of course I can understand if you consider occasional crashes to be OK.
&gt; How many replacements for C++ have come and gone? If we're talking about high performance, AOT compiled systems languages without a mandatory garbage collector or a large runtime, I can't name any others. Java and C# are JIT compiled and use garbage collection, along with Go, D and Swift. Based on these (perhaps too strict) criteria, Rust is the first real competitor to C++ since it's inception.
I find debugging more frustrating and boring than fixing compiler complaints (remember, compiler always tells you the exact line and reason). That might be personal preference though.
&gt; a sane dictionary/map that lays things out contiguously? Yes. Rust's standard HashMap is implemented using open addressing, linear probing and Robin Hood Hashing as far as I know. This should give you a "more contiguous" memory layout than an array of pointers to nodes of singly-linked lists.
The plugin does, the tool only outputs a json with information for the expansion. You could write a tool to show the expanded code on another window, rather than modifying the code in place, for example.
I'm using C++ since 20 years. I fell in love with Rust at first sight (well, second sight really. I am a somewhat sceptical fellow, but it still is love). Rust encourages a lot of good practices, like immutability by default, stack allocations, no global mutable state. Maybe it takes longer to write Rust code, but it is easier to read. Thanks to `cargo` its usually much faster to get ready contributing to a Rust project. The only thing I currently miss in Rust is the ability to have type depend on compile time constants like Matrix&lt;4,3&gt;
&gt; drive the compiler crazy On the other hand, uncaught memory bugs won't drive *you* crazy. ;)
My understanding is that rust isn't governed as a Mozilla project even if they have a lot of influence. One thing servo people wanted for efficiency sake for some of their code is something similar to single inheritance. Adding Inheritance might be a bit controversial.
Regarding variadic templates, constexpr and const template parameters, I agree that they are missing and I believe they will be added at some point. Regarding 5, the only way I had issue with this was boilerplate. There's an RFC that aims to improve delegation. I'm highly interested in that because it would make inheritance unnecessary. I find error handling in Rust the best I've ever seen. I personally wouldn't mind removing `panic` too. 8 - there's not much you can do about OOM unless you expect it to happen. The only case I experienced this was trying to allocate huge image (many pixels). I guess handling this to improve UX would be nice feature to have. 9 - nobody prevents you from copying (forking) std types and create your own crate. ;) I believe it is possible to add reflection with procedural macros. I've been even thinking about doing it.
The range of a two's complement number of n bits is -2^(n-1) to 2^(n-1)-1. This means the absolute value of the minimal n-bit signed integer is not representable in n bits. You should expect weirdness when doing that. The problem is about types. If you expect abs(T t) to return something of type T you will always face this issue. You could define your own abs with different input and output types, if you need to deal with this case, the standard won't probably be interested because it adds a check that can become very expensive when programmers assume a cost for abs. Also, if you are working with numbers so close to the limit of your type you should be aware and take care of these cases, but it's not as often the case. 
“Overriding” refers to replacing something in the vtable with something else—as opposed to adding a new dispatch entry in the vtable—so it makes some sense to slap `override` on a virtual dtor as long as it’s actually overriding a superclass dtor. Whether or not it calls the base class (whether automagically or explicitly) is orthogonal to its override-ness. I can’t think of a reason to slap `final` on it; I’m not in a mood to comb through standards, but if it only prevents *explicit* overrides, you might be able to prevent any non-field-dtor actions in the subclass.
I tend to prefer something like this: #if defined(__GNUC__) || defined(__clang__) # define cxx_unreachable __builtin_unreachable() # define cxx_trap __builtin_trap() #else # include &lt;stdlib.h&gt; # define cxx_trap abort() # ifdef _MSC_VER // or whatever # define cxx_unreachable __assume(0) # else # define cxx_unreachable ((void)(*(volatile char *)0 = *(const volatile char *)0)) # endif #endif #ifdef NDEBUG # define assume_true(x) ((void)((x) ? 0 : cxx_unreachable()) # define assume_false(x) ((void)((x) ? cxx_unreachable() : 0)) # define assume_unreachable cxx_unreachable #else # define assume_true(x) ((void)((x) ? 0 : cxx_trap())) # define assume_false(x) ((void)((x) ? cxx_trap() : 0)) # define assume_unreachable cxx_trap #endif That should make it a little safer, in theory—if assertions are disabled, then actual unreachables get used, and otherwise, traps are used (so you get a similar effect to assertions). 
&gt; also i can't imagine how hard it must be to dive into a big source base (for example 6M loc) and try to add new features without the compiler going nuts.. Rust compiler is known to complain about everything, this is due to how it wants stuff to be explicit when visible outside of a single function (for instance, constants need to have their types declared, but local variables don't). However, this has a second side - everything compiler has to check is localized. For instance, function bodies don't matter when type-checking anything other that function, everything what is needed is in function definition. This includes generic functions, which say which interfaces a given type needs to implement to be used with a given function. Changing pretty much anything (with exception for public function signatures, public fields in structs, public enums, macros) doesn't affect code outside of crate (other than having to recompile it), the only unfortunate exception to this rule I can think of is implicit implementation of `Send`/`Sync`. This makes it easy to keep API compatible without risk of having compilation errors in external code.
Can you give an example of what you find emotional in the doc? I'm curious...
Don't you mean Round Robin?
There is a world of difference between a language for games, where performance trumps all, and systems, where safety and reliability are at least as large, and long term maintenance..
I agree - I program mostly C++ and have interest in eventually moving to Rust as much as I can, but the Rust people were so distracted with the "Rust is safe" thing that I had to put in some effort to find out for myself the things that *actually* made me want to use it: ~~concepts~~ ~~typeclasses~~ traits, modules, good macros, the packaging system. Rust has some really good features that end up being not promoted a whole lot.
Did you try https://codereview.stackexchange.com/ ?
Just want to add that some of these features are already on nightly. That is, you can use placement-new if you need it, and you can switch the global allocator to whatever you need. They are just not in stable Rust yet (maybe the global allocator part is, I don't remember). What is not done yet is switching the allocator on a per-container basis in the standard library (like the allocator type parameters in C++ STL). This is not available. There is a PR that implements this, but is not merged yet, and AFAIK it will still take a while before this is merged. Also, interesting for C++ programmers is to know why placement-new is not on Rust stable yet. The main reason is: because of C++! In C++ _all_ STL containers have both insertion methods (like push back), and emplace methods that use placement new (like emplace back). Currently Rust's box-syntax (placement new) has this distinction on nightly as well, but people are actually trying to remove it, so that all containers have a single insertion API that always does the right thing (you typically always want to do in-place construction if you can). It is not known whether this will be possible, but this needs to be explored before the feature is stabilized, since it would remove an arguably minor paper cut, but these do add up.
My biggest professional experience with C++ was a codebase I inherited from a company that my main company bought. All their devs jumped ship but we needed their code to continue to scale up for a year or so before we could get that line of business migrated over to our platform. This was the jankiest, most bugridden code I've ever seen. It worked completely by accident, and the smallest change would send you into spirals of seemingly unrelated bughunts. In order for it to keep up with the growing business, I had to take apart the whole system and build it back up piece by piece. The core problem was that it was written to be 'highly concurrent' (as the lead dev explained to me the week before he left) but had zero defense against race conditions ('locks are too slow'). If it had been written in safe Rust, 90% of the bugs I found would have been impossible. Obviously the value-add over well-written C++ would be much smaller. But I know from personal experience that at least some C++ 'experts' aren't nearly as trustworthy as they think they are, and I'd much rather inherit code that imposed some discipline than allowed a free-for-all.
&gt; developers can move pretty far up the safety scale in C++. Sure, have you used clang format? I invoke clang-format every minute while writing C++ code, and been doing so for 2-3 years. I just dump code, hit tab, it looks good. I never think about formatting while writing code, ever. Instead, my brain focuses on other things. In C++ one can prevent _some_ memory errors, but every single time I iterate over a container I hear rustc inside my head saying "don't mutate the container! don't mutate the container! don't! don't! don't do it!". Why? Because that might invalidate the iterators, and the code will compile, and the program might run and pass the tests, and when some user feeds it enough input, the container will reallocate, the code will crash, and I or somebody will waste hours debugging it. In Rust, I never think about any of this. While writing C++ my head is full of: "Use smart pointers! Don't write new/delete! use make_unique/shared/weak_ptr" Don't do this, don't do that, design like this so that users won't make errors, write interfaces that are easy to use correctly and hard to use incorrectly, assert that indices are in bounds, assert that pointers are not null, etc etc etc". In Rust all this stuff is never in your head, so you can focus on other things while writing code. This applies to debugging too: "There is a bug, I or someone did a mistake, what kind of mistake is it? Is it some logic bug? Did somebody forget an if or a switch case? Is it a memory error? A segfault? out-of-bounds? read of uninitialize memory? iterator invalidation? a multithreading error? ...." While debugging Rust programs 90% of this overhead that exists while debugging C++ disappears. A missed case in a switch? That cannot happen, ever. It is hard to know how this feels, because for this to happen one needs to delve beyond beginner level in Rust (~2 weeks) since at the beginning there are just many concepts that one must learn. Once they fade away and one becomes productive, switching back to C++ is horrifying because suddenly one needs to pay attention to so many things, and follow so many conventions that the compiler doesn't check, or bad things happen. 
I looked it up and now I can't believe I haven't heard of it before. Super impressive!
&gt; (maybe the global allocator part is, I don't remember). Not yet, it needs the allocator interface to be stable too.
Yeah the whole chaining thing a red-herring IMHO. I read `override` as "I expect there to exist a base class version of this function which is declared virtual'. The reasons why it might fire are a little different - regular functions typically go wrong (perhaps under refactoring) because someone typos the name or the params don't match up, which can't happen for dtors, but not declaring as `virtual` is equally valid, and which applies in both cases.
Yes, link here: https://codereview.stackexchange.com/questions/158711/naive-lock-free-work-stealing-queue
Huh. TIL.
Maybe, but I've seen this curious pattern across several, widely used projects. Maybe the idea was that since structs are global, you have to avoid them or make otherwise sure that their tags do not collide. (But I expect that C compilers which support LTO offer implicitly local structs as an extension, and compilers without LTO support do not really have to care about the distinction.)
Pop() needs to decrement `bottom` before accessing `m_jobs` in order to be symmetric with Push(). Likewise, the store back to `m_bottom` needs to occur before accessing `m_jobs` to avoid collisions with Steal(). Steal() similarly should store back the index before accessing. Steal() should consist almost entirely of a loop -- if `compare_exchange_weak` fails, re-load and try again until it succeeds or the queue is depleted. Just some friendly advice: make sure your overall ordering of operations is logically correct before you start playing with `memory_order`. There's no point in optimizing incorrect code. EDIT: In fact, I'm thinking you must load `bottom` and `top` simultaneously (packed together into the same `atomic&lt;&gt;`) due to the possibility of Steal() and Pop() converging on the same entry from different directions.
Absolutely. And just because Rust has that as a premise doesn't mean that we have proven or disproven it either!
Pop() and push() called from the identical thread, steal() called from other thread. 
well now I just feel silly. I made the assumption that the compiler representation followed the target integer representation and therefore this wouldn't work. Seems that's not the case and therefore this is portable. Thanks!
unit templates such as boost units and other generally use floating/double types as the underlying type. The safe numeric library currently addresses only integer operations. If it becomes popular, it could be expanded to include floating point types which raise a totally separate class of issues related to program correctness. But you're question is relevant in a a different case. Suppose you're a financial institution which can't afford to lose a billion dollars because of some stupid bug you might want to use the library in a way similar to the following: Presumably you've got some sort of class for holding money. Something that looks like template&lt;class base_type, unsigned int decimal_places&gt; struct money { long int m_value; // amount of money in cents ... }; // display money template&lt;class base_type, unsigned int decimal_places&gt; std::ostream &amp; operator&lt;&lt;(std::ostream &amp; os, money&lt;base_type, decimal_places&gt; &amp; m){ // display money in whole and fractional parts unsigned int cents = 1; for(unsigned int i = decimal_places; i &gt; 0; ++i) cents *= 10; os &lt;&lt; m_value / cents &lt;&lt; '.' &lt;&lt; m_value % cents; } ... so you can create using dollars = money&lt;long, 2&gt;; If you want to be sure that your money class doesn't create a disaster you can say using dollars = money&lt;safe&lt;long&gt;&gt;, 2&gt;; And get all the benefits without changing even one other line of code in your program!!! If you're really anal about performance you could say #IF NDEBUG using dollars = money&lt;long, 2&gt; #ELSE using dollars = money&lt;safe&lt;long&gt;, 2&gt; #ENDIF Of course there is much more to this. For more information check out the safe numerics library in the boost library incubator. www.blincubator.com Robert Ramey
See, this is what I mean. If you want to get me interested in Rust bring up these examples but do not just shout "Rust is safe". This makes it much more interesting than "safety". Especially when the "Rust is safe" part comes up in the context of buffer overruns or null pointers. The implications for concurrency and parallelism are also extremely interesting.
Consider what happens then the queue has one element and `Pop` and `Steal` are called simultaneously from different threads. For me it looks like they both succeed and return the same element. Moreover, the queue is left in inconsistent state (top and bottom are swapped). 
Homeboy, the OP never said anything about speed concerns of using a double. While his use of "bothered" may imply that, I think the point of their question was more along design decisions and justifications. It's valid to question designs, especially ones that may be used as the standard for decades. I agree that this may be a great foresight, but asking about the WHY doesn't mean one is "removed from ground zero". If nobody ever asked these sorts of questions, there would be no control of quality in the libraries we use every day.
Can't the type be templated which would allow the library user to specify 16,32, or 64 bit floats? It would be up to the user to be aware of narrowing/casting but that's no different that when using floats/doubles by themselves anyway. 
I'd circumvent such type-traits when http://stackoverflow.com/q/27053125/1000282.
I am not expecting it. Just saying what puts me off about the phrase "Rust is safe".
Steal() is spin wait in worker thread run loop.
Ah, suddenly that document makes a lot more sense than when I attempted to read it before! Thank you very much.
&gt; Specifically auto-deref and type inference from how a variable will be used. To be fair, C++ has copy/move constructors/assignment operators, which implicitly get sprinkled all over the place :)
In rust's case I want the ability to opt out of anything that can panic at the language level. In C++ I want to restrict behavior. My best shot is warnings and SA, but even the most pedantic compilers don't cover anything close to what I need. Just one example... I want to remove array to pointer decay altogether. The language can do it, but it's opt in on the function signature. Why doesn't anyone give me a warning about it? The answer is because it's valid C++, and people can do it safely. But it's not a tradeoff I want. Maybe I'm in a different situations than most of /r/cpp... I'm working with legacy code that dates back nearly 20 years and two other companies, that sort of followed 20-year-ago best practices. My platforms restrict my compiler choice so I can barely use any C++17, but even where I can it doesn't save me as much as I want it to. And I have a company full of different skill level engineers, many of whom don't read emails about best practices. Now rust doesn't solve any of that... waiting on c++17 and slowly adopting better practices is the best bet. But I like rust because it's a fresh start... it doesn't have 30 years of legacy choices it still has to support and allow. It's a pretty decent language out of the box. Not perfect, and it could all go sideways at some point. But for now it's what I want to be phasing in. In 5 years when someone writes some new code at my company I want it to be in rust.
Some vector types would be nice. I'm more used to the GLM vector types and the general support+functions that come with those, but they get used in tons of non-graphics projects. Standard library vector types would be neat, but probably won't ever happen. Also don't get me started on CUDA's goddamn vector types and just how shitty Nvidia's handling of those has been...
I agree with you that I am afraid that the over-emphasis of Rust's safety has unfortunately cast a large shadow over other strengths of the language. Personally, it's not so much the safety that I find interesting (Python is safe, after all), but instead the fact that the core enablers of said safety (ownership &amp; borrowing) can be used as-is to build other kinds of verifications in your type ecosystem. Couple examples: - ownership guarantee that your state machine cannot dispatch two events from the same state =&gt; just have the dispatch consume the current state, - borrowing allows locking at compile-time, so you can ensure that an object doesn't change within a certain scope =&gt; manual loop hoisting! For me, this is a new playground, much like C++ templates were. The two uses I mentioned are already quite useful (especially the first one), and I cannot keep but wondering what's next.
Ah damned, I munged the two together. Sorry :x.
&gt; In rust's case I want the ability to opt out of anything that can panic at the language level. Does this mean "never call anything that can panic"? Or something else?
&gt; if you're so unhappy with C++ and in its current (and probably future) state I am less unhappy about C++ than I am about Java :) &gt; So - what's the reason? Why switch jobs and not switch the company? I don't see using Rust quite immediately, but: - my boss and company are happy to use bleeding edge technologies, it just takes the right project to come up, - and from then on, as Rust matures, to switch more projects to Rust. We are all very pragmatic though: a big rewrite is costly, so it's not happening. The only way to switch would be a gradual shift, writing new code in Rust and throwing obsolete C++ code away.
I think the safety is much more appealing when advertised to devs like myself who used cpp a little in college but not much since. I know that there are tons of gotchas but I don't know what I don't know and that scares me. The idea that the compiler will help me learn before my code crashes during some critical process really eases my stress and lets me focus more on writing good code and less on "what am I severely messing up that I have no clue about". Just wanted to share another perspective. Also really enjoyed reading the conversations in this thread. I'm learning a lot. 
Seems like solid points to me. Where is the fault in the reasoning? If you know C, you know already know Go; yet a C programmer cannot confess to knowing Rust after spending a few days with it, so a legitimate comparison from ESR is not possible here. His viewpoint should have been withheld, at least until he knows enough about Rust to make a fair comparison. That's not much to ask. It's only logical that he would receive criticism from jumping into a technology half-heartedly, and instead of asking for help with some of his questions about the language, he assumes knowledge which is entirely untrue, and then asserts that he knows more than the language designers. Not the kind of person I would look to for objective advice. It would seem that he even continues to reiterate complete falsehoods about Rust in future posts even though he was already corrected on these misconceptions by the language designers and experienced users of the language. I'd say there is more than enough reason to be off-put by ESR.
&gt; Seems like solid points to me. Where is the fault in the reasoning? It's not the reasoning, it's that the comments are very, very aggressive. If that was in an official Rust space, the moderators would have gotten involved, I'd bet. Basically, the points aren't wrong, but they need some extra chill. It's very combative, which doesn't help anyone.
&gt; In general I would suggest to market Rust less against C or C++ and more on its own. As /u/steveklabnik1 mentions, this is actually kind of what the Rust website does. For example, if you work full time on javascript, you might only know that in C-like languages there are memory errors, and multi-threading errors, but the examples I showed you will tell you nothing because the language in which you think doesn't have these problems. So... the website tells them that in Rust they can write low-level code without needing to worry about memory errors, and that's already enough for them, because it enables them to do something that they couldn't easily do before without investing a huge amount of time learning all of the "good practices" of a low level language. On the other hand, a low level dev (C++/D/C/... dev) already has a tool that allows them to solve the same problems that Rust does solve, so their questions and approach to the language is completely different. They want to know "what does Rust allows them to do that their language cannot", or "which things are easier/harder to do in Rust than in their own language". They also have more concrete expectations about what a low-level language should be able to do, and more specific questions like "How does Rust safety differ from smart pointers". This audience would learn Rust more efficiently from a resource tailored to them. Sadly, this resource has not been written yet. 
Would it be possible to have "three versions" of The Book? Reader could choose one of "Never programmed before", "High-level programmer", "Systems programmer". The more advanced version user would choose, the more details would be hidden.
I mean calling this "lock-free" is pretty rich. I guess lock-free just means "with locks, but locks are hidden under a layer of abstraction".
Maybe. I've already written this book twice; writing too more might just not be in me for a few more years :)
The blog post didn't turn me away from using Rust. I thought ESR made interesting points, and decided that for him Go was the better choice. That's fine. There are many such posts about C++, but I still use it in many situations. What threatened to turn me away from Rust was Michael Murphy's (many) comments. He absolutely refused to accept the possibility that he could be wrong. He didn't stop to consider anyone else's viewpoint. Whenever anyone said they thought that maybe Rust wasn't the perfect choice in literally every situation and that sometimes another language might be a good choice, there was Michael Murphy, telling them that they're wrong and that they're fools for thinking that, and in fact they are lazy (or simply stupid) for not taking the time to fully understand Rust's borrow checker. It leaves a bad taste in my mouth. And makes me wonder what contributing to such a community would be like (although I guess I could just use Rust and never contribute back to open-source projects). &gt; I have to ask why you're programming in the first place. Is it to look cool? Or be trendy? It's because I love to program. If I'm abused for trying to help others because I made a different choice or came to a different conclusion than someone else, then I'm going to avoid that community. By the way, I do actually use Rust. I'm subscribed to /r/rust and I think the community is _by and large_ welcoming. But Rust just seems to have more than its share of diehard zealots.
&gt; Result/try!/? get you close to the ergonomics of exceptions except in when using closures, like with iter.map. FWIW, you can usually propagate failures out of an iterator by using something like `.collect::&lt;Result&lt;Vec&lt;_&gt;&gt;&gt;()?`, which short circuits just like you'd want. This works for any type that implements `FromIterator`, not just `Vec`.
Not that I'm aware off, and besides, everything other than transactional memory is based on locks. On some level, all synchronization primitives are either a spin-lock/test-and-set instruction or a disable interrupts instruction.
No because you use a test-and-set in a busy loop to implement locks anyway. You can't use the raw instruction for all that much, besides implementing locks or a different type of blocking synchronization primitive. It doesn't provide synchronization on its own. When I hear "lock-free", I expect it to be "blocking operation free", not just a slightly different abstraction on top of spinlocks/test-and-set.
Do you know how many hours I dug through the docs, reddit, and google to find out about that? It still has caused me some awkward moments but I don't remember what they are atm since I'm taking a break from my personal project to work on cobalt.rs to be able to host my blog.
&gt; When I hear "lock-free", I expect it to be "blocking operation free" You're thinking of wait-free, which is a stronger guarantee than lock-free.
I highly appreciate what you did!
I almost always have a godbolt tab open. It's incredibly quick and easy to see whether a given abstraction gets compiled away, or whether something gets optimized better one way or another.
My understanding of a test and set cpu instruction is that it's no more "blocking" than for example a mov or an add. It just takes one instruction cycle and both writes a new value and returns the previous one. Is this not the case? 
gcc was written in C for many many years, had a huge legacy codebase, and therefore an enormous one time cost to switching: and still decided to switch. if you google around you can find bits and pieces of the rational for doing it. In the specific case of compilers you will often find that algebraic data types (think `boost::variant`) , and even recursive algebraic data types are extremely useful. The main argument for C in languages (like in Python) comes down to the language being simpler for people who are not experts in C or C++ but rather in the actual language (Python in this example), but want to make a small contribution, and that C having a stable ABI makes it easier to create bindings for certain things. I actually think (despite disliking C) that these arguments might be persuasive for a very small codebase. But as soon as your codebase gets larger doing it in C and suffering all the issues that comes with, is not worth it. With the ABI issue in particular, the bigger your code becomes the more likely it's worth it to have a C++ implementation and a C ABI where necessary (which is really not a difficult thing). Also, targetting LLVM's IR (intermediate representation, that is the input to LLVM and the output of clang) for a new language now is almost a no-brainer. You immediately gain a whole pile of platforms and optimizations for free and it's easier than generating assembly directly.
No. On single-core, it's executed atomically so you would be right. Unfortunately on multicore CPUs it's not that simple. If two cores simultaneously dispatch test-and-set, one of them will be forced to retry until the other core's operation goes through, so this is effectively a hardware spinlock. There's other ways to handle this, I think using extra registers, but since this is hardware, my knowledge isn't too advanced. That being said, I now do see the difference of using test-and-set instead of a operating system lock, like `std::mutex`. The OS lock forces your thread to yield, so there is a greater penalty to doing that. 
I suggest you to read the paper about work stealing that was written by the people who originally developed Cilk programming model: http://supertech.csail.mit.edu/papers/steal.pdf
Yes and no. ccp_darwin was talking about images, where the pixel represents the incoming physical light intensity. As there is no maximum for this value it would be not beneficial to map this on the range [0., 1.]
Possibly, yes.
&gt;the only thing that can be done by the core that wins is that one instruction, essentially delaying the 2nd instruction by one cycle This is not right, even without the complexities of hardware. Core 1 fires off test-and-set, at the same time as Core 2. Core 1 is processed, which Core 2 probably receives an interrupt which prompts it to retry the instruction. However, before it can do so, Core 3 fires off test-and-set, forcing Core 2 to block. As you see Core 1 and 3 can force Core 2 to block for arbitrarily long by simply repeatedly firing test-and-sets. The key point is that, Core 2 isn't blocking in a sophisticated way like a real lock would, it's physically going to re-execute the same instruction. Mutexes don't have this problem (precisely why we don't use raw test-and-set instructions), they implement actual waiting mechanisms that prevent this kind of thread starving. &gt; This is opposed to a mutex which can guard an arbitrarily large and long critical section. This is right, which I why I was saying I agree.
You are thinking of how spin-locks are implemented. I'm talking about how the test-and-set instruction is implemented in hardware. The CPU core whose test-and-set isn't even allowed to test gets an interrupt on x86. This happens because test-and-set is atomic, so if one core has already started test-and-set all others will cause a fault until the ongoing test-and-set finishes. The core that handles interrupt simply retry the instruction, in a loop, as long as necessary. 
&gt; It should help us better understand how different programmers. How different programmers what?? D- for ambiguous spec.
I don't like macros.
I only see it from professors who stopped learning in the 70's (that was more common in the 90's but sometimes still pops up) and modern code with lots of number crunching that does it to take advantage of SIMD instructions or possibly to save every last byte in low resource embedded systems.
Thanks for pointing out the error, it has been fixed. 
Anything else? Ha ha! There's one macro in the entire 1500 LOC codebase.
honestly, the FTL_TASK_ENTRY_POINT bit was the first thing that caught my attention. even if that's the only macro, it appears to be a pretty important part of the implementation edit: my issue with that macro is that it obscures what looks like a normal function call. what are the arguments? where does 'args' come from, and why do you give up type safety with the c-style cast?
Coincidentally, all this is implemented inside the safe numeric library which has just the other day been approved for inclusion into Boost. More information available at www.blincubator.com
You are totally right. I had assumed that the declarator would have included the virt-specifier-seq if it would accept it. But in the class.mem section it clearly is a separate element. 
Nice read, minor nitpick: unless your PC is in realmode, the interrupts are listed in the interrupt descriptor table, IDT not the IVT.
As far as I know, using a fixed-width representation is common, with the width set at the smallest unit of currency your program needs to deal with.
Lock-freedom is a nonblocking progress guarantee, too. 
Yes. I work with older compilers at work and through experience I don't really trust them to emit sensibly optimized code. It's simply that I have to be a bit more explicit in what I want them to optimize away. Also I find the easiest way to debug template-heavy code is often to examine the assembly prior to linking.
&gt; fixed-width representation That is interesting. I had not thought about doing that. Wouldn't you still need to round things to the nearest cent? I still think a class might be the way to go, maybe I could represent dollars at a long and cents as an int? 
It was adopted at the meeting as far as I saw from the live updates.
I get why it didn't happen, but it would have been really nice to get one of: modules, concepts, ranges or coroutines into C++17. If all of these come at once in C++20, it's going to be a bit overwhelming and I see adoption being very slow, which will then make it take a long time for all of them to trickle down into university courses. If you look at the number of TS's in that diagram over time, it seems like the focus that the committee had for C++11 has been spread a bit too thin.
What would you recommend someone with a little.C++ experience from school and middling Rust experience from hobby projects check out if he wanted to learn modern C++?
Does ADA count?
I am not sure. The execution path is dynamic within a target range, but I can get NaN from floats and such. I'm not convinced it's not me. Just that enabling optimizations causes obvious errors in processing even if not in actual program flow.
This survey is relevant to C++ and is looking for users of C++ to specifically take it. 
But we got LFTS (optional, any, variant, string_view), Filesystem, Special Math functions, and Parallelism TSes. 
Please explain why you think the parent comment about Swift was incorrect. 
thanks, i will read inside it.
Best recommendation I can give is do a hobby project in C++. My hobby projects from the student years involved implementing rulesets from complicated games like Magic -- it's a fun challenge. Or write stuff that you actually need, e.g., a financial or time planner. I really cannot recommend books that much... maybe [some videos on C++ design patterns](https://www.pluralsight.com/search?q=c%2B%2B+design+patterns)?
not really spin specific queue. my understand worker thread run like this: while(active) { job = selfQueue.Pop(); if(job) { execute(job); } else { job = getRandomQueue().Steal(); if(job) { execute(job); } else { sleep(1); } } } am i right?
May I suggest dropping all those 'long' types. Either use 'int', or if you want something that can hold larger numbers, use int64_t. All you know about 'long' is that it's at least the size of 'int'.
Finally, I can fully commit to start writing a C++17 textbook. 
Yes, it was accepted. When a paper is revised during the Meow meeting, it will appear in the post-Meow mailing, even (and especially) if it was accepted at Meow. Few papers require no revisions at the meeting where they're accepted, but it does happen.
Or, you know, just count everything in cents ?
Valid point, I still think in terms of my old embedded C days when an int was 16bits and long was 32bits. I guess some platforms might still define int and long as different sizes, I would have to research that.
I like how putting override in the destructor of derived class will give me a compile error/warning when destructor in base class is not virtual. 
I thought modeling money was complex when I was just thinking about stocks, but you are right it gets even more complex with other instruments. That is what I like about object oriented languages, I can create my own class to model complex entities and redesign when necessary!
The only reason Steal() should fail is if the queue is empty.
Your code blocks don't have the overflow property set correct making it really hard to read on IOS: http://i.imgur.com/8HhmBH3.png 
You will get truncation issues if you do it with integers, potential rounding issues with floating point. You could design your own "CheckedInt" type that detects (and possibly corrects) these kinds of errors or use a library that offers arbitrary precision. Anyway still quite a pointless discussion because the post was about refactoring and not about designing a system to perfectly represent currency :)
Your right, the code looks terrible. Honestly, I had a hard time inserting the code with Drupal. I used the &lt;pre&gt; and &lt;code&gt; tags and still had to escape all of the &lt; and &gt; signs. Do you know how I can set the overflow property correctly?
True, but I am enjoying the discussion. If I ever want to implement a full money class, I feel I have a good head start!
still no concepts... every day we stay further from ~~God~~Stroustrup's light.
Thanks for the info, I wasn't aware of the procedures :)
&gt; it would have been really nice to get one of: modules, concepts, ranges or coroutines into C++17 Ranges requires Concepts, and Ranges wasn't ready yet; and IMO it would have been a mistake to introduce Concepts as a language feature without the corresponding basic concept definitions in the standard library, which are part of the Ranges TS. That would have led to three years of people defining their own, subtly incompatible definitions of the basic concepts, which in turn would have led to maintenance headaches for years to come (in much the same way as many old codebases still use their own string types, because they predate `std::string` -- I'm looking at you, Qt). It's a tremendous shame that Modules didn't make it, because I think the benefit to C++ will be even greater than that for Concepts. But reading though the latest papers, it seems there are still a few things to be hammered out (not least the macros issue), so I can see why it's not there. I don't know much about Coroutines, but I gather there has been much discussion about the basic architecture, stackless vs not, suspend up vs suspend down etc. To an outside observer it seems to be the most controversial of the TSes, so it's perhaps not a surprise that it didn't get into the main standard yet.
Sean Parents talks are all great. I think I've seen about 3 varieties of this one, and while most of it is the same, re-watching it every so often I always learn something new - either I missed some points before, or he really did make additions to the talk.
Everyone of your points is addressed by D. Not interested?
&gt; I don't know. I feel like telling a C programmer "why C++ is better than C". I hope I at least got you interested enough in the language by mentioning things "beyond memory safety" so that you will try it. Rust does have a learning curve. Learning Rust in a week (and by that i mean ~40h) is not possible. In a week you can learn the language, and you will be able to use it to write C++ like code in Rust. But it takes 2-3 weeks (~120h) to "forget" C++ and learn to write Rust in Rust. Its an investment, a way to justify it is that integrating Rust with an existing C++ code base is really easy via C FFI. Thank you for your detailed posts. And thanks to everyone who is contributing to this thread. Yes, I am learning Rust, and I thank you and everyone else here for bringing to light so many insights on the state of things, it really helps.
You can find the slides [here](https://github.com/boostcon/cppnow_presentations_2012/blob/master/fri/value_semantics/value_semantics.pdf?raw=true).
Read [Known limitations](https://github.com/philsquared/Catch/blob/master/docs/limitations.md) before start using it.
This talk is a gem.
A bit can only ever be 0 or 1, so *bit value* sounds correct. Maybe call it *single bit value* to be extra precise. The position of a bit is only meaningful when talking about bytes, so just like digits and their composition into numbers using bases other than 2 I'd call this the *positional bit value*.
Thank you! I will try this out and see if it works in my CSS
Another alternative might be to refer to the "state" of a bit vs its numerical value. It makes intuitive sense when a binary word is used to represent a group of binary flags, a common use case for that kind of bit-fiddling.
I didn't know that, thanks!
The language is advertized as "safe and fast". That's its defining feature. So if you have to choose between the two it feels wrong. 
The top operation is a single bit bitmask. I.e. you're masking out all the other bits, but leaving that one in place. You'd perform that operation if you wanted to copy a bitfield from one structure to another. The bottom operation is a bit(field) extraction. You're extracting the bitfield out so you can operate on just that value.
Neat idea! I like the usage of trap in debug mode. Couple of things: 1) your definition of `cxx_unreachable` and `cxx_trap` isn't quite right. You probably want to add `()` afterwards so they can be used like a function call. Also, you want to move the `void` cast to the `0`, otherwise the ternary operator will complain. `#define assume_true(x) ((x) ? (void)0 : cxx_unreachable())` 2) Clang defines `__GNUC__`, so you should always check for `defined(__clang__)` first. It doesn't matter here, but I think it's good practice. Plus, someone latter might want to handle clang differently than GCC and split it: #if defined(__GNUC__) || defined(__clang__) #endif #if defined(__GNUC__) #elif defined(__clang__) #endif
Swift uses reference counting rather than a complete runtime garbage collector, so you can't put it in the same category as Go, D, and Java. Imagine Rust, but all types are wrapped in reference counters. Slightly more overhead, but nothing on the order of a runtime GC.
[removed]
The &lt;&lt; and &gt;&gt; operators are bit shifters. &amp; is a bitwise operator for logical AND. | is the complementary operator for bitwise logical OR. I would refer to the bit value in a particular variable as "bit value," but if you need to be very precise, you might indicate the bit's significance or the position in the memory segment. In the first example, you are generating a bit mask by shifting binary 1 left a number of times. Then you bitwise AND with the value. The digit you are testing never moves place. In the second example, you shift the value right and then bitwise AND with binary 1. First example, for *n* bits, the bit you want is in the *n*th significant digit. If you shifted it right *n* digits, you'd have a binary 0/1 in the least significant digit column. Same result as the second example, but it took more work. Well, if all you care about is whether that one bit is a zero or a one, then you can mask the initial value by the bit (1 &lt;&lt; n), and if the result is zero, then the bit was zero. If the result is anything other than zero (result != 0), then that bit was 1. Voilà! Now you can do it both ways. (And you probably see how this could be used to manipulate and compare multiple bits simultaneously.) 
I must be stupid, but how do I sign up for cpplang.slack?
&gt; Ranges, which they call iterators for whatever reason Because *iterator* is the standard name for these things that has been used since time immemorial.
Try this: https://www.codelite.org/
What was wrong with the standard library's naming convention? &gt;`throw std::runtime_error("There was an error opening this file!");` Which file, might be useful information to have... &gt;`Config(){}` You mean `= default`?
[Invite page](http://cpplang.diegostamigni.com/).
Being a compile time expression as determined by context is a deliberate decision in D, and it turns out to be quite advantageous. The static initialization thing was a much earlier decision. The intent is to make clear what is runtime initialized, and what the order of initialization is. 
Ah ok thanks! I'll definitely make that change. 
[juCi++](https://github.com/cppit/jucipp) has nearly everything you've asked for. The primary potential exception would be interface customization--it does support some, but you haven't said what you want to customize, so it's hard to guess whether it does the things you want or not.
Audio podcast please!
lack of minimap is a pain but i'd still recommend it over clion
You could just inherit `std::ifstream`. Since ifstream doesn't enable exceptions by default, your constructor would call default ifstream constructor, enable exceptions on it and then call open (don't pass filename directrly to constructor because this would not throw). Calling `ifstream::close` in destructor is then no go, since it could throw. Just use default dtor, that will chain to ifstream dtor, which closes the file without throwing. If you want to detect failed close, just call it manually before it goes out of scope. You are not handling failed reads. By enabling the exceptions on the stream, you don't have to care about them. After enabling exceptions, don't use `ifstream::read`, but use `ifstream::readsome`. The former throws an exceptions if it can't read as many as you ask it. In your parser, in `State::EMPTY` case, it would be more appropriate to throw `std::logic_error`. If you get there. it is not a runtime error, but error in your code. And even better, don't throw anything there, since it could be caught, which is not desired for programming bugs - just use `assert(false)` there, to abort your program. You use `m_` prefix for static variables. You can, of course, but people usually use them only for member variables, and use `s_` prefix for static variables. When reading the code, they could think it is a member variable. And because it is actually a constant, I wouldn't give it prefix at all.
lol he is trolling. 
CLion w/ student license
Alright will take all of this into mind. I don't think I'm going to keep with the `File` class, but if I were, should I be using private or public inheritance?
yes
VS Code is many things. Lightweight is not one of them.
Toilet-paper coders should stop making thousand-line files. It just doesn't make any sense.
Eclipse has an awesome cpp indexer/navigation and keybindings. 
What do you think about Kotlin? Fully Java-compatible but more powerful and succinct.
Emacs &amp; vim. Qt &amp; CLion Or use Visual Studio. 
Any idea how many more "rounds" we need to go through for the N/W TS to see the Standard-light at the end of the tunnel? ;D
What's pluggings do you recommend for vim?
CLion, it is great
KDevelop by far, specially for cmake.
`randomWorker` creates an engine every time, which is heavy. Moreover, it uses `random_device`, which is even more heavy, involves syscalls (opening `/dev/random`, for example) and may be locking.
For C++ development, specifically? YouCompleteMe, Color_Coded, and YCM-Generator are great if you use make, autotools, cmake, or qmake. If you don't use one of those, then you'll have to setup the YouCompleteMe and Color_Coded config files yourself, which can be quite daunting. In General? Fugitive and CtrlP.vim are really nice. I try to fly light. Over-customization just means things break more often :-P
I'd consider the notes on line endings to be extremely poor/misguided advice - if you're program is Windows-centric or *nix-centric then it's tempting to think you might get away with not caring but just plain foolish if the code is cross platform. Considering your code is completely platform agnostic and it's EXTREMELY easy to handle files with both line endings I wouldn't dump it. Besides, how is some user supposed to know what line endings are? All they know is their (Mac using) coworker sent them a file from Excel and it won't open. This is the reason every text editor supports reading/writing different line endings - well except notepad, but even wordpad will do it.
I consider your first paragraph on line endings to be extremely poor advice, especially for a project like this. See my response below for more detail.
I agree, but figured I just wouldn't do it rather than outright tell them I think that's wrong 😅.
RLS was the alpha that I was alluding to (should have mentioned it by name for anyone else who might find it useful). Yeah, maybe I'll try it out this weekend. I use vim so it might take a maze of twisty plugins to get it working...hopefully not though.
It's really just a straightforward application of the [FromIterator](https://doc.rust-lang.org/std/iter/trait.FromIterator.html) trait. The "magic" arises from some slightly non-obvious but ultimately very simple implementations of that trait.
&gt; C++ was enterprisy, it's not anymore. Maybe in 90s. Last 17 years, enterprise is dominated by Java. And for a good reason too - you can far more easily support and develop "enterprisy" Java, even if the language and VM works in "mysterious ways" sometimes, than you can in other languages. There is also huge plead of technologies (DB, Web, Auth, Caches, tooling, instrumentation) all of which have been already developed and had a big user experience to absorb. &gt; developers adoption in general for mobile and desktop development The keyword is here is _general_. If we are talking worldwide _general_ adoption of _different_ software or applications on all devices and for all people - JS and HTML wins hands down. This is why I prefer to have a focus on some specific area, even during debates on reddit (lol), because most of the time overgeneralized view gives you disappointing\strange results. This is also allows you to focus on pros and cons of a language to the specific domain. Just look at the web - most of the "technical" resources call Java a "COBOL of 21th century". But despite that it's still one of the most(if not most used) with constant flow of new project's. EDIT: Refactoring my English =D
I don't remember, I think it was in the GUI area.
This is one of the few points where I changed the code to simplify the post. In my real code, both the distribution and the generator are members of Engine and initialized once. As you note, initializing prngs can be expensive
Completely true, if you look at the original molecular posts it suggest to have some form of control (using a condition variable to lock workers til there is more work to do for example). I left this for an optimization step later
Should've learned Boost.Spirit.
1. write psuedo code. 2. convert it to compilable code. 
When you shift before masking that will tell you whether a bit is set or not. When you mask with a shifted bit, that will give you either 0 or a value with just one bit set in the position you shifted to. It's easy to get the two mixed up. Some low level code will name each bit for convenience, but do they name them 0-7? 1-8? Or do they number them as 0x01, 0x02, 0x04, 0x08? I find the bit number to be best. You can always shift a 1 to get to the mask, but you can't undo that as easily. It's best to be as explicit as you can.
Go with a public one. Otherwise you would have to declare all the methods you want to use from a base class and delegate them. Instead of using private inheritance, it is sometimes better to use composition (like your File class), the only exception would be for empty base class, for empty base class optimization (if you used composition, it would take space in your class, even if it has no member (it must have an address; at least one extra byte, but it can take more if padding is required before your first member variable), whereas if you use private inheritance, it won't take any space.
I use TagBar, which uses ctags to provide an overview tree of the current file. The current function is highlighted in the tree, and jumping to a function is as easy as selecting a node. Enough for me Oh, it also supports Python and js iirc
I think this very much depends on whether you're writing a compiler or an interpreter. Programming an interpreter is easier, but it needs to be very efficient, since it'll determine the performance of anything written in the language. On the other hand, writing a compiler is harder, but you most probably don't care about the performance of the compiler itself, only the generated code. In the interpreter case, I'd go with C or C++ (I'd personally go for C++), but if I were writing a compiler I'd go with Haskell.
I was talking about QtCreator though
I will be messaging you on [**2017-03-31 09:24:05 UTC**](http://www.wolframalpha.com/input/?i=2017-03-31 09:24:05 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/cpp/comments/61ka0l/main_function_first_or_void_function_first/dff74dl) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/cpp/comments/61ka0l/main_function_first_or_void_function_first/dff74dl]%0A%0ARemindMe! 5 days) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! dff9ela) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Sorry, I thought it was a followup of that "I use vim" comment. My point is that if you pick him there's a minimap-like plugin
One of the keys they point out in their design is that the owner of the queue pops in LIFO and others steal in FIFO (they use different ends of the queue, so the atomics they modify are different).
Just noticed that the use of compare_exchange_weak in this example _may_ not be valid. Compare_exchange_weak may give a false negative, in the sense that the operation should return success, but due to a spurious failure may return otherwise. The strong version makes sure this effect does not happen, but it comes at a cost. Therefore, weak versions of CAS are recommended if their success is used as retry condition in a loop. Anyway, if you don't think/care that these failures may affect the outcome of your queue, your are goot to go. &gt; When a weak compare-and-exchange would require a loop and a strong one would not, the strong one is preferable unless the object representation of T may include padding bits, trap bits, or offers multiple object representations for the same value (e.g. floating-point NaN). In those cases, weak compare-and-exchange typically works because it quickly converges on some stable object representation. http://stackoverflow.com/questions/25199838/understanding-stdatomiccompare-exchange-weak-in-c11 
Why Haskell? Just curious
Pragmatism vs dogmatism
The release of 5.1 was only a few days ago. If you are already on LTS, wouldn't it be more sensible to stick with the last stable release until packages for 16.04 are available? Although that may not happen, as 5.1 may need newer versions of some kdeframeworks, that won't be backported. https://launchpad.net/~kdevelop/+archive/ubuntu/release has 5.0.3 for 16.04. Otherwise would you mind explaining, why the appimage doesn't work for you? I think LTS distros are one of the intended use cases of appimages.
I'm flattered! I would consider waiting a bit though because I'd like to implement the suggestions here, and I'd hate to break your code with the changes I'm going to make.
Does it have a C++ indexer? It's call hierarchy for member or member function, rename member/variable, mark all occurrences of a member/variable, different syntax coloring for member/static-member/free-var. Other little things? - move/duplicate limes up/down, comment-out block of lines, hotkey to go back to the last edit.
&gt; (example from Nicol Bolas) FWIW, I don't think this is his (her?) real name. The Google Groups email address behind this handle suggests something much less exotic.
I can't read the text on that image, but is it similar to Emacs using Speedbar?
It does
For the record, I wasn't trolling. I'll admit the comment about the line endings was poor advice. On the other hand, I don't think the comment about iterators was nearly as bad as you said. Yes, it might be overkill considering how much memory modern systems have, but the double iterator pattern would let you do something like this: csv_parser parser("file_name.csv"); for (auto&amp;&amp; record : parser) { for (auto&amp;&amp; field : record) { // use field } }
At work I deal with TSV files sized in the 10s-to-100s of GBs range on a daily basis; any code that tries to load TSV or CSV files eagerly, in their entirety, is broken in my book.
One is a power of two, the other is a boolean. Maybe something along those lines might be useful. 
Machine learning, training datasets. Different parsers across different languages; too many bad ad-hoc ones for sure. ;-/
Heh, that's fair enough. You can't really bring in just one part of Boost :P
They recently switched parsers and now are based on CommonMark which might lead to incompatibility.
You could replace some of those static casts with more readable C++ casts. For example: char(t) instead of static_cast&lt;char&gt;(t) Also unless I missed it, might be worth putting the specification you are working from in the readme...
They may be as fast on modern CPUs, but they certainly aren't as fast on modern GPUs!
I agree. As far as I can see in OPs example I would have to write one declaration more (property int Age) instead of just using getters/setters? Why would I want that? 
&gt; Then you gradually add more and more, and around release time your application can be fully statically type-checked. if only! in my case I'm pretty sure there will still be model changes in ten years (the software is heavily research-driven).
I don't quite see the resemblance of those cases with casting an integer type. The functional style cast will actually be converted to a static_cast at compile time... But it's your code obviously :) I just picked up the habit of functional style castings based on warnings from ReSharper.
Did you read more than the title? It was comparing static_cast vs a c-style cast regardless of type, the type of `int` is irrelevant. I like this summary of it: &gt; 1. `static_cast&lt;&gt;()` gives you a compile time checking ability, C-Style &gt; cast doesn't. &gt; 2. `static_cast&lt;&gt;()` can be spotted easily &gt; anywhere inside a C++ source code, C-Style cast is harder to spot. &gt; 3. Intentions are conveyed much better using C++ casts.
But I can do all that with standard getters/setters?! Do you have an example for e.g. logging that's more convenient or "better" with properties? 
Perhaps a better example would more strongly support the use case of properties? This being said, how would the proposed syntax exist as forward-declared declaration and implemented in a separate C++ source file?
Structured bindings + std::array never crossed my mind. I like it!
IIRC C++Builder (ex-Borland relative of Delphi) also had properties as an extension, as they were necessary for Borlands library. 
Yep. But most compilers support `__declspec(property)` anyway. It's a bit clumsy though.
You can change internals whilst keeping external API consistent/compatible. It's done in Python all the time.
3 important reasons: * It's arguable whether functional programming is ideal for all problem domains, but one thing is certain that domains that are heavy in pure data transformations are where FP shines. It's the undebated stronghold of FP. * Haskell has a very powerful type system that lets you express extremely complicated and abstract concepts and control flows without having to rely on conventions and runtime checks. Such a type system comes in very handy when you have programs that generate other programs. * Haskell's core community is programming language theorists (even though it's diffusing into the industry and so many people with varying backgrounds are pouring in), so you can expect to find amazing libraries and ideas for the task of writing a compiler. Just the prospect of being able to ask Haskellers questions in the langauge they use would be a big gain.
Not by this very talk, but by a previous talk by Sean (I think it was at Going Native), and also a talk by Zach Laine at CppCon 2015. Basically I learned the technique and then figured we might be able to do something nice with metaprogramming, and that was Dyno.
because it is ambiguous whether Age is side-effect inducing or not (depending on Age being a property or a public-visible member). `p.Age = 20` -- it is not obvious what Age is, yes? `p.setAge(20)` -- programmer intent is obvious On syntactic sugar: `int Person::Age::get() { ... }` vs `int Person::setAge() { ... }` I just saved two characters and don't need a new paradigm introduced with the language. Also, property int Age { void set(int value) { if (value == age) return; age = value; property_changed(this, "Age"); } int get() { return age; } } I really don't see how this is any better for developers than: void setAge(int value) { if (value == age) return; age = value; property_changed(this, "Age"); } int getAge() { return age; } 
I think properties also get unnecessary verbose and redundant. You have to add a (differently named) private member and always the same code. If we had operator. or something like it, we could build wrapper classes like read_only&lt;int&gt; or notify_change&lt;int&gt;, which is imho the most readable way.
Not if something starts off as a public internal variable; so everyone is using `p.r = 10;`. You want to change to using a different internal representation of the data, no longer using `r` ... sure, you can create getters/setters, but it breaks the old API, and everyone using `r` directly will be fucked. Enter properties. You can change internals representations, which keeping external API backwards compatible... even if it's only for transitional/incremental changes. Question comes into whether it was right to have `r` public, it may have been, it might not have been. Regardless, a user shouldn't have to know anything about the internals of the object they are using, to use it; just the API. Properties help with that. 
qtcreator. I think it's the best you can get. Clion is not even free, and definitely not as smooth as qtcreator.
&gt; this is a proven concept Being a proven concept doesn't necessarily mean that it's a good concept.
Hm. But now I'd always have to check whether p.r is a property and using it might have side effects I don't know about? I'm not sold.
Maybe I'm weird, but I view only one compiler/build system to be a bad thing. &gt; Developers have to use obsolete standards (e.g. C++03 and even C++98) Any real-life examples of this? PGI, Intel, GCC, Clang are all C++11 compliant. PGI and Intel also support most C++14 language features. &gt; Sometimes the compiler developers don’t care about what language ISO Standard says and do whatever they want (example: GCC’s std::list::size() is O(N)). Did you read the issue? C++11 changed the complexity requirement. C++0x/C++11 iterop was never guaranteed. GCC wasn't 100% fully C++11 compliant until 4.8.5 (all regex library issues were resolved). &gt; Google C++ Style Guide recommends not using unsigned types &gt; C++ Core Guidelines recommend using unsigned types on several occasions. &gt; Having a single style guide, which is accepted by the whole community is a huge win. Companies have their own policies. If you work for a company and they want something done in a certain way, you do it. C++ Core Guidelines is much newer and vetted by those who help write the standard. Bottom line: C++ Core Guidelines &gt; Google C++ Style Guidelines *unless* you work for Google. &gt; Safety I agree &gt; Compiler messages If concepts were used to implement the C++ standard library throughout, error messages would arguably be just as clean. You're forgetting that C++ needs to maintain backwards compatibility. Rust makes no such guarantees. I like being able to compile code I wrote 10 years ago without failure. &gt; Toolchain Sorry, I like the versatility of using CMake, pkgconfig, and other utilities. Try using a C-library with Rust without the need of using additional build toolchains like pkgconfig.
Why should it be obvious whether something induces a side effect or not? I mean, when you make a getter, it may induce a side effect, so what?
It doesn't. You cannot substitute a function for a property.
Actually, you have things precisely backwards: properties are ugly, avoidable hackery. C++ already provides a much better way to do things. Properties fall into two broad categories: those that are just pointless, and those that are actively wrong and damaging. What you've shown in your question is one of the merely pointless varieties. You've made a variable private, then made it effectively public again by providing unrestricted access to reading and writing it. So, what you've produced is a public variable, but with lots of noise, and opportunities for the compiler to make access to it slower. So that leaves the properties that are actively damaging and evil. These are the cases where your getter and/or setting do more than just provide direct access to the variable. A typical case would be something like: void set(int value) { if (value &gt; 200) throw range_error(); age = value; } When most people initially look at this, they see it as exactly the sort of thing that really justifies using a property to start with--we've kept the variable private, and the setter ensures that we can't enter ridiculous data, such as claiming that a person is ten thousand years old. So why do I say this is actually worse, and an example of a properties being actively bad? The basic problem here is that we're starting by defining an "age" and saying it's of type `int`. In reality, however, `int` defines some properties, including a minimum range of -32767 to +32767. That's clearly not what we want at all--what we really want is an integer type with a range of 0 to 200. That being the case, what we should do is define that type, then simply define an instance of that type for our age. In this case, we probably don't have to think very long to know that we're likely to want integers with various different ranges allowed (e.g., ages of different types of things). So, we might as well define a template that lets us define individual ranges quickly and easily. template &lt;class T, T lower, T upper&gt; class bounded { T val; void assure_range(T v) { if ( v &lt; lower || upper &lt;= v) throw std::range_error("Value out of range"); } public: bounded &amp;operator=(T v) { assure_range(v); val = v; return *this; } bounded(T const &amp;v=T()) { assure_range(v); val = v; } operator T() { return val; } }; With this, we can define our age as: ranged&lt;int, 0, 200&gt; age; ...and life is good. We've defined a type, then the type enforces the constraints defined for that type, rather than defining one type, then enforcing some different set of constraints entirely separately. Now, given the *history* of C# or Kotlin, their choosing to use properties instead of a good design is probably somewhat understandable. Both of these basically started from Java. Java was designed so badly that 1) we couldn't really define a `bounded` that worked worth a darn, and 2) the overhead of defining a type is high enough (e.g., every class requires a new file, and frequently an entire tree of almost-empty directories) that it's understandable that people using it decided to give up on designing software, and instead just hack things together using properties instead. So, for the C# and Kotlin, the basic situation was starting from something that was completely broken in ways that created *constant* irritation. If they actually fixed the design, they were going to end up pretty much re-inventing C++. Their target was Java programmers, who've been learning a warped and broken idea of "object oriented programming" for a long time now (many have never really used anything else to any noticeable degree). With Java as a starting point, teaching people to actually program *well* was essentially a lost cause. So what they settled for was making daily use of its broken design marginally less irritating. That doesn't apply to C++ though. It didn't start from Java, so Java's broken design never applied to C++ to start with. We can do the job correctly, and when we do, we can see properties for what they really are: an irrelevant, ugly hack.
Why? If you are a user it should make no difference if it's a property or not. If you're using the suggested syntax it would be just the same as a variable. It might do some logic on it, to change it into the new internal representation, it might print a warning to stderr or the logging system ... "this will be deprecated next version, please update to using the provided setters/getters" Documentation. If it's in the API documentation, it would be clearer what the pseudo method is actually doing. 
Yes, but with `operator .`, writing something like `foo.X = bar` would trigger a *getter* on `X` which would return a non-rvalue that you couldn't write `bar` into. With `operator .`, IIRC, `foo.X` would be equivalent to writing `foo.GetX() = bar`. Now, I know, you can go ahead and return a reference from `GetX()`, but this is contrary to the way properties work. In the case of properties `foo.X = bar` should trigger precisely `foo.SetX(bar)`.
Very good point. I guess if it looks like direct access of an internal variable ... you'd expect only that occurring. Once something like that becomes accepted and common place, you'd just be careful noting anything can have side effects ... which is true anyway.
I meant by using a setter originally. 
&gt; Any real-life examples of this? PGI, Intel, GCC, Clang are all C++11 compliant. PGI and Intel also support most C++14 language features. In LLVM &amp; Clang we have to use C++11, because MSVC does not support C++14 (and until very recently didn't support C++11 fully either). &gt; Did you read the issue? C++11 changed the complexity requirement. C++0x/C++11 iterop was never guaranteed. GCC wasn't 100% fully C++11 compliant until 4.8.5 (all regex library issues were resolved). I did. The issue link is probably not very representative. Didn't get your point, though. As for C++14 ISO Standard: &gt; C.2.13 Clause 23: containers library &gt; Change: Complexity of size() member functions now constant Then I go to the `std::list` libstdc++ implementation: https://gcc.gnu.org/onlinedocs/gcc-4.6.3/libstdc++/api/a01055_source.html At L00845 we have: ```c++ /** Returns the number of elements in the %list. */ size_type size() const { return std::distance(begin(), end()); } ``` [`std::distance` docs](https://gcc.gnu.org/onlinedocs/gcc-4.6.3/libstdc++/api/a01137.html#a5852ded2c7147a161b33951ef37ecba8): &gt; Returns n such that first + n == last. This requires that last must be reachable from first. Note that n may be negative. &gt; For random access iterators, this uses their + and - operations and are constant time. For other iterator classes they are linear time. Thus, I conclude that `std::list::size()` complexity is still O(n) while The Standard wants it to be O(1). Have I missed something? &gt; Companies have their own policies. If you work for a company and they want something done in a certain way, you do it. C++ Core Guidelines is much newer and vetted by those who help write the standard. Bottom line: C++ Core Guidelines &gt; Google C++ Style Guidelines unless you work for Google. Fair enough. However, that still creates a mess. A huge one. I'm more into the idea of "let's all try to build a more or less good code style". It doesn't cover literally everything. One can modify rusftmt config and live happily ever after. P.S. I worked at Google and we used `unsigned`, too. &gt; If concepts were used to implement the C++ standard library throughout, error messages would arguably be just as clean. You're forgetting that C++ needs to maintain backwards compatibility. Rust makes no such guarantees. I like being able to compile code I wrote 10 years ago without failure. If, but they weren't. However, that's not the only issue. There is a number of similar C failures, but you are right: most (but not all of them) are related to this. Yes, C compliance and backwards compatibility is a good thing sometimes. But it's a terrible thing many times: it makes some new features very very hard to introduce. It also makes the language specification 1000+ pages long, with all the unnecessary stuff there. Stuff that no one uses or that no one should use. &gt;Try using a C-library with Rust without the need of using additional build toolchains like pkgconfig. That's because C libraries still use those. I'm very unhappy about that anyway. &gt; Sorry, I like the versatility of using CMake, pkgconfig, and other utilities. That's just me, but Makefiles and autotools are plain ugly. Again, I don't want to start a holywar, but embedding projects into one another becomes so much harder with this versatility. As a developer, I don't like having to mess up with the system and different build utilities just to make sure that every dependency is alright.
Rust seems like an interesting language that has a lot of good ideas. I find it a bit frustrating when people seem to think the way to proselytize for Rust is by bashing C++ (especially in a C++ forum!) &gt; Rust is a modern programming language, which recently received much attention and became quite popular. There are a few comments like this in the article: unsupported fluff. It's popular? By what measure? I did a quick google search for "programming language popularity" and the [top result](https://www.tiobe.com/tiobe-index/) and [second result](http://pypl.github.io/PYPL.html) don't indicate that Rust is popular: Language | TIOBE Rank | TIOBE Percentage | PYPL Rank | PYPL Percentage ---|---|---|---|--- C | 2 | 7.742% | 7 | 6.9% C++ | 3 | 5.184% | 6 | 6.9% Rust | 43 | 0.382% | 22 | 0.3% That doesn't seem "popular" to me. The reason I point this out isn't to say that Rust is unpopular and therefore crap. It's to say that this article is, no matter what the intro claims, trying to cheer lead for Rust. &gt; One of the problems C and C++ have to face is that there are too many compilers and most of them are horrible. I think this is a little ironic, considering that the paragraph before this, the author was talking about how great LLVM is. LLVM started out as a C++ compiler! The other two main compilers for C++, GCC and MSVC, may have their issues (I'm not super worried if `std::list&lt;T&gt;::size` is O(N) in GCC, the standard before C++11 allowed that), but they are very far from "horrible". Yes, GCC has its issues, which is why LLVM was started in the first place. Still, GCC has made improvements due to the pressure from clang (as well as a separate group of people thinking about the same problems). LLVM is still young though, and GCC still has a leg up in the architectures that it supports. &gt; Three cheers to rustc’s human-readable error and warning messages! Unlike C and C++ compilers, rustc provides a good explanation of what’s wrong with a the particular piece of code, kindly highlighting the affected char range and giving some hints: That's great, but again: why focus so much on bashing C and C++? I can understand how a beginner would appreciate more human-readable error messages, but I can certainly figure out what the issue is from a C++ error. &gt; Unlike C and C++, which have several documentation tools and a number of documentation rulesets, Rust only has one, which is an advantage. Why is that an advantage? It just is? &gt; For example, many C++ Standard Library functions accepting parameters of some special type aren’t able to check whether passed parameters are having the correct metatype efficiently, e.g. special iterator metatype (ContiguousIterator, RandomAccessIterator, etc). std::sort functions look like this: template&lt; class ExecutionPolicy, class RandomIt &gt; void sort( ExecutionPolicy&amp;&amp; policy, RandomIt first, RandomIt last ); template&lt; class RandomIt, class Compare &gt; void sort( RandomIt first, RandomIt last, Compare comp ); template&lt; class ExecutionPolicy, class RandomIt, class Compare &gt; void sort( ExecutionPolicy&amp;&amp; policy, RandomIt first, RandomIt last, Compare comp ); &gt; With Rust it would’ve been much cleaner. I'm disappointed there wasn't an example of what this would look like in Rust. (Also, why was the overload `void sort( RandomIt first, RandomIt last );` ommited?) Concepts would make it easier to enforce the iterator requirements, but the standard library certainly checks that. There is certainly a `static_assert` along the lines of: static_assert(std::is_same&lt;typename std::iterator_traits&lt;RandomIt&gt;::iterator_category, std::random_access_iterator_tag&gt;::value, "Iterator must be a random access iterator"); Alternatively, it could be of the form: template&lt; class RandomIt, std::enable_if_t&lt;std::is_same&lt;typename std::iterator_traits&lt;RandomIt&gt;::iterator_category, std::random_access_iterator_tag&gt;::value&gt;* = nullptr&gt; void sort(RandomIt first, RandomIt last); No, not pretty, but its certainly possible in C++, even without Concepts. &gt; Existing Issues I'm glad there was a discussion about existing issues. I wish there was less of an attempt to white wash those issues though ("However, LLVM starts to support more platforms, so this is not a major issue" -&gt; if you need to target one of those platforms, it's certainly a major issue to using Rust) The lack of template packs is pretty disappointing. It's a very powerful feature of C++. I wasn't aware that Rust doesn't allow operator overloading. I've always found the Java style `a.multiply(b.add(c))` much uglier than `a * (b + c)`
[VSCode](https://code.visualstudio.com/) plus the [vscode-cpptools plugin](https://marketplace.visualstudio.com/items?itemName=ms-vscode.cpptools) along things like [cmake-tools](https://marketplace.visualstudio.com/items?itemName=vector-of-bool.cmake-tools) or whatever build system you prefer.
Vim with YouCompleteMe fits the bill. And yes, it does work well in Windows :)
It is as much a guarantee as anyone else makes. We do not intentionally make breaking changes &amp; we aggressively search for regressions before release. C++ makes breaking changes between standards.
&gt; Thus, I conclude that std::list::size() complexity is still O(n) while The Standard wants it to be O(1). Have I missed something? Yes, you missed the version of GCC. The code you link to is from version 4.6.3, a fairly old version (from March 1, 2012, more than 5 years ago). The newer versions fix that issue: see [here](https://gcc.gnu.org/onlinedocs/gcc-6.3.0/libstdc++/api/a01627_source.html#l00955)
&gt; We do not intentionally make breaking changes &amp; we aggressively search for regressions before release. Then change your language in the docs to guarantee it. Or start permitting `-std=rust1.16` or something of the like to guarantee that the compiler acts in an expected manner.
It's a browser that runs an IDE in JavaScript. It's basically a way of relegating the hard cross-platform UI bits to a big runtime that the browser is. 
&gt; GCC wasn't 100% fully C++11 compliant until 4.8.5 If we are talking about library issues, I was sure they changed the major version when they finally fixed std::string. Of course that still didn't mean 100% compliance, just try to catch an excpetion thrown by the iostream classes by its c++11 type. 
Qt Creator is awesome even if you don't use Qt in your project. It's really simple, but powerful. Autocompletion and source navigation mostly work well. (occasionally it won't follow a symbol for me). It took me minutes to import a medium sized project and start working on it.
Ah, I see. So if I understand correctly, it's illegal to do something like: float abs(float); double abs(double); long double abs(long double); That seems like almost a bigger deal than operator overloading. Operator overloading helps write cleaner code, but dispatching to different functions by type is a powerful tool.
Ah, I see the point. Thank you very much, I was wrong.
Lots of digital processing will add together thousands of terms to yield the final sample. Adding together just 1024 16-bit integers gives you a result with, worst case, a 6-bit error-free range. There are ways to mitigate this, but that's the basic premise. I used to play with digital synthesis a while ago and some output samples were sums of on the order of a million terms. 32 bits is nowhere near enough to represent such results without losing lots of accuracy in the source material. 
TIL that standard C++ contains the Riemann zeta function :o
`rustup install 1.16.0` Edit: I actually can't stand the `-std=` argument to GCC. I use it for work because I can only use `gnu99` to target my project, and the default, C89, won't fly. C99 won't either, though I'd like to go in and fix that if I can, and we're never going to see C11 while I still have hair and hope. I'd much rather treat this like we do cross compilers: install a dedicated copy with its own name as the front end, and pass to a back end such as GCC or LLVM. That way it's immediately obvious and you can't fail a build by moving to a server that is using a different std flag and somehow overrides the one in your project files.
So your solution is to install an older compiler without newer bug fixes?
Operator overloading can be achieved by implementing traits in `std::ops`. Function overloads are not a thing, though. I target SPARCv8 at work. LLVM targets SPARCv8. The LLVM vendored into Rust does not (or at least didn't, I might have accidentally gotten that changed but Rustup doesn't list it). LLVM also recently targeted AVR, and Rust has yet to do so. I like Rust plenty but until LLVM grows into a more universal compiler and Rust collects that growth, it is lagging behind C/C++.
No, that's also possible with traits.
Given that Rust doesn't have a standard so the `-std=` flag is literally meaningless, yes. I'm hopeful that Rust will eventually be able to un-bundle LLVM and use the system installation, at which point I imagine this stops being an issue. Or, since Rust puts a *lot* of emphasis on not regressing in the parser, to the point where each release stage requires compiling the entire public ecosystem looking for flaws, update your compiler and halt at 2.0 if that becomes necessary.
What would the difference be if it were in the language instead of the std library? (I am a novice, sorry if it is obvious.)
Not quite. If the concept isn't very good and you aren't forced that concept, then most people will simply avoid using it and there will likely be no complaints.
You are correct in that you can't have functions with the same name in the same namespace, but you can basically achieve that through traits: trait Add4 { fn add4(self) -&gt; Self; } impl Add4 for i32 { fn add4(self) -&gt; i32 { self + 4 } } impl Add4 for f64 { fn add4(self) -&gt; f64 { self + 4.0 } } fn main() { let b = 3.add4(); let c = f64::add4(4.5); println!("{}", b); println!("{}", c); } In that example, I've called the trait implementation in two different ways: first as if it were a member function, and the second as if it were a static function of the `f64` type.
&gt; I'm hopeful that Rust will eventually be able to un-bundle LLVM and use the system installation, This is already true today, and we have tests to ensure it works.
I think this is off-topic. I'll leave it up (other mods may choose to remove it), but I'll caution: posts about how language X is better than C++ aren't posts about C++. If I continue to see a steady stream of Rust posts, my mercy will diminish.
Might be related to tab characters. You could use [Markdown tables](https://help.github.com/articles/organizing-information-with-tables/#creating-a-table) with regular code blocks, should work. (On the other hand, HTML should also work, so...)
&gt; Like what? This smells like a poorly designed build system the developer wanted to "hack" together rather than there being an explicit dependence on Perl/Python/etc. Unless the C++ library actually states #include python.h there is no real dependence on having python installed. I mean to run build scripts. Like... https://github.com/pol51/OpenSSL-CMake/blob/master/INSTALL.W64 You need to install perl to build OpenSSL
&gt;but you most probably don't care about the performance of the compiler itself, only the generated code. &gt;In the interpreter case, I'd go with C or C++ (I'd personally go for C++), but if I were writing a compiler I'd go with Haskell. Only if its a toy compiler though, for real world stuff haskell is going to be unacceptably slow. I mean compiling C++ is already crap in GCC/etc
OK, I agree with what you're saying here (except some bits beyond my ability to agree or disagree) except that you say these are the *only* reasons for properties. What is your response to [my claim](https://www.reddit.com/r/cpp/comments/61m9r1/what_do_you_think_about_properties_in_the_c/dffnn8m/) that we already have broken attempts to imitate properties in the C++ library, particularly for subscripting of `std::map`? For TL;DR reasons - I'm not arguing for properties, I think the idea is compelling, but that doesn't mean they can fit in C++ now. Also - we *could* in principle imitate properties more closely already by returning instances of special assignment-overloading classes similar to the range-enforced type you suggest, but (1) for `std::map::operator[]` that never happened, (2) for `std::vector&lt;bool&gt;` where something very similar already happens/ed (iterators into bit-vectors) it's notorious for causing problems, and (3) an obvious reason why it didn't happen for `map` is that isn't just bounds-checking, that's an object implementing a reference with specialized smarts to content (which may not even exist yet) within another object, so extra complexity, the usual range of annoying issues WRT lifespan/dangliness etc, plus back in ye olden times with ye 1980s and 1990s compilers, not a reliably zero-cost abstraction. Another thought - if `std::map::operator[]` *did* return a special "smart reference" class instance which could defer the insertion of a new key until the `operator=` on that reference is called... doesn't that means those deferred insertions could be interleaved? Leading to more complexity to cope with that possibility? Or at least more declarations of "thou shalt not invoke undefined behavior" where properties would make the bad things impossible to write? 
&gt; template &lt;typename T&gt; abs(T x) { return (x &gt; static_cast&lt;T&gt;(0) ? x : -x); } &gt; &gt; That seems silly to me. Is template specialization allowed? Can one achieve this behavior through a back door? A generic `abs` can be written with traits: use std::ops::Neg; use num::traits::Zero; fn abs&lt;T&gt;(x: T) -&gt; T where T: PartialOrd + Zero + Neg&lt;Output = T&gt; { if x &lt; T::zero() { x.neg() } else { x } } 
That is a contributor's fork of the website GitHub is inaccurately publishing; that info is also on the real site. Rustup would let you directly install it too.
I can see your point, sorry about that. Although it might be not clear from the context (as many people mentioned) my goal isn't to make C++ look bad or turn people to Rust side but to outline some things I like about Rust and things, which could and potentially will be better in C++. I'm sorry if that's something I shouldn't have done.
&gt; I find some error messages intimidating Just double click in the "Required from here" line in your IDE. 
&gt; if you need to target one of those platforms, it's certainly a major issue to using Rust) In particular, if you're developing for a platform that only supports C++98 or 09, there's essentially no chance that you have a Rust implementation available at all. Looking at it slightly differently: the exact same thing that lets Rust run on a platform (i.e., targeting that platform with LLVM) also allows Clang to target that platform. The correct conclusion is that C++ has a clear advantage in this respect. Every platform that Rust can target, C++ can target as well--but there are platforms that C++ targets that Rust doesn't (and probably never will).
You can do that with parametrized traits. Overloading with different numbers of arguments using different traits isn't recommended though.
&gt; A generic abs can be written with traits: Now what if I'm operating on a custom data type (let's say bigint) with a vastly different `abs` algorithm ? or if I want to do `abs(array[64])` with some SSE intrinsincs ?
[removed]
There is a clear thesis in your article, saying now that black is white will not make it white. You are even white washing the issues as someone else already stated in the comments. 
Clang started out doing a lot for GCC compatibility - extensions, ABI, even command-line options - though it's not quite 100%. Now that it's taking the Windows ABI more seriously, anyone know what the policy is for VC++ extensions? (generally, not really this particular one). 
I'm wrong when I'm wrong and I admit it in these moments. Rather than making comments like this you could try to be helpful instead by pointing the issues you mentioned out and helping to fix things, which you think are wrong.
&gt; But I can do all that with standard getters/setters? Don't you get tired of writing void setFoo(const std::string foo) { if(foo != m_foo) { m_foo = foo; on_fooChanged(foo); } } void setFoo(std::string&amp;&amp; foo) { if(foo != m_foo) { m_foo = std::move(foo); on_fooChanged(foo); } } const std::string&amp; getFoo() const { return m_foo; } everytime ? With properties (and more generally extendable attributes like in C#) you could just do a one-time thing such as : template&lt;typename Obj_T, typename Prop_T, std::string_view theName&gt; attribute_on_member property_attribute { property_attribute(Obj_T&amp; obj, Prop_T&amp; prop): m_obj{obj}, m_prop{prop} { } Obj_T&amp; m_obj; // optimized by the compiler since we will already have a reference to the object Prop_T&amp; m_value; // same static constexpr const std::string_view m_name = theName; // one can always dream Prop_T get() const { return value; } void set(const Prop_T&amp; val) { if(val != value) { value = val; notify(value); } } void set(Prop_T&amp;&amp; val) { if(val != value) { value = std::move(val); notify(value); } } void notify(const T&amp; t) { obj.dispatch(someNotificationEvent); } std::string_view name() const { return name; } }; class MyClass { [[property_attribute&lt;"bananas"&gt;]] std::string bananas; [[property_attribute&lt;"bonkers"&gt;]] int bonkers{}; }; int main() { MyClass m; m.bananas = "foo"; cerr &lt;&lt; $(m.bonkers). // subtile usage of reflection operator attribute&lt;property_attribute&gt;(). // who cares about template arguments anyway name(); // happy serialization }
&gt; Because foo.bar = baz should not induce a side effect. unless `decltype(foo.bar)` has an assignment operator. So you have to check your declaration anyway if you want to be sure.
As far as command line options, there is clang-cl, which uses flags closer to MSVC++ than GCC. They currently accept the calling convention keywords (like `__stdcall`) for ABI compatibility, but they do not accept most `__declspec` attributes. Clang does have the framework present to properly support them, unlike GCC, which just treats `__declspec(x)` as a macro for `__attribute__((x))`. 
&gt; Ok. How would you install OpenSSL using Windows + VS for your project? Actually, LibreSSL builds with cmake, so you can just do `cget install https://ftp.openbsd.org/pub/OpenBSD/LibreSSL/libressl-2.5.1.tar.gz`. &gt; A lot C++ packages require additional stuff like Perl, Python 2 and Python 3 for another As a lot of packages are moving away from autotools to cmake, so this becomes much less. &gt; BUT! It's huge mess, you need to fix a lot packages on your own. This is what a lot of distro mantainers already do for packages, and hopefully there changes gets upstream. However, there is a lot of packages that still need work, and any package manager will need to make adjustments to that. A lot of people don't think about making there build system package-manager friendly, they use custom variables/system to find dependencies instead of using package configuration or embed there own package management into the build system or library. 
I can't fix your bias for you, this is something you need to work out yourself if you don't even see it. The issues section in your article and /u/shmoopty comment are a good start. You can read more about how to recognize more issues here: http://www.write.com/objective-writing-tips-keeping-your-research-paper-free-of-bias/ https://www.edanzediting.com/blogs/maintaining-objective-tone-scientific-writing-avoiding-promotional-language https://en.wikipedia.org/wiki/Bias
Oh for goodness' sake. This is /r/cpp, not /r/rust. We've just had a [big discussion about Rust](https://www.reddit.com/r/cpp/comments/611811/have_you_used_rust_do_you_prefer_it_over_modern_c/) a few days ago, with 235 comments at the time of writing that is still on the front page. That will do for a while, thanks. Quite a while.
&gt; In rare cases, one might use unsafe Rust constructions, but in 99.9% cases these are not necessary and therefore the number of vulnerabilities a piece of software may have tends to zero. That's optimistic. Closing out certain classes of bugs is great, but don't imagine that solves everything.
It will still work *on current versions of Windows* -- but since it is relying on modifying undocumented internals of the thread information block, there's no guarantee this will hold in the future. Here's an example of where it can fail: https://svn.boost.org/trac/boost/ticket/10657 
I recommend QtCreator. It's a fully fledge IDE but without the bloat you can find in other IDEs (eclipse, kdevelop, visual studio, xcode)
 fn apply&lt;A, B, C, F, G&gt;(mut f: F, a: A) -&gt; impl FnMut(&amp;B) -&gt; C // must still be `for&lt;'r&gt; impl FnMut(&amp;'r B) -&gt; C`, because that’s what filter requires where F: FnMut(B) -&gt; G, // must not be `for&lt;'r&gt; FnMut(&amp;'r B) -&gt; G`, because regular functions do not implement it G: FnMut(A) -&gt; C, B: Copy, // for dereferencing A: Clone { move |b| f(*b)(a.clone()) // this must do any bridging necessary to satisfy the requirements }
You can test the (alpha) flatpak package as described here: https://community.kde.org/Guidelines_and_HOWTOs/Flatpak
What if we had an "operator .&lt;name&gt;" where &lt;name&gt; is something that looks like a regular member name. It seems like this would allow for property-like behavior through the use of proxies, but it would be more general. We'd also be able to take advantage of the existing mental models of operator overloading.
Intel definitely supports it.
&gt; You don't take an address of a property. Why would you want to do that, in the first place? Generic composition. I can take the address of a getter function or a setter function and pass those through to various functional-ish libraries. I can take the address of a lambda and forward it along. I need to be able to bind in some way to a property's getters and setters so I can bind them to a serialization or GUI system. These kinds of things are _essential_ to higher-order programming techniques. If I can't do that with a property, what gives? We'd have to keep using getters and setters whenever we needed to interface with any libraries that worked with higher-order primitives? &gt; I'm not sure what propertly overloading means or is implied here. Can I write a property that has different setters for int vs float? What about getters overloaded for `&amp;` vs `&amp;&amp;` vs `const&amp;` (e.g., because I want the getter to move out its value if the `this` object is expiring, or to be constant if the `this` object is constant, etc.). Can I make the property a template, or its individual getters/setters templates? Can I specialize or partially-specialize them? e.g., can I write `auto x = foo.myprop&lt;T&gt;` or `property int myprop { int&amp; get() &amp;; int get() const; int get() &amp;&amp;; };` or `property int myprop { template &lt;typename T&gt; set(T&amp;&amp; value) { _foo = std::forward&lt;T&gt;(value); } };` or so on? &gt; Reflection on properties should work fine (see C#) The C++ reflection proposals have nothing to do with C# and do not look or work in any way similar to that. We're discussing properties in C++ here, not properties in C#. :) &gt; This isn't trying to be a real proposal so far, rather soliciting feedback from C++ users. The topic's come up. A lot. I think it's fair to say that a decent subset of C++ users want them. Getting them right is the actually hard part that nobody seems to want to do. :)
GCC and Clang don't. 
I like this a lot. One thing I've done to help with perfect forwarding hell was **gasp** write a macro. It works with all types and saves many, many characters. `#define FWD(x) (std::forward&lt;decltype(x)&gt;(x))` Example usage with your code: (Line 193)[https://gist.github.com/Starl1ght/ddf43886d405df7aae072768455f3e16#file-main-cpp-L193] `return Branch_t&lt;ARGS...&gt;(FWD(name), FWD(args)...);` Since you explicitly specify your return type for `MakeBranch` you can simplify it further: `return {FWD(name), FWD(args)...};` &gt; I don't really like, that search for command in tuple is O(n), but no idea how to optimize. Well, you don't need to have your lookups be done with a tuple, do you? A possible refactor could be defining strongly typed enums/classes with a hierarchy that could guarantee (near-)constant access e.g. `unordered_map`. C++17 would help by providing `variant` -- it could allow you to have arbitrary nestings.
&gt; I target SPARCv8 at work. LLVM targets SPARCv8. The LLVM vendored into Rust does not (or at least didn't, I might have accidentally gotten that changed but Rustup doesn't list it). I believe rustc has supported it at a ["Tier 3"](https://forge.rust-lang.org/platform-support.html#tier-3) level for a while, which means no official builds (and hence not listed in rustup), but I suspect it can be targeted as a cross-compilation target via [xargo](https://github.com/japaric/xargo) (maybe something like `xargo build --target sparc64-unknown-linux-gnu`). &gt; LLVM also recently targeted AVR, and Rust has yet to do so. (Kinda coincidentally, LLVM-mainline gained this support because [someone was interested in using Rust on an Arduino](http://dylanmckay.io/blog/rust/avr/llvm/2017/02/09/safer-microcontrollers-almost-here.html).)
Clang does via -fms-extensions. I don't recommend them
The advantage is that you can then safely use public variables while maintaining forwards compatibility. In C++, if I expose a public variable, I can never get rid of it. I can't add any verification that happens on setting the variable. I can't generate the value on the fly. This is the entire reason why you would use getters and setters. In languages with properties, I can use public variables without worrying about it. If I ever want to add extra logic that happens on read/write of the variable, I can just change it to a property, without breaking any code that uses the class. That is the strength of properties. You are correct that there is nothing that can be done with properties that cannot be done with getters/setters. The difference is that when properties exist in a language, I don't need to write them until they are needed, whereas getters/setters need to be used from the start.
I've had the misfortune of dealing with properties in C#. It results in ambiguity of whether you are accessing data or calling a function to give you a result. I find that it adds little to nothing while taking away quite a bit of certainty. I consider them to be nonsense and a huge design mistake. 
It make me feel that I am forced to learn Rust. I am tired of of this kind of articles.
I don't think it makes sense to offer a version selection flag, because the Rust developers have committed to only making backwards incompatible changes when they fix fundamental language issues. It generally doesn't make sense to pick an intentionally buggy version of the language -- if your program *needs* a Rust bug to work then you should just use that compiler version. FWIW, Rust 1.15.1 was a breaking change because it fixed a soundness issue (present in 1.15.0) that could not be fixed in a backwards compatible manner. EDIT: In retrospect, a version flag makes sense because it would allow a developer to confirm that their code compiles in an older version of the language. This could help a library or application developer support a language version of their choice.
I have never understood getters and setters. I am being hyperbolic but I will just make the members public if I don't mind someone getting their address (e.g. reference to or pointer to) and if they have no preconditions.
operator. has been considered by the committee. We are still discussing the design.
Emacs
Couldn't this mostly just be done with a proxy object? Seems like another case for the dot operator overloading proposal and it could be transparent. 
&gt; Maybe I'm weird, but I view only one compiler/build system to be a bad thing. I uncover a lot of latent bugs by using both gcc and clang for testing. Having two independent implementations is actually a great plus from this viewpoint.
I'd go so far as to argue the the incredible silly choice of using single-letter names is the problem here, not the grammar. :) Boil down a lot of C++ TMP into single-letter names and it'll be pretty undecipherable, too.
I find it nearly impossible to comment without looking at a reasonably complete, detailed proposal. Lots of ideas seem decent enough at first glance, but fall apart when you start looking at the details and the corner cases of where they might get used (and abused). C++ is sufficiently complex that fitting things in to work well with the rest of the language is extraordinarily difficult.
&gt; Getting them right is the actually hard part that nobody seems to want to do. I'll go on record as saying that "getting them right" is probably impossible. That said, if they were going to happen at all, it should *probably* be basically a lot like another lambda syntax--that is, a special syntax that creates a class that overloads a few operators in prescribed ways. I don't think this is really a *good* way to do things, but at least it's one that can be specified and work, without producing too many special cases and oddities.
C++ supports flags like this in the case of standard versions, which do actually make breaking changes. If Rust were to actually make a breaking change, we would almost certainly support a flag like this to put you on version 1 vs version 2. But minor versions are released every 6 weeks, they are backwards compatible, and the delta between any two immediately subsequent versions is very small (the size of 6 weeks of work). It would not be reasonable to forever support the slightly reduced feature set of `1.16` vs `1.17`. This user is comparing apples and oranges, doesn't seem to be well informed about the state of Rust, and is taking a pretty aggressive and superior tone. That is probably why they are being downvoted.
So I ended up trying it out. And `forward&lt;decltype(x)&gt;(x)` does appear to work https://godbolt.org/g/DIswBK