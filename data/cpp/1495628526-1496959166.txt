Thanks for providing the link! :)
Well besides the fact Linus Torvalds hates c++
Mostly just due to age. Pretty much all major kernels in use today are old and back when they were first started C was the best option. Back then C++ tools were very new and not very good compared to the C compilers on the market. Plus C compilers were available for many more systems so if you wanted to target multiple systems you had little choice but to use C. 
I don't understand his reasoning beyond C++'s increased compliation time. 
The usual reasons given include the following (note that I don't necessarily agree with all of these): - C++ does require a runtime, such as to support exceptions and RTTI. It's possible to not use those features and disable them, but the kind of C++ that you end up writing if you do that resembles "C with classes", not modern idiomatic C++. - It's possible for a seemingly innocent expression like `a + b` to involve a huge amount of code being executed, since the `+` operator might be overloaded. When designing a kernel you often have to be very conscientious about what is allowed to happen at any given point, e.g. when a certain lock is held you absolutely cannot do something that allocates memory, or when executing in an interrupt handler you absolutely must not call certain functions. And not being able to tell at a glance what an expression is doing makes it harder to enforce those kind of rules. Again, you can avoid this by not using any operator overloading, and not using RAII so that allocations are explicit, but that just takes you back to "C with classes" — you're giving up so much of C++ that the result isn't really compelling compared to just using C. - Many kernels started life at a time when C++ tooling was not nearly as mature as it is today, and nobody's going to go back and rewrite parts of something to introduce C++ when it's been C for years/decades. (Well, that's not strictly true, as you can find examples of large projects that have done just that, e.g. gcc. But again gcc is a user-mode application and the concerns of the above two bullet points don't apply, so it's a much easier sell.) - Some of the really compelling features of C++, such as inheritance and virtual functions, can be manually implemented in C anyway. The Linux kernel does this all over the place, using structs containing function pointers. 
Easy enough if you have experience. At least here in the UK. Embedded development, games programming, back end systems, anywhere where memory footprint and speed is a concern with maintainable code bases. Getting your first foot on the ladder with no experience is tough though. C++ is an unforgiving language.
https://view.officeapps.live.com/op/view.aspx?src=http://download.microsoft.com/download/5/b/5/5b5bec17-ea71-4653-9539-204a672f11cf/KMcode.doc
Pistachio, Fiasco and maybe other L4 family microkernels are in C++. Parts of Google's Fuchsia are significantly written in C++. A well chosen C++ subset can work as well or better than C IMO.
Its kernel is based on Little Kernel, which started in 2008, so not 'quite new'.
Well, yes, modern C++ plus strict discipline on build/physical layout issues. C++ modules might one day alleviate some of the pain but right now those issues are unaddressed by the standard.
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/6d2be8/help_with_a_function_inside_a_function/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Sorry for the terrible layout. It looks fine when I edit it even here on reddit but when published it just gets meshed together.
&gt; but the kind of C++ that you end up writing if you do that resembles "C with classes", not modern idiomatic C++. By disabling exceptions and RTTI? Not a chance. Did you forget that templates, lambdas, namespaces, RAII, and a million more features are available without runtime? --- &gt; It's possible for a seemingly innocent expression like a + b to involve a huge amount of code being executed [...] That's true for function with names as well. If an operator overload hides a huge amount of code in a non-intuitive way, then it's poorly designed/implemented/documented. Same applies for C functions. 
I'm not familiar with cmake ExternalProject, so I've logged a reminder to look into it at https://github.com/ned14/boost.outcome/issues/40. Can you show me what compiler flags you are invoking cl.exe with when building main.cpp?
&gt; Then I went back and read the AFIO thread and found the same: The author was the one who became hostile, the reviewers were fine. *Most* of the reviewers were fine. Not all were. But that's part and parcel of submitting your library for review.
The biggest difference between C++ and C# is how memory is handled, as there is no garbage collector. You have to do your own memory management. Definitely read up on that, and *never* treat new keyword in C++ like you would in C#. (This is a great way to introduce memory leaks.) If you encapsulate memory management in the class and properly implement the destructor though, you should be fine. Otherwise, I think you can figure out how to proceed. The two languages are actually pretty similar imo.
Cmake isn't too hard. Referencing cmake scripts from open source projects will help you understand how it's all tied together
Users are free to implement their own algorithms. For example, one might implement something like poll by polling the `await_ready` state on a set of futures. A proper awaitable type would be better to be freely composable. I don't think the ABA problem applies here, the lock-free algo for (shared)_future is quite straight-forward.
&gt;c++ does require a runtime. OK, I had to google that. I had always assumed that exceptions were done by registering an interrupt handler (to either the OS or directly to the hardware). The rest is library code. Also, maybe confused with "runtime" and "runtime library". For example, when writing c++ for Windows, you usually dynamically link to a runtime library. Can statically link if you need to though. So I found [this](https://www.codeproject.com/Articles/2126/How-a-C-compiler-implements-exception-handling) and [this](https://softwareengineering.stackexchange.com/questions/113479/are-there-any-real-world-cases-for-c-without-exceptions). So it seems to me that it depends on the targeted platform.
Ive been working in c++ for about 4 out of the last 5 years and I can say even for someone in my position, its intimidating how fast and much the language has changed. All I can say is to start digesting it a piece at a time. Try to focus on the most important concepts and go from there. If you need help identifying what is important, reading open source projects is probably a good place to start. 
&gt; Your example about OpenGL is kinda like a self-pwn; taking one of the most important API's in the world, and demonstrating how it's not particularly nice to use in Rust You seem to be missing the point. You can generate an OpenGL wrapper in Rust with zero-lines of code using rust-bindgen, and just use it, like you would in C, C++, D, or the language of your choice. You would just need to write `unsafe { ... }` around OpenGL calls (at expression/block/function scope). When you say: &gt; and demonstrating how it's not particularly nice to use in Rust you seem to be meaning that these `unsafe` blocks make it less nice to use C APIs in Rust than, let's say, in C itself, but most Rust's users would argue that they make it easier to use because they make the unsafety explicit. In C you cannot tell whether some library API is safe or not, and whether you need to look at some libraries API docs to figure out if there are some pre/post conditions that you must uphold or not. In Rust it is crystal clear when you must do so. Also you seem to be suggesting that writing a safe abstraction over OpenGL is a "a Rust thing/problem", but it is completely orthogonal. Writing a safe OpenGL wrapper in C++ or D is actually harder than in Rust due to lack of language support for properly doing this. In fact, there are many "safe" C++ OpenGL wrappers, but they are barely used because they do not succeed. Rust "safe" wrappers over OpenGL aren't perfect, but they are widely used because they are way saner than just using raw OpenGL and the run-time overhead for this is very low (note: rust wrappers around sane C libraries typically do not impose any run-time overhead, but OpenGL is so insane that even when adding run-time checks, making it 100% safe to use is almost impossible). Anyhow, maybe I am misunderstanding what you meant, or what you seemed to be suggesting. If so please correct me, but my TL;DR: is that using unsafe C libraries in Rust is as easy as doing so in C it self, or easier, if `unsafe` helps you make your code more readable (most people think this is the case). If the C library has a "sane-safe-C-API" writing a wrapper for it in Rust is trivial due to language support, which is not the case for C++ or D. If the C library has an "unsafe-by-design" API, writing a safe abstraction around it is going to be hard in any language, but it is less hard in Rust because of language support. &gt; Working in a team environment on large scale software just has way too much learning curve for the inexperienced programmers, and pays too much attention to managing safety then to actually writing solutions to problems that you're being paid for. I disagree here as well. First, inexperience programmers need to learn something anyways. Second, Rust's learning curve for modifying programs of any size or writing small programs is way lower than C++'s. Third, Rust truly excels at extreme-scale codebases. What's steep is learning to design programs "the Rust way", but that is not something that inexperienced programmers should do in any language. This is steep because "the Rust way" is different from any other programming language, so one starts at zero (also, experienced programmers find this more annoying than inexperienced programmers because they are used to transfer knowledge from one language to another but that won't work with Rust which will be frustrating). Still, this is a one time cost that really pays off the larger the code base gets since it allows performing very large refactorings, adding new features, or implementing "dangerous" performance optimizations without introducing new bugs and with a lot of assistance from the compiler. Arguably, one can always audit / code-review / refactor small programs in any language, so if anything I would say that Rust advantages shine less in small programs than in large ones. I hack often in clang and every now and then on rustc, and while writing similarly sized patches for both, what in rustc takes hours, in clang takes a week, which is a two orders of magnitude loss in productivity. This is not only because of C++ vs Rust as the language of the compiler implementation, but also because clang compiles C++ code which is way harder than compiling Rust code, so take it with a grain of salt. Yet I am reasonably confident that my rustc PRs do not introduce many bugs, while I am always almost certain that my clang patches introduce bugs, despite of the more through code-review process that LLVM has (two reviewers vs 1 of rustc). The biggest productivity win is that when I make a change in rustc in a data-structure, for example, the compiler tells me exactly all the code I have to change and why (e.g. not only "renames" but also things like "this invariant does not hold here anymore" or "you introduced a data-race here"). This severely limits the places of the code-base I have to learn to those that the compiler tells me about. With clang, even after fixing all the places that the C++ compiler tells me I need to change, I also need to compare my changes to the rest of the whole code-base and figure out if I can potentially have introduced a problem somewhere. While reviewers help, they are also human, and they don't know the whole code base. So while Rust tells me accurately which things I do need to know, C++ somehow expects me to know what I don't know. The larger the code-base, the bigger a problem this becomes. EDIT: and I am not suggesting that everything should be written in Rust either. If you already know another low-level language, 100% safety is not a concern, you don't need many dependencies, and you know in advance that your program won't be big, then using the language you know will be infinitely more productive than learning Rust in a week and using that knowledge to design and write a program. 
There is one thing in which C very clearly beats C++, and that's ABI stability. The C interface is a stable, and a lingua franca between languages. The C++ interface differs between compilers, versions of compilers, and versions of included libraries. Using something as simple as std::string(*) in your interface is already a recipe for disaster. This can be avoided by having the entire interface as extern "C" but that makes it far less convenient to use from a C++ point of view. (*) Maybe I should say "fundamental" instead of "simple", but I hope you get my point...
Unfortunately this example is really challenging for optimizers because it asks them to look through two levels of indirection; it's impressive that GCC and LLVM are doing as well as they're doing here. Interestingly, if you add one parameter, only clang is able to figure it out. Whatever optimization pass is responsible for this, it looks like Clang gained it in 3.7, and GCC gained it in 7.1.
People's opinion of C++ seems mostly defined by what it looked like in the first project they saw it.
So there's exceptions and RTTI (which can be turned off). There's thread local storage (typically not available in the kernel), but that can be easily avoided. There are more subtle issue at hand though. When do global / static constructors run? There usually isn't a C++-runtime helper that will do this for you, so you have to figure out how to make them run on your own. When do the destructors run? OS kernels want to have lots of control over the in-memory layout and placement of code and global data structures. The kernel wants to be able to indicate that function X is only used during initialization, and can be removed from memory afterwards. Function Y will only be used outside of interrupts and high priority contexts, so it can be paged out as needed. Function Z is called during an interrupt, so it must be page locked. The mechanisms and annotation for doing all that are, by necessity, vendor extensions, so you can't technically rely on it in C, but in practice you can. The tricky part though is that C++ makes a lot more code and data on the programmer's behalf that isn't obvious. Got a class with a virtual function? Well, you should make a decision about the location of the vtable. Will the vtable be page locked or not. Is it discardable? How do you even refer to the vtable in the appropriate linker scripts? Using a template? Should foo&lt;int&gt; be page locked? What if all of source.cpp was declared as pageable, even though it uses foo&lt;int&gt;? None of these problems is insurmountable, but they do provide a significant barrier to entry. Depending on the use case, it may make sense to optimize for ease of use (e.g. page lock all the things) rather than performance. The big OS vendors (rightfully) don't want to do that though.
Usually it's more in the $1-2k range I think (but agreed it's certainly possible some charge $5k!). In this particular case it's just a conference actually, even looks like a workshop paper. Many publishers, probably including ACM in this case, even allow to put the "pre-final-submission", camera-ready version online on your own homepage as a PDF. CodePlay should really check and do that.
std::shared_ptr behaves a whole lot like a C# reference.
Modern C++ exceptions on GNU ABIs are mostly done through DWARF tricks IIRC. Signals/interrupts are usually kept constant-ish after boot. Exceptions are to be used in rare circumstances only, so there’s a whole big walk-back process that’s used in addition to the exception stack, the former (DWARF) being highly ABI-dependent and not at all pretty, the latter (exception stack) somewhat user-mode-dependent, neither being something you particularly want to mash into your kernel. You can do `setjmp`/`longjmp` tricks in C for exception handling—and actually, if you’re super-clever and don’t mind being a little dangerous, you can get a `setjmp` down to mostly inlined register spills/kills.
I've actually never used a C# reference in my work, but I understand what you mean :)
As /u/SuperV1234 points out, same can be said of an innocent looking `add(a,b)`. If it trivial function or operator overload involves thousands of lines of code you have a design problem. But if an operator overload does do something customised, that's because that's what it was meant to do. An `operator*()` on 2 large matrices could take a long time, but what else would you have it do instead? And is `mul()` any different? And is anyone seriously suggesting that code be tested for correctness and performance just by looking at it? C gives you different and worse surprises, like the lack of strong typing, an object model, templates, RAII etc. and the substituted techniques such as pointers-to-pointers, heavy macro use, convoluted `goto error` control flow etc., means it's just more likely to be plain wrong than competently written C++ code. The technically justifiable reasons IMHO are age (C++ compilers for non-mainstream targets were unavailable or poor quality back in the day) and the ABI. The less justifiable but real-world reasons are momentum (projects that start a certain way are hard to change), and luddite lead developer(s).
Most of those ABI differences are for standard library types like you illustrated with `std::string`and which you wouldn't likely want to use in a kernel anyway (in favor of more purpose-built data structures). `extern "C"` wouldn't help an iota in those cases, either. The ABI for core features like classes, virtual functions, and so on hasn't changed much. One might also note that the ABI stability doesn't actually matter for most kernels _at all_. One doesn't exactly compile half a kernel with GCC 3 and the other half with Clang. At worst this affects module/plugin boundaries, which is a much smaller surface area and easily kept in C where it a real concern. Micro-kernels avoid this problem entirely by using protocols rather than C or C++ ABIs for their module boundaries, which has a raft of other benefits.
Maybe I should've said "std::shared_ptr behaves a whole lot like a C# variable". In C#, variables are references to reference-counted objects by default.
The biggest caveat with large-scale c++ projects is that newer developers will likely break all your code. You need good standards in terms of preprocessor, indenting, by-ptr/by-ref args, memory management, inheritance etc etc.
&gt; There is one thing in which C very clearly beats C++, and that's ABI stability. why would this matter for a kernel ? it's not like you link against it or use two different compilers to build it ? 
I'd argue for avoiding PImpl like the plague, tbh. Its still in a lot of API design textbooks and reference materials, but I don't really think its disadvantages weigh out its advantages nowadays.
&gt; This class is rather simple to implement in exception-safe manner. What is claimed without evidence, can be dismissed without evidence. The burden of the proof is on you, not me :) Besides, I explained in much details why it would be severely non-trivial to make this class exception-neutral, let alone exception-safe, which is pretty much impossible. But maybe you're confused about what exception safety is? :) &gt; What is more, this feature (task grouping) isn't really necessary -- tasks can do it themselves (all such tasks can share an object where they report (decrement a counter and signal when 0) on execution completion). Which is what I'm doing, only inside the pool. What would be the point of making this external? This would just make it more error prone. DRY :) &gt; Performance claims are hard to substantiate Indeed, but then: &gt; especially considering that you use std::vector as a queue and std::function (which is rather bad when it comes to performance). Quite contradictory :) For std::vector, random access is O(1), so `.back()` is O(1), `pop_back`is O(1), and `push_back` is O(N) on realloc but O(1) otherwise. As elements are push'd and pop'd all the time, this is effectively O(1) virtually all the time. And the free list alloc makes creating a task O(1) and deleting one O(1) virtually all the time, by the very same reasoning. Maybe you suggest using a list instead? But the memory alloc for every node plus the cache misses would outweight any advantage. Or maybe you suggest using some lock-free or optimistic locking container? Yeah, except the condition variable still requires a mutex, you know? A std::vector was the best STL container for that. As for std::function, yeah, it's easy to refactor it into `void (*)(void*)` if you don't need the flexibility of passing a lambda. &gt; Instead of fighting critics, I suggest asking for advice. I don't fight anyone, I just don't eat your bullshit :)
&gt; yes you can. This argument reminds me 2 decades (or more?) old claim "you can't write exception safe stack". Look it up -- you'll find answer to your question :-) It's not what I said. You can indeed write an exception safe stack. My rhetorical question was "How do you handle an exception raised by push_back?", and most of the time, there is nothing sane to do.
Kernel should always be the program which eats very less resource, can talk to devices and minimal in size. C gives all these things. C++ has abstraction which is costlier than C.
[eCos](http://ecos.sourceware.org/anoncvs.html)(which is a embedded RTOS) kernel is written in C++.
That's a terrible measure, mate.
Out of the first page of search results after filtering to C++ code files, scrolling down I see: * `dynamic_cast&lt;SuperHero*&gt;(p)` - That's the entire file. An uncompilable fragment. * `int dynamic_cast;` - Again, the entire file. Someone is explicitly trying to make sure RTTI is disabled by using dynamic_cast as an identifier. * A 19-line file called test/dynamic_cast.cpp involving types called A and B * The same 19-line file duplicated in a different repository * A four-line main.cpp that contains a definition of main that attempts to dynamic_cast an uninitialized void* variable to int*. * The same four-line main.cpp duplicated in a different repository I'm sure somewhere on GitHub someone is actually using dynamic_cast, probably. But these search results seem to support the assertion that it's very rare for a major C++ project to actually use RTTI. None of these results are even actual projects, let alone major projects.
There is a lot of worse things that can go under the radar in C, for example due to passing around void pointers, manual memory management, etc. 
???
Or by what they've learned at College or Uni (and still learn today, sadly)
It's true that a lot has happened between 2011 and 2017 - it's really great and long overdue! I do think that other languages are as scary though change-wise. Look at how Python evolved, and I don't necessarily mean from 2.x to 3.0 - also from 3.0 to 3.6, a lot happened. Or a bit similar for Java 6 to 8.
This document is a bit old. You currently build your windows drivers with the official visual C++ compiler which just has several features disabled. (No RTTI, no exceptions, no static constructors) Most other things are allowed, but can be a bit different then in user mode programs. E.g. you must supply your own new and delete functions. Note that KMDF, the actual library which should be used as a base for newer (&gt; 2001) drivers is implemented in C++.
Some parts of Windows are written in C++, I would guess that most inner parts are still some C variant. Drivers and kernel driver libraries are to some degree written in C++. E.g. KMDF or AVStream come to mind. How much of the rest is unclear, especially because some windows kernel developers suggest to write in C, but use .cpp file extensions to get the stronger type checking from C++.
These type of threads are all the same, which is really, really confusing. Folks always speak to the syntax, new-delete vs. *_ptr vs. GC, tooling/build system aspects, but they never ever mention IMHO the biggest hurdle from coming more contemporary environments: A good class library that offers real functionality. In c++ you will spend most of your time trying to accomplish a given task that doesn't necessarily deal directly with everything already stated. You will require XML and JSON reading/writing capability, serialization mechanisms, networking and filesystem access, sane datetime and timespan apis, perhaps things like GUIDs, and basics like being able to trim various characters from the start/end of a string as well as good type-safe, position independent string formatting abilities. c++ and it's STL will not provide those things to you in any meaningful capacity. You will be spending most of your time mastering an assortment of other libraries written by hundreds of different people. And once you use those libraries, your software will also look like it's been written by hundreds of different people :) Your time and energy will be spent there. The syntax will come to you, your library choices will dictate your usage of *_ptr's (and perhaps even build systems), and all of that will dictate what environment you eventually leverage to keep yourself sane (IDEs).
That doesn't hold any water because the cost of a function in C isn't apparent either. Both can be found by profiling if it actually ends up being a problem, which pragmatically is rare. 
I am not talking about a function call as such. An expression which can be as simple as `a = b` can do many stuff other than a simple assignment. It is actually an overhead in understanding for a person looking at your code. And it is a very common place in open source projects where you can find yourself in a module alien to you. Having said that, I am not bashing operator overloading. I am a big fan of DSLs..but the cost associated with discipline is more with C++. If you have a system to make sure everybody makes sane design choices, then C++ is a great choice for such scale (eg: Linux) of projects.
Are you kidding? I don't have a list, but plenty of schools touch on C++. CU Boulder does, my community college did, DigiPen does. Stanford does. I'm sure lots more do.
&gt; Large scale projects have automated tests and continuous integration systems This is the ideal situation, but if you ever work for a company that is supporting customers from 20+ years ago, I can guarantee you they have not fully implemented this kind of system. Most companies chose not to invest unless they are hiring lots of junior programmers.
/GS /TP /W3 /Zc:wchar_t /Gm- /O2 /Ob2 /Fd"main.dir\Release\vc140.pdb" /Zc:inline /fp:precise /D "WIN32" /D "_WINDOWS" /D "NDEBUG" /D "CMAKE_INTDIR=\"Release\"" /D "_MBCS" /errorReport:prompt /WX- /Zc:forScope /GR /Gd /MD /Fa"Release/" /EHsc /nologo /Fo"main.dir\Release\" /Fp"main.dir\Release\main.pch" 
&gt;General * Added option to search `Files in File System` with Silver Searcher (`ag`) (experimental `SilverSearcher` plugin) * Added exclusion patterns to `Advanced Find` and custom locator filters * Added navigation pane on right side of edit mode * Removed dependency of Welcome mode on OpenGL, improving experience in virtual machine environments and certain setups (QTCREATORBUG-15727) * Fixed wrong UI colors after suspend (QTCREATORBUG-14929) * Fixed crash with invalid themes (QTCREATORBUG-17517) Help * Fixed that help bookmarks got lost (QTCREATORBUG-17537) Editing * Added optional shortcut for duplicating current selection * Adapted to changes of code pasting services (QTCREATORBUG-17942, QTCREATORBUG-18192) * Fixed freeze when highlighting `Kconfig` file (QTCREATORBUG-14611) All Projects * Added support for `.qrc` files in project tree for all projects * Added Qt Creator variable `CurrentRun:Executable` (QTCREATORBUG-12201, QTCREATORBUG-16830) * Added choice of build system to most project wizards (QTCREATORBUG-17308) QMake Projects * Fixed wrong warning when specifying absolute path to mkspec (QTCREATORBUG-17237) * Fixed deployment of symlinks for versioned shared libraries CMake Projects * Added support for `server-mode` with CMake 3.7 or later * Added products and targets to project tree * Added option to build individual products and targets * Removed the need for `CodeBlocks` extra generator * Added header files to project tree, even if not listed explicitly in project files * Added import of configuration of existing builds * Fixed `Build &gt; Clean` Generic Projects * Added expansion of Qt Creator variables in project files C++ Support * Added support for `clang-query` in `Advanced Find` to experimental `ClangRefactoring` plugin * Added switching project and language context for parsing files to editor toolbar * Added support for `--gcctoolchain` option * Improved performance of first completion in file on Windows * Fixed handling of Objective-C/C++ * Fixed cursor position after correcting `.` to `-&gt;` (QTCREATORBUG-17697) * Fixed that quotes were added when splitting raw string literals (QTCREATORBUG-17717) QML Support * Added option to automatically format QML files on save * Added menu item for adding expression evaluators from QML code editor (QTCREATORBUG-17754) * Fixed reformatting of signals (QTCREATORBUG-17886) * Fixed issues with jumping text cursor while editing (QTCREATORBUG-15680, QTCREATORBUG-17413) Nim Support * Added automatic reparsing when files are added to or removed from project * Added Nim compiler setting to kits * Fixed that loading projects blocked Qt Creator * Fixed crash when opening empty projects Debugging * Added pretty printing of `unordered_multi(set|map)`, `boost::variant` and `QLazilyAllocated` * Fixed that expression evaluators were not evaluated when added (QTCREATORBUG-17763) * QML * Fixed accessing items by `id` in `Debugger Console` (QTCREATORBUG-17177) * GDB * Fixed issue with templated types that are pretty printed differently depending on argument type (`std::vector&lt;bool&gt;` versus `std::vector&lt;t&gt;`) * CDB * Changed to Python based pretty printing backend, resulting in faster startup and more, faster, and unified pretty printers QML Profiler * Added performance information to QML code editor (QTCREATORBUG-17757) * Improved performance of rendering timeline and loading trace files * Improved error and progress reporting for loading and saving trace files * Fixed pixmap cache size information when loading profile (QTCREATORBUG-17424) * Fixed UI issues (QTCREATORBUG-17939, QTCREATORBUG-17937) Qt Quick Designer * Added support for HiDPI * Added text editor view * Added tool bar for common actions * Added changing type of item by changing type name in property editor * Added support for `qsTranslate` (QTCREATORBUG-17714) * Added actions for adding items, selecting visible item, and adding tab bar to stacked containers * Fixed that `Dialog` was not allowed in `.ui.qml` files * Fixed that error messages could be shown twice * Fixed handling of escaped unicode characters (QTCREATORBUG-12616) * Fixed that document needed to be manually re-opened after type information became available * Fixed crash when root item is layout * Fixed that expressions were not shown in URL input field (QTCREATORBUG-13328) Version Control Systems * Git * Added option to only show the first parent of merge commits in log * Added action to skip a commit during rebase (QTCREATORBUG-17350) * Added option to sign-off commits * Fixed handling of already merged files in merge tool * Gerrit * Added detection of Gerrit remotes (SSH only) * Added support for accessing Gerrit via HTTP(S) Test Integration * Removed `experimental` state * Improved display of test results (QTCREATORBUG-17104) * Added option to limit searching for tests to folders matching pattern (QTCREATORBUG-16705) * Fixed detection of inherited test methods (QTCREATORBUG-17522) * Fixed missing update of test list when QML files are added or removed (QTCREATORBUG-17805) SCXML Editor * Fixed adding elements to `else` case (QTCREATORBUG-17674) * Fixed that copying and pasting state created invalid name Beautifier * Uncrustify * Added option to select config file to use Platform Specific Windows * Fixed that it was not possible to save files with arbitrary extension (QTCREATORBUG-15862) * Fixed ABI detection for Clang * Fixed that ABI of MSVC2017 was considered different from ABI of MSVC2015 (QTCREATORBUG-17740) Linux * Worked around issue that Unity menu bar vanished after editing main window in Design mode (QTCREATORBUG-17519) Android * Improved package signing (QTCREATORBUG-17545, QTCREATORBUG-17304) * Fixed issues with new Android SDK (25.3.1) (QTCREATORBUG-17814, QTCREATORBUG-18013) * Fixed debugging of release builds iOS * Added option to select developer team and provisioning profile used for signing (QTCREATORBUG-16936) * Fixed that starting simulator blocked Qt Creator * Fixed `Run Without Deployment` on Simulator (QTCREATORBUG-18107) Remote Linux * Added incremental deployment to `tar` package deployment QNX * Added support for 64bit platforms
the problem with "get_size" is that there are 2 functions with the same name and arguments, and a template parameter pack can be empty so both are valid if there is only one template, so it conflicts. Changing the second one to have 2 templates + the pack do the trick.
Hmm. The only two things which stand out are the choice of _MBCS over _UNICODE and the precompiled headers. In the test directory there is a with_msvc.bat file. It contains: cl /EHsc /O2 /GL /D_UNICODE /DUNICODE /DNDEBUG /DBOOST_OUTCOME_ENABLE_ADVANCED=1 unittests.cpp /I../include/boost/outcome/v1.0 So try: cl /EHsc /O2 /D_UNICODE /DUNICODE /DNDEBUG main.cpp ... and see if that works. If it doesn't, drop me an email and I'll help you get your code working.
&gt; I think thats what his main problem was and its pretty much agreeable if you have such a huge community and are maintaining one of the most widely used OS. Sorry to nitpick, but Torvalds maintains the kernel, not the whole OS. 
Ah, that makes sense. For the record, your solution: template&lt;class T&gt; size_t get_size() { return sizeof(T); } template&lt;class T1, class T2, class... Ts&gt; size_t get_size() { return sizeof(T1)+sizeof(T2)+get_size&lt;Ts...&gt;(); } And yep, that works, awesome! I'm kind of amazed I didn't find a single post that had this solution when searching, they all had super ugly helper structs, the prettiest was the enable_if solution, but I honestly like this one more, it's just way clearer, thank you!
So would I, if there was any alternative. However, there isn't: if you want to ship a library it's the only way to keep binary compatibility while adding new features. 
It matters because not every kernel is Linux. One could easily envision a microkernel that offers a stable ABI for externally loaded drivers and other services. Such a kernel would be able to load drivers developed by 3rd parties (using entirely different languages if necessary, never mind compilers), without requiring all those drivers to always be released in lockstep with the kernel itself. 
As a primarily C++ programmer, I tend to agree with him. I am presently caught at a crossroads of whether I want to start writing new code in "modern C++" or stick in this C++ backwater my code currently is (some would call it C+-... it's exactly what every C++ programmer has seen... some subset of C++ which doesn't use certain language features). I find modern C++ to be almost entirely beyond my ken to reason about, and there are even many aspects of it that I find completely confusing just from a "trying to read" standpoint. There is loads of modern C++ that takes me far, far longer to correctly read than it should (that's partly on me). Just popping open a boost header will make my head explode, sometimes. 
&gt; I also don't see how function call is more explicit than an assignment. Perhaps I haven't used C for too long. struct vec2 a = { 1, 2 }; struct vec2 b = { 1, 1 }; struct vec2 sum; vec2_add(&amp;sum, &amp;a, &amp;b); is definitely more explicit than a C++ variant with operator overloading. There's absolutely no "magic" (I know how that sounds) here. An overloaded + would be another abstraction layer. C is not about abstraction... rather the opposite. (If one could actually say C is about anything... I personally think, e.g. complex number support in C99 is stupid and an inconsistency that shows that C, like C++, is also a pragmatic language.)
I imagine that his disgust may have increased unbounded, then. :) 
A purpose-built data structure would suffer from the exact same problems as std::string though. And surely a kernel occasionally needs to acquire and return strings and other collections of things (also bringing in the question of who will release any acquired memory afterwards). Not a kernel, but right now I'm trying to deal with a DLL that can _only_ be linked to by code written with Visual Studio 2010 - the authors decided to pass data using std::string everywhere. I understand why they made that mistake, but it leaves me with a complication in my toolchain that I'd rather not have. This area is a bit of a weakness of C++, and as far as I know it is bad enough that nobody really has a clue on how to solve it (I find the suggestion to have frozen, stable versions of STL containers, uhm, 'unimpressive'), nor is there any work going on in a WG that I know of. 
&gt; The last thing I don't like about the code is that attribs&lt;&gt; have an actual memory footprint because of their static variable. I don't know that that's true at all. The static variable doesn't need to take up memory anywhere, and it probably doesn't. Your code isn't even defining it (before C++17, at least). &gt; attrib&lt;float,float,float&gt; is a type itself already so I don't see how I can access these 3 floats in attrib_size, it just sees it's been given some type. By specializing it for `attrib`, like this: http://coliru.stacked-crooked.com/a/63c95bed90e00d07 (using a static function since you didn't want a static variable).
&gt; The last thing I don't like about the code is that attribs&lt;&gt; have an actual memory footprint because of their static variable. That isn't a per-object cost, and it isn't even really a per-type cost (as long as the static data member isn't "odr-used"). However, you can do this non-intrusively. &gt; I don't see how I can access these 3 floats in attrib_size, it just sees it's been given some type. I believe that this is the technique you're missing - you can inspect types via partial specializations. Here's one way: #include &lt;stddef.h&gt; #include &lt;type_traits&gt; template &lt;typename... Ts&gt; struct attrib { }; template &lt;typename Attrib&gt; struct get_size; template &lt;&gt; struct get_size&lt;attrib&lt;&gt;&gt; : std::integral_constant&lt;size_t, 0&gt; { }; template &lt;typename First, typename... Rest&gt; struct get_size&lt;attrib&lt;First, Rest...&gt;&gt; : std::integral_constant&lt;size_t, sizeof(First) + get_size&lt;attrib&lt;Rest...&gt;&gt;::value&gt; { }; static_assert(get_size&lt;attrib&lt;&gt;&gt;::value == 0, "BOOM"); static_assert(get_size&lt;attrib&lt;short, float, double&gt;&gt;::value == sizeof(short) + sizeof(float) + sizeof(double), "BOOM"); template &lt;typename... Attribs&gt; struct attrib_size; template &lt;&gt; struct attrib_size&lt;&gt; : std::integral_constant&lt;size_t, 0&gt; { }; template &lt;typename FirstAttrib, typename... RestAttribs&gt; struct attrib_size&lt;FirstAttrib, RestAttribs...&gt; : std::integral_constant&lt;size_t, get_size&lt;FirstAttrib&gt;::value + attrib_size&lt;RestAttribs...&gt;::value&gt; { }; using position = attrib&lt;float, float, float&gt;; using tex_coords = attrib&lt;float, float&gt;; using normals = attrib&lt;float, float, float&gt;; static_assert(attrib_size&lt;&gt;::value == 0, "BOOM"); static_assert(attrib_size&lt;position, tex_coords, normals&gt;::value == 8 * sizeof(float), "BOOM"); int main() { } (I am not using C++17 fold expressions here, which would simplify the code. Additionally, `get_size` and `attrib_size` could be combined.)
I understand your point, I've just never seen it to be true. I've seen lots of people who haven't transitioned to C++ think it will be a problem. You still have to do the same thing in C one way or another. As always you can profile either to find out the actual speed in your actual program. 
&gt; Last time I checked, the C++ code is still pretty much C with classes. Classes and RAII are the core of what makes C++ what it is. This sounds an awful lot like a no true Scotsman argument... 
Profiling common C++ code using Callgrind also displays info in the code itself.
And goto.
It doesn't, if you see malloc, or goto, or manual growable arrays while reviewing C++ code you can immediately reject it. 
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6d5xsx/where_can_i_learn_there_software_engineering/di04wb7/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
shit, i always forget about binary compatability....
[LLVM disables RTTI](http://llvm.org/docs/CodingStandards.html#do-not-use-rtti-or-exceptions), and instead they implemented [their own RTTI-like](http://llvm.org/docs/ProgrammersManual.html#isa) functionality. You could also go nuts and use `std::variant` everywhere (I'm looking forward to seeing a project doing that). My point is that C++ doesn't become *C with classes* once you disable RTTI.
We could go back and forth listing individual projects that do or do not use RTTI for all eternity. Just off the top of my head, non-RTTI equivalents: Firefox -&gt; Chrome, MAME -&gt; Dolphin, KDE -&gt; Ubuntu Unity. I don't think anyone is going to convince anyone else to change their prior opinion without auditing a semi-exhaustive list of popular C++ projects. It would be interesting to do a survey like that to see how often exceptions, RTTI, and C++11 features are used, but probably a lot of work to collate. (As a side note, I find it somewhat interesting that all of the RTTI projects you listed were started prior to the release of C++03 while the non-RTTI equivalents are more modern.)
 struct foo *a = ...; struct foo *b = ...; struct foo result; add(a, b, &amp;c); Tell me, does `add()` allocate memory? 
Then why propagate them?
* a=b is slow in C if sizeof(a) is big, and you have no way of seeing it * if a=b needs to do complicated things to "assign" b to a, in C you see `assign(&amp;a, &amp;b)`, and you don't know how expensive they are This argument really is half-baked. The correct manner to reason about performance, both C and C++, is profiling and code size measurement, not speculation based on the appearance.
Your peers will hopefully be a huge help. We're a C++ game dev shop and have hired on several C# folks who've blossomed into excellent C++ devs with the helpful mentoring of their teammates. Advice is to spend some time reading up on C++ and be open to learning. It's a fairly easy transition IMO. :)
Thank you for the reassuring comment! Ah, yes. That is good advice. I would've most likely overlooked those parts. Thanks :)
That doesn't sound pretty :|. That MATLAB application. Thank you for the tips too! I've started getting myself into reading open-sources codebases. It can be a little challenging, but I'm determined :). Yes, I've heard about "Effective Modern C++". It's on my wishlist, I'm hoping to buy it soon :). I shall do! Thanks for the great tips!
I've never heard of PImpl until yesterday. I'll research it and see what people say about it :)
I strongly second the recommendation of Scott Meyer's books (Effective C++ being one of them). I wouldn't sell them so much as good for _learning_ C++, but they are indispensable for learning how to use C++ in a disciplined way that will avoid many of the famous "footguns" of the language. Meyers' "Effective STL" is also extremely useful; the Standard Template Library can be a little steep of a learning curve compared to the standard libraries of other languages, but this book really opened my eyes to how powerful it is, and how worth learning to use well it is. Not only that, but the STL is a very fine example of good interface design, which is a critical but tricky art in C++; internalizing its patterns and design principles will really be a good leg up in getting familiar with good design idioms.
Nobody in their right mind wraps every `push_back` call with OOM checks. In normal C++, "checks" are in fact by and large not needed, and OOM ones are probably more rare than others. Using -fno-exceptions is a **massive** no-no if you're a library or if you use standard library (in which case it is practically UB because the very interface of the standard library implies exceptions). As for handling an OOM - you do not "handle" it yourself. You make sure that your own state stays coherent and let it fly up the stack. Especially if you are a library. And you **do not** make the choice for me, because you **do not** know my context. Edit: One offending piece of code is e.g. _job_size++; _job_task.push_back(task); _job_function.push_back(job); _task_pending_count[task]++; and should become something like _job_task.push_back(task); auto guard = makeGuard([&amp;] { _job_task.pop_back(); }); _job_function.push_back(job); guard.Dismiss(); _job_size++; _task_pending_count[task]++; (Uses ScopeGuard of the folly library). The above code offers the so-called strong exception safety guarantee, but also a safety from future changes where you exit prematurely.
and almost all other system components other than kernel is written in C++.
I am done explaining my original intention.
You are mistaken that address space fragmentation does not cause `bad_alloc` on Linux. It does, in all three overcommit modes). You are also mistaken that `malloc` (and, consequently, `operator new`) uses overcommit under Windows. You can overcommit there only with other system calls.
I think that you are drawing a wrong parallel between the dynamic and automatic storage ("heap" and "stack"). Automatic storage does not offer a way to detect exhaustion, but dynamic does. This has been the case since forever, in various languages, so it's unfair to say "don't deal with exhaustion in dynamic storage, because you can't in automatic". Stack exhaustion is a bug to be fixed and requires a concerted effort of involved parties (libraries etc). Heap exhaustion, not necessarily.
I understand your intention. I am offering some arguments why I think there is the flaw in the resulting opinion. From there, I for a different opinion. It comes down to which arguments we choose to value :-).
Yup, there is that. But unfortunately, it is one of the reason why I have to work in C (for one of the module, not all) for my current company (a startup). The lead architect felt C++ as complicated beast :(. If we continue to debate on that decision, it would never end, thats guaranteed :)
&gt; A purpose-built data structure would suffer from the exact same problems as std::string though No, no it would not (not _necessarily_, anyways). C++ doesn't magically force people to break their own data structures' ABIs. If you want your data structure to have a stable ABI, then, you know, just don't break the ABI. Same rules as you've got in C: don't change or move around member variables and don't change function signatures. I'd go so far as to argue that it's easier to maintain ABI in C++ because you can far more easily introduce changes via overloads or inheritance to avoid breaking ABI, not to mention the benefits of newer features like inline namespaces. The actual C++ low-level ABI itself hasn't really changed on most platforms. Heck, the _C_ ABI on Linux has undergone as much ABI instability as the C++ ABI. I distinctly still recall the transition to glibc from libc5. :) The C++ ABI doesn't break in the library because C++ the _language_ requires breakage. It breaks because the standard changes the rules about how some types and functions work, e.g. adding stricter efficiency requirements or a new feature that can't be supported by a particular vendor without changing some member variables. The standard does not mandate that your own types or functions have to work any particular way, though. And the committee goes to very great lengths to ensure that core language features rarely break ABI. There's some dark corners here and there but they are easily avoided or even outright disabled in major compilers. &gt; . And surely a kernel occasionally needs to acquire and return strings and other collections of things (also bringing in the question of who will release any acquired memory afterwards). You don't have to use `std::string` to have strings, you know. :) It's entirely reasonable to write a `my_string` type solely for the purpose to allow you to guarantee a permanent stable ABI. It could be a drop-in replacement for `std::string` _today_ but wouldn't be able to guarantee that source compatibility in the long term, of course, but that's the trade-off.
Yes, I've noticed that. In terms of blog posts and StackOverflow posts. Just need to be on the look out and adapt where needed... Those books are a little outdated, but I do have them also in wishlist. *Effective C++ seems to be the most recommended book. Thanks for the timeline advice! That's a great suggestion! :D. I can manage about 5-8 hours a week on my pet projects so I can definitely do the 6 hours a week. I'll just have to buy the books though. Thank you for the great and detailed reply :)
There are kernels written in C++. However, not all features of C++ can be used in an unrestricted way. For example, if you used `std::string`, you'd need memory allocation (ok, overload operator `new`), and exceptions (how else would you report failure?). Exceptions mean you need runtime support which itself cannot be written in C++, and interacts badly with things kernels do (what do you do if an interrupt handler throws?). Thus, the way to go would be to start with a subset of C++ (e.g. templates, classes, namespaces, but no exceptions, RTTI) and use that to bootstrap an environment where more C++ can be used. Most microkernels work this way: the kernel uses minimal language features, and later doesn't care what the services running on it are written in.
It even has plain C files. They might use a few templates and modern C++ features, I don't know, but it's not really typical C++ code (if there is such a thing). I don't really care though, I'm not into diving so Subsurface has no use to me. :)
Going off on a tangent now, but it is an interesting subject... As far as I know the problem consists of several parts: - A class being different internally, despite having the same name: std::string might have a completely different layout from one version to the next (for example, with or without short string implementation). This can be solved by requiring classes to have a stable implementation, but that pretty much requires the STL _internals_ to also be standardized, rather than just the API - something that may not be desirable. This is a tough problem, one that could perhaps be solved by something like this: x namespace my_dll { #include &lt;set&gt; set&lt;int&gt; foo (); export set&lt;int&gt;; }; Basically, not just export the symbol `foo`, but also all functions for dealing with `set&lt;int&gt;`. The namespace is simply to stop it from clashing with the native `set&lt;int&gt;`. I don't know if this is feasible or not, but it might be a way out. - Memory allocated from one runtime must be returned to the same runtime. No idea how difficult this is to solve or what might be involved. - Basics like struct layout, sizes, padding, etc. This generally works for C because of the platform ABI, and not nearly as nicely for C++ because of differences in V-table and RTTI implementation between compilers. Presumably this could be solved by standardizing layout - something that should probably be limited to specially marked classes. x extern "C++" { class bar { .. }; }; Something like this could be used to require class bar to have a standardized layout, suitable for consumption by other compilers, compiler versions, etc. Maybe there are other issues too, but this is what I can think of offhand...
&gt; Parallel STL is an implementation of the C++ standard library algorithms with support for execution policies, as specified in the working draft [N4640](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4640.pdf) for the next version of the C++ standard, commonly called C++17. The implementation also supports the unsequenced execution policy specified in the ISO* C++ working group paper [P0076R3](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0076r3.pdf). &gt; Parallel STL offers efficient support for both parallel and vectorized execution of algorithms for Intel® processors. For sequential execution, it relies on an available implementation of the C++ standard library. - Links: [Parallel STL Beta Release Notes](https://software.intel.com/en-us/articles/parallel-stl-release-notes) [Getting Started with Parallel STL](https://software.intel.com/en-us/get-started-with-pstl)
IOKit drivers for Apple's Darwin are written in a subset of C++. More elegant solution for the same problem that Linux resolves with their lovely function-pointers. https://github.com/opensource-apple/xnu/blob/10.12/iokit/Kernel/IODeviceTreeSupport.cpp
Interesting!
Keep in mind that Intel uses EDG's front ends. Right now EDG supports most of C++17 and is C++11 and 14 complete. Eventually Intel will therefore support all of these, namely once they integrate a newer front end.
How much will it cost? 
FWIW, PGI compiler also uses the EDG frontend. I've found that C++ feature support is pretty uniform across the two vendor compilers.
If you're working on most open source software projects, you can get it for free* https://software.intel.com/en-us/qualify-for-free-software
That is interesting, but it looks like they only offer the Linux version
IIRC, Intel stopped doing Pro/Cluster-specific features for the C++ compiler after version 15, so I don't _think_ it will matter...
I think that's worth something, although I'm guessing that implies windows 10. 
What do you mean by variable templates? I could swear that variadic templates have been supported for a long time so I'm guessing it is isn't that.
It's a C++14 feature: http://en.cppreference.com/w/cpp/language/variable_template It's how the `std::foo_v` type trait values work.
Same thing here. Never mind that their licensing system makes the compiler nearly useless for CI. Never again.
The low-level Itanium ABI is a done deal - it's stable. The only unstable part is the library internals.
Is this work based on STAPL, or was it designed separately?
I have Intel Compiler working just fine under Travis CI. I used https://github.com/nemequ/icc-travis. Had to make sure the uninstallation was called and the ping back to deregister to Intel was done. No problems in the past 9 months.
&gt; had to pay Past tense. And Intel has updated their licensing terms to give the linux compiler to Open Source projects (as I posted above). &gt; I dont remenber rigth but it was the first and last time i used IC So what you're saying is just because something was bad means you'd never use it again? That's a bit extreme.
Ok, stick your VS project into a .zip file and send it to me. Something weird must be going on, Appveyor tests Outcome per commit using VS2015. It definitely works.
Unfortunately, yes.
That's rather saddening, given that even Arduino, the lowest common denominator of anything embedded and modern, ships with a C++11 compiler and C++11 support is enabled by default. I write C++11 for little 8 bit microcontrollers all the time, and it truly leaves C in the dust in terms of safety and performance of generated code. avrgcc is quite swell.
I'm still trying to understand move constructors. ;) 
Modern idiomatic C++ can use values and `std::optional` and no exceptions. As for RTTI, any sane runtime has very reasonable cost for `dynamic_cast` if your class hierarchy isn't stupid. If you don't use virtual inheritance, `dynamic_cast` can be guaranteed to be cheap and with a well-defined bounded cost. I use such C++11 on 8-bit AVR all the time. The generated code is very good, and the source is much easier to understand and much higher level than equivalent C would be.
&gt; Template Meta-Programming That's what I thought, but "heavily leverage TMP to facilitate compiler optimisations" was kind of new to me. Are you doing expression tree at compile time like Blitz/Armadillo? Something different? Care to share words/links?
There's no C++ without move constructors, universal references, and the value zoo. They are fundamental concepts now - have been for 6+ years really. Nothing like them exists in any other common programming language, they are quite innovative features and without understanding them you can't claim you "use" C++.
You're proven my point, then. Thanks. (No, having a CI system dependent on a working Internet connection and working Intel servers is not OK. Even if you use Travis-CI, depending on Intel's servers adds another point of failure).
You link to that specific runtime too.
First of all, fixing that won't be as easy - it's the one place that most wrappers introduce a form of overhead compared to pure C rollout. The main problem is that the function you pass to lua_pushcfunction needs to be stateless. I managed to do it without overhead in the wrapper for my engine, but it takes quite a bit code, and makes the registration function a bit uglier. I haven't looked too much through the other parts as this was the one that personally interests me the most. One thing I can note, you seem to be lacking a way to iterate arbitrary lua tables, which is pretty needed in real life applications of a wrapper, but I assume that is planned.
No. The obvious solution is not to prematurely pessimize. Nobody tells you not to use C++. Use C++ correctly and you'll be fine - that's what everyone tells you here. How on Earth could it be misconstrued to mean "don't use C++" is beyond me. I use a similar context stack written in portable modern C++ and it works just fine and has a very low cost, and can be used in performance-sensitive code. I've even used it on AVR Arduino a few times - it helps when you don't have a debugger available. And AVR Arduino is pretty much a 16-bit platform with resources more typical of an 8-bit CPU.
The nice thing about move constructors (and move assignment) is that most of us, most of the time, don't *need* to understand them. It's nice to have a general idea of the sort of thing they do, but most of the time no more than that is needed. Most of us can simply rest secure in the fact that if we do something like: std::vector&lt;int&gt; f(); ...that the compiler will take care of making it fast, even if the vector we're returning is huge, so copying it would be expensive. (And yes, I caught the winkie, but thought this bore saying anyway--I think a lot of beginners get the idea that they really need to learn huge amounts of deep technical detail before they can use C++ at all, and that's really not the case). 
Does this mean that Intel is shipping its own standard library, again? If I recall, they were shipping Dinkumware with older versions, but at some point started defaulting to whatever was installed on the system.
I like the idea, so much so that I've implemented similar pointers in the past, it's that useful. I have a few remarks/questions however. --- I find the PIMPL example misleading. From what I see in the implementation, `value_ptr` requires a fully-defined type for: - copying, - destruction. However, in the PIMPL example, the `Pimpl` structure is only declared and yet all copy constructors/... are neatly defaulted in the header. I have serious doubt this compiles. --- For implementing PIMPL, there are two solutions: - push all definitions into the `.cpp` file, where `Pimpl` is defined, - use a slightly more complicated pointer (ala `shared_ptr`) which captures the copy/destruction semantics at the construction site. The latter has more overhead, and given that all non-special methods will be defined in the `.cpp`, the former is not very taxing. --- Otherwise, the implementation is not too refined: - `value_ptr` should privately inherit from `Cloner` to trigger the Empty Base Optimization, - there is a bug in the copy constructor, `cloner` is initialized with itself, instead of being initialized from `v`, - I am not quite sure what the value of the `clone` method is: it's just a copy constructor in disguise, - the implementation of the assignment operator is surprising, why not use the underlying copy assignment operator instead of cloning again? This is wasteful.
your test ptal_expected_monad_errorobj is using the monad in a non-functional way. Making the map pure should show different performance characteristics. Furthermore dynamic_casts are in most cases avoidable as could use a variant and visit the types of interest. Unfortunately, ptal_expected does not seem to have any facility to join both execution paths (does it ?). If you don't do it, you are missing out on some optimizations that could take place as clang/gcc are capable of merging all lambdas into one and remove all ifs. Take a look at: https://hackernoon.com/error-handling-in-c-or-why-you-should-use-eithers-in-favor-of-exceptions-and-error-codes-f0640912eb45 In particular at the assembly output: https://godbolt.org/g/5f6mT9 Would be nice if you add this implementation to your testsuite.
You can export a C ABI in C++, though...
Stupid question, but still. Why bother with ICC, when we have gcc\clang\msvc? Never used it.
according to [their github](https://github.com/jbcoe/polymorphic_value#iso-standardisation), it's `polymorphic_value` (previously `indirect`) 
Public headers are headers that people using your component will need to access. Private headers are those that they do not need, and whose existence does not leak outside of your component. This also relates to public and private dependencies - anybody knowing you must know your public dependencies to understand your header files, and does not need to know the private dependencies (and in fact can ignore them nearly completely). Long story short, keep your public headers &amp; dependencies limited where possible. This is what makes your compile cycles long. What makes public dependencies happen? : - Templates - Public value types - Callback types that you implement in a public header - Lack of action to reduce it, by letting unneeded includes lie around Reducing is: - PImpl pattern(s) - Implementation-local classes used for callbacks - Encapsulation All of these have their own reasons &amp; side-effects they cause. Just try not to get caught up in a huge public dependency mess.
Yes i'm planning to add more features, for now i wanted to add the more basic stuff, like "get","call","set" etc. By the way thank you for the feedback !
No; one includes `&lt;pstl/algorithm&gt;` rather than `&lt;algorithm&gt;` and algorithms for the sequential policy just blindly forward to the system stdlib.
Unrelated to STAPL
I would add BeOS and Symbian to the list.
Yes, to ensure exception safety.
Here's my trip report: It owned. Everything owned.
It's definitely possible for a `value_ptr` implementation to only need a fully-defined type for construction. In fact you can have `value_ptr&lt;T&gt;` where `T` is an abstract class.
Great! Looking forward to the slides.
https://www.reddit.com/r/cpp/comments/4i7l4s/intel_c_compiler_160_update_3_released_adds/d2wbxfv/
My work isn´t open source so i will have to pay, i check the prices rigth now, the basic version cost 700€ wich will not have the intel advisor or the vTune forcing you to pay 1600€ to get those, and it is only the beginning, is the same as i remenber, it makes you feel as a walking wallet, i saw the "addon" thing so be ready to spend big amounts of money And for me it is not extreme, the product was a scam and i dont read anything good since i left, besides i left for the price but i promised my self that i banned it for what they did on amd cpus code, i couldn´t be sure it my clients runned on an intel or an amd cpus so maybe some versions i did had that problem making my product look terrible because it was running on an amd machine, you lost me definitely when you didnt play honest and use the trust you had to do bad things, if you forgive them is ok, i dont and i dont think i will anytime soon
They're smart about a lot of things but double indirection isn't one of them :(
I will. I'm fine with criticism of the constructive kind, but all the Reddit crowd seems capable of these days is repeating public opinion and hate-bombing any one who doesn't bleep in tune with rest of the herd. There's very little substance in this thread, mostly people trying to steer anyone away from even thinking of the approach and coming up with exceptional cases where it wouldn't work. Constructive would be thinking of improvements.
I'm 40, coding since 8; some take the short route, others insist on making everything as difficult as possible. You had no reason to attack me, I did nothing wrong. You are the one who has a problem with other people disagreeing and/or expressing alternative views. Once you snap out of that funk, learning will happen much quicker. It's not a toy, I've built pretty complex 10kloc systems on this without missing any features. I'm sorry it's not useful for you, I never promised that.
A word of advice: just glance around the thread at the upvotes and downvotes. You can infer what you like. No one attacked you. In fact, my first comment to you was to point out that you seemed to be attacking everyone else. 
I looked at the code, you should definitely use compressed pair, it could save you some space in case of empty copier. Next, in your constructor you should firs copy the cloner and then copy the T by the new cloner, not by the old one (you need to swap declaration order if the two member variables). Next, in your copy c-tor you I'm not sure how do you initialize cloner member variable, maybe you should copy it from source value ptr. Maybe you should name your member variables with m_ prefix. Next, no custom deleter as template argument or (compressed) member variable seen, that is not optimal.
Y0 man, I've come here for help, not to be belittled. Why would I troll about something as mechanical as C++ and blockchain? I'm here to learn, not to be berated by my peers. Thanks for your help /s
wrong sub &gt; For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow. 
It's okay. I understand that my question is a bit nonsensical. I understand that I won't learn it all because there is A LOT to learn, but I do have the time and energy to invest my time into learning as much as possible over the next three months. Just want a C++ veterans advice on the best way of going about this. 
&gt; 1. Wandbox &gt; 2. Compiler Explorer &gt; 3. Coliru Excellent list! Wandbox is great for snippets using Boost or pastes that need multiple files, Compiler Explorer is great for exploring assembly and comparing results of different sources, and Coliru is the simplest option for straightforward, single-file pastes. It is very nice being able to test the latest and greatest in experimental/upcoming features in C++17 in such an easy, painless manner. I have also been using these three extensively, and I fully encourage that others use these for their C++ pasting needs. &lt;3
I saw an immediate performance improvement due to better auto-vectorization. In particular it inserted AVX2 when MSVC2013 couldn't. Crucially, it worked as a drop-in replacement which means the improvement was free.
You throw `std::string` but its constructor might also throw. It shows you are not experienced C++ programmer. You are wrong, in your example bar will terminate the application. It sounds you just implemented the `expected` idiom.
In your tree example, shouldn't the constructor distinguish between lvalue/rvalue arguments for subtrees? It seems that when subtrees are temporaries, it makes little sense copying them.
Any reason why should I have a value pointer, instead of a value? 
Tree data structures come to mind.
Lots of excellent comments. &gt; cloner is initialized with itself, instead of being initialized from v I noted that myself last night! However, I made a quick test in [melpon](https://wandbox.org/permlink/0jnBmmwTHR5R4t3s) and apparently this "technique" works in both clang and gcc, which puzzles me. Regardless of whether it works or not, I agree completely that it's a terrible idea to have a parameter shadowing a member variable.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [isocpp/CppCoreGuidelines/.../**CppCoreGuidelines.md#Rr-smartptrparam** (master → 07d2413)](https://github.com/isocpp/CppCoreGuidelines/blob/07d2413d8015c49ffebc138447c64948d26cf26e/CppCoreGuidelines.md#Rr-smartptrparam) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply di2cvtw.)^.
This was in 2014/2015
My ACCU talk video mentioned in the podcast can be viewed at https://youtu.be/XVofgKH-uu4
&gt; as it would create deep copies automatically That cannot happen when polymorphism is involved. You have to have a 'clone' virtual member function. But if you have that, there is no need for value_ptr. 
I've heard universities can lag quite a bit on terms of what's standard on the industry, and personal experience seems to agree. I don't think there is any restriction against c++ in my course, just that it isn't taught. Part of it may be that c++ can make it very easy to write slow code, and speed matters on an 80mhz processor. I'm aware generally speaking of how to make it fast, but not everybody is. 
The primary meaning of move is an indication that the owner will not look at the value any more. The receiving function can use the value as scratch area, instead of making a separate copy. Second meaning is for objects that really should not be copied (for example owning pointers, filehandles, representations of input/output terminals.) 
Isn't this just an *std::optional*? Did I miss some crucial difference?
&gt; the restrict clause (which may or may not be important long-term as GPUs are able to run more and more of full C++) AFAIK, SYCL is the first standard to remove the requirement of marking functions compiled to a device code. The specification requires from the compiler to deduce which functions are called by GPU kernels (section 9.4 of SYCL specification). On the other hand, HC C++ API - an AMD implementation of C++AMP - replaced this keyword by using [function attributes](https://scchan.github.io/hcc/)(section "Annotation of device functions"). It's an interesting choice because compiler developers are not required to implement new keywords.
They have recently published beta drivers with a partial support for OpenCL 2.0 features. https://streamhpc.com/blog/2017-03-06/nvidia-beta-support-opencl-2-0-linux/
Qt Creator has [FakeVim](http://doc.qt.io/qtcreator/creator-editor-fakevim.html) and I've never run into a vim command that didn't work as expected. I minimize all of the chrome so that it basically just looks like a text editor and have enjoyed using it ever since.
I still don't understand what problem these are supposed to solve. To me it feels like solving a problem with syntax when it could be solved with architecture. 
&gt;(and you typically don't have `malloc` *per se* available for kernel code anyway). Perhaps a dumb question, but why is that? I have no kernel development experience, but wouldn't you still need to be able to use something like malloc()? 
[This](https://askubuntu.com/questions/572868/lightweight-c-c-editor-with-code-completion-and-debugging#573163) 2 year old post on askubuntu mentions CodeLite and gedit-plugins. These sound like GUI options, but they may be of use.
Yes. I know. I was being facetious.
Correct, you can use it to create or show any C++ project, even those not using Qt. 
Yes. Mainly because it's what cppreference uses :) http://en.cppreference.com/w/cpp/experimental/fs/recursive_directory_iterator scroll down to the bottom to see it in action
AFAIK the only case where a special method of `Foo` would be required is when constructing a `value_ptr` from a `Foo*`. In that case I agree. But copying an existing `value_ptr` can just invoke a virtual method in the control block, for example. Here's a very simple example of how it can work: https://ideone.com/YRIPCz
type-erasure (capture the most-derived type, call that copy constructor) can be used instead of a clone() virtual function.
Avoiding writing state machines. Yes, anything that can be solved with coroutines can be solved (less efficiently) with threads, but that can add 10-100x more overhead.
A typical butthurt response. Sigh.
And Clang has modules.
Fair enough (not original responder btw), but you can add this flag to your compiler options to get a vectorization report iirc: `/Qvec-report:1 ` Higher levels of reporting report back about which loops it attempted to vectorize, and tell you why it couldn't vectorize them. Can be useful when trying to optimize and clean-up your code. And also makes me realize that my compiler must hate me, lol.
One missing feature in FakeVim is the {-} non-greedy matching in regexp. It's often useful when you're refactoring function calls or other things with brackets.
I can confirm it works really well. I would recommend the clang based one, that seems to work the best.
Am noob, are there any examples of their usage?
FYI, QtCreator's error checking and auto completion are mostly clang based at this point. You can switch off clang but then it sucks. I think the solution is just to have a better, more mature clang based completer. I use spacemacs with emacs-ycmd for completion, and it works fine. I have a python file which I can give you, which finds the flags for a given file, which looks for a compile_commands.json file which is a totally standard way of doing it. I've been running with this setup for about a year on a very large codebase with some pretty weird kinks and overall it's been working great. Spacemacs/emacs has the evil package, which is the best vim emulator by far far far (yes I've used FakeVim). All that said, if you are desperate to avoid clang and use vim emulation then Eclipse is a much better bet than QtCreator. Eclipse's vim emulator is much better than Qt's and Eclipse doesn't use clang at all for anything.
An example are Enumerables in C#, which has native support for coroutines. https://www.codeproject.com/Articles/474678/A-Beginners-Tutorial-on-Implementing-IEnumerable-I Basically it's a much nicer way to write what in C++ is done by iterators. 
https://youtu.be/N3CkQu39j5I My presentation of using coroutines to write Go style channels
I'm just asking for an example and not abstract handwaving. 
Well, I guess nothing. With coroutines, you can have more readable async codebase (there are other use cases as well which I am not that familiar with) as the function becomes resumable. Otherwise with threads, you would probably create a context and dispatch it to the thread with a callback function (there are other ways too). This gets hairy as your code base grows. With coroutines, you do not have to create a context, it is done for you and also you do not have to provide a callback function as you are going to yield on the operation.
I see an example coroutine, but not an example of something that can only be done with a coroutine or a thread. That example basically boils down to: enum Tree { LEAF, LEFT, RIGHT }; struct coroutine { int yield = 2; Tree operator()(){ ++yield %= 3; switch (yield){ case 0: return LEAF; case 1: return LEFT; case 2: return RIGHT; } } }; int main() { coroutine cr; cr(); // LEAF cr(); // LEFT cr(); // RIGHT } It's just being used for simple stateful iteration. I don't see the benefits that would necessitate adding more syntax to C++.
Pretty much this. I tried various "package for Vim and Emacs, I tried Kdevel, I tried CLion... none felt like a ready to go environment. I'm the kind of freak that really enjoy customizing but at some point I just gave up on making those things work as I wanted in a semi portable manner. With QTcreator its just a binary + a css file, the "vim mode" works and you can build your own custom keybindings. Its not QT specific, I use it for projects that have nothing to do with qt and are build with CMake. So no need to use qmake or include any part of qt. Also... what's wrong with clang based auto-completion ? I mean, I assume most of it is clang based, since its much easier to "reuse" clang code for that sort of thing than it is to do so with gcc code.
why are constexpr and rvalues dealbreakers? I work in embedded and we use constexpr as much as possible. RTTI not so much and exceptions only on a few systems. We're shipping C++11 and 14 code right now.
Your example doesn't implement the "same-fringe problem" at all. The coroutine has to traverse the tree, left-to-right but yours has no sort of recursion/tracking of position. Notice how the first example in the linked page calls itself: yield tree_leaves(tree-&gt;left); You can implement this without coroutines, but it will be \*much\* more complex than your code. You'll have to maintain a stack of positions in the tree to return to and a state variable for each one.
I recently enjoyed plenty of the algorithms https://github.com/artcampo/
Recursion is just using the call stack as a stack data structure. In this case it would just mean another instance of the struct. 
`optional` is a pure value-type with no real indirection; consequently it can't be used polymorphically.
No, it'd need to be a growable array of these structs, not just a single second one. The point is that using the stack is natural and easy and emulating it is unnatural and harder. Coroutines allow you to do either, but without them you're forced to do the latter.
The preview buffer shows additional signature information and current parameter location, I generally don't use it and just rely on the popup. You just need to have preview enabled (I disable it https://github.com/oblitum/dotfiles/blob/62631b8b21190769b36464715f0b172032fa5d18/.vimrc#L380). I just rely on cmake in tmux panels. For quick single (or a few) source compilations I use quickrun, which is already configured in my .vimrc so I just need to open a new .cpp file, start coding and hit `leader+r`. In this quickrun setup, when I need some extra flags for clang that are not in the default quickrun setup in my .vimrc, I make use of small vim-localvimrc files in a given folder to extend my vimrc with additional compiler flags, etc. Here's some old sample session using Swift: https://www.youtube.com/watch?v=I9NCiAVc0-0. For C++ with quickrun, which just calls the compiler, I do need `main()`. If you want to try some more dynamic setting you may check https://github.com/metakirby5/codi.vim with https://root.cern.ch/cling.
Two things: - You can now create conan repositories in bintray.com to upload your packages, freely. Bintray has lacking features in current conan.io, like organizations, permissions, etc. - Bintray.com will have a moderated/curated repository of conan packages called "conan-center". This will potentially solve the current varying quality of packages in conan.io
I use MS Visual Studio. Even with code that isn't compiled on Windows (just share it via samba and add files to fake solution). Not sure what it's current relative status is, but for many years it was the best IDE hands down (mostly thanks to editing convenience, syntax highlighting and Intellisense).
Sorry, I didn't see your ;) 
Clion, visual studio
And only GCC has concepts :( but no modules and no coroutines :(
C++98 is Fine too. My team is compiling a project on the CentOS 4 (Dockered) Box with GCC 4.1 and Boost 1.64. 
We will be working on NeoVIM integration in [juCi++](https://github.com/cppit/jucipp) during the summer. 
Yes. I actually used such an implementation myself, taking inspiration of how `shared_ptr` does it. The OP's implementation however is barebone, so offers better performance (no indirection) at the cost of less flexibility.
No. The only valid reason to keep using C++98 is if you have to maintain legacy code. The OP is not in this situation. 
&gt; An expression which can be as simple as a = b can do many stuff other than a simple assignment You should ask the people behind C why they made floating point operations part of the standard - depending on target architecture a+b could be a library call with hidden costs. 
Goto has its uses. Recently helped me eleminate an if in a time critical nested loop. 
Why would anyone code c++ on an iOS device(just curios)?
Yes, that's more or less how we roll as well. What was pleasantly surprising is this "go back and remove fancy stuff" situation does not happen very often in our case. If this were not the case, the development workflow would be rather uncomfortable.
Do you use templates? Do you use STL? Do you use 'auto'? 
Here is a recent blost post: https://blogs.msdn.microsoft.com/vcblog/2017/05/19/using-c-coroutines-with-boost-c-libraries/ (Using C++ Coroutines with Boost C++ Libraries) that shows step by step how to build your own coroutine adapters starting with nothing but a compiler and boost::asio and boost::future
It's all I have at the moment. I want to learn code, I have all the resources to learn, except a good compiler. I only get a limited amount wifi I can use before everything slows down to 14kb per second, so I thought I could ask everyone here about which app to download.
It seems really cool! Does it ever go on sale?
Where does the memory come from? Malloc usually holds onto a (large-ish) block of memory and hands them out in smaller chunks, keeping tabs on what's "allocated" and what's "free." When it runs out of space in the block, it requests another block from ... uh ... the *kernel.* Which is also where it got the initial block from. In the kernel, your hardware's MMU and page mapping scheme is no longer transparent to you. YOU gotta decide how to partition the memory for yourself and for userspace.
Yes, that was a joke :( I hate C++98/03 because of lots of reasons. However, there are tons of legacy C++/C with Classes code, which makes me sick. For starters, I recommend C++11. AFAIK, C++14 is a little better than C++11, but differences are not so big. For maximal compatibility, Use C++11/14 with GCC 4.9+ or clang 3.5+ or MSVC 2015. 
Why has noone suggested emacs yet? Evil mode is a thing.
I'm not the oop kind of guy. You could remove the `virtual` keyword from the language and I wouldn't be too much lost. However, I couldn't work without templates, RAII, move semantics, sfinae, lambdas and many other modern c++ goodies. I can't wait for constexpr if, template arguments deduction for classes and other c++17 stuff!
To get inspired, take a look at Jason Turner's CppCon presentation. He writes a small game for the Commodore using C++17. https://youtu.be/zBkNBP00wJE
Thank you very much! Cool. Not sure how useful that is - it sounds good in principle but bintray.com requires you to sign up - either paid or a free open source account. It doesn't look like a package repository to me. So it doesn't look immediately useful for me or consumers of my library.
Lambas, so much! And the small little things. &lt;random&gt;, &lt;chrono&gt;, initializer lists (sometimes), auto, and probably much more which I forgot and would only notice if I was forced to go back to a really old compiler.
I agree. It also should be understandable. One letter variables rarely have that property. 
&gt; Also quoting a styleguide that... I never said anything about the merits of the rest of it. My experience with codebases that use RTTI just indicates that their description happens to be accurate and it's easier to quote it than essentially rewrite the same description. Some of Google's opinions are wacky but I don't think that's a good reason for ad hominems since anti-RTTI sentiment isn't exactly uncommon. &gt; ...1:1 mapping between specific classes in a third party library ... sometimes the class it returns is even right, the times it is not... It sounds like the third party library has some design problems... and now you have to use RTTI... which is what the quote is saying.
cargo cult
You can also use GCC 7.1 directly in Visual Studio using the Windows Subsystem for Linux. I wrote a blog post about [learning c++ concepts in Visual Studio](https://blogs.msdn.microsoft.com/vcblog/2017/02/22/learn-c-concepts-with-visual-studio-and-the-wsl/). The post is really a how-to for compiling GCC in WSL and hooking it up to VS.
See, there's the purist flaw. There's no need to take away features. From what I've seen the vim plug in for vs does have both of what you describe.
Use the CLion IDE by JetBrains. It has built in autocomplete and refactoring features as well as a built in plugin called IDEAVim for full vim emulation. It's great.
Well, browsing to bintray.com I cannot find a public repository, everything requires sign-up, so this does not look like a public package repository to me. _Edit:_ It seems like nothing of this is live yet. The public repo will be conan-center which there exists no info yet. &gt; we are launching conan-center, the new central public repository for Conan C/C++ packages. Conan-center is a curated repository &gt; Over the next few weeks, we will be taking steps to copy the current central repository hosted at conan.io to Bintray So - patience ;-) [This](http://docs.conan.io/en/latest/move_to_bintray.html) contains more concrete info. I'm looking forward to it. A curated package repo is what we need.
&gt;From what I've seen the vim plug in for vs does have both of what you describe. I use vsvim daily it doesn't support plugins. This isn't a deal breaker for everyone, but I could see it could be for some. Stock vim is a great editor, but some of the plugins are super useful. It can also be slow at times, and hang the editor (although that may be more the fault of Visual Studio than vsvim).
Ah, what I meant by plug-ins is it is already a plug in, obviously it wouldn't support other plug-ins.... Is there a vim plug in that isn't a vs feature or a separate plug in or handled by settings of the vsvim?
Hi /u/GorNishanov, does Clang implementation work with MSVC's STL?
Maybe I am too young but I never have been bitten by the CPU being to slow. It's always ram, disk or network IO. Which is ofcourse easer to fix in general then branch prediction perfomance problems but really how often do you see this in your day job. 
Windows 10 only though *cough cough*. Has so many bugs and flaws compared to the ultra-stable and robust 8.1. I really wish I could use it but no thanks to all the HDMI sound problems and various crashes and slowness (this is on 2 devices and after multiple clean-installs and having tried a variety of builds). And don't even get me started on the forced restarts, which happen right before an important meeting, presentation, or when boarding a plane on a 11 hour flight with all cached tabs lost after reboot. Oh wait, soon we won't have a choice anymore and will all have to upgrade to the shitty Windows 10, since Microsoft is not supporting newer CPUs on old OSes anymore - just a matter of time before it doesn't even install anymore. Go ahead, I'm awaiting the downvotes ;-) I'm not a hater, I love 8.1 and would love to use 10 for all its new features, but there's so many serious regressions and issues with forced restarts and privacy.
Perhaps, perhaps not. In terms pure numerics, the only really major new feature is move semantics, which is already added inside ifdef.
Visual code, emacs.
... You're going to need to learn the ins and outs of the syntax first. C++ has a serious learning curve. Read 'A tour of c++', then the data structures book by Knuth. I forget the title, but it has data structures in the name.
Couldn't you have done the polar projection stuff etc on GPU?
I might have been able to offload some stuff to the GPU, but the data still would have had to be massaged first. I'm looking at the header file containing the structure, I had a 15-bit amplitude (0 to 11585) and 14-bit angle (-3217 to 3216), plus a bunch of flags that could change at any time and would affect the rendering. I had an array of 128 of those, multiplied by about 100 graphs on the screen at most, at 60 fps. Since it eventually worked fine at about 20% CPU usage across 2 cores (iirc), I didn't investigate further.
AFAIK std::exception has no c_str constructor, so I generally inherit from std::runtime_error
I'm a bit confused on your background with CS. You are you are aspiring to become a machine-learning researcher, yet evidently it doesn't seem like you have much of a background in CS which is why you're asking I assume. In any case, I'd recommend reading books on C++ and books on data structures/algorithms separately. For algorithms/DS I recommend [The Algorithm Design Manual](http://www.algorist.com/) and [Introduction to Algorithms (commonly referred to as CLRS)](https://www.amazon.com/Introduction-Algorithms-3rd-MIT-Press/dp/0262033844). Recommended books for C++ are on [isocpp.org](https://isocpp.org/get-started). If you want to learn machine learning concepts and algorithms then I recommend some books on artificial intelligence and machine learning. To start with, [Artificial Intelligence: A Modern Approach ](http://aima.cs.berkeley.edu/) then [ISL](http://www-bcf.usc.edu/~gareth/ISL/). And/or potentially some associated MOOC courses, I recommend [Learning from Data](https://work.caltech.edu/telecourse.html) it's a really good course which teaches you fundamentals in machine learning such as learning theory and asks questions for why you can learn and etc. In general, with all these books, you could possibly learn C++ by implementing their exercises or specific algorithms. Some examples would be basic CS related things binary search, sorting algorithms, heaps/priority queues and their associated implementations in the standard library. Then specific to Machine Learning you could implement decision trees and as an extension AdaBoost, a perceptron or a more generic neural network, and the list goes on.
I'm guessing he means "The Art of Computer Programming" of which the first is "Fundamental Algorithms". None of them talk about Data structures *in their title* though and it doesn't seem like he has one in [his catalogue](http://www-cs-faculty.stanford.edu/~uno/books.html). Edit: clarified with the italics bit
And the captured code will be invoked via an std::function right? Since the clone() method would have called the copy constructor as well, i still do not see the benefit or value_ptr over unique_ptr. 
1. I'm using Chrome as my main browser but okay, I'll try whether Edge can do this. It doesn't solve the main problem though that there are many situations where Windows just decides that now is the time to auto-restart to apply Windows updates, because your computer is "unused", and when you pop the lid open or come back to it, you find yourself with a restarted desktop (it learned to re-open some of the windows in the latest build I think but most open work is lost). And I've got "Pro" and disabled this as much as possible, it still does it after a few times of ignoring the "Please reboot now" button - because, sometimes I do want to wait restarting for a few days to apply these freaking updates, because restarting and having to re-open all my open work which includes VMs, dozens of Explorer windows, a couple of VS'es, many terminals, etc, **is** in fact inconvenient and when I have a deadline I want to postpone this for a few days. I don't get how MS gets away with this in the professional environment to be honest. It's such a no-go. 2. While you are very strictly technically correct, it is just an excuse for the main reason, which is strategy, and not technical. Can you honestly say that there is a solid technical reason why Windows 8.1 can't run on x86/x64 Kaby Lake and future generation CPU's? You're saying the reason for things like this (https://arstechnica.co.uk/information-technology/2017/03/windows-7-8-ryzen-kaby-lake-support/) are technical, and not strategical? Sorry, I don't buy it. And don't blame the CPU vendor on it, I really can't take that seriously. These CPU architectures are all x86/x64 and compatible with all 20+ year old software. This is on Microsoft. As I said before I am not a hater and I wish nothing more than a decent Windows that just works, like Windows 8.1, but with the awesome things from 10 like WSL, virtual desktops, etc. But Windows 10 has just too many regressions and no-go's.
As I understand applications on WSL can't interact with "native" Windows programs? 
`cmov` is not always faster than a branch. Correctly predicted branch is virtually free, while `cmov` introduces false dependency chain. What is better in the end depends on prediction hit rate. As a result, GCC has switched back to generating branches instead of `cmov`s in some cases. See GCC bugs [54073](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=54073), [53346](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=53346), [56309](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=56309). Commewnt by Jack Stine from 54073: &gt; I have done quite a bit of analysis on cmov performance across x86 architectures, so I will share here in case it helps: &gt; Quick summary: Conditional moves on Intel Core/Xeon and AMD Bulldozer architectures should probably be avoided "as a rule." &gt; History: Conditional moves were beneficial for the Intel Pentium 4, and also (but less-so) for AMD Athlon/Phenom chips. In the AMD Athlon/Phenom case the performance of cmov vs cmp+branch is determined more by the alignment of the target of the branch, than by the prediction rate of the branch. The instruction decoders would incur penalties on certain types of unaligned branch targets (when taken), or when decoding sequences of instructions that contained multiple branches within a 16byte "fetch" window (taken or not). cmov was sometimes handy for avoiding those. &gt; With regard to more current Intel Core and AMD Bulldozer/Bobcat architecture: &gt; I have found that use of conditional moves (cmov) is only beneficial if the branch that the move is replacing is badly mis-predicted. In my tests, the cmov only became clearly "optimal" when the branch was predicted correctly less than 92% of the time, which is abysmal by modern branch predictor standards and rarely occurs in practice. Above 97% prediction rates, cmov is typically slower than cmp+branch. Inside loops that contain branches with prediction rates approaching 100% (as is the case presented by the OP), cmov becomes a severe performance bottleneck. This holds true for both Core and Bulldozer. Bulldozer has less efficient branching than the i7, but is also severely bottlenecked by its limited fetch/decode. Cmov requires executing more total instructions, and that makes Bulldozer very unhappy. &gt; Note that my tests involved relatively simple loops that did not suffer from the added register pressure that cmov introduces. In practice, the prognosis for cmov being "optimal" is even worse than what I've observed in a controlled environment. Furthermore, to my knowledge the status of cmov vs. branch performance on x86 will not be changing anytime soon. cmov will continue to be a liability well into the next couple architecture releases from Intel and AMD. Piledriver will have added fetch/decode resources but should also have a smaller mispredict penalty, so its doubtful cmov will gain much advantages there either. &gt; Therefore I would recommend setting -fno-tree-loop-if-convert for all -march matching Intel Core and AMD Bulldozer/Bobcat families. &gt; There is one good use-case for cmov on x86: Mis-predicted conditions inside of loops. Currently there's no way to force that behavior in situations where I, the programmer, am fully aware that the condition is chaotic/random. A builtin cmov or condition hint would be nice. For now I'm forced to address those (fortunately infrequent) situations via inline asm. Update: see also this SO question https://stackoverflow.com/questions/28875325/gcc-optimization-flag-o3-makes-code-slower-then-o2 and Linus's message from 2007: http://yarchive.net/comp/linux/cmov.html Update 2: There is also relevant LLVM bug https://bugs.llvm.org/show_bug.cgi?id=33013
I started from zero with "Programming: Principles and Practice in C++" ~~"The C++ Programming Language"~~. It's a nice book, when you are new to programming. (I wouldn't count Matlab.) It does not only teach C++, but many other more general programming concepts. My second book was "C++ Primer", which is fantastic if you are already a programmer or know C++ a bit. However they go quite fast trough many complex concepts. When it comes to algorithms and data structures I'd recommend one of the classic textbooks like [CLRS](https://www.amazon.com/Introduction-Algorithms-3rd-MIT-Press/dp/0262033844). Another nice book I found was this [manual](https://cses.fi/book.html) to competitive programming, which contains many implementations in C++. You will properly understand C++ or algorithms and datastructures by reading though. You need to implement stuff. For this you can take a MOOC like Coursera's introduction to algorithms or consider pages like [hackerrank](https://www.hackerrank.com/) which ask you to implement little things and provide test cases. https://cses.fi/book.html
Yes, older versions of any compiler can be difficult. That's especially true for MSVC. We're also doing whatever we can to help developers move to newer compilers but there's often code that can't be touched. 
Actually, we have the switch :-). That was one of the earliest things done so the ongoing implementation could be tested independently, and in combination with other features. But as you say, the implementation is still in early stages partly because of focus on a popular conformance issue we need for the main compiler and the modules component. So, in terms of core language TSes, the VC++ team is at coroutines+modules+concepts.
It's also available for free: https://isocpp.org/tour
&gt; It may be worthwhile to allow the value and error types to be any arbitrary type -- even the same type. For reasons and decisions outside my control, I often work in codebases where an enum (not enum class) is the error type. But this Outcome implementation wouldn't work in such a codebase, because a value type of int would then be constructible from the error type. I appreciate this. But the need to make them non-ambiguous stems from the use of simple overloads instead of SFINAE in order to keep compile times minimum. And I would argue that it's trivial to wrap a C enum into a custom error_code category, and that would be a far better way of solving your problem.
Volume 1 Chapter 2 "Information Structures" and Volume 3 Chapter 6 "Searching" talk about data structures.
In c++ you can't inherit ctors so that doesn't matter 
You can since C++11.
Fair enough! I wish my experience was better ;-) I keep thinking I'm just "the unlucky guy" but then again this has been my consistent experience since it came out 2 years ago, and across several devices, all reasonably aged and new business-series notebooks from HP, Dell and Lenovo, used (presumably) by lots of companies. And when I go back to 8.1 on each of these devices, magically, suddenly all the issues, bugs and annoyances disappear :-)
"A Tour of C++" is in my opinion a reference book, and didactically not good. So: Do have a look at it, but if you can't learn from it, don't fret. I would recommend a 3-step approach, you can do these in parallel: 1) Learn modern C++11/14/17 from videos - best resource of modern C++. (GN2012/13, CppCon, ... you can find many links if you search this subreddit). 2) Learn Alg &amp; DS from a good lecture - I'm sure MIT OCW or Coursera have some "go-to" recommended ones by awesome teachers. 3) Learn Machine learning - again choose the best videos or books out there, many awesome courses on Coursera from Stanford, Andrew Ng etc. Or books like Bishop PRML, BRML, MacKay, etc. Also, don't forget deep learning - see again courses and web resources. There's no real combined course, you won't find a course that teaches you good C++ **AND** DS (or ML). Learn them separately, each from their most renowned lectures.
Enum classes fix many of the problems C enums including implicit conversions, lack of namespacing, and unspecified storage types. std::thread, std::atomic, and std::mutex as well as all of their helper functions are so much easier to work with than pthreads and intrinsics and have RAII semantics. The memory model was another very important addition and the various memory_order types can drastically improve performance in certain situations. Uniform initialization syntax makes value initialization of template types trivial and reduces unnecessary typenames. Also helps avoid most vexing parse issue. Unfortunately it interacts rather badly with std::initialize_list and aggregate types and the [rules](http://en.cppreference.com/w/cpp/language/list_initialization) can become reather complex. Type aliases work with template parameters (thus can be used to alias long template instantiations which can make code much more readable) and have a more coherent syntax that fits with other types of using declarations. extern template is a nice alternative to explicit instantiation that can reduce redundant instantiations for some specific instantiation cases and still allows access to the template definition for the rest of the cases. override and final keywords are just nice to have. Now you get a compiler warning if you misspell the name of an overriding function. Addition of unordered_map and unordered_set to the standard library is something that was sorely lacking. No longer constrained to logarithmic time containers.
I was in your shoes a couple of years ago. At that time I was very proficient in R and Matlab, I also dabbled in python and bash. I already knew some C++, but most of what I knew was actually C, if you want to become a good efficient C++ coder, you need to know the STL to some extent. Also the syntax for C++11 and C++17 introduces a lot of nice things that are worthy to look into. I picked upp *A tour of C++*. It is good, but a bit dry sometime. It is not long, so it introduces a lot of key-concepts in a dense manner. Read it, then you can read other books or use some online content. The biggest advancement for me was to start doing coding competitions and only using C++. This enforces you to try to develop algorithms by yourself and also learn how to use the language efficiently at the same time. I recommend [hackerrank](https://www.hackerrank.com), there are also some tutorials there for learning about data structures and algorithms. [This free book/pdf](https://cses.fi/book.pdf) is excellent for getting started with competitive coding and C++. For machine learning in particular I would try to get familiar with some external libraries for linear algebra, but start with the basics.
And FFTW does that at runtime. 
Thanks. How long does it take to read Stroustrup's "The C++ Programming Language", "Programming: Principles and Practice in C++, or "The C++ Primer"? I am actually planning to read A Tour of C++ and then jump to the algorithms and data structures. 
How is it different though then just putting labels where yield statements would go. Basically it seems to me like people want extra syntax that feels like it offers more structure but doesn't actually accomplish that. I understand scopes being kept around, but that seems to be to be something that should rarely be a factor that makes the difference between something being brittle or not. 
Wow, care to elaborate why please? Or are the downvotes solely because I said something slightly negative against the Holy Book of "A Tour of C++"? (I admire Mr. Stroustrup greatly, but that doesn't mean that I need to praise every single work of him without any exception.)
Sorry, I meant that I read "Programming: Principles and Practice in C++" (PPP) above. The book "The C++ Programming Language" is more like a dictionary to look up stuff and I doesn't serve well as introduction. The meat of PPP are roughly 1000 pages. It is not densely written and meant to be read along a first semester of computer science. It also comes with exercises, which are sort of simple (no tricks or ideas needed), but instructive and a good way to chttps://www.coursera.org/specializations/algorithmsheck your understanding. "If you haven't done the exercises, you haven't read the book." (Stroustrup). I read PPP and did [this](https://www.coursera.org/specializations/algorithms) course at the same time. After that I read "The C++ Primer" and started to do a lot of competitive programming. I think "A Tour of C++" is more meant to showcase some features of C++ than to be a proper introduction. If you aren't sure about picking up C++, it's probably a good read. Otherwise (or after that) I would pick a real book. In any case, as other have pointed out it is a good idea to learn the language separately from algorithms and data structures. The latter are basically mathematics and have to be understood independently from a programming language. Of course, once you got the foundations of both you can perfectly put your knowledge to proof by implementing stuff. Again, coding websites are great for that.
Ah yes, FFTW. Many years ago I wrote a simple implementation as of the split-step Fourier method for simulating a quantum-mechanical system. A bit of work with a profiler demonstrated that it was spending all of its time inside FFTW and I decided I wasn't clever enough to stand any chance of improving its performance. There was a big of a trade-off between using pure powers of two and numbers like 2^7×3 as the grid size.
I'm not saying that the state machine method isn't brittle: it works fine in this case, as evidenced but the fact it's the default implementation for the emulator. What it is though, is _different_ from how the low-level code is structured. In the case of emulators, keeping things readable and as close as possible to the low-level mechanics is half the battle. Another thing I just remembered here is that the state machine approach here completely ignores a huge class of states: emulated DMA timings. They're treated as taking zero time, which isn't how the real hardware works. When you could have a non-constant loop with various wait times inside, it makes the state machine that much harder to write. Writing a state machine for this stuff is certainly possible, but more effort than translating what's already there.
You got it wrong: Principal Architect *in* train wrecks. Read my LinkedIn title more closely!
Seems like something to do with bittorrent, unfortunately the link in the repo to the wiki explanation is currently not available: https://wiki.theory.org/BitTorrentSpecification#Bencoding
Have you ever futzed with VTune? Back when I started using it (2005?) I discovered all sorts of crap about performance I never would have gleaned through something higher up the chain, like gprof. 
especially in C++17
ms compiler isn't even C++11 yet. Compliant with 17 seems a stretch. And even if they eventually claim it, using what they "support" is often buggy.
msvc isn't c++11 yet. But fortunately you can use other compilers on windows.
Don't even open a book if it's not covering C++11. It may as well be a brand new language. Everything past that is just syntax, but it can sure make your life easier 
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6dsa60/books_to_learn_c_along_with_algorithms/di6528z/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I totally disagree with you. I think it makes a lot of sense to have an inheritance structure for your exceptions. It makes the intent of the code clearer: if I have a module `foo` and a class `bar` in that module, it's immeditely obvious that a `catch(foo::bar::error)` is catching an error from constructing a `bar` instance. Similarly, `catch(foo::error)` is catching anything my module can throw. Importantly, `catch(foo::error)` is also *only* catching an error my module can throw. If I am using a standard library component that might throw, I will never accidentally swallow an exception that I wasn't expecting when I wrote my code. There's no way to achieve that while simultaneously catching anything your module can throw without defining a module-specific base exception. Always deriving from `std::exception` is of course good advice, but I don't think anyone is suggesting otherwise in this thread. I think the point is that adding some extra links in the inheritence chain gives you more flexibility without any significant performance overhead (exceptions are expensive, but only when you throw them, so any performance hit will only come when it's thrown. Plus, any performance penalty will depend on the implementation).
Spacemacs
Most of the time branch prediction can be successfully handled by PGO. As well as some other micro-optimizations.
Yeah, primer is really good
Thanks for your detailed advice! I am actually well aware the lack of teaching sources for C++ and ML, which brought my point that I am going to learn C++ first and then try to code ML algorithms via C++ by myself. Now, I am confused about "modern" C++....I see that C++ has different versions like C++ 11 and C++ 14...So, what C++ do you recommend to me? Also, what is the difference berwyn C/C++ and C++11? Could you also recommend good compilers for MacBook? 
Sounds like boost strong typedef 
Thank you for your detailed advice. It seems that Stroustrup also wrote another humongous book in C++ "The Complete Reference"...how it is different than PPP? I still would like to begin with A Tour of C++ first... 
Thanks! It seems that Stroustrup also wrote another book in C++ "The Complete Reference." How is it different from PPP?
In practice if every module is using the handful of exceptions provided by the standard library, there will be a lot of differences in interpretation, and in the end you are not going to be able to meaningfully centralize cleanup anyhow. I think you are misunderstanding the purpose of the standard library exceptions: they are not there so that you can re-use all of those exceptions in your own libraries. They are there to serve the standard library, which does rather specific things. Many exceptions are very very specific, like regex, various bad casts, bad optional access, length_error, etc. Put another way the standard library does not follow your suggestion. I would consider using a standard library exception in some cases, e.g. if you are implementing something like a container. But if I am doing a third party module like networking, or performance profiling, testing, command line arguments, etc etc, I would expect to identify a few major classes of errors early that should have their own type separate from any standard lib exception, and put them in a hierarchy as I suggested. Doesn't have to be elaborate, perhaps 3/4 exceptions inheriting from a base would be typical.
I've heard nothing but praise for the Primer other than that it might be a bit too deep for someone with no experience.
Nothing wrong with chapter 6, it made absolute sense. I loved chapter 6 personally. 
You might be thinking of delegating constructors, but C++11 does have both delegating and inheriting constructors...
What questions are there? 2011 was a long time ago. And conformance doesn't say anything about bugs. I spent forever on the 'can't have two auto lambdas nested' bug where it gives an error message in some random system header file. Come talk when you're done. 
Will do. Thanks!
Sure there is. I said that an important principle is to keep the HLE code as similar as possible to the low-level details. The low-level version doesn't use a switch statement.
I like to keep the bar a bit higher than msvc. 
Now Im super curious whats in chapter 6 
"Top 6 chapters about programming principles. You're not gonna believe in chapter 6!"
It's perfectly fine to pass around non-owning raw pointers. You can even store them if you need extra references between your objects, but then you need to be careful about the lifetime of the object being pointed to. In that case you could also use a single shared_ptr for an owning and weak_ptr for non-owning pointers. This will cause some errors to surface earlier. &gt; I can delete that raw pointer You probably don't need to call `delete` anywhere in your code at this point.
There is a proposed explicitly non-owning pointer, but compared with a raw pointer which could be from legacy code it just makes usage clearer: http://en.cppreference.com/w/cpp/experimental/observer_ptr 
Aah, that's exactly what I thought experimented C++ programmers were using with RAII / unique_ptr. A simple observer class. But it seems it is still experimental and that using raw pointers are perfectly fine, nice to know that it does exists though :)
There's an experimental [`observer_ptr`](http://en.cppreference.com/w/cpp/experimental/observer_ptr) for exactly this use case ([the world's dumbest smart pointer](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4282), PDF warning). I'm not sure of its status right now. [It's not exactly popular](https://stackoverflow.com/a/24158171/4885801) and gives you nothing but code that's a bit more self-documenting. I personally see nothing wrong with returning a pointer instead. If it cannot be null, I would prefer a reference.
Yes :) The owner is World class, I don't transfer ownership I just want to be able to use / store a reference of a collider owner by the World. I'll stick with the raw pointers until observer_ptr is a thing :)
Looks pretty good, would finish up the `shared_ptr`, `unique_ptr` convention quite nicely.
Because most (if not all) vim emulation are not feature complete (and I only consider vim features, not vim-plugins features), like :bufdo, :g, some weird bugs with macros, autocomands, remapping on the fly, … aka everything that make vim a great text editor and not yet another text editor.
If you work on linux, I bundled nvim+YouCompleteMe+Python2/3 in one relocatable tarball: https://github.com/hotgloupi/nvim/releases I successfully use it on old servers (centos6) as well as more up to date distrso (ubuntu16.04, debian 8). The only missing piece is the integration with gdb ... 
I think the default compiler will be fine on Mac, should be a fairly recent clang? Otherwise you can install clang or gcc from homebrew I think - I'm not a Mac user. Well, there is no clear definition on "modern C++", and different people's definitions vary. Take it as using a modern compiler (&gt;=gcc-4.9, &gt;=MSVC2015, &gt;=clang-3.7), using the useful things from C++11 and 14 like smart pointers, lambdas, range-based for loops, etc., and stick to good-practice principles like RAII, allocate on the stack whenever possible, no non-owning raw-pointers, prefer free functions over member functions, etc. Everything from the last group was already possible 15 years ago so does not depend on C++11 or something but the combination of all of it makes the language or rather your code more bug-free, easy to use, easy to read, just more powerful. "C/C++" on the other hand is generally referred to to someone using a C++ compiler but essentially coding C or something like "C with classes", so they may use features from C++, but not using them in a proper and safe way. Many people learn C++ this way actually thinking it's just "C with classes" and then never learn anything better and think the language sucks or is too hard. Also people who think C++ is all about OO go into this group - C++ is absolutely not about OO, it's a multi-paradigm language, and OO is **one** of **many** tools in a big toolbox.
&gt; data format I created The only constructive suggestion I can think of at the moment is please provide a technical reference for the data format.
I'll try to write one ! Do you have any good reference on how to write a technical reference ?
For Types you mean having a map that stores the enum -&gt; string equivalence ? And for the tabs stuff I'll check that in my IDE, it's true that it doesn't looks pretty in Github's code viewer :(
Nice ! The YAML spec is a pretty good base to get started, the document is quite long and detailed though, it will take some time to write mine :)
https://github.com/toby-allsopp/ranges-coroutines
for this particular case, use std::shared_ptr
&gt; It's perfectly fine to pass around non-owning raw pointers. This is just not so. Passing around raw pointers with ownership, nullability and definedness that are specified by documentation rather than enforced programmatically has been a continuing source of program failure for many decades now. See my more complete answer [here](https://www.reddit.com/r/cpp/comments/6dyq6l/is_it_alright_to_return_raw_pointer_from_unique/di6i859/).
If you know it's non-nullable, references are exactly the right choice. Remember, `&amp;` and `*` are inverses, so if `p` is a pointer, then `&amp;*p` is exactly the same pointer. If you return `Collider&amp;` users of your API can just say `&amp;getColliderByID(id)` if they need a `Collider*` again. 
thanks
Raw pointers are nice for observing, i.e. the current approach *could* be OK. But you air the possibility that “I can delete that raw pointer”, and that seems to indicate that you're doing manual `delete` somewhere instead of letting the smart pointers do their job. In that case the current approach is not OK. To support the observer approach you can define an [`observer_ptr` class](http://en.cppreference.com/w/cpp/experimental/observer_ptr) that simply doesn't support `delete`. To support *shared ownership*, where an object is destroyed when the last of potentially multiple owners releases it, you can use [`std::shared_ptr`](http://en.cppreference.com/w/cpp/memory/shared_ptr). 
~~Random thoughts, most of them common knowledge (I think)~~ * ~~have a shallow, but wide exception hierarchy (that is, tend to give different failures in your codebase different exception types)~~ * ~~derive from `runtime_error` (or its derivatives)~~ * ~~never, *never*, **never** lose the original error info; e.g. failure from a C API? Put all error info provided by that API into the exception you throw, plus your own context; for example, if you fail to open a file with fopen, put errno in the exception object (that's "C API" part), but also open flags and the file name for which the call failed (that's "your own context" part)~~ * ~~treat exceptions you throw as part of your public API; once you throw something because of some failure, do not change to throw something else.~~ [Understand what boost::exception talks about and use it. :-)](http://www.boost.org/doc/libs/1_64_0/libs/exception/doc/boost-exception.html)
A Tour of C++ is better actually, I wanted to add it but couldn't find it. Its the book I started learning C++ from. The Principles and practices book might actually be a bit too long, I for one read specific chapters and never actually read it cover to cover, but I'm very much an "engineer" at heart and prefer practical examples and on-hands experience to a lot of theory, so if you prefer reading to coding maybe go for it... otherwise just scrap it from the list, read A Tour of C++, read some SO docs, do some small projects and possibly skim through Effective Modern C++ and you should be all caught up with 80% of the contetn of PPP. Also as far as libraries for "math" go there's an interesting one I've stumbled upon lately called blaze: https://www.youtube.com/watch?v=w-Y22KrMgFE (though compile times with it a are a bit longer than one might want, but its probably easier to use than Armadillo or eigne for someone inexperienced with C++)
As I don't catch the exceptions, performances aren't a problem here :)
No I don't delete it manually ! But the fact that I could delete it was enough to make me wondering if I was doing it the wrong way !
But a Collider here can't and shouldn't exist outside of the World, doesn't that make World's Collider ownership valid ?
There are cases where pointers are necessary, but no ownership is ever transferred. One could still use unique_ptr if the overhead of doing so is acceptable and it can save a lot of code, but also introduces new problems, like preventing covariant return types. I don't think using a pointer in such a case is wrong.
PPP is an introductory textbook, while "The C++ Programming Language" is a reference book, which means it lists of the features of the language and says what they do, but does not necessarily teach you how or when to use them. I don't see any book by Stroustrup called "The complete reference", neither on his site (stroustrup.com) nor on amazon. Edit: And "A Tour of C++" is aimed at people who know some programming already (in some other language, or in an old version of C++) but want an introduction to C++. Edit 2: there is a book "C++: The Complete Reference, 4th Edition" by Herbert Schieldt and not by Bjarne Stroustrup. I do't know know anything about it, but from the title it must be a reference style book too. 
I understand that you have some kind of container, right?, with a method .getCollider( )? It looks as if you should define your own iterators to this container. How does the look up work? Did you consider using std::map&lt; std::string, std::unique_ptr&lt; Collider &gt;&gt; , or unordered_map? Another question: Are there only colliders in the container? Why are you using unique_ptr at all? Do you have Java/C# background? Why is the method called getCollider( )? In a strongly typed language, there is no need to have types in a name.
I started with Python but now I mostly use C++, there's only colliders in that containers but there are other containers (sprite container, gameobjects container etc..), I'm using unique_ptr to free automatically the memory and because this is considered a good practice from what I understood. The method is called getCollider() because there is also getSprite(), getGameObject() etc.. :)
&gt; One could still use unique_ptr if the overhead of doing so is acceptable You mean `shared_ptr`?
&gt; The downside of that method is that I can delete that raw pointer I don't really understand this argument. Yes... you can delete it. You could also format your hard drive. Why would you delete a raw pointer you have no idea you own?
This is quite naive. My point stems from a very simple empirical observation: the call that experiences a failure is, in a **vast** majority of situations[1] ill-placed to deal with a failure, hence "clean up and bail out". Somewhere, high up the stack, there *might* be something that some layer can do to meaningfully react. And I suggest that you have a look at your own code for the evidence of my claim. &gt;You want to know if... No I don't, by and large. Why you think I can do anything of meaning *at the place of the failure*? A case in point: a browser. So I turned Wifi off. What does a browser do? It tells me that there's no network. I need to fix it myself and retry (and it better not try to turn Wifi on behind my back!). Even a browser does **not** sit in some modal loop around a call to `thing.connect(destination)` and retries after the operator intervention. And don't even start me on any kind of non-interactive scenario, there's even less to do in that case. [1] which is different from "every situation" and you are putting words in my mouth in order to twist the argument.
Hi, you should use unique_ptr only if there is inheritance involved. &gt; I'm using unique_ptr to free automatically the memory This is what I was fearing. In C++, well-designed objects automatically clean up their own memory when they go out of scope. You should define your objects in such a way that you can declare a local variable of your object, and make assignments with it. In order to do this, you must define constructors, copy constructors, assignment operator and a destructor (if your object holds resources that are not held by any of its fields.) If you get these three operations right, then your class object can be used with the same simplicity as a primitive object in local variables and expressions. This is the most fundamental aspect of understanding C++, and people coming from reference-oriented languages (Java/C#/Python) have problems with understanding this. 
It seems to me that you should use std::unordered_map&lt; std::string, Collider &gt; , and use find( ) instead of getCollider. 
I use this pattern all the time. void f(Obj const* data); // always const pointer to signal 'I do not mess with pointer' void g() { unique_ptr&lt;Obj&gt; obj = ...; // allocate f(obj.get()); // function f does NOT mess with life-time of obj or pass it to another thread } // obj dies here If you don't use pointers, unique_ptr is practically close to useless. Sure you can just use shared_ptr all over the place, nothing wrong with that (besides being a bit slower). But I like the semantic clarity of unique_ptr + raw pointers.
&gt; C++ has an excellent type for that - the reference. A reference is a non-nullable pointer that you don't have to delete. It can't ever have an undefined value. It actually can: int&amp; dangling_ref() { int i{}; return i; } int&amp; r = dangling_ref(); `i` isn't alive anymore, therefore `r` is dangling. edit: And also, `std::optional` doesn't allow for `T&amp;`. There has been so much discussion on this, what semantics `optional&lt;T&amp;&gt;` should have, that the committee decided not to bring this issue into the standard. Instead, if you need an optional of a reference, sadly you gotta use `std::reference_wrapper`.
It is error prone, you could believe you own it because of reasons.
Yes, and even the other way round as well. That way adding/removing a type in future is as simple as adding in a new pair in the initialiser, and the function implementation never needs to change. Otherwise, I quite like the format, it's very clean and human readable.
&gt; Vulcan It's [Vul**k**an](https://www.khronos.org/vulkan/). Vulcan is an ancient Roman god.
True, unless you can get to a point where there are no acceptable `delete` calls in your code (except for RAII destructors). In such a case, seeing a delete in code is already a bug.
Exactly this! I think OP should design with this in mind from the beginning, particularly given his situation and task.
I didn't realize TomTom was still in business.
It works reasonably well in the llvm codebase, where we're moving toward: 1. raw pointers are non-owning, and nullable 1. smart pointers for ownership 1. references for everything else
You could either generate two maps by hand, or make an initialisation function that builds the inverse mapping from the forwards one. I agree, it does feel a bit dirty (you could wrap it up as a class to avoid the need for a global initialiser, keep an instance somewhere and pass references to it around), but it allows the implementation to become a black box that can be thoroughly tested once - after that you'll be able to add new types without worrying about having introduced errors into that section of code (eg copy/paste and forgetting to change something if you're as lazy as I am!)
So when is the collider removed from the vector then? When the World is done, or when a GameObject is destroyed? Are all GameObjects deleted when the World is destroyed, or does this happen during the game too?
The correct way to do this is: void f(const unique_ptr&lt;&gt;&amp; data) { // use the data } void g() { unique_ptr&lt;Obj&gt; obj = ...; // allocate f(obj); } // obj dies here This is an obvious case where you have ownership and you can use unique_ptr instead of shared_ptr. 
&gt; NEVER in my experience I had to optimize an extra memory reference I'm guessing you've never worked in Game Development then. There are no absolutes in C++. That's what makes it a rich and powerful language.
Even better: void f(const Obj&amp; data) { // use the data } void g() { Obj obj; f(obj); } // obj dies here 
It's an UB to return references to locals, hence this example is not valid (you could argue in a same way about null refs with broken code).
Yes, sorry, I guess I should have provided a bit of context in the submission. It's indeed BitTorrent's Bencode. Thanks for providing a working link! I'll fix the README this evening when I get home.
You might as well just have an initializer list with a bunch of std::functions in it then, that at least saves you a few brackets and that defer function. But why not simply having a constexpr hashing function, and hash the strings in the case statements? You handwave your way around that possibility, but to me it seems the nicest possible solution. It's certainly a lot more pleasant to read.
&gt; I need to pass the pointer to the GameObject 1. Do you really? Can’t you pass a reference? Chances are, you not only can but *should* pass a reference instead of a pointer. 2. Even if you really need to pass a pointer, you can easily pass `&amp;GetCollider(id)`.
There is a special place in hell for people who overload things like `operator&amp;` or `operator,`. IIRC, not even the standard library bothers with types that have overloaded `operator&amp;`. Plugging a type like that into an `std::vector` for example is undefined behavior. Edit: This was changed with C++11 (see below). However, overloading `operator&amp;` is still a bad idea.
Well, I guess you could do something like `std::optional&lt;std::reference_wrapper&lt;T&gt;&gt;` right? That's certainly quite ugly, though.
For some reason it is also the company which attracted more applications (so far).
You should see the video about `Boost.Hana`: https://youtu.be/Oc4enqNH-Mc. There is a simple implementation of a compile-time event system. It's the practically the same as your `switch2`. Only other names for functions and classes.
I believe you are confusing the platform with the content. I am sure there will be remote jobs and some adverts specify the C++ version used, but if companies don't there's not much I can do. A working search will be added soon. The public question form could be very interesting, but it will require some time.
Why would you need that long list though? Important thing is that all comes from a common base class, if it does, you catch the base, job done.
Just looked it up - apparently this changed with C++11. Previously types with an overloaded `operator&amp;` (which does something differently than return the address) were not `CopyConstructible`. See: http://en.cppreference.com/w/cpp/concept/CopyConstructible
You could store a reference in [std::reference_wrapper.](http://en.cppreference.com/w/cpp/utility/functional/reference_wrapper) When a pointer is needed,you can trivially get a pointer from a reference using [std::addressof.](http://en.cppreference.com/w/cpp/memory/addressof) 
Got it, thanks.
Sorry, but your example doesn't compile even when the logger is commented out. That is because your collider is an L-value. To make it compile you have to make it an R-value, which you can either do through std::move or by returning the object that make_unique returns directly without saving it to a named variable. Feel free to compile it on your own machine: #include &lt;vector&gt; #include &lt;memory&gt; /* this won't compile void insertIntToListIncorrect(std::vector&lt;std::unique_ptr&lt;int&gt;&gt;&amp; vec, int num) { std::unique_ptr&lt;int&gt; ptr{std::make_unique&lt;int&gt;(num)}; vec.push_back(ptr); } */ void insertIntToListCorrect1(std::vector&lt;std::unique_ptr&lt;int&gt;&gt;&amp; vec, int num) { vec.push_back(std::make_unique&lt;int&gt;(num)); // ptr cannot be accessed because it never got stored into an L-value. } void insertIntToListCorrect2(std::vector&lt;std::unique_ptr&lt;int&gt;&gt;&amp; vec, int num) { std::unique_ptr&lt;int&gt; ptr{std::make_unique&lt;int&gt;(num)}; vec.push_back(std::move(ptr)); // you can't use ptr after this line because it was moved. } If you take the (intuitive) route of passing the R-value when it's returned from make_unique then there is no fear of it being moved already. If you pass the result of std::move() to a function then by definition the variable can only be used for destruction, you should handle that variable like a pointer that was deleted. You might dislike this, but using a shared_ptr because there is a variable that was clearly marked as "do not use" is basically saying C++ is too hard, let's move to Java. As for the performance hit of reference counting of shared_ptr not mattering, it did matter at my job where we had to rip out the standard's atomically reference counted shared_ptr and replace it with a non-atomic one because the performance hit was too great. 
The null check is done on `delete`, not `unique_ptr`, so even raw pointers will have that branch (C++ ensures `delete`-ing a nullptr is a null-op). **Edit:** Actually looking at `unique_ptr`'s implementation it does seem to do a null check, which is probably because of custom deleters. I'd imagine at least the compiler will be able to prevent the null check being performed twice, but I can't tell for sure. **Edit2:** Googling for info on this and the general consensus seems to be that `unique_ptr` only has overhead with a custom non-trivial deleter.
Real programmers write web frontends in C++.
That's how you end up with Flash.
thanks! should be updated now. Good point about the most recent working draft. I wonder if digraphs will be also removed at some point? 
\#3 will SHOCK you!
Kind of... PHP is written in C++, right? :) 
But even without custom deleters, you can have cases where a human can prove that the ptr will be null at the end of the function and thus omit the delete while a compiler can't prove this and thus has to add the delete (in the destructor and delete). As I said this a tiny overhead and having *correct* code that exposes this behavior is rare (and is probably in need of refactoring) but it does exist. (again I might be wrong)
There are plenty of ways for references to dangle without it being UB.
&gt; Finally, I have two choices about how to deal with that pointer when I'm done - delete it, or ignore it - and there's no way to tell from that declaration which is which. You're talking about modern C++ though, and there's no reason for why a raw pointer should ever be owning in modern C++. You could just use `owner&lt;T&gt;` if you wanted to do that.
It's been so long since I've used raw owning pointers that I can't really think of situations for where that would apply, or how often it happens, haha. But yea, I stand corrected, there _could_ potentially be some overhead, but it's so minimal it's pretty irrelevant. You could also argue that instantianing a `unique_ptr` without assigning to it directly has some overhead because it's assign nullptr, whereas for a raw pointer it would just be uninitialized.
We're almost perfectly resistant to both overloaded comma and addressof now. Pathological commas defeat us (never seen in the wild).
That would be nice, although they aren't as toxic as trigraphs (as they don't infect string literals) and C++11 introduced digraph disambiguation so `vector&lt;::std::blah&gt;` doesn't introduce a `&lt;:` digraph.
Post here: http://nosubstance.me/post/coding-windows-cpp-on-linux/.
I guess I didn't explain that clearly. The actual hardware is a programmable chip: the low-level emulation is translating whatever combination of ROM and additional code that the game uploaded. That's the part that's coded more like coroutine.
In VFX and computer graphics, leaving the CPU pegged for an hour to compute a frame of a 3D render is pretty normal. Storage and network are *also* too slow, but CPU being too slow is sort of the nature of the beast. My current dayjob is in a large CDN, doing mostly network related stuff. Being compute bound is much less common that in VFX, but as soon as you optimize the storage and network aspects hard enough, eventually something else becomes the bottleneck. And a bunch of stuff I have been dealing with recently is related to NUMA, and the memory controllers are a part of the CPU, so you can consider it a special case if the CPU being too slow, even if the symptom is something like dropping packets from the network card because they have to cross NUMA domains to get to the wrong node's RAM at the wrong time. Optimizing some other thing on the CPU to be more efficient can mean there's more L3 cache available for the network traffic to get where it needs to go.
I've used VTune and it's indeed a really powerful tool, but its license is not really affordable for an individual. In my case my previous company had the license and I was able to get to play with it for a while. The poor man's yet still powerful tool for Linux developers is 'perf' which allows you to profile your applications using CPU performance monitoring (hardware) counters. You need your kernel configured in some special way but typical distributions have already done that. Check out the following man pages: - perf record - perf report - perf stat
If all you care about is the common base class, you don't need the specialized exceptions. It's noise, mental masturbation, cleverness without purpose. It adds nothing of value, but it makes your program harder to understand by adding a parallel class hierarchy which mirrors your normal one, just for the purpose of reporting errors. And what for? In the end you just log `e.what()`... Some of your users will see those possible exceptions and insist on handling them individually (reasoning that since the programmer insisted on providing them, he must have had a good reason and it is therefore important to handle them separately as well). And all of them must check every thrown exception to make sure it can be caught in a single catch-all clause. All of that is cognitive load without any benefit. 
That doesn't address my question at all, it's just circular reasoning. I'm asking how a co-routine matches the instructions running on the chip but not like similar mechanics using the language as it stands now. So far your explanation is 'because is it does'. I don't think I'm being dense just because I can't accept someone saying the same thing more forcefully instead of demonstrating or backing up their point with more detail. 
why is this downvoted?
There is also the issue of applying from another country. I know for a fact that even though it's not stated explicitly on the ads that the Microsoft roles will **NOT** consider anyone that is currently either not in the US or the exact country where the role is held. That needs to be somehow conveyed to the applicants. 
`f` doesn't own `data`, nor does it care who does or by what mechanism ownership is enforced; this is just forcing some implementation detail from `g` into `f`'s interface, making `f` less useful. There's a term for this &amp;mdash; [leaky abstraction](https://en.wikipedia.org/wiki/Leaky_abstraction) &amp;mdash; and it's in no way "correct".
Could you add if they sponsor visa or not? Thank you.
This post is complete randomness
Does the committee have any metrics on the use of digraphs and trigraphs in current codebases from participating members? Are they used at all?
If you're writing modern c++, returning a non-const pointer is perfectly fine. If you have a class with 3 methods: Thing* getThing(); unique_ptr&lt;Thing&gt; getThing(); shared_ptr&lt;Thing&gt; getThing(); You can read those as: - Get a pointer to a thing. I can expect the lifetime of this thing to be valid for the lifetime of the object I am calling. There is no safe way for me to extend the lifetime of this object other than copying the object (not the pointer). I am not an owner, therefore I should not change the lifetime (by saving up the ownership graph, or deleting, etc). - Get a pointer to a thing. I am becoming the new owner of the thing. I determine the lifetime of the object. If i do not extend its' lifetime (store it somewhere outside local scope) it will be destroyed. - Get a pointer to a thing. I am an owner of the thing. If the current owners all go out of scope, i am extending the lifetime so I can safely access it whenever. 
As I wrote before, there's two cases, the common one (just report it) and the rare one (I need to distinguish a particular failure). The rare case is the answer to "why specialized".
That's what happens when I go back and overthink a comment I didn't think much about in the first place. Really, though, I start comments like that fairly often and I had noticed, but I hadn't taken the time to figure out why per se, so thanks.
Now using a const std::string&amp; just a little oversight, thanks !
jobs are not published automatically, I have to approve them and I am a C++ dev myself. Also, the [post job](http://www.cpp-jobs.com/post-job/) page states clearly that "tech" recruiters are not allowed to post.
probably someone who thought I was advertising or something
True randomness cannot be generated in code, and thus needs dedicated hardware. This hardware is not present in most systems, and thus code to use this type of hardware is not in the C++ standard. Pseudorandom numbers can be generated in software. The challenge is to generate these numbers uniformly over any given interval and to approximate true random as much as possible. This usually takes high dimensional mathematics to achieve. Personally, I have decent results with the [Xorshift](https://en.wikipedia.org/wiki/Xorshift). It is even deterministic with set starting values: useful for debugging. Edit: challange -&gt; challenge.
Thanks!
Here, have a complementary random number: 7
[Image](https://imgs.xkcd.com/comics/random_number.png) [Mobile](https://m.xkcd.com/221/) **Title:** Random Number **Title-text:** RFC 1149\.5 specifies 4 as the standard IEEE\-vetted random number\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/221#Explanation) **Stats:** This comic has been referenced 723 times, representing 0.4544% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_di7wlhg)
&gt; deterministic with set starting values All prngs are deterministic by their nature
&gt; code to use this type of hardware is not in the C++ standard Actually, it is: [`std::random_device`](http://en.cppreference.com/w/cpp/numeric/random/random_device) (Although, that will fall-back to a software PRNG if there is no such hardware available. It's usually implemented as a wrapper around the OS RNG; e.g. `/dev/random`).
Deleting is not the only troublesome part of raw pointers. You could simply store &amp; use it when it's not valid anymore.
I know, but still worth mentioning. Then again, with some clever use of race conditions in a multi-core environment the determinism can be removed. Took me a while to find that bug.
I am not forcing any implementation detail. g() owns the pointer, not f(). 
&gt; If it didn't, does it really matter if that was because of module X, Y, or Z? Outside of trivial cases, yes, it does. If I want to write an application that is more friendly than "it worked, or it didn't", then the way various error conditions are met is very important. Consider these (straw-man) examples: - a "bad security token" error is more important than passing a wrong argument somewhere (because error handling will have to send an email alert to the administrator, reporting a possible hacking attempt). - an "invalid configuration" error may mean "close the application and reinstall it", or it may mean "make sure the JSON file is correct at this and that location" -- each a distinct user-level notification message. - an internal error (std::out_of_bounds for example) is a programming error and should be reported to the developers. All these errors may be reported by the same library, and the handling for each is definitely more complex than "it worked or it didn't".
Hey cool that you're using Grammarly! I'm a bit surprised then, so that means it only catches very basic mistakes. Your grammar is far from bad, don't worry about it. Sorry I don't have any concrete examples as I didn't make any notes. If I see your next blog post, I'll keep it in mind :-))
Imho Linkedin job search is awful and the system is abused by tech recruiters. The advantages for something like this website are focus and quality control. Not sure what I could add on top of that. 
Emacs with evil-mode (or with spacemacs and a vim setup [which is evil-mode]) CLion has a vim plugin, same with Qt creator and I think VS also has one.
I also converted all those filthy tabs to 4 spaces, should be easier to read :)
How is that supposed to be better than e.g. SO careers?
Assume a user who doesn't know you, and proceed from there. It requires some discipline, but you'll have to acquire such discipline when writing any kind of documentation anyway.
 s/7/4/
7 is clearly more random than 4
A significant difference between `switch2` and the hash / lambda methods is the former will only allow to execute a function, while the others allow arbitrary code to be run. Of course, you can `defer` a lamdba, but then you not only lose the benefits of `defer` (reduce syntaxic sugar), you've actually increased it! Note: that trade-off balance likely depends on your codebase. I guess it will be less of an issue in a heavily functional codebase, than in a more traditional C++ codebase. The article is good, and it's always nice to have alternative propositions, but I would recommend the hash one ^ ^
Proposal for removing trigraphs ([N3981](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3981.html)) contains some data, (but does not how exactly is was obtained). &gt; Case study &gt; The uses of trigraph-like constructs in one large codebase were examined. &gt; We discovered: &gt; 923 instances of an escaped ? in a string literal to avoid trigraph replacement: &gt; string pattern() const { return "foo-????\?-of-?????"; } &gt; 4 instances of trigraphs being used deliberately in test code: two in the test suite for a compiler, the other two in a test suite for boost's preprocessor library. &gt; 0 instances of trigraphs being deliberately used in production code. &gt; Trigraphs continue to pose a burden on users of C++. Edit: and for completeness, IBM's arguments against removing trigraphs: [N4210](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4210.pdf)
&gt; Edit: and for completeness, IBM's arguments against removing trigraphs: N4210 It's kind of rage-inducing that people are still talking about ASCII and EBCDIC in 2017. Unicode exists, use it.
7 is also the most powerfully magical number ;)
Somebody already did it: https://www.youtube.com/watch?v=wxVBuZK8Dl0 (libabigail, abidiff)
Floating point optimization in clang always ignores `NaN` and `inf` values while GCC let's you specify optimizations with more control, so you can relax the rounding behavior while preserving `NaN`/`inf`. I know that's really minor but I had to refactor some code last week because of it. 
&gt; Or are the mouse, satellite, and stock market effectively "dedicated hardware" in this case? Yes, because thses are not "in code", but external. The website [random.org](https://www.random.org/) draws their randomness from atmospheric data.
The main issue with &lt;random&gt; is... can you imagine trying to explain it to a new programmer? We used to be able to hack up a simple dice roller in a couple lines of code using srand and rand, and a deck using random_shuffle. Now we're not supposed to use those any more and instead teach new programmers to memorize (or more likely Google each time) words that look like a jumble of letters and numbers to the untrained eye, and are twice as verbose as the old way.
In the example this: #include &lt;stdio.h&gt; void foo(char *s) { printf("Hello %s\n", s); } void bar(char *s) { printf("Hello %s\n", s); } is being optimized as this: LC0: .string "Hello %s\n" foo: mov rsi, rdi xor eax, eax mov edi, OFFSET FLAT:.LC0 jmp printf bar: jmp foo I wonder, why it cannot be optimized as tis: LC0: .string "Hello %s\n" bar: nop foo: mov rsi, rdi xor eax, eax mov edi, OFFSET FLAT:.LC0 jmp printf Basically, without the (expensive) jump. Edit: Thank you all, I didn't know about the alignment restrictions and the static branch predictor smartness (but I guessed it). Yes, the multiple multibyte NOPs are not worth it. That's the reason I stay with the high level languages such as C and C++ and avoid assembly writing completely (but I stay interested in it and reading about it).
[Relevant Dilbert](http://dilbert.com/strip/2001-10-25)
Ha! My daughter did a science experiment having people (almost 800) choose random integers in the range from 1 to 10. The most common choice (with 30% occurrence): 7.
You know what has always irritated me about that massively upvoted question, though? It's that nobody ever suggested to use `std::partition`, which is `O(n)` rather than `std::sort` which is `O(n log(n))`.
couldn't the compiler just inline the code? With the function bodies and signatures being identical. I'm not sure how expensive a jump instruction is relative to other common instructions, but inlining smaller functions would trade memory(repeated code) for possibly speed(less jumps). edit: i didn't read the article before commenting. my bad...
Yes it is okay to use a raw pointer from a unique_ptr as long as the raw pointer does not express ownership. Meaning the place that is using the pointer only modifies the pointer value and does not cleanup the pointer. Before deciding to return a pointer, I would first decide if I need to use a pointer. If there is a case that the Collider object that I am looking from does not exist that I would return a pointer and a nullptr if the Collider object does not exist. If the Collider object has to exist then I would return a reference. I would consider using a vector of Collider objects rather then a vector of smart pointers to Collider objects. If the reason you use pointers is because you need to construct the object with different parameter just used 'emplace_back'. If you still want to use pointers but want to avoid using raw pointers [observer_ptr](http://en.cppreference.com/w/cpp/experimental/observer_ptr) suggested by [Walter Brown](https://cppcon2016.sched.com/walter_e_brown).
and it's as fast (or faster) to do a jump than several NOP to align?
I think it won't make much difference in the long term. Branch prediction will get this jump right.
Any decent branch predictor will get that jump correct so the jump is free and 1 cycle, vs potentially multiple cycles of nops.
&gt; yet your interface mandates default_delete. How does the interface mandates default_delete? I don't get it. BTW, how do you make the code boxes? 
I mean when we're doing encryption and some 10 dimensional being comes by he's going to be like "Dude, they think it's secure, they're not even using 6 dimensional addition". ^/s
Isn't Branch Prediction only relevant for conditional jumps?
It's a nice article as it's always good to know what can the compiler do automatically, but from the practical point of view, there are no real conclusions here as almost all these optimizations are enabled by default at reasonable optimization levels (`-O2`/`-O3`) anyhow. That is, all, except the last one: "interprocedural pointer analysis" (-fipa-pta). And now I can't help wondering: can it ever be useful to enable it manually? What kind of benefits could one expect to get from it? Has anybody already experimented with this by chance? 
Depends. You might not have even decoded the instruction yet when you determine what the next PC is. Unconditional jumps are still a part of your branch prediction logic, just you don't need to account for history and other things to get it right.
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/6ea95f/help_needed_with_sorting/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; can you imagine trying to explain it to a new programmer? Why does this argument get constantly trotted out? Compared to the total programmer population "*new programmer*" is a small subpopulation, and the members of that subpopulation aren't members thereof for long (as they progress and are no longer beginners). There are bad designs that can be easily explained to new programmers, and good designs that can't be easily explained to new programmers. Find a reasonable argument.
nou
http://en.cppreference.com/w/cpp/experimental/randint solves that issue.
Wait, you could actually _follow_ that? I think _I'd_ have to get out a piece of paper and write things down like I do when I go through math exercises: line by line such that each line is only one syntactic/semantic transformation further along than the previous one, with comments off to the side stating what those transformations _are_ if need be and arrows to feed earlier definitions through. 
It would be even better if it could just do bar: foo: mov rsi, rdi xor eax, eax mov edi, OFFSET FLAT:.LC0 jmp printf If the standard doesn't allow this because technically the functions have to have different addresses, I'd consider that a bug in the standard and just ignore it (or provide a flag to ignore it). When does your code ever depend on functions not having the same address? We already have maybe-or-maybe-not-the-same rules for string literals.
Why branch predictor should be involved? jmp is unconditional.
You should probably make it more clear (or urge the companies to do so) whether it's a C++ job, or a C/C++ or C job. Quite a big difference. Of course, sometimes you can tell from the role/job ad.
most random (scientifically) confirmed!
Despite the number of replies talking about pointers, this is the answer the OP needs.
While I mostly agree with your sentiments, I don't agree with your approach for two reasons: 0. Making the destructor privates prevents use of allocation on the stack (automatic storage). I can't think of many types I've ever written where this would be a good thing, and I can't think of _any_ where I thought that I was so prescient or that my design was so bulletproof that I felt comfortable forcing something that drastic on the consumer. 0. `friend`ing anything in the stdlib is not portable, as there are no guarantees that any particular implementation doesn't delegate the real work to some other function. MSVC in particular is very fond of delegating out to checked helper functions in debug builds, so it would be likely that the _actual_ deallocation would not be in `std::default_delete` itself and one would have to instead `friend` some \_Implementation\_\_Detail &amp;ndash; but only for _that_ build configuration on _that_ platform. Ew. :-]
Still no windows support? ;_;
You could have a function pointer, and test `if ( p == &amp;foo ) { something; } else { something_else; }` 
These are very cool optimizations, and it's very impressive that the compiler can reason about these things. However, I think one thing not emphasized in the article is the fact that all the functions in question have internal linkage (that is, are `static` or in an anonymous namespace). Since these optimizations change the ABI for the function, they cannot be performed if the function does not have internal linkage. It's worth keeping in mind the fact that internal linkage gives the optimizer a significantly larger number of opportunities. 
I tried `-fipa-pta` on an embedded codebase I build with `-Os` and it increased the binary size slightly.
Have we fallen so far that mutable global state "looks good" now? 
This is why java is way better, if you want to do things you just import the perfectly written standard library for it and it covers every possible use case. No "you're only allowed to generate numbers between 0 and 1 and most of them will be biased towards one side so it's not at all random"
Also check out [Intel Architecture Code Analyzer](https://software.intel.com/en-us/articles/intel-architecture-code-analyzer), although set aside at at least a few nights of background reading necessary to grok its output There are plenty of free tools in this space aside from VTune. valgrind's cachegrind tool is particularly useful, not to mention its --branch-sim option. They provide per-instruction breakdowns on i/d cache hits/misses and branch prediction behaviour. IACA lets you see what your code looks like once it enters the processor pipeline, in particular it makes spotting dependency chains and execution port contention obvious
Random number in range [5, 100000) and shuffling a vector: srand(time(nullptr)); // shitty generator, shitty seeding int x = (rand() + rand() * (RAND_MAX+1)) % (100000-5) + 5; // shitty uniform distribution std::random_shuffle(vec.begin(), vec.end()); std::mt19937 mt(time(nullptr)); // shitty seeding, less shitty generator int x = std::uniform_int_distribution&lt;int&gt;(5, 100000)(mt); // good uniform distribution std::shuffle(vec.begin(), vec.end(), mt); Yes, so much more complicated.
Indeed! ;-)
You can return the raw pointer, but you should also adopt a convention that raw pointers are "non-owning" and so you never call `delete` on them. Design your code so that all deletion of dynamically-allocated objects is done by smart pointer destructors. 
I believe the Microsoft COM smart pointer class overloads `operator&amp;`, to give the address of the stored pointer instead of the address of the smart pointer. (Yes, this is horrible) 
That's happening? Oh, thank goodness. Do you suppose I could submit some test cases for things that do not behave consistently (relative to clang and gcc - what the correct behavior should be isn't entirely clear in some of these cases, but the MSVC handling is definitely less *useful*)... Notably, the order of application of predefined macros vs. variadic macro substitution is problematic with using the (non-standard, but effectively universal) _COUNTER_ with concatenation in a variadic function macro...
not for the codeplay implementation (v1.2) but the triSYCL one works fine (v2.2) the codeplay version is more used though, so most examples and tutorials use it (and also the few libraries that use SYCL), the 2 versions are really similar but there are a few differences so watch out
You should include a description of what similar tools exist and what you think your tool does better than those. That will help people understand quickly if your tool is something that would potentially interest them.
A good integration test covers not just one combination of functions, but tens and hundreds of them. As a rule, it checks some meaningful user case. In fact, integration tests are weapon of mass destruction in the war against bugs. And they are effective against both already known and still unknown. While unit tests are simplу individual traps, tuned to specific pre-known possible bugs. We need hundreds of them to fully cover one single user case.
This article is devoid of useful information. 
&gt; I think we can both agree that having f mandate how data is deallocated Method `f` receives a `unique_ptr` **reference**, so no deallocation is done inside `f`. EDIT: yeay, `it works` !
[program counter](https://en.wikipedia.org/wiki/Program_counter)
They're not doing great and the salaries are meh. So you're not that wrong
So, I wanted to try out coroutines and installed the latest trunk. I do not find few things in libcxx that would enable me to do anything. So, is the integration with libcxx pending ? I think yes (?)
Even worse, [sometimes that is the fastest solution](http://nibblestew.blogspot.com/2017/05/gee-optimization-sure-is-hard.html).
Yes, the work has started. We're probably a ways away from text cases but interesting examples are very useful right now. Especially cases where Clang &amp; GCC disagree. Thank you! My mail is firstname.lastname@Microsoft.com. 
I'll mention it here because it wasn't clearly spelled out in the announcement (or I didn't see it anyway): includes support for msvc 2017, and includes QtCreator 4.3.1
The comments on the blog page are really toxic ones. 
Any updates to QtCharts?
This article is basically a copy of [this](https://medium.com/@LoopPerfect/c-17-vs-c-14-if-constexpr-b518982bb1e2). 
The generator, and other library types, are not a part of the TS yet; but they will be in before it lands in the actual standard. I'm actually working on designing and proposing the generator types now. [Here's a work-in-progress implementation](https://github.com/efcs/libcxx/blob/coroutines/test/support/coroutine_library_types.h)
When I look at these I think I could do most of them, but I have not idea how much they pay.
I personally think that anyone using prebuilt large toolkits with available sources to release commercial projects on is nuts, but that's just me. If you don't have the infrastructure to build the whole enchilada from scratch, you're doing it wrong, and most likely this also prevents you from adding your own changes to Qt. So you're *purposefully* losing the advantage that having access to buildable source that you can legally modify gives you. I just don't get it.
Looks like it uses promises &amp; futures as its model of asynchronicity which isn't ideal as [Chris Kohlhoff discusses here](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3747.pdf). If I were looking for a C++ REST API provider I'd probably write something on top of [Beast](https://github.com/vinniefalco/Beast) or look for something written on top thereof. Pistache also seems to implement its own...everything...using raw system calls rather than using something like [Asio](http://think-async.com/) which I would consider suspect.
Why would I want to build Qt myself if I don't want to add anything to it? No need to waste time compiling it when there's no need.
Yes I agree, but `randint` has the advantage that it can be used today.
If you have to write it more than once, you're doing things wrong to begin with. Put it in a function template – done.
It's reasonably good, but this was the very first impression I had with it https://www.amazon.com/gp/review/R2TXODQ714G38S?ref_=glimp_1rv_cl
Which exactly feature do you want? There is a chance that the feature is in `&lt;atomic&gt;` but needs some flag, like `-std=c++1z`. Comparative list of features is here: http://en.cppreference.com/w/cpp/compiler_support
I completely agree with your final point re. randint. I also in principle agree with P0347. However, the real value of Melissa O'Neill's proposal is the seeding tech in it while remaining consistent with the overall approach of the standard library, even going as far as satisfying the pain that is std::seed_seq/SeedSequence concept. She unfortunately seems to have lumped everything in her randutils into that proposal, instead of taking a strong hint from other proposals (including the tiny randint), that specialisms take less work to pass and verify. I hope she gets some proposal advice from very helpful people like Howard Hinnant (author of std::chrono) and other successful proposers. Perhaps her proposal should carve off the seeding separately and do the rest of randutils as a different proposal instead.
`atomic_shared_ptr` is a part of Concurrency TS. You shall look if the library implements that TS. For GCC's libstdc++ the support table is [here](https://gcc.gnu.org/onlinedocs/libstdc++/manual/status.html) and it states no support for Concurrency TS. You information about support in GCC 5 was apparently incorrect. For Clang's libc++, TS implementation status is [here](http://libcxx.llvm.org/ts1z_status.html) There is no mention of Concurrency TS either. **Update**: You probably confused it with "atomic operations for std::shared_ptr" (which is listed in GCC 5 release notes), which is [something different](http://en.cppreference.com/w/cpp/memory/shared_ptr/atomic), and what `atomic_shared_ptr` is a replacement for. 
It's perfectly legal...
&gt; Asio comes in two variants: (non-Boost) Asio and Boost.Asio. http://think-async.com/ Also, Boost.Hana has zero Boost dependencies.
&gt; last time I looked into D they had two competing standard libs and I wanted no part of that That was a very long time ago. It's practically a different language since then. D is usually more performant than C/C++ in my experience, and that can be attributed to: better code availability/inlining, introspection, sane templates which offer much more flexibility for case-specific optimisation, compile-time function evaluation eliminating runtime work when constants are given as arguments, not-zero-terminated strings (huge!). There's just much more high-level knowledge available to the compiler, and backends like LLVM can do an amazing job. The GC was identified as an issue years ago and has since become optional, and even if you choose to use it (it's convenient for many applications), it's easy to control. I feel the ecosystem is gaining momentum, and guys like Andrei and Scott showing support is encouraging. Tooling is better too, Visual Studio is well supported, which most industry uses in my experience, and interaction with C and C++ both work well, a big win if you have legacy code.
yeah, I'll probably revisit D again at some point, I always liked the ideas behind it, it's just that when I was looking for something new to learn they had two standard libs duking it out :) 
&gt;If you have to write it more than once, you're doing things wrong to begin with. Put it in a function template – done. A new programmer?
Roll a dice srand(time(0)); int x = rand() % 6; vs std::random_device r; std::seed_seq seed{r(), r(), r(), r(), r(), r(), r(), r()}; std::mt19937 mt(seed); std::uniform_int_distribution&lt;int&gt; dist(0, 6); int x = dist(mt); 
Blog post did: http://nibblestew.blogspot.com/2017/05/gee-optimization-sure-is-hard.html
Is REST simply http for the C++ community? Imho the main benefit of a RESTfull framework is the help with HATEOAS, which implies the support for generating endpoints programmatically. If that's not part of such a lib, it remains simply a http router lib. I have not found such a lib in C++ yet.
Oh my, this is flying under the radar but MSVC finally gets release PDB symbol files. Proper profiling and debugging.... REJOICE!
Most of this difference is basically internal though. Your code looks pretty similar between the two--e.g., `foo.send(bar).then(baz);` So, with the interface looking pretty similar, the obvious difference would be in performance. I don't see any benchmarks published for it yet, so I did a quick run with ApacheBench, comparing its `http_server` example ASIO's multithreaded http server example. Disclaimer: the results really aren't entirely comparable. In particular, ASIO was serving the contents of a file from the file system, while Pistache was serving some data it generated internally. ASIO was providing a larger reply than Pistache as well (so we'd probably expect this to favor Pistache in request rate/speed, but ASIO in bandwidth). My interest (for the moment) wasn't in really determining which was faster, only in getting some idea of whether Pistache's use of futures instead of callbacks would prevent it from being competitive at all. That said, the short summary of the results is: ### ASIO Requests per second: 21463.05 [#/sec] (mean) Time per request: 0.093 [ms] (mean) Time per request: 0.047 [ms] (mean, across all concurrent requests) Transfer rate: 2368.48 [Kbytes/sec] received ### Pistache Requests per second: 47652.24 [#/sec] (mean) Time per request: 0.042 [ms] (mean) Time per request: 0.021 [ms] (mean, across all concurrent requests) Transfer rate: 3071.34 [Kbytes/sec] received I'll repeat: this is *not* a definitive comparison. It's nothing more than a quick test to get at least *some* idea of whether Pistache might stand some chance of competing, and I'd say it's enough to be able to say that yes, it may be able to. Using futures instead of callbacks *may* handicap it to some degree--but if so, apparently not by so much that it's an order of magnitude slower, or anything like that.
Kind of sitting here fiddling my thumbs as a QWidgets developer - there literally are no improvements for me at all for the last few releases, including this one.
That's a don't downvote other people because of their opinion 
&gt; It appears GCC does this, at least for C. You might want to be a bit careful as this kind of nitty gritty detail is where C++ and C can start to diverge quite sharply.
In this case the problem is me not understanding how to read cppreferences, I assumed that if a library feature is present there, respective hearder to include it must be present in at least one implementation libcpp. Do the various sg study groups have their own custom versions of libc++ if one wishes to try these features ? Or do at leas the wgs have library implementations which are not included in the mainstream compilers but can be used ?
Still I haven't used this feature ever. I don't see any need to inherit ctors.
Inside boost yes, but I said stand-alone library - completely separate. See link to ASIO below in other post.
&gt; Looks like it uses promises &amp; futures as its model of asynchronicity which isn't ideal as Chris Kohlhoff discusses here. I have a few doubts on the analysis exposed in section 4 of the linked paper. The paper says that with the callback approach "no additional synchronisation is required". Well... such a statement assumes that the callback can be executed freely on a thread which is different from the initiating thread. However, in most use case scenarios, the callback will need to access data which is shared with the initiating thread, so some synchronisation will indeed be necessary. So, to make a fairer comparison, the advantage of callbacks is that you don't have to pay for a synchronisation if you don't need it, while the future approach will do synchronisation for you and you always have to pay for it. 
Aside from the most basic features everyone knows, I appreciate memory page permissions to detect when memory is written. I'd love to learn about newer features too.
I like the idea. Here is a compile time implementation of FNV-1a, which should have much better collision resistance than the dbj function in your link: // See http://www.isthe.com/chongo/tech/comp/fnv/#FNV-1a namespace fnv_1a_64 { static const uint64_t OFFSET_BASIS = 14695981039346656037ULL; static const uint64_t FNV_PRIME = 1099511628211ULL; template &lt;size_t N&gt; static constexpr uint64_t hash(const char(&amp;str)[N], size_t I = N) { return I == 1 ? OFFSET_BASIS : (hash(str, I - 1) ^ str[I - 2]) * FNV_PRIME; } // runtime struct Wrapper { Wrapper(const char* str) : str(str) {} const char* str; }; static uint64_t hash(Wrapper w) { uint64_t hash = OFFSET_BASIS; while (*w.str) { hash ^= *w.str++; hash *= FNV_PRIME; } return hash; } } // namespace usage: int main(int, char**) { using fnv_1a_64::hash; std::string whatever("asadf"); switch (hash(whatever.c_str())) { case hash("JPG"): case hash("PNG"): case hash("AVI"): case hash("MPG"): case hash("MPEG"): break; } } 
There's plenty of resources on this, so I'll focus on the ones that either serve as good starting points or are among the most representative ones: Last Branch Records (LBRs) and Intel Processor Trace (PT) come to mind -- although see also ARM's CoreSight: https://thenewstack.io/hardware-tracing-fast-precise-performance-analysis/ A general introduction: https://www.sigarch.org/in-depth-system-analysis-using-hardware-assisted-tracing/ They can be used for the record and replay feature of GDB: https://sourceware.org/gdb/onlinedocs/gdb/Process-Record-and-Replay.html They also allow good tracing support -- see "Low-Level Tracing for Latency Analysis: From Baremetal to Hardware Tracing Blocks", http://tracingsummit.org/w/images/6/6c/Suchakra-tracingsummit2016.pdf More: * Cheat sheet for Intel Processor Trace with Linux perf and gdb: http://halobates.de/blog/p/410 * Intel Processor Trace resources: http://halobates.de/blog/p/406 * Announcing simple-pt — A simple Processor Trace implementation: http://halobates.de/blog/p/344 * Linux: https://github.com/torvalds/linux/blob/master/tools/perf/Documentation/intel-pt.txt * Windows: see https://moflow.org/ and https://github.com/intelpt Overview of Last Branch Records (LBRs) on Intel CPUs: http://halobates.de/blog/p/367 Performance Monitoring Units (PMUs) Note: these are not at all particular to Intel and are definitely present on most modern CPUs. In fact, here's an example for ARM: https://developer.arm.com/products/software-development-tools/ds-5-development-studio/streamline In addition to perf on Linux (cf. [perf status on ARM and ARM64 ](https://archive.fosdem.org/2015/schedule/event/arm_perf/) -- admittedly from 2015), the following support the access to the corresponding hardware performance counters for both Intel and ARM: * perfmon2 - http://perfmon2.sourceforge.net/ * Performance Application Programming Interface (PAPI) - http://icl.cs.utk.edu/papi/ What's Intel-specific is Top-Down Analysis Methodology (TMAM) -- an organized, methodogical way to use PMUs to track down performance issues -- and the tools that support it. * For an introduction, see https://software.intel.com/en-us/top-down-microarchitecture-analysis-method-win * For a more deeper introduction, I'd recommend Yasin's publications (in particular "A Top-Down Method for Performance Analysis and Counters Architecture"): https://sites.google.com/site/analysismethods/yasin-pubs A pretty good open-source tool supporting TMAM is pmu-tools (VTune also has support); see: * pmu-tools part I: http://halobates.de/blog/p/245 * pmu-tools, part II: http://halobates.de/blog/p/262 * toplev tutorial and manual: https://github.com/andikleen/pmu-tools/wiki/toplev-manual 
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [torvalds/linux/.../**intel-pt.txt** (master → a374846)](https://github.com/torvalds/linux/blob/a37484638ca5e0aa7c205ecb91c9ace92e83c32c/tools/perf/Documentation/intel-pt.txt) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dibb21i.)^.
Did you mean returning a reference from a member function?
It always surprises how much that relatively short period of time really damaged the ecosystem. I guess it happened right when D had its first big burst of enthusiasm, and that severely damaged the languages uptake. Residual effects still linger to this day. I wasn't there at the time, I missed that fun :)
That looks very promising, I'm especially looking forward to a talk by Chandler Carruth (keynote even), as those are always very interesting and entertaining. Which leads me to my actual question: will the talks be available online afterwards (YouTube or similar) or even streamed live? Couldn't find that information on the site.
a method is just a function that has "this" as an implicit parameter. So returning a reference works the same.
When you write: class X { int data; public: int &amp; fun() { return data; } }; X x; x.data() = 12; it's similar to: struct X { int data; }; int &amp; X_fun(X * this) { return this-&gt;data; } If you understand how you can modify a global variable via a returned reference, i.e.: int x; int &amp; function() { return x; } function() = 12; // equals to "x = 12;" you should not have a problem understanding that it's the same thing with a member function.
This is an example that I understand : function ( &amp;x ) { x=x+2;) int main() { int y; cin&gt;&gt;y; //y=10 cout&lt;&lt;function(y); //y is 12 The example with struct seems too difficult. So I still have problems with understanding. :(
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6emib6/problem_with_methods/dibeddm/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
 int y = 10; int x = y; x += 2; // here, y = 10, x = 12 but with references: int y = 10; int &amp; x = y; x += 2; // here, y = 12, x = 12 because "x" is using the same memory than y (similar to a pointer, but different syntax) That "x" is the parameter of a function is irrelevant. It is an "alias" to it's argument (in your example "y"). So when you change one, the other change too.
&gt; In particular, ASIO was serving the contents of a file from the file system, while Pistache was serving some data it generated internally. ...that's a pretty big difference.
Even more painful, trigraphs were in Phase 1 of lex. The result of this was that it happened before EVERYTHING else. The result was that they could do some really funky and unpredictable stuff. For example, Phase 2 is replacing the '\' followed by a new-line character with 'nothing' (with some exceptions for raw string literals). Phase 3 is tokenization, which, (I believe) is when digraphs come into place, which is a MUCH more sane place for that to happen. My favorite 'coding test' that I would use to torture new coworkers was something like this: int main() { int i = 7; //What is the value of i after the following line??/ i += Some_Really_Insane_MathSTuff; } Sadly, MSVC stopped enabling trigraphs by default, so I started having to send project files. Then, the Visual Studio code-coloring showed the line as a comment, and people got hip to this trick.
why? you need to modify its source code?
What do you mean? Can I use qt in production without a comercial license??
&gt; That's too narrow. "same type" doesn't affect function templates. In your hypothetical f, f&lt;anything&gt; is of the type void(). But you still have to answer if they are the same function template specialization. Thanks! I'll expand upon this a little. &gt; And that's where the problem comes into play. Oh, I'm not sure I follow this part. Do you mean there's only a problem for function templates? because different instantiations of function templates can still have the same type? Doesn't it still come down to being able to reliably perform equality comparisons? &gt; The fact that every instance of your CONSTANT is a distinct type even with the same constant should be mentioned when you introduce the macro, rather than buried in a subsequent section. This effectively resolves the "equality" problem by saying "never equal". Yes, that's a great idea. I'll move that part up one section. Thank you for the feedback!
Or sticking with golang. To be honest, I don't think that performance will have great impact with GUI apps, but c++ feels more native to me idk. Go compiles to binary as well, if I'm not gonna find a good one, gonna use go.
It really depends on what you are trying to do. Golang is great language for almost everything. But when you need that extra performance you might also settle for c++. As suggested Qt is a great GUI framework that also has Go bindings. 
Yes, the only requirement is that your users have to be able to swap the Qt portion of the program for their own. ~~So Qt has to be linked dynamically, and the user has to be able to replace the .so/.dll files of Qt.~~ An easy way to do that is linking Qt dynamically, and letting the user replace the .so/.dll files of Qt. The children of this comment for the alternative. Edited for accuracy, in response to /u/doom_Oo7's reply.
&gt; Boost.Asio internally uses "raw" system calls too? Sure, which is all the more reason to just use Boost.Asio rather than rolling your own. Why would you want to worry about doing C-style error handling around raw system calls, cross-platform support ([the author of Pistache admits it only supports Linux](https://www.reddit.com/r/cpp/comments/6ehhqe/has_anyone_tested_andor_reviewed_pistacheio_c/dib3zy1/), presumably because this work hasn't been done), et cetera when Boost.Asio has not only done it for you, but has done it for you and been much more thoroughly tested and reviewed than I think Pistache ever will be?
Who said OP wants to write an industry-ready cross-platform REST library? I personally enjoy doing stuff on my own without relying on any external library. Sure, you might be slower than boost, but at least you have control over the implementation.
Also look at wxWidgets. Its license is more permissive than qt (although I think qt will work for you as its LGPL) 
Ok my bad, I thought OP wrote the library, which is obviously wrong. Sorry to waste your time.
No. It's LGPL. As long as you don't modify their code, you're fine linking against it.
Everyone seems to hate `[&amp;]` and `[=]` here, but there's a use-case where they're perfectly OK: std::for_each(..., [&amp;]{...}); In general, if you're using the lambda in a way that it doesn't outlive the current scope (which is quite common if you're using certain functional patterns), it's perfectly fine to use default capture clauses.
Your main choice would be Qt, but not sure you want to go through the LGPL hassle. Also Qt is not really modern C++. It's quite good otherwise though. Also you can go for two separate libraries, one for http and one for GUI. Choose the best in both domains. For networking maybe you want Asio (standalone) or cpprestsdk, not sure what exactly you want to do. For GUI the choice is actually a bit harder as you want good looking (native) style and accelerators with Alt, tabbing and keyboard shortcuts and stuff like that presumably, which most C++ libraries like Nana not support probably, last I checked.
Can you link to the actual announcement, as the title suggests? Can't find it. I only see Chandler and Jason, which have already been on the page weeks ago, so nothing new?
**Company:** ESI Group **Type:** Full time **Description:** ESI Group is a leading innovator in Virtual Prototyping software and services. We make sure our clients can bring their products to life, ensuring reliable performance, serviceability and maintainability. ESI US R&amp;D, Inc., is currently seeking a Software Development Engineer at our San Diego, CA offices. Just a mile from the Pacific Ocean, we are a small team focused on developing and maintaining desktop software applications in the field of vibro-acoustics simulation. Our clients include NASA, Boeing, Airbus, GM and Ford. We are looking for people with a Bachelor's Degree in Computer Science/Engineering/Mathematics. We use C++ and Qt for our desktop applications. Also desirable is experience with numerical methods, OpenGL or other 3D APIs such as OpenSceneGraph, Python, HPC tools and APIs such as MPI, and Windows/Linux development. We are open to more Junior candidates that have a solid understanding of C++ fundamentals. **Location:** San Diego, CA **Remote:** No **Visa Sponsorship:** No **Technologies:** Mostly C++11, Windows and Linux, all depends on project. We use Qt for our GUI. Some 3-D visualization with OpenGL/OpenSceneGraph. Python for scripting. **Contact:** I work here, send me a PM and let's talk! Alternatively, go ahead and send an e-mail to Tracy at ext-tracy.sidall@esi-group.com. Don't forget to mention Reddit :)
FIrebase API, but I think that there's already an official library that does that ;)
Yes. It's very common.
&gt; Deploying libraries or maintaining a build system when there are dependencies on boost is not particularly trivial either (unless we're talking headers only libs, of course). find_package(Boost 1.58.0 REQUIRED filesystem program_options thread) add_library(my_lib ...) target_link_libraries(my_lib Boost::boost Boost::filesystem Boost::program_options Boost::thread ...) Truly excruciating. I can see why you'd much rather write and test your own. I mean writing a few multi-thousand line libraries and testing across platforms and versions vs. 3 lines of CMake. The choice is clear.
Facinating; Loved it! I wish more people wrote about template metaprogramming :S
Obligatory "LGPL requires dynamic linking" reaction comment : **NO.** You **CAN** statically link LGPL libraries to your code, as long as you provide object files that would allow relinking. Source: https://www.gnu.org/licenses/gpl-faq.html#LGPLStaticVsDynamic 
Sure, but let me clarify a bit. When you set the next PC, you might not know the instruction you're pointing to is a jmp. Maybe you just know the size, so you do PC+4. A few pipeline stages later you decode it and realize this was a mistake, so you flush your pipeline and write the correct next PC into your branch history table. Then the next time you hit that address, you look up the PC from the branch predictor and realize it's a jmp, even without decoding the instruction, and you get it correct the second time around.
After the first access, the file will presumably be cached. Though I (we?) don't know enough about the test to know what syscalls, if any (after the initial access), it will end up using as a result of using that file.
I'm absolutely in agreement that it would be better to be using the same file and data for the transfer. We just don't know how close of a test it is, at all. It could be pretty close, or not at all comparable really. As jcoffin said though, he wasn't trying to get a definitive answer, just a ballpark idea of its performance viability. He was very forthcoming about the limitations of the test.
&gt;I don’t like macros either. But at least this is a pretty simple one. The simplicity/complexity of a macro has nothing to do with macros being bad. A macro being simple doesn't excuse using macros. In fact I'd argue the simpler a macro is the **less** reason there is to use a macro since that reduces the value a macro adds.
I'd assume the front end instruction decoder recognises the `jmp` instruction immediately, rather than just consuming instructions linearly and then realising later that one of them earier on was a `jmp`? So you reckon the BTB or similar is involved here? It seems a waste of resources to use limited size CPU lookup tables for something that can be statically determined. I can't see anything in Anger Fog's microarchitecture guide about static jumps under branch prediction, only actual branches, ie things with &gt;1 outcome. But I guess we are getting into the minutiae of how the CPUs instruction prefetcher works, which I'm not sure is even published 100% and may vary between CPU generations. But I guess the point for the OP is it's cheap/free.
Wait, when do I have to pay for Qt then? Only if I change the sources? Edit: Nevermind. I found out in the [GPL FAQ](https://www.gnu.org/licenses/gpl-faq.html#GPLRequireSourcePostedPublic). If you never publish your binaries, and for companies that means publish *outside* the company, you don't have to publish the source and can use even GPL'ed code (you don't even need LGPL) without problems.
As long as you link it as shared library... Yes
Right, this is an attractive option. There are couple of wrinkles I'll point out. ##### Often, you actually need the exact type. One such case is when the function argument is deduced. Consider the following case: template &lt;typename Tuple&gt; void f(Tuple t) { static_assert(std::get&lt;0&gt;(t) == 101, ""); // error: no matching function call to get. static_assert(std::get&lt;1&gt;(t) == 202, ""); } f(CONSTANT(std::make_tuple(101, 202))); This doesn't work because `std::get` deduces its argument, to `std::tuple&lt;Ts...&gt;` for example. The argument needs to be actually of that type. Implicit conversions are not an option here. ##### Once they become values, we're burdened with propagating them through composed functions properly. Let's build on the previous example a little bit: template &lt;typename Elem&gt; void g(Elem e) { static_assert(e == 101, ""); } template &lt;typename Tuple&gt; void f(Tuple t) { g(CONSTANT(std::get&lt;0&gt;(t.value()))); // already know we need `.value()` here. } f(CONSTANT(std::make_tuple(101, 202))); This causes the following error: error: reference to local variable 't' declared in enclosing function 'f&lt;R&gt;' g(CONSTANT(std::get&lt;0&gt;(t.value()))); ^ That is, we need to thread `f`'s argument `t` through to the usage. We can do a `=` capture for the lambda, but that doesn't get us all the way to inside the `R`. If we keep it as a type, all of this goes away. We can indeed do better with `constexpr` lambdas. But since I'm not yet writing C++17-only libraries / code, I decided to just with types for now. If you're interested in how we can get more value-y in C++17 with composed function calls and such, here's a [sketch](https://wandbox.org/permlink/GQbuSBpxQvws9QpC)
Qt is LGPLv3. Closed-source code and LGPLv3 is not that big of a deal. On request, you have to provide source code for Qt that you've used and with whatever is needed to re-link your product with the Qt. With dynamic linking, it's a no-brainer as one can substitute their own Qt dlls. With static linking, you need to provide a static library with your code to be statically linked with Qt. 
That's **wrong** and is a myth. See [my comment above](https://www.reddit.com/r/cpp/comments/6enpdi/looking_for_a_good_gui_library/dibz21q/?st=j3eujf5i&amp;sh=cf93bde9). Whether you modify the code or not is **irrelevant**. Your obligation under LGPLv3 is to provide source code to Qt *on request*, and to facilitate the user re-linking the Qt to the rest of the product.
&gt; Only if I change the sources? **Changing the sources doesn't matter**. LGPL compliance requires that you provide - on request - the *exact sources* of Qt that were used to build your application, as well as the configuration settings and any other data needed to rebuild Qt so that it can be relinked. Your obligation to provide sources to Qt is *always* there when you license under LGPL, and modifications are irrelevant.
OP used the term "GUI library" somewhat incorrectly. They meant an application development framework.
The implementation is about a page long. Use your own :)
Two notes: First C++17 and constexpr lambdas help on that topic. Instead of having to use a lambda to generate an "anonymous type" with a constexpr member function by using a local type and returning it, now you can use a constexpr lambdas which is by definition anonymous and constexpr. Björn Fahller explores this here: http://playfulprogramming.blogspot.se/2016/08/strings-as-types-with-c17-constexpr.html Second, you cannot use your CONSTANT\_VALUE with decltype since decltype rejects lambdas. So no: `decltype(CONSTANT_VALUE(std::make_tuple(101, 202))) t;`. I guess you can get around this by creating an "anonymous type" manually by using some macros to generate unique identifier (something with \_\_FILE\_\_ and \_\_LINE\_\_ and other dirty stuffs) to name a struct that contains your static constexpr value member function. 
You can also use this to mimic overloading on `constexpr`-ness, using `if constexpr` (I'm sure this can be prettified using Boost.Hana somehow, because it allows you to write `42_c`). #include &lt;cassert&gt; #include &lt;type_traits&gt; template&lt;class T&gt; constexpr auto is_integral_constant_v = false; template&lt;class T, T t&gt; constexpr auto is_integral_constant_v&lt;std::integral_constant&lt;T, t&gt;&gt; = true; template&lt;class T&gt; constexpr auto is_intlike_v = std::is_same_v&lt;T, int&gt; || is_integral_constant_v&lt;T&gt;; template&lt;class T, std::enable_if_t&lt;is_intlike_v&lt;T&gt;&gt;...&gt; auto fun(T x) { if constexpr (std::is_same_v&lt;T, int&gt;) { assert(x == 1); } else { static_assert(x == 42); } } template&lt;int N&gt; using int_constant = std::integral_constant&lt;int, N&gt;; int main() { fun(1); fun(int_constant&lt;42&gt;{}); }
Hey Paul! I left a reply to /u/hanumantmk regarding the use of values rather than types, let me know what your thoughts are. I didn't use the `operator()` because I wanted to keep myself straight and using `.value()` helped me associate them to `CONSTANT`, rather than being confused about which places I'm invoking functions vs where I'm merely getting values out to call functions with, etc. If the use of `operator()` isn't a burden though, in C++17 I'd probably just opt to pass constexpr lambdas around :)
I am against MOC. But this is incorrect i think. MOC does generate C++ code. That's all. Please correct me if i am wrong.
You could use 2 different libraries, one for UI and one for networking. What's wrong with that?
Thanks, i will.
Actually, I think in C++17 I would just drop the macros entirely: #include &lt;tuple&gt; template &lt;typename Elem&gt; void g(Elem e) { static_assert(e() == 101, ""); } template &lt;typename Tuple&gt; void f(Tuple t) { static_assert(t() == std::make_tuple(101, 202), ""); g([=] { return std::get&lt;0&gt;(t()); }); } int main() { f([] { return std::make_tuple(101, 202); }); }
I use boost, and I use cmake. And those 2-3 lines, while simple, hide A LOT ( I had to debug cmakes own FindBoost.cmake today, I think it's about 2000 lines of code). On unix-like systems, one can make a safe assumption that boost is already present one way or the other. On OSX, for example, it's easy to install it with homebrew or macports. OSX scenario: So I copy those "excruciating" lines and cmake finds boost, yay! Job done. But my app uses c++11/14, and for whatever reason the build of boost that I got thru macports or homebrew, wasn't built like that. Best case scenario, everything is fine. But boost has conditional compiles in places, where the implementation or the interfaces may be different for modern c++. Worst case scenario, everything builds and links fine, but when you run your application, there's a static initialisation error somewhere in boost code, and good luck debugging that. So now, to play it safe, you need to build boost with the c++11 flag yourself, just in case. Again, little harm, can also he done in 3 "excruciating" commands. Once you figure out the way to tell cmake, often stubborn, to NOT find the macports/homebrew version (you need to delve into the FindBoost documentation to find the exact name of the variable), you can go ahead and build and now you got rid of the bizarre runtime error. So after you build your library or app with cmake using the "install" build, you have a pristine new library/app that has a hard-coded dependency to a library called "libboost_thread.dylib" (we're still in Mac). So when you run your app, guess which one the dynamic loader picks up? The one in /opt/lib (macports or homebrew), with the runtime error, because that is considered a system path by the dynamic loader and it always looks there. So once you figure out that the Apple recommended way is to prepend "@rpath" to the library install names, and let the executable provide the rpath, perhaps relative to its own location, you go and figure "oh, I should build the boost libraries so that they have the recommended setting. But good look finding that option anywhere in the B2 build tool. Cmake has a simple way of doing it, but boost isn't officially built with cmake. Other 3rdparty libraries that provide prebuilt binaries, such as Qt or TBB, actually do follow this setting correctly. The problems mentioned above? All fully gone if you go with the standard &lt;thread&gt; and &lt;filesystem&gt;. As per my previous message, my emphasis was on deployment and build system. If the goal is to develop a library that others will use, you need make sure that they'll be able to successfully build and link against it if necessary. If it's a headers only library, and it uses boost (headers only or not), do you provide boost? Do you rely on the user getting the right version of boost? Is there any guarantee that boost or whichever portion of boost your library uses will remain code compatible? Binary compatible ? Binary compatible depending on compiler options? Boost is many components and it's too flexible in how you can build it (on nix based system you can make the safe assumption that they're built as dynamic libraries. On windows there's so many damn build options and that bizarre naming scheme it's too much). Take TBB for example. It's always shared, it always has the same name, it is backwards compatible, and the only thing you have to consider to use it is that your c++ runtime is backwards compatible with whichever c++ runtime tbb was linked against when it was built. With boost it depends on which boost component, whether it is a library or headers only, and if it's the latter, how it was built. If your product is a library that does things, it is always safer to shield your developers from any headaches. But what do I know... 
There are 8 speakers now. If you wait a few seconds on the page, it counts up and shows the rest.
It would be nice if they were. I guess they have to make a decision to either nice people to come in person because it's a relatively remote location or have the videos online which might desuade people from coming. Having videos online would promote the quality of the conference though. Having a delayed upload might be a good compromise. I'm going so I'll be happy to being my dslr for recording if they need it.
I agree that making the `tuple` constant is the thing getting in the way, and that's because `tuple` is just a stand-in for any literal type that we may want to pass around as constant. Of course in the specific case of `tuple` we could've by-passed the whole thing and passed two `int`s via non-type template parameter. Maybe I'm not following your point. Hm, that's interesting. That code doesn't compile for me on clang, but does on gcc... It complains about a reference to local variable.
&gt; LGPL compliance requires that you provide - on request - the exact sources of Qt that were used to build your application So what happens when you simply use one of their packages, like I imagine most people do? I don't distribute, but if I did I'm curious what the legal implications are there. I just statically link with their stuff on Windows for example, (which are just helper libs, as the application then searches for the dynamic libraries in the path). I install their packages. Would I tell them "Whatever you packages in 5.9.x"? These distributions don't even come with Qt source, I can't give it to them! They have it!
&gt; // yes, this is the correct signature I'm not disbelieving, but I've never seen that, what's that about? Or is it just an example of what you do?
~~I've added an issue.~~ (edit: added in master, with example) It's pretty trivial to implement in CLI11 internals. If you solve it in the same manor as the poco solution, setting up callbacks, CLI11 could do it. But that's a much uglier solution than the one I'm thinking of.
It looks quite powerful and the API docs are nice. Good work! A couple of issues: * The name of the Github release is the direct name "CLI11.hpp" which is not how the library itself expects to be used * On Windows, I got a 'getenv' unsafe warning with msvc "/W4" enabled. You could do with slightly changing at least one of the examples to show how an option is typically used. Is ".count()" the normal way to detect an option, for example? What if it is a defaulted option value? A mention as to what a subcommand is from a user's perspective could be handy since the term appears in the help output, and how it interacts with positionals from a dev perspective. Is there a hook into the help system for the subheaders like the "Subcommands" title? Does CLI11 support aliases, i.e. multiple (--)long name options? Is a variable and its name always required for adding options or is there some alternative way to add? What is the purpose and what can you do with a set?
[This one doesn't look toxic](https://blog.qt.io/blog/2017/05/31/qt-5-9-released/#comment-1199796).
The good about WxWdgets is that uses native OS widgets and binary size is small if compared to Qt. But unfortunately the documentation is poor, the layout management is tricky(imo) and there is no a good tool like Qt Designer.
Please read the sidebar.
I am trying sciter (https://sciter.com/) and i think it just perfect if you do mvc, the gui will be html/css and the source code C++, you will have the best of both worlds and it allows incredibles things, look the images at their web, fully customization is assured
Wow, I've never seen this before. So you're making a tuple just to serve as a variable that can be captured for use in the lambda? Is this function example, if I"m understanding it correctly, returning a lambda that captures the given variadic arguments? What's the use of `std::apply` in that context?
You won't believe it... even Bjarn himself is looking for it :D
It looks like this is trying to solve a more general problem of lifetimes of stuff, but only with lambdas. Since the more general problem is not solved in C++, how can it be solved in a more specific situation? And from that perspective, *should* it be solved in a specific case?
Ok to be fair the term *restful* appears also in many other library description with different languages. So lots of people seem to consider REST just as a synonym for talking http with different endpoints. Sadly that simplifies the proposal too much and shadows the true difficulty (and foundation of the solution) of navigating through your application states without pushing deep knowledge about the processes to your clients.
&gt;Once you figure out the way to tell cmake, often stubborn, to NOT find the macports/homebrew version (you need to delve into the FindBoost documentation to find the exact name of the variable) Do you want to be taken seriously or not? You have to **delve** into the FindBoost documentation, are you serious? I Googled "*FindBoost*" and [this was the top result](https://cmake.org/cmake/help/v3.0/module/FindBoost.html). What else do you complain about? The fact that compiler errors don't also spit out relevant man pages so you have to go to cppreference.com? None of what you're saying justifies rolling your own replacement for basically any Boost library, especially when you consider that if you're that bent out of shape about dynamic linking you can just statically link Boost. And before you complain about how no one knows how to do that I googled "*build boost static*" and [this was the top result](http://www.boost.org/build/doc/html/bbv2/tutorial/linkage.html). In case clicking that link is too laborious compared to rewriting all of Boost I'll sum it up for you: ./bootstap.sh ./b2 link=static Seriously, stop inventing justifications for your [NIH syndrome](https://en.wikipedia.org/wiki/Not_invented_here) and just use Boost. Even if it was every bit as bad as you say it'd **still** be significant time and labor savings over rolling your own.
docopt.cpp seems more simple, but powerful to me.
&gt; I don't understand all the drama around macros. Is this code well-formed? #include &lt;iostream&gt; namespace my_namespace { void assert (bool val) { if (!val) { std::cout &lt;&lt; "Assertion failed!" &lt;&lt; std::endl; } } } int main (int argc, char ** argv) { my_namespace::assert(argc == 1); } How about now? #include &lt;cassert&gt; #include &lt;iostream&gt; namespace my_namespace { void assert (bool val) { if (!val) { std::cout &lt;&lt; "Assertion failed!" &lt;&lt; std::endl; } } } int main (int argc, char ** argv) { my_namespace::assert(argc == 1); }
&gt; so I'm guessing wide-char / Unicode support What makes you think that `std::string` and Unicode are mutually exclusive given that `std::string` is just another name for `std::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt;&gt;` and that the type of a UTF-8 string literal is `const char [N]` where `N` is the number of UTF-8 code units in the string plus one (for a null byte)? Or are you from Windows land where "*Unicode*" apparently means UTF-16LE (which isn't even real UTF-16) and nothing else?
Where in the standard does it talk about disabling exceptions?
&gt; foo_error should derive from a standard exception class, like std::runtime_error of course. And probably *only* `runtime_error`. I'd also note that for logic errors (anything under `logic_error`) you should throw the standard errors – they aren't things you should really be handling at runtime anyway, so you don't need to handle them.
Honestly, I'm with you on some points but can't be with you in all. Some boost libraries are the actual base for the standard so that means something, they are good, exceptionally good and in some cases, I still prefer them over the ones deployed with the compiler but boost is not bug free, especially the not so much used libraries. I have run into some bugs super hard to find because I trust this set of libraries. Another point is regarding build systems or CI systems, it is pretty naive to argue that including 3 lines in CMake will solve all your problems with the compile and linking phase, I'm working on a big company and I have friends and familiars on facebook/amazon/google/... and we don't use cmake by default, we use it at some points but not as the "build" script. It may be included in some parts but this doesn't elude that boost is hard to maintain in a CI environment when you have to release stable builds to customers and keep it updated to fix bugs.
I don't think I have, at any point, made any attempt to justify this man's choice of not using boost asio and rolling on his own. I agree he should've used boost. My point was that blanket statements in favour or against "all" of boost are moot, because each library inside boost is different in terms of whether it is headers only or not, whether it is periodically maintained, the documentation is good or not, the interface is more or less stable or not. Boost is a really big collection of things at this point. And you seemed to completely miss my point about the rest. Yes, static boost is a solution and straightforwars to build. And yes, theres a Boost_USE_STATIC to tell cmake to ignore the dynamic ones it favours by default. My point was the journey to get there from a seemingly innocent call to FindBoost on Mac to going through weird run time errors to eventually having to either build boost statically (easy), or rewrite the install names of all the libraries I needed (also easy, once you understand why you have to do it). But frankly, not with my time dealing with an extremely condescending chain of comments that are overtly rude. You have yourself a good day.
&gt; you're making a tuple just to serve as a variable that can be captured for use in the lambda? Yes. &gt; Is this function example, if I"m understanding it correctly, returning a lambda that captures the given variadic arguments? Yes, it captures them inside a tuple. &gt; What's the use of std::apply `std::apply(function, tuple_of_arguments)` calls the function with the elements of the tuple as arguments: `std::apply(std::min, std::make_tuple(2, 3))` calls `std::min(2, 3)`.
Maybe try forcing your browser to reload the page, there are definitely 8 speakers on the page now.
See http://www.open-std.org/JTC1/sc22/wg14/www/docs/n1256.pdf section 5.1.2.2.1
got PTSD from looking at the example software that use it.
That kind of makes sense, but does it produce better asm? Kind of pointless to stray from the defaults if there is no good reason.
"Has to include networking features like http requests". It is not GUI
Is it possible to make a prefix-command with CLI11? See https://stackoverflow.com/questions/37996617/create-a-prefix-command-with-boost-program-options
Every time I encounter some C/C++ library, I first look into string handling and encoding/decoding. Most of the time I will be disappointed in that these libraries will only work out of box in an ASCII only/pure UTF-8 environment. If you need Unicode (especially in a cross platform way) you have to do a lot more.
Small String Optimization. I am not sure if a command line argument parser is generally the place to worry about optimization (depends on use case), but I would imagine SSO fits the bill for this perfectly.
This is very easily done with [ProgramOptions.hxx](https://github.com/Fytch/ProgramOptions.hxx): [complete source](https://gist.github.com/Fytch/86e63f073afa2ab2e2d0f333212e5d67)
Almost. If you don't have any overlapping flags, yes; just use allow_extras. If you know what the allowed commands are, use subcommands with no fall through and allow_extras. The only case that wouldn't work currently (but probably could be added) is arbitrary commands with overlapping flags.
Not necessarily better assembly output, but you don't have to provide overloads for both `string const&amp;` and `string&amp;&amp;`. Plain old `string` covers both cases: it generates a copy in case of `const&amp;` and is moved in case of `&amp;&amp;`.
Unfortunately the prefix program must work for arbitrary programs. Therefore overlapping flags can not be excluded. It actually even should work on itself.
Specifically this bit from 5.1.2.2.1:2: &gt; The parameters `argc` and `argv` and the strings pointed to by the `argv` array shall be modifiable by the program, and retain their last-stored values between program startup and program termination. 
I would also like to know what redditors think about [Meson](http://mesonbuild.com/).
&gt; boost is hard to maintain in a CI environment when you have to release stable builds to customers and keep it updated to fix bugs. I can't say I can understand your line of reasoning. Boost is open source software. If you're worried about there being bugs in Boost you can fork it and maintain your fork. The more important/interesting question here is: What's the alternative? So you don't want to use Boost because it's allegedly difficult. What're you going to do instead? Is writing a replacement for the N libraries you'd benefit from using from Boost really easier than just forking Boost, figuring out your build scripts once, and patching Boost as necessary? I mean sure, Boost probably contains a few bugs. Your replacement for Boost won't? So you're going to either have to fix Boost (which could benefit not just you, but the open source community-at-large!) or you're going to have to fix your replacement (which just benefits you), and then there's the issue of writing the replacement in the first place.
&gt; My point was the journey to get there from a seemingly innocent call to FindBoost on Mac to going through weird run time errors to eventually having to either build boost statically (easy), or rewrite the install names of all the libraries I needed (also easy, once you understand why you have to do it). And my point is that even if you're a complete beginner wading through all of that (you aren't) it will **still** be vastly faster than rolling your own, especially when you consider the ongoing maintenance costs of rolling your own. &gt;But frankly, not with my time dealing with an extremely condescending chain of comments that are overtly rude. I apologize for that. Having dealt with game developers extensively I go from 0 to 100 pretty fast with anything approximating NIH syndrome.
I get that a lot of these template tricks are fun and I enjoy them also, but I think some people get carried away with them and create too much tmp code that doesn't do much. How is detecting if a type is incrementable useful? If a function tries to use that operator on a template type parameter variable, and the operator isn't implemented, then it just doesn't compile.
Aren't they different things?
I've been toying with the idea of generating a project that can be used for benchmarking C++ build systems. It will be synthetic (so that different build system support can be generated easily) but it's probably better than nothing.
Added in pull request.
There's a minor typo: where it says "It’s not going to work because the variadic pack template... Ts is going to eat up all the template parameters", you mean "typename... Ts"
Can you add [argagg](https://github.com/vietjtnguyen/argagg) and [args](https://github.com/Taywee/args) and your thoughts on them to the 'other libraries' section? 
This is a very well known issue with macros, so, as an experienced C++ programmer, you'd weigh this and things like this while considering whether using a macro is a good idea in a given situation. Because sometimes all template metaprogramming tricks are exhausted and you make a choice between: 1) write hideous, boring and error-prone bolierplate 2) write your custom C++ code generator 3) use a simple macro Sometimes (3) happens to be the best choice.
All good points. I would just like to emphasize the importance of correct incremental builds. We lost so much time tweaking LLVM / Clang where CMake would get confused when we added a file or checked-out a branch. It was often easier just to delete the build folder and try again. In the end we ported the build process to Buck. There are still some optimizations to do, but it already a massive improvement (not just for correctness but also speed). When debugging, it is crucial that you can have confidence in your build system! Buck has good IDE integration for Java projects, but none for C++ as of yet. This is something we would like to contribute if there is much demand. 
For Buck they (optionally) integrate with a service called Watchman that detects file changes. It is incredibly fast! 
Are these recorded? I'd be interested in listening to the CMake talks.
Please make searching and posting REMOTE jobs easier and explicit.
Alas, there are many thriving job sites with steep prices, so that certainly works.
&gt; ‘I built C++ primarily for myself and my colleagues’ What did they ever do to you?! **I KID! I KID!*** I actually quite like C++ (most of the time).
The Android NDK has a Clang-based C/C++ Compiler that you can use to compile your project. For Android, you can wrap it in a very small IDE project: https://stackoverflow.com/questions/14914970/wrapping-a-c-command-line-executable-in-a-standard-android-application
Is this a console application or a gui application? If it's a console application then you can compile the source code on the table itself(android) with Termux and run it from there
So you just reinvent `is_detected` but implemented with some much_longer_names. In a world with the detection idiom toolset in the standard library - and with an implementation readily available from cppreference and elsewhere - what's the point of this article again? And inaccurate names, too. The point of `void_t` is not to "try to instantiate" the type; the instantiation is done whether or not the type is wrapped in `void_t` or `try_to_instantiate` or whatever "expressive" name you try to give it. The point of `void_t` is to map the resulting type(s) to a single, well-defined type so that you can easily do partial specialization matching with it.
They are different things.
I missed that, thank you for bringing it up. I've included your remark in the body of the post.
It's a console application, but to attempt a GUI based one would've required at least Qt or some other framework that I'm unfamiliar with. I'll dig into Termux and see what I can do. Thank you!
Would compiling the C++ code via this method work as it would any other IDE/compiler, or would I need to adjust the source code to meet the different kinds of format that it uses? And thank you for the suggestions, I'll look into them!
I personally like it but mostly because I'm the original creator and lead developer. :) If there are any questions about Meson post them below and I shall do my best to answer them.
&gt; The thing is, all the build tools will be roughly close to each other because on large builds the build system can't do anything as the time is dominated by compilation. You'd expect that to be the case, but I've seen the build times of clean builds cut in half by switching from make to msbuild, and msbuild isn't exactly fast. The difference was due to that the project had lots ands lots of very small files, so the overhead of launching several processes per file compiled (which is more expensive on Windows than on the platforms Make was designed for) ended up taking longer than the actual compilation. Switching to a "faster" build system *usually* isn't going to be very useful, but it's not impossible.
The code shouldn't need changing, the NDK is pretty much just a Linux system. The configuration/building is a little bit of work, but the NDK makes it pretty easy.
[It will](https://blogs.msdn.microsoft.com/vcblog/2017/05/10/c17-features-in-vs-2017-3/). :-]
So wait. The article uses "instantiate" types in a template expansion. But that's not how I use "instantiate" - which means "creating an instance of a type". Isn't the phrase "template substitution"? So for example it should be `try_to_substitute`?
How does it cope with pointers transported through uintptr_t (and perhaps arithmetic done there before converting back to pointer)?
I am taking bets on if Sagrada Familia or Boost.AFIO will be completed first. ;)
While that is true, I think I prefer well-developed, well-thought out features over half-baked ones.
Yeah, make on windows is crap because process creation is unnecessarily slow (it's the only major OS where that's true) and nearly everything is a new process in Make. However, the question is about CMake vs Bazel, buck so it should be moot since you would use Ninja or VS as the build system w/ CMake for any real development.
I've used both pretty extensively at work, and use Bazel for my hobby projects. They're great to work with, so long as you buy into the monorepo pitch. Hermetic, reproducible builds are good, the library compartmentalization they force is nice, etc. The remote compilation / caching that's coming down the pipeline is exciting. The big problem is that they're a little bit all or nothing -- whatever third party project you want to depend on probably assumes an autotools deployment strategy: you download, make, and install your dependencies in a way your project doesn't need to understand, and then find them in whatever directory you installed them to within your project. There's a lot of problems with this way of doing things, but the reality is that you can't rewrite the world, and will end up either making a build target that just globs together all your dependency's sources, or else invokes its build system from within yours. A secondary problem is that the portability story is a little meh -- it's much harder to do feature detection the way you would in a configure script (and Windows is a little bit of a second-class citizen for Bazel, although that's changing quickly). On balance I think using them is a pretty good decision if you're an organization deploying internal binaries for your web app (or whatever), but if you're releasing something open-source it's not a good choice. A data point that I think is informative: *everyone* I know who's spent some serious time using blaze derivatives (Buck, Bazel, Pants, and I think a couple more?) spends most of the rest of their career missing them; people become fans. I don't think I've ever met anyone who regards CMake (or autotools, or ...) as anything but a necessary evil.
If you're looking for something more robust to correct English, I suggest you look into [Antidote](http://www.antidote.info/en). Disclaimer : I work on this software.
I once taught a class and a student wrote variables named happy, happy1, happy2 and so on. He got points off for non descriptive variable names, but I shudder to think what beginner students get up to now.
Great question! I had a look at your repository. You are providing interfaces called "asynchronous initiation functions." They do what the name suggests; namely, start an asynchronous operation! The very best way to do this is not to use coroutines at all, it is to follow the "Universal Asynchronous Model" described in N3747 (http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3747.pdf). Take for example your handshake function here: https://github.com/KayEss/pgasio/blob/e1e967ecc61afddc8f2d473300b1eae55b2861e1/include/pgasio/connection.hpp#L21 You are requiring callers to use coroutines. But you don't have to. If you implement the extensible model, callers can not only use coroutines but also futures, completion handlers, or user defined types. In fact your interface can support EVERYTHING, including the coroutines in Boost.Asio, the coroutines in Boost.Coroutine, and the coroutines in the standard library! A better signature for your handshake function signature could be: template&lt; class AsyncStream, class HandshakeHandler&gt; BOOST_ASIO_INITFN_RESULT_TYPE(HandshakeHandler, void(boost::system::error_code, connection&lt;AsyncStream&gt;)) handshake( AsyncStream&amp; stream, std::string_view user, std::string_view database, HandshakeHandler&amp;&amp; handler); The implementation of handshake would have to follow some rules in order to get all that to work. I can help answer questions if you open an issue on your GitHub repository and mention my username **vinniefalco** (or email me, at the address on my GitHub page https://github.com/vinniefalco). I have implemented all of this in Beast so there are plenty of examples for you to copy. In fact I have written a "composed asynchronous operation tutorial" (it uses Beast) which shows you how to write these initiation functions step by step in order to take advantage of Asio's universal asynchronous model. Note this model is very similar to the model in the Networking-TS N4656 (http://cplusplus.github.io/networking-ts/draft.pdf) so you will be ready for it. Here's the tutorial: http://vinniefalco.github.io/beast/beast/core/tutorial.html
Looks just like YAML
For me if constexpr + auto template parameters + constructor deduction + structured bindings do a lot to clean my code already. It is true you do not change "fundamentally", but only having if constexpr is a bless in my code.
you need write your [own adapters](https://blogs.msdn.microsoft.com/vcblog/2017/05/19/using-c-coroutines-with-boost-c-libraries/) to use asio with coroutines TS, and it's quite different.
I will be messaging you on [**2017-06-06 08:44:58 UTC**](http://www.wolframalpha.com/input/?i=2017-06-06 08:44:58 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/cpp/comments/6f06je/learn_how_to_write_proper_c_code_opencv/dieex3c) [**4 OTHERS CLICKED THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/cpp/comments/6f06je/learn_how_to_write_proper_c_code_opencv/dieex3c]%0A%0ARemindMe! 3 days) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! dieex7o) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Might wanna x-post it to /r/ProgrammerHumor.
I'm having some trouble understanding some parts. 1) If the template class has a single template argument template&lt;typename T&gt; struct is_incrementable&lt;T&gt; : std::false_type{}; Then how is it possible for the specialization to have 2 template arguments? template&lt;typename T&gt; struct is_incrementable&lt;T, void_t&lt;decltype(++std::declval&lt;T&amp;&gt;())&gt;&gt; : std::true_type{}; Is this always possible (specializing a 1 arg class template into a 2 arg class template)? 2) And why is the first argument (T) required. Why it doesn't work without it? 
Holy shit, I was convinced I was crazy until I read your comment.
I think you've missed my point: I said "if you're using the lambda in a way that it doesn't outlive the current (the one it's defined in) scope" For many functional programming patterns, if you were forced to list the captures explicitly, the pattern would stop being convenient, and you'd be making life more difficult for everyone for no reason.
You are absolutely right, but I wouldn't be to worried. You seem to have a spot on mentality. I would take that over average experience any day. Without mentoring it is essential to really take the time to understand an evaluate different design decisions before diving into implementation. This will hurt productivity in the short term, but pay of hugely in the long term. Still, lots of what you write will need to be improved or simply replaced sooner or later. Acknowledge that and write modular code from day one. This is also an "overhead" in the short term, but just make that investment. Also make heavy use of warnings as errors and linters. Almost like having a mentor if you do the research to understanding the relational behind the warning, not just blindly following all fix it hints. If possible go for clang/cmake based tool chain. Lots of good tools to easiliy integrate into your build environment.
I'd strongly recommend you to read anything written by Scott Meyers and Herb Sutter, [this](https://github.com/isocpp/CppCoreGuidelines), and take your time to watch most videos from GoingNative 2012/13 (at channel9.msdn.com) and CppCon 2014/15/16 (hosted on youtube). Also check out these websites: https://isocpp.org and https://meetingcpp.com , they will point you to other good blogs/resources to keep an eye on.
You will write bad code, we all do. All junior devs i have ever worked with have written small test programs to prove what they wrote works. They then throw those away. DO NOT DO THIS. Learn to use and love a unit test suite. once you have a test suite testing everything you ever thought to test, you will be very comfortable rewriting your bad code. Everytime you find a bug in old code, replicate it in a test before you fix it. AND KEEP THE TEST, AND RUN THEM BEFORE EVERY COMMIT. Once you know you are testing your code on each change, you can get away with fragile, you can get away with quick hacks to push code fast, as your tests catch when it breaks, your confidence in fixing things goes up, and your code will get better. Nobody ever shipped perfect software, but good developers can ensure the software they do ship does not get worse.
Would that be the commands as described in [ask ubuntu](https://askubuntu.com/a/915737)? $ sudo add-apt-repository ppa:jonathonf/gcc-7.1 $ sudo apt-get update $ sudo apt-get install gcc-7 g++-7
What's annoying about dlib's cmake scripts? 
Problem: The console seems to disappear as soon as the program ends. Correct solution: Learn how to use your tools properly. (Hint: Ctrl-F5 / "Run without debugging", or just run the program from a preexisting command prompt.) Incorrect solution: Modify the program to explicitly wait before terminating, in the most annoying way possible by using a platform-specific program, which means that if you want someone else to test your code they have to change it first to get rid of that crud. Besides, properly behaved command line programs do not wait for input before terminating.
Yeah, indeed, I also fully agree on those points. And unfortunately I don't have a good solution either. The most important part that needs a complete redesign is the "core" part. It's unquestionably horrible: type-safety is thrown out the window, there is unnecessary tight coupling, lots of bloat and run-time overhead, etc., etc. For matrices and linear algebra, we already have, say, Eigen, but there is not a single good image representation and processing library with a good design. Anything else should be a collection of separate specialized libraries, but the "thematic" split that OpenCV tries (imgproc, feature2d, etc.) is insufficient. In my previous job (related to real-time AR on mobile) I explicitly avoided any use of OpenCV throughout the entire production code base (quite successfully!). I wrote some excellent replacements for cv::Mat and many image processing and feature-based matching operations, but attempts to open up this code didn't go anywhere. And my own attempts at cleanly rewriting some of those things suffer from lack of time...
One of the biggest problems is that system("pause") is not portable - it works on Windows, and may work on other systems, but won't work on my experimental OS where the pause command is "florgl" (obviously a silly example, but I hope you get the point). When you want a pause, it's better to use methods that will have exactly the same behaviour in any environment.
Believe it or not, not all IDEs work the same out of the box, and some of them can be pretty hard to understand if the user doesn't even understand software development yet. There is literally no reason for all the condescension towards a new user who came seeking answers in an earnest effort to learn.
&gt;&gt; if its wrong why iam being taught this is my teacher an idiot Eventually,your teacher may teach you a better way. They just ask you to do it this way now to reduce the amount of new stuff you are being bombarded with right now. Your teacher is teaching you C++ and that trick is there to work around a behavior of the tool you are using to do your work. That trick is not necessary in [QtCreater](https://www.qt.io/ide/) for example because it [does the right thing out of the box.](http://imgur.com/a/YKrnJ) 
&gt; QtCreater Typo.
What alternatives are there to OpenCV though?
This whole thing of having to include dlib\_all.cpp or something like that (_Edit: I checked, I think it was dlib/all/source.cpp_), which I had to include in my cpp file, is quite annoying and I'd say pretty non-standard. It's even more annoying if you want to use dlib from your own headers-library. There was some linker errors and problems with #define's too that it wanted set but I couldn't set them properly. Also I had some issues with finding dlib's cmake variables correctly with find_package, I couldn't get the import target, I think I tried this with dlib as git submodule. I also remember that while there was some documentation (I landed on the FAQ several times), I don't think I was able to find a proper "hello world" example on how to set this all up. It was all a while ago, sorry I don't recall details. But it all seemed very non-standard way of doing things and I just wished it was a "normal" library with proper import targets and no ".cpp" file magic to include. Would make everything much easier. Or maybe that is possible and I got it all wrong, but I did spend a significant amount of time on this and browsed/searched the dlib page very extensively and even dug into a lot of dlib's cmake scripts.
They're using TypeErasure to be able to accept other objects ([see here](http://docs.opencv.org/3.2.0/d4/d32/classcv_1_1__InputArray.html))
I would definitely agree that OpenCV is not an example to learn modern C++ from, but most of the issues written there are way overblown. The interaction you usually have with OpenCV is usually so trivial that you hardly ever have any issues caused by its weird approach to coercion and types (I've used it quite a bit as a helper library for various machine learning tasks, also using its haar cascades, font recognition etc). Mat goes in, Mat or Value comes out, done. Yeah, it's a bit icky at first, but you get used to it. You usually immedately convert to some other type anyway, so the "surface area" touching OpenCV tends to be pretty small. Either way, there aren't that many alternatives, depending on what you need. A better recommendation in most cases is probably to suck it up and learn how to use OpenCV rather than to use a library that has a shinier interface but will be slower, have less features/more bugs, be less portable and won't work as well. Also, there isn't really anything wrong with deciding which internal algorithm to use to perform a task based on some const/enum/etc passed into the function, virtually every one does it that way (including e.g. armadillo and eigen) Some other stuff in there is totally bogus as well, like proposing GLM as a "lightweight" library to Eigen -- just adding GLM includes to my single-file project makes compile-times go from a couple of milliseconds to 5 seconds! It's one of the most template-heavy libraries out there, and you **really** pay the price in terms of compile-time. I'm not saying it's a bad library (and I use it), but it's nowhere near "lightweight". Also, while eigen is a great library, I think there are still reasons to use other libraries and/or to roll your own in certain cases. SuperLU for instance gave me way better performance than eigen on a certain sparse system I was working on (but I only tested on the particular type of system I was interested in, I never conducted any kind of "general" performance comparison)
Honestly, strongly disagree with this sentiment. There are 3 things in C++17 that really have the opportunity to change the way we write code: `if constexpr`, `std::optional`, and `std::variant`. If you ever write generic code, `if constexpr` is practically magical. You mean I can write all the logic I want in *one* function instead of having to tag-dispatch to two others??? `std::optional` and `std::variant` are long overdue to C++ and really change the way people think about how to solve problems. Sure, there are lots of implementations of the two and there have been for years, but there really is a big difference between simply having a `std::optional` and using `boost::optional`. Now that we have "baby's first sum types," we can really dive into functional programming. And once people really start using these a lot, it'll really push the motivation for language-level `variant` and pattern matching ([p0095](https://wg21.link/p0095). It's a brave new world out there. I mean, C++14 was basically "just" relaxed `constexpr`, generic lambdas, and `auto` return for functions. Two of which are strong pushes towards - let's make functional programming *easier* and more *natural*. We'll get there. 
Thanks for these explanations, appreciate it a lot - I have saved them and will use them for when I'll give it another go in the future (I'm sure I will!). I completely feel with you regarding old blog posts of people that do stuff wrong, it's a pain. However as I said above I *was* first looking on dlib.net and I either didn't find that example, or I had some issue with it (maybe what I'll mention below). (_Edit: Right, it is linked on http://dlib.net/compile.html, so I probably did find it, and there was some other issues with it! :-) Definitely not the issue of missing documentation._ ) The example you linked: I think it has several issues. Mainly that it uses `include(../dlib/cmake)`, who god knows can do anything and expose anything. What I want is `find_package` and just the dlib import target - from the dlib subdirectory, without having to externally build it first (so it is done locally in the build dir and doesn't need admin rights / installation into /usr/...). Also it magically seems to bring some variables into scope like `USING_OLD_VISUAL_STUDIO_COMPILER` - not good practice. I want a non-intrusive CMake way to integrate dlib. Just the import target. Not whatever other variables you might expose to my script too. Let me know if I'm wrong about any of this, I'm curious to hear your opinion.
The slower compile-times where in regards to glm. I don't think Eigen has that much of an impact. Most people who use OpenCV just need it for things like for grabbing camera frames from a webcam, displaying them on the screen with some boxes/text, and then usually inbetween something like feeding it through tensorflow or so. Or they do simple image filtering operations etc with it. I think for that it's fine, and there aren't many viable alternatives out there. OpenCV gets you started REALLY fast and is supported basically everywhere, and if you use its builtin filters etc to do basic things (like CSCs), they are fast. I agree that it sucks that it isn't more flexible or extensible, but if you need something more advanced, you can roll it yourself or find something else -- I don't think this is the usecase that most OpenCV users fall into. I agree that there isn't that much of a reason to roll your own matrix libraries, but it can happen if you have some sort of special structure that isn't well-captured by any of the existing libraries (and implementing it for a particular purpose is pretty easy). The existing libraries are pretty flexible though (e.g. armadillos sparse matrix class can let you bulk-insert, sorted, unsorted, with uniqueness check, without, ... and any combination thereof) so there probably aren't many occasions when you need to do it. One example where I did it is a physics simulation where I started out with a sparse matrix representing particle positions (velocities, ...) and did integration on them, and eventually I switched away from the matrix class to just a linear array of values that I iterated over (and then later I ported it to the GPU.) Another example is one I used for representing image/sensordata (non-sparse), and I could get the layout to be much more compact by using a different # of bits for the different channels. But these are the kind of cases where you don't need to do advanced things with your matrices anyway, you kinda just perform matrix-vector multiplications over and over again, or you slide some small convolution window over the matrix or, ...
The other day I wrote a constexpr `is_sorted`. Used in a static assert, over an array of ~300 elements. It used about 8Gb of ram to compile, and killed our build server.
Why use quicksort instead of mergesort? Mergesort is guaranteed O(n log n), quicksort is only O(n log n) average. Usually quicksort is used instead because it does the sorting in-place, but this is not the case here (and that would be impossible as a constexpr).
How'd you manage that? Were you doing it via some sort of template recursion? I [hacked up](https://godbolt.org/g/YsROPn) a simple constexpr with a for loop and it works just fine. Or were you restricted to C++11?
Have you looked at Boost GIL? It's a bit template-magic, but it seems incredibly sophisticated and well thought out
And has not been maintained in the last 10 years, if I'm not mistaken...
Which C++ coroutines are you talking about?
https://isocpp.org/files/papers/N4663.pdf
C++11 had entirely different/stricter rules for `constexpr` that disallowed (among other things) iteration and having more than one statement. Constexpr algorithms in C++14 are a much more straightforward affair.
That makes a lot more sense. At some point in the article it's written with one 
That's not what i'm talking about. When a function looks like `void doTheThing ( InputArray input );` I automatically read that as a pass-by-value, but in actuality, `InputArray`is a typedef for `const _InputArray&amp;` (not `cv::Mat` as I mistakenly said earlier). I don't like the fact that this detail is hidden.
Ok, thank you for digging up this example. So if I understand well you're saying that seeing where the action actually happens (the decltype expression) frees you from guessing what's going on under the hood the various abstractions, thus making the piece more straightforward to understand, is this about right?
Yes, exactly
And mergesort is so much easier to write!
When you write code for private projects you can write code as complex and unreadable code as you want. But don't expect anyone to care about it.
why so angry just chill 
I am chill af bro 
It's 5am in the mornikg and I am high on cocaine d
i prefer the devils lettuce 
a pedantic addendum: quicksort is faster until input is too large to fit into memory, where mergesort will win because it does not assume constant time access to elements. 
More specifically: Clang and GCC might do inlining if you specify `inline` (as with any other function), but they don't seem to when you omit `inline` (whereas with other functions they will) MSVC just flat out doesn't inline, even if you specify `__forceinline`. https://godbolt.org/g/v3samU
I get the consistency argument but I can't remember ever writing `T* const`, if I want a const pointer I use auto or a typedef or I am in a generic context....). So I don't need to worry about it and can put const on the left.
If you wanted a const for the auto, which would you do: * const auto v = get_value() * auto const v = get_value() 
&gt; So how does constexpr fit into this, also on the right? C++ grammar does not permit this as best I can tell.
On the left and I'd love to be able to omit the auto entirely but that ship has sailed sadly.
I don't think I'd use it, but template &lt;class T&gt; using ptr = T*; is an antidote to a lot of C's type-syntax madness.
I have been thinking about doing a talk at CppCon this year on LTO. My initial motivation was the link-time code gen in the modules proposal, but this makes me want to do it even more.
Off topic question, have you found any tools to help with re-factoring constant correctness into the codebase ? I'm currently trying to do the same thing with a large~ish (hundreds of thousands, not millions of lines) codebase before it gets too stale, but something that can semi-automatically suggest where const could and should be placed would be great... its seems its even harder to make this call with move semantics :/
Your post has been automatically removed because it appears to contain profanity or slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/6f688l/how_can_i_jump_to_the_next_level_modern_c/difri4a/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It was a regular for loop with C++14 constexpr. I think I'll investigate it more ~~on monday~~, since it works perfectly on goldbolt.
Quick googling gave me this - [Check for const correctness with the C++ Core Guidelines Checker](https://blogs.msdn.microsoft.com/vcblog/2017/03/07/check-for-const-correctness-with-the-c-core-guidelines-checker/). I believe Clang Static Analyzer would also be capable of doing this. Edit: I found it in [clang-tidy](https://reviews.llvm.org/diffusion/L/browse/clang-tools-extra/trunk/clang-tidy/cppcoreguidelines/).
I don't remember exactly where and when but I read a post which was saying that defining endl like that instead of using std::endl has a better performance. Probably I'm wrong tho.
It does, but because it does something totally different. cout &lt;&lt; "hi" &lt;&lt; "\n"; Will print hi to stdout, with a new line, but it won't flush the buffer (meaning it's possible that it won't actually display the output immediately) cout &lt;&lt; "hi" &lt;&lt; std::endl; Will print hi to stdout, with a newline and will flush stdout: meaning anything that has been buffered will be actually displayed. 
Thanks I didn't know that. Now I will use it explicitly.
I know of https://github.com/rizsotto/Constantine This is a Clang plugin, I don't remember if it can fix things automatically but it's possible.
Wow, you seem to regard compilation phases as sacred entities. In real life software, you end up with abstraction needs that are impossible to express within your programming language. Then you have two choices: Write boilerplate (Boring, error-prone, hard to maintain, hard to refactor) or generate code. However you choose to generate code (be it macros or a python script etc.) you'll leave the usual semantics of your programming language behind.
Types are essentially read right-to-left: char const &amp; // Reference to a const character. char const * const // Const pointer to a const character. my_class:: * const &amp; // Reference to a const pointer to a member of my_class. The only reason anyone is ever confused about what is constant is because people are still using the const-at-the-beginning-of-the-line kludge. If people would stop doing that, the confusion would go away.
Is `int [3][4]` "array of 4 array of 3 int" or "array of 3 array of 4 int"? I thought it was the latter.
Const on the right is the one true path, non-believers must be converted. With fire.
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6f688l/how_can_i_jump_to_the_next_level_modern_c/difv0g5/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
!removehelp
I see the argument, but I wonder if the placement of const is the biggest issue, when you're dealing with references of pointers of pointers. For simple types `const type` just reads better than `type const`. As with pretty much all of these discussions, in practice the most important part is to be consistent and to accept that your opinion/preference on that matter isn't the only true one.
I think this is only an issue with raw pointers, which I don't use very frequently. I either use (const) references, or smart pointers. The parts where I do use pointers is most often when interfacing with C libraries, and they don't typically use const pointers either.
I prefer it on the left as its closer to its english translation. Making it more natural to follow. See examples here https://cdecl.org/?q=int+const+value and https://cdecl.org/?q=const+int+value regardless of where you put the const, it reads as declaring value as const type. 
&gt; For simple types `const type` just reads better than `type const`. I think that just because it's what your used to. I used to be a left const person, for 15 years. About 5 years ago I switched to const on the right and find it much much better.
`std::array&lt;std::array&lt;int, 4&gt;, 3&gt;` is an array of 3 arrays of 4 ints. I don't care about C that much.
In the C code I dealt with before, `const` was on the left. At my current gig, `const` on the right is more common. It looked weird the first few days I was at the company, but now I really like it.
&gt; The only reason anyone is ever confused about what is constant is because people are still using the const-at-the-beginning-of-the-line kludge. No, the reason anyone is ever confused about what is constant because C's declaration rules are awful and you shouldn't write those complex types. Instead, use auto or a typedef.
I would wager that the small constant factor of quicksort is because it does the sorting in-place.
I would comfortably place readability over compile time -- that is, assuming we aren't nearing the realm of [pathological code compilation](https://www.reddit.com/r/cpp/comments/6f1xor/constexpr_quicksort_in_c17/dif0izy/).
Left because if I ever need multiple variable declaration, right const just brings confusion, and other reasons.
This project was created for fun :) Additionally, this project is developing just for one week, so documentator can't have a lot of cool features :D 
Well, it's well-defined in C and C++, it's just hard to remember the rule unless you're a language lawyer.
I might be wrong, but as far as I remember this was just a big one-time code dump. Kind of the equivalent of a GitHub ' "Initial commit." - 9 years ago' for every file. I don't think this instills confidence in a project.
I'd say what's more important heavily depends on the kind of project
&gt; With fire With dynamic_cast&lt;&gt;
`auto` begs to differ!
Const applies to the thing to the left unless there is nothing to the left is a very easy to remember rule. That's why I also prefer const on the right.
If you are interested, I implemented some benchmarks some time ago in a mini-project and the Sieve of Eratosthenes was the first of them. You can see it here: https://www.reddit.com/r/cpp/comments/3i2iu1/the_abstraction_penalty_benchmark_idiomatic_c_vs/ 
`explicit constexpr` or `constexpr explicit`? I usually do the former thing.
The [code](https://gist.github.com/heejune/c04050cc376198135e2ce3d218cae4e5) shown is both semantically wrong as well as poorly optimized: * `precompute_max_count` should depend on `n`, otherwise the function is useless. * Why save all the primes if you're only going to return the nth one anyway? * `std::sqrt` in loop header: risk of the compiler not optimizing it properly, just take it out of the loop manually. * `std::count` on `vector&lt;bool&gt;` is horribly inefficient because it check each bit with a proxy element. Write your own sieve type so you can use SSE's popcnt (`__builtin_popcount` in GCC).
&gt; Compile time will decrease over time with no work on the part of anyone involved LOL True!!!
How about including an exemplary output? I am interested in seeing the generated pages but I don't have Python installed.
&gt; Compile time will decrease over time with no work on the part of anyone involved. I would only sacrifice readability or maintainability if the compile time were egregious, but I'd never make that trade "incrementally". Or sometimes they increase, as they did with clang for the last few years. Also it's not only compilation time but memory usage, in RAM as well as on-disk. at some point my software needed roughly 20 gigabytes of RAM to link a debug build so many people were blocked from contributing; one of the sub-libraries was almost 800 megabytes on-disk (and 3mb in release mode...).
&gt; I think that just because it's what your used to. It's mostly because in English adjectives come before the noun they're referring to. Now you could of course read "const" as a noun but that's kind of inconsistent with "volatile".
Narrow/contrived application to derive a general rule.
Why would I use this instead of [`std::weak_ptr`](http://en.cppreference.com/w/cpp/memory/weak_ptr)?
Simply define template&lt; class T &gt; using ptr_ = T*; template&lt; class T &gt; using ref_ = T&amp;; Now the author's right-`const` read-right-to-left examples int const * a; int * const b; int const * const c; … become the left-`const` read-left-to-right declarations ptr_&lt;const int&gt; a; const ptr_&lt;int&gt; b; const ptr_&lt;const int&gt; c; This works nicely also with template argument deduction. C++11 `auto` is more of a problem. E.g. `auto* const p = foo();` can't be replaced with `const ptr_&lt;auto&gt; p = foo();`, because the `auto` keyword can't be used as a type. In my humble opinion this is a symptom of a missing crucial piece of the language. But happily it's only about communicating to the compiler and other programmers your expectation about the `foo()` result type, and that can be done in many other ways. For example, one may write `auto const p = pointer( foo() );` with `pointer` defined as a simple forwarder of pointer values. 
You'd probably be correct (though I'd say local variables should still be const if you don't intend for them to change). I guess there are still generic lambda parameters and template parameters/members though.
Live it, breath it, do it! int main ( int const argc , char const * const * const argv )
one declaration per line, declare as needed!
I am very interested in this too. Can buck / bazel build things any faster than CMake with the Ninja generator?
I was getting ready for some bizzsnatch who just wants people to do things his way. But then I read a simple list of good solid advice. I have a simple formula. Those who push their own set of coding rules that specify spacing, case usage (in way too much detail) etc. Are generally crappy programmers who argue that somehow using camelCase is going to make for a solid product. Their arguments are superficially solid when they claim that consistency is good and blah blah. They completely miss the point that the goal is a solid working product that can be maintained. Seeing that the world is filled with code that violates their rules and we all have no problem reading it, then they, and their rules are a perfect example of their incompetency. So I see here someone doing fantastic work and advocating a pretty damn simple set of rules. 
 const char a[] = "right const" , b[] = "is for", c[] = "deluded and/or rippies", d[] = "still uneasy with", e[] = R"(Ritchie's "declaration reflects use")", f[] = u8R"(lying at the core ¯\_(ツ)_/¯)"; 
I like this idea but I'm not sure how well it scales as the `ptr_` and `ref_` types would be littered across one's code base. As for the "crucial missing piece of the language", it's not missing, though it does require repetition and is not pretty: `const ptr_&lt;decltype(foo())&gt; p = foo();`
The problem with cmake might be summed up in the fact that there's no standard way to achieve almost anything, and every library implements various levels of cmake support, and almost always in its own way. It's almost a given that if you have 10 3rd party libraries, each of their cmake modules will fail to find it in a subtly different way, and each of those modules will require a slightly different approach to telling it where to find said library. Sometimes the support is minimal and almost comically proof-of-concept. Sometimes you get 2k lines of cmake spaghetti bundled with a lib just to freakin find it and it looks like you could code that search in less lines of plain C than that. And there's 0 documentation besides the rudiments for any of the cmake support modules for various 3rd party libraries. Even otherwise well documented products like Qt are comparatively mum on the details of their cmake support. Thus people resort to copypasta from other projects, without any understanding of what they're really doing, and whether it's idiomatic cmake, or nearly obsolete vs. future proof, and the users end up stuck with a mess no different from the autotools mess where the evangelists scorn everyone for "doing it wrong" while nobody really can tell what it is that they should be doing right, never mind how to do it right. From the point of view of human factors, I consider cmake largely a failure, and people who evangelize its use to be largely disconnected from the reality of using it, ever so eager to swipe their own past experiences under the rug.
DISCLAIMER: use std::weak_ptr instead of DeferredUniquePtr :) Sorry for wasting your time.
I agree with the ordering, though perhaps not the individual prioritisation of each part - chrono is the most useful STL header I never want to use due to its verbosity.
beefier computers are still cheaper than programmers.
Do you have to do inserts or is the data static?
I think static will do for now, dynamic maybe later on
It should be rather fast. I guess anything but binary won't do. But good suggestion otherwise
If if small data I'd just read it into memory. If you have any kind of actual performance / size issues I'd use [RocksDB](https://en.wikipedia.org/wiki/RocksDB). There are other choices, but it'll be fine for most applications. (It's not a tree; it's key value but you can likely make it work.)
It largely depends on what sort of work you're seeking. In general, C is the language of choice when working with low level (device drivers, operating systems, etc.), and C++ is more commonly used in high performance, higher level software (video games, computational physics, etc). As C++ was originally a superset of C, most C++ programmers are comfortable in C, however the languages have diverged somewhat since '83. It's much easier for a C++ programmer to learn C than vice-versa. Hope that helps.
Also it very much depends if area where you live (or you plan to live at) has a healthy C++ job market. If it doesn't, then you will be forced to consider relocation to grab a good C++ job. This unfortunately is a case where I live at but I am not necessarily willing to relocate just because of the career. So I would say it is also a quite important point to be considered.
If you're doing it on magnetic disk, you want a B or B+ tree. For SSD there may be better structures nowadays I'm not aware of. As for implementation, it's a very complicated matter to do it right and efficiently, and probably not even worth it to roll your own. There may already be tons of libraries implementing all these data structures efficiently, and there are also many databases which use them extensively, so maybe you could leverage them as well (SQLite may be a fine candidate).
I suggest starting with C++. Then you will not need to unlearn C when you start learning C++ at a later stage. C++ Primer Plus book: &gt;Also if you know C, you must unlearn some programming habits as you make the transition to C++
That's the typical argument, but it's not an answer because it really depends on how one reads the types. Example: const int&amp; t; Is this a "constant integer-reference" or a "constant-integer reference" or an "integer constant-reference"? All three are a valid English way to interpret that variable type. So, to me, it's not a "constant integer-reference" because all references are const. It's not quite a "constant-integer reference" because it's unknown if that thing being referenced is actually const. It could be claimed though that that doesn't actually matter -- it's just an interface, but still, with that little bit why not make the jump to the third option; "integer constant-reference", an integer reference through which the referencee is const. Or int const&amp; t; 
It's more complicated than that when dealing with pointers and references because the thing being pointed to might not actually be constant. Of course, it's an interface, so it might not actually matter, but still there's something I don't like about "declare a reference to a constant int" It might not be the int that's constant, possibly it's just the reference that is. So, I prefer "declare a constant-reference to an int" Or int const&amp; 
Consider also that C shops can sometimes be hopelessly old fashioned.
I still think you should try. XML parsing and serializing is bread and butter these days, I really think it'll be very fast. Besides, I/O itself will probably be your bottleneck, the format will change very little.
That isn't an answer to why though. He just asked for a tree structure in a file. 
Which involves basically writing a baby filesystem that uses a file as backing storage. It's not something trivial, especially if your records are different sizes.
It's also worth mentioning that there are now two styles of C++ : Legacy C++ (based on the C++'98 standard) is a lot more C like and features a lot of manual memory management - raw pointers and new/delete. Modern C++ (based on the C++'11 standard) is a lot less C like and prefers the use of smart pointers and MakeXYZ functions instead. It results in very different code, and you really do need to know both!
My program is taking 1-2 gb of ram per process to compile with GCC, it is becoming a real problem. It's not even that big or complex. Interestingly clang only take around 500 mb.
just use mmap(or your OS equivalent)
I guess I just let the msvc and gcc compilers do the work, both of them accept the above without complaint.
:)
Check out 'FlatBuffers', an open source project that does just that. 
It all depends on the nature of the work you are trying to get into. Regardless, you will also have to be keen on algorithms and data structures as well. That is the current state of the market. C++ will only get you so far.
"This paper proposes a new hashing infrastructure that completely decouples hashing algorithms from individual types that need to be hashed."
There's a million options to solving the problem. Storing search trees for 2D/3D points in xml is likely going to be way slower than the binary approach and the file will become way bigger. I can't just implement each possible solution, or I'd never finish anything.
I'm not saying put it on the left if it's actually constant, and the right if it's not. I'm saying always put it on the right because it makes more sense because the constness has nothing to do with the referencee. At least to me. 
Done! :) But output isn't very readable :/ 
Well, when some small notational device is used ubiquitously it becomes transparent. Let me quote C.A.R. Hoare about that, from his book [Communicating Sequential Processes](http://www.usingcsp.com/cspbook.pdf): &gt; Notations are a frequent complaint. A student setting out to learn the Russian language often complains at the initial hurdle of learning the unfamiliar letters of the Cyrillic alphabet, especially since many of them have strange pronunciations. If it is any consolation, this should be the least of your worries. After learning the script, you must learn the grammar and the vocabulary, and after that you must master the idiom and style, and after that you must develop fluency in the use of the language to express your own ideas. All this requires study and exercise and time, and cannot be hurried. &gt; So it is with mathematics. The symbols may initially appear to be a serious hurdle; but the real problem is to understand the meaning and properties of the symbols and how they may and may not be manipulated, and to gain fluency in using them to express new problems, solutions, and proofs. Finally, you will cultivate an appreciation of mathematical elegance and style. By that time, the symbols will be invisible; you will see straight through them to what they mean. Of course this is also an argument that `*` and other operators sprinkled throughout the code is not a barrier to understanding, either. But these symbols can't be understood in isolation: one must consider, i.e. read and analyze, the context. The `ptr_` notation dispenses with that additional burden, and to boot it's readable for novices. So, if I were to argue this (and hey, it appears that I am! how weird), I'd say it's an advantage that `ptr_` and `ref_` would be appearing just about everywhere throughout the code, because that way these pseudo keywords become transparent to the reader. :) 
XML is not really considered "human readable" today anymore (or depending on how you twist words, "readable" maybe yes but not "human consumable"). We've got way better file formats nowadays (JSON and YAML spring to mind). If you're curious about this topic there's plenty of blog and forum posts on the topic of why XML is not considered a good human readable format. :-)
You can try [cereal](https://uscilab.github.io/cereal/index.html) with json or binary. I know you didn't want "no full deserialization" but give it a go, it's extremely easy to use and set up.You'll have to spend less than 30mins and might just find the perfect solution. (or not but then you'll know soon)
sure, the best answer is to evade the question.
You may want to compare against Rich Geldreich's [pjson](https://github.com/chadaustin/Web-Benchmarks/blob/master/json/third-party/pjson/pjson.h) or his updated implementation in [vogl_json](https://github.com/ValveSoftware/vogl/blob/master/src/voglcore/vogl_json.h).
For human-readable formats, [JSON](http://www.json.org/) and, in particular, [Yaml](https://en.wikipedia.org/wiki/YAML). The latter is particularly suitable for human-edited content such as configuration, since it supports comments (JSON doesn’t). Apart from that there are of course various binary serialisation protocols such as [MessagePack](http://msgpack.org/index.html). If human readability isn’t a requirement, these are generally superior since they are vastly more efficient and take up less space. Lastly, a lightweight database interface such as SQLite is more often appropriate than people think.
I mean, I don't disagree because you basically paraphrased what I just said. Maybe the way I said it made some people unhappy?
Neither. Both. Focus on differences and how they both differ from other languages. Learn how to solve problems and design solutions...and then use the power of various languages to solve it. If you do specialize in one, like I have, retain and continue to seek general knowledge and let the language/library details just sort of seep in. Just assume you're always going to have a reference on your desk, because you are.
You just have to understand how declaration was originally designed to reflect variable's use (https://www.reddit.com/r/cpp/comments/6f5j79/why_i_put_const_on_the_right/dih11bk/?context=3). This is the most important thing regarding C and C++ declarations and one shouldn't miss learning it. Naive recipes such as "types read right-to-left" can readily apply in some case and cause confusion in others. It's like asking you to blindly apply tricks for doing summation instead of actually learning the mathematics. If you want to see more illustration regardings Ritchie's design see: - https://stackoverflow.com/a/13076065/1000282
Considering you don't have unique_ptr, and that without move semantics you can probably not write your own sane replacement (even with limitations), I'm not sure you can avoid new/delete in C++98?
If you use any sort of binary structure structure with offsets, you don't parse anything. You memory map a file. 
What kind of tree structure? I have code that stores a trie on disk that uses offsets. No parsing necessary. You do have to encode to this binary format, though.
&gt; Any suggestions or someone knows a project I'm not aware of? I’m afraid I can’t help you … I haven’t used Yaml from C++ yet so I’m not aware of any. That said, I understand why header-only libraries are less attractive for Yaml: though it’s similar to JSON, it requires a somewhat more complex parser (at least that’s my intuition; I didn’t compare grammars in detail). And parsers are something that you’d normally want to implement in its own translation unit since their compilation can be slow, especially when using modern parser generators (= Boost.Spirit).
I've always considered sizes on multidimensional C arrays to be just multiplicands. In C passing an array always collapses down to a pointer anyway which means that you can also access a multidimensional array passed to a function as a single dimensional array of size 3*4. https://stackoverflow.com/a/21625371
You know Stroustrup is always very professional, but I'm sure he was rolling his eyes in his heart. It wasn't the only foolish question in the interview as the interviewer appears to have only a shallow appreciation of technology, but I'm sure the interviewee is used to it. What I would love to see is different language creators like Bjarne Stroustrup, Bill Joy, Simon Peyton Jones, Anders Hejlsberg, Ken Thompson, et all interviewing each other! One can dream at least! :-)
This is an interesting claim. But cannot be truly verified until metajson is apart of the nativejson-benchmark. Which as it turns out is quiet easy, all that is required is to make a PR and Milo seems to always be very keen to incorporate any new libraries. https://github.com/miloyip/nativejson-benchmark 
Right now std::hash is provided only once per type which means that you can really only have 1 hash algorithm per type. Howard's proposal is much better because the hashing algorithm is tied to the container instead - the type simply identifies how to add to the hash. This means you can change-out hash algorithms trivially at the point-of-use without needing to change the hash for the type as you do now. This is super powerful if, for example, you have multiple containers key'ing off the same type but having different performance/security trade-offs. For example, one container might use user-input values (i.e. you want to use a collision-resistant algorithm or even a cryptographic hash) as the key while another might use it with a fixed-set of values you know the perfect hash function for. Right now, you have no way to control the hash algorithm that's used because std::hash&lt;std::string&gt; is defined in the STL so you need to wrap them in their own types &amp; hope you implemented the hash algorithm correctly. With Howard's proposal the type simply indicates which values get incorporated into the hash and the hash'ing algorithm is external. So if you wanted to do a sha256 hash, you could. If you wanted to do a sha256 hash that truncated output to 32-bit for hash tables, you could do that too. All without changing any code for any type.
Thanks, that's a great explanation!
Sqlite is a good choice for flexibility if you want to perform queries, you have multiple records, etc. If you have just the 1 record protobuf, flatbuffers, cap'n'proto, thrift and even json work well. You'll typically get the best performance from flatbuffers &amp; cap'n'proto since they have no encode/decode step (just some security/validity checks).
Here is what I wrote in 2011 (formatting will probably suffer after copy-paste): ``` Compiler parses our declarations in somewhat complex way according to recursive algorithm dictated by following grammar (see C++ standard): simple-declaration: decl-specifier-seq opt init-declarator-list opt ; decl-specifier-seq: decl-specifier-seq opt decl-specifier decl-specifier: storage-class-specifier type-specifier function-specifier friend typedef it gets more complicated if you keep unrolling it, but rules quoted above should suffice for my purposes. Most important one is decl-specifier-seq -- it is recursive rule that will analyze our type declaration from the right to left, chipping away smallest blocks it could consume and trying to put it together -- i.e. compiler reads type declarations backwards. This is how int const* volatile&amp; becomes reference to volatile pointer to const int. Compiler combines left and right parts (ignoring order) on each step of recursive parsing process -- that is why unsigned int is the same as int unsigned and int const is the same as const int, but const int* will never be treated as const pointer to int (because on first step it'll separate only star \*, not int\*). This logic allows funny code that you would never expect to compile (but it does), e.g. int typedef my_int; is a valid C++ declaration. :-) Anyway, I always prefer to write int const* -- it is easier to read (just read it backwards) than trying to follow logic used by compiler. It is also about consistency -- regardless of nesting level modifier gets applied to declaration on the left side, and consistency is good -- it simplifies process and frees mind to do important things. It is also about safety, consider example: typedef int* MyType1; \#define MyType2 int* const MyType1 var1; const MyType2 var2; MyType1 const var3; MyType2 const var4; In sample above var1 and var2 have different types (but var3 and var4 -- same)... This effect could break code sometimes. And finally, C++ is full of complexities, ambiguities and special cases -- it is nice to eliminate one with trivial convention. :-) ```
This is still very much a work in progress (it doesn't even have any real tests to speak of), just thought I'd throw it over the wall here and solicit some feedback. It's a very messy combination of C pretending to be C++, but I'm reasonably okay with that, at least until I can find the time to carefully tidy it up without damaging performance. And regarding that, if anyone has feedback on better ways of doing [this commit](https://github.com/dw/csvmonkey/commit/b62f7e031eec578801fdfaec798cb3f4b364decf), which sadly knocks 100mb/sec off my microbenchmark, I'd be happy to hear it. Still not sure where the additional cost comes from. Replacing .at() with manual if(.. &gt; ...size()) throw(..) brought about 25mb/sec back again, but I was just basically shooting in the dark. 
I guess I could embed the resize in a member function and invoke it explicitly from the two sites that might exceed the array size. It was just the first idea I came up with
Is it possible to ask for a new item for the utilities category? Something like `rsync`. I am interested in doing it myself but not sure why it is not there and if you are interested in extending the utilities category.
Cool! Haven't looked closely to review the code, but performance speaks for itself. As a potential library consumer, good test coverage is mandatory though. Edit: also a permissive license.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6fj5tm/what_libraries_are_present_for_netflow_capturing/diilk97/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I intentionally build only C and C++ as I have zero interest in other languages (strictly speaking, my only interest is in C++, but I use C libraries). I can't speak for other distros. However, I provide my entire build scripts and environment so you can build your own distro with Fortran if you want.
Due to time constraints, I avoid adding components that I don't use (I make exceptions to this rule very rarely). I use WinSCP to sync stuff to my Linode. If you'd like to add rsync to my distro, I encourage you to check out my build scripts and environment; my distro is meant to be extended by interested users (and if you don't replace components, merely adding them can be very easy, since you don't have to rebuild anything).
I once needed a reference to const array and that's when I realized that `T (const&amp; arr)[N]` does not work. I ended up choosing `const T (&amp; arr)[N]` between it and `T const (&amp; arr)[N]`.
Time to upgrade. Thanks, STL!
I don't bundle an MPI implementation or Python with my distro, so those parts of Boost are disabled.
There's also [Catch](https://github.com/philsquared/Catch) and [doctest](https://github.com/onqtam/doctest) for unit testing frameworks. Also, I think if you look at CMake as a build system configurator instead of comparing it to pyvenv/pip/setuptools/etc. then you'll find it does the job just fine. It looks like you intend this to be a Python extension though I'm guessing you're going to end up relying on setuptools to do the build rather than CMake.
Why don't you simply don't use at(i) and use [i] ? at(i) will check for the position every time and possibly throw while [i] will not check for the position and has no overhead compared to array access. 
Does it off-topic?
Why is it illegal? I must be missing something, since I'm a novice in reading the C++ standard. I'm looking at the draft ([n4296.pdf](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4296.pdf)) in section 3.6.1, and it says there are two types for the `main` function: &gt; * a function of () returning int and &gt; * a function of (int, pointer to pointer to char) returning int It is because "pointer to pointer to char" precludes "pointer to pointer to **const** char" ?
Which one is the official one?
I make ClauText using C++. (so I selected CPP) then, which topic is better? just Programming?? 
Thank you for this. But there is one problem, that is the bundled GDB does not support python scripting. What can I do about this?
Well, it was terminally broken and nuked because of that...
/r/programming is indeed better. And your post could use some styling. Also, indicating the goal of your language (is it a pet project? Do you expect anyone to pick it up?) is a good idea, as it changes a lot the feedback.
 then, How do I move this post to Programming topic? just remove and re-upload?
I would say a decent amount of new drivers are in cpp, as well as other stuff in the kernel space. There aren't many places c is used that c++ isn't used. Learn c++ imho, since it's nearly a superset of c you can look for jobs wanting either.
&gt; Under the Linker Input Property Page add the library dependencies: m;GL;GLU;glut. No, don't do this. Under Linux you should not add libraries manually but instead get the dependencies with pkg-config. Adding `m`is ok but not the others. It would be better if the Linux build would just delegate to a build system that can deal with all of the weird things going on. As a person who has written [one such build system](http://mesonbuild.com) I can say that reimplementing all of that will _not_ be your happy place.
Great article, but is it possible to do this with cmake and msvc?
Disabling the verbose terminate handler means you don't get the contents of `exception::what()` printed to the terminal by terminate. The default "This application has requested the Runtime to terminate ..." message is not very illuminating. terminate called after throwing an instance of 'std::runtime_error' what(): failed to frob the blinkenlights 
how would it handle `optional&lt;T&gt;`, `variant&lt;T&gt;` types ?
I know, but that's how MSVC behaves, and if someone wants to know what was thrown, they should catch and print what(). I might change my mind though.
Indeed, json array can hold values of different types. I take it as a feature request. I should not be too long to implement.
Hello, I reported this `thread_local` related [bug](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=80816) to the GCC buglist a few weeks ago. Today I tried to reproduce on the GCC provided by your distro, and surprisingly the bug is gone (well, I had to replace `std::thread` with `boost::thread`). Very happy about that :). I see that you are not linking against winpthread like the upstream mingw. How exactly does this work? AFAIK the mingw64 upstream uses gcc's emutls which result in some calls to `pthread_key_create` and friends, and that is quite buggy. Which flags do I need to pass to gcc to get whatever configuration you have?
Last time I tried building, GDB had a bug where it didn't work with Python 3 on Windows (only 2). Not sure if that was fixed. There's also some trouble to get it to look for Python relative to gdb.exe rather than an absolute path, I had to pull in a patch from the AdaCore source archive.
No, it does not required the member of the json text encoding to have the same order as the predifined static structure.
This is now in the backlog: https://github.com/iodcpp/metajson/issues/4
I put BOOST_FUSION_ADAPT_STRUCT support in the list of next features to implement, thanks for the suggestion.
I wouldn't encode it as an array but as a struct "{...}". To give you an idea, this is what I'm using right now: https://github.com/catedrasaes-umu/jsonip Is an incomplete library and not very fast, but is very handy to take a human-readable snapshot of the state of my app. If I don't need human readable I serialize to msgpack that also supports Boost.Fusion. The best part for me is that I don't need to write any serialization code except one BOOST_FUSION_ADAPT_STRUCT and I get msgpack and json serialization for free.
I don't understand, could you write for example what would give your serializer for the tuple [1, "foo", true] ?
Thanks a ton!
If I want to add libraries as default to the included GCC compiler, where should I put them? Stuff like `experimental/filesystem` etc.
Does `std::thread` work yet?
the implicit const of references is on the right because it couldn't be on the left, it can't be swapped just like in `int *const p`, left const only makes sense at the top level, because it's possible, so your argumentation about consistency "because for references it's always at the right" makes no sense.
Best comment on the article: &gt; Why not simply use double quotes: &gt; set(AVX2_FLAGS "${CUSTOM_FLAGS} -DAVX2_AVAILABLE=1 -mavx2") No lists. No foreach. It just works.
You make it sound like this is some unquestionable rule, and I'm sorry but I disagree. Ignoring the idea of wasting time writing tests for a prototype that had a 90% chance of ending up in the trash had the techniques applied proven to be fruitless, attempting to write clean logical tests while in the same frame of mind as analysing instruction dependency chains and branch mispredictions is only going to result in some God awful brittle and mistargeted tests, the kind we've all seen and shuddered at many times over the course of our careers. For a small project like this I have no problem with writing tests after the fact, because by then the only legitimate question on my mind is "how will this break?", as opposed to the usual binbag full of excitable cats that is my thinking process while tinkering with lower level stuff.
I have a question, as this is my first time seeing this project. Is the aim of this project to integrate GCC into windows via this "distro" so that a program can be written for GCC once, and compiled for both linux and windows?
Is it not the other way round? MSYS2 has a mingw-w64 shell.
That's the magic of upgrading to the latest version! :-) &gt; I see that you are not linking against winpthread like the upstream mingw. How exactly does this work? Boost.Thread calls the Win32 API directly. I don't know how GCC's `thread_local` implementation works; possibly they're directly calling the Win32 API too, even as libstdc++ wants to call pthreads. &gt; AFAIK the mingw64 upstream uses gcc's emutls which result in some calls to pthread_key_create and friends, and that is quite buggy. And that's why I run away screaming from pthreads wrappers. &gt; Which flags do I need to pass to gcc to get whatever configuration you have? See `mingw-w64+gcc.sh` [on GitHub](https://github.com/StephanTLavavej/mingw-distro/blob/master/mingw-w64%2Bgcc.sh).
Yeah if you really have to do pre-C++11 I guess it's not a so bad compromise with the techniques you gave. I did not thought of the out ref to swappable "unique-ptr-like" container trick, could be useful in case I have to do work in that env (but I would really prefer not to :P )
The points I was trying to make were that: - just because it doesn't outlive the current scope now it doesn't mean that it will never outlive the current scope, e.g., after refactoring (like moving code from the serial to the parallel STL). - the compiler won't tell you that a lambda doesn't outlive the current scope. So it is a nice neat comfortable ergonomic feature, but one should know the possible perils of its usage.
Your HTTP Cert is boned. But very nice :)
I like it. How did you learn the more modern techniques in C++? Is there something like 99 problems for modern C++?
&gt; Nice blog, and thanks for citing my SO Q&amp;A No problem, I've said before I think your sort implementations are a really fantastic example of readable modern C++. &gt; BTW, in C++17, the advance, next, prev and distance utilities from &lt;iterator&gt; have been made constexpr I wasn't aware of that, thanks, although it seems this change isn't in GCC/libstdc++ 7.1 :(
just like happens with references (https://www.reddit.com/r/cpp/comments/6f5j79/why_i_put_const_on_the_right/dihpzdt/), arrays themselves are always const, what can be const or not is the element. So, IMO, it's more correct to say array of consts rather than const array. You first declaration is indeed an attempt at giving const to an array, not the element. 
Out of curiosity, what is involved in getting a new GCC build to run on Windows?
Yeah you should just be able to extract the gdb build from elsewhere that was built to your needs. Failing that just build your own. Gdb is literally just a make, make install and you're good to go. 
I think they support multiple variables on a bar graph now. Not sure what else, qwt is still my go-to but I think QtCharts is close to having everything I need. The changelog is available on their website.
Daniel Pfeifer now also has a talk online from C++Now 2017 :-) https://www.youtube.com/watch?v=bsXLMQ6WgIk
Good very nice implementation, I think C++17 is going to change the way things are done.
Yes. Suppose this sort of thing were allowed. char *p,**p=&amp;p; const char **ppc=pp;//not actually allowed **ppc="fred";//point to const data p[0]=0;//hmm 
Looks good to me
&gt; How did you learn the more modern techniques in C++? As I said, I can't claim credit for any of the code in the post. All I did was take other people's code (in particular /u/TemplateRex's quicksort implementation) and sprinkle some `constexpr` around. In general though, lurking on /r/cpp is a really good way to keep up to date with modern C++. Reading blog posts, watching conference videos and so on will help you learn a lot without really realising. One day you'll come across a problem and you'll think "I know how to solve this", because stored in the back of your mind is something you read or watched on here a few months ago. &gt; Is there something like 99 problems for modern C++? Unless you're referring to Jay-Z, I'm afraid I don't know what this is :-)
The hard part about CMake, at least for me, is not the basic configuration of the project, but dependencies. And there is far too little information on that topic. It's not even that hard to do it right, but if the dependency does it wrong, there is often little I can do. And I don't count writing my own FindFoo.cmake a solution because that is something that doesn't belong in a projects repo in my opinion. I don't think I've found a solution that eliminates all these problems: * Libraries not beeing in a common place. Expected variables and environment variables seem to differ greatly between solutions and FindFoo.cmake files, especially when written by third parties. And no, I definitely don't want to throw the dependencies in a subfolder of my project because I really don't need ten copies of Boost flying around. I also absolutely don't want to hardcode any paths. If I set %FOO% to C:/lib/ on Windows that should be enough. * No FindFoo.cmake existing, not even written by someone else, definitely not by myself. Should still be possible to do "something". * No weird "all my projects are subprojects of one common CMake project". I want my own dependencies act like any other. * No pillaging of my config environment by projects that require add_subdirectory() but completely ignore the target() variety of methods or anything sane that happened with CMake in the last few years. * No upgrading of CMake just because Boost pushed a new version but all paths are hardcoded into FindBoost.cmake files shipped with CMake.
After you're done with Meyers' books you will be ready for Herb Sutter's "Exceptional C++" serie
Aye, it's like VS doesn't care about all the existing Linux projects already in development.
Did you throw -std=c++1z ?
Thank you. Not sure why anyone downvoted, I see your point tho, this is a lot for a beginner to take in and I understand it could get overwhelming. I appreciate your response u/markuspeloquin 
Yeah, the deducing constructors and constexpr lambdas don't work otherwise :-) 
I feel dirty for doing this lol, using gdb from msys2. While it seems to work, I don't know if there will be compatibility problems down the road. Too lazy to compile myself, especially after the fact that someone else mentioned problems with python.
It used to be obnoxious (in the mingw.org days), because stuff would break all the time. My favorite was when mingw-runtime would crash when built with the latest GCC, so the problem wouldn't appear in a single non-bootstrapped build. Crossing over from 32-bit mingw.org to 64-bit mingw-w64 was also complicated magic (although I eventually figured it out with the help of mingw-w64's documentation). These days, it's pretty smooth sailing - mingw-w64 is well-tested and I rarely have problems bootstrapping. Things like the in-tree build started working again, for example. However, some other components remain nightmarish. grep and coreutils are the biggest examples.
That's probably because it's "new" (according to AV reputation analysis) and unsigned. I haven't figured out code signing yet. Ultimately though, using my distro means running my binaries, so you have to trust them. For the record, I run Norton AntiVirus on my system, and it is clean (I use signature scans, not heuristics). I also switched my website over to HTTPS, so you can be confident that you're downloading directly from my server. If I provided a zip (or if you used 7-Zip to extract the exe, which it can do), you'd be in the same position with the distro's executables like `g++.exe`. Perhaps someday I'll investigate code signing.
Check out [spotify-json](https://github.com/spotify/spotify-json), which has the same approach. It comes with support for common STL and Boost types and is easily extensible.
The code is not very pythonic in many ways. * Files should almost always opened using the ``with open (...) as fobj`` idiom. That way the file gets closed properly. * strings should not be concatenated wit the + operator. Use da list and then the ``string.join`` method * for short dynamic strings use placeholders and the ``.format`` method. Much more readable than the used endless fragments of strings and values concatenated with + * The *template* based approach could be enhanced by using a real *template engine*, like jinja. * use a proper command line parsing lib, like the *argparse* module from the stdlib. * the main function is too long * the way you deal with the different kind of annotations feels nor well crafted. Imagine how the code becomes an even more spaghetti look, if you need to add more tags? Better use a dispatching dictionary to map tags to handler functions! Last but not least: I don't like the syntax of your annotations. It feels and looks clumsy. But that's of course a personal taste. Besides doxygen one could also use [Sphinx](http://www.sphinx-doc.org/en/stable/domains.html#id2) for C++ projects.
These books might contribute something to learning C++ well. For example, if you burned them, they could provide light for long enough to read a chapter or two from a book on [The List](https://stackoverflow.com/q/388242/179910).
There are many mistakes you can do during refactoring, and for many of them the compiler won't protect your. Like you have a sequence of 5 lines of code, and you just copy 3 of them randomly around your codebase. It's quite possible that the new arrangement will be syntactically valid but it'll cause serious semantic problems. I think our disagreement lies in the fact that you want to treat lambdas as logically consistent isolated components, and I want to treat them just as regular code (i.e, I don't attempt to copy it around while refactoring). There have been cases where I too wanted to treat them like that, but sometimes, you just want to express complex flow patterns (like continuation passing style) using lambdas, and then they're just code.
Agreed, but I would take most of the "c++ in depth series" after Meyers. Depending on OPs experience (I'm assuming a new c++ programmer) may take 6-12months to be ready for some of the more hardcore books in that series.
Many thanks for putting it up. 
Actually an almost fully `constexpr`-enabled `&lt;algorithm&gt;` header has already been proposed in [P0202](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0202r1.html). IIRC, it was deemed future work since it would not be ready in time for C++17 anyway. The paper describes a few problems with marking every algorithm from the header `constexpr`: * Some algorithms such as `std::stable_sort` or `std::stable_partition` may dynamically allocate memory, which makes them unusable at compile time. * Some algorithms such as `std::copy` often rely on C library functions such as `std::memcpy` or `std::memmove`, which aren't `constexpr`. Compilers often have equivalent built-in functions usable at compile-time, but it was still somehow a problem from a standard point of view.
Thanks, did not know this one. It has a lots of similarities yes. I'll have a look. 
Slides are [available on github](https://github.com/boostcon/cppnow_presentations_2017).
There is even [an application](https://stackoverflow.com/a/41627474/1430927) for compile time sorting algorithm.
Thanks stl. Doing a good service for the community (for free!). It's a shame that you couldn't get openmp going. There's a lot of people you could attract to learning c++ with that enabled (I'm thinking young people interested in gamedev and vfx). 
No, it is worse. Burning them pollute air and emits CO2. Recycle those paper instead. You can get free light from the sun.
Yup. They are *good* example of bad C++ books.
The fact that one of my answers on Stackoverflow pointing out exactly the same thing (literally, that typedefs are "not just text replacements") is one of my highest upvoted answers indicates to me that this is in fact a really common assumption. We can work around this by teaching const on the right consistently, with its really simple and consistent mental model (and showing that const on the left is an exception to the rule) instead of teaching const on the left and then handwaving it confusingly when it necessarily appears on the right.
There's more than one (which is cool): the library [frozen](https://github.com/serge-sans-paille/frozen) provides a `constexpr` immutable `set` implementation which sorts its values at compile-time so that simple binary searches can be used for the retrieval of the set's values :)
+/u/CompileBot C++ #include &lt;iostream&gt; class A { private: void f(int) { std::cout &lt;&lt; "whoops" &lt;&lt; std::endl; } }; using PMember = void (A::*)(int); void hijack(A&amp; s, int n, char dummy = 0); template &lt;PMember pf, typename T&gt; struct Hijack { friend void hijack(A&amp; s, int n, T) { (s.*pf)(n); } }; template struct Hijack&lt;&amp;A::f, char&gt;; int main() { A a; hijack(a, 10); return 0; }
C++ Primer (5th Edition) it's good to start https://www.amazon.com/Primer-5th-Stanley-B-Lippman/dp/0321714113/ref=sr_1_1?ie=UTF8&amp;qid=1496834580&amp;sr=8-1&amp;keywords=c+primer Try to avoid books like "for Dummies" or "Teach Yourself". 
http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list
&gt; char dummy = 0 What's the char dummy and typename T for? The code still works without it (gcc 6.3) 
When I try to debug in QtCreator it tells me "The selected build of GDB does not support Python scripting. It cannot be used in QtCreator" What is the best workaround for this?
https://github.com/boostcon/cppnow_presentations_2017/blob/master/05-19-2017_friday/effective_cmake__daniel_pfeifer__cppnow_05-19-2017.pdf
You linked the C++Now 2017 playlist instead of Daniel's talk. Can you change the link? :)
I wouldn't call those indistinguishable from the outside; they return objects with a very particular specification? And storing the function that returns the coroutine object is different than storing the actual coroutine object. Or do I misunderstand the proposal?
The braces used in [this video's](https://www.youtube.com/watch?v=w7ZVbw2X-tE&amp;index=2&amp;list=PL_AKIMJc4roXJldxjJGtH8PJb4dY6nN1D) title are weird. The correct ones would probably be `&lt;` and `&gt;`.
I think that's why he said "tried".
Although C++ is nearly a superset of C, they are used very differently. Mainly, C++ has more libraries to know. New programmers tend to be a bit shocked when going between the two.
C and C++ are pretty different in terms of how they're used, but they are *related*.
https://github.com/boostcon/cppnow_presentations_2017/blob/master/05-19-2017_friday/effective_cmake__daniel_pfeifer__cppnow_05-19-2017.pdf
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [boostcon/cppnow_presentations_2017/.../**effective_cmake__daniel_pfeifer__cppnow_05-19-2017.pdf** (master → 3996081)](https://github.com/boostcon/cppnow_presentations_2017/blob/39960812f9930ee69fb34638f0c1d645bfa2f816/05-19-2017_friday/effective_cmake__daniel_pfeifer__cppnow_05-19-2017.pdf) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dil5y8y.)^.
I reposted the link.
Those are angle brackets. Braces look like this: `{` `}`. The video title uses substitute characters because real angle brackets cause problems in some situations, such as when saving the video (or a shortcut to the video) using the title as the filename. Most operating systems don't allow angle brackets in filenames because they are used as redirection operators on the command line.
That was with old versions, and we had our cache that got corrupted several times. We lost confidence and stopped using it then. Now, I'm no longer working at the same place, so I can't really help, sorry! I would recommend that you checkout sccache from Mozilla too. They have a crossplatform implementation supporting MSVC and distributed caching too. Pretty cool I think!
The standard solution should probably be mentioned on this thread: [allocator::construct](https://stackoverflow.com/a/21028912)
&gt; but I would really prefer not to :P I'm really glad I don't have to any longer!
I first saw this technique [here](https://web.archive.org/web/20121030234734/http://byuu.org/articles/programming/public_cast) (warning: a couple typos in the code), called `public_cast` - although the syntax obviously isn't identical to `static_cast` et al.
I started watching it last night but fell asleep :) My fault not the presenter's! It looks very interesting, but it makes me wish even more for a well organized documentation.
I meant, they're closely related. C++ is almost a superset of C and if you write a lot of C++ code and handle code from many sources you're bound to encounter serious C-style code. Going from C to C++ is harder, but if you can work in C effectively chances are you're smart enough to figure out C++. A lot of people know both just because they're used in similar domains, and have a lot in common.
So currently I'm working on a Shader Tool for Games and other things. Kinda comparable to this one but without the flownode system https://www.youtube.com/watch?v=9dLycXtChkU
Wow, a tool like that could be immensely useful, have you been working on it long? 
Some users here complained that they couldn't get the full featured PCG rng library to compile on some platforms. This code should compile on any platform and give you a statistically decent and extremely fast pseudo-rng. It is very simple to add to a codebase and use, see API in readme.
How do you guys build the Folly library on windows? Does it even work?
youtube videos? I just use the youtube-dl tool: https://rg3.github.io/youtube-dl/.
Maybe for four months now, off course I only work occasionally on it.
Video linked by /u/ChaIix: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [ShaderTool - Introduction](https://youtube.com/watch?v=9dLycXtChkU)|World Creator|2014-06-19|0:06:56|24+ (100%)|3,563 &gt; Internet: www.shadertool.com Early Access available... --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/ChaIix ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=dili48e\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v1.1.1b
I'd wager that a lot of people who know both actually don't know the design patterns and best practices of one of the two too well, or at least don't have much practice with them. As a "modern C++" programmer you do encounter C code, and of course I can read it well, but I try to avoid it whenever possible and it boils down to *using* it, and not developing and architecturing new code with it. But in general I do mostly agree with your statements.
You might want to make this adhere to the [UniformRandomBitGenerator](http://eel.is/c++draft/rand.req.urng) or [RandomNumberEngine](http://eel.is/c++draft/rand.req.eng)concept to make it usable in the `&lt;random&gt;` context.
I felt like the second half of the talk went a bit off too much on a tangent. Of course it's all very relevant and important. But there would've been more important "general" stuff about modern CMake to talk about first, so the first half could've easily been extended to a full talk. And then, put all that "extended" stuff in a separate talk (maybe online, next year, or at CppCon / MeetingC++) about CMake and all the code analysis tooling stuff. But definitely everyone using CMake (and people who don't because they think CMake sucks) should watch the talk, it's great!
An astrology framework for calculating natal charts and running compatibility analysis for potential partners. Also a chart renderer and simple tools around the framework.
hey there how are you :)
one person's leak is another person's correctness: a vector that doesn't zero on resize cannot be used in some of the expressions where a vector that does can be.
I kind of wanna put this on the programmingcirclejerk but God dammit, don't I ever agree with it. Yeah, I'll do the jerk with ya. C++'s main strength is that it scales with you and as you improve, you're now able to write code that scales with complexity as well. 
I wouldn't, not in a million years. There are of course thresholds, but at no point do I think "readability" (which is more about familiarity than anything else) is more important than compilation time.
We can't use actual braces, for some reason, so Unicode is the best we've got.
A cards game that uses SDL2. A multiplatform translations app.
Drop into...what? It doesn't adhere to the standard library concepts so if I want to compose it with something I do...what?
Currently working on a software defined radio receiver.
I'm writing a tool for process memory scanning and injecting similar to CheatEngine and trying to learn Windows driver development.
&gt; This isn't about the storage that the int occupies, it is about the int's lifetime. The lifetime for standard layout types like `int` is no different from the lifetime for types in general in C++ -- the same rules are followed. You're conflating 'storage lifetime' with 'construction/destruction', but not all types require a constructor to run for its lifetime to start, as long as suitably-aligned storage is allocated. The standard makes this clear at [basic.life] (the "Object lifetime" section), which says that the lifetime of an object of type `T` begins when storage with proper alignment and size for type `T` is obtained, and for classes or aggregates containing at least one non-trivially-copyable subobject, when the initialization is complete. Since `int` is trivially copyable and is not a struct/class or aggregate, its lifetime begins as soon as its aligned storage is obtained. Since C++ defines `std::malloc` as returning storage properly aligned for any type `T`, using `std::malloc` is sufficient for creating new `int`s -- no further artificial construction is required, even for language lawyers. C++ also defines a type's "value representation" to be a subset of the possible "object representations" that can be present in the bits of the underlying storage for trivially copyable types, with a footnote that this is intended to make the memory model for C++ compatible with that of C. In fact, the standard specifically defines an example that uses `new` to create `int` in terms of `malloc` alone, so that behavior must be standard C++. See [diff.cpp03.language.support], which includes this example that the standard says should output "custom deallocation" twice due to the redefinition of `operator new` and `operator delete`, and never uses placement `new` to "construct" the `int` so created: #include &lt;cstdio&gt; #include &lt;cstdlib&gt; #include &lt;new&gt; void* operator new(std::size_t size) throw(std::bad_alloc) { return std::malloc(size); } void operator delete(void *ptr) throw() { std::puts("custom deallocation"); std::free(ptr); } int main() { int * i = new int; delete i; // single-object delete int * a = new int[3]; delete [] a; // array delete return 0; }
/u/tcbrindle: I've decided to host versioned single headers of [mpark/variant.hpp](https://github.com/mpark/variant/blob/master/include/mpark/variant.hpp) at the [single-header](https://github.com/mpark/variant/tree/single-header) branch!
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [mpark/variant/.../**variant.hpp** (master → 6581f32)](https://github.com/mpark/variant/blob/6581f32f455d3382f2a39bb93cf986dcf4e01039/include/mpark/variant.hpp) * [mpark/variant/.../**single-header** (single-header → dde83cd)](https://github.com/mpark/variant/tree/single-header) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dilu6eo.)^.
I'm building an NES emulator. Because I'm pretty sure that's never been done before.
I think the primary point is that you never have to pay for behavior you don't want in Rust. If you don't want to pay for the guarantee that you have valid utf-8 bytes, you can just use `&amp;[u8]` instead of `&amp;str`. You save the cost of validation without giving up safety. Allowing operation on either bytes or strings is a common practice in Rust. See the [nom](https://github.com/Geal/nom#features) library for example. If you want to use utf-8, you *have* to know that it's valid, or else you lose compiler-guaranteed safety. If you want to opt-out of compiler-guaranteed safety, but still treat your bytes as utf-8, that's exactly why unsafe exists. You only pay for the behavior you want. The difference is not that you pay for more, it's that unlike C++, rust assumes you want safety, and lets you opt out.
What were some of your findings' highlights?
**Company:** [TERMA](https://www.terma.com/careers/jobs/) **Type:** Full time **Description:** In our office in the Netherlands we develop ground segment software for the space industry. We are looking for two people to join the team: an experienced [C++ developer](https://www.epos.dk/REK/Terma/Joblist/ShowJobOffer.aspx?dbalias=EposREC_Terma&amp;lang=en&amp;jobOfferEntityId=1177&amp;joblistId=1) (with knowledge of Qt), and a [software product assurance officer / C++ software developer](https://www.epos.dk/REK/Terma/Joblist/ShowJobOffer.aspx?dbalias=EposREC_Terma&amp;lang=en&amp;jobOfferEntityId=1176&amp;joblistId=1). "Ground segment software" is software that is used to test spacecraft on the ground, before they are launched into space. **Location:** Our office is located in a very central location in Leiden, the Netherlands. The company language is English. **Remote:** No **Visa Sponsorship:** No **Technologies:** The fulltime C++ developer will be expected to work in a small team (7 people) who primarily use C++03 with some restrictions ("no exceptions" being one). Their work is Qt-based, and runs on Windows and Linux. The combined PA officer / C++ developer will be expected to work in a smaller team (2 people) who use C++11 with some C++14 and 17 thrown in (the only restriction being that it should work with the compilers on the platforms we support). Their work is not Qt-based, and also runs on Windows and Linux. In addition, this person is expected to provide PA support for both teams. **Contact:** through the links provided above.
Thermal testing software for the space industry: [STAMP](https://www.terma.com/space/ground-segment/stamp) Currently 330,000 lines of fairly modern C++. Oh, and we are looking for someone to come help me! Check the 'hiring' thread ;-)
&gt;There's no reason in my mind why something comparable to the code below couldn't be included in future standards Something like this - [std::apply](http://en.cppreference.com/w/cpp/utility/apply)?
Very cool! This should finally let me adopt `variant` in my work codebase.
Well I'm fine, what are you working on currently ?
From what I understand, std::apply lets you apply a function with a tuple as argument list. What I want is to do is apply a function once per tuple element.
I wanted to learn more about using encryption and found even libsodium's API took a while to understand. Wanting to practice modern C++ I wrote a kind of portable [password manager library](https://github.com/kookjr/libpwman) wrapper for a small subset of libsodium. Hopefully people who are better at user interfaces (that's anybody) can use it to create some non-cloud based password managers, if you like that kind of thing.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [ericniebler/range-v3/.../**tuple_algorithm.hpp** (master → 06894b8)](https://github.com/ericniebler/range-v3/blob/06894b8dfe6894542e3f564287219bed3f2c58f8/include/range/v3/utility/tuple_algorithm.hpp) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dimak7u.)^.
Robotic stuffs at work, games and digital comics tools at home.
I was a bit irked by the fact there was a lot of "don't do this, don't do that", but no clear examples of what I should then do instead.
Saying they are used very differently is just plain incorrect. While the c++ standard does have a large library that in no way would provide a use case where you would want C. Any competent team is either going to use some c library or have an internal one that cover a lot of the really common data structures. Also, you if you meant all libraries you're even more incorrect.
clang &gt; 4 will crash, but it's been fixed in clang 4 https://godbolt.org/g/smyIt0
I don't get the GLOB hate. I find it rather tedious to list the filenames so when I stopped using GLOB I just used vim to generate the list for me. Instead of using a function that generates a list of files at project generation time I now use a function that generates a list of files at close to project generation time. What exactly did I gain by this? It's enough to be aware that newly created files will not be picked up automatically. Maybe some sort of watchdog should be running and looking for changes. Some other languages do it that way.
I know this is just a rant, but with a few more bits of detail you can actually elicit some serendipitous online help. I like sharing this with my interns: https://www.mikeash.com/getting_answers.html
Thanks. Will look into it. 
Same question! We have a project in Go, that we may want to rewrite in C++. But leaving GORM is a bummer...
Right now, I'm doing a SDL2 Turn based strategy game for hobby (and maybe, possibly, who knows, thinking about launching it as a mobile game). My "day job" is Java though, is hard to find C++ jobs where I live.
Most code on the slides shows you that actually - at least the basics, which should get you like 50-75% along the way (or even 90-100% for very simple projects).
I'm working on an action adventure game about undeads which is called [Re:creation](https://eliasdaler.github.io/re-creation/). [Here's a screenshot](http://i.imgur.com/n3eUCxD.png). I use C++14 and try to get most of it. I use [SFML](https://www.sfml-dev.org) as graphics, have a lot of things scripted in Lua and I make some in-game tools with [ImGui](https://github.com/ocornut/imgui). [A gif of a level editor](https://i2.wp.com/i.imgur.com/iQibpSk.gif).
The game looks great and the level editor is just awesome
Robotics in general, or a specific type of robots? (please don't be skynet level stuff lol) What game are ya working on at the moment 
Is it like Ultimate Epic Battle Simulator? 
What theme of card game? Fantasy? Modern? Medieval?
Written in C or other? 
That is using old CMake functionality, I wouldn't recommend it.
Regarding the part about header only libraries, I think his answer was incomplete. The real reason why you need to have a target for it still is that it is an implementation detail. As a user, you shouldn't have to care whether it is header only or not and use it the same way. As a developer of that library, you are then free to change it however you want, adding dependencies that will be propagated automatically or just adding some compiled sources if need be, all without breaking your users code.
Yes, i think graphics programming is one of the most interesting topics and with a lots of challenges. Sorry there is no github project because i am using SVN :D. Until now there was no need to change and my git experience is small. Do you have any benefit for using git? Maybe git can convince.
Sort of. My dream is to make an MMORPG, in a large persistent world, which allows events with many players in the same area, but there is no open source engine for that. I have a lot of 'original' ideas for this, but there needs to be a platform to create this on. 
I'm aiming for something like The Battle for Wesnoth, or advanced wars. 
What is 'debugoptimized build'?
Somehow, `std::hash&lt;std::thread::id&gt;` is included in `&lt;thread&gt;`. It's even used that way without including `&lt;functional` in cppreference
What's the difference from GnuPG? 
I work on a [C++ web framework called Wt](https://webtoolkit.eu). It's mostly used by developers who are familiar with Qt, and in embedded applications. I managed to run the [widget gallery](https://www.webtoolkit.eu/widgets) on my OpenWRT router once (it was about 10 MiB).
A GameBoy emulator with an API in Python. End goal is to have machine learning learn to play some GameBoy games.
So far; stronger crypto, easier key-exchange, encrypted database of peers and capability to encrypt/decrypt arbitrary files for personal use. In the longer run I intend on building more elaborate features on top of the same foundation.
That is Meson's equivalent to CMake's "RelWithDebInfo" build type. Roughly it means `-g -O2`.
I love the look-and-feel of your game (based on the screenshots). Been following your blog for some time. :) Also, a lot of people seems to do games as a hobby. Looks like it's fun not just to play them but to make them as well. I know I have a lot of fun working on mine.
scraping stock prices sounds like something that doesn't need to be done in a language like c++ but can easily be done in python for instance. but yeah, maybe you just want to do it in c++ 
&gt; just getting rid of Golang's in-your-face, paleo-style error-handling was a major win I laughed way too hard at this.
Abusing the INTERFACE keyword is another option of course :) I think this ends up suppressing errors, so it's harder to debug (and CMake is already hard to debug!)
I'm building my own small, imperative Programming language!
Well, as a C++ programmer, I do "Hacks and Quark" every single day.It isn't unusual Also, if compilation of third-party libraries, that build won't go further. If IMPORTED_LOCATION property refer to nonexisting library, that build also fails. It's not hard to find what makes build failed.
Who says C++ Primer is outdated? The latest version is updated for C++11 and is a very good book. The Stack Overflow list is there for a reason. It's not "outdated" just because books are a few years old. https://www.reddit.com/r/cpp/comments/5xvazf/what_books_and_or_website_should_i_use_to_learn_c/ https://www.reddit.com/r/cpp/comments/5pqv8o/whats_the_best_c_beginners_book/ There's threads in that last post that discuss moving from python to C++.
because i get directed to stack overflow, which as i said in my title seems outdated, and if its not, i just need to know as fast as possible.
I'm hoping to make a interpreted language, doing a Lisp as practise but in the end I want a Smalltalk style language, maybe Ruby in design 
thanks!
That sounds awesome, how has work been going on it? 
Only to clear the screen. Input is entered as ”A1" (XY), checked for validity and if it's good it updates the table (double array). ... Yeah noob project!
I'm not sure what you're trying to argue with that comment. C is better for some things but those things tend to be embedded applications. C is by and large far more verbose and uses certain things like function pointers at times, which a programmer doing C++ applications might *never* need. Likewise, C++ has a ton of shit in it that a C programmer would never be aware of unless he studied it. Also, one could learn to be a reasonably proficient C++ programmer without learning much C. For a programmer that focused on one or the other, being proficient and aware of best practices in both takes a bit of effort. &gt;While the c++ standard does have a large library that in no way would provide a use case where you would want C. I don't think I argued that people should use C or not use C, I said there are cases when one or the other is better to use. I personally prefer C++ with only a few C standard favorites thrown in, however I know there are reasons to stick strictly to C for some applications in spite of its drawbacks. C++ is really designed for generic and systems applications more than embedded. Rather than make me half-ass explain the reasons why C is preferred for certain applications, go look up why Linus Torvalds likes C for the Linux kernel (I don't necessarily agree with him, but he makes good points), and go talk to some hard-core embedded programmers.
We needed GCC 4.9 support in order to work with a particular version of the Android NDK.
T!hat's cool, I have no clue of professional compiler design, so my project is going to look similar to the windows console. My goal is not to make a very usefull language but to prove and consolidate my learned c++ skills!
I'll certainly keep it in mind when I get around to doing a simple enough engine (if that exists lol) 
Great to have a fellow hobbiest, there wouldn't be anything that would make my language stand out from the crowd so it'll be a labour of love
*Accelerated C++* remains in the list for two reasons: 1. Even though it uses C++98, the *practices* it advocates are relatively modern, and 2. There's nothing else really similar to it that *does* use a more recent version of C++. That said, I'd concur with your recommendation of C++ Primer, 5th edition.
Updating my json serialization library to store the meta info statically so that there is no space cost per instance to use it and only the cost of using it when serializing/deserializing. Previously, it was quicker and easier, to have a per instance cost. Also working on my node like c++ library that sits on top of asio. Oh yeah, and whatever the nerd snipers hit me with. They are relentless.
As a Rust user, I have to say that these are benchmark games. I think it's mostly to prove that rust has the capability to be as fast, or faster, than C++ - but I don't think there's any disagreeing that a well-written C++ program can be many times faster than a below-average Rust one (or vice-versa).
It's used as the underlying storage type for a `variant`, and it's required for `constexpr` support. Are you asking about more specific parts of it?
I see, please let me know if you run into issues! 🙂
Proper SIMD excluded, parallel additions are obviously the best way to do this; the problem is that you've gone and implemented it inefficiently. https://github.com/jpakkane/speedup/blob/502d3cd42ddc79f9bf03ded39c0b7d5c8a8fc6f4/speedup.cpp#L121 Here's a better way, cycle-by-cycle 1. `high_bits = x &amp; SIGN_BITS` 2. `low_bits = high_bits &gt;&gt; 7` 3. `mask = SIGN_BITS - low_bits` 4. `mask ^= SIGN_BITS` 5. `to_sum = x &amp; mask` 6. `to_sum_hi = to_sum &amp; EVERY_FIRST_BYTE`; `to_sum_lo = to_sum &amp; ~EVERY_OTHER_BYTE` 7. `running_sums += to_sum_lo`; `to_sum_hi &gt;&gt;= 8` 8. `running_sums += to_sum_hi` Now repeat up to 255 times before doing a reduction on `running_sums`. You can unroll this to get at least two of these running in parallel, since modern machines are fairly wide. There is no significant loop carried dependency, so you can easily saturate the functional units. The latency can be lowered, but if you're pipelining the loop it's better to go for lower FU usage, which this seems to give. If you really want to do a LUT, note the `PEXT` instruction.
FYI, NASA and F1 Williams are the 2 most prestigious companies which purchased QxOrm/QxEntityEditor (I'm proud of that :)). That doesn't mean that the library is perfect but it can be useful for some projects. 
It's interesting. I haven't had a proper look at it yet, but it could be nice to eventually be able to either run a Wt app completely in the browser, or even better, some sort of hybrid scenario where your client side and server side code can be written in C++ (and some of it shared), a bit like the reverse of Node.js. I'm not sure how attainable that is, but it would be interesting to explore.
You mean the compiler? It's written in C++17, of course.
VS2017 compiler fails to vectorize this (/Qvec-report:2). And it doesn't seem to help to add pragmas (loop(hint_parallel(256)) or loop(ivdep)) or change the array access: https://godbolt.org/g/1KdcfE. It seems you need to either use a different compiler or use intrinsics or a SIMD library.
The problem with that approach is that you don't forward all the current build environment to the sub-cmake project that way. If you have a toolchain file, it won't work. If you have global options (like enabling ASan), it won't work. If you wanted a debug or coverage build, it won't work... It's way easier and robust to extract the files for it and just use `add_subdirectory(googletest EXCLUDE_FROM_ALL)` there to get it to work.
ah yeah sorry about that, i'm currently quite busy so i didn't try to compile all the code in the post, the most important examples i have compiled tho again sorry, i'll fix it right away
What on earth does this need C++1z for?
Correct, the official implementation is header only and fairly simple to use too. Some users here complained that it couldn't compile on windows. I tried dropping the headers in a windows codebase of mine and it contaminated the std namespace in intellisense, for example. Also this implementation should produce random floats in [0,1) much faster since it uses a really efficient bitshift technique that the author of xoroshiro128+ created. The pcg implementation (and this implementation yesterday) uses ldexp to create floats from ints which takes 150% longer to produce floats in my benchmarking.
So the ",T" is wrong right?
Because the type of the argument "x" is dependant on the result of the enable_if. This enable_if is dependant on T. So the compiler can't deduce the type of T. The only way to fix this is to explicitly tell the compiler what type you want for T. (or to add another argument)
You do realize that "RC" stands for "Release Candidate" right? The full version of Visual Studio 2017 is now in general availability. Do the upgrade to that and see if it resolves your issues.
Oh, sorry, I misspoke about RC1/2 -- I am actually using a "2017 Preview v 15.3.0 Preview 2.0", freshly updated three hours ago