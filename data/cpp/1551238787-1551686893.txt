&gt; 'm a little out of the loop, I expect I'd be terrified of a change in semantics towards lazy argument evaluation It'd certainly be a new opt-in feature, of course. It would replace a major use of macros which already have problems worse than I'd expect a properly-integrated lazy argument solution to take place. It may not take the form of actual lazy arguments, but rather "hygienic macros" or any other number of solutions. Basically anything that lets one write `debug_log(something_expensive())` and be sure that the call to `something_expensive` is compiled-out if debug logging is disabled or compiled out. Not aware of any active proposals in this front at the moment. I suspect any such solution here would go a _very_ long way towards deprecating macro (and header) usage in modern C++. &gt; When I last left off C++, templates still had to be defined entirely in headers. This has never been _entirely_ true, but it's certainly true enough. :) That said, C++20 has (will have) Modules which removes the need to ever use headers for language item declarations (be they templates, classes, functions, etc.). The remaining uses of headers will entirely be: - legacy uses - preprocessor tricks Some module features are even removing the need to use headers even for old code (e.g., it will automatically convert an imported "header" into a module interface) but the preprocessor tricks remain an issue. C++23/26/ZYX Reflection will remove _some_ use of macros, but the `debug_log` kinds of things currently have no active solution on the horizon. If we get those we can move on from headers entirely in new code, I think.
I’m okay with rants but I don’t see what this contributes. 
Do not want. What I would like is an explicit 'goto case' a la C#. That said without deprecating rhe current walkthrough lacking an explicit break.
You don't? I do, that's not even a rant to be honest, the guy is being pretty open and clear about what the pain points are, and that is the contribution, if C++ hopes to please that niche of programming.
I disagree. This is not as much a rant as a carefully considered position on C++
I have no objection to what you said but I'm curious about data structures that can only be implemented with memory leaks.
Difference of opinion. I thought it was unfocused and confused in its message. 
What a bunch of whiny nonsense. Most of his complaints boils down to things that he doesn't use because his legacy stuff was designed around older versions while also complaining about things that aren't there (like modules) when they are actively being worked on. He talks about making his own 'bespoke' data structures then whines about alignment. He complains about having well performing debug builds which is a compiler issue. He complains about not having SIMD types built in and serialization in the standard library even though there are libraries that exist for these and he could make his own if he needed to design something 'bespoke'. Really seems like someone blaming all sorts of stuff on the language and offering no solutions.
Which part specifically seemed carefully considered to you?
I was mostly puzzled when he says no one uses the STL, but then went on to mention some desired features that sounded like candidates for the STL. 
The elements in the expanded code can be of different types.
I agree that for users, prebuilt binaries make things much easier. You can find them under Releases on the gitlab page. If you are getting along fine with Python, then there is no need to change. However, if you need something else, you should also look at objcopy in GNU bintools. Also available on all platforms, and a little more mature...
Did you read the title??.....
Did you read the article?
Yes.
There are more usage requirements of libraries than just "use header -&gt; link this library". In CMake, you can have properties on targets which say "you must build with at least C++14 to use me", "add these preprocessor defines", "you may include me, but I include files in /some/other/path, add *its* -I flag", "you need these linker flags to actually work with me", "I'm -fPIC, you should be too", and more. While I understand the motive for build graphs completely inferred from source code, C/C++ is just not that place today (in general; Buck may be able to force such conventions on the source code it builds, but CMake doesn't).
\&gt; Interestingly, CMake, the most popular C++ build-system, does not get this right. Where it could offer guarantees, it only offers conventions. Well, by the time CMake could discover `-MM` flags, the build has already been written and CMake (the program) is out of the picture. Linking to a CMake target is also not just "add this library to your link line" either, so a simple response file written somewhere during the build for the linker to use is not sufficient (nevermind that this file may be updated by any TU compilation rule in a library target, something build tools tend not to like too much). I guess combination configure/generate build tools can do this, but CMake is a build *generator* and does not execute the build at all.
I've added some c++11 unorded\_map interface now, my code is quite fast from my benchmark. I'll put to the benchamrk code to git a few days later. you can try to add it to your test case. &amp;#x200B; ================ n = 3024465 hash map =============== 400 emlib4 540 flat hash 572 hopsco 576 robin hood 684 hoodflat 2584 unordered\_map =======================================================
Important messages should not be written to `std::cout` anyway. Both of `std::clog` and `std::cerr` are line-buffered and will automatically flush on `\n`. Important messages should either be sent through one of them, or through a logging framework which is appropriately configured.
&gt; I don't want to post all the relevant bits, but the crux of the issue, for the lucky among you who don't do social media, is the growing disconnect between people woking on big, complex, performance-sensitive and often monolithic and legacy-ridden codebases that we find in game development, and the ideas of "modernity” of the C++ standard community. I'm just going to throw it out there: I'm tired of reading this kind of stuff from game devs. There's just so much of this kind of stuff. Acting like they are the only ones with performance issues. The only ones with complex codebases. The only ones who actually ship code. The ones who are just solving more unique and difficult problems than anyone else, for which c++ falls short by more. This stuff is just nonsensical on its face. Tons and tons of people on the committee, and otherwise participating constructively C++, are working on large, complex, performance sensitive (and sometimes why not monolithic and legacy) codebases. None of those is unique in any way to game development. This whole paragraph is so fucking cringe I couldn't even keep reading. I'm only writing this because I'm worked up, but I honestly suspect that the reason that so many game devs seem to feel the need to posture on the internet is because they are overworked and underpaid relative to so many other places that employ C++ devs; believing their disciple is the "best" seems like an additional form of compensation or self reassurance many people seem to need (judging by how common these posts are).
Googling for "iprof profiler" and "iprof profiling" both return as the ***first*** result: &gt; IProf: Industrial Strength Profiling - Silver Spaceship Software
This is not bikeshedding: profiling has a concrete meaning in software engineering, sorry. The StackOverflow answers in that link you provide are actually *disagreeing* with you. Please do not misconstrue them.
I really enjoyed Clean Integral Code. It's easy to understand and provides some great insight about many pitfalls of integer type.
Ahh, I see. Thanks for clarifying.
As a former game developer and current committee member, that was hard to read -- mostly because I couldn't shout through my screen. I know exactly why the game developer world is the way it is, and why the committee is the way it is, and it's really much simpler than the author realizes: game developers are under horrible pressure to ship, ship something no one has ever seen before, do it without paying very well, do it by throwing people at the problem, on cycles of binge and purge, and chronically underinvested in anything that doesn't immediate translate into the next title. Those are industry problems, but they rub off on and see internalized by the people willing or able to survive there long enough. The reason C++ isn't giving have developers what they want is, despite having a study group dedicated to listening to game developers, none of them show up. That's not quite fair -- there are notable exceptions, who are exceptional in that they're not coming with mandates from big studios and laundry lists like the author presents, they're individuals who just want to participate for personal interest. What's more those of us who know what game development is like, know how impossible it'd be to deliver something that would make anyone happy, let alone everyone -- the graphics proposal is exactly this. And probably audio next. Having worked on a couple game engines, there's very little from those code bases one could generalize to a standard, let alone again integrate it back into an unrelated game engine. Those code bases are designed to be monolithic and hackable as a single unit. Games don't like gluing random libraries together -- they'd prefer to reimplemented from scratch for their custom temporal requirements. About the only thing I think would make games happy and make a broader community happy would be a library for CPU vector math. So where is the open source library for said that establishes demand and best practice? That's right, game companies don't invest in community. And there's the problem in a nut shell. Community investment is a one way street where C++ should serve games, but games doesn't need to serve itself through the community.
Games don't use STL because it's worth their time to rewrite containers from scratch to support unique use cases, tight memory requirements, or 2% performance increases. That's also exactly why nothing we give them works make them happy.
It seems like you really missed the point. &gt;Most of his complaints boils down to things that he doesn't use because his legacy stuff was designed around older versions I honestly don't know where you got that idea. He mentions "legacy" code once in passing in the opening paragraph. &gt;while also complaining about things that aren't there (like modules) when they are actively being worked on. Yes, it's being worked on. So is cold fusion. Neither helps anyone writing C++ today. &gt;He talks about making his own 'bespoke' data structures then whines about alignment. He said they write their own data structures because the standard library did not historically play nicely with alignment. &gt;He complains about having well performing debug builds which is a compiler issue. Unless you're referring specifically to MSVC's notoriously slow debug iterators this is not a compiler issue but an issue with the standard library. "Zero-cost abstractions" in C++ are more often than not predicated on the compiler removing numerous layers of indirection which doesn't happen in unoptimized builds. &gt;He complains about not having [...] serialization in the standard library even though there are libraries that exist for these and he could make his own if he needed to design something 'bespoke'. But this is exactly the problem. Everybody ends up writing their own serialization, middleware providers write their own serialization, and suddenly within a single application you have multiple different serialization systems trying to interface with each other. &gt;Really seems like someone blaming all sorts of stuff on the language and offering no solutions. If somebody says to you "it's not you, it's me" they're probably not about to offer any solutions for your failing relationship.
He also has zero sense of perspective of how C++ community works. They're used to big vendors running up and and asking them how to make their GPU or console run the latest game faster -- but C++ is not a vendor. If game developers want something specific they need to pay the relative pittance to actually show up to committee with concrete proposals to see though standardization. Where's the preexisting libraries we can standardize as best practice for game development? They're all proprietary and hyper specialized to a game engine you say? Hmm...
Nailed it.
While writing the benchmarks I've added one that is very similar to what you are doing in your benchmark: https://github.com/martinus/map_benchmark/blob/master/src/benchmarks/RandomDistinct.cpp This benchmark puts a lot of weight on insertion performanc, and absl doesn't shine with that.
How many titles have you shipped? Games will never stop using C++, because at the end of the day, games are made by huge corporations, with the help of other huge corporations, so that they can make lots of money from the bored and vaguely dissatisfied masses at Walmart or the next viral thing everyone's talking about at school, and what the programmers think about their language is mostly irrelevant. If it wasn't game developers would be at committee meetings, it maybe just fucked off and writing their own language. Some of their complaints have merit. Some show a complete lack of awareness. Either way no one is hurting them but themselves.
Keep in mind that we're talking about a world with only smart pointers. The simplest that comes to my mind is a cyclic doubly linked list. If you use reference counted `shared_ptr` the count won't ever drop to 0 (memory leaks). And if you use `unique_ptr` you would need some trickery to have a node pointed to by both adjacent nodes (invariant violation), and then you'd run into issues like use after free. You can say "just use `weak_ptr` to break the cycle", but I really don't see how would they help. &amp;nbsp; Now one might argue that linked lists shouldn't form a cycle, but it was just an illustrative example. One can easily imagine tree-with-loops kind of graph structure where the loop would exhibit the same implementation issues. &amp;nbsp; Bottom line is, sometimes you absolutely need raw pointers.
I don't know... I only worked on a AAA game once in my 12 years in gamedev, and it didn't ship in the end, but in all our projects, we used STL and even, at times, Boost. Certainly, in some areas it's worth to implement your own containers: deep rendering code, maybe physics or low-level networking. But the rest of the game code? I don't think game mechanics or UI often needs custom containers, aside from an intrusive linked list, which exists in Boost, and would make a nice addition to STL. Anyway, both this things are often moved out of C++ into some scripting language, like Lua. Performance is not *very* critical there, but the speed of writing and re-writing the code is. But let me tell you - I absolutely love things that has been happening to C++ since the 11 standard. Lambdas and auto and in-place initialization all make code faster to write, which is the prime requirement (along with performance) for a game. They might make the codebase an unmaintainable hell (though not necessary: simple self-restraint and common sense are usually enough to prevent this), but it's a game! Unless you're writing a MMO, you're going to ship it and forget about it pretty soon. Once again, I'm not talking about reusable parts - render, sound system etc., but the game mechanics and UI code, which is going to be thrown out for certain. The only thing I'm pissed about is that generative C++ is so far away. I need this thing in my life! Writing serialization is one of the most boring, yet inevitable tasks that exist, and generative C++ will make it about 100 times quicker and remove tons of boilerplate and repetition. The code will be a little harder to understand, since generated functions will not be directly visible. Do I care? Not. One. Bit. Anything that allows me to write less boilerplate and make less mistakes when repeating the same stuff in several places is a godsend. I guess maybe this difference in opinions comes from me being a game mechanics/UI programmer who never touches things that require high performance. Call me a glorified scripter, but that's the way I see things from my trench. Bring on all the new features!
Anyone want popcorn? No reason to be shy, there's enough for everyone!
Lots of games are made in c#. At least one prominent game developer is making his own language (called Jai) Modern c++ is being used in games. Unreal Engine games can be written in c++14, and while they have an STL replacement, they have added things to it from c++17 and the guideline support library. There are some good reasons they don't use the STL, but I suspect they could move to STL if they wanted to. And for the record I've shipped five games 😀
&gt;How many titles have you shipped? Oh please, stop posturing.
Curious, about serialization, why not just use protobuf?
It would be nice for people to stop this gamedev/non gamedev clivage. And I mean that for both sides. The author is right on quite a few points, and is basicly saying that those (in gamedev) who do not like the new additions should just shut up if they are not gonna contribute. (yes, it's kind of running in circles). It is not worth the hate I'm seeing here, but again, this is reddit. please just stop antagonizing gamedev/non gamedev, this is just counter productive. 
my thoughs exactly. failing to open a file isn't such an exceptional case so return value + no discard is fine here. &amp;#x200B; &amp;#x200B;
&gt;I don't like it because it goes against C++'s spirit: don't pay for what you don't use. We're in 2019. CPUS are fast and memory is cheap. the reasons to write C++ are "performance" only. If you want to squeeze out every gram of performance from your hardware, use the larger C++ standard. &amp;#x200B; If you just want something fast which is also safe (+ doesn't use a language VM), subC++ is suffice. this argument is invalid for subC++. it's still very very fast cuz it's still C++, but it's safer. for 90% of apps out there, this is an OK tradeoff.
Executors is gonna be in c++23 though - arguably one biggest and most important new features that we've been waiting ages for
Doesn't contradict what I said does it? Do whatever you prefer in your codebase and make a decision about it in your company's style guide and be done with it. Having this argument on the internet again and again doesn't bring us any closer to an agreement, so why spend the time? But then, the c++ community on the internet (including me) really likes to argue about those tiny details in our coding styles.
True, I forgot about them. But google explicitly tends to use standard library names, when they want to mimic its concepts (as here with the begin/end). And yes, being able to work with different styles is apparently a core competency for every c++ programmer ;)
Amazing! so it's not such a new idea. let's do the same for C++
The problem is getting data into the protobuf in the first place; it's great as a serialisation mechanism, but terrible for runtime storage - its data layout is often bloated and allocation heavy. You can't select containers, or use anything other than primitive types.
absl is excellent when you only do lookups, but it gets relatively slow when you do lots of insertions and removals. There the robin hood maps with backward shift deletion shine, they are a lot faster even though they need to shuffle elements around. This can be clearly seen in my benchmarks. In all of my benchmarks, my robin_hood::unordered_flat_map's or tessil's tsl::robin_map find performance is just a just a bit slower than absl, but insertion &amp; removal performance is much better. My map even has practically the same memory requirements as absl's flat_map, tessil's uses a bit more memory. 
As a gamedev working in C++, I don't really get it either. You're (for the most part) free to not use the features you don't want or need. However, the issues with compile times, debug build performance, debugger problems with modern C++ features and so on are very real for us. And the language has been getting worse for a while. 
&gt; Then implied concepts were not aimed at usability improvements. The relevant sentence says _"And we keep adding metaprogramming (templates) features before tacking complexity and usability issues (e.g. concepts, that now are scheduled to be in C++20)."_ Looks to me that he's implying that concepts *are* aimed at usability improvements, he's just lamenting about them not being integrated yet.
&gt; "Zero-cost abstractions" in C++ are more often than not predicated on the compiler removing numerous layers of indirection which doesn't happen in unoptimized builds. This is mostly a tooling issue. There are several solutions to this: make optimized builds more debuggable (you *do* know about RelWithDebInfo, right?), make debug builds faster (perhaps by module-specific optimization levels), finally create syntax (range for, coroutines) that help the debugger focus on relevant code in step mode. 
On the spot. Do game developers have phones? Do they use mobile internet? Well, those Telecom-grade backend systems are quite often built using C++. Performance is crucial. Stability is crucial. Code base size and complexity? Well, some of those systems originate from the mid-1980s (or earlier). Tell me a game which has been maintained for over 30+ years. The complexity of a network redundant system is just mad. 
&gt; generative C++ is so far away [Reflection TS](https://github.com/cplusplus/reflection-ts) is looking a dead cert for C++20, and once you have `reflexpr` you can write your serializers using a compile time loop construct (e.g. `hana::for_each`).
Aaaaaah missed "In the second part of the series" before "we’ll see changes from C++17, and we’ll even have a peek of what will happen in C++20". Great article, looking forward to the follow-up!
What about flatbuffers? https://github.com/google/flatbuffers
Not a game dev, but I'm using protobuf right now at work. The thing is a bit of a mess, with required field being actually optional, the incompatibilities between versions… but the root of the problem is that protobuf does not serialise your objects. Protobuf serialises *its* objects, defined in the .proto files. Those files then generate C++ (or Java, or other) classes, which have the specified structure, and easy to use serialise and de-serialise methods. Problem is, those classes are probably not what you want to use in your application. Accessing the data in them is a chore, and forget about controlling the memory layout (for all I know it could be pointer spaghetti under the hood). So in practice, we have our objects, that we translate back &amp; forth to protobuf objects, and then we (de) serialise *those*. While we no longer need to serialise, we still need to translate, and the runtime cost is greater than serialising directly. This makes protobuf fairly useless, especially when you have saner alternatives like [MessagePack](https://msgpack.org/). 
 Not all gamedevs agree with this dude.. &amp;#x200B; I'm perfectly fine with the C++ additions of 14/17/20. Won't use all of it, but unlike this guy I don't believe something I'm not using is somehow going to hurt me.. &amp;#x200B; Also C++ compile times are manageable--although it does require (somewhat excessive) discipline on the part of the devs . Adding SIMD types to C++ isn't going to be that useful.. we already have intrinsics and can implement this ourselves, which is probably for the best if performance is what we are after. &amp;#x200B; \*If I could magically switch to Rust, and Rust had an ecosystem on par with C++.. well I'd do that.. but that isn't the case-- &amp;#x200B;
Him bashing std::move is actually hilarious. I already see how his blog posts looks like when the game industry moved from C / Assembly to C++
Could you add Qt's?
Isn’t that like saying that 6 is a multiple of 4 because 2 is a divisor of 4 and 2 is a divisor of 6 as well?
In 3? Uh, you still have to discover a lot, believe me, haha.
Do not get me wrong. I think concerns should be shown. But it has gone through approval, through a proposed TS for tooling and investigation of best practices, and a TR is coming. Yet you still keep saying how bad it is going to be. I do not know modules in enough detail to comment deeply, but I am sure that if it was so bad or intractable as you seem to show it, then they would not have been in. The same way concepts in C++11 were kicked out. 
For hashing integers if you want to (mostly) remove the overhead of the hash from your benchmarks and still get good results(compared to identity), you could use a hash that simply invokes \_mm\_crc32\_u32/\_mm\_crc32\_u64. Just 3 cycle latency, and pretty decent hash.
The original point was about debug performance, not debugging. Better tooling doesn't magically fix the fact that there is at least an order of magnitude more code generated for your "zero-cost" abstractions without compiler optimizations enabled. The processor still has to execute those instructions regardless of how clever your debugger is.
&gt; Unfortunately, incbin is not available on windows. Yes it is. That is if you are using gcc or clang compilers. I am using `.incbin` inline assembly all the time on Windows when I am compiling with clang using Visual Studio. Works perfectly fine (mainly for .glsl shaders).
Rather c=1+i where c is zip_with 1=transform and i=zip. When talking about 1, i or c you must be aware or the 2 others.
Not sure I will ever go back to clean up legacy CMake, but good to know the knowledge is out there. 
I've actually played around a bit with `_mm_crc32_u64`, folly uses that too. But it has a big problem: it produces just a 32bit hash, so the upper 32bit of the uint64_t are set to zero. In some cases this is very bad behavior for absl map, it simply times out; and my robin_hood map is also slowed down a lot because it uses some of the upper bits of the hash. This can be sped up by simply multiplying the crc result with a random odd uint64_t value, but this adds enough overhead that the result is slower than what I'm doing in robin_hood hash now.
One do not "just use" protobuf - you need to write a second definition for every serialized class, in a separate place (proto file) that's easy to forget to update when you add or remove fields, or change their types, and you need to integrate the code generation step into your build process, which is relatively trivial, but still not a zero-cost operation (even less so when cross-compiling stuff to Android or iOS). Also, protobuf-generated classes weren't very convenient to use in game code for us, and we had to copy data from the deserialized class back to our own structures (that depends on your preferences, of course, but we like our game object states to be public POD structures, without multitude of accessors). Then, there is the fact that Google's protobuf library relies on global static variables to work (or at least used to rely on them last time I used it), which caused us a very *interesting* debugging session on iOS once, when some system framework silently linked in a second copy of protobuf library. Fun times! In general, protobuf is a kind of solution, but far, far from ideal one. I might even argue for Boost.Serialization instead: it forces you to write (de)serialization operator in the class itself or nearby, and has the set of quirks of its own, but removes the need for external compiler and allows you to keep your structure otherwise the way you want it. Also, there are a few solutions that use LLVM to generate serialization code with less mental overhead. But it's also a crutch. Reflection (and/or generative C++) FTW!
Yes, I'm very glad Reflection TS made it (though it'll be a few years before it's safe to use in cross-platform code; specifically, Apple's libc++ seem to always lag behind the standard these days: still no support for std::variant last time I checked, boo!). But generative C++ opens up so much possibilities! It's like templates on steroids. Or macroses, but more sane, featureful and debuggable.
You are right - didn't think of those. We also might get some reflection. But on the other hand: I believe it when I see it ;)
That is absolutely not the problem with debug builds in game development. If your debug build is running at 0.3 fps, your ability to run the game in debug mode is pretty low, regardless of tooling. It used to be that debug builds where, say 50% slower than optimized builds. Nowadays, the difference can be huge to the point that your full debug build is next to useless.
Hu, I would have expected that they computed the hash slot as: \_mm\_crc32\_u64 &amp;(some power of 2 - 1) &amp;#x200B;
Well we will have to disagree to some extent. I see std::endl behavior making perfect sense in a streams implementation. This due to the end of a line often being an end of record. You end up getting the right behavior for simple writes to terminal or files. Right being max functionality with minimal programmer involvement. The stream does the right thing without requiring extensive developer involvement. 
&gt; You're (for the most part) free to not use the features you don't want or need. Unless you ask advocates of modern C++. Then you're told that you must (must!) use some things (containers, various 
Great post! &gt; a library for CPU vector math Would Eigen not satisfy the requirements in game-dev? It is a "more general" linear algebra library but it has fixed size types for 2/3/4-element vectors, 3x3/4x4 matrices, it has transformations, cross product etc.
I don't know how absl does it, but in robin_hood map I do something like this: auto h = hash(key); idx = h &amp; sizeMask; additional_hash_info_bits = h &gt;&gt; (64 - 8); So I use the lower bits for the index, and store some of the upper bits additional_hash_info_bits for quicker comparisons.
&gt; I might even argue for Boost.Serialization instead Or perhaps [cereal](http://uscilab.github.io/cereal/), a more modern alternative :-)
That's funny because I haven't seen such advice in Core Guidelines. Where did you find it? It's terribly incorrect and I'm afraid you got a wrong idea of what the Modern C++ really is.
So enable optimizations in your debug build?
OK, so you need to enable optimizations in your debug build. If that makes debugging your own code difficult, module should help fix things by allowing per-module optimization levels. Again, this is a tooling issue.
It's easy to ignore what someone on the Internet says and just use what you want (although I haven't found a use case for raw pointers for long time even if I find them conceptually easier). What's hard to ignore is when you (finally!) make the switch to C++11 and suddenly your codebase takes 27 minutes to compile after a crucial header change.
Try mentioning raw pointers here or in other C++ forums and see how almost every time someone will claim they’re outdated / non-idiomatic / against ”modern C++”. That’s why I put the quotes around ”modern” in the original comment. Containers are great _when_ they suit the problem but they definitely do not always do that. 
I'm guessing here, but my best guess is that /u/sempuki means something like https://github.com/QuantStack, where there are a number different projects designated x*, but yes, as /u/sempuki says, they're not game-devs.
I agree with your point. Absolutely, each tool works the best for what it was designed for. I hope you would educate such people that they have an incorrect idea of the Modern C++ and point them to Core Guidelines, they agree with you too! 
I’ve been lucky enough to work on projects without significant use of the slower additions, so I haven’t run into that myself. The struggle is real, though, particularly with the on-going fashion of header only libraries.
&gt;Acting like they are the only ones with performance issues. The only ones with complex codebases. The only ones who actually ship code. The ones who are just solving more unique and difficult problems than anyone else, for which c++ falls short by more. **This.** And to be fair, it's not only the gamedev industry with such an attitude. It just happens that they, many individuals, are being very vocal about it recently. What I found as a common fallacy among such groups of people is the false sense of uniqueness and difficulty of problems they're trying to solve. And \_that's\_ what makes them think they're accountable for different "opinions". I've seen it basically across a whole lot of different industries which happen to rely on software engineering in one or another way.
I sometimes need to be able to step outside of "safe land" to get things working. I like C++ because I can write most of my code in "safe land" (smart pointers, RAII) but break out when I need to
I’m pretty sure he means that concepts is a metaprogramming feature that is getting into the spec before, in his opinion, more important things regarding complexity and usability.
That's true. And specifying a function as `noexcept(true) || const noexcept(false)` in the type system is probably hard or impossible, if it makes sense at all.
I did lots of research into package managers and build systems for $WORK. We were greenfield so anything was on the table. These are my findings, YMMV. * Conan - Claims to support every build system but you need to write these Python scripts to tell Conan how your build works. Lots of magic, made me nervous. You also need to manage remotes, local remotes, so many remotes! We wanted something simple and this put me off. IDE integration did not work reliably. I asked about reproducible builds and they said it is as reproducible as you want to make it. So it is not really reproducible. https://conan.io/ * Hunter - All packages are defined inside a single repository. You need to fork to add packages. Everything is driven by CMake. We want to deprecate CMake internally due to poor syntax, no reproducible builds, and all the other issues you probably know already. https://github.com/ruslo/hunter * Buckaroo - Opinionated but simplest solution. No need to manage remotes or forks of package lists since all packages are just Git repos. We use GitHub private so this was a plus for us. We were a bit hesitant about using Buck build system, which they require. Turns out the Buck gets most things right (I used and liked Meson, Bazel in past), and writing Buck files was less work than integrating CMake projects anyway. Also, and this was big for us, Buckaroo actually supports Java too. Maven support was hacky though. We were able to create iOS and Android builds from a single build tool / package manager. Documentation is poor but they were responsive to my emails. Needs more packages. https://buckaroo.pm/ * VCPKG - Similar to Hunter but from Microsoft. They don't have older versions of packages which might be a problem. Again everything is done in CMake, so builds get more complex and slower over time. I think VCPKG has the most packages. https://github.com/Microsoft/vcpkg I hadn't heard of Bake before doing my analysis. How do you think it compares? Some people in C community were talking about package managers too https://www.reddit.com/r/C_Programming/comments/6uv091/any_good_c_package_manager/ I want my package manager to handle C *and* C++
YES! Buck and Bazel work this way. You do not need to manage build folders by configuration, and they always detect changes properly. https://github.com/fbsamples/bucksamples/tree/master/hello-buck-cxx This is the future of C++ build systems. Eventually the community will catch on. 
What separates the gamedev industry from many other prominent users of C++ is the combination of need for low latency and inability to ”just throw more hw at it”. Particularly the first bit seems to be neglected by the wider C++ (and programming) community almost always (just observe how often ”lock free” is taken to mean ”throughput better than simple mutexes” with the implementations falling back to using mutex if there’s contention).
a-god-damn-men!
Are those telecom systems blindly using the latest fads instead of having specific requirements of things you do and don’t do? I’m fairly sure it’s the latter. Yet whenever people (here and elsewhere) tell others to ”use modern C++ / idiomatic C++”, they’re saying ”use this subset I approve of because I know what’s better for your problem than you”. So really, what gamedev people mostly seem to have a problem with is the C++ community (forums and people who select what gets into the standard) more than the language itself.
Strangely, this starts working only with GCC 7.4, earlier versions don't recognise `__builtin_constant_p` as returning a compile-time constant value. ICC 19.0.1 also doesn't seem to support it, does anybody know whether it has some alternative builtin?
It’s not the same, for the sole reason that `zip`, as a quasi-archetype of the class of `zip_with` operations, is occasionally used as a synonym for `zip_with` (it functions as a special case of [synecdoche](https://en.wikipedia.org/wiki/Synecdoche)). This is somewhat sloppy but, given the proper context, there’s generally no risk of confusion.
Why are containers constructor and destructor `noexcept`? Doesn't that depend on the contained type's constructor and destructor?
The question one should ask himself/herself is *why* would you need to *run* the game in debug-build in the first place? That is the crux of the problem. FWIW I can't remember if I ever needed to *run* the whole car-infotainment system or solely the navigation-part of it while developing a GoogleMaps-like auto-completion engine for it (from scratch). As to get a feeling about the size of the project, whole infotainment system counted 10+ MLOC. Navigation systems happen to share many similar aspects with the video games: * Custom GUI frontends (very often running *multiple* frontend instances *simultaneously*) * Customer- or project-specific features built on top of the core (a.k.a "game-play" part) * Core part implementing algorithms and common stuff which is shared across different projects (a.k.a. "game-engine" part) * Crunch-time development due to stringent milestones (read impatient customers and often *many* of them *at the same time*). * So, pressure was (is) quite high. * We're talking about German company which means no or very little overtime. * Still, each developer was deploying no less than 1-2k LOC per 2-week (Scrum) sprint in average and very often much more than that. That's a lot of code. So, in principle navigation systems have their (own) 2D/3D graphics engines, database backends, a lot of data from external sensors to process, AI stuff ingrained somewhere deep inside, hard algorithms to solve and many many other things ... And yet they also have to maintain the FPS rate. Automotive industry happens to have solved the problem of many issues others are complaining about, including inefficient development and main source of frustration through the usage of debuggers and debug-builds. How did they manage to do that? They *completely ruled-out* the usage of debuggers and debug-builds by putting much more effort into the well laid-out system architecture, many-levels testing (system/integration/unit/mocks *and* CI.
\&gt; What separates the gamedev industry from many other prominent users of C++ is the combination of need for low latencyReally? I thought the main use-case of C++ is low-latency, deterministics, soft real-time systems. I don't see why gamedev
I've tried to add QHash, but it's syntax is so different from all other more stl-compatible hashmaps that I don't want to add it at all.
Yes, (low level) embedded has even stricter requirements than gamedev. I didn't mention it since it appears that a lot of people in the community like to pretend it doesn't exist. And I did put "many other" instead of "most". FWIW, I've worked mostly in embedded for the last 10 years and know well just what kind of limitations there can be (and why blindly telling someone to "use modern C++ feature X instead of what you do now" is a bloody stupid thing to do).
 A better point is that protobuf/flatbuffers/capnproto etc are *not* part of the STL, but people who use these libraries don’t complain about these features not being in the standard. These companies and individuals saw a need and contributed back to the community. I’m not saying game developers do not contribute to the community, but I don’t see what’s holding them back from accepting this model. If it’s because the requirements are too volatile from title to title, well then what the heck would you want in the STL? I do understand tooling complaints, however. 
Reflection is very very needed I agree. In C# it's so easy to send and receive data from SQL, network, file etc. However with a bit of an investment you can write your own generator if protobuf, flatbuffer, sbe (simple binary encoding) doesn't fit your needs. At my previous workplace (which was in fintech, low latency high throughput stuff) we used protobuf, sbe and our own generator where and when needed. It was still nicer to use c# but c++ got very close in many ways.
Game developers think they’re special snowflakes and the only ones doing “real programming” and it’s fucking hilarious. Most of them are barely doing any best-practices work that are considered table-stakes in the rest of the software engineering world. They just cowboy crunch their way through each project, and when the code can (usually) run a few hours(!!!) without crashing they declare it good enough to ship, and then throw most of it away and start the same thing over again for the next project. Half of them dont even think stuff like version control is a good idea, or it’s some sort of frivolous toy that lazy CRUD app devs play with instead of doing “real programming”. 
Not bad. But seems to be not maintained any longer? The last commit on GitHub is from 2017.
Did `char8_t` make it in for C++20? I don't see it mentioned above.
Regarding the noexcept destructor: according to cppreference the requirements of [Container](https://en.cppreference.com/w/cpp/named_req/Container) are that its elements are [Destructible](https://en.cppreference.com/w/cpp/named_req/Destructible), which in turn requires that the destructor of the element does not throw exceptions. &amp;#x200B; The noexcept constructor does not seem to be required as far as I can tell: a container (as in, a type that satisfy the container concept as listed in cppreference) must be [DefaultConstructible](https://en.cppreference.com/w/cpp/named_req/DefaultConstructible) but that concept does not seem to require \`noexcept\`.
That is the big difference, many game developers are self learners without any major engineering background, coding away stuff that just kind of works. It only started to change with the bachelor degrees for game development, but even the most credible ones are about 10 years old now.
Same for `resource`. Actually, the most common case is that the constructor throws, since fetching a resource can fail for many reasons.
That's interesting. Does that mean that an `std::vector` of some type that can throw in its destructor is not a Container? Is there some other concept that describes such a container? &gt; But on the other hand...why not -- why should the default constructor of, say, `std::vector` allocate and/or throw exceptions. Standard library containers can't throw as far as I'm aware, but a custom built Container could pre-allocate memory in its constructor. Maybe that's why it's allowed.
No, raw pointers are fine in some circumstances -- most commonly as iterators for contiguous arrays, or as "nullable references". The advice you'll see is to avoid *owning* raw pointers. Use smart pointers instead, and RAII techniques to manage memory. Never call `new` or `delete` yourself, except in a smart pointer/container implementation. Your code will be safer, easier to reason about, and vastly less likely to leak memory. What's not to like?
You should probably preface the "document" with a surface-level explanation of what the proposal stands for, along with why would someone want or need this. At first glance, just the naming seems to collide way too much with standard library names. Just the fact of having an std::io namespace alongside std::ios would raise many concerns. Not to mention, for example, that the concept of a \`\`\`std::io::file\_stream\`\`\` already exists as \`\`\`std::fstream\`\`\`. &amp;#x200B; &amp;#x200B;
Fair point on the constructor. I don't understand the intricacies of throwing from destructors so I won't comment on that.
Well, there is the minor fact that I don't have a C++ heap at all in my current project (everything is allocated at startup)... RAII is great for dealing with random ordinary objects. But when you're dealing with actual memory buffers (often with alignment restrictions) that have a strictly controlled lifetime, trying to force them into RAII / smart pointers can easily just make everything more complicated with no benefit at all. What I'm protesting are absolute statements like "never call new" that pretend that there is "one true way" to do things, irrespective of the application. Yes, 99% of the time in ordinary programs you're better off with smart pointers but _I mostly don't write ordinary programs in the first place_ (realtime embedded stuff). It's kind of taking "Goto considered harmful" and pretending that applies to literally 100% of cases and that there can never be a case where it really is the best (or least bad) solution.
I feel like most of us in AAA would actually not care if vector math types were standardized as many of us could whip this up in our sleep. I won’t speak for the OP but game changers for C++ to us would probably be more “core.” For example, standardizing name mangling so we could do standardized lookup and function patching, or destructive moves, stack allocation, conditions for guaranteed vectorization, etc. These problems are just a lot harder and can be on the fringe relative to the core c++ programmer. I definitely appreciate the API getting terser for the STL and such, but only really notice this in side projects. The STL being as slow as it is never really winds up affecting my work so much (and this isn’t meant as a jab at STL maintainers; the STL is sort of slow by definition). I’m following stuff like the flat map and polymorphic allocators and trivially_relocatable though. Lots of us at multiple studios that I’ve interacted with are really stoked about modules as well as this DOES address a heavy pain point. At the end of the day, it feels like much of the tension is that different people ascribe different meanings to “generic code”. For most, generic code means templates that account for the full type to be stored or manipulated. For others (aka me), generic code should in many cases only be a concern of size and alignment, rule of five be damned, because it’s easier to ditch the builtin RAII mechanisms and write your own but have performant code that compiles fast as a result. At that point though, you start to move pretty far afield of what the language expects you to do. 
I'd rather use expansion statements, available in C++20 :) [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1306r1.pdf](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1306r1.pdf)
Added motivation section.
It's not hard to get more than 2% perf increases over STL.
First of all: I like the idea of having byte streams instead of character stream with insertion and extraction of basic types not trying to convert between textual representation and binary representation as current iostream do when using `&gt;&gt;` and `&lt;&lt;`. As _babu_ said: I'd put a little bit more context and general design overview before I'd link it without any comment on reddit. What I'd especially like to see is a discussion of the relation to exising IO-streams. Could this just be implemented on top of existing std::ostream / std::istream? If not, why not? And if you are not restricted by the std::stream interface, then a discussion of what alternatives would be possible would be interesting. I generally hope that std::byte will get a lot more adoption in the standard library and gradually replace `char`.
You could fix the string literal conflict by saying "C-style string literals aren't in the subset, use std::literals::string\_literals::operator""s. Huge backward compatibility restriction, but I think it would be safer than changing the meaning of existing literals.
The only part I disagree with is to avoid delete'ing the default constructor. There are certainly cases where we have a type that only makes sense to exist if it has been constructed by giving it information it needs. Sure they are relatively rare, but it's not like they are a bad design choice when they make sense.
This article is full of factual errors. It confuses source files with translation units, and talks about linking to .cpp files when one links object files instead. &gt; unlike most languages, C++ splits code into headers and translation-units No it doesn’t. It splits code into headers and implementation files. Translation units are (roughly) the result of running the preprocessor on a source file. &gt; Headers are not necessarily evil. Yes, they are. The only reason they exist is because when C was invented computers didn’t have enough RAM to compile a whole program. &gt; We can query the compiler for actual header-usage. That’s what ninja does. It’s not new. I don’t use C++ much these days, but if I did I’d be wary of using a package manager that doesn’t understand how C++ is built or what translation units are. 
It works very weird in GCC 7.1-7.3 [https://godbolt.org/z/yMltaT](https://godbolt.org/z/yMltaT).
This. SG14 is only serving to keep a toxic community alive. Just kill it.
Because the encoding is slow and doesn’t support random access. 
&gt; Well, there is the minor fact that I don't have a C++ heap at all in my current project (everything is allocated at startup)... To me it's fairly clear the parent is talking about the allocating new and delete, not the placement ones. I think it's still true though in a sense: if you have new and delete of any sort scattered throughout your code you're most likely got bugs. I assume your placement news and deletes are well managed, not used like someone's naively porting Java code to C++.
The difference between an automotive control system and a game is that you \_need\_ the FPS for the software to function properly. If your menu or a map runs 1 FPS, you might not even notice. If your game runs 1 FPS, it's often impossible to do anything in the game. If you're debugging problems with gameplay, network latencies or graphics for instance, you will want your test environment to be as close to the actual thing as possible. And things like "how the controls feel" is impossible to unit test. "Do not use a debugger" is a poor piece of advice if you need is to inspect the program state with a hard to reproduce condition. Granted, traditional printf-debugging and/or logging is often a workable solution but that just speaks of the poor state of C++ debuggers. 
It’s all to do with RAII, which uses the fact that objects will automatically destroy each other and themselves. We can design our programs such that there is pseudo garbage collection by using “data ownership” idioms, such that things are automatically destroyed when they go out of scope. This means using smart pointers and data members with lifetimes tied to the lifetime of their owners. This also ensures that destructors are able to clean up things as well, if that is their responsibility, thereby maintaining valid states of the program. If a destructors call the destructors of the objects they own, and perform special tasks like preserving state, then ensuring that they don’t throw also ensures that destructors propagate automatically and fully down their ownership hierarchy. If one allocates an object in a constructor, one would also want to destroy it in the destructor, which means it has “ownership” and a responsibility to clean up what it allocated. Using a raw pointer to do this, meaning it was allocated with the “new” keyword, means that if the destructor throws before the “delete” line, that memory will leak. If we instead use a smart pointer to allocate the data, it is not necessary to call the delete operator because the smart pointer (which is the actual data member) is automatically destroyed when its owner is destroyed, which in turn “smartly” deallocates the data *it* pointed to. No need for “delete”. If the destructor doesn’t throw, then the destructor can finish what it needs to do, destroy what it needs to destroy, and so it’s responsibilities are taken care of.
I understand ownership and RAII, but I think you are underestimating how sophisticated the behavior of throwing destructors can be, see e.g. [https://akrzemi1.wordpress.com/2011/09/21/destructors-that-throw/](https://akrzemi1.wordpress.com/2011/09/21/destructors-that-throw/)
My personal style: * Use copy-init style in simple cases where this makes sense. For example: int i = 4; std::string str = "Hello world"; std::string other = str; * Use list-init style where you are (conceptually) doing "component-wise" initialisation, for example: std::array&lt;int, 3&gt; arr{1, 2, 3, 4}; vec3f v{1.0f, 2.0f, 3.0f}; std::vector&lt;int&gt; vec{1, 2, 3}; * Otherwise use direct-init style to call constructors Of course, this all goes out of the window in generic code, but that's "uniform initialisation" for you...
Flatbuffer members are immutable for all but trivial types. They're very inefficient to work with as general-purpose objects.
You might want to reconsider specifying dtor =default https://youtu.be/D8eCPl2zit4
&gt; That is the big difference, many game developers are self learners without any major engineering background FWICT all these rants came from experienced and recognized gamedevs. So, I wouldn't really go that far calling them self-learners and w/o engineering background. The fact that they're experienced is only stressing out the point I am trying to make even more. It's the mindset which is not open and the wrong "house" they're barking at. &gt; coding away stuff that just kind of works. Yes, definitely the pattern which is reoccurring but only in industries which can afford such an attitude. A game crash doesn't mean much when compared to a human life which is at the price when your software runs in a car or any other similar health-on-risk environment. &gt; It only started to change with the bachelor degrees for game development, but even the most credible ones are about 10 years old now. Gamedev is no special to any other industry where knowledge of applied math is needed and I don't see bachelor degrees for each and every one of them. Foundational knowledge is what should be taught in Universities. Everything else throughout the career is usually only expansion on these principles.
Then the issue is build time (and the fact that quite a lot of debugging info is hard to follow with debug opt builds). But yeah, I am just saying what the issue is with normal debug builds in modern C++. It used to be that debug build were much quicker to produce than release, slightly bigger and slighty slower. Nowadays, they are still much quicker, slighly bigger, but are now dramatically slower.
&gt; why would you need to _run_ the game in debug-build in the first place? So let's imagine we're not doing a game but instead, say, dealing with USB audio (real world use case for me). In this case there is no option but to run the thing and if the debug build is too slow, it literally means you cannot debug that code at all in the debugger. There are plenty of other cases I can imagine where the problem requires significant amount of code to run to appear and where an unoptimized debug build is simply too slow to be run at all. Another related case in embedded systems is when the unoptimized build is too large to fit into the memory, at which point you're again in the same situation. And good luck trying to run only half of a Bluetooth stack (another real world case in my career).
Ha! Never heard of it, but seems it supports protobuf (the dynamic nature of it, though not sure if that code path is efficient enough) - https://github.com/google/openrtb/blob/master/openrtb-core/src/main/java/com/google/openrtb/util/ProtoUtils.java
I think this takes the wrong approach because: 1. It conflates serialised i/o with bit casting i/o. They should be two, completely separate, layers, which can be statically switched in depending on the traits of `T`. 2. It is not Reflection based. 3. It does not constexpr compose scatter-gather i/o buffers for an i/o engine to consume. 4. It appears to have no ready interface into Ranges and forthcoming Ranges i/o. 5. To achieve zero copy memory mapped i/o with UB, it is currently believed that the C++ memory and object model needs to be refined. 6. To get decent optimisation of constexpr composed scatter-gather buffers, it is currently believed we need a fair few new attributes to annotate the function calls. WG14 is actually taking the lead on this, currently, as C would like to teach the compiler's optimiser about scatter-gather buffers. 7. It makes no reference to why it substantially improves on the existing WG21 proposals on this topic. We are currently taking a bottom-up and top-down approach, hoping for a partial meeting in C++ 26.
It's actually pretty incredible just how disconnected game devs are from the rest of the C++ community. You always see pretty good representation from big companies like Google and Microsoft at events, to the point where I know people who work at those companies by name. Why is this the case? You would think a company like EA or Activison would have just as much interest as those other companies. We need more guys like John Carmack who was incredibly open and involved when he was at ID.
Then I guess we both agree that debuggers are unsuitable for many problems out there. And even more so in areas where execution through the debugger affects tight (bus) timings you have to satisfy with your code.
What? SG14 is composed of people from various industries (not just game Dev) that are making constructive improvements to C++. There are some game devs that are contributing hugely to C++. We should be encouraging people to take their concerns to SG14 instead of writing vitriol. The people writing this junk are not "kept alive" in any way by SG14. 
This is not due to the debugger but due to the compilers giving only the options of either unrunnably slow code or code that has removed too many intermediate variables to figure out what's actually happening. The unrunnably slow code would be at least partially mitigated by having similar guarantees to what the standard provides with guarantee of short-circuit evaluation of expressions. Basically a guarantee that while unoptimized code might run at half speed, it would never run at only 10% speed.
yes, in r/cpp_questions (or r/learnprogramming)
What exactly are the consequences of not writing “noexcept”?
Congratulations, you've just managed to ignore every bit of information I've written above. Navigation system _is_ a 2D/3D graphics simulation which has _very few_ differences to what the video game is consisted of and yet you managed to trivialize it to a-map-where-1FPS-is-not-a-problem (?) without a "gameplay", graphics or networking bits. Are you aware that a single modern car today has *more than 100+ (yes, hundreds) MLOC* and it encompasses every imaginable technology in it? But sure, gamedev has special kind of problems no one else is encountering ... It's your choice after if you will still believe in this fallacy or not. I just tried to share my own experience from a very similar (and arguably more complex) environment/product.
Yes, I am aware that a modern car is extremely complicated and the problems that you are working on is probably very hard and complex. However, it is not a game and knowledge from your domain cannot simply be directly applied to games, no matter how similar they might seem to you. Of course gamedev has special kind of problems unique to it - just like every single other discipline of engineering out there.
Among all the BS, why game dev is so special and they can't use STL (90% of the standard library has nothing to do with containers, but that seems to be ignored) there are three points I have to agree with: 1) Design by comittee: There are good reasons, why c++ got standardized and why the development process is what it is, but fundamentally, design by committee doesn't help in creating a well designed language. There are just too many divergent interests on the one side and too much reliance on volunteers spending their free time to bring the language forward. 2) Zero cost abstractions are only zero cost in one dimension: release build performance. Other dimensions that matter are build time, debug performance, debuggability and readability. We got so used to think of TMP and inlinable functions in general to be "zero cost" that people start to believe that a feature implemented in a several hundred lines of TMP code with layers and layers of indirection is somehow the same as an actual language feature. 3) High performance: c++ tries to get not in the way of high performance software (compared to e.g. GCed languages which come with some fundamental overhead that you can't avoid) but on the other hand it doesn't really provide any help for the creation of such software. Only a tiny fraction of a typical machine's perfomance can be deterministically reached with standard c++. No direct vector instruction support, no standardized support for GPUs and no tasking system that deserves the name. Point 3) will hopefully get addressed in c++23 with executors. 2) may get addressed with modules (e.g. faster build times and maybe via different per module optimization settings) but that is all future stuff.
&gt; Also, since wchar_t is 16 bits on Windows I don't think this will work there This example works on Windows, except that MSVC's iostreams are incapable of UTF-8 console output. #include &lt;locale&gt; #include &lt;codecvt&gt; #include &lt;iostream&gt; #include &lt;Windows.h&gt; std::wstring_convert&lt;std::codecvt_utf8&lt;wchar_t&gt;&gt; cvt; int main() { std::string s = "こんにちは"; SetConsoleOutputCP(CP_UTF8); printf("There are %zu code points in %s\n", cvt.from_bytes(s).size(), s.c_str()); } even with the old MSVC: C:\MSDE\sergeyz\Visual Studio 2015\Projects\ConsoleApplication1\x64\Release&gt;ConsoleApplication1 There are 5 code points in こんにちは 
Generally you seem to want a lot of "standard" ways to do things that are actually only possible on very few platforms and need a very detailed specification of how the HW works to even be able to describe the semantics of those mechanisms. I don't see why such things should be in the standard as opposed to be defined as an extension by the embeeded doolchain you are using for your specific target. On top of that, there are a few things I don't understand: - Size of the stdlib: Generally speaking: Your linker should be able to remove all parts of the standard library which you are not using (in many cases they won't end up in the object code to begin with, because they are templates or inline functions). Second: Why do you care about the size of the standard library on a hosted target, when you are working on non-hosted ones for which the toolchain vendors will not provide a complete standard library to begin with? That being said, there are effort underway to specify exactly, what parts of the standard library should be available in standard-conforming, non-hosted environments. Also this stuff: &gt; Look at how much code you pull in when you replace a VLA with std::vector. &gt; Look at how many things in the C++ stdlib that implicitly malloc. &gt; Look at how much of the C++ stdlib is essentially unusable without exceptions. Or vtables. Ignoring the fact that hardly anything in the stnadard library requires vtables and even allocation isn't that common, you seem to complain about some/many consturcts in the standard library using mechanisms not available / unsuited in embedded develeopment, but those consturcts are inherently unsuited there anyway. - what has `register` to do with anything? It has never been more than a hint to the compiler that didn't guarantee anything. &gt; Give me standard support for encapsulation without runtime penalties (looking at you PIMPL) - can you explain in more detail what you mean by encapsulation? The only kind of additional encapsulation pimple provides over the classic mechanisms is physical decoupling (you don't have to recompile everything if you change internal members and the abi remains stable. I'm not sure why that is a common concern in embedded programs, which are usually not that big to begin with. 
Or possibly on [stackoverflow](www.stackoverflow.com)
There was a new symmetric coroutines proposal, seen for the first time at Kona. The committee decided not to wait for it.
I am not working in the automotive industry anymore. Just sharing good practices I picked up from there for which I consider that other industries are falling short. So I guess we'll have to agree to disagree.
containers like vector will avoid your move constructor if it is not noexcept, to preserve their strong exception guarantee (if an exception is thrown by say push back, the vector is unchanged). if the vectors buffer must be reallocated, and moving an element could throw, then that element would be lost; so vector will copy such type instead. 
It seems to me that the `*_stream` classes are largely a duplicate of existing `std::*stream`s, except that they additionally store the `format`. But it seems to me that `format` should be passed as an argument of `io::read` and `io::write`. If we drop these `*_stream` classes and use the existing iostream hierarchy, and make `format` an argument of `io::read` and `io::write`, then the proposed functionality can be implemented as iostream manipulators, which seems to require less change.
If you want that type of syntactic sugar C++ is probably not the language for you...
If you have other declared constructors, the default constructor is already not provided. You don't have to additionally explicitly delete it.
1. Please elaborate. 2. I'm aware that reflection has recently adopted `constexpr` approach and they are designing a new API. Otherwise, I didn't have time to look deeper. 3. Unfortunately, my understanding on OS-specific interfaces for IO is mostly limited to POSIX `read` and `write` calls. I would like to learn more. 4. It consider switching to `std::ContiguousRange` instead of `std::span` for some wording but since so far the API is based on virtual functions, I can't use it right now. Nor I can test the Ranges since they are neither in libstdc++ nor in libc++. 5. Again, this is way out of my expertise, for me `std::vector&lt;std::byte&gt;` is good enough. 6. No comment. 7. I haven't seen comparable proposals, IIRC your LLFIO proposal was extremely confusing to me. You can PM me with link to study group.
The move constructor/asigmnent should *never* be deleted. [Source by the main move semantics author himself](https://stackoverflow.com/questions/37092864/should-i-delete-the-move-constructor-and-the-move-assignment-of-a-smart-pointer/38820178#38820178). The post have them commented, but suggests to add them when someone wants to be explicit. imo it should suggest not to add them unless strictly necessary.
That's actually a really good point 👌
Good point about core versus library, but the lack of library suitability to games establishes several important points, most important of which is game developers are (understandably given economics) not participating in the open processes available to them. There's been talk of a standardized ABI, and I don't think there's much opposition to it in principle, but it's a hard problem when you have to support legacy, you want to not break ABI for your users, and compilers want to reserve the right to optimize. I suggest you dig into past papers and read up on the issues and propose a way forward. If you want help, message me.
C++ will be a niche language in 5 years. It'll be the new COBOL. Have another language under your belt if you want to remain employable.
This is an odd bit of shade being thrown. Is it from personal experience? I don’t know many successful game or film devs that didn’t have a CS degree or EE or some other hard science/engineering background. Those that are successful without are sometimes even better positioned as extremely strong autodidacts. 
EA and Activision simply don't want to pay their best developers to try and wrestle with the community when they could be writing more games. The industry is so completely hit driven they're simply not long term focused, to the detriment of the long term health of the industry and it's workers. Burn out is a huge problem.
That's not posturing, that's your game dev resume to game devs. Don't call out other people for "not getting it" when you don't get it in the first place. You're not right about any of your points.
The \`\[\[deprecated\]\]\` trick works in clang but not gcc, the latter does not print the param types in the deprecated warning.
It shows in the fact you've made reasonable points. No one ever said no one uses anything but C++. You can make a game in basic if you wanted to. I'm assuming we're talking the kind of games where using STL or not makes a real difference.
As far as I know, all `std::swap`s provided in the standard are required to never throw exceptions, and as of C++17 `std::swap` for `std::list&lt;int&gt;` is indeed specified as `noexcept`. Prior to C++17 `std::swap` had undefined behaviour, if the allocators did not compare equal, and didn't propagate on swap, then the behaviour was simply undefined, and since narrow contracts are never `noexcept`, `std::swap` for `std::list`s wasn't either.
Pretty much nobody says that. If they do, they aren't representative of any group of people. What people will say is that *owning* raw pointers are mostly a bad idea, except in the implementation details of owning data structures. And that you should often prefer references over non owning raw pointers. That is correct. On the other hand, I see plenty of game devs especially assume that unique_ptr has costs that they can't explain or demonstrate (because those costs are incredibly close to zero). The difference between these two "bad" opinions is that on one side it's a tiny minority opinion, that will be quickly told they are wrong. On the other hand, you have a large minority within game dev writing blog posts and explaining how they just care so much about perf they can't use unique_ptr. Very different situations.
**Every** language relies on the compiler reducing abstraction to machine code, pretty much by definition. C/C++ is pretty unique in providing a relatively simple mapping to assembly in many cases. Again, there's no real alternative for AAA.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/aveh1j/store_sliders_values_into_variables/ehentbw/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
You can look at this problem as a failing of debug builds, or as a success of optimization. I find it a bit ironic that the complaint can boil down to "optimization is working too well!"
Experience following the industry since the ZX Spectrum and C64 days, former IGDA member, attendance of a couple of GDCE conferences, former attendance on demoparties, reader of Hugi, participation on Flipcode, having made friends with a couple of people on the field. Are my credentials good enough?
I’m not asking for your credentials. I’m just in stark disagreement as we must be in different circles. 
There's definitely real issues. Let's work on real proposals to make things better.
Does Destructible really implies that destructor cannot throw? Why then there is a separate trait `nothrow_destructible`?
You're really sensitive to what you think some random guy told you over the internet ...
The destructor should be noexcept otherwise exception safety is problematic. In the accompanying blog post (https://foonathan.net/blog/2019/02/26/special-member-functions.html), I elaborated a bit about the non-empty state you mentioned: If you have a move constructor to a class, you will introduce some form of "empty state". I've argued that this "empty state" should also be created by the default constructor. As move constructors should be noexcept, the default constructor can also be noexcept.
But not the default constructor. If you have one, it usually puts it in an "empty" state which can be `noexcept`.
I originally also argued that you should only delete the copy constructor/assignment, move is implied. But some people like to be explicit, so I kept that in. In the accompanying blog post (https://foonathan.net/blog/2019/02/26/special-member-functions.html), I've explicitly warned about the the pitfall you mentioned.
Yes, this was just there to illustrate what happens if you don't do that.
Then check the background of major developers that got into the industry during the 8, 16 bit days, and early Windows 9X timeframe. A couple of Retro Gaming studio history interviews or old time Gamasutra postmortems are a good starting point. There might be a few GDC Vault interviews as well.
&gt; There is no way to convert integers from native endianness to specific endianness and vice versa. Yes, there is, and there has been one since C++ exists. It's just basic arithmetic: https://commandcenter.blogspot.com/2012/04/byte-order-fallacy.html Native endianness is a red herring, because we have always had portable ways to convert "native endianness" to/from any desired endianness.
Did it occur to you that these days and those days are not the same. 
Those developers are still a large majority of the industry, they are the ones that built it. As I mentioned, it only started changing during the last 10 years, or if you prefer maybe 15 years. So naturally it occurred to me.
In the *resource* example, you wrote the destructor as: ~resource() noexcept; If there's **no** class hierarchy, do I need to write the `noexcept` specifier? Isn't it automatically generated by the compiler?
Your original statement is literally a gross generalization of a field youve been out of for ten to fifteen years. The industry has grown so much in that time that you’d have to walk quite a few hallways before you found someone who still codes regularly that also coded the commodore. Just walk it back. 
Louis Brandy calls issues with `map::operator[]` the greatest C++ newbie bug in his [cppcon talk](https://youtu.be/lkgszkPnV8g)
Is this sophisticated, or just ~~basic exception safety~~correctness though? If `operator new` could leak, it would have been *completely* useless.
&gt; No one ever said no one uses anything but C++. I shouldn't Reddit with migraine brain fog 😁
TL;DR map/unordered_map subscript operators mean update or add if not exists. "Just don't use" is an overkill if that is exactly what you want.
&gt; Him bashing std::move is actually hilarious. Is it ? I'm not laughing when in debug it causes one more function call nor when I have to include a whole header for a "core" language feature that simply just casts. I do not agree with him that move semantics are bad however, I even think it's awesome. But I still don't like std::move being a library bit instead of something part of the language (yeah I know, QoI blahblahblah....)
Gonna put my language lawyer hat and I would request a truly portable code that work when integers are neither big or little endian. It is possible, you just can't rely on any bit pattern and have to do actual arithmetic.
This is garbage. There's no need to add more bloat to the standard.
Do you know what the most recent proposal/paper/whatever for this is? the only papers i find are only about reflection.
I'm the author of reckless. I came by this thread because I was searching for benchmarking code for the other libraries that I want to compare my library against, so I'm a bit late but I'd still like to make some comments on these benchmarks. * Setting CPU affinity can have an adverse effect on the performance of reckless (and probably the other libs) if you don't do it very carefully. The problem is that if you set CPU affinity before the library's background thread is created, then the background thread will inherit the CPU affinity and all your threads will run on the same CPU core. That could account for the poor worst-case time you get with reckless. Given that you are measuring performance using an OS timer, I doubt that setting the CPU affinity is really necessary. * With asynchronous libs there are two distinct performance numbers that you can measure: latency of single log calls, and throughput when logging at full burst. The first measures the time for queueing a log entry. The second measures the time for the entire chain, including formatting log entries and writing them to disk. If your typical use case is the second, then putting everything on an intermediary queue and sending it to another thread just adds unnecessary overhead. In that case it's better to just synchronously write the logs. So I find that running only a full-burst benchmark kind of misses the point of using an asynchronous logging library. Also, if you're writing at that rate then you'll fill hundreds of megabytes of disk every second. The expectation is that logging will generally not run at such a rate that the buffer maxes out. In my own benchmarks I have run both kinds of tests. The [periodic calls benchmark](https://raw.githubusercontent.com/mattiasflodin/reckless/de548af1f5ea9f716f76b691402b52107ef701e3/doc/images/performance_periodic_calls_asynchronous.png) keeps writes below the limit where the queue maxes out, whereas the [call burst benchmark](https://raw.githubusercontent.com/mattiasflodin/reckless/de548af1f5ea9f716f76b691402b52107ef701e3/doc/images/performance_call_burst_1.png) fills up the queue at full speed. As you can see from the second graph, every time the queue fills up then you will get a high-latency call as the log call has to wait for the queue to flush to disk. With reckless, though, my own benchmarks have shown that the throughput is still better overall, as you can see if you apply a [moving average](https://raw.githubusercontent.com/mattiasflodin/reckless/de548af1f5ea9f716f76b691402b52107ef701e3/doc/images/performance_call_burst_1_ma.png) to the call burst benchmark. * I'm doubtful about the use of std::chrono for measuring single invocations, as I think the overhead of the time measurement overshadows the time for the actual log call. You should at the very least try to measure the overhead using a "no-op" base line that only measures timestamps and doesn't actually call a logging library. Then there's the issue of precision, as typical calls to reckless take only about 100 microseconds. Did you check what time source chrono uses for your tests? * Finally, reckless does have crash safety just like g3log does. LIke gabime said, it would be nice if you would share your actual code for the benchmark (including your modifications) so that we can troubleshoot any potential performance issues that you may have found. If you are only going to make one kind of benchmark, I think the most honest and useful one is to perform some reasonably realistic task and generate log entries during the process. Then you compare the _total_ running time with the same task without logging enabled. This is what I have tried to do in my [mandelbrot set benchmark](https://github.com/mattiasflodin/reckless/blob/c1d0932eb884cb2026e7c072f9c2299241b02f6a/doc/performance.md#mandelbrot-set).
As for explicitly writing the `= default`, what are peoples thoughts on this? Part of me likes the idea of seeing it written out explicitly, but it also seems excessive (harder to read?) in the "normal" case for example.
Nice! That was a good resource. Thank you
On the contrary I feel std::map has one of the best possible interfaces across all languages. Directories in C# for example have a way worse interface, where updating a value which might not exist requires like at least 5 lines, introducing a named temporary for TryGetValue, and then having to do a second search to insert the new value in case it doesn't exist. std::map&lt;&gt; also gives you the opportunity to skip the default constructed value &amp; going with a find/insert approach, which is still going to be less lines. This gets way worse if the value happens to be a struct in C#. Python requires defaultdict, which is not really an improvement on std::map in this regard. Point is I can't think of any solution which doesn't either require default constructing a value or requires searching the associative container twice. Besides, classes which are expensive to default construct is a poor plan from the start, and if they are you're probably okay with a level of indirection for a pointer instead anyway.
I am trying to transition some legacy embedded projects to CMake, but being stuck with old compilers it can be hard. OBJECT libraries is is very close to the way the native compiler projects work and so make transitioning easier. Even with newer compilers I think that things like aliased/weak functions and link time optimization can be much harder to get working with static libraries.
I can't point you to the part of the standard it got it from, but cppreference lists \`Destructible\` as a requirement of \`Container\`, at the end of [this page](https://en.cppreference.com/w/cpp/named_req/Container).
It's sophisticated to me at least (did you check the blog post I linked above), but we are talking about destructors so I don't understand the \`operator new\` comment
Yeah, seen that post before (didn't read it now). You copy-pasted the part with `operator new` 😁, I just continued. But destructor that throws is in the same situation - if `operator delete` didn't delete the underlying memory, it would have been bad. But throwing destructors are rare.
&gt; On the contrary I feel std::map has one of the best possible interfaces across all languages I hope you only refer to accessing items, because this: if (someMap.find(someValue) != someMap.end()) { ... } is horrendous when compared to if (someMap.contains(someValue)) { ... }
https://github.com/USCiLab/cereal/tree/develop dev branch is from Oct 2018 The problem I have with cereal (I only just started using it a month ago), is that you can't have optional fields, so if your model has a dozen or two fields and just one or two are non-default, the exported archive is awkward. Generally easy to use though.
&gt; My average build is about 2 seconds(without LTCG); took a lot of work to keep it that way, but extremely useful.. &gt; &gt; Could you talk a little bit about how you managed that? Is it a unity build or like pimpl everywhere or what? I'd love 2 second builds.
In C++98, it's spelled `if (someMap.count(someValue)) { ... }`, but C++ added [map.contains](https://en.cppreference.com/w/cpp/container/map/contains)
Even more in the "incompatible" direction but I'd be interested: uthash.
what is even more horrendous is doing if (!someMap.contains(someValue)) { someMap.insert(someValue); } 
I don't understand why they don't just add an `operator []=` to work like python does. If it doesn't exist (but *not* if it's explicitly deleted), fall back to `operator []` and hope it's a reference.
I would probably try finding a job in one of the following languages (ordered by priority): 1. Low-level C (drivers/kernel) 2. Haskell 3. Erlang 4. Golang 5. Java I find it very unlikely that I'll be able to go above 4 though, since 3 and 2 are quite rare, and most jobs of type 1 require previous experience which I do not have.
I don't understand what you mean by `|| const noexcept`. You mean a conditional `noexcept` specification, like `noexcept(noexcept(x.swap(y))`? But that wouldn't help the `L` example. Maybe the problem is that we have `noexcept` to say "I provide the nothrow guarantee", but we don't have any annotations to say "I provide the strong guarantee," "I provide the basic guarantee," "I provide no guarantee at all."
Scala, because I'd miss the long compilation times otherwise.
I found TypeScript to be satisfying. Other than that, probably C or C#.
On phone, but basically one line for find into an iterator, a test Vs end, an insert if the test fails that assigns the iterator returned from the insert to the find iterator. Then lastly in the same scope you did the initial search the find iterator now contains a valid value to modify. 
I assume you're actually referring to Dictionaries, not Directories, in which case that class' subscript operator will do exactly what you want the same way it works in C++: https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.dictionary-2.item?view=netframework-4.7.2#System_Collections_Generic_Dictionary_2_Item__0_ myDictionary[key] = value; This would work in both C# and C++, and should only perform lookup once. The C# version only creates the entry if you're invoking the setter, and then only if it doesn't already exist, whereas the C++ version must create the entry if it doesn't exist. You can see the implementation for C#'s version here: https://referencesource.microsoft.com/#mscorlib/system/collections/generic/dictionary.cs,179 The code for the Add method is right below it, and you can see that using the subscript operator will either overwrite the value or add it. Using Add throws an exception if the key already exists in the dictionary.
&gt;The only thing I'm pissed about is that generative C++ is so far away. I have a [free code generator](https://github.com/Ebenezer-group/onwards) to help with this. This input: [https://github.com/Ebenezer-group/onwards/blob/master/src/cmw/tiers/account.hh](https://github.com/Ebenezer-group/onwards/blob/master/src/cmw/tiers/account.hh) [https://github.com/Ebenezer-group/onwards/blob/master/src/cmw/tiers/middleBack.mdl](https://github.com/Ebenezer-group/onwards/blob/master/src/cmw/tiers/middleBack.mdl) Leads to [this output](https://github.com/Ebenezer-group/onwards/blob/master/src/cmw/tiers/zz.middleBack.hh). &amp;#x200B; &amp;#x200B;
I agree. Every other language I know that overloads the indexing operator also have an index-setting operator (C# is a prime example, where the indexer is just like a property).
C Rust C#
And here we have another of the possible traps of C++, the `int` that implicitly converts to `bool` (or, more specifically, the `if` that accepts any integral value).
How is that a trap?
Go/Java/Rust
If someone forgets to write the rest of the condition, the compiler would still accept it. (For example: `if ([very long expression that returns an int] &gt; 3)`, the programmer can forget at the end of the `if` to write `&gt; 3` and only catch the big much later)
ITT: people thinking they would do game dev better than actual game devs under the same conditions and pressures (time, money, changing requirements). Maybe they should prove it, instead of posturing from their high horses that they know better?
Who said anything about being out of it? Apparently I have touched some kind of nerve here.
I still can't see it as "a trap". If you need a non-trivial comparison (read: not comparing against 0) you just *won't* forget it. I don't know anyone in the world who has made that mistake. On the other hand if implicit conversion works for your case, as it often does, adding `== 0` or `!= 0` is really just noise. &amp;nbsp; Case in point, libclang API has a ton of things named like `clang_Cursor_isNull()` or `clang_isInvalid()`. Judiging by the name you'd expect these to return a `bool` which aligns perfectly with the documentation, except... All of these return `int`, so, in case of no `int` to `bool` implicit conversion, you would have to litter everything touching libclang API with `== 0` or `!= 1`. I've tried doing that just to be explicit and appease `clang-tidy`. It resulted in an ugly mess and very noisy conditions. Bear in mind that removing this kind of implicit conversion would mean that `if (!foo)` would also be invalid in every case where `foo` isn't already a `bool`. 
In essence, C++ `map::operator []` behaves differently from other languages. Why is that surprising? If you read the documentation you'd know that. The closest map operation that behaves similar to maps in other languages is `map::at(key)`. It looks like Raymond Chen would love it. Although, with `at()` his code (`if (m.at(i)) { m.at(i)-&gt;Recolorize(); }`) would be even more broken because it would throw an exception.
If the template took a default value, you might be more conscious of the side effect of calling operator[].
What are the top 3 features that will make an upgrade feel worth it? 
Whether it's cout or a file stream, flushing is important to maximize the likelihood of getting important messages if the program is interrupted. I know std::endl is for causing flushes, and since that's what I normally want for a line of text that's going to always be my default. Calling attention to the cost of std::endl may be good but only in the context of *necessary* optimizations.
Python or Julia or D...
I’ve used CppRest to write a server, and it was really nice. Serving files was a bit hard, but starting the server, and having lambdas invoked when endpoints are hit was trivial. 
C++ people do like to argue more than average. I think the argument presented for not defaulting to endl is misguided so that's why I'm weighing in. Sure endl costs something but it is a good default, and should only be omitted during optimization if necessary by thoughtful programmers.
If you don't have a C++ heap at all then never calling the heap allocation functions directly sounds pretty trivial.
It has many C++ jobs, remote as well. But whatever - python is amazing language, you can write elegant, robust and intelligible code, there is no better language about me, it's great to see many syntax sugar from Python to C++.
I already moved, back in 2006, to Java/C#.
C# or swift
&gt; Half of them dont even think stuff like version control is a good idea I've never met a non-hobbyist game dev that thinks version control isn't a good idea. Even most hobbyist game devs I know of swear by version control.
definately python and or c
A bad API is not a good excuse for bad language design.
If the issue is no jobs, then obviously picking some fairly obscure and lightly adopted language isn't going to do much good. Now matter how high profile the company pushing it, it probably has little chance of really making it. However much someone might like Rust or some such, how many actual jobs are there for those languages? And, from a look at Rust, it just seems to constrictive, and too non OO friendly anyway. If you are a Windows person, C# would sort of have to be it. Though C# seems to be on the same path as C++, which is to become incomprehensible. If you are in the web world, then Typescript creates far less gag reflex than Javascript. But, I think ultimately both of these are dead ends. Though it's slow in getting there, WASM will hopefully finally get us away from these languages which are fine for web sites but totally inappropriate for real development. I guess if you really live in Android world, then Java would be it. But, if you really live in Android world it seems like you'd already have to know it anyway, right? I've been learning some C#, and have been of necessity doing some Typescript. 
I talk to game developers literally every day so kindly take your condescending bullshit elsewhere.
Python, because I've actually almost never used anything else professionally x)
The code in there works when integers are neither big not little endian. It doesn't rely on any bit patterns.
I have my own build system and project definition system. And of course I have my own entire soup to nuts code base so I can make everything very consistent. So the amount of work required to define what I call a 'facility' executable/library is very straightforward. That info is passed to a pluggable tools handler that knows the specific tools for the target platform, and it does the work. A typical project definition is: PROJECT=CQCEvCl SETTINGS DIRECTORY = EventSys\CQCEvCl DISPLAY = N/A EXPORT = CQCEVCLEXPORT MSGFILE = Yes TYPE = SharedLib VERSIONED = Yes END SETTINGS IDLFILES IDLFILE SRCFILE = CQCEvCl_EventSrv GEN = CLIENT NAMEEXT = EventSrv END IDLFILE IDLFILE SRCFILE = CQCEvCl_Shared GEN = GLOBALS NAMEEXT = Shared END IDLFILE END IDLFILES EXTLIBS CIDCrypto$(CIDLibVer).Lib CIDRegX$(CIDLibVer).Lib CIDXML$(CIDLibVer).Lib CIDOrb$(CIDLibVer).Lib CIDOrbUC$(CIDLibVer).Lib END EXTLIBS DEPENDENTS CQCKit CQCRemBrws END DEPENDENTS END PROJECT &amp;#x200B; In this case it's from the higher level automation system code base, so it includes external libraries from the underlying general purpose stuff, libraries from the current level, IDL files that need to be generated, whether it has loadable text that needs to be built, and some other stuff not show here but not a lot. The built tool does header dependency analysis and builds up the dependency files that it uses to decide what needs to be built. The dependency analysis is invoked manually, it's a lot of overhead to run on every compile in a code base this large. There are no huge lists of manually created dependencies and what files to compile, or crazy obscure rules and all that. &amp;#x200B;
Well if their usual update trajectory holds, it will be twice as slow and crash twice as often, so we’ve got that to look forward to!
1. New name, 2019 &gt; 2017 2. New Splash Screen 3. Sort new projects by popularity &amp;#x200B;
This one of the best cpp talks I know of. Brandy is so entertaining in how he presents the topic, and I think I have seen all of these bugs multiple times, some of which I wrote myself. The defaultconstruction of a shadowing temporary is a particularly nasty one to spot if you are not familiar with.
That's a "see also" thing. relevant part of the standard is [[container.requirements.general]](http://eel.is/c++draft/container.requirements.general), and it does not mention Destructible.
English link: https://docs.microsoft.com/en-us/visualstudio/releases/2019/release-notes
If you are working on huge projects, the out-of-process debugger will prevent crashes when debugging from running out of address space. For me personally, that's by far the most important improvement, as it's something that bites me regularly.
I have black friends.
Sometimes a construct is well-behaved even if the compiler/library can't see it.
But destructors are by default noexcept: [[except.spec/8]](http://eel.is/c++draft/except.spec#8) &gt; The exception specification for an implicitly-declared destructor, or a destructor without a noexcept-specifier, is potentially-throwing if and only if any of the destructors for any of its potentially constructed subobjects is potentially throwing.
I just wish there was a const version of the subscript operator.
You may find reading the documentation at https://ned14.github.io/llfio/ more useful than a WG21 standards paper. If you sign up to https://github.com/experimental-io, that's where some of the i/o standards work is happening. To be honest, not much has happened recently as Kona was all about finishing C++ 20. I would expect a raft of progress for Cologne and Belfast though. I'll also be speaking at ACCU 2019 on the C++ object and memory model, and sounding out WG14 for possible changes before I go annoy SG12 with proposals at Cologne.
&gt; On the contrary I feel std::map has one of the best possible interfaces across all languages. Directories in C# for example have a way worse interface, where updating a value which might not exist requires like at least 5 lines, introducing a named temporary for TryGetValue, and then having to do a second search to insert the new value in case it doesn't exist. You're right, but that's why I always add three extension methods on `IDictionary&lt;K,V&gt;`: `GetOrDefaultAdd`, `GetOrDefault`, and `GetOrAdd`. I like using `map&lt;&gt;::try_emplace` more often than `map&lt;&gt;::operator[]` now. Our map equivalent at work also has this nice method named `UninitializedInsert` which lets you placement-new the element in case constructing elements is slow. auto insertResult = mymap.UninitializedInsert(key); if (insertResult.second) new (insertResult.first) T(); It's not commonly used, but nice to have available.
I thought this was a joke but it turns out not really.
Haven't used it, but the most interesting feature I've seen is ML-driven intellisense. No clue how well it actually works though.
This might not be 100% new in 2019 and I am a bit dumb, but as a mostly Linux guy I was very happy with all of the cmake integrations - and it even chose ninja as a generator. I didn't even have to go through all of the random UI options to figure anything out, cmake was enough to setup all of my different builds and build options.
Sounds like an industry ripe for disruption.
What would it return though? A std::optional&lt;const T&amp;&gt;? There's also the problem if your map isn't already in a const context, it's going to always use the non-const version, so you'd need some other get function. Though nowadays you can do this: if(auto it = map.find(key); it != map.end()) { ... } which isn't THAT bad.
There was a huge thread some time ago where someone was arguing with some programmers over the value of the STL. The *only* ones arguing that the STL is unusable and wrought with problems were game devs. Most of the game devs who replied said things like "I was told never to use it" or "my studio forbids it". There were only a small handful that detailed why (lack of allocator control, some parts throw, etc). Generally speaking, there's a strong case of cargo culting in the game dev community and what's worse is that it hides behind a mask of elitism, due to the perception that only games care about performance and have complexities that no other applications have. I have worked in video games for a decade and shipped AAA games. The code I saw there was often NOT very optimized and NOT very maintainable. Code was frequently littered with TODOs, emergency hacks that were introduced to get through milestones or to final the game. This "temporary" code often stuck around into the next iteration(s) of the game. 
What language/workload? For C++, my top three might be: - Template debug bar - Vastly improved CMake project support - Very Improved lifetime static analysis Of course there are several other larger improvements for C++ devs that might be bigger things for some people than those three items. Also just a huge number of small quality-of-life feature enhancements. Overall, I've been absolutely loving the 2019 preview releases compared to the last few years' worth of updates (which were mostly just about better C++ language e.g. compiler/library support for me). Most of my grips with the 2019 previews are, honestly, things that are just as bad in older versions (or in any C++ IDE, because C++ is so hard to tool).
Does your crystal ball also say which new fad language of the day will be relevant 5 years down the road? I'd bet on C++ against any pick you might come up with and have a strong chance of ripping you off. LMAO.
It *could* behave like `map::at` and throw an exception, but IMO that large of a behavior difference based solely on the constness of the map is a pretty terrible idea. Too many places where type inference or refactoring could flip the meaning "silently." Designed today, some kind of `optional&lt;mapped_type&amp;&gt;` would be a decent option I think, but that wasn't really an option two and a half decades ago. (I forget what `optional&lt;T&amp;&gt;` behavior is now, so maybe it wouldn't work out of the box even now.)
[Concepts, Coroutines and Modules](https://twitter.com/GorNishanov/status/1100485900755062784) :D.
I don't think this is a very good argument for *not* doing so though. `myclass() = delete;` is an affirmative statement that you (at least slightly) considered whether this class should have a default constructor and decided the answer should be no. Omitting it entirely could have been done for that reason, or it could have been laziness and not realizing it's not provided and an oversight.
Yea, and they added some of their own "cmake-gui"-like GUI options, so instead of having to edit those custom VS json files (which are/were good!) you can now edit them in a GUI comfortably. A very good QOL improvement.
I don't know what lambdas are yet, but I would know eventually because I'm still learning c++
What? At least the project loading got considerably faster, like REALLY. Lots of measurements around the web to back that up. Also VS very rarely crashes on me. If they're update trajectory holds, it'll be twice as awesome as 2017. (well it's not, as 2017 was already awesome, but there's very nice improvements in 2019). Compare that to Xcode that is in a stand-still C++ wise basically, for a decade or so now.
Even as a German person... why would you want to read *machine translated* release notes... come on - just learn a bit of English and go read the original ones @OP.
I've had trouble finding C++ jobs I'm comfortable with for years. So I started a company and develop a [C++ code generator](https://gitlab.com/Ebenezer-group/onwards). If I couldn't do C++, I'd consider Python or D. 
By the way, how would IO functions work if `std::byte` is not 8-bit? How does work the current `void *` API? For example, what will happen if you write char with value=257 to file/socket? (e.g. on architecture that has 32-bit char)
There's an interesting analogy here with the database world, I think. There are a tiny handful of behemoths - Google, Facebook, Amazon, and, well, basically nobody else - who deal with data volumes off the scale. For them it made sense to put a lot of effort into designing bespoke database engines that are highly tuned to their specific needs. But then everyone else thought, "OMG if those guys are abandoning RDMS we should too!" and thus the NoSQL movement was born. But Random Social Media Startup #314159 has neither the resources nor the specific needs of Google et al; it turns out the 99% are better off with traditional databases that are cheap, well-tested, and versatile. Now we're seeing something similar in C++. The huge game behemoths like EA and Activision (and, again, almost nobody else) are developing the kind of bleeding edge quadruple-AAAAA games where having a custom replacement for `std::vector` that shaves a couple of bytes and a microsecond off every allocation is worthwhile, and they have the resources to implement it. But 99% of game devs aren't in that position - they just like to think they are. Random Game Startup #314159 doesn't need that kind of tooling but will benefit from some of the features actually being added to C++. But you're going to have trouble convincing them of that because it's so central to their self-image that they're bleeding edge developers who can write code that out-performs everyone else's totally unrealistic benchmark by, oh, a whole percent, maybe two with a good tailwind.
The thing is that I always read such stuff in English, even if microsoft.com redirect me to German site. This is why I accidentally posted German link. Sadly cannot change it any more.
This is not important for everyone. * Short Vector Math Library (SVML) intrinsic support. * OpenMP SIMD vectorization support, even if basic one. * C++20 operator &lt;=&gt; support :) 
Was P0934 (Fixing ADL) discussed on this or previous meetings?
The Entry API of Rust's HashMap is a nice design that solves these problems. Basically, the method `entry` returns an object that can be used to get, modify, or set a value without performing the search twice. The API doc has some example codes: https://doc.rust-lang.org/std/collections/hash_map/enum.Entry.html
They've been torpedoing since like 2010 in my experience. Ever since it got rewritten with all the XAML shit or WPF or whatever it is. Random lock ups for minutes at a time, switching from Debug to Release in the property viewer? Go make yourself a sandwich while i completely freeze (to do what, exactly?). Debugger performance is hilarious. Xcode is terrible, but MSVC is dogshit too. 
P.S I know you're on a deadline but your community license has just expired, let me redirect you to our login page that has JS form submission code that doesn't work and routinely 500s if you do manage to submit it so we can generate a new license, if you're lucky. Maybe all of this goes away when you fork out for the enterprise edition, but if Community is supposed to convince me to upgrade, they can forget it. Glad it works well for you, though.
If you are a ReSharper user, you will never know how it works and whether or not it works at all :)
Ah those pesky language-based auto-redirects.... :-) Annoying indeed!
Concepts
Ah, yes, if you are talking only about the default one, then it may be `noexcept` in most cases.
Any reasonably modern and common language, I guess, but I'm not picky. C, Python, Rust, Go, Java, C#, just off the top of my head and in no particular order of preference.
If that really happened, I would use profane English for a while.
Templates define an implicit interface that their parameters must satisfy, but don't require the "boilerplate" of actually writing out that interface. OTOH in most cases where that interface is non-trivial you will basically have to write it out for documentation purposes anyway...
What’s documentation for? /s
&gt; Very Improved lifetime static analysis I really, really hope they integrate all the `clang` tooling easily within the IDE: the static analyzer (as in XCode) and all the `clang` sanitizers (as the Profiler and the other run-time tools they have).
rigtorp::HashMap, https://github.com/rigtorp/HashMap, linear probing, backshift deletion I wrote it for a work load with lots of element churn (insert-delete pairs) and needed to avoid tombstones. Would be interesting to try using backshift deletion with SSE/AVX based lookup. 
&gt; where updating a value which might not exist requires like at least 5 lines, Huh? dictionary["abc"] = 5; Or if you mean update a field, sure, but still, it's not too bad: if(!dictionary.TryGetValue("abc", out T got)) got = dictionary["abc"] = new T(); got.Field = true;
Go, Scala and Python.... or C. &amp;#x200B;
Well exactly, everyone knows template code is self-documenting :)
Hmm.. an interesting idea and I kinda like it. It does pose further questions like should there be an `operator[]+=` and all the other variants?
Off-topic.
Just being documented is not a good enough reason for intuitive behavior. Not only is it unique to C++, it's also not consistent with other structures from the STL like `vector`.
Especially when read from the compiler error output.
Unfortunately, VS 2019 is virtually unusable for C++ projects because of completely broken IntelliSense: https://developercommunity.visualstudio.com/content/problem/443265/getting-intellisense-errors-e2996-and-e2998-wo-any.html Adding a single boost header to `pch.h` is enough to break it. At least it was in Preview 3. Preview 4/RC seems to be fine with a single boost header, but add a few more and bang - no IntelliSense.
1. Floating-point `to_chars()` shortest `fixed` is 60-80% faster. 2. Floating-point `to_chars()` shortest `hex` is available. 3. Floating-point `to_chars()` precision `hex` is available. I am definitely an unbiased impartial source on this topic. 
This. Is there some pattern or best practice for defining the requirements to be satisfied by template parameters? A couple of nested templates inside a shared pointer and compiler messages explode!
Concepts?
I've pinged our IntelliSense devs about this.
The problem with concepts in C++ is they check the syntax, not semantics. Given a concept naively intending to require "numerical" division with "/" will accept types overloading "/" for path concatenation. Then it will or will not fail inside the template implementation without the benefit of easier to read compiler errors that come from concepts. For the semantic-level concepts, look at traits in Rust.
Concepts, coming in C++20, are supposed to help by letting you define a compile-time interface that template arguments must match 
Concepts!
Ah as suggested by another comment. Thanks!
... concepts?
Yeah I read that comment after typing mine 
Thank you, Stephan. I want to try new releases, but just can't code without IntelliSense anymore...
I'm still using VS2013; ignoring C++17 (and maybe even C++20, it sounds like), have there been many QoLs added since?
Many studios have their own protobuf-esque thing (either separate description language, or a header parser) that's catered to working with content authoring tools in addition to network message serialization.
You can always require the resulting type of the division to be a valid numeric type (ConvertibleTo&lt;double&gt; for instance).
How would you check for semantics when defining an interface? It's all about what functions or operators can be called, whether it's concepts, virtual functions or traits in Rust.
C++ doesn't require interfaces in the java sense of the word. If you're defining them for all your classes, it's a java accent, and you're writing all that boilerplate because you're speaking C++ with a java accent. You can write a base class with virtual functions that are defined in the base class. That's fine. If you have two classes that depend on each other, well, that's probably a design problem. But if you want to do it anyway, you can write a pure virtual interface class and then do a concrete base class that fleshes out the commonly-used functions, which you'd then inherit most of your objects from. I do that in my [media project](https://github.com/FlyingRhenquest/media/tree/master/include/fr/media), where frame2cv inherits from video_decoder_subscriber which in turn inherits from decoder_subscriber_interface. I define subscribe in video_decoder_subscriber, so I just need to implement available_callback in frame2cv. There's not really any boilerplate in there.
The main argument I saw is: struct NoDefaultCtor { NoDefaultCtor() = delete; NoDefaultCtor(int); }; std::map&lt;std::string, NoDefaultCtor&gt; m; NoDefaultCtor ndc(5); m["abc"] = ndc; // works ndc = m["abc"]; // fails to compile At least now _both_ lines fail to compile.
The type would have to explicitly state that it is fulfilling a named concept, not just implicitly by accident, then implement the concept's requirements. So it would be similar to implementing an interface, doesn't use a vtable for dispatching and doesn't have to be confined within the type definition and . It could be extended outside of it.
This is super incorrect. The people advocating modern C++ are not saying to use a subset at all. They are saying "Feel free to use the whole language and here are some guidelines as to when the features are appropriate and inappropriate." The people not using modern C++ are saying, "I don't want to use the whole language. I want to use this subset." This second group is angry with the direction of the language because with each version of the standard the subset they have defined becomes less and less reasonable to use. 
GLM is probably a better example of a good open-source game-related math library.
templates are essentially c++ duck typing 
IntelliSense dev here- this should be fixed in the next release.
&gt; They are saying "Feel free to use the whole language and here are some guidelines as to when the features are appropriate and inappropriate." In a sane world, certainly. But in the world we live in, even in this very thread, peoåöe say absolutes like [”never call new or delete yourself”](https://www.reddit.com/r/cpp/comments/av8mmz/c_its_not_you_its_me/ehe3z1j/). There’s a vocal subset of C++ community that seems to consider ”purity” more important than solving actual problems.
[CONCEPTS!!!](https://youtu.be/HddFGPTAmtU)
Fails to compile with current containers, but could be specified to throw instead.
No, because that is reference-returning `operator []` followed by `operator +=`. Or maybe value-returning `operator []` followed by `operator +` followed by `operator []=`.
Sorry for zombieing a comment section but those benchmarks have an interesting but somewhat accurate flaw. Some random engines when initialized with a single call of `rd()` actually lack enough entropy to properly initialize their state. The easy fix is to combine multiple calls of `rd()` into a `std::seed_seq`. I have even seen people mess with it so they could just pass an `std::random_device` and it would internally wrap the `seed_seq` around many of its calls. This however is more indicative of poor interface design (which you need to follow for the standard) and it is thus likely that most users will use their random engines this way. Therefore the test could be indicative of 'average use'. However when someone is already worried enough to consider other random sources besides `&lt;random&gt;` it feels a bit like an accidental strawman to not compare the strongest versions of each with eachother. It is still however a very valid point when a third party library creates stronger randomness with less 'effort' and oppurtunities for hard to detect mistakes 'out of the box'.
&gt; Pretty much nobody says that. [Ahem](https://www.reddit.com/r/cpp/comments/av8mmz/c_its_not_you_its_me/ehe3z1j/). And it’s not just once or twice. As far as I can remember, every single time I’ve mentioned raw pointers in this sub (as in ”there are some use cases particularly in embedded systems and signal processing where raw pointers are cleaner solution than alternatives”), people insist such code is outdated and wrapped pointers are always better, without exceptions.
Hmm.. I think you're right. Since those operations require another object to be instatiated, the weird property of `operator[]` would actually be a feature. also I like the first suggestion better. `operator[]` should always return a reference.
As in RTM or first Update?
https://stackoverflow.com/questions/43803368/conversion-from-nullptr-t-to-bool-valid-or-not Please search before asking here.
&gt; community license has just expired Wut? It doesn't expire. You don't even need to be logged in to use VS, though it was pretty annoying to log be logged out occasionally in VS15 but they've fixed it in VS17 (at least I don't really remember it being a problem with the newer versions).
RTM or the next RC release, whichever is sooner.
Yes, people have thought about (and written) different languages.
&gt; behaves differently from other languages Clarification needed. There are languages/containers in other languages that behave the same.
I suppose it would be easy to provide an obviously short list of C++ features that are not potentially dangerous.
I hope the high CPU usage is fixed. After a while, I get 25% cpu usage which makes the editor completely laggy. 
Instead making another byte-stream, you can leave the stuff about stream bebind(they are already in &lt;iostream&gt;), just write something about binary struct pack/upack like the [python struct](https://docs.python.org/3/library/struct.html)
Great!
IMO yes. Everything is faster, cleaner, and more helpful in so many little ways that just add up to a more pleasant experience.
I stopped hitting that after Preview 3, fwiw. Not sure if it's really fixes or if I'm just not hitting the problem cases anymore.
&gt; If you're defining them for all your classes, it's a java accent You shouldn't define an interface for every single class in Java either.
What boilerplate?
std::function is the modern way to do it where you only have to specify the signature. Templates can do it too but build time usually takes a lot longer
It looks pretty decent in C++17. if (auto iter = map.find(value); iter != map.end()) { ... }
So kind of like typeclasses in Haskell?
The Curiously Recurring Template Pattern (CRTP).
Interestingly the C++03 section fails to mention stuff like [Boost.Local Function](https://www.boost.org/doc/libs/1_58_0/libs/local_function/doc/html/) that can be used to emulate local function calls for template functions, bypassing that C++-98 error. As an added advantage, from what I recall they can be converted to native lambdas when in C++11. Lambdas look cool, in particular when the IDE's syntax highlighter helps you, but in general I still prefer function objects or local function emulation simply because it works all across the board (some lambdas only work in C++14 onwards, I presume there are also others that work only in C++17 onwards, and I would not feel it strange that there are lambdas that work only in C++11 but not in C++14 onwards etc), and it fits better with code reuse. 
Are you kidding me? Here's what the guy says: &gt; The advice you'll see is to avoid owning raw pointers. Use smart pointers instead, and RAII techniques to manage memory. Never call new or delete yourself, except in a smart pointer/container implementation Yes, that is almost word for word what I wrote above. He *specifically* says don't use *owning* raw pointers. He doesn't say "never call new or delete, full stop". He says don't call them *except* when you are implementing a smart/pointer or container, i.e. for implementing your own ownership classes. Please give me an example of a valid use case for raw pointers, that doesn't fall into one of the caveats given by myself or the fellow you are quoting (or would be given by anyone knowledgeable in "modern" C++).
Not sure why you were downvoted but this is correct. Eigen is agnostic to the vector spaces you operate in, but GLM is aware of left vs right-handedness, supports convenient generation of view frustum matrices, dual quaternions, SIMD, and ensures alignment for driven uniforms and constant buffers on the GPU.
That doesn't explain why the other call also doesn't compile.
If you’re a student (or know one), know some C++, then this is a great chance to earn some moolah and get some real world experience. 
See: [https://www.boost.org/doc/libs/1\_69\_0/libs/beast/doc/html/beast/concepts/File.html](https://www.boost.org/doc/libs/1_69_0/libs/beast/doc/html/beast/concepts/File.html) [https://github.com/boostorg/beast/blob/5af7ad2e159c70d3ddde0c5ebbfc8c171c9648f7/include/boost/beast/http/basic\_file\_body.hpp#L47](https://github.com/boostorg/beast/blob/5af7ad2e159c70d3ddde0c5ebbfc8c171c9648f7/include/boost/beast/http/basic_file_body.hpp#L47) [https://github.com/boostorg/beast/blob/5af7ad2e159c70d3ddde0c5ebbfc8c171c9648f7/include/boost/beast/core/file\_base.hpp#L133](https://github.com/boostorg/beast/blob/5af7ad2e159c70d3ddde0c5ebbfc8c171c9648f7/include/boost/beast/core/file_base.hpp#L133) &amp;#x200B;
Moreover, according to that post, conversion from `std::nullptr_t` to `bool` is allowed in [direct initialization](https://en.cppreference.com/w/cpp/language/direct_initialization), which is used in [the criteria for contextually convertible to bool](https://en.cppreference.com/w/cpp/language/implicit_conversion). So `std::nullptr` should be contextually convertible to `bool`.
I will say, seeing this crazy C# subset custom compilation pipeline to some horrible native code actually makes me feel better about the quality of the C++ toolchain overall. &gt; When we use C# we have complete control over the entire process from source compilation down to machine code generation, and if there’s something we don’t like, we just go in and fix it. Sorry but as a gamedev, stuff like this nonsense is why I can never take Unity seriously as a professional AAA engine. It might be good for prototyping and other things, but come on. You can't add layers of abstraction on top and claim you have more control then just native with intrinsics (as necessary). Furthermore, even if that's true, this means less control for the enduser, aka you are catering to the hobbyist/indie/small-studio engine and should just admit it at this point. That, or come to grips with the realization that the weight of supporting the expensive C# runtime is not without its drawbacks.
Modules support and much better clang support as an optional compiler. Right now I have to use a custom build tool, just to support clang 7+ with modules support.
Please add better support for clang with modules support, right now I have to use a custom buildtool and intellisense is all messed up, with modules in general.
That would be nice, for now QtCreator’s clang integration in extremely well done.
Can that go into 2017 as well? It's a C++17 feature after all.
C++20 basically. Spaceship operator too.
Ah, the modern equivalent of `if (strlen(s)&gt;0)`
Without concepts you have SFINAE hell.
sounds like... an iterator? I guess it's probably nicer to use than the hinting version of insert though.
There's one easy way to do this: create tags like we currently do with iterators using iterator_category = std::random_access_iterator_tag; Concepts can check these things.
hmmm, what happens if the constructor throws? Does the map later try to destroy that uninitialized entry? Seems dangerous.
Wow, you could not have missed the point any harder.
Five years ago called and they want their prediction back.
Exploring constexpr optimization, bitfields for struct members &amp; alignment, and some other simpler things.
The general answer would be no, but as a special case, we added the ability to retrofit `&lt;charconv&gt;` to VS 2017 15.9. We still need to decide whether to ship a "bolt-on" library that completes 2017's charconv, but the technical ability is there.
I can't figure out why clang thinks that in both cases the converted constant expression requirements are not satisfied. The conversions happening are Integral -&gt; Boolean which can be used for converted constant expressions. The only exception to this is a narrowing conversion, but that [is also not the case](http://eel.is/c++draft/dcl.init.list#def:narrowing_conversion).
How about an equally clunky struct with function pointers as members?
 template &lt;class T&gt; struct OptinC : std::false_type {}; template &lt;class T&gt; concept C = requires ... &amp;&amp; OptinC&lt;T&gt;
It's only a library change, so it's a much easier ask than Concepts or Modules that require compiler support.
&gt;That, or come to grips with the realization that the weight of supporting the expensive C# runtime is not without its drawbacks. Isn't the point of Burst that it doesn't use the C# runtime? 
To me, the point of Burst is that they already have the C# runtime they need to interoperate with so providing better perf means they need to carve out a subset of C# and provide a custom runtime (as opposed of just providing a native engine API like every other engine with a lot of production usage)
&gt; you're speaking C++ with a java accent. You lately see people doing way too much template wankery where virtual inheritance (Java style used judiciously) would be sufficiently performant and easier to use. 
Pure virtual functions.
We disable exceptions.
At least they now allow you to switch to the original version with a button instead of hacking the url
Isn’t std::move just equivalent to `static_cast&lt;T&amp;&amp;&gt;`?
&gt; hacking the url https://tenor.com/view/nagato-suzumiya-pc-msdos-work-gif-7506285
 it's quite simple, can you test with my hash [https://github.com/ktprime/ktprime/blob/master/hash\_table5.hpp](https://github.com/ktprime/ktprime/blob/master/hash_table5.hpp) &amp;#x200B; &amp;#x200B;
Yes.
No. It's not for C++20.
You're probably hitting some kind of bug with your project or a plugin you're using. Not really reason enough to go calling it 'dogshit'. I'd recommend reporting this but given your attitude I doubt you will.
Clang? Haven't even got IDE/project support for MSVC modules yet. That sure would be nice to have.
;). I've used a url redirector plugin in firefox solely for Microsoft. Luckily they did not translate the page title. 
Haha, I thought you meant just changing the `de-de` to `en-us` or whatever.
Yes, that is exactly what the redirector did. But hacking sounds cooler (hey, I had to write a regex to do it ;))
I've tried to add it, but it doesn't have a default constructor
Since \`char\` is defined as character in the execution character set, it works... Just uses unusual ECS and bit patterns I guess.
I think we've shown that clang has bugs around this. Anyhow, compiler bugs are off topic here. Questions go to /r/cpp_questions or bug reports to the compiler.
It looks much more ugly than interface though.
It is... Almost. It is a function returning the cast. Which means we rely on inlining, so you pay some cost in debug. Plus you need to include a header, which add compilation time and you need to remember which header its in. For a feature you almost want to use everywhere. 
That is not a universally true statement. Pure virtual functions have their place. If you actually need runtime polymorphism, they can be a good choice. No, std::function is not always the answer.
So, if I understand correctly, they didn't like what C++ compilers do with their C++ code. So instead they just made an other compiler for a subset of another language? Somehow I can't believe that would be the most efficient way to have solved this problem. But ofcourse I don't know the details. In any case, it's kind of shitty to then start shitting on C++ and it's toolchain if you had to make your own compiler/toolchain for another language to solve the same problem.
Do you also rip off the C++ runtime then?
Actually it is 90's C++ accent, Java got it from C++ frameworks.
"interface" is If I remember the first example in Herb Sutter's metaclasses paper. (can't wait to have those)
- if constexpr (MemberPtr) { + if constexpr ((bool) MemberPtr) { std::cout &lt;&lt; MemberPtr &lt;&lt; "\n"; } ``` gcc and MSVC do this implicitly.
I prefer to be lazy and rely on the compiler in this and other cases, and not to do anything unless I have to. It makes code cleaner and compiler can sometimes generate more efficient code (see example from [**Jason Turner**](https://www.youtube.com/channel/UCxHAlbZQNFU2LgEtiqd2Maw) I've linked in another response). It's actually called "Rule of Zero": [https://en.cppreference.com/w/cpp/language/rule\_of\_three](https://en.cppreference.com/w/cpp/language/rule_of_three) [https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rc-zero](https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rc-zero)
If you are inserting or updating items in a map, it is even easier than that. Given: std::map&lt;int, std::string&gt; m; // stick some example values in the map m.insert({1, "I"s}); m.insert({5, "IIIII"s}); m.insert({10, "VV"s}); You can just insert (or emplace) new items and it will tell you whether it already existed: // brand new item, 'inserted' will be true if (auto [i, inserted] = m.emplace(2, "II"s); !inserted) i-&gt;second = "II"s; // updating an existing item, 'inserted' will be false, so we explicitly add the item if (auto [i, inserted] = m.emplace(5, "V"s); !inserted) i-&gt;second = "V"s; And C++17 makes it even easier: m.insert_or_assign(10, "X"s); It's also nice that the newer member functions don't require constructing a pair, but can just take the key and value as arguments.
Yeah I'm curious about this as well. I assume they don't like having to write a purely virtual interface class.
Then how do you "define an interface that must be fully satisfied by implementors at compile time" without the "define" part? Makes no sense. What I'm guessing is this "respected colleague" was fan of duck typing, which they can use templates to get if they want, but the duck typing of templates is considered a usability bug, not a feature (hence C++ concepts).
I still have the issue in preview 3. I will try this RC. If it's still present, I'll test disabling either Intellisense or Visual Assist.
Is there any way I can 'migrate' this post there?
We need CUDA support in the compiler ASAP.
Hi, I'm deleting this post and re-posting it in r/cpp_questions. You can check there if you're still interested.
Hi, I'm deleting this post and re-posting it in r/cpp_questions. You can check there if you're still interested.
Hi, I'm deleting this post and re-posting it in r/cpp_questions. You can check there if you're still interested.
When will VC++/MSBuild support inheritance of include paths, preprocessor definitions etc.? Build tools like CMake, Meson etc. have been supporting this for ages.
You're absolutely right. I am aware of the flaw, but totally missed it in tze the benchmarks. 
Good luck
&gt; Then how do you "define an interface that must be fully satisfied by implementors at compile time" without the "define" part? Makes no sense. Came here to say just this.
`std::function` is pretty heavy - there's at least one extra level of indirection over a virtual function. In some cases the optimizer could inline the virtual function if it already "knows" the type of the class - I don't remember if any compilers actually do this. And what if there's data associated with these methods? How does a collection of `std::function` handle that, other than with terrible hacks like "capturing references and hoping that they are still valid when the function is called" or "using `std::shared_ptr` for almost everything"? Finally, you solution doesn't really give you a method "of defining an interface that must be fully satisfied by implementors at compile time". (Still, shame on the people downvoting you without explaining...! :-) )
One answer is: well, virtual functions. But define your interfaces better. Where you have one interface with 15 functions, you might have meant 4 interfaces with 3-4 functions, depending on the aspects required. But one way or another, if your interface requires it, then you're going to need to write some code no matter how you do it. The other answer is: go and watch the C++ Seasoning talk(s) by Sean Parent.
&gt; also I like the first suggestion better. operator[] should always return a reference. Eh, why? There are many use cases where you do not want to return a reference, but return instead some proxy object stored on the stack. 
Anything I can actually use today?
I must say, I love that the Visual Studio devs hang out in the user forums like this and actually pick up bugs like these, rather than responding with "please create a bug report".
It doesn't support C++ on OS X. You have xcode...
for 10 years, intellisense is still a PITA. It's slow, inefficient, inaccuracy, requires lots disk space, and still crashes from time to time. I'd consider qtcreator has the best intellisense, code inspect integration.
A large issue however is the reliance on niche version control languages. For example Perforce. Due to a fear of checking in big files to git.
Clumsy and error-prone? Yes. Easy? Not so sure. The cleanest way I've seen so far is Haskell typeclasses and Rust traits inspired by typeclasses. As a bonus, Rust traits serve as both "concepts" at comptime and "interfaces" at runtime.
Yes. You need to explicitly declare your type conforms to trait. This opens two interesting opportunities, one being static trait functions, second being marker traits.
I mean I can totally understand the reasoning to have a C# game engine written in C# to unify all the tooling / developers skills. It goes a bit in this direction what Linus said about ARM/x86 [https://www.zdnet.com/article/what-linus-torvalds-really-thinks-about-arm-processors/](https://www.zdnet.com/article/what-linus-torvalds-really-thinks-about-arm-processors/). That being said they could have probably just used clang instead of roslyn and pretty much achieved the same xD
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/avq1k1/best_books_for_beginners_to_learn_modern_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Delete your .vs folder and .suo file. Should work fine after this. Using the Recreate Dtabase setting will not solve the issue; you must delete the files.
In case of having a lot of common boilerplate code, you can use public non-virtual interface and private virtual implementation. &amp;#x200B; Something like: `class BaseButton` `{` `public:` `void Draw()` `}`
Probably never...they already have vsc
`return {};`
 In case of having a lot of common boilerplate code, you can use public non-virtual interface and private virtual implementation. Something like: class BaseButton { public: void Draw() { DrawBackground(); DrawBorder(); DrawImage(); DrawText(); } private: // either some handy base implementations or '= 0;' virtual void DrawBackground(); virtual void DrawBorder(); virtual void DrawImage(); virtual void DrawText(); }; class SVGButton : public BaseButton { private: // reimplement DrawImage() virtual void DrawImage() override { RenderSVG(); } } void f() { SVGButton* button = ...; button-&gt;Draw(); } &amp;#x200B;
The objection isn't that detecting the native endianness is easy, the objection is that the native endianness is irrelevant. The relevant endianness is that of the serialized data, and presumably this is a known endianness. Converting between native endianness and _any_ known endiannes is always just basic arithmetic (with caveats re. floating-point).
reaching the end of non-void function without return statement is an UB except in main(). If false case is rare, you may use exception instead.
Every time this link is posted as a reply to a post the OPs never read it and assume they are right, this is yet another example. As harsh as it sounds, as soon as I saw that line I questioned the authors creditably with a proposal for something related to binary streaming and the design of the unheard of library
You can extend the rule to every return type, so that omitting the return statement or doing \`return;\` is equivalent to \`return {};\`.
AFAIK, this RC is identical to the latest preview, and I've also encountered this issue a few times on preview 3.
There is a bit of ceremony. The virtual keyword, =0, the rules of 0/3/5, the need for a virtual constructor if the bases constructor is public. Java is certainly more succinct when making interfaces. 
Use `std::nullopt` [https://en.cppreference.com/w/cpp/utility/optional/nullopt](https://en.cppreference.com/w/cpp/utility/optional/nullopt)
| Reaching the end of non-void function without return statement is an UB. Of course, hence it's a what if :) I actually chose to use an exception to stop the propagation through the next handlers. 
I wish I could event omit the return statement itself. 
Concepts can be emulated using the detection idiom. Also, if you support only GCC in your project, you can always enable the concept TS.
Amazing. While this sounds overly dramatic, if this one hadn't made it in, it probably would have killed my hope for the future of C++. I was seriously worried that the small amount of backward compatibility it introduced would be enough to kill it or severely cripple it. The fact that the committee was willing to break a small amount of existing code to make the language much saner, more consistent and easier to use makes me optimistic we can see similar changes in the future. 
What I posted was a hypothetical specification for a member function providing a strong guarantee, either does not throw (mutating) or potentially throws (non-mutating). But yes that does not really solve anything. We probably do not want to specify all levels of exception guarantees in the type system, I at least can not imagine a pretty way to do it. Right now we have a very strong guarantee (`noexcept`) or no guarantee, in the type system.
Thanks! Very helpful. &amp;#x200B;
Fresh install, multiple machines, my projects as well as others i've downloaded to test.
My comment above really seems to have bothered you, judging by quotes elsewhere in this thread. I don't know why: I maintain that using smart pointers and RAII to manage allocations is superior to doing so manually. &gt; *I mostly don't write ordinary programs in the first place* If you don't write "ordinary programs", then there's no need to feel bound by "ordinary advice"! If you're very close to the metal, then of course you're going to have to do "ugly" things sometimes. Such is life. The point is to try to minimise the number of places in your code-base where these "ugly" things appear, and (if possible) use safer abstractions instead. I really cannot see why this is controversial. It's basically the same as the advice in Rust or C# to minimise the use of the `unsafe` keyword, and wrap such code in a safe API where possible. In C++ we don't have a strict safe/unsafe split in the language, but we can still try to follow the spirit of the advice, even if the compiler can't do as many checks for us.
What's wrong with: return std::nullopt; Explicit. No possible misunderstanding.
I'm unconvinced his argument generalizes to your conclusion -- if you take his example and do `=default` instead of defining it manually, GCC, Clang, and MSVC all produce identical code.
Don't see how this is supposed to be more concise than an abstract interface.
Have you tried using GCC's `-Og` optimisation level? From the [GCC docs](https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html): &gt; -Og &gt; &gt;Optimize debugging experience. -Og should be the optimization level of choice for the standard edit-compile-debug cycle, offering a reasonable level of optimization while maintaining fast compilation and a good debugging experience. It is a better choice than -O0 for producing debuggable code because some compiler passes that collect debug information are disabled at -O0. &gt; &gt; Like -O0, -Og completely disables a number of optimization passes so that individual options controlling them have no effect. Otherwise -Og enables all -O1 optimization flags except for those that may interfere with debugging This sounds like exactly what you're after. 
English english link: https://docs.microsoft.com/en-gb/visualstudio/releases/2019/release-notes ;)
Why stop there? Have the final expression be the return value. optional&lt;bool&gt; handler() { // Some code false; // nothing after this line, so this is actually return false; } God, I hate that some languages consider this a feature or even worse - good practice.
`static_assert` will get you some mileage too.
&gt;return std::nullopt; 20 characters that could be simplified (if wanted). Take `main` for example, for historical reasons, no matter if the signature is `int(...)`, you can omit the return statement. In the case of optional, it makes semantical sense, can simplify the usage without 
I admit focusing on your comment was probably unfair. It just was the most recent example of such absolutes being given and highlighted how even people with reasonable views still often end up "laying down the law" in absolutes like "never use X". The "controversy" stems from there being a lot of vocal users in the community who _do_ seem think there are literally no exceptions. If the usual comments were "try to avoid raw pointers, modern C++ provides better alternatives to most use cases", nobody would protest (I shudder at the thought of writing heavy object handling code without containers and wrappers). Then you users with specific needs, like in the gamedev industry, who look at what people are writing, see many such naive comments and come to the (hopefully incorrect) conclusion that the whole "modern C++" is more about language purity than helping developers get things done. Then they write columns such as the one linked in the OP and here we are.
That would put a copy of the entire virtual table in each object, which can be rather wasteful.
 virtual foo() = 0; That's boilerplate compared to C# interfaces. Nor can you ensure that the abstract base class stays an interface. Anyone can add a data member or an implementation of a method and ruin it. Interfaces are actually one of my biggest gripes with C++ as someone who splits their time between C# and C++. I guess concepts are meant to solve it at the cost of yet more compile time.
If you define your concepts correctly you shouldn't need that so much. Also CRTP can be used for strongly typed things.
Sure, but I haven't seen the serialization library that can do this portably. We all say that it is possible but when time comes to write code, people write obvious byte swap and forget about corner cases. That's why I think it is important to have it in standard library so we don't have to reinvent the wheel every time.
There's examples for reading big- and little-endian data into a native-endian uint32_t right there in the article linked. There's no byte swap involved, because (as the article argues) byte-swapping implies you care about the native endianness, _which you don't_. If you have four (unsigned) 8-bit characters that you want to reassemble into a native-endian 32-bit (unsigned) integer, you're going to do `(chars[x] &lt;&lt; 24u)` for the MSB no matter which of those three chars happen to contain that MSB. Have you read the article?
&gt; But it misses the point by requiring the types to support operation that may not make sense for them. If a type doesn't support all the operations required for a concept, it is probably not fulfilling that concept...
Well, because it only requires C++11. In later version of C++ it looks very nice, and with concepts nicer still.
Excluding complex numbers, quaternions and matrices.
Trading ease of use for a bit of extra overhead, you could allow users to register a std::function&lt;void(WhateverEvent const &amp;)&gt; and then wrap it in a lambda that returns true after calling it, so the type you store is still std::function&lt;void(WhateverEvent const &amp;)&gt;. I thinks users can suck it up and return true though, that is not unreasonable. 
yes, destructors are implicitly noexcept
I've used a similar approach for a tree visitation algorithm that allows callers to optionally terminate traversal. Algorithm is templated on a lambda, and uses a templated helper that's specialized on the lambda return type (helper returns lambda's result or 'false' if lambda has no return). My case didn't involve storing the lambda, but the same approach could be used to either return the original lambda or a wrapper for storage. 
I didn't say it's impossible. It's just tedious - because of templates' duck typing. Unfortunately that's a very typical example of C++ "easy to make mistakes, hard to avoid them".
they wont release VS for mac.
VSC should support c++ on mac. you just need to supply it with its own compiler such as gcc/g++ or clang. it just needs a lot more setup on mac. i will agree it is convoluted AF.
VSC should support c++ you just need to supply it with its own compiler such as gcc/g++ or clang. it just needs alot more setup on mac. i will agree it is convoluted AF.
Nothing prevent you from building your own concept that perform that check if you need it for the types you need it. Noticed the "for instance" in my previous post ? The stl concepts are not going to guess what are your own user numeric types whose operator are overloaded.
Yeah, isn’t the “boilerplate” just actually implementing the functions? Doesn’t seem redundant at all.
He got rid of the photo!
Let's not over promise. It is a large proposal that a lot of people (like me!) are very excited about that _could_ make it to C++23. And it's even a language feature that the Direction Group has called out as a goal. But it's definitely not a sure thing.
Exactly as unbiased as my top 3: 1. Modules support 2. Spaceship operator 3. Better `/permissive-` support
I want to instantiate an instance of `template &lt;typename T&gt; class foo` from libfoo as `foo&lt;std::complex&lt;float&gt;&gt;`, and `class foo` uses arithmetic operators of T which are provided by `std::complex`. Everything should work fine. But the author of libfoo took your advise to test for `ConvertibleTo&lt;double&gt;` to make sure that the arithmetic operators actually perform arithmetic operations. Since `std::complex&lt;float&gt;` is not `ConvertibleTo&lt;double&gt;`, I now cannot use libfoo even though I should be able to, regardless of any other concepts I build.
VSC is too convoluted... compared to VS? 
I don't know about allowing plain `return;` in a non-void function, but I quite like the idea that falling off the bottom of a non-void function would be equivalent to `return {}`, as it is for `main()`. Better yet would be to actually require a diagnostic, rather than being UB as it currently is, but this might require complex control-flow analysis that asks too much of compilers.
It's an industry that needs to be unionized. 
Runtime concept idiom (see Sean Parent's talk: https://www.youtube.com/watch?v=QGcVXgEVMJg)
People post one of these every month or so. I'd recommend looking at the others and seeing what they have that yours doesn't.
compared to windows vs yes
No, this is really a bug and is easily reproducible by creating a project from scratch (no .vs and .suo).
That is correct. \`print\` is easy to write using the formatting API and I plan to propose it for C++23.
If you assume that bytes are 8 bit, you're already writing non-portable code. And before C++20 going from signed to unsigned and vice versa was shooting yourself in the foot. I'll probably have to re-read two's complement paper to be sure that signed-to-unsigned conversion is safe. And after that, well, if we can guarantee specific order of bits in unsigned variable, I guess then we will be able to use bit shifts after that. But please point to the standard that says that all the stuff you say is actually guaranteed.
It's not really a fear - git literally doesn't handle large binary files efficiently; every user ends up with a full-size copy of every revision of it in their machine. Until Git LFS, but that was too immature when we started our project, especially wrt exclusive checkout. Perforce it is! Awful for coders, but sensible for artists
... what? Why is using a better tool for the job a bad thing? Git is notoriously bad at dealing with large binary files. LFS helps, but it can be... Janky... Furthermore, perforce is _much_ more user friendly for non-programmers, and the ability to lock files built in (as opposed to git where it kind of works with LFS, but requires additional tooling to actually _work_ imo) is _huge_ when you have unmergeable binary files and potentially hugh teams. All of these issues are addressable of course, but if there's a tool that just works, why not use it instead of fighting something else? I love git. I use it for pretty much all of my projects. But your argument is utterly ridiculous and shows that you don't really know what you're talking about.
&gt; The conclusion was that abseil hash tables aren't optimized for iteration. Thanks, that's very useful information.
 **Company**: [Arxan Technologies](http://www.arxan.com) **Type:** Full time **Description:** Arxan protection solutions give our customers the confidence to publish applications in untrusted environments. Currently protecting more than 350 million devices worldwide, the company provides the industry’s most comprehensive application protection solutions. Arxan protects applications at the source and binary code level to expand the area of trust and provides a broad range of enterprise services and patented security capabilities. We are looking for a Software Developer to join our GuardIT team, focused on securing desktop and server apps for Mac, Windows and Linux. This is a unique R&amp;D position that will take full advantage of your knowledge of compilers, linkers, and OS internals and expose you to a wide variety of application protection techniques. If you are excited about software security, this is the place for you. You will work in a collaborative, agile environment solving deeply technical and challenging problems. You will research and develop anti-tamper techniques in order to detect and deter the modification of applications. Explore different instruction sets and binary file formats, and maybe even identify the occasional compiler bug or two. **Required Skills:** * Minimum 3 years' experience developing in C/C++ on Linux, Mac OS X, and/or Windows * Experience working with x86 or ARM assembly * Bachelor’s degree in Computer Science, Computer Engineering, or equivalent * Desire to work in a highly collaborative environment * Solid communication skills in English with the ability to work successfully with remote teams * Strong interest in application protection **Desired Skills:** * Deep knowledge of the function of compilers, linkers and loaders * Experience developing cross-platform applications * Familiarity with Python, Perl, or other scripting languages * Experience with reverse engineering * Familiarity with one or more binary file formats **Location:** West Lafayette, IN **Remote:** No **Visa Sponsorship:** No **Technologies:** C/C++ on Linux, Mac OS X, and/or Windows **Contact:** Please send cover letter + resume [here](mailto:hr@arxan.com)
That's interesting. I've mostly seen the Rust port of the Swiss Map in action ([`hashbrown`](https://github.com/Amanieu/hashbrown)) which is slightly different, compared to Rust's `HashMap` which uses Robin Hood with Backward Shifting Deletion and when both use the same hashing strategy (Fx), then the only benchmark when RHwBSD outperforms hashbrown is `grow_by_insertion` (by 10%). This may suggests insufficient benchmark coverage, or that the tweaks performed in the Rust version would be interesting to port to the C++ version...
Is there also an issue with the new "C++ Productivity Improvements in Visual Studio 2019" as detailed: https://devblogs.microsoft.com/cppblog/c-productivity-improvements-in-visual-studio-2019-preview-2/ or am I missing a setting to turn them on?
\&gt; Is print even being standardised? Not for C++20.
C++20 feature that the projects you work on won't get until 2030. 
We're already working with NVIDIA to support CUDA. Can you please try [CUDA 10.1 with VS 2019](https://devblogs.microsoft.com/cppblog/cuda-10-1-available-now-with-support-for-latest-microsoft-visual-studio-2019-versions/) and let us know if the ICE still happens?
You don't have to change for references/pointers everywhere, don't change allocation strategy, don't have to inherit from it etc.
 class Countable { virtual int count() = 0; }; class Number : public Countable { int count() override; }; int Number::count() { return ... } I think the thing that simplifies this is modules. C++ already has boilerplate in terms of implementation of member functions, adding virtual interfaces doubles this. I'm a fan of the way Swift does it: protocol Countable { func count() -&gt; Int } class Number: Countable { func count() { return ... } } The work to define the interface is required no matter what, C++ doesn't add to that. But the bloated work is from the C compilation model.
Well, the bloat is the virtual and = 0. C# interfaces are roughly equivalent to that Swift example.
VSC suffers from being extremely customizable and, thus, needing to be extremely customized. If you don't want to customize it then it's a much worse version of vim/emacs/whatever. Seems to me like a lot of plugin authors design their plugins in a vacuum and ship it when they like the UI presented by their plugin alone without realizing that the user probably has 20 others. 
They probably won't. It's an entirely different product that was just rebranded to be named "Visual Studio." And being that they probably won't support shipping the IDE's main compiler as clang I doubt they ever release a C++ IDE. 
Well, this is probably never going to happen, and IMHO that's a good thing. This would just result in another additional unintuitive behavior. What I much rather would like though, is for c++ to incorporate statements expressions, like [GCC has](https://gcc.gnu.org/onlinedocs/gcc/Statement-Exprs.html), and then you could get code [like this](https://ned14.github.io/outcome/tutorial/essential/result/try/) (scroll down to the OUTCOME_TRYX example). This will basically be the same as try in swift or rust afaik. And since coroutines were merged into c++20, we [will get that](https://github.com/arBmind/2018-cogen-en/blob/develop/code/co_optional/main.cpp) :-)
&gt; The other thing - knowledge of what you can forward declare (which is btw thechnically just another boilerplate) is actually pretty arcane and people end up with unnecessary headers included in headers more than needed most of the time. Easily my least favorite thing about C++. Especially when I'm working on a project that I'm not familiar with. 100% pedantry.
What would be a good starting point (blog posts/talks/...) to find out how much nicer this would look with A) C++14 and B) C++17? I suppose with C++17 it might be done quite differently, but does C++14 help already too?
This entire thread is why a standard sub C++ will never happen. Nobody will ever agree what is in and what is out. 
I think the author of the PolyCollection library in Boost would agree with you. That documentation has this: Three container class templates are provided: boost::base_collection boost::function_collection boost::any_collection respectively dealing with three different types of dynamic polymorphism available in C++: Classic base/derived or OOP polymorphism. Function wrapping in the spirit of std::function. So-called duck typing as implemented by Boost.TypeErasure. The C++ Middleware Writer has [serialization support for base\_collection](https://github.com/Ebenezer-group/onwards/tree/master/src/cmw/poly).
You assume that you already have template code in place everywhere? In my experience, generic code via templates is a lot more viral than generic code via references, but of course if you want to fit "interface-checks" to an existing codebase it depends on what is already there.
I'm not terribly familiar with C++17 but I believe `std::is_detected` is the new approved way (and also much easier and shorter to write)
Is anyone working on common types for the various use cases for coroutines similar to [these from Andreas Reischuck] (https://github.com/arBmind/2018-cogen-en/tree/develop/code) for the standard library?
When you say 'mov y, eax' aren't you essentially clobbering the reference stored in the lambda object rather than writing to the stack variable at which it points. If so, you can't really expect good things when using inline asm to rebind a reference when codegen would assume it to never happen.
&gt; The compiler accepted this code without complaint, but weirdly, the compiled code did not work as expected. The instructions generated did not reference the correct stack locations for the captured variables. When reading from the captured variables, incorrect stack locations were accessed, potentially leaking sensitive stack data. When writing the captured variable r, the write went to an improper location on the stack, potentially corrupting data or control flow. This sounds more like a compiler but than some nefariously subtle vulnerability. 
The `print` API offers a few more features like handling terminal colours though. I don't know whether there is a will to get this standardised.
The most annoy thing is that you have to remember a lot of traps like this. Couldn't the compiler help develop out of these kind of thing?
That's odd, they should definitely be on by default so it sounds like a bug. Are you referring to quick fixes specifically or are you having issues getting other features to run (like Go to Document on #include?). I contacted some engineers to investigate this further.
They released Preview 4 at the same time as the RC which are identical, but didn't actually document what the changes were between P3 and P4 :/
 int Beispiel::tuWas(int i) { int x, y; int z = (x = i*4, y = i%4, 12); return z+x+y; } I saw this in one of my exercises and fail really hard to google anything about it. Does anyone recognize it and can tell me what's the point about it? I tried some stuff in VS17 and it seems like z gets always the value of the last int. Something like this works too: int z = (3, z = 5, 2) // z being 2 after the line. No compile error.
It is strange, sometimes MS's feedback on the developercommunity is great, but sometimes it is awful. I submitted a report in August ([https://developercommunity.visualstudio.com/content/problem/312318/c-await-is-still-a-keyword.html](https://developercommunity.visualstudio.com/content/problem/312318/c-await-is-still-a-keyword.html)) and it is still under investigation. How can that be? Is there a chance that this will be fixed soon?
I like this!
Update: okay so we just added a setting in Tools &gt; Options to toggle quick fixes on/off. You can find it under Text Editor &gt; C/C++ &gt; View &gt; IntelliSense Error Fix Suggestions. It looks like the bug is with the setting being set to "False" instead of "True". If you toggle it to True, the quick fixes should come back. Thanks for pointing out this issue, we'll work to get the bug resolved for everyone as soon as possible. 
&gt;Visual Studio Remote Code Execution Vulnerability &gt;Exploitation of the vulnerability requires that a user open a specially crafted file which was compiled with an affected version of Visual Studio. In an email attack scenario, an attacker could exploit the vulnerability by sending a specially crafted project, or resource file, to the user and convince the user to open the file. Am I missing something obvious here or the article does not explain everything? If "a specially crafted file which was compiled ..." just refers to executing a malicious file, how is this called a RCE?
u/ned14 have you considered making OUTCOME_TRY_X using coroutines support (and thereby making it work on msvc) like done for [optionals here](https://github.com/arBmind/2018-cogen-en/blob/develop/code/co_optional/CoOptional.h)?
I really don't see why failing to compile when not supported is a problem ?
It's not. The article just describes a convoluted way to corrupt the stack and tries to assign some deep meaning to it. It's like saying that just having the ability to write past the end of a stack buffer is an RCE vulnerability.
Codegen bugs happen all the time. And it's precisely because they are so nasty that compiler developers are usually jumping on them as soon as they get reported.
Sorry, wasn't clear with my comment - I understand it's obviously not, I'm just really surprised that's how Microsoft describes it, the quote is from their site, not ZDI. :) 
Oh
I tried to do a similar thing but backed off since I couldn't get the IDEs (clion and VS) to properly get the system headers. Does dockcross have any solution to that issue?
Nah, I got you loud and clear. I was just trying to add to it by saying that not only should it not have been classified as a vulnerability but that I feel it should never have been reported. The issue described in the ZDI article isn't interesting. All it does is corrupt the stack by using inline assembly that was never going to work with the lambda machinery, but then goes on like it's an important discovery.
VS for Mac is Xamarin Studio. It will likely never not be a .net thing
Thanks for letting me know. Now I can safely visit the site again.
That setting lit up the feature but seeing some rather odd results. For instance when project set to using v141 cout &lt;&lt; "Hello World!\n"; the suggestion is to add include: #include "../../../../../../Program%20Files%20(x86)/Microsoft%20Visual%20Studio/2019/Professional/VC/Tools/MSVC/14.20.27404/include/iostream" Despite #include &lt;iostream&gt; already being present When set to v142 it suggests adding #include &lt;iostream&gt; I will raise some bug reports. Note also the blog posts on VC++ refer to setting in Experimental that have moved elsewhere. Mainly the https://devblogs.microsoft.com/cppblog/in-editor-code-analysis-in-visual-studio-2019-preview-2/ which states: "you can do so via the Tools &gt; Options &gt; Text Editor &gt; C++ &gt; Experimental &gt; Code Analysis menu" - I don't believe this is correct now 
I've pinged Gor.
Unfortunately I don't know, you could try to ask @thewtex on Twitter, I believe he is the maintainer. I discovered the project while looking for an easy way to build Qt applications on CI-servers, where this could fit the bill. I found it quite impressive how I could set up the toolchain and crosscompile a windows binary using only 3 commands on a clean machine with docker installed: docker pull, generate the dockcross script, then run the build.
For more details, you'll want to read [this](https://github.com/abseil/abseil-cpp/issues/223).
Many thanks Stephan!
As a novice, it would be annoying and confusing why _writing_ to a map would work but _reading that same value back_ would fail. As an intermediate user, it seems like a needlessly complicated change to the language in order to turn "operator[] has some pitfalls for associative containers" into "operator[] has a different set of pitfalls for associative containers".
See also https://github.com/toby-allsopp/coroutine_monad
I doubt many c++ users would go for that. It would trade the rare scenario of "the default value is okay if it's not in the map" for the rare scenario of "I'm absolutely sure this object is in the map" (or "I'm okay with wrapping it in a try-catch &amp; taking the performance hit").
The issue, I believe they have, is the C++ compiler is not required to apply ever optimisation. Often you need the optimization to get the speed (for example vectorisation), so to get that speed you are forced to write your code in as a set of intrinsics which is compiler specific (non portable). So often you will see a big block of SSE intrinsics followed by a block of Neon intrinsics. They do pretty much the same thing so it would be nice if they generated by the compiler rather than you. I don't think there is a nice way to do that in as a portable C++ toolchain?
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/avwtvp/noob_compass_bearing/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
They say ["continuation is the mother of all monads"](https://www.schoolofhaskell.com/school/to-infinity-and-beyond/pick-of-the-week/the-mother-of-all-monads) and coroutines are great for expressing continuations.
Honestly, I'm sort of tired of hearing this sort of thing as well. I should mention that, in professional environments, I tend to hear much less of this sort of thing. Most game dev professionals are... well, professional, and just quietly do their job with the language we have. We do have a few special circumstances, but really, not *that* special in terms of language requirements. I disagree with the author's fundamental take on C++ 11 as well. I absolutely love the changes that have been made, on the whole. It's made my day job so much nicer. Yes, there's always things here or there we'd like to see different, but exactly where else in life don't you have to deal with compromises? &gt; I'm only writing this because I'm worked up, but I honestly suspect that the reason that so many game devs seem to feel the need to posture on the internet is because they are overworked and underpaid Dare I mention you're falling into the same trap by stereotyping game devs as downtrodden low-salary slaves? Remember, you tend to only hear about the horror stories. 
**Company**: [Disbelief](http://disbelief.com) **Type**: Full time **Description**: Disbelief is a game development studio focusing on contracting and consulting services. We’ve worked with both AAA and independent studios to help their projects ship. Notable projects we’ve worked on include Gears of War 4, Borderlands: The Handsome Collection, and Perception. At Disbelief, we’re problem-solvers, first and foremost. We like to dive in to figure out the reasons something isn’t working before fixing it. We take pride in solving problems others can't. We value a sensible work-life balance and work environment. We work with leading edge technologies to make them perform at the top of their capabilities. Currently, we’re looking for a junior programmer. This opportunity is for a full-time position in Cambridge, MA or Chicago, IL. Junior programmers at Disbelief are called on to develop and debug in a variety of areas from game play to core engine programming. You are expected to learn new systems and projects as you grow as a developer, with support and training from more senior members of the team. Most importantly, you will work to solve problems with the help of the team. *Key Responsibilities* * Clearly communicate your work to others * Debug code * Estimate task work * Consider performance when writing code * Document your code *Skills and Requirements* * BA/BS in Computer Science, or equivalent experience * Excellent communication skills, both verbal and written * Some type of systems programming in any language. * Good understanding of C++ * Knowledge of version control with P4, git, or equivalent **Location**: Cambridge, MA or Chicago, IL **Remote**: No, but we do enjoy working from home up to two days a week, when project constraints allow. **Visa Sponsorship**: No **Technologies**: Most of our work is C++ of varying standards with a sprinkling of other languages as needed for tooling. We do a lot of graphics programming work, using shader languages and platform graphics APIs. Since we often are debugging the lower levels of systems, being able to read x64 or ARM assembly is useful. Primarily we work with Unreal Engine 4, but we also work with Unity and custom game engines. Our work uses rendering, physics, audio, VR, AR, and other APIs frequently. Our primary platforms are PC, Xbox One, PS4, Switch, and VR/AR devices. **Contact**: [jobs@disbelief.com](mailto:jobs@disbelief.com)
**Company**: [Disbelief](http://disbelief.com) **Type**: Full time **Description**: Disbelief is a game development studio focusing on contracting and consulting services. We’ve worked with both AAA and independent studios to help their projects ship. Notable projects we’ve worked on include Gears of War 4, Borderlands: The Handsome Collection, and Perception. At Disbelief, we’re problem-solvers, first and foremost. We like to dive in to figure out the reasons something isn’t working before fixing it. We take pride in solving problems others can't. We value a sensible work-life balance and work environment. We work with leading edge technologies to make them perform at the top of their capabilities. Currently, we’re looking for a senior programmer. This opportunity is for a full-time position in Cambridge, MA or Chicago, IL. Senior programmers at Disbelief are leaders and developers in their project. You should be comfortable working independently and with a team to develop, test and integrate software into a larger codebase. A key responsibility is mentoring and guiding fellow programmers to improve. *Key Responsibilities* * Clearly communicate your work to others * Mentor fellow programmers in and out of your team * Communicate with clients on team progress and problems as they arise * Debug code with precision * Estimate your and others work * Assess impact of issues on schedule * Diagnose and solve performance issues * Document your code * Study version histories and code documentation to solve present problems * Implement features in innovative ways *Skills and Requirements* * BA/BS or MS Degree in Computer Science, or equivalent experience * Excellent communication skills, both verbal and written * 3-5 years of experience in writing software in C++ * 5+ years in game development, or 10+ in a related industry * Experience working on a large code base * Experience with version control with P4, git, or equivalent * Experience with multi-threaded systems **Location**: Cambridge, MA or Chicago, IL **Remote**: No, but we do enjoy working from home up to two days a week, when project constraints allow. **Visa Sponsorship**: No **Technologies**: Most of our work is C++ of varying standards with a sprinkling of other languages as needed for tooling. We do a lot of graphics programming work, using shader languages and platform graphics APIs. Since we often are debugging the lower levels of systems, being able to read x64 or ARM assembly is useful. Primarily we work with Unreal Engine 4, but we also work with Unity and custom game engines. Our work uses rendering, physics, audio, VR, AR, and other APIs frequently. Our primary platforms are PC, Xbox One, PS4, Switch, and VR/AR devices. **Contact**: [jobs@disbelief.com](mailto:jobs@disbelief.com)
**Company**: [Disbelief](http://disbelief.com) **Type**: Full time **Description**: Disbelief is a game development studio focusing on contracting and consulting services. We work with both AAA and independent studios to help their projects ship. Notable projects we’ve worked on include Gears of War 4, Borderlands: The Handsome Collection, and Perception. At Disbelief, we’re problem-solvers, first and foremost. We like to dive in to figure out the reasons something isn’t working before fixing it. We take pride in solving problems others can't. We value a sensible work-life balance and work environment. We work with leading edge technologies to make them perform at the top of their capabilities. Currently, we’re looking for a programmer. This opportunity is for a full-time position in Cambridge, MA or Chicago, IL. Programmers at Disbelief are called on to develop and debug in a variety of areas from game play to core engine programming. You are expected to learn new systems and projects as you grow as a developer. You are also expected to use your knowledge to solve problems both you and others in your team have. *Key Responsibilities* * Clearly communicate your work to others * Debug code * Estimate task work * Assess impact of issues on schedule * Write performant code and specialized systems * Document your code * Study version histories to guide current problems * Implement new system features *Skills and Requirements* * BA/BS in Computer Science, or equivalent experience * Excellent communication skills, both verbal and written * 1+ years of experience in writing software in C++ * 1+ years in game development, or 3+ in a related industry * Experience with version control with P4, git, or equivalent * Understanding of multi-threaded systems **Location**: Cambridge, MA or Chicago, IL **Remote**: No, but we do enjoy working from home up to two days a week, when project constraints allow. **Visa Sponsorship**: No **Technologies**: Most of our work is C++ of varying standards with a sprinkling of other languages as needed for tooling. We do a lot of graphics programming work, using shader languages and platform graphics APIs. Since we often are debugging the lower levels of systems, being able to read x64 or ARM assembly is useful. Primarily we work with Unreal Engine 4, but we also work with Unity and custom game engines. Our work uses rendering, physics, audio, VR, AR, and other APIs frequently. Our primary platforms are PC, Xbox One, PS4, Switch, and VR/AR devices. **Contact**: [jobs@disbelief.com](mailto:jobs@disbelief.com)
But then how do your beans work?! THINK OF THE BEANS, MAN! Yeah no, I just see a lot more of them in Java than in C++. I think about three quarters of the ones that I've seen defined in Java on past projects I had to maintain weren't really necessary either. Seems like a java cargo cult kind of thing. Kind of like using Hungarian notation in C/C++ projects.
&gt;not consistent with other structures from the STL like `vector` Wouldn't take that as an argument. Is doesn't work that way for `vector` because it wouldn't make sense. Or what should this code do? auto container = std::vector&lt;int&gt;{}; container[100] = 1 Value-Construct 100 Integer? Leave that all uninitialized? Yes, `std::map` and `std::vector` share some properties, but not all of them. Why? Because, all abstraction aside, they have widely different use-cases. And the way it works now is just so convenient. Just think about the classic example of counting characters without this feature: auto char_count = std::map&lt;char, int&gt;{}; for(auto c : text) { if(auto iter = char_count.find(c); iter != std::cend(char_count)) { ++*iter; } else { char_count.insert(c, 1); } }
If I were a guessing man, I'd guess that they're talking about implementing all the interface functions in all the downstream classes. Which would probably result in a lot of cutting and pasting if you just plowed into it without thinking about what you were doing at all. Which as we all know, is the absolute best way to program. Because if you thought about it for a minute, you'd just derive a base class from your interface class, define the common functions there, and then derive the rest of your classes from them. But perhaps his point was that you don't need to define an interface with pure virtual functions at all, since you can just implement the virtual functions in your interface class. Which works pretty well as long as you're not writing header-only libraries with objects that depend on each other.
How would you warn about this? Flag every use of operator\[\] on a map? Even if the value is known to be already there? Even if that's exactly the behavior you want? I may be biased on this, because C++ was my first language with a bigger standard library (C can't have these pitfalls because there just isn't any map in the std. \*tips on forehead\*), but I was never that surprised by this function. Coming from arrays and in extension vectors it kind of made sense to me that operator\[\] wouldn't throw if there wasn't any value. \`vector\[vector.size()\]\` does not either.
Can you say something about the compilation times? Some time ago I also set up a container for cross compilation myself. I wanted to mount the source files into the container too. IO restrictions of docker for Mac made complication times a pain in the ass. About 6 times slower than native cross complilation, which resulted in 30 min or more builds ☹️
I think this would be my favorite feature. optional&lt;int&gt; parse_int(const std::string&amp; str) { int value; if(try_parse(str.data(), &amp;value)) return value; else std::printf("Couldn't read the int") } Wow, this works so well that it can even parse the english language! parse_int("Twenty-One") == 21 //Even german parse_int("Einundzwanzig") == 21 // Or is it a bug? parse_int("Shoot yourself in the foot") == 21 &amp;#x200B;
Let's not turn this language into the abomination that is Ruby
https://en.cppreference.com/w/cpp/language/operator_other#Built-in_comma_operator
It's funny, cause this exact comment you pointed at backpedals in the next line: &gt;except in a smart pointer/container implementation. And that's a really good advice for 99% of the people and 99% of code you are going to write. Yes even as a Gamedev. Raw new and delete should only be used with very good reason in very rare cases.
&gt;And the language has been getting worse for a while. What exactly got worse in the language itself?
But unions are basically socialism.
I love it! For anyone wondering how this works, check what `printf` returns.
Hi Felix, I'm sorry, it was my bad, I should have looked at it sooner. We usually triage incoming bugs according to severity and breadth of their impact and then address those in the assigned priority order. There was a slew of regressions and high-priority items that prevented me from looking and responding to your ticket. That said, I will try to address it in the coming days so that the fix becomes available under /permissive- in VS 2019 Update 1. Sorry once again for not getting back to you sooner.
I used to use it often. My Linux distribution of choice is fedora which makes it difficult when cross compiling to aarch64 for example. Later on I switched to either Debian containers (good multi arch support) and the linaro pre compiler GCC toolchain.
If you're going to be using the XMacro method anyways, you can use it to define the original enum class, so you only have to write them out once. In this case, you would do ``` enum class PixelFormat: UnsignedInt { #define _c(input, format) input, #include "pixelFormatMapping.hpp" #undef _c }; ```
Asm blocks are not standard C++, and it's been frowned upon for a while already.
Any progress on std:: overload or something similar to use with std:: variant?
Colors support is still a bit experimental. I'd give it more time to bake.
There is always `co_print`.
&gt;Can you say something about the compilation times? Some time ago I also set up a container for cross compilation myself. I wanted to mount the source files into the container too. IO restrictions of docker for Mac made complication times a pain in the ass. About 6 times slower than native cross complilation, which resulted in 30 min or more builds ☹️ I assume Docker for mac isn't a native one. Docker is based on cgroups and namespace of Linux Kernel. Try get a Real Linux box.
I explicitly avoid inline asm. Put it in its own file and link to it or _maybe_ a declspec(naked) function. But given x86-64 doesn't tolerate it at all, the former is a better idea. Play stupid games, win stupid prizes.
Then again, the syntax enables such elegant code as this. &amp;#x200B; // Calculate word counts std::unordered_map&lt;std::string,int&gt; m; for(auto&amp; word:words){++m[words];} &amp;#x200B;
&gt; Anything in particular you'd like to know about? How are they resolving independence of the order of compilation?
Installing and setting up vscode cpp plugin took 20 secs max. "Convoluted"
I installed it to do C but what a disappointment. Turned out to be worse than notepad++
Great, so you've got helloworld.cpp on fucking lock. Let me know when passing VsDevCmd environment variables to the cmake plugin to call clang-cl isn't a fucking miserable experience.
&gt; In practice, it is exceedingly rare to hear of a compiler introducing a vulnerability into 100% correct, non-malicious code Well the code is not 100% correct, it relies on non-standard compiler extensions (inline assembly). 
I believe part of it is that it is simulating Concepts with a lot of template meta-programming. I expect as we have concepts and as the implementations mature, the compile times will get better.
ELI5 please?
Can't u just invoke cmake via cmd? I use vscode as a text editor and debugger (autocomplete, and stuff like that). That's what it is. 
The signed and unsigned is still just integers your dealing with, you can can use math to decide if something is positive or negative for signed depending on how you read the bits (or convert from unsigned to signed) you could be rely on signed overflow and 2's compliment. 8-bit is generally more easily to assume, even though the standard does not define it as the systems which aren't 8-bit are next to non-existent these days. If you want to get into things outside of 8-bit then your in for a world of pain, is it continuous bits your sending (e.g. 32-bit for 36-bit) or 8-bit byte in a larger byte (e.g. 9-bit). What about if your on a 16-bit machine, would you expect 1 byte fread or recv on your network to contain two 8-bit characters or just one 8-bit char in a 16-bit char? The FTP RFC has a good little read on the issues with different word sizes: https://tools.ietf.org/html/rfc959 
@[fatihbakir](https://www.reddit.com/user/fatihbakir) I suggest you create an issue at [https://github.com/dockcross/dockcross/issues](https://github.com/dockcross/dockcross/issues) , @thewtex and myself (@jcfr) are both maintainers of the project (with contributions from any others) and would be help you.
What kind of "width of a string" is the number of code points useful for? Things it's not: - size on screen - size in glyphs - size in memory - size on disk - size in a tweet - size for use in sorting - size for use in transformations (uppercase, lowercase, etc) It means "size after converting to UTF-32" but I'm not convinced that's super useful.
My statement comes directly from programmers at Massive in Malmö. They have to use Perforce, many would strongly prefer git.
Two questions. What's ANSI mean here? What do you use randomly indexing into identifiers for? Aren't they just opaque blobs?
They have to use perforce because it handles binary files better... Binary files are kind of a big deal when working with huge teams of artists. I would guess that the overwhelming majority of programmers would prefer git to most other VCS.
UTF-32 will still cause code that assumes "one character is one character" to break; you mentioned emojis and that's a good example of something that causes that and that is in widespread use
What an awesome project. Is NVIDIA hiring for this?
thats simply an engineering issue, the gamedev industry's reluctance to participate in the c++ community is exactly what is at issue
I don't have any slots right now, I'm afraid.
in my benchmarks where I randomly insert and erase entries, tsl::robin_map is about 40% faster when the number of elements is kept around 200 or so. The performance difference goes down a bit when the map gets larger, but still 20% or so in my benchmark.
I've added your emlib4 map, and it has really excellent find performance, especially for small maps. But it completely freezes up in my my benchmark where I randomly insert &amp; remove elements. This benchmark does something like this: Map&lt;uint64_t, uint64_t&gt; map; for (size_t i=0; i&lt;100000000; ++i) { map.emplace(rng() &amp; 0xff, i); map.erase(rng() &amp; 0xff); } So there unfortunately seems to be a bug in your map.
Are there any plans for additional tutorials to be added to the Thrust documentation? There was a "CUDACasts" series on YouTube but that appears to have died off. I've been using CUDA for image processing for a while, and decided I'd like to try my hand at using the thrust library, but I've been stumped on how to apply a simple image kernel like a mean blur to an image, so I've resorted back to custom CUDA kernels again. Can you suggest a location with good examples? &amp;#x200B;
 compile it with falg = -O3 -fno-strict-aliasing . I do not know the reason. But clang++ and ms c++ is OK. my emlib4 is the fastest hash for some special case Map&lt;uint64\_t, unt32\_t&gt; map or Map&lt;uint32\_t, unt64\_t&gt; map. try it.
Many thanks for the feedback!
[The linked CVE](https://portal.msrc.microsoft.com/en-US/security-guidance/advisory/CVE-2019-0546) says, at the time of this writing, that it's not publicly disclosed. TFA came out too early?
Why do you suggest a non-standard compiler extension makes something incorrect? The code written was absolutely correct according to the compiler's specification; which is why Microsoft recognized this as a bug and then decided to revise their compiler by disallowing this feature.
Does it have `thrust::array` now?
&gt; The code written was absolutely correct according to the compiler's specification Where is the compiler's specification for inline assembly in a lambda? Particularly what the guarantees are about which register is in use for what. 
I think they do it because *every* trashing of the stack is a *possible* RCE. Experience shows that t is safer to *assume* these can be turned into RCEs.
References are not objects. The language assume they are not pointers, they can’t be changed, they can’t be null, they are properly aligned, they are always dereferenceable... So yeah, this is just UB doing what it is supposed to do: allowing optimizations by assuming that certain things can’t happen.
No, but it's on my TODO list. File a bug if you really need it - it won't take long for me to implement. We do have a `thrust::optional`.
If it comes down between me being able to write sane code, and emojis, sane code is going to have to come first. 
We do need to update our documentation and tutorials. I'm afraid I don't have a great place to point you too right now.
That's a good point. I would rephrase: the tooling has gotten worse for my needs. However, that's not separate from the language itself, because the tooling has changed to accommodate the language. 
Thats what I do too, but thats not what I'd call an IDE.
There is no need for this. C++ veterans already know how to handle the unsafe parts of the language and C++ newbies aren't in positions that can introduce unsafe parts in reasonably organized projects. 
Roslyn is only for C# =&gt; MSIL. Their IL2CPP and Burst compilers are based on LLVM.
But that's not what the choice comes down to. It's between that code and ton of other examples where it breaks. Emojis are just a readily available example that everyone can recognize.
It's not advertised as an IDE. You are frustrated because you're trying to use a software for a different purpose and it's not working as expected? 
Why would I be frustrated? I'm quite happy with both VSC and VS.
Does msvc 2017 or 2019 with Cuda 10.1 support C++17 now?
Personally I like to use `operator()` for this purpose: `x[y]` returns a mutable or constant reference depending on the const-ness of `x` (and correspondingly may change the content of `x`, e.g. add an element or clear some cache etc in the mutable version) and `x(y)` always returns a constant reference. If the default-constructed element is small, the container may contain a standard zero element a reference to which it may return, otherwise it throws if `y` is not contained in `x`.
Nice improvements from the previous version, I am particularly interested in the polymorphic_allocator and memory resource usage ( covered on mr_basic.cu sample) . 
simple_thread_pool duration = 2.058 s thread_pool duration = 1.171 s xxx::MysteryPool duration = 0.139 s There is still room for another order of magnitude improvement. The mystery_pool is hindered by the std::function overhead but trading convenience for performance. With custom job class it can be still ~4x more speed. Your bottleneck is the queue and exclusive serialized access to it.
"All the stuff I say" is that recomposing unsigned 8-bit characters into unsigned 32-bit integers is easy; there is nothing controversial about that and all operations involved are well-defined. It _is_ non-trivial to deserialize signed integers before C++20 due to the implementation-defined conversion from unsigned to signed, and likewise if your `char` is signed you'll have similar problems in the opposite direction. But that has nothing to do with endianness, and I specifically didn't mention signed types because that's tangential to the byte order fallacy.
I realize you might not be the right person to ask, but do you have any insight in when CUDA will offer support for the RT cores? Optix can already make use of them, alongside DirectX and Vulkan, so why not CUDA itself?
It's certainly one of my main source of recent c++ knowledge :)
There's a reason C++ doesn't have an "interface" keyword. Interfaces are OOP abuse.
I can't comment on that, sorry :).
No C++17 support yet.
Alright, thank you anyway!
Yes, I originally considered this as well, but as mentioned in the article, I wanted to keep the header humanly readable with [each value documented](https://github.com/mosra/magnum/blob/169031fb7bf30e2c98c81cbf865aa5a4662aa716/src/Magnum/PixelFormat.h#L64). This magic is far from humanly readable :)
I feel their pain. I really do. But I cant shake the feeling that their complains are in the lines of "The C++ Committee can not give me what no one else can give me and it's their fault! I'll implement it myself"
Why is that? Surely it’s expected due to the existence of pure virtual functions.
The misuse of coroutines to implement the TRY operation is an abomination. I will not support it. Nor would Boost permit such an abomination to enter Boost, and rightly so. https://wg21.link/P1095 proposes extending `operator try`. I would be surprised if a proper language extension does not make C++ 23. If the committee chooses the design in P1095, it would automagically support all `ValueOrError` concept matching types such as Outcome or Expected by default with no extra work.
C++ allows non 8-bit bytes and we are stuck with it. I'm not sure how Networking TS handles this but I'm sure those 16 bit and 32 bit DSPs would want at least some local IO.
Of course it is trivial to convert unsigned 32 bit integer on a 8 bit machine. Nobody disagrees with that. The problem is converting signed numbers and that's why people didn't bother with signed-to-unsigned conversion and used byte swap instead. &amp;#x200B; I didn't look deep into the source code of Boost.Serialization but Cereal uses the same byte swap algorithm for all POD types including floats.
Completely agree with the view of Modules. The fact is, the next two ISO meetings should guarantee that Modules is implemented in such a way so it can be evolved.
Thank you for answering. I was not aware that (mis)using co-routines this way was considered bad.
Awesome! I didn't know that coroutines work with clang-cl.
&gt; I am labouring under the assumption that (even) today memory block is contiguous for 1D arrays but not necessarily so for 2D arrays. I don't know what you plan to do, but the word matrix, with me, immediately pulls up two other words: blas/lapack, so, there can only be 1 answer, IMHO.
Correct me if I am wrong bu there is no mentioning of \`std::error\` , \`throws\` or anything else as described in [P0709R2](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0709r2.pdf)?
std::error is the, I think badly needed, "core language enhancement" .. I do not see it even mentioned.
All the pics in this report are very gorgeous :)
Byte-swapping signed integers is just as much shooting yourself in the foot as unsigned-to-signed conversion is, as far as the standard is concerned (except you now also have the problem of detecting host endianness). Byte-swapping in serialization code is a cargo cult, and there's not much else to it.
Can I use all C++17 with CUDA 10.1 and GCC 8?
Of course, that is my point. Nobody does it right because it is so hard to do right.
I really want modules in the next c++ standard. I also really want them to work. Personally I'd prefer to delay c++20 to c++21 and make sure we have at least two implementations that implement the current wording before it gets approved. Of course, once you start down the road of delaying the release date we might run tinto the same problem as c++0x.
&gt;Value-Construct 100 Integer? Leave that all uninitialized? Maybe? If it's alright for std::map to default-initialize one element, why wouldn't it be for std::vector to do the same with multiple? But obviously I'm arguing *against* the implicit construction. &gt; And the way it works now is just so convenient. Just think about the classic example of counting characters without this feature: Except the problem is not with the behavior of the function itself, it's with the naming. You could very well have a `get_or_create()` to be more explicit and allow your usecase, and then have another `[]` do an unchecked access.
As a long-time daily user of multiple different matrix implementations over the years I am baffled - how exactly is this "simple" when compared to anything else? 
Hasn't the problem of the optimizable stack frame of the coroutine been solved by lambda that implicitly capture by reference? Or is this exactly why lambda that captures by reference can easily cause code bloat?
Okay, why is [P1382](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1382r0.pdf) considered a better alternative over `volatile` keyword? As someone who has used `volatile` for the intended purpose and I just don't see how deprecating `volatile` helps embedded developers who actually need it.
I thought volatile only property was to make store and loads considered to have side effects. I'm I wrong? If not, why volatile cannot be replaced by that?
I think the idea of volatile variables is just weird. What is volatile is the reading/writing of variables. These proposal work towards reflecting that. It's also much easier to reason about, optimize and specify.
Sure, but we still have years and years of implementation experience both at Microsoft and Google
You miss the point. They do not provide custom runtime. &amp;#x200B; Subset of C# is compiled to machine code. What they wanted is to have control over how code is compiled, so for example loops are always vectorized, memory is always perfectly aligned etc. 
You are right that storage for multidimensional arrays is best flattened into a 1D array so that all elements are part of the same contiguous span. On the use of lambdas, I don't see how they help here - classes are more flexible. For instance, the lambda has only one interface; its function-call operator - the matrix indexing operation in this case. This forces use of a visitor-like pattern for matrix operations. The lambda does not provide its dimensions to visitors, so a visitor such as for\_each\_cell has to provide the matrix dimensions as arguments. It ain't easy to design nice and efficient matrix classes. See for example Stroustrup TC++PL 4ed Chapter 29; A Matrix Design. See also the mdspan proposal [P0009](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0009r9.html) \- the ongoing effort to standardize a multidimensional array reference type. It is kinda cool that lambda capture can copy arrays by value into the closure. That might be helpful as temporary storage. You'd still want a matrix\_span type that refers to the storage to provide the matrix operations.
I see your point, but here's where I see a problem. Let's say you have a sensor that is attached to a pin and whenever it detects something an ISR is triggered, and if `REGISTER_FOO &amp; SENSOR_MAS == 1` a `volatile` variable is set to `1`. The same happens when it stops reporting that something is there - ISR is triggered and the same variable is set to `0`. In this case a 100% of your reads, in terms of P1382, will be `volatile_read`s. It's much easier to forget to type `volatile_read&lt;int&gt;(sensor_value)` than it is to just declare `volatile int sensor_value;`. Especially if we take into account the way of thinking at the point where one declares the `sensor_value` compared to the way of thinking when one just uses it. When declaring `sensor_value`, my way of thinking is: - First write the ISR - Set up the registers to enable the appropriate IRQ to call the ISR - Oh right, I'm dealing with interrupts, I need this thing to be `volatile`. When writing something that needs to read that value: - `if (sensor_value)` - Followed by a potentially long code that reacts to the detected object. - The idea that `sensor_value` is/should be `volatile`/`volatile_read` never crosses my mind. Also, requiring to write `volatile_read` whenever reading a sensor can potentially introduce a lot of noise, compared to `volatile int sensor_value;`.
Neither of which implement modules as specified in the standard. 
Really? In my experience tooling got a lot better over the years. CMake is no longer that horrible to work with and especially the whole clang-tooling is just wonderful to work with.
I have only skimmed both proposals and have almost no experience writing c++ beyond fizzbuzz type excercises, so am could verry well be missing something obvious... Couldn't some abstraction, say `volatile_value&lt;T&gt;`, that uses `volatile_read` and `volatile_store` for all loads and stores be created. (And maybe be combined with the proposed `constinit`.)
You can overload based on volatile qualifier, but this removes this possiblity. What's the alternative now?
Now, since the coroutines are in C++20, can someone point me to quality study materials? I've found [this on r/corouines](https://www.reddit.com/r/coroutines/comments/7y2fid/c_coroutine_resources/). AFAIK msvc and clang have (incompatible with each other) coroutines support, so I can play with it. Is the current accepted paper changing anything regarding to currently implemented behavior in these compilers? [u/GorNishanov](https://www.reddit.com/u/GorNishanov) can you please add some insight? :)
&gt; It's much easier to forget to type volatile_read&lt;int&gt;(sensor_value) than it is to just declare volatile int sensor_value; well, that's template 101 isn't it ? https://gcc.godbolt.org/z/a4TKfM 
Hmm... `operator=(T new_value) { this.old_value = volatile_store(new_value); }` for writing and `T operator T() { return volatile_read(this.old_value); }` for reading would achieve that. That would make it possible to write `volatile_value&lt;int&gt; sensor_value;` which doesn't seem so bad. In case of read only or even write only `volatile` variables, only one of these two operator overloads could be defined.
I would much prefer the power of pattern matching. But would this assume that we get our c++ reflection features accepted into the standard?
You are missing the point. They are addressing a weakness in their commercial product to have a better position against their main competitor. 
I'd say the generalization is rather straightforward: template&lt;typename InIt, typename InEnd, typename F, typename... OutIt&gt; void (InIt first, InEnd last, F fun, OutIt... outputs); where `F` takes the value-type of `InIt` and returns an integer between 0 and `sizeof...(OutIt)-1`. Implementing that is a little bit harder but also doable. Just use a `std::index_sequence` to call the following with all possible indices and you are pretty much done: template&lt;unsigned I, typename ValueType, typename... OutIt&gt; void output(unsigned i, const ValueType&amp; value, std::tuple&lt;OutIt...&gt;&amp; outputs) { if (i == I) { auto&amp; it = std::get&lt;I&gt;(outputs); *it = value; ++it; } }
The author's lack of humility is unbelievable. Instead accepting the fact he is abusing a non-standard extension and therefore failing to obtain the desired result, he just assumes the compiler is "introducing a vulnerability".
The author's lack of humility is unbelievable. Instead accepting the fact he is abusing a non-standard extension, and therefore failing to obtain the desired result, he just assumes the compiler is "introducing a vulnerability". Is far more probable this is a corner case where the combination of language features and compiler extensions is not supported and compilation must fail. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/aw6plv/udp_and_video_streaming_server_can_anyone_help_me/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It was honestly a typo. The second instance of runtime was supposed to be *toolchain as per my first comment but nothing you said in your paragraph is different from what the article states (arguments I don’t buy). Feel free to agree to disagree 
For future historians: He is being sarcastic.
"Deprecating volatile" is clickbait title. It does not propose to deprecate volatile variables at all. It propose to deprecate wrongly allowed uses of `volatile` qualifier that make little sense. For example volatile value parameters for the functions make no sense to me: int vtest(volatile int i) { return i + 5; } On the other hand references and pointers to volatile data is fine.
Which means there could be a bug hiding, but there's isn't really any doubt about fundamental implementability.
I can't speak for the committee, but when people mentioned the technique at Rapperswil during lunch, groans were universal around the table. C++ is full of stuff that is possible, but not wise. `co_await` communicates a meaning which if it does not fulfil, that is surprise. Surprise is bad for long term code maintenance. Code should do what established norms says it ought to do. It's similar to recent proposals that `co_await` could do synchronous i/o i.e. it suspends nothing, and actually blocks the kernel thread. I find that too to be an abomination. `co_await` communicates the meaning "go do something else useful until this lengthy operation completes".
The problem is subtle, and I only understand in the overview, but essentially in order for one to be able to create an optimized frame that can both: be managed explicitly by the user (like a lambda) and be optimized by the compiler (embedding frames, minimizing size), you need the front end of the compiler (that knows about C++) to have a communication channel with the back end (that knows about the machine), and there is no compiler which has such a channel. Building such a channel was described by compiler writers as expensive and in research territory. One common argument was "who cares if the frame takes a bit more than necessary, it's better to have deterministic control of where the memory is than if it's strictly minimal". The problem is (apparently) there is no upper bound on frame size -- even a whole 4k page per frame isn't guaranteed to always work. There's also ABI issues in the same vein as lambdas -- one might try constraining where you could portably use Coroutines across ABI, but it's apparently trickier than lambdas. The bottom line was: although we all want such a unicorn as "deferred layout types" so we can have our cake and eat it, we had a choice between a good, proven solution that meets 80% of the most important use cases, for which several avenues of evolution still are available; and shooting for the stars, spending 6 years without *any* Coroutines, with no guarantee of being any further ahead. I think it was the right choice.
That's not the point, what I mean is that they have the experience to determine what can be standardised
Right. That is not a proposal for C++20. Herb has deferred discussion of it until after C++20.
Unfortunately, no.
Thank you for this detailed answer. I find the concept of front-end back-end communication really interesting.
I know what "Deprecating volatile" was about. However, P1382 and /u/c0r3ntin's trip report speak of different plans - complete removal of `volatile`.
If you're talking about volatile-qualifed member functions, what even is the use case of that?
Indeed I have little doubt that future historians will be reading my Reddit posts.
With regard to modules, I feel strongly that we need to get gcc/clang/msvc all implementing it and field tested before we standardize. Otherwise, as they say, the first "import" turns me into a test subject. But for such a fundamental change to the tooling and language we need to get this correct and know how it will break things.
Telling your intentions to the compiler is not ceremony and making assumptions is not being succinct.
How exactly is this shitty? "X does not solve our problem so we decided to make our own using Y" seems like a pretty reasonable thing for an engineering team to say....
We allow the c++ compiler to make all kinds of assumptions, and utilize them as part of our workflow regularly. Default constructors and operators, implicit conversions on single arg ctors, etc. And there are very few assumptions given that in Java you use the interface keyword, and you don't get any default behavior. 
That's pretty significant indeed. I am looking forward to the results of the benchmarks you are gathering here to get a better understanding of each map's sweet spot.
There is some work on `task` and `generator` types.
Based on the titles, a lot of them look like they are struggling: 7.3 Bay area (llvm) - [LLVM's monthly social gathering.](https://www.meetup.com/LLVM-Bay-Area-Social/events/256839346/) * 11.3 Paris - [C++ FRUG #33 - 3/2019 - The three threes session](https://www.meetup.com/User-Group-Cpp-Francophone/events/259291569/) * 11.3 Hannover - [2. Treffen](https://www.meetup.com/C-User-Group-Hannover/events/258848545/) * 13.3 Utah - [Monthly Meeting](https://www.meetup.com/Utah-Cpp-Programmers/events/259085935/) * 13.3 Karlsruhe - [(Functional) Rust (Vortrag von Oliver Scherer)](https://www.meetup.com/C-User-Group-Karlsruhe/events/256872567/) * 14.3 C++ Italy - [Meetup Marzo / Modena - Git-Powered Docs](https://www.italiancpp.org/event/meetup-marzo2019/) * 18.3 Austin - [Monthly C/C++ Pub Social](https://www.meetup.com/The-Austin-C-C-Meetup-Group/events/qdpklpyzfbx) * 19.3 El Dorado Hills - [March Meetup](https://www.meetup.com/edh-cpp/events/257906199/) * 19.3 Portland - [Monthly Meetup](https://www.meetup.com/pdxcpp/events/258162121/) * 22.3 Cluj - [3rd Meetup](https://www.meetup.com/Cluj-Modern-C-Plus-Plus/events/258922279/) * 25.3 Bremen - [C++ User Group](https://www.meetup.com/CPP-User-Group-Meeting-in-Bremen/events/259062) * 27.3 Munich (Qt) - [Let's meetup and talk about Qt / QML](https://www.meetup.com/Qt-Munich-Meetup/events/259358797/) * 27.3 Hamburg - [Noch nicht bekannt](https://www.meetup.com/CppUserGroupHamburg/events/257854645/) * 28.3 Moscow - [C++ Drink Up ](https://www.meetup.com/Moscow-C-User-Groups/events/259371795/) &amp;#x200B; I'm interested in starting a group in the St. Paul, Minnesota area. I think meeting on a quarterly basis would be a good way to start and would help avoid titles like the above. &amp;#x200B;
Thats fine, its often just the default title, as meetup allows recurrent events. More details usually follow during the month. Of course some groups might also are struggling to keep up with meetings. With a meeting on the 1st, I have to post today, so not much time to update there.
I really like the end of the presentation, where he puts some examples on how to use type safety for low level programming. Unfortunately, the slides in the video de-synchronize with the speaker and lag behind :(
I now realize I may be lagging behind quite a bit, having not following all the coroutines development over the last year or so... ... can I infer from this talk about stack frames that the coroutine proposal that is standardized is about *stackful coroutines* where one can suspend a coroutine deep into its callstack?
Oh, didn't notice that there is a difference in the slide stream with the speaker. Thanks for reporting!
What's the status of [Filling holes in Class Template Argument Deduction](http://wg21.link/P1021)?
Buckaroo sounds most similar to bake from your description. In my initial posts I should have made a clearer distinction between package managers used to install system packages (things that end up in your \`/usr/local/bin\` or equivalent) and "build system that do package management", where the build system has features to automatically find/clone/build dependencies. Bake falls in the latter category. You can automatically install bake packages by providing it with a git URL. It does not have its own package repository like vcpkg, conan or npm. Instead the package manager is used as a development tool to make building projects that have many dependencies easier. Bake doesn't install any packages to system paths. Instead, everything is stored in \`$HOME/bake\` (by default). That way, you don't need admin privileges if you want to download additional packages. Bake assumes you have full control over which packages you install in your \`$HOME/bake. It is therefore not a good tool for deployment, as it doesn't attempt to match versions of different packages. It assumes the developer installs the versions of dependencies against he/she wants to develop, and then distributes their work through other means. Bake may support limited versioning in the future, to make it easier to share code between devs, but it doesn't aim to replace package managers like vcpkg or conan. The future goal for bake is that you, as a dev, can say: hey, execute this bake command to run my application: bake run --url https://github.com/SanderMertens/example --cfg release --version 1.2 but that's about as far as I want to take it.
No, Coroutines TS is "stackless", which doesn't mean it doesn't have a call frame -- it needs to put the variables that need to survive a resumption somewhere, it means it can't do that arbitrarily deep like a stack can.
I highly recommend defining acronyms at first use. I had to search to find out CTRE means "Compile Time Regular Expressions", and was hindered by the the fact that it's a stock symbol, a misspelling of center, and a robotics library.
Wasn't there some kind of ... kinda trick mentioned in the "Templates" book that requires at least mentioning a const volatile constructor?
&gt;exceptions, typically to deal with unrecoverable error conditions. &amp;#x200B; That is certainly not true. Most serious code this days does not have "unrecoverable error conditions". Unfortunately that is a show-stopper for mine ( and most C++ code bases that I am familiar with ) &gt; WebAssembly itself does not provide support for exceptions. &amp;#x200B; Btw. our exceptions are managed completely fine is WASM ( complied via Emscipten), so not entirely sure what you are saying. &amp;#x200B; &amp;#x200B; &amp;#x200B;
Class wrappers around memory - mapped primitives.
Considering that the last fix was invented only just during the last meeting despite several years of implementation experience makes me doubt that that is the case.
Can't you just declare the instance of the class volatile?
Yes and they are confident that it's doable. If minor tweaks are required, well then what's the problem? Tons of minor stuff gets tweaked and fixed in the standard when it's discovered all the time
&gt; It's also much easier to reason about, optimize and specify. I agree that we should have a more fine-tuned way to specifying the same semantics. However, I don't see how you can claim `volatile` is hard to reason about or optimize. Its beauty is that it is very easy to understand and use for users, specially embedded/hardware developers. Way easier than anything that will let you "optimize"!
https://old.reddit.com/r/cpp_questions/comments/a7emow/how_to_copy_assign_volatile_data_with_stdarray/ Passing `volatile Foo` to `operator=(const Foo&amp; rhs)` results in a compile time error, because there's no conversion from `volatile`-qualified to non-`volatile`-qualified `Foo`.
Why in examples used "if constexpr" instead of "@meta if"?
You won't be able to call non-volatile member functions for the same reason you cannot call non-const member functions on const objects.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/awa6wh/c_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Did anyone else think Kona was some type of drug based on the title?
For those who want a working example, you can find one [here](https://gist.github.com/Florianjw/33d10b3a7822050b2e55db332ff66cbf).
&gt; the programmer can forget at the end of the if to write &gt; 3 and only catch the big much later Sooo... `bool` is a trap too because you can write `if (very long expression that returns bool == false)` and if you forget the `== false` you might only catch it much later?
Hi, I'm one of the organizers of the Portland C++ User's Group (PDXCPP). I feel like we're doing pretty well! We aren't a large group but we have a great core of members who have been regularly attending for years now. :-) I hope you'll be able to make it sometime!
Thanks, I've been to Portland a few times. I'm willing to give a talk about my free [code generator](https://github.com/Ebenezer-group/onwards) if there's interest. I'll pay for my travel expenses. 
I'm in Minneapolis and would attend!
Why are you learning c++ ? 
No mention about executor/networking - a major expected feature that slipped. Personally I would prefer it over module, but on the other hand major companies already have their own network stacks so they may not keen on pushing this which is understandable. Still, it would be good to read about the development on post-con mailing.
Go
This seems like a much better solution. I'd love to play with things like #pragma language_feature(explicit_enum_cast) to require explicit conversion from C enums to numeric types. I suppose at that point, it's not that different from having a linter which warns on certain language features.
Read "Efficient Modern C++". Look at Boost libraries documentation. Don't give up until SFINAE is a second nature to you 😉. For projects, do something you are excited about. I love make games, so I like to pull SFML, a cold beer, and write myself a clone of... Pong. (I didn't say I was good at that 😋). If you want to look at other languages, Rust will teach you a lot of things you can directly transfer to C++. It enforces a lot of good practice with an iron hand.
Start working on some projects. Some people only work on open source projects. I think that's a mistake. Work on some closed source stuff also. I have [a project](https://github.com/Ebenezer-group/onwards) that's a mixture of closed and open source code.
Maybe just having a std::volatile type similar to std::atomic would help.
Volatile means the value can change outside of the translation unit's scope, from what I understand as a more technical and precise definition. 
This is good stuff. And unlike others that advertise libraries here, you actually have looked into and acknowledged prior art. This makes the library more appealing to me and I'm glad to have looked into this.
Thanks :) c++ coroutine became available since 5.0, and works well with debug build. However, its optimizer sometimes removes statement with \`co\_yield\` or \`co\_await\` since 7.0 For now, clang-6.0 is more stable for the feature.
cppcoro is already rich and I usually recommend them. The only point I'm worrying is that cppcoro became a heavy one for beginners :(
If 95% of the time they'd be doing `return false`, chances are 1. they would do it wrong (fail to return false when they should; I would expect e.g. an exception to escape instead) 2. this is used to signal "hm, I failed", in which case they either eat quite likely useful error information (which is a *massive* no-no) or they need to do *even more work* to report the error, possibly through a side-channel they invent each in their own, slightly different and incompatible manner.
Can't the wrapper simply wrap a volatile variable instead?
Networking was not discussed in Kona, the reasoning being that LWG (or was it LEWG? I forgot which) doesn't have the bandwidth to get through it in time for C++20. With that in mind it makes sense to make time for other topics instead, and then tackle it for C++23.
Thanks, the world makes sense again :) I was confused by the wording "call frame"/"stack", I've never seen a generator's member being referred with such words.
return std::nullopt; is alot less ugly than return {}; to me 
Find some katas online, and try to solve them using Test Driven Development (TDD). Start here, maybe? [http://codekata.com/](http://codekata.com/) 
Which embedded compilers / RTOS support modern C++. I know green hills OS support c++11. Any out there that using &gt; c++11 ? 
Updated version, now the slides don't go out of sync at 57:ish.
Ugh no. We're not going to optimize for characters. Be explicit and expressive. 
Finance industry is far more performance driven than the gaming industry
But can throw more hardware at the problem.
That's false. You're up against every other trading firm. They also have really great hw. It doesn't change anything about the pressure to write high performance software. It just means your target hw is updated more frequently
BLAS/LAPACK/EIGEN ..You might be hotly against it , but in all of my 25+ years of C++ I am thinking they might be a overkill in more than 3/4 of programs. IMHO
int m\[3\]\[3\] &amp;#x200B; There is nothing simpler than that. But ... would you let your team use this? I have seen grown ups coding: &amp;#x200B; long matrix\[0xFFFF\]\[0xFFFF\] ; &amp;#x200B; And then asking for bigger machines ... they are mu target audience :)
Agree. I would not use them "naked" as in this core proposal. I would use them as matrix storage in the privates of the matrix class. I can also make them into template parameters to easily switch between stack or heap.
Ah and btw this is where lambdas indeed are not simple to use ... they are actually called "closures" if I am not mistaken and for a reason. If I need to keep the state and in this scenario, I think, simple functors might be a lot simpler/better tool.
I would not put blas/lapack together in the same category as eigen (sure it's good, but different). Why would you forgo code that has been tested and optimized for decades for very well defined tasks? Iff you're multiplying 2 matrices, f.e. I'd rather do it the proper way. Intel MKL is free to download and use and gives you all those goodies (and much more), AMD has an equivalent lib.
Okay, I admit defeat, you’re right.
VxWorks 7 supports C++14. I use it for RTOS embedded work.
I really appreciate your effort to make new c++ features work better together as well as your work at the committee meetings. Your blog posts are very insightful. Always pleasure to read!
Recent IAR ARM versions support c++14. Also use it for embedded work.
Is there a reason why that's the case? It really limits what you can do with `volatile` objects and STL.
In all fairness, game devs are among the rare few for whom placement new is frequently needed, and make\_unique isn't an option... ... of course, a properly designed replacement for the standard heap new/delete would be a much better answer, but they're often working in engines that don't have that.
It seems the size is 2.9GB for W10, but ok thanks, I shall look into MKL. 
This video overview from 2017 might help you: https://www.youtube.com/watch?v=9WHRfU7U9lk
[removed]
cppreference.com
Please don't use URL shorteners - they trigger reddit's spam filter. I've manually approved your comment.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/awjmq5/getting_into_c/ehn2q4b/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/awg25t/unit_testing_with_boost/ehn46b7/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I think that we could argue that dumping support for non-8 bit bytes as something in the vastly overwhelming common good and be done with it. At some point you have to be cruel to be kind, and that would be one of those cases. The needs of the vast majority can sometimes outweigh the needs of the tiny minority. 
I'd say it's pretty important to understand char\* before learning about std::string, imo std::string to new beginners is like magic under the hood. What they need to understand is that strings are literally char\* but as a class that has member functions to do specific things, some necessary, some not. Without understanding this, they lose the need-to-know on critical things. &amp;#x200B; using [https://akrzemi1.wordpress.com/2014/03/20/strings-length/](https://akrzemi1.wordpress.com/2014/03/20/strings-length/) as reference. &amp;#x200B; Know your roots. It's important. It's BS because what are the chances? Sure enough I went along for ages without needing all these myself. I won't deny that it's more knowledge than you need for a small to medium project. But what's legal code isn't always good code. People who wrote the damn std library sure as hell needed to know char\* to create std::string. There's a reason for that.
It's not "considered bad" - Niall just doesn't like it. Using coroutines for this use-case (optional/expected unwrapping and things like parsers) is a perfectly reasonable use of coroutines. The problems are that the specific choice of keyword `co_await` prejudices the asynchronous use-case and that you can't guarantee no heap allocation (these were two of the concerns brought up in [P0973](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0973r0.pdf)). It remains to be seen how reliable the heap allocation elision optimization will be for using coroutines in this context. Given that the coroutine _never_ outlives the caller in this scenario, I'd like to think there's a chance - but that all remains to be seen. 
The approach I've taken in my system is that there are binary streams, and then there are text streams built on top of those. Binary streams have an endianness that you can set. There is also a system wide indicator of local system endianness. If the binary stream is not the same as the local, it byte swaps. The binary streams have stream operators for all the fundamental types, and everything ultimately comes down to streaming those fundamental types (or a raw binary buffer which is still legit for storing blobs of defined content, PNG file or whatnot.) String objects read/write themselves on binary streams as blobs of UTF-8 encoded text. The odd man out is floating point values. The streams call a per-platform handler for those, and defines Intel IEEE as the on the wire format to be translated back and forth between. My object request broker uses binary streams to flatten/resurrect objects and always sets those streams to little endian, as a canonical format. So data gets swapped out and back in as required, relative to local system endianness. It's simple but it provides an effective means to transport objects across platforms. Text streams can be built in terms of an underlying binary stream, but in that case it's just using the binary stream as a way to read in chunks of bytes from some source to decode (or encode and write.) Each text stream is given a text converter that will convert between some encoding and the local native character format, so the streams themselves don't have to be the be-all/end-all of text transcoding, they are easily extensible via pluggable text converters. It does of course require some per-platform support. In my case that's a fundamental part of the system, in the form of a 'virtual kernel' that everything is written in terms of. Ultimately, the lack of something similar has hamstrung C++ forever. It's always the way it goes when you have 'standards' based stuff vs. 'products' based stuff. The product based stuff always ends up being more 'standard' in a way. I.e. most every practical C++ program becomes a hodge-podge of non-standard bits and bobs, whereas a language like C# provides the sorts of functionality that allow the bulk of applications can be written within the official product, and any C# programmer will be familiar with those tools. In my opinion, its these issues that should have taken up the time of the C++ folks all these years, not creating the ultimate container abstraction. When you can't really write even fairly modest practical, commercial programs within the standard, that's an issue. OK, go ahead and down-vote me into oblivion.
GCC and scmRTOS works for me.
&gt;I'm gonna stop working alone since today, and willing to contribute some open works with the feature. I hope it works out for you. My main project is a mix of closed and open source. When the economy falls, you may be glad to have diverse investments.
I realize this was posted 5 months ago, but I just want to say I really hope part of that was a Sonic Adventure 2 reference. 
Is the remote option USA only, or do you allow Europe as well?
This! Pure virtual functions, and abstract base classes, are used for run time polymorphism. Many responses here mention templates or concepts, which are compile time. This talk shows how to use type erasure to implement run time duck typing in C++. Type erasure requires more work to set up the interface, but once done, none of the types that implement the interface need to repeat any boilerplate or refer to the interface at all.
I've never used autoconfig or other build systems but, if the compile step fails because you don't have the required dependencies it's either your fault or the developer that didn't say what to install before. 
try to copy a std::function inside a DKM.. it goes boom ;) should be fixed in SR610, luckily 
I dont know why you have had such a poor experience with cmake, but if I see a cmake build system in a project the first thing I think is "sweet, this should be easy to get building."
I have had bad experience with using Cmake for my exercism c++ programs on both ubuntu and windows. Couldn't get it to work. 
I tried for two months to set up Cmake to create some test cases and a minimal "installation script" for a C++ header-only library. Eff it after far too long, I decided to try a Makefile, it was ready in 15 minutes. At most I can guess that CMake is popular because it has better stuff to register and detect dependencies; whether the authors use it or not tho it's another problem altogether.
CMake coupled with small shell scripts is the best build system C++ has these days (although Meson isn't too bad). Platform independent for the most part, and pieces of your build that are platform dependent can just be ifdef'd away. &amp;#x200B; It seems that you're just missing a dependency. Try `which llvm-config` and see if the dir that binary exists in (if at all) has all of it's dependencies. &amp;#x200B;
I too had a similar experience with cmake trying to install trilinos on windows, gave up after a couple of days of trying. It felt like I was having to guess my way around too much, maybe its.easier on linux?
Before cmake, writing your own makefiles was hard and tedious. It wasn't easy to learn how to do it properly. That's why now we have cmake to do it for us. I guess your problem comes from the fact that many people don't know how to write CMakeLists.txt properly. They just assume everyone have installed exactly the same things they have. So, people who knows how to do it, can do it much easier and faster and people who don't know how to do it wouldn't know to to write regular makefile in the first place. It would seem that you are downloading software from developers that aren't very good at their job. 
Roughly speaking, that the compiler should not generate code that caches reads nor that coalesces writes.
&gt; outside of the translation unit's scope Outside of control flow. How? Hardware interrupts.
This sounds like the opposite of reality.
AddLLVM is provided by the LLVM dev package, did you install it ? e.g. libllvm-dev for instance
The member function modifier dictates the modifier of `this`, so it loses qualifiers.
cmake. you can use it elegantly, or abuse and blow it up :) just like there are programs written for people, with the user in mind, and then, there are other programs that are awful. this sums up what I usually see in my environment.
You can start by providing a snippet of code that allows others to reproduce the error. But generally speaking CMake just works. It has horrible documentation and syntax, but it's easy to incorporate other libraries supporting it into your project.
Regarding deprecating comma in subscript expressions, code using boost.proto likely to have them. My project does. I'm not necessarily opposed to the paper but the section on existing use is not very convincing.
CMake is poor on Ubuntu, I give you that. Once I hit a library that was registered in the CMake database on Ubuntu but was not installed actually... It took me a while to figure out the problem. Probably for endusers autoconf is good, because all the dependencies are likely in the system paths anyway. As a developer I need more flexibility like switching the dependency libraries etc., and I prefer CMake because it has standard ways to do those things. On Macs and Arch I didn't hit the nastiness like in Ubuntu (seriously, I hate how Ubuntu is configured...). 
For a variety of specific reasons, I and my team maintain a large collection of software, mostly open source, but with in-house products mixed in, all built from sources. By large collection i mean large. Maybe 1/4 the size of a linux distribution. So, I get to spend a lot of "quality time" in company of build systems. I routinely maintain projects based on the autotools, on cmake and on bazel. Incidentally, our distribution also includes autoconf, automake, libtool, cmake and bazel *themselves,* that we build from sources and make available to the rest of the company. My conclusions are the following: 1) I hate them all equally, for a variety of specific reasons 2) I have given up on humanity and the hope that it can achieve a configuration/build system that (a) does the right thing, (b) is portable, (c) is flexible and (d) just works. Goals (a),(b),(c),(d) are, in short, too hard to satisfy at the same time. If (c) includes manually curated versioning of products so that you guarantee version compatibility among products, there is no solution except paying someone sort of full-time to get the job done, and the job includes a lot of ugliness. cmake is not any uglier than older or younger alternatives.
Why the hell do you need an "installation script" for a header-only lib? And why would you write that in CMake or Make? Use the right tool for the right job, which is just a bash one-liner. ps.: Header only libs are just static libs in disguise. Cheers.
It seems like this is a case of getting a solution to a software problem by insulting the problematic piece of software on a public forum
Header only libraries should be properly installed and be found via find_package just like any other library.
I take it you're never actually written any automake then
If this group is interested in hearing about my free [code generator](https://github.com/Ebenezer-group/onwards), I'm willing to pay my expenses to travel there. I was born in America, but am half Swedish, so this would give me another reason to visit Sweden.
Cmake is amazing and revolutionised c++ for me. Autotools is a hemorrhoid in the C++ ecosystem.
I think it's more of a misdiagnosis. The issue isn't cmake vs. autotools, it's library fragmentation and that there's no maven equivalent. I guess people are trying with stuff like Conan. It's now a huge hassle to build almost anything. There are a dozen disparate dependencies, any one of which could have a platform specific bug. People used to target a more common set of dependencies. If I have to build an opensource thing from scratch, I apt/yum install maybe three or four things to shut up dependency errors. If it still doesn't work I give up pretty quickly these days.
Rant to the title: Simply because there is no better option. There isn't another (meta-)build system which supports that many OSs/compilers despite the painful dependency management. Automated dependency managers such as conan.io attempted to make things easier in the last few years, but simply failed to become the new standard due to not offering an equivalent feature set. CMake is a battle-tested build system AND a crappy manual dependency management system. We, in 2019, are waiting for the next crazy guys to automate all this stuff and build a C++ project on any OS with all dependencies through a button press.
GNU Make is really not hard and is super flexible for all sorts of tasks beyond compiling and linking. If you know you have exactly one or two target platforms and one dev environment, I see no reason to even bother with CMake or Autotools. The point of the complicated meta-build systems is mostly to target a bunch of different configurations on a bunch of slightly different platforms. Most people never need to do this. It really mostly comes up with open source. With virtual machines being so easy now, I'm inclined to generally prefer plain makefiles in most closed source business contexts. How to build my thingy: Here's a base Fedora vm image, run this shell script to install deps and configure, run make. 
what advantages does this offer over QtCreator?
As long as I can do \`static\_assert(CHAR\_BIT ==8, ...)\`, I don't think there's much harm in the code that explicitly chooses 8 bit bytes.
If you look carefully, this is pretty much exactly what I propose. There are small differences though. For example, I allow non-IEEE floats but there is an option to force IEEE. There is also support for UTF-16 and UTF-32 with optional BOM handling. &amp;#x200B; Hopefully, this proposal will remove the need for that dreaded "per platform" code outside of standard library so you can just say "my data is in little endian with IEEE floats" and get what you expect.
Indeed.. it also happens to be a well known and effective method of getting that solution.
TI cgt supports C++14 as well.
I wish all the everything-must-be-a-web-app people could understand that their ideas don't apply to the embedded world. Resources aren't cheap outside of consumer x86 PCs, and they are being told by their teachers otherwise.
Use Meson.
Why not start with CMake and/or Meson. If you have to eventually port your software you will have to redo your Makefiles. If you want IDE support, release/debug builds? Coherence among targets from projects (like coverage/debug/release). Also, Makefiles are quite more difficult to read in my experience unless they are very basic.
What is the advantage of GNU Make?
I suspect the figures are highly inflated (as compared to real dis-use) because of the way Windows Explorer handles sizes of junctions and symbolic links [badly (for this purpose), as it double counts] and the generous use of them in the MKL installation, in other words it's not as bad as it looks. There's an on-line installer, where you can select the components you need, maybe you don't need (a) PGI(-interface), Fortran and/or ia32 code and limit both the download-size and disk-usage.
&gt; Why not start with CMake 1) It is an added moving target with its own bugs. GNU Make is rock stable, battle tested, and cross platform. 2) Make is useful for all kinds of things people pretend you need a complex separate system for. A "test suite" can be a dozen lines. No need for a convoluted framework that will inevitably break.
Its such a disaster to maintain automake compared to cmake...
Not to contradict your post, but I love cmake and can't live without it. It has a bit of a learning curve, but works very well once you become familiar with it.
Seems like homework questions would be a better fit for /r/cpp_questions/.
Definitely it's not a homework question. It's what i'm interested in. If it was a homework i was taught what to do and where to go through.
&gt; boost.proto I'd be willing to look into that, can you show some sample code?
&gt; The issue isn't cmake vs. autotools Judging by the tone of the post, I'd say the issue is, as is often the case, between the chair and the keyboard.
I don't know the exact technology behind VPNs but I have written a simple proxy server before. If all you need for communication are TCP/UDP connections, Boost ASIO library is a good cross platform library for connecting and sending data over TCP/UDP and it also supports SSL/TLS and blocking as well as non-blocking IO. The native way of connecting on linux is using `socket()`.
Maybe review some of the available open source VPNs to get a better idea
Be aware that unlike pretty much every other system, Windows doesn't have built in tun/tap driver. Writing your own is non-trivial, to say the least. And then you'd have to convince Microsoft to sign it. Most just don't bother and reuse TAP-Windows from OpenVPN.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/aws9uo/what_is_the_roadmap_to_write_a_vpn_from_scratch/ehouyzd/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Very interesting. Will all of that be part of c++20?
But you could stick to a given version of those. In my experience they are very stable as well. In Meson you have generators, custom_target, run_target and custom_command for all these needs. The advantage of Make is that it is available everywhere out of the box. I like Makefiles also but when you start to move around there are many variants and the syntax...
Yes, i had read about this and it has a c++ library to use.
Imho, make offers zero advantage over cmake for 90% of the usecases. Neither in readability nor functionality, nor simplicity. So while I understand why some make experts might not want to switch to cmake, there is imho no reason to prefer make over cmake if you know both.
Hopefully. It was approved in Kona, but is not yet merged. Gonna see in a few months (July if I remember correctly)
Proposal is for adding `std::format`, without helpers like `print` or `format_to` - and it is not yet accepted, the wording will be discussed on the next meeting in July.
Maybe, I dunno, CMake should see that you're on Debian and *literally suggest you get that package*?
That sounds like another thing that would be trivial to solve if constexpr if behaved like static if in D if constexpr(is_reference_v&lt;T1&gt; || is_reference_V&lt;T2&gt;) { template&lt;typename U1, typename U2&gt; pair&amp; operator=(const pair&lt;U1, U2&gt;&amp; other) { a = other.a; b = other.b; return *this; } }
Oh? Link, please?
Well, qtcreator is just a code editor, while MSVS is a complete IDE.
https://github.com/OpenVPN/tap-windows/tree/master/src tap-windows.h
I have not much experience with automake, but I would be really interested how you would it make work on Windows out of the box? Nevertheless from my experience most of the time problems with any build system are caused by missing dependencies or dependencies not found. Your example is no exception, did you install LLVM development libs? Usually on Linux dependencies are easier to handle, because packages exist and are usually installed at default locations (/usr/local). Most of the time I think CMake makes quite a good job to resolve those dependencies. On Windows there's no standard location, so it's a little more difficult, but works after all. TL,DR: CMake surely has it's flaws and dependency resolution is not always straight forward, but your vent looks like you are just missing dependencies.
Nevermind. I thought you meant some nice wrapper.
qtcreator is a full IDE also, at least for c++
Do you, by any chance, have any opinion on Cargo (Rust's swiss army knife)? Regarding (c) flexibility, I think there are two levels of flexibility: 1. The ability to depend on different versions of a library A in different binaries. 2. The ability to depend on different versions of a library A in the same binary. (c.1) is purely a matter of package management, and should be solved there. Combine with some way of identifying source/binary compatible upgrades (SemVer?) to avoid an explosion of the number of versions on the system. (c.2) is first and foremost a toolchain issue. You *can* have different versions of the same library A that are source/binary incompatible in the same binary as long as the toolchain is geared for it. It does involve some legwork, though: 1. Types from different versions should differ, even if they are named the same, to prevent accidentally compiling when it shouldn't. 2. Symbols in binaries from different versions should differ, to prevent linkage error. In C++ this can be achieved using folders/namespaces for each version; it's error-prone and not very user-friendly, but possible: that's how we handle multiple concurrent versions of the same protocol where I work. Of course, it's much easier all around when the toolchain handles it automatically.
After using the installer to de-select, the size came down to approx 2.1 GB ...
The compiler still cannot compile code like this #include &lt;initializer_list&gt; #include &lt;type_traits&gt; template &lt;class ValidTraits, class T&gt; constexpr bool IsValidTrait() { return true; } constexpr bool all_of(std::initializer_list&lt;bool&gt; ilist) { return true; } template &lt;class ValidTraits, class... ArgTypes&gt; struct AreValidTraits : std::integral_constant&lt;bool, all_of( {IsValidTrait&lt;ValidTraits, ArgTypes&gt;()...})&gt; { }; https://godbolt.org/z/nuJKcZ , says "error C2059: syntax error: '...'" 
Usually the README.md already tells you which dependencies to install.
Thanks for the fix! Sync problem is gone now. I was curious about the \_write only\_ access C++ abstraction the speaker talked about and found \[this article of his\]([https://www.embedded.com/electronics-blogs/programming-pointers/4024953/How-to-enforce-write-only-access](https://www.embedded.com/electronics-blogs/programming-pointers/4024953/How-to-enforce-write-only-access)) that explains that. It's a really simple class that only exposes a constructor and an assignment operator. &amp;#x200B;
It worked.
Is there any reason you are not using Yocto or buildroot for linux distribution building? A lot of the work is pre-done for you. Let me know of a specific problem with any software. The only nasty stuff I have dealt with are Makefiles done by people who shoot themselves in the foot and autotools projects from the depths of hell. I personally prefer meson over CMake, but these 2 make your foot shooting abilities smaller by a significant amount.
This is exactly the reason why when all "just works" things are considered, the remaining is ease of use and documentation. Then, there is meson.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/awtqmj/searching_for_some_books/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Does LLVM/Clang-based count? Plenty of those now too (arm, avr, arc).
It is very flexible and simple for the Hello World version of you project. Then: 1 Adding a clean target. Well...that is a phony target right? Phonies are interesting. Shoot yourself in the foot. 2. Adding different levels of your sources, so recursive directories. You know you should not call make inside make right? 3. You want dependencies of headers done right? So please add the correct dependency generator of your CC to generate the .d files. 4. Auto generated compile time definitions. Welcome to shell :) I could go on...
To be honest it seems not so important cause the library is very simple to integrate so even if it won't be standardised I'll keep using it. 
If I go down the main install folder and find the folders that are not junctions or symbolic links, I find for x64, the lib's 744mb, the dll's 495mb (426mb and 281mb for ia32 respectively) and then some bits and bobs. I guess you have to consider that these are "fat" binaries, there's (binary) code in there for all supported cpu's.
The main point is that this crazy subset of C# can outperform C++ for hot loops. Unity wants to use this stuff to replace some sections of the renderer. The limitations of it are a feature for them. It enforces you to go with the data-oriented systemic approach. This both allows them to use multithreading in a good way (becouse the compiler can check inputs/outputs of a burst job, and enforce their syncronization), and it also allows them to turn optimizations to 11, inline EVERYTHING, and even allow structs to reorder their memory to SoA or similar to improve the vectorization. Their goal is that if you are able to use burst for your algorithm, your algorithm will have extreme speed and be vectorized. Apart from the whole performance stuff, the control over the pipeline allows them to hot-reload this jobs individually when needed, and have compile times of a couple seconds at most. Coming from normal engine dev, where you need to restart the entire thing + can take a long time to compile, its a huge upgrade. There is a very serious chance they will be able to leapfrog unreal engine on the performance side just from the inmense improvements to workflow.
How should it do that?
You can add this one as well: [https://github.com/msinilo/rdestl/blob/master/hash\_map.h](https://github.com/msinilo/rdestl/blob/master/hash_map.h) It's a bit dated (for example it doesn't use rvalue references), but still it's quite fast.
`auto` only works if you are assigning a value of the correct type. I don't think there is a clean way to avoid `std::ptrdiff_t` in the following cases: `for (std::ptrdiff_t i = 0; i &lt; std::ssize(); ++i)` `struct X { std::ptrdiff_t size; };`
Rust: 1 compiler, 1 build system, 1 source of libraries (crates.io), so yes it works very well.
At any rate, any existing code can be mechanically translated from `foo[a, b]` to `foo[(a, b)]`. But yeah, there is definitely existing code which uses the comma operator inside the subscript operator.
Unfortunate that the audio is incredibly terrible.
+1 for Yocto
No this is the new video with the noise filtered by audacity. Compare to original: https://www.youtube.com/watch?v=wn25aBW_FjE
It was LEWG :)
Yes, this is the thing: we maintain a software collection that is *comparable in size* to a small linux distribution, but is *not really* a linux distribution, in the sense that it does not boot, it does not contain a kernel, and it does not provide user-mode libraries that are heavily tied to the kernel or to kernel modules (e.g., libudev.so, libcuda.so). We do provide our own glibc and stdlibc++, so we are getting close to almost being a linux distro, but we are not the Linux sysadmins, we are not given root. We work closely with them, but we don't want to deploy the OSes across the company, and they don't want to deploy the user-mode app collections. Our collection tries to be self-contained precisely because it must work on top of a variety of existing systems in the company, some based on RHEL6, some based on RHEL7. We are also self-contained to limit coupling between the two groups, so that they are free to maintain OSes without impacting us too much, and we are free to upgrade the software collection without having to wait for them to upgrade depencencies, which usually can happen only during a scheduled maintenance window. In addition to that, our internal clients must have the option of using our environment, not using it, or using multiple versions of the environment we offer. We organize everything in a manner that they switch from one to another by just adjusting PATH and LD_LIBRARY_PATH. Some of our users are sophisticated in the math they run, and they want a guarantee of numerical reproducibility, so they can't have package versions inside a given environment shift under their feet. So, basically, once we bless a version of our environment and we publish it for use, we freeze it and never touch it again, even if some of its packages turn later out to be buggy. 
I don't know Cargo at all, and we don't have any users that need Rust. Maybe I should learn about it. Our users write in C++, python and R. I am, however, painfully familiar with instance (c.2) of the multi-version library problem. We had to ship a large open-source product in the form of a static library (btw, not a build target supported by the community that releases it) that included google protobuf3, and link against in-house products that wanted protobuf2. We solved it by renaming the protobuf namespace (the one containing v3) in the static library... in the binary of the static library. We used objcopy --redefine-syms. We learned in the process more about C++ symbol mangling than anybody should ever know. 
IMHO the original is better to listen to. The noise filtering gate is very distracting and has that underwater sound. Despite the high noise in the original it's less distracting. But good to have options.
I recently stumbled upon his output iterator articles and have began thinking about new ways to use them instead of for loops.
Seems weird to have no maths, physics or electrical circuits classes in a 4 year computer engineering program? Is this common in the Netherlands?
I recently graduated in a computer science master in the Netherlands (I’m Dutch). I’d say the amount of math you get is very dependent on the master program (computational science or data science would be math heavy. Regular programs have relatively little math), Physics and electrical circuits are not part of most computer science programs (neither should they be, it’s electrical engineering).
I really don't think the syntax is that bad when you get used to it. Some design decisions are kind of silly, but I wouldn't say it's explicitly "bad".
Why it took many years to realize it? I bet it could have popped out easily if you would have thought "I need control + abstraction" 
Well, `format_to` is in the proposal [P0645](https://wg21.link/P0645]). And it better has to, because `format_to` is the workhorse of formatting of custom types unless you can get away with deriving from one of the built-in formatters. For an example, see my implementation of `format_chrono_duration_value`and `format_chrono_duration_unit` in `{fmt}`'s custom formatter for `std::chrono` types. What's missing is the support for non-standard string types which I spent much time on last year. It helped me a lot in my own projects and was a major topic in my talk on {fmt}. This is something that may be added in C++23.
I had the same experience but it wasn't always like this. Now with stl and modern standards it's a really nice language but very different then i was used to. Still a sucker for plain old c though.
I happen to think standardization is important, because while fmt is easy enough to integrate as a third-party library, having it as part of the standard gives it significantly more gravitas and general visibility. It allows broad-based adoption and compatibility that even the best third-party libraries don't enjoy. A similar thing happened with smart pointers in C++ 11, or with threads and atomics support. It's not that smart pointers, threads, and atomics weren't available before, but having them as part of the formal language specification gives developers more confidence to begin using them ubiquitously. Otherwise, you end up with competing implementations and non-interoperability, which seems pointless once we've narrowed in on what most people seem to agree is a solid, well-tested design that's clearly superior to the existing standards.
You are right obviously but, I mean, thread atomics and stuff like that have a different impact on language, interfaces and interoperabilty of code than formatting that, for me, is usually more of an internal detail. So Ill be happy when it will br standardised but i'll use it anyway in the mean time. 
It's a mistranslation. "Technische informatica" means there's more focus on embedded, networking and security instead of things like web and databases. It's still computer science, not computer engineering.
&gt; Now with stl Now = 1998
Just wait till you use some sexy lambda expression as a slot in Qt. This is where the fun begins.
I'm in the second year of TI right now (Wouter is my teacher actually). We had a mathematics course last year. This year we have a vision and an algorithms course, that both contained math (especially vision). Physics is not really taught, but like another commentor posted; "Technische informatica" is focused on embedded/high performance solutions. It's a mix between electrical engineering and computer science.
has it been so long already.. i'm from the time when there was no template support in some compilers :)
\&gt;i have to apologise for dissing this language and OOP without ever giving it a chance. &amp;#x200B; No need to apologise, you're the one that's been missing out. ;D 
C++ is a multi-paradigm language. You are not bound by the concept of OOP. C++ gives you wings. (or a jet engine if you want to call it that way)
Templates &gt; OOP
It's frustrating because it's possible to write such ugly terrible code in c++.. but it's also possible to approach the best possible implementations...
For “angry C++” you seem pretty happy. Clickbait username 🤡
I highly recommend reading "A Tour of C++: 2nd Edition". It will really walk you through how nice the language can be and it's very short. I've been using C++ for years, but after starting to read this book it's becoming very apparent to me how easy it is to write clean code in modern C++! I also recommend giving rust a try as well. I just started learning it two months ago and I've actually been really productive with it (something you don't hear often for some reason). It's made me start thinking differently about C++ code as well, even when I'm not coding in rust, which is another plus.
I don't remember the last time I ran anything in debug. Sadly if I need debug in certain spots, I have to toss around #pragma optimize off. I make do though
Isn't it past your bedtime old man? Lol. Must be awesome to see so much improvement in the language over time. I only started using c++ in 2013 but I can appreciate the massive improvements that have been made since then.
That’s a valid option. If you read R0 of the paper I have a bunch of details of what’s fine, what’s unintuitive, and what’s broken. Working on this with Paul means that users such as the Linux kernel are considered in how we handle volatile. IMO the extra typing is a good thing. C++ is all about abstractions, and volatile simply isn’t. If you want to abstract around volatile, I’d rather the language force you to do a true abstraction, with fewer sharp edges. 
How so?
C++ is nice. Wait until signed integer overflow meets optimizer. C++ is definitely nice.
R0 of the paper has the exact definition, as well as the intent and real-world uses for volatile. 
Great post! One minor correction: `formatter::format` in the `complex` example should return the updated output iterator, e.g. ``` template&lt;typename FormatContext&gt; auto fmt::formatter&lt;complex&gt;::format(complex const&amp; number, FormatContext&amp; ctx) { return format_to(ctx.out(), "{0}+i{1}", number.a, number.b); } ``` which is both a bit simpler and will work with any output iterator. Also it is possible to reuse formatters via inheritance or composition.
It gets even more fun when the signal you connect it to then gets emitted from another thread.
`format_to` is not only there, it was added per committee feedback =).
Bingo. Good fucking luck getting hundreds of non programmers to even remotely understand, setup, and use git. 
And thanks a lot for all your work to improve {fmt}, @Daniela-E! 
It can be error prone to remember to use call volatile\_read every time. However if the type were std::volatile&lt;int&gt;, then reading from it would always do the right thing, just like std::atomic&lt;int&gt;.
Keil supports C++17, just don't expect it to be free.
The only way to write fast code is to make sure everything is an inlined template and complex computations run at compile time. No jumps allowed in this codebase.
this is fuckin hot
You can write something without using classes but a bit more complicated and less easy to read. But you can't really do what templates do with C. OOP is helpful in big programs/games, not as suitable in other cases but all I mean is that templates are a more important feature imo. I don't quite understand what you said but I think that it was sarcastic, correct me if I'm wrong.
&gt; We used objcopy `--redefine-syms`. We learned in the process more about C++ symbol mangling than anybody should ever know. Sounds painful :( 
That is unquantifiably better in my opinion.
"why can't it just like figure it all out man" AddLLVM.cmake is not a built-in CMake file so why the hell would it know whether it even *is* in a package much less which one *based on what linux distribution you're on*? Why would CMake even do this? What build system would do this? This is a dependency for the CMake script itself, not the project it's generating build scripts for. If anything, this is the fault of the developers for not telling you the dependencies clearly or the fault of the user because they're using a distro that insists on splitting off headers and other build-time hooks into "-dev" packages and doesn't understand what extra work that entails.
haha old people need less and less sleep :) Yes, it's quite weird seeing how much progress has been made in both software and hardware. When i first used a tiny bit of c++ it was around the late 80's i guess. It was on our family xt compatible with i believe a borland compiler. Everyone started with writing a string class :)
Join the dark side :-). Really now, grokking the borrow checker rules makes you be more careful even when using a different language. It doesn't have to be C or C++, the borrow checker also protects you against concurrency issues. Also, `cargo` is the bee's knees.
I work with a bunch of old schooler game developers who still write "C with classes" and reminisce about days when CPUs had no FPUs, so I totally get where you're coming from. I started learning C++ ~4 years ago, so have the benefit of "growing up" on modern C++ with a performant and featured STL. I don't think I would have even liked programming much if I had to deal with OS-specific mutexes / critical sections, char buffers, heap arrays, and the lack of lambdas / std::function all the time!
I'm imagining a type trait like std::prompt_user_yes_no_t that will let the compiler get input from the user. 
Sure, I'm the same way of course. In my own game engine, I'll either use the standard or the third-party fmt library going forward, because I've already done the integration work. And I didn't meant to imply it would have as big an impact as major language features, as it was just drawing a parallel. I'm also looking at it from the perspective of a [third party library](https://github.com/JamesBoer/Jinx) writer (that's my most fully-featured open-source library to date). There's a logging function there, but internally I use printf-style formatting, because I don't want to add any additional dependencies (there are currently *no* dependencies, which has some of advantages). If fmt were part of the standard, I'd most certainly be using it as part of my library's design. But adding another dependency is a somewhat heavyweight decision for a third-party library to make, at least while you're trying to encourage adoption by reducing any possible friction. Anyhow, given that it's on track for standardization, it's sort of a moot point anyhow, I guess. Overall, I've been pretty happy with the direction C++ is heading, and anticipated additions like this to the standard are just a cherry on top.
I honestly think the oop of cpp is quite a bit behind Java. Abstract classes can cause headaches. I fond myself writing a kind of bloated declarative style. Forcing myself to write in a 'good' oop style requires alot more mental effort than in Java, Python, C#...
I i could go back in time and talk to my younger self, "DUDE SERIOUSLY C++ and DS9!"
C++23 feature confirmed
He was talking about going too far with templates ( a common reaction ) Templates are incredibly powerful and build on C++'s strength of being a highly extendable tool.
Here's a Sunday riddle for you: did you know that C++ demangling is univocal, but mangling is not? I.e., a mangled symbol can be demangled in only one way, but the inverse is not true.
The primary expressiveness boost from Templating is the ability to genericise your type handling systems, so it's a bit of an apples to oranges comparison. C++ gives you many powerful tools to create systems which are able to process types rather than just variables.
Hallelujah
Hah yes indeed. i'll remember 355/113 till i die i guess :) But the hardware has got a _lot_ better also. Older programs were very small in comparison to todays. They had to be even.. even allocating a big buffer was often troublesome. Gladly the x86 platform had all these 'wonderful' memory models which made learning c and assembler harder then it should be. Certainly coming from 68k. But, i do believe having to learn on a (very) limited machine will make you appreciate and better understand the 'modern' ways. 
C++ gives you fucking everything lol It's like someone said "what if we added... \* everything \* to a language"?
Oh, it's the same old story with the same reasons other people hate OOP or C++: it's weird and uncomfortable and someone showed them a bad thing that can happen when it's done poorly or it looks super complicated and they don't immediately understand why. Kind of the mirror image of people who like all these new languages or things that look more or less the same as the old languages or things they purportedly replace are all always somehow "better" even though they have less features. It looks icky so it's bad and we need to start over and re-invent it. You know, like Meson. (oooooooooooooooooooohh)
Eh you are right! I usually write embedded systems and not generic libraries in a library context standard is much more important! 
It's also possible with other languages too. I really hate people do some cryptic list comprehensions in Python. I still find reading large C++ libraries like Opencv far more readable than their Python counterparts. I actually quite like the verbosity of the types and avoid auto if it's not something like a huge template iterator, or the return value of std::bind(), std::function() etc. Using autos for simple types or parts need explanation etc. is an anti-pattern for me.
aaaaaaand here it is. 
Where is reflection then?
Are reflections a critical feature though? Like, is there a situation in which using a reflection is the only possible solution? 
It was only a matter of time for the rust evangelists to find this thread. How dare people enjoy C++. 
Only solution? No A far better solution than a custom build system to generate reflection information, like Unreal Engine 4 has? Absolutely 
&gt;C++ gives you fucking everything lol It's paradigm is "what if we added... \* everything \* to a language?" vs &gt;Are reflections a critical feature though? Like, is there a situation in which using a reflection is the only possible solution? The retreat was so fast you had to have gotten whiplash. I almost didn't believe the reply was from the same account. Just give /u/miki151 his "touché" and move on.
Much better. I think audacity is capable of doing a much better job. This kind of noise should be quite easy to remove from audio I believe.
Alright, alright lol I was obviously joking with "gives you fucking everything"... But alright, touché :)
Ah, another person tricked by reddit's "Fancy Pants Editor". I kept wondering what was going wrong with my comments that I was writing in markdown until I saw that "Switch to Markdown" link in the lower left.
Since these are kernel threads, I’d expect that they respect the system clock. Is this implemented differently elsewhere?
Having programmed in Java, I think C++'s OOP is more advanced than Java. Virtual functions are on an as needed basis, instead of every function. Multiple inheritance is allowed, with virtual inheritance solving the rare diamond inheritance problem. Covariant return types.
Your environment is very similar to the one I work with. Exactly the same problems and challenges. We even use RHEL6, with some machines still on RHEL5. If i did not know that these RHEL distros were not so seriously outdated that even docker cannot work due to unsupported kernel futures, I would suggest you to try containerization or virtualization. As we had the same problem what we have done is, with Yocto, we created what is called a NativeSDK buildtools, which is a tarball that contains all the software we need. It is then extracted as a kind of sysroot. It contains from modern glibc (not the old cranky version in RHEL) among others. If you need help I can guide you to generate this tarball. The list of software to bootstrap Yocto for RHEL6 is actually in this recipe I augmented: [https://github.com/ptsneves/poky/blob/sumo-extra/meta/recipes-core/meta/buildtools-tarball.bb](https://github.com/ptsneves/poky/blob/sumo-extra/meta/recipes-core/meta/buildtools-tarball.bb) &amp;#x200B; So, Yocto can still solve your problems, as It has a huge base of recipes for common software as well as build systems. CMake, meson and autotools have the build mostly automated. It also offers much better guarantees of reproducibility than what you could do by yourself. There are some projects with serious host contamination at the build time. The only problem is that Yocto has somehow a steep learning curve but it is worth it, specially because you can augment it with recipes for your proprietary software.
Why can't there be a standard C++ library distribution system like Python?
"Simpler". Weird usage of that word. Also I get what you're saying but yeah... I love C++ (template libraries are BIS for the work I do) but text processing in it is absolutely attrocious compared to Python (for instance).
My general rule with auto is to not name a type twice on a line. auto blah = make_unique&lt;Blah&gt;(x, y, z); Is pretty clear, for instance.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/awz15f/which_one_is_the_final_c_standard_library_file/ehq4eb2/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I tested with Audacity and got better results. What I did was: * I selected an area with uniform noise: 7.85 - 8.55 seconds * Effect - Noise reduction: clicked Get Noise Profile * Selected the whole audio * Effect - Noise reduction - OK (just the default settings)
Modern C++'s motto should be "leave no room for a lower level python".
Simpler in this specific example because you don't need a separate return statement which makes the body a one-liner. f-strings is a recent addition to Python and something like that might be available in C++ in the future. For now we need to have the core functionality in which already be a great improvement.
I only used (=maintained) Visual Studio project files, Makefiles and CMake files, but also saw some SCons files. As /u/cazzipropri mentioned in this thread - I hate them all. But unlike /u/cazzipropri, I hate Makefiles the most. Seriously, the are they worst. Here is a small list of things I like about CMake compared to Make: ### The language Sure, both CMake and Make have their own terrible language, and many people will say that Make's is much easier ("You just write the make rule, and it works"). Sadly, in most real-world applications I've encountered, the rules contain various magical symbols such as "$@*?%", which convey no connection to their actual purpose. On the other hand, CMake is as simple (every line is the same: `function(argument list)`) without any confusing symbol. On the other hand, CMake also support conditional statements, loops, non-environment variables and functions, allowing to better express your build logic through modularity. ### Better "out of the box" features Compare the simple Makefile (I really hope I got it right): main: main.c $(CC) $^ -o $@ Compare it with the simple CMakeLists: add_executable(main main.c) 1. CMake checks modification of the build files themselves. No need to re-run configure or delete/touch some files to force recompilation, just because you added some flags or dependencies. 2. Automatically tracks headers. If main.c is dependent on main.h, then the Makefile above won't cause recompilation in case it changed. CMake just handles that for you 3. Targets can be referred to by name. If I link to another library, I don't need to figure out where it is on disk and track the current build path, CMake handles it for me. This allows me to move files around between directories with minimal effort ### Modularity Modern CMake supports per-target properties, which include compile-definitions, include directories, compilation and linkage flags, and more. This allows to easily support compilation of your own libraries with whatever flags you want (strict or not), while not worrying about affecting the build of any 3rd-party library you use. When I use Makefiles, I worry my *environment variables* will affect the compilation of other libraries. ### Transitive properties between targets Similar to modularity, but this deserves its own bullet and for me is the main sell-point of CMake. When specifying a dependency using `target_link_libraries()`, all properties mentioned above are calculated transitively. That means that if my executable is dependent on a library, I don't need to care about *that* library dependencies. CMake will just pass the correct compilation flags, include directories and link options to my own executable. &amp;nbsp; To conclude, when I encounter a library which is built with CMake, I know I can just integrate it into my project's directory, add a `add_subdirectory(lib_path)` and compile without worrying about... anything. Also CMake has built-in support for [External Projects](https://cmake.org/cmake/help/latest/module/ExternalProject.html) (including Make-based projects)
Extremely interesting. I'll check it out tomorrow morning! Nice to hear of other people with the same issues.
Now try Rust! :D Bring on those downvotes- I am not afraid.
https://media0.giphy.com/media/1guRIRFV5gN4ikrUakg/giphy.gif?cid=4bf119fc5c7c4f9a395231744538b177
Having a generally agreed upon formatting API is equally useful for interoperability. For example, with [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1361r0.pdf](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1361r0.pdf) you'll be able to format all the chrono types using the same facility and over time more standard and user-defined types will be supported within the same framework.
I see! I did computer engineering, so I guess that's why it's more math, and also some physics and some electrical engineering. And I guess it also depends on how applied and/or academic the program is.
Welcome to the 90's brother!
Or how ugly it can get!
Seriously underrated comment.
I would hate to read your code. How do I know? I top use std::functional all over the place...
I didn't find this talk too useful to be honest. It introduces the curriculum of that University in quite a lot of detail. Unless you're really interested in that, a prospective student of that Uni, or interested in curriculum-building, it's not too useful and also doesn't really help to bring across the point of "why stop teaching C". In the last 1/3, the talk is more about "stop teaching C" but the main messages is kind of "stop teaching complicated printf/scanf specifiers and teach with simple examples instead". Anyway I guess the whole talk is definitely interesting in some respect and I am sure it will be appreciated (oh well, even more so if it had good audio...), I guess I am just a bit disappointed because I expected a talk along the lines of Kate's "Stop teaching C" ;-) But that bar is definitely insanely high ;)
Used Audacity for the noise filtering. Thanks for the feedback, maybe I was a bit too aggressive in the settings.
Why?
I felt similar after coming back to C++ after not-using it since C++98 was the standard.
They key thing is that C++ doesn't try to be idiot proof. This enables tremendous power and elegance. It equally enables you to blow your foot off if you don't know what you're doing.
How does it compare to other similar libraries, for example Boost.Outcome?
why downvoted tho? 
Nice try Bjarne. You're not fooling anyone.
We don't talk about Rust on the C++ subreddit :D
LOL are you insane? Rust is a fucking meme
I don't have any problem being "that guy". I put off learning rust for years, but now that I'm using it, I'm regretting taking so long to give it a good try.
&gt;and avoid auto Modern editors should be able to show you the type just by hovering over the auto keyword. Emacs plus lsp (clangd) displays this with the cursor on auto: int [auto] 
The closest thing to this 'try(x)' is `OUTCOME_TRY(var, x)`, which cannot be used in an expression. IIRC, the other solutions are to manually propagate the error or to put the 'success path' inside a lambda. Moreover, this try()' dosen't require any specific type, but requires compound statements (or 'expression blocks'), which are available on GCC and Clang (but not MSVC). Here is some examples (if there is other ways please tell me) : With Boost.Outcome : outcome&lt;int&gt; get_num(); outcome&lt;int&gt; add_nums() { OUTCOME_TRY(x, get_num()); OUTCOME_TRY(y, get_num()); return x + y; } With expected : expected&lt;int, error_code&gt; get_num(); expected&lt;int, error_code&gt; add_nums() { return get_num().and_then([] (int x) { return get_num().and_then([x] (int y) { return x + y; }); }); } With try() : std::pair&lt;int, error_code&gt; get_num(); std::pair&lt;int, error_code&gt; add_nums() { return try(get_num()) + try(get_num()); }; 
I want /r/rust to leave
There are situations that there are no "modern" editors or plugins available. For example looking for just a small part of implementation without downloading the whole base or reading pull requests from GitHub/Gitlab/cgit... . Or just skimming the git diffs when the code is partially exposed. Or situations when you don't have the tools available, like deploying on embedded systems. 
C++ is sort of the Lollapalooza language. You could ask two people to implement the same algorithm and they might not look at all alike. These days some folks appear to be striving to make their entire program one large template. main() { Program&lt;Implementation&gt;(); } You make one mistake and the compiler will issue a googleplex of error messages, none of which actually tell you what's wrong. &amp;#x200B;
Alright sorry for bringing in something I thought OP might appreciate since they seem to be interested in trying languages. The other half of my first comment was about C++ and I said you can write good code in C++ as well. Considering rust has the same target audience as C++, it doesn't seem too insane to bring it up here. People certainly talk about C++ a lot on /r/rust.
Great! So how do I get the CMake modules that your project needs in order to build? 
&gt; Nevertheless from my experience most of the time problems with any build system are caused by missing dependencies or dependencies not found. Your example is no exception, did you install LLVM development libs? &gt; &gt; Yes I did, but that doesn't matter, because on Ubuntu, none of the development libs contain `.cmake` files. Everything is supposed to be in the `cmake-data` package, and if it isn't then you're just shit outta luck. In fact, I've gone to the original sources of the dependencies when I had this problem before, and found that *they didn't contain the `.cmake` module either!* So I suppose everything is supposed to be distributed with CMake itself. And that implies that if it isn't, then you have to get the author of the code that needs that dependency to give you the relevant file.
I'm glad it works on *your* system. That's what I keep hearing. 
I like it... :(
Can you elaborate? 
Pull any CMake project off of GitHub and run `cmake` in the build directory. That always reproduces it for me. 
I usually get enough warnings on this with GCC, I'm sure other modern compilers would warn too.
It's been my reality for years. 
Nope. It's *no* easier on Linux. 
Having a large standard library helps too. Boost, libpoco and many such _modern_ libraries make writing high-level code a fun and productive endeavor.
&gt; It seems that you're just missing a dependency. Try which llvm-config and see if the dir that binary exists in (if at all) has all of it's dependencies. &gt; LLVM is installed on my system. The problem is that Debian doesn't ship LLVM.cmake as part of it. 
What OS (and distro if you're using Linux)? 
Nice try. I have `-dev` versions of all the dependencies installed, including the one that CMake can't find. 
Anything that can reduce the amount of macros is a good feature.
&gt; CMake is poor on Ubuntu, I give you that. Once I hit a library that was registered in the CMake database on Ubuntu but was not installed actually... It took me a while to figure out the problem. &gt; &gt; I have the opposite problem. The dependency is installed, but it's not registered (because Debian ships the database as a static package). 
Opencv is terrible on many aspects, not just because of the limitations of supporting older compilers. Whoever thought it was smart to have a type erased type that forces you to use template accessors and the whole API using it but half the functions not saying what format they actually accept (since those aren't templated) was either insane or evil.
Not everyone lives in the US so it could be morning over there.
CMake has the distinction of being the only build system that I've never been able to get working, for *any* project. 
I dozed through the part about curriculum. I would say the main message is they are teaching more C++ and Python since they stopped teaching C.
I think using this kind of template to abstract the actual reads/writes would be good. And you can also make various versions to ensure read only or write only (because in many cases it works only one way), which could prevent mistakes. You can `const volatile` now, but you can't make something write-only. And that could be a bug in your code.
Okay
That implies the dev did their job correctly, which is not always the case. Sometimes the readme just doesn't help at all.
It will be interesting to see how students come up with real world high performance solutions to problems with no physics or electronics background. How can you optimize a problem with no domain knowledge? 
Even the documentation is usefull, it's just not always easy to decipher.
Well then you are probably not doing the correct things. Many developers including myself rely on CMake to generate our build systems specifically for the reason that it is easy as pie. If a CMake based project is not building on your platform and it is advertised to support your platform and you have all the stated dependencies installed, then my next course of action would be to Let the project maintainer know of the issue, because it is likely a mistake/oversight of that person[s].
I wrote it at 2 pm as a joke
So Exectutors and Networking for 23?
The link says: "A list of open source C++ libraries". If they would change their standard to free C++ libraries, people could consider libraries like [my library](https://github.com/Ebenezer-group/onwards).
You can get pretty close with vanilla macro functions. I've written a bit of type parameterised code in C myself. 
The way I see it, C++ is really ideal for learning canonical CS because you can access all the fancy algorithms and different styles of coding you don't get with raw C, while still having access to the guts and machinery if you want it. Anything you want, it has. It kind of forces you to learn more, in a sense, especially if you don't skip straight to smart pointers. &amp;#x200B;
Well that depends on your project and your platform. Use your distro's package manager to install the missing dependency if your on linux. OSX has homebrew. Managing build dependencies in Windows can be a little bit more involved. When you run cmake, it should tell you what dependencies are missing in the error output. CMake uses the *find_package* command to locate and add the dependency targets. That should fail with a useful error message.
I like his incremental approach to things. He's able to weave a lot of things together in this talk. 4 stars
Don’t forget when you refactor something and end up with functions that return a new class that is compatible with the old class. With auto everything just compiles.
Too bad you need to rely on a GCC and clang extension to return from an expression.
You keep posting your library everywhere, but if you want people to look at It (for more than a second) I'd suggest making the readme more appealing. A wall of text makes me want to close the tab before I've even figured out what your library does. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/ax31f0/can_someone_help_me_find_a_tutorial_or_guide_on/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
 &gt; main() &gt; { &gt; Program&lt;Implementation&gt;(); &gt; } 🤣🤣 Oh my sides
Can someone point me to a good overview of the reflections TS? The link seems to be the actual standardese which is hard to follow. Are there any higher-level papers or blog posts?
&gt; The key thing is that C++ doesn't try to be idiot proof. I’ve been trying to verbalize why I love C++ so much. I think that’s why. When you have beautiful C++ code, it’s *really* beautiful.
I think there is a proposal about that. But deterministic exception is clearly superior.
C++ is a devil
It is not always possible. I get it. All in the name of optimizations and cpp compilers do a great job there. But language has just to many "don't do that but we will not tell you if you did it and everything blows up" things.
Also: &gt; Accounts &gt; An account is needed to use the CMW. Before running the middle tier, you have to get an account and modify your cmwA.cfg file to include your account number(s) and password(s). To get an account send an email to support@webEbenezer.net and include a password between 10 and 50 characters long for your account. We'll reply by giving you an account number. Nah. If it were good enough at whatever it does to warrant that kind of nonsense I'd have heard about it from somebody besides the author.
The suggestion in freestanding for throwing functions was to require them to have no definition so it gives a linker error, but so it does interact with sfinae identically as hosted.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/ax41qf/homework_help_erratic_math/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The original sound quality is sufficient.
This is very common in Europe. While my American colleagues have a smattering of general knowledge to supplement their engineering knowledge base, my European colleagues are very focused. It's somewhat embarrassing when the American Electrical Engineer explains how RAM operates after powerdown to the computer engineers. When I went through school, cold boot attacking was a lab.
It's being seriously debated: [proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/n4766.pdf), [discussion on Herb Sutter's website](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0194r3.html).
Yes. It's a really good thing, it gives us time to * Make sure executors and coroutines are well-integrated * Make sure Network and executors are integrated * Make sure coroutines and network are integrated * Reflect on whether we can design a better networking library with the tools and knowledge we discovered over the past decade. `asio` was created in a world without lambda, executors, coroutines... 
As someone who stopped paying attention around the C++17 timeframe, what caused the outrage about modules? I don't recall them being too controversial at the time.
Do that, then give up when you see the hoops you have to jump through to borrow multiple elements from a vector
As someone who intends to implement your freestanding library proposal on Arduino I'm definitely looking forwards to seeing it moving ahead.
It is extremely simple, and fits small personal projects very well. Make at the most basic is just a Dependency Resolver. The rest, you can stuff it with commands that do your thing.
I forgot to add. Do not go back in time with Make :) God forbid your machine does not have a persistent clock, or you change your timezone westwards
&gt;Despite the reddit-verse's outcry, modules went in to C++20. What where the objections from the reddit-verse and are they actually being addressed ? 
Continue on contract violation is such a bad idea that I amazed people kept their braincells
Hm, this has some interesting potential for code reuse. Let's try it.
I believe that some people at Bloomberg would disagree with that statement.
What the video shows is not runtime duck typing, it is compile time duck typing, because the binding happens at compile time. Using the technique shown in the video doesn't actually offer any benefits over inheritance with interfaces. If you have a class that doesn't have the member function you need, you must either a) modify the sources, if you have them, by introducing the function you need or b) extend the class by inheritance and introduce the function you need or c) write a wrapper class that contains the class you want as a member and introduces the function you need. All these things will be one by using interfaces though, so there isn't any actual benefit. Neither this solution uses less heap allocations. It just hides the allocations from the user. And it also does not save us from writing the interface: as in the example, the drawable interface is there. Also this technique is error prone when there are functions with the same name but with different signatures. This is a duck typing issue on C++, where the wrong implementation to be called is chosen simply because the wrong implementation fits better with the types required. This is not possible with interfaces, because the compiler will say the code cannot be compiled because abstract methods are not implemented.