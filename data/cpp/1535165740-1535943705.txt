I don't see the article saying they are better?
Have you even read the error message? All that spew doesn't tell you how you got to std::sort, but where it went down from there until it finally hit an impossible operation 5 functions *down* the call stack in the internals of the stl.
Please give a concrete example if what you mean. Where is a lack of error messages enforced?
I have, and sometimes it is necessary. Compilers of late have been really good in that I can skip straight to the error message and figure out the error. Or maybe it's just me being more experienced. &amp;#x200B; But sometimes there are errors that I did not know about, or needed some insight as to what the compiler was "thinking". The most common of these rare times is the fuzzy edge cases of specialization/overload resolution failures due to some rule that comes into play in certain conditions.
Havn't tried the code yet, but noticed that the header files have a lot of unwanted includes which should ideally go into the .cpp files. Keep the headers small. 
The problem I often have with this in practice is "Great, so my type doesn't satisfy concept xy, but what exactly is missing?" I think this can partially be solved, but fundamentally, just spewing information on the console while playing a guessing game of exactly what information the programmer needs to diagnose that particular problem (while not providing top much noise) is a very limited mechanism. For really great error reporting, you would need the ability to interact and query the available information according to your needs. 
&gt; you’ll have to lift a.compare(b) into a free function and provide overloads for int I don't really understand why this is considered bad. To me it seems correct and perfectly functional.
I believe `std::endl` outputs a newline *and* flushes the buffer. So repeatedly using it repeatedly flushes the buffer, which probably can cause performance issues depending on how often you call it.
I haven't gotten to IDE integration yet, but it is planned...
Ha, well-spotted! But the article is about bike-shedding a very minor structural point, not about writing actually correct code. All the same you'd think people would at least test their code even one time before posting it online... Personally I prefer this one: constexpr bool IsLeapYear (int year) { if (year % 4) return false; if (year % 100) return true; if (year % 400) return false; return true; } 
Yeah no problem! Whenever that happens I'll be right on board - this is some great stuff :)
I see I'm late to the party. Would you be available (via discord or slack or another live-ish medium) to help work out a restructuring of a rather large hobby project of mine in this manner?
Isn't that exactly what the whole article is about?
That was just a snippet of the error message. The article says there were 16 lines. &gt; cascade of 16 errors, including such beauties as The other parts are where it goes from your code into std::sort, which is the part that can be very important in a more complex situation.
Yes, but that part (how you got to sort 2) isn't removed by this technique.
Exactly. It keeps everything up to std:: sort but hides all error messages inside std:: sort.
i see now. thank you.
The title implies they are somehow better.
Actually, by default, cout directly forwards every input to the according c-stream (there is no additional buffering) and that c-stream will get automatically flushed on "\n". So, by default, there is almost no difference between "\n" and endl. I have to admit, that I'm not 100% sure if this was specific to one platform or generally true.
Aren't begin/end customization points? Didn't see it mentioned in the article. I think range-based-for has the sanest design, you can either have begin/end functions or begin/end member functions and it will work. Should be the standard for any customization points IMO. Even for operators. Given a three way compare function, operator &lt;,&gt;,== etc could all be defined implicitly (if range-based-for can silently call begin/end, so could operators silently call compare).
No, you need a separate socket for each connection. You could setup a proxy server and open multiple sockets there and multiplex them somehow for client connections, but I don't think that is what you would like to do. 
&gt; That's great, but I never intended an X to be sorted in the first place - how did that type even get there? That information is now missing. No, it's not. You still have the stack leading to the `static_assert`, and therefore knows who called `sort2` with `X` (and who called them, etc...). What is hidden is the part of the stack *from* `static_assert`, which is useless since `static_assert` already gave you the error message. Concepts would be neater, but not quite there yet.
Hi. Are you going to support this wrapper in future?
I agree. I'd also much prefer to use compare(a, b) than a.compare(b). There already is precedence for this in the form of std::begin/end, you are supposed to use begin(a) instead of a.begin() in templates because of C Arrays. Having similar compare/to_string etc free functions would at least be consistent for once.
They're more convenient because you don't have to worry about member vs free functions to call them, which makes them somewhat more uniform with built-in types.
Especially if this is used in a medium to large project,the cost of this could be very high. I worked on a project where we did just this, and the generated headers were included in a PCH file. Every build was a clean build, taking multiple minutes. There are advantages to having the files generated by your build system though. Requiring developers to manually run an extra step to generate the code is error prone, and can result in either strange build errors (that undoubtedly one programmer will end up always being called on to fix) or just wrong code(someone changes the code generator to fix a bug or to optimise the generated code, but you're still running the old code). We eventually fixed it so that protobuf would build to the cmake build directory and would re generate the code if either the protobuf files changed or the compiler changed. It meant we could treat protobuf files as real source code and the generated code as build outputs, so there were much less issued. We didn't do it like this though. 
Argh, yeah I confused those two. I was under the wrong impression that „Halbordnung“ was the German term for strict weak orders, but apparently this is one of the cases where the translations are literal in all cases.
Thank you! I'll look into those. I'll be adding documentation to the code once my mid terms end :D
I totally disagree with these post. Having only one return path was a false good idea of the past. cpp core guidelines advice using early return for good reasons (sorry, I'm on mobile with bad access to internet, I can't give the link). The example #1 is harder to read, because if you see many if/else without return, I don't expect to find a return value. To know that it's a return, I have to read the whole function, notice that their is no return, then going back to the begginig of the if/else. With example #2 it's really clear that the unusual case are eliminated first, then we have the nominal use-case.
Thank you! I'll fix those. While we're at it, I wanted to clarify something. Should I be use \`.h\` extension for header files or \`.hpp\`? I know it doesn't matter in the bigger picture, but what are the standards? What I feel is that \`.hpp\` should be used when coding in C++ and \`.h\` for C. Is this the industry standard?
Can you please make a comparison in the calls for both. For instance, he ultimately declares the stream operator (to use for stringification) as non-member friend. What rules make it better then non-member friend to_string? 
I'm not sure what you mean? You can just write: `a &lt;=&gt; b` for operators Otherwise you'd have to write `a.compare(b)`, but it doesn't work for built-in types, so you have to try `compare(a, b)` as well.
AFAIK, there are no standards w.r.t header file extension. My personal opionion; .hpp should be used for c++ files, .h for c headers. Modern C++ language is no longer "C with classes" and it needs its own header file extension. Boost uses this scheme and i feel it should be adopted by the rest of C++ community too. 
The only thing I saw was that operator&lt;&lt; is defined for many existing types while to_string is not. To me that is so easily remedied that it's almost irrelevant.
How do you distinguish between included dependencies and submodules? Shouldn't there be an "extern" in there ... to replace "third_party" and make it one word. 
Upvoted for the sync_with_stdio reference. A lot of people don't know about its performance gains.
But he defined the &lt;&lt; as non member. Does he prefer it over to_string only on the bases that not all types have an overload for primitive types? I am just trying to pinpoint all his complains regarding functions vs operators as customization point. After all - If the behavior you’re trying to customize is spelled as punctuation: Easy peasy. - If the behavior you’re trying to customize is spelled as an English word: Horrible Are very strong statements 
Here's the link to the latest version of that file: https://gitlab.kitware.com/cmake/cmake/blob/master/Modules/FindProtobuf.cmake
It seems still very limited though - from their documentation it seems they only support one single ARM GPU and it's an exotic one on some embedded board. So no real luck on Android.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
For anyone reading this, the free ticket promotion ended yesterday. Anyways this looks like a great conference and is worth tweeting about anyway, **and** getting a ticket! :-)
Just dump all the data you'd like to keep to file. I recommend using CSV as your data format and writing each time step to a different file. This is not as efficient as writing to a binary file but it is more portable and human readable. If you need the memory savings (above files should be only a few GB in total) then you can always convert to single precision, write to raw binary file format, or store only every n'th iteration. I would create a directory structure like: * simulation_name * * iteration_number * * * matrix_A.csv (or .raw) * * * vector_B.csv (or .raw) Should be fairly straightforward to write some C++ (or, really, Python or Julia!) to manage this data.
There's lots of ways. Kinda depends on other factors, like if you want to do anything else with the data, like post-process it in a third party program. Ideally you'd want to translate these and save them in a standard file format. I don't know much about the stat mech / particle based side of things, but if you're using paraview or visit or something, check out their supported filetypes. If literally all you want to be able to do is save and load matrices into your own program, that's trivially easy. 4000x200 is relatively tiny, you can just save it in a CSV if you wish. Or there's the boost::serialization library if you want to be a bit more sophisticated (I use this, and it works nicely with Eigen matrices.)
There are always alternatives. E.g., ??= is the same as #, so you can use that if your keyboard lacks it.
I missed that.
It says it's a private company. What does 'compute platoon' mean? The comparison with CUDA is a bit surprising (and confusing). I'd never heard of OpenCL being compared with CUDA and described as being so different.
Army, in the sense that I can't think to a single company (let alone with no hardware stake) investing more into it. And considering they are making opencl \*tensorflow\* a thing.. I guess that *is* something? And I don't think the key word is "different". Just partial if any. 
There's no technical reason why C arrays (and native types in general) couldn't have methods. In plenty of languages, `1234.foo()` is valid syntax
&gt; that c-stream will get automatically flushed on "\n" Right, so `endl` flushes twice for every newline instead of once. Even if the second flush has nothing buffered there's still likely measurable overhead.
&gt;you'd think people would at least test their code even one time before posting it online... Testing isn't my hightest priority either. My thinking is that as the C++ Middleware Writer becomes more popular, I'll have more resources to help with that. &amp;#x200B;
performance is the whole point here. why would you put the programmer into a position to trade convenience vs. performance, when there is no need.
Implementing (a == b) as !(a &lt; b) &amp;&amp; !(b &lt; a) is a horrible idea, and not only because of performance. &lt; is good for things like sorting: say, in case of case-insensitive comparison "Ab" and "aB" can be "equivalent" - we don't really care which one comes first in a sorted list, but that does not mean that the strings are actually equal and we should access "Ab" when "aB" has been requested or vice versa.
Implementing `a == b` as `!(a &lt; b) &amp;&amp; !(b &lt; a)` might be semantically correct, but it's pretty inefficient - and there are almost certainly better ways to do it. And the more types do it this way, the more exponentially worse it gets. Consider something like `vector&lt;string&gt; a`, what does `a == a` actually do? You'd have to walk the whole thing twice, once for each comparison. But then each comparison itself would have to walk each `string` twice too. So you're effectively walking each `string` four times? That's pretty bad. This is why something like Boost.Operators doesn't work like that - it can give you `&gt;`, `&lt;=`, and `&gt;=` from `&lt;`... but you need to provide `==` to get `!=`. Generating all six comparisons from a single function has precedence in other languages - I'm not sure there's precedence for generating 5 comparisons from `&lt;`. There are other advantages to `&lt;=&gt;`, like being able to `default` it so you don't even have to write `&lt;`, and allowing you to write a single function to do mixed comparison (although a hypothetical generate-everything-from-`&lt;` could have done this as well). More interesting is the use of `&lt;=&gt;` in [P0732](https://wg21.link/p0732) to allow for non-type template parameters of class type. I'm not sure how simply generating from `&lt;` would have led to this ability - even if this wasn't at all part of the motivation for `&lt;=&gt;`. 
You write one operator and you can automatically generate &lt;, &lt;=, &gt;, &gt;=, and !=. With your solution you not only have to write &lt; and &gt; but they have to be consistent with each other (which is very easy to get wrong).
I'd argue that's because there's nothing in C++ 14 or 17 that's *remotely* as fundamental to the more "modern" language style as what changed in C++ 11. Yes, 14 and 17 refined and added nice new features and libraries, but the code I wrote with either C++ 11 or C++ 17 look vastly more similar to each other than what any C++ I wrote before C++ 11. I think it's just a recognition that C++ 11 was something of a watershed moment for the language. I agree that it's a stretch to call RAII or strong typing "modern". Rather, it should just called "best practices" for C++ programmers. They were part of the language from the start for a reason.
You don't mention -- and perhaps overlooked -- that the spaceship operator can also \`= default\`, allowing many custom types to be comparable with no code at all. And, as mentioned, more efficiently than combining and inverting \`&lt;\`.
Of course you could ovverride equality, it just the default. So by default you only need to implement one, and occasionally 2, and almost never all of them.
I mentioned this exact case in my post. I am proposing this as the default which you could override. 
I still don't think his addresses the main point. Of course you would usually want to implement equality as well, this is just the default. So why is implementing three way better then = and &lt;?
Why couldn't default be added to the existing operators?
Sure, but then three way isn't going to help with that either, and your type will not work with standard library algorithms.
Your right, so override it when needed. How does three way make this case better?
Why is writing one function potentially better than writing two functions?
I think you're either ignoring/undervaluing the convenience of only having to write one function, or ignoring/undervaluing the convenience of how easy it is to right that one function, or both. Let's write spaceship for `pair&lt;T,U&gt;` and `vector&lt;T&gt;` (assume that `T` and `U` are comparable for simplicity: template &lt;typename T&gt; using comparison_t = decltype(std::compare_3way(std::declval&lt;T const&amp;&gt;(), std::declval&lt;T const&amp;&gt;())); std::common_comparison_category&lt;comparison_t&lt;T&gt;, comparison_t&lt;U&gt;&gt; operator&lt;=&gt;(pair const&amp; rhs) { auto c = std::compare_3way(first, rhs.first); if (c != 0) { return c; } return std::compare_3way(second, rhs.second); } comparison_t&lt;T&gt; operator&lt;=&gt;(vector const&amp; rhs) { auto sz = std::min(size(), rhs.size()); for (size_t i = 0; i != sz; ++i) { auto c = std::compare_3way((*this)[i], rhs[i]); if (c != 0) { return c; } } return size() &lt;=&gt; rhs.size(); } How would you write all six comparisons your way? (Note: `compare_3way()` is needed to work for those types that do not have `&lt;=&gt;`, but will call `&lt;=&gt;` if possible).
i think you would need to implement 2 in most cases. and i don't see the downside. &lt;=&gt; is easy to understand, and to integrate into the language without introducing significant complexity to either hobbyists or expert library writers. but clearly you have given this more thought than i have. but then you should be able to more clearly state why a new operator is bad and why relying on existing operators is good. &lt;=&gt; makes intuitive sense. assuming you had the burden of giving a rationale and not Herb Sutter, what would it be?
Replacing '==' or '!=' with combination of &lt; and &gt; is not just bad from the performance perspective. It is incorrect in general. For example there is no guarantee of equality between a and b of !(a&lt;b)&amp;&amp;!(b&lt;a). The very first obvious example where this would not work is NaN for a and any float for b. This code b will produce 'true' for any combination of NaN and number since any comparison between NaN and non-NaN results false.
Just to clarify, my intent is not to argue that this way is superior, but to understand what is compelling about three way. I am open to the possibility that there is a big idea I am missing. I am not familiar with some of those C++20 features, and this isn't generic enough, but here is a sketch: ``` operator&lt;(pair rhs) { if (first &lt; rhs.first) { return true; } else if (rhs.first &lt; first) { return false; } else { return second &lt; rhs.second; } } operator=(pair rhs) { return (first == rhs.first) &amp;&amp; (second == rhs.second); } operator&lt;(std::vector&lt;T&gt; rhs) { size_t size = std::min(size(), rhs.size()); for (size_t i = 0; i &lt; size; ++i) { if (this-&gt;[i] &lt; rhs[i]) { return true; } else if (rhs[i] &lt; this-&gt;[i]) { return false; } } return size() &lt; rhs.size(); } operator=(std::vector&lt;T&gt; rhs) { if (rhs.size() != size()) { return false; } for (int i = 0; i &lt; size(); ++i) { if (this-&gt;[i] != rhs[i]) return false; } return true; } ``` 
Oh ok, that makes sense. I agree its compelling to have a default right now since there is none.
If you define operator &gt; as something else than comparison you are not looking to use stl algo. Just syntactic sugar. You have 3 different operators for which you can define totally unrelated behaviour. 
&gt;wouldn't Ab be equal to aB under that equivalence relation *Equivalent* for display purposes (e.g. sorting), not *equal* for access. Picture a list of entries displayed to the user. Could be files in a directory or tables in a database, whatever. It seems logical to put similar things together, so you might want to sort them not only in a case-insensitive manner, but *linguistically* (e.g. [ignoring diacritic, symbols and punctuation characters](https://docs.microsoft.com/en-us/windows/desktop/api/stringapiset/nf-stringapiset-comparestringex), with [Unicode normalisation](https://en.wikipedia.org/wiki/Unicode_equivalence#Normalization) and other crazy stuff like 'Æ' == 'AE' or 'ß' == 'ss'). Your comparison operator could be advanced enough and take into account additional character weights etc., keeping the relative order between 'a' and 'A' (say, uppercase first), or it might be simple enough and just do `return StrCmp(Normalise(Upper('a')), Normalise(Upper('A'))) &lt; 0;`), effectively considering them equal. For sorting that's not really important - they will stick together anyway. But at the same time all those entries are completely different. If you define your "equal" as "not less and not greater", you might delete "Encyclopædia" when the user hit 'Del' on "Encyclopaedia". That probably won't make them happy. Actually, you can create directories like AA, AE, AF **and Æ** in Windows Explorer and see for yourself.
&gt; the whole point here. &gt; Source? 
&gt; (a &lt;= b) &lt;=&gt; !(b &lt; a) This one (and some others) is not true when floats and NaN are involved.
I would add the (controversial) caveat that for GUIs, Qt with its memory model (for the UI code) is still the best way to go. Extrapolating from this, `new` is OK so long as the resulting memory is managed by some library and not by you. It's `delete` that I would consider a warning sign.
How does this compare to DDS?
This whole thing sounds like the same argument applied to 'auto' and lambdas. There are significant benefits to making the easy thing the best thing.
The problem with automatic downloading of dependencies is that it tends to interact badly with system versions. Wherever possible, you should be dynamically linking to a system install of any dependencies. This way, when bugs are fixed in those libraries, users can update it *once* and everything picks it up.
Probably because the hate on GLOB seems to be contagious but barely anyone brings forward a reason as to why. Other than "new X doesn't Y if you don't Z", which is barely different from "new X doesn't Y if you don't add manually and Z".
Most libraries I use aren't system libraries though. Some are even just header only things from github.
System wide installation doesn't mean system library. With the very small header only libraries, vendoring is an option so long as they are kept up to date, but for anything non-trivial, one canonical copy per system should be preferred. If you ship or download your own copy of libraries, users will almost certainly fail to keep those dependencies up to date. It's even worse if you actively prevent them from doing so by fixing dependency versions.
That is the whole point of systems like npm though..
That's the *problem* with systems like npm. If you have 10 different applications installed, are you going to keep track of all the recursive dependencies and update the packages for each applications when necessary? Probably not. Are you going to update them regularly? If you're anything like me, again probably not. And you probably have a lot more than 10 applications installed. I'll run a system update at least once a day. Anything I manually installed from source only gets updated when I remember (usually when there's a new major version), but dynamic linking means they're always using the latest version of dependencies. A package manager that only installs each package once, globally, and dynamically links to this goes a long way toward solving the problem. Then the question is 'Why not include packages in other languages?', 'Why not ship binaries?', 'Why not use it for OS updates?' Congratulations, you've invented the system package manager. And for small, possibly header only, utility libraries, we already have a de facto standard, vetted, repository where you don't even have to list your dependencies, just include the headers and link in the necessary shared libraries. It's called Boost. Maybe it's a little too strongly vetted (and I have no idea why range-v3 and fmt aren't in it), but that's just an argument for a `boost::contrib` or similar.
And as a user, I don't want you self installing anything I can install systemwide. That's just begging for your application to be using outdated (and potentially insecure) versions of all your dependencies. Generally, in the C++ world, backwards compatibility is very important, so if you target an older version, you shouldn't see any problems on a system with a newer library version. On languages with package managers on the other hand, their very existence seems to encourage breaking backwards compatibility without giving much thought to it. Pick your dependencies, think carefully about availability (which probably means you sound prefer the standard library wherever possible, and boost next, unless there's a very good reason) and support (i.e. whether bugs will get fixed in a timely manner) and write your CMakeLists.txt. If you want to be nice to your users, list what the dependencies are, but otherwise leave it to them and distribution packagers to sort out dependency resolution. I am aware that this makes installation in Windows or macOS very difficult. In both cases, the standard is to install pre-built binaries so just go with that. The nice thing about dynamic linking is that you can still ship your own copy of DLLs or SO files. Similarly, supporting RHEL or Debian Stable might be difficult. Appimage / Flatpak can be options here.
Yeah I don't want that. Doesn't work in reality and you're completely ignore important points. It's this type of mindset as to why using c++ is a pain in the ass to use. We'll just need to agree to disagree.
Someone *is* forcing me. If I want to use what you've written, I'll have no choice but to use this package management system. Now if you're the only one using what you write, there's no problem, but then you can just install the libraries you need and move on. How doesn't my suggestion work in reality (bearing in mind it's how things are done know, and how they have been done for a long time)? What important points am I ignoring?
&gt; NaN &gt; C++ Pick one.
The solution is called `std::unique_ptr`. And even for GUI I really cannot say good things about my experience with Qt. Stuff that should work without question like storing member-widgets by value result in double-free-errors at runtime, when they work GREAT with gtkmm. The signal-slot-implementation that returns false (for which no example in the official documentation EVER checks) if you try to connect a signal to a slot whose IDENTIFIER does not exist in the entire codebase. This is in spite of the fact that they require that weird MOC with it's RIDICULOUS limitations that could easily check for it. BTW: In gtkmm attempting to connect unfitting functions, resulted in compiler-errors in C++98. Allocating `new` should at the very least be deprecated, as `malloc` and placement-`new` do everything you will ever legitimately need.
Can someone tell me the difference between fabs(),fmod() and mod() opertor?
You can only use unique_ptr if you own the object. You don't own the Qt Widgets you create, the parent widget does, to avoid deleting things that are still visible. Here the double free if you store it on the stack (which also requires that you own it). With signals, if you use the new (modern C++) style `connect`, you do get a compile error.
I know that this may be out of context but................
Yeah, I agree that vector is USUALLY the best structure - especially when your alternative is an array. But, there are situations where that just won't do - the fact that it has to be contiguous memory space can hurt, etc. &gt; Also this is not a C++-related discussion since "BTree" is not part of the standard. I was going to post this in /r/programming, but they don't allow text posts. I figured /r/CPP would get a kick out of it more than, say C#... because in the C# world, we often don't roll our own datastructures, but in CPP, we might have to.
&gt; I am open to the possibility that there is a big idea I am missing. I am not sure what you're looking for. If you're looking for an argument that `&lt;=&gt;` is as transformative to C++ as `auto` or lambdas, then it's simply not. Otherwise, you're writing twice as much code, that's probably repetitive and possibly less efficient. Note that your `pair::operator&lt;` could do up to 3 comparisons whereas mine does up to 2. And this accumulates, so your `vector&lt;pair&gt;::operator&lt;` could do up to 6 comparisons per element whereas mine still does up to 2. Also, it's not like `&lt;=&gt;` prevents you from getting early exit. It's just that I don't need to duplicate the logic to do so: bool operator==(vector const&amp; rhs) { if (size() != rhs.size()) return false; return (*this) &lt;=&gt; rhs == 0; } bool operator!=(vector const&amp; rhs) { if (size() != rhs.size()) return true; return (*this) &lt;=&gt; rhs != 0; } 
I've always had a fondness, though no real use, for [Fenwick Trees](https://en.wikipedia.org/wiki/Fenwick_tree) and [Skip Lists](https://en.wikipedia.org/wiki/Skip_list). One cool data-structure that I use, and call Jagged Vector for lack of a better name, is a memory-stable equivalent of a Vector. Its two main operations are: - Index: O(1). - Push Back: O(1) amortized, memory stable. And it can be made wait-free, if limited to those operations. The structure itself is relatively simple: - An array: `std::array&lt;T*, N&gt;`, with N typically 8, 16 or 32. - Where the first `T*` reserves space for a power-of-two number of elements (for easy division/modulo) passed by user. - And each subsequent `T*` reserves space for as many elements as all previous `T*` combined, giving a progression factor of: 1, 1, 2, 4, 8, 16, ... If it is to be made lock-free and wait-free, then the `T*` need be a `std::atomic&lt;T*&gt;` instead. I picked the name Jagged because of how the structure looks: . . .. ....
`&lt;=&gt;` implementation, or defaulting, causes the other operators to work instantly. Doing the same for `&lt;` and `==` could break existing code. `&lt;=&gt;` return value type carries metaprogramming information about guarantees provided by its order. `&lt;=&gt;` is one function not two. DRY means less eork, less bugs. `&lt;=&gt;` has precident -- from strcmp to the same operator in other languages. `&lt;=&gt;` cannot break existing code. It is opt in. `&lt;=&gt;` is easier to write than both `&lt;` and `==` correctly and efficiently. 
B+Tree for sure.
What a stupid thing. "this is a public building, why am I not allowed to record" This, ladies and gentlemen, is the reason the US is not the leading country in world anymore. Stupid people 
Very nice writeup that clarifies a lot of things beginners might struggle with. I wish there was one of these for more languages...
Skip lists have always got on my nerve a bit. They're just so... ugh!
Am I being detained?
Then you should definitely have a look at [BwTree](https://15721.courses.cs.cmu.edu/spring2017/papers/08-oltpindexes2/bwtree-icde2013.pdf). The basic idea is illustrated in Figure 2.
Well, it’s arguable that getting an incorrect, nonsensical, or correct result from comparing things that make no sense to compare—is all fair game. _”Pray, Mr. Babbage, if you put into the machine wrong figures, ...”_
Hashtables (e.g. `std::unordered_map`) because of amortized O(1) lookup, insertion, and deletion. If you need these operations and don't care about traversal order, some kind of hashtable is usually the way to go.
Your second point isn't listed in the comments but was the substance of his edited quote. Adding metaprogramming to individual operators would possibly break code that assumes operator&lt; returns bool and would require duplicating it consistently leading to the same problems today with not knowing if OPs examples are valid or not.
Please, spellcheck your blog posts. 
&gt; What would be common use cases for it though? I'm trying to think of a slot where it would fit in but my brain fails me at the moment. I have used it under two different circumstances: - for the memory stability of its elements. - for the memory stability of its segments. The memory stability of individual elements is interesting for data that is referenced throughout the application, possibly from different threads. A `std::vector&lt;T*&gt;` (or other smart pointer) would be a less efficient substitute for this use case, as it would involve separate memory allocations, with their associated meta-data overhead in the allocator. And passing indices and only obtain a reference temporarily does not work in multi-threaded applications. The memory stability of the allocated segments, instead, makes it possible to implement concurrent data-structures. The main application I've toyed with, but have not used in production, is to implement a lock-free open-addressing hash-map on top of this. The main issue with many lock-free data-structures in C++ or other GC-free languages is that it is difficult to guarantee that a piece of memory is no longer accessed and can be safely released. Yet, for a hash-map, growing the underlying array is necessary as the hash-map grows. The Jagged Array/Vector neatly side steps this issue by being a memory-stable dynamically growable array; so one thread can extend the array while others still access the previous segments without any coordination. How to distribute the elements, however, is an *hum* interesting problem, best left as exercise to the reader ;)
What exactly do former Algerian heads of state have to do with c++?
Thank you for the explanation! I'm still wondering whether I could use this to replace a std::vector to provide a linear array to help things to stay in CPU cache (I've been dicking about with this Entity-Component-thingy for a bit) to lessen the cache misses. I think this might just be the ticket.
I always thought AVL and Red Black trees were conceptually cool.
This user seems to be [blessing many subreddits](https://www.reddit.com/user/ivonodi) with "links to something".
&gt; I wish there was one of these for more languages... A few more resources on the interoperability between C++ and other programming languages (focusing on foreign function interfaces): https://github.com/MattPD/cpplinks/blob/master/interoperability.ffi.md 
I really like the union-find data structure, since its operations run in amortized inverse ackermann function of n, which is just a hilariously slow-growing function. It's amazing that something like that actually arises from an actual practical data structure.
Hi Jondo, I am working on the performance comparison against a commercial DDS product and will publish the result soon. Just a hint, on my test environment, the round trip latency 50% data is 105us, and the top 1% data is 59us. Dividing that number by 2, u have the end to end data.(53us and 30us). In the meantime, you are welcome to run the test on your platform - no license needed. The command name and options can be found here: https://bitbucket.org/hmbd/hmbdc-rel/wiki/Home Stay put!
Yeah, that makes a lot of sense. If you're using ECS or similar you'd have an idea of how many entities you'd have in flight at any given moment and could command the array to make sure we've good to go before we begin.
&gt; You can only use unique_ptr if you own the object. You don't own the Qt widgets you create, the parent widget does, to avoid deleting things that are still visible. Hence the double free if you store it on the stack (which also requires that you own it). Which in no way contradicts my statement that the design of Qt sucks and is the antithesis of modern. &gt; With signals, if you use the new (modern C++) style connect, you do get a compile error. I've actually read about that, and it did in principle exist back when we used it, but at least then all the documentation we locked at still presented the old ways. (I haven't checked since, as I learned during that project that Qt is just an epic design-fail on every single level.) And this really isn't everything I loathe about it. It's naming conventions are completely different from the correct ones (stdlib-naming-conventions that is), it vomits all it's stuff into the global namespace, writing a library that makes use of GUI is obviously not an intended use-case, easily being able to introduce weird segfaults in the static destructors (but only about 35% of the time), so good luck debugging that. It's containers use `int` and `unsigned` as index-types, so good luck with using `std::size_t`, aka the type that every sensible library uses. We quickly learned not to touch anything from Qt that wasn't a HARD requirement to come from there. In the end we managed to produce working [software](https://github.com/opencv/opencv_contrib/tree/master/modules/cvv) that was accepted into the contrib-repo from opencv (main-repo was denied because of our use of C++11), which is quite a good result given that we were six third-semester-students who (for the most part) had never before participated in collaborative software-development. Still, everyone of us ended with a firm dislike of Qt. 
I partially agree on the memory model, though it's one of those things that you can't really change once it's set. The golden rule in C++ is that backwards compatibility is absolutely paramount. It's the one thing that sets C++ apart from still the other 'better C's. As for naming, snake_case was an arbitrary choice for the STL. Personally, I don't like it, and use CamelCase for my own code. When you use 80 column lines, the underscores start to be significant. Qt also predates namespaces, so backwards compatibility means it is to be in the global namespace. The initial Qs should prevent any conflicts though. As for writing a library that uses it, all of KDE Frameworks is built on Qt, so it clearly is designed to be used like that. size_t *is* unsigned int, and this use of unsigned is generally considered a mistake, so the STL is no better here. I agree that you're better off using STL containers wherever possible though.
Thank you, switched to using `spec` directly and added the license.
Heaps and other such implicit data structures always have something elegant to them.
``` std::string &amp;&amp;fmt(std::string spec, ArgsT &amp;&amp;... args) { _fmt(spec, 0, std::forward&lt;ArgsT&gt;(args)...); return std::move(spec); } ``` It returns dangling reference and that move at the end prevents copy elision.
Just revert that commit https://github.com/codr4life/snabl/commit/8367b94f6564d4be552ae6a7d4dc17a8ced4b0b3 :P
Not until I understand why it's a bad idea. Just saying something doesn't make it so, I'm still not convinced you know what you're talking about. No offense :)
&gt; Just saying something doesn't make it so, I'm still not convinced you know what you're talking about. No offense :) Here's a hint: when you ask for a review, don't be an ass. Rvalue references are just like lvalue references. Just imagine replacing the return type with `std::string&amp;`. &gt; the reason the code seems to be working is because it's undefined behaviour that happens to work on your machine. It fails on mine.
Rvalue reference is a plain reference with extra information that life of the object is very near the end. So returning `string &amp;&amp;` from local `string` returns dangling reference because on caller side the function already destroyed all local variables. Explicit calling `move` could prevent compiler deduce about origin of variable and that could stop [return value optimization](https://en.cppreference.com/w/cpp/language/copy_elision).
Like stated elsewhere, I ran the code through Valgrind like I always do and it didn't say a peep. But I guess this problem only shows up when the calling side is attempting to move the value. `string_view` is a good idea, that's also fairly new to me so I'm still warming up to it. No escapes yet, but trivial to add. Aight, thanks, I'll have a look. From my experience, the risk of mismatching spec and arguments outweighs the need for dynamic formats.
Fixed, thanks.
So asking for a review means I have to swallow whatever comes back without questioning? How is that supposed to lead forward? I was just being honest, I trust my own experience more than any random internet code ninja. Got it, thanks. 
Got it, thanks a lot.
&gt; So asking for a review means I have to swallow whatever comes back without questioning? No, but 1) be kind, and 2) look it up. A simple search for "rvalue reference return" would have given you plenty of information. By all means, trust your experience and distrust ninjas, but do your homework.
I have, and I am; and it's still perfectly ok to ask questions and question answers. The information out there is not exactly crystal clear if you ask me. Anyways, all is well, on with the show.
Why should `size_t` be `std::size_t`?
Alright. I always wondered what was the deal with `size_t` vs `std::size_t`.
These fail: fmt("%%0"); // not escaped fmt("%%%0", 1); // throws I won't look for further bugs.
I need this specifically for cmake 3.x, not 2.8.
See, expectations, not bugs. There's a difference between trying to help and finding faults. One takes effort and leads somewhere, the other doesn't. Your previous message was of the former kind, this one of the latter. If you still can't see it, that's ok. It will happen when it's supposed to and everything is forgiven and released.
Cmake 3.x is in the epel. sudo yum install epel-release sudo yum install cmake3 Then run ccmake3
To name a few broad categories that were difficult for me to understand at the beginning of learning c++: - Templates - template functions - template classes - Inheritance and polymorphism - difference between inheriting publicly or privately - the order of object creation when classes are derived - algorithms - how to use the existing ones effectively - how to write your own algorithms. 
I have cmake3 installed and the epel-release, but couldn't find ccmake. I just solved it by yum installing cmake3-gui. Being a noob sucks so I really appreciate your help and quick reply! I ended up going with a different path this time, but it's answers like this that make it easier for noobs to stay motivated. Thanks man
Thats odd. I’ve think ccmake is in the cmake3 package. Either way.... glad it’s working 
&gt;Both languages guarantee that these types are laid out as two consecutive objects of their base, the first for the real part the second for the imaginary part.
Hashmap, its always a hashmap. Have an interview, most of the time the answer is hashmap...
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9ajue3/ccmake_on_centos_7/e4w6mg8/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
+1
But you're losing at least 2 cycles to process the longer file name. You need ".h" for best performance.
Initialization could use a nice graphic to clear that up. Something to sort of sum up [https://accu.org/index.php/journals/2379](https://accu.org/index.php/journals/2379).
Pretty sure disk access time for reading the header file would be far far far greater than that. And the time for lexing, parsing, preprocessing, generating code, optimizing the code, linking etc. In the grand picture of a c++ build , the two cycles ( not completely convinced about the two cycles though) is irrelevant. Remember Donald Knuth's words. "Premature optimization is the root of all evil (or at least most of it) in programming." 
When to use const. What const means in different places. 
Definitely pointers! I tutored for a class that dealt with C and introductory C++. How to handle raw memory was definitely one of the trickier points. Stuff like: * Why does a function that initializes a variable take a pointer, but a function that initializes a pointer take a double pointer? * What's the difference between an array on the heap and an array on the heap that contains pointers on the heap? How do I free up either of those things? * Why does reassigning a pointer on the heap create a memory leak? * Etc. A diagram with one region being that stack, the other being the heap, and then boxes representing variables and arrows indicating "pointing" really clarified a lot of this stuff.
Might as well throw in preprocessing in the mix too! It's definitely key to understanding why declaring a variable in a \`.h\` file and then including said file in multiple \`.cpp\` files causes a \`multiple definition\` linker error, and why the compiler didn't catch such a thing.
I honestly don't get why pointers are difficult for people.
SQL database :p Takes care of difficult stuff like persisting stuff to disk and making sure it's persisted, WAL, transactions that can be rolled back, etc.
Value initialisation, default initialisation, list initialisation, aggregate initialisation, zero initialisation... Yeah this caught me out recently. Still bitter about it.
Maybe you are programming for too long? After programming 10+ everything seems easy. 
I understand rvalue references like this: its a reference that allows you 'steal' its content from original source, nothing else. Its just a kind of permission and nothing is magically 'moved' 
[This](http://itscompiling.eu/wp-content/uploads/2016/05/value-categories.png) one? 
I personally have always used #pragma once and never had to deal with that in my 4~ years of C++. Yes, I know it's not part of the C++ standard however I don't care because it works on every compiler I've ever used so it doesn't matter.
If you didn't guess, it was meant as a joke. I know that it wouldn't make any significant difference. I mean **two *whole* cycles** when compiling? Optimization of the century!
I think the main problem is that they're called "pointers." To me, those diagrams with arrows pointing from one place in memory to another never made sense. They should simply be explained as "addresses," where operator* is a function that maps from that address to an object that lives there. Here, another problem is also declaration syntax and *p not looking like a "function call" to a beginner. You also add the tradition of sticking * to the right, and all things considered, I understand why beginners find it confusing.
A regular reference is a reference that can bind to an lvalue (if non-const) and both lvalues and rvalues if const: void f(Foo&amp; arg); // bind only to lvalues void f(const Foo&amp; arg); // bind to both lvalues and rvalues An rvalue reference is a reference that binds only to rvalues: void f(Foo&amp;&amp; arg); // bind only to rvalues The biggest problem people have here is that they don't understand that arg itself *in all three cases is an lvalue*. I.e. in the third case, if you pass arg onto another function or similar, nothing is automatically moved. You still have to `std::move` it explicitly.
Great list of C++ points! Here's some [C++ tutorials &amp; books](https://reactdom.com/cplusplus)
I wrote a new blog post with the separate results for the initialization phase, have a look: [https://www.bfilipek.com/2018/08/searcher-preprocessing.html](https://www.bfilipek.com/2018/08/searcher-preprocessing.html) &amp;#x200B;
Yeah, right :) Anything in particular you had in mind? 
I apologize. I should have guessed it. Cheers.
1. You don't, you use references instead. 2. There is none, because you were using smartpointers. 3. It doesn't, because you were using smartpointers. 4. etc. Honestly, why do people insist in teaching the worst possible bits in the worst possible way? 
Well, #pragma once isn’t a solution for multiple definitions. It would be great to have articles about compilation pipeline (maybe even with constexpr trivia) for beginners.
Raw pointers are still a must for everyone to understand, even if you’re not going to use them everyday.
No worries, it's not always obvious.
Overloads and specialization resolution rules. Type deduction rules.
yeah but then you're blowing everyone's mind who doesn't really have a mental model of memory
You're not wrong, but what is confusing sometimes still is what "in different places" means. As in, pointer to const or const pointer, or both. 
From Effective C++: The const keyword is remarkably versatile. Outside of classes, you can use it for constants at global or namespace scope (see Item 2), as well as for objects declared static at file, function, or block scope. Inside classes, you can use it for both static and non-static data members. For pointers, you can specify whether the pointer itself is const, the data it points to is const, both, or neither: char greeting[] = "Hello"; char *p = greeting; // non-const pointer, // non-const data const char *p = greeting; // non-const pointer, // const data char * const p = greeting; // const pointer, // non-const data const char * const p = greeting; // const pointer, // const data This syntax isn't as capricious as it may seem. If the word const appears to the left of the asterisk, what's pointed to is constant; if the word const appears to the right of the asterisk, the pointer itself is constant; if const appears on both sides, both are constant. When what's pointed to is constant, some programmers list const before the type. Others list it after the type but before the asterisk. There is no difference in meaning, so the following functions take the same parameter type: void f1(const Widget *pw); // f1 takes a pointer to a // constant Widget object void f2(Widget const *pw); // so does f2 ... class Rational { ... }; const Rational operator*(const Rational&amp; lhs, const Rational&amp; rhs); Many programmers squint when they first see this. Why should the result of operator* be a const object? Because if it weren't, clients would be able to commit atrocities like this: Rational a, b, c; ... (a * b) = c; // invoke operator= on the // result of a*b! Such code would be flat-out illegal if a and b were of a built-in type. One of the hallmarks of good user-defined types is that they avoid gratuitous incompatibilities with the built-ins (see also Item 18), and allowing assignments to the product of two numbers seems pretty gratuitous to me. Declaring operator*'s return value const prevents it, and that's why it's The Right Thing To Do. There's nothing particularly new about const parameters — they act just like local const objects, and you should use both whenever you can. Unless you need to be able to modify a parameter or local object, be sure to declare it const. It costs you only the effort to type six characters, and it can save you from annoying errors such as the "I meant to type '==' but I accidently typed '='" mistake we just saw.
And this is key to understanding pointers. When I taught elementary C to freshmen at the university, one of the first things I sketched on the whiteboard before jumping into pointers was a big array of boxes with numbers underneath and inside them, representing variables with their addresses and values. Once I had explained what they were in terms of code, and then drew an arrow from the inside of a box (the value it holds) to the base of another box (the address), the term "pointer" usually clicked.
so - why is string::find() so fast in the last measurement???
I think ```#pragma once``` isn't part of the c++ standard. But most compilers will probably understand it today.
How, exactly, is a "graphic tutorial" going to help understanding how `const` works?
If you don't understand pointers, you certainly won't understand smart pointers or references (which are essentially non-nullable pointers).
Very few of these proposals are good for "an intuitive graphic tutorial with metaphors and diagrams galore". I mean - const correctness? How compilation differs from linking? Overloads? How are you going to draw pictures of these?
I learned C before C++ and I must say that this concept was never a problem as this is about the only thing there is to understand about C.
How std::remove\_if() can change an O(n\*n) algorithm into O(n), and why that matters.
That's of very little consequence. Qt's classes and API is masterfully organized, with minimal abstraction leakage (if any at all), which is a whole lot more important.
&gt; arg itself in all three cases is an lvalue. I.e. in the third case, if you pass arg onto another function or similar, nothing is automatically moved. You still have to std::move it explicitly. Wow, indeed, that was very helpful, thank you very much!
"Discouraged its use" is an understatement given what the docs _actually_ say: "This method is used internally by the C++ Standard Library only. Do not call this method from your code." 
You could and should use raw pointers iff they are non-owning, this is approved and advocated by the great overlord himself.
`east const` solves this problem. I don't use `east const`, though.
iostream.h - the same crap as last time.
you can do `(std::min)(a, b)` if you need to use `std::min` instead of `min` macro, note the braces around function name.
Always use const unless you want to mutate the value. 
I actually I have the same issues when doing minor upgrades, 99% in third party libs which use non concormant code. This comes from years of msvc being non concormant, but I support the current behavior hoping that all libraries both closed and open source start using /permessive- It's about the time! 
You're welcome! It gets even more fun when you have "rvalue references" in templated functions. Sometimes actual rvalue reference, sometimes forwarding reference, knowing the difference and the rule for when it is one or the other...
As spec is a function argument, moving is exactly the right here. But you are right about the dangling reference.
 // read until it arrives at end of file while(file.eof()); uhh ... wanna bet?
RVO will most likely not happen here, because spec is a parameter
That's a really good point. I don't use it either (bad old habits you know?) and most of the codebases I deal with don't use it, so it's kind of difficult to get hang of. And because of this, the problem still persists I think.
It's like OP is asking for even more warnings after having totally disregarded the warnings he already got.
This is so bad on so many levels...
Argument from Incredulity.
Bad advice. `const` disables move semantics.
No, it does not. See `mutable` keyword. Also, when dealing with pointers or references to const, there is `const_cast` and pointer/reference aliasing.
This is crap.
&gt; Now we have some legacy code with bad test coverage that used seekpos(), and what is worse, explicitly ignored C4996 warnings which are emitted in case using deprecated features. I'm not very keen on VS, but this is the most popular ignored warning I ever see. The problem is that multiple (perfectly conformant) standard library functions are marked as unsafe/deprecated and MSVC encourages to use more safe versions which are non-standard. This led many people to ingore/disable this warning.
They are used in implementation of all STL (unordered)sets/maps in all 3 major implementations.
Move does mutate the value so no const here.
- value vs move semantics + references - `const` - pointers (raw and smart) + RAII - iterators - operator overloading guidelines - templates (surprising facts such as "overload resolution is after type deduction") ___ To the OP: Are you making some guide? I would be interested in it as I had already started something similar (see my flair).
I’m thinking about it! It’s been highlighted to me that I might be good at putting things in layman’s/intuitive terms, so it’s just something I’m considering. Could also help me learn, too.
It's now always obvious, especially for beginners. For example, I have seen many times people making return value form a function `const`. Then defining the function, there is apparently no move semantics involved, so they think it is a good idea to make return value const. But move is likely to happen in the caller just after the function call.
To be fair, you can disable all of the more peculiar warnings with macros. *\_CRT\_SECURE\_NO\_WARNINGS* disables the ones about "more secure functions" being available.
*std/string\_view.hpp* #include &lt;experimental/string_view&gt; namespace std { using experimental::string_view; } &gt; [Unless otherwise specified, the behavior of a C++ program is undefined if it adds declarations or definitions to namespace std or to a namespace within namespace std.](http://eel.is/c++draft/namespace.std#1.sentence-1)
That's a very hot topic at my company too. Let me tell you about my recent experience, I think it will be useful for others. Some months ago, some teammates have accidentally installed a minor update of VS that was "unplanned". We were all on 15.7.1 and a few people upgraded to 15.7.5 - that was not "approved" (planned) - because they thought it was ok to install a minor update. One person, actually, was still on 15.5 (he spent some weeks on vacation when we all upgraded to 15.7.1) and he just wanted to upgrade to 15.7.1. Alas, he could not avoid 15.7.5 because Visual Studio Installer always pushes the most recent update - that was 15.7.5 at that time. When such people built our projects with 15.7.5 everything was fine. The problems started appearing at run time. I investigated and discovered the cause was an undocumented breaking change. The fix was quite easy but, unfortunately, it would have implied republishing lots of stuff internally. At that time, we could not afford that and we needed to plan this task properly. However, my teammates got completely stuck because they could not work with 15.7.5. They needed to install 15.7.1. How? I thought the **Visual Studio Installer** could do the job. I expected a sort of "version selector". I was wrong: the installer does not let you just choose which update you want to install. It just uses the most recent. And, unfortunately, only the RTM and latest release of Visual Studio 2017 is available for (manual) download. I contacted Microsoft and they replied that the option for customer to download n-1 release is explained [here](https://www.visualstudio.com/en-us/productinfo/installing-an-earlier-release-of-vs2017). Basically, organizations which need to maintain a consistent build of Visual Studio are required to [create a Offline Layout](https://docs.microsoft.com/en-us/visualstudio/install/create-an-offline-installation-of-visual-studio?view=vs-2017) of the version to be installed). This means this is not as plug and play as you can expect, at least from a company point of view. Our IT started supporting this process more than it has done in the past. **The bottom line is**: the Visual Studio Installer has limitations. It will be evolved and our feedback - as customers - is important. In the meantime, you have to protect your company from such problems. You can follow Microsoft's advises or not, it's just important to be aware and take measures.
It solves the problem, but is counter-intuitive, i.e. nobody (or hardly anybody) uses it. `int const * const` is perfectly clear, tough, if you know how to read it.
Perhaps we could collaborate? I have some work already done but I need more content before website could go live. I have a plan but doing stuff together with someone else would greatly help.
Needs more pumpkins?
From use-case point of view: any FFI will use raw pointers. More general: C is still greatest common denominator in terms of abstraction. Any interoperability between runtimes will leak some behavior that better cannot be described without notion of pointer.
Stacks and queues.
isn't `std::string::find` implemented on top of `strstr` - which is super fast and heavily optimized in the current implementations?
It's a define. You can put it in the command line build options
Const expressions
&gt; Structure and union types, have the same representation, as long as they don’t declare function members. (C++ calls these POD, plain old data structures.) I believe the restriction is about \*virtual\* member functions. See also the standard layout concept: https://en.cppreference.com/w/cpp/named_req/StandardLayoutType
Intrusive circular multilists.
&gt; Jagged Vector So what's the practical difference between this and a deque? Is it solely the allocation strategy?
&gt; there are times when you just can't afford to drag dependencies around. Totally agree with that, especially when it's boost - drag in one, you have to drag in everything. But we can all afford to drag in [fmtlib](https://github.com/fmtlib/fmt) :-)
We need a really concerted effort to stop Indian universities from teaching C++ using Turbo C++.
Bingo, that's the one
Like a [Venn Diagram](https://medium.com/@barryrevzin/value-categories-in-c-17-f56ae54bccbe)?
Uhh, that’s not the point of them. You can move out of lvalue references too. You just never had a chance to, because pre-C++11, there was no moving as a language construct nor idiom (other than non-compile-time-checked auto_ptr and such). Moving is useful on lvalues, but if you know that an rvalue reference was bound to an rvalue (it doesn’t have to be unless you take extra steps!!!!!), then you can be sure that moving won’t be unexpected to the caller, as the value falls out of the caller’s scope immediately and automagically. There are generally two ways you can be sure that an rvalue reference is bound to an rvalue: 1. an overload - one taking lvalue reference, another taking rvalue reference, 2. a universal reference that becomes an lvalue-reference or rvalue-reference, depending on what it was passed; of course this is templated code. 
variable initialization and std::initializer_list. It is very confusing sometimes. 
Boost.graph
True. Many people thinks that best C++ feature compared to C are OOP or any other b****sh*t. But RAiI support is the real C++ killer feature!
the #include preprocessor directive just copies the text from the file you included to where the include directive is, that's literally all it does. hence if you #include the same file in two places, the compiler sees it as you literally having typed the same thing in two different places, and so obviously it seems like anything you declared in the included file has been declared twice.
The problem is "I tutored for a class that dealt with C and introductory C++". Teach C **or** C++. [Stop teaching C (when teching C++)](https://www.youtube.com/watch?v=YnWhqhNdYyk)
Thanks for sharing your experience, you're mentioning issues I haven't even thought of yet.
next
&gt; `using namespace std;` I love the idea that this is the *only* thing someone needs to know about namespaces, lol.
Yeah, agreed. I don't want to get into an argument which one is better, but as you said it's not that often that you encounter east const. Also, the core guidelines are [against it](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#Rl-const). So why are both allowed? I dunno but it can be a source of confusion.
&gt;It's always possible however to retain an older toolset (i.e. compiler) or Windows SDK version when installing a newer update. That's what you should stick to, if regressions or changes to undocumented features as specific as this one might affect you. Yes, it is possible to pin the toolset. Usually we first update the IDE and keep the old toolset, an then switch the toolset in a joint effort. However the toolset of MSVS 15.7 and MSVS 15.8 is v14.1, so there is nothing I can pin. `_MSC_VER` now is 1915 and before probably was 1914. Plus deprecating `seekpos()` was done by changing the STL implementation, accordingly the value of `_MSVC_STL_VERSION` was increased to 141. If you know how to do this please let me know.
So this is just `std::vector`, but worse?
I would say there are at least two distinct meanings of const. `const` on a declaration of an object (`std::string const s = "abc";`) makes that *object* `const`. `const` on a pointer or reference means "the referent won't be mutated *via that reference*.
I'm not.
Didn't you just say you ignored the warning emitting by C4996?
Speaking for your self, which is fine :) It depends on the project, couldn't be any other way.
Yeah I didn't like it either, but I just tutored for the class, I didn't make it :/ And I doubt the university department is gonna take much advice from a student regarding syllabi :(
What is the point of this? 
No. You don't get to just declare something not a bug. If this `snabl` of yours is a library, its string formatter is buggy. Say I want to output `%placeholder%` where "placeholder" can be different depending on user's locale (`%name%`, `%όνομα%`, `%nom%`). I cannot do this with your formatter. printf("%%%s%%\n", s.c_str()); // works as expected std::cout &lt;&lt; snabl::fmt("%%%0%%\n", s); // throws You declared `%` as a special character in `snabl::fmt`. Now be a dear and keep it consistent. Either it's always a special character and thus needs escaping with `%%` to get a literal `%`, or it's a special character "whenever you feel like". snabl::fmt("%%0%%1 %0 %1", s); // "%0%%1 s %1" &lt;- this is unacceptable for multiple reasons There's also the hilarious case of more than 10 arguments to format, as a side effect of `char('0'+i)`: std::cout &lt;&lt; snabl::fmt( "%0 %1 %2 %3 %4 %5 %6 %7 %8 %9 %: %; %&lt;", 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233 ); // outputs "1 1 2 3 5 8 13 21 34 55 89 144 233" // "%10" will, of course, yield "10" instead of "89"
Cool, didn't occur to me that you could even do that. I'll have a closer look tonight, but this looks like an obvious step forward from a quick skim.
The hilarious part is that you're actually helping, despite your goals being less than noble and your attitude reeking of ego issues. 
Your flair just taught me about `auto auto(auto auto) -&gt; auto { auto; }`. So now you're a C++ teacher.
What do you think my goals are? I *am* being snarky, primarily because of your adversarial attitude two comments prior, that still continues in this one. But I am also trying to explain to you where you are wrong so that you can be *right*. Seriously, quit that attitude.
No you get of my back before someone gets hurt, seriously. You might want to look up constructive criticism, it's the only kind that leads forward. So you found some bugs, and you feel like that earns you the right to act superior and puke your hatred over me. And it's not ok, it was never ok but it stops here.
But that's not even a valid C++ code.
Making it always return 0 strikes me as a worse change than removing it altogether. If they removed it, your code would break at compile time. Leaving it there with bad semantics makes your code broken in a way not detectable until run-time.
:olaf: 😄
When new features are proposed, they uniformly get "can we make this more verbose?" When new features are in use, they uniformly get "can we make this less verbose?" Inside an always-constexpr function requring constexpr everywhere seems like a bad idea. 
Glad that can be useful to someone. Thanks for raising the issue here on reddit, I think it's a good opportunity to discover how many people are facing similar problems with VS updates.
And now you taught us it's invalid code! See!?
In Glibc, for example, strstr implementation uses some variation of the Boyer-Moore algorithm.
`ghfght t hrthinrt rt hirt hrt h` This is also invalid code. Damn, I'm good at this teaching thing.
&gt; Why did you deprecate and break the function at the same time, why not deprecate it now and break it with the next major update. If you ignore C4996's how would you even have known if it had been deprecated in a previous version?
Whenever I feel like using functional programming would be a good fit for a small problem and I don't have a need for a named function. Mostly I use lambdas with template metaprogramming though.
I don't see how making your own QApplication helps with platforms that don't have Qt. Nevertheless, yes, Qt does require you to adhere to the Qt model where its event loop is in control. You absolutely have a point about unsigned long, I've written my share of buggy code by assuming int was 64 bits long on x64. The STL isn't *by definition* correct, though. The standards committee make mistakes. Uncontroversial ones are vector&lt;bool&gt; and various now deprecated things like auto_ptr. More controversially, iterators and iostreams. Unsigned size_t is something that probably makes sense on 32 bit and lower but with 64 bits, we can sacrifice one for safety. Unsigned isn't a non-negative integer, you can subtract a larger one from a smaller and it will happily overflow.
The same approach is used in Boost Spirit.
More general architecture than just C++, but I think a discussion of composition vs inheritance would be very useful for a beginner, when learning about polymorphism.
Thanks, thats actually a good tip. However, it still doesn't help if you are trying to bridge an embedded vendor platform with some existing C++ libraries that already have your min/max and booleans code all in there. It's all doable and manageable, just a huge pain every time.
Thanks for pointing that out. I updated the code, now it should be easy to read.
I and many other knowledgeable folks are always available in the cpplang Slack. Drop by and someone is bound to give you help. Check around for the proper channel (probably #cmake), or send me a PM.
thanks for your work man.
In C++ Primer 5th Edition, they have... int &amp;&amp;r2 = i * 42; ...as valid code. How is that legal?
`deque` does not promise memory stability of its whole, though you can achieve memory stability of its elements. Most notably, calls to `push_back` invalidate its iterators: the elements themselves do not move, but the "base" vector which has the pointers to the sub-arrays may get reallocated.
Most of the discussion [here](https://stackoverflow.com/questions/1452721/why-is-using-namespace-std-considered-bad-practice) is worth reading. TL;DR: better avoid bugs now rather than try to find them later. `std::sort()` and `::sort()` won't collide,^* but calling `sort()` with `using namespace std` may. ^*&amp;nbsp;[ADL](https://en.cppreference.com/w/cpp/language/adl)&amp;nbsp;notwithstanding
No, no he didn't. He said it clear as day, the legacy code ignored it.
I agree. That doesn't negate the fact that he's working with code that he's stuck with performing incorrect behavior. I don't know why people automatically assume the person asking the question is 100% responsible, especially when they lay out in great detail how it's existing code.
so the implementations are not restricted here, and can use differnt optimizations
But aren't rvalue references not supposed to have a named address, like r2 in this case?
For most Mac, Windows and Linux there is Intel VTune. This profiler also comes with a library usable for custom event markers. You can also remotely connect to a ssh (linux?) machine or Android device. I really liked it if you need to profile something that is not in Windows. I think they switched their license recently and anyone is able to get a license for 30 days for the newest version and is able to reapply for 30 days after each licence ended. So you always need to install the latest version. Otherwise there is the commercial version or student edition.
oh conan is a package manager? Seems convenient! Thanks!
I've been banging on your idea a bit and finally settled on a simplified version of the same strategy where I simply store the converted arguments in the struct. An obvious improvement from my first implementation if you ask me, since the arguments are now much more convenient to work with and there's no need for recursion. https://github.com/codr4life/snabl/blob/master/src/snabl/fmt2.hpp https://github.com/codr4life/snabl/blob/master/src/snabl/fmt2.cpp Thanks again for speaking up :)
I could do that, I guess. Any pointers on how that macro call would look? Thanks!
Yeah, whoever decided to set that warning with non-standard "secure" extensions can go die in a fire. I'm still bitter about that one, many, many years later.
&gt; And I doubt the university department is gonna take much advice from a student regarding syllabi :( I have confidence in you.
TBH, this extension \*is\* part of C11 standard (Annex K), just an optional one that most vendors preferred to not implement, in favor of their own extensions (often predating C11).
Value categories. I still feel very "shaky" reasoning about them. I've developed some intuitive understanding that's enough for me to write my code, but the whole (r|l|pr|x|etc.)value tree is confusing and very unfriendly to the human programmer.
How to write great libraries using just modern c++. Whatever that pulls in should cover all the features that matter the most. Bonus points for project layout and build architecture.
It's not 14.1 for both. [It's 14.14 and 14.15 respectively](https://pbs.twimg.com/media/DkqMpzjUwAAT21L.jpg:large).
Yes, it is! It's a package manager that works with any build system. It's got a bit of a learning curve, but it shouldn't be too hard to get started. I hope you find the SFML package useful.
Btw, would be nice if it was "added by default" for -permissive- switch. Suggesting non-std functions in "strict" mode doesn't make much sense.
This doesn't have to be invalid code. All those words could be macros.
Yes. But OP seems to be accusing Microsoft for the issue which just comes across as entitled
The reference lifetime-extends the temporary, so it does have an address because the "temporary" needs to be stored somewhere :)
To be fair to /u/Brandlingo, I don't think this one was actually annotated with [[deprecated]] before.
Microsoft didn't even support C99 features at that point, and those C11 features were not standard (as opposed to merely optional) in C++.
I suspect there are fewer instances of capital T in the input on that last measurement, meaning `basic_string::find` stays in `memchr` for more of the input.
Does boost actually work correctly with the return 0 behaviour? If so, I'm surprised they need to call it. They could just use 0 directly. If not, then it sounds like boost has been broken by this change. I'm not seeing any upside to it.
Ah, yeah. Gotcha! Thanks for the reply :)
OP says the code is 20 years old. It may not have been a private function when it was first written (I don't know).
Alright, I'll give it a shot. First, if some of my early comments offended you, I apologize. I did not mean to sound superior nor did I want to discredit your work. Few people go as far as organizing and making code available online, and _then_ ask for reviews to try and make it better. Kudos for that. With that being said, some of my later comments _were_ meant to be unpleasant, as a response to yours. At this point, I don't think you can expect much else in this thread. I'd call it a day and move on. Second, you seem to be unfamiliar with technical discussions. I've been around for a while, spent a lot of time on [newsgroups](https://en.wikipedia.org/wiki/Usenet_newsgroup) in the late 90s, early 2000s, then various forums, SO, reddit, etc. Forums for technical discussions, especially programming, and _especially_ C++ (`comp.lang.c++` had a bit of a reputation) are not for the faint-hearted. As programmers, we are concise, terse, precise, sometimes curt or abrupt, but always willing to spend time to help. You've had a lot of man-hours spent on helping you in this thread. When I wrote this: &gt; These fail: &gt; &gt; fmt("%%0"); // not escaped &gt; fmt("%%%0", 1); // throws &gt; &gt; I won't look for further bugs. I had three things in mind: 1. I'll give you a short example that can reproduce the problem. You'll be able to copy them in your test suite, run them and fix the problems. 2. I'm notifying you that I'm done looking for problems. At that point, I had been monitoring your git repo for several hours, looking for changes, to see if you had any misunderstandings. 3. It's also a hint that you have some work to do. In your answer, you said this post was about "finding faults", that it wasn't constructive and that it didn't require effort. First, it _did_ require effort. I spent time looking at your code, finding bugs, writing tests, debugging and coming up with a short test case. Second, I find reporting bugs that way to be constructive. It's easy for you to diagnose them with [MCVE](https://stackoverflow.com/help/mcve) like that. "Finding faults" is what it comes down to. As a programmer, you should be expecting posts like mine. In fact, if your library gets popular, that's what your bug reports will look like (hopefully). Technical forums are impersonal. We comment on code, not on your abilities and not on you. So don't take things personal, because they're not. Learn the conventions and customs of technical forums. We're all programmers here, we all love coding and we're here to pool our resources so we can get better. In any case, I hope you won't get frustrated. I'd be happy to give you a hand again and I hope I'll see more of your library in the future. Cheers.
But what is the point of this data structure?
Boost actually works correctly with the return 0 behavior because they were adding it to other internal values to workaround "can't process files bigger than INT_MAX" bugs in VS2010 and earlier. See https://github.com/boostorg/iostreams/blob/develop/include/boost/iostreams/positioning.hpp#L69
Kinetic Data Structures are pretty boss.
Could we have more similar solutions in the future like `operator+-*/%` that automatically makes the type members behave like *Integral*s?
If you use GLOB the resulting build system won't know when it is no longer valid and cmake has to be reran. It's fine when you are soloing since you will know to just rerun cmake but imagine if you have a large team. Everyone is creating new files all the time. Now each time you sync your code your build will most likely break and you have to rerun cmake. It's a trade off really. You want your build system to know when it's has been invalidated? don't use glob. You want max convenience to detect sources? Go ahead and use it. 
One of the issues pointed out is the need for non-member functions, since primitive types don't have members (there are also other reasons to prefer free functions). The obvious solution to this problem is UFCS \[1\], which would allow treating primitive types as if they were classes with methods (but, naturally, UFCS might create new problems). The proposal to add it to the language \[2\] appears to be dead. \[1\] [https://en.wikipedia.org/wiki/Uniform\_Function\_Call\_Syntax](https://en.wikipedia.org/wiki/Uniform_Function_Call_Syntax) \[2\] [https://isocpp.org/blog/2016/02/a-bit-of-background-for-the-unified-call-proposal](https://isocpp.org/blog/2016/02/a-bit-of-background-for-the-unified-call-proposal)
It is because C++ doesn't clearly delineate classes and structs. I just follow a simple principle - if it is stateful without interfaces, it's a struct. If it is stateful with interfaces, it is a class. If it is stateless, it should be represented with lambdas/templates/constexpr chains.
No, Microsoft is not implementing Annex K, and their implementation is quite different from it. You can have a look at [that here](http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1967.htm#impementations).
So then what is int&amp;&amp; r2 in my example above?
Hey, I know that guy 🙂
Well, the Data Structure itself has no point cos a data structure just organizes and stores the data, what really matters is the underlying principle behind the implementation of the DS. And this post describes the List data structure which is implemented using arrays, hence array-based. The post is a part of an entire series of Data Structure and Algorithms. And the next post is going to be about the pointer based List(aka Linked List). So the final goal is to help readers understand how different implementations can be favorable in different scenarios.
I was wrong then, thanks for the correction. So, it looks like they authored [the initial proposal](http://www.open-std.org/jtc1/sc22/wg14/www/docs/n997.pdf) and were keeping up with it for a while (e.g. by replacing `errcode` with `errno_t`), but not for the final version, eh? Guess, there's some politic struggle beyond the scenes at MS, as usual.
How much updating do you want on stuff that isn't supposed to be used? Does Apple tell people when they change their internal APIs?
why are you telling us that you're being honest?
Why is the default_searcher so much slower than string::find? I would expect it to be a bit slower, but a 2-3X slowdown seems excessive.
You're a teacher too!
So? You have to rerun cmake. What is the problem?
You're a teacher too!
That's what I'd seen! Though it was in PDF form at the time
I'm new to conan, did I mess up? sfml/2.5.0@bincrafters/stable: WARN: Can't find a 'sfml/2.5.0@bincrafters/stable' package for the specified options and settings: - Settings: arch=x86_64, build_type=Release, compiler=gcc, compiler.libcxx=libstdc++11, compiler.version=7, os=Linux - Options: audio=False, fPIC=True, graphics=True, network=False, shared=False, window=True, bzip2:fPIC=True, bzip2:shared=False, freetype:fPIC=True, freetype:shared=False, freetype:with_png=True, freetype:with_zlib=True, libpng:fPIC=True, libpng:shared=False, zlib:shared=False - Package ID: 6cfadfcdefda18d69f64560ab776887b04dbc1bd ERROR: Missing prebuilt package for 'sfml/2.5.0@bincrafters/stable' Try to build it from sources with "--build sfml" 
Do I need to install ninja? sfml/2.5.0@bincrafters/stable: Calling build() CMake Error: CMake was unable to find a build program corresponding to "Ninja". CMAKE_MAKE_PROGRAM is not set. You probably need to select a different build tool. CMake Error: CMAKE_C_COMPILER not set, after EnableLanguage CMake Error: CMAKE_CXX_COMPILER not set, after EnableLanguage -- Configuring incomplete, errors occurred! sfml/2.5.0@bincrafters/stable: sfml/2.5.0@bincrafters/stable: ERROR: Package '6cfadfcdefda18d69f64560ab776887b04dbc1bd' build failed sfml/2.5.0@bincrafters/stable: WARN: Build folder /home/john/.conan/data/sfml/2.5.0/bincrafters/stable/build/6cfadfcdefda18d69f64560ab776887b04dbc1bd ERROR: sfml/2.5.0@bincrafters/stable: Error in build() method, line 130 cmake = self.configure_cmake() while calling 'configure_cmake', line 121 cmake.configure(build_folder=self.build_subfolder) ConanException: Error 256 while executing cd '/home/john/.conan/data/sfml/2.5.0/bincrafters/stable/build/6cfadfcdefda18d69f64560ab776887b04dbc1bd/build_subfolder' &amp;&amp; cmake -G "Ninja" -DCMAKE_BUILD_TYPE="Release" -DCONAN_EXPORTED="1" -DCONAN_COMPILER="gcc" -DCONAN_COMPILER_VERSION="7" -DCONAN_CXX_FLAGS="-m64" -DCONAN_SHARED_LINKER_FLAGS="-m64" -DCONAN_C_FLAGS="-m64" -DCONAN_LIBCXX="libstdc++11" -DBUILD_SHARED_LIBS="OFF" -DCMAKE_INSTALL_PREFIX="/home/john/.conan/data/sfml/2.5.0/bincrafters/stable/package/6cfadfcdefda18d69f64560ab776887b04dbc1bd" -DCONAN_CMAKE_POSITION_INDEPENDENT_CODE="ON" -DCMAKE_EXPORT_NO_PACKAGE_REGISTRY="ON" -DSFML_DEPENDENCIES_INSTALL_PREFIX="/home/john/.conan/data/sfml/2.5.0/bincrafters/stable/package/6cfadfcdefda18d69f64560ab776887b04dbc1bd" -DSFML_MISC_INSTALL_PREFIX="/home/john/.conan/data/sfml/2.5.0/bincrafters/stable/package/6cfadfcdefda18d69f64560ab776887b04dbc1bd" -DSFML_BUILD_WINDOW="True" -DSFML_BUILD_GRAPHICS="True" -DSFML_BUILD_NETWORK="False" -DSFML_BUILD_AUDIO="False" -DCMAKE_POSITION_INDEPENDENT_CODE="True" -Wno-dev '/home/john/.conan/data/sfml/2.5.0/bincrafters/stable/build/6cfadfcdefda18d69f64560ab776887b04dbc1bd' 
That web page is hard to read but I can't really put my finger one why.
Hmm, never met this one before, probably it fits better =) Thanks!
It still has the same semantics. Const on a pointer means you cannot change the value of the pointer i.e. the address the pointer points at, as corollary it means "the referent won't be mutated".
Thanks for posting. You obviously are very passionate about this. &amp;#x200B; Unfortunately, there are some issues with this code, that makes me think that is not native C++, but rather Java flavored C++. &amp;#x200B; First big issue, is that you need to think about the copy constructor. The way you are doing it now will lead to a crash. &amp;#x200B; For example, if I write AList&lt;int&gt; newList(10); auto newList2 = newList; it will crash. You need to decide how to handle copy and assignment. &amp;#x200B; Second issue, is that it is completely non-idiomatic C++. C++ code that writes data structures should follow the standard C++ library in terms of how member functions are defined (I think your remove is most akin to pop\_back) and use STL style iterators. &amp;#x200B; Third, I disagree with the premise that you should hide 2 vastly different complexities behind an virtual interface. You talk about implementing List with both arrays and linked-list. They are fundamentally different structures with different tradeoffs and attempting to change from one to the another at runtime via base classes and runtime polymorphism is bound to end in grief. &amp;#x200B; I love how you are so excited about algorithms. However, learning idiomatic C++ will make your code much better. Writing Java style C++ will lead to pain and frustration. At a minimum you should be very familiar with value types, the special member functions, and with the standard library algorithms, iterators, and collections. Once you learn these concepts, a whole new world of looking at data structures and algorithms be revealed. I am sure many people on this board can recall when they learned about the STL and how it changed how they looked at data structures and algorithms. &amp;#x200B; Looking forward to your future posts and code. &amp;#x200B; &amp;#x200B; &amp;#x200B;
Delete this and go your own homework. The school year just started, it gets a lot harder than this.
Format code for Reddit by putting 4 spaces in front of every line. Or use gist or pastebin or something.
=&gt; /r/cpp_questions
Your first messages show a lack of tact and seem smug (even if it wasn't intentional). That's why OP got angry, and it's understandable.
One of our teams had to hard-code VCToolsVersion env variable to 14.14.26xxx (don't remember the exact number) of the compiler, such that folks who accidentally installed 15.8 are sticking to the 15.7 compiler (14.14). This, because of https://www.reddit.com/r/cpp/comments/90noeh/c_binary_compatible_api_abi/e2vyack/ https://developercommunity.visualstudio.com/content/problem/274945/stdmake-shared-is-not-honouring-alignment-of-a.html Basically we had precompiled a bunch of libraries (Qt, others), and use the in this way. With this change, we need to recompile everything, honoring the _ENABLE_EXTENDED_ALIGNED_STORAGE to get conforming behaviour, although it's not clear how some of the SDKs that we use are compiled, for which we don't have source code (though it could possibly be investigated somehow). That to be said, up to this point, cooperation between vs2015 and vs2017 compiled libs was ok. I think there was one or two issues, but this is completely new, where we have to basically move everything over the new version. Still no good response from Microsoft on how to track this easier - e.g. how to make sure that a precompiled lib is compiled one way or another, etc. For example FBX SDK, or various others... 
To the author (/u/notskm) - If you have any experience with VCPKG - how would you compare it to Conan? (Others?) 
https://pastebin.com/djrGJe1R
So... how will you overcome the shortcomings of linked list after the linked list comes in?
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9avpqk/c_class_bug_for_text_adventure_game/e4yl5ox/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I think the automod message would be more useful as a top level comment (Or is it PMed to the poster as well?)
The precompiled version (compiled with) vs2015 *does* work, just not with the aligned storage fix, because there's no time machine to go back to vs2015 and make it honor the extended alignment. (If you set _DISABLE_EXTENDED_ALIGNED_STORAGE, it makes 2017 15.8 work like 2015.)
&gt; It is because C++ doesn't clearly delineate classes and structs. I would say it's very clear, to all intents and purposes, they are the same, but with inverted default visibility, cannot see how they are not delineated. Why I cannot write template&lt;struct T&gt;, while I can write template&lt;class T&gt; is beyond me, but fortunately template&lt;typename T&gt; came along and solved that problem.
Interesting, I was taught that maps were generally implemented with hash tables. The more you know.
@BillyONeal Thanks for the explanation. &gt; Initially I completely removed the function This would have helped with the legacy usage of course, but the deprecation message made finding the Boost patch really easy. So I guess I understand that decision now. Our problem actually is not changing the code. Thankfully you had provided the Boost patch and fixing our own code was not hard. Also I reevaluated all statements to ignore warnings and was able to remove almost all of them, so this had some impact for which I'm actually thankful. The problem is that we now are afraid that something similar might happen, especially that it might hit some of the dark legacy corners which are poorly - if at all - tested. This is aggravated by the fact that this hit us during a release phase. Everybody who had already updated to 15.8 was blocked now because their local build was broken (actually it still is due to problems with the new optimizer and Boost.Serialization). Of course we want to avoid something similar to happen and consequently new update policies have come into effect which freeze the VS version before entering a critical release phase. (we use Scrum-but, but we are a hardware organization so our increments are not deployed every sprint) &gt; What was your code doing with this function? Determine the size of a file which is also relying on the implementation, I'm aware of that. I would assume that this stems from StackOverflow answers like [this one](https://stackoverflow.com/a/16325024/1969455). I'll hopefully replace it with `std::filesystem:file_size()` once with enabled /std:c++17.
Would installing this component give more choices under `Project Properties &gt; General &gt; Platform Toolset`? Currently I can choose 14.1, not 14.14 or 14.15.
There is no problem. You asked for an argument and that's it. You don't care for it then go ahead and use glob.
The extras in cstdio are there to make it better for C++ (instead of C). C code is not the best C++. It is simpler, but also less safe, less elegant (for C++) and more ambiguous. I am of the opinion that the stdio header APIs should not be used in C++ at all, but if you use them (for example, if you have to work in a codebase that uses them), you are better off with cstdio than with stdio.h.
OK, out of curiosity I installed the v14.14 toolset. Unfortunately I still can only select the toolset [Visual Studio 2017 (v141)](https://i.imgur.com/McJJvan.png). So unless there is a way to make use of it this difference is of academic use only. &amp;#x200B;
I like graphs too, you should check out [lemon](http://lemon.cs.elte.hu/trac/lemon).
that will be described in what comes after that and so and so on...
I really appreciate your constructive critique of the post. I'll definitely look into the problems you mentioned. Thanks a ton !!!
Intel® Threading Building Blocks implements this exact data structure and calls it [`concurrent_vector`](https://software.intel.com/en-us/node/506079).
Kangaroos, Skippy-like?
This message means that there is no pre-built binary for your platform. The package creator can create different binaries for several different configurations, but yours is not among them. You can read a bit [further here in the FAQ](https://docs.conan.io/en/latest/faq/troubleshooting.html#error-missing-prebuilt-package). You can inspect which binaries are in the server with: \`\`conan search sfml/2.5.0@bincrafters/stable -r=bincrafters\`\` (append \`\`--table=file.html\`\` for creating an easier to read table in html file)
But as C++ is Turing-complete (heck, even TMP is) it must be possible, by definition, without trying, to implement a `BTree` in C++, so since the sub is called CPP, it's relevant.
Yes, if you want to build from sources, you need to have installed the required build tools in your system, and it seems this package is using Ninja to build. There is the concept of "[build-requires](https://docs.conan.io/en/latest/devtools/build_requires.html)", packages that can contain build tools. There are existing packages for CMake for example. But these are mostly used for "production" builds in companies and teams. For open-source packages in bintray, you are supposed to have the build tools installed.
Unordered ones yes, they have O(1) amortized complexities. Ordered maps/sets are tress which sort by given predicate and have logarithmic complexities.
Actually, I said I had not seen a **convincing** argument (for why it should be in a guideline). Besides the fact, that there a ways to automate that, no one could actually explain to me, why it is better to manually replicate information in the build file that is already available in the source tree than manually rerunning cmake. And for the record, I am working in a team, that uses globbing and I can't remember this ever being a problem (admittedly, our projects are not that big - maybe a few hundred files without external libraries). There are certainly constellations where this make sense, but so far I haven't seen one and thus I wonder why this advice keeps ending up in generall cmake recommendations.
That's why somebody invented `inline variables` feature in C++17!
So there was an undocumented internal API. And you've been expliciltly asked not to use it. And still you did, voiding any possible warranty. And then it stopped working. So why so much rant about it? Just don't use undocumented internal stuff if you want safety, it's UB. Or use it at your own risk (it's a free country) as long as it works for , but don't complain when it stops. &amp;#x200B;
Two serious issues I see Dictating a build directory encourages people to write code that depends on the location of the build directory :) So code will reach into the parent directory with ../.. and get assert files and stuff like that - it encourages sloppiness. I run across this from time to time - were code expects to be build in source/project (and some tools like cquery/projectile) Personally I have my code on a USB drive and then I build files on disk. That forces me to have the two decoupled The second issue is that add_subdirectory for dependencies doesn't scale and breaks for larger projects. First, many projects aren't even meant to be used in that way BC project names and version numbers get overriden. Second is that you will have multiple targets with the same name btwn dependencies (like I think both Eigen and OpenCV define an 'uninstall' target). And third, the biggest problem is when 2 libraries for instance use ZLib and drag in their own versions. Then you get hidden issues with linking and undefined behavior. Dependencies should be handled with a dependency manager like Hunter. I made a long write up explaining all these issues and why you have no real choice but to use Hunter or something bigger like Conan in large projects - please take a look :) https://geokon-gh.github.io/hunterintro.html 
afaik only iostreams have &lt;iosfwd&gt; - and even then they sometimes include &lt;stdexcept&gt; which can be heavy
Understanding the preprocessor is also necessary for avoiding circular include problems, where \`a.h\` includes \`b.h\` which includes \`a.h\` and then you get an error saying the contents of \`a.h\` are not defined. This is a very common stackoverflow question. Headers are not modules. Understanding that it's simple textual replacement (with examples/infographics/diagrams/whatever) explains why header guards are needed, and why circular includes give errors.
Given that I was down-voted, you're not the only one who missed the irony, no problem.
Please no metaphors. They lead to incorrect beliefs about C++ behaviour.
This seems to be quite a crappy build-tool, why doesn't this build-tool then just download the sources, build that component, install it and use it, just get on with it. What's up with this build tool?
Build tools shouldn't download binaries, they should build stuff, from source.
Looks like "not very good", see my other comments in this thread.
Package managers and other tools should allow users to do what they want. Want to build from sources? Add \`\`--build\`\` argument. 
There is a good comparison here: [https://www.reddit.com/r/cpp/comments/8t0ufu/what\_is\_a\_good\_package\_manager\_for\_c/](https://www.reddit.com/r/cpp/comments/8t0ufu/what_is_a_good_package_manager_for_c/)
I would just use virtual inheritance.
That is a valid solution, if you can express your type structure with virtual inheritance and you end up with a similarly flexible and performant program. But templates are a superior mechanism of achieving composability at zero runtime cost. It only **seems** complicated, but the meta-programming is actually quite straightforward.
Anyone thinking that [hana](https://boostorg.github.io/hana/) would have been a natural choice here?
This is discussed in Stroupstrup, The Design and Evolution of C++, 6.5.2. The committee rejected this, because (1) the extension is not safe. A user would be not necessarily aware of the declaration and a compiler has no way of ensuring it. (2) alternatives have not been sufficiently explored. (I know that some compilers generate code that checks for overlap, and then call different function). (3) The extension is mostly effective on non-standard architecture. Hence it should be dealt with in other ways, for example a pragma for these architectures.
Or just don't have that many features in the same class. Remember single responsibility principle?
And for this reason the conan binaries are "mangled" to reflect the environment for which they are build. Take a look to the introduction page on the conan site https://docs.conan.io/en/latest/introduction.html#binary-management It should answer to both your critiques
by default conan tries to fetch precompiled packages from your local cache or from the online repo cache. To force conan build missing precompiled dependencies, use \`--build=missing\` flag when running \`conan install\` command.
I dont know about a graphic tutorial, but the difference between value categories of expressions and the type of expressions would probably be a good thing to explain. Probably with a special nod to explaining that lvalue/rvalye reference are types, and not value categories. Once someone understands this, move semantics becomes very simple and obvious, along with stuff related to binding and lifetime.1
I'm not sure what you're talking about. Conan is a package manager. If you want to build this package, you need ninja installed. Alternatively, you can use a Conan profile that has Ninja listed as a build\_require or the package can be changed to automatically grab Ninja so you don't have to worry about it. &amp;#x200B; I'm not sure what the Bincrafters usually do there. If you want, you could open an issue on GitHub. If somebody else replies, you'll probably just be told to use a Conan profile, though.
As other people have been saying, you can tell it to build from source and it will. The binaries are simply a convenience.
I don't. I use Conan because of its flexibility. In the long run, I think it'll be the one that wins out because of that. I can speak based on what I've read, but I may not be 100% correct. &amp;#x200B; Based on what I've seen, VCPKG is a simple solution to a very complex problem. It'll probably have a lot of limitations as a result. I'm not sure if it works with any build system. Last I knew, building from source was either not possible or severely limited, for example \[citation needed\]. &amp;#x200B; Conan is a complex solution to a complex problem, with far fewer limitations. Even so, Conan is very simple if you're just consuming packages. Getting set up with Boost, for example, is trivial. Add it as a \`require\`, run \`conan install\`, and you're good.
You either need to install Ninja or use a Conan profile that lists ninja as a `build_require`, as others have said. &amp;#x200B; Out of curiosity, what OS and compiler are you using? For most people, I think the prebuilt binaries should be available.
I no longer think CRTP is worth it, especially when moving away from object oriented programming, the premise of designing a class to be interface does not hold anymore. Objects represent features. If I want to have certain functionalities, I'd have several objects rather than several inheritances for my class. In order to make my class communicate with some other API, I'd either design the API to be generic, or use the feed backs from those objects - callbacks, their values, etc. The whole idea of mixin sounds like architecture going out of control. Is there a real-world example where a feature has to be implemented as inheritance?
wireshark
No, that is not i want. I didn't mean a program to analyze packets. I want a cpp program to connect to a server and log whats happening in the background.
yes. [std::enable_shared_from_this&lt;T&gt;](https://en.cppreference.com/w/cpp/memory/enable_shared_from_this). Interestingly, this feature will be used heavily in the upcoming networking TS. I have always found the ability to add features very useful. As to your issues with the API, consider that CRTP modifies the API statically. It is compile time. Classes that inherit from something *is a* something new. Additionally, this has the massive benefit of completely avoiding the virtal table while still being nearly as flexible. There are a lot of ways to think about this technique and its repercussions, but so far, most of them that I can think of are positive after you get around the diamond inheritance issue. 
I get what CRTP does, I just disagree "is A" is better than "has A". Without inheritance and polymorphism at class level would mean you won't necessarily store the object as a pointer, which means you don't worry about lifetime management, and you won't have shared\_ptr in the first place. Diamond inheritance issue is a flaw in the mental model of the architecture, not actually how it is implemented.
$ openssl s_client -connect www.google.com:443
you might want to learn how to use libssl then you can look at my attempt [here](https://github.com/mkn/mkn.ram/blob/master/os/nixish/src/https/server.cpp) if you like you can add your own logging
Sounds like a compiler bug; nothing the library does should be able to cause a broken stack.
Then you were also working around old vs bugs where just casting to streamoff did a bad thing on &gt;2GB files. This certainly isn't a "policy" thing; like I said originally the function just got burninated; putting back this thing that returned 0 was the result of a "fire drill" when we realized just after 15.8 preview 4 that Boost hadn't merged the fix into a release yet :/. Luckily this is the only thing I know of that's this "crusty", seems unlikely to happen again.
Patricia tries are also pretty cool, as they're more compact.
are there benchmarks comparing with intel tbb's flowgraph ? 
Love it! Is there a way to change the default template for a new file/project?
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
**Company:** [Union Pacific Railroad](https://www.up.com/index.htm) **Type:** Full time **Description:** Union Pacific Railroad is currently hiring C++ developers to work on the Computer Aided Dispatching (CAD) system. The CAD system is mission critical to UP's transportation network, operations and employee's safety. Design, develop, implement and maintain new and modified systems utilizing new and experimental information technologies to support the departments of the railroad. These positions require highly motivated, creative individuals with strong technical skills who are able to work in a team to deliver complex solutions within limited time frames. C++ developers are in the technical career path, which is for employees interested in an individual contributor role, who wants to work with other team members to ensure a project's success. The main elements of the technical path include: 1) No direct reports, 2) Heavy technical skills, 3) Heavy teamwork, 4) Heavy client/customer contact, 5) Heavy daily planning and execution, 6) Creativity **Location:** Omaha, NE, USA **Remote:** No **Visa Sponsorship:** No for USA **Technologies:** We use C++ on Linux with a homegrown distributed messaging system. Qt experience is helpful. **Contact:** If interested, you may email [Kelly Risley](mailto:kcrisley@up.com), or apply via [https://up.jobs/job/opening/Sr%20C++%20Developer/Omaha/NE/085448?jsl=39492080](https://up.jobs/job/opening/Sr%20C++%20Developer/Omaha/NE/085448?jsl=39492080)
did you check https://en.cppreference.com/w/cpp/numeric/math/fabs https://en.cppreference.com/w/cpp/numeric/math/fmod and (presumably, since there is no "mod()") https://en.cppreference.com/w/cpp/numeric/math/modf ?
We havn't done anything on this, but we did switch form OpenMP to Cpp-Taskflow in one of our research project [OpenTimer](https://github.com/OpenTimer/OpenTimer). The results show about 20-40% improvement. 
Is there any way of passing data (messages) between the nodes (tasks)?
Thanks, that makes more sense. 
I don't think anyone is or was claiming that "is a" is better than "has a." The reason I brought up "is a" is that you were talking about the API. The "is a" relationship in this case allows you to modify the API by changing what you inherit from at compile time. This behavior is all about static API modification. Design is all about consequences, so claiming something is better than something else without context rarely makes sense. This is no different. The benefits here are mostly avoidance of the virtual table within concept based programming and the possibility of allowing designers to have the ability to create reusable functionalities which are separate from the core data structures. For different people this can have different meanings. I'm sure some of those are negative and some are positive.
The edge between nodes only describe "dependencies" and we do not have explicit means to pass data around. Currently, Cpp-Taskflow works on a multi-threaded environment and the memory is shared. You can always pass data around by the lambda capture or refer to a shared storage. If this doesn't get you what you want, you can use the \`future\` feature returned by taskflow. This allows you to pass data between nodes.
Hey stranger-- you were quite correct! We are on arm32, but cmake3 does exist. Thanks for the tip!
You suck.
Wow, how long did that take u to come up with.
Is this satire?
It’s been 5 hours, I’ve tried 6 different solutions. What else can I possibly do?
&gt; convince me this is even worth learning. why?
If your bored enough to read this, I assumed you’d be willing to do so.
If your this upset take a break. Seriously it helps. I started writing C++ when I was a child, over 15 years ago. It was super hard at times. Whenever I would get as desperate as you seem to be it meant I needed a break or more likely sleep. Sometimes letting your brain chew on problems like this while your doing something else is the key to figuring something new out. You’ll be fine. Just take a break. It’s worth learning, it’s just hard.
Sounds to me like you're having more compiler troubles than language troubles. Getting your compiler to work with a modern standard would've fixed two out of your three problems (the sizeof one, I'm guessing, happens because you're using sizeof on an array[] of unknown length - which won't work because sizeof is a compile-time operator, not a function). Incidentally, have you passed the c++11 flag *before* or *after* the file you're compiling? That can make all the difference. 
* Template * ABI * Portability * Pointer arithmetics 
If you're not trolling... yes, getting *started* with C++ is challenging, and the language has arguably one of the hardest learning curves. Getting the "infrastructure" (compiler, dependencies, linker, flags, etc.) setup is also incredibly frustrating. I would suggest you not try to compile it yourself locally at first, when just trying to follow a book's examples. Instead, use an online C++ compiler. For example use [coliru](https://coliru.stacked-crooked.com/) through [cppreference.com](https://en.cppreference.com). For example take a look at the bottom of the [std::vector] (https://en.cppreference.com/w/cpp/container/vector) page. You'll see an "Example" with a button labeled "Run this code". Click that. Edit the code. Click "run" again. etc.
No sorry, it is hardcoded in `src/window.cc` at the moment.
Thanks everyone for the great suggestions. Far more feedback than I was expecting, excellent! The favourites (that I feel would fit the format) seem to be: - Pointers (raw, smart, arithmetic) - Value categories - Underlying mechanics of C++ (compilation units, linkers, ABIs) I’m planning to start off with pointers, which might lead quite nicely into value categories. The underlying mechanics might also translate into the kind of format I have in mind. My plan is to try and express my own intuitions for these concepts on paper, and improve based on feedback. That said, I’d be interested in hearing about other people’s intuitions for the above. For those who are interested, I’m inspired by 3blue1brown’s maths videos and hope to produce something similar (although I doubt I’d ever achieve such quality!). In article form, something like this: http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/#comment-1009
Why not submit an issue on the project page?
I don't use IDEs so I don't benefit from all the automagical stuff. But I don't quite get the difference between "Having to remember that new files aren't picked up automatically" and "Having to remember that I also need to add new files to CMakeLists.txt". In both cases I need to remember something if I create a new file. In one case I need to run a certain command (which I probably still have in my history), in the other I need to open a file, find the right spot to put the path and then paste it. I used to automate the latter by having a "put all files in this directory in the format CMake expects" command in VIM. Which pretty much was an exact copy of the glob command I would put in my CMakeLists.txt. If I forgot to run CMake the file wouldn't be picked up. If I forgot to open CMakeLists.txt and run my magic command the file wouldn't be picked up. Not much of a difference really.
This is not directed just to you but your post has gotten me interested in conan again. I do a lot of cross-compilation though, and reading through the [cross-building](https://docs.conan.io/en/latest/systems_cross_building/cross_building.html) it seems too hands-on for me at the moment. I need to do a deeper dive still, but it looks like I would need to maintain ```profiles``` in my repo for every expected target, and it looks like they will need to be generated, probably from some template file. It would be nice if conan could make use of existing CMake Toolchain files, which have pretty much all of the same environment and compiler settings I see in a ```profile```. Would you expect a bunch of files like "&lt;root&gt;/conan/profiles/arm-angstrom-linux-gnueabi-gcc-rel" to be maintained in your repo? I will need pretty much all dependencies built from source, and I am a bit confused on "conan install". I guess the built packages are placed in the corresponding profile's install directory? I like the look of the cmake_find_package generator though.
No need to maintain profiles in the recipe or source repo. Actually, profiles can be maintained in a dedicated repository or zip file (in an http url), and be installed with "conan config install" command. This command installs configuration like profiles, but also remotes and other possible config, like custom settings.yml, in conan, so they are available for building different packages. &amp;#x200B; Packages installed by "conan install" are not placed in the profile directory, They are stored in the conan local cache (typically &lt;userhome&gt;/.conan/data), which is common for your projects too, you don't need to rebuild packages from sources in different projects (you can use different caches, and cache per-project if you want, but that is not the default) &amp;#x200B;
It looks like an awesome and really useful project, very cool! Just one nitpick, found this while randomly browsing through some files - it's a file for "C++14 people" only but still part of the library: https://github.com/cpp-taskflow/cpp-taskflow/blob/master/taskflow/threadpool/threadpool_cxx14.hpp#L32 You define stuff inside `namespace std` here. I think that's technically UB, isn't it? Or at least it's not allowed by the standard. I think that even if it works in practice on many compilers, many people, including me, would mind, and it would be a no-go to include that code into own code. You may want to consider changing that.
I question if that's ever a likely scenario to warrant switching to a stable sort.
Yes. This is a good point. In fact, this file was contributed by one of our users who is only interested in the threadpool but he needs a C++14-compatible one. This is not included in taskflow and only for side interests. 
How so?
Thank you for the offer! Maybe after some time; I’m completely new to any article writing and I think I need the flexibility to play and fumble with it a bit first. Keep in touch though?
I also think this would be a good one to cover! There is a list of “not-quite-an-article-but-more-than-a-paragraph” topics forming which might pair together to make a full article, that this fits into very nicely.
This is really a separate file/project then, or is it not? Like I see no relation to Cpp-Taskflow at all, it's a completely separate, isolated file (unless I've missed something). Seems like nobody using Cpp-Taskflow in C++17 mode would use it, and nobody using C++14 mode could use anything more than just that threadpool_cxx14 file? The only advantage I can see is that it might be more convenient to have a "fallback" directly inside the Cpp-Taskflow library so users who want both C++17 and C++14 compilation don't have to include another file/library for a thread pool. But then again if that was me I would use something like [progschj/threadpool](https://github.com/progschj/ThreadPool) that doesn't "invade" namespace std :-)
Thanks for the recommendation. I took a look at Lennon today and it looks really promising. I plan on using it in one of my next projects. Thanks.
Glad I could help. 
It can be solved without stable sort if it is a problem.
Hi, as far as I know, there is no breaking API. All the old API remains useable in this new release. 
No. We currently didn't handle this but we can include this to the TODO list. 
Have you got some performance benchmarks on this? And how's the compatibility?
Thanks, please do. Always nice to see so it does not have the "Works on my computer" syndrome. 
Not more than I run my own profiling so it runs fast enough for me. Platform compatibility? Runs best on Linux, runs fine on Windows. "Maybe" runs on OSX.
That does work, but why do we have to wrap `malloc` in `placement new` if we just want "plain old data"?
We have just being using Visual Studio 2015, or at least its toolset (v140) to avoid this sort of the problem. I must admit I don't have much sympathy with your particular case, but there have definitely been some other breakages with minor updates to the 2017 compiler. A particularly annoying one, which is not MS's fault, is that CUDA checks the version is at most some specific minor version number and doesn't even attempt to build otherwise. This means every minor version update is *guaranteed* to break all of our projects using CUDA. I only hope that by the time VS 2015 stops being supported there is some other version (2020 or whatever) getting minor version updates so that 2017 is frozen. If MS fully moves to a continuous update model, like they have with Windows 10, we'll lose the ability to make reproducible builds forever.
&gt;Not more than I run my own profiling so it runs fast enough for me. I'm thinking more like, how many triangles do you need to dump into a scene before it starts to lag?
Ha! Pry my two space indentation from my cold dead hands!
Because POD is still an object. `malloc` doesn't return an object, only an address. `malloc` is typeless and defines no object lifetime semantics.
nah ... that corridor will be too narrow for me to get to your corpse ... :D
I know about that reasoning, I'm just saying it's not a good reason to throw away `malloc` for and array of `int`s for example.
Yes, Meeting Embedded is a new, one day conference in front of Meeting C++. It starts with talks focusing on embedded &amp; C++ and then goes deeper into the embedded space. Keynote will be by Dan Saks.
It's so nice to see that a lot of companies are starting to embrace C++17. At this time there are 11 posts which use or are migrating to C++17.
Why not just use `new`?
And how much water can a group of people consume?
No problem. Just message me when you are ready.
Ah, C+.
I like to call it C+-.
form my experience (See [https://github.com/Manu343726/ctti](https://github.com/Manu343726/ctti)) this works as follows: &amp;#x200B; \- GCC &lt; 4.x did not consider \`\_\_PRETTY\_FUNCTION\_\_\` constexpr \- Recent versions of GCC (6-7?) no more consider \`\_\_PRETTY\_FUNCTION\_\_\` constexpr (I'm not sure why they changed that behavior back). \- GCC does not demangle enumeration constants, so templates like \`template&lt;Enum Value&gt; f(): f&lt;Enum::A&gt;();\` are demangled as "void f&lt;Enum Value&gt;() \[with Value = (Enum)0\]", so no free compile time serialization of enum values. Clang on the other hand demangles the functions using enum value names ("\[with Value = Enum::A}") \- MSVC often ICEs when doing complex constexpr processing (See my issues, there are some funny backtraces)
It's nice that the UI team is now taking C++ as seriously as the compiler devs have been! These are all pretty great improvements, I've already been using the template intellisense one.
Will do!
This is awesome! Great release, folks. Seconding /u/jcelerier's line of questioning - I'm curious how this stacks up against e.g. TBB, given that you say "and is by far faster ... than existing libraries". 
You are reiterating an argument which was already made. And I can even see your point. But you now, one rarely has written the entire code base one is responsible for, I'm talking of a big legacy code base, if you dig deep enough you will find VC6 adaptions still live. So hard to tell if back then it was that obvious that `seekpos()` should not be used, there certainly wasn't any deprecation warning attached to it. So please get of your high horse.
Thanks
Great news! I always have a hard time finding embedded talks as they are mixed in more generalist conferences. I'm guessing the talks will be recorded and published on the usual meeting cpp youtube channel?
`mos::gfx::EnvironmentLight` and `#include &lt;mos/gfx/environment_light.hpp&gt;` - this is a bit inconsistent. Everything else seems to be written using lowecase style.
Now they only have to run the constexpr tool over their windows headers ;)
Last time I used a data breakpoint it ran incredibly slow - has that changed at all?
Write a ray tracer.
Look into [nlohmann json](https://github.com/nlohmann/json) which is a c++ header only library. I personally use it and it's just magnificent. The documentation is very extensive and clear, it took me about an hour to have all the basic functionality down. &amp;#x200B; Some examples: &gt;!Creating json objects:!&lt; // create an empty structure (null) json j; // add a number that is stored as double (note the implicit conversion of j to an object) j["pi"] = 3.141; // add a Boolean that is stored as bool j["happy"] = true; // add a string that is stored as std::string j["name"] = "Niels"; // add another null object by passing nullptr j["nothing"] = nullptr; // add an object inside the object j["answer"]["everything"] = 42; // add an array that is stored as std::vector (using an initializer list) j["list"] = { 1, 0, 2 }; // add another object (using an initializer list of pairs) j["object"] = { {"currency", "USD"}, {"value", 42.99} }; // instead, you could also write (which looks very similar to the JSON above) json j2 = { {"pi", 3.141}, {"happy", true}, {"name", "Niels"}, {"nothing", nullptr}, {"answer", { {"everything", 42} }}, {"list", {1, 0, 2}}, {"object", { {"currency", "USD"}, {"value", 42.99} }} }; &amp;#x200B; &gt;!json string to object:!&lt; // parse explicitly auto j3 = json::parse("{ \"happy\": true, \"pi\": 3.141 }"); // get can fetch anything from the json object std::string happy = j3["happy"].get&lt;std::string&gt;(); &gt;!Reading and writing:!&lt; // read a JSON file // json j = the json object like j3 in the above example std::ifstream i("file.json"); json j; i &gt;&gt; j; // write prettified JSON to another file std::ofstream o("pretty.json"); o &lt;&lt; std::setw(4) &lt;&lt; j &lt;&lt; std::endl; &amp;#x200B; &amp;#x200B; This library has a single\_include file.
Thanks a lot,so there isn't any library that cpp has already? If not,this looks great,I'll read it.
This is a great hit! We will include this to our TODO list.
I don't know, I looked for a very well made json library and I kept finding nlohmann's.
This is slightly off topic, but what's the difference between constexpr auto DATEFORMAT_MMDDYY = "MMDDYY"; and const auto DATEFORMAT_MMDDYY = "MMDDYY"; or const char* DATEFORMAT_MMDDYY = "MMDDYY"; Why does VS generate the first one?
&gt; I'm not an expert, so don't quote me on this one, but I think this is what you're looking for. Thank you. &gt; Both PI1 and PI2 are constant, meaning you can not modify them. However only PI2 is a compile-time constant. It shall be initialized at compile time. PI1 may be initialized at compile time or run time. That makes sense I guess. I'm still not a fan of using auto instead of const*, but I guess that's the modern C++ way.
When it comes to front-end web development, it's like dictatorship. You use JavaScript or die. I know, there are transpilers but it is not complex solution to that "dictatorship"
Don't have much use for the first few, but the debugging related things are fantastic
I've mostly only used xaml from C# myself so far, and it was amazing to use a proper modern UI toolkit (compared to the old Winforms editor), though there were some random omissions (no spinbox control? The expandable/collapsible thing doesn't support centering the button without restyling the entire control?) I had a little experience using it with one of the old managed C++ variants a number of years back and it was definitely not pretty. Most of my C++ personal projects end up using raw WinAPI to create the Window because they have very little in the way of actual UI beyond a menu (which the old resource files still work fine for).
My understanding of the AOS/SOA dichotomy is that it's mostly about [locality of reference](https://en.wikipedia.org/wiki/Locality_of_reference) in [caching](https://en.wikipedia.org/wiki/CPU_cache). [This SO question](https://stackoverflow.com/q/9936132/4885801) is basically the archetypal case of cache friendliness. Can you give a bit more information about how your library handles this? A quick look at the code gives me the impression that `av::vector` is strictly using SOA. If that's the case, it may make it more convenient to work with SOA (which is typically a pain) while at the same allowing AOS, but it's all syntactic sugar. AOS vs. SOA is a design choice that depends on how the data is accessed. You can't have it both ways, unless you duplicate the data. But then again, I might be misunderstanding this whole thing.
You are right about the dichotomy (well, there is also SIMD instructions favored in case of SoA). Yes, `av::vector` is strictly using SoA, as it stores arrays of each component continuously.
Right, this is a wrapper around an SOA data structure that makes it easier to use as an AOS, got it. Code looks clean and well-documented. All that comes to mind is exception safety. A quick look at `resize()` gives me the impression that you'd leak members if an exception is thrown by a member's constructor because the size isn't updated so destructors won't be called. I see nothing about exceptions in your tests.
Yes, you are absolutely right about exception-safety ! I'll handle it and document it soon. Thanks for reading my code :) Have you ideas for a better name ? I'm not good at this ...
Just to make sure: Auto type deduction also decays arrays into pointers?
&gt; Yes, you are absolutely right about exception-safety ! I'll handle it and document it soon. Good luck :) It's a lot harder than it sounds. &gt; Have you ideas for a better name ? I'm not good at this ... Me neither. `soa_vector`?
And C has to introduce constexpr ...
Please calm down, I didn't mean to offend you. &amp;#x200B; My only point is that complaints like "why did you break my code" don't make much sense in this case (see above), it's neither your or MS' fault and the best you can do is sigh, rejoice that you caught it fairly soon, grep the rest of the codebase for 'seekpos', fix and move on.
Yes I like it ! I'll surely take soa::vector c:
That's odd. As far back as I can remember, Visual Studio has used hardware data breakpoints, so there shouldn't be any runtime overhead. 
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
&gt; I'm not sure if that's a proper solution. Why's that?
It's listed in the message, and it's an extremely common platform. &gt; - Settings: arch=x86_64, build_type=Release, compiler=gcc, compiler.libcxx=libstdc++11, compiler.version=7, os=Linux 
Why would the code want to know the warning level of compilation?
You're referring to name mangling of symbols. He's talking about conan selecting which package (build of the library) you get based on just about every factor that could be critical to take into consideration, regardless of the symbols' mangling. I'm guessing you didn't follow the link.
Nice to know but I'm still on VS 2015. Unable to download &gt; 2 GB of VS 2017 installation. Only for the privileged with high-speed connections!
With the new web installer you can do it piecewise.
I need that just my code option. Nothing like trying to debug a null string exception when its in the middle of the template header.
Who cares about C ;) ? Certainly not microsoft.
Write a small compiler with LLVM :)
You haven't read the answer fully, have you?
The Intel ISPC guys actually recommend a hybrid solution. If working with image channels or coordinates, instead of xyzxyzxyzxyz (which actually would be very cache and pre-fetch friendly, but not SIMD friendly since you are limited in your SIMD length by the number of coordinates) or even -xxxx -yyyy -zzzz ( SIMD friendly, but not as cache friendly ) They recommend something like xxxxyyyyzzzzxxxxyyyyzzzz (where the number of components is the same or more than the SIMD lane width (so 8 or 16 etc.). This uses wider SIMD lanes while retaining a single linear prefetch. I think this method might actually be built in to ISPCs structure of array feature. 
I'm leery of this: vector_span() = default; vector_span(vector_span const&amp;) = default; vector_span&amp; operator=(vector_span const&amp;) = default; that looks wrong. I guess they are private. Note there is a proposal for auto[...args] = some_function(); that introduces a parameter pack of unboxing. 
Maybe that's a sign that's too long for such an elementary thing.
This is a nice solution, I'll maybe implement it (as a 'hybrid\_vector&lt;T, size\_t Padding, Alloc&gt; or something like that) . I think that pure SoA still have their use case (when we want to iterate on only one component, it will be more cache-friendly).
I usually `return std::make_unique&lt;ObjectType&gt;().release();`
6 more posts and there will be perfect balance.
The function will be called by some Qt internals, won't it? In this case I'd stick to how Qt uses it in their own code: https://code.woboq.org/qt5/qtdeclarative/examples/quick/quickwidgets/quickwidget/fbitem.cpp.html#_ZNK6FbItem14createRendererEv Return a new'd raw pointer.
I've asked the IDE team to comment here.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Because, as it turns out, there was a better way. Ninja, as it was before, was added as a requirement in the build.py script for the CI builds. However, I told the package to always build with Ninja, which was unnecessary. tl;dr The package can now be built without Ninja.
Not anymore! It can be built without Ninja now.
What I came up with for now : - Backtesting and Algo trading library (for domain knowledge) - a custom memory allocator - implementation of some machine learning algorithms with Python bindings first and third are within my (hopefully) future path and are pretty interesting - Thanks for the suggestions everyone, but keep dropping your ideas this might be a source of inspiration for other people 
Build a genetic algorithm to solve an optimization problem. e.g. timetable scheduling for a university. There's lots to learn, and lots to code.
Is there also a place where we can see some results? At least I couldn't find it on the gitlab page...
Always prefer composition. Only use inheritance when you need polymorphic behaviour. 
add me to the thread, please :) - Steve, VC Dev Mgr
Whoah, looks great! Any chance for student priced tickets?
'genetic' algorithm? I would recommend a project that isn't buzzword nonsense. Optimizing time table scheduling would simply be bin packing.
this is an interesting problem! 
SOA is just ´hybrid_vector&lt;T,std::max&lt;size_t&gt;(),Alloc&gt;´ (I forgot how you get the max value of ´size_t´), so if you have a valid implementation of hybrid_vector, you have a soa for free.
std::string - it’s so flexible 
reading the question, I'm wondering why use binds ever? It seems like lambdas are just better in every way?
Yep. Use lambdas, don't use bind(). Even if you think bind() is better, don't. Sincerely, STL maintainer who rewrote bind() from scratch.
cool! btw, I super appreciate your posts here. It's amazing to get questions answered directly by the maintainer
There are some results and analysis on the gitlab wiki: [https://gitlab.com/chriscox/CppPerformanceBenchmarks/wikis/Analysis](https://gitlab.com/chriscox/CppPerformanceBenchmarks/wikis/Analysis)
Not yet, my old contacts with the MSVC team appear to have moved on.
Well, that would explain why my really old notes on how to report MS compiler bugs don't work anymore. (and most often I just sent them directly to an "relationship manager" or compiler dev.)
I think you forgot the /s there. I've been writing C++ for just under 10 years and there's an abundance of sharp edges.
It is not assumed or defined in the recipes, by the package creator. Because if you already have such build tool installed, it is a bit annoying having to wait for the download, unzip and install of another copy of such build tool. So build tools is something that the end consumer provides. If the end-consumer wants to use a conan package instead of a system wide tool installation (and given a package for the tool exists or they create it), then, the package can be added in the consumer "profile" as a build_require. But is the consumer who control thats. It is possible to "hardcode" build-requires in package recipes, but the rule of thumb is that this would be done only for library dev-tools (like a testing library) or for rarely used tools. Common ones (popular compilers and build systems) are installed or defined as build_requires by the users in profiles.
I mean it. As for difficulties in the language - take a guess, are there more problems in the language, or in a million-lines project? Language is by far not the problem. C++ is difficult when used wrongly. 
Conceptually yes but I think the code can be optimized further without the general approach 
Cool stuff thanks for sharing. 
Yeah. Two things: 1. If you can move into writing unit tests for the C++, that could get you into developer territory. If that's where you want to be, definitely worth it. 2. Knowing the language and some programming (and design patterns and all that fun stuff) will provide insights into where developers are likely to cut corners or have blind spots. You can then mercilessly test all those corner cases.
Data breakpoints well never be slow, and haven’t been in a very long time. I think VC 6 was the last release that tried to do anything with emulation. If you try and set more than 4 – the 5th breakpoint (and beyond) will fail to bind. &amp;#x200B; **More details if you care**: Breakpoints will always be fast except one case -- having an associated condition for the breakpoint that makes it so that most of the time the triggering instruction is executed, the debugger will get into break state, detect that the condition isn't met and then continue the process. In these cases, the overhead can sometimes be crazy-high (ex: 1,000,000x slowdown in the case of a tight loop). This is because modern processors are extremely fast. So the cost of hitting a breakpoint is many many orders of magnitude higher than executing the instruction normally. But, the cost of hitting a single breakpoint is still fairly small relative to the cost of everything else that has to happen to get the debugger into break state. So if there are no conditions involved, breakpoints will be just fine. 
Sometimes `bind` is the most clear and direct expression of a desired concept, just like `std::accumulate` is sometimes better even though you can just use `for`-loops for everything. Here's a [previous discussion][1] I've had on this topic which I think still stands up. [1]: https://www.reddit.com/r/cpp/comments/3m0rsk/functional_whats_new_and_proper_usage/cvbs8bq/?context=3&amp;st=jlfr58qn&amp;sh=ad0b1598 
Yes always! Proper OOP practices and architectural design are neglected in introductory material.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9bemmd/beginner_struggling/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
That's it then - every time I've used a 'data breakpoint' it actually wasn't and I was making a conditional breakpoint related to some data. "value changed" isn't really useful when the value changes several hundred times per frame and you're only looking for a specific value.
What are you talking about? [Genetic algorithms](https://en.wikipedia.org/wiki/Genetic_algorithm) are a super well-known approach.
clock\_time analysis is up now: [https://gitlab.com/chriscox/CppPerformanceBenchmarks/wikis/ClockTimeAnalysis](https://gitlab.com/chriscox/CppPerformanceBenchmarks/wikis/ClockTimeAnalysis)
&gt; Good luck :) It's a lot harder than it sounds. Just make it refuse to compile if the copy constructor throws. Then if people complain, make a SFINAE version for that case (or let someone do the PR).
That's not wrong. This thing is only useful for structures that don't allocate memory, probably PODs, or something close.
But are you often making an array of structures that themselves need allocation? If they need allocation, you're getting an indirection anyway.
Is there interest in hearing about this [code generator](https://github.com/Ebenezer-group/onwards)?
I'm happy to note that we definitely don't require everything to be cmake based! For example, see openssl, boost, ffmpeg, qt5, and many MSBuild libraries :) &amp;#x200B; \&gt;something that is not packaged by the upstream vcpkg team. &amp;#x200B; The vast, vast majority of our libraries are actually externally contributed with only a few core libraries that were primarily written by the upstream vcpkg team!
We actually \_primarily\_ build from source -- though we do have options for sharing binaries! &amp;#x200B; We definitely work with any build system and we've designed things to be incredibly easy to use even if there isn't special support -- all the libraries are placed in a unix-style layout (\`/include\`, \`/lib\`, \`/bin\`) so you don't need a separate set of \`-I\` and \`-L\` directives for every library. You might want to check out our docs for options\[1\]. &amp;#x200B; \[1\] [https://github.com/Microsoft/vcpkg/blob/master/docs/users/integration.md](https://github.com/Microsoft/vcpkg/blob/master/docs/users/integration.md)
Well, there you go! Thanks for the clarification, I'm sure that'll be helpful to anybody stumbling across this. I still believe Conan is the better option, but it's nice to know that vcpkg has a good amount of flexibility.
Give some examples. In my conversations with experts the problems they bring up don't fit your characterization.
Stuff like putting garbage strings in config files or input boxes. Programmers never sanitize their inputs. Despite my development experience, I'll take test positions that have a high probability of teaching me some new stuff that I can't pick up anywhere else -- like Ericsson's APZ21260 telephone exchanges. Those are a masterpiece of engineering and well worth spending some time with, if you can. So anyway, I did some testing for a couple of webapps on a project (Not Ericsson related.) Someone dropped some billing integration code on me for testing. First thing that pops into my mind is, well, they'll be running this thing in cycles where it'll have to deal with a few million access records, so how does it handle a million records. I hacked up some junit code to populate a test database with random records and told it to fill the database with a million records. His code crashed. So I lowered it to 100,000. It still crashed. Lowered it to 30,000, then it ran for 30 minutes and then crashed. Down around 20K records, it would complete in about half an hour. Funnily enough, the SQL join that I'd written to actually verify that his results were correct ran in under 20 seconds. Turns out he was using spring and hibernate and trying to do the join in Java instead of SQL. IIRC they decided to just run their code more frequently than they'd been planning to, so hooray for that :/ Same guys wrote some Google Web Toolkit code to do a bunch of different things. That company was doing functional testing with junit (Yeah, I know, you're not supposed to do that.) So I couldn't really test their GWT code but I could validate the API calls against the backend with junit's playback functionality. Turns out they did all their input sanitation and validation in Javascript on the client side. Imagine my surprise when I was able to create an administrative user with some http calls to the backend. They said something to the effect of "Oh you're just making calls to the back-end, no one would ever do that!" I sure hope that project got killed after I left. Those two cases weren't particularly C++ related. Now that I'm writing C++ code again, I'm going through trying to make my project reasonably bulletproof. For a while there, there were several places where you could crash out with a sigsegv. Like if you tried to start the server twice. That was a good one. Oh what happens if I try to start the server again while the server's running? Easy enough to fix, but not necessarily easy to catch. I've also squashed a couple where some code crashes if you exit without shutting down some services, but it seems there might still be a crash related to that. I'm trying to recruit some folks who use the system to let me know if they can reproduce that reliably, hopefully I can get some actual testers on it in the next little while (It's actually a video test automation framework, so that should be pretty easy.)
Zalgo is good for inputs.
It's a C++ library that you work with from Python (boost::python ftw,) that kicks off some threads that python doesn't see or interact with outside the API. And those threads initialize some libraries and open some devices... really not something that should try to start again once it's started. I already had a "running" flag in my code, so I just tested it in the start(). Calling functions multiple times is a pretty decent way to shake the tree for errors. It's a pretty neat system. There's a ffmpeg loop going on in the background, decoding data from a v4l device and setting states based on what it sees in the video stream. You can check the states at any time in Python, and they can change at any time. You can check to see if the video output is black or frozen, you can look for images of any size up to the entire screen, you can do OCR in specific regions and all that gets dispatched to the background threads to be tested. It's been reasonably stable and most of the software on the system will run now for a month or so at a time without intervention from me. Every once in a while, something on the system clobbers my custom-built ffmpeg libraries and I have to rebuild them. That's one of the bigger thorns in my side right now, but production will be on a stripped down version of the OS (No browsers, local GUI tools running or anything,) so hopefully that'll eliminate that problem. A couple of managers I've talked to have been pretty open to the idea of open sourcing it, I'm going to have that discussion with them in the next couple of months. Validating stuff in Javascript is fast and keeps you from having to call the backend unless you need to, but you should always expect a hostile party to be accessing your backend directly, too, so you should always validate and sanitize your inputs there too. One of the problems I have with GWT is that it's not very apparent to a beginner exactly where any particular code is running. They don't really have that client/server conversation in their head. GWT does make some effort to prevent spoofing to the backend, but it was pretty easy to circumvent on the setup that company was running. If you can install your own certificate and run a man in the middle attack, you can still watch the conversation between the client and the server. That's basically what I did with Jmeter (it makes it really easy to do that.)
Can you tell the people responsible for dev. community that their editing experience is literally worse than plaintext? Every time I am reporting stuff through it, I dread what kind of hash it will make of my text. Also the "code" block doesn't work in any way, which is just sad.
Thanks, much appreciated!
Is this on the AUR? - Searching only yields V1.0.3
Good to know! 
For example, our std::thread and std::async used to use std::bind. That resulted in "fun" as soon as someone tried to pass std::placeholders::_1 through thread or async. Thankfully we burninated that mess.
`std::accumulate`is specialized for-loop. `std::bind`does the same as C++ lambda. Your argument doesn't work.
&gt; Or that it was edited after I made this comment. lol
The core issue of SOA/AOS is that switching from one to the other is super hard in C++ because it is interface breaking. Because most of the time you need to change the way data are organized after you first made your program work, like for any optimization, you only try to switch to SOA or back to AOS (and maybe separate hot data in small AOS struct) you will experiment then but will have to rewrite all the code accessing these data each time you do so. If a tool (language or library) helps using the exact same interface to manipulate both, at least to access the data, that would solve most of the issue. Here it's not bad but that loop will have to be changed if we switch back to std::vector.
That's certainly a good place not to use `std::bind`; any time something is supposed to be able to transparently pass through user arguments any special hooks the internals react to can't be user accessible. I think I also recall some comments by STL about some differences in semantics between asynchronous and bind so that that implementation handled references or something incorrectly? In any case those, while good reasons not to use `std::bind` there, it doesn't really sound to me like something that matches NotAYakk's characterization either. 
Not true. In exactly the same way that `for`-loops can easily do things other than accumulation, lambdas can easily do things other than functional binding. So in fact binding is a 'specialized lambda' just like accumulate is a specialized loop. So in an exactly analogous way that seeing `std::accumulate` means you don't have to parse a `for`-loop to tell if the loop is doing accumulation or something else, seeing `std::bind` means you don't have to parse a lambda to tell if it's a binding or something else.
I like the idea of providing the same interface. How does `AV_DEFINE_TYPE` work?
I would definitely recommend learning, practising and using C++ or any other programming language. In the future I will never hire a tester, who has no programming experience. First of all I think having programming experience will make you a better tester and if you can write or at least check the unit tests too, this will help the overall QA process. Second in the future I might need someone who can also code, so the programming experience will secure your job.
Would `reversed(make_range(data+4, data+8))`really work? iterator\_range does not provide rbegin/rend?
Thanks ! If I take the exemple from GitHub, we have this : SOA_DEFINE_TYPE(user::person, name, age); // The line above is equivalent to : // namespace soa { // template &lt;&gt; struct members&lt;::user::person&gt; { // vector_span&lt;0, ::user::person, std::string&gt; name; // vector_span&lt;1, ::user::person, int&gt; age; // }; // } These `vector_span&lt;Pos, Aggregate, T&gt;` are basically `T*` which can retrieve the number of objects through their template arguments. Then, `soa::vector&lt;T&gt;` inherits `soa::members&lt;T&gt;` to let you access these objects. 
It is true. Sadly you **have to** write a seperate function with bind. 
Ahh, so basically the macro specializes the template for SOA layout. I would add some static asserts or whatever possible to provide clean compilation error in case someone forgots to place the macro.
I already have an assert if the soa::members is empty (saying that it must be specialized), but yes I will add more compile-time asserts soon (for forcing noexcept moves or forbidding having reference members for exemple).
So, the only utility you get out of this is range-for loops, because they're the only construct pre-C++20 that accepts a range. For anything else, this is pretty much useless.
&gt; Sanitizing inputs is not C++, it happens is virtually every language. Sure, but it is one of the languages, where unsanitized input can have the most severe consequences. Every time you index an array based on unsanitized user input is a case of UB waiting to happen with all possible consequences. Remember Heartbleed? In Java, python or JS, an attack would have deterministically terminated the application (or at least the current exchange if the exception were caught somewhere) in c / c++, it allowed a remote attacker to read any information stored in the current process.
A lot of codebases already have something like this anyway, or at least an "array slice" (aka array_view, aka span), which is similar but begin and end are both pointers into contiguous memory (or pointer and size, which is a trivial transformation of the same thing) - pointers are a type of iterator (specifically contiguous iterators as of C++17, or random access iterators before that). Said codebases make heavy use of ranges in their own APIs.
Nothing prevents one from writing functions that accept ranges pre-C++20.
What is missing is the single parameter make_range that turns any type of contiguous array into a pair of pointers (aka, zero overhead type erasure).
I'm very sorry for you if all the code in your codebase only takes ranges as a pair of pointers. There exist a world beyond the STL.
I have a what looks a like a simpler library that does the same called ["Tasks"](https://github.com/mhogomchungu/tasks) and the best it can do as far as graphs are concerned is; 1. Running tasks sequentially and in the order they are specified. 2. Running tasks concurrently. Instead of creating tasks "randomly" and then manually start ordering them with "precede", "broadcast" and others, why not create them in order and run them in the same order they are created? With my limited understanding of what you are trying to accomplish, the only reason i can think of why you want to do it your way is if the graph can be modified while its being processed and this does not seems to be the case since once of the mentioned caveats is that a graph is not supposed to be modified while its been processed. 
If you think you have to write functions just to use bind then you definitely should not be using it. No. Its purpose is to support functional binding in a context where that makes sense. Namely that you already have functional components. It would be silly to write a function just to bind it since if you're doing that you can just write the function to not need to be bound.
&gt; It would be silly to write a function just to bind You can bind partially. `std::bind`doesn't give you any clue what is happening. `std::accumulate` does clearly state that there is a summation.
Most code uses iterator pairs. I know there are library solutions, but if you have that, you have no need for functions presented in this article anyway.
Of course. It's just not common.
No it wont. iterator_range is also missing a constructor, he calls one in make_range. He could also change the call to iterator_range&lt;It&gt;{first, last}; .That would work without constructor. The missing rbegin/rend is still missing: [godbolt](https://godbolt.org/z/DbGvE7) 
No, our code doesn't. As I said, I'm sorry. I much more prefer to operate on ranges as actual entities wherever reasonable. To use an analogy: If you have a function, that has a 2D point as an input. Do you prefer passing x and y separately or a shingle point object? Sure, the x and y vrrsion might be more flexible, but most of the time, if you want to pass a point, pass a point object (you can if course always convert from one to the other).
&gt; from an exiting one No, from one defined at an other location. Only your version control can tell, if it existed before. That's my last post. We can agree that we disagree.
C++17 exists and we're still writing helper functions to deduce class template arguments? ;P
Yeah. The "real" C++, plattform-independent-api timers are missing. `high_resolution_clock` and `steady_clock` (often aliasing each other).
&gt; No, from one defined at an other location. Only your version control can tell, if it existed before. It's a misreading to take "existing component" to mean "a component that existed in prior revision of the software." That's not what I wrote and whether it existed in other revisions is completely irrelevant to my point. The point is that it's another component that usefully exists separately and so is usefully understood on its own, understanding which can then be built on. Lambdas can build on it in a wide universe of ways (or they make things out of whole cloth, combine lots of other components in complex ways, etc.), or bind can build on it in a limited variety of ways.
Today I learned that C++ has interfaces by using a class with virtual functions coming from a Go background I was not only surprised but also I noticed few projects on Github don't use them, the question part is what does the C++ community think about using interfaces in a similar way to Go? 
And I'm saying it was widely adopted in many code bases, even if not by the standard library. Well, we probably both know only a tiny, tiny bit of the c++ code out there, so "widely adopted" might be wishful thinking from my part.
`clock` does entirely different things on Windows vs. other OSs – comparing the performance of things that don't perform the same function seems a bit.. odd.
What, an expert at the standard library breaking the library by using bind? No, that is an example. Or template&lt;class T&gt; auto stuff_less_than( T&amp;&amp;t ){ return std::bind(std::less&lt;&gt;, _1, std::forward&lt;T&gt;(t)); } is equally broken. Or STL's comment about unique ptr in the linked thread. Or decoding the error messages when there is an error. Or lifetime issues of bound parameters. Almost any use of bond beyond monkey-do "bind one arg locally and use it right away in non generic code" is fraught. And that code is fragile and can break under refactoring. Bind has too much magic. I get that the non magic uses can be concise and simple, but the equivalent lambda is also darn simple. And the magic gets in the way. 
The old system was awkward, but I was impressed by the responsiveness. Issues that I and some coworkers submitted were generally responded to promptly and fixed before long. I was kind of shocked by how non-dysfunctional whatever team handling it was. I trust this probably continues with the new system.
\&gt; The clock\_time test is interesting: showing decreased timer precision on some platforms, and very high overhead for time related functions on some VM hosting systems. I've found that calling gettimeofday() on AWS instances was neither quick nor particularly scalable. Doing the same from a Linux VMWare guest on a Windows 10 host was fine.
&gt;AUR Not yet. Right now it's under alpha release. 
If lambda just were not so verbose (I don't want to imply that bind is usually any better)
Well, &gt; Thanks to Stephan Lavavej for comments on this answer. it isn't completely unimaginable that the post was revised (although this could also just mean that STL reviewed the post before it even went online.
Sadly deduction guides don't work for type aliases. For example if you define template&lt;typename T&gt; using cspan = span&lt;T const&gt;; Then just using `cspan(...)` won't work.
`gcc in.cpp -o run_me` Not much simpler than that for experimenting with the language.
gcc
I know visual studio is not just a compiler as you asked for but I recommend trying it out. It's easy to install and use, project management is simple, overall great for beginners.
The big problem with `reversed` is lifetime. std::vector&lt;int&gt; get_ints() { return {1,2,3}; } for (int x : reversed(get_ints()) { std::cout &lt;&lt; x; // segfault } I find I have to get fancy. template&lt;class Src&gt; struct reversed_t { Src src; constexpr auto begin() const { using std::begin; return std::make_reverse_iterator( begin( src ) ); } constexpr auto end() const { using std::end; return std::make_reverse_iterator( end( src ) ); } }; template&lt;class Src&gt; reversed_t&lt;Src&gt; reversed( Src&amp;&amp; src ) { return {std::forward&lt;Src&gt;(src)}; } this stores a forwarded maybe-reference to the source range and fixes the above segfault, because when passed an rvalue it makes a copy and when passed an lvalue it stores a reference. 
Depends on your operating system.
Our school currently have Dev C++ [4.9.9.2](https://4.9.9.2) and only have the default compiler, as stated on the compiler options. Thanks for the link! I guess I better head there
Maybe your school could update to a more recent version. C++11 is seven years old.
Problem is, my professor said that I should 'downgrade' my code so that it matches with the compiler in our school. :(
I don't think there is anything particularly c++11 about that code, what error are you getting?
Giving us the error would have been a good start.... Anyway, Dev C++ is so ancient I suppose it comes with a compiler that doesn't support C++11, which mean that `std::to_string` is not on available. By looking at the doc of [`std::to_string`](https://en.cppreference.com/w/cpp/string/basic_string/to_string) we can see that you can optain the same thing using `sprintf` (you'll have to create your own buffer though)
You're professor needs a new job, or to go back to school
In our school, if I try to debug the program using the code it says that `to_string` is undeclared or something. Cheers to all that try to help!
Please see my comment! Thank you
What operating system do you run?
YAIT (yet another incompetent teacher) There is no easy to use replacement in ancient C++. Write your own to_string: #include &lt;sstream&gt; #include &lt;string&gt; template &lt;typename T&gt; std::string to_string( const T&amp; val ) { std::stringstream s; s &lt;&lt; val; return s.str(); } 
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
What I am trying to do is having the `studId` become the filename of a text document. Here is the code, if this helps. &amp;#x200B; string studId2 = to_string(studId); studId2.append(".txt"); ofstream newstudent(studId2); &amp;#x200B;
If you're doing it the old C++98 way you can either use string streams or go old school and just sprintf the integer into a static char buffer that append to the string. Probably best to switch to a new compiler though.
I have not used make_reverse_iterator before so I’m curious about how it works. Is your implementation of begin and end in reversed_t back to front? The example on the cppreference page about this function makes me think you are meant to create the begin reverse iterator from the regular end iterator and vice verse.
Thanks fixed
eclipse and visual studio are probably the easiest to use. Both work without a big setup or console knowledge and allow you to compile and run your code by pressing a green play button.
My suggestion is to start out right off the bat with good habits: `gcc in.cpp -Wall -Wextra -o run_me` (Feel free to adjust as desired. If I were teaching a course, I'd actually include `-Og -fsanitize=address -g` in the "default" build configuration.)
[removed]
&gt; Be kind &gt; I won't look for further bugs.
[https://github.com/ryanhaining/cppitertools#reversed](https://github.com/ryanhaining/cppitertools#reversed)
awwwwtf
This is from 2005. I have to repeat this: 2005. Quit your school. Or speak to the teacher and then to the headmaster or something. Even the most recent Dev C++ version is from 2015... I think it uses gcc as compiler but I don't even want to imagine which gcc version if it's from 2005. Any code you write for this, forget about it again immediately. Don't learn C++ like this. There should be a public hall of shame for schools and classes like this. Anyway, good luck for the future! :D
It is supposed to do the same thing. It may report a different precision, but it is the same function and should perform well across platforms.
Because compilers and OSes are slow to update to standards (sometimes REALLY slow, *cough*C99*cough*). I have tests written for many C++11/17/20 functions - but until more compilers support them correctly, they aren't as useful to test. When a majority of compilers do support them, then I will release them (as I did with the random numbers tests). Also, those functions call into the lower level library calls that I already test - so it will mostly be measuring overhead and implementation details.
I was working on a MIPS emulator. Overall, I had it working very well - I even had debugging working in MSVC2015 with line-by-line debugging/stepping (that broke when gdb debugging changed in 2017). I wanted, however, to use the debug registers to handle a few things in the emulator, such as concurrency extensions. However, when I would set them, they simply didn't work - it appeared that the MSVC environment was overriding what I was doing.
WinDbg is sometimes useful for this as its debug event handling is an order of magnitude faster than Visual Studio's, so it may be able to handle the conditional breakpoint at a usable rate when VS can't. 
!removehelp
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9bjx1o/college_freshman_need_a_simple_compiler/e53yzr6/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
/r/cpp_questions 
Like this ? https://imgur.com/Eyw0rR9
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9bm2br/new_student_in_a_computer_science_class/e540i1f/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; What, an expert at the standard library breaking the library by using bind? No, that is an example. Your characterization was that there are all these things that require being an expert at bind enough to implement it or things break in mysterious, surprising, and perhaps silent ways that can't be understood without that expertise. BillyONeal's example doesn't fit that because it's perfectly understandable simply reflecting on the interfaces, without that expertise. That doesn't mean one won't make these mistakes, but it means your characterization doesn't fit and so it doesn't support your assertion. &gt; Or STL's comment about unique ptr in the linked thread. That's just down to understanding how bind works with arguments. It's in the specified interface for bind. Lambdas had the same issue with capturing unique_ptr in C++11, and in neither case is it some deep mystery that only makes sense to implementers. &gt; Or decoding the error messages when there is an error. The error messages are not any less readable than many other parts of the standard library and experience deciphering those translates just fine to `std::bind`. Here at least lambdas do have an advantage in being a language feature, though. &gt; Or lifetime issues of bound parameters. There's not anything special about these lifetimes once you know how bind's arguments work in the first place, so someone that encounters an issue here is going to encounter the exact same issue in any other context where they try to do the same, forbidden things. Lambdas are subject to similar errors and similarly do not require the expertise of an implementer to understand. &gt; Almost any use of bond beyond monkey-do "bind one arg locally and use it right away in non generic code" is fraught. And that code is fragile and can break under refactoring. The issue BillyONeal described with generic code certainly doesn't mean all generic usage is 'fraught.'
Thanks you! I just added the code and it solved the problem I was looking for. The system("pause") code is what my professor taught us in class and expects us to have in our projects. Who am I to argue with someone who grades my work that I barely have any understanding in? 
1. `begin` and `end` must allow different types. 2. Accepting rvalue ref makes this really dangerous construct.
Glad it helped. I'm not one of the super religious against system() calls, especially for students first getting into it.
There are a ton of non intuitive things. sfinae, while powerful, frequently gives horribly long error messages. Some non trivial combinations of templates and subtypes require you to write "template" or "typename" in unusual places and a lot of compilers give incomprehensible error messages when you forget (clang does alright here). The most vexing parse is ugly and counterintuitive. The static initialisation order fiasco (and many other subtle bugs with globals) is hard to debug. The language has been steadily growing and the standard is now nearly 2000 pages. It's really hard to have a good grasp of something that big and a lot of the latest advice about how to write good modern c++ is built on a foundation which requires you to understand a ton of stuff before you can really make sense of it all. C++ is difficult when used wrongly but the main problem is that using it correctly isn't intuitive.
I think I can make a simplified test work for most compilers with just the C++11 pieces. What I had written previously included a few C++14-isms that weren't supported as widely. (C++17 and C++20 code will have to wait, of course) If the simplified tests work, I'll include them in the next release (approximately one month).
Site is unusable on mobile with a force forward to some ad.
Thanks. Appreciate it. 
I haven't wrapped the entire API, just the bits of it I need for a test system. I can do screenshots very well, but my video recording bits are a bit iffy. I didn't even want that functionality in the system originally, but it was a frequently asked-after feature. Even after 3 years of working with FFmpeg, I'm still not comfortable of my capability to record video and audio together into a video file. I could never actually tell you exactly how long a clip is going to be versus how long it _should_ be, for example, and that's a thing I should know. I've wrapped my head around ffmpeg's timing system reasonably well, I think, and would generally rather work in milliseconds or microseconds, given an option. I do also have some classes that try to enable that sort of thing, but I think it's clunky to use. I feel like my code does a better job than any of the actual documented examples I've found out on the internet, though, I suppose that's not too bad. My immediate manager's been encouraging me to pursue open sourcing the whole thing and we're at a point where it'd make sense to do so, so I'm going to talk to people about it after the long weekend. I won't claim the code is amazing or even all that great, but it's doing it's job well enough that people who see the system in action are excited by the possibilities. If we got some additional contributors, we could start to delve into some of the more general purpose features that ffmpeg has to offer.
I'm not saying you should not measure the low- level primitives as base line. I'm just saying, that by now the average c++ programmer here on reddit is only going to use them if std::chrono *doesn't deliver* for some reason and your benchmarks would be a valuable input to determine when it *doesn't deliver* &gt; I may be testing more compilers than you do, and encountering more compatibility issues. I run tests on a lot more systems than what I include in the example analyses. (hint: some OSes are stuck on GCC 4.x, and some embedded and proprietary compilers are slow to pick up standards) That is probably true, so just exclude those systems - I mean you are also not testing win32 functions on linux and vice versa. I'm aware of course that it is not zero effort, so don't take this as a demand or anything from my side. Just as strong interest. GCC 4.x is not particularly meaningful given that that spans almost a decade of releases, but std::chrono is definitely supported in 4.8 and I believe also in 4.7 (although implementations back then were experimental and changed later). &gt; Plus, the standard library does not always pick the best choices (as seen in previous tests). Which is exactly why I would like to see a benchmark of the standard library - so that I know if it is a viable solution on the systems I care about. E.g. std::mutes used to be pretty expensive on msvc for some time, shop there where situations where I didn't use it even for cross-platform code.
Well in my case I was just pushing frames, no audio at all and no worries of timing, constant frame-rate (that you can just adjust yourself later on when remuxing the stream).
You have to use the `Retarget Solution` in the right-click menu in `Solution Explorer` (that sounds a lot more complicated than it is) and there you can then select the SDK of your choice (out of the ones you have installed of course).
Thinly veiled ad... Please try harder next time.
So, is 15.9 going to be finally ***the*** release we have all been waiting for, with basically full C++17 without workarounds (conforming preprocessor, two-phase...)? If so, thanks **a lot**.
It looks like it could be quite cool, but it's a bit hard to tell. How about adding a couple of pictures to the readme? Also the link to your docs is dead (https://github.com/utilForever/Hearthstonepp#documentation). And if I read it correctly, it only supports 20 cards so far?
https://steveire.wordpress.com/2016/03/19/aaargh-aaa-right-good-and-hygenic/
Not enough C++ in that CppCast for me personally, though it was somewhat interesting. I had been hoping for a discussion of say applying the CompCERT formally verifiable memory model to the C++ memory model, mainly as I'm going to try grasping that thistle in 2019 in order to propose the necessary support for memory maps, and I was really hoping somebody else had done it for me. Oh well. 
You could also try classic heuristics such as simulated annealing and/or tabu search. It would be fun project to test which of the 3 search methods work best in your case.
Sorry for the late question here, but what is the tool wc you mention?
I thought it was just a release fixing remaining Haha bugs, not everything else....
I was under impression that there won't be 15.9 and the next big release would be VS 2019. I could be wrong though.
I'm still waiting for modules to be mentioned again.
Sometimes my VS2015 just hangs for 30 seconds and comes back to life again. Any idea what might be going on?
From TFA: -- &gt; - Throughout the remaining updates of Visual Studio 2017, we will continue to exhaust the remaining MSVC bugs that block upstream version of the Boost.Hana library. &gt; - We will continue to provide status updates on our progress. Next update will be when we release VS2017 Update 9.
The article says Update 9 will fix the remaining MSVC bugs that affect Hana and Range-v3.
Now I just need a project to try it out 
My guess is, that if hanako and ranges work, that shouldn't be any major c++11/14 bugs in the compiler anymore (at least no more than in gcc or clang) unless of course, those fixes are actually custom tailored workarounds but I doubt that. However, add fat add I know, neither library uses c++17 stuff?
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Good to know, thanks. I've read here somewhere the discussion whether or not the can fix some bug introduced in 15.8 in a patch update and assumed it was because they couldn't make "proper" update (i.e. reminded me the situation with VS2015).
I believe when a function has side effects like modifying a global it cannot be optimized as well as a more "pure" function. For instance the compiler cannot assume that a series of calls with the same arguments will always return the same results.
statics inside scopes are not thread save. So there is no atomic operation. It's just a simple if branch each time you hit the definition point.
That's correct for C++03; the GP is correct for C++11 onwards.
Could you give me any info about that? Do know nothing about that. Atomic operation indicates they are not thread local by default, so what exactly are they now?
https://en.cppreference.com/w/cpp/language/storage_duration#Static_local_variables
Thx. So since C++11 the initialization is atomic. But performance wise is still is just a simple if block after the first time initialization.
`Zero locks/frees` Consider that locks can be faster than lock-free code under circumstances. `Zero throws` Sigh, I really hope that [changes soon](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0709r0.pdf). Not being able to use exceptions in high performance code is a terrible problem. 
&gt; I know that I should run tests, but if somebody has done it before... it won't help you a lot since even between two generations of intel cpus, some very basic instructions can have relatively (in the literal sense) important cost changes, like some SSE instructions taking 3 cycles instead of 2.
Preallocate everything at the very start of the program. Use linked lists to store blocks temporarily out of use. Usual tricks to avoid malloc.
I think they mean the linux utility [wc](https://linux.die.net/man/1/wc)
15.9 will have a few modules goodies.
This is why I am really excited by the heap-free coroutine proposal I read the other day. I want to be able to use coroutines to do something as stupid as "count up to 10" with a guarantee that no exceptions or (non-stack) memory allocation can possibly occur.
Well, that depends on hardware.
Given he works at MS, I'd say he _is_ the source for that. ;-]
Write an [interpreter](https://github.com/codr4life/snabl), even a calculator with variables will flex your brain more than most projects because of its meta nature.
How do you differentiate between: [](Object&amp; x, Object&amp; y) { return x+y; } [](Object&amp; x, Object&amp; y) { x+y; } // Where Object::operator+ is defined to have side-effects [&amp;]() { return x+y; } [=]() { return x+y; } ?
No. stdlib design is such that it has to throw. Adding an element to any container has to throw. Str1+Str2 has to throw. And so on. I can `-fno-exceptions` my code, sure, but I also need to build *stdlib* like so and rig std operator new to crash, for this to be even remotely correct.
Precisely.
Not sure which features are/were still blocking Hana, but at least Peter Sommerlad's scope_exit implementation still doesn't compile (in 15.8.2) due to some limitations on usage of auto (gives C3533), especially this: template&lt;typename TT, typename = std::enable_if_t&lt;std::is_constructible_v&lt;T, TT&gt;&gt;&gt; explicit box( TT &amp;&amp;t, auto&amp;&amp; guard ) noexcept( noexcept( box( (T &amp;&amp;)t ) ) ) : box( std::forward&lt;TT&gt;( t ) ) { guard.release(); }
I already watched this series in 1870.
Ah right, that would explain. Thanks
Well, copy heavy code can be highly performing *if* that's what your code does e.g. math on lots of data. So it's hard to give that as a rule, as it *depends*.
This course covers some parts of “Elements of Programming” in a more accessible way. The main topics are: (semi)regular types, efficient binary reduction, free lists, iterators, linear and binary search, in-place merging, in-place sorting. Altogether, you end up implementing significant parts of the original STL. Alex Stepanov is a great lecturer, lessons are entertaining and full of anecdotes. If you are interested in the how and why of the STL, this course is a must. 
But _which_ std::sort is it comparing against? libstdc++? libc++? Which version?
Actually, it's not only globals: any indirection is an optimizer nightmare. For example, see: int foo(int* a) { *a = 1; bar(); return *a; } You look at this, and think: "oh, it's gonna return 1". The compiler looks at this, and think: "there is a possibility that `bar()` may modify `*a`". The problem: aliasing. In C, and C++, most pointers are devoid of aliasing information, and therefore the optimizer assumes the worst (that they are aliased). --- There are several situations where this happens: - dereferenced values &amp; function calls. - globals &amp; function calls: a global is always a "dereference". - data-members &amp; virtual method calls. If a single function/method needs to access a reference/global/data-member multiple times and you wish to avoid the cost of multiple-accesses (because you don't need it), you need to treat it as you would a function/method call that you memoize; one solution is to make a local (stack) copy of the data: struct Simple { virtual ~Simple() = default; virtual bool debug() const = 0; virtual void other() = 0; void doit() { auto isDebug = this-&gt;debug(); if (isDebug) { ... } other(); if (isDebug) { ... } other(); if (isDebug) { ... } } }; 
&gt; Preallocate everything at the very start of the program. Can you elaborate on this? I only understand this to be that everything should be newed on program start, but I'm sure there's a different meaning.
I don't work on MSVC so I can't give you plans, and [the post where they introduce `__declspec(empty_bases)`](https://blogs.msdn.microsoft.com/vcblog/2016/03/30/optimizing-the-layout-of-empty-base-classes-in-vs2015-update-2-3/) just says "a future version", but I assume it will just be at the next ABI break. They even introduced `__declspec(layout_version(19))` to say "no I don't want the EBO for this class, use the old layout for compatibility.
It does avoid confusion with string concatenation: "path1" + "path2" + "path3" = "path1path2path3"
I work on compilers, and I can tell you that question actually has no meaningful answers. You have to understand the concept of pipelining before you even look into this. That is, a memory load is an instruction that takes 240 cycles, but that you can issue every 50 cycles. Or if it end up being in cache it is 4 to 42 cycles long, and issuable every cycles instead. You have to understand the concept of super-scalar execution. Where you can actually run 4 or 5 instructions in the same cycle. And those instructions can be vectorised and fused. And you have to consider the problems of branch prediction. There is generally a complete misunderstanding of performance in computer science teaching. Getting x800 speedup by knowing what you are doing is not unheard of. I suggest you look at how modern cpu microarchitecture work, and how compilers maps C++ to their instruction set. You will get extremely valuable insight by digging into this. Measuring instructions independently is not going to work.
How will I divide my paths, though?
I think the OP is pointing out that, for paths p,q,r p /= q; // OK r = p / q; // OK p += q; // OK r = p + q; // Error 
It's not that obvious to me why it's essential. If you're building paths from prvalues or const lvalues, you'll be building them from proper path components so you'll use `operator/`. `operator+`is for things like adding extensions, which if you're building a path you can do on the string underlying the filename component. auto const path = directory / (name + ".txt");
btw, this decision was originally in Boost.Filesystem - see https://github.com/boostorg/filesystem/commit/5ee2bb41893aae1e8ab1bfae2c0a44c0fc7a22a0
&gt; ssssort::ssssort(Iterator begin, Iterator end) why do you hate us
Dear hosts, thank you for another interesting episode! &amp;#x200B; I am not involved with formal verification professionally, however as an amateur, I would like to point out to few relevant resources. &amp;#x200B; There is a tool to enrich C code with annotations to formally prove its properties - Frama-C ([https://frama-c.com/](https://frama-c.com/)). Here is a nice tutorial that showcases its application to a number of STL-like algorithms [http://frama-c.com/download/frama-c-wp-tutorial.pdf](http://frama-c.com/download/frama-c-wp-tutorial.pdf). &amp;#x200B; There is a C++ plugin for it as well - [https://frama-c.com/frama-clang.html](https://frama-c.com/frama-clang.html) \- however it seems to be experimental. &amp;#x200B; The C++ Contracts discussion goes along the Ada SPARK ([https://www.adacore.com/sparkpro](https://www.adacore.com/sparkpro)) history: initially SPARK was using annotations in comments, but eventually switched to Ada langauge contracts. However as far as I am familiar with the C++ Contracts proposal the expected coverage would be rather limited and would not allow level of specification suitable for proofs. &amp;#x200B; Interestingly, both Frama-C and Ada SPARK use the same backend for proofs - [http://why3.lri.fr/](http://why3.lri.fr/). As the result, it is possible to prove mixed C/Ada codebases, here are some industry reports [https://frama-c.com/FCSD17.html](https://frama-c.com/FCSD17.html). &amp;#x200B; Hope the links would be useful to others to quickly explore the idea. &amp;#x200B; Looking forward to next episode!
So, you figure out the total memory your code will ever use ever, preallocate everything at the beginning, then use it. Thus avoiding ever calling malloc or free during program execution, except at the very beginning. Useful advantage: no need to deallocate anything on program termination, just exit.
Is that really possible for anything beyond a small app?
What does /= do to a path?
What’s making you switch the career are you Tired of writing python anymore 
The `+` operation in mathematics is commutative, meaning that `a + b == b + a`. This is not the case with paths: `a/b` means something different than `b/a`. Since path concatenation is not commutative, it is inappropriate to use `operator+`. Division, however, is noncommutative, and thus it makes sense to use that operator for path concatenation. The original authoring of `std::string` got this wrong, too, with `operator+` and concatenation. Unfortunately, that horse has already left the barn.
There's a pinned post for that I think.
&gt; (Why they allow += but not + is beyond me. I would consider it a bug.) `+=` and other `X=` methods can not be commutative no matter what. Also there is no ambiguity on the returned type since the left hand side is assigned (with `+` you could have surprise when adding `path` and `string`) 
What is that called. &amp;#x200B;
Enough with the patronizing gate keeping, linking it is enough
Surely this won't be a top rated SO question in 5 years.
The non UB approach is to use placement new and delete on the object to switch it between its active and inactive state. Most people just reinterpret cast of course.
You can build almost anything with that technique, but the cost of doing so exceeds most budgets so most people don't for most software. Where I'd like to get to is a formally verifying compiler which can calculate all possible memory states for you, and rewrite your code to hoist all memory allocation out. That optimisation pass might take days to run for any program of reasonable size, but for final release binaries it could be worth it.
Did your test use `make_shared`? That can lower the number of allocations compared to a naive implementation.
It did, but the design I came up with allows emplacing the value all the way down and allocating meta data and value together without helpers so that shouldn't make a difference from here.
Just FYI: shared_ptr doesn't use locks but atomics.
Aren't shared\_ptrs only thread-safe in terms of the reference count? It's not actually locking the object, and the count can be implemented with atomics. It is only when you need to use one of the atomic functions on the shared\_ptr that it locks, and even then, you wouldn't use those functions nearly as much as simple copying. &amp;#x200B; And in the clang implementation: template &lt;class _Tp&gt; inline _LIBCPP_INLINE_VISIBILITY _Tp __libcpp_atomic_refcount_increment(_Tp&amp; __t) _NOEXCEPT { #if defined(_LIBCPP_HAS_BUILTIN_ATOMIC_SUPPORT) &amp;&amp; !defined(_LIBCPP_HAS_NO_THREADS) return __atomic_add_fetch(&amp;__t, 1, __ATOMIC_RELAXED); #else return __t += 1; #endif } The refcount is only atomic if threads are involved.
Why are you rolling all kinds of stuff yourself that's already been rolled for you? You're writing an entire networking layer when Boost.Asio exists and reimplementing raw, binary representations of IP addresses when operating systems already provide this out of the box. 
I can't quite tell for sure if your website is meant to be poking fun at yourself via satire, or if it's genuine. Also, I have never seen an open source library like this targeting windows first and say Linux is planned for the future. It's almost always reverse. Why would you target MSVC first when you can just target both via CMake and whatnot right of the start?
Dunno. It wasn't me who downvoted you. An unfortunate number of people downvote for all the wrong reasons. Your question was totally valid.
Maybe it started out as a project to learn how to do that stuff, then later became worth releasing? I've done that a few times except for the worth-releasing part
I didn’t think it was you, but I see it happen too often on this sub and /r/askscience. People should not be afraid to ask questions. I also noticed it in college. People were afraid of looking dumb. 
The `__atomic_add_fetch` is a builtin, so maybe that does something under the covers to decide whether it needs to generate atomic instructions. &amp;#x200B; If you haven't been using C++ for a long time, then may I introduce you to [https://clang.godbolt.org/](https://clang.godbolt.org/) . You can actually check what instructions are being generated and compare it with your own.
Use `std::unique_ptr` whenever possible, and even better, automatic storage. That's my general rule. Of course, there are cases where shared ownership is the desired behavior, but `std::shared_ptr` is generally abused.
Wait why though? I always conceptually thought of aliases as actual aliases (i.e. something that could be replace by the compiler with the original type).
Noted, I tried adding one earlier and it was never triggered by the benchmark. The move constructor sees plenty of use though.
Also there's this: `using Int = int;` Why?
tbh it is pretty cool
It'll compare with the `std::sort` in the implementation you use to build it. A quick check with g++ 7.3 and Clang++ 6.0 (i.e., the ones I happen to have installed on this machine at the moment) shows broadly similar results when compared to either one--in both cases, ssssort is winning by a fairly substantial margin when the number of elements is large enough to care. Almost as interestingly, with ssssort, the standard deviation is much smaller (i.e., assuming I'm reading things correctly, its time is substantially more consistent). Here's a small sample with g++: [I've removed that last couple of fields from each record--I didn't read enough to be sure what they even meant.] RESULT algo=ssssort name=random size=1048576 iters=5*3 time=41.7932 stddev=0.0426082 RESULT algo=stdsort name=random size=1048576 iters=5*3 time=81.2647 stddev=0.557989 RESULT algo=ssssort name=random size=2097152 iters=5*3 time=89.1378 stddev=0.0456605 RESULT algo=stdsort name=random size=2097152 iters=5*3 time=171.022 stddev=1.01597 RESULT algo=ssssort name=random size=4194304 iters=5*3 time=191.25 stddev=0.0949533 RESULT algo=stdsort name=random size=4194304 iters=5*3 time=357.377 stddev=2.13253 RESULT algo=ssssort name=random size=8388608 iters=5*3 time=418.019 stddev=0.241325 RESULT algo=stdsort name=random size=8388608 iters=5*3 time=745.484 stddev=3.16563 RESULT algo=ssssort name=random size=16777216 iters=5*3 time=897.086 stddev=0.197205 RESULT algo=stdsort name=random size=16777216 iters=5*3 time=1561.06 stddev=11.9951 ...and with clang++: RESULT algo=ssssort name=random size=1048576 iters=5*3 time=40.0891 stddev=0.0649939 RESULT algo=stdsort name=random size=1048576 iters=5*3 time=80.3667 stddev=0.64317 RESULT algo=ssssort name=random size=2097152 iters=5*3 time=85.8555 stddev=0.157158 RESULT algo=stdsort name=random size=2097152 iters=5*3 time=168.748 stddev=1.94463 RESULT algo=ssssort name=random size=4194304 iters=5*3 time=184.206 stddev=0.0999623 RESULT algo=stdsort name=random size=4194304 iters=5*3 time=353.116 stddev=1.46595 RESULT algo=ssssort name=random size=8388608 iters=5*3 time=402.902 stddev=0.154481 RESULT algo=stdsort name=random size=8388608 iters=5*3 time=739.322 stddev=3.00853 RESULT algo=ssssort name=random size=16777216 iters=5*3 time=864.807 stddev=0.280346 RESULT algo=stdsort name=random size=16777216 iters=5*3 time=1534.52 stddev=10.9707 [in both cases, using the library that installed with that compiler by default] 
I bet this was inspired by Python’s pathlib which does the same thing... or maybe some other library did it before either?
best website i have ever seen https://www.kareldonk.com/
Just to be pedantic, an atomic could use a lock, though on common architectures a type like atomic&lt;int&gt; won't.
Depending on the hardware architecture a bit, atomic operations can be very inexpensive. Or, looked at another way, you pay for them all the time. On x86 the weak atomics are just the normal integer instructions. And the hardware makes unshared cache inexpensive to maintain. Benchmarking then can be terribly hard, just because arranging the conditions is difficult. If your code isn't multi threaded, you don't pay much for the correct behavior. And you get correct behavior when it is. 
Take the one less traveled. 
So, is it a super position of all networks?
please don't post code reviews to /r/cpp
As much as I agree with everything you're saying, shared ownership is exactly what I'm looking for here. I'm writing an interpreter, and I need to be able to redefine types, macros and functions while still keeping the previous version around until all references are dropped and then freeing it. That being said, your answer reminded me to take another look at each use and switch to passing a reference where possible. 
Is there a std algorithm for that?
The purpose of this post was figuring out why `std::shared_ptr` is faster than I expected. I can't really see the problem here...
/r/cpp_questions 
a raw path, that could be std.
The summary of the /r/cpp subreddit is: Discussions, articles, and news about the C++ programming language or programming in C++. This is a discussion about the language, specifically about an implementation detail. I think this very much belongs in /r/cpp, it's *directly* relevant to my C++ programming work, as I maintain a smart pointer library myself. I want to know why std::shared_ptr is getting better perf than OPs hand-written one.
I hear that all the time, but I have spent quite some time debugging a random issue, where in the end it turned out that a reference was passed through many classes on and on. And at some point one of the references lived longer than the original object. I bet that whe the decision for a reference was made, it was all consistent. But in a complex system, sometimes such lifetime things have to be changed. And then it is really a bitch to debug. Would they have used shared_ptr, it wouldn't have been a problem.
I refuse to have anything to do with `operator&lt;=&gt;` on principle until WG21 reverses the decision to name the associated library header `&lt;compare&gt;` instead of the obviously superior header name `&lt;=&gt;`.
The point of the rules are to "keep the gate". 
First, having a move-assignment operator is an important optimization to reduce the overhead of atomic reference counting. A benchmark ought to reassign an existing variable to expose the performance impact. Second, atomics are expensive. I timed a bunch of smart-pointer alternatives on my Intel Skylake CPU. Generally, raw t\* non-move constructors and assignments take 0.2 cycles (that is, they can usually be issued along with 4 other instructions, in a single clock cycle). Single-threaded shared\_ptr takes around 1 cycle, and multithreaded shared\_ptr 18 cycles in the uncontended case, but up to 600 cycles when lots of threads frequently operate on the same pointer. Of course these costs can be mitigated by passing them into functions as const shared\_ptr&lt;t&gt;&amp;, but there's no way to avoid the cost when extracting a member of a struct or assigning in a loop. I've been experimentally building a system for concurrent garbage-collected smart pointers which are thread-safe and cost around 4 cycles per constructor and assignment, but it's rather complex and not fully proven out. Generally, automatic memory management + many threads = hard problem.
The weak integer *loads* are just normal instructions. shared_ptr must lock inc or lock xadd
Because += and concat are the "unsafe, touches native format directly" expert tools, and + would almost certainly be misused.
All of my holy fuck. There are all the things have replied 'lol' which have, in all honestly, only made me exhale slightly, and then there is this which actually has earned it. This can't be serious. I refuse to believe somebody made this unironically. This is too on the nose to not be comedic satire.
 &gt; Ptr(Imp &amp;imp): Ptr&lt;T&gt;() { set(&amp;imp); } Why bother passing in as a reference, via operator*, just to take the address again? Consider putting size_t nrefs before T val. You might be getting some automatic struct padding here by mistake. You've got a possible bug in your dec() function. I wrote an issue on github about it. Move constructor for the pointer type is useful when returning things by value. There's some automatic rvalue-reference magic that can happen there. Personally I'm skeptical about the whole &gt; template &lt;typename... ArgsT&gt; &gt; Ptr(const Make &amp;_, ArgsT &amp;&amp;... args) &gt; : _imp(new Imp(forward&lt;ArgsT&gt;(args)...)) { } function. That seems more the responsibility of a static factory function than the job of a tag-dispatched constructor. Your copy constructor checks to see if your *current* _imp is null or non null. It hasn't been initialized to anything yet!!! Don't bother using that "set()" function for the copy constructor. Just do the operations directly in your copy-constructor, skip the part that checks your current values.
The OP is asking why the std::shared_ptr is faster than their simple but pretty straight forward hand-written non-atomic version. Considering that std::shared_ptr is using RTTI, I'd say that's a good question...
That wouldn't explain why std::shared_ptr is benchmarking as faster than you're less complex and more straight forward implementation... I agree with your initial assumption that std::shared_ptr would be slower than a hand-written non-atomic implementation in many situations. Among other things you're not using atomics, and you're not not doing anything tricky in your code. The compiler should have plenty of room to wiggle things around. More uses of "shared pointer" should mean more opportunities for your custom implementation to be slightly faster, not slightly slower.
You also might consider not bothering to compare against self in the operator= implementations. You doing that reminded me that I need to bench mark my own shared pointer code to see if doing that check is worth it or not (since I use atomic operations in my case, it might be worth doing). But for your non-atomic implementation, it might be that the branch for comparing _imp to src._imp is more expensive than simply doing the dec() and inc() calls. Or not. Donno.
__atomic_add_fetch does provide the compiler with the ability to optimize better than, e.g. hand-written assembly. But I've yet to see a situation where the "lock" opcode is omitted from the resulting assembly code. I'd love to see an example where it can make this decision. Possibly something to do with local variables?
OP is complaining that std::shared_ptr is *faster* than their non-atomic hand-written and fairly straight-forward "Ptr" type. You're right on everything you said, but I think OPs more looking for an explanation of what black-magic the stdlib is using to get this better speed despite using atomics and RTTI. 
Aight, thanks a bunch. Nice catch, I needed the reference at one point to get the right overload to run. Will do. Now I'm impressed, I can't see myself figuring that one out. Could you expand a bit on the move constructor part? I have a move constructor, so I guess that's not the one you're talking about. I agree. I was trying to peel off as many layers of dispatching as possible to rule out anything that could slow it down. But the sentinel probably nullifies whatever benefit I get there. The copy constructor delegates to the `Imp` constructor which further delegates to the `nullptr` one. Someone will consider that bad style, but I like the idea of reusing the logic however simple. 13 years of maintenance programming did that to me.
From a quick perusal of your code: 1. Don't roll your own network stack. Use Asio, or Qt, or something/anything widely used already. 2. Don't create your own message format/encoding. Use google protobuf, or flatbuffers, or something/anything widely used already. 3. Don't create your own IP Address class, even to parse/output IP address/mask info. Most network stacks have their own, or else use Facebook's Folly library IPAddress class. 4. Don't create your own mutexes, recursive mutexes, spin-locks, etc. They're already provided by the STL, but... preferably, avoid accessing shared resources from multiple threads altogether - enqueue work onto a single thread for the same resource, if you must have multiple threads to begin with. And I'd avoid spin-locks completely. 5. Boost has a UUID generator already. 6. Don't create your own random number class - there's one in the STL, and Boost, and a bunch of other places. I don't mean these things as criticisms. At my job we created a few of those types of things ourselves too, years ago - either because we didn't know about them being available elsewhere at the time, or because we thought we could do it better ourselves for our use-case. We regret writing them ourselves, to this day.
I find it odd to me the way to ship clang checks to a wide audience is committing them directly to the central LLVM repository. It would be nifty is clang-tidy has some kind of plugin interface.
&gt; Now I'm impressed, I can't see myself figuring that one out. I assume you meant this for the bug in the dec() function. Yea, I didn't figure it out either. One of my bosses pointed out the *same* problem in my own smart pointer library, and I've been trying to massage 20 years of legacy code to accept my completely re-written library for the past year :-) Definitely be careful with exception safety. It's a hard subject. I had to rewrite all my smartpointer code to assume that an exception could be thrown by basically any function call that involved code that wasn't my own. It was a bitch. Lots of std::exchange() on the pointer value, doing things in weird order to ensure that the "best worst thing" would happen if an exception was thrown in certain places, etc. Generally "acquiring" a reference count of a smart pointer is safer than "releasing" a reference count. If the exception throws on acquisition, then your smart pointer's not around anymore anyway. But if it throws on releasing, then you have a memory leak. &gt; Could you expand a bit on the move constructor part? I have a move constructor, so I guess that's not the one you're talking about. Sorry, I mistyped. I meant the move operator. Move constructor / move operator, both tend to be quite useful. You might consider, instead of different operators for const&amp; vs &amp;&amp;, just do a single operator=(Ptr src); operator=(Ptr src) { if(_imp) { dec(); } _imp = std::exchange(src._imp, nullptr); } I'm not sure whether it's worth checking to see if _imp and src._imp are the same or not. If it were an atomic implemenation I'd say *good possibility* but for non-atomic, i'm not sure the potential extra decrement / increment is worth caring about. Copy-constructors : Ah, so it does. Ptr(const Ptr&lt;T&gt; &amp;src): Ptr&lt;T&gt;(*src._imp) { } Ptr(Imp &amp;imp): Ptr&lt;T&gt;() { set(&amp;imp); } So you're not comparing an uninitialized value, but you're still checking to see if _imp is non-null so you can call dec(). *maybe* the compiler is optimizing that out. I wouldn't want to say without checking on godbolt or something. But you can still drastically simplify if it's not. Definitely check compiler explorer though. Ptr(Imp &amp;imp): Ptr&lt;T&gt;() { if ((_imp = &amp;imp)) { incr(); } }
It was just a wild guess :) That's why I suggested he use godbolt to see his code.
I see. Yep, exceptions in C++ is a different level of suffering from most languages. Cool, thanks. About the `Make` tag. Even with a static method or external helper, how do I prevent the `Args &amp;&amp;` constructor from clashing with others? Assuming I want to keep supporting emplacing the value with perfect forwarding all the way. I guess I could do something with tuples but that's another level of complexity to take into account. Maybe I'm missing something obvious here, perfect forwarding was barely a glimmer in Bjarnes eyes last time I was swimming in these waters.
The way I do it in my library is that, since I want to support being able to attach to raw pointers that were created externally, I have a constructor for raw pointers to the type. That, of course, means that your raw pointer constructor needs to call the inc() function, since it can't assume the passed in pointer was set up correctly for you. Maybe have a private constructor that takes a Factory() tag, that skips the inc() call, but otherwise just sets _imp to the passed in value. Then have your factory function construct the value with nref = 1 like you do now, and pass it to Ptr(Factory(), new Imp(...)); Basically my point is that I think separating constructing the type-to-be-shared, and constructing the thing-that-does-the-sharing into two different areas of concern is better from a code-smells point of view. Not necessarily perf.
Boost is a nontrivial dependency, and a lot of projects avoid taking a dep or transitive dep of boost. A lot of people also could use boost but don’t like the compile time hit their libs tend to entail, or the general design tendencies of boost libs. Also, discouraging people from implementing things themselves encourages monoculture and a lack of understanding things.
No it is an entanglement of all networks
How else are strings supposed to be concatenated then? Plus operator is pretty universal across languages so it makes perfect sense. Requiring commutativity from plus is a semantic thing. Not all monoids are commutative and that's perfectly fine. Unless you enforce algebraic properties through types and actually make use of those properties, it's all going to be in the programmer's mind and has to be consciously followed still.
It was maybe ported from java
[removed]
Your comment has been automatically removed because it appears to contain profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9byd7x/quantumgate_a_peertopeer_networking_library_for_c/e578ys2/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Plenty of non-toy software rolls their own async io code. Not to mention, portions of the stdlib. In some of those cases it’s unwarranted, but in many it’s not. Certainly if one of your coworkers shows you that they’ve written a complex library rather than use something off the shelf, you should probably have some questions, but I’m not sure why people here often act like its a bad idea if someone comes out with an alternative to a popular lib.
Note that OP is complaining that his Ptr class is *slower* than std::shared_ptr. So proper use of make_shared would only make the speed difference worse, not better.
Quote from a professor of mine: &gt; Because all software has bugs. &gt; All else being equal (features, performance, etc), the smaller of two pieces of software is the better. &gt; Therefore, the best possible software has zero lines of code, and at least one bug. The reason why people discourage reinventing the wheel is because in the overwhelming majority of cases, the resulting wheel isn't really all that round, or wheel-worthy. Which isn't to say that there isn't value in the learning experience, and that a monoculture is a good thing. It's just an observation of why a lot of people discourage re-implementing common things.
Correct, still few points: If you have something in STL use it. Forget about any third party libraries. But QT is copyrighted, BIG and has own drawbacks. Boost is BIG. Asio is ok, still have to be correctly integrated. 
:D
This is bad reasoning. I can define `+` to be noncommutative in some contexts and `/` to be commutative in some contexts. It's obvious that `/` was chosen because it matches the path separator character. Referencing properties of operations on numbers in reference to syntax of paths doesn't really make a strong argument. It's more like a DSL than an operation.
Wat. There's a comment from 2 hours ago using the f word and this one from 28 minutes ago gets deleted? What qualifies as profanity?
Having a trivially-copyable/POD type doesn't make aliasing violations defined behavior.
&gt; Why would you target MSVC first Because developing only in VS and not having to handle all of unixy build system shit is a... relaxing experience.
I really disagree with this mentality, and so many people share it (such as /u/voip_geek). That a good solution already exists, so why should we try to do better. That a good solution already exists, so it must be suited to all domains. Something will come along and be better than boost asio. People will start off by saying they should just use asio. Then years later they'll tell everyone to use that new framework instead of rolling their own. 
&gt; and a lack of understanding things Could not agree more. 
Totally unimaginable!
I think people aren't saying "Why should we try to do better". I think people are saying "You're not doing better, use the better, standardized, version of this concept". You don't accidentally "do better" than standardized and widely utilized libraries. If someone's trying to do better, great, lets have it! If someone's trying to come up with new ideas, that's also great. But it's incredibly unlikely for someone to accidentally stumble on a better way to represent IP Addresses, for example.
QT is available as LGPL. Still has drawbacks, but not the same as "copyrighted" without any additional information. All software is copyrighted, always, and automatically, at the point of first creation. Boost is copyrighted, just under the Boost license.
That's the point – OP's Ptr class is the naive implementation, which may be performing worse due to greater allocation count.
I'd like to add that there is an important distinction between copying and moving a shared\_ptr: The latter does not require any atomic operations, hence it is usually much faster than copying. Obviously you are correct that one wants to avoid any unnecessary operations, but for shared\_ptr you need to focus on avoiding copying (e.g. by passing shared\_ptr parameters by value).
It is possible that the compiler have optimizations for the resulting shared ptr code since it might have been a common bottleneck.
[removed]
Your comment has been automatically removed because it appears to contain profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9byd7x/quantumgate_a_peertopeer_networking_library_for_c/e57b8yg/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Hush you.
:D 
&gt; on common architectures a type like atomic&lt;int&gt; won't. well, if you don't count x86 and arm as "common architectures"... https://gcc.godbolt.org/z/wkphRE
I don't think the loss in semantics is worth the 0.0000000000001 second gain in running destructors of smart pointers. I am (stupidly) commenting before watching the video though, so maybe later I'll regret saying this.
Haven't had a chance to look at the specific code in question, but I'll just point out another case where a non-thread safe reference counting pointer was measured to significantly outperform `std::shared_ptr` on a particular [arbitrary microbenchmark](https://github.com/duneroadrunner/SaferCPlusPlus#simple-benchmarks), compiler and platform. In this particular benchmark the heap allocations are the largest expense, so as others have pointed out, combining the reference counter object and the target object into a single heap allocation instead of two separate ones (like `std::make_shared()` does) can make a big difference I think. Also, microbenchmarks may not reflect the real world cost of atomic operations. It's not just the speed of the atomic operation itself, but also its effect on surrounding and concurrently executing code, right? At compile-time they can hinder the optimizer, and at run-time they can hinder concurrently executing code that may be trying to access the same cache line that contains the reference counter. That is, as others point out, if the `std::shared_ptr` is even using atomic operations in your particular benchmark. I think. &amp;#x200B;
I haven't looked at your code, but a common "mistake" when using shared_ptr is passing it by value to a function. For most use cases you can pass it by (const or non-const) reference.
For interpreters it can be worth considering std::variant instead of shared_ptr if that fits in with your design. 
Most likely /u/quicknir meant mutexes. The lock opcode is how x86 assembly indicates the following instruction should be atomic
It's using... **RTTI**?!
Please be aware, that Andrei works in an environment, where 1-2 percent application performance improvement will pay his salary for many years. Not everything that makes sense for him makes sense in general concerning the tradeoff between maintainability and performance.
Specifically, what part/ function of shared pointer turns up in your benchmarks?
I had to stop at the spaces before parenthesis.
&gt; I can't quite tell for sure if your website is meant to be poking fun at yourself via satire, or if it's genuine. lol As for Windows, I specialize in software development for the Windows platforms. So that's why I started like this. Also, Visual Studio -- It's the best there is. I fully intend to also support Linux though. But you have to begin somewhere and in my case it's on Windows...
It must use type-erasure for the deleter; a common approach to type-erasure involves virtual members.
Thanks for the feedback. 1. I looked at Asio and saw that the NetworkingTS was coming so I decided to wait for that instead. I also have some specific low level requirements for the things I build and I'm not sure it'll be completely useful. But when that becomes available I'll definitely be looking at it. 2. I also looked at Protobuf and msgpack etc. but for my purposes it was better to keep it simple and not pull in dependencies. 3. For IPAddress I mostly use the underlying OS functions. The class is a wrapper mostly apart from the additional mask stuff. When the networking TS comes I'll look into using it. 4. The only mutexes I created were ones that std doesn't provide. 5. The UUID in this case is a custom one with specific format that I need. 6. I actually use PCG-Random, and it can be configured to use Mersenne Twister from std (but it's far slower); the class is a wrapper mostly. &amp;#x200B;
Because, for example, an `int` is not always the same size depending on architecture. In case it needs to be something else in the future, changing it would hopefully be as simple as changing the typedef...
On x86 atomics should not matter that much unless you have contention on them, or you are touching them like crazy. If you have contention, obviously you need them anyway; if you are updating the counts too much, it will even have indirect impacts when using non atomics : compiler might not be able to do *some* optims across the write access in some cases -- although with alias analysis this should less be the case, but not all compilers to that; similar thing for processor (write combining of things before and after) -- of course things are worse with atomics, but writes are far from free even without, depending on multiple factors. That being said, I'm often impressed by the quality of implementation of major compilers and STLs, especially on critical items like smart pointers, implementation of thread-safe local static, and so over. It's usually hard to beat them if you are not an expert, and even often when you are. So the only thing that comes to mind would be maybe static branch prediction (and impact on cache usage depending of the hotness of basic blocs and where they are placed)? Try https://en.cppreference.com/w/cpp/language/attributes/likely or the equivalent language extension for your compiler, and of course look at the produced binary. Only a wild theory, though. 
The Networking TS was based on ASIO, and the changes it incorporated were then put back into ASIO. If you want to target the Networking TS, use ASIO.
There is a lot of talk about atomic, but the other major performance consideration for std::shared_ptr is the memory allocation. If make_shared is not being used, the extra allocation in the std::shares_ptr constructor could be contributing to the degraded performance. Some of the non STL implementations I’ve seen don’t have a make_shared equivalent which allocates memory for the object being managed and the control block in a single allocation. Of course, this is only going to really matter if there are a lot of creations, it has no bearing on copy/move. In my experience frequent memory allocations (which typically involve one or more atomic themselves at some level) have a greater performance impact than frequent atomic usage, so extra memory allocations are one of the first things I look for in my code when trying improve performance. Personally, I try and make sure I don’t use the std::shared_ptr constructor. In most cases std::make_shared can be used. If your implementation was performing two allocations instead of one, that could be the explanation for the lower performance in your custom implementation.
He worked at Facebook at the time. .0000001 times millions and millions of servers was worth it. 
std::partition
Have you taken into account that the reference count object is located next to the constructed object when you call `std::make_shared`? It does something similar to `std::enable_shared_from_this`. template &lt; typename T &gt; struct ref_counted { std::atomic&lt;unsigned int&gt; _refcount; T _value; }; auto ptr = new ref_counted( /* args */ ); return &amp;ptr-&gt;_value; This helps keeping the counter close (good data locality) and reduce pressure to the allocator (half the amount of allocations).
In that case you aren't doing yourself any favors with that alias. If you build your code for a 32-bit and 64-bit system it's already using two different sizes. Not that I think a type alias is the right choice, but if you want an alias you should pick the size you need: `using Int = int64_t` But this kind of stuff is generally a huge waste of time to maintain since you can't predict the future. Either pick a specific size or just use `int` and don't worry about it.
By your own example, += isn't essential either then. Reality is that it's convenience either way. One thing I often do is build a path without an extension, and then add two different extensions for two different files I want to use. The lack of + makes this hilariously awkward.
I don't understand why it has to be so black and white either. Every single person could recommend using an off-the-shelf solution in every case and in my opinion that's not encouraging a monoculture. No one is saying "don't roll your own thing", they're saying "always *consider* not rolling your own thing".
I know it's not your point, but asio is an interesting example. It's been around forever and has continuously evolved to incorporate new ideas. I fully expect years from now asio will still be the right low-level solution and I fully expect it will look a little different too.
Nope, I'm not saying that. Of course someone will come along and do better. OP may even have a better implementation of something. But you don't do it by reinventing the wheel of *everything*. For example this thing even has its own memory pool implementation. To reinvent it all, and have people want to use it, you'd have to explain why reinventing it all was necessary or better. The stated goal of the project is: "to become a platform for distributed computing based on a mesh networking model." That's a fine goal. A great way to do that is start with commonly available and widely used building blocks, put them together, and build on top of them to create a p2p mesh networking library. OP asked for feedback, so I gave my 2 cents: don't reinvent this stuff, for this project's goal. If, on the other hand, your goal is to build a better mouse trap, then by all means do that and explain what's better about it - but don't build the house the mouse trap goes into.
For one, your shared ptr is optimized for when you have one/zero copies aka unique ptrs job You are right though... origionally i was talking about refcount being ugly but perhaps its better not to care
&gt; You also might consider not bothering to compare against self in the operator= implementations. As written the check is needed for correctness, because the decrement comes before the increment. It's: if (_imp != src) { if (_imp) { decr(); } if ((_imp = src)) { incr(); } } It would need to be: if (src) ++src-&gt;_nrefs; if (_imp) decr(); _imp = src; I agree that this is likely to be faster on average, but you can't just delete the line with the test. And you can't reuse incr() unless you make it a member of Imp, because you need to increment the source count and src is not a Ptr&lt;&gt;.
You're much better off using int32_t and related types if you need a type of specific size.
looked around randomly throughout the code and stumbled onto [this](https://github.com/kareldonk/QuantumGate/blob/master/QuantumGateLib/Core/ListenerManager.cpp#L152-L155): a bit worrisome
Well it's probably not done in existing implementations, but whether it can be done in principle is another matter.
I'm guessing, but maybe he's talking about that `std::make_shared()` allocates the T object and ref count in one memory allocation, as a slightly larger object, with the ref count right before the T in terms of layout? As opposed to when you create a `std::shared_ptr` by calling `new()`, which ends up performing a double-allocation: one for the T object in `new()` and one for the ref count. So if OP's hand-rolled shared pointer does that double-allocation, it would be slower than `std::shared_ptr`+`std::make_shared()`. Because not only would creating/destroying one be slower, but also when you make a referenced copy/assign you invariably need to actually *access* T for some useful purpose, and that access might require going back to RAM.
Start the reference count `nrefs` at 0, not 1, and do not pre-decrement in `decr`.
8-/ nothing is easy with this language.
Yes I don't doubt that. I'd be interested to see the numbers for people who do use unique PTR tho. Is it still worth optimizing shared PTR if it truly is so shared?
How important is it to "immediately" free them when references are dropped? Can they be freed at strategic moments where you know all references have been dropped even without ref counting them? Such a moment could even include exiting your program; keeping useless items in a vector/hashmap until the end may be faster than considering every user a new owner with ref counts.
That's not true! What about... Uh...
Wouldn't moving be implemented with an atomic swap of the internal data? If it's not atomic, 2 threads moving the same source shared\_ptr could end up with "duplicated" ownership of its ref count.
IMHO this is not really a good practice. Adding a new field to your struct and some loosely related part of the code start doing other things ? Too unsafe for me.
&gt;This is bad, locality of reference is much more important than saving the extra 8 bytes by not allocating a ref\_count on a null smart ptr That would be my best guess for what's slowing your implementation down. 1% additional cache misses will hide any optimization your Ptr had over shared\_ptr.
I was expecting a components pattern video. I was disappointed. 
Wow. That blog sure is.. something else. Just.. wow.
He's talking about if some developer adds a field to the struct in the future while forgetting about this function call on all struct members. This is prone to cause very subtle bugs.
I meant adding a field will change the outcome of magic_get, and I will maybe have forgotten I used it
Well, the case is to iterate over every single field of the structure. If it doesn't suit your needs, just don't use it, like the regular range-based for.
I maintained a project that calculated satellite locations at specific times and generated some additional data files relating to pointing the satellite at a specific ground track for a set period of time. Originally the code was written in perl and ruby (UI dev came in 5 years after the perl was written and didn't want to write code in perl,) I rewrote it in C++ when we needed to add a new satellite. The old perl code kept satellite information in undocumented arrays of arrays of arrays. The new code could read the satellite ephemeris from an Oracle database or parse it out of a flat file and then generate the required data files (satellite's location every .2 seconds for a specified duration, how the satellite needed to rotate to maintain its ground track for that time, the actual ground track for that time, and a couple of other files.) These files were used as inputs for end-to-end testing on a ground system. It used Oracle's SQL and the Eigen C++ math library for the required matrix and quaternion math. At my current position, I've written a video test automation system that uses ffmpeg to grab video frames from HDMI capture cards. It uses OpenCV and Tesseract to do image recognition and OCR. It provides a python scripting interface through boost::python and a server interface via the served C++ rest framework that we can use to manipulate screenshots (Specify what coordinates we want to OCR or find an image in.) I serialize and serialize the objects with Json using boost property trees on the C++ side. There's some custom javascript code served to a web browser that can accept, display, manipulate and create objects with screenshots and coordinates in them. It really isn't a horrendously complex piece of software. Most of the development effort was figuring out various behaviors of ffmpeg. Some of those behaviors are still unclear, but I've learned to go digging around in their source sooner rather than later when I have a question that needs answering. These are unusually interesting projects. Most of the time the industry just wants you to parse a file and stuff it in a database, maybe generate some reports from it. My previous projects were generally old-style C, Java or more esoteric (in some cases propetary) languages. I'd looked at C++ before in the bad-old-days and didn't care for it. I picked it up again for the satellite project and found that the language is very nice with the advent of the C++11 changes to the standard. I might have a client ask me to do an older version of C++ on some ancient SCO machine or something, but at this point I'd probably tell them to go stick their head in a goat.
I maintain a sorting algorithms library, and benchmarking super scalar sample sort generally gave it faster than usual standard library implementations of `std::sort`, and even faster than pdqsort in many cases.
Hehe...as stated above, it's not exactly your mother's smart pointer :)
Probably not, if you look closely at the implementation posted you'll see that it doesn't even support allocating the control block separately. Which means that the only case for the reference implementation is `std::shared_ptr`'s best case as far as allocations go. And simply not supporting all the features should have some kind of impact.
From what I understand, `std::shared_ptr` will allocate the control block together with the value whenever it can. Which leads to exactly the same kind of indirection in my mind. The difference is that this is the only case the reference implementation supports.
The implementation posted doesn't even support allocating a separate control block, it's always allocated together with the value.
True, when again, if you want to iterate over all struct fields, you want just that. I.e. ALL fields. If you had only specific fields in mind, when your code already poorly suited for "generic" for. It'd be similar case to iterating over array of fixed length. If your code breaks, if this length is changed, when range based for was a poor choice to begin with.
"Hello, world" is kinda easy!
After actually glancing at the code, I really do think the person I originally replied to is saying that the ref count should somehow be a member variable of the smart pointer object. Not a separate allocation, or allocated together with the object that the smart pointer owns. Which is just stupid.
Look at this through the eyes of a beginner: #include &lt;iostream&gt; using namespace std; int main(int argc, char *argv[]) { cout &lt;&lt; "Hello, World!"; return 0; } What is an iostream and why do I need to include it? What does the # sign mean there? Why do I need to use the name of some sort of venereal disease? Why would I need a namespace? Why can't I just call things by their name? Why do I need to understand this concept to print things? The fuck is a `char * argv[]`? What is going on with that? If it is included, why isn't it used in printing? As a follow up, what is a pointer? Oh, it's something tons of novices trip over...? Why is it included in my first contact with this language? * Okay, sure, you could write this without the arguments to `main`. but then you're arguing that having multiple ways to start every program is simpler than having just one. That every program starts with one of two functions (oh, or more, that compilers may-or-may-not choose to accept) is just the start of the fractal explosion of nuance to this language. Why do only some of the lines end with a `;`? Why can't I just write it without the `;`? Why do I use `cout` instead of just `print` or `display`? If I remembered I had to use `cout` instead of something simpler like `print`, how am I supposed to know that I must `#include &lt;iostream&gt;`? Why isn't basic functionality built into the language? What next, do I need to `#include &lt;trig&gt;` to use cosine? Why is there extra syntax, `&lt;&lt;`, just to print? What does `return 0` have to do with printing? Why are there two `int` on the line with `main`? Do they even imply the same use? Why do I even have a `main` function at all? Why can't I just write simple code without a `main` function? Even with all that, this code pulls the rug out from underneath you: you shouldn't write `using namespace std` there! That's "bad code smell". Compare with Python: print "Hello, world!" Now, the complexity is all there for a reason, and C++ is my primary language for a reason, but nothing about it is easy... even before we start talking about how to *run* the above programs!
Why is that?
In previous versions of the code UInt16 used to be a typedef to unsigned __int16 which is Microsoft specific. I later changed that. The same was true for the others. I like that kind of flexibility that typedefs offer.
 #include &lt;stdio.h&gt; int main() { puts( "Hello World!" ); } This avoids most of your listed questions. 
The kind of things you usually want to use compile time reflection for, it's much worse to add a field and forget to update your methods than to automatically use the fields: - debug printing - logging - serialization There's lots of other uses I've come across in my own code but these are the generic ones.
Personally I find that not getting the names of the fields is a deal breaker for most of the actual things I would use compile time reflection for. I use Boost Hana instead. It's true that you have to declare your structs with macros, but the macros work very well and this doesn't end up being a big deal.
 why do you hate ~~us~~ ussss &amp;#x200B; Fixed.
Try the tinyrefl. It utilizes the clang AST (cppast library) to get the names. I really wanted to try the enumerator-to-string, but I've had hard times building it on Windows. 
The new breed of C++ is honestly making me feel insecure. I remember when it was structs with methods and vectors of T.
&gt; No debate on how to write that! `print("Hello, World!")`
Even if it makes perfect sense to iterate over all fields of a struct right now, doesn't mean that will still be the case in 12 months. A code base is amorphous and change unpredictably in all kinds of ways over time. It is hard to guarantee that no-one will ever change the semantics of the struct. Unless I see a compelling use case for this, I'd prefer not to use this feature.
\#define NOMINMAX Works for windows.h
It seems like an interesting choice if you really need a good amount of reflection for types you don't control. But if not, it seems like using a macro is much simpler than have a special build step that does literal code generation, which appears to be what it does (and IMHO the fact that you're having trouble building it sort of speaks to that). For an enum that you control, using a macro is a far simpler solution than this. I've actually written a simple library for this; header only, no dependencies, nothing to build, no build system integration required: [https://github.com/quicknir/wise\_enum](https://github.com/quicknir/wise_enum).
Thanks, I know. Still annoying though and I wouldn't complain if those where the only macros. 
&gt; Syntax is consistent for a given language. My snippet works fine in both pythons though. And I'm not trying to argue the simplicity of python vs. C++.
&gt; Even if it makes perfect sense to iterate over all fields of a struct right now, doesn't mean that will still be the case in 12 months. Even if it makes perfect sense to &lt;do thing A&gt; right now, doesn't mean that will still be the case in &lt;N&gt; months. Range for in question is not different in any way to any other &lt;feature X&gt;. 
&gt; print "Hello, world!" First your python example has been invalid for years, the print needs (). Second it doesn't even print the same the C++ version does, as print adds a new line. To get the same result as C++ you need to write: import sys sys.stdout.write("Hello World!") Fun fact: one of my first confusions with python was finding a way to "print" without getting a new line added. Next this isn't going to do the right thing once you add multiprocessing on windows (I think?). Instead you want to nest it in if __name__ =="__main__": #do not execute unless called directly &gt; What does return 0 have to do with printing? It is completely redundant, you might want to add the following for similar uselessness in python: sys.exit(0) 
I don't get your comparison to arrays. Arrays are almost always semantically homogeneous, and structs are almost never.
I want this more for enums. 
&gt; A much better question is why we need a path object to begin with. path objects have a lot richer semantics than strings. F.e., you could compare relative and absolute path of the same file for equality
Neither do I, I was just talking about the "idiomatic C++" approach. (I also recall a recentish cppcon video decrying "teaching C before C++".)
Structured binding packs give more power than the for loop. They can emulate the for loop, while the for loop cannot emulate the structured pack.
Really appreciate the response and the information! Thank you very much for all the detail. You’ve inspired me to focus on some SQL libraries and to tinker around with some of the base functions to build off of. 
The OP confuses ideas with good marketing with good ideas. Then he overcommits: The guidelines he cites say to avoid goto, not never use it. So yes, just because some bug was caused by code adjacent to goto doesn't make the goto indefensible. Programming is hard. If you want a discipline where you can cite an authority then not have to think about it, try... actually I cannot think of *any* discipline where that is reasonable. Goto rarely, but goto when it helps. Use RAII commonly. Test when you can afford to, on the time:return scale you are working on. Use templates, but be aware that they have the power to generate a lot of code and that can be a problem. The STD library is a decent default, but be aware of its limits and flaws. Anyone who shows up with a book of dogma and argues from revealed truth should not be trusted. 
So people have noticed deficiencies. In most languages you fix these by one-off language features. C++ has gotten into the habit of extending the language to permit *writing* the language feature you'd otherwise want. Not with infinite descent, but 1 or 2 layers. This doesn't always happen, but when it doesn't we often find we regret it. The price is that you get insane amounts of power and choice. You can still write vectors of structs. And it remains just as useful. 
If you are easing for_each type algo on struct fields, it assumes you are already have some homogeneous code/algo. See the example in the article. It already deals with multiple different fields. If you want homogeneous fields, I assume you can specify it in the lambda (that way your code won't silently misbehave if you add another field of different type). So any code that could silently break is the one that assumed some specific struct structure, which is wrong to begin with. Same as assuming that `arr` in `for (auto &amp;x : arr)` has exactly/no less/no more than/etc/ `N` elements.
Using that signature for main in a hello world example is just plain stupid, as is the `using namespace` and we can discuss whether or not a hello world should contain std::endl; and the return 0; The purpose of a hello world example is to show the minimal amount of code the prints some text on the console files really doesn't serve that purpose but is am deliberate exaggeration. I'm not arguing that c++ is pretty complex, but you don't have to make it worse than it is. Also, if you compare it to most other (non-interpreted) languages it is not more complex than they are. 
So? If it gets the job done efficiently and in an raii to understand way, why go for something more complex. That part of c is part of c++. Why behave as if it doesn't exist? Also, the non-c version isn't much more complex either.
By that measure, usage of something like `std::shared_ptr` is out of the question then; unless of course you roll-your-own with something like `boost::intrusive_ptr`?
Where does the author say to never use goto? Btw.: Not using a particular error prone feature, even if you really found one of those unicorns (they exist) can have the advantage of simplifying other tasks. E.g. code review: A simple rule "Don't use goto" - once agreed upon - can simply be checked and enforced. If you just say "avoid goto" and someone iin the team uses it, that leads to discussions whether or is really warranted here (which is often more a matter of what you are used to than "objective" metrics. Also, you need some suppression mechanism for your analysis tool to say "here it is really ok" and so on. What I'm trying to say: On a case by case basis it might be advantageous to employ certain features/ patterns / techniques. Looking at the big picture though, it might be better to go for the somewhat inferior but much more common technique. 
Ugh! This reminds me of the usage braced-initializers behavior on ctors accepting initializer_lists. I've basically advised my team to simply avoid it altogether, especially for external APIs. But at least with this CTAD quirk, if you create an unexpected type, you'll run into compilation issues when you actually do use it differently. So it's not as bad as braced-initializers. However, it certainly doesn't feel nice reading code that sometimes uses CTAD, while other times doesn't (for the same reasons as with auto). With this kind of inconsistency, I'm leaning towards a discouraging the use of CTAD in my codebase. I never minded writing make_* factories anyways. I've even seen codebases adopt a convention of templated classes having a static member function called "make". So with C++11; we got Almost Always Auto. Perhaps with C++17 we can Almost Never CTAD.
Iostreams are for formatted output; with no formatting taking place here, I'd argue it's the wrong tool for the job, and that _`std::puts`_ (rather than `::puts`) is the correct tool here.
The difference between those two functions being important does a lot to reinforce my point that even hello world is not easy in c++!
You are conflating "easy" with "obvious". It is extremely _easy_.
Well I actually just googled c++ hello world and copy pasted that... And I was taught a form very similar to that a couple decades ago, so this isn't some cherry picked example. A lot of people have that snippet as their first contact with the language. I certainly have never seen a STD::puts in a hello world before, for example.
To a newbie those two are very similar things. Do you think learning c++ would be any harder if we rot13'd all the key words? Or would it just be less obvious.
It's low? Compared to... a repl? A jupyter notebook? A CLI? Framework.js? This must be why C++ programmers are so poorly paid and have such awful job prospects. Because it is so easy the market is flooded in comparison to all the other languages! A lot of things "aren't difficult concepts", but that doesn't mean they are easy to a beginner, and that doesn't mean they don't inject baggage into the learning process. For example, after staring at the inverse of the Schur compliment for a while I decided it was intuitive. Yet I doubt most students (who really just want to solve a linear system) would call applying it to solving bundle adjustment problems easy. And it isn't clear what benefit knowing that technique gives a practitioner who really just wants to call Optimize(). 
&gt; This must be why C++ programmers are so poorly paid and have such awful job prospects. Uh, lol? Not only is this entirely fallicious, but it's entirely counter to my personal experience. Have fun with your "argument".
Whoosh
&gt; Today, if we’re using CTAD with a copy, the copy takes precedence. OK, I gotta ask the obvious question: why?!? Why would a "CTAD copy" take precedence? I'm just a simple programmer. Being a simple programmer, I had assumed that this: std::tuple c(a); would be syntactic sugar for some imaginary thing like this: std::tuple&lt;auto&gt; c(a); where the "auto" is deduced from the argument `a` (with decay, unless it's in a reference_wrapper), *before* picking any constructor/copy-constructor of the fully-determined type. I did *not* expect these two to be the same: std::tuple x = foo(); auto y = foo(); because I would expect the `x` to be a `std::tuple&lt;decltype(foo)&gt;`, while the `y` to basically be `decltype(foo)`. And I think I'm like most programmers. ;)
No, I got your sarcasm; I happen to disagree with it – outside of a handful of cities, C++ jobs are hardly abundant or overpaid. And sarcasm or not, the line of thought is no less fallacious. ;-]
Hmmm.. responding to myself... I can think of a counter-example: void do_stuff(std::weak_ptr&lt;Foo&gt;&amp; weak) { if (std::shared_ptr ptr = weak.lock()) { ... } } It *would* be pretty surprising for `ptr` to be a `std::shared_ptr&lt;std::shared_ptr&lt;Foo&gt;&gt;`. Dammit, JF Bastien's right.
You can have a look at the vc++ Blog. They definitely used puts, but that's also the only place I've seen. I don't remember what my first c++ hello world looked like, but I know how I teach c++ and throwing code at them at isn't used doesn't make sense. All that being said. It isn't hello world that people struggle with - why are we even discussing it? Also , all the things mentioned here are not a problem initially (to use X I have to include Y, things from the standard library are prefixed with `std`, a pointer is an address). Where c++ gets tricky is if you try to learn what all those things really do and how they interact. If you - as kate said in her presentation - stop to teach c first one don't only start to teach people how exactly vector works before you show them how to use it, the first few classes can work out quite pleasantly. It is when you try to teach people c++ from the ground up that they say "omg that's complicated - all I wanted was X" and stop there after two days
Right now we have many build systems with their own solutions for library management. However, if something like this caught on, it would be probably end up being more convenient, I like it.
Plugin it's a shared library that may be loaded at run time used for extend its core software with some extra optional functionality. 
Typically, I would expect to see something along the following lines: If (condition) // with space func(args); // without spaces Anyway, don't take my joke too harsly, the actual content of the video is good.
If you mean something like pip install for cpp, then its just a library / package managment, calling it plugin is a bit wierd. Anyway, it is exetremly needed, and all the existing package managmement tools are horrible (Nuget for example, which is not cross platform as far as I know). If you can come up with a decent package manager that would be great.
You can, but you will find they are never equal. What you probably meant is that you can test for equivalence. That works fine for strings as well: if (std::filesystem::equivalent ("c:\\source\\foo\\bin\\foo.exe", "foo.exe")) ... As a side note, this means we can also finally standardize `#pragma once`. Previously the big stumbling block was that file equivalence could not be determined, but since that functionality is now in std::filesystem there really isn't any reason not to finally standardize this massively useful feature. 
How does it compare to this existing framework? https://www.boost.org/doc/libs/1_68_0/doc/html/boost_dll.html
I'm already using a library like this : https://github.com/Marqin/dynamicLinker If you have a solution to share globals between exe and plugin, I would be really interested ! 
Say I've written a simple text editor like nano in cpp, what does that mean I manage plugins for this application
I'm not so familiar with this library, but I guess that it does the job that part of my fremwork will do, which is the loading part. The main focus is the whole division of plugins. Also, one thing that I have done is make some modules (like the loader) optionals, so if you don't have boost in your application (I don't like boost for instance), you can built your own loader or use another that uses other loader (Qt or dlopen, for instance). The main thing is that you register your interfaces, let's say that your application will support to extends some dock widgets and some actions in your menu. So you register the interface of the dock widget and the action in the framework and if there is any shared library that is compatible with these interfaces, they will be loaded and registered to thiese interfaces "magically". 
I think that this answer fit here as well: https://www.reddit.com/r/cpp/comments/9c9kqz/do_cpp_users_wantneed_a_cross_platform_framework/e596d8c?utm_source=reddit-android
Sort of, yes. 
What I would love to see is a plugin system that takes LLVM bytecode as the library input so that a single compiled plugin could be distributed to all platforms.
Something like this? https://pocoproject.org/pro/docs/00100-OSPOverview.html
Yeah we did a similar thing at my company - used a macro to generate a real enum class, plus associated enum-&gt;string, string-&gt;enum, iterators, ostream&lt;&lt;, etc. It's really not that hard or ugly, and a lot better than an external code generation step. Unlike your implementation, we used Boost PP; we did it as a single sequence of tuples, so the limit's 254 not 64. We didn't think about using an `optional&lt;T&gt;` style return value - instead we have two functions for conversions: an exception-throwing func and non-throwing one that takes an argument for what to return if the conversion failed. I kinda like your model better I think so I may suggest we change ours to use an optional-style (though last time I checked we've got over 700 enum classes being generated, so it might be painful to change now). Also we had to work in C++11, in both gcc and clang, and inside both namespaces and classes. Can wise_enums create an enum inside a class/struct?
Whoa, I'll study the details latter, but seems a lot like the Bundle Management described there. 
No one is arguing against typedefs; the standard already has that typedef: `std::uint16_t`. Once again reinventing wheels. ;-]
You can also try ``` print("Hello, World!", end='') ```
Your text editor probably doesn't have many different features. For example, it might not have spellchecking. It might not have regex-based find/replace. It might not have google translate integration. Whatever. You can't think of all the features but obviously someone will want something you don't have. However, you know that other people will want to add those features. You want them to be able to without you needing to be involved. If your code is open source on github, then they could write a patch and make a pull request, but then it will take some time for you to pull it, and you might decide never to do that. If your app is proprietary, then it's even worse, it's simply not possible for them to add new features. So, you might use something like this, or roll your own, to make a 'plugin' system. That is, your text editor will, at runtime, scan the 'plugins' directory for .so or .dll files. Then, it will link with them. then, write code in your app that when 'menu-&gt;plugins-&gt;&lt;dll filename&gt;' is clicked, It will search through those files for a compiled C++ function called 'text_transform_plugin_main(std::istream&amp; in,std::ostream&amp; out);' (for example), and call it from inside the dll at runtime. Now, if someone wants to add google translate functionality to your text editor, they don't have to contact you. They don't even have to recompile the text editor. All they have to do is compile their google translate functionality into a C++ library with that method, compile it as a .dll file (like en2es.dll) and copy the compiled dll to the compiled application 'plugins' directory and click 'menu-&gt;plugins-&gt;en2es' and boom, it just works. Basically it lets your users develop extensions or additional functionality for your app without needing to ask you permission or have access to your source code.
Since you're in the design phase, don't reinvent the wheel: look at how windows COM works. 
Have you seriously never used plugins e.g. in your IDE? browser? text editor ? office software? Or is this just about clarification to make sure everyone is exactly talking about the same thing?
Check again, he's not talking about any of the things you're talking about. He's talking about 'plugins' for C++, like libraries. 
I have. Explain to me what a cross platform framework for plugin management is.
So as I said: why do you ask what a plugin is? &gt; Explain to me what a cross platform framework for plugin management is. That is a different question to your original. Cross platform usually means it can be compiled and run on windows as well as on linux -no reason to believe it means something different here. The rest is up to the author to explain (I don't know anything beyond what is written in this post) 
It _is_ going to be in the stdlib eventually, and there is an implementation available right now that is incredibly well tested and reasonably well documented. Why delay?
Is your question why you are learning outdated C++?
Because C++ has moved on. Like, by a lot. Turbo C++ isn't even C++ compliant because it wasn't even updated to the first standard. &amp;#x200B; Please tell your university, and any programming student you meet to tell their university, to stop using Turbo C++. Use clang or gcc or Visual Studio. The first two are free and the second has free versions. And they're all standards compliant.
[SaaS world](https://github.com/Ebenezer-group/onwards) requires some build integration. I think it's inevitable.
Are you planning for your directory to possibly be a network resource, that is, a remote URI? That could allow remote updating of deployed programs. Of course latency would be a problem, but a caching system could be implemented. Another way of looking at it would be that your local directory could be considered to be the local cache, and you have the option of defining a remote URI where your framework could check if the local cache is in sync with the remote "repository". The Eclipse IDE extensively uses plugins ("Everything is a plugin" is their motto :) and have streamlined the process. You could have a look to what they do, too. I find your framework interesting, although admittedly I haven't investigated the already-existing options. Please keep us informed.
Maybe he's running `Turbo C++` under `ms-dos-3.3`.
It sounds like it's an IOC container with plugin support.
I've done something like this myself [windows](https://github.com/mkn/mkn.kul/blob/master/os/win/inc/kul/sys.hpp) [linux/bsd](https://github.com/mkn/mkn.kul/blob/master/os/nixish/inc/kul/sys.hpp)
I'd suggest looking into [dynamix](https://github.com/iboB/dynamix) - with it you can separate interface from implementation and build a plugin architecture on top of that. It allows you to structure your business logic in a different way from the traditional classes/inheritance approach. I'm using it for my game engine achieving great modularity - I'm even able to hotswap entire plugins at runtime (and thanks to the [lightweight reflection/serialization](http://onqtam.com/programming/2017-09-02-simple-cpp-reflection-with-cmake/) - I'm able to even change the layout of classes at runtime...!) There is a great lecture about the dynamix library by the creator: https://www.youtube.com/watch?v=-s0zYXGCfJk
No we used to run turbo-c under dosbox that ran on Vista/win7 . Produced 16bit binaries wouldn't run on the machines that produced them. It was weird.
yep. 
COM IS language agnostic 
Unless there are Indian CS professors on reddit, you are unlikely to get a satisfactory answer here.
No answer they might possibly give would be satisfactory. It's highly negligent and an incomprehensible decision.
My employer's codebase has a number of these issues. Some of them arose many years ago, when the relevant C++/std features were still problematic, and now the benefit of changing them wouldn't be worth the pain of the transition period. For others, we're still not convinced the mainstream is right. For example, we have our own string class. We like it because it is reference-counted, which std::string can not be. It also supports Unicode nicely, where for a long time std::string was agnostic about character representation. Is it based on UTF8 or ANSI or some code page? We also have our own smart pointers. I think if I were starting from scratch I'd advocate using std ones instead. However, to switch now would be very painful. It would take a lot of effort just to get it to compile, and there would surely be new bugs because our idioms differ. One advantage of our pointers is that they are intrusive, which means they avoid having an extra memory allocation without needing to use make\_shared(), and a raw pointer can be converted into a counted one without duplicating the count and without needing some weird shared\_from\_this overhead. We also have a smart pointer that stores a non-const raw pointer, exposes it as const, and provides a kind of type-safe const\_cast to get at the underlying non-const one. Our weak pointers have less overhead. What we have works, so why go to the trouble of changing just to match some arbitrary standard? I'm still not convinced about auto. I find the code easier to read when the types are manifest in the code. We've also had silent bugs where a function returned a type different to what was expected. Maybe if we started from a clean codebase those bugs wouldn't have happened, but we have to live with the codebase we've got. Meanwhile it's simply not that onerous to write `int` or `iterator` or whatever. The redundancy of manifest types helps readability and helps detect bugs. 
I'd like it too, but frankly shipping LLVM along with a normal software is a fucking pain (and a 80 megabytes-something addition to your releases).
plug-ins aren't generally for simple applications. But imagine that you want to support a lot of file formats for your text editor - having import / export support as plug-ins means that other people can easily add their own file format without touching your code or recompiling
&gt; (for now this link is made using an ID), I hope that you are at least usin UUIDs, else it *quickly* becomes a big pain.
I did not want to bring up DosBox, runs one of my favorite games, so nothing against that. But F-U-C-K, what are these people (your teachers) thinkin', it's an out-right disaster, change schools ASAP. How good can their teaching be if the proposed tools are, well, archaic doesn't even begin to describe it. Good Luck, modern C++ is a lot of fun!
The fact that you cannot explain what it is is precisely why I asked. Because I assumed the author meant something different by plugin. You can see the rest of the comments and a lot of people are confusing it for a shared library or package management system. 
Meh...that's nothing. I will just add it to the 50 something rules list we already have.
When we took the compiler theory course I used to think wow this frontend stuff is great, there's a lot of things one could do with ASTs outside of compilation. I bet no one has thought of that. Imagine my surprise when I later found out about llvm :P The turbo-c issue has mostly to do with computer science curriculum being designed in early 90s and people not caring enough about it to be changed. In recent years having internet has really helped change the tide, students are more aware of recent compilers and more of them arguing with teachers everyday. Sometimes they succeed in convincing, sometimes they don't. Funny thing, there are still c++ books coming out using pre-standard c++ that often have a c++03 "appendix" where they briefly cover templates and STL. I'll see if I can find some pages.
Shared ptr is to be avoided yes, as the compiler can't optimise away something which has guaranteed side effects due to the use of atomics. Intrusive ptr can be better, but if you're reference counting things in a single thread use case, that suggests suboptimal design because there is an implied lack of single ownership of resources. As with all rules, one must break them occasionally, but a rule is useful to make you stop and pause before each time you break it.
Why is it `int argc, char* argv[]` and not `const char*[] argv` or even `const string[] args`? The older I get, the more I see, how complicated C++ is. I used to think, it has to be that way, but I'm beginning to doubt myself. I still think, C++ is a great language, but it is a bit complex.
Not sure what's with the condescending tone of the title. Maybe you're unaware that he's retired from C++ for a while. That's not "fallen" - and shame on you trying to make retirement shameful.
I have a ton of other work left to do and this is not immediately required. Also better to wait until it's in std and final. I'll evaluate it then and see which part(s) I can use.
It was not my intention to be in any way condescending, I think the quote literally fits. I always considered Scott to be one of the greats of C++ and now (understandably) he has _fallen_ from C++ greatness. If anything I think this reflects poorly on the language that maintaining your level of expertise requires so much work (to say nothing of keeping up). 
Name one language, that is actually useful, that doesn't require maintaining your level expertise. Understanding the developments in your field - it's called professionalism. If you haven't noticed, C++ has had 2 new standards in the past 7 years. Even a perfect language upgraded with two completely new standards would be hard to keep up with. Hell, even Java programmers have complained about having to keep up with the introduction of lambdas and streams.
So you are unhappy that they did something smart for a change?
Obviously nobody expects Mr. Meyers to keep up with new language features, he's explicitly talking about fact checking stuff he wrote. &gt; Hell, even Java programmers I get that the reddit community is siding with you on this issue but I have to say that I find it ironic that I'm the condescending one.
Look at the Copy&amp;Swap idiom. There you don't have that problem at all.
Considering the size of today's games, 80 MB seems like a small price to pay. Couldn't it be statically linked as a library into the executable to minimize shipping issues?
&gt; Not sure what's with the condescending tone of the title. It's a Bible quote from 2 Samuel. It's a pretty common literary reference and it's generally considered to be respectful: &gt; 1:25 How are the mighty fallen in the midst of the battle! O Jonathan, thou wast slain in thine high places. &gt; 1:26 I am distressed for thee, my brother Jonathan: very pleasant hast thou been unto me: thy love to me was wonderful, passing the love of women. I took it to mean a positive, "What a shame that this great figure in the C++ field has so completely retired".
It doesn't right now. I just realized though, there is way to do it. The functions need to be declared as friends. They would have to be separate macros but I could add the capability to do it. Are you interested? Right now, my suggested workaround is to just declare it in a detail namespace and then create an alias in the class, which I don't think is so bad. Happy to answer any other questions. Also if you look at the issues page you can see a bit of a roadmap of future improvements (I'll probably add this as well).
You can't use string in the arguments afaik
Don't mix the Windows Component Model with the COM implantation. While the model itself was state of the art back in the good old days, it's superseded by now. The COM implementation on the side is the most error prone (due to pseudo virtual functions) and slowest (due to the use of shared process memory) implementation of an interface I've ever seen. Oh, and basically it's not portable at all, because of lack of support for the COM interface generator MSVC uses.
&gt; I think it makes sense, because you rarely want to have nested templates. Maybe? But then, would you really write tuple t2 = t1; to mean copy?
Yes, just like a explicitly writing template arguments for `t2` would do. 
But explicitly writing template arguments and `auto` both guarantee behaviors, while just writing `tuple` does not.
How does `tuple` not guarantee behavior? Type -&gt; placeholder for CT -&gt; auto
Oh I see. Thanks!
This is a post about the errata of a C++ programming book. It's not a biblical tragedy
Most implementations provide their own alternative entrypoints and it seems nobody cared enough to make a std::vector&lt;std::string&gt; one. Possibly because the conversion is a one liner and anything complex has to use a decent argument parser library anyway, so nobody cares. From your alternatives the a char** argv without the argc could work since it is terminated by a null string so there is a way to find the last pointer. You couldn't do the same with string[] since there is no null string object. 
No, on the contrary: I wish they did it more often. 
Thanks! I'll study it more deeply. 
Plugins are an implementation detail. I usually just statically link the whole thing together. There’s no point to explicit factoring of stuff out into plugins, unless the plugins are an API that the customer can write their own code to, as a means of extending the functionality of closed source software. Even then, there’s no need for that API to be used by the implementation. Shared libraries speed the compile-debug iterations during development, but again — none of this should have any bearing on how the final product ships. Don’t expose development tools and all that, unlesss absolutely necessary. 
\&gt; but I've had hard times building it on Windows &amp;#x200B; Yeah, sorry about that. Most TMP tricks that static reflection uses under the hood are not MSVC compatible (yet). Also installing LLVM/libclang on windows is a bit of a pain. I have windows support in my roadmap, but that would mean having a reliable way to get the llvm dependencies (I'm working on cross-platform LLVM/Clang conan packages), and then touch the library internals til MSVC accepts the TMP sorcery.
I'm planning the way that it's possible to change the "default way" in the future. I'm not think about finding from network for now, because it increase the complexity and I don't have enough time. But I'm keeping that in mind, since it would be a great improve. 
Geez, it's at the BEGINNING and NO ONE is using. Sure I'll use something more quick, I'm just more concern about architecture instead of the little details of implementation. 
And yet another all powerful, hard to use feature in the making instead of giving users the simple, restricted, easy to use feature they want. Well, that is c++ for you. 
I don't really get you. Maybe you thinking about package manager, which is NOT what I mean. I don't know if you read all the post, but... What? "unless the plugins are an API that the customer can write their own code to" yes, it may to. Why there's no need for an API like that? You prefere to rebuild your application everytime that a new (maybe optional) feature comes in? 
That is like complaining, that a lip will produce a different output if you add another element to the array. The whole purpose of the loop is to adapt to the array's or in this case struct's size.
Qt plugins deal only the loading part. 
I think I miss understood the question before. It uses the dlsym, yes, but not to load shared libraries built to help your development, but to load shared libraries that may be built further for your own application. It's not a "runtime package manager" 
Just reading the comments here makes me wonder how perception changes depending on one's culture. Perhaps the OP should have stuck with the title in the blogpost to prevent confusion.
Every time you think a post here is an innovative idea, there's someone mentioning an existing Boost implementation of it. 
&gt; this is the first time in the language where we can have two variable declarations that look like they’re declaring the same type but are not. So char x[] = "a string"; char y[] = "another string"; does not count? (There's a more misleading variant of the above declarations: using strlit = char[]; strlit x = "a string"; strlit y = "another string"; but I guess it is too uncommon.) 
I don't understand. If we were consistent with CTAD, such that this from the linked blog: std::tuple x = foo(); resulted in `x`being `tuple&lt;tuple&lt;int&gt;&gt;`, then why wouldn't this: std::shared_ptr ptr = weak.lock() result in `ptr` being `shared_ptr&lt;shared_ptr&lt;Foo&gt;&gt;`?
Was that a jab at Java programmers? I thought his point was that even Java - generally considered a much more user-friendly language than C++ - requires keeping up with new features.
vcpkg is great, but as far as I know, llvm package in it doesn't contain libtooling nor libclang.
How so?
I knew it was old (but not old enough to be this outdated),but unfortunately not the people who designed this curriculum. 
Could contracts save us from this bug? Seem like an easy thing to check and could do that check only in debug.
I can directly construct a `tuple&lt;tuple&lt;int&gt;&gt;` from a `tuple&lt;int&gt;`. But I cannot directly construct a `shared_ptr&lt;shared_ptr&lt;int&gt;&gt;` from a `shared_ptr&lt;int&gt;&gt;`. This is what I mean by `shared_ptr` not having wrapping behavior.
This is very cool. I didn't know this existed. 
!removehelp
What kind of code do you actually expect the compiler to generate for this kind of for loop? Do you expect that \`var\` will be different sizes in different iterations of the loop, and everything on the stack frame after it will shift up or down in each iteration of the loop? How do you expect that debuggers like \`gdb\` are going to cope with that?
This is nothing special, std::vector (and all containers) own all their contained items. By having a vector contain itself, all he's done is created a circular ownership loops. &amp;#x200B; It's no different than writing: struct A { shared_ptr&lt;A&gt; next; }; { auto a = std::make_shared&lt;A&gt;(); a-&gt;next = a; } // Leaked a Of course this leaks memory, in C++ the programmer is responsible for breaking ownership loops. 
How would your simplified model handle template constructors? For example the `vector` constructor taking two iterators. How would that work? 
Actually checking in the general case (circular ownership semantics) is not at all easy. It amounts to implementing tracing garbage collection, a notoriously finicky task that leaks to all kinds of corner cases. Moreover, it's not a part of the 'contract' of any one object or unit of code. Rather, it's the sum total of a bunch of (possibly cross-library) interactions that ends up creating a loop, and no individual component is responsible for "closing it". &amp;#x200B; Herb Sutter actually gave an excellent etiology of the problem and a proposed limited solution for tracing circular references in C++ in a [talk](https://www.youtube.com/watch?v=JfmTagWcqoE) here. You can view his (highly-experimental) [repository](https://github.com/hsutter/gcpp) here.
But why on earth would you have to write code like this? I mean genuinely, Is there any use case for such code?
When you say this is nothing special, what do you mean? Do you mean it's common for a vector to have a reference to itself so that this situation is nothing exceptional? Or did you mean that this situation isn't magical or supernatural? Like there's a reason why this happens and that reason can be explained and understood? If your suggestion is the former, I'd argue you're wrong and most uses of a vector do not contain cyclic references to themselves in the way described by this video. If your suggestion is the latter, then I don't think your comment is saying anything that the video isn't saying. The video isn't suggesting that this has no explanation or has no cause, this video is saying that when we use a vector, we might take for granted some properties and make assumptions 99% of the time that work just fine. This scenario is that remaining 1% of the time where our heuristics break down and special care needs to be taken.
It wouldn't - it would try to construct a `vector&lt;iter,iter&gt;` and would fail compilation, with some ugly error because the second `iter` would be treated as an allocator for `std::vector` but not meet allocator requirements. I'm guessing that's not what people would want, but it's simple and consistent. To me, consistency trumps convenience. It's not the end of the world that you can't use CTAD to do everything. Special rules suck. Having said that, I'd still be ok with the user-defined deduction guides being part of step (1), so that for vector this (might?) fix it: template &lt;class Iter1, class Iter2, typename std::enable_if&lt;std::is_same&lt;Iter1,Iter2&gt;::value&gt;::type = 0&gt; vector(Iter1 b, Iter2 e) -&gt; vector&lt;typename std::iterator_traits&lt;Iter1&gt;::value_type&gt;; Yeah, seems crazy. But really having `tuple x(y);` act differently based on the number of arguments also seems crazy. :(
M_get_deleter() and M_dispose() are the one I see most frequently, it improved somewhat by avoiding copying the pointers where possible.
[https://gitlab.com/chriscox/CppPerformanceBenchmarks/wikis/ClockTimeAnalysis](https://gitlab.com/chriscox/CppPerformanceBenchmarks/wikis/ClockTimeAnalysis) is now updated with EC2 Linux results. &amp;#x200B; ( and I just love that 15% of the links in Amazon's twisty maze of documentation lead to 404s )
If you aren't using it for something, you have a problem. 
Sure this leaks memory? Per definition yes sure. Buut [https://godbolt.org/z/g2eTTW](https://godbolt.org/z/g2eTTW) I'm unsure. You can see 2 Calls to \~V(); Guess another example of compilers being smarter then us?
Nontemporal loads/stores are powerful, but it's rather easy to introduce bugs using them. Be careful before using in production.
Vectors (and C++ more generally) does not in any way guarantee a property that objects to not (directly or indirectly) own themselves. If anyone is taking that for granted, they are just plain mistaken. &amp;#x200B; So when I say it's nothing special, I mean that this is an example of a general phenomenon (memory leaks caused by cyclic ownership) and that this general phenomenon is a commonly-known property of C++ which contrasts it with languages that have tracing GC. &amp;#x200B; See Herb Sutter's cppcon talk I linked in another reply. &amp;#x200B; &amp;#x200B;
&gt; I mean, I can focus on the actual work instead of wasting effort on extraneous overhead. As much as I agree, I've worked with too many people who never bothered to learn anything more than what you've described. The moment their project became remotely complicated, needing different build configurations, or even just needed to be added to CI/build pipeline, they were totally hamstrung. Too often, since I had the knowledge, I was tasked with solving their issues and integrating their work with everyone else's. Somehow, they always seem to be more senior than me, and are never made to change their ways, so I get to spend the next few years hearing about how CMake is such crap and a huge nuisance, despite the fact that they're the ones who initially couldn't handle whatever the particular problem was. I've stopped volunteering to help people fix their builds. I'll advise, but no longer do it for them. I really wish there was some magical middle-ground that was as easy as managing simple VS solutions (or even QtCreator projects) yet not fraught with gotchas once you reach moderate complexity.
FWIW, PS4 also contains similar instructures
It was more a question, why we are using char* as strings in C++ for our main function. I know why, but a beginner already has to know 2 string types. One is a hack using a convention to pass around pointers to null terminated arrays and the other one is a library type, that has many reimplementations in different APIs (think Qt). Most languages have a type like our std::string as a builtin, which also gets used in their main function.
The char*[] without doesn't work in C++, because you can't determine the size of an array at runtime. This is also an additional complexity in C++ , which is just accepted in C++. A simple language would probably use fat pointers or something else, to allow asking for the size instead of having the as an additional argument in functions. C++ chose to solve this in the library with std::vector and std::array, but that is additional complexity someone new to C++ has to learn. There are proposals for something like std::vector in main. I don't think they are necessary, they would probably just add to C++'s complexity. I just wanted to point out, that that is an additional complexity, that someone new to C++ is exposed to.
The last line swaps v, which is a vector that holds a single element, with v.front(), which is an empty vector. This leaves v as an empty vector. Nothing now refers to the vector that holds a single element. Hence leak. One of the calls to \~V() will be executed zero times because it is in the destructor of an empty vector.
What specific bugs do you have in mind? Nontemporal operations can certainly result in a slew of performance bugs if used wrong, but correctness-wise should have identical results to movdqa when used on a single core. &amp;#x200B; For multicore, you do have to worry about ordering, but the hardest part about that is not wrecking performance by naively placing sfence everywhere - adding an sfence to each release fence would suffice for correctness, unless the stdlib mutexes don't respect ordering w.r.t. nontemporal instructions.
Well Lisp already exists.
Ohh yeah didnt see the ret instuction on clang, and jmp on gcc. Thank you for pointing that out.
Do you have any material in mind that would help starting digging?
&gt; The char*[] without doesn't work in C++, because you can't determine the size of an array at runtime. One of the requirements of argv is that argv[argc] == NULL. So you could check it if needed. 
Indeed! Not sure if that's covered by https://gcc.gnu.org/bugzilla/show_bug.cgi?id=84101
OK. That's true. Talk about unusual special cases regardless. Let me rephrase. As long as you don't work for the u.s. government, in the united states, all software is automatically copyrighted at the moment of authorship. Your milage may very based on country.
Commenter points out how complicate C++'s "Hello World" is for a real beginner; dozens of back-forth responses ensue, arguing over various ways to take advantage of special `main()` behavior or use less-common language features to make it simpler, thereby proving commenter's original point. Ahh, gotta love reddit. :)
The copy and swap idiom has some drawbacks as well. Does some extra pointer and size_t copies that otherwise wouldn't be necessary. Take by value and then move the member values is better. IMHO.
Yes, you're right. I should have elaborated further.
Thank you for clarifying for me. I appreciate it.
Trade-offs; [TL;DR](https://twitter.com/rygorous/status/727582946761179136 ): "On x86, NT stores bypass all memory ordering *and* force-evict data from *all* cache levels. Even L3." Other than doing well in microbenchmarks, the main use of non-temporal moves is moving data/buffers between GPU and CPU. Some notes from http://lists.llvm.org/pipermail/llvm-dev/2016-May/099025.html: "x86 NT stores do have a valid use case, but it is limited, and a compiler absolutely should not be generating them without either (a) an explicit request from the programmer, or (b) a reasonably precise memory model that includes caches of an explicit targeted machine, because they are only beneficial if you can prove that the address being stored to is not in cache, and would not be present in cache at next use even if a normal store were used. For very simple synthetic benchmarks with large loop trip counts (and by “large” I really mean “staggeringly huge”, given modern L3 sizes), it’s possible to statically know that these criteria are satisfied without a full cache model, but those cases are pretty limited and not obviously beneficial outside of benchmarks. Weight against this small benefit, there are a two big things that can go wrong with NT stores, which make me very wary of auto-generating them: - they break some of the usual ordering guarantees. - the performance is catastrophically bad (significantly worse than normal stores) when the address is present in cache. My experience is that while there are indeed a few beneficial real-world uses of these instructions, if they aren’t deployed extremely carefully they cause more problems than they solve, and LLVM doesn’t at present have the infrastructure that would be needed to accurately inform their use." See also: * http://sites.utexas.edu/jdm4372/2018/01/01/notes-on-non-temporal-aka-streaming-stores/ &gt; But, while non-temporal stores are expected to have a shorter buffer occupancy than that of a cache miss that goes all the way to memory, it is not at all clear whether they will have a shorter buffer occupancy than a store misses that activates an L2 hardware prefetch engine. It turns out that on the Xeon E5-2680 (Sandy Bridge EP), non-temporal stores have *higher* occupancy than store misses that activate the L2 hardware prefetcher, so using non-temporal stores slows down the performance of each of the four STREAM kernels. I don’t have all the detailed numbers in front of me, but IIRC, STREAM Triad runs at about 10 GB/s with one thread on a Xeon E5-2680 when using non-temporal stores and at between 12-14 GB/s when *not* using non-temporal stores. * https://blogs.fau.de/hager/archives/2103 &gt; What are NT stores good for? Again, most references cite them as a means to avoid cache pollution in cases where stored data will not be re-used soon. That’s true to some extent; every word that you don’t store in your cache means more room for other, more frequently used data. But that’s only one half the story. Imagine you have a code whose working set fits into the outer-level cache and which produces data to be stored in memory. Using NT stores for such a code will probably slow it down because, depending on the LD/ST balance, performance is then limited by the memory interface. The true benefit of NT stores can be seen with a truly memory-bound code which is not dominated by loads, like, e.g., the STREAM COPY benchmark, relaxation methods, the lattice-Boltzmann algorithm, or anything that can be formulated in terms of stride-one store streams: By saving the RFO, the pressure on the memory subsystem is reduced. See, e.g., my talk at the KONWIHR results and review workshop in December 2007 at LRZ where the performance boost through NT stores was demonstrated using a 2D Jacobi (5-point stencil) code. * https://stackoverflow.com/questions/35516878/acquire-release-semantics-with-non-temporal-stores-on-x64 Enhanced REP MOVSB (ERMSB) is often preferable for copying data (depending on the range of sizes) -- cf. https://stackoverflow.com/questions/43343231/enhanced-rep-movsb-for-memcpy
You've heard the parable of the academic who was shunned, ultimately losing his post and entering industry, for staunchly taking the unpopular stance that his peers in academia suppressed dissenting opinions far more aggressively than those outside the Ivory tower?
PS4 is an AMD x86_64 chip (https://en.m.wikipedia.org/wiki/PlayStation_4) so that’s not surprising.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9cg4rb/please_help_me_with_this_c_problem/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I work in robotics, and we had exactly the need for a framework for plugin management. We looked a bit to existing solutions ( https://github.com/OSVR/libfunctionality , https://github.com/sourcey/pluga , http://www.dre.vanderbilt.edu/Doxygen/6.5.0/html/libace-doc/a05228.html , https://pocoproject.org/docs/Poco.SharedLibrary.html ) but eventually we rolled out our own solution, available at https://github.com/robotology-playground/sharedlibpp . A new project in this area that I think it is quite interesting is ignition plugin, available at https://bitbucket.org/ignitionrobotics/ign-plugin . A non-trivial feature that I think it is important to have in this kind of frameworks, is to be able to (optionally) compile a bunch of plugins and the relative factory class as a static library without source code changes, to support systems without dynamic loading capabilities. 
Thanks! I'll take a look at these projects. I neve thought about this feature that you mentioned. I'll think and study about it and see if it fits at my project, but it seems to be more a change in the build process than the framework "core features". Maybe is there a way to make this process easier, though.
Makes sense. Thanks!
Sometimes, boost hana doesn't work because \- You are on c++11 and not c++14 \- You need to support a specific version of msvc In these cases I have this one that I made: [https://github.com/cbeck88/visit\_struct](https://github.com/cbeck88/visit_struct)
I'd probably just use boost fusion then (and have used it in the past). Your library also introduces a repetition over all the fields. One repetition is better than more, but zero is best, which is what you can achieve with fusion.
Haha yup I called it out mainly because these instructions are pretty common in the console world for things like loading and save states where bypassing the cache is a common optimization 
One part is indeed the build process, another part is that the factory class should be able to allocate a class available in the static library instead of a class that is allocated opening a plugin using `dlopen`/`dlsym` or similar. 
I've personally used nontemporal instructions to great performance benefit in the real world - the use case was mostly that we kept certain garbage processes from polluting the L3 cache so more was left to important ones, but the same principles apply. CAT has somewhat gotten rid of that use case but the same thing works within a process. &amp;#x200B; I agree with the LLVM email and responses on the twitter thread; I would never advocate autogenerating them because of the ordering and some bad cache cases. To have any use they require having serious knowledge about your memory access characteristics. On recent processors I got some auxiliary measurements that the performance wasn't too bad when lines were present in the cache, but I certainly didn't enumerate all the ways that memory can be in the cache. &amp;#x200B; I actually cite that exact part of the McCalpin article in the post! The inconsistency is easily the worst thing about nontemporal instructions and what really limits them to special-purpose-only IMO. One can use benchmark code I provided but it depends on the application. &amp;#x200B; I think the last post you mention is going after a different goal than what I'm writing about. I'm purely considering uses where one sacrifices certain regions of memory by storing them to ram in order to ensure that important datastructures reside in memory. Bandwidth isn't much of consideration here. One dumb example could be a server cache - if the cache holds say 20gb of pages, one might want to enforce that the pages remain in ram (where they'll likely be anyways) to ensure that search and lookup structures remain in the cache. &amp;#x200B; The last I tried it REP MOV\* still write-allocated cache lines. Another benefit of using nontemporal instructions is that if you have many 'small' stores, say 128-256 byte blocks, you can keep them out of the cache instead of playing games with REP to convince it to use some internal nontemporal stuff. &amp;#x200B; I'll add a section about the downsides- I had kind of assumed the worst performance downsides were obvious because the stores were intended to evict from cache and go to ram, but it's probably worth mentioning.
I view that as a non-issue : if you need it, you can trivially make a macro over my macro so that no repetition occurs. I could add it but none of my users have asked for it. The more interesting case is, you get a bunch of structs from a hardware vendor and you can't change the header (or at least, its really fishy to do so). In my case I can still visit the structs using my macro and get the names. I have used boost fusion before. I've found the syntax to be really painful at times, and the compile times as well, its another "supporting pre c++11, use boost::mpl" library. I think boost fusion is good for talking to boost spirit and that's about it in my book.
You can also just run it yourself and see only one destructor: https://wandbox.org/permlink/ARr9rX1vmzxe8LeJ
Indeed. That one at least has the "develop your own feature" part solved. As I've never used lisp I can't speak to the quality of the one-off features.
You mean MRAM? It'd be great for sure, considering that it's not as fast as SRAM that are used in caches.
Saving without losing FPS basically?
They're working on that, but the more important the feature, the longer it takes. We got `constexpr`, that's a good first step. The rest is coming.
Is there a way to say "this pointer is not shared on different threads"?
But that's only when you need it though right? I'm pretty sure any sane implementation would not do RTTI on types without virtual members. If you don't have a smart pointer version that directly calls `free` or `delete`, you're likely doing something wrong. Note that it might not be explicit in your code, but the compiler should end up generating this kind of code.
\&gt; For you, as a software engineer that uses c++, do you like the idea of a lightweight modular framework for plugin management? &amp;#x200B; There is already the POCO framework and the BOOST.DLL libraries for managing plugins. But the problem of C++ plugins is the lack of C++ standard ABI among compilers. So if, a third party developer compiles the plugin with a different compiler or even a different version of the same compiler that was used to build the main application, they will not link. The only way to ensure that classes compiled with different compilers be compatible in the plugin system is the base class be an interface class, a class with only virtual methods and no STL containers and also the cannot have any STL container in the class signature, just C-types as STL is implemented differently among compilers. The Windows famous COM/OLE system which Microsoft nowadays calls Windows-rutime works in this way, but it uses the registry to locate the DLLs containing the implementations of the standard interfaces. &amp;#x200B; The ABI issue is solved on Unix as the compilers, gcc and clang are adopting the same ABI, but not on Windows as Microsoft's Visual C++ Compiler, VC++, MSVC - still breaks the ABI on every major release.
I can explain what a plugin is which was your original question. And as I asked in my original post &gt; [Don't you know what a plugin is?] Or is this just about clarification to make sure everyone is exactly talking about the same thing? So the purpose of your question was the latter right?
Oh cool, you watched the video too.
Personally I'd prefer more work in the one- off feature domain (e.g. enums, maybe properties) than in the generalized metaprogramming domain. 
Memory leaks are nothing special. They are just memory addresses who go out of scope. ^^^^^^^/s
Well, as I said some where else: [For better or for worse:] That is c++ for you.