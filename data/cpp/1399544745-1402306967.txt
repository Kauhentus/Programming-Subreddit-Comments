You don't need them, but it helps with the readability and some other useful stuff. An example is to create syntax highlighting based on the prefix/suffix of the Raw string. In this case I can highlight beautiful json inside the example in Vim editor.
Is is_permutation the first and only algorithm in the standard library with O(N^2 ) complexity? **Edit:** Yea, I meant is_permutation instead of is_partition
&gt; I'm not sure I completely understand what's going on in that code. And it doesn't seem like you ever set `_index` to a value, so I suspect there's at least one bug. Well, it's only a demo of the dispatch method, so indeed nothing is constructed... `_index` is supposed to be an index in the type list indicating which is currently constructed. The purpose is to demonstrate how to get O(1) visitation on concrete types, which is what happens underneath in `boost::variant`. It can be used for moving, copying, destructing, or any other visitors really (your imagination is the limit). It's more efficient than going through the base class when the user wishes to invoke methods on the concrete type that are not virtual, and leads itself well to inlining even for virtual calls. Note: the `static` variable is `const` and thus thread-safe. The language guarantees that a local is initialized only once (and guards it appropriately), and in the case of a completely constant variable the compiler can even put the variable in the `.rodata` section. TL;DR: it just works. &gt; For regular method calls, emplacer does a reinterpret_cast to the abstract base class (which is always safe because it only allows itself to hold subclasses) Unfortunately, that is erroneous, and thus unsafe ([in action here][1]): #include &lt;iostream&gt; struct Base0 { virtual ~Base0() {} }; struct Base1 { virtual ~Base1() {} }; struct Derived: Base0, Base1 {}; int main() { Derived d; std::cout &lt;&lt; "Derived: " &lt;&lt; (void*)&amp;d &lt;&lt; "\n"; std::cout &lt;&lt; "Base0: " &lt;&lt; (void*)(Base0*)&amp;d &lt;&lt; "\n"; std::cout &lt;&lt; "Base1: " &lt;&lt; (void*)(Base1*)&amp;d &lt;&lt; "\n"; return 0; } Yields: Derived: 0xbf9a3218 Base0: 0xbf9a3218 Base1: 0xbf9a321c As we can see, as long as your base is: 1. polymorphic (ie, has at least one virtual method) if your derived class is 2. is the first non-empty base inherited by the derived class 3. is NOT inherited virtually then it will probably work on compilers following the Itanium ABI (don't know about MSVC). However, there is no guarantee in the Standard that it will always hold and there are plenty of concrete cases where it does not actually hold. Notably, break any one of the points above and it will in all probability break. If you want to play it safe, use the dispatch method I highlighted in my previous post with the following visitor: template &lt;typename Base&gt; struct BaseCaster { template &lt;typename T&gt; Base* operator()(T&amp; t) const { return &amp;t; } }; [1]: http://ideone.com/J4GjJH
I suspect you meant to say `is_permutation`. Also I believe `sort` was originally allowed to be O(N^2 ) worst case because in practise quicksort was better on average than mergesort. Since the development of introsort, C++11 has restricted `sort` to O(N·log(N)) complexity.
&gt; Well, it's a hell of a lot cheaper than just calling `sort()` Depends, libc++ at least has optimized its `sort` algorithm for already sorted (or reverse sorted) collections, so while it's still likely that `is_sorted` is faster, it may not be faster by much. However, `is_sorted` is still useful, especially when you cannot modify the collection (and need choose between two algorithms) or for sanity checks.
I believe you meant `is_permutation` here.
I remember being interesting in the fact that the Mill CPU provided multiple flavors of addition (and other operations): - fail on overflow - wrap on overflow - saturate on overflow (and I may be forgetting a flavor or two) But as mentioned when it's not baked into the language it's a pain for the optimizer to guess the intent, leading to sub-optimal generated code.
That's interesting. The C++03 standard indeed only mandates average N*log(n) complexity and recommends using the stable versions for worst case guarantees. Still it seems to be the only algorithm that performs in O(N²) on average. And what is even more odd is that that test can be done in N*log(N) complexity with some extra memory. Anyone know the rationale why this algorithm was included?
&gt; I am not a C++ syntax expert, but does static_cast have a close tag or did his text editor insert one? auto const r = static_cast&lt;uint32_t&gt;(v % 10);&lt;/uint32_t&gt; possibly my favorite comment ever on a c++ article.
Those are (almost all) the talks for Meeting C++ 2014. I could only publish those where I have the ok from the speaker, so a few are missing, keynotes aren't yet online, but Scott Meyers and Hartmut Kaiser will give them. Already known through the voting is the popular track: * Monads in chains * Expression Templates Revisited: Separating Facts from Urban Legends * Pruning Error Messages From C++ Template Code * Sqlpp11, An EDSL For Type-Safe SQL In C++ For Databases, Containers, Streams And More * Multithreading done right? * Testdriven C++ with Catch * The C++ Memory Model Schedule by begin of June online, will fly tomorrow to C++Now...
This is pretty cool. I wrote one of these that wasn't as flexible. I'll definitely keep this in mind if I need it again.
A user-chosen end marker is a standard thing for heredoc-style quoting as it's the only way to ensure you never need to escape anything. Suppose you wanted to have a string literal that contained a snipped of C++ that itself had a raw string literal (e.g. `R"end(std::string json_string = R"({"name":"John", "age": 12})"; )end"`). Obviously any constant syntax for this can't possibly work as it'll always appear within the string as well, so it's left up to the user to pick unique deliminators for each level of nesting.
I think the argument is that in practice, you're actually more likely to run into the special cases - if you're maintaining a sorted list, for example, it's likely to only be completely random once, then it will be the almost-sorted case that would often work poorly with quicksort. So it's still a case of, if you know your particular pattern, you can choose a better sort; they're just favoring the case that's more likely among less educated developers who are likely to just use the default, and hence on average doing better.
Looks like the site is down, so [here's a text-only google cache version.](http://webcache.googleusercontent.com/search?q=cache:codexpert.ro/blog/2014/05/07/five-new-algorithms-to-cpp11-you-should-know-about/&amp;strip=1)
At my office, some of the data we process comes in as sorted vectors 99% of the time. If it's not sorted, it's not our job to sort it, we have to kick it up to the people we get the data from. We use is_sorted as a sanity check on these before we continue trying to process them. If it's sorted we go about our merry way, if not we can quit processing right there.
I sincerely hope that's not a troll.
Is there a mirror somewhere? It looks like .ro is not accessable from where I'm working.
Just click again. :-)
I do admit finding it slightly strange, seeing as if you are maintaining a sorted list (for example), you can easily use [`inplace_merge`](http://en.cppreference.com/w/cpp/algorithm/inplace_merge) to do minimal work to put the newly pushed back elements in their sorted position.
That's actually most different. The algorithm in libc++ is not explained anywhere so it's a bit of a pain, but it's (in spirit) equivalent to [TimSort](http://en.wikipedia.org/wiki/Timsort) which has been adopted as the default sort method in Python and Java now (if I remember right).
It would be helpful for those of us who have done callbacks forever if you had some side by side comparison of the two approaches.
I get what you're saying, that people might do it, and all too often. But nonetheless that doesn't make it right. If you have sorted data and you want to make changes while keeping it sorted, then simply sticking the changes onto the end and doing a full re-sort seems careless. The designers seemed to be faced with a decision: optimise standard case (i.e. completely unsorted) or optimise various special cases. Where either decision will adversely affect the other case. Personally I feel (and I wholly admit this is just a feeling, I don't have figures to back it up) that since the special cases seem to represent an incorrect approach to the problem, then optimising for them was the wrong tradeoff. 
Nope. It's a TLD that no one in the group that controls the firewall has decided to let through yet.
 * Always use RAII. * Rule-of-3/5/0 * Become familiar with programming principles like modularity, orthogonality, separation of concerns, etc... * Don't write crappy code. 
I put [an example for signals in the wiki](https://github.com/schlangster/cpp.react/wiki). It mainly focuses on the "less boilerplate" aspect. Not covered there yet is that unlike with uncoordinated propagation, you also get properties like glitch-freedom and avoidance of redundant updates. For example: VarSignal in; Signal x = in + K; Signal y = in + J; Signal z = x + y;` When in is changed, z is only updated once (no unnecessary updates) and z will not be updated before x and y (no glitches). But you pay for these properties with a certain overhead. I measured the example from the link with this code: http://pastebin.com/TCtiui3h Callbacks: 0.023599s Signals: 0.309419s I'll add some more examples that cover the motivation for events etc. in the future. Edit: When changing both dimensions at once with D::DoTransaction([&amp;] { myShape.Width &lt;&lt;= i * 4; myShape.Height &lt;&lt;= i * 2; }); its down to 0.177204s.
Ah, good old-fashioned cheating.
Personally, I an not a huge fan of missing semicolons, and I also prefer using curly brackets for defining block scope. It makes each statement and block unambiguous. I think a better place for adding syntactic sugar is the templating system. For instance, the `auto` keyword could be really useful here; a simple template likes this: template&lt;typename T&gt; void Foo(const T&amp; X); could be made equivalent to this: void Foo(const auto&amp; X); ...much like polymorphic lambdas.
I'll be the annoying one and ask: Any plans for video recording? Any idea on a video release schedule? CppCon has been promising to be a strict superset of Going Native, but I fear they won't be able to livestream and release videos as quickly as GN 2013 was able to. This is okay, of course. I just want the videos eventually. It'll be a huge loss to the C++ community if videos are not made available. I, along with others, link to the GoingNative 2013 videos often. Edit: On a slightly related topic, I was bummed to hear C++ and Beyond 2013 videos are at best delayed, and at worst lost. Hope to hear some news on that front soon.
Would making the update to z lazy help the performance?
I agree - and that's exactly why I wanted to get rid of some of the punctuation. Having read a lot of code in C++ &amp; JavaScript on one hand, and in Ruby &amp; CoffeeScript on the other (which don't have the braces &amp; semicolons), I realised that code with less punctuation is invariably easier for me to parse.
The only problem with all this remains STL's horribly long iterator syntax. Bleh.
Probably, .ro domains are considered very dangerous. :))
Quick -- how wide is a tab? Does everyone you share code with agree? 
&gt; I’m quite fond of languages with minimal syntax. Not only it is easier to read and write code in these languages – it also provides an opportunity to reduce errors (both at compile time and at run time), when you consider that every character in a program has the potential to cause an error due to being misread or misplaced. In addition, long, dense lines of code littered with punctuation increase the cognitive burden on the programmer. How is number and kind of whitespace less likely to cause an errror due to being misread or misplaced? There are obviously very different tastes when it comes to syntax. Personally I do not like the syntax of Python or other languages where the amount and type of whitespace changes semantics. It could, however, be useful if someone made a translator from their favorite syntax (i.e. Python, Lisp, TCL, Pascal, ...) to C++, so that they could use the rest of the language without being confused by syntax. Cooperation between developers with different tastes on the same project could be a problem. Ideally, languages should be defined without any syntax (or a simple i.e. Lisp-like syntax for storage), and different frontends could then provide syntax for the different tastes. 
Indentation is easier to parse for a reader - otherwise why would we bother indenting blocks in C++? So what we have now is essentially *two* ways of delineating a block used at the same time. 
It's the same as in Python :) 
Templating like that wouldn't really make much sense because its not automatic type inference here. Personally I think [D's templating](http://dlang.org/template.html#function-templates) works well: void Foo(T)(const T X); Which looks very clean. In fact D syntax is around just really nice. 
&gt; C++ is plagued by many special characters throughout the code I tend to agree with that. When I first saw C++11 lambdas, I was a bit confused. I get the impression that the standards committee is a bit hesitant in adopting new keywords as part of the language spec (which would make sense if clashes with variable names in old C++ code is a concern). I'd love to see lambdas like this int Moo = 0; const auto&amp; Foo = [&amp;Moo](int Boo) -&gt; int { return Moo + Boo; }; ... defined something like this: int Moo = 0; const auto&amp; Foo = int function(int Boo) capture(&amp;Moo) { return Moo + Boo; }; ... where `function` and `capture` are reserved keywords. `capture` is optional, and can be omitted if you don't intend to capture anything. The latter version needs more characters to type, but it is self-documenting code, and the syntax is more or less more consistent with existing syntax for traditional function definitions. 
It doesn't really matter as long as it's wider than zero and you don't mix it with spaces.
If the author thinks that syntax is the most pressing problem to be solved in C++, he doesn't know shit about C++.
Cool. I've found myself often wanting any_of, none_of and all_of when asserting on collections of elements. Nice to see them standardized.
Who said anything about the most pressing problem?
Nobody. I'm saying that you're proposing a "solution" to a non-problem. IOW, C++ has its problems, but syntax is not one of them. (E.g., will your syntax enable the compiler to produce more user-friendly error messages when template instantiation fails?)
Python handle that quite gracefully. In real project, this is not an issue : * the rule about indentation needs to be homogeneous only at the file level. So you can mix libraries with different settings. * you have efficient tools to detect incoherent settings across your codebase. * for any (sizable) project, you read more than you write, therefore the net gain in productivity due to readability. * there a very very strong community convention of 1 tab==4 spaces. Python have other problems : the low speed, the type system, the "expression vs statement" and the parallelism approach. Syntax is not one of them in a sizable project (and if it is a small project, you often don't need to care about this stuff). 
*Hmpff.* That is, until the posts delves into line concatenation symbols. After that, *Ugggh.* 
&gt; noone in the team 
A good idea. I would like if the capture syntax was thrown away entirely from the signature part and captured values be used for example like this: int Moo = 0; const auto&amp; Foo = int function(int Boo) { return captured.Moo + Boo; }; That would also reduce the times that you type some code and only deep in the implementation (well, hopefully not very deep since it's a lambda function) you realise you need that one more variable. You type *captured.* before the variable name and go on with the code, instead of having to go back to tweaking the function signature. It can also prevent capturing variables that aren't needed in the function anymore (for instance, some temporary debugging variables that the developer might forget to remove from capture list).
Well, according to documentation (https://docs.python.org/2/reference/lexical_analysis.html#indentation), the tab *character* is replaced by the amount of spaces needed to align with the next multiply of 8 spaces. That is the old standard behaviour of terminals. A Google search reveals that there are different opinions about tabs vs. spaces, and even the preferred size of the tab-character in the Python community, just like in other PL communities. This means that some developers will have their editor configured to insert a tab character when hitting the TAB key, other configurations will insert 4 spaces, some inserts 2 spaces. This must lead to problems when people are working together in the same code base. You might say the same issues will apply to indentation of other languages, which is true, but the program willl still compile/run on a computer with a different setup. It will also be possible to see exactly what was the intended semantics of the code, because all meaningful tokens are visible.
This is one of the reasons I never got around to doing much Python. I really like the explicitness of C++. I missing tab isn't going to screw me over. I want to make sure that something is a block.
&gt; You type captured. before the variable name and go on with the code, instead of having to go back to tweaking the function signature. One issue I see with that is you lose control how the object in question is captured. You'd want specify whether something is captured by referecne or by value. This is especially important if your lambda will be invoked through a binding or a packaged task. 
Yeah that happens, and encapsulation and abstraction often means it happens a lot. Another example in a similar vain is something like this: struct x { std::string a, b, c; x() : a{"quick"}, b{"brown"}, c{"fox"} { } }; Will do 3 separate allocs instead of 1 large one. However...sometimes when performance really really matters and you can make a case that this is causing a bottle neck you can look into remove these things. A good example of that is say the BLAS where the subroutines do not allocate, but you have to pass workspace in as an argument. But it's not often such a level of optimisation is required.
What's 'worse' is that the code you listed isn't even very good. To write it out efficiently you'd have to add `const&amp;` to to the lambda param. Which just adds to you're point. auto iter = std::find_if(m_properties.cbegin(), m_properties.cend(), [&amp;] (const std::shared_ptr&lt;Property&gt;&amp; property) { return property.get()-&gt;GetType() == propertyType; }); That said, I don't think this line is all that great: return (iter != m_properties.end()) ? *iter : nullptr; It's be better to just return the iterator, or an optional&lt;T&gt; rather than adding pointers into your code.
&gt; This means that some developers will have their editor configured to insert a tab character when hitting the TAB key, other configurations will insert 4 spaces, some inserts 2 spaces. why would it be ok to mix tabs and spaces even in langauges where white space isnt significant? I never worked professionally on a code base where it wasn't stated what standard to use. This is a non-issue in the real world.
C++ already have the same backslash usage as python have, what it really does is escaping out the new line character
That's true. And probably one of the reasons lambda is implemented currently the way it is. There's lots of control in C++ that is not present in purely object-oriented languages such as Java.
Well, if that's the requirement, you surely can't go better than O(N²) - but if I were to come across such a task, I would make sure to either provide operator&lt; or a hash function to make this sub O(N²). So why this requirement? Why not let this take an ordering like next_permutation and prev_permutation? Just to be clear, I'm not asking "Why does this algorithm have O(N²) comlexity?" but "Why was this algorithm included in the stdlib when it has to be in O(N²) on average the way it is currently defined"? (For non-degenerate cases, anyways). Especially given the circumstances that it seems not very generically "good", i.e. in most, if not all, use-cases, you should be able to implement a sub-N² variant (via an ordering or a hash). It just seems like this is hiding a performance problem in plain sight, which none of the other algorithms seem to do. So this kind of seems to violate the old advice that you should use stdlib algorithms when in doubt. But maybe it just seems that way - TBH, I haven't come across a lot of use-cases for this test anyways. 
or borrow Microsoft idea and use ^. MyClass* rawPointer; MyClass^ sharedPointer; MyClass# unique pointer 
It wouldn't be ok, but happens in real life. Some popular editors are by default configured to mix tabs and spaces. Some programmers doesn't care which characters they put in to a file, as long as it compiles and look ok in their editor. I have seen this happen a lot of times. I have written and explained indentation rules for my team with no disagreement from my team members, just to see that they broke the rules in their next commit.
That is actually nice. I haven't used Microsoft's C++ technologies, too bad syntax like that isn't standard.
Good find, thanks for pointing out. The code was from some old project that I used to try the new C++11 tricks, back then I recall I had read from some tutorial/article that smart pointer objects should be passed around by value, not by reference. Can't remember why, but there was sound reasoning for it in the article. Haven't used C++ at all lately so it's good to get corrected.
In the example given at the end the only real difference besides braces I see is how the author is trying to highlight a simplified for loop syntax... except the example on the right is no longer how we write that in modern C++. If he shortened it to modern syntax the number of lines would be nearly the same, maybe less depending on the writers preference for placing braces on newlines (the author also threw in some additional blank lines on the right that aren't reflected on the left). for (const auto&amp; appender : appenders_) { The other place the author appears to intentionally overcomplicate the righthand side with C++98 syntax is iterators which can be defined as this, to further shorten the code example. auto iter = std::find(_appenders.begin(), _appenders.end(), static_cast&lt;EventAppender*&gt;(NULL)); I'm not against trying to improve the language but for all that was shown the only real difference I've seen is removing braces which really just seems to be a matter of personal taste. C++ is a pretty complicated language and I cannot see anyone realistically making a branch of it just to remove braces. It also feels like the author went out of their way to make the C++ side overly verbose as well, they even mention C++17 which means they should be aware of the very basic C++11 features pointed out above.
&gt; The less you have to type, the faster it is to implement things, and that leads to happier development. Bullshit. I spend much more of my time thinking than writing code. Faster typing, if anything, is conducive to more buggy code. C++ needs better abstractions for working with collections of data (something like Java's streams or linq), not a cosmetic change that accomplishes nothing.
&gt; Just because he suggests something which doesn't solve the number 1 problem why is that wrong? What's wrong with suggesting a facelift to a homeless woman? &gt; Also, do you even know who the author is before you start throwing shit about him? He's a living person who had a public brain-fart. Do I need to know more? --- Also, from the about box on his homepage: "I found that there were no books which focused specifically on C++11, and I wrote C++11 Rocks book as a result. " Well, there are Stroustrup's books which *specifically* cover the new features. Then I downloaded the sample book chapter, on type inference, from the website, and on page one he uses iterators to iterate over a collection. What about range-for, when he's already advocating C++11? Range-for is also perfectly suitable for explaining 'auto'. Who is he? Another average C++ programmer with an overinflated self-image.
&gt; What's wrong with suggesting a facelift to a homeless woman? Arguing with analogies is just plain stupid. Moving to another domain invalidates mostly everything by leaving out some details. But I can see you are just out to cause havoc and by childish behind the protection of your monitor - carry on. 
I prefer const everywhere (where possible) - so you don't change your variable by accident. And reference instead of value - so you save one copy and temporary object. If I wrote the lambda, it would look like this: `[&amp;](auto `**const&amp;**` property){ return property-&gt;GetType() == propertyType; }` Also I'm nos sure about the ternary operator, both return sides must yield the same type. I've burned few times myself, assuming `NULL`will be auto-converted to my smart-pointer-like class, but it didn't, when I was testing my code with different compiler (Mac's CLang vs MSVC).
Isn't this the exact opposite of where things are headed in CS? in recent years, there is a movement towards referential transparency, i.e. a function always returns the same results for the same arguments, but in the case of this library the same function returns different results each time it is invoked and there was a change somewhere else in the graph. I think that doing reactive programming in an imperative way, i.e. as in a spreadsheet is just asking for trouble, because the same function object will return a different value each time it is invoked without any connection to its arguments. 
Four-space indents with tabs replacing each set of eight spaces is an actual indenting style used by real projects. AFAICT the entire point is to ensure that the end result is unreadable unless your editor is configured exactly the same as the author's.
&gt; Some programmers doesn't care which characters they put in to a file, as long as it compiles and look ok in their editor. I consider that an argument in favor of semantic whitespace.
The drawback is that this requires the client to specify the ownership information in the call, which is arguably redundant (although it’s not if the client uses [AAA style](http://herbsutter.com/2013/08/12/gotw-94-solution-aaa-style-almost-always-auto/): `auto ptr = …`). An alternative is to defer construction and returning a proxy object which has implicit conversion operators to `shared_ptr` and `unique_ptr`. Then the code could be used – without runtime overhead – like this: unique_ptr&lt;shape&gt; ptr1 = make_shape(type, bounds); shared_ptr&lt;shape&gt; ptr2 = make_shape(type, bounds); `make_shape` would look something like this: deferred&lt;shape_factory&gt; make_shape(shape_type type, rect bounds) { return {type, bounds}; } And `deferred&lt;factory_type&gt;` would call the appropriate `make_with_ownership` in its conversion operators.
Sometime I wish C++ had interface like Go or trait like Rust, inheritance and virtual function make me run away in horror.
That's a good point about the casting. If nothing else, I'll try to fix that. But I won't have time until at least the weekend.
I think this may be somewhat of a misunderstanding. I'll try to clear it up with an example: int Width, Height, Depth; auto CalcArea = [] (int width, int height) -&gt; int { return width * height; }; auto CalcVolume = [] (int area, int depth) -&gt; int { return area * depth; }; `Width`, `Height` and `Depth` are manipulated imperatively, because the input to our program has to come from somewhere. `CalcArea` and `CalcVolume` are pure functions to calculate area and volume, respectively. To get the volume, you'd have to call `CalcVolume(CalcArea(Width,Height), Depth)`. Issues: * Without side-effects, we have calculate area explicitly; * expression is re-calculated even if the parameters did not change from the last time; * repeated sub-expressions are not cached. So normally, you'd have to wire those functions together manually, cache intermediate results, make sure everything is updated accordingly. Something like this: void SetWidth(int v) { if (Width == v) return; Width = v; SetArea(Width, Depth); } void SetHeight(int v) { if (Height == v) return; Height = v; SetArea(CalcArea(Height, Depth)); } void SetArea(int v) { if (Area == v) return; Area = v; Volume = CalcVolume(Height, Depth); } What this library provides is something to glue together those pure functions automatically. Explicit syntax (leaving out the domain stuff): VarSignal&lt;int&gt; Width = MakeVar(...); VarSignal&lt;int&gt; Height = MakeVar(...); VarSignal&lt;int&gt; Depth = MakeVar(...); Signal&lt;int&gt; Area = MakeSignal(CalcArea, Width, Height); Signal&lt;int&gt; Volume = MakeSignal(CalcVolume, Area, Depth); Alterative syntax, with questionable operator overloading: Signal&lt;int&gt; Area = (Width, Height) -&gt;* [] (int width, int height) { return width * height; }; Signal&lt;int&gt; Volume = (Area, Depth) -&gt;* [] (int area, int depth) { return area * depth; }; (Actually, I think it's nice because it visualizes the dataflow best.) Even less verbose, overloaded arthmetic operators for signals: Signal&lt;int&gt; Area = Width * Height; Signal&lt;int&gt; Volume = Area * Depth; If I understood you correctly, your point was that calling `Volume()` (alternative: `Volume.Value()`) relies on side effects, and consequently it's hard to reason about what it does. But it's actually a pure function of `Area` and `Depth` as you can see from the definition.
Very nice explanation. Pure functional and reactive are not at odds. Your library (plus the tons of pure functional reactive libraries in Haskell) is proof of this. Very nicely done library :-)
We would definitely like to record the sessions. However, we would also like to have much higher quality recordings (i.e., professional) than at C++Now. So while it is high on the priority list, we cannot yet promise anything. There are currently no plans to do live streaming. Releasing the videos (if we do record them) fast is not a priority either.
Isn't that what we want from the stdlib-providers? Maybe just limit it to types that you know for sure provide a strict-weak-ordering (integers, numbers, std::string, …). I would want my stdlib-provider to do this. (though I'll have to talk to the libc++- and libstdc++-dudes until MS acknowledges that Linux **is** the superior OS and decides to port all their software ;-)).
It's not the way C++ "looks" that makes it what it is. Ditto with Python. This is like painting a Prius Rosso Corsa (Ferrari's famous red color) and asking folks if they like it better...
Methinks you're the OP in disguise.
What is the unqualified end? First I've seen it, though admittedly have not been keeping up with c++14 too closely. 
I personally use a smart pointer pushed/returned from an entity pool in my game engine. I can access it via a raw pointer and share it as well if needed. But, different strokes for different folks.
One allocation for the price of two!
Start working through GitHub issues for the boost libraries. You can cherry pick easy issues to start off with, it will help you learn the internals of some cutting edge c++ code, and boost is very well known in the industry, so will look god on your resume.
What this guy says, plus have they released the server pieces yet? There are many client implementations including libcurl that would be just as effective.
I'm primary a .NET developer. And professionally work as well. I have also used Java for development, node.js, etc. I'm not really satisfied with the level of efficiency these have. Nor am I interested in making a website quickly, I'm more interested in making a good framework using C++. Also note, that the most efficient and largest companies use C++, so it must not be THAT insecure with pointers. 
Well, certainly it is *possible* to develop safe C++, but it takes more development effort. On the web everything is about fast iteration and rapid turnaround. Big companies use C++ because they can afford the design, implementation, testing, and maintenance, and still get a return on investment on the long tail. For a hobby project you don't want to waste time ramping up. IMO the main benefit of C++ on the web is highly-tuned performance. That would mean things like data processing, not web sites. Even then, I would personally rather invest my time in a newer language like Go, which has better support for things that high-performance web software needs (e.g. concurrency). 
Sounds nice; never used it.
It wouldn't be a pure win, and it would involve allocating memory in an otherwise non-allocating function. This is not the kind of cheating that I would implement.
I think the API for this is great and from what I can tell is headed to the standard. Right now only TCP based connections seem to be modeled, perfectly suited for creating and consuming web services. Support for UDP is still missing and this is disappointing as TCP just doesn't cut it for real-time simulations with a number of people.
I recommend watching http://channel9.msdn.com/Events/GoingNative/2013/Inheritance-Is-The-Base-Class-of-Evil which describes a much more elegant approach to the same problem without the need for inheritance (thereby side-stepping unique_ptr vs shared_ptr as an implementation detail). If you can't follow that approach, I would present that unless you're writing an API, the object will likely be used uniformly in terms of the kind of ownership, thus you should just have your internal API conform to the type you need; if that need changes, refactor accordingly (it's not a complicated refactor).
Nice place to visit, but it wouldn't want to live there! 
Essentially that's all I do with the dot net environment for the most part. All front end is done with CSS/JavaScript/html
I've tried looking at CppCMS but as you had mentioned it has gone somewhat flat, so I was turning to other methods. Is this really feasible still? 
Touche sir! 
I came for the waters, but I was misinformed.
Are you a common cpp programmer?
From what I can tell, you would want to support more TCP since its a faster connection. I know UDP is pretty slow. Do you feel that's a motivation? Edit. I have no idea why I'm getting downvotted for this
Have a look at [wt](http://www.webtoolkit.eu/wt). It's a bit like qt, modern and in active development with company backing. 
My boss and coworkers work on it, although I haven't looked at it. I can ask them to comment if you have specific questions (remember that Microsoft generally doesn't comment on future plans; anything that has been released or announced is fair game).
I'm definitely interested in making a stand alone cpp web mvc style application instead of piggy backing a cpp project off of a dot net or so, is that reasonable?
Should be possible on Windows. I don't see why it wouldn't be. 
As long as there is a distribution for it which I guess I can agree. There shouldn't be any reason it wouldn't work 
As with any project, you should be able to compile it given you have the dependencies in searched paths. However, there are also distributions for lazy Windows developers ready to download. :P
That's completely reasonable. The ideal candidate program to use Casablanca is a cross-platform C++ program which wants to consume data from REST endpoints. In order to make that easy, we have a bunch of built-in functionality such as a json decoder and http client. source: I'm a dev on casablanca. 
I was looking at it, and decided it was a little too early for it. I am presently developing an alternative solution (also to know exactly what has to go into it). (Note: I am in my summer inbetween BSc. and MSc. so I have time to do this). Another team that works with the same professor as me used libmicrohttpd with a nifty c++ wrapper they found. 
We do have support for making a web server: [http_listener](https://casablanca.codeplex.com/wikipage?title=HTTP%20Listener&amp;referringTitle=Documentation). Libcurl is a great library if you're looking to pull raw data from web servers with C-style programs. Casablanca aims to make the task a bit easier by facilitating asynchronous programming, automatically parsing JSON, and enabling a modern C++ coding style.
&gt; Don't be a masochist. Some people like C++ and are more efficient using it...
Openframeworks isn't very idiomatic c++, as I think it was originally targeted at the processing crowd. Personally i prefer [cinder](http://libcinder.org), and use it daily.
&gt; Don't be a masochist. Use a more popular (web) language. Well, using most of the popular web languages implies using a dynamically typed language. Which is like the pure definition of masochism :)
Beats me, have a play with it.
&gt; Start working through GitHub issues for the boost libraries. Boost internals after just one semester, talk about running before you can walk? I'd say spend the equivalent of another semester writing some projects **using** Boost, follow that with writing some utility libraries using template meta-programming. Only **then** start looking into fixing issues. Really, it sounds like you're saying - "Here's how to game the system: make a few trivial commits to Boost, then start calling yourself a contributor to make youself look great".
Sure, that was somewhat intentional. Note that you can *still* use `auto` – but of course you have to specify the type anyway: auto ptr = unique_ptr&lt;shape&gt;{make_shape(type, bounds)}; Again, this is by design. The “AAA style” article I linked above explains why this is beneficial.
That might be okay but it’s not what I’m suggesting (and OP’s article actually explains why this might not be wanted).
You can, see the “AAA style” article I linked, and [my earlier comment](http://www.reddit.com/r/cpp/comments/2549ic/developers_perspective_factory_functions_and/ched7vi).
Also it is good to use non-member begin and end, especially in generic code: template&lt;typename T&gt; void func(T const&amp; collection){ using std::begin; using std::cend; auto const end = cend(collection); auto it = begin(collection); for(; it != end; ++it){ ... } 
&gt; [dynamically typed language] is like the pure definition of masochism I guess some of the folks over at /r/BDSMcommunity might feel insulted from that ;-)
It's a good *movie* too!
&gt;with a number of people. Could you explain what you mean with those people? And could you give some real-life examples where UDP comes in handy?
&gt; So same as in qt, naked pointers really aren't a problem. Let's start with the fact that they cause lots and lots of completely unjustified heap-allocation for no practical gain at all. Continue this by taking the tons of possible leaks into the calculation that result from exception-unsafe code that this style almost forces you to create (unless you use `std::unique_ptr` and it's release()-method which only proves how insane this model is). Than there is the problem that you always have to check for null and never know whether pointers are owning or not. 
Thanks a ton either way for offering up your source code. I really wanted to see a system in full swing either way. I'll hit this up!
&gt; I will not dare to ask why I need to add .cpp at end of .h while template declaration. Don't do this. Who's telling you to do this? They're insane and wrong.
I love how the only commented line in the header is: #include "MyMap.cpp" //included .cpp 
I complain *every time* I see that. It's needlessly verbose and requests extra operations that may or may not be optimized away (in particular, an extra move construction and destruction). It should be written as `unique_ptr&lt;shape&gt; ptr(stuff);`.
Why mix braces and parens there?
To expand on this for OP's sake, definitions of template functions and template classes should live in headers, not .cpp files. Having to include a .cpp file in a header is a sign that you're doing something wrong, because its contents should have just been in the header to begin with. If that means that you have a header with no corresponding .cpp file then so be it -- there's nothing wrong with that if it's a template class. Compiling such a .cpp file by itself would have been a no-op anyway, because there would be nothing in there that instantiates anything; this is not the same as the case where you have regular (non-inline) functions that need to be compiled. You only need a .cpp file in rare cases like when doing explicit instantiation. 
+1 on the Bogart quote. Walter, I suspect you're being too obscure for this crowd.
I wondered as well if I was being too obscure, but it's my favorite quote from the movie, especially the laconic way Bogart delivers the line.
How do you deal with cinder's general compile-time killing effects? I found that even for a small (&lt;1000 line) project I got 6min+ compiles.
"those people" being thousands of connected clients. Real-life examples come in the form of MMO's, many MMO's opt to use UDP with a custom reliable protocol on top that is often "faster" than TCP.
I'm not sure why you're getting downvoted for asking an honest question. The reason for saying TCP is slower is its reliability aspects, as pgquiles points out the messages themselves aren't sent any faster, it's how they are queued and processed on the remote end that makes it "faster". That said I understand the WHY behind the lack of focus on UDP, it seems geared more toward niche uses than TCP. Especially in this day and age of building and consuming web services.
What platform? Even on my 2010 iMac I don't see anything like that.
The easiest way to do this is to dynamic cast the object until you find its real type, then take the address of the function, assuming you know the possible types.
It wouldn't really be the good type of cheating. It's pretty solidly in the realm of pointless benchmark-whoring, and it'd actively hurt things in a lot of cases: worse compilation times, an extra branch for small ranges with known size, 1+ memory allocations for small ranges of unknown size, it's not allowed to fail so if the memory allocation fails you have to fall back on the O(n^2 ) midway through doing things, and of course it's time that could be spent on more useful things. I certainly want my stdlib implementer to cheat when it's useful to do so, but I really don't think this is one of them.
&gt; It's also hideously old. Ouch. We don't get library builds for anything newer than VS2010 from most of our vendors, and our C++/CLI project isn't migrated from VS2005 yet because with VS2010 we have to target .NET 4.0 and our company's baseline specifies .NET 3.5 :(
Nice! C++ has several "web frameworks", the ones I know are: * [Django inspired web framework - CppCMS (this one)] (http://cppcms.com/wikipp/en/page/main) * [QT inspired web framework - Wt](http://www.webtoolkit.eu/wt), * [Sinatra inspired micro web framework - Wayward](https://github.com/simonask/w), * [Rest based "web framework" - Casablanca](https://casablanca.codeplex.com/), * [ASP inspired web framework - Cppsp](http://xa.us.to/cppsp/), * [RPC based, compiler to server + javascript - Duetto](http://www.leaningtech.com/duetto/) . All of those have excellent performance. 
My favorite: "I'm shocked, SHOCKED, to find there's gambling going on in this establishment." "Your winnings, sir." 
Wtf is a 'lazy destructor'?
Man, would love to get in on that. I work for a major web dev company and I'm trying to get them to move to c++ from a bunch of these badly modified CMS's. 
I'm in my ass end of my last two semesters for my b.s. In c.s. O I'm trying to familiarize myself and find something different for my organization
Big companies use C++, but not exclusively. For example, Microsoft usually uses .NET code for web services, but C++ for the Windows, etc. I believe Google is similar. Edit: I should add that if you want to do it in c++, go ahead. But you don't have to do it to follow the example of big companies.
Casablanca is such a gold mine of great quotes. I suspect the entire dialog of the movie is on the IMDB quotes page! Supposedly, Bogart thought the dialog was ridiculous and the plot unbelievable.
I'm more interested in cpp for personal reasons and for a lot of philosophical reasons as much as effieincy. . 
It is my suspicion that casablanca will turn out to be something really nifty in a year or two.
I think it is meant to be humorous, as in, "look at this lazy destructor, it does nothing!"
I can attest to the fact that Wt (pronounced "witty") is pretty awesome. I am not biased at all. I totally am not an Emweb employee ;-). In all seriousness, I actually knew and was very intrigued by Wt before I applied at Emweb, and I do think that bringing the widget abstraction to the web is a very interesting thing, and allows for very smooth development of highly interactive web applications. PS: Your Wayward link is wrong, it also goes to Wt.
&gt; Would you use libevent in C++ No I would use ASIO instead. http://think-async.com/ ASIO is written in C++ using modern idioms. It is a tried and true library used in many important applications. 
Thanks! Fixed.
Seconded. The approach in the article is so full of undefined behaviour, it is quite likely to break in a future compiler-release.
what is the benefit?
It's incredibly fast. And you can build a page with beautiful C++11/1y.
It says most of asio can be used without external dependencies, sockets probably not in the 'most of' part :)
I see. I was just a bit surprised. :) Thanks.
~~I see, is there any data comparison for the speed?~~ what kind of server does it needs? a, never mind I found it http://cppcms.com/wikipp/en/page/benchmarks_php, that is impressive! but I must say building and maintaining a complex site with C++, that is insane. 
I don't see how the Oracle vs. Google case is in any way relevant to Casablanca. It'd only matter if you created your own library that implemented the same API, and I have no idea why you'd expect MS to sue over that as opposed to things like suing every other browser vendor, wine, etc.
&gt; you have efficient tools to detect incoherent settings across your codebase. But that *is* an issue, you do not need any tools to check that your curly braces are in good order. It's never a good thing if there are two invisible and indistinguishable symbols that generate problems if mixed up.
It is not. If your build breaks when you change the *visual style* of your editor and add more code to a file, there is something fundamentally wrong with your programming language.
Yes, thats unfortunately the downside of the whole story. For every change in the .cpp files you have to recompile your whole project and stick to your programming model. But that shouldn't be really a big problem. To minimize the expenditure, people add some kind of html-cpp-template. In our case with cppcms you have the so called templates for the html pages: http://cppcms.com/wikipp/en/page/cppcms_1x_templates . And if you need to change something on your site, you have to edit only the html files. So you are writing basically a html-template parser. A very very slimmed down version of php, but keeping the efficience/performance in mind. 
It was a pretty powerful windows computer using visual studio 2012, now vs2012 is a /really/ slow compiler, when I tried with xcode5 and clang on a mac the compile took less than 60s, but the resulting executable did not work right. I was also using CMake instead of letting cinder make me a project. I think part ofthe problem was that most cinder headers pull in a hole lot of boost, I would love to see the cinder people replace some of their boost usage with the c++11 equivalents.
If you use good build tools you don't have to recompile the *entire* thing, but the point of recompiling each change = ouch still stands.
What about HTTP support? Libevent has a builtin http server.
Thanks for commenting! That is good to hear. I would have never dreamed of reaching for C++ to consume REST endpoints and decode JSON responses from them, so it's refreshing to hear about a REST SDK to make this easy in C++. There are a handful of toy projects I coded in Ruby due to easy of implementation that would have been just as fun to do in C++ if Casablanca was around at the time.
Released a library based on actively hacking these tables including MI cases (that he doesn't handle yet) and they work on GCC 3.x/4.x, MSVC and multiple other platforms. The only ones that need any work at all are EDG based compilers. Heck, try it - https://github.com/dascandy/hippomocks
You're not spoiling anything. Just playing around with a new idea. To be clear, you're saying that the proposed solution by /u/tending would not work? I'll look into the code you posted in another comment later, when I have time.
The address of Base1::f() is of type void (Base1::*)(). That's a type you can't convert to any regular pointer type with either a C cast, a reinterpret_cast, const_cast, dynamic_cast or even a static_cast. You'd have to make a horrible conversion routine to get anything out of it - I called my version a horrible_cast. The trick is to make a union of both types, and to write one and then read the other.
I guess native socket API is kind of a dependency. But if you are using a system without socket support you are already out of luck.
ASIO is lower level than that.
There's a [HTTP server](http://www.boost.org/doc/libs/1_55_0/doc/html/boost_asio/examples/cpp11_examples.html) in the examples. I have no idea if it's any good or if it's just a toy.
It sounds like you're looking for [cpp-netlib](http://cpp-netlib.org/) -- it's built on top of (Boost.)Asio (not sure whether it would work with the standalone version) and [provides](http://cpp-netlib.org/#overview) just that: &gt; The project aims to build upon the latest C++ standard (currently C++11) to provide easy to use libraries for network programming. We use the latest compiler versions and features with an eye on pushing the boundaries on leveraging what's available in C++. &gt; Currently the library contains an HTTP client and server implementation, a stand-alone URI library, a network message framework, and some concurrency tools. Alternatively take a look at the [POCO C++ Libraries](http://pocoproject.org/) (standalone w/ really fast build times).
Cool that you included Wayward on your list! Author here — I have to note that it's *super* early days for the framework, and that it certainly isn't ready for production at the moment. I'm currently working on development workflow, with Rails-like automatic "reloading" (which is to say on-demand recompilation), and it's looking good.
What do you mean with "isn't very idiomatic"? Isn't it just a wrapper lib?
Would you use cocos for a level editor?
Also, cinder is Mac/Win only.
I would use pointer casts since they return null when they fail rather than throwing, since throwing is expensive. Otherwise that's exactly what I mean.
One idea is to make an Apache module, as in [here](http://thomas.eibner.dk/apache/api.html) or [there](http://www.codeproject.com/Articles/491909/Apache-x-Modules-In-Cplusplus-Part). Your code acts as a request handler. You build it as a shared library (.so/.dll), and you instruct the apache daemon via its configuration what URI (server side view of URLs) are routed to it, and what is the path to your module on disk. Debugging can be tricky, they say to attach the debugger to the apache process. In this case you don't worry about event processing or thread pool management, because it would be Apache's business. While your module interface is in C, you can have all the internal implementation in C++ and expose the required methods vía extern C wrapping. On the stand alone setup, as a sort of academic exercise, you have a single thread example [here](http://www.boost.org/doc/libs/1_42_0/doc/html/boost_asio/examples.html#boost_asio.examples.http_server_4). While not using multicore, you have boost ASIO with coroutines, that bring a kind of enhanced control flow readability better than the sometimes called "callback hell" of other purely reactive frameworks. The price is that coroutines imply some kind of setjmp/longjmp of voodoo under the hood that can be counter-intuitive to some. 
Well, officially that's true, but there's good progress on the linux and android fronts, and iOS has been a first class citizen since the jump. Thankfully i'm not required to target linux or any mobile platform, so cinder suits me well, but if portability is paramount to your project, then you might be better off going with something else.
I'm using libevent for [Wayward](http://github.com/simonask/w). There are C++ bindings, but so far I'm keeping things simple (and dependencies down) by using the C API. However, the philosophy of Wayward is not to use the most advanced or cool features of C++11 as possible, but to keep things simple and dependency-free, to avoid complexity (meaning bugs, meaning unsafe code). You may want to take a different approach.
I would suggest FastCGI.
Does FastCGI support threads/libev?
How well does your libevent scale? Have you stress-tested requests?
You really don't need libevent. If the purpose is learning, writing your own event loop and event handler is very instructive. You can make it pluggable in several ways. One is by making it a library that others can link to. Another way is to expose a messaging api via some inter-process daemon (such as dbus). You can also use file descriptors or sockets as raw channels. I wouldn't start it as something pluggable. Do the bare minimum you can to accept an http header, parse it, and return a reply. Once you have that, you'll need to start understanding more of what the headers mean, and come up with way to route them. A typical webserver does the following: 1. Listen on a socket/port combination 2. Establish a connection and make a tcp socket for it 3. Receive headers 4. Parse the headers and formulate a response based on the request 5. Send a response with appropriate headers and response codes 6. Optionally keep the socket open and receive more data in the case of a comet request or websocket 7. Terminate the request If you want to implement the http(rotocol) yourself, you'll have a number of RFCs to read. I recommend writing tests as you go with a command line utility like curl. The great thing about a project like this is that it's extremely easy to verify if you have something working (or not). Good luck with the project. If you open source it, I wouldn't mind popping in periodically to comment or whatever.
I have never tried that or the GuiEditor. Generally I am a bit of a purist and just do things in my own code. I see cocos2d-x as a multi platform multi device way for my code to be distributed. I don't so much see it as a solution for my actual coding tasks. 
I found this link so far: http://www.codingunit.com/cplusplus-tutorial-compilers-gnu-and-visual-studio
It is a great movie! Most movies I view once maybe twice, Casablanca is one that I've yet to feet tired of. 
Excellent movie! It is what I thought about when first seeing the title. 
Well you don't have to use `setjmp`/`longjmp` for coroutines, you could be using fiber techniques.
Might I suggest looking at [Polycode](http://polycode.org/)? I haven't really used any of them so I can't really compare. Polycode seemed shiner but still needed development when I kicked the tires, but that was quite some time ago. I avoided Cinder due to it's lack of decent cross platform support. OFW seemed like a pain to integrate into a project but I didn't look to much at it.
FastCGI is a protocol. You can implement a FastCGI server using literally anything you want that's capable of communicating over a socket.
Not yet, but libevent is a thin wrapper around your system's native `kqueue`/`epoll`/IOCP/`select` mechanisms. Theoretically it only adds overhead as far as a few extra memory allocations and thread locks.
well aware of that fact, but it's simply not worth the additional code overhead.
I recommend using libevent 2 directly. Neither of those wrappers support all of the (recent) features, and it's pretty trivial to use libevent in a C++ application. As for HTTP, I don't have any experience with the built-in HTTP server, but I do know it will eventually be replaced by libevhtp according to the [2.1 changelog](https://raw.githubusercontent.com/libevent/libevent/master/whatsnew-2.1.txt), so you probably shouldn't expect too much from it.
I thought fibers were implemented using setjmp/longjmp. How are they implemented then?
It depends on the operating system. WinAPI has support through [`CreateFiberEx` and friends](http://msdn.microsoft.com/en-us/library/windows/desktop/ms682406(v=vs.85\).aspx). POSIX has support through [`setcontext` and friends](http://en.wikipedia.org/wiki/Setcontext), although its future/status is less clear than `CreateFiberEx`.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Setcontext**](https://en.wikipedia.org/wiki/Setcontext): [](#sfw) --- &gt;__setcontext__ is one of a family of [C](https://en.wikipedia.org/wiki/C_(programming_language\)) [library](https://en.wikipedia.org/wiki/Library_(computing\)) [functions](https://en.wikipedia.org/wiki/Subroutine) (the others being __getcontext__, __makecontext__ and __swapcontext__) used for [context](https://en.wikipedia.org/wiki/Context_(computing\)) control. The setcontext family allows the implementation in C of advanced [control flow](https://en.wikipedia.org/wiki/Control_flow) [patterns](https://en.wikipedia.org/wiki/Design_pattern) such as [iterators](https://en.wikipedia.org/wiki/Iterator), [fibers](https://en.wikipedia.org/wiki/Fiber_(computer_science\)), and [coroutines](https://en.wikipedia.org/wiki/Coroutine). They may be viewed as an advanced version of [setjmp/longjmp](https://en.wikipedia.org/wiki/Setjmp/longjmp); whereas the latter allows only a single non-local jump up the [stack](https://en.wikipedia.org/wiki/Call_stack), setcontext allows the creation of multiple [cooperative](https://en.wikipedia.org/wiki/Computer_multitasking#Cooperative_multitasking.2Ftime-sharing) [threads of control](https://en.wikipedia.org/wiki/Thread_(computer_science\)), each with its own stack. &gt; --- ^Interesting: [^Coroutine](https://en.wikipedia.org/wiki/Coroutine) ^| [^Fiber ^\(computer ^science)](https://en.wikipedia.org/wiki/Fiber_\(computer_science\)) ^| [^Setjmp.h](https://en.wikipedia.org/wiki/Setjmp.h) ^| [^Call ^stack](https://en.wikipedia.org/wiki/Call_stack) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+chfvg9d) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+chfvg9d)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Your answer: "just call a different fiber implementation from your fiber implementation" is a bit unsatisfactory. So maybe I could rephrase my question to: How are those OS specific fiber libraries implemented without using setjmp/longjmp ? If there is a way of implementing efficient fibers without setjmp/longjmp I'd like to know. 
A semaphore is not a condition variable.
Just to be more clear, boost:coroutines (via boost:context) abstract away the need to include setjmps yourself. I was pointing only that the semantic oddities of setjmp point to a warning sign attached to coroutine use, saying that "beware: your control flow intuitions may cease to hold, ye who enter here".
It seems that FastCGI is a form of CGI, where the server has to spawn a process to handle each request inducing a performance penalty.
Boost asio really sits a level below: cpp-netlib is a library built on ASIO and boost that adds HTTP support. http://cpp-netlib.org/0.11.0/index.html
The "Fast" part of the name is referring to that it doesn't involve spawning a process for every request.
Meh, it still requires the use css. Until web programming ditches the need for CSS I am staying the hell away from it.
You could use the one in the [devkit](http://www.fastcgi.com/drupal/node/5), or find a decent third-party library. I wasn't happy with the devkit-supplied library, since it seemed to be targetted towards updating existing CGI projects, and instead ended up writing my own implementation, which was much easier to integrate with the rest of my code. The [specification](http://www.fastcgi.com/drupal/node/6?q=node/22) is pretty easy to understand, combined with the sample code from the devkit, it doesn't take much to get a basic FastCGI connection working. At the bare minimum, I recommend implementing the Responder role, and adding support for persistent connections. While I also added support for multiplexing over a single connection, none of the current major web servers seem to support it, and using multiple persistent connections probably performs just as well.
A pure FastCGI setup would indeed require an absurd number of processes. The standard solution is to just toss nginx in front of it and have just enough worker processes to be able to max out your processor (which naturally can take some tuning depending on how CPU-bound your application is). The end result is a rather nice separation of concerns (one program handles all of the issues with large amounts of incoming connections, one manages the worker pool, and your actual application just has a dead simple single-threaded request in -&gt; response out model) with pretty low overhead.
FWIW this is the type of thing that is extremely unlikely to change in future compiler releases.
I'm rather enjoying this series of articles. Thanks for writing them!
Do you mean using multiple machines?
No. You certainly can have worker pools running on multiple machines, but there's nothing about the setup that requires it.
I'm going to swallow my pride and ask a question that I feel I should be able to answer: On question #5 - why is the size of the ES structure 6 instead of 4? I understand the concept of alignment, but clearly there's something here that I'm missing.
Fuck no. And if someone feels the need to help a C++ reference, go [here](http://www.cppreference.com/support/). 
Nice! I like micro web frameworks, I found Wayward very cool!
&gt; But Qt for example uses his Q prefix anyways. Qt predates C++ namespaces and I wouldn't use it as an example of modern C++ practices.
Qt uses the Q prefix because Qt is older than the C++ standard and they do it for backwards compatibility for the most part. Plus, even when C++ was standardised they were from a time when people thought namespaces were bad. You shouldn't use prefixes in C++, namespaces are the alternative and that's what they were made for.
Pretty much any modern coding standard says to use namespaces and not prefixes. As others have pointed out, QT predates the standard.
For *suffixes*, namespaces have the downside that it gives Yoda-like names. E.g. if you have `X_thingy`, `Y_thingy` for reasons of legibility in plain English, that would change to `thingy::X`, `thingy::Y` etc. Especially with nested namespaces, this could become awkward.
Discussion at HN https://news.ycombinator.com/item?id=7732049
when and why did people think namespaces were bad?
You shouldn't really be worrying about English *grammar* within a name. For one thing, not all programmers who read your code will have English as their first language. Besides, one thing you should learn from Yoda - changing the word order may sound a little odd, but it rarely makes things harder to understand. There are other cues to indicate what is meant, and this allows some freedom to re-order things in English (and much more in some other languages). In this case, we know as soon as we see the `::` that the container is specified first, the content second. That even applies whether the container is a namespace or a class. 
People back then used to think they were "too new" to be used and thus weren't a "stable" feature. If I recall, this was the reasoning provided for Embedded C++ eons ago as seen in their [FAQ](http://www.caravan.net/ec2plus/question.html). It's a really old practice. You can see even some older projects refusing to use namespaces.
There is relatively new C++ library that uses prefixes. http://bulletphysics.org/wordpress/ If I remember correct there should be even explanation why this was done, unfortunately I can not find it right now. 
I'd say it depends on the scope of the project. A library compatible with both C and C++ shouldn't really use namespaces for obvious reasons. But if it's purely a C++ library, or there is an option for namespaces, it's probably a good idea to use them. The OpenGL Loader Generator gives the option to use C++ style calls that actually uses a gl namespace, and I personally am finding it nice to be able.to use that instead of.all the gl* calls. In general, if there were an option of using C++ style with every C oriented API like Berkley Sockets I'd love it. No need for pointer polymorphism or need to even.pass pointers, just pass references.
use namespaces
I never intended to use it as modern example... It was the first obvious "C++" library that came to my mind. I am sure there are a lot C++ libraries out there, that uses prefixes...
What about both? I always use a namespace library or something... But what do you think of additional prefixes? Although Qt is a bad example, when I speak of QThread, everyone knows what I am talking about. So what do you think of prefixes as... "name-design" and not to solve the name ambiguity problem? To make a name more unique for example. 
You're over generalizing; no one said that. Perhaps I should have been clearer: it is extremely unlikely any compiler will change their vtable layout scheme (or anything tangentially related to it) ever again.
Namespaces are recommended practice, however for a published API I actually prefer a prefix, since when you google, it's easier to find QtWindow vs Window vs Qt::Window
&gt; when you google, it's easier to find QtWindow [snip] vs Qt::Window It's very dubious whether that true. I mean it's not like you can ever test it properly. Any time I search for stuff I include the namespace and seem to get very accurate results.
&gt; You shouldn't really be worrying about English grammar within a name. Absolutely, code should be unambiguous and descriptive. That doesn't imply it should read like plain English. In fact, written English can be very ambiguous unless one takes great care with punctuation and grammar.
&gt; when I speak of QThread, everyone knows what I am talking about. Why would speaking about a hypothetical `qt::thread` be any different?
&gt; A library compatible with both C and C++ shouldn't really use namespaces for obvious reasons. Such a library is either plain C itself, or a C++ library hidden behind a C-style interface. In either case you can't use namespaces for the C part, but in the 2nd case, the C++ part should most definitely use namespaces. 
&gt; CPerson or CThingy If you are refeeing to just the "C", then in those cases the prefix is part of [http://en.wikipedia.org/wiki/Hungarian_notation](http://en.wikipedia.org/wiki/Hungarian_notation). It's not really being used in the same sense as the `Qt` prefix. Mind you, I'm equally against it.
There are problems with namespaces. Or rather, how they are commonly used. Like a lot of C++, namespaces require discipline or they get out of control. Namespaces create a lot of pointless busywork because people start using them for organising their projects; dividing a single project into dozens of namespaces. Multiple namespaces only creates maintenance hassles when you move classes between namespaces and then accessing your multi-level nested or elaborate namespaces requires long lists of "using" at the top of each file just to access common functions. And because namespaces are long and onerous to type (unlike two or three letter prefixes) people use "using" so much that it actually leads to other problems (e.g. conflicts with same-named classes in different namespaces). This highlights the problem that when using namespaces, the style is to make class names too generic. And having multiple classes with the same name (even though they're in different namespaces) can cause problems with IDEs and other aspects of your toolchain that don't necessarily parse the namespace. Finally, when you see someone's code example – or worse, you're reading the API that supposed to explain how to use the code – and it doesn't tell you which namespaces have been used in the example, it can make it painful to actually replicate the example in your own program. For my own programs, I rename namespaces down to 2 or three letters (e.g. namespace fs = boost::filesystem) but never actually omit the namespace itself. I also avoid multiple namespaces in a given project (except for special case design patterns).
Yes, though I consider the main source of the C prefix to come from MFC, where Microsoft did use it as a prefix to avoid collisions. Ironically programmers started naming all their classes Cstuff. Microsoft did a lot of hungarian, but they didn't tend to use it in class names.
I believe Qt did this when namespaces didn't work properly.
Then they haven't spent enough time in PHP.
It's easier to grep when you have the prefixes in place. This doesn't always work with the namespace-only version because in some contexts you don't need the namespace qualifier
I think prefixes are silly and Hungarian notation worse, Joel's article on its founding are the only thing that I think makes any kind of save for it. http://www.joelonsoftware.com/articles/Wrong.html
Or, rather, in some cases, even when one takes great care with punctuation and grammar.
To be fair, that makes a lot of sense. I'd be hesitant to adopt a bleeding edge feature like that in my code until I knew it was going to stick around for a while. I would've thought they would change the code over when the namespaces became more concrete, however.
Thanks a lot! I have ton of stuff to read now! Awesome answer! 
Actually that naming itself tells you something. X_thingy, Y_thingy tell me that "thingy" is something that belongs to X or Y. That is, X and Y are similar objects - they both have a 'thingy'. Thingy::X, Thingy::Y tell me that X and Y are common to Thingy. Thingy is therefore a namespace with variables X and Y. Why isn't it a class? Scope operator. It *could* be a class, but if it is then X and Y are static members which are pseudo-globals just like variables in a namespace are.
&gt;(e.g. conflicts with same-named classes in different namespaces) Because of this, would you not normally use something like `namespace po = boost::program_options;` ? Then you can have namespaces within namespaces to organize a large project without having to worry about conflicts because of `using`s. 
&gt; So what do you think of prefixes […] not to solve the name ambiguity problem? To make a name more unique for example. “to make names more unique” *is* solving the ambiguity problem. You’ve just relabelled it. You’re trying to find arguments for prefixes (good!) but in fact the only argument so far is the ambiguity, and as stated before, this is solved better by namespaces. There are other conventions for prefixes unrelated to ambiguity, however. For instance, in Java there’s a convention of prefixing abstract classes with `Abstract`, in the same vein as factories are suffixed with `Factory`. I’m still undecided whether this is a good idea in C++, however: Java libraries suffer from an over-use of formalised design patterns, and without such naming conventions there would be utter chaos. Most C++ libraries get by without this.
Joel’s article, of course, pulls a bit in the wrong direction. It explains beautifully why Apps Hungarian was used, but then it goes on to advocate its use, and neglects to mention that there is a better solution. Instead of making the code merely “look” wrong to the user, it should be made to look wrong to the compiler / type checker, to prevent its compilation / execution. In other words: the same can be achieved, only better, by using strong typing. His “solution” by contrast is error-prone and requires enormous discipline, and despite his assertions to the contrary, even somebody grown accustomed to spot mismatching Hungarian prefixes will often overlook them. It’s a terrible article, because it makes a very strong, compelling argument for something that’s utterly wrong. He fools his readers.
The versatility of the library notwithstanding, Bullet generally seem to be a bad example for API quality. It’s an unholy mix of C and C++ that should not be imitated. The only comment I could find on this is [a forum entry](http://www.bulletphysics.org/Bullet/phpBB3/viewtopic.php?f=9&amp;t=9642) in which the maintainer essentially said that he likes it that way, and that’s that.
Near the bottom of page 5, "Conversely, *and*" should be "Conversely, *any*"
IMHO, You should have tools to check that the coding policy is respected, that the layer architecture is respected, that common errors are not made (via a static analyzer), that the code is documented, etc. Incoherent tab settings is a minor things in this context. 
IIUC this proposal falls back to source code copy-paste for header only libraries (like Boost). It is not clear at all that this will deliver faster compilation time in these cases, since the only proposed solution (explicit instantiations) has already been available for a long time.
Yes if the offset is divisible by the chunk size - but if deque iterators know where the map lives (which they basically need to know one way or another) this could be done automatically in the non-member function. We have not attempted to do that.
I looked at using libevent in C++ many years ago and decided it was a no-go. I can't remember specifically why. I was able to successfully use libev, however, and would recommend it.
Based on my experience with Boost.Asio, I would not recommend ASIO. My two biggest complaints were 1) the heavy unintuitive use of templates, drastically increasing compile times and often producing uninformative error messages, and 2) it is (or was at the time I used it) necessary to recompile in order to use a different underlying multiplexing mechanism (e.g. to switch from select() to epoll). Note that I am not afraid of templates or template metaprogramming; I used both heavily when I wrote the Rice C++ wrappers for the Ruby API. I simply find the Boost.Asio use of templates to be difficult to grok and difficult to use correctly.
Care to summarize what libuv provides that libevent and libev do not?
I have a different reading. The proposal falls back to `#include` when you wish to import *macros*, but it is perfectly possible for a module to be *header-only* if it only contains templates (and it's implicitly not header-only if it also contains non templates or explicit instantiations...) This is sound, and actually seems a tad simpler than Clang's approach of private and public macros. Actually, it did not touch on module.map (ie, mapping headers into a module structure) like Clang did, which is another simplification. My only question is: does it work :) I'd like to see a side-by-side comparison of this and Clang's system, it would be quite interesting.
Given that Doug Gregor is the driving force behind both approaches, I expect those approaches will somehow come together.
I am glad to see movements on that issue. C++ compiling/linking time is a very big "flowness" breaker while developing and perhaps the most outdated looking part of the language.
`using namespace ExternalLibrary;` Or, if you prefer, `using ExternalLibrary::Person;`
What's wrong with it? It seems fairly decent.
so that is the reason why VC++ has(had???) such a small chunk size. mystery solved. talk about foresight :) jk aside, having somebody like you communicate with normal ppl on the internets is amazing and I really appreciate it. :) 
Bike-shed: I think I prefer using `public:` and `private:` over `export {}` module my.module; public: // declarations exported from the module private: // declarations not exported I do like having both `module` and `import` as keywords, but I think having `import` is the more important of the two, and probably causes fewer problems than introducing `module`. If we have to limit new keywords then I think using `export` in place of `module` as Doug's presentation shows is a better option than using `using module` in place of `import`. --- Non-bike-shed: I don't think that not allowing a module to export macros is going to work. As much as I wish we could eliminate macros, and the preprocessor entirely, they're important for many existing libraries, including ones that are very much C++ libraries and not C libraries. For example: many boost libraries use macros. The standard library should also be fully modularizable. And frankly I don't want to have to mix `#include` and `import;`. I realize that exporting macros complicates things. It requires the preprocessor to understand modules so that it can get macros exported by a module. However it is implementable, as Clang's module system supports exporting macros. I think exported macros work in Clang's implementation even when doing separate preprocessing, so an integrated preprocessor isn't required. --- I hadn't looked at the mailing list for a while because it wasn't active, but I see that there's been more activity recently. I'm glad to see proposals and more activity now, but I still would like to see a proposal based directly on the experience of developing and using Clang's module system, and modularizing existing libraries under this system as Apple has been doing. I've been generally following the progress of Clang's implementation but I haven't yet heard anything about them working on a paper yet.
Can you make this without the C prefix? namespace Folder { namespace OneFile { class COneHeader { public: void foo() {} }; } class COneFile { public: OneFile::COneHeader oneHeader; }; class CSecondFile { }; } class CFolder { public: Folder::COneFile oneFile; Folder::CSecondFile secondFile; }; int main() { CFolder folder; folder.oneFile.oneHeader.foo(); return 0; } 
I really hate this “try as hard as possible to avoid new keywords, because somewhere someone might be forced to rename something”. Renaming can in fact be completely automated so this really shouldn't be that much of an issue. The primary concern should always be “What is convenient to use”.
renaming can NOT be completely automated in c++ (or indeed in almost ANY other language). This is because once you add metaprogramming and reflection to a language you get things that are not really identifiers that refer to names. In c++ it is macros that complicate automatic renaming.
CppCms There are many options to connect CppCMS application to web server: Protocol: you can use FastCGI or SCGI protocols, you can also run over HTTP protocol behind proxy. http://cppcms.com/wikipp/en/page/cppcms_1x_tut_web_server_config
Templates as well. And any custom meta-programming, such as code generators.
CppCms is a framework on it's own. I'm looking just for a small FastCGI library.
libev was created to address some issues with libevent - there's a good writeup on stackoverflow [here](http://stackoverflow.com/a/13999821/955273), but essentially these are: (paraphrasing from the linked answer) - global variable usage in libevent made it hard to use safely in multithreaded environments - watcher structures are big because they combine I/O, time and signal handlers in one - extra components such as the http and dns servers suffered from bad implementation quality and resultant security issues - and timers were inexact and didn't cope well with time jumps In turn, libuv was created to address some issues with libev - joyent created a [github issue](https://github.com/joyent/libuv/issues/485) to track these, but it basically boils down to: (again paraphrasing from the linked issue) - libev only supports level-triggered I/O. On Linux, we want to use edge-triggered mode - it cuts down the number of syscalls by a substantial margin. - libev's inner loop does a lot of things we don't really need. Gutting the inner loop like we did in 649ad50 gave a 40% performance increase on some benchmarks. - libev is Linux only - libuv has Microsoft IO completion port support, helping port node to Windows. Finally, for the boost ASIO vs libuv comparison, there's a comprehensive answer on stackoverflow [here](http://stackoverflow.com/questions/11423426/how-does-libuv-compare-to-boost-asio) 
Please put it on github, I'd really be interested.
Here are some notes that I made a little while ago. I ended up going with GNU cgicc. Hope it helps! [GNU cgicc] (http://www.gnu.org/software/cgicc/) * Just CGI, but seems to cover everything. * Actively developed. Last release in Jan 2014 * Available in Debian [RudeCGI] (http://www.rudeserver.com/cgiparser/) * Just CGI. Pretty bare-bones. * Last release in 2009 * Available in Debian [Wt] (http://www.webtoolkit.eu/wt) * Lots of features (e.g. Javascript generation) * Has free interfaces with PostgreSQL, Firebird, MySQL. * Oracle interface requires $$ (maybe we do not care). * Really meant as a web framework. So it includes the front end. * This meant that, given the brief time I looked at it, I could not figure out how to do simple CGI app. * Actively developed: last release Aug 2013 * Available in Debian [CppCMS] (http://cppcms.com) * Could not find any documentation beyond doxygen, but does seem to have cgi classes. * Actively developed. Last release June 2013 * Not in Debian * They have debian packages for wheezy, but not anything recent. [fastcgi++] (http://www.nongnu.org/fastcgipp/) * Sporadic development. Last release Aug 2012. * Not in Debian [FastCGI / CGI C++ Library] (http://cgi.sourceforge.net/) * No activity since 2010 * Not in Debian 
It is true, but in practice, you only need the following and thats all. Nobody force you to use more feature from this framework #include &lt;cppcms/application.h&gt; #include &lt;cppcms/applications_pool.h&gt; #include &lt;cppcms/service.h&gt; #include &lt;cppcms/http_response.h&gt; #include &lt;iostream&gt; class my_hello_world : public cppcms::application { public: my_hello_world(cppcms::service &amp;srv) : cppcms::application(srv) { } virtual void main(std::string url); }; void my_hello_world::main(std::string /*url*/) { response().out()&lt;&lt; "&lt;html&gt;\n" "&lt;body&gt;\n" " &lt;h1&gt;Hello World&lt;/h1&gt;\n" "&lt;/body&gt;\n" "&lt;/html&gt;\n"; } int main(int argc,char ** argv) { try { cppcms::service srv(argc,argv); srv.applications_pool().mount(cppcms::applications_factory&lt;my_hello_world&gt;()); srv.run(); } catch(std::exception const &amp;e) { std::cerr&lt;&lt;e.what()&lt;&lt;std::endl; } } And this is the config: { "service" : { "api" : "fastcgi", "ip": "127.0.0.1", "port" : 8000 }, "http" : { "script" : "/hello" }, } 
WTF is AR?
Active Record I assume. DataMapper is also a ruby ORM. This question seems like it in the wrong sub. Also if avoiding AR in ruby use sequel its the spiritual successor and its regularly updated, DataMapper hasn't been in a few years.
Since you are posting in the C++ sub I will take it that's your primary language. The ORM I would recommend in that case would be [ODB](http://www.codesynthesis.com/products/odb/). It has native support for common Qt types such as QString and the Q containers.
Some time ago I bookmarked one called [ODB] (http://www.codesynthesis.com/products/odb/) that seemed interesting (haven't tried personally).
Exactly, you can easily implement DM on C++. I'm surprised there are not many projects in this field.
[Wt has a package called 'DBO'](http://www.webtoolkit.eu/wt/doc/tutorial/dbo/tutorial.html) that may be helpful. Unfortunately it has the same license restrictions as ODB. edit: but it does have a commercial license as well edit2: it appears that the poco project has a few links to different database types under the [poco::data subsection of their site](http://pocoproject.org/docs/).
The [Poco projects net libraries](http://pocoproject.org/docs/) might make this possible, they have a full subset of http based parts.
It would be nice if they also added something like "import this;" to include all header files in current project
I certainly hope so, modules are long overdue in C++ and it would be a really good incentive to switch to C++17 should they make it in time.
I'm not sure how this proposal addresses template compilation times - and they're the worst offender in my experience. 
Especially since the Q_PROPERTY interface is such a logical target. It boggles my mind that this isn't already a part of QtSql. Maybe a good GSoC project for Qt next year?
The libraries I'm working on started out with prefixes, and are gradually moving to namespaces as our target compilers improve. The original decision to use prefixes had its roots in antiquity when namespace support was unequal (or even unavailable) in compilers. The move to namespaces is teaching us that it's still unequal, with many compilers having different ideas of how ADL works, but the issues we've encountered haven't been show-stoppers. If I was starting a new project now, namespaces would definitely be the way to go. One important thing to remember is that "using namespace" outside of an inline function in a header is very rude.
I assume that it works. Do you think it will be faster for header only template libraries (without macros)? Two-phase look up probably requires the template code to be copy-pasted inside every TU...
Sorry, I meant that different: Sure unique names solve the ambiguity problem, but they do more. You can more easily remember those names... I meant "unique" in the way "unique little snowflake": Special ;-)
There's an HTTP client/server library atop `boost::asio` called [cpp-netlib](http://cpp-netlib.org/) that might also be useful.
Having to write my own HTTP server, means i have to reinvent the wheel to tackle problems like the C10k. I prefer to focus on my application.
This might look interesting to you. I don't think it has any special support for Qt types, but it follows the DataMapper pattern: https://github.com/simonask/w (see &lt;p&gt;, it's object persistence portion of the framework).
&gt; Yes if the offset is divisible by the chunk size hmmm , but if what you say is true that means for offsets of 1007 and block size 10 you could still do the 7 pop_front/push_back and then do the fast rotate... could be I am missing something, because honestly deque implementation is much more complicated then vector one. 
boring article, what I really NEED(as a dev) is cpp Prime or how are they gonna call it... Language that can be parsed more quickly by compiler and cpp can be mechanical translated into it(without loosing human readability of the source)
Like so? class Folder { public: class OneFile { public: class Header { public: void foo() {} }; Header header; }; class SecondFile {}; OneFile oneFile; SecondFile secondFile; }; void main() { Folder folder; folder.oneFile.header.foo(); Folder::OneFile::Header header; header.foo(); } 
a) uto b) http://stackoverflow.com/a/21994914/700825
What specifically did you find a hassle about FastCGI? I have written FastCGI stuff and uploaded it to shared hosting accounts. It has worked flawlessly. Even cheapo shared hosts now all support FastCGI.
&gt; when and why did people think namespaces were bad? Namespaces were/are implemented through (non-standardized) name mangling. This ends up causing all sorts of problems if one has to call C++ modules from code written with other programming languages. So, namespaces were seen as syntactic sugar whose use was at the expense of unforeseen and unnecessary problems. The same issue also affected the decision to use templates.
In a project I was involved, I tried [QDjango's Object Relation Mapper (ORM)](http://doc.qdjango.org/qdjango-snapshot/group__Database.html), but i ended up using [litesql](http://sourceforge.net/apps/trac/litesql/) but i don't remember why. Litesql has no QT dependency and uses pre c++11 smart pointers :S. QDjango uses the Qt meta information to do the mapping.
Well, one big difference is that [std::unordered_set](http://en.cppreference.com/w/cpp/container/unordered_set) contains unique objects, whereas [std::array](http://en.cppreference.com/w/cpp/container/array) has no such restriction. Another difference is that the size of a set can change over time, whereas the size of a std::array is fixed at compile time.
They're pretty different. std::array is basically the same as the primitive arrays, except it acts more like an STL container and supports at() for bounds-checked accesses. Useful for smaller things where you know exactly how many elements will be in a list. std::unordered_set is a hash set, so it's useful when you want cheap tests for membership of large sets at the expense of slightly more expensive insertions.
your link is bad and you should feed bad, slides for tech talk are useless
Deque Is Weird^TM. I'd have to look at the implementation carefully.
I don't think you looked very hard. They're extremely different. A `std::array` is an array, while a `std::unordered_set` is a hash table. The data structure most like `std::array` is `std::vector`, and there is significant overlap between their use cases. 
`std::array` is a wrapper around plain arrays which gives them an interface consistent with all the other standard containers, like `.size()`, `.front()`, `.back()`, `.begin()`, `.end()`, `.swap()`, etc. In addition, a `std::array` has *value semantics*: - assignment: `a = b` copies the container contents when `a` and `b` are `std::array`s, but is illegal for plain arrays - comparison: `a &lt; b`, `a == b`, `a &lt;= b` works when `a` and `b` are `std::array`s and compares the underlying elements for lexicographic order; when `a` and `b` are arrays, this compares addresses, which is completely useless - may be returned from a function - may be passed as an argument to a function without pointer decay and without forgetting its size `std::unordered_set` is the hash-based companion to `set::set`. It gives O(1) average access time compared to `std::set`'s O(log n). And it requires implementing a hash function (or using a standard implementation) and `operator==`, rather than implementing `operator&lt;` ~~and `operator==`~~ as required by `std::set`. Edit: oops. 
I should also mention that Qt and GTK+ allow customization of the looks with stylesheets. I haven't really looked into that, so I don't know to what extent.
I know the exact answer to this, because I built a UI today like you want. Basically, here is a great place to [start!](http://mui.codeplex.com/) Be sure to follow the Getting Started documentation and the .dll's are includied in the downloard.
Assuming you meant `std:array` (vs. `std::vector`) and `std::unordered_set` (vs. `std::set`), for the former, it consumes less space (slightly) than `std::vector` and does not decay (like `T[]` would decay to `T*`). For the latter, if order is not important and a good hash function is available, `std::unordered_set` will probably out-perform `std::set` for many uses.
Haha, I was having a play around with this exact thing just a few days ago and am definitely considering using it. 
You can probably do something like this with Qt/QtQuick. They are pretty customizable.
If you want to be tied to one platform and one compiler for the rest of your (applications) life, go ahead :) Spotify does a little better than that...
I never mentioned a need for it being cross-platform like Spotify. Windows is my main focus, but it would be nice to have the possibility to port it to other platforms I suppose.
&gt; &gt; &gt; std::unordered_set is a hash set, so it's useful when you want cheap tests for membership of large sets at the expense of slightly more expensive insertions. Considering a use case that requires storing unique values and ignoring membership tests, what are the relevant differences between those container types?
&gt; It's an associative container whose key is the value itself. &gt; equivalent to an array. No. It's an *associative* array with values equal to keys. Those are very different from arrays. int main() { int nums[] = {5, 4, 3, 2, 1}; // An array of numbers std::cout &lt;&lt; nums[4] &lt;&lt; std::endl; // Does not print 4. }
Use a std::unordered_set. That's the kind of thing it's designed for. std::array is not suited to this, outside of *maybe* some pretty specialised cases. I don't really understand how you are confusing these containers (maybe you're thinking of PHP's arrays, which aren't really arrays as most other languages know them?).
&gt; It's an associative container whose key is the value itself. Both the link you've given and the generally preferred [cppreference - std::unordered_set](http://en.cppreference.com/w/cpp/container/unordered_set) go on to say &gt; Internally, the elements are not sorted in any particular order, but organized into buckets. Which bucket an element is placed into depends entirely on the hash of its value. So it is a hash set (You'd want to check the standard to see if an alternative implementation is allowed) and not "equivalent to an array".
&gt; A use case that requires storing unique values and ignoring membership tests If the container is to enforce the uniqueness, then it has to in some way perform a membership test.
I would say QtQuick is the perfect fit for it. I created a [configuration window](http://imgur.com/ArjPUfC) for my visualizer using QtQuick and it's a really nice to work with compared to all other gui technologies I have tried. 
Even with libtooling there are hard cases: #define FOO(X, Y) (X) . mo ## Y struct A { int mo_foo; }; struct B ( int module; }; int main() { A a; B b; FOO(a, _foo); FOO(b, dule); } Libtooling can go ahead and detect that the result of the macro includes something that needs to be replaced in one case, but someone has to decide on the right way to change it. Should it be: #define FOO(X, Y) (X) . no ## Y struct A { int no_foo; }; struct B ( int nodule; }; or struct B ( int mo_bar; }; FOO(b, _bar); etc. 
Alternative implementations are *not* allowed, the standard explicitly specifies the semantics of the `std::unordered_*` containers in terms of `hash&lt;key_type&gt;` (where `hash` is a template defaulting to `std::hash`).
One is a set, the other is an array. These are fundamentally different data structures in their goals and requirements. At its most basic, a set is a structure copied from mathematics which has two particular properties: * No duplicate elements * No particular order of the elements – at least not the order in which the elements have been inserted In addition, a `std::array` is a fixed-width container, `std::unordered_set` isn’t. I’m also not sure why you’ve singled out `std::array` and `std::unordered_set` for consideration. Along the lines of the same distinction there are many other standard containers: `std::set` also implements a set (although it does impose an order, but again one not affected by insertion time), as opposed to `std::vector`, `std::deque`, `std::list` and `std::slist`. (Of course these all have fundamentally different characteristics, apart from being non-set-like.)
Good to know, thanks for clearing that up.
Well, yes, it must be implemented as a hash set, but you don't have to use `std::hash`, the hash type is template parameter that you can specify. The requirements for the hash type are given in &amp;sect;17.6.3.4, and are rather open ended. It must be a functor that takes a single argument and returns `size_t`, and the return value must depend only on that argument, and it must not modify the argument. `std::hash` of course meets those requirements, but that doesn't mean you can't use something else. 
Oops, yes, clarified this. For what it’s worth, the “hash” requirements you’ve cited actually overlap quite precisely with the [formal requirements for a hash function](http://xlinux.nist.gov/dads//HTML/hash.html) in a formally defined hash table, which is *equally* open-ended. So even if somebody takes quite large liberties within these bounds it would *still* be formally a hash table. Just maybe not a good one.
They still do, as far as I know. 
- `std::array`'s size is constant while `std::vector` has a dynamic size. - `std::array`'s elements are stack allocated while `std::vector` elements can be allocated wherever you want (stack, heap, both, ...). So: - if you need a container that stack allocates its elements and has a guaranteed fixed size, use `std::array`. - Otherwise, use a `std::vector`. Where is the overlap? You could try to use a `std::vector` as a fixed-size stack allocated array. But since you cannot guarantee that is fixed size, and since you don't know the amount of memory that it will try to allocate (and you need to know this to correctly size a stack allocator), you would run into problems very fast. It would thus be very unwise to do so since: - it would be more complicated than using a `std::array`, - it would be slower than a `std::array`, - it would require more memory than a `std::array` (and the exact amount of memory is hard to predict since operations like push_back can request any amount of memory), and the best of all: - it is not portable since you will have to guess the amount of stack memory that you need for every single STL implementation, and - since you cannot fix its size, it could still try to grow beyond the stack allocated memory that you give it (and depending on the stack allocator, it might be able to do so), resulting in errors or extremely FUN [*] to debug situations. So I disagree. I don't think there is any overlap at all between `std::array` and `std::vector`. They are completely orthogonal library components that serve different purposes since it is very hard/impossible to guarantee a `std::vector` size as well as its memory requirements and thus almost impossible to use a `std::vector` correctly as a stack-allocated collection of elements. [*] In the sense of loosing is FUN.
Anything that you can use an array for, you can use a vector for (aside from a few corner cases like using `a.size()` as a compile-time constant). There's nothing stopping you from making a vector and never changing its size, and there's no difference (besides speed) between stack allocation and heap allocation. It's the same sort of relationship as between pointers and references. Everything you can do with a reference, you can do with a pointer.
Wrong subreddit OP. 
Your UI code will be tied to a single platform, but cross-platform applications with good UIs end up with a lot of platform specific UI code anyway. It can actually serve as a nice design guide by forcing you to decouple anything you want to use on multiple platforms from the UI.
Except then reality kicks in, and the whole thing is, and forever stays, an unportable mess :) I've seen it more than a few times. Vendors like microsoft, apple, ... have a huge interest in tying you down to their platforms, so they work against your wish to decouple things. If you don't start by developing for all your target platforms from day one, with every day that passes it becomes more difficult to make the port retroactively (unless you have iron discipline) -- eventually you'll give in and slip some compiler-specific things in here or there, or you'll end up relying on some-or-other library that isn't ported easily, etc. Oftentimes it's subtle stuff that you don't even necessarily think about until it's too late, like e.g. difference between case sensitivity in your filesystem.
&gt; when a and b are arrays, this compares addresses, which is completely useless Even worse, I'm pretty sure this is actually undefined behaviour. The ordering operators only have defined behaviour when the pointers point to elements within the same array, which is never the case here.
I agree. For UI that doesn't emulate the look-and-feel of the native platform, QtQuick is by far the best UI framework I've worked with. Once you get the hang of it, development is really quick. It's a bit difficult to avoid a spaghetti mess in the beginning, but once you've got some experience under your belt, you begin to realize how you can structure and decouple things for tidy and maintainable UI code. Oh, and incidentally, I've written a Spotify client using QtQuick: https://github.com/Andlon/sonetta. It's not reached alpha, and a UI redesign/rewrite is in progress (not reflected in the screenshots), but I suppose it's getting somewhere - hopefully. (Note that it's designed for use with an ordinary TV remote, not mouse/keyboard/touch.)
There is a spotify client written with Qt: https://gitorious.org/qtify/qtify 
Well, if you want specific order, you need container with arbitrary positioning of elements, that is array, vector, list, forward_list, deque (hopefully I haven't forgotten any ;-) ). None of these guarantee uniqueness and as such, you will have to iterate them to check for their presence. (Unless of course you have the uniqueness guaranteed by method of creation) Also note that *std::array* is stack allocated and unresizable, so if you are not sure how large the container will have to be (or if it would be large), you want to use *std::vector*. (And seriously, how does the name *unordered_set* make you think that you can pick specific order of elements?)
&gt;Oh, and incidentally, I've written a Spotify client using QtQuick Wow, this looks great. QtQuick it is!
The author shows examples of how a context switch is done for x86. Is the process similar for other CPU architectures, such as PowerPC or ARM?
In case anyone is still reading this, I've made some progress on the documentation. It is still far from done, but already contains useful information. It can be found [in the wiki](https://github.com/schlangster/cpp.react/wiki). It probably would've been more constructive to post the link AFTER I documented everything, but I did it to motivate myself to start working on the documentation in the first place :)
ODB has a free proprietary license (no GPL restrictions) for object models that don't require more than 10,000 lines of generated code. That translates to about 10-20 persistent C++ classes each with half a dozen data members. And if you need more than that, then maybe it is not a bad idea to pay for a commercial license? It is quite affordable. This page has more info: http://codesynthesis.com/products/odb/license.xhtml 
A superoptimizer for boolean values. Now upgraded to find things like: &gt; divide a large constant by an arbitrary 32-bit value, the result cannot be zero. GCC does not find this one I'm glad CS folks are working on this, but progress tends to be very, very slow. If they come out with something generally useful in the next 5 years it will be a surprise.
Looking around for coroutine implementations for ARM (ones that don't use ucontext etc) might help you find something helpful.
&gt; Optimizing code for statistically rare cases. Making sort work faster for sorted arrays to the detriment of all other arrays is a bad idea (http://stackoverflow.com/questions/6567326/does-stdsort-check-if-a-vector-is-already-sorted). I appreciate his general point but calling (almost-)sorted data “statistically rare” seems ill-informed. In fact, there are many real-world cases where data is already in a rough order, and it *does* make sense to optimise your general-purpose sorting function so that it doesn’t run into a worst-case when encountering this common behaviour. This is the rationale for Python, Java and libc++’s `std::sort` implementation to use [timsort](https://en.wikipedia.org/wiki/Timsort).
Yep, I would dare to say that if you're writing a library/module/some concrete unit of code independent of any other code, if you have more than a single namespace, you're probably doing something wrong. Like you mentioned, there are special cases, but they are **special** for a reason.
The conference ends tomorrow, so expect all the presentations to be added to this repo soon.
When did video cameras stop being a thing? 
Since the conference is still happening its not likely that videos will show up until next week. That seems to be how it has gone in years past.
there will be videos (I filmed some of them). I'm not sure how soon they'll be up but I'll ask and edit this comment with the answer. EDIT: for the answer see the other volunteers post in this thread. 
Why does github have its own badly coded pdf reader that doesn’t even begin to work properly? I have a nice pdf plugin already, and it overrides it. :/
Good question. [It was asked on StackOverflow](http://stackoverflow.com/questions/11972076/why-is-the-cplusplus-website-bad) a while back. I've had pretty good success with the recommendation of /u/Dragdu for [cppreference.com](http://www.cppreference.com). It's accurate, but the last I looked, it didn't have a lot of examples.
Interesting. My browser pops up a dialog to download pdf files. Are you sure the reason is Github?
That's a link to the raw file with the download content disposition set, so anything other than a prompt to download the file is due to your browser doing something dumb, not Github.
Yeah, I don’t know what was going on. Thanks.
Based on the results of projects John's worked on in the past (such as the one that recently led to the integer sanitizers in gcc and clang) I wouldn't be surprised to see, within that timeframe, an LLVM optimizer pass that entirely uses data generated by a superoptimizer. It might not happen that quickly, but this is not one of those things that's perpetually 5 years away.
My second year attending the conference, always awesome speakers here.
That fucking first slide...
I think procedural read/write to XML is only part of what I want from a modern XML API. A code generation approach, like how ODB maps existing static C++ structures to database schemas, strikes me as something that's begging for quality C++ implementation in areas like serialization, IPC and RPC. Alternatively, here's a small code dump of an approach[0] I was exploring some months ago. My test subject was reading Wayland XML protocol definitions[1] into a handful of pointer-linked structs, with a more declarative approach along the lines of ODB #pragmas. I basically wrap a ref to the *root* of the Boost Property Tree node in a template (xml_encoded&lt;T&gt;) and use Boost Fusion to make the compiler work for me in generating the traversal code necessary to fill everything in from an XML file. The 4 macros defined from line 209 onward detail the 4 different ways I identified to map struct members to the XML tree. It handles &lt;vector&gt;, an optional type (wl::optional can be aliased to std::optional if you use LLVMs libc++), and shared pointers. [0] https://gist.github.com/anonymous/0b6234dcf296f6800c54 [1] http://cgit.freedesktop.org/wayland/wayland/tree/protocol/wayland.xml
The presented API is what everything else can be built on top of: in-memory or hybrid model, XPath, etc. And yes, if you look at the example code for object persistence, it is begging to be auto-generated. And yes, I have thought about making ODB generate this code ;-). The first step in getting there is to find a good, small, dependency-free XML library. So that part is sorted...
Not a real (as in, non-conforming) XML parser. I cover this problem with many new XML libraries in the first half of the talk (will be on the video).
I agree that it was nice, but rather depressing as well as it explains so succinctly why the standard library is so completely useless.
That's what I get for being used to working in Visual Studio. Thanks for making me learn something.
[Original article](http://habrahabr.ru/company/ifree/blog/197520/) (on Russian).
More like "Most Popular Languages on Github and Stack Overflow".
As other's will probably mention, this ranking excludes a lot of buisness code which doesn't make it onto GitHub for obvious reasons. That being said it also a good indicator of what programmers prefer to use in their spare time which is also interesting. 
It probably also excludes a lot of embedded / microcontroller programming, where 95+ percent is either C or C++ (a lot more C than C++). Even within embedded, although C++ can run on small microcontrollers (assuming the development toolset supports it), C++ tends to be used more as the project size and team size grow. I think it's a combination of the platform being beefier, a larger team is more likely to have a couple people (minimum) with C++ experience, and lastly, as projects grow, some of the features of C++ (such as namespaces) really simplify things a lot.
It also excludes one of the largest free software communities hosted at git.kde.org which is 99% C++.
The line where it currently goes wrong is file.seekg (0, ios::beg); which should read the binary entries with the correct lens before converting it back to an int.
Tried to go back to the introduction, but the translation needs a lot of work when compared to other educational resources. :(
So you do this: memcpy(&amp;loc_status, memblock, size*sizeof(Int_Type)); What is loc_status, and does it have room for size*sizeof(Int_Type) bytes ? memblock = new char [size]; is a memory leak, since you never delete that memory. Also, learn your debugger, so you can run your code and see where it crashes. 
thanks totally missed that, but for my case the file is present, is opened and contains data
loc_status is local int and it writes all over the stack. The Horror. (Plus the part with converting bytes into int fill me with dread, given quality of the code.)
hi thanks for your reply, int loc_status is declared above, the file contains only one int value in binary format. I see your point with the memory leak but atm it doesn't even get pass the point where it reads the file. 
Did you verify those assumptions (e.g. what does size = file.tellg() return) ? If the file only contains 1 int, there's no need to include the size everywhere, you could just hardcode the size there, and you could read directly into your loc_status variable without the need to dynamically allocate (and leak) memory. Which leads to a bug, if your file contains 1 integer, size = file.tellg(), will return 4 since an integer is (likely on your platform) 4 bytes. So size*sizeof(Int_Type) results in 16, surely bigger than what fits in your loc_status variable. (And what on earth is "Int_type" ?)
thanks, I will check as soon as I am back at my machine. Int_Type is just a typedef for an int in the piece of software that I am working in.
&gt; you shouldn't use char* Why? Confusion with strings?
First: Do your memory allocation outside of the inner loop. use an std::vector or a boost::array instead to avoid memory leaks (like you have) Second: avoid memcpy. use std::copy. It is safer and will simplify to a memcpy when optimized (except with the correct pointer values and size parameters!) Third: Your usage of memcpy bothers me; you are trying to copy a buffer of unknown size into a fixed-size integer container. For any size greater than 1, your program will do **bad** things. You said you have some sort of binary interface, which should be representable by some structs that you have serialized to the file. Allocate a single one of these structs, and simply istream::read() directly into it. Fourth: Your methodology of message-passing is dubious. If you have control over both sides of the interface, I would suggest investing some time reading into some more robust data-sharing techniques. Unless you are pressed for time, you should address my points from the bottom-up (:
istream::tellg and istream::seekg simply provide access to the internal "get" pointer. What your code is actually doing is: - size = how many bytes I have read into the file (0 at the beginning) - memblock = buffer of "size" chars (0 chars at the beginning) - seek back to the beginning of the file - read "size" bytes into memblock (0 bytes) So your code does nothing. You should just be reading, without any of this tell/set cruft.
`char` is treacherous - it may be signed or unsigned (and it is always a distinct type from `signed char` and `unsigned char`, unlike its bigger siblings where `short` is synonymous with `signed short`). Definitely use either `unsigned char` or `uint8_t` when working with bytes.
Vocabulary types should be consistent. If you do bitwise operations on bytes anywhere in your program (like shifting), then all bytes should be `unsigned char`. Best to make the decision immediately, rather than use `char` in a bunch of places and then realize that you need to change it. (Remember, the type prevents pointers from being compatible.)
Not commenting on how you read the int from the file, I think enough people have commented on that already, but here is something which might make your life easier. Get the os to notify you the file has changed. You therefore go from a busy polling loop with a sleep to a blocking idle. On linux use [inotify](http://man7.org/linux/man-pages/man7/inotify.7.html) to have the os tell you the file has changed. If you're using windows, use FindFirstChangeNotification, FindNextChangeNotification, ReadDirectoryChangesW. More info here: http://msdn.microsoft.com/en-us/library/aa365261(VS.85).aspx On OSX, the relevant api is the fsevents api. 
True, but it still doesnt solve OPs problem of a mysteriously looking return type, instead of a return type consisting of template barf you then have as return type a new class thatadds magic behaviour. So I'd say both solutions have similar drawbacks. Why not, instead of working with tags as OP suggested directly pass the pointer type? then you would have something like: template&lt;..., typename ptr_t, ....&gt; ptr_t make_shape(...) Wouldnt that work? (and be more readable)? 
As C++ expatriate in JVM/.NET land, I found the two following slides quite interesting, [My Thoughts on Large Code Base Change Ripple Management in C++](https://github.com/boostcon/cppnow_presentations_2014/blob/master/files/change_ripple.pdf?raw=true) [Keynote: Beware of C++](https://github.com/boostcon/cppnow_presentations_2014/blob/master/files/Josuttis_C++Now_140515_handouts.pdf?raw=true) Looking forward to the videos, to see what was actually discussed alongside the slides.
&gt; but it still doesnt solve OPs problem of a mysteriously looking return type That’s not a problem I an *trying* to solve. What this is trying to solve is the potentially redundant type information that you’d have if you invoked OP’s code as follows: std::unique_ptr&lt;shape&gt; x = make_unique_shape(t, b); This contains the ownership information twice. &gt; Why not, instead of working with tags as OP suggested directly pass the pointer type? Because that doesn’t remove the redundancy at all, it just moves it from the function name or type tag to a template argument.
If you read more than the first half of his post, you'd realize that's the opposite of what he is advocating. He's saying that the OP should work on easy stuff to get to know the internals as well as develop his C++ chops, then grab harder stuff. Additionally, having just finished his first semester, there's going to be a significant learning curve to more than just C++ (code reviews, source control, etc). IMHO, there's no time like the present to start!
&gt; He's saying that the OP should work on easy stuff to get to know the internals as well as develop his C++ chops, then grab harder stuff. And I'm suggesting that anything easy enough to actually fix in Boost after **just one semester** is almost certainly 1) too trivial to learn anything from and 2) not nearly important enough to *honestly* put on a resume. I suggested what I still believe is a better approach to continue learning. Anyway, OP wasn't asking for an OS project to help on, they asked from some ideas for a pet project.
It generally means a knowledge of both C and C++. Unless it specifically says something like "C++11," you can expect it's just a broad statement that covered both.
Factoring numbers are fun :) Just for comparison, here is a code doing something similar (I think, find two primes that multiplied returns the desired number), but using lambda and async/future: https://github.com/AranHase/rsa_fun/blob/master/sourcetree/rfmath.cpp#L305 Ps.: (Not sure if its 100% correct)
Uh, okay. That's one hell of a long article concluding with, &gt; this interpreter is of no practical use Would someone sell me on why I should spend 20 minutes reading this?
I disagree on the typedefs, it’s information hiding, well applied. Your argument could be levelled with the same force against any use of user-defined types instead of tuples of core types, which is certainly not what you intended. The rest of your points is spot on.
The Qt Quick compiler is the interesting part. Having intermediate C++ code from QML means that the C++ optimizer can do some optimization. It would be nice to have some benchmarks and ofcourse have it available in the free version so that one could accelerate the upcoming KDE5 desktop! 
&gt; The typedefs are there because I kept trying out different types -- using typedefs allowed me to make those changes in just one spot. Most of the typedefs are fine anyway, I think your code is better for them. The only real problem I see is when a generic typedef overly specifies the type it represents, like using Vector_32 = std::vector&lt; uint32_t &gt;; If you later switch the type to be a `std::vector&lt; uint64_t &gt;` then the typedef says the wrong thing This happens once in your code with using SharedPtr_Primes = std::unique_ptr&lt; Math::Primes &gt;; But this same problem occurs with Hungarian notation and some people happily stick with that, so I don't know what's best really. BTW, one thing I do see, and only learned this recently enough myself, is that the `_t` postfix is reserved on POSIX - [If I do a `typedef` in C or C++, when should I add `_t` at the end of typedef'ed type?](http://stackoverflow.com/questions/3225386/if-i-do-a-typedef-in-c-or-c-when-should-i-add-t-at-the-end-of-typedefed).
Dammit. And I just started porting from 4.8 to 5.2 last week. Oh well. Time to re-download and re-compile!
I thought QML would come with native look-n-feel on iOS and Android, but still not :(
We'll have to agree-to-disagree. Type-aliasing was needed in &lt;C++03 because template's weren't parsed properly. Since it's been fixed in C++11, there's much less reason to do it. My take on typedefs is to use them sparingly when the template specification would otherwise be ridiculously complex (e.g. std::priority_queue since you almost always inevitably have to specify the comparison). Is Mutex_t really more readable than std::mutex? declare using std::mutex; &amp; you've now got an all lower-case typename with 2 fewer characters to type. Perfect example of why going crazy with typedefs isn't a great idea: &gt; SharedPtr_Primes = std::unique_ptr&lt; Math::Primes &gt;; Code readability is more important than typing convenience (of course this is a learning project so code readability tends to not be valued as much - I'm just posting what I would point out if I code-reviewed something like this at work).
I'm not trying to discourage you by the way. I commend you on trying to learn. Writing clean multi-threaded code is extremely difficult to get right so practice, practice, practice. Threading tips: 1) If you are using time for synchronization it's almost certainly wrong &amp; likely to lead to race conditions. There are always synchronization primitives that let you interlock the code (condition variables and/or semaphores) 2) Use composition of smaller pieces. This code tightly couples thread creation/destruction with handling thread results. A thread-safe producer-consumer queue will serve you better here. 3) Isolate the parts that are thread-aware from the parts that aren't. 4) Be very careful with integer counts &amp; try to avoid them. Bonus tips: since you're doing a descending sort, you can have even less typing: std::sort(g_Results_Waiting.rbegin(), g_Results_Waiting.rend())
Yeah, this scratchpad code is *not* well-designed. It's just playground code that grew organically as I tried out different ideas. I would never ever *ever* write actual project code that ended up like this. The shame would be too great. :) isPrime didn't originally exist as I was just factoring 64-bit ints and only needed First_Divisor(). The dedicated prime code was added *after* the factoring code was in place.
&gt; Is Mutex_t really more readable than std::mutex? I'd agree with you there, same for `Lock_Guard_t`.
That's fine. I wasn't trying to shame you. Just providing some friendly feedback. We all have code we're not proud of &amp; you were brave enough to publish it to a public forum, so kudos :)
Oh, I'm not discouraged in the slightest. :) Know that the code I write for actual projects is *far* better designed and refactored. I'm fairly new to using the std:: algorithms and don't have a good handle on what works by default and what requires custom comparitors, but on a positive note I learned how to easily pass in custom comparitors as lambdas. That's going to come in *very* handy. What I find funny is that my little scratchpad code is vastly better designed and formatted than the "professional" off-shore code I've been doing reviews on at work. It's not that I'm good; they're just *that* bad. :(
We have a very strong pre-submission process on my team, so even if you were a co-worker I wouldn't be worried. As for off-shore code, I'm aware of the horror. My brother is a manager of an out-sourced team there &amp; the stories he tells makes thedailywtf look like an elite team of engineers.
.0 releases of GCC tend to be fairly buggy, and 4.9.0 is no exception.
I should look at upgrading the version we use on this project from 4.6 to something newer. We're only using 4.6 because it comes with RHEL 6, and sheer laziness and ease of dealing with it prevents us from changing.
Well a lot of it was fixed/improved by now, but basically there used to be some factually wrong information and some examples/tutorials that had php.net's level of quality. (So between useless to actively harmful) In contrast, cppreference had pretty good material on the standard library and quite a lot of syntax (templates, lambdas, etc), contains example implementation for a lot of the &lt;algorithm&gt; headers, has examples that are usually useful (or at least aren't flat out wrong) and it is under active development. Recently, they integrated their examples with coliru, and now you can have them compiled and run straight from the page. Nowadays it is mostly inertia. (And the fact that cppreference doesn't use ads, has cleaner design and, at least to me, feels nicer to use.)
If I remember correctly the compilation process is quite painless and takes only about 40 minutes when using jom (webkit and some other components disabled).
You can keep going without problems. Supporting Qt5.X is really easy if you support any of the .xs. The big switch is 4.x to 5.x
yeah, but we're also running into some strange OpenGL issues in 5.2. Hoping the 5.3 update will help fix some of that (although there's not much about it in the release notes). Porting from the old QGLWidget to the new QWindow/QSurface OpenGL format can be a bitch
sic...why not? why provide x86 but not x64?
&gt; If you later switch the type to be a std::vector&lt; uint64_t &gt; then the typedef says the wrong thing It does, but for a different reason than you'd think: that badly-named type originally indicated that it held *primes* less than 2^n , in this case n==32. There used to be a Vector_8 and Vector_16 for primes less than 2^8 and 2^16 respectively, and I tried out different combinations of int sizes for those vectors, so having: using Vector_8 = std::vector&lt; uint32_t &gt; would be perfectly fine. Turns out, there's so few primes less than 2^16 it didn't make any difference regardless of the size of int used, and in the end only Vector_32 remained. Had this been a real program I would have gotten rid of that one as well.
Those typedef styles are hold-overs from a template AI library I'm writing where the mutex and lock types are accessed via MyObject::Mutex_t and MyObject::Lock_Guard_t. There are different kinds of mutexes so I abstracted the typenames out into typedefs for ease-of-use. So they're there because I was on auto-pilot while sketching out the initial classes in this code. :)
I know Arizona State University and Colorado State University have extensive online programs (BA and MA), although I don't know about C++ in general. I wouldn't doubt it, however.
Rule of thumb is that you should do things in the least powerful way possible. This applies especially in C++, where there are fifty million fucking ways to do anything. Examples: References vs. pointers. Prefer references whenever you don't need it to be nullable or relocatable. Pointers can do everything that references can do, but they're also easier to screw up. Functions vs. macros. Use functions. There are many small functions that are traditionally implemented as macros, like `max` and `abs`, for efficiency. Inline functions get you the same efficiency, but they're not as powerful, so there are fewer ways to screw them up. Const vs. non-const. Use const when possible. If you think that you shouldn't be modifying something, there's no need to be able to, so you should remove that ability to avoid screwing up. This member vs. non-member function thing is another example of this. Some methods, like a `vector`'s `reserve`, can absolutely not be implemented (at least not efficiently) by its public interface, but other things, like `find`, can, so it's better that they aren't.
My attempt was to understand through rephrasing. I was wondering if my statements were correct.
&gt; The compiler takes QML files and compiles them to native code showing a big difference in performance on operating systems where one cannot use a Just in time compiler, namely iOS and WinRT. I assume this is because of bullshit legal reasons and not any technical restriction, yes?
You could try this one in Coursera but is finished now, so I don't think that you can receive the certificate. You can still watch the videos though. https://www.coursera.org/course/cplusplus4c 
Also worth reading in this context (and perhaps will help to clear things up): * Scott Meyers: [How Non-Member Functions Improve Encapsulation](http://www.drdobbs.com/cpp/how-non-member-functions-improve-encapsu/184401197) * Herb Sutter: [GotW #70: Encapsulation](http://www.gotw.ca/gotw/070.htm) * Herb Sutter: [What's In a Class? - The Interface Principle](http://www.gotw.ca/publications/mill02.htm) Related: * http://stackoverflow.com/questions/1692084/how-non-member-functions-improve-encapsulation * http://stackoverflow.com/questions/3817414/large-scale-usage-of-meyers-advice-to-prefer-non-member-non-friend-functions
The drawback to this has always been discovery, for me. Lots of things can be implemented as free functions but it might not be obvious to the user. So you end up with half your interface being member functions and the other half not, seemingly arbitrarily. I usually settle on implementing as much as possible as free functions and adding methods that just wrap them. Maybe even static member functions.
C++11 added `begin(arr)`/`end(arr)` to the standard library.
The sort function might not be the best example since the user expects that it is a free function like the one in STL. If you provide a free sort at first, and then later realize that it would be better to make it a member, you'll need to do it in a dirty way (friend, or the free sort would call the member sort - just like std::begin/end) - You can not remove the free sort, you'd break API compatibility. If you go for the member sort from the start, you'd get a clean interface, and all generic programmers will hate you because they will need to specialise all their sort-using generic algorithms for your class. :)
Yes. Third-party JITs are forbidden on these platforms.
Yes, iOS stores (and I guess WinRT as well) does not allow software that generates assembly code as the v4 jit does.
The only big drawback of C++ is that there is no syntax sugar (like in D) for skipping the first argument to a non-member non-friend function by using the member access operator ".". Why is this a big deal? Well: - `o.do_this().do_that_after().then_do_another_thing();` reads (like humans do) left to right. - `then_do_another_thing(do_that_after(do_this(o)));` reads right to left. Non-member non-friends provide the best encapsulation compared to the alternatives (what an irony.. eh Java?), however the language makes them unnecessarily hard to use. If you want to read more search for D's Uniform Function Call Syntax or UFCS.
&gt; What does that have to do with C++11? As I said, std::begin was [added with C++11](http://en.cppreference.com/w/cpp/iterator/begin "std::begin"). That's what it has to do with C++11.
&gt; and I'm leary of boost just because it's such an intimidating tool Sooner or later you will *have* to face Boost, there simply isn’t a practical way around it when programming C++ for most general-purpose applications. It’s not particularly intimidating either: Boost.Filesystem is a fairly simple API, there isn’t much to learn. Boost on the whole is not one library, it’s a set of quite independent libraries, no need to use them all at once.
Doesn't have C++11 containers. This [question](http://stackoverflow.com/q/10699265/1381108) has a more updated overview.
This is an important point: On one hand, there seems to be the notion that its good practice to do something like this: namespace FooNamespace { class Foo { // ... }; int do_something(Foo&amp; f) { ... } } (seen in one of the meyers/sutter links posted by mttd). However on the other Hand I've seen people advise strongly against using too many / nested namespaces and rather use "one per library". This seems to be contradictory, what is the way to go, and why? 
It should be noted that Boost.Filesystem is going to be a TS for C++1y in the near future under `&lt;filesystem&gt;`. So it's a good idea to learn its API since it'll benefit you in the future more than likely.
I must admit I never took the time to design a diagram for my answer though, hope people don't mind text.
I need to find elements by key and now I'm stuck in limbo...
This is the real kicker for me. I didn't really like his example with "nap".
Could you elaborate this more? Your "Foo library" example only has one namespace, so it looks like in asking the question, you've achieved both goals.
Start----&gt;did you try vector? ----&gt; use vector | the rest
There still aren't enough arrows pointing to vector. :-D
What I mean is the idea of basically encapsulating each class into a namespace instead of having only one namespace for your library/application which consists of several classes. Putting each class into a namespace would make it possible to put functions "related to the class" into that namespace and have them easily accessible and group them logically together, and might help Koenig lookup. However I read (dont recall where unfortunately), that namespaces should only be used very sparsely as it can make accessing things tedious (dont know of a good example of that though). Would you advise for using namespaces around single classes plus their global functions that logically belong to them, even if that means introducing many namespaces? Or would you just put all your global functions into one big namespace and make sure they do not collide in ways you dont want to by appropriate naming?
I prefer it in text. I didn't like parsing the diagram, which I found noisy.
Ah, I see. Thanks for explaining. Personally, I try to keep all the classes and free functions that are intended to work closely together / have related functionality in a single namespace. I try to avoid dumping everything in a single namespace (like namespace std does) and keep everything to smallish, focused and complete logical units. E.g. for a game, a graphics namespace might have vertex buffer, shader, and texture classes + free functions, but not game specific or math classes and functions. I think it is very unlikely that within one namespace unit like this, that there would logically be two entities that want the same name and thus conflict. E.g. there might be a graphics related buffer and a file IO related buffer, but the file IO classes and functions should be separate from the graphics system. I also try to avoid having namespaces too deeply nested, and avoid going beyond two (or three for a detail namespace) where I can.
Thanks, that sounds like a good approach :)
Because more often then not vector is still better. Deque adds quite a lot of book keeping. I have nothing against deque. When it's needed it's a great tool.
great read thanks !
man opendir tells you about dirent. There's other ways too , read man ftw If there is any difference in using that vs boost filesystem, the difference would be so miniscule compared to the potential I/O that's done and the work you need with opening/closing files and directories that it will not matter. Use whatever is most convenient for you, though using boost filesystem will help you make the application portable to e.g. windows. 
The fact that Herb Sutter is actively working on the C++ ABI problem is the most exciting thing there for me.
I would kill for at least quick overview, ie how much of itanium ABI will be reused (I would expect quite a lot, seeing how it is defacto standard on unix), whether the stupid name mangling of itanium ABI will be thrown out, etc. Oh well, only ~4 months to go. (And many years until standardization)
Also, a virtually equivalent library to Boost.filesystem is a TS in C++14. N3505, for the curious.
It's interesting how much of libuv's code wouldn't be necessary if it was written in C++11 vs C (I understand why obviously, ABI compatibility in C++ is a nightmare). It might be interesting to see someone reimplement it in C++ (using the STL for threads, mutexes, conditional variables, atomics, etc) and seeing how the codebase compares. Basically you'd just need an intrusive-list and the code for async I/O
This is the first time I've heard of ref-qualified member functions! Time to do some reading... *read* *read* *read*
I get your point, though find is (again) less then a perfect choice :) If the implementation can not be made generic, or has no reason to be, implement it as a method. Then, think about whether there is a generic method that does the same thing for other classes. If so, make a non-member one as well. Example 1. class Dog (the usual alternative to abusing Cars as an example :) ) We want to make a bark() method. Since only dogs can bark (lets suppose this is true), and it requires knowing internals of a dog to implement, it should be a member function. Example 2. class Dog We want to make a function that returns a string, for example the name of the dog. Lets call the function to_string. This time, the method is not unique to the dog (we like to be able to convert almost everything to string), but it still requires knowing the internals. So it /needs/ to be a member. But, what if there is a common, global function like to_string that people are used to? What if there are useful other methods that use the global to_string? In that case, you should implement the global one overloaded for your class, that uses the member function. (again, or do the friend thing - it is not really considered as totally evil in this case) This is the group in which IMO find, sort and similar belong to - if the class really needs to implement its own versions of those. (for the case of sorted containers, binary_search, lower/upper_bound should be used rather than find) Example 3. common collections, ranges, itterable things Just provide a generic range concept so that the classes can work with stl algorithms. &gt; btw I think "STL" does in this way doesnt count ;p Heh, STL has its issues. But, when it comes to composability of different independent parts of it, it is one of the best libraries outside of functional world. And, considering when it was created, I can not but admire Mr Stepanov. 
The lock-free one sounds really interesting. Can anyone point me to how to solve the ABA problem in a clean way in C++11? I ended up using hazard pointers when trying to implement something similar to what *swap!* does in Clojure.
Glad to see this project is still alive. The best C++ Win32 GUI library I've ever had a chance to use.
&gt; However, what is the exact rational behind it? One reason is that it can really improve readibility, because it's much easier to understand code if you can immediately rule out the vast majority of things it might do at a glance. 
Sorted vectors can be good substitutes for ordered associative containers if you insert all the data up front and then perform lookups without changing the data. There's even a Scott Meyers Effective STL chapter about it: http://my.safaribooksonline.com/book/programming/cplusplus/9780321545183/associative-containers/ch03lev1sec5 And if you're reaching for an associative container, you will likely want to reach for an unordered one (also covered in the above chapter, though it predates having standard ones!)
&gt; For example, mapping a string (say, a filename) to a pointer (say, a loaded copy of that resource) is a natural fit for a map, and would be insane to implement on top of a vector. No, that's not at all insane. A sorted vector of `std::pair&lt;std::string, T*&gt;` will beat `std::map&lt;std::string, T*&gt;` on performance given sufficiently more reads and updates than insertions and removals. Implementing `std::map`'s interface on top of `std::vector` doesn't take all that much code, and if you can use boost `flat_map` already does that for you.
ATL and WTL are great! Very useful for any win32 stuff. And as of vc12 header only. 
Good point, and I was trying to quickly come up with an example where queries wouldn't be too much more frequent than insertions. So I guess the case where other containers beat out vector are even fewer than I thought.
Agreed. Pity it doesn't support Mingw though.
5.4 is the current target for the "QOpenGLWidget" to replace the now deprecated QGLWidget. Hopefully that sorts out some OpenGL issues I am ahving with OS-X and sharing contexts between QGL/QOpenGL stuff...
I would totally love some sample code if you have any to offer on this. I really love cpp and went to use it for web development, but am struggling a bit to get up and going on it. 
Thanks for your answer! with "'STL does it this way' doesnt count" I'm not trying to critize STL, but my goal is understanding why certain decisions are better than others and what the trade-offs are, so saying "somebody else decided this way too" would not have helped me :) (and programmers unfortunately sometimes tend to guru-ism and do everything the way their lords do without questioning). In Example 2, I like your point that "the friend thing" is not generally evil, it actually has an upside: With the member AND non-member functions approach, the interfaces would seem weird to a first time users: some classes have a .to_string, others have not. Worse, which ones have it actually implements on implementation details, namely whether or not to_string can be implemented with whats available from the public interface. In such a case, a non-member friend function actually seems like a good idea.
You can merge lists in O(1) if you don't need to preserve original lists.
Oh i'm aware. Our current issue is that the OpenGL view size doesn't necessarily meet the actual view size.. It ends up being quite larger. We'ere still looking for a workaround
O(n) because order matters. You can't just append one list to the end of another.
So you're telling me that, not counting allocations or copies, merging sorted lists into another sorted list is O(1) while similarly merging vectors is O(n)? Take a moment to consider how you'd implement that. Also take a moment to consider what the page you linked is actually saying.
http://plasmahh.projectiwear.org/cce_clean.svg
My observation is that deque's extra book keeping is amortized enough that it really doesn't matter unless your container is virtually empty, and it tends to be more flexible and perform better in a wider variety of cases. The only big loss is if you need to hand the container over as a contiguous chunk of memory. In the end, if the reasons to use a vector over a deque matter, you should probably be considering all container alternatives, whereas deque is more general purpose "okay without me even thinking about it".
You are presuming the merged collections need to remain sorted (likely, but not necessarily a requirement).
What is that state of that across vendors? I hope it gets added to C++17 propper.
I wouldn't.
http://plasmahh.projectiwear.org/cce_clean.svg
Dr. Memory is a good, free, Windows alternative for valgrind. I really recommend checking it out if you haven’t already.
Memory currently targets 32-bit applications only. =[
&gt; Dr. Memory currently targets 32-bit applications only. 
Yes, a bit surprising when most computers sold now are 64-bits, even personal ones.
This is a very good example! https://github.com/simonask/w
&gt; Thanks for your answer! No problem :) &gt; would not have helped me :) Understood and agreed :) &gt; "the friend thing" is not generally evil Agreed again. There are two fractions in the c++ world - one says that friends are always evil and break encapsulation. The other group says that if a stand-alone method should actually belong to a class (things like to_string, stream operators, etc.) but for some reason (like the above, or of necessity like operator&lt;&lt; and &gt;&gt;) are declared as non-members, they can freely be made friends since they, semantically, belong to the class.
How does it compare against ASan and MSan ? Those are like factor 10-20x faster than valgrind.
Hint: It depends whether or not you have cycles. If you don't have cycles, the current standard will help you: shared_ptr supports atomic access functions. :) If you do have cycles, you really want GC... thus my proposed talks on lock-free code and garbage collection are closely related.
Yeah, header only and also compatible with Windows CE / Mobile, so it was possible to build desktop &amp; mobile apps from a single codebase, quite a big deal back in the day.
Most applications are still 32bit. And regardless, you can compile a 64bit app to 32 and test it in this without much of a hitch.
English has different words for a reason: "splice", "concatenate", and "merge". In programming, "merge" means "maintain sorted order".
In my case I wanted to implement something like [*swap!*](http://clojuredocs.org/clojure_core/1.2.0/clojure.core/swap!) in Clojure. The problem is that when I need to swap the content of the shared_ptr with some other shared_ptr. In order to do so I need to check whether the shared pointer is pointing to the same place. Otherwise we need to reread the new pointer, do something and try to swap again. So I would need to use: &gt; atomic_compare_exchange_strong( std::shared_ptr&lt;T&gt;* p, &gt; std::shared_ptr&lt;T&gt;* expected, &gt; std::shared_ptr&lt;T&gt; desired); But that is not implemented in libstdc++. In libc++ is implemented but, if I remember correctly, it uses some sort of lock, just like boost::shared_ptr. There is an old thread in comp.lang.c++ [here](https://groups.google.com/forum/#!topic/comp.lang.c++.moderated/3df814DcRnw[1-25-false]) where, if I understand correctly, Andrei and others claim that we would need a DCAS to do that swap in a lock-free fashion. I ended up using hazard pointers, but I'd really like to get rid of them if I can :) 
It might depend what you work on, I have not once worked on 32 bits applications in the last 7 years.
It seems monads are becoming a bit of a talking point in the C++ community. Between this and Bartosz's blog post a few months ago...
It'd be great if complex functionality such as instruction manipulation didn't have to be tied in with specific instruction sets. Can anyone recommend a good memory debugger that supports many CPU architectures?
It doesn't *really* [mean that](http://dictionary.reference.com/browse/merge). Even in a mathematical sense you can talk about merging in a context where order doesn't even exist, which I imagine is partly why it is called "merge sort" instead of just "merge" ;-). Commonly used English terms unfortunately tend to be terribly ambiguous. 
I understand the idea of using `Error` first and `T` second, that's how `Either` is used in Haskell because `T` is the *right* result (!) However, when reading `expected&lt;E, T&gt;` it seems that I am expecting `E`...
One benefit of putting the unexpected type first is that it *may* make aliases look a little cleaner (but this is subjective). e.g. template &lt;typename T&gt; using expected_s = expected&lt;string, T&gt;; vs. template &lt;typename T&gt; using expected_s = expected&lt;T, string&gt;; but it really makes no difference. Now, if C++ supported currying types... then we'd be in business. Imagine using expected_s = expected&lt;string&gt;; desugaring into the first form above.
Quick A: atomic&lt;&gt;::whatever can always use a lock under the covers if it needs to, such as for atomic&lt;BigStruct&gt;, but it's (a) safe and can't deadlock because it's a leaf-level lock and (b) it can be implemented as a cheap spinlock which shouldn't hurt unless under heavy contention (and if you have heavy contention on a specific atomic there are other scalability issues -- any contended cache line as good as takes a lock at the HW cache level from a scalability POV).
The best way to get a "feel" for things is to write lots of code &amp; to try &amp; use as many language &amp; library features as possible. Then you'll see where you're making mistakes or when behaviour is surprising &amp; you get a feel for where pitfalls could be. Which order you do things (get a feel for it, then get knowledge or vice versa) isn't super important. Getting a high-level overview, writing lots of code to get experience, &amp; then diving in again to fill in gaps/get a detailed explanation of what you're seeing is probably the best way to master a topic. For C++11, I'd say the biggest "booby" traps (i.e. deceptively simple concepts that will bite you in the ass) are lambda captures &amp; moves. If you're looking on tips to avoid those booby traps, write simple straight-forward code that tries to follow what looks like a well-travelled path.
The plan is that all of the TS (8 planned so far) will be added to C++17. For now, they'll be available under `std::experimental`. The idea is that they'll be able to get feedback from people actually using them, then they will be able to make sensible changes for when they're put into the core standard library.
First of all, thank you for taking your time to reply :) &gt; (b) it can be implemented as a cheap spinlock which shouldn't hurt unless under heavy contention (and if you have heavy contention on a specific atomic there are other scalability issues I really need to post my code and benchmarks because I actually see a quite noticeable performance increase when I compare implementations (1) based on boost::shared_ptr (which uses a spinlock for atomic_compare_exchange_strong) and (2) based on hazard pointers and a compare and swap where there are no locks in the critical path. As I'm obviously much less knowledgeable than you, I must be doing something wrong for sure:) 
Ordering isn't the same as sorting (ah... the ambiguities of common English strike again). Even if it were, there can be cases where the order of the lists trumps the order of the elements within the lists, which means the "splice" operation is precisely how you'd want to do a merge. There are also cases where elements in the original lists need to be kept in sorted order, but merged lists do not... The devil is in the details.
What kind of errors does this generate when the requirements are not met? 
Well, you're not wrong. I guess we just interpret things differently.
You would get the usual errors when attempting to misuse a template. You can give "nice" error messages through usage of "static_assert".
Well taking this trait and function: TICK_TRAIT(is_incrementable) { template&lt;class T&gt; auto requires(T&amp;&amp; x) -&gt; TICK_VALID( x++, ++x ); }; template&lt;class T, TICK_REQUIRES(is_incrementable&lt;T&gt;())&gt; void increment(T&amp; x) { x++; } And then calling it like this: struct foo {}; foo f; increment(f); Produces an error like this with clang: ../demo.cpp:25:2: error: no matching function for call to 'increment' increment(f); ^~~~~~~~~ ../demo.cpp:14:19: note: candidate template ignored: disabled by 'enable_if' [with T = foo] template&lt;class T, TICK_REQUIRES(is_incrementable&lt;T&gt;())&gt; ^ ../tick/requires.h:25:52: note: expanded from macro 'TICK_REQUIRES' #define TICK_REQUIRES(...) typename std::enable_if&lt;(__VA_ARGS__), int&gt;::type = 0 This is pretty concise and gives enough information for most commons cases, however, sometimes you may want more information. In that case the `TICK_TRAIT_CHECK` can be used. For example, say we had a `is_incrementable` type defined like this: TICK_TRAIT(is_incrementable, std::is_integral&lt;_&gt;) { template&lt;class T&gt; auto requires(T&amp;&amp; x) -&gt; TICK_VALID( x++, ++x ); }; Then if we use `TICK_TRAIT_CHECK`, we can see why `int*` is not incrementable: TICK_TRAIT_CHECK(is_incrementable&lt;int*&gt;); Which will produce this error: ../tick/trait_check.h:95:38: error: implicit instantiation of undefined template 'tick::TRAIT_CHECK_FAILURE&lt;std::is_integral&lt;int *&gt;, is_incrementable&lt;int *&gt; &gt;' Which shows the traits that failed including any refinements. So we can see that it failed because `std::is_integral&lt;int *&gt;` is not true. 
&gt; Words mean what we use them to mean, and the usage in programming is clear. It's really not. Heck, there are many cases in programming "merging" means to add the elements of one associative entity (say, like a std::map) in to the another entity, overwriting in any cases where the elements overlap. Much like "map" is a noun in C++ but a verb in a lot of other languages, the programming world suffers from namespace overloading as much as anywhere else. &gt; The usage in C++ is extra clear, as we have functions named merge. I agree that the meaning of std::merge in C++ is extremely clear. However, "merge" without qualifiers is at least ambiguous enough that [C++ reference sites provide example code referencing the meaning I describe above for unordered maps](http://www.cplusplus.com/reference/unordered_map/unordered_map/operator=/) and the C++ committee proposal [n3645](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3645.pdf "Splicing Maps and Sets (Revision 1)") proposed a merge operation that is a not so subtle variant on the version I mention above (elements get removed from the source, elements already in the target get left in the source) --which I found terribly confusing. The folks at Google who worked on C++-based protocol buffers [were similarly confused about what Merge means](https://developers.google.com/protocol-buffers/docs/reference/cpp/google.protobuf.message_lite#MessageLite.MergeFromCodedStream). I'm all for having specific meanings attached to terms to clarify discussions, but failing to acknowledge these ambiguities exist in the first place just makes matters worse.
I myself prefer non-member erase, though I don't see why it should be a uniform interface for all the STL containters, including the associative ones. For example, erasing an element in an unordered_map takes constant time on average but using a free erase function could take linear time (of course, it's still possible for member erase in unordered_map to take time linear in the size of the map, but that's the worst case). However, this does make sense for sequential containers. 
Without automatic type deduction on the return values of functions, I would really hate typing out `expected&lt;exception_ptr, map&lt;string, map&lt;int, string&gt;&gt;&gt;` every single time I'm 'expecting' a `map&lt;string, map&lt;int, string&gt;&gt;` object to be returned from a function. Although I did like the idea of `boost::optional` (and now `std::optional`) I don't see how this is a necessary addition to the standard library. It's nice to use if I just typedef really long types everywhere (or if we have automatic return type deduction from functions), but otherwise, its really cumbersome.
Thanks for reading. erase(pos) and erase(first, last) return iterators so they can tell you where the following elements end up. But if you give me a whole container, and tell me to eliminate bad elements, what information do you want afterwards? The bad elements are gone, and the container knows its own begin and end. For forward_list only, I suppose the algorithm discovers the size of the container, which otherwise isn't available. Honestly I don't care about forward_list, the world's least useful container. For the other containers, if you can think of anything useful to return, I'm open to suggestions.
Thanks for the reply. Thinking about it a little more, you're completely right. It had escaped my mind that the iterator returned from `erase` after going through the erase-remove-if idiom would be pretty useless. I like this proposal. I went into it thinking that this might possibly affect the inevitable ranges proposals but you answered it in the Q&amp;A section.
&gt; I don't see why it should be a uniform interface for all the STL containters, including the associative ones. Suppose that you have a map from names to things, whether they're employees or game enemies or whatever. Usually you look things up by name, inserting/removing stuff that way. But sometimes you want to look through the whole map, and remove stuff based on something about the value component, not the key component. For example, all enemies with zero/negative health. That requires a linear-time scan, which is exactly what this proposal is about.
Non-member functions are primarily useful for keeping class interfaces small and fundamental, and for genericity between classes and non-classes (which is what std::begin() does with containers and arrays). Something like push_back(container, element) wouldn't really buy anything.
I try to pre-emptively answer all questions. :-&gt; I didn't consciously think of this one though, so thank you - now I will be prepared if somebody asks it at Rapperswil. (I can also point to list::remove[_if], which returns void.)
boost choose to return the container ([remove_erase_if](http://www.boost.org/doc/libs/1_55_0/libs/range/doc/html/range/reference/algorithms/new/remove_erase_if.html)). Maybe useful for chaining calls? Either way looks like a welcome addition.
Why doesn't `std::experimental::any` have a templated `is` method, which wraps the process of calling `typeid` on some type: `a.is&lt;std::string&gt;()` vs. `a.type()==typeid(std::string)` &gt;Such small-object optimization shall only be applied to nothrow copyable types. How does this make sense? Is it so difficult to have a "*disengaged*" buffer inside the object? `std::experimental::optional` is literally specified immediately before this.
Hmm, perhaps.
That can be determined by inspecting the size (again, except for forward_list).
Boost.Range v2 push_back(container, range) utility is really handy. Could you elaborate more about why you think that it "wouldn't really buy anything"? I was considering writing a proposal to it since we were debating adding it to Boost.Range v3 as an utility [0] but are not really comfortable with the idea since it is not a range algorithm (but a container utility). I have to add that I think Boost.Range v2 erase_remove_if(container, predicate) algorithm adds more than push_back(container, range) since what it does is more error prone to do without the utility. However, at least in the kinds of programs I write I use push_back way more than erase_remove_if, so I consider both to be equally important. [0] https://github.com/ericniebler/range-v3/pull/4
Well then, good things that we do have auto return type deduction.
Subjective indeed :x
`push_back` doesn't have a free version. I was thinking of things like `sort(container)` calling `container.sort()` for `std::list` and `sort(begin(container), end(container))` for everything else, which would give you a more generic interface.
That's pretty good. How are compilation times? (are you the author? If so, I would suggest to put the above information in the readme, I think it's rather important).
&gt; FAQ, A10: … Note that an author of a user-defined container can overload erase_if() for their container in their namespace. I don't understand this, could somebody explain it to me?
Presentations from last week's C++Now conference: https://github.com/boostcon/cppnow_presentations_2014 Lots of people trying to figure out how to incorporate functional concepts into C++ -- with limited success. Personally, I think the current trend of spotty pseudo-functional coding style (e.g. begin(c) rather than c.begin()) will continue but will fall short of a complete paradigm shift (like Bartosz et al hope to see).
Ah, curried template parameters! Now it all makes sense... But no, they need to switch it to &lt;T,E&gt;. 
No, please. I don't want to chain calls like this. I'd hate to see something like this in a project: for(auto it = std::erase_if(some_vector, [](const auto&amp; item) { return item.has_some_property(); }).begin(); it!=some_vector.end(); ++it) { do_something(*it); } 
IIUC, STL's point is about the trivialness of a container algorithm, and about whether it can be implemented in terms of more primitive container interface. Push_back is itself a low-level container primitive, and so it doesn't make sense as a separate container algorithm, and without ranges, I tend to agree. With ranges, I disagree. Until the containers themselves get push_back members that take range arguments, a separate push_back algorithm makes perfect sense.
I'll stick with void, since it can be changed later, but not the other way around.
OT question: I live not too far from Rapperswil. Are there going to be public talks that one could attend to? Where would I have to register? I'm not a computer scientist, rather a theoretical physicist. However, I'm using C++ fairly often. And since C++11 I've become quite interested in its modern features and development. EDIT: I found the [agenda](http://isocpp.org/files/papers/n3979.pdf) but can't find anything about registration, and conditions.
and good old typedef
If someone wants garbage collection in C++ they should think about using [`std::shared_ptr`](http://en.cppreference.com/w/cpp/memory/shared_ptr) and how they can just call [`make_shared`](http://en.cppreference.com/w/cpp/memory/shared_ptr/make_shared) for most cases where garbage collection would be useful in an application (`std::unique_ptr&lt;T&gt;` would also work, but it's more restrictive (no copying, for example) and doesn't yet have a `make_unique` function). I'm meaning to say that in *most* cases where garbage collection would be useful, it's already possible in the form of `std::shared_ptr`. Of course there are cases where it isn't the best choice, but those cases aren't very common and adding garbage collection v.s. just using the already-standard smart pointers is much more work for much less payoff.
Wait, we're finally getting around to trying to fix C++s abi problems? WHAT IS THIS MADNESS
Garbage collection would be more of a negative supplement to what the language already offers. This is something that many other languages excel in, whereas in C++ it would be tacked on like a poorly thought out sequel. If I need garbage collection, I rely on a stable VM that's been around for years and whose original implementation included GC (hello java, python, ruby...). The primary problem is that new developers don't realize that C++ can be used on embedded hardware. Realistically speaking, software caters to hardware and allows software engineers to explicitly determine the best way to take advantage of the target hardware. There are enough additions to the standard library that causes the runtime overhead to grow past what hardware can offer at an optimum level. C++ has always shone brightly as a mix of low-level C and high-level OOP. Quite frankly though, GC is something that C++ should be used to implement [similar to unique_ptr and shared_ptr] rather than tack on as a way to stay current. It is, always has been, and should remain a language that promotes the ability to implement something, rather than be an old fossil trying to stay hip.
No, that idiom doesn't apply since std::erase_if is only overloaded for specific standard container types, not arbitrary T.
There was something about [`make_unique` being put into the C++14 standard](http://en.cppreference.com/w/cpp/memory/unique_ptr/make_unique) for "array types of unknown bound", which was the only issue with the plain unique_ptr initialization, IIRC.
I'd quite like to have a `gc_ptr&lt;&gt;` that provided reasonably performant precise garbage collection at no runtime cost to the parts of the application not using it, since sometimes the natural interface for something does involve cyclic ownership. Anything short of that, though, seems like it'd just be actively harmful. If the GC isn't good enough to use in "serious" programs, then it's yet another C++ feature that people have to learn not to use, and it'd be a particularly dangerous one since it'd be so appealing to beginners.
&gt; Garbage collection would be more of a negative supplement to what the language already offers. I have this criticism with a lot of the modern fortran additions. There's a ton of conceptually awesome stuff that got added, but a lot of it is very painful to use in the language because of how it's "tacked on" to the language.
PM me with your email address and I'll get you connected up with the right people. The committee is always in need of more C++ users (as opposed to vendors) attending!
(replying directly so you'll see this; sdeetee can definitely help you!) See isocpp.org's [Meetings and Participation](https://isocpp.org/std/meetings-and-participation) page for more info, particularly: &gt; Meetings are open to the public, and we welcome people to attend for a meeting or two as an observer; this lets you participate and argue and do most everything, except only you can’t actually participate in change approval polls. As a courtesy to the host, though, it’s nice to have notice of who’s coming so that we can be sure there are enough seats and refreshments, so if you plan to attend as an observer please contact the respective meeting’s host (listed in the meeting’s announcement paper) to let them know. Boost's [C++ Committee Meeting FAQ for Boost Members](http://www.boost.org/community/committee.html) is also informative, although slightly outdated.
Thanks, hadn't looked at Boost.Range (my job is one of the few where it is physically impossible to use Boost, so I don't get to explore it very much these days). I agree that making v.insert(v.end(), first, last) more convenient is nice.
If you look at how std::remove() works for vectors, it permits the vector element and the given value to have different types. In my terminology, this "transparently" handles heterogeneous types. People do this a *lot* in practice (I know because I receive the bug reports) and C++ has evolved to permit it in more places: lower_bound() in C++11, map&lt;K, V, less&lt;&gt;&gt; in C++14. Given a map&lt;K, V, less&lt;K&gt;&gt; and a pair&lt;X, Y&gt;, it may be possible to compare pair&lt;const K, V&gt; == pair&lt;X, Y&gt;, without K &lt; X compiling. So you can't use associative lookup to help. In general though, you are correct that erase(key) is applicable if you want to erase a whole value from something in the map family.
Both `make_unique&lt;T&gt;()` and `make_unique&lt;T[]&gt;` were voted into C++14 and shipped in VC 2013. I know because I proposed and implemented them. [N3656 make_unique (Revision 1)](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3656.htm) was the Standardese that was voted in.
begin(c) and c.begin() are just different notations, they have nothing to do with functional programming. Both list.map(...).filter(...).foldl(...) and foldl(..., filter(..., map(..., list))) are functional.
&gt; or use some combo of shared_ptr and weak_ptr You make it sound like this was something bad and not good engineering practice.
In the general case, you have no guarantee that two libraries built with different compilers (or versions of a compiler) can interact. A common workaround is to rebuild your entire project, including dependencies. It also means that to update nicely a past product (eg by changing one DLL), you must keep the same exact compiler you used when you initially shipped.
what do you gain through garbage collection? You do not have to think again about deallocation of objects .. **BUT** .. you loose a defined way of destruction of objects which normally frees resources. Therefor, you have to think for each object you use, whether you have to call a user defined function to definitivly free resources, or not (e.g. file handles, ...) ... as it is in java. I rather have to only think of allocation/deallocation of objects (with shared_ptr, ...) then to not and instead know for each object, whether i have to call a finalizer method, or not .. The GC approach is way more error prone.
Yeah, breaking cycles is not as hard as people make it out to be. Sure, you have to think about your data structure, but I mean, you should do that *anyway*.
Thank you :)
There are cases where garbage collection is faster than what C++ have in terms of shared_ptr and unique_ptr though.
Wait a minute, isn't GC *already* in C++11? At least as an optional component, no compiler vendor actually bothered to implement it. There are also a bunch of [standard functions](http://en.cppreference.com/w/cpp/memory) to interact with it.
Reading the comments here it becomes apparent that very few people actually read the articles when they click a link.
Not really, after all there is no reason some destructors could not be executed. Of course the issue of destructing cycles whose individual members do something to each in their destructor is a nasty issue...
It does not seem like you know how a GC works: Here from Java: The GC **might** be called before the program ends. If it does, it will call the finalizer method (similar to a destructor). Now have a look at the following: void func(void) { A a = new a(); // do stuff with A } Now, if A e.g. acquire resources, then are they released? Java says: **MAYBE** sometime before the program ends. There is no guarantee that the resource will be freed and a destructor be called. What if it holds the lock for an important resource? What if if is a buffer that must be written to the hd before the end of the program? There is no guarantee that anything of that will ever happen from the GC, even if you say so in the destructor. If you rely on it, you have to read documentation for each class and find out, if you have to do some clean up after the use (and you have to remember to do so)
Remember, it's not strictly the case that garbage collection is incompatible with the performance requirements of an RToS. Most systems have a lot more memory than they ever actually use--even on a chip where memory is at a premium, if the chip has any kind of heap, it's not unusual to find it's using up 20% or more of the total storage available, and unless you are pushing the chip beyond its limits, you never allocate the entire heap anyway. Furthermore, a garbage collection system is not _necessarily_ precluded from using the more traditional techniques of reference counting in order to reclaim memory. The only thing garbage collection has that reference counting does not is the ability to detect and eliminate unreferenced objects--that kind of thing doesn't have to happen all the time. Edit: A word which totally undermined my whole point
Clang is making a valiant effort to support MSFT C++ ABI and SEH. And providing a clang-cl frontend that is compatible with cl.exe. I think "good enough" support will be ready within a year. There was definitely discussion on the mailing list about the value of putting time towards an undocumented ABI. In the end, the need for compatibility with the huge number of MSVC binaries won out.
Oh hell no.
Indeed, and icc (intels compiler) is in about the same boat. vc++ compatibility is advertised, but only with certain versions of vc++ and only with the correct compiler flags. I hope the ABI gets somehow standardized, so that microsoft is forced to stop playing their stupid games with c++ that waste everyones time...
Perhaps this talk will be about forcing compiler vendors to get off their ass and implement it?
Well, it is easier to just make a reactionary comment about GC in C++ without reading, or seeing that it is on Sutter's blog, or that it does make a lot of sense. **For everyone who is only reading comments:** The main reason we are talking about GC in C++ is that it helps enormously with certain kinds of lock-free containers, if your data can have cycles in them. 
&gt; Remember, it's strictly the case that garbage collection is incompatible with the performance requirements of an RToS. Not necessarily, you could use a real-time collector. But dynamic memory itself is problematic in general because of the fragmentation issue (which is present even if you use a `malloc`/`free` implementation with hard bounds).
This is basically how I feel. I understand the hesitation the community feels WRT garbage collection, but a not-terrible gc_ptr would be extremely powerful. It's actually possible to implement a gc_ptr in C++11. I did this as an experiment once, but it's not without it's flaws. Basically implement it by remembering where in memory the objects stored in gc_ptrs are, so that you can effectively run a mark/sweep on them. Its very slow, and only works if you use them consistently. That said, having implemented this, I'm fairly confident that a lot of the reflection stuff would help immensely here, and one of these could be implemented as a library, given the right reflection API.
I use GCC for C++ on Windows, I don't see this problem you're having, could you explain? 
Not in typical cases, and even when it is true, you're giving up determinism (and deterministic destruction) for it, which isn't worth it IMO.
FWIW, leaking when you hit OOM is pretty insignificant. Honestly theres not much you can do there and typically the OS is just going to shut your program down. More common is when you aren't using int's and the ctor for one of them throws.
I think the standard committee basically punted on it for C++11, basically saying that they'd get to it next time around, but leave this stuff in there for now because they're pretty sure it will be needed.
std::locale is not worth it IMO, and it's not useful in the typical case, yet there it is. There is a valid argument for GC.
If you're using gcc on windows for C++, you will not be able to use C++ libraries other people have made and compiled with microsofts compiler (the most common one to use on windows.) That's a huge problem especially for e.g. commercial libraries. You won't be able to use things like PhysX or Scaleform unless you have purchased the (significantly more expensive) source-license and then compiled the library yourself with gcc. That's how microsoft keeps msvc a relevant compiler -- otherwise everyone would've left for gcc or clang a long time ago, since those are (by pretty much all accounts) far superior. Right now your only options, if you need a better compiler on windows, are to either use one of the compatible ones (icc: expensive, slow in compiling, runs slower on AMD chipsets), to not use any libraries you don't have the sourcecode to (often not an option) or to shell out the extra money. Hopefully clang will remedy this issue soon.
In some cases it's not really possible, such as when the ownership structure is dictated by application usage. At work I work on a game engine. The ownership structure of the object graph is declared by files (typially xml or binary) spit out by other tools. The user of the tools has to be careful to ensure they don't create reference cycles. Unfortunately they aren't always a programmer, and so this happens somewhat frequently. I've thought many times about how to apply GC to this, but replacing the shared_ptr (actually intrusive_ptr) with some sort of object handle would be infeasible given the size of the codebase.
I'm very much for GC in C++. I've actually implemented a couple in the past. Saying they're faster than manual memory management isn't really true in the general case, and even in the cases where it is true, you're giving up determinism. Not to mention the fact that the GCs that can beat manual memory management are basically incompatible with languages like C and C++. These typically win by being able to do tricks like compact the live objects and other such things requiring the ability to move pointers around. Really, IMO, the best we can hope for is a gc_ptr which is reference counted with cycle detection. (That said, I think this would be great)
That's what I figured -- an issue with closed/non-shared source software, rather than an innate problem with GCC on Windows. I don't really view that so much as a problem with Microsoft and/or their ABI. There's a lot of things to hate/dislike/begrudge Microsoft for (such as producing a shoddy C++ compiler), but going their own way with their own compiler isn't -- in my opinion -- one of them. I think the ire should be firmly focused on out of date/regressive licensing models, closed source software in general, or the insistence of people upon using Microsoft's shoddy compiler, thus validating it/them.
In software design, complexity is the enemy. As [thomcc points out](http://www.reddit.com/r/cpp/comments/26c6hd/proposal_to_add_garbage_collection_to_c/chq1ojq), there are programs where your object graph layout is dynamic and unpredictable by the very nature of the problem being solved. Sure, you could use weak_ptr to avoid circular references, but it gets non-trivial *fast*. If you don't need deterministic object deallocation (and aren't going to be hampered by collection pauses), GC is absolutely the way to go for solving those particular kind of problems.
Every time I've compared msvc and gcc on Windows, msvc has produced significantly smaller binaries that run slightly faster. While the C++ frontend has certainly lagged, the backend is quite solid, and in an ideal world I'd be using the clang frontend + msvc backend on Windows.
Are you sure that's not because you've built with a bunch of compatibility layers enabled? Or without optimization switches? Or maybe because you've built for 32 bit vs. 64 bit? In my tests (and tests I've seen from other) gcc produced faster binaries (I've never compared size)
Can someone expand a bit on why it might be beneficial to have it standardized in the language as opposed to writing an implementation within the language as it is? Is there a plan to standardize on the garbage collection implementation?
Can you produce those comparisons? Every time someone claims their comparison shows MSVC outperforming GCC they are never able to produce an actual piece of source code that backs it up, and people make this claim a lot. Search online for actual reproduceable benchmarks comparing MinGW and MSVC, and until recently they both produced code that comes very very close to one another in terms of both speed and size. Recently GCC has pretty clearly come to outperform MSVC for 32 bit code and both are significantly slower (15%-30%) than Intel's C++ compiler. As for smaller binaries, chances are you are statically linking to MinGW's C/C++ runtime and with MSVC you're using the dynamic MSVCRT.dll.
But it doesn't help with lock-free containers though, in fact it makes things worse. What it does is move out the cost of locking from the actual point where the container operation is performed, to being spread out for the entire duration of your program because the garbage collector itself ends up doing the locking that would have otherwise been done by the container. Basically, if your language already has a garbage collector, then sure lock free data structures using that garbage collector don't introduce any extra costs. But if your language doesn't have a GC and you're adding a GC for the sake of accommodating lock free containers, well sure on paper your container may be lock free, but the overall system is not lock free, you're just deferring the locking from the container itself and to the garbage collector.
The beauty of C++ (and C) is that if you really want a feature, you can implement it yourself (and spread it around). For example, you can define your own `new` and `delete` which might generate data for your graph- pointer value, size allocated and/or type (thanks, templates), etc.- and add it to a linked list or data structure of your own choosing. And if you don't want to do that, [it already exists](http://en.wikipedia.org/wiki/Boehm_garbage_collector) and is used commercially. Just don't add implicit garbage collecting to C++, make it optional and it's not an issue.
I'd suggest not making assumptions about what I know or don't know about the implementation of lock free data structures. If you have a point to make, just make it in a way suitable for this discussion format rather than just making a blanket statement about researching an entire field of study as if that constitutes a counter point to what I said.
Preface by saying, I'm no expert on garbage collection, and I haven't followed the discussion on adding GC support to C++. In order to do GC we need to know what memory is live and what can be reclaimed. One way to do this is to scan the live set from its roots (globals, thread locals, and stack), and recursively mark memory as live. Anything unmarked after this process is garbage. For an efficient implementation of this there are ways to avoid scanning the entire set every time (see generational garbage collection), however, the basics of the problem demands that we have some way to scanning and recursing our allocation / object graph. Without language support, or a well defined stack and globals layout, this is hard to do right. It would also be helpful to be able to pause threads to do accurate scanning from stacks.
You made an assertive statement that GC doesn't help with lock free data structures, as it if it were plain fact, when it isn't. Apologies for my wording, but that to me suggested some ignorance of the topic, and I felt talking opinion as fact deserved to be called out. To your point about lock overhead being moved from the data structure to other points in the program. Of course it is true that GC itself has a cost. However, that cost isn't per operation of the data structure. It's also not per allocation. The cost of a scan scales usually with the size of the live set. In a producer / consumer scenario the live set will typically be very small, so low cost. In a more balanced communication or persistent storage scenario, some level of reuse is often possible, which will keep scan frequency down. How this compares with plain locking, or against other reclamation strategies, will very much depend on the scenario and the data structures. I 'd be very keen to see what kind of performance can be achieved in a language which is mostly not GC'd, but some GC thrown in to deal only with these particular problems.
&gt; It would also be helpful to be able to pause threads to do accurate scanning from stacks. I may be mistaken, but I think that's how the majority of the java garbage collectors run.
interesting to know .. but yeah, if you use using the c# using statement, you can also always use shared_ptr in c++.. and the java solution, less elegant is a pretty nice description for it :)
I hope it's OK to submit my own blog. I'm currently working on timing a build with CMake 3.0 with the latest Ninja and see if that makes a difference since apparently there are differences with how header dependencies are handled. Edit: [Stats](https://docs.google.com/spreadsheets/d/1fzQSLbSsFJh9Fjyt-mPwSE1ZpzEN1pHv_-bAjjARVls/edit?usp=sharing)
This is a great read for me. I’m new to generalized build systems (and, to be honest, the finer details of build systems in general), and am currently trying to grok CMake. SCons has been in the back of my head to look at some time, as well.
Since you're just starting, picking one and learning it well would be a good way to go. In a couple of years, you'll probably start feeling a little bit of build-system envy and will know what you don't like about the one you chose. Maybe you'll switch at that time and in another few years, repeat the cycle :)
My personal biggest reason for running Cmake is that it generates proper native project files for different IDEs. Few do that, I've found. 
Sometimes there's a reason why stuff is apparently missing (e.g. vector lacks push_front()), sometimes there isn't.
I thought it was a technical restriction that was at least theoretically for safety reasons(I may be wrong though).
MinGW doesn't have a CRT, it uses the msvcrt.dll from the OS, which is not supported by MS but mostly works. VC has both static (libcmt.lib) and dynamic (msvcr120.dll) CRTs; the dynamic CRT may be installed systemwide but it is not an OS component. (MinGW does have its own STL, libstdc++, which can be either static or dynamic, just as VC has libcpmt.lib and msvcp120.dll.) Note that there is one thing VC does which MinGW still doesn't: VC's linker has had /OPT:REF for ages, while binutils' --gc-sections has never been ported to Windows.
Yes, the "minimal GC support" functions are permitted to be no-ops, which is what we've gleefully done in VC.
There is also Google's gyp which stands for generate your project. I think it uses a json representation for the build specificiation.
Yeah, the `int` case isn't very interesting. Some memory allocation failures should be handled (e.g. if try to allocate a gigabyte cache in a 32-bit application in response to a user action you really should be able to resolve a failure as an error message rather than a crash), but if allocating four bytes fails you're going to need some very carefully thought-out handling to be able to do anything useful. I was trying to simplify the example as much as possible, and perhaps using `int` was more than is possible.
Which was pretty much the worst possible route they could have taken. Adding stuff to the standard that no one actually has any plans to use anytime soon is awful.
I have to admit, I'm also skeptical on the benefits/detriments of adding garbage collection to the language. I personally can't think of a lock free structure that *requires* garbage collection to be implemented effectively. I would have to guess the set of use cases are a subset of the use cases for lock free programming, which are arguably significantly smaller than the typical use cases for the language. I'm aware there *can* be performance gains for batching memory operations. However, I'm still unconvinced of an overall benefit.
Have you used CMake before? I haven't tried any of the new 3.0 stuff. Are there any good features that were helpful / simplifying? A few months ago I successfully converted my workplace's amalgamation of bash scripts and kludged makefiles into a predictable and simple CMake file configuration. I was able to successfully build on linux and windows using all of the IDEs I tried. This was a big step-up from what we had which relied on cygwin. Now I can use VS natively! The biggest help I had was groking the openchemistry cmake build system until I understood exactly what it was doing. I didn't find many helpful tutorials online, but going line through line I was able to adapt many of their idioms and it turned out fantastic.
Well, some OSes (linux unless you configure it not to, probably mac, probably some bsds) overcommit, so malloc won't ever return null, nor will new ever throw bad_alloc. The program will just crash when you try to access the overcommitted region of memory. That's why I made the comment. But yeah, I understand it was a simpified example.
Have you tried using [ccache](https://ccache.samba.org) and/or [distcc](http://distcc.org). They're fairly easy to configure, and they might reduce your compile times by a bit over vanilla CMake/Ninja.
Half the time, I'm on Windows so distcc doesn't help because I use the MSVC compiler but I could potentially use it on OSX. Thanks for the tip.
Yes, I had used it before but not to build my own code. It's a good idea to look at the way others use CMake to learn. Yay for open source!
The compiler ABI is indeed undocumented but de facto very stable - the compiler team is very conservative about making such changes. It's the library where we break compat gleefully, and what prevents major version mixing in practice. (As soon as you drag in a single STL header, you must play by my rules.)
Don't have any performance figures but here are some size comparisons. I work on an open source text editor component called Scintilla with source code available at https://sourceforge.net/p/scintilla/code/ci/default/tree/ A windows build produces two DLLs, Scintilla.DLL is the basic functionality and SciLexer.DLL includes lexers for a hundred languages. Building for release with 32-bit MinGW gcc 4.8.1 and 32-bit Visual C++ 2013 produces: * gcc 4.8.1 * 537,088 Scintilla.dll * 1,074,176 SciLexer.dll * Visual C++ 2013 * 385,536 Scintilla.dll * 774,144 SciLexer.dll So Visual C++ produces executables around 70% of the size of those produced by gcc. The MinGW build dynamically links to MSVCRT.DLL and the Visual C++ build statically links in the C runtime. There is one feature missing from the gcc version: since MinGW doesn't include Direct2D headers, that is disabled in the gcc build. If you want to use Direct2D (for antialiased drawing and slightly better looking text) then MinGW64 includes the required headers. -- Edited to improve formatting
Yeah, been using that a bit for building Google Skia, but that was after I had a cmake system up and running so I haven't looked too much at it. 
&gt; The GC might be called before the program ends. If it does, it will call the finalizer method (similar to a destructor). Which is quite uninteresting: both the C++ Standard and *any* GC implementation would obviously be free to specify *another behavior*. There is no *one GC to rule them all*, it's a generic terminology for a broad scope of possibilities.
I don't think anyone is thinking about *implicit* garbage collection. Rather I think they are thinking about: - the necessary interfaces for people to implement garbage collection (which should have gone in in C++11, unless they missed some things) - specifications for the behavior of garbage collection, I can see a couple thorny issues regarding destructors... unless maybe it's left unspecified - getting an implementation out, with a *precise* garbage collector
I don't see how that changes any of my points whatsoever -- if either of them changes, the average library compatibility breaks, and you're hosed. 
I like procedural build systems. I have used SCons and Waf before, and I really like the concept of [tup](http://gittup.org/tup/). When it's a bit more stable maybe I'll swing back around and try it again, since the last time I tried it, support on Windows was lacking. On Windows, I prefer psake (when I'm not just using raw Visual Studio output). I have avoided CMake for a long time for exactly the reason you did: I don't like the look of the language. I don't even think it's a step up over an XML-based system (Ant/Nant/MSBuild/etc) since at least they're somewhat human-readable.
That's a property of Java's implementation of GC, not of GCs in general. There's no reason you can't guarantee the eventual destruction of objects, other than that it's slow to do so. A GC for C++ would have to do this. Probably reference counting + cycle detection is the way to go there. The only objects that would have their dtors called late would be those in cycles, but they'd still get called, even when the program exits before the gc would naturally run (e.g. it would run at exit)
Could you explain why you consider that an advantage? I've always preferred SCons for the reason that everything remains under my control, rather than adding another point of failure like possibly incompatible-with-the-systems-make-implementation make/nmake/ninja/vs-files, generating more files that you end up have flying around, only having to run a single command, ... All the gains I can really see you getting from that is that you can press the "play" button in visual studio or some other IDE, and I'm sure you could just configure it to run "scons" instead? (your user needs to have scons/cmake installed anyway, so...)
And that's why I replied - you said it was "ever-changing-for-no-real-reason" and "they are purposefully doing this to kill the competition". For the libraries, the first half of each is true and the second half of each is false. For the compiler, the ABI is nearly invariant (I say nearly only because I recently heard about a fix that broke compat in a minor way, which was deeply surprising), so each is false.
I don't see any reason to make any kind of distinction between compilers and libraries ABI here. Both are under the same vendors control. Your users don't care which of your components the breakage comes from, that's a red herring. If it breaks, we're the ones who have to deal with the issues. I don't care about microsofts internal politics. And you still haven't given my any actual reasons as to why I should agree with you that: - the breakage happens for any real reason, - it's not done purposefully to kill competition. Do you think any of your users ever said "phew, I'm so glad I can save a few bytes here, totally worth breaking compatibility with everything in existence!", or "this micro-optimization has saved me so much work, because it has pushed my programs speed past the threshold where it meets my performance requirements without me having to hand-optimize it, so totally worth having to pay for an upgraded version of my libraries!", when I can just go to ICC, which is compatible with BOTH the standard ABI and microsoft ones, and is STILL massively faster than vc++? No. Nobody ever said that. You also have not provided any reason for why none of my (admittedly vague) proposals for alternative strategies would not be superior to the clusterfudge we have now. If you think your users want optimization (and they do, of course!) optimize the things that really matter and provide benefit to your users. So far you haven't changed my impression that the stuff you're doing right now is busywork, assigned to you for keeping the competition down.
The size of every vector object matters. So does correctness (I was horrified when I realized that VC broke vector swap in 2005, before I joined - we had to fix that). I have nearly unlimited personal discretion as to what we do or don't do in VC's STL - but if you'd like to believe that Borg High Command is controlling my thoughts, go for it.
&gt; The size of every vector object matters. And that *somehow* makes it necessary to break the ABI with every revision? Everyone else seems to do fine without doing that. Heck, even if you insist breaking the ABI, if you release the specification for it so that others can adapt (ideally before a new VS version is released), that'd be fine. Or if you want to go the extra mile, you could even provide some sort of implementation. Or at least advise software creators about the issues and recommend to build versions compatible with other ABIs as well (this is obviously already considered good practice amongst the more sensible developers). Just about ANYTHING would help to make the situation better, really. &gt; ... broke ... Yes, obviously correctness is important. That's another total red herring -- nobody will fault you for fixing something that's broken. And that's not what I'm complaining about either. But hey, had you used a standard ABI (or at least documented yours), maybe the issue would've never happened in the first place (or have been discovered earlier)? Just a guess. &gt; ... nearly unlimited personal discretion as to what we do or don't do in VC's STL ... But are you the one who is making the choice to not start a project to document the ABI? Are you in a position to say "from now on, we'll have a stable ABI"? Or any of the other things I suggested above? Try pitching that to your HOD/BA/whatever sometimes and see if you get any pushback. I don't think this is a technical issue, and I'm not blaming any of the engineers -- it's clearly a management/culture issue of not caring about the customers and wanting to hinder competition. As most programmers, I'm willing to put up with an almost unending amount of inconveniences if I can derive some reason for why any given inconvenience is worth having. Having to do stuff in some-or-other arcane way? Sure, if it's for the sake of performance. Writing a lot of extra code for tests? Sure, if it's for the sake of quality. But so far you still haven't given me any reason why I would want to put up with what VC does -- you're telling me accepting this inconvenience makes your product better, yet your product is inferior to ones that don't cause me that inconvenience? Does not compute. It's not like I don't *WANT* to believe that this inconvenience that I have to put up with does me *SOME* good. I'd really like to, but there seems to be no reason. 
&gt; Everyone else seems to do fine without doing that. libstdc++ is still shipping a forbidden-by-C++11 COW string, so no, they're not doing fine.
Actually got no real reason, I just think it feels nicer for some reason. I know some systems (for example scons and jam, iirc) can do what you suggest; generate a project that just runs the build system as a custom build step, but... I just don't like the way that leaves all the project settings in the IDE hanging somehow. But, it's just a matter of personal taste, no actual true benefit I can think of right now. EDIT: One reason, as mentioned in the article, is that IDE based build systems like IncrediBuild can do their thing. When I first started messing with build systems a lot we were actually running IncrediBuild, so that was probably why I opted out of "non-native" systems at that point and maybe how this taste was developed, but I don't remember really. (Although back then, almost 10 years ago, I didn't go with cmake either but made a custom template based project generator.) 
That's yet another total red herring. http://msdn.microsoft.com/en-us/library/hh567368.aspx VS does not provide a 100% compliant C++11 implementation either. Are you *really* sure you want to apply that metric? Didn't think so. And I re-iterate: That's not what I'm complaining about. Fixing bugs (and even breaking compatibility for it!) is okay. *Having* bugs sometimes is okay as well, particularly if it's in new functionality. What is not okay, is to waste peoples time uselessly. Address the real issues, not strawmen.
Our library deficiencies aren't due to ABI limitations, though. We are immune to that particular class of problems.
Note that one of the big reasons *C* is still around is its sane and consistent ABI. If C++ had this, it might have killed C for good by now.
Overloading operator * for *every type* in the global namespace seems incredibly evil. I would much prefer it to be written as a variadic function.
The way to handle that using reference counting would be to check for strongly connected components in the object graph when reading it in from the xml file, and then have all of the objects in each component share a single reference count. Not trivial to do by any means, but probably much simpler than trying to introduce GC. At the minimum you should write a verification tool for the config files that checks for cycles and warns the user (I'm guess you don't have such a thing already based on your mention of detecting cycles on exit).
Good point. Even though my operator* is wrapped in a namespace*, it would be easy enough to misuse. I originally designed this as an EDSL under Boost::Proto, but didn't love the resulting syntax. I also looked at a variadic function and didn't love that syntax, either, but, as you point out, that would avoid some complications. *I didn't mention that in the blog post, though I probably should have. 
So it turns out that CMake is only kind of case-sensitive. You can write calls in ```lower_case``` but stuff appending to a list needs to use ```list(APPEND```. That was one of the things I used to make the code a little more aesthetically pleasing.
"IDE based build systems like IncrediBuild can do their thing" -- well, that's kind of what I'd prefer to avoid, since those most likely will just screw up my stuff...
Yeah, dynamic objects that can participate in cycles makes things a lot harder. I suspect any generalized solution would very strongly resemble just using a garbage collector for cycle detection.
CMake commands can be lower case, parameters to commands must be uppercase. I am saddened anytime I see a project use scream case. Likewise for using the of if/macro/function closing syntax. Scratch that I am just saddened anytime I see a person use macro instead of function. 
I don't think I agree with this. Implicitly performing explicit conversions has always been somewhat dubious in my mind, but overall worthwhile. This might be crossing the line. 
I don't understand what the inconsistency is in the only braced-init-lists version.
Anyone know what problem this proposal is intended to solve? Seems like this proposal isn't really addressing any actual issue that developers have, but I could be entirely wrong.
I think it would allow things like this: std::tuple&lt;int, bool&gt; f() { return {0, false}; } which isn't currently allowed because that tuple constructor is explicit. You can currently write: std::tuple&lt;int, bool&gt; f() { return std::tuple&lt;int, bool&gt;{0, false}; } but that requires you to repeat the type and it also has slightly different semantics as the former is direct initialization of the tuple, while the latter is move construction. The compiler will elide this move so it doesn't matter from a code generation perspective but... I didn't see this mentioned in my skimming of the paper but this could potentially make the language more powerful by allowing direct initialization of explicit constructors for non-movable types. Consider a non-movable type like std::lock_guard, now imagine you want to write a function make_lock_guard. This type is non-movable so you cannot return it by copy/move construction, but you can use "return {}" for direct initialization like this: #include &lt;mutex&gt; template&lt;typename T&gt; std::lock_guard&lt;T&gt; make_lock_guard(T &amp; mutex) { mutex.lock(); return {mutex, std::adopt_lock_t{}}; } int main() { std::mutex mutex; auto &amp;&amp; guard = make_lock_guard(mutex); } Unfortunately, we could not write: template&lt;typename T&gt; std::lock_guard&lt;T&gt; make_lock_guard(T &amp; mutex) { return {mutex}; } because that constructor for std::lock_guard is explicit, so we had to work around it with a different non-explicit constructor, but this option may not be possible for some other non-movable type. My understanding is that the explicit constructor would be available under this proposal.
While it does enable some things not currently possible (as covered by detrinoh), I suspect the primary motivation is the bit about the compiler knowing exactly what you mean but forcing you to type a bunch of redundant boilerplate anyway. Sutter's current focus seems to be on getting more people using C++, and making C++ friendlier to the user is an important part of that.
Qt framework. that is all. Cross platform for mobile and desktop/server environments. Open and commercial licenses.
Is there a list out there of what they fixed with Update 2 for VC 2013? All I saw was 'fixed some language conform issues with Visual C++' on their release changelog.
two, inverse maps?
I saw some mails where the compiler team was trying to gather a more detailed changelog, but I don't know if/when it will be published. No STL bugs have met the combination bar of being nasty enough and low-risk enough to service post-RTM, since I shipped 3 fixes in 2010 SP1 (one was for a string memory leak, very bad with a 2-line fix). For the next major version, I am preparing a detailed STL changelog as I did for 2013.
Special case. Adds inconsistency by definition.
&gt; Sutter's current focus seems to be on getting more people using C++, and making C++ friendlier to the user is an important part of that. I think making C++ friendlier will be useful for all C++ users. On my development team, there are many old hats that are afraid of C++'s 'newer' features (smart pointers, templates, etc...). Showing them how things are easier will make it easier for the project to progress to newer and safer techniques.
&gt; the direction of c++ is that there are an increasing number of features with functionality overlap. Could you site some examples?
you might want to consider icecc/icecream. 
In the old syntax the closing parentheses must contain the syntax of the opening parentheses, e.g.: if(WIN32) ... endif(WIN32) Now you can just have endif()
Occasionally, although most of the issues I've had, arose from the outdated cmake version I have to support at work. So typically the cmake step itself already fails right off the bat with some syntax error, missing/unknown symbol, etc. But another thing is really just that I want complete control over how the compiler is invoked, with what flags, what files go in and out, and where, so that if something goes wrong, I immediately know what's what. For some of my projects I also cross-build for win, linux, osx, android, ios, with extra-targets for e.g. "oldgcc" (RHEL) or "iosclang", and I'm having a hard time imagining how I could make that work with cmake... making the makefile invoke the right compiler, with the right pathes to the android NDK, etc etc -- and now all of that with "different build-system-backends"? I don't know, that just seems very error-prone to me. SCons allows me to keep all of that relatively simple. Also, if $SOME_EXTERNAL_SYSTEM is used, it'd probably create more random files in the project directory (and if somebody starts using my project f.ex. with ninja, something I have never used myself, they might git commit some generated .ninja (or whatever) files to the repository, because I don't have those in the gitignore) which I'd dislike. So overall I just don't really see any huge benefit in going through this whole procedure? In addition to that I can only imagine how much more complex this must make cmake itself, seeing how it has to generate code in many languages etc... and more complexity means of course more possibilities for bugs. (Although you could plausibly claim that cmake is probably very well-tested compared to SCons, since SCons is pretty niche)
This looks very useful, I may just end up using them thanks!
Ah yes.
&gt; For some of my projects I also cross-build for win, linux, osx, android, ios, with extra-targets for e.g. "oldgcc" (RHEL) or "iosclang", and I'm having a hard time imagining how I could make that work with cmake I'd do it by checking the target platform in the cmakelists.txt and include different cmake files with different settings (cleaner than just defining everything in the same file imho, though you could do that as well). But cross compiling with cmake is a PITA, I'll grant you that. :-) &gt; Also, if $SOME_EXTERNAL_SYSTEM is used, it'd probably create more random files in the project directory The way most people use cmake is to do out-of-tree builds (in a build/-subdirectory, for example). Then you avoid all build-time files that you don't want people to commit, not only the build system files. :-) &gt; So overall I just don't really see any huge benefit in going through this whole procedure? Well, I don't particularily care about what flags are needed on all obscure platforms, so I'd rather let cmake sort that out. I also like the fact that I could switch to ninja by just passing -GNinja to cmake. It was also nice to have cmake automatically generate msvc project/solution files when I used VS. &gt; Although you could plausibly claim that cmake is probably very well-tested compared to SCons, since SCons is pretty niche I'd say that is true, I haven't had any problems arising from bugs in CMake itself. It seems to be a very well written piece of software.
It's not very portable, because a counting macro is not defined in the standard, but this works in g++ and Clang. It also won't work well with loops, since it's a macro after all and would just use the same evaluation for all loop body executions: #include &lt;iostream&gt; #define ___STR(X) #X #define STR(X) ___STR(X) #define MAKEPATH(path) (path "/" STR(__COUNTER__)) int main() { std::cout &lt;&lt; MAKEPATH("path") &lt;&lt; std::endl; std::cout &lt;&lt; MAKEPATH("path") &lt;&lt; std::endl; std::cout &lt;&lt; MAKEPATH("path") &lt;&lt; std::endl; std::cout &lt;&lt; MAKEPATH("path") &lt;&lt; std::endl; std::cout &lt;&lt; MAKEPATH("path") &lt;&lt; std::endl; return 0; } But I don't think you'll want a macro for this. What's wrong with the usual... for (int i = 0; i &lt; ...; ++i) { // Make path with i } ... ?
&gt; I don't really see any huge benefit in being able to switch to ninja or whatever -- why would I want to do that, really, does it give you any huge advantages? I was a bit skeptical as well, but I actually had noticeable shorter build times with Ninja, and shorter build times are always welcome. :-) &gt; E.g. can I write my cmake so that the generated output files can do some arbitrary check I define in the cmake script? Maybe I want to verify the user is in the correct path, that he has all subfolders/sub-repositories in place, maybe I want to update subrepositories automatically, or maybe print a warning message if something doesn't seem to be quite right, etc. I think you should be able to do everything you mentioned here with CMake, it is very flexible, but no guarantees. :-)
The issue with making it a variadic function is that it becomes much uglier to use, especially if you have some experience with composing functions Haskell-style (which I assume is the inspiration of the linked implementation). In fact, I wrote exactly such a `compose` function^1 for a Haskell-inspired template library (not using C++14 features though), and found that I almost never actually used it--doing so just didn't flow right as compared to point-free notation in Haskell. Having said that, I agree it's not nice to overload `operator*` globally either. In a namespace is slightly better, but still a bit iffy--*possibly* with some very clever SFINAE. This is of course why I originally used a function myself. I guess my end conclusion was that C++ just doesn't lend itself very well to function composition. [1] Worked a bit differently from OP's. It would compose any sequence of callable objects, so long as the right-most one (the first one to be applied if the result of the composition was called) was of a type from which I could deduce argument types, e.g. a function pointer or an `std::function`.
Yeah, this would certainly be a whole lot better if generic lambdas had a nameable type. No doubt about it. I also considered that this isn't actually likely to resolve in a surprising way unless there are user defined types with operator() defined. But rethinking that, operator() is probably a fairly common operator to override. But, yeah, I certainly was hoping for something with cleaner syntax than a variadic function. That might just be the best way to go, though. Writing a Boost::Proto EDSL would remove the namespace issues, but all my candidate Boost::Proto solutions had clunky interfaces as well. The best I could come up with was to prepend _id * to the list of functions you actually wanted to compose. Seems like it would lead to some very confusing code, though -- just the opposite of the intention. 
OP here. Good to hear things are improving! VS is still my favourite environment to code in, will have to try it again and see how it fares.
I'm not familiar with Boost::Proto, so can't really comment on that. However, prefixing with an identiy function object as you mention could indeed be a workaround. Adds some verbosity of course, and I guess in some cases confusion, but all in all, not horrible. Another possibility would be to provide both a variadic function and an operator, but guard the operator behind `#ifdef USE_COMPOSITION_OPERATOR` or something like that, to make sure users explicitly opt-in. Or you could just keep it as is. Could be confusing in some cases, but I assume if people were to use a library like this, then they find the convenience worth the possible confusion. In the case of my own library, I already had a number of other overloaded operators (monoid "append", fmap, bind, &lt;*&gt;, etc) and felt another one would be pushing it.
How about initialisation, it should be simple but it's far from it - see [this comment](http://www.reddit.com/r/programming/comments/1m1izv/goingnative_2013_writing_quick_code_in_c_quickly/cc4ww2x) by Andrei Alexandrescu.
Verified that /u/sh4na is the blog author. :)
It doesn't really look like the compiler will turn C++ code into mill machine code. Instead it looks like you can call into some kind of library from C++ to generate machine code.
The amount of resistance I've seen here on reddit to the new features in c++11 baffles me. I knew there was no going back the first day I got c++11 support on my mac and wrote my first working lambda and suddenly realized just how ridiculously useful they are.
Initialization is actually the biggest one for me. If you look inside the constructor, or at arrays, there are even more possible combinations. Some of the other things would include `auto`, `decltype` and templates, the permutations of pass-by conventions, the multiple ways of using `noexcept`, `=default` and declaration omission, and so on. Hopefully, nobody misunderstands me. The language additions have generally improved the code that can be written (the memory model was a godsend), and generally compiled code does what I would expect. However, I occaisionally worry I'm being nibbled to death by ducks.
It's not the overlap that worries me, it's the fact that each new feature introduces new undefined behavior. It's way past the point anyone in the room can recite the list of undefined/unspecified/implementation-defined behaviors that come up in C++, and compilers just cannot effectively prevent them all... For example, let's look at `move`: void goo(std::string&amp;&amp; s); void foo(std::string s) { goo(std::move(s)); std::cout &lt;&lt; s[3] &lt;&lt; "\n"; } Why, why am I allowed to use `s` after moving ? Because it cannot be proven, in general, that you moved from `s`... 
In my opinion, your assertion about GC and lock-free algorithm exposes your ignorance of the modern non-blocking algorithm techniques. A proper, generic memory reclamation technique can greatly simplify the most of lock-free algorithm while improving performance of their implementation too. Of course, there are several techniques which can be applied without using GC, such as the hazard pointer or the reference count, but they have their own drawbacks. For example, the reference count usually imposes unacceptable performance penalty for a scalable lock-free container while the hazard pointer has been patented by IBM. Maybe you can design and use your own algorithm at your own risk, but I'm skeptical about the patent issue since many novel memory reclamation techniques have been patented, or are in the process of being patented. GC may also has its own cons, but the expected benefits are also significant - generality and simplicity provided by GC are unmatched by any other techniques. Moreover, when GC handles every memory reclamation, a potential performance gain from eliminating memory barrier overhead can be relatively a minor (although significant in sometime) benefit. It is also worth to note that many of modern, efficient memory reclamation techniques are essentially specialized GC - they defer requested memory reclamations until certain safe moment rather than freeing the memory in deterministic way.
Having a disagreement on an issue is not grounds to call someone ignorant and doing so is a very poor tactic in an attempt to dismiss and silence an opinion as opposed to actually discussing it. There is nothing ignorant about my position that adding garbage collection to a language in order to accommodate lock free data structures is misguided and completely negates the entire purpose of lock free data structures, namely performance. Using an existing garbage collector to implement lock free data structures is entirely sensible, since the garbage collector already exists it makes sense to use it. But taking a language without a GC, and adding one just so you can implement your lock free data structure is simply illogical. You have simply moved the locking away from the data structure itself and onto the garbage collector. Sure you can claim strictly speaking that your data structure is lock free, but your data structure now depends on an environment which involves locking and that environment can not strictly be isolated since a garbage collector will have global consequences and effects on performance throughout an entire application. And please don't bring up the extreme argument of and point towards the existence of lock free garbage collectors, they have absolutely horrible, horrible performance compared to the alternative.
Well, I guess it depends on how/if you use an IDE. There's a bunch of things regarding preprocessor defines etc that'll screw up things like autocompletion, syntax highlighting etc if it's not properly set up in the actual IDE project. Since in my case I'll be running the native compiler of the IDE anyway, I'm fine with communicating with it through project settings so that all parts along the way have the same view of what's going on.
Implementing user-space RCU might be a good example. It is quite hard to implement it in an user-space. And even doing so, it could be inefficient than an equivalent implementation using GC, due to imposed memory barrier.
I'm not heavily familiar with RCU implementations, but I didn't think it was the garbage collection aspect of RCU that prevented it from being implemented entirely in user-space. There's generally a non-trivial penalty for implementing garbage collection as well, so it possibly would not be usable in embedded scenarios.
I suggested several concrete examples why GC can be valuable for many circumstances, and you just ignored them, right? For example, I've mentioned the potential performance gain by elimination of memory barriers (which can be significant if a read-write ratio is high, see RCU in Linux!), and you just repeated your logic that the introduction of GC surely entails a negative consequences on overall performance. This is why I refer to your argument as an ignorance, as there is no other possible interpretation for me. I should concede that my stance might not be appropriate, I don't think that I'm the one opposed to discussing it. And I need to mention that GC can always be implemented in an optional, pluggable way. As many practices prove, adding a GC can be done without harming "Zero overhead principle". For example, Rust implements GC, but it also can stand alone without a runtime. And Boehm GC is even implemented as a library. Also, when the non-blocking property is so important, non-blocking implementation of a GC is viable, while its efficiency might be debatable as you said. (However, it is also true that the situation can be greatly improved if we just take a specialized GC for the purpose rather than a generalized one.) But I don't think theoretical strict non-blocking property is so important outside hard real-time systems. Most of high performance, scalable memory allocators, such as jemalloc/tcmalloc, are implemented using a lock (as far as I know). But it is negligible because they are usually non-blocking in the fast path. Same logic can be applied to this issue - the most of gratuitous memory barrier in the fast path (which is the major obstacle for the scalability of simple read operation) can be stripped out if we can assume the existence of GC. It might be true that GC imposes undesirable, non-deterministic latency, but the overall throughput is a completely different issue. It's just an engineering trade-off. If so, I think that having more tools would be better than having nothing.
&gt;I suggested several concrete examples why GC can be valuable for many circumstances, and you just ignored them, right? I'm not ignoring them, I just don't see how they have any relevance to anything I've said. Did I say somewhere that garbage collection doesn't provide any benefits in any circumstances? The discussion is about the implementation of lock free data structures and whether adding a GC to a runtime environment is a proper trade-off in order to accomodate the implementation of such data structures. You're arguing for the sake of arguing and being very disingenuous in the process. Going on and on about the benefits of garbage collection as if it has anything to do with my point and it doesn't, so I don't know what to reply to. My point was that adding garbage collection to a language that doesn't otherwise support it in order to implement lock free data structures is not a proper engineering trade-off. If you just want to ramble about garbage collection and its benefits then be my guest, but it's not the point of this conversation.
&gt; bugs involving NSDMIs and initializer lists Now this explains why I couldn't get a atomic_flag to initialize in an nsdmi! 
&gt; That would be C If only you had a C compiler, right? LOL! More seriously: Yeah, but that's not what we want. We want to be able to make libraries with powerful, sleek C++ APIs. Besides -- this solves nothing. If I already have the issue that vendors give me libraries compiled with a 32-bit version of VS2005, what do you think are the chances they'll consider my request for a C API/etc? Not very good, I'd say. &gt; The subatomic representation details would neither be useful I guess this discussion is not going to go anywhere if we fundamentally disagree what your customers want (of which I'm one of.) libstdc++ does it right: breakage is aggregated, announced, people can adapt to it. When it happens, compatibility is already there. I doubt any of the ICC/clang/whatever developers have ever complained about how difficult it is to adapt to gcc/libstdc++/etc ABI. something, something, when you do your job right, nobody will even notice that you did it, something.
&gt; Do you think any of your users ever said "phew, I'm so glad I can save a few bytes here, totally worth breaking compatibility with everything in existence!" ... No. Nobody ever said that. Well, I'm one of those users and was quite happy about that change. So yes, at least one person has said that.
&gt; that since the special cases seem to represent an incorrect approach to the problem, then optimising for them was the wrong tradeoff I dunno, I think they had it right by making the common operation have the best performance in realistic situations, rather than focusing on the exact spec and its guarantees. Making the majority of people do extra work isn't ideal, even if the spec technically leans that way.
Author here. This little library started off as a for fun project to figure out how far I could push function reflection in C++11. Turns out that was pretty far and I believe I've managed to put together a rather interesting library. That being said, this it's not quite ready to be used in a production setting just yet and I've actually moved on to another project. I do believe that the library is rather interesting and it would be a shame to watch it rot in a corner so I'm looking to gauge community interest. If there's a high enough interest, I'll consider keeping up the development and doing extra tedious tasks like optimizing for compilation times and adding features like proper documentation, enum reflection, proper getter/setter support and writting the rest of the std reflections. In any case, be gentle. It's my first time :)
Even if it is not finished it is really nice of you to share it with the community, thanks for it, it looks really interesting :)
Is it implied that dynamic memory management for ```std::abi``` types will be also handled by the OS owner's library? What happens if you delete the memory for a type in the ```std::abi``` namespace using a different compiler/RTL? Interesting read.
That's Committee-speak for any entity that maintains a compiler and/or Standard Library implementation.
Dynamic memory management is performed by function calls (the new/delete operators invoke operator new/delete in the Standard Library; Terminology Is Fun^TM ). As Herb explained it to me, std::abi is the One True Runtime Library (CRT/STL) for a platform, and its headers/libs can be compiled/linked by any compiler. This is how he prevents VC/Dinkumware's STL, libstdc++, and libc++ from clashing (they all have different lineages and cannot be mixed into a single binary due to the One Definition Rule - can't have totally different definitions of std::vector). The "normal" STLs, which may be fast-evolving, are protected from each other and other versions of themselves via inline namespaces. And the ABI STL is distributed by the platform owner (VC for Windows, presumably libc++ for Mac, presumably libstdc++ for Linux).
Most notably: "It should be possible for an operating system API to expose a well abstracted modern C++ API that uses features like classes, virtual functions, and overloading, and also meets normal OS API requirements for ABI stability.". It's about the time. 
Thank you. I contacted him and things worked out. Cheers! 
__^[wow ^so ^verify]__: ^/u/sh4na ^-&gt; ^/u/CapnRat __^Ð98 ^Dogecoins__&amp;nbsp;^__($0.0391706)__ ^[[help]](http://www.reddit.com/r/dogetipbot/wiki/index)
I don't care, I want modules ! DAMN IT.
&gt; but you still wouldn't be able to use types from other libraries Until they will be upgraded with `abi` section.
`std::` vs `std::abi` Microsoft wont sway `std::abi`, we will be getting safe zone here. Improvements will be delivered to `std::` still as often as they want. GCC will unleash optimizations for `std::`, we will be getting performance boots in places where we don't need `abi`-compatibility. Their desire for stability will be satisfied by `std::abi`. ᴵ ʷᵒᶰᵈᵉʳ ʰᵒʷ ʸᵒᵘ ᵐᶦˢˢᵉᵈ ᵗʰᶦˢ⋅
So essentially this means that headers of a library, that are directly or indirectly exposed actually have to be wrapped in extern "abi", right? Now when a part of your remaining code depends on this exposed code, you'd have the choice between std::abi and plain std. If you chose std and you started mixing std and std::abi, it would be left completely unclear whether there were any conversion costs or what the conversion costs are, because it depends on whether your current STL implementation is ABI compliant with the platform ABI. It is kind of unsatisfying to know that well you have this class, it has a getter that returns a const std::map&lt;..&gt;&amp;, but you can't really know whether it's O(1) or O(n) for a full copy. I feel like this uncanny feeling would actually make people choose std::abi everywhere in those cases. This however may have some dated and sub-par implementation -- after all there is some reason vendors chose to break the ABI...? I also don't feel like this proposal would make GCC for example break ABI more deliberately. After all if you do change it, you cause a runtime cost for all users of mixed std and std::abi namespaces... 
We all know he hates C++ and C++ developers.
Looks nice! Maybe you should add that the library is for _run-time_ reflection, since just reflection can also mean compile-time reflection.
MODULES MODULES MODULES MODULES!!! Looks like not much is happening here. And still, every larger project has one guy trying to keep the build sane, but the voices asking for it remain a few. I would understand the lethargy if the associated tasks were trivial. But even a simple question like - *"which includes are no longer necessary after the last edit"* are fucking complex and dangerous with the current build model. There are few tools that kinda sorta almost solve individual problems for one particular environment and no comments after your includes please. A binary ABI would ease the binary distribution problem (and have some fringe benefits for builds), but in a world moving towards sharing source code, we should make that easier. 
Can someone explain what are the advantages of modules? I know that managing dependencies on windows is a nightmare, but what are the advantages in a linux environment?
This sounds like a tough problem to solve, to me. Would programmers be required to choose one or the other when coding? To me, what makes "sense" is that I should continue using std::* in an extern "abi" (that bit is perfect) and the compiler warns me if anything in that extern block is unsupported by the host OS. Is that how you imagine this works? How much of this understanding is correct: // interface.hpp extern "abi" { std::vector&lt;std::string&gt; function( std::string const &amp;, int n ); } // interface.cpp extern "abi" { std::abi::vector&lt;std::abi::string&gt; function( std::abi::string const &amp; s, int n) { std::vector&lt;std::string&gt; vec; // compiler, not abi version return vec; // converts to abi::vector&lt;std::string&gt; } } Perhaps a small comment on how Qt would change to adapt to this new proposal, since that would be a *huge* win.
Faster build times.
&gt; Looks like not much is happening here. And still, every larger project has one guy trying to keep the build sane, but the voices asking for it remain a few. There's a separate study group for modules (WG21 SG2). They are working hard, but it is a difficult problem. I don't believe that proposals like 'abi' will be slowing down the modules study group.
* Faster compilation times * (maybe) no longer a need to create header files splitting the definition of class among two files.
&gt; that proposals like 'abi' will be slowing down the modules study group. I didn't mean to suggest that. I meant the resonance in the C++ community at large that seems to be lacking, which I just can't grasp. Admittedly, in one talk a few years ago, when Herb asked the audience what they want to see improved in C++, one grumpy hair monster curtly said "Build Model". I was stumped (like most of the audience) - "is that a weirdo?" Fortunately, when he started to explain what he meant (or was that in the online discussion?) he listed a lot of things that bug me in my daily work, and I has a label for this bag of problems for the first time. 
if you have a large application, you can choose to load modules or not at runtime, instead of instancing every possible code. It also allows you to load a module that do some stuff without recompiling your code, which is a godsend for developers. I guess you can somehow do this with a library, or with a class if you follow some procedure, but it gets hairy as everyone do their own way. I'm not really sure though, maybe I need to be taught a little bit more about design in programming or in C++ in particular, I admit not having read herb sutter's books.
How is this different from the current situation, where the C++ compilers running on linux follows the ABI documented at http://mentorembedded.github.io/cxx-abi/abi.html ? 
I beg to differ: the only specified valid operations on a moved-from objects are *assignment* and *destruction*. Some objects *may* guarantee more, at their own discretion, but the Standard does not guarantee anything more in general. Therefore, you cannot *ask* the `s` object whether it was moved from or not (unless it is specifically designed to allow it), you have to guess it (or use a flag somehow).
Fair enough, it's a pretty good stab at a proposal. I hope (along with others, it seems) that it is prioritized along with modules. Both these features improve productivity.
The requirements for `MoveAssignable` and `MoveConstructable` explicitly say that the moved-from object must be left in a valid state. You are of course free to create your own types which have move constructors that are not `MoveConstructable`, but any problems you encounter as a result are entirely your own fault.
Using `extern "abi"` and `std::abi` types is not at all sufficient to actually maintain ABI compatibility while continuing to develop a language. By exposing another library's types in your public API you're binding your level of ABI stability to that library's, which is of course true in any language, but far less relevant in most other languages. Things that don't compile to native code generally don't have the distinction between ABI and API stability to begin with, and the things which break ABI compatibility in C are much more obvious/
Modules, yes! 
Is Linux a platform ? I would argue that the distributions are platforms since they may choose to elect other compilers/standards.
I guess I don't quite understand the value of most of this. Platforms already effectively have a platform C++ language ABI. For example: - gcc and clang on OS X target a common language ABI. - gcc and clang on linux target a common language ABI. - msvc, intel's C++ compiler, and clang on windows target a common language ABI (Though clang has not finished implementing it. RTTI support was just introduced). gcc on Windows chooses not to implement Windows' C++ language ABI and it could continue to do that or it could add support regardless of this proposal. In particular I would guess that under this proposal gcc on Windows would consider the platform to be the mingw or cygwin environment, and so the stable ABI it would target would still not be the same as MSVC. And since the point of those projects is to bring code over to Windows without modification, if projects use `extern "abi"` then gcc on Windows will need to go ahead and compile that code, but using the mingw/cygwin ABI and not MSVC's ABI. I guess if Microsoft documented their ABI that would make it easier for other compilers to implement their ABI, but they could do that regardless of this proposal. Compiler switches I guess are a problem, currently addressed by users not applying any ABI modifying switches so they get the default platform C++ ABI. I guess there's some value in users being able to designate portions of their program where the compiler will ignore ABI modifying switches. It would be funny if we got some flags to change what `extern "abi"` means though: for example a gcc flag that controls whether the stable ABI is MSVC's ABI or mingw's ABI. --- Vendors can already provide binaries that can be linked and used with different compilers and which use C++ types in the interface. They do have to specify what standard library implementation they use, but then as a user I can build my code against the same standard library implementation using whatever compiler I want and link with their binary. I guess I can see some value in the user being able to say some parts of their program use one standard library implementation and other parts use a different implementation. So they could use, in a single translation unit have code interacting with a binary that uses VS2010's library and then also use VS2012's library for their own code. Maybe a simpler feature would be sufficient. Say use `extern "stdlib:libc++"` and `extern "stdlib:msvc2010"` to declare that some code uses that standard library implementation. Compilers would either have built-in knowledge of include and binary locations for each "stdlib:&lt;key&gt;" or would allow the user to configure them with compiler switches. Then standard library implementations would need to use inline namespaces so that the symbols wouldn't clash. libc++ already does this for example so libc++ can already be linked in the same binary as, e.g., libstdc++. There's a gap in libc++'s current solution which is that a user defined type that has a member of a standard library type will be ABI incompatible and the inline namespace is not sufficient to catch this as a link error. So that's where `extern "stdlib:&lt;key&gt;"` comes in, so that the compiler can check this at compile time. --- I'd like to see more from this proposal on what current practices are and how these solutions fall short. For example, libc++'s use of inline namespaces to enable mixing libc++ and libstdc++, or libc++'s and libstdc++'s practice of maintaining std:: as stable. How would users of these features transition to a new 'stable' ABI. How would cygwin/mingw environments play into these platform ABIs? Since libstdc++ has refrained from introducing a C++11 conformant std::string because some users need `std::string` to remain stable, how will they transition to `std::abi::string` as the stable object? Obviously the linker won't just start linking previously built objects with the `std::abi::string`. If everybody could rebuild then ABI stability wouldn't be needed anyway. Maybe it would be better to say `std::string` is the abi stable object and introduce `std::unstable::string`. In fact gcc has already introduced `vstring`. Will the initial requirements on std::abi be C++11's requirements? --- On platforms that don't maintain a stable library ABI I can certainly see an advantage where vendors would in the future be able to ship a single binary targeting the new stable ABI, and then users would be able to use that binary with future version of the compiler. The vendor would no longer have to ship a binary for each version of Visual Studio, and Visual Studio users would no longer have to stay on an older version just because their vendor hasn't released the library for newer versions. On platforms that already maintain stable library ABIs it seems the only value is that they could move to MSVC's model of breaking ABI's. Or they could as long as vendors are willing to rebuild their projects targeting the new stable ABI. I.e. the new stable ABI is only going to be usable by those who don't already need and use ABI stability...
No, Linux isn't a platform. And, this would have implications for more than just GNU/Linux. A large number of operating systems (Linux distros being a subset) implement the [POSIX](https://en.wikipedia.org/wiki/POSIX) standard for system call definitions, as well as use the [System V ABI](https://en.wikipedia.org/wiki/X86_calling_conventions#System_V_AMD64_ABI). This could imply changes to both. It's fairly doubtful Linus would have anything even remotely nice to say about this, but I think a possibly more important question would be what does everyone who currently relies on POSIX and/or the System V ABI (VxWorks, QNX, FreeBSD, NetBSD, OpenBSD, Solaris, OSX, clang, icc, gcc, java, etc...) think.
Just taking a look at this example from the pdf: module M2; export { bool g(int, int); } import std.math; // not exported, local to M2 int f(int x, int y) { return x + y; } // deﬁnition of g exported by M2 int g(int x, int y) { return f(abs(x), abs(y)); } I am not sure this deals with the problem of a type being imported and exported in a function. For example say you import std.vector, but exporting a function map(std::vector&amp;, ...). Unless the model will allow for this exporting to have name resolution of stuff afterwards.
Personally if they can solve the writing stuff twice (hpp/cpp) problem, I'll be all over them. If I can write my code once in one file and be able to write a bunch of "using" and "namespace" at the top that'd save me sooo much pain. I tire of reading headers with all the extra namespace noise in them. I _think_ this will happen with modules (4.12 in that proposal).
struct rectangle with x and y?! is x and y lower left then? as would be natural by then using width and height to quickly navigate to the other parts of the rectangle. or is it the center point of the rectangle? or... why not have a point lower_left; or point center; in struct rectangle instead?
Question is not only about abi. There is conflict of interests. Even compiler vendors are involved too. Some people want stability, even at price of hindering progress down significantly. Another people want performance and improvements and mostly don't care about abi. This proposal intended to satisfy both sides, at price of having 2 standard libraries at once. Also, in case you missed that. Having abi is not pure win, it has its drawbacks, e.g. performance. 
&gt; Using extern "abi" and std::abi types is not at all sufficient (...) Care to elaborate?
IIRC importation of modules is transitive. When you import your module, you'll implicitely import std.vector Don't quote me on that tho, I might be confusing with the older (2012) paper.
&gt; So essentially this means that headers of a library, that are directly or indirectly exposed actually have to be wrapped in extern "abi", right? No. Only parts exported from binary and their dependencied. Abi not needed for header-only libraries, e.g. template 3d math library. Abi not needed for helper functions and classes, which are not part of actual api. &gt; unclear whether there were any conversion costs First, costs may be documented by platform abi maintainer. Second, I believe most conversions will be trivial to optimize. Third, this is still better than no abi.
Personally I'd prefer import std::vector; over import std.vector; 
TL;DR: a wrapper around cairo. Very cool tho.
Just don't blame #include, blame those who don't know other way than abusing that poor little thing. 
Err, even when used responsibly, `#include` is a huge contributor to terrible compile times...
My understanding is that they didn't go for that because they don't want to imply a connection between modules and namespaces, when one doesn't exist.
Not in this paper.
[this](https://code.google.com/p/include-what-you-use/) may help...
I guess any proposal toward standardizing documentation would probably wait until modules is ratified then?
Well, I was using "responsibly" to mean "each file only includes what it uses". And doing that doesn't really help with compile times. Most of the time I see this violated it's files that don't include something they depend on (because it's transitively included), so it wouldn't make a significant difference. The problem (with the preprocessor, and one of the ones modules are trying to solve) is that the compiler needs to reparse all the headers you use in each compilation unit, despite it having been seen during the last compilation unit. ... It doesn't help that you aren't allowed to/can't reliably forward declare stuff from namespace std, and there's nothing like `&lt;iosfwd&gt;` for other headers.
I haven't looked at unity builds yet (thank you). I would agree, having to compromise between compile time and design is far from ideal, but usually any potential cost is minimal. Things like passing by value instead of passing by const ref, are hopefully no-brainers.
I was just reading this proposal and it hit me when I got to section 4.5: no more headers. This can't come fast enough. This other example makes me question what the goal is of grouping modules in this way. Is it simply convenience? We all have seen those giant "include this list of header files for convenience" which just slow down the build in the end. module std.sequence; export { module std.vector; module std.list; module std.array; module std.deque; module std.forward_list; module std.queue; module std.stack; } What would be the expected impact here? There is clearly going to be more disk access when de-serializing the std.sequence module. Maybe a C++ compiler can have a daemon mode that cached these modules while compiling so that when a certain set of compile-time arguments matched, no extra disk access would be necessary. Then we'd be worrying about RAM paging instead of disk accesses for compilation which could possibly be pretty cool since it's easy to add RAM (to a point). 
Generally, as a sort of convention, rectangles start at the top left and have the width and height added to get to the bottom right. I believe the reason it ended up that way is because images use a similar format, and the actual method of drawing to the screen involves essentially streaming an image to video RAM.
Visually appealing? Scott Meyers needs to lose his amish boy hair cut already. Sheesh. EDIT: Calm down [kids](http://blogs.plos.org/dnascience/files/2013/12/bowl-cut.jpg). It was a [joke](https://isocpp.org/files/img/meyers-gn13.PNG).
It would be incredibly neat to add SFML to C++, it is a very modern library, and has been around for a while. I would really rather SFML than a cairo wrapper, but it would be exciting to see any graphics library to the C++ std.
I think you mean Ambassador Soval.
While you're probably right, I'd be curious to hear what's the distinction between run-time and compile-time reflection?
Wait, which graphics frameworks are you referring to? I haven't seen many that use something other than (x, y) referring to the top-left and width + height to get to the bottom right. I'm not saying you're incorrect, I've just never seen those systems and it sounds more intuitive than what I've seen so far.
There's several impacts here, some as you likely have noticed. 1) No more headers means no more textual inclusion. This means the compiler can "compile" each module ahead-of-time (really just processes it to an internal format). Yes - it would cache them somewhere (not necessarily a daemon, clang uses an as-you-go cache IIRC) for later re-use. Since these are basically the AST of the module, loading them is really quick (no parsing, no semantic validation, etc) &amp; you have far fewer disk accesses (don't need to fstat each dependency). 2) More accurate incremental builds: not really sure if this one is making it into it, but theoretically incremental builds that don't change the semantics of the program (e.g. changing a comment) wouldn't cause a rebuild of everything that uses your module (just a re-build of your module). 3) No more "include this list of header files for convenience". In theory every module would just import all the modules it depends on directly instead of trying to improve compile-times with forward-declarations (i.e. I can just import foo &amp; I can call anything imported via that module).
The big one is std::vector &amp; std::string. If you have the wrong version of your systems C++ library loaded (or if the user of your library is using a different C++ library), then you're SOL. It's really a shame. It basically means you either avoid STL or have your own implementation of the subset of STL you need for the ABI.
For having the origin at bottom-left, the one that immediately springs to mind for me is [Cocoa](https://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/CocoaDrawingGuide/Transforms/Transforms.html). All of the other APIs I've thought to look at (GDI, X11) have used upper-left as origin, so I could be wrong about this being common. For having a rectangle that is created with xyxy, the framework I use most often (G3D) has [factory methods to create Rect2Ds from xyxy](http://g3d.sourceforge.net/manual/10.00/class_g3_d_1_1_rect2_d.html#ad6584f4855af009216a940846f4bd613), which I find often mesh with how I think about a particular rectangle (e.g., selection rectangles have one point as the first click location, and the second point as the current mouse position)
- Maybe we could do like Python and only **import** things. It's pretty boring to configure compiler args, preprocessor flags and linker flags each time you start a new project.
Best comment in this whole thread
That haircut is great.
OpenGL uses a lower-left (mathematical) origin.
I don't get it. You mean "while continung to develop a library"? But then we have major version numbers, to break compatibility someday. And afaik it's common practice today, regardles of platform and language. &gt; In the KDE project, we will provide binary compatibility within the life-span of a major release for the core libraries (kdelibs, kdepimlibs).
How, in first place, we get different versions of C++ runtime on same system? (Assuming proposal is accepted.) Either they are different major releases of C++ abi or they are runtimes for actually different platforms (f.e. 32bit vs 64bit on same OS). I don't see third option. First case is why we using major versions numbers — to guarantee (abi) compatibility within major version. Fo both cases, that's developers job to ensure he is linking against correct runtime, and using libraries compatible with this runtime. Otherwise it is silly, like plugging python 3x libraries into python 2x framework, and complaining they are incompatible.
&gt; No. Only parts exported from binary and their dependencied. Abi not &gt; needed for header-only libraries, e.g. template 3d math library. Abi not &gt; needed for helper functions and classes, which are not part of actual api. I don't understand your reply. I am obviously not talking about header only libraries (duh). I was talking about all headers that are exposed through the public interface. If you have a class A which is the public interface, and A has a member instance of class B, whereas B is some helper class, that contains some STL members. Then obviously changes in the STL ABI change the B ABI and thus the A ABI, which is why B has to be wrapped in extern abi as well. And that's what I said: All headers directly or indirectly contained in the public interface (in this case B is indirectly contained) have to use extern "abi". &gt; First, costs may be documented by platform abi maintainer. Second, I beliee most conversions will be trivial to &gt; optimize. Third, this is still better than no abi. They can't be documented by the platform ABI maintainer. They would have do be documented by the compiler vendor or rather the STL distribution for your compiler. And that doesn't help you much, because at the time of writing the code, the costs may be different than when you recompile the code a couple of months later with a new compiler (STL) version. How weird is that? You take a new compiler versions and suddenly new (potential) bottlenecks are introduced into your application...
Run-time reflection means the type doesn't have to be known at compile time. You could use it with any dynamically-generated object from anywhere without ever knowing what actual type it was.
&gt; It would be incredibly neat to add SFML to C++ You mean, like: #include &lt;SFML.h&gt;
This is going to be the best thing that EVER happened to C++ since its creation. 
Any idea why C++ can't use a similar model as OpenGL with its Core profiles to deprecate certain features that have been superseeder with newer, better language/library features. This could be set on a per file basis to keep compatibility with libraries and it would prevent programmers from slipping into old habits. I'm pretty confident that it would work.
See N3996 3.4 [0]. Run-time/compile-time reflection lets you query information about types at run-time/compile-time. Since C++ is statically typed, compile-time reflection also lets you create new types and modify existing ones. Run-time reflection cannot (since types are only checked by the compiler, at compile time). Examples of querying information: - List all member functions of this object that have this signature. - List all data members of this object along with their access control specifiers. Examples of creating/modifying new types: - For every private data member: create a setter and getter function. - For every member function: call this function at the beginning, call this other function at its end. - Array of Structs to Struct of Arrays transformations. For libraries implementing compile-time reflection, see &lt;type_traits&gt;, Boost.TypeTraits, Boost.MPL, Boost.Fusion. For libraries that use compile-time reflection, see, e.g., Boost.Serialization. [0] http://isocpp.org/files/papers/n3996.pdf
What would be the alternative to heap allocation for a widget? You can't keep it on the stack unless you want to sacrifice a thread per session? And somehow, the "tons of possible leaks" due to exceptions never ever seem to turn up in practice. Perhaps partly because a widget is immediately parented at creation in most cases. If you keep pointers to widgets not part of your own hierarchy, then you are making spaghetti; use delegates instead. This ownership problem is also a no-showup in practice.
Optimizing for compilation time *is* needed. You just work on too small / simple projects. It just comes after other priorities you may have. http://xkcd.com/303/.
[Image](http://imgs.xkcd.com/comics/compiling.png) **Title:** Compiling **Title-text:** 'Are you stealing those LCDs?' 'Yeah, but I'm doing it while my code compiles.' [Comic Explanation](http://www.explainxkcd.com/wiki/index.php?title=303#Explanation) **Stats:** This comic has been referenced 151 time(s), representing 0.7026% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcdcomic/)/[kerfuffle](http://www.reddit.com/r/self/comments/1xdwba/the_history_of_the_rxkcd_kerfuffle/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me)
C++ does deprecate features (auto_ptr) and even removed some (export templates). It's limited though: it only applies to constructs that are very rare or that are obvious bad practice.
#include is widely regarded as C++ worst problem by it's biggest users, making quicker compiles impossible. It, and the way can and often does interact with preprocessor defines, is the biggest reason why other languages run circles around C++ in compile speed. Facebook is spending considerable resources on streamlining their compile process because it is seen as such a problem.
I just hope this feature will be approved for C++18, and quickly implemented by major compilers !
I hope we see more breaking changes in C++ as the standards evolve, this talk by Scott Meyers was definitely an insight into some of the problems with C++.
I agree, I'm not sure I would wholly endorse SCU either, but I'd rather at least be familiar with the concept. Actually, another drawback I can see might be the lack of distributivity. It seems like the build would have to be run on a single host, with a lot of cpu/memory. SSDs are awesome for I/O, even if they can be a bit expensive. Actually, I tend to compile on ramdisk where I can. It's surprisingly practical; even more so with distributed builds. Although, RAM's still *technically* more expensive than SSD.
Our definitions of valid state may not match though. From n3485, § 17.6.3.1, [moveconstructible]: &gt; `rv`’s state is unspecified [ Note:`rv` must still meet the requirements of the library component that is using it. The operations listed in those requirements must work as specified whether `rv` has been moved from or not. —end note ] And library components have very few requirements. For example, nothing say that `.size()` on a `std::string` should not throw (or crash).
`size()` is `noexcept`, so no, it can't throw. It is exactly as legal for `size()` to crash when called on a moved-from string as when called on any other string. `size()` has no requirements listed, and therefore is not allowed to fail when called on a `std::string` object (calling it on something other than a `std::string` involves hitting UB, so that can obviously do anything). The bit you quoted explicitly states that `size()` must continue to work as specified on a moved-from object, and therefore still can't fail.
For one, libc++ &amp; libstdc++ are both possible libraries on OSX &amp; Linux. Granted the chances of using libc++ &amp; libstdc++ on Linux is unlikely, it is a possibility on OSX. Next, why does the version matter: libstdc++ has in the past been backwards-incompatible from an ABI perspective. It's been really good in recent memory, but I don't know how they're managing std::string: they used to use an implementation that has been disallowed by C++11 &amp; a conforming implementation would not be ABI compatible. In a more common scenario, I believe (from a recent post by STL) that the Visual Studio STL implementation is much more aggressive about not maintaining binary compatibility across versions. So now you have a dynamic library that was built against a specific C++ runtime. It will load the correct runtime. Similarly you have a different dynamic library/application code that uses a different incompatible version. Where's the problem? They'll both be using the correct runtimes. Imagine this API: class Foo { std::string computeSomeString(); }; &amp; imagine that one side of the API (A) is the library implementation portion linked against C++ version X &amp; the caller of the API (B) is linked against incompatible C++ version Y (perhaps even a different vendor). Side A will allocate the string by calling the string constructor implemented in X. Side B will call the destructor of the string, as implemented by Y. X: string::string(const char *str) : _d(strdup(str)) {} string::~string() { free(str); } Y: string::string(const char *str) : _d(new char[strlen(str)]) { memcpy(_d, str, strlen(str)); } string::~string() { delete [] _d } We can now see a problem - we're going to call delete[] on a pointer allocated with malloc. An even more serious problem can arise. Imagine that X uses COW for it's string but Y doesn't: X: class string { ... private: char *_data; size_t _capacity; size_t _len; size_t _references; } Y: class string { private: char *_data; size_t _capacity; size_t _len; } So now we can see that if we were to try to pass strings across the API boundary, A would access uninitialized memory accessing a string from B &amp; B could leak memory trying to destruct a string from A. Additionally, if _references was nicely put at the end of the struct you could have even more issues. Yes if you stick to the same vendor &amp; same version of the library you won't have issues. I think what developers actually want is to at least raise the restriction of having to be built against the same version of the library. In other words, I should be able to download a pre-compiled library X for my version of the C++ runtime &amp; link against it without having to worry that it was also built against the same version of the C++ runtime I'm building against. You can imagine how difficult it would be to pick a version as the number of libraries grows unless you are completely in control of building the source code.
Seeing some of Microsoft's legacy code makes me feel better about the legacy code I'm cleaning up. Good video, thanks for the share.
Yes, automatically, no installation required, unless you find it useless to have a graphics library in c++ in the first place, but I think this would be very neat. Fiddling with installing libraries on windows is quite annoying, and for some beginners without guidance, impossible.
If you have to use Visual C++ you don't have this problem.
OpenGL API works this way, but most libraries translate it to top-left origin instead of bottom-left.
&gt;What is the reasoning for changing the deduction for only the case without the '='? If you removed that then I think you would not be able to deduce std::initalizer_list when you need to declare a value for it via copy assignment with auto, which is useful for generic programming. Perhaps there is another way to deduce it that I'm unaware of. I believe it's mostly for consistency as = { x, y, z } is commonly used for std::initializer_list construction.
hm? What do you mean?
Instead of using std::unique_ptr for RAII, I found [ScopeGuards](http://www.drdobbs.com/cpp/generic-change-the-way-you-write-excepti/184403758) mesh really well with code bases that don't let you use exceptions. The "throw translation function" is definitely cool, I never thought of this possibility. 
I was reading the module proposal and they said that the design would be remarkably different if it wasn't for backward compatibility. Could a standard ABI help with this, i.e. introducing backward-incompatible source code changes, while maintaning ABI compatibility, a bit like Java and its bytecode? (Note that I think that the module proposal is also very important for this to work.)
You make it sound as if implementing Microsoft's C++ ABI is easy. It's completely undocumented with lots of quirks and strange behavior in corner cases. Seeing this proposal come from Microsoft makes me kind of happy. Having a compatible and open ABI especially for Windows would be a huge boon.
I think what he's implying is that visual studio doesn't fully support modern C++ yet. They're behind the other compilers, but it's not like they're stuck in C++98.
GDI uses a top-right origin (with larger positive x values moving left) for RTL locales.
I don't mean to imply that it's easy, but it has been done before and clang developers are doing it now. I certainly think it would be good for Microsoft to document the ABI, but Microsoft can do that without this proposal and even with this proposal Microsoft could just choose not to conform.
This isn't about using MS products did you actually watch it?
Legacy cruft makes it difficult for new devs to get involved with things though. OpenGL suffers from this, its a horrible mess of new and old legacy OpenGL, and a mix of tutorials around the internets being a bit wishy washy between the two
Am I reading this right? Enum values outside their enumerations are now undefined behavior? Enums used as bitmasks and the like seem too common to do something like this, (not to mention the cited issue with testing an enum value.)
SFML is cross platform, and MSVC has been keeping up decently. GCC and clang both work on windows.
You are correct about #1. There is a higher potential for loss should a crash happen. There was no reason for the software to crash, nor did it. We had very good error handling. The real loss from a crash (trading state) was far more significant a concern than log entries. Yes, I mentioned for #2 that I put in blocking. But for a real-time system that is also catastrophic. So I also put in warnings when it was 2/3 full. Whenever the warning came up we'd increase the size of the buffer. Though simply clearing the buffers quickly kept the buffer sizes from growing too much.
Which would make sense if the majority of suggestions wasn't C++98
The ring-buffers were per-thread. Signals are very slow, the same speed as mutex contention. Just to emit a signal to a waiting thread would take over 100ns. That is why we needed to spin-lock in the consumer. We didn't have lambdas at the time. Though I'm not sure they could have helped (other than make the code easier to read). The fixed number of parameters was just to avoid any memory allocation during the logging. There are lots of solutions for asynchronous logging, but I wanted one that pushed down towards the absolute minimum time possible. Most applications are probably totally find with solutions that take a few microseconds to log.
100ns too expensive every now and then? Spin away! :-)
As far as I understand proposal, `std::abi` may be stable for span of few versions of C++ standard. So, theoretically, major abi release may live for decade. I guess then situations like you described won't happen very often. And when one happens, developer has options to use old standard. I don't see how we may handle this. If dependency is outdated, and there is no way to upgrade it (proprietary library, lack of human hours, whatever), but you want to use it with newest abi, well, then you are just out of luck. And this is not specific to C++ or abis. Do you have proposal to solve this issue?
The logging system we use has another approach to handling the full situation: it discards stuff. This means that in case of bursts you may get a log: 1: Fooing the bar 2: ... !! 235 logs skipped !! ... 3: Baring the foo This second line is both our warnings and a precise count of the loss so we can have accurate enough information to take action.
Interesting. Thanks for the reference.
Honestly, I haven't watched it yet, so I can't comment. I was just pointing out the snark above me.
Does anyone know if this is going to be streamed online like going native?
Some papers I found interesting: &gt; Types don't know # Make it easier to to define `std::hash` for your custom types by providing a hasher that you can just feed arbitrary blobs of bytes in to, both reducing the amount of boilerplate involved and making it so that the standard library can just supply a high-quality hash algorithm that everything uses. &gt; Removing trigraphs??! Pretty self-explanatory. Even if it's a pretty minor bit of cruft, it'd be nice to actually remove some cruft from the language. &gt; Polymorphic Deleter for Unique Pointers `unique_ptr` doesn't type-erase its deleter since that imposes runtime overhead, which can make custom deleters pretty awkward to use. This adds a predefined generic type-erased deleter to use with `unique_ptr` and a `unique_safe_ptr` which uses it, giving the user similar syntax as with custom deleters for `shared_ptr`. Would certainly be nice to have sometimes. &gt; Range-Based For-Loops: The Next Generation (Revision 1) Just minor tweaks and some responses to questions. Mostly just pointing this out since I'm happy to see STL is still pursuing it. &gt; Adding Standard Circular Shift operators for computer integers More operators to overload! oh and I guess it'd also eliminate a common source of UB too. &gt; Non-member size() and more Non-member `size()`, `front()`, `back()`, `empty()` and `data()` for uniform syntax for containers and C arrays. I use `boost::size()` for arrays regularly, but the others seem less important. &gt; Uniform Copy Initialization Makes `NonCopyableType f = {5};` not a compile error. The current behavior seems pointlessly annoying to me. &gt; Adding Standard support to avoid padding within structures Standardized `#pragma pack` with the most disgusting can't-introduce-new-keywords syntax possible. Important feature to have, but terrible solution. &gt; Adding attribute reflection to C++ Custom constexpr-based attributes. A relatively lightweight way to achieve some of the things static reflection could be used for. &gt; Static refection And a not-so-lightweight static reflection proposal. Based on some pre-existing TMP-based reflection libraries. &gt; 0 overhead principle violations in exception handling Itanium ABI Zero-cost Exception Handling isn't actually quite zero-cost; it still bloats the binary a bit and for embedded systems this can be an actual issue. Doesn't propose any solutions since it's just bringing awareness to the fact that this isn't actually an entirely solved problem.
So if that module stuff gets implemented correctly could we get rid of those .h forever? I mean writing everything in a .cpp file where we define its public classes, templates, etc? Also it should help tools to offer better autocompletion and other nice, useful features.
&gt; Removing trigraphs??! &gt; &gt; Pretty self-explanatory. Even if it's a pretty minor bit of cruft, it'd be nice to actually remove some cruft from the language. A paper on this subject which doesn't analyze why the previous tentative didn't succeed (trigraphs were removed then added back during C++11 standardization) and show how the proposal solves the underlying issues have no chance. At best it will relaunch an effort from people more aware of the background.
What I don't understand is how library authors/users would even make use of this. If std:: -&gt; std::abi *may* involve a conversion, how could anyone write portable code that actually avoided a conversion without per-platform #ifdefs? int count_words(const std::abi::string&amp; str); The user of the library can't avoid a copy on platforms where conversion is unnecessary since that could wouldn't compile on platforms where it would be necessary.
Streaming -- very unlikely. Recording -- hopefully.
I'll be going. Can't wait!
How long did you take to design and implement everything you mention in the article?
There are some examples of code that just make me go, "WTF were these people thinking?" Those samples would be good examples of that. Even from a legacy perspective I'm going, "WHY???"
Horrible proposal. Industrial C libraries with all their quirks should not be mechanically wrapped into C++ standard. Standard libraries should be "mathematical" in their description. If it's anti-aliasing or font hinting style, it should be defined with text or formally, not by implementation. (hinting style is defined not even by cairo but by freetype implementation). Not to mention that this wrapper is 90s C with classes style library, not something like Boost GIL.
The initial waiting was created because I wasn't certain on what buffer sizes I needed or how often it might happen. Initially it blocked sometimes. After many improvements and buffer size tuning it basically never blocked anymore. I took care to ensure the blocking path didn't add any load on the non-blocking path. Blocking was also a momentary event. The system was generally idle, so the consumer always caught up quite quickly. There was a momentary pause in that case, but the business decision was to accept that and keep the logs.
That's very hard to say. It was continually improved over the life of the project. Each improvement was an iteration. It was really helpful to have the profiling tools available. A lot of time was also spent learning the appropriate low-level details, which means I could do it quicker next time. I'd probably take me about 4 weeks to build a new system from scratch and achieve the same level of performance and features.
Does this imply that the nomenclature that 'concepts' belongs to is not restricted to C++? I was under the impression it was only being discussed in relation to this language.
Long overdue, but great to see it again. Hope committee pushes this in, in some form soon.
Cool
These are concepts in the general sense. Stepanovs opinion is that 'concepts' are fundamental. i.e. things like Regular types exist and have properties that must be discovered, modelled and carefully composed, like how mathematics builds upon itself. Future C++ concepts are just tools to model this fundamental framework.
With the number of talks they are proposing, I would say yes, though I don't wish to be presumptious about your financial situation. Also, look into airbnb, that could save you quite a bit on the hotel costs.
You can also try AirBnB or some such think if you want a cheaper option for housing.
I think yes. Of course its more attractive if you don't have such large travel costs. Most (non-student) attendees will be send by their companies, so for students this is also a very good opportunity to maybe meet your future coworkers. So see it as an investment in your future. Also maybe you can get travel funding from your university. But I'm slightly biased as I run the Meeting C++ conference ;)
By student, do you mean a grad student doing research? Is going to cppcon going to be essential to your work? Are you trying to get something into the standard? Are you working on compilers, language design, or something similar? Would it be beneficial for you to rub shoulders with experts in the field- and be honest with yourself on that answer- I would say "no" unless at least one person there will say "oh __cplusplus! So nice to finally meet you!" The bar might seem high, but thats because $2k is a chunk of change to a student (or even a non-student, I could go on a very nice vacation for that amount), and a lot of the material will be written about in blogs, journals, etc. Unless you can answer yes to almost all of those questions, I personally don't think it makes sense to go. Most of the people there will be there on their company's dime.
Public transit in the area is excellent, you could look at hotels in Kirkland by the Totem lake transit center 10 minutes away and jump on e.g. hte 535 bus, which goes to Bellevue transit center a block away. Expedia shows hotels for &lt; $100 in Kirkland. Here's that bus schedule (doesn't run on Sundays) http://www.soundtransit.org/Schedules/ST-Express-Bus/535
http://imgur.com/a/x0RTL#0
As I understand it, at root this is a proposal to bundle up a bunch of language/platform implementation choices and a standard library implementation and give them a name. Via "extern" or a command line switch, you can instruct the compiler to use those choices and that library implementation when building your object code. So why limit this mechanism to a binary 'stable'/compiler-defined option? I put stable in scare quotes because of course it won't be: The proposal anticipates that breaking changes will happen on a something-like-OS-releases timetable. But those breaking changes will be frequently tied to visible standard evolution, which might not track particularly closely to my vendor's release schedule. Why should I have to wait for a new release of my OS if my compiler and the compiler used by the supplier of my binary dependencies are both ready to support some new feature of C++19? If instead this were a general framework for the specification and use of *arbitrary* new "extern" types (and associated implicit std::xxx namespaces), then any implementer or group of implementers could (more readily than today) specify an ABI, give it a name, and compilers/platforms could support it or not, as user demand warranted. The standards committee wouldn't have to worry about a list of breaking changes: Compilers/platforms could support multiple ABI's representing different points of evolution of the standard. I can understand the desire to have "one true ABI" for every platform (however defined), but to me the ideal world would be one in which clang and gcc don't have to agree on an ABI in order to keep Linux from bifurcating into two "platforms" in the language of this proposal. Instead, let them each support (or not, as their interests dictate) both -stdabi=clang-c++17 and -stdabi=gcc-c++19.
&gt; Types don't know # This is looking good, however there seems to be a slight mistake in the "seeding" version: template &lt;class HashAlgorithm = acme::siphash&gt; class process_seeded_hash { public: using result_type = typename HashAlgorithm::result_type; template &lt;class T&gt; result_type operator()(T const&amp; t) const noexcept { std::uint64_t seed0; std::uint64_t seed1; std::tie(seed0, seed1) = get_process_seed(); HashAlgorithm h(seed0, seed1); // ^~~ Requires that `HashAlgorithm` be constructible from two `uint64_t` using std::hash_append; hash_append(h, t); return static_cast&lt;result_type&gt;(h); } }; Since the `HashAlgorithm` is supposed to be default constructible, this is not actually viable. We can however replace it with: HashAlgorithm h; hash_append(h, seed0, seed1, t);
Such an heresy... my blood is boiling!
Nice, I've been wanting something like this for the boost datetime stuff for ages, now if only it worked on free editions grrrr....
Welp... this is something I'll gladly donate to. I've been wanting something like this for years. boost::variant debugging info is worthless by default.
What does the move constructor have to do with anything here? An arbitrary range of `double` is not legal input to `std::sort`, or a function that tries to divide by the elements in the range, or a function that demands no duplicate values, so obviously a trivial wrapper around `double` is not either even without the move constructor. If the only operations an algorithm can assume are defined for a moved-from `double_t` is assignment and destruction, then clearly the same holds for `double`, and it is impossible to write a safe function which accepts every possible double as input.
Hi, I'm Bryce - I am the student liason for CppCon (so, I am perhaps a little biased). I strongly believe that, if you are a young C++ programmer, attending a conference like CppCon is incredibly valuable. I think students benefit as much (if not more) than any other type of attendee to the conference. CppCon will have an awesome program (larger than any previous C++ conference); but the sessions are only one part of the conference. The discussions and personal connections made outside of talks are just as important as the scheduled material. When I was 18 (not so long ago; I'm still a student myself), I attended my first C++ conference; the friendships I formed there have had a major effect on my career trajectory. Interacting in-person with the C++ community is an amazing experience for anyone interested in C++, especially younger programmers who may be uncertain about what they want to pursue in the future. I don't think I'm a special case; I've had the distinct pleasure of organizing the student/volunteer program for another conference, so I'd like to think I'm quite familiar with the experiences of student attendees at C++ conferences. CppCon will be bigger than previous C++ conferences (C++Now, Meeting C++, BoostCon, etc); but it's the same community. So while the environment may be a little less intimate, I believe that CppCon has much more to offer than sessions; it's a chance to become involved in a really awesome and diverse community. As Jon Kalb would say: the sessions are the second best part of a gathering of the C++ community. If you want to know what the best part is; ask an attendee. 
Hop on github and search for games that have c++ tagged as the language. Also, xpost to /r/gamedev
Civ 4 comes to mind, but you'll need find find a VC8 SDK to use it (hard to find without an msdn subscription)
Copy-concatenate, then inplace_merge().
sry, but this is a useless comment. If you think, something should not be done, then atleast also tell us, why we should not do it .. The post in its current state has nothing to offer ...
It seems to me that all that matters is whether the destructor can be called on a moved-from value. If it isn't ever called, that solves the problem. Is that what this is suggesting?
declval is a function, so you cannot use braces like that.
To put it simply, compiler optimizations. Type erasure just makes it that much harder for the compiler to inline the lambda body. Work with the type system, not against it by using std::function's type erasure where it isn't necessary.
it may be worth asking as a comment in his new blog instead of here.
I don't know about america but $1200 seems a bit expensive for 5 nights... can't you find another option like cheaper hotel with taxi or some stuff?
Especially because both lambdas and function inlining work best with small functions that are used infrequently.
I think, this one is what you need: http://www.microsoft.com/en-us/download/details.aspx?id=6510
I haven't actually played around with it myself, but the DOOM 3 BFG source is quite nice and clean. You will need to have it installed though (the resources aren't open source): https://github.com/id-Software/DOOM-3-BFG
You can check out Unvanquished (FOSS RTS/FPS game). https://github.com/unvanquished/unvanquished Fairly large active team under heavy development.
IIRC making moves actual moves (no dtor on source, move takes its 'life'), instead of funny mutating copies, was pondered by the committee, but they deemed it too dangerous, as there would be zombies lying around in pain sight ... I think there were also other reasons, but i cant find meeting transcript right now. Probably that it would be difficult to implement could be another reason.
Order it in any book store or with any online retailer. For the Netherlands, I'd order it [here](http://www.bol.com/nl/p/programming/9200000022689409/).
If I just need _func_ to be invocable like `func(int{})` and don't care about the result type, I usually SFINAE the function out: template&lt;typename Func&gt; auto run_within_for_each(Func&amp;&amp; func) -&gt;decltype(func(int{}) , void{}); Does anyone know of a better approach that gives a better error message? (clang says something like function not found, candidate function was SFINAEd out). Boost.TypeTraits has `is_function` and `function_traits` but not a `is_callable_with&lt;Function, Args...&gt;::value`.
Tough problem to solve, for sure.
I'm sorry, but I don't really get the problem. No one forces you to put all the code into headers. No one forces you to do the macro magic all the time. No one stops you writing lean headers and if you have a reason to put the code into the header, you can do that too.
still not beautiful, but for such a rare written operation pretty enough. tnx :)
What have you tried? What, if any, error messages do you get? /r/learnprogramming might be better for this.
no one got any advice?
Several calls to copy are missing the namespace specifier. Also, the copy in the operator= code in 18.3.2 should be changed to this: std::copy(a.elem,a.elem+a.sz,p); // copy elements The original code (assuming the std:: was added) would copy the elements of *a* over the elements at *elem*, then immediately delete *elem*. The allocation *elem* may also be too small for this.
Why is he using for(auto&amp;&amp; ...) in his find-maximum example, and not for(const auto&amp; ...)? Especially when he's promoting littering your code with const?
I think for most projects, exchanging runtime speed for build time has things backwards.
Followup: We've had great success with room/ride sharing for other C++ conferences; for C++Now, for example, all the volunteers are partnered with a conference attendee who has a spare room in a hotel suite. We've already had a number of inquires about room sharing, so we have created a Google Group for people to coordinate: room-ride-share@cppcon.org https://groups.google.com/a/cppcon.org/d/forum/room-ride-share We just put it up, so it's quite empty right now; but I'd encourage you to stick a post on there. 
We intend on recording the sessions. We have no plans at this time to livestream the first year of the conference (e.g. this year). Source: CppCon planning committee
Almost all sessions are recoreded. Videos will be posted 2/3 weeks after the conference.
http://www.reddit.com/r/cpp/comments/26my6n/keynote_the_last_thing_d_needs_scott_meyers/ Im sorry i dowvoted before i saw the "summary" it ofc isn't a repost
It seems to me that Stroustrup should retire. He's spreading a lot of bullshit lately.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Argument-dependent name lookup**](https://en.wikipedia.org/wiki/Argument-dependent%20name%20lookup): [](#sfw) --- &gt; &gt;In the [C++](https://en.wikipedia.org/wiki/C%2B%2B) [programming language](https://en.wikipedia.org/wiki/Programming_language), __argument-dependent lookup__ (__ADL__), or __argument-dependent name lookup__, applies to the [lookup](https://en.wikipedia.org/wiki/Name_lookup) of an unqualified [function](https://en.wikipedia.org/wiki/Function_(computer_science\)) name depending on the [types](https://en.wikipedia.org/wiki/Data_type) of the [arguments](https://en.wikipedia.org/wiki/Argument_(computer_science\)) given to the [function call](https://en.wikipedia.org/wiki/Function_call). This behavior is also known as __Koenig lookup__, as it is often attributed to [Andrew Koenig](https://en.wikipedia.org/wiki/Andrew_Koenig_(programmer\)), though he is not its inventor. &gt;ADL occurs only if the normal lookup of an unqualified name fails to find a matching [class member function](https://en.wikipedia.org/wiki/Class_member_function). In this case, other [namespaces](https://en.wikipedia.org/wiki/Namespace_(programming\)) not considered during normal lookup may be searched where the set of namespaces to be searched depends on the types of the function arguments. Specifically, the set of [declarations](https://en.wikipedia.org/wiki/Declaration_(computer_science\)) discovered during the ADL lookup process, and considered for resolution of the function name, is the union of the declarations found by normal lookup with the declarations found by looking in the set of namespaces associated with the types of the function arguments. &gt; --- ^Interesting: [^Andrew ^Koenig ^\(programmer)](https://en.wikipedia.org/wiki/Andrew_Koenig_\(programmer\)) ^| [^Typename](https://en.wikipedia.org/wiki/Typename) ^| [^Outline ^of ^C++](https://en.wikipedia.org/wiki/Outline_of_C%2B%2B) ^| [^Barton–Nackman ^trick](https://en.wikipedia.org/wiki/Barton%E2%80%93Nackman_trick) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+chwwwkt) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+chwwwkt)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Nope. I'm working on it. I hope to have them all up by the end of June.
Not really an issue for the vast majority of movable types which will simply pass some kind of handle around. 
How did you solve the issue of recognizing which pointers are members of objects? 
Have you thought about using bit maps? having two bitmaps, one for objects and one for ptrs, where each set bit represents an object at the specified address. 
I just checked if the pointer was within the range [addr, addr+size) of an object. This requires that all gc_ptr be reachable from a gc_ptred object, but worked reasonably well.
It was a toy, proof of concept implementation. There were certainly optimization opportunities, but nothing that would help the big inefficiencies I think. I still need to be able to iterate over the gc_ptrs reachable from a given object. Not sure if bitmaps would help me. Or do you mean give up M+S entirely and do something else? When I tried this I wasn't familiar with other techniques, and while I have a copy of the GC book, I haven't read the whole thing, so if this is an algorithm I'm unfamiliar with, no, I didn't try it.
How did you do that? if your program had thousands of gc pointers, you certainly didn't check all of them against all the gc'd objects. How did you find the best subset of pointers to check against the range [addr, addr + size)? 
No, I am talking M+S, but using bitmaps in the background instead of linked lists.
&gt; An unsafe operation is a fragment of a safe operation, it must be combined with other operations to restore the object to a fully formed state. Move is unsafe, but sort is not. In my mind, if you keep these two sentences in mind as you write your code, you'll be just fine.
Seems to necessitate a "move destructor"... Not to mention, you now suddenly have named references to memory-that-once-contained-an-object. Previously, such conditions would've implied a malformed program -- how do you now rationalize that situation? The whole idea seems unworkable to me...
In that case, the answer is a straightforward 'no I did not think of/try that'.
Do you know where?
Heh. &lt;html&gt;&lt;body&gt;&lt;center&gt;&lt;h1&gt;Hello Wotld!&lt;/h1&gt;&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;
Yeah, it took me until the fourth instance of reading "Hello Wotld" to actually notice it.
@skazka16 : Very interesting articles overall, but could you please share - if these types of writings help with finding some good leads (freelancing/contracting, consulting, jobs) for you?
Interesting. But it is my understanding that t.someAction(0) is not restrictive enough: you wont get a concept assertion for, for example, someAction(char*). Instead, you might consider t.someAction(1).
Are hazard pointers still patented?
Awesome! Thanks for the link. I didn't know Lang.NEXT 2014 had happened. There goes a lot of my upcoming free time. The videos are sure to be interesting.
Here are some more details why to prefer `auto&amp;&amp;` over `auto const&amp;`: [`n3853`](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3853.htm). Edit: there is another link on the same topic: [`n3994`](https://isocpp.org/files/papers/n3994.txt). And comments of the author on [reddit thread](http://www.reddit.com/r/cpp/comments/1vxgeo).
It says that the implementation matches the "Filesystem V3 Technical Specification (TS)" - where can I find the contents of this TS? EDIT: Is [this](https://github.com/cplusplus/filesystem-ts/blob/master/n3803.pdf?raw=true) the right version?
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3940.html is the most recent draft.
I'm not looking for anything like that. 
Yes.
Scumbag Visual Studio 2013: Costs huge amount of money. Doesn't support default move constructor generation.
sorry but we can't be asked to change IDE every year. Just update the damn compiler. 
User defined literals is my favorite feature that still isn’t in Visual Studio. Guess I’ll keep twiddling my thumbs.
UDLs (both compiler and library) are supported in Dev14 CTP1 with the exception of imaginary floats (which will be supported in RTM for sure, I have local changes to enable `operator""if`).
Very nice! I’ve got a long-term project I’m starting. I suppose as long as I’m standards compliant, I should be fine using stuff like that willy nilly (and unit testing and dealing with bugs as they come, and all that).
&gt; Cool, huh? no, not cool. because they probably expect $$$ for it.
God damn you, I wanted to sleep an hour ago then I saw this post. Now, in I'm even more tired and I still haven't slept... Seriously though, thanks for the link. Excellent panel!
As much as I hate Visual Studio, you can't blame Microsoft wholly for this. They're making a product people buy. If people didn't buy the product they'd be forced to pick up their game. I.e. blame the people who are complicit. That said, the longer this gap between the other compilers and MSVC++ goes on, the more and more laughable and pathetic it becomes.
Why would you not update the IDE as well? 
Wait — why is this numbered “14”? Shouldn't it be 13, since the last major release of Visual Studio was version 12? In other words: * Visual Studio 2005: 8.0 * Visual Studio 2008: 9.0 * Visual Studio 2010: 10.0 * Visual Studio 2012: 11.0 * Visual Studio 2013: 12.0 * Visual Studio 201x: **13.0** Did someone decide to skip over version 13.0 in order to make the version number match the marketing name (Visual Studio 2014: 14.0)? Or perhaps because of a silly superstitious fear of the number 13?
I was not asking about your intention (maybe partly). But from your answer I assume no one contacted you so far. Thanks anyway.
previously, such an update was called a "Service Pack".
&gt; Or perhaps because of a silly superstitious fear of the number 13? Probably. Office skipped version 13 too (2007 was 12, 2010 was 14).
&gt; The __restrict keyword is now supported on reference types in addition to pointer types. This is awesome!
I am very curious what was done with the STL et al to reduce obj size so much. 
Um... you're welcome! ;-)
You break the ToS. What happens after that is up to Microsoft.
Superstition. They usually skip version 13, as many companies do. Office did as well. This is confirmed.
And exactly whats wrong with selling software?
It means you need some sort of NULL handle or flag value for the source of the move. No problem for pointers, but not all handle types are nullable, and not everyone wants the extra bool in their class. Of course, no one necessarily HAS to support move. It's been pointed out elsewhere that move violates some stricter RAII concepts. Instead of the frowned-upon uglyness of two-stage initialization (where you let the user monkey around with various set() methods before calling some sort of initialize() to bring the object to life), you now have to deal with the possibility of two-stage destruction: Moved out, then deleted. All in all, though, I'm just happy to be able to relax and have vectors of unique_ptr.
Service Packs are production ready CTP's aren't.
I haven't yet (as I am just starting to experiment in C++11), but I have always despised using STL algorithms because I end up having to declare and define functor classes, where the intent of the class is documented so far from the use of that class. And so much boiler plate for so simple a task, just to do things like "count the elements inside a map of vectors." Resulting in it being in all ways better to just write the loop out by hand. So while lambdas may not be earth-shattering for most, I really appreciate it.
ah ok
That is mind boggling, how does Microsoft justify that policy?
The last release of VS was in 2013. VS14 will be released in 2015, a major update. What product lines regularly release service packs 2 years down the line with major substantial new features?
Saying it's not for production code mainly just documents explicitly that we don't support this early build for production use, and if you do that anyway you're on your own. The CTP is a P (Preview) -- as Soma's blog put it, it's a "very early build, [so] please install in a test environment with no earlier versions of Visual Studio installed." It's to let you try it if you want and get a view of what's coming and a chance to play with an early drop. It is not at the level of quality and testedness we'd set for a full release; for example, for a full release we'd normally support installing it side by side with previous versions, but you shouldn't do that with this one yet.
And? The compiler is free. So you're taking issue with the fact that the compiler is called "VC14" and not "VC12 SP1"?
Oh, ok. My impression from /u/leadzor was that Microsoft would somehow punish a person/company who used it in production code. Thank you for clarifying.
no, i am taking issue with the fact that i pay good money for an unfinished product (vs2013) and then they expect me to pay again for an improved (not finished) product a year or two later. The compiler may be free, but can i use it with the product i own already (vs2013)? No.
I'm sure they have guidelines on what to do if you break the policy, and those guidelines are settled down and written. I didn't mean to say they can just do whatever. What I mean is that I guess that if you break the ToS by releasind production, comercial software, and somehow Microsoft finds out, she has the power to decide if either they'll sue you, or just politely ask to take the product down without any further consequences. But IMO, I don't see them going after some corner software firm around the block. I guess they really only care if, for example, someone like Adobe developed something commercial using their new suite.
It was a combination of compiler fixes and STL code changes. On the compiler side, it was taught to not emit unnecessary code for various things (that would be dropped by the linker anyways). Then we changed the STL in minor ways to avoid doing things that would cause the compiler to emit code. For example, `const piecewise_construct_t piecewise_construct = piecewise_construct_t();` emits code (the initializer is required by an obscure rule), while `const piecewise_construct_t piecewise_construct{};` does not. We will try to pay attention to object size in the future, so that we don't accidentally introduce bloat again. I was surprised that it was so bad in 2013 because I hadn't looked at it before (unlike compiler memory consumption, say).
Amusingly, the compiler version (larger than the IDE version because the compiler predates *Visual* C++) went through version 13 in the 2002 release; 2003 was compiler version 13.1. Note that Dev12's compiler version was 18 while Dev14's is 19, incrementing normally. This is the version that really matters since it's reported by _MSC_VER (1900 for Dev14). 
I have been thinking about picking up the 2nd edition of Programming having waited until its release rather than pick up the 1st edition however I have read a number of reviews saying that there are a number of errors and problems with the recommended header file to use (the std_lib_facilities.h from Bjarne's site being out-dated). Is this true? Quite disappointing if it is :(
I thought exactly this when I saw the news. A major new version every two years considering it is quite expensive makes keeping up to date much harder. Especially when the competition for a lot of people is free (Xcode, g++, clang, etc)
Out of curiosity, what is the timeline for the VS14 full release. I couldn't find information about that.
Bjarne's updated site is [here](http://www.stroustrup.com/programming.html). InformIT, being the careless idiots they are, did not bother to use the correct link. 2012: http://www.stroustrup.com/Programming/ 2014: http://www.stroustrup.com/programming.html
Yeah but the 2014 link still points to the old std_lib_facilities.h from 2010 :/
Where'd you find those reviews for the book?
I found a couple while searching, the only one I can remember directly is this one from Amazon http://www.amazon.com/review/R32EJT7KVJO08L/ref=cm_cr_rdp_perm?ie=UTF8&amp;ASIN=0321992784
Thank you very much for your input. I had actually already read that thread and glimpsed over the proposal. In the proposal and thread, it is mainly described why you would prefer *auto&amp;&amp;* over *const auto&amp;* as the *default*, and I can clearly see that. It's a very interesting read and I am able to understand quite a lot of it, however, not all. So what I can not understand why you would prefer *auto&amp;&amp;* in cases were you loop over a non-const range and you do not modify the elements. Shouldn't *const auto&amp;* be better/faster/more correct in that case? E.g. in the example in the talk, or if you do something like just vector&lt;string&gt; vec{"a", "b"}; for (const auto&amp; e : vec) cout &lt;&lt; e &lt;&lt; endl; Why would you prefer *auto&amp;&amp;* in that case?
Company culture tends to change overtime as collaborators come and go. Maybe they got slightly more superstitious in the later years. IIRC, Adobe also skipped the version 13.0 on some of their products, like Photoshop.
That's not a lightweight C++ HTTP server. This is a lightweight C++ HTTP server: http://blog.dlib.net/2007/03/adding-web-interface-to-c-application.html :)
In this instance it'd actually be cleaner to write a RAII wrapper than to use unique_ptr. 
Even if Adobe released something using the CTP I can't imagine MS would care unless they didn't go on to buy licenses for the final release.
[Our Corp VP said](http://blogs.msdn.com/b/somasegar/archive/2014/05/28/first-preview-of-visual-studio-quot-14-quot-available-now.aspx): "Visual Studio "14" will most likely be available sometime in 2015, with a more complete preview release and final naming available later this year."
Doh! How did I miss that? Thanks Stephan. 
Yeah, trying to grok how this is called a template library. Yes, it has templates, but... Still, looks like a lot of hard work you can take advantage of pretty easily.
It states in the license agreement that the user understands that this version of the product is to be installed in a test environment and not to be used for production code. Now if you're just some ordinary dude, I don't think anyone will care if you use a CTP for your own ordinary programming, but heck I doubt anyone will care if you download Visual Studio from The Pirate Bay. In either case, no one is going to come knocking on your door or anything. But it does mean that a CTP can not be used by a corporation that needs to adhere to legal policies about what software can and can't be used. So basically if a corporation uses a CTP to ship a product, it's breaking the terms under which it agreed to license Microsoft products and that could be a liability issue, not to mention that a company would have to be pretty freaking stupid to release software to its customers using a CTP.
Yes, it certainly is not affordable for most people. Thankfully, we're not obliged to purchase it.
Note to all : Visual Studio Ultimate is literally over $10000 per seat.
&gt; ... why you would prefer auto&amp;&amp; in cases were you loop over a non-const range and you do not modify the elements ... So you want to view `const` element when iterating over non-`const` collection? Hmm... Seems weird to me. You should use something like `for(e : make_const(vec)){...}` as suggested by STL [here](http://www.reddit.com/r/cpp/comments/1vxgeo/cewpnv1).
If you're interested, I've created for fun a small tracing precise garbage collector for c++11 [here](https://github.com/axilmar/cppgc).
anyone got linksto the past video recordings?
This is the first year of CppCon so no past recordings to watch :) Guess you could say that Going Native is the precursor, if you haven't checked them out already I do recommend them: http://channel9.msdn.com/Events/GoingNative/2013
If you're using glibc, you can use the `backtrace()` function directly. Here's an example: http://stackoverflow.com/questions/77005/how-to-generate-a-stacktrace-when-my-gcc-c-app-crashes .
I'd love it if someone could explain just what in the hell is going on there.
For the curious, there's also a *normal* way to do it, as shown here: http://codegolf.stackexchange.com/a/30059
I do this kind of thing as a hobby (well, not so much lately, but I did for a while) so I'm always interested. (Sadly I can't seem to find the source my old C++0x GC, hence me not posting about it). Anyway, cppgc looks nice for a start, but needs some work. I'm not a huge fan of the API and you didn't test enough. Here's some test code with three functions, each of which trigger a segfault (the tests start at line 356, the code above it is your library, obviously) https://ideone.com/r0xxOs. I started with the last one, and worked backwards until I decided that you didn't test enough. Anyway, as I said, IMO, the API needs some work. Here's some unsolicited advice: - Forcing everybody to subclass gc_object is very bad. It's made worse by the fact that gc_object has a virtual dtor. You should do everything with gc_ptr, even if this is slower or uses more memory. - You can't make gc_ptr's inside methods of subclasses of gc_object, due to the gc_member_ptr thing and gc_member_ptr's ctor not being public. Not sure if this is intentional (for some reason). - There should be a way to allocate an object, triggering a garbage collection only if needed. Forcing users to manually call a function to collect garbage is downright unsafe. In the example code above I have a make_collected&lt;T&gt; that does this and avoids leaking if the constructor throws, which you can use if you want. A better version would keep track of the currently allocated bytes in the garbage collector and collect if we hit OOM or if we go above a user specified threshold. Feel free to PM me if you decide to take any of my advice, fix any bugs, etc.
And blink is replacing GYP with GN (Generate Ninja). Just what we needed, another metabuild system. :)
As the sole comment on the snippet said, wizardry. Just some good old fashioned twisting language constructs into something most mere mortals can barely comprehend. In other words, just C++ as usual. ;D
You have offended my honor, sir!
C89, even.
Thank you Sir :)
Wow... Just... Wow
I've been doing this kind of thing as a hobby as well, for a lot of years now. Thank you for looking at my library, which is obviously a toy library and not intended for real use. &gt; Forcing everybody to subclass gc_object is very bad Agreed. &gt; It's made worse by the fact that gc_object has a virtual dtor Agreed. The library doesn't follow the c++ principle "don't pay for what you don't use", obviously. &gt; You should do everything with gc_ptr, even if this is slower or uses more memory. That's kind of impossible though. It's only the operator new that can knows the exact size of an object that is allocated. &gt; You can't make gc_ptr's inside methods of subclasses of gc_object, due to the gc_member_ptr thing and gc_member_ptr's ctor not being public. Not sure if this is intentional (for some reason). Yes you can. The classes gc_member_ptr and gc_root_ptr are public classes, and so are their type aliases. &gt; There should be a way to allocate an object, triggering a garbage collection only if needed. Forcing users to manually call a function to collect garbage is downright unsafe. In the example code above I have a make_collected&lt;T&gt; that does this and avoids leaking if the constructor throws, which you can use if you want. A better version would keep track of the currently allocated bytes in the garbage collector and collect if we hit OOM or if we go above a user specified threshold. Yes and yes! absolutely yes!!! ... My toy collector is not very useful as it stands, but it's the simplest possible approach. But doing a real-world useful gc_ptr is just downright impossible. Edit: my collector is not actually useful for another reason, it's completely thread unsafe. If you find a way to do a thread safe collector without stopping the world at every pointer assignment and without using operating-system specific tricks (like making pages read only and catching page-write exceptions) let me know. In a multithreaded version of my bitmapped collector, I had one mutex per page frame. The collector had to lock 1024 mutexes (for the 32-bit memory space) before entering the collection phase. 
Appears to be identical to the first edition.
From the actual codegolf question's recommendations: &gt; Using defined variables like `__LINE__`, although allowed by the rules, are discouraged
lol, I think it might end up going full-circle and people will start using SCons to generate Ninja files.
This uses \__LINE__ EDIT: I guess it doesn't. I also thought this was serious.... :(
Huh? What do you mean?
For anybody who's curious how the macro expansion works, here's how. First, let's format it so that each part is easier to see: _(EXTRACT, _(Q,_,E,_,$$main$$,), _(@22,,_,_), _(Z,N,L,I,_,,L), __STACK_TRACE__) And now let's rename the two defines so that it's a bit easier still: #define CONCAT_BCA(A,B,C,...) B##C##A #define SHUFFLE(A,...) CONCAT_BCA(__VA_ARGS__, A) SHUFFLE(EXTRACT, SHUFFLE(Q,_,E,_,$$main$$,), SHUFFLE(@22,,_,_), SHUFFLE(Z,N,L,I,_,,L), __STACK_TRACE__) Now let's expand the SHUFFLE macro. It moves the last argument to the end, and then passes the resulting argument list to CONCAT_BCA: CONCAT_BCA( CONCAT_BCA(_,E,_,$$main$$,Q), CONCAT_BCA(,_,_,@22), CONCAT_BCA(N,L,I,_,,L,Z), __STACK_TRACE__, EXTRACT,) Now CONCAT_BCA only uses the first 3 arguments. Any other arguments are ignored, so let's just discard those: CONCAT_BCA( CONCAT_BCA(_,E,_), CONCAT_BCA(,_,_), CONCAT_BCA(N,L,I)) This becomes: CONCAT_BCA( E##_##_, ##_##_, L##I##N) Which becomes: CONCAT_BCA( E__, __, LIN) Which becomes: __##LIN##E__ Which is, of course: __LINE__
I was just about to sit down and edit my response to show the macro expansion. Thanks for saving me the effort! I think you explained it more clearly than I would have.
Yep. Mail me at work if you want confirmation. Also, see my [lengthy explanation on Reddit for why the STL is ugly](http://www.reddit.com/r/cpp/comments/20gzfb/the_exceptional_beauty_of_doom_3s_source_code/cg3fh48). I like to think that my presentations communicate useful information and therefore aren't boring, and I think I succeeded with rand last year.
It is good that people who like writing cleverly obscure code can use social exercises like this as their creative outlet, rather than exercising their talents in production code ;) The only thing that worries me is some junior engineer seeing stuff like this and using it, *not* *realizing* that there is a clear and clean way to achieve the goal. Teachable moments, sometimes requiring liberal application of a clue-by-four. 
Thanks for these detailed posts. It's great to be able to point people towards information coming straight from the horse's mouth, so to speak.
re "highly-aligned memory": Can VS2012 already take advantage of that optimization?
I for one am certainly glad you guys fixed the weather, though it has been getting a bit hot lately...
Thank you for these improvements, STL. You mentioned being able to request new intrinsics. Out of curiosity, could we add a __readcarryflag intrinsic? I reported a bug log ago which was closed as will not fix for a good reason. http://connect.microsoft.com/VisualStudio/feedback/details/691456/-readeflags-intrinsic-can-be-reordered-by-the-compiler I appreciate it and understand it. But the unfortunate result is that I have been stuck with assembly which breaks some optimization. __readeflags() makes the intent unclear. You don't know if the user means to read the zero flag, the carry flag, ... And as a result, it is difficult to reorder instructions and optimize around __readeflags(). My bug pertains to this. It was changing an integer + operator to not set the carry flag. And as a result, __readeflags() could safely be reordered (even past barriers!). If we had a __readcarryflag() then the compiler would know I intend to use the carry flag, and not to optimize away any instructions that would have effected the carry flag. Plus, the resulting asm is more simple. It might be asking a lot. I accept the issue was closed and do not expect anything. But I figured, if you're already capable of requesting new intrinsics, I would greatly appreciate intrinsics which break the eflags register into its separate pieces. Thanks again for everything! Especially DevDiv#755427/Connect#796566 :D :D
LOL, you couldn't resist mentioning the Frozen#2013 fix, could ya? 
&gt;That's kind of impossible though. It's only the operator new that can knows the exact size of an object that is allocated. I'm pretty sure I just overloaded the global operator new in mine to do what I needed. Still not pay for what you use, but the cost was less. &gt; But doing a real-world useful gc_ptr is just downright impossible. I'm not totally convinced of this, but it's certainly a hard problem. I think it would have to be reference counted with cycle detection to be really useful in c++ because you still want deterministic destruction where you can get it. &gt; my collector is not actually useful for another reason, it's completely thread unsafe. I was actually going to comment about the thread safety, but figured I had said enough. &gt; If you find a way to do a thread safe collector without stopping the world at every pointer assignment... Why would you need to do this? You only need a write barrier for incremental collectors (not to mention some write barriers are lock free, though i think that requires careful heap layout which would be impossible in c++). 
In a game you are literally defining the rules of engagement yourself, so it's much more likely you can use all the usual tricks (preallocate contiguous memory) as you are going to know the maxes, mins and other extremes upfront (or you can hope to deduce them via experimentation). I used to do hft and while we tried to understand and preallocate as much as possible there are some rules of engagement, so to speak, where allocation and deallocation really were the most common operation. I guess my point is that we were trying to model something external to our control, so it becomes much more likely that you're going to encounter scenarios where managing dynamic memory is necessay. 
&gt; I'm not sure how much stock I put into the opinion of a guy who's programming language is needlessly complex by default. I mean... this is the C++ subreddit...
Note that you actually want to use the "utf8mb4" encoding with mysql (the "utf8" encoding only supports characters of up to three bytes because mysql is wonderful like that).
I'd probably have gone with wrapping JSoup in a small Thrift service. Alternatively you could have tried something crazy like carving out the [Firefox parser](https://mxr.mozilla.org/mozilla-central/source/parser/html/), it looks pretty self contained. The WebKit (and therefore KHTML and Blink) parsers look a bit more ingrained... but you're actually spoiled for choice.
There's a difference between questioning a design decision and saying that you don't value the opinion of the creator of the language.
I saw a great presentation at GDC 2014 about game optimization. One of the things that was presented was that 90% of the time spent running a program is reading and writing memory. The other 10% is the time to do the calculation. Using data structures with contiguous memory helps reduce cache misses and that has the biggest impact on reducing the 90% of the program time. 
Is there anywhere I can read more about these tricks or the experimentation involved? Sounds quite interesting.
Are you able to elaborate how the performance is measured / how you monitor the l1/2 cache?
Isn't that the same as using an std::list and keeping an iterator to reference the item?
I've said it before - this is why I love boost flat_map / flat_set. One particularly pathological case sped up by a factor of hundreds. 
No. An intrusive list is the same as having a `T *next, *prev;` on the object, but encapsulated.
`std::list` could be fairly trivially implemented on top of an intrusively-linked list template class so there are use-cases where they're identical, but an intrusively-linked list is much more flexible. The primary functional difference is that `std::list` has to be able to create the elements in the list (so that it can add the previous/next pointers), while an intrusive list doesn't. This means that an intrusive list can be polymorphic without requiring a second memory allocation per item, and do clever things like have stack-allocated or global objects in a list. For a simple monomorphic list with each item allocated separately on the heap, the only functional benefit of an intrusive list over `std::list` is that `std::list` doesn't let you opt-out of O(1) size(), which is occasionally significant.
2012 added autovectorization, but I don't know if it emitted the AVX instructions that especially benefit here. I would have to ask a back-end dev. (P.S. If you can, please upgrade to 2013.)
I am so obsessed with Frozen. My Lync status (IM client) at work is: "Do you want to build a program? It doesn't have to be a program."
Glad you like the Facet Allocation Mismatch fix - that was easily one of the top 5 most difficult fixes I've made. While I have the ability to request FE/BE work at a higher priority for the STL, I can't really do that on behalf of other issues. When a bug appears to have been incorrectly resolved or accidentally dropped on the floor I can definitely ask another team to take a second look, but otherwise I don't have magic powers. Sorry!
deque is usually implemented as two vectors or range within a vector, so the same general concepts apply. deque is a great container!
I've actually trained myself to become attuned to it, so that deviations from our _Ugly/etc. conventions jump out at me. Any lowercase `idx` or call to `tie()` without our `_STD tie()` macro (expanding to `::std::tie()`) is a bug, and my job is to serve as the last line of defense against such bugs. I try to rigorously enforce the other style conventions (even when they are contrary to my personal tastes, like for braces) since when everything is uniform I can spot inconsistencies more easily. I hop to user-style code when working on repros or test cases, which is easy to do (I just relax my hyper-vigilance and drop the _Ugliness).
Depends on what platform you're using. For Linux/x86 you have Cachegrind which provides metrics. On Windows, Visual Studio comes with a profiler that provides such metrics, or you can use Intel's VTune.
Fantastic. Thank you.
&gt; you are bad, you should feel bad Hey STL, I know you frequent reddit where such comments are common, but please don't use phrases like that in your blog. Even though you're desensitized, that phrase is offensive.
C11 removed it first. C++ is just following suit.
Well, I think your weakness is all pages which don't give you the correct content until JS has run. I've chosen to use QWebkit for this job, fairly slow though: http://meetingcpp.com/index.php/br/items/analyzing-websites-with-qwebkit.html
You mean libraries need to be included before use? Oh the horror!
I can't think of one uniform place, but generally when writing high performance code the considerations are (these are off the top of my head): 1) Preallocate as much as possible. 2) Avoid copying things (greater than the size of a register) 3) Avoid system calls in your critical path. 4) Avoid locking at all costs. 5) Keep memory as contiguous as possible. 6) Avoid dynamic dispatch 7) precalcuate as much as possible ahead of time 8) do all of this while not compromising on your algorithms design. 
When I was doing web-scraping I found Arabica by jez higgins at https://github.com/jezhiggins/arabica very helpful. I used Taggle which converts html to xml very nicely
Well, the case where lists outperform vectors is one where you are inserting/deleting elements in the front (and the list is big or the elements are big). A vector can nearly always do better with end insertion and will always be better at end deletion. It is at that point where you would have to ask "why am I messing with the front here?"
btree gives you no locality.
A btree's representation is identical to a flat_* until it grows over a certain size.
Go away, Stephan.
Shameless plug: http://www.metaxcompile.com/rikitiki/ Feel free to use/steal/learn from whatever you want on this. If you have questions please ask! I'm releasing a make update soon to support Iis and cef as servers too. It uses a lot of c++11 stuff, mainly variadics and auto. The new update uses some of the futures and lambda stuff. Probably the biggest thing done here that you couldn't do without the new standard is the routing functionality -- where it pulls variables out of a template string and applies then to your handler function for you. 
Do you find yourself ever using hardware performance counters like PAPI? I do HPC research, and I tend to go to PAPI before anything you listed. Although, I've just started using Vtune, and it's pretty amazing.
&gt; GDC 2014 [Code Clinic: How to Write Code the Compiler can Actually Optimize](https://raw.githubusercontent.com/macton/presentation-archive/master/gdc14_code_clinic.pptx) by Mike Acton
Okay, bye. :-&lt;
Yes. Also, 32-bit time_t is an abomination.
Offensive jokes have no place in official corporate blogs.
I don't think it's offensive ("bad" is a weak negative adjective and does not refer to any particular things) and all VCBlog posts are reviewed before publication. We live in a world where messing up code, like saying "goto fail;" in the wrong place, can wreak amazing amounts of damage. Some practices are simply bad and programmers should be clearly aware of this fact. 
I don't think it's possible to communicate with someone that considers that joke offensive without offending them, so there's really no point in even trying.
&gt; two vectors. Huh, I always imagined it as a sort of vector that loops around its currently-allocated contiguous memory space, storing pointers to begin() and end().
That's what I meant by "range within a vector" -- though honestly I am uncertain which approach is used by which implementation. 
`flat_map` is significantly simpler and in its best-case scenario (pre-sorted data that will never have any insertions or removals) it's strictly better than a btree, and that best case scenario does actually happen. Defaulting to using a btree certainly wouldn't be a terribly idea, but it's not universally better.
Have you tried reserving the space needed ahead of time?
No. Reserving the space will improve the performance. However, the item count in my that program can range in hundreds of thousands to millions, it's hard to reserve the space without wasting a lot of memory. Now when I expect there are a lot of items (such as more than 10K) in a container, I always use deque. 
Wouldn't it be cleaner to have a separate script `/usr/bin/rtcc` that calls `/usr/bin/tcc -run`? I think this is how `rdmd` calls the `dmd` D compiler.
I understand how a list can have worse performance given these constraints, but both Bjarne and Sutter also say that std::map&lt;&gt; performs worse than std::vector&lt;&gt; for this scenario as well. To test this I wrote a small app that I believe does the same as they suggested: https://ideone.com/oP0ckk and it shows that __vector is an order of magnitude slower than tree-based structures__ for inserts (I tested with std::set but it should be the same.) Note: - I didn't include erase, but that should show the same perf characteristics - I didn't try any tricky loop-unravelling for my vector iteration, but I believe that the iteration isnt affecting performance much anyway - I limited the loop to 10K items because ideone times out on larger sets, but increasing the size doesnt change the results What am I doing wrong? I must be missing something... edit: interestingly a deque performs even _worse_ than vector, though I'd have thought that the slow insert times would be somehow mitigated by the deque's bucketing mechanism (see https://ideone.com/hZeKYy )
Just use CINT, http://root.cern.ch/drupal/content/cint
Do you know there is already a tool for this based on LLVM and Clang called Cling. http://root.cern.ch/drupal/content/cling And there is even a C++ REPL (Script) plugins for Maxon Cinema 4D made by me based on Cling :) https://bitbucket.org/remotion/c4d/downloads
This should help - http://en.wikipedia.org/wiki/Comma_operator
There's also [Runtime C++](http://runtimecompiledcplusplus.blogspot.com/)
It seems to me that insert for very small vectors should be faster than map... Perhaps their statements in regards to map are limited to only this case? How many items are in your map and vector? If my presumption is correct id be curious to know at what point it's no longer true...
The iteration does matter. If you [change the vector insert to use a binary search](https://ideone.com/XGhIml) it runs in one fifth the time of the linear search. It's still 5x slower than the set though.
Here's the explication of the answer (20). I just copypasted it from cppquiz.org The comma operator is applied on two expressions: a and b. According to §5.18¶10 in the standard: "A pair of expressions separated by a comma is evaluated left-to-right; the left expression is a discarded-value expression (...) The type and value of the result are the type and value of the right operand" So first a is evaluated, yielding the value 10 which is then discarded. Then b is evaluated, yielding the value 20, which is then the resulting value of the (a, b), and assigned to x.
I cooked a C99/C++ scripting tool (in 170 lines of bash) awhile back: https://github.com/rhysu/c99sh Rather than adding a bunch of one-off headers/macros, c99sh makes it simple to use any C/C++ library with pkg-config support. There is a per-user or per-directory rcfile controlling automatically included headers, linked libraries, and compiler flags. Lots of effort to get usable error messages. No, however, caching as I didn't find recompilation of small script-like programs to be prohibitive.
It's not a C++11 feature. The comma operator has worked the same way all the way back to C. The example would work the same in C90 if you replaced `cout` with `printf`. The questions are all worded to say "according to the C++11 standard" but that doesn't mean that they are necessarily testing things that changed in C++11. 
thanks for the reply. as I understand it that would be violating the rules outlined by Herb Sutter in his talk - the point he was trying to make was that iteration is super fast because the cache takes advantage of data locality, so his (and Bjarne's) samples were apparently set up to explicitly demonstrate this fact
I suspect this may be an error originating from the GL drivers - the `count` parameter for `glDrawElements` is the *number* of indices, ie. `6`, whereas you're passing in `6 * sizeof(GLuint)`.
I thought that as well, but when I passed that parameter as 6, I still get the same problem.
Yes, I think vectors are probably the best solution. At least, I cannot think of any occasion where std::array would be better right now. If you are dealing with constant sized arrays they are both basically the same, the only difference being that with vector, you don't have to specify the size explicitly.
I should actually start taking advantage of the STL. Yeah, a lot of my practice comes from looking at "C with Classes" code (like Doom III's source). Anyways, I changed my code to this: http://pastebin.com/f9mg4vVK But now the glBufferData() functions are yelling at me for passing off the second parameter with the vectors. 'Error: no suitable conversion function from "std::vector&lt;float, std::allocator&lt;float&gt;&gt;" to const GLvoid *' exists. What's up with that? EDIT: Now that I think about it, I don't think I even defined those vectors right. Gee, I should really learn how the standard library works.
 glBufferData(GL_ARRAY_BUFFER, player_vertices.size(), static_cast&lt;const GLvoid *&gt;(&amp;player_vertices[0]), GL_STATIC_DRAW); // or, with c++11 // glBufferData(GL_ARRAY_BUFFER, player_vertices.size(), static_cast&lt;const GLvoid *&gt;(player_vertices.data()), GL_STATIC_DRAW);