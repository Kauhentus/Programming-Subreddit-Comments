It doesn't have GUI designer. But in terms of code/refracting/features/configuration I think it's better. 
If they actually read "The Design of C++" Bjarne explains the shortcomings of C declaration syntax, what he would have like to do about it and why he's glad he didn't. Other oddities are also explained. For example, this is a pointer because reference weren't a thing at the time this was introduced, and so on.
&gt; As long as it is~~n't not~~ free software, I wont use it. I am confused. You want to use free software or you don't want to use free software? Edit: I think you want to say &gt; As long as it is not free software, I wont use it. which I totally second. 
This is a very vague description of both your assignment and what you're asking for help on. Have you tried starting from the examples you got from your lectures, recognizing what does what in them, and seeing if you could reuse that to do what you want?
Do you have an introductory C++ text that you're using with this class? If not, get one; e.g., "Programming: Principles and Practice Using C++". You should start there and then post specific questions to /r/cpp_questions.
Any thoughts on some of the papers? I'm interested in discussion on the following papers: * [Noop Constructors and Destructors](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4393.pdf) * [Simple Contracts for C++](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4415.pdf) * [Source-Code Information Capture](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4417.pdf) * [Parameter Stringization](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4418.pdf) * [Type Property Queries (rev 4)](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4428.pdf) and other type reflection proposals (N4447, N4451, N4452) * [Towards improved support for games, graphics, real-time, low latency, embedded systems](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4456.pdf) * [IO device requirements for C++](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4463.pdf)
I agree, which is why I use it in all the projects I'm in charge of. :-) However in my experience a lot of businessy places (including where I work) like to use RHEL/CentOS, and they tend to have ancient compilers. I'm not sure what 7 has, but I can tell you for a fact that RHEL/CentOS 6 have GCC 4 point something by default, which doesn't even have move semantics.
Oh yeah, I'm aware of that, I was jut listing all the non-library things that are needed for my project that they would need to handle on their own anyway. Doxygen would be another (albeit optional) dependency that is often found and wouldn't be handled by biicode. So (for my purposes at least) it seems a bit silly to simply lump off half of the dependences into a dependency manager and make the users manage the other half themselves, instead of simply providing a solution that can give a complete development environment. This is the reason I think a tool like vagrant would be more useful (although I don't use it myself so I can't recommend for or against it).
In addition to what people are suggesting, /r/learnprogramming would probably have users more willing to help with your problem, although they'll still probably want you to take a first stab at it yourself.
Yes! Had a (friendly) argument with a interviewer for a large tech company about this. The question they asked was "given 2 lists of values what's the best way to find a common value between the lists" - so if we have 2 arrays A[] and B[], find indices i and j such that A[i]==B[j] I said - sort them, then go over them by size (like "merge" works) until you find the common value They said - that's O(n log n), you can do it with O(n) using hash tables (enter the values from A into a hash table / unordered set, check if the values of B exist there) Now, hash tables are random access, while sort works with continuous memory access. In sort, your memory access is almost entirely cache-hits, while hash-tables are almost entirely cache misses. The log(n) factor is at most 40 in any one computer, most likely 30 or even 20. The cache misses is a factor of several hundreds. Still took some convincing though. 
Towards improved support for games, graphics, real-time, low latency, embedded systems N4456 looks really interesting! It would be great that all this would be addressed in the next standard. &gt; -fno-exceptions, -fno-rtti or equivalents should be guranteed to be supported by the library, possibly via feature-testing support for these features. Type Property Queries (rev 4) n4428 would be great to have it right now :)
Visual Studio isn't needed to build C++ applications using MSVC. The issue with supporting MSVC in any other IDE than Visual Studio is debugging. MS uses a proprietary format for their PDB files.
You're probably looking for std::rel_ops! http://www.cplusplus.com/reference/utility/rel_ops/ It does exactly what you want, without the macro.
For reference, if you Google "VAX C++", it's the first search item ;)
They know that not all companies are willing to switch to a new IDE, which might also include completely changing their build system as well, they are basically expanding ReSharper to include C++ support
Isn't it? From biicode's website: "Premium accounts - Biicode is free and it will always be. If you want to keep your code and collaborations private, upgrade to premium." Sounds like the same pricing model as github.
For interview questions like these you should ask how large is the object being stored in the arrays. Try benchmarking an unordered_set against a sorted vector containing integers. Try it again with an object that's larger than your cache line.
6 has 4.4 and 7 has 4.8 (i.e. have fun being stuck on incomplete C++11 until 2020 if you care about rhel).
I really hope this doesn't happen. I find it super unreadable.
He means free as in freedom. 
Yea, forgot to mention the question was specifically about integers. With large objects you can always sort pointers to the objects instead of the objects themselves, but then you've still got random access memory reads (dereferencing the objects). Still - for large objects sorting (pointers) is even better than hash-tables, because sorting is O(n log n), where the constant is 2 memory reads (now random access) and one compare, while hash-tables is O(1) but with one memory read and hashing the object Comparison of large objects is typically O(1) - you usually compare large objects by going one by one over each field until you find the first that's different (usually the first one) Hashing large objects is O(size of object), as you have to go over the entire object's data for a good hash. And the hash calculations themselves are often not trivial. From my experience - for large objects `std::map` (or `std::set`) tends to actually work faster than `std::unordered_map` (`std::unordered_set`). I've tried it where the key was a vector of typical size of 100 elements - the "less than" operator would almost always just check the first element while the hash has to go over all of them - giving a factor 100 advantage to the `std::map` vs. the `std::unordered_map`
Even MinGW has issues ([MinGWx64 variant](https://youtrack.jetbrains.com/issue/CPP-668)), which sucks because I have a bunch of red text from C++11 features like move and mutex. Once they add support for more compilers that will solve their biggest issue (although they do still compile and debug fine even if it can't resolve the symbols in the editor).
CLion runs on more platforms, and has realllllly nice static analysis built in. Downvotes? What the hell is wrong with you people?
What VM software do you use? I've been trying to use Parallels 10 on Yosemite, but every time I load a Windows 8.1 VM my CPU goes to 100%+ usage and my fans run wild, even though my machine should be fast enough (2013 Air with 8 GB ram).
why isn't this opensource?
Thanks for the info. clang is faster than gcc for my libraries, which are really computer intensive
exactly! I was writing a comment when I saw yours! 
Why isn't visual studio a "proper IDE"?
I don't develop on windows ...
no thanks, jeff
I haven't used it yet, but Xcode has LLVM based diagnostics which I imagine gives more accurate syntax highlighting, linting and code navigation.
This is already in D and it is very useful! I hope this will be in the next standard. 
Good read, thanks for also touching on false sharing and actually demonstrating a simple technique for solving it.
We're running Windows 8.1 on the latest Parallels in Yosemite with no troubles. However, we're using hefty Macbook Pros. I don't know if an Air has the CPU power to comfortably run a VM, but my initial suspicion is "no". This would explain the 100% usage and fan whooshyness. Just a guess, though. First step would be to contact Parallels support and ask 'em.
&gt; -fno-exceptions, -fno-rtti or equivalents should be guranteed to be supported by the library, possibly via feature-testing support for these features. That would be amazing to have! In testing I found an not-insignificant speedup when compiling my games without exceptions.
Well the main point is that some developer can not use exceptions and RTTI. In such a case using STL containers is also very problematic. So we for example have replacement for them without exceptions. This also resolves other problem with STL containers. On problem is that STL from VS2012 is not ABI compatible with one for VS2013. So you can not use it ad DLL boundary, but with custom container this is perfectly fine.
They look fine for me, using OpenJDK 1.7
It works in every case that the normal operator works! Because you do it as a 'using std::rel_ops...' it is essentially the same as just typing them out! Only downside is that because it is a template, it needs to be done in the header file.
Regarding the font issue: Try running it on TuxJDK (https://code.google.com/p/tuxjdk/). That did the trick for me.
puppet account?
so is it like npm for c++? because that would be fantastic! I "grew up" in c/c++ dev, now writing javascript for test environment (what I should be doing instead of reddit). Loving how quick and easy (and dirty) adding new modules are, but hating performance and limited memory management controls. (playing with Emcripten though, seems fun)
Very interesting. Shame the interviews audio is poor compared to Bjarne's. Wouldn't it have made more sense to capture the source audio from each and mux together?
 const auto prefix = "XX"; std::equal(prefix, prefix+2, code.begin()); Did I mention that we need ranges? 
My thoughts exactly! Now I wish I had enough time to write a paper on this.
Some other important missing ones are `std::stoi()`and its friends.
`code.BeginsWith("XX");`
Ah, indeed. Maybe `std::stoi` will get `string_view` overloads.
doesn't work in chrome on my nexus 5
I'd really like **slicing** to be added to C++. So `a : b` could be overloaded like this: std::slice operator:(std::slice_firstlast_tag_t, size_t first, size_t last) { return std::slice{first, last}; } std::slice operator:(std::slice_emptylast_tag_t, size_t last) { return std::slice{0, last}; } std::slice operator:(std::slice_firstempty_tag_t, size_t first) { return std::slice{first, std::slice::npos}; } std::slice operator:(std::slice_emptyempty_tag_t) { return std::slice{0, std::slice::npos}; } And then you'd have: template &lt;typename CharT&gt; std::basic_string_view&lt;CharT&gt; std::basic_string&lt;CharT&gt;::operator[](std::slice sl) { return std::basic_string_view&lt;CharT&gt;{*this}.substr(sl.first, sl.last); } So you could write: auto creditcardnumber = "0000 1111 2222 3333"s; auto last_four = creditcardnumber[12:]; // std::string_view auto wcreditcardnumber = L"0000 1111 2222 3333"s; auto wlast_four = creditcardnumber[12:]; // std::wstring_view --- or something like that.
Please make this a proposal, at least a post to the std-proposals newsgroup (it takes ~15 seconds to make a quick post there). The whole point of the TS process that they use now is that there's a big opportunity for improvement over time before standardisation!
Package managers already do dependency management.
[Done](https://groups.google.com/a/isocpp.org/forum/#!topic/std-proposals/IfHXi6FW6U4).
Compared to allocating a single block of memory?
I played around with it a bit, and doing using namespace std::rel_ops; doesn't work in other functions (like `sort`). Instead you have to do using std::rel_ops::operator&gt;; (for each operator, but doing it once is enough for all your classes) http://cpp.sh/2wo6 It's really cool.
""s should be a string_view so that "foo"s creates a string_view instead of a copy of a temporary string. "foo"s would also be a constexpr string_view.
No, ""s should be string-view so that existing code is made faster. Can you provide a non-synthetic example where the behaviour change would result in broken code (or even code that doesn't compile)? I can't think of any current valid code that would break; the only example I can think of is synthetic examples that either use overload resolution to select between string &amp; string_view or TMP that selects between string &amp; string-view. The only "breakage" I see is that code that used to be well-formed might not be well-formed but that's something that can happen in new iterations of the standard, particularly since C++17 is equivalent to C++11 in terms of breaking changes. EDIT: There is one snippet that might break: void foo(std::string&amp; f) {} auto s = "foo"s; foo(s); wouldn't compile anymore. However the breakage is a compile-time error which is much less serious than runtime-errors that can occur when turning on C++11.
&gt;No, ""s should be string-view so that existing code is made faster. That's silly reasoning, it's not necessarily faster. &gt;Can you provide a non-synthetic example where the behaviour change would result in broken code? auto s = "foo"s; s.assign(3, 'a'); -- auto s = "foo"s; s.push_back('x'); -- auto s = "foo"s; foo(s.c_str()); All are examples of parts of the `basic_string` interface that aren't in the `basic_string_view` interface. They're fundamentally different types with different meanings. Saying "they should change `"a"s` to be a `string_view` literal: it's fine it can just convert to `string` if you need one" is like saying "they should change `1` to be a float literal: it's fine it can just convert to `int` if you need one."
Is this much better than using ExternalProject_Add() in CMake? I've been able to do that without too much hassle. Just make it an option on whether to use the system library or download / install it through CMake.
Good god, man, use some traits.
Is awful in so many ways.
I think concepts fill the typeclass void Edit: Damn autocorrect
 const auto prefix = "XX"; std::equal(begin(prefix), end(prefix), begin(code), end(code)); -- std::equal("XX", code); Yeah you might be right :)
There has got to be a better phrasing of that head line.
This subreddit is full of crazy people! Imho you said nothing wrong, so I will upvote you!
No it isn't. Only one instance is created ever.
Singletons are in fact surprisingly versatile. They are easily mixable with other patterns and idioms. Factories tend to be singletons. You don't need two factories giving the same product/object! I've seen numerois C++ projects to use MyTypicalClass::New(). Guess what, New here is singleton to underlying factory, I don't see people bitching about it. So here is one implementation of Singleton with none of the drawback people associate: // PIMPL Singleton //T is the base interface //TI is the concrete implementation template &lt;class T, class TI&gt; class SingletonPIMPL { public: static T* Inst() { if(!instance){ instance = new TI; assert(instance != 0); instance_smartptr = std::unique_ptr&lt;TI&gt;(instance); iface = static_cast&lt;T*&gt;(instance); } return iface; } protected: SingletonPIMPL(); ~SingletonPIMPL(); private: SingletonPIMPL(SingletonPIMPL const&amp;); SingletonPIMPL&amp; operator=(SingletonPIMPL const&amp;); static T* iface; static TI* instance; static std::unique_ptr&lt;TI&gt; instance_smartptr; }; template &lt;class T, class TI&gt; TI* SingletonPIMPL&lt;T,TI&gt;::instance = nullptr; template &lt;class T, class TI&gt; T* SingletonPIMPL&lt;T,TI&gt;::iface = nullptr; template &lt;class T, class TI&gt; std::unique_ptr&lt;TI&gt; SingletonPIMPL&lt;T,TI&gt;::instance_smartptr = std::unique_ptr&lt;TI&gt;(); this implementation is easy to test since singleton interface and implementation are separated. you can always mock the implementation and test the rest of your app. your app is just a collection of singletons and each one implementation is up to you. the implementation you can hide in a inner namespace ala 'detail' or make use of the c++ friend relation. I rather say don't worry about instanciating the impl class, people will end up using TheManager anyway/anyhow. here how you use it in your app: #ifndef INJECT_PIPELINEMANAGER class PipelineManager; class IPipelineManager; namespace{ typedef SingletonPIMPL&lt;IPipelineManager,PipelineManager&gt; ThePipelineManager; } #endif now in your utest project you simply #define INJECT_PIPELINEMANAGER and create your own mock definition of ThePipelineManager. End of story. The alternative as pointed in some of the shared articles is IoC and injections framework. Which means: 1) you have new dependency in form of library 2) you end up writing thousands lines of code passing dependency down to your lowest function Now you can look at this guy whinings about Singleton at : https://www.youtube.com/watch?v=-FRm3VPhseI and forget everything he drags about since I showed you it is all LIES! DON'T look at singletons as global state but rather global point of reference !!! 
Have you never heard of abstraction?
Weird, the link changed to http://rrsd.com/blincubator.com/bi_library/http/?gform_post_id=1460
I'm trying to contribute to Boost with a simple and powerful HTTP server library (which will support other backends, like FastCGI, in the future). I'd appreciate if you provide feedback: http://rrsd.com/blincubator.com/bi_library/http/?gform_post_id=1460 
To each their own. But yea, damn me for using PascalCase for C++ methods! It's not like everyone else does the same thing. /s
Begins\_With for the win! ;-)
This is not only about Game Development. [Maxon PluginCodeStyleGuide.pdf](https://developers.maxon.net/wp-content/files/PluginCodeStyleGuide.pdf)
Even after the shift to opensource the whole initial idea of "we won't make things opensource until x users are on our service" made this distinctly unappealing to me personally. I also really don't like the invasive "adding biicode" pull requests which have cropped up on github. I don't really think that any package manager should try to force code changes onto the projects that it attempts to manage.
&gt; It's not like everyone else does the same thing. /s ---- There is the right way to do naming in a language: That is following the style that the standard-library of the language in question establishes. There is the unprofessional and childish way of naming things: Using something else while pointing out that it helps distinguishing different things within ones own code and thereby completely ignoring that the now several different styles of naming produce more confusion than the style in question could ever remove. And than there is the “I just want to see the world burn”-way of doing things by using something else, that cannot even point out some benefits and even puts the confusion by the second way to completely new levels. ---- Please note that the above is completely language-agnostic. Please also note that I don't say anything about the usual style-topics that are not part of the interface (I strongly believe in tabs for indentation and opening braces on the same line, but if you disagree, that is perfectly fine, because we can use each others code without creating a mess).
I can actually see this becoming a standard for concepts. (Which are by the way another reason to use snake case, because the case will soon be the only way to distinguish function-templates.)
Yes raw/naked 'new' and especially 'delete' should be not used in today c++ code. Because of this is would be nice to have standard way to disable them. [Is it possible to completely disable the default C++ new operator?](http://stackoverflow.com/questions/18365804/is-it-possible-to-completely-disable-the-default-c-new-operator) 
I coded something similar once, except with the additional feature of very easily initializing it: https://gist.github.com/sim642/9184484. Also a base case of 0 dimensions sounded much more neat to me, less duplicate code.
RAII https://en.wikipedia.org/wiki/Resource_Acquisition_Is_Initialization
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Resource Acquisition Is Initialization**](https://en.wikipedia.org/wiki/Resource%20Acquisition%20Is%20Initialization): [](#sfw) --- &gt; &gt;__Resource Acquisition Is Initialization__ (__RAII__) is a [programming idiom](https://en.wikipedia.org/wiki/Programming_idiom) used in several [object-oriented languages](https://en.wikipedia.org/wiki/Object-oriented_programming_language), most prominently [C++](https://en.wikipedia.org/wiki/C%2B%2B), where it originated, but also [D](https://en.wikipedia.org/wiki/D_(programming_language\)), [Ada](https://en.wikipedia.org/wiki/Ada_(programming_language\)), [Vala](https://en.wikipedia.org/wiki/Vala_(programming_language\)), and [Rust](https://en.wikipedia.org/wiki/Rust_(programming_language\)). The technique was developed for [exception-safe](https://en.wikipedia.org/wiki/Exception-safe) [resource management](https://en.wikipedia.org/wiki/Resource_management_(computing\)) in C++ during 1984–89, primarily by [Bjarne Stroustrup](https://en.wikipedia.org/wiki/Bjarne_Stroustrup) and [Andrew Koenig](https://en.wikipedia.org/wiki/Andrew_Koenig_(programmer\)), and the term itself was coined by Stroustrup. RAII is generally pronounced as an [initialism](https://en.wikipedia.org/wiki/Initialism), sometimes pronounced as "R, A, double I". &gt;In RAII, holding a resource is tied to [object lifetime](https://en.wikipedia.org/wiki/Object_lifetime): [resource allocation](https://en.wikipedia.org/wiki/Resource_allocation_(computer\)) (acquisition) is done during object creation (specifically initialization), by the [constructor](https://en.wikipedia.org/wiki/Constructor_(object-oriented_programming\)), while resource deallocation (release) is done during object destruction, by the [destructor](https://en.wikipedia.org/wiki/Destructor_(computer_programming\)). If objects are destructed properly, [resource leaks](https://en.wikipedia.org/wiki/Resource_leak) do not occur. &gt;Other names for this idiom include *Constructor Acquires, Destructor Releases* (CADRe) and one particular style of use is called *Scope-based Resource Management* (SBRM). This latter term is for the special case of automatic variables. RAII ties resources to object *lifetime,* which may not coincide with entry and exit of a scope (notably variables allocated on the free store have lifetimes unrelated to any given scope). However, using RAII for automatic variables (SBRM) is the most common use case. &gt; --- ^Interesting: [^Manual ^memory ^management](https://en.wikipedia.org/wiki/Manual_memory_management) ^| [^Destructor ^\(computer ^programming)](https://en.wikipedia.org/wiki/Destructor_\(computer_programming\)) ^| [^Dispose ^pattern](https://en.wikipedia.org/wiki/Dispose_pattern) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cqegdjq) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cqegdjq)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
There are some parts of the STL that are pretty hard to write - for example &lt;type_traits&gt; specifically the ones that directly rely on the compiler such as is_class, is_union, is_enum (maybe is_trivially_constructable, etc?). Combined with `initializer_list` I'd say that at least parts of the STL are required to get the most out of C++.
Why does dimension of 0 reduce to Type, rather than dimension of 1 reducing to type, and zero becoming nullptr_t or something else?
C++0x was running extremely late, and make_unique wasn't considered critical. (Unlike make_shared, users can implement make_unique.) By the time I started attending meetings in 2012, it was clear that make_unique would be valuable even if it wasn't absolutely essential, so I wrote up a proposal (which wasn't trivial; make_unique for arrays required thought) and it was accepted into C++14. So that's the story.
"8x speedup right?" forget about it! it doesn't work with pure CPU computing left alone IO. I recall a presentation from my faculty of a guy about developing some log2N parallel loading of some huge GBs binary matrices. My main problem is the fact hardware is sequential in order, thout they got quite ram cache on them those days, and pure random as logN access to file segments is gonna stall/flatten perf to N, that is almost liniar/serial But let me ask you: why "The file I would like to read is a normal txt file." going binary will greatly reduce the size to start with! so why not pre-process before attempting the main task. which is what btw? do you need to record back i the same txt format? "But I'm not sure how would I store the read data by each thread process in a consistent fashion" that’s should not be a problem if you know how many lines you need to process in general then you can split in N ranges for each thread N if you intend on using stream.readline(...) of course you need some thread knowledge how to spawn-wait-yield on all to finish 
Running late makes sense, I had forgotten that it was originally codenamed C++0x!
&gt; STL container are created with assumption that the user will use exceptions. So it is not really safe to use them without. Well, they basically are allowed to throw std::bad_alloc I don't see a way around that, beside: * Don't use a dynamic container * Ignore exception. That is a perfect thing to do in most situation ( the allocation will most likely not fail anyway, most systems over-commit) * Design a container that exposes the result of the allocation by a mean other than exception. You will end up with the most hideous chimera. Also, C++ is designed with the assumption the world is an ASCII-centric world and websites developers assume your browser has a JS engine. Damned.
[This is the proposal you mentioned?](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3588.txt)
This pattern is also used to implement singletons. I don't know why you can grasp a `get_instance` function for a singleton but not this.
&gt; type_info For me RTTI seems to be Half-baked. '&lt;type_traits&gt;' also uses compiler magic now too.
Yes; the revision [N3656](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3656.htm) was accepted.
Well written paper &amp; has lots of ideas worth following up on I think. I quibble with the suggestion to split-up algorithm as that would only be worth it as a short-term benefit if C++17 doesn't get modules (if it does than at any implementation of this improvement would be in parallel with modules &amp; unneeded I think). Point #7 I think misses associative containers where you need to be able to do heterogenous lookups without expensive intermediary allocations.
Wouldn't an interface suffice for that?
Oh man, I've seen you here and there on reddit, (you replied to my RNG post), and I thought you named yourself after the Standard Template Library. Nope, just your initials. Really cool.
Yes, I know that STL is a library ... it was the "external" that made me chuckle, since STL is just part of the C++ standard library --- not really what I usually consider "external". Thinking about it more, though, I guess what they're saying is "don't use *any* libraries we haven't written ourselves, *including* the standard library".
Oh, I get that you may not be able to use the container library. It was just the description of "external" that I found funny when applied to a part of the C++ standard library. On reflection, it seems that the meaning must have been "no libraries we haven't written ourselves".
&gt; On reflection, it seems that the meaning must have been "no libraries we haven't written ourselves". No this is wrong. First this is an advice and not a hard rule. Second it is perfectly fine to use external libraries as long as they fit into such developer philosophy. 
&gt; (In fact, as we'll eventually see, no one really succeeded, [...] What, the solution`random_device_seed_seq seed; std::mt19937 eng{seed};` from my [answer](http://www.reddit.com/r/cpp/comments/31857s/random_number_generation_it_might_be_harder_than/cq08lli) doesn't qualify? The definition for `random_device_seed_seq` can be made to conform to the full requirements of a Seed Sequence, if that's the issue. &gt; because even if you try to use 624 integers to initialize the seed_seq, it's not going to do what you'd like! The article doesn't really cover what happens to `seed_seq`'s results as more input is given. Some tricks were used to try out two inputs. Do you expect that the collisions in the output of seed_seq will continue to approach a poisson distribution as more data is fed in/generated? &gt; Why does seed_seq exist, if initializing 624 ints using a single int isn't a good idea in the first place? In practice I don't think I've seen anyone resort to explicitly using a seed_seq if they only want to supply one input. I always see several, like five or six at a minimum. &gt; The idea that repeated calls to generate must always generate the same values needs to go. The SeedSequence concept in C++ does not require `generate()` to be consistent. It actually specifies: &gt; fills the supplied sequence [rb, re) with 32-bit quantities that depend on the sequence supplied to the constructor and **possibly also depend on the history of generate’s previous invocations.** That should be loosened up even further though.
How providing iterators is harder and more error prone than writing a whole bunch of efficient algorithms ?
(a) you write the algorithms once and use many times. If the *use* of the algorithm has a small % bug chance, it virtually guarantees bugs (as you use them many many times). But if you can't write a 3-line algorithm without bugs, you shouldn't be writing professional code yet. (b) algorithms that get iterators as input are very verbose. (c) providing iterators is hard. At least doing it "compliantly". Half-assing it is easy, but then it isn't guaranteed the algorithms will be efficient (or even work correctly)
&gt; The iterators might not be a part of your design. They should be. If you are writing your own data structures, you should be thinking about how you navigate through the data structure. Maybe you don't always expose the iterator to the user, but you can leverage STL algorithms internally to do many non-trivial things though. &gt; Sometimes it's even hard to write (good) iterators Sometimes, but for most common data structures(such as for arrays or linked lists) they are trivial. &gt; This isn't the case with std::vector (which basically uses pointers to the data as iterators) But in most high performance cases you will be allocating in contiguous blocks which means you can just use pointers for the iterators. &gt; Also, the whole iterator thing comes to solve a problem you often don't face: what if I want to run an algorithm on a part of the container only? Because rewriting `std::sort` is less error-prone? 
The problem here isn’t predictability nor cryptographic security, it’s statistical robustness.
&gt; The constructors take it by lvalue-reference, disabling the use of temporary sequences Yeah, I don't understand why it's specified that way. That's one of the things that ought to be fixed. 
&gt;(a) you write the algorithms once and use many times. If the use of the algorithm has a small % bug chance, it virtually guarantees bugs (as you use them many many times). But if you can't write a 3-line algorithm without bugs, you shouldn't be writing professional code yet. Well, that's a good reason to use &lt;algorithm&gt; designed to be written once and used consistently across containers. Also, you *will* have bugs and spend a lot of time reinventing the wheel. Granted, std::count is simple. what about std::sort ? &gt; (b) algorithms that get iterators as input are very verbose. I suppose you are referring to the need to provide .begin() and .end() ? The Range TS proposal will change that ( and much more) &gt; (c) providing iterators is hard. At least doing it "compliantly". Half-assing it is easy, but then it isn't guaranteed the algorithms will be efficient (or even work correctly) You can make the same case for algorithms though. As a given container will on average need to support several algorithms and only expose one or 2 class of iterator, you are better of providing the later. Iterators are an important part of the STL and of the C++ philosophy in general. They are both powerful and expressive. E. Nieber's Range proposal reaffirm that further. They also let you to think of data structures and algorithms separately, which tend to lead to better designs. 
Assuming you can actually get 624 sequential outputs. It's not uncommon to use an OS source of randomness along with a PRNG, and you grab 32 bits of /dev/urandom, modulo by 100 or something, and throw away that many outputs from your PRNG upon a random call into your own stub call. That prevents you from running out of OS randomness, but you can still use a PRNG like MT and make it very difficult for an attacker to predict the next number. Also, you can make it very difficult for the attacker to begin even finding the sequence from a seed by just throwing away the first couple million produced numbers. The periodicity of MT is *enormous*. The amount of output you would next to store from a PRNG to compare against to figure out all of that is impractically large. 
Also - about "iterators should be part of my design" - what if I need to write thread-safe containers? Containers I can safely access from multiple threads at the same time? Iterator access is done via references - so while if I use getters and setters, I can easily lock a mutex on access, with references for iterators suddenly... it's more complicated. I need another temporary objects with operator= and stuff. And that's non-compliant anyway so it's moot. And if I want "write one / read many" mechanics? Or - to have multiple mutexes for different locations in the save vector? It's really hard to implement iterators with this mechanics. But if I let people access my container using indices - it's trivial.
I have my theories, but if I'm right with them, the reasons are not particularly good.
Agreeing on what the problems are is the first step to finding good solutions.
The best way to define a problem is to offer a solution for it. Otherwise you run the risk of solving the wrong problem.
&gt; I have my theories Please, share!
That's funny: You found a line that actually contains a bug, but pointed to something else. ;-) What you pointed out as problematic really is legal: Section 6.6.3, paragraph 2: &gt; [...] A return statement with an expression of non-void type can be used only in functions returning a value; the value of the expression is returned to the caller of the function. The value of the expression is implicitly converted to the return type of the function in which it appears. **A return statement can involve the construction and copy or move of a temporary object** (12.2). [ Note: A copy or move operation associated with a return statement may be elided or considered as an rvalue for the purpose of overload resolution in selecting a constructor (12.8). — end note ] A return statement with a braced-init-list initializes the object or reference to be returned from the function by copy-list-initialization (8.5.4) from the specified initializer list. [...] No, the bug was elsewhere: I shouldn't have used braces but parenthesis there, and when I tried to compile it, in fact both clang and gcc didn't produce errors. Lesson: “Even if you don't write real tests, because testing whether a random result is really random cannot be reasonably done, you should write unit-tests nonetheless, to ensure that your templates get instantiated when building.”
I really dislike the RNG system of C++11. It really is hard to use. I understand the need for generality in C++, but there should also be a "default" that *just works*. Similar to how `ostream` is a very general framework for output, but you also have a "default" `std::cout` that *just works*. Imagine if you had to do the following to write to `stdout`: std::output_devices::stdout out_device; std::ostream_buffer_char out_buff(out_device); std::ostream out(out_buff); out &lt;&lt; "Hello, world!"&lt;&lt;std::endl; it would be ridiculous and unusable. And like printing to `stdout`, generating a random number is something very common and needed in low-skilled programming. So people will continue to use `random()`, which is HORRIBLE, but *just works*, because using the C++11 way (a) requires you to remember a TON of stuff, with very non-descript names like `mt19937`, and (b) even seasoned programmers and experts don't really know how to do it "correctly". I would have really liked to see a default random number generator in a global variable, that *could* be just `std::mt19937` created via `std::random_device` for all I care (or even unseeded! Unseeded is fine - just give me a simple way to seed it as well) that just exists! 
I wrote a microservice that produces card deck shuffles. A pair of these running processes are used by thousands of poker tables. The PRNG itself is seeded and then a random (large) amount of output is discarded and with every additional call, more random output is discarded. The reason not to use /dev/urandom directly is to avoid the potential problem of running out of useful entropy. The initialization cost doesn't matter one iota (these processes spin up in a few seconds and are kept live for weeks on end), but the overall output is impossible to predict from one or even many connected clients. Concurrent requests for shuffles produce even more places where you're not getting sufficient state. Also, with something with enormous periodicity, you probably *don't* want to reseed frequently, maybe never. 
FWIW, on my list of upcoming blog posts (I have to write the text, not the code), I have a nice wrapper that puts all the pieces C++11 gives you together in a nice way so that: * It’s really powerful, not just some cut-down-for-beginners trivial thing (I’m looking at _you_, `randint` proposal!) * It’s really easy to use. Best of all worlds. Coming soon.
&gt; But the iterator is the same thing as an index into the data structure No it isn't! Because you don't have the data structure handy to access with the iterator's index. So you have to keep both the index AND the (pointer to the) data structure. Meaning that (a) your iterator is bigger than an index (with the `end` it can be more than 4 times bigger) and (b) causes another dereference (because you access your object via a pointer). So it's less efficient than remembering an index, and takes more memory. -------- about `std::vector&lt;bool&gt;` and proxy in general: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2160.html It may have been fixed in C++11, I don't really know, but in C++98 - the iterator for std::vector&lt;bool&gt; was non-compliant. The reason is that an STL iterator must allow you to do the following: value_type &amp;v=*iter; in other words - hold a reference to an actual value, that you can change and will then change in the container. This does not work for std::vector&lt;bool&gt;, it does not work for any proxy reference, and by design (you get a true reference to the data) prevents any ability of access control (like mutex). 
Oh, I see what you mean: The problem is not that there is a disabled copy-constructor, but that the move-constructor isn't added back (which I thought it was). Elision has indeed nothing to do with that. And now, that I switched the standard-library instead of the compiler, I do indeed get an error. libstdc++, I trusted you! Why do you betray me! I guess I should file a bug report or submit a patch. Anyways, not today anymore (It's 1 AM here).
&gt; Sorting a vector&lt;bool&gt; doesn't make sense What? of course it does! Sure, you could use bucket sort for it, but that's true for a `vector&lt;char&gt;` as well - are you saying you shouldn't sort a `vector&lt;char&gt;`? I even remember reading an academic article about how to sort bits arrays in efficient way (multithreaded way) &gt; That is not true [about the `std::vector&lt;bool&gt;`] http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2160.html specifically: &gt; &gt; The 1998 C++ Standard Library's vector&lt;bool&gt; specialization was a mistake - it does not meet the requirements for a container, its iterator **does not meet the iterator requirements** specifically, the requirement that the following code works: value_type &amp;v=*iter; &gt; using iterators for something a like a packed bitvector is a perfect example of how iterators can improve performance for a iterations vs using indices Yes, vs INDICES, but not vs your own implementation. If I want to count the amount of '1' in a bitset - I can do it about 60 times faster than using `std::count`. If I want to sort it I can do it with bucket sort. If I want to find 1 in it, I can do it 60 times faster than `std::find`. Iterators are WRONG and LESS EFFICIENT in this case. And they are wrong and less efficient in some other cases as well. They are good, for general use. Like all of STL - it's good for general use. But if you have performance-critical code you often will have to implement your own containers and just not use STL at all.
YES! :D
&gt; No it isn't! Because you don't have the data structure handy to access with the iterator's index. So you have to keep both the index AND the (pointer to the) data structure. Meaning that (a) your iterator is bigger than an index (with the end it can be more than 4 times bigger) and (b) causes another dereference (because you access your object via a pointer). Why can't you instead keep a reference to an array of mutexes that can actually lock in a granular manner if that is what concerns you so? Instead of locking the entire object for every set/get operation, you can lock precisely the indexed data. You can also use a global mutex table you point into with an offset, so that your iterators are one pointer bigger, but your object is a mutex and probably a lot of unnecessary locks smaller. &gt; in other words - hold a reference to an actual value, that you can change and will then change in the container. How often do you copy huge objects? I don't understand the problem here. Usually you'll access data by reference anyway.
&gt; Why can't you instead keep a reference to an array of mutexes... because it's not encapsulated: my CONTAINER takes care of all the access control stuff, not my algorithms / rest of my code. I don't want to handle mutex-s every time I access this container: my system is built to run massively multithreaded, and my container is built to be thread-safe on all access, so I don't need to worry about it. No possibility of bugs in the usage of the container. &gt; Instead of locking the entire object for every set/get operation, I'm not &gt; you can lock precisely the indexed data can't either. The data is too big - can't afford that many mutexes. Instead I divide the data into chunks - each having it's own mutex. &gt; You can also use a global mutex table you point into with an offset what? WHAT?! So you're solution to me wanting a convenient (thread safe) container class is to use a global variable (array)? That makes NO sense. So why even use a class to begin with? Why not have all my data global? What if I want multiple containers of the same type - do I need to add more global vectors? No, the mutexs are inside the container, and hidden from everyone else. The container takes care of locking and unlocking as needed when you access its data. &gt; How often do you copy huge objects? I think you missed the point. There is no copy here. There is a reference. And it's not to a "huge object", it's to one item in the container. STL requires that every compliant iterator allows the following code: value_type &amp;v=*iter; So if I have a `vector&lt;string&gt;`, it should be legal to write: vector&lt;string&gt; v; vector&lt;string&gt;::iterator iter=v.begin(); string &amp;str_ref = *iter; and now I have a reference to the actual string that is the first item in `v`. That is a requirement of iterators. If an iterator doesn't allow it - it's not a compliant iterator. the iterator of `std::vector&lt;bool&gt;` doesn't allow it, so it's not a compliant iterator. And by this very requirement, that I can get a TRUE reference to every object in the container, the very design of iterators prevents me from using access control.
&gt; then every data structure can be searched by advancing and comparing until it is found. sure, it CAN, but you're doing it WRONG if that's how you count items of an `std::set`. Not imagine a different scenario: every container has its own `find` and `count`. This is already the case for all containers except for `std::vector`! (and `std::array` in C++11) (oh, and probably `list`?) OK so imagine that's the case. Now I have some code that uses `std::vector` and I want to change it to `std::set` for efficiency (because I search a lot). Bam! Works right out of the box! The code is exactly the same - it uses `v.count(item)` - and works for all containers! So actually using `std::count` made my code LESS easy to change. Now the same with `remove`. Very hard to use correctly if you're a novice. And very hard to just "look at" and see if you have an error. And doesn't work on many of the containers. So why is `remove` in &lt;algorithm&gt; instead of `vector` having an `remove` member? "Because now it's more general!!!" and you can erase objects from a subsection of the vector so we have this beautiful piece of code: vec.erase(std::remove(vec.begin(),vec.end(),VAL),vec.end()); instead of vec.remove(VAL); that references `vec` 4 times (!), so if `vec` is some inner object like `my_data.content[USER]-&gt;headers.POST_headers()`, now my code is a horrible unreadable mess instead of the simple clear code it could have been. OKOK, but we can remove values from a sub-range of a vector, right? Yes, we can! Say we want to remove between indices i,j: vec.erase(std::remove(vec.begin()+i,vec.begin()+j,VAL),vec.begin()+j); Cool! And so readable I'll never ever have a bug here! Much better than implementing a vec.remove(VEC,i,j); But still, it's general so cool. Now what if I don't care about preserving the order? That is important because erasing members of a vector is O(n) swaps in general (even if I remove from a sub-range! It's still O(n) where n is the full range). but removing elements if I don't care about preserving the order is just O(k) swaps where k is the number of time the value appears. So how do you implement this with iterators? You can easily create a "remove_no_order" that does it correctly inside the range, but that's not enough - because if you use a subrange, now you don't have an easy function that just moves (swaps) all the "erased" values from your subsection with the values at the end. Because by design such algorithms don't have access to the entire container (just their range), you can't even write such an algorithm using this design. This iterator design PREVENTS me in this case from doing a good, efficient algorithm, that I could easily do if I had access to the entire data. ---------------------------- bottom line: yes, STL is good. But saying that you should always use it is just misguided. It has tons of flaws, and iterators specifically although interesting make code look worse and often even run worse. There are plenty of reasons to recreate your own containers and algorithms - and really, &lt;algorithm&gt; isn't such a great library...
&gt; Btw, as you are the expert here: How many uint32_ts would you use to seed a general-purpose mersenne-twister? For instance a global one in the stdlib. If possible, I wouldn’t use the Mersenne Twister at all. It’s not fast, the period is ludicrously huge, and it has some statistical issues (more detail [here](http://www.pcg-random.org/other-rngs.html#mersenne-twister)). Thus, I don’t think there *should* be a global Mersenne Twister in the standard library. Especially as you really need one per thread to avoid contention, and so you’re adding lots of needless per-thread bloat. But if we _really_ want the Mersenne Twister because we really want that huge 2^19937 a state space for some reason, I think you should just bite the bullet and initialize it with 624 ints from `std::random_device`. C++11 makes it a pain to do this and conform to all the (largely unnecessary) requirements of a _Seed Sequence_, but it *is* possible. So, I’d use a class that does that. If in general, I need an actual `std::seed_seq` for an arbitrary RNG that I know nothing about, I’d probably use 256 bits of system randomness. Any bias wouldn’t be detectable. But I wouldn’t be too happy about the whole thing.
&gt; Iterators are WRONG and LESS EFFICIENT in this case. No, general-purpose `std::count` and `std::find` are wrong in this case. Its the same reason the associative container have a member `find` and `count` as well. However, internally, you can use the algorithms, though, to implement the faster `find` and `count` methods(using `find_if` and `accumulate` respectively). So iterators and the STL are still useful in this case. 
Specialise the functions for containers that provide specialised versions, have a standard version otherwise. You can do the same with inheritance and a vtable, but at runtime. STL is supposed to be general. I agree that it is too verbose. I even agree it isn't the right hammer for every nail. But you don't *have* to use it. If you don't like it, you can implement something for your specific problem. Otherwise I can use the STL and be sure that the code *works*. I think that's an advantage.
&gt; I'm still missing the point. Let's take your example again No, the example (both mine and yours) are fine, and work fine. But if you replace `string` with `bool` they don't work anymore, and the C++ standard requires that my example with iterator work for any type if the class be considered a container (so the iterator be considered an iterator of a container). You can't do vector&lt;bool&gt; v; vector&lt;bool&gt;::iterator iter = v.begin(); bool&amp; b_ref = *iter; which means `vector&lt;bool&gt;::iterator` doesn't conform to the C++ standard of iterators of containers, and hence any algorithm using this iterator isn't guaranteed to work correctly (or at all). You're not allowed to have proxy references in your container iterators. It's against the C++ standard. &gt; And I hate std::vector&lt;bool&gt; because that specialisation should be an option But the point is - not that they shouldn't do a default specialization (which they shouldn't) but that you CAN'T do this specialization even if you wanted to! You can't create a container that uses a proxy to get/set values. It isn't allowed. Iterators are so inconvenient in "i do my own containers" that even those who created the standard can't figure out a way to use it in anything by the most simple use cases. ----------------- About the mutex thing - I think we might not be on the same page. So I'll just give an example implementation: class SafeVec{ private: int *data; mutable std::mutex m; // actually multiple mutexes etc. public: // all the usual constructor/destructor stuff void set(size_t i, int val){ std::lock_guard&lt;std::mutex&gt; guard(m); data[i]=val; } int get(size_t i) const{ std::lock_guard&lt;std::mutex&gt; guard(m); int res=data[i]; return res; } }; fully encapsulated, no one has to worry about locking / unlocking / thread safety when using it, no global mutexes. Now how would you access values with iterators, given that the standard doesn't allow you to use proxy classes?
Right, when I said "iterator" I meant "container iterator" as we were talking about containers here. I'm sorry if that wasn't clear. I want to write a container, thus use container-iterator functions from &lt;algorithm&gt;, so my iterators must conform to the container iterator standards. People keep talking about `sort` for example (arguably the only non-trivial code in &lt;algorithm&gt;), so what's the point in creating an iterator for my container if I can't use `sort` on it?
&gt; No, general-purpose std::count and std::find are wrong in this case. but the whole point is generality. I used to use `std::vector` which *doesn't* have a `count` member, and so I HAD to use `std::count`. If you're saying it's wrong in this case, what should I have used? And if `std::count` is practically only useful for vectors (and arrays), why not make it part of vector? why even let me use it for `std::set`? The very fact that I CAN use `std::count` for an `std::set` is wrong. It makes the code look correct even though it isn't. If I look at some code and see: num=data.count(key); I know it's using the correct `count`. But if I see num=std::count(data.begin(),data.end(),key); I might *think* it's using the correct `count`, because I don't know what `data` is off-hand. If I want to make sure though - I'll have to go through maybe a lot of backtracking of the code to find what type `data` is and see if I'm using the correct `count`. That's a bug - using the wrong `count`. It will get the correct result, but will be too slow. The very existence of `count` and how it is able to work on `std::set` is wrong.
If I'm going to specialize the functions (which introduces bugs of its own that are hard to track), and also have to create iterators for my container (which isn't trivial at all, requires me to have the same code twice - for `iterator` and for `const_iterator` - and each one of those has a LOT of functions to be a compliant random-access iterator, and so many rarely used functions will easily introduce a lot of bugs etc. etc.) why would I do it? What do I gain? The algorithms in &lt;algorithm&gt;? Which algorithm (other than `sort`) is even worth all that work? Rewriting the useful algorithms in &lt;algorithm&gt; as member functions to my class is actually less work than creating an iterator, double checking if the standard &lt;algorithm&gt; version works here and specialize the one that doesn't. Also, remember that I will need to specialize the algorithms twice: once for `iterator` and once for `const_iterator` (at least things like "count" and "find". No, I'd much rather use STL when convenient, but when creating my own containers - not creating iterators. It's just easier. **edit** &gt; Otherwise I can use the STL and be sure that the code works only if your iterators work. The amount of bugs I had because my iterators were 'flawed' really put me off of iterators :( And it's very very subtle bugs at that...
 &gt; Rewriting the useful algorithms in &lt;algorithm&gt; as member functions to my class is actually less work than creating an iterator, double checking if the standard &lt;algorithm&gt; version works here and specialize the one that doesn't. We work in very different fields. My view is that I don't have to do &gt; double checking if the standard algorithm works I know it works. At worst it isn't *efficient*. I need a very good reason to write my own containers or algorithms when there are standard versions because the standard versions allow me to reason about my code with a justified assumption that the standard parts are bug-free. The codebase I'm working in uses the STL; but it also has a simulation component that uses containers we made that do their own allocation and minimise indirection. But we wrote these containers specifically because in those places correctness wasn't enough. Code-line wise STL absolutely dominates. So that's the kind of disconnect we have, we don't really disagree. Our contexts are just wildly different.
&gt; But if you replace string with bool they don't work anymore, and the C++ standard requires that my example with iterator work for any type if the class be considered a container (so the iterator be considered an iterator of a container). That's true and I don't like that. &gt; You're not allowed to have proxy references in your container iterators. It's against the C++ standard. Well I can't call that a standard container, but I want to see him who forbids me from doing just that. That's the weird thing about something being allowed or not. ;) But seriously: &gt; Now how would you access values with iterators, given that the standard doesn't allow you to use proxy classes? *I* would wrap the value type itself (in the container). So `std::vector&lt;mutexed&lt;int&gt;&gt;` or something. But then *efficiency* is *usually* not my main concern. The kind of code I write is constrained by the speed of user input much more than the speed of the STL. And if I really needed absolute speed (which you seem to), or even a specific memory layout, I would also roll my own container.
Yes, different use cases call for different tools :) And iterators are not always the right tool. I most definitively use STL anywhere I don't need special containers. Like you said - they work. Although many times they do cause me bugs (because of the verbosity - if I want to `std::remove` from a vector... I need to repeat the same vector 4 times. For complicated 'path to vector', when I need to change something I often just remember to change it 3 times and get a horrible bug) But if I do need special containers - like you said you also need on occasion - writing iterators for them is often detrimental in the long (and short) term. It just takes so long to write "correct" iterators. And to be honest, if I use "home made" iterators, I'm always afraid I introduced some subtle bug. 
You're free to use [my random number generator wrapper](https://gist.github.com/jrandom/64c8972b438bf8f1d0dd) which I wrote precisely because I could never remember how the stdlib stuff worked and kept having to look up the documentation. Edit: After reading some of the other comments here, I'd like to clarify: I don't *dislike* the existing RNG structure -- it's a great set of low-level tools that you can use to build friendlier high-level tools (like my wrapper linked above) that behave exactly the way you want them to. I generally only need normally-distributed numbers, but if I ever need a Poisson (or other) distribution that holds state and whatnot, I can create exactly the type of class I want that will handle such generation in a way perfectly fit for my use case. This is C++, not Python. We build our own awesome from scratch. &lt;/cave_johnson&gt; *That being said, seeding does need some fixing. :)*
&gt; People keep talking about sort for example (arguably the only non-trivial code in &lt;algorithm&gt;), so what's the point in creating an iterator for my container if I can't use sort on it? There are more non-trivial algorithms than `sort`. There is rotate, lower_bound, upper_bound, search, binary_search, merge, set algorithms, heap algorithms, permutations, partial_sum, adjacent_difference, etc. 
&gt; lower_bound, upper_bound only work on vectors (arrays?) in an efficient way. So why are they in the "general" algorithm section rather than in the "vector" section as a member function? You keep claiming these are general algorithms. Maybe we use the word differently - but to me an algorithm that only works (well) for one specific type but fail for most other types isn't general. It's an important algorithm - working for one (or two) types is great. And I'll use it. But it isn't general. &gt; search please - if search is so great, why does `string` (the only "container" where search is actually regularly used) implement it's own version? (although in `string` it's called `find`) You know what? Let's discuss `search` further: It finds a sub-sequence in a sequence. So why does `string` re-implement it? You gave the example of `count` in your other reply, that I should implement my `count` using `accumulate`. So... why don't even the people who write STL use the algorithms in &lt;algorithm&gt; when they need the exact same thing? `string::find` literally does the exact same thing `std::search` does. But it isn't implemented using that. Why? Because the implementation isn't general enough / isn't good enough even for their own use when creating a slightly different class. And if they can't use it when they implement their own stuff - why do you assume that I can? More importantly - did you see the `std::search` implementation? It's O(n*k) worse case where n is the length of the container and k is the length of the segment. That's bad. There is an O(n) implementation - although it's not "general". So I can't use that either in most cases. And it's true for everything. The algorithms in &lt;algorithm&gt; are useful (arguably) when you use STL containers. But they simply aren't good enough when you have to write your own container because your needs are different. Even when the STL programmers write their own container that's just a bit different (`string`? `vector&lt;bool&gt;`?) they can't use &lt;algorithm&gt; efficiently. So why do you assume that I can? Or that I should try? If my containers don't benefit from having iterators - why would I write iterators for them? What do I gain from adding iterators to my containers? 
But `sort` isn't one of them, right? Nor is `search` (although `find` is). Nor `replace`, nor `remove` nor `lower_bound` nor `upper_bound` nor `min_element` nor any of the container-specific algorithms. The only ones that do are the very very simple ones. None of the algorithms you told me where "non-trivial" or "worth my time" apply here. So again - what's the point of me creating my own iterators for my own (non-trivial, non-wrapper) (in other words - needs a getter and a setter) container? What do I gain if I can only use the non-container functions anyway?
&gt; Again, you're showing me the use of &lt;algorithm&gt; for an STL class. Sure, it works for STL classes. I am showing how to implement a bitvector. I used `std::vector` in the example but the same applies to use a pointer to memory: struct bitvector { char * data; int size; int count() const { return std::accumulate(data, data + size, 0, [](int n, char x) { return n + charbits[x]; }); } }; You can use STL algorithms on other things besides the provided containers. &gt; And specifically in "bitvector" - I actually can't create container-conforming-iterators. You can still create iterators that can be used for many algorithms such as `for_each` and range-for loops as well. Not everything is required to be a `ForwardIterator` in C++.
&gt; only work on vectors (arrays?) in an efficient way. So why are they in the "general" algorithm section rather than in the "vector" section as a member function? They work on any container including `std::list`, `std::array`, and `std::deque`. &gt; You keep claiming these are general algorithms. Maybe we use the word differently Yes, you probably should go read Stephanov's Elements Of Programming and From Mathematics To Generic Programming to get a better understanding how generic algorithms work in general.
they don't work on deque. Well, technically it does (when deque is sorted, so you use it as a vector and not as a queue), but technically it also works on std::set. It just doesn't make sense. Also, you keep pumping them and then keep telling me I should just use InputIterator which doesn't work with them - so you try to have it both ways: saying these are general algorithms that are worth me making an iterator for my class AND that I should make iterators for my class that don't work with these algorithms. In other words - you keep preaching without thinking or listening. You completely dismiss me and claim to know and understand my needs and design decisions without for a second entertaining the idea I might know what I'm talking about. I might have the decades of experience programming resource-critical code in C++ and that I have some knowledge that maybe you don't and know maybe better than you what it is that **I** need. And that maybe I'm not stupid - maybe I understand all these things, but also know that in some cases (most cases I've worked with) creating iterators or trying to force the use of &lt;algorithm&gt; is bad for me and my code. Maybe, just *maybe* I know what I'm talking about in regard to my design needs.
&gt; Well, technically it does (when deque is sorted, so you use it as a vector and not as a queue) It has to be sorted whether its a vector or a deque. &gt; Also, you keep pumping them and then keep telling me I should just use InputIterator which doesn't work with them I never said use an `InputIterator` with `lower_bound`. &gt; In other words - you keep preaching without thinking or listening. But you are not wanting to listen and learn from very smart people(not me) who have lots of experience working on generic programming *and* performance critical code. &gt; trying to force the use of &lt;algorithm&gt; is bad for me and my code. Perhaps &lt;algorithm&gt; is not the best, but then you use raw for loops which is even worse.
&gt; It has to be sorted whether its a vector or a deque. yes, but it can make sense to sort a vector. Not a queue. &gt; I never said use an InputIterator with lower_bound. Do you even try to listen? Or are you just trying to be right? No, you never told me to use them both together, but when i told you why I can't create an iterator - you told me I could create an `InputIterator`. When I asked why I should bother, since it won't give me anything useful - you told me that things like `lower_bound` are useful. You can't have it both ways. &gt; But you are not wanting to listen and learn from very smart people(not me) who have lots of experience working on generic programming and performance critical code. You mean, like I have literally decades of experience ONLY writing performance critical code in C++ as my ONLY job for - like I said, decades? Or like the original comment we are all replying to now - where the people behind Maxon explicitly write in their C++ style guide &gt; &gt; 2.1 External Libraries &gt; &gt; Do not use external libraries (e.g STL or BOOST) unless absolutely necessary. which is the reason we're even having this discussion? Or the original article we're even replying in, that specifically discusses why the current implementations of STL aren't good enough for performance programmers (in gaming specifically) - although they aren't specifically discussing iterators or &lt;algorithm&gt;. They do, however, discuss their aversion of lambda functions that are the core of the example you give for accumulate. &gt; but then you use raw for loops which is even worse. No... raw loops are so much better readability-wize. So much clearer - as the entire code is before your eyes. Sure - a function is always better than naked code for readability - but most of &lt;algorithm&gt; still has naked code, and is still technically almost exactly a loop, just slightly different (and less clear) semantics.
Maybe i'm in the wrong thread, but what would you use for game development? From simple use to things like galaxy/world generation? I understand the flaws of rand() and i'm willing to write a wrapper to simplify the use of more complex algorithms, but i dont know wich one is best suited for game development. Can you give me a general direction to look at? 
Not to be mean but is any of them an actual serious game dev? I know that at least 2 of them are not
or use a for loop. And BTW - in the accumulator example: better variable names won't help as the problem is with the variable order, nothing to do with the names. Better names would just make the issue less obvious. And this is simple code, yet will require very non-trivial debugging. The same code in a loop is virtually impossible to write badly. In this simple case - how could you create such a subtle bug with raw loops? Something that will be very hard to spot for a novice/intermediate programmer skimming over the code? And you mentioned debugger - how would a debugger fare with this accumulate bug vs. the for loop? (if you even can write this code with a bug in a for loop...)
So no actual game devs huh?
Ok, so coming from someone who doesn't have a very firm grasp of the subject matter to say the least.. How *would* I initialize a prng in c++11, assuming I care about a good distribution 
The iostream library is hardly something to look to as a model; people have been complaining about it for years because it's complex and difficult to learn all its dark corners, many of which shouldn't be used anyway, and the global iostream objects are really not appropriate for professional programs, etc. Personally I like the `&lt;random&gt;` much better; I don't agree that it requires you to remember all that much, and knowing `mt19937` after using it so many times really isn't a problem as far as I'm concerned (though being able to just use `default_random_engine` would be better), and the problems in terms of experts getting it 'wrong' are overstated, IMO. I certainly don't think adding a new global or thread_local object to the standard library is necessary. Yes people are a little too free with using 32-bit seeds, yes the seeding interface can be improved, and yes it there are better generators that can be added. I'm certainly looking forward to /u/ProfONeil putting a proposal forward to address these issues and I expect the C++ committee will be receptive to such ideas. There are also [problems](http://stackoverflow.com/questions/25668600/is-1-0-a-valid-output-from-stdgenerate-canonical) with the floating point distributions which I would like to see addressed as well. But in general I think the `&lt;random&gt;` library gets the basic pieces right and I don't see that any fundamental changes are necessary.
use code.c_str().
&gt; std::strncmp so what happens when your string is size 0 ?
well all true, but there is something about consistency !!! jumping to C libs should NOT be frivolously ! 
I don't get it ! Why string_view ? is it simply string but immutable? or is it like fixed_array where it can be allocated on the stack? if it is the formal it sounds great, couldnt care less for the first :)
Hi, I'm the developer of LibFlatArray. It's true that you could use LibFlatArray::soa_grid as an alternative for boost::multi_array, but that's not its intended use. The "soa" stands for Struct of Arrays. The library's main purpose is to store 1D/2D/3D arrays of objects (structs) in a "struct of arrays" format. These arrays comprise a single member of all objects. In fact we only use a single array, thereby eliminating the struct altogether. **Advantages:** kernels which iterate through such an array can be efficiently vectorized and address calculation is greatly simplified. Despite not actually storing objects, the library provides an object-oriented interface. **Drawback:** increased compile times (may jump from seconds to minutes).
Honest question: when would you care about this kind of thing? You can't use the mersenne twister for cryptography anyway, and for simulations or games a 32-bit seed should be enough, right?
How is this better? int count() const { return std::accumulate(data, data + size, 0, [](char x, int total) { return total + charbits[x]; }); } How does this make the bug more obvious? &gt; Its better to keep it simple and use an algorithm. If people feel the need to add if statements / breaks / early returns in the loops - how will algorithms help? Other than preventing them from doing it that is. So you're saying that algorithm is better because it gives you LESS options and makes writing code harder, so you'll write less code? I don't get it. Say I discover that I need an early return in the middle of my for loop - but instead of a for loop I used accumulate - how do I fix it? Concrete example from our current code: Say I need to count but only until some sort of event happens: size_t count(){ size_t res=0; for (size_t i=0;i&lt;size;++i){ if (res&amp;0xFF == data[i]) return res; res+=data[i]; } return res; } (I have no specific use case for this specific function, but you talked about early returns so I invented an example) Now - how would you even do this with `accumulate`? I really don't get your thought process here - you're basically saying "sometimes you need to do things that are complicated. I don't like that. If you use &lt;algorithm&gt;, you will not be able to do these things so it's better" But what if I actually need to do these things? &gt; Well it would be about the same in the debugger No it wouldn't - because it will jump around between functions and files, change contexts etc. It will actually be extremely difficult to debug &gt; but I usually read code before I start stepping through a debugger. In Ah, so you can debug it using a debugger if you don't need the debugger because you'll spot this subtle error by looking at the code because you're just so good and anyone who doesn't know intuitively the correct ordering doesn't deserve to program anyway, right? &gt; In which case the flipped parameters in std::accumulate would be obvious No, it really wouldn't. *maybe* if you're a seasoned programmer who used `accumulate` thousands of times you would find this immediately, but for novice programmers this bug would be really REALLY hard to find. ----------------------------- Wow, you are just so closed up to the possibility that other people have different experiences than you.
Yea, took me a while to get why the code wasn't working for me :/ I have gcc 4.8.2, which obviously (now) doesn't work here. However clang also doesn't work for me (version 3.4) - do you know which version of clang does work?
&gt; Fixed build failure on GNU Hurd Most important update
That works. With today’s Clang and GCC implementations, you can get away with a class that just provides the `generate` method and it’s quite easy. Unfortunately, if you want to be technically correct, you need to match the requirements for a _Seed Sequence_ given in the standard, which means you have some added baggage to implement.
I'll bet the article was reviewed by someone with a non-technical background (for grammar, good formatting, etc.) and was asking the author for clarification. The author didn't see that note before the doc was published.
What about the examples I give in the article? Do you find those unpersuasive?
I generally only prototype functions or classes if they are actually going to be consumed somewhere else or if I have a circular reference. Personally I believe it to be a waste of time to write prototypes for internal structures or functions. If it needs to become public and accessible from a header then at that time do so.
And it looks like it has some build issues. Specifically boost.variant.element_index depends on boost.type_traits but doesn't include the header file for it.
I usually get away without any "function prototypes" in cpp files because I order my functions in a way that I don't need'em. But I guess not everybody's doing it like this.
I'm not aware about GNU Hurd , what is it?
GNU project micro kernel, under development since before Linux. Didn't really take of for various reasons. It (the post you replied to) was a joke.
3.5 should be fine I guess
http://xkcd.com/554/
Are you kidding me? All your code to implement a mutex pool does not only make things more complicated but also slower. Because how do you make your mutex pool thread safe? Use a mutex yourself? Suddenly you find yourself having similar (easier) problems heap implementations have to face. And suddenly lock congestion can become a problem at yet another location, not even talking about memory locality. Now, what were the benefits again? I really don't understand why some here are so defensive of the STL, when it is clear that it is not fit for every situation. Simply put, there can be very sound reasons not to use the STL.
:(
Ah! Right :) Makes sense! :)
&gt; Because how do you make your mutex pool thread safe? Use a mutex yourself? One atomic test-and-set? The point of my post was to reject the notion that iterators *have* to be huge and unwieldy. Or have to hinder synchronisation. They don't, and for all their problems there's also a benefit, namely a uniform interface. Whether that's good for a particular problem or not depends on the exact characteristics of the problem. &gt; I really don't understand why some here are so defensive of the STL I don't understand why some here are so aggressively against it. I've conceded that the STL isn't the right tool for every job. But for someone whose code, or at least 90% of it, isn't real-time or resource critical, the STL is godsend. 
Have you tried with `-stdlib=libc++`?
I never even knew this existed outside of OSX. Works! Now I have to learn how to use regex, as my original code (from this article) only matches the entire string or nothing.
 * Official topic is https://groups.google.com/a/isocpp.org/forum/#!forum/reflection * Official requirements: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3814.html What I want is an instant RPC and JSON read/write capability for any class, so class Player { int id; std::string name; std::map&lt;int, std::string&gt; properties; void register(); }; template&lt;typename T&gt; struct RPCClient { // some magic here }; template&lt;typename T&gt; struct RPCServer { // some magic here }; template&lt;typename T&gt; void saveAsJson(const T&amp; t) { // some magic here } // and use as Player player; savaAsJson(player); RPCClient&lt;Player&gt; clientPlayer; clientPlayer.register();
Even libstdc++ 4.9 doesn't fully support C++11, yet.
totally hear you. We are examining our options here.
not having done much with templates, this has been a really fun example teasing apart how it works =)
An editor that writes two errors in one paragraph, while also missing other errors in the article?
I feel like this would be much more useful with some sort of C# style attribute system, since reflection just isn't always that useful without some kind of programmer input. Marking fields as transient (no saving), using methods as getters and setters, adding descriptions to fields, etc all need input from the programmer in some form or another. It is currently very possible to write a neat registration-based reflection system (with a few responsibilities laid on the programmer of course) that uses the language and operates at compile time. I have written such a system, and honestly I don't think I'd replace it with compile-time reflection the features they're proposing. 
Reflection sucks, there's too much hidden black magic behind it which goes against the spirit of C (which C++ is based on!). Reflection is a fucking disaster in C# and a leading cause of shitty and slow applications.
A global "default" random object comes with its own collection of problems (I worked on a codebase where someone basically did what you said initially - a global wrapper using mt19337). One is that (if you want to make it hard to use it wrongly) there must be no way to reseed, otherwise people will do it and destroy your nice properties. Another is how to deal with multithreaded programs (which is also a problem with std::cout/cerr). And a side note - "single seed for the entire program" gets tricky if you really mean program (across DLL boundaries). I also don't agree with 'random_device is a precious resource shared by the entire system' as a general statement ... how did you mean that? This sounds too close to the urandom/random argument (e.g. http://www.mail-archive.com/cryptography@randombit.net/msg04763.html). (And please don't use random_device for crossplatform crypto - e.g. gcc on windows used to (don't know if it still does) produce the same sequence of numbers from random_device on every program invocation).
no more testing on OS X?!?! 
Being able to enumerate class member data somehow would be good. Basically get member `std::type_info`, the member name as `const char*`, and a mechanism to transform their values to a particular type of choice, e.g.: `std::string`. Also, the ability to convert `enum` instances, or even cast into string is dearly lacking as well.
Enum value to string.
The biggest motivating example is writing a single serialization routine that can work with almost any type (whether it's for JSON or binary). This also extends to Howard's hash proposal - you could write a default hash implementation that would work with any type provided all it's member types were hashable as well. Obvious other common examples are the ability to iterate over enums regardless of value, writing generic enum serialization routines. A non-obvious example might be the ability to write enforcement of more ambiguous things like the 2nd argument is named "foo" for functions with long argument lists. Another use might enable you to introduce changes without a lot of up-front refactoring. For example, if a data structure may have a private member variable that is the lock, you might want to acquire it (some data structures may not have a lock). Yes it can be done more simply by exposing a function that just gives you the lock &amp; testing for the existence of the function via TMP: being able to use static reflection might lessen the amount of refactoring that needs to be done though. My personal favourite would be if it were possible to statically reflect on the input variables/types on a function. That could let you do things like disambiguate int8_t/uint8_t from char (so that if I were to serialize a char as ASCII or serialize it as a number because it was declared as int8_t/uint8_t).
&gt; This is a fine way to implement your functions in a novices single threaded program using the randint I showed: so you created global variable. I know you're against it, but you had to do it anyway. That's what I'm saying - if your design calls for global variables, then just make global variables. &gt; guidance is straightforward and easy to explain. But is it? In your particular example, the guidance will have to be "create just one of these objects I give you and make it global" (as you yourself did). So why not just have a global instance? &gt; Though to be honest I don't much see the value of using generic integral values for time even in python `time.time()` is extremely useful. It's constantly used to measure how long a piece of code took: T=time.time() do_something() T=time.time()-T print "do_something took %f seconds"%T That is the main use of `time.time()`, I think. And of `tic/toc`. About the "using random_device" part - that was assuming you're not going to make `randint` global (which you chose to do, even though I thought you were very much against that). If `randint` is global then indeed you're right - it isn't "the same as just using `random_device` without any engine". ---------------- OK, also I would like to see things your way. You said &gt; I probably wouldn't define the interfaces the way you did super. How would you define the interfaces? I just want one thing: assume that `cast_d6()` (or whatever you will use instead) and `cast_d20()` are completely separate. It's just a simulation of "two different, unrelated things that use random". Don't make both of them members of the same class or something like that. Keep the "d6" and "d20" randoms separate. Now how would you define the interface in a way that's consistent with your vision? 
Everything provided by Qt's moc and object model, without the restrictions on multiple inheritance (due to the obnoxious QObject) and templates :)
Could you please mention an example where a generic serialization exists? Usually classes have a meaning so the serialization shoudl represent this meaning. with your proposal we will just list the members of a class which has almost no interest 
I would love to see almost all the suggestions mentioned in this thread, as long as I don't have to pay for them if I don't use them! :)
I realize that parts of Boost have always been bloated, but god damn that graph is a bloated mess.
That's what I most miss in C++ from Java.
The graph shows every connection between the libraries related to the Endian or Sort Libraries. Note, that this is the maximum, the graph is generated with bcp, the boost tool for extracting parts out of boost. A lot of those connections are just there because the library might have an specialization for types of that other boost library, or supports it in some header. 
The graph shows every connection between the libraries related to the Endian or Sort Libraries. Note, that this is the maximum, the graph is generated with bcp, the boost tool for extracting parts out of boost. A lot of those connections are just there because the library might have an specialization for types of that other boost library, or supports it in some header.
[Can Qt's moc be replaced by C++ reflection? ](http://woboq.com/blog/reflection-in-cpp-and-qt-moc.html)
This is that what I need often too. And of course unnamed enum's need to be supported. Something like this may be? enum { EA,EB,EC }; reflect&lt;decltype(EA)&gt;::count; 
&gt; attribute system Yes to release full power of reflections we will need [[attribute]] system support. 
This method provides a uniform way of serializing both trivial and non-trivial data. With it you can write a template function that performs serialization on any class without virtual functions.
&gt; What is the benefit of this over simply copying the bytes of a struct? Well, if you are just copying the bytes of a `std::string` or a `std::vector` you are missing something...
I'll just leave a small note here, *reflection in C++14*: template &lt;typename Class, typename T&gt; using DataMember = std::pair&lt;char const*, T Class::*&gt;; class SomeClass { public: private: friend class Reflector; // entry point for reflection, only uses "reflector_access_to_attributes" template &lt;typename T&gt; static DataMember&lt;SomeClass, T&gt; make_member(char const* c, T SomeClass::* p) { return DataMember&lt;SomeClass, T&gt;(c, p); } static auto const&amp; reflector_access_to_attributes() { static auto const R = std::make_tuple( make_member("name", &amp;SomeClass::name), make_member("age", &amp;SomeClass::age) ); return R; } std::string name; int age; }; Writing the `Reflector` is left as an exercise to the reader; it's not that complicated, but it does involve twiddling with some meta-template programming. Similarly, coming up with a macro of the form `DEFINE_ATTRIBUTES((std::string) name, (int) age)` is also left as an exercise to the reader. It helps removing the boilerplate.
Yes, I understand what the graphs show. What I don't understand is what the goal of including the graphs in the blog post was.
"These two libraries are super cool, look how much everyone uses them?"
Yeah, run-time costs I'm really not that concerned about. Compile time checking/validation is more valuable.
I thought about this as well, even attempted to write my own thread pool, but what I ended up doing is roll my own `async` function that uses `std::packaged_task`s to return a non-blocking `std::future`s. The custom `async` function would either wrap libdispatch, or a `std::thread` launch, or some other lib, depending on platform. &gt; I must keep certain tasks on a single thread (all my calls to OpenGL, and to FMOD) As far as I know, you could dispatch GL commands across several threads, as long as you keep a mutex around the shared OpenGL context. At least this is possible on the Mac. Another alternative is to run a dedicated render thread, that just pops `std::packaged_task`s off a lock free queue. You could probably do something similar for FMOD. So a separate, dedicated `std::thread` instances with their own task queue for GL and FMOD respectively, and a custom `async` for everything else.
You're right - it might actually not be. But `random_device` isn't necessarily `/dev/urandom` (for example - on windows it never is ;) ) But the point is - the standard *treats it* as such. Otherwise you wouldn't mind people using it directly instead of as a seed. 
They mention there being a more complicated form of their RTTI model, are they actively using one, or are they just using the system described in that document?
I am stuck with `enum` enums. I also think that using `enum` to describe enumeration values is great for declaring your intent, i.e.: yes, this is an error code. Ideally, I'd like to see something like D does: http://ideone.com/8SkyvW D is often called a C++ done better, and in this case, it definitely is in my opinion (not so much for reading stdin to get a value, though). By the way, I wouldn't worry about performance/space requirements: after all, on any decent compiler, this metadata would only be generated when it's actually used 
 struct VersionedData : public std::serializeable { int m_version; MyData m_everythingElse; } ?
D has a lot of really nice features that I often miss in C++. By the way D compiler can parse C++ enum's.
I said in my post I was looking at Intel TBB, but I can't find any information about thread affinity, priorities, or on how to fire off tasks from a main thread, and manage the graph from the main thread. Any help with these resources would be appreciated!
Will do - my cursory google suggests that it's a little [high level](https://icnc.github.io/index.html?nav=about.html) for what I want. They talk about not caring about task based, or data based parallelism in that post. If you have any resources I'll gladly have a look. It seems that TBB is what I want, It just appears to be poorly documented.
Last time I looked at LLVM/Clang code I could see only this system. Why would they replace it with another one ?
&gt; it could be a function that returns a static object, or static members of a class, Those are also effectively global objects. If you can do it as a function, without global state, then fine. &gt; There already are a few of those in C++11 Indeed. It's unfortunate. Some other examples are `errno`, the global locales. If only we could go back and fix these. &gt; `high_resolution_clock`, `system_clock`, `steady_clock` Fortunately these don't need state in the standard library, and the state they do need is generally in hardware anyway.
You still haven't explained *why* having a global in the standard library is "entirely unacceptable". 
Maybe something like [HPX](https://github.com/STEllAR-GROUP/hpx).
Good points, thank you.
That's not the point. The point is that the standard considers `random_device` as a random source you should use very stingingly and as little as possible. If the only thing was that it's slightly slower, then the design would be "use `random_device` wherever you can spare the time, and only in very speed-critical code use one of the provided pRNGs" In other words - all the example of use of `distribution`s would use `random_device`, and the common wisdom would be "DON'T use the pRNGs unless you have PROVEN that `random_device` affects your running performance, which it seldom will" (or, of course, you need a seeded random) The example of `std::permute` would use `random_device` etc. In other words - `random_device` would be recommended as the default generator. But it isn't - because the *design* if `&lt;random&gt;` is that you should use it as little as possible. Doesn't matter if specific implementations don't need it - the "correct" usecase is to use it as little as possible.
Is there something similar for GCC?
https://gcc.gnu.org/onlinedocs/gcc/Precompiled-Headers.html
Yes: https://gcc.gnu.org/onlinedocs/gcc/Precompiled-Headers.html Basically you "compile" header file to precompiled one: gcc stdafx.h -o stdafx.h.gch Then every time you'll include stdafx.h, gcc will look if it has stdafx.h.gch next to it (by appending `.gch` extension). And if it has, it will load this precompiled header. Be sure to read carefuly in manual the conditions you must obey for this to work. 
Is there something similar for clang?
You have mentioned that your tasks have a few dependencies on each other. TBB and CnC use a declarative way to define dependencies which I found inconvenient. [GPC API](http://parallect.codeplex.com), on the other hand, is much more flexible and does not require defining dependency in advance. It uses Mutual Exclusion Queues and I/O Completion Ports (windows based).
Does this solve the problem? class Window { public: void Show(); bool Close(bool force_close = false); boost::signals2::signal&lt;void()&gt; show_signal; boost::signals2::signal&lt;bool(bool force_close)&gt; close_signal; }
I really can't take seriously any article written by a "pvs-studio" guy. I don't find him trustworthy as he generally states ignorance of a static analyzer already being present in Visual Studio, LLVM, GCC, Clang, etc and that his closed source product is always somehow better. All the articles tend to do is plug pvs-studio at least once, **and in this case, he's done it twice.** Very shameful Intel would publish such a click baity article writer.
&gt; /FI It says as much in the article as well.
The [POCO libraries](http://pocoproject.org/documentation/index.html) make threading pretty easy. [Here's the thread presentation](http://pocoproject.org/slides/130-Threads.pdf), the Task functions are about 3/4 the way down. I can't comment about how good the performance would be. 
It's good that you're keeping performance in mind, but I think you may be too focused on optimization too soon. I would recommend you start off with a simple implementation that just uses the standard library. Once you're happy with the design and you create an implementation that meets your requirements, do some profiling if you are unhappy with the performance when running a build that had suitable compiler optimizations enabled. Use the profiling results to determine what your first optimization should be. Premature optimization can sometimes lead to a needlessly complex codebase with little to no (or negative) benefit. 
&gt; That's not true, assuming you're not counting the kernel resources that back up descriptor 1. You only have one "screen" you can write to. The "screen" is the resource, you only have one of it (two if you consider stderr). If you create local version of `cout`, it will just be a wrapper to the same global resource. &gt; That's certainly one bad thing. This is why talking to you annoys me so much. You're just trying to be smug, and really not trying to explain yourself or convince me of your point of view. You're just trying to be "look at me. I know stuff that you obviously don't" If you were really trying to explain your view and not just being smug - you'd say something like: "That's certainly one bad thing. Another is..." What, do I have to pry your opinion out of you? Is it a secret? And about seeding - you're wrong there too. I'd explain why, but maybe I'll try being smug for once. Obviously you're not even trying to explain yourself, and obviously you're not even trying to understand what the other side might think. I'm going to disengage now. Good night!
Cool. It works "out of the box" in Unix-like systems, and MSVC. I had to do quite a bit of hacking to make it work in mingw/g++ ; apparently the Poco developers don't really care about that platform!
I've no interest in supporting it either. MSVC2013 and Clang 3.5 are my targets. I managed to get a simple task system working with TBB, so I may not be going for POCO just yet, I'll keep an open mind to it though.
Many lines doesn't indicate anything. One can divide a library up as fine as per header, and get many many lines, or amalgamate everything into one module and get one line. 
&gt; even attempted to write my own thread pool Thread pools [turned out to be even easier in C++11 than I would have initially suspected](https://gist.github.com/jrandom/08048c79ce0c752e9160). :) Granted, that's a pretty minimal system and requires that the task lambda handle all input/output. I couldn't figure out how to add variadic parameters to `Add_Task()` and associated subsystems (some problem with the `std::function` template or something), but I get by fine with the all-lambda approach. I've been using it [to drive parallel genetic mixing simulations](https://gist.github.com/jrandom/14695d3de8a9f7340d01). Lots of fun with 12 cores (24 hyperthreads). If you took that code and added a queue (and condition variable) for each individual worker thread, a priority system probably wouldn't be too hard to wire in.
When I worked on my thread pool implementation, I ran into problems dealing with tasks that would stall worker threads, I also had to resolve live locks between multiple tasks, deal with work stealing, and so forth. I simply didn't have the patience nor the skill to resolve some of these issues. At the end of the day, all I needed is concurrency for a bunch of unrelated jobs, so a custom `async` did the trick. It simplified task dispatching a lot, which I think was the most important thing. When I needed parallel processing, particularly compute work, I just threw the problem at the GPU.
so you mean "nearly everything people claim should be global shouldn't be"?
I complained about pvs people plugging their product, but as far as product plugs go, pvs people are angels imho. How do they display ignorance of competing products?
Nope :) only on OS X. I don't have regular access to a Linux box but I have a Mac and a wjn8 desktop at home. 
It goes beyond that, imagine: struct Person_v1 { std::string name; int age; }; struct Person_v2 { std::string lastname; std::string firstname; int age; }; If you want to deserialize a `Person_v1` in `Person_v2` you need custom logic to handle splitting `name` in its two constituents. No automated API can derive that custom logic for you. There are myriads of other such gotchas: - handling attribute name changes - handling attribute invariant changes - handling attribute deletion - handling attribute addition - handling attribute addition for non-default constructible attributes serialization is much harder than most people realize, especially as you try to strengthen the invariants of the classes you wish to (de)serialize.
Yes, but the problem is that you really need build system support to make it work reliably. This is really difficult with Autotools and doable (but not simple or 100% reliable) with CMake. For native cross-platform support you need to use [Meson](https://github.com/jpakkane/meson/wiki/Precompiled%20headers) or possibly [Premake](https://premake.github.io/).
I personally don't see the point of initializer_list. Real code hardly ever initializes lists like that because the data is rarely hardcoded; only toy examples work this way. The complexity and problems caused by this feature lead me to believe that it's addition to that language was a major mistake. 
Thanks! Sometimes such warnings can be awful. If you have several libraries you could easily get 100 of such messages
I agree with that. Also the lack of `constexpr`, or the fact that the size of the list is not encoded in the template arguments makes it hard to use it in the few cases where it makes sense (mostly linear algebra).
The one case I see time and time and time again in my codebase is for unit tests. Stacking up lists of hardcoded values to feed to functions as part of testing.
What they probably mean is that this ~0.01% never happens in the LLVM/Clang code so this is no need to handle them. 
If you need performance then you need to design project for this. For example use proper structure layout for SIMD. And of course writing serial code is not the same as writing parallel code. You need to design your project for this from the beginning. &gt; Premature optimization ... Unfortunately this will be used as excuse to write bad and slow code all too often. May be in hope to optimize this later, but then this never happens because it is too late, and the design do not allow this any more. 
I agree with /u/digitallis and /u/mojang_tommo. I find it a lot in both my unit tests, and in places in my code where I need a static look up table because I'm referencing a bunch of precalculated engineering values.
[Not much](https://code.google.com/p/waf/issues/detail?id=503), unfortunately.
If you are already using boost, you can try the boost asio library. Its io_service runs tasks given it. You could have two io_services running, one single threaded for OpenGL calls, and a second one running on multiple threads. Wrapping certain tasks in a strand will also ensure tasks passed to the strand never are run simultaneously on multiple threads, even though they are passed to an io_service running on multiple threads. See [pool threads](http://think-async.com/Asio/Recipes?skin=clean.nat,asio,pattern#A_thread_pool_for_executing_arbi).
2009 . There's a module in extras to link the pch, but it only works with GCC and clang, i may need to patch it for msvc.
I as well, but this is an intelligent approach :)
This is uniform initialization, not initializer lists. Initializer lists are of homogenous type. I don't have a problem with uniform initialization, except when combined with initializer lists. :-)
Whoops! Ah... okay, nevermind. *this must be my "learn at least one new thing every day" event for the day...*
But what does initializer_list give you that std::array doesn't? You always could initialize it statically for such a table. std::array&lt;int, 4&gt; a = {1, 2, 3, 4}; If you need it in a vector, it's one extra line. std::vector&lt;int&gt; v(a.begin(), a.end()); 
But precalculated tables were always possible before initializer_list using C arrays or std::array. std::array&lt;int, 4&gt; a = {1, 2, 3, 4}; All initializer list does is allow one to directly construct into something like vector instead of arrays only. Which I still say is super rare in real systems.
Well uh you *used* an initializer_list to create an array, which is what I do for the lookup tables :P So yeah, I basically use initializer_list for the sake of not having to manually push_back all values into a vector usually, I never had to pass it around as a parameter for example.
std::string isn't null terminated, is it? so using &amp;str[0] with functions that expect null terminated strings seems like a bad idea? Like notsure1235 said, use strncmp(str.c_str(), "XX", 2) instead?
Weird - debugger works fine here.
It was added specifically to fuck up uniform initialization syntax; a feature that had no downsides and could have been universally applicable... Until it strongly preferred constructors taking initializer lists. Everything in C++ has to be difficult to reason about and context sensitive. Otherwise it would be an intuitive language, and we can't have that.
"Uniform initialization syntax" has some other corner cases. Some examples: Can't use it to copy construct an aggregate. Can't use it to construct a void. 
You're lucky. It breaks for a *lot* of people. What version of OS X are you running? (I think the break happened with Mavericks and up.)
OSX Yosemite 10.10.3, with Qt Creator 3.3.1 (opensource) and Qt 5.4.1 The online installer kept hanging when my machine slept, so I ended up downloading the offline installer. Maybe try that?
Well, that's not a glitch at all. Mac has two C++ std libs installed there. What you do here, you basically specify that particular one you need and that's it. In fact, libc++ is the way to go on Mac, truth.
Thing is, you can use the config flag for C++11 and all works as expected. You only need this extra line when using C++14. ... or maybe that's *why* there's multiple libs installed? What's the other one?
I prefer to have the libraries as a part of the solution, unless they are very large (Boost). That way, I can just use library references within Visual Studio, and they will take care of using the right debug and release libraries. Solution properties -&gt; Common Properties -&gt; References -&gt; Add new reference.
&gt;Can't use it to copy construct an aggregate. Apparently the standard says that it is supposed to copy-construct an aggregate.
This appears to have been fixed in C++14, great news.
I would like to propose auto generated 'fields' method: struct S{ int a; std::string s; auto fields() = default; /* it's equivalent of: auto fields(){ return std::tie(a,s); } */ bool operator==(S const &amp;other){ return fields() == other.fields(); // similar for operator &lt; } };
Because `array` is an aggregate. It's basically just `struct array { T data[N]; }` so it can be initialised in that way.
I find this example quite unreadable. There's just too many quotes, and the `_a` doesn't help either. If anything, it should be like printf2("{h} {w}!", w = "world", h = "Hello"); . I know that's not possible with the current language, and your syntax is probably the best we can do. But I still think even in my example there's unnecessary repetition.
http://en.wikipedia.org/wiki/Named_parameter Because I had no idea what named parameters are, and your link doesn't really explain anything. The code is ugly. :) And by the looks of it, the parameter names are evaluated at run-time (they are just argvars), whereas most languages that support named parameters natively evaluate them during compilation. How is this related to C++ 14?
For CMake there is a [third-party module](https://github.com/sakra/cotire).
It is possible but still ugly :) consexpr auto w = "w"_a; consexpr auto h = "h"_a; printf2("{h} {w}!", w = "world", h = "Hello");
Did you see readme? I put exactly same link there, but in fact it may be difficult to see. Implementation is based on constexprs and overloaded resolution so both Clang and GCC are able to even inline calls to variadic functions like 'make_widget'. Following code: template &lt;class... T&gt; Widget make_widget(T&amp;&amp;... args){ Widget w; w.width = selector("width"_a = 10, std::forward&lt;T&gt;(args)...); w.height = selector("height"_a = w.width, std::forward&lt;T&gt;(args)...); return w; } int main(){ Widget w = make_widget("width"_a = 123, "height"_a = 10.f); // rectangle assert(w.width == 123 &amp;&amp; w.height == 10); printf("%d\n", w.width); } was compiled to: .LC0: .string "%d\n" main: subq $8, %rsp movl $123, %edx movl $.LC0, %esi movl $1, %edi xorl %eax, %eax call __printf_chk xorl %eax, %eax addq $8, %rsp ret Checked with https://gcc.godbolt.org/
C++ is trying to not discriminate any user type from primitive types. Why array can be initialized with initiliazer_list and my vector class is not able? They should not differ. This is one of the most valuable reasons to use c++ for me.
"mutable" has a different definition in C++ (and is even a keyword). Mutatable objects are [objects that can *mutate*](http://en.wiktionary.org/wiki/mutatable) given a mutation rate. "mutable" is used for [C++ variables that can change inside a const object](http://en.cppreference.com/w/cpp/language/cv) (useful for values that have non-trivial calculation times and can be generated on demand), and for removing the 'const' modifier for lambda capture-by-reference variables.
ingenious, but for C++17 why don't we just push for a proper named-parameter syntax, e.g. `make_widget(width=&gt;10.f,height=&gt;10.f)` `make_widget(.width=10.f,.height=10.f)`or whatever Its' great that templates are so powerful but it doesn't mean we have to stretch them to everything. A proper feature will be better for compile times, and they'll be more user-friendly to setup
The other one's probably `libstdc++`, the one bundled with `gcc`.
I would much prefer this through (compile-time) reflection. No need to add more language rules if one of those reflection proposals will go through and we suddenly have a nearly identical library solution.
Awesome thanks! That is above and beyond, I didn't really expect actual example code.
I strongly recommend using sequential consistency (the default) unless you're an expert and you're absolutely certain that something weaker is correct. (Note that on x86/x64, SC is cheap.)
I will make that change, thanks for the tip. Is there somewhere that gives a brief explanation of the differences (other than one being allowed to fail)? Edit: When you say sequential consistency you mean compare_exchange_strong? 
Only in the context of passing it on but not storing in a variable or anything
Er, yeah, brain fart! Edited.
OK, that sounds good
The first two depend heavily on coders' experience. I would say it gives the freedom to be closer to the hardware, allowing faster speed and lower memory usage. 
I also agree with the punishment. 
Is not even ambiguous. There is only one length in std::string and that one is given by length and the very same value is given by size. I say, burn alive that heretic defiler of young minds!
This is so insane, how can you write such complicated things in CMake script and don't go crazy ? Have you thought about having the CMakeLists written in Python or Lua instead of parsing a new syntax from inside the CMake script ? I know that Kitware did some experiments with Lua some time ago, but sadly it was abandonned.
Bullshit, the instructor is wrong. The context is std::string, not some fairy tale string where unicorns shit rainbows.
who says I haven't gone crazy ;) I did look at the possibility of using python or lua. But Introducing a new dependency would suck (even though its not much) the main argument however is that interop with the cmake scope would be very complicated if not impossible and using another language would be a replacement for cmakescript which would be nice but incompatible with all existing cmake.
Oh. Wow! Didn't know about that one. Thanks! I'd much rather use boost's than my own. I'll still try to understand STL's comments and correct my own implementation, if nothing else than as a learning exercise. 
STL for C++ overlord!
Yes. Low level programming is not about ease of programming. It's about performance and reliability. Java is not the right tool for every job, nor is c++. Get out of the mindset of there being end all be all tools for things. There aren't. 
Yes, same guy. Retired from them though, I wrote c# code at a different company. 
I'm not sure why I'm responding to this troll, but generally C++ is still the best alternative if some of the following are true (among others): - You need direct access to the underlying hardware (i.e. you want to use specific processor features like SIMD, AES-NI, TSX, need to utilize GPU/coprocessor or other specialized hardware, or you are working in an embedded system) - Low latency is important (Java suffers from unpredictably long GC pauses when dealing with large heaps in long running programs) - this is important for applications such as high frequency trading, databases, gaming - High performance is important (you need precise control over memory layout of your objects - very hard to do in managed languages, or want to benefit from advanced compiler optimizations) - this is very important in HPC computing amongst other fields. - You need powerful abstraction facilities (arguably sometimes too powerful) - otherwise you could just use C - You need direct access to the underlying OS facilities i.e. Linux syscalls or the Win32 API *and* you need to work well on different OSs. I work on software that needs to support different versions of Windows, Linux, BSD, Solaris, etc. Granted, these may not be true of the common CRUD applications that form the bulk of the software development effort of startups and enterprises, but there is still a lot of extremely mission critical software that has these needs, so C+++ is not going away any time soon. And finally, from the perspective of a working programmer - ignoring business reasons or technical justification - writing C++ is fun. Sure, it can be extremely difficult/frustrating at times, but it is sure a hell of a lot more interesting than banging out AbstractFactoryFactories and autowiring Spring classes with huge XML files. 
Java is *not* better than C++. It could be argued (in my opinion wrongly) that C++ is straight-up better than Java, but most certainly not the other way around. That said, `friend`ship is probably not the best C++ feature to highlight in such a debate ;)
I'd be careful going around labeling people as "trolls" as I honestly did not intend on trolling. Sometimes I can get a little "rough" with my wording and overlook it until someone points it out. All I wanted were the reasons people still like coding in C++ for practical applications so thanks for that at least. Though I'm hesitant to buy into the claim that C++ can always provide a higher performance than Java. Sure it might be better all around in regards to latency and performance but that doesn't necessarily mean it's always going to better in those aspects.
Ok! I addressed the comma operator overload issue. I think I got the forwarding part correct. Is perfect forwarding of the tuple&lt;Ts..&gt; necessary? Also, the easiest way to accept l-values and r-values was to create two methods. I couldn't figure out how to combine them.. (Edit: Formatting) template&lt;typename T, typename F, std::size_t ...Is&gt; void apply_to_each_item(T&amp; t, F&amp; f, std::index_sequence&lt;Is...&gt;) { auto dummy = {0,((void)f(std::forward&lt;typename std::tuple_element&lt;Is,T&gt;::type&gt;(std::get&lt;Is&gt;(t))),0)... }; } template&lt;typename F, typename ...Ts&gt; void for_each_in_tuple(std::tuple&lt;Ts...&gt;&amp;&amp; t, F&amp;&amp; f){ apply_to_each_item(t,f,std::index_sequence_for&lt;Ts...&gt;()); } template&lt;typename F, typename ...Ts&gt; void for_each_in_tuple(std::tuple&lt;Ts...&gt;&amp; t, F&amp;&amp; f){ apply_to_each_item(t,f,std::index_sequence_for&lt;Ts...&gt;()); }
In the heart, C++ probably requires a greater understanding of programming than other languages (memory management, templates, ...). But **exactly this** is what C++ makes so extremely flexible and powerful (and popular!). There are C++ libraries and toolkits out there that use a well selected set of C++ features, thus making them easy to use. A good example is [Qt](http://en.wikipedia.org/wiki/Qt_%28software%29), its signal slot concept and introspection system, and most importantly its flexibility to integrate with languages such as JavaScript, QML. And it is - thanks to C++ - fast as hell.
Isn't `std::result_of` superfluous here? Wouldn't something like `using result_type = decltype(&amp;foo)();` be equivalent? I've thought of `result_of` and `decltype` to be roughly equivalent (there are some differences), on gcc I think `result_of` is even implemented in terms of `decltype`. I don't see why you would do `result_of&lt;decltype(something)&gt;`, `decltype` already gives you a type?
In this case yes. In the general case, no. `result_of` uses `INVOKE` semantics to get the result which is a bit more complicated than just regular `decltype`.
You might hate that, but those language package managers like gem have the huge advantage that they work cross-platform without much effort. Have you ever maintained a package for a linux distribution? If not, let me tell you: It's not necessarily hard, but it's really time-consuming. If you want your library or program to be available to people, you need to either package it for at least all of Debian, Fedora/RHEL, Arch etc., which all have completely different packaging systems and software versions, and somehow make it installable on Windows and OS X... **or** you package it once for pip, gem etc. and save many hours of work for crossplatform-packaging and testing for every version you want to release. I also prefer systems like pacman over anything else as a user, but I can understand developers who don't want to learn and keep packaging at least 10 different packages for the same tool.
 void circle::area() { double A = pi * radius * radius; return; } You are declaring a local variable A of type double, calculate something, store the result in the local (to the method!) variable. Then you return and A gets destroyed. Same thing in circumference. And in print you declare two variables, don't initialize them (so they hold an undefined value) and print them. That means you are printing random garbage from memory. Either you return the values from the methods by giving them a return type, e.g.: double area(); double Circle::area() { return pi * radius * radius; } Or I guess you could store the result in a member variable. EDIT: Also, in your example, you read a value into 'r', then you call area() as if 'radius' would be magically set to 'r' without you passing it over somehow? And you are including the 'cmath' header without using it? You can use the predefined Pi constant M_PI, or simply not include it. I don't think your problem is with classes, you should review the basics. Read about variables and functions.
&gt; Nonsenses. I have being working for many years in the back-end, and I never ever needed to know the number of code-points. Ah, sorry, now I know you never ever had this problem I begin to understand that so many other string APIs are just overengineerd as you are the ultimate reference... 😈
&gt; Don't act all high and mighty as if you're the only person around here that's used languages other than C++. Ah... I see... you are acting complety different 😈 Sorry, we won't agree on aech others positions - you do not accept my axioms, neither do i accept yours. So let's end it here!
Boost.Fusion is probably the most reinvented library because people don't know about it (with for_each being the algorithm that's most common). There's a lot more coolness there though like transform, fold, etc. it's great for writing generic code. What you're doing is still good practise though, because writing this stuff is hard so keep it up!
Thank you. I managed to correct the code.
Yea i agree i have a lot to work on. Thanks for your help.
Ok! Attempt #3! In addition to your comments, I added the (void) to guard against comma operator overloading and I added the `decay` which is necessary to compile. (I finally understood STL's comment!): template&lt;typename T, typename F, std::size_t ...Is&gt; void apply_to_each_item(T&amp;&amp; t, F&amp; f, std::index_sequence&lt;Is...&gt;) { [](...){}(((void)f(std::get&lt;Is&gt;(std::forward&lt;T&gt;(t))),0)...); } template&lt;class Tuple, class F&gt; void for_each_in_tuple(Tuple&amp;&amp; t, F f) { apply_to_each_item(std::forward&lt;Tuple&gt;(t), f, std::make_index_sequence&lt;std::tuple_size&lt;typename std::decay&lt;Tuple&gt;::type&gt;::value&gt;{}); }
&gt; Java doesn't have friend classes like C++. So there's that. Surely this is a joke? (EDIT: what I mean is - of all the many features that C++ has that Java does not, to concentrate on a tiny language feature like `friend` that has a reasonable equivalent in Java - package level access?)
&gt; Could have been coded with another language as well, No. Have you never stopped to wonder why _every_ browser and _every_ animation program and all the games that rely on high-powered graphics all use C++? It's because you can't get anywhere near the performance of C++ on any other language. &gt; You know what else was coded in C++? Internet Explorer. And you wonder why people are downvoting you!
And if you don't think you can create memory leaks in Java, try a loop that creates new instances of `java.lang.Thread` and then drops them on the floor. Turns out that threads never get garbage collected if they never get started...
`decltype(foo())`
"A bit more complicated" is the understatement of the century. INVOKE is the hardest thing I've implemented in C++.
As I said, I know basically nothing about Java. I know that friendship is a really tiny feature of C++, but it was one of the only two things I know for sure Java doesn't have. The other is that you can do either automatic or manual memory management in C++ (and do them at the same time, where some things are automatic and others are manual), which probably would've been a much better thing to say. Anyway, the reason it's important in this discussion that I know nothing about Java is because I can't really compare the two languages.
You're welcome! I still need to write up all the stuff we've done in the STL since CTP1 - there's so much it'll take me a couple of days at least. (The biggest thing is the &lt;functional&gt; rewrite, including C++17 invoke().)
Sounds to me like you're the one imposing a coding language superiority now doesn't it? C++ master race? And no I don't wonder why people are down-voting and frankly I don't give a crap. All I'm here for is the responses and answers.
* `using namespace std` is unnecessary. * `float` should be `T` since you've gone generic. * Assuming that `T` is default-constructible, you could avoid duplicating the call to `_Op` with a do-while loop. * `_Op` is a reserved identifier. * If you make BinaryOp the first template parameter, and add a default value for the corresponding function parameter, it enables the cleaner syntax `AtomicOp&lt;plus&gt;(foo, 42)` in addition to `AtomicOp(foo, 42, plus{});`. * `d` should probably have a non-deduced type, so that `T` is only deduced from the atomic parameter. Otherwise, calls like `AtomicOp(foo, 42, plus{})` will fail deduction if foo is e.g. `atomic&lt;double&gt;` or `atomic&lt;float&gt;`. Altogether [**DEMO**](http://melpon.org/wandbox/permlink/aRqqxVAFzWdB8y0w): template &lt;typename T&gt; struct identity { using type = T; }; template &lt;typename T&gt; using identity_t = typename identity&lt;T&gt;::type; template&lt;typename BinaryOp, typename T&gt; T AtomicOp(std::atomic&lt;T&gt; &amp;f, identity_t&lt;T&gt; const d, BinaryOp op = BinaryOp{}) { T old = f; T desired; do { desired = op(old, d); } while ( !f.compare_exchange_weak(old, desired) ); return desired; } 
If I had a choice for portable byte code to run in a garbage collected sandbox, I'd choose C# over Java. Reified generic types are much more powerful. Also, Java has been playing a game of catchup lately in the language features war.
You gave me a use case where it's OK to not allow reseeding. But why would you work not preventing it? Showing an example where the lack of a feature (reseeding) doesn't hurt isn't the same as showing why we have to remove that feature. I agree we have to keep the current features - they are good and very important and they should stay. I must be able to create my own independent random stream. But in addition - a global random stream is very important as well. What I would like to see is the local pRNGs being seeded from the global pRNG when you want them "randomly seeded", thus allowing a user to repeat an entire run by resetting the global pRNG to the same value ("at the beginning of main()") With the current implementation - if you want to debug a piece of code that uses many many different pRNG instances (from many many different libraries?) - you'll have a very hard time of it. Especially if the bug is rare - as you can't easily set up all the pRNGs when you want to repeat the run. In other words - instead of the best practice being using `random_device` to load your pRNG, I'd like to see the best practice being using some global pRNG to seed your local pRNGs, and that global pRNG would be seeded by `random_device` (or by a given value if you want to repeat a run)
Reverse Polish Notation calculator? It'd be a good way to implement a stack.
Are there solutions to problems?
You can always open a bug and propose a fix... Seriously, it feels really good to have one of your fixes incorporated into the standard or a library!
I bet you could get something to work, but I doubt it would solve the problem of a nested function call. :\
thanks, it was my school assignment:D
If this is not too big, I always recommend to do a programming language interpreter for a language of your own design (it can be as full-featured as you want it to be). You'll learn a lot and it looks cool in the portfolio.
Sure. Have you tried asking friends if there is a simple program they wish they had?
thanks, i will look into that. right now im building a language for a school assignment. grammer, parser etc. is it somewhat similar or more fun?
Stream video from a webcam connected to a raspberry pi or beaglebone. Process it in OpenCV on the embedded device and display the filtered live video in a web frame on a remote computer. Should be fun. Stretch goal: Add OpenCV's face recognition library to identity people in the video. Edit: Who would downvote this? I am writing this right now for my little robot drone project! It's good fun, relatively quick and there are plenty of examples to build from online!
that sounds awesome, i will look into it. why process it on the device and not on a computer?
Oh, I suppose you could process it either place. The embedded platform is good, because it has performance constraints, so you have to tweak the streaming parameters to make sure the video isn't laggy or jumpy. Those problems disappear if you process the stream on the PC. What fun would that be‽
:DD 
A lexer and a parser are of course the first step. But this is pretty much a solved problem. You don't need to write them from scratch - you can use a parser generator such as bison/yacc or ANTLR. Then for interpreter you will have to write a language runtime, where you will handle the flow control, memory management, type system, ... It can be a very ambitious project, but it can also be very simple. A RPN evaluator is technically a programming language interpreter albeit for a very simplistic and limited (non Turing complete) language of RPN expressions.
Those seem like great points. It is way more thought through than I need (I don't even really need anything other than float for now) but all of those things seem beneficial. What do you think of d actually being a const reference? Since atomics can't be copied, adding one atomic to another would not compile I think. 
Because layers of abstraction are always free?
I think that they meant that Java is at bottom a C++ application, so java can never be 'faster' in the sense that you could always just emulate the java VM running a java app as your C++ application and be at least just as fast. Not that that would be a good use of anyone's time...
Saying that Java could be faster than C++ is nonsensical - it would be equivalent to claiming C++ could be faster than assembly language.
is there any framework like spring for c++ i haven't been doing c++ for quite some time
&gt;What should it do? search your code base. Instead of a single line search query, have 2 fields. first field for keywords, and a second field to enter some ruby code or what gives so the searcher can do custom ranking in the search. &gt;Something like that will make my life easier in going through random code bases. So what's wrong with `grep` or `ack` with sort (and awk if the ranking thing is complex)? 
&gt;If this is not too big, I always recommend to do a programming language interpreter for a language of your own design (it can be as full-featured as you want it to be). &gt;You'll learn a lot and it looks cool in the portfolio. Nonono! Write a Forth. Everyone can put together a lexer-, parser-, attributed grammar and optimiser generator chain. But few do forth (or other stackies like ps)
I went through the CLRS Algorithms book and implemented them until I was done with interviews. https://github.com/thejohnfreeman/clrs
 AtomicOp&lt;plus&lt;&gt;&gt;(a, 5.0f);
I don't really understand why you are asking the compiler to make optimization without using optimization flag? All problems are solved with -O1, so what's the issue?
tldr: if you don't tell your compiler to optimize it won't optimize.
which might easily end up: strncmp(0,"XX",2) WTF is this then :) you are comparing apples with pears, PLZ use C++
1) you don't override allocation! you provide custom allocators, we are talking STL here, no? 2) in this case it is what you remove from the table, namely NULL PTR :) 3) how readable and secure is strncmp(str.c_str(), "XX", 2) compared to obj1 == obj2 ????
&gt;&gt; It got rejected again (having been proposed many times before). heh what a surprise opt in could use '=&gt;' in the declarations I guess, but I'm sure they'd have thought of that too
Who said anything about nullptr? A string of size 0 is the empty string, I.e. a pointer to '\0'. Can you pass nullptr to a function that expects a valid pointer? Sure, and it will do exactly what you would expect. Should you avoid using every function that can crash if you give it an invalid parameter?
Actually its the lexer's job to detect such errors.
all true? sorry for posting in wrong subreddit!
One example use that I'm missing in his thread: using reflection for an FFI - i.e. binding to an embedded scripting language without manually specifying method names and signatures or having an extra binding generation tool in your build process. Oh I'd *love* that!
So many `&amp;amp;` and `&amp;lt;` and `&amp;gt;`...
I use Code::Blocks with a library that uses this techniques in its headers, and it causes C::B to give the wrong tooltip help :( (when you mouse over a function name it gives a tooltip of the comment just before that function's declaration)
Sorry for that, already fixed:)
I'd rather see clever naming styles implemented directly in code, and making such comments redundant.
Eclipse CDT has one, I'm sure other IDEs do as well.
Is GCC 5.1 build for Windows available somewhere ? It would be also nice to be able to use GCC directly form Visual Studio just like [Clang](http://llvm.org/builds/). 
should be -std=gnu11ptr
It compiles because the 'g' is silent.
I for one is very thankful that you keep up with it at all. Your build is my preferred mingw on Windows. I try to keep some of my codebases compiling with both Visual Studio and GCC, although recently it has been more clang and mingw because I've been playing around with the C++14 constexpr stuff.
So they don't have any examples of two files in the same module sharing symbols. Does this essentially eliminate the need for header files in that case, or no? For example, let's say I have ClassA and ClassB in module M and ClassB has a ClassA data member. By simply putting "module M;" at the top of "class_b.cpp", does it automatically have access to ClassA or do I still to have "class_a.h" and explicitly include/import it?
Seems pretty simple to me : 5.1 New features 5.2 Bug fixes 5.3 Bug fixes 6.1 New features 6.2 Bug fixes 6.3 Bug fixes No more micro releases. 
This would be great to be able to test some of my code with new GCC 5.1. Thank you for the distro ! 
Why aren't they using semantic versioning? (note: 5.0/5.1 break the C++ ABI)
:P the same issue would exist in both languages. 
OK, thanks. If that is indeed the case, that'd be a huge paradigm shift. Hopefully more material is released with some more in-depth example cases.
I've got some projects that still use Signals instead of Signals2 because, apparently, Signals2 is incompatible with Intel C++. Is that still the case?
Or may be it is too clever ? 
Why would I want to use Go as a C++ developer ? Why not D ? Why not Rust ? :)
 std::vector&lt;someType&gt; myVector = createVector(...); Creating `myVector` here requires calling a constructor of `std::vector&lt;someType&gt;` that takes another `std::vector&lt;someType&gt;` (I removed the `auto` just to be clearer, but it's exactly the same). If you take a look at the [list of `std::vector` constructors](http://en.cppreference.com/w/cpp/container/vector/vector), you'll see that there are two choices here: vector( const vector&amp; other ); vector( vector&amp;&amp; other ); The first of these is called a copy constructor and takes a `const` reference to a `std::vector`. The second is called a move constructor and takes an rvalue reference to a `std::vector`. Somehow the compiler has to decide which of these to pick. This decision determines whether the object is being copied or moved. So how does the compiler decide? It all comes down to *value categories*. Every single expression (and subexpression) in C++ has a value category. They can be divided up into lvalue expressions and rvalue expressions. The value category of the expression that is being passed to the constructor determines whether the copy constructor or the move constructor will be chosen. In your case, `createVector(...)` is an rvalue expression, which means that `myVector` will be move constructed. Determining whether an expression is an lvalue or an rvalue can be tricky, but you basically just think of rvalues as representing temporary objects or values. In this way, we always move from something that we don't need any longer (which is good because it's a destructive operation). I recently wrote [an article describing a simple way to think about lvalues and rvalues](http://josephmansfield.uk/articles/lvalue-rvalue-metaphor.html) that might help.
I'm sorry, but I'm confused. There were two questions in the comment you answered and yes to one means no for the other. Which one gets your yes?
[Why not both?](http://www.outrightusa.org/joomla25/images/images/57237343.jpg) 
Codebase becomes unmaintainable? Blame the tools instead of those who are supposed to manage it. It's aaaaall C++'s fault. Don't argue. It is. 
In your example, it's very likely that it's neither copied nor moved, but constructed in place through RVO (return value optimization.) This is one special case where the compiler is specifically allowed to break the rules and not call a move or copy ctor at all. 
Wow, I really have no idea how I've not stumbled across your distro yet. It basically has all I want for my mingw needs, thank you very much for the effort you put into it! From some quick tests it looks like it's going to be my new distro of choice now. In general, thank you for all you've done (and are doing) for C++ in general. It is very much appreciated!
That doesn't matter. Why would it? This works because behind the scenes the caller passes a pointer that indicates where the return value will be stored, and the function can use that to construct the object there directly, bypassing the need to copy it or move it there, e.g. std::vector&lt;int&gt; make_vec(); void caller() { std::vector&lt;int&gt; ret = make_vec(); ... } std::vector&lt;int&gt; make_vec() { std::vector&lt;int&gt; vec; // default-construct into 'ret' vec.push_back(...); // modify 'ret' vec.insert(...); ... // etc return vec; // no-op, as vector is already at its destination } 
.0 is for development. So if you somehow end up with a GCC that identify itself as 6.0, you will know you have an unreleased development version possibly with some of the features that will end up in 6.1 and probably a whole lot of bugs.
I'd say so. Preview it on Google Books if you're unsure if it's what you're looking for.
6.0.0 for new features, 5.2.1 for bug fixes.
It is already obsolete, the correct way to do it post C++11 is to use anonymous namespaces.
I usually use: llvm.org/builds/ for any Windows builds, but it is rare that I use clang on Windows (there I am using mingw and Visual Studio). I did forget to mention that I am one of those dual booting to Linux guys. I do some of my development in Linux and there is where I use Clang (built from source which is somewhat easier to do than GCC) and the latest GCC available from Arch Linux.
That sounds like perhaps the worst possible approach to me. C++ is not Java. When you use C++ to do things "the Java way" then C++ is arguably just a very very bad Java. Learn modern C++. Accelerated C++ is not _too_ bad for that IMO. But C++ has changed a lot since then. And don't cling to Java baggage. 
GCC contains 7 language frontends, some very stable, and some experimental. And some of the languages comes in several variants, some tracking ongoing standards. Every feature version is likely to break some API or ABI somewhere in the collection. 
&gt; The core language of C++ has not changed much since '98 This couldn't be any less true. The way you code in C++11 and the way you code in C++98 is extremely different. I recommend reading _Effective Modern C++_ instead.
I recommend reading it. But I'm not entirely convinced it's a book suited to learn C++ from (coming from Java). Perhaps... AccC++ + EMC++ :)
http://visualgdb.com/toolchains/embedded You can but it builds Linux executables!
&gt;Perhaps the hardest and most frustrating bit was, to actually go through all the examples/exercises, especially the trivial ones which I knew I can solve in less then a dozen lines in python. That's just the normal dev time &lt;-&gt; efficiency tradeoff. It's all about picking the right tool for the job, I rarely use C/C++ unless I need to do number crunching or be as close to the metal as possible. 
statis has been "undeprecated" I believe. http://stackoverflow.com/questions/8460191/is-namespace-static-still-deprecated-in-c11
As /u/Rhomboid said, in my answer I have assumed that the compiler is not performing copy/move elision (which would be perfectly acceptable).
With C++11, lots of the common C++ wisdom changed, there are loads of new idioms. Some are clearly different (smartpointers), others are more subtile (move semantics), so I'd recommend more up-to-date introductions. But since I was a C++ guy before, I took a gradual transition to C++11, so I unfortunatley can't provide viable alternatives. I liked the videos from the Meeting C++ conference though. Another hint, try to figure out if yout next job uses C++98 or C++11, there are quite some companies which have legacy code tied to Visual Studio 2010 and therefore can't use C++11, in which case my musings above are clearly irrelevant.
I missed that one.
As long as you don't think that C style strings are better to teach than `std::string` (and similarly `malloc`d arrays are better than `std::vector`) teach pointers in whatever you care to. (They should come after references anyway)
It's always bad to try to think in one language and try to convert your thought to another. As you already know a structured language, I recommend to try a C++ book directly and not a Java to C++, because you will be introduce to some of the c++ concepts that doesn't exist or map from the ones existing in java. Even if you need C++98 for your job I think it's better today to learn C++11 before C++98. The C++11 "feels like a new language" If you want quick introduction to C++11 "Programming: Principles and Practice Using C++" if you need something more deep there is a nice list on SO http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list
I think there's a clear difference in teaching concepts and teaching development best practices. I believe it helps your C++ code a lot if you know, what the machine sees (the C-string a.k.a. char array). Same goes for plain arrays, a std::vector is clearly superior in production code, but ignorance of C-style arrays means ignorance to memory management issues, which in my opinion is an area, where C++ yields superior control compared to Java. If you absolutely don't want to care about your memory, changes are you don't want to use C++.
Can you and your puppets please stop spamming this subreddit? 
The following is true for many languages, but it will answer this specific question too. What you need to consider is: * Performance/hardware requirements This basically means, how fast do you need to run your code, and what hardware limitations and requirements are there? * Specific support (such as available libraries relevant to the task you are planning, etc.) It's nice if that specific physics library exists in a stable version for the language in question. * Flexibility Can you imagine and implement what you need in the language of choice? Usually the answer to this question is "yes" for all languages out there, but sometimes there are special cases where a certain language can perform some things that another can not. * Speed of development How fast do you need to develop your application? Do you need a quick script solution to a trivial problem, or are you in it for the long haul? Answering the questions above will give you a good hint of what language you need to use. There are more considerations to make, but the above ones are pretty important. In the end, it might be that you just need to write a quick Python script, or even a Windows batch file. Never limit your choices of programming language, as you'll lose so much effectivity. So, let me give you a few examples to give you a good idea of when you *could* choose C++ over Java, for instance. * Performance is a vital issue *and* you need fine-grained control of it. (you mentioned this yourself) * Hardware access is a must (this will always resort to a low-level language, in the worst case you'll be writing assembler) * You need a library that doesn't have a port to any other language. (A poor example could be the latest OpenSSL library, but you get my point) * You need full control of every aspect of your application - from memory access, to virtual function calls, cache memory fences, etc. This might tie in to performance, but doesn't neccesarily mean it has to. Now, let me do the opposite. When *could* you choose Java over C++? Note that I always write *could* and not *should*. * You are writing a multi-platform GUI application with no need for hardware support. * You need quick development times, quick deploy/rebuild times. * You want (relatively) consistent code behaviour across platforms without digging too deeply into compiler/standard library behaviour. * You want to use a managed memory environment. * You want a language that's easier to use. C++ usually means two things; *power* and *freedom*. You can really do *anything* in C++ - for better *and* for worse. Just because you can cut roses with a chainsaw, doesn't mean you should. The same goes the other way around. Just because you could cut down a tree with scissors doesn't mean you should. Finally, I've had major experience with two IDEs and like both. My main workhorse is of course Microsoft's Visual C++ (there is a free Express edition, if you are interested). I've also used a lot of Eclipse as well and found it competent enough. If I had to choose and could choose what platform to work on, I'd always choose Visual Studio as a personal preference.
They're not puppets, but I do think everybody either has some connection to Biicode or there are just plenty of people in Madrid who want to support them. The previous person you pointed out was a bit worse because they wrote their comment in a misleading way (as though they had no connection). Nonetheless, I don't think posting links to Biicode announcements is against the rules in any way (as is being done in this case), as long as they contribute to the subreddit in other ways.
Why do you think so? It seems to offer no tangible benefits over for example [nlohman's json](https://github.com/nlohmann/json), besides having speed which "can" be "comparable to strlen" (whatever that means). Instead with nlohman's json you get stl-like access, 100% code coverage, and almost native json object construction in c++, among other shiny things. Might sound harsh (sorry about that!) but just saying "this is the best yep definitely" is not really a useful comment: if that is in fact the case, I am truly curious about your reasons for saying so. Edit: Maybe I'm editing this prematurely, but I think it's the right thing to do. The reason I posted this response is because I thought the post I responded to was unconstructive. I'm not saying RapidJson is bad or fake in any way, I was just trying to give an example of (how I think) people should substantiate their claims when they are saying something is a "good" or "best" library (since there are many reasons why something might be good or bad - scroll down for a few examples).
Indeed. The cleverest comments have 0 characters because the code is self-explanatory
Another one that is held in high regard is "Effective modern C++" by Scott Myers, and it was specifically written to convey good practices with the C++ standards. There are quite a few sample chapters available, just have a look if it's to your liking...
One more note about `const`: if you encounter `int const&amp;` or `int const*`it means that **you** cannot change the value (without cast) using this reference or pointer, but others can. Consider [this example](http://coliru.stacked-crooked.com/a/36d7681705413ee8): #include &lt;iostream&gt; static int a = 1; void mutate(){ a = 2; } void fun(int const&amp; const_ref_a){ // prints 1 std::cout &lt;&lt; const_ref_a &lt;&lt; std::endl; mutate(); // prints 2 // it changed even it is const reference (reference to const int) std::cout &lt;&lt; const_ref_a &lt;&lt; std::endl; } int main(){ fun(a); }
Thanks for posting link for another C++11 JSON library. But it does not work with VS 2012, 2013 and even not with VS2015, this makes it simple unusable. It is also heavily dependent on STL. Of course for many C++ developers this is not a problem at all. &gt; RapidJSON is self-contained. It does not depend on external libraries such as BOOST. It even does not depend on STL. Beside all the other advantages of RapidJSON this one is also important and very rare advantage. It also work with Visual Studio 2012, 2013 that are still used. Of course this was my personal opinion.
&gt;besides having speed which "can" be "comparable to strlen" (whatever that means) It means the dude fussed with allocators and SIMD instructions so that it's the fastest parser around. It's seriously fast. Simple Json parsers have the bad tendency to do a lot of small allocations which degrades performance significantly. It is truly the best and it will be an order of magnitude faster at parsing json than nlohman's impl. I don't even have to run a benchmark. Just looking at the code I can tell you that all the values are copied, there's no allocation buffering, and there's no SIMD specialization. 
That's too bad. I was hoping this would be a viable in-project package manager, much like how conventional language package silos function (like npm, cargo, dub, etc.) Touching the OS, and going superuser... that's no good. I'm reminded of the worst offenders on CPAN...
More biicode spam again. I am sick of hearing about this over and over again. Your website is pretty. Good job.
Could you mention all the other advantages, for those of us who don't mind boost and don't use VS?
That's a very interesting claim which I'd like to see backed by benchmarks, preferably by the author. Nevertheless you're probably right, so I guess it's one of the reasons why you would pick this one over another json lib.
Well I want/need C++11 and even C++14 but I can not use all of it. 
Well it is also Fast! :) And do not uses that much memory. This is also problems that I have with some Boost libraries, they are slow and waste a lot of memory. 
Only found this one: https://www.biicode.com/david/david/qt/master/1/bii_post_process_hook.py
There's already a list of several [here](https://miloyip.github.io/rapidjson/md_doc_performance.html) Also, why does the author have to do one for nlohman's? If you want benchmarks against it, knock yourself out.
Here's my main gripe with this json library. From the documentation: &gt; Other aspects were not so important to us: &gt; Memory efficiency &gt; Speed &gt; Rigorous Unicode compliance Well, then what's the point? Why would I want to use a library that treats performance and memory efficiency as "not important". One of the reasons we use C++ is exactly for performance and explicit control of memory.
&gt; That's why they use the Copy-Paste method ... Unfortunately, there is often no better alternative to be found. Learning to effectively use templates and function pointers has virtually eliminated any repetitiveness in the code I write. Any time I feel that itch to copy/paste a chunk of code and make minor tweaks to it, I stop myself and think very carefully about whether there's an alternative, and there *almost* always is. I think to say that there's *often* no better alternative is to disregard the many powerful features available in C++ and exonerate people from violating the [DRY Principle](http://en.wikipedia.org/wiki/Don%27t_repeat_yourself). Then again, the examples given are where people are copy/pasting single lines of code. At that point, it really seems like those programmers need to work on their typing skills or use an IDE with autocomplete. In the amount of time that would be spent navigating the cursor to the specific thing that needs to be changed and then modifying it, they should just be able to type it all out fresh.
Sometimes performance and memory efficiency are not top requirements, and in that case you can trade them for usability and maintainability. However I agree with you that if speed is a concern you're probably better off not picking nlohmann's json. On the other hand, RapidJson *might* also not be a good pick, since if you have strict performance and efficiency requirements RapidJson might not be fast enough for your specific case. Or maybe it is. It just depends.
Does anyone have an updated version of Pete Goodliffe's script that built ready to use OS X and iOS frameworks from Boost source? Last version that worked for me with the original script was 1.4something, then something broke. I think the script should be part of the official Boost distribution.
Seriously, not *all* the examples were this bad, but if you have something like this double max4 = 0.0; double max5 = 0.0; double max6 = 0.0; double max7 = 0.0; // etc. in your code, then WTF.
I swear I've seen this article before, yet this says it was posted yesterday...Am I going crazy here?
The preprocessor has its place in writing code, but only for a person who knows what he's playing with. 
Eh, yeah, I would only use preprocessor macros as a last resort, or if I think there would be a *huge* payoff from using them. I think the key to keeping C++ code DRY is clever use of templates. Templates are weird and tricky when you're first learning them, but the value of competent template usage is enormous. I've also found the new std::function and lambdas in C++11 to be extremely useful at making chunks of code extra reusable.
It seems like a good way to handle this (that still makes me a bit nervous) is by reducing the noise in the repeated part. #include &lt;iostream&gt; int varX = 0; int varY = 0; int varZ = 0; const int srcX = 1; const int srcY = 2; const int srcZ = 3; int main() { #define SET(coord) var##coord = src##coord; SET(X); SET(Y); SET(Z); #undef SET std::cout &lt;&lt; varX &lt;&lt; varY &lt;&lt; varZ &lt;&lt; std::endl; } Now, if only C had decent macro hygiene...
&gt; The STANDARD template library? retarded. No it is not. Some developers simple can not really use whole STL. At least the part that can throw exception. One example are game developers, but there are more in other fields. Imagine a program that is build from many independent DLL's/Dylibs any of them can be compiled with different compiler and possible use different incompatible STL implementation. Where exception will not be used. Do you really want to use STL containers to pass data from one to another ? ABI is only one not solved STL problems. 
This, and I think they published a paper as well... I remember reading something a week ago or so...
(Maybe) because this version only brings support for full C++11 in the library. They seem to want to wait for this switch until later.
Can this biicode spam please end? At this point, I don't care how cool it is. I refuse to use it out of spite. 
Macros would introduce more problems. Better to just use a custom function. You could even have one that takes all of them, either as an array, put them in a coordinate structure or just as 3 separate primitives.
Is it true that "Tour of C++" is just some chapters from "The C++ Programming Language"?
[Speaking of his hair](https://youtu.be/wQxj20X-tIU?t=374)...
Not really. It presents C++ from the point of view of C++11, using modern C++ style and safe approaches to coding instead of C style coding. It is targeted to developers moving to C++ or that have lost touch with the language and want to refresh themselves about what correct modern practices in C++ are being used. Maybe for those that already grok "The C++ Programming Language" might not be so interesting, but I did enjoy reading it.
Well, you might perhaps want to use some macros also in Modern C++ code, or?
We don't like macros in C++ besides header guards and workarounds for language features. They are invisible to the compiler and can change change the meaning of any character. The idea is to only reach for macros if the following features cannot be used for the same purpose: - inline functions - constexpr - templates meta-programming - compile time reflection (if it happens to be accepted into the standard)) - user defined literals
Well, that as well, but also the language in general. I haven't used boost while going through the book, but I did some experiments later. One can hardly argue that it is quicker to write in C/Cpp than in a interpreted language such as python (not talking about the performance, obviously). Even when considering simple things, like class and inheritance definition, or operator overloading. For someone who was used to most of these things be taken cared of, they might seem a bit "tedious" at first.
&gt; Even when considering simple things, like class and inheritance definition, or operator overloading in C++, class is class whatever {members here}; in Python, class is class whatever: members here Inheritance is : class derived : public base (in C++) class derived(base) (in Python) (Similar situation for operator overloading; BTW, to me operator overloading in Python is actually quite ugly due to the \_\_functionname\_\_ convention for overloaded functions) There's no difference in line count, which is what you mentioned ("dozen lines"), and I reacted to. You rather seem to be complaining that you need to type longer due to type information? Well, yes, it's a static/dynamic typing trade off. But that's largely not related to line number.
Seems like a lot of work IMO. I would just go for something like this: #define FIELDS(F) F(VISIBLE) F(HIDDEN) F(FROZEN) #define AS_ENUM(X) X, #define AS_STRING(X) #X, #define AS_REVERSE_MAP(X) {#X, GameObjectState::X}, enum class GameObjectState { FIELDS(AS_ENUM) }; char const* const stateStrings[] = {FIELDS(AS_STRING)}; std::unordered_map&lt;std::string, GameObjectState&gt; const reverseMap = { FIELDS(AS_REVERSE_MAP) };
Excellent, balanced article; thanks for posting!
Did you forget to write the body of your post?
Well, of course it presents C++11, but TC++PL 4th does it too. I'm talking about the content of the first part of TC++PL. Look at the TOC: http://www.stroustrup.com/4thContents.html Is it really that part literally "A Tour of C++"?
I like the solution, it's short and concise, but wouldn't fit my problem. And the amount of work is actually much less for implementing programmers in my example. As for performance, it's hard to tell without measuring if an unordered_map would actually beat a linear search for only a handful of items. I'd bet money on that a linear search would win if the number of states are few, but you read a lot of files, though. If you are saying that a better-looking cleaner solution costs more lines to write, then I can only answer that amount of lines is not my biggest issue. I was looking for a solution that would in-code look very much like a typical enum declaration. Apart from that, I needed a controlled way of allocating memory for any extra strings that needed to be generated. My solution, for instance, only allocates memory once for the conversion table. Also, in my solution, you see code that is easily interpretable from normal C++ enum code, which the above isn't. Finally, it's a single-line solution that works very well with Visual studio's autocompletion, and always finds the correct method. SomeGameObject::GameObjectState will now show the enum and the conversion function, which is important. So again, I was looking for a clean syntax that was uncomplicated both to maintain, but also to use in a large team of programmers. Which I believe this is, in both declaration and use (both provided below): class SomeGameObject { public: STRINGIFIED_STATIC_ENUM(GameObjectState, VISIBLE, HIDDEN, FROZEN) // Pretty enough // Other data stuff here... }; auto state = SomeGameObject::GameObjectStateFromString("VISIBLE); Also, keep in mind my solution also covers the offset case, which makes it a little more bloated than you might need, but those lines are easily removed.
This seems very nice but do you have any more information than what MS is saying? I'm currently trying to learn C++ using SDL and OpenGL THEN when I get a little more info in my head I want to compile that to android (but have the ability to test the code on my PC and later learn to build for other platforms.) (its like I do anything to not learn too much Java.) Edit: ex. any independent benchmarking done ?
Erase .js extension from link, otherwise it links to some unreadable js code, not your cpp code. Format your code properly, eliminate typos, remove commented out pieces, split your functions in such way, that every function does just one thing. And you will find error in no time without help of other people. Don't think i'm ranting about lazy students, please. Code formatting, proper variable names, etc. is really important thing, especially for students - around 70% head-bashing situations with homework was about some really obvious mistakes, that was hiding under piles of code mess. Once mess was removed bug was obvious. 
Thanks!
Is iOS supported yet? The information on that page is confusing.
or you could just int var[3] = {0}; int src[3] = {1, 2, 3}; int main() { for(int i=0; i&lt;3; i++) var[i] = src[i]; } which is much easier to reason about
In my experience "clean up once EVERYTHING is running" doesn't work quite well, at least in complex systems. Cleaning up huge pile of garbage, especially if it's not only commented out pieces, but whole classes and files is very tedious, error-prone process. Cleaning should be done in small, frequent steps along with implementing things. This way you will never end in situation when something doesn't quite work and there is spaghetti, garbage and dead code all over the place. * Make small change. * Make sure it works and doesn't break anything. * Refactor / cleanup * Commit * goto 1. After big thing is done, works and code is clean do cleanup of your commit history and merge to main branch. It may sound like too much struggle for homework, but if you're planning to be a programmer it's better to make such thing a habit asap.
(ง ͠° ͟ل͜ ͡°)ง
Microsoft manages to offer better NDK support than Google itself!
Kaiser is an adjunct professor at my university. He teaches intro to C++. Learning C++ from him was special. 
Google has dropped the ball for those of us that use the NDK. This is just the support of the setup that many of us are now using since Eclipse ADT/CDT was put to sleep.
Completely noobish question - how different is using this platform vs Java application development for Android? Aside from it being cross-platform that is.
I'm looking forward to John Lakos' slides so I can see them in technicolou?r!
The motivation behind creating this library was that there was no proper C++ implementation of mustache that I could find when I started. In a strange coincidence, kainjow started to work on a [similar project](https://github.com/kainjow/Mustache) at almost exactly the same time as me. Nevertheless I finished mine as well, hoping it could be useful for someone.
They're planning on supporting iOS in "the next release" but it's difficult to tell if it's the next pre-release, the next Visual Studio product release, or whatever. Their product manager was talking about it on one of their YouTube channels. I'll try to find it if you care. 
Right, just want to make clear that by no means I want to start some silly language battle, since we al know which one is what for, but doing the equivalent in C++ takes more then 3 lines. class Whatever(B): def __init__(self, myarg, herarg={'do':lambda c: pow(c)}, *args, **kwargs): self.something = kwargs.get('some', None)
It's not a separate platform for Android, it's using the existing Android NDK platform. But instead of using Eclipse with the NDK you can now use Visual Studio which many believe has a better editor and debugger.
It's pretty crazy isn't it? I was so surprised to learn of the lack of NDK support in Android Studio.
Using Eclipse for Android is also deprecated with no real replacement for NDK stuff.
From the whole atitude the Android team shows against the NDK users in terms of support and Google IO presentations, I can only concluded that they were forced by management to offer it.
When comparing the C and C++ developer experience offered by the iOS and WP 8.x SDKs, with the current state of the NDK tooling one cannot do anything else other than wonder where are all those elite programmers Google is supposed to hire.
I've asked Ankit to comment.
Please note that \_Leading\_underscore\_capital identifiers like \_UTIL\_ENUM\_H\_ are reserved exclusively for use by the compiler and standard library. Having toolset implementers use \_Ugly identifiers and everyone else use Pretty identifiers keeps everyone from stepping on each other's toes.
Thanks STL!
&gt; auto priority_view = vector&lt;job const*&gt;{}; This is exactly the sort of trendy coding style that in 5 years people will look at and say "Good God, what were we thinking back then..." 
I guess they don't really want you to write Android code in native code that cannot be easily migrated when they decide to port their VM to say Intel, Power PC or whatever.
Just put *APP_ABI := all* in the *Application.mk*, don't use Assembly, problem solved, or add PNaCl support to the NDK. Writing portable code across multiple processors is a solved problem.
&gt; What would the new namespace be? I really don't want to be writing `std::concepts::` instead of `std::` in new code. :/ That hasn't been discussed yet, but I would expect something like `std::v2`, and some way to opt into `v2` as the default with `v1` available in `std::v1`. There are ABI issues to work out, but that's the direction I'm thinking. That's *my opinion*, not the committee's. &gt; C++17 is going to have concepts in the language, and will probably have concepts in the library, right? Well, having recently spoken with some folks on the committee, it seems that (a) we want concepts in C++17, and (b) there's little appetite for delivering the language feature without the corresponding changes in the library. There will be a big push by some people to get concepts/range library support baked in time for C++17. My Magic-8 ball says, "Reply hazy try again."
You want wider adoption. Others here want less advertising. Those are incompatible for a new project like biicode.
Thank you, Perfect timing for that information. I'm still learning the setup so I haven't started coding my application over. (Perfect timing as in before I had messed it up.) 
wait, question... if you're targeting NDK, does that even use ART? Or does it not have a runtime at all, and just runs natively? If it just runs natively, how good is compatibility with NDK? At least with the ART you know you're good to go on pretty much every device... do you sacrifice portability by using Visual Studio to target NDK?
Yikes
Run time generated (or they could just be static variables in the .dll so it wouldn't be a problem). I'm more interested in persistently storing values but not having an external file.
Great minds think alike! :)
If it were only this then we'd be fine.
Are you looking to 'fingerprint' your binary? Ì have done something like that before by using a binary search and replace. Just have the dummy value in your source code that you can replace with the real value later. 
&gt; possibly overcoming the hurdle of the OS preventing the file from being written to. That's not a small hurdle, at least on Windows. You have to get into really tacky hacks, like embedding a copy of a separate updater executable in your main executable, then writing a copy of the updater executable out to a temporary directory, running it, having it wait for the main executable to terminate, then modifying the main executable, then itself terminating, optionally relaunching the main executable. Except that this leaves a copy of the updater executable laying around in the temporary directory. You can ask the operating system to delete it on the next reboot, but that may not be for a long time. This is a general problem that uninstallers also face. People have come up with [a number of techniques for dealing with this problem](http://www.catch22.net/tuts/self-deleting-executables) but it's safe to characterize them all as extremely ugly hacks. As an aside, you can freely append any arbitrary data to an executable and it will still load and run normally. This is how self-extracting zip files work: you write a small stub extractor and then concatenate the actual zip file to the end of that, and distribute the result. Since the zip file format stores a header at the end of the file (and that header contains offsets relative to the end rather than to the beginning of the .zip file), the stub merely opens itself as a zip file, which involves seeking to the end to find the header there, and then extracting as normal. But you can use this technique for arbitrary data of any kind, for example you might make up your own format, e.g. `executable + &lt;custom stuff&gt; + &lt;dword containing length of custom stuff&gt;`. Reading this means seeking to the end minus 4 bytes, reading a length, then seeking to the end minus 4 minus that length, then reading or writing data starting at that position. You can use this instead of trying to parse the PE headers to find the .data section. It might even eliminate the problem of not being able to modify an in-use executable, because this portion of the file will not be mapped into memory. In general though, this plan sounds horrid. Anybody interested in copying your program will be able to easily subvert this, and all it takes is one such person with a modicum of technical savvy to figure it out for the rest of them. 
ART only handles Java on Android. Native libraries are compiled before packaging and executed natively, so they are independent of ART.
Not that I would ever advocate actually using it, but that's exactly what the Registry is for.
How do you write to a currently opened binary? I thought Windows wouldn't allow you to do that.
Surely there are more reasons for picking c++ besides performance. And no, I don't know something faster. These things were not the things I was talking about, please read my edited original post above. I merely picked nlohmanns json because I happen to like it and can phrase nicely why I like it. I didn't mean to state that nlohmanns json trumps all. 
That sounds like a good idea for static binaries instead of recompiling them, although I want to write run time data as well.
&gt; That's not a small hurdle, at least on Windows. Yup. Add to that that all of these techniques will probably trigger an AV program and alert the user.
Sorry but the right answer is to not use hacks and use OS provided APIs to do content rights management properly om a separate data file. For e.g. if you want to check if your binary is tampered with, most OSes provide a way to do that. If you want to unlock features, OSes provide a way to do that. Once you have this, you can have a separate datafile that you can read/write and ensure only you can, since your main program is now airtight. 
There are multiple compile-time reflection proposals that solve this and more.
* Overcomming the pain of writing to an already open file on windows will be tremendously hard. * It will broke any signature scheme the executable could have on windows &amp; osx * I guess the executable could be flagged by any sensible antivirus software as malicious If you ever so manage to come up with something that ""works"" it would certainly be broken enough to piss of you legit users and not robust enough to not allow illegal use anyway. I don't know what a good DRM system would like, but I guess writing a bunch of values in the windows register is sensible. You also could derive a unique number based on a fingerprint of the computer, but that is hard to achieve too. Maybe you could use the windows serial number ? some harddrives also offer a unique serial you could use. 
Just a few things (this isn't complete): I would really recommend using a couple arrays instead of 9 ints and chars. If you have C++11, you can get rid of the dependency on Windows by replacing `Sleep` with `std::this_thread::sleep_for(std::chrono::seconds(1.5))`, or another time unit. In C++14, that `std::chrono::seconds(1.5)` can become `1.5s`, given `using namespace std::literals;`. Your `winOrLose` function could get rid of all of the output statements and make the function that calls it have a single output statement since each output line is so closely related to the return value. 
Wow. That's a lot to do in two years. If they pull modules off I'll be impressed.
 Interesting to see ADT + pattern matching.. hope that does indeed make C++17
Const-casting would *not* be a better demonstration. Const casts are on the level of pointer hacks. The example may seem a bit contrived, but it's not unimaginable that, e.g. some callback lambda modifies something you're holding a const reference to.
Isn't free code review much better than just some game scores? ;-)
Variable sized arrays are currently not part of the C++ standard, although GCC and Clang provide support for them. Some unresolved issues which prevented them from being accepted in the standard was dealing with stack overflow as well as what kind of behavior they should have if they're a member of a struct.
I honestly didn't know VLAs weren't part of the standard. I guess `bad_alloc` wouldn't be an option.
Suggest a better way to do it. Be constructive. 
I think the C standard just doesn't allow them to be in a struct, that's why Linux using VLAIS (as a GCC extension) is a big stumbling block for porting it to clang.
a proper match would be really nice
We are having this conversation so I'm going to say yes, it does need to be pointed out.
I just wish universal references were easier to add to a function without completely fucking up the autocomplete and having to make a template parameter per regular parameter. I guess concepts would mostly fix that, but explicit universal reference syntax for function parameters would be so nice...
What? No. It's a while loop. There's no reason whatsoever for a comment there to say "Beginning of loop" because that's about the most general thing you could comment. What is the loop for? what does it do? It's a shit comment, that's all.
He forgot white space overloading ;)
I would be happy about such a pull request! :-) And could you be more specific about the include guards?
Isn't a large part of the design to enable modules to be applied to existing code without modification?
Looking forward to ranges, I really hope they make it into C++17. A SIMD vector sounds very interesting as well. Good points there by Stroustrup about the committee.
So you wouldn't immediately see a problem with: int x = 5; //declaring integer variable x and initializing it to value of 5
Either Qt Creator or CDB doesn't seem to have support for C++11 containers though. I can't see anything in `std::unordered_map` etc.
Yeah, but thats a point of contention. Theyre already introducing new syntax, why not allow us to have something clean and intuitive and more powerful at the cost of minor structural reworks in existing code? 
GCC 5.1 has full C++14 support and pretty printers. So maybe give it a try.
Wonderful comment. Lets see where this line of reasoning leads to: * don't call into STL functions (what if you have step into them?) * don't use STL algorithms (what if you have to debug them?) * don't use STL containers (what if they are buggy?) * don't use Standard libraries ...and roll your own containers, algorithms, etc.
&gt; They might touch similar concepts, but they are presented in different ways. The 4th edition of TC++PL gained "Tour" chapters that cover the same topics in about the same detail (judging by page count) as the "Tour" book. That makes your above claim a bit tough to swallow, to be honest.
Agreed. You can't do much wrong with "Accelerated C++" for introduction purposes. I should probably checkout whether "A Tour of C++" is a modern version of that. 
&gt; Don't worry about any of this until you get on the job As an interviewer for a C++ position, I would question candidates on their knowledge on how to use C++ effectively. Learning only syntax and semantics does not tell you *how* you should write code and *why* you should write it in a particular way.
Try looking [here](https://isocpp.org/blog/2015/04/2015-04-pre-lenexa-mailing-available). Variants are [N4450](http://open-std.org/JTC1/SC22/WG21/docs/papers/2015/n4450.pdf).
I see, thank you for taking the time to explain all that in detail. I still like Java better but I see that C++ has the stage when it comes to the things you mentioned for it. Also, have you heard of NetBeans? It is currently my favorite IDE for Java and also supports C and C++ (though I have not tried it for them yet).
The actual support is usually provided by the debugger (GDB or CDB). Now I don't know about the MSVC debugger, but with GDB you can install "pretty printers" for almost anything, that is STL classes, Qt, Kde, and it is quite easy to write printers for your own classes if you need so, it is a simple python script. So if you are using GDB just google for "gdb stl pretty printers", add the relevant lines in your `.gdbinit `and everything should work in your IDE.
This is exactly the opposite of my experience. I cannot abide bashing of QT Creator without specific examples.
In addition to updating VS's visualizers whenever the representations of STL objects change, we've made several improvements in 2015. The ones I can remember: added chrono/initializer_list visualizers, made reverse_iterator's visualizer much less confusing, displayed when map-family iterators reach their end.
* Debugging experience is worse: Hovering over variables often doesn't work, over STL containers it doesn't work at all. The variables are shown in the debug window but navigating them is a pain, also a lot of container-internals are shown * Code completion is worse (hard to give a specific example) - but I haven't tried the new QtCreator with the clang code-model yet * No Image/Matrix visualisers for QtCreator - Try working with Image Watch on VS and you'll never go back to text-only debugging or writing tons of images to the harddrive * Sometimes issues with importing certain CMake projects, the files are listed in weird "../" subfolders. Never had issues with CMake generating VS sln files * While debugging in VS, you can jump back, change lines, re-execute lines These are some random points I just remembered, I'm sure I could come up with more. A few of them are sadly quite big issues for me, they hamper my productivity a lot. I'm sure you could counter-argument each of these, I try QtCreator regularly and I like it and actually also recommend it, but I get most out of my day-to-day work if I use Visual Studio. I'm really glad people like QtCreator &amp; CLion, it only means they will get better and better, which is awesome. (just fyi: it's _Qt_, not _QT_ :-) )
Also VS support visualizers for Boost types https://visualstudiogallery.msdn.microsoft.com/c7e02633-86d9-4262-b745-6cc647afb3a8
I will not claim QtCreator is super awesome, perfect and bug free. It is a piece of shit. It is just less shitty than any other IDE I have used. Your list of complaints are among the reasons I use QtCreator. &gt; Debugging is worse The weird things the VS debugger did is part of why I stopped using it. Hiding important things about standard containers. They made promises about reversible debugging, editing and re-running, and remote debugging that never worked right for me. I have managed to get remote debugging working, but it turned out to be easier to just install tools on the remote system than deal with the hassles the remote debugger gave me (That is not a universal solution, but it was the only workable solution at the time). If you don't like seeing what is actually in memory I can't help you there, though I do agree some nicer support for inspecting internals of complex things would be nice. &gt; Code completion is worse I cannot comment on VS code completion effectiveness it slowed down my 8 core 16gb of RAM machine too much to use. It also affected the stability causing crashes. After the amount of troubleshooting I a confident its hardware was flawless, days of memtest and hard disk scans on that machine. I switched to QTCreator despite working on a vs project. I only used vs to compile. I hardly use code completion anymore in any IDE, but when I do QtCreator finds the member function calls I want and never offered false positives. &gt; No Image/Matrix visualisers Never used them, no comment. &gt; While debugging in VS, you can jump back, change lines, re-execute lines I have followed several MS tutorials and read much documentation, but I never managed to get most of the advanced debugging feature working. But then again I never got most things microsoft promised. &gt; Sometimes issues with importing certain CMake I exclusively use CMake for my development and I am not sure what happened here. I have not experienced this problem. This does not mean it is not a real problem. Maybe try switching the view of that documents pane from "Filesystem" to "Projects"? **My gripes with VS:** When I try to make a simple C++ project it insists on giving me some managed C++ junk. I found a couple of ways to do it without introducing .Net and all that stuff I don't want, but the easiest is to use CMake to generate the project files. If the IDE cannot be bothered to make options obvious why use it. Speaking of options, I feel bombarded by options when I drop into any menu. 90% of options in VS menus are entirely not needed by 99% of teams, but microsoft cannot make them command line switches because there doesn't appear to be a clear cut between the compiler and the IDE. Then when I google to find the option I need I learn it is not supported yet. **IF** it is supported by the compiler adding the option is easy, but too often it is some feature only supported by the IDE or some microsoft specific component. With QtCreator I do frequently have to enter command line options but because all of the option related to the compile are compiler flags I never need to worry about not being able to use it or script it once I have decided to use it. Multithreaded compiles do work in VS but have odd restriction an rarely go as fast as clang/gcc. I enter a single command line option and compiles go very fast. Everything to do with precompiled headers. The speed gain is minimal (some claim 90% reduction in compile time) when I tested on a application I working on it *Increased* the compile time. Then there is all the horrible stuff it does when you are structuring your project, forcing you to change your include order and grouping unlike things into a single monolithic header file. It also discourages portability because of restrictions on using preprocessor directives with precompiled headers. Then there is performance. I have no clue why, but for the things I build MingGW builds faster executables than vcc. I couldn't believe it at first. I bench marked over and over again, but vcc just doesn't optimize as well as old a and poorly ported versions of gcc. Finally, for me as near as I can tell it only works with microsoft's compiler. So all the platforms I care about simply don't work with it.
That is some crazy black magic going on there. :-)
This is really cool!
What's the problem with it exactly?
You can debug code you have and not STL code by stepping over it in the debugger instead of stepping into it. That solves half of what OP was asking about. It doesn't let you see the data on all the standard containers though.
It's not that you are wrong. It's that the person who wrote the code clearly isn't familiar with the logic. So making a suggestion or explaining the reasoning will help the OP more than just pointing out an error that they don't understand.
Key thing to remember is that `constexpr` means "evaluatable at compile time", not "constant expression". I guess `compiletime` wasn't as attractive a keyword although IMHO `constexpr` is confusingly named. `typedef` is another keyword with a poor name (it doesn't define a type, it provides an alias for an existing type).
It was clearly *intended* as a "constant expression," though, as in, a stateless expression that always yields the same value no matter when it is evaluated.
It's not an error, just bad taste strongly hinting at poor code. Many of us working folk are filled with dread when we see comments like this in code we have to maintain.
Heartless words. Everyone has to start somewhere.
It was a joke – some people got it, you didn't, and that's okay!
I had the following C++ IDEs working just fine: Qt Creator, Eclipse CDT, Xcode, CLion. Currently using Qt Creator and can say that it is much faster than VS, has great CMake integration, and thanks to better toolchain based on GCC or Clang has way better C++ support and faster compile times (plus I can use ccache). VC++ is just too buggy, for example, I recently had to work around a bug in basic visibility which is C++98, not to mention incomplete C++11/14.
&gt; I really hope they change the syntax of modules to look like namespaces and give them their own scope like python modules. This is not compatible or will segregate things. Modules and namespaces are going to be different things. I think it is reasonable given the constraints.
I don't think it has (gcc has this weird thing where they say they are "complete" when only library things are missing - gcc 4.8.2 is labeled as "full c++11 support" and 5.1 still added c++11 library features ...)
Yeah, NetBeans is good and I used it a lot before. Nowdays I usually write Java in Eclipse - but that's just a personal perference/comfortability thing. Since C++ has fairly low IDE-requirements, any IDE will perform good enough. You should just stick with an IDE that you like, that way the "switch" won't be as intimidating either.
Good point, although all of these discussions are usually too shallow. In my experience there are plenty more situations where you might want to consider passing by value. For instance, it might even be more efficient in some concurrency scenarios to actually pass a non-trivial-to-copy object by value, as it might reduce a critical region, or even be more cache friendly. This is especially true for functions that do heavy work on a small data set where most of it is stack-allocated and thus can be placed in the same cache page.
And `int` does not mean "integer" but "intestine".
&gt; The preprocessor is a very useful tool for code generation. Ugh. Its main advantage is universal availability and standardization. Other than that, ugh. The C++ Build Model is a major burden for large applications. This is where all the header files, lex/parse/sem come in. Off all the pending C++ features, "modules" would have the biggest impact on my typical work day. &gt; I use C++ because I don't want a GC. The question is not which applications don't need it, but those that would benefit from it. *I don't want GC in C++ so noone else should need it* is kinda silly. 
I think this is exactly the sort of thing that C++ programmers wouldn't like to see :) Realistically, when you swap out features of a programing language for other features, there are going to be pros and cons; it's not a matter of "better" or "worse", so naturally it'll come down to personal opinion on which one is "improved". And, I think it's silly to say something like garbage collection is an "improvement", because it's the epitome of something that comes with pros and cons. Pros: you don't have to manage memory. Cons: your code is slower. But, we use C++ usually because we *want* to manage memory to get the speed out of it.
&gt; Ugh. Its main advantage is universal availability and standardization. Other than that, ugh. I never said it was nice to use. It is useful and gets the job done. You can't simply remove it without providing a better replacement. Building code by concatenating strings ala D is not better. &gt; The C++ Build Model is a major burden for large applications. This is where all the header files, lex/parse/sem come in. Off all the pending C++ features, "modules" would have the biggest impact on my typical work day. I don't think I disagreed on this :-) &gt; The question is not which applications don't need it, but those that would benefit from it. I don't want GC in C++ so noone else should need it is kinda silly. Chances are that if you're using C++, you care about not having to deal with a GC and all the problems that come with it. You are free to use a GC library if you insist, but that's no reason to tie the language / standard library to it. (D fails horribly at this)
* No more preprocessor The PP is NOT a good tool for code generation. D has vastly better tools for this purpose - that are part of the language not a separate language with its own bunch of undesirable issues. * No more header files, today. If the only reason for headers is to import macros, it really indicates how the PP holds us back. * Lexing... Agree here - should not be relevant to the users of a language. * Name conflict bugs are impossible. This is very useful when name conflicts arise when using two libraries. You're just lucky it hasn't bitten you *yet*. * Default initialization I agree with you on this, as long as a compiler warns I see no issue. * The D STL is readable. Pointing to a reference does not make the *library* readable. D's STL gives much more meaningful error messages. * No more diamond inheritance. Why is everyone so scared of multiple inheritance? Sometimes it just makes sense. It may be harder to implement, but Eiffel in particular has managed it for decades now (more elegantly than C++). * GC This is optional in D. Unfortunately it is not always obvious which library features require it, so not ideal. D *can* be used in a lot of places that C++ is. For some jobs it is a viable replacement. But it doesn't quite hit the spot. I'm hopeful that something will hit that spot soon, because C++ is vastly too complex now. It's beyond most programmers to learn the language to the level of library writing, and that is a bad thing.
&gt; It is useful and gets the job done. Sometimes even in a not-too-dangerous way. I won't say "avoid at all cost", but clearly it's substantially flawed for any non-trivial use. &gt; I don't think I disagreed on this :-) Yeah, well, it's where the things you don't care about come in :~) (And it's the central point of OP where I'd hand it to D) &gt; Chances are that if you're using C++, you care about not having to deal with a GC and all the problems that come with it My point is not "having to deal" with GC, but having the option to (for selected data). That's the spirit of C++ IMO. There are indeed good reasons for keeping it out of the standard - OTOH library would guarantee availability, and language could improve syntax and diagnostics. 
Among other things, [traction](http://bit.ly/1IeQrUL) means: the extent to which a product, idea, etc., gains popularity or acceptance.
There are a number of problems with `alloca`. Overflowing the stack could be considered one of them, but I'm not sure it's really an issue `alloca` or VLAs are meant to solve. There are always risks when a language provides direct access to memory. One of the bigger issues seems to be lack of portability though.
But that is how your office uses c++, I have worked a lot of places and all of them use c++ differently. Some places are heavy template meta-programming, some places don't allow templates at all. Some places use exceptions, some places don't allow it. Some places, like yours, think that "Effective C++" are great reference books, others see them as a great reference for things not to do. There are so many aspects of the language that focusing on a small subset of them during interviewing is dumb. If you find a programmer that can think you can teach them your style of code pretty easily. If you limit the people you hire to your small subset of the language you are missing out on diversity of knowledge and you are just working in an echo chamber. I hate those types of places to work because there is little growth potential. I think it's pretty great that the office they is going to work at is willing to cross languages to hire, unlike it seems you would be willing to do.
Go definitely have its own set of problems. Its definitely not a answer to everything. Good C++ solution would definitely beat it in terms of speed and memory consumption. And flexibility too. But Go is simple. Like **really** simple. Its has some good features out of the box. Its easy to learn and be productive in it. Easy to support. Easy to read. And best part - it doesn't claim to be silver bullet. It merely solves some practical problems. &gt; Go is the new Java Not sure how I feel about it. Java, in its core, is not a bad language. I have two problems with it tho - it doesn't move forward fast enough to be *today* programming language, and have too many "EE walk-arounds" which is difficult to understand before you face them in practice. The second is also true for C++, and I think, for every adopted language in the market. Java is just the winner in that area. Type-erasure is both good and bad. I have love\hate relationship with C++. And I like both Go and Rust. But when comes to "we need this thing to work fast and this thing is going to be large" I know its going to be C++. Plain C? Too much effort in custom implementations of what STL would give me out of the box, without getting any results.
 std::string a = ...; std::string b = ...; a = b; a += ...; If `a` is long and `b` is short, changing `a = b` to `a = std::move(b)` can actually make the program slower as a whole, as `a`'s old memory allocation is discarded and the `+=` has to allocate memory (and end up copying `b` anyway). This may be relevant to the linked thing for setter member functions (but generally not constructors).
Too extreme. Means it won't be anything more than a niche language. C then C++ will continue to be among the first things ported to a new OS/architecture.
Much of the core philosophy of C++ was always sound. Parts of C++ haven't aged well. I would have preferred seeing a resyntaxed C++ that found some clever way to still integrate with ancient C++ code. Instead we got a language different from C++ in many of the wrong ways (GC being one of them). And it set itself up in opposition to C++. That's not a winning strategy, especially with c++11 out and about.
iostreams: the weak link in c++ definitely. Internationalization and grammars really show how weak iostreams is on the text processing side, and being forced to attach a locale to binary only files exposes a really bad design flaw. Of course multiple inheritance doesn't help here either. intel TBB: I personally strongly dislike being locked into specific hardware, instruction sets or OSs. Pass on that. I started avoiding boost proper for a couple of reasons: using one boost library seems to pull huge sections of boost in, and boost updates seem to break compilers, and it compiles slow due to dirty template tricks. There are some useful tools in there. No comment about hana. unfortunately their sample code uses a ton of "using" and "auto" statements which frankly makes the sample code kind of unreadable. What are hana features and what aren't? A pretty good real world example of why "using" and "auto" can be a bad thing.
Until Scott Meyers can produce some concrete numbers justifying his claim that pass by value has non-negligible performance costs, then I think he's contributing to a lot of the bike-shedding that has been going on among C++ thought leaders regarding C++11. It's a lot of "I'm worried about this, you should prefer to do that..." but no actual empirical or really any scientific evidence has been produced. The advice provided by compiler writers with actual numbers to back it up, like Chandler Carruth who works on Clang and presented his findings at CppCon, is that pass by value is generally preferable. The compiler can elide redundant copies/moves and furthermore it eliminates any aliasing issues which provides more optimization opportunities.
Visual Studio 2013 Community (free edition of Pro) will do what you want.
Portability is only an issue if alloca isn't supported on the platform you are targeting, which is a stupid statement that goes without saying, but sometimes still needs mentioning. You shouldn't refuse using tools because some day your Win32/OSX code might need to be ported to Solaris and alloca behaves differently there. However, it will be much more elegant to allocate a N-byte chunk with VLAs, than with alloca.
&gt; * Lexing stage separated from parsing stage separated from semantics &gt; I don't even know what to say. Never cared, never will. You only need to care if you're a compiler writer. Otherwise, it's wrapped up in the "long compile times" concern.
You don't have any classmates you can work with? It can be quite beneficial for you and whomever from your class to work on it together. Obviously not copying each other. Out of curiosity, what do you have to do for your project?
First things first: Not here. To quote the sidebar: &gt; Discussions, articles and news about the C++ programming language or programming in C++. &gt; For C++ questions, answers, help and advice see /r/cpp_questions or StackOverflow. If you have specific questions, do what it says. If you need help in general, you might have a chance finding a CS-student who likes to earn a little extra money. For that you'd look at blackboards of a university if you have one in your area. Other than that, yeah, programmers earn a lot, so they won't be too cheap.
I did go to the other subreddit, posted a question there but I know it's not here I'm simply wondering if there was any external website to get help from. But your explanation makes sense so thanks. 
Have to write a program that finds a set of numbers from an XML document, and pass them to an array to average them out. The array part we have we just are unsure of how to find them. Anyways yeah it's a group project but like many group projects we're all unsure of what to do / two aren't even showing up to meetings so I may ask around the class to see if anyone has ideas. Thanks for your input! 
Such as?
This is the simplest one I could think of: #include &lt;iostream&gt; constexpr int inc(int a) { return a + 1; } int main() { volatile int a = 1; std::cout &lt;&lt; inc(a) &lt;&lt; std::endl; return 0; } EDIT: relevant part of the assembly, compiled with `-fno-inline` to make the runtime calls really apparent: [gist](https://gist.github.com/Gustorn/44c4f78cd8c145d42ed1) 
To add to to the other replies: Be careful with constexpr if you are often switching or migrating between C++11 and C++14, because this keyword has a different meaning in those two standards. The most important (and potentially breaking) change would be that constexpr implied const in the old standard, but now in C++14 you have to mark it as const explicitly to achieve C++11-equivalent behavior for constexpr's. You can read more at http://en.m.wikipedia.org/wiki/C%2B%2B14#Relaxed_constexpr_restrictions and https://akrzemi1.wordpress.com/2013/06/20/constexpr-function-is-not-const/
Non-mobile: http://en.wikipedia.org/wiki/C%2B%2B14#Relaxed_constexpr_restrictions ^That's ^why ^I'm ^here, ^I ^don't ^judge ^you. ^PM ^/u/xl0 ^if ^I'm ^causing ^any ^trouble. [^WUT?](https://github.com/xl0/LittleHelperRobot/wiki/What's-this-all-about%3F)
You have a point (that nitpicking though) ;)
Especially today, given that both Go and Rust are also targeting the same niche as well.
&gt; The question is not which applications don't need it, but those that would benefit from it. I don't want GC in C++ so noone else should need it is kinda silly. Can you choose to not use the GC while using the standard library? Because that is what the complaint is about.
Unfortunately I don't know anything about these. There might be ports to these architectures, but I'm not sure.
I wrote [autocheck](https://github.com/thejohnfreeman/autocheck). What do you feel is missing? What dissuaded you from contributing?
I don't know how many times I've had to tell people that Go isn't in the same ballpark as Rust or C++, but at this point it's just sad the myth is still around.
Actually, even simpler... constexpr int id(int a) { return a; } :)
&gt; as a's old memory allocation is discarded I see. However I cannot find in the specification why this should be the case. The memory management strategy of `std::basic_string` is explicitly omitted (please correct me if I'm wrong!), so what actually happens in this case is implementation defined: - If `a` has heap allocated memory (is long), then `a = std::move(b)` can also copy the content of `b` to the heap if `b`'s contents is stack allocated (short), so the `+=` won't need to allocate memory. - If `a` has heap allocated memory (is long), then `a = b` can also discard the heap allocated memory and switch to a small string if `b` is small, so the `+=` will need to allocate memory. My point being: the slow thing can happen wether one uses `std::move` or not. From my reading of the standard the definitions of the copy and move assignment operators are loose enough to allow efficient strings with SSO. I guess one will just need to rely on implementations doing the smart thing, and fill a bug report if they don't. 
I had written autocheck with [shrinking in mind](https://github.com/thejohnfreeman/autocheck/issues/8), but didn't get around to it before moving on. I don't think it requires fundamental architectural changes, but I guess that's a matter of opinion. Composition is available in autocheck, although maybe it is difficult to find in the [docs](https://github.com/thejohnfreeman/autocheck/wiki/Generator): auto str = ac::string(); auto vec = ac::list_of(str); auto x = ac::element_of(vec); // element_of is not written for autocheck, but easily could be, // in my opinion These are implemented as free methods, but could also appear as `operator *`, although I would probably prefer a named function since none of the operators except `operator ()` have the "expected semantics" of composition.
this is nice, but I find property to be too general word to convey the special type of testing you try to achieve using 'quickcheck'. This type of testing reminds me of a concept I was considering a while ago. Combinatorics driven testing :P The idea is that you build a permutations of all possible arguments to a function and you test the full space by picking each from the space you generate. Going random would be an option for traversing the space. The only problem is, such spaces tend to skyrocket and some mathematical analysis becomes requirement to make it reasonable if at all possible for the most complex of scenarios :( But that is the only way I can think of to introduce formal/systematic prove of software correctness. 
&gt; std::strncmp it is right there: char* text is pointers not text! someone interpreting the pointers to be char arrays is making it text! but hey it is the same as string of bytes :) but we all know the one does not translate to the other, because we have encodings @! one of the many reasons to stick to c++ and forget about C-style semantics 
What's required for shrinking depends a bit on your ambitions. The naive solution is for each generator to provide a member function to shrink a generated value like this: std::vector&lt;T&gt; shrink(const T &amp;value) const However, there are some issues with this: * Such an implementation would need to calculate all the possible shrinks of `T` at once. * In this implementation, there is no way to map over the generator without losing shrinkability. To preserve shrinkability, you would need to provide both the mapping function and an inverse mapping function. Also, not all mappings are invertible. This makes composability worse. * How would this work if `T` is not copyable? What I wanted to demonstrate with `operator *` was not composability but the fact that generators can easily (without monadic bind and lambdas) depend on values of other generators, not just be composed of other generators in an applicative fashion.
NOT! if you decide not to use the subset of C++, namely C, which there for good 'historical' reason. So the 'right' way of approaching this is to wrap the naked pointer into c++ string and the do your work, unless something prevents you from doing so!
hehe, to summarize your comment: 'abstractions are useless' and of course you have to pay for them and yes they hide the details. It is a constant trade-off ! "C lib is perfectly fine and more secure than what you thing." tell that to people depending on OpenSSL :))) everything you say about obj1 == obj2 can be said about strncmp, it is an abstraction again. the difference? something I was hinting but none pay attention: without the type safety guarantees of c++ char* something, could be literally anything and some cases it ends up text and only 1 type of text ASCII! I don't see a clear description of the case you supply one or both pointers as NULL. i can only 'assume' it is not part of the contract by having assert(arg1) first thing in the body, but hay I have to see for myself and we are back at your argument about using STL! Same for allocations, what guarantees do you have that strncmp won't malloc? exactly none! 
Yes, "property based testing" is perhaps a bit of a misnomer but I'm not the one who started calling it that, that's what people actually call frameworks like QuickCheck (including RapidCheck). I've seen the word "generative testing" used as well. Regardless, it's a very useful and actually very pragmatic type of testing that is practical in real world code.
So, what? Avoid using all functions that use pointers? I'll say it again: foo.c_str() does not return a nullptr. It just doesn't. It is safe to pass one of those to the c-style functions.
Who else knew after only reading the title that this had to be from the PVS-Studio guys? (not that their work isn't great, but they're overdoing their advertising a bit)
I doubt modules will happen. They are just too hard to get right and ultimately have only marginal advantages over header files.
hehe, Cons for GC outnumber any Pros. - non unified resource management (mem is not the only thing we need to manage e.g. files, handles, sockets, textures, etc.) - unpredictable - it breaks fundamental OO principles see: https://minorfs.wordpress.com/2011/04/29/why-garbage-collection-is-anti-productive/ Not to mention how silly the hole concept is: It is like your mom coming and going out of your room to collect the litter you accumulate on the floor. Then you point how effective she is, that she doesn't bother you, like stop you from continue gaming, that is NON-blocking :)) While once you realize you can throw/dispose your garbage in the trash can you automatically make your mom not a slave anymore so she can go have some life.
I didn't want to do identity, so even if it's inlined, it is easy to spot in assembly.
&gt; Good templates and code generation built into the compiler gives more understandable code and error messages. whaaaaaaat? if anything an error through template is the best obfuscation known to mankind :)
quick ans : NO long one : http://forum.dlang.org/thread/kjo7id$22jk$1@digitalmars.com?page=4 note: it is a darn long thread
I'm not claiming you did imply otherwise :) I just wanted to point out that I think this kind of testing is a nice balance between traditional unit testing (not exhaustive at all but very simple to implement) and formal verification (completely exhaustive but hard to implement) :)
What are the pros and cons of using TBB versus standard C++ threading these days?
Beside the complications of mixing headers and modules - how are modules worse than headers? The biggest problem with headers is the one definition rule which modules at least attempts to solve.
Yup, TBB provides a nice automated thread pool for high performance functions like parallel_for_each along with some high performance thread safe containers. I believe c++17 may add high level parallelization which will be nice. 
Like me ;) This is frustrating.
yes you can use it on AMD
I suspected it at first, then saw the link was on intel.com thinking OK, well this should be interesting. Then clicked the link to find PVS-Studio .... ahhh, oh well.
&gt; non unified resource management Agree! &gt; unpredictable Agree! But I think that OO is not everything. Also GC can be pretty nice to have in some cases. But not in all cases. 
Try again. There are more questions that just 15. There may be a couple duplicates. The problems I got the 2nd time around were much easier than the first set -- some of the second set deal with stuff I deal with on a daily basis and my score went up (13 vs 6).
[**@zlrbt**](https://twitter.com/zlrbt): &gt;[2015-04-13 14:45:51 UTC](https://twitter.com/zlrbt/status/587627763915476992) &gt;Understanding boost preprocessor's BOOST\_PP\_REPEAT with ReSharper C\+\+ @resharper\_cpp [#cplusplus](https://twitter.com/search?q=%23cplusplus) [#cpp](https://twitter.com/search?q=%23cpp) [*pic.twitter.com*](http://pbs.twimg.com/tweet_video_thumb/CCesVk1WYAAfHPa.png) [^[Imgur]](http://i.imgur.com/fEUgazC.png) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/346swq%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
That was fun. This was the only question I got that stumped me: Q: char* crypt_md5(const char* pw, const char* salt) { MD5_CTX ctx,ctx1; unsigned long l; int sl, pl; u_int i; u_char final[MD5_SIZE]; static const char *sp, *ep; .... /* Dont leave anything around in vm they could use. */ memset(final, 0, sizeof final); return passwd; } A: [spoiler](/s "A buffer containing private data should be erased before function returns. The memset() function is used for this task, but it is incorrect. As compiler is aware that after calling memset() the 'final' buffer will not be utilized anymore, it is possible that compiler will remove memset() call altogether.")
The only time I would accept injecting code with the preprocessor is injecting data into an array or something similar and changing directives for debugging. Can you provide an example of what you're taking about?
What is cache-local functional parallelism? 
1. They make cyclic dependencies very difficult to handle. 2. Changes in source files often trigger rebuilding of the entire program. 3. They are often not flexible enough. 4. They further complicate the language without much benefit. The ODR can easily be enforced by a capable enough whole-program compiler. GCC 5.1 already has support for this. God bless header files.
InstaEdu also does some tutoring. Not exactly sure what their rates are. cplusplus.com/forum/beginner is a place to get free help (but that's for specific questions, not for a tutor). I also do online tutoring (see mycpptutor.com for more details). Good luck!
In 08' you would have been using at best v8 of the Intel compiler (v9 came at during Dec for testing etc.) The Intel compiler injects run-time CPU dispatch code used on executable start-up to populate a lut of function pointers pointing to the most optimal implementations of said functions (eg: memcopy, memcmp et al). The CPU check intentionally identified all non genuine Intel processors as non-conforming (supposed lacking sse etc instruction sets) and populated the LUT with fallback (naive) implementations. Agner Fog produced a patch you can apply to binaries built with the Intel compiler to enable them to run on AMDs just as fast as they would run on Intel processors - The patch simply removes the compare for the string "Genuine Intel" http://www.agner.org/optimize/blog/read.php?i=49 AMD took Intel to court, and subsequently Intel fixed the issue(s) in v9+ In short v8 and before comparisons of binaries built with the Intel compiler on Intel vs AMD h/w are ALL invalid. This issue also affected: IPP, MKL and TBB based uses 
(someone has to say it) ... Gimli was a _Dwarf_ (maybe you meant Legolas ? :P) But seriously, thanks for the writeup!
While interesting, the project seems to be a bit of a mess: - Bunch of headers with no structure - No namespaces - No mention of compilers supported - No mention of what version of C++ it targets (C++11, C++14, C++17?) - [Non-uppercase macro usage](https://github.com/KrishnaAchuthan/curry/blob/master/fn_fwd.hpp#L5) - Use of reserved identifiers in macros (`_STUFF`) Probably other things I missed on this first look. I didn't bother checking code itself.
Isnt std::bind already partial function application?
It'll be like Smalltalk, Simula, or Modula-2. Interesting but not widely used.
Classic intel.
Thank you so much for taking the time and reviewing. I agree that it is a mess. This is exactly the kind of constructive criticism and tough love that I was hoping to get from reddit. This was a weekends and evenings project and most of my focus was on functionality up until now. I will clean it up. By the way, it is C++14 and until a couple of check-ins ago it compiled fine on MSVC 2015 as well as GCC 4.92, Clang 3.6.0 with std=c++1y switch. 
&gt; TBB usage patterns result in high rate of cache thrashing Hm, this surprises me. I always thought TBB's algorithms were designed to make optimal use of the CPU cache (i.e [Strike when cache is hot](https://software.intel.com/en-us/node/506103).) Can you give an example of bad usage pattern in TBB?
[Seems so](http://stackoverflow.com/questions/362694/intel-s-threading-building-blocks-runtime-exception-license-what-does-it-mean)
So these are all issues with the implementation of modules from [N4465](http://open-std.org/JTC1/SC22/WG21/docs/papers/2015/n4465.pdf)? I do not believe these are problems with a module system but instead an issue with tightly locking down a module, ignoring namespacing in regards to modules, and avoiding resolution of objects until whole program compile time. Personally I'd be alright with injecting an object name resolution step between the current front end lexing/parsing and back end compilation just to make cyclic dependencies easy. I'm sure the majority - including myself - really want modules for compile times though. It is painful when working with nested templates to make any change due to the cascading effects. Secondly while GCC and most of the Unix variants have nice headers which avoid macros I cannot say the same about Windows and some of our other targets. So I also really need the hiding effect that modules will hopefully provide.
I wish there were a proposal to allow PMFs and PMDs to be called like functions. Instead, the Standard Library has to do a lot of work to implement invoke() and compensate for this arbitrary deficiency in the Core Language. Seriously, if somebody says pmf(obj, args), what else could they possibly mean? DMR wisely solved this for function pointers. He said, if I see pf(args), then it's obvious that you want me to automatically dereference this function pointer. C virtually never does anything automatically, so this behavior stands out as being unusually helpful.
Because when you have to nest many functions it gets difficult to read and write: auto r = transform(filter(numbers, [](int x) { return x &gt; 2; }), [](int x) { return x * x; }); Versus this: auto r = numbers.filter([](int x) { return x &gt; 2; }).transform([](int x) { return x * x; }); This problem is currently being solved in C++ by using [pipable functions](http://pfultz2.com/blog/2014/09/05/pipable-functions/) which is being used for many C++ libraries like [Boost.Range](http://www.boost.org/doc/libs/1_56_0/libs/range/doc/html/index.html), [PStade Oven](http://p-stade.sourceforge.net/oven/doc/html/index.html), [Linq](http://pfultz2.github.io/Linq/), [Streams](http://jscheiny.github.io/Streams/), and [ranges-v3](https://github.com/ericniebler/range-v3). So, having a native and uniform way of calling methods would be much better than trying to use operator overloading for the 'bit or' operator.
Possibly scheduling/allocation and memory level parallelism?
Docs are going to be released asap and if you want to contribute, well, you are welcome :-)
Even if I wanted to contribute to this project, it's difficult when I don't know what the library does or how it works. Telling users to write their own docs is one way to ensure you don't recruit any users.
I might sound like a douche, but when I see macros in modern C++, I cringe a little.
Pointers to member functions/data.
What about C++98, did they finally finish implementing it?
A more realistic use-case for this might be "from within a Windows VM on your Linux machine". I'm not sure it's sufficiently better to justify the effort, but based on the Android preview it's the best gdb frontend I've used.
History vindicated us for `export`! That bug still repros. Filed as DevDiv#1164605 in our internal database.
It is, this just provides a cleaner interface to that. For instance, you don't have to use placeholders unless you want to curry out of order.
Thanks
Wait. So /u/drbartosz [goes to Italy](https://twitter.com/glmeocci/status/502925778687102977) and a few months later we get this... This is no mere coincidence!
Kick it back until it's dead!
Is this a in the standard? Because it should be. Coroutines are an amazingly useful tool sometimes.
It's under discussion with the iso committee. here's the Lenexa mailing: https://isocpp.org/blog/2015/04/2015-04-pre-lenexa-mailing-available 
This looks great! Thanks for taking the time to write it all up.
 * Terse Range-Based For Loops The element type specifier can now be omitted from range-based for loops. The terse form for(widget : widgets) {…} is equivalent to the longer C++11 form for(auto&amp;&amp; widget : widgets) {…}. Proposed for C++17 [N3994] * Resumable Functions (resume/await) The resume and await keywords provide language-level support for asynchronous programming and enables resumable functions. Currently, this feature is only available for x64 targets. Proposed for C+ +17 [N3858]
It should be an elephant.
&gt; Since last time, we have made some changes to our experimental implementation that tracks the [latest proposal](https://isocpp.org/files/papers/N4402.pdf) (with the exception that resumable_traits and resumable_handle are called coroutine_traits and coroutine_handle as in earlier proposal).
You're welcome! This took me about a day; I'm expecting that my STL changelog will take 2-3 days to write up.
We've implemented the new Filesystem TS (massively upgrading our old "TR2" implementation), and in RC we're providing the TS's &lt;experimental/filesystem&gt; header and the TS's namespace. (The plain &lt;filesystem&gt; header and std::tr2::sys namespace are still provided for a minimal amount of back-compat. Plus it'll move to &lt;filesystem&gt; when it's Standardized anyways.) My boss and some of my coworkers have been working on stuff for other TSes: concurrency/parallelism (I can never remember which is which), await, and array_view. I'd have to ask them in order to give authoritative answers about spec/implementation status. As for the Library Fundamentals v1 and v2 TSes, which are squarely within my domain, we have not attempted to implement them for VS 2015, since implementing Standard features is higher priority. (Also, TS stuff is likely to churn, and keeping up with that is a lot of work, as we discovered during the TR1 era.) We'll look into implementing the Fundamentals in the next major version, although I reserve the right to change my mind and wait for stuff to be voted into the Working Paper (where it will be less likely to churn). I *may* be able to implement my Uniform Container Erasure for 2015 RTM (it's just a matter of adding the headers to our build system, and the mechanical work of translating my existing implementation into bulletproof _Ugly production code), but constexpr is my first priority, and I will sacrifice erase_if() if necessary (or more likely, go to Dreaded Shiproom to convince them that I should be allowed to sneak changes in during RTM lockdown).
The Committee ultimately rejected my fix for the "for (auto elem : range)" mistake, so we removed the syntax from 2015. It was also implemented and then removed from clang. I've been thinking about asking the compiler to add a warning for "for (auto elem : range)", saying "I TOLD YOU SO", or words to that effect.
The point of magic statics is that they can be implemented without paying the expense of a mutex, thanks to Burrows' magic algorithm (which VC uses). My understanding is that the cost is basically unobservable, although I don't have concrete numbers. I used Win32's InitOnceExecuteOnce() to reimplement call_once(), since it was easier than the magic statics algorithm, but we might change that in the future.
Sounds quite reasonable, thanks! I'm really glad VS has put in the effort for the equivalent async/await in particular. They really simplify things on my end, though I imagine it's a pain for the compiler writers to ensure they work properly.
Still no Expression SFINAE. &gt; On top of that, our C++14 Standard Library implementation is complete, except for Expression SFINAE in result_of and std::function Of course, SFINAE is not necessary to implement SFINAE-friendly `result_of` and detecting general function callability.
Tough crowd!
Non-mobile: [arrogance fed by incompetence](https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect) ^That's ^why ^I'm ^here, ^I ^don't ^judge ^you. ^PM ^/u/xl0 ^if ^I'm ^causing ^any ^trouble. [^WUT?](https://github.com/xl0/LittleHelperRobot/wiki/What's-this-all-about%3F)
Wow, this is much more C++11-feature-complete than I expected, thanks for listening to our pleading and begging. I'll be eagerly awaiting the interstellar colonisation :p
Another nice thing about generic lambdas is that they further reduce the need for bind(). If your classes have memberwise copy/moves, you shouldn't declare them at all - just let the compiler generate them.
yeah good point - except I was getting compile errors from my auto-generated constructors when I had a move-only member (unique_ptr) I thought it was a VS bug, but will update this once I have finished installing VS2015 (Im in Oz so this may take a while)
Looks like I'll have to start coding c++ on windows :-D, nice done with these release.
2013 didn't support rvalue references v3, so it basically followed C++98's rules for generating copies and didn't consider moves to be special. Classes with unique_ptr data members would therefore get compiler-generated copy ctors/assigns (which would fail to compile if used), and not get any move ctors/assigns. 2015 follows C++11's rules, which will handle this case.
AFAIK `float` and `double` have the same width on every platform, but `int`, `short`, and `long` don't. So there's a need for `int32_t`, but not `float32_t`.
**internet** types?
I appreciate your new found directness, but I dislike your lack of substance. Now you are properly attacking me by accusing me of being on the wrong side of the Dunning-Kruger effect. That would make sense if my example wasn't supported by the opinion of another who is an expert (The StackOverflow answerer has over 18k of points). I am sure I could find more cases where visual studio behaves differently than the documentation indicates. **All I have been saying this whole time is certain features haven't worked as advertised**, and I have had fewer problems with the open source tools. Given the amount of contributions I have made to open source software (7 projects now) and the amount of of commercial shops (6) I have have developed for I think I can speak about my breadth of experience with tools. Open source tools have been reliable but require learning concepts (sometimes complex concepts) while microsoft's tools are (not always) easy to spin up but historically have not worked as promised. Cross-domain debugging was **one concrete example of what failed**, rather than attempt to trot out a uselessly long list I felt one solid example and allusions to others would suffice. I have had other debugging failures in my 15 years of experience with C++, and even noted an easy to describe selection, yet you have ignored these. I will stand by this example, the ms docs said it should work one way and at the time it did not and the StackOverflow post marked as the answer agrees. This example shows issues where authentication got in the way of troubleshooting, which you ignored the details on. I never said it couldn't be made to work either, in fact I said I could *"get it to work with authentication off"*. On PCH I didn't said they never worked, I said *"when I tested on a application I working on it Increased the compile time"*. It failed so grossly on a single application, this does not mean it will fail on every application. Rather it means people need to think critically about the real costs and not assume a thing always works as advertised. I go out of my way to take in books, articles, videos, other's source and engage in discussion. I find it unlikely I am so low on that scale that I would delude myself into thinking I have all the answers or ignoring the skills of others ( such as /u/Elador whom I disagree with but is clearly knowledgeable about his tools). I feel compelled to point out you have cited nothing but your personal experience (without detail) and have made no reference to external material other than to insult me. Despite your arrogant perspective you claim to know my level of expertise. You should assess where Dunning and Kruger might place yourself. **With your last post you conclusively demonstrated that either are not reading what I write or are choosing to misrepresent what I write**. At best you have poor reading comprehension, at worst you are a troll and somewhere in the middle you might be some kind of microsoft shill, in any case is it worth my time to continue? 
I didn't quite phrase that right. I meant that on any two platforms, `float` will have the same width on both platforms, and so will `double`. Not that `sizeof(float) == sizeof(double)`.
Neat, thanks for pointing out the proposal. It explains support on different platforms, and other things I was interested about.
I think this would have to be runtime. 
aha, thanks for the clarification (and replies) STL, keep up the great work!
Interestingly, Cat does make use of just a *single* macro (DO). Instead, if you are referring to the tests, well yes, YATS test suite utilizes macros but it's not the subject of this work.
 vector&lt;job const*&gt; priority_view; But seriously, a lot of the code in that blog post looks like it was written by a Java programmer.
That could be quite noisy. Consider: std::vector&lt;uint64_t&gt; f = ... for (auto i : f) { // warning here isn't meaningful - const auto&amp; is wrong and auto&amp;&amp; implies move semantics that are not relevant } If there's a way to warn that for when the false-positive rate is low then that would be interesting.
I hear you, but there is an advantage to always using auto like this; the variable can never be uninitialized. With vector it depart matter, but it might be a good habit none the less. 
Great news about the C++11/14/17 coverage! The only real downer is that there's no mention of the RC being upgradable to RTM. I thought this was a thing?
&gt; my gripes with VS... **Everything** (emphasis mine) to do with precompiled headers. &gt;On PCH I didn't said they never worked, I said... Changing tune much? (To note but one blatant example). &gt;is it worth my time to continue? Probably not, but you don't have the guts to stop, so knock yourself out. I, however, can stop anytime, and it is right now.
Sorry, no compiler on mobile to check for typos.
I am glad modules are in the high priority group, hope they make into C++17 and improve greatly compile times and tool support.
So "new" that they's still updating the article: Error: Cannot open the requested blog entry. Possible Cause: entry is currently under editing.
Less [spyware](https://msdn.microsoft.com/en-us/vstudio/dn425032.aspx) (preferably none).
&gt; mechanical work of translating my existing implementation into bulletproof _Ugly production code So all the STL developer have pretty looking and easier to read STL code but all the user will get this _Ugly and hard to read code because of MACROS ? :( 
This subreddit has really opened my eyes to just how little I know of C++. So what is a coroutine if I may ask? 
A coroutine is a routine that can be interrupted halfway through, and then resumed from that point later. This trivial example prints "HELLO AWESOME WORLD". #include&lt;boost/coroutine/all.hpp&gt; #include&lt;iostream&gt; int main() { boost::coroutines::symmetric_coroutine&lt;void&gt;::call_type c( []( boost::coroutines::symmetric_coroutine&lt;void&gt;::yield_type &amp; yield) { std::cout &lt;&lt; "HELLO "; yield(); std::cout &lt;&lt; "WORLD" &lt;&lt; std::endl; }); c(); std::cout &lt;&lt; "AWESOME"; c(); return 0; }
Or not. Their download page is dead. =[
Awesome. Thank you! :)
http://www.microsoft.com/en-US/download/details.aspx?id=46871 
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2660.htm
Ah, thank you. Didn't they release the community version of that though?
&gt; community version Yes it should available too...
In the installer you can choose to install Xamarin, does this just install the (pretty useless) starter edition or what does it install?
We always provide a no binary breaking changes guarantee with RC. is that what you mean? (vc dev manager here)
I don't believe that ranges have any dependencies on std::function/result_of.
Yes, that. I'm happy to take my chances with the RC, but not if I can't upgrade it to the final version later.
The standard doesn't mandate that. It doesn't specify anything related to their size, only that double cannot have a precision less than float, and that a long double cannot have a precision less than a double.
Please direct your questions to /r/cpp_questions. This subreddit is for discussions, articles, and news.
The #include graph is pretty amazing but I wish it would only show you the project the file you created the graph for. The edges are only created for a single file so its seems like a huge waste of my UI space to show me that 150 other projects contain 10,000 cpp files which do not reference or have anything to do with the cpp file I'm generating the graph for.
I guess VSCode is only for Mono and Node code? I saw it on HN so idk much.
That is great to hear. MS shows great progress in the C++ column for VS2015. I hope you and the guys in your department get to keep your funding.
Node is a subset of javascript, and Mono is C#. Unfortunately it looks like it doens't have debugging support for c++ yet.
Thank you for the detailed write up, STL! As always, the tables (and the insightful notes) are very much appreciated!
Old story mate
One nice thing about this syntax is that it allows you to add "member functions" to existing types. For example, you could add a "member function" on std::string which would return its size (pixel width by pixel height) when a certain font is used. auto size = str.sizeWithFont(font);
Ok you can pass NULL pointer. However, I really thing that we can always pass some arguments to functions that are wrong. Almost all the time (what's about overflow, underflow, etc...) The STL is not better because the protocol is not visible and not check. This is just when you are going to use it that you may trigger an error in part of a code that you didn't write because a function is missing for an object. This is absolutely awfull in term of programming. Then selectin obj1 == obj2 instead of strcmp is just a matter of taste but this is certainly not better. In addition this is confusing because if some more operator overloads exist it will be difficult to follow the type of the object and the function call. At last, some things in C are old and may be change but C is easy to use and light. The proof : look at printf: a huge number of companies (even google) prefer using printf than C++ Stream. That's the proof (by example) it is not more dangerous. Do not forget the user. Don't be focus too much on the trick of your lib and think KISS (Keep It Simple Stupid) BTW, about openSSL: people defending the open source told us every day that it is a guarantee to have no bug, no hidden problems because everybody can check everything: it seems that this is also false :-) That's the same funny things : open source is safe, C++xx is simple and readable...
It's primarily an editor and can't compile &amp; debug C++ code (yet - they might add such functionality in the future).
1. There's a typo in the first two examples: Iterface_Impl does not subclass Interface. Slightly confusing. 2. The virtual destructor calls are necessary in both cases of make_shared. The object is deleted in ~shared_ptr&lt;Interface&gt; which doesn't know about the dynamic object type. 3. The test case is extreemly favorable to the custom make_shared: the author creates more than 50 implementations for a single interface. Real world applications have a much closer interace-to-implementation ratio; the bloat should be significantly less noticable in this case.
And how's Win32's InitOnceExecuteOnce implemented? Mutex? No mutex? Speed comparable to Burrows' algorithm?
um... I'm gonna start calling it C++1z now. (but that's OK! I'd rather they take the time to get it right if they're really going to attempt all those features!)
Typos corrected.
Oh, and the number of implementations is based on real world code. You'll note that I saved something like 23% in the overall build size of ChaiScript by switching to that implementation of make_shared. It uses a shared_ptr holder for a derived class that's templated on user-defined function signatures. The number of function signatures that might exist is limitless. Much more important than even the compile size is the amount of time and resources during build: 34% less ram, 14% faster build. That 34% less RAM can make a big difference in the parallelization of your builds. Another project I work on has &gt;300 classes in an object model hierarchy. This objects are implemented using a shared pimpl. There's technically no reason to ever instantiate a shared_ptr for anything other than the base class. Rearchitecting away from derived typed shared_ptrs could have a huge impact on compile time and size, potentially. 
pronounced "C++ Onesie"
Looks like time to learn c# then. Thanks for the help
&gt; C++1z Lets call it C++xz and get Mercedes to sell it. But seriously Concepts is going to be a game changer. Everyone seems hyped on modules to ease their day-to-day, and modules will eventually happen, but I think Stroustrup's emphasis on Concepts is the important take away.
&gt; (including Windows Explorer!) oh FFS
Magic. Seriously, I don't know (although I could find out). It's certainly a lot faster than locking a global mutex, which is what we used to do.
Oh, I know I was right. :-&gt; Note that auto&amp; elem is perfectly reasonable too - it mirrors the constness of the range. (The only thing it doesn't handle is proxy iterators.)
Probably an atomic_flag, I'd imagine. I've been using those and they're pretty damn fast. Not entirely sure of its overhead compared to no-check though.
Developer of Hana here. Hana is about heterogeneous and compile-time computation. Since the type of the objects we're manipulating is usually precisely what we're trying to compute, and since we use the compiler's return-type deduction to perform that computation, it is not surprising that we use the auto keyword a lot. Regarding the sample code, I assume you are speaking about the overview in the README. If so, it is meant to be a minimal working example, hence the #includes and the using directives. Regarding what are the features of Hana, well you can think of it like a modern Boost.Fusion and Boost.MPL, but all done with a single library. Alternatively, since you don't seem to like Boost libraries, you can also just think of it as a library of algorithms on tuples. 
Great! Nice to see that VC++ is being developed in a more open (to user requests) way now.
It's somewhat more complicated because you need at least 3 states: "uninitialized", "somebody's working", and "initialized". Ideally, when somebody's working, you don't just spin (although that's what my lame-but-correct XP fallback does).
this looks like it'd still be the visual compiler for windows stuff, but use clang for mac and linux stuff. So its not really clang for "windows" but clang for windows to target x.
yes. by the time it ships that is our intention. thanks, steve. VC Dev Mgr
If all of your code is proper cross-platform code, then why not.
This is a point to consider in the GPL vs. BSD/MIT argument. Is it a good or a bad thing that Microsoft is able to integrate the open-source clang / llvm into it's own dev tools without open-sourcing most the applications that make use of it (visual studio, their compiler, etc)? Does it help if they throw some bones such as vs code and clr?
awesome. really. while i know this may not be your domain, can we ever expect an easy to use platform to develop UIs for windows in C++? Like the .net guys have? I saw that MFC got some love with the layout feature, but anything else? More? Anyway, with the VS Community edition, and now this, developing on windows (commercial apps) may finally be something to look forward to.
We are talking about building for windows here. see my reply above. This is work in progress. It will allow you to build cross-plat conformant c++ code for windows.
Oh, that's pretty cool. Unfortunately I'm not really into Android. Will it be supported for Windows at some point? And if so, any ETA?
C1 (ms frontend) will continue to get investment. We intend to be good citizens with Clang and have done some early reach outs to a few developers working in the area we have modified related to debugging information. Right now we are trying to stay laser focused on portable code for Clang. 
Does it have to be cross-platform to use Clang? If i have a project that only targets Windows (at the moment), can i use Clang?
Maybe "standard compliant" would be a more precise / easy to understand term ? This clang wrapper would still be able to understand win32 headers &amp; calling convention, right ?
You already could, using unmodified upstream Clang. See http://llvm.org/releases/download.html for official Windows binaries with Visual Studio integration. What's new here is a compiler that uses the Clang frontend and the C2 backend.
One of these days, I'd like to find one or more volunteers who are familiar with building components and reporting issues to maintainers. I've figured out workarounds for over a dozen bugs, but I just don't have the time to report all of them and get them fixed upstream (I've tried for several with varying success).
our intention is to be good citizens and upstream the clang part of the changes. right now that is mostly codeview symbol information. we had reached out to a few clang developers working in similar areas to let them know we were working on this but now that we've announced this project publically, we hope to collaborate more openly. of course, top priority will be shipping though.
no, we are not abandoning the existing compiler front-end. This is an "and" not an "or". 
not sure I understand the question. You mean windows store apps? then we've always supported that. And as announced at Build we also support writing Android and iOS apps in C++ in Visual Studio 2015 RC 
this is going to be in Visual Studio 2015 in an upcoming update (post-RTM).
Thanks for the info, sounds awesome! I'm really impressed by all the things MS has been announcing for developers just this week alone.
current plan is in the express edition. (although, we recommend community edition)
According to my knowledge, libstdc++ still doesn't have a native Windows implementation of thread. (I am uninterested in POSIX wrappers.) But fortunately, Boost has a native implementation. Simply compile with `-DBOOST_THREAD_VERSION=4` and you'll get Standard-conformant behavior. I have nothing against libcurl but I don't use it - the distro contains only what I use myself (and gdb, so people will stop pestering me about it).
Not very interesting watching someone correct errors in a project but you learn things. Mainly how useful a tool like PVS is.
I think that's really undesirable if you want to make something with no dependencies. After all, the standard library does come with `std::thread` and if I'm using all the other C++11 features it'd be a bit weird to still be using `boost::thread` with a specific conformance macro. Thanks for the answer though. I think it'd be good knowledge to learn how to compile GCC and friends but it seems really complicated.
Apple already did that. If you use clang as packaged with Xcode or whatever, that is NOT an open-source compiler. I've seen people who can't build their code with open-source clang because it depends on proprietary Apple patches.
I think that there's a critical point where a project becomes large enough that it can't be replaced, and evolves fast enough that that it doesn't make sense anymore to maintain private changes to it. For these projects, the GPL is not a necessary incentive to share code. LLVM and Clang would definitely belong to that group. Sony had a private fork of Clang and LLVM, and found it to be a nightmare to merge, so they are slowly going public.
&gt; C++ probably requires a greater understanding of programming than other languages Interesting. I'd say C++ gets in the way of programming more than any other language. &gt; There are C++ libraries and toolkits out there that use a well selected set of C++ features, thus making them easy to use LLVM is a better example, IMHO. However, the worst thing about LLVM is that it is written in C++ and, consequently, is hugely bloated and slow. &gt; A good example is Qt...thanks to C++ - fast as hell. I considered buying a commercial Qt license years ago. I found that, thanks to C++, it is as buggy as hell. Doesn't hold a candle to WPF on .NET... 
last time i tried, it didn't support debugging, and it would fail to compile anything that used exceptions also intellisense had no idea about anything clang was doing that msvc didn't
OK. Is it possible to slot the existing clang-cl into VS community 2013, or are we waiting for 2015?
If only the community edition was smaller in install size. Limited C drive is a pain.
&gt; The other is that you can do either automatic or manual memory management in C++ (and do them at the same time, where some things are automatic and others are manual), which probably would've been a much better thing to say. Not really. C++ has no real support for automatic memory management whereas Java has very advanced support for it but no real support for manual memory management. Pointers is perhaps the best example of something C++ has that Java does not. 
I'm also a bit confused about the terminology you use and your 3 boxes. What if I just have 1 of your "boxes" and not 3: a simple, small library written in conforming, cross-platform C++11/14 code, and a small command-line demo app for it. Let's say it also has a dependency on Boost. And the project is maintained with CMake, which generates a SLN. Will I be able to compile that with clang to be able to use the newest C++14 features that `vc` doesn't support yet? And in this scenario, will I have the same awesome debugging experience that I am having now with `vc` or will there be limitations? (I'm thinking about working [Image Watch](https://visualstudiogallery.msdn.microsoft.com/e682d542-7ef3-402c-b857-bbfba714f78d) for example)
Did you do some benchmarks between the two ?
This is great news ! What MS is doing now is the same as Intel do with its [Clang based compiler for OS X](http://llvm.org/devmtg/2014-04/PDFs/Posters/ClangIntel.pdf). They use Clang front end instate of [EDG](https://www.edg.com/index.php?location=c_lang). Apparently Clang AST will be used too instate of problematic AST from MS CL. I really hope that OpenMP 4.0 will be supported too !
How would one obtain sysroot a for cross compiling from a Windows host to an OS X target? XCode's EULA prohibits using their SDKs to develop on anything but Mac hosts...
There have been at least two cases that I *know* of where that hasn't been the case: the initial release of arm64 support, and some new `-f` options.
This is the point.
Expressing unique ownership with a raw pointer is certainly bad practice
something like: example::Message example::Stream::Next() { ... return Message(stuff); } ? *edit*: or std::unique_ptr&lt;example::Message&gt; example::Stream::Next() { ... return std::unique_ptr(new Message(stuff)); }
The issue with GPL code is that it severely limits adoption. Would clang be where it is today if it was under the GPL? Most likely not. There was already GCC, and while the code is of questionable quality, it would've been less work changing it than remaking an entire compiler suite if a GPL licensed implementation would be good enough. As long as a project is active, it being under MIT or GPL doesn't really matter, since it's just good PR to push it upstream, and less time spent fixing conflicts. It's a win/win scenario for 99% of the cases, and in the rest it would've never have mattered anyways.
I'd recommend overloading `operator &gt;&gt;` instead of the conversion: Stream&amp; operator &gt;&gt;(Message&amp; m); The parameter is a message, not a pointer, so you can handle the memory yourself: Message m; s &gt;&gt; m; or, if you really want dynamic memory: Message* m = new Message(); s &gt;&gt; *m; //Do stuff; you can reuse the same object for multiple messages delete m;
If you watch our cross-platform build talk by Ankit Astana, you'll see him demo the android support. In that demo, he shows how you can switch between GCC and Clang for code we build for Android. imagine the windows projects having that same selection mechanism. Thanks, Steve the vc dev mgr 
I am most emphatically talking about patches that were never released (at the time. After the open-source people reimplemented the arm64 backend from scratch, Apple finally released theirs, for example.)
or jus message message() const { return { whatever }; }
That sounds so awesome. Thank you very much for the clarification! VS2015RC is already close to a christmas present (it can't compile range-v3 yet, can't mention that often enough :P) but this update will kick ass even more :-) Thanks!
I've subclassed so much of mfc I've seriously considered starting a branch. But I've no idea how that could work with the code licensing. 
Or even better, just make the conversion into an explicitly named function.
Joel Spolsky explains it well in his blog, using the term "Fire and move". In essence, while everyone is too busy transitioning to the latest Microsoft fad, their time is not spent on developing something truly groundbreaking to bypass Microsoft's market altogether. They're always churning one step behind MS. Meanwhile, MS is one step ahead and can develop new widgets for emerging markets.
How is this different from passing in a callback function/lambda?
That's not just clearer, it's safer. There is barely any reason to use new in C++11.
Looks like you're missing a `*` on this line: int leertasten(char txt1, int textlaenge) Currently `txt1` is just a single `char`, not a string. By the way, this code is C, not C++, yet you've posted this on the C++ subreddit. In the future, please don't post screenshots of your code/errors and instead just copy the code/error text itself.
well then that is because there are more errors.
well fuck you too. We're trying to help you and you just won't accept any answer. Sometimes there is more than one problem with your code. We cannot magically fix all problems. How about showing us what the errors are if you change that line?
Put 4 spaces before each line of your code to format it properly.
&gt; Also: It is C++. Just because the C++ compiler accepts the code it doesn't mean it's C++. * Old style headers and C APIs (`stdio.h`, `string.h`, `strlen`, `printf`, `scanf`) * Nonstandard crap that should **never** be used (`conio.h`, `getch`) * `char *` instead of `std::string` * `void main(void)` is not valid C++ (IIRC, it's not even valid C), it should be `int main()` Also, do yourself a favor and write your code in English.
Thank you so much ! Now I can finally continue working :-)
Viel Spass. :)
&gt; Could you please tell me whether microsotf has changed this or not? Of course MS will change this. I assume that MS will give fixes for Clang front-end (parser and co.) back to the community, but this will not happens with back-end (codegen). 
Someone helped me and got downvoted for helping me. Yep, this is the best community. 10/10. Le reddit
Also get rid of &lt;conio.h&gt; (who on earth still uses that!) and getch(), don't use C style strings (why #include &lt;string&gt; if you aren't going to use them?) and use int main().
&gt;I tried to get help and everyone didn't want to suck my dick &gt;Le reddit FTFY
Not very useful to me without a shell and full coreutils and other utilities used in autoconf scripts. Is it easy to configure an IDE to use gcc from this bundle for building more Windows oriented programs?
Logically, a regular function takes a set of parameters, executes its internal logic, and produces a single result. If you call the function again, it starts again from the beginning. A resumable function can execute part of its logic and produce a value and suspend, then later be invoked again and resume where it left off, possibly producing another value, etc. You can use non-resumable functions to get the same effect as a resumable function, but it is more complicated; you have to manually store state and remember how to continue where you left off.
Couldn't he use one of them new fangled smart pointers in that situation? Am still trying to figure out how and when to use those, I guess "always" instead of C style pointers? &gt;&gt;
&gt; The bad news is that it's only for Windows 10 and above. We understand not everyone is there yet :) Windows 10 isn't even released yet.
we are using unreal engine, which will obviously force us to having making a license with them, though this will be decided after the product has been made
As part of the debug information work, is DIBuilder going to refactored to be able to spit out MSFT-style debug info? It seems like DIBuilder is close to being agnostic and it would be nice for frontends to use a single API. From my understanding, this is should allow Clang to emit PDB files as long as link.exe is used. Are there any plans to contribute PDB support to lld or just documenting the file format so that it could be added?
And i did also note, that this was more for experience. I just really dont want to have to find new c++ programmers half way through the year because people are not committed. I want a good end product.
Well, err, C++11 fixed a lot of things. There is still the sad that that it's new.
I think the main difference is that make_unique is easily implemented, and thus is included in every C++11 implementation. C++14 stuff deals more with stuff needing actual compiler changes and improvements.
Just to be clear, you're wanting experienced programmers but you're also stating this is an "experience" and won't earn money? Most experienced programmers are earning money for their work. If you're looking for an experienced programmer to be "committed" to the project, you either need to have a REMARKABLE (and feasible) end product or you're going to have to pay them. /u/Misker is the type of person you're going to be able to get to work on your project, someone who wants more experience. 
1st of all, I never said i wanted anyone who was "experienced", look what i said, i said i wanted someone "decent" so we have someone to use, but i also want that person to be comitted, /u/misker said "i cant pledge much help" so obvisouly he wont be around all the time to help us, which is what i want. And its not they do work for free, everyone will get a cut of the game and a cut of profits.
Alright, you never stated "experienced". You ARE looking for people who are dedicated, "decent", and able to produce a professional looking product. These qualities are normally found in industry-employed or experienced programmers. Decent programmers are typically employed, you will most likely not find someone to "be around all the time to help". Why would a programmer want to work on your project? 1. As /u/l97 said, there is nothing so far to be excited about. 2. You say that they won't work for free and that everyone gets a "cut of the profits", but in the original post you stated that you don't anticipate this to be a "big earning game". 3. You want someone to be around all the time to work on your project, but they won't be paid until the project is completed. Unless this project completes and starts making money QUICKLY, bills will be coming due. 
Thanks, I'll find the right person to report it to.
Even if message is an abstract class, you can still use stack allocation (assuming you don't need to transfer ownership) eg: DerivedMsg derived; Message* message = &amp;derived;
In this case, Message is returned from the function, implying transfer ownership. 
I´m quite young and plan on studying software engineering this year. Right now I´d have enough time to attend the one in munic and the one in heidelberg. I´ve used c++ for more than 3 years and would classify my knowledge as advanced. Are those meetups viable for someone like me?
It's not "Clang/LLVM" based gcc compiler, that's gcc ported to use the LLVM backend. Nothing related to Clang. That's probably one reason for the performance disparity; the gcc frontends are designed for the gcc backends. Also, an algorithm that is inefficient in the first place isn't a good source of performance comparisons...try a memoized or iterative algorithm. Try this: https://gist.github.com/chbaker0/ae282ec6d3319ae8eb91 EDIT: looks like I'm wrong, and this `gcc` is just a symlink to `clang`. My second point still stands. Also, what the hell is up with the flood of downvotes in this comment section?
Optimal compilation can be postponed for later phases of development. How long does it take to compile? Clang used to faster than GCC.
I can reproduce this locally as well on OSX gcc-4.9 test.c -O3 -flto time ./a.out 45 4.5s clang test.c -O3 -flto time ./a.out 45 6.3 As /u/mebob85 points out, this isn't a good benchmark to compare. It is still interesting though.
No, that's just Clang. llvm-gcc was dropped a few years ago, and the "gcc" executable now shipped with Xcode is just a symlink to clang.
I was pretty sure it's GCC with the [DragonEgg](http://dragonegg.llvm.org/) plugin, but I could be wrong.
Xcode 5 removed that. There is a reason why the version information does not mention GCC.
Gcc is able to do some surprising optimization to eliminate one of the recursions, see: http://stackoverflow.com/a/10058784 This doesn't matter much though, because you'd never write code like this and expect your compiler to turn it into an iterative version any more than you would write bubblesort and expect your compiler to produce quicksort. It's the performance of the iterative version that matters. 
That rule of thumb is extremely old. Clang these days generates extremely competitive code &amp; still wins better compile times: http://www.phoronix.com/scan.php?page=article&amp;item=clang-gcc-broadwell&amp;num=1
Definitely go. Go as often as you can! You'll benefit so much.
Table of contents: 1. The Nature of the Beast. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 C++: What’s It Good For? 2. The Origin Story. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 C: Portable Assembler C with High-Level Abstractions The ’90s: The OOP Boom, and a Beast Is Born The 2000s: Java, the Web, and the Beast Nods Off 3. The Beast Wakes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 Technology Evolution: Performance Still Matters Language Evolution: Modernizing C++ Tools Evolution: The Clang Toolkit Library Evolution: The Open Source Advantage 4. The Beast Roars Back. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 WG21 Tools Standard C++ Foundation Boost: A Library and Organization Q&amp;A Conferences and Groups Videos CppCast Books 5. Digging Deep on Modern C++. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 Type Inference: Auto and Decltype How Move Semantics Support Value-Semantic and Functional Programming No More Output Parameters Inner Functions with Lambdas Lambdas as a Scope with a Return Value 6. The Future of C++. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 Setting the Standard Never Make Predictions, Especially About the Future Bibliography. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . My personal opinion is that it reads like a large blog post, and probably doesn't need to be in book form. Chapters 1-4 seem to be targeted towards people who have never used C++ before. Chapter 5 jumps into code excerpts more suited to those who are already familiar with the language. I guess I'm not really sure who the target audience is. 
It's self-evident isn't? C++ is like the beast indeed.
It will be. When modules get implemented. Then it'll be the big O. And I'm not talking about Big O notation.
Learn English you PVS Studio Russian fuck.
Ok it seems there is some advances with clang 64 bits. However, from visual studio 2013 it is not able to build a Library because clang seems lost in the directories (the x64 prefix seems the cause but I still need to investigate). So it is not fully tested currently ... I would be happy if someone could fix this bug 
When is this planned?
[C++17](https://groups.google.com/forum/#!msg/unofficial-real-time-cxx/j8gDKf4SzKM/p2Obh31eD60J).
Check the sidebar. 
Is this a book ?
This is strange because I am using Clang only fir 64-bit and it works in most cases.
try to use size_t 
Ugh, people falling for benchmark cherry-picking :(
Why can't you help Clang guys to implement full SEH support? That's the last thing that's missing for prope clang support on windows. IIRC it would be enough if you made it clear that implmenting SEH in Clang does not lead to patent violations. After that it's only PDB left.
The [*Ease of Use without Loss of Power*](http://www.pcg-random.org/posts/ease-of-use-without-loss-of-power.html) post also contains the answer to my post here in this subreddit, [*Random number generation: It might be harder than you think to write code that rivals novice-level code written in Python*](http://www.reddit.com/r/cpp/comments/31857s/random_number_generation_it_might_be_harder_than/).
If anybody wants a quick reference, the [Ease of Use without Loss of Power](http://www.pcg-random.org/posts/ease-of-use-without-loss-of-power.html) post describes the front-end API. Great work. The process of reviewing/editing the [unpredictable random numbers sample](http://www.cppsamples.com/common-tasks/unpredictable-random-numbers.html) on C++ Samples taught me all about the bad spots in `&lt;random&gt;` and your posts were helpful at the time. I'm a little uncomfortable even having the sample on there because it (over?)simplifies quite a complicated topic (and the six calls to `rd()` seem quite arbitrary). Hopefully `&lt;random&gt;` will take some tips from your header in the near future and the sample will become completely unnecessary. I'll definitely be using this header from now on.
Great... now you just need to make it use PCG instead. :P
You highlighted the word “best”, but the words you should have drawn attention to are “built-in”. Actually yes, I did mean _pointlessly_ and stand by it. The Mersenne Twister is huge, but despite its hugeness * It fails statistical tests. * It is trivially predictable after 624 outputs. It’s also the case that being huge can be a way to mask being mediocre. Much smaller RNGs can pass incredibly stringent statistical tests and have a period that is galactically huge. Here’s a quote from [the PCG paper](http://www.pcg-random.org/paper.html) about RNG periods: &gt; 2.4.2. _The Necessity of a “Large Enough” State Space and Period._ &gt; &gt; If the period of a generator is too short, it could repeat itself while in use, which is undesirable. A larger state allows for a longer period because it allows more distinct states to be represented, but we quickly reach a point of diminishing returns. For example, given a choice between a generator with a period of 2^128 and one with 2^(256), we might do well to realize that if we had a trillion computers each examining one number per nanosecond, it would require more than ten billion years to mostly explore the period of the 2^128 generator. (Even a period as “small” as 2^56 would take a single CPU core more than two years to iterate through at one number per nanosecond.) If [2^256](https://www.wolframalpha.com/input/?i=2%5E256) is overkill (and it is for general-purpose use), [2^19937](https://www.wolframalpha.com/input/?i=2%5E19937) is just silly. But if insanely huge is your thing, you’ll love `pcg32_k16384` which has a period of [2^524352](https://www.wolframalpha.com/input/?i=2%5E524352) and the added bonus of doing [party tricks](http://www.pcg-random.org/party-tricks.html).
&gt; /u/ProfONeill I just skimmed through the header. I haven't tried it yet but it looks really nice, thanks! &gt; &gt; Here some hopefully constructive feedback: Thanks for the thanks, and the feedback! I'd be delighted to take patches that fix any issues with the library, so feel free to send them my way! &gt; - It would be nice if the library would support ranges for which `begin` and `end` return iterators of different types (like the ones in range-v3). This is a non-breaking change. I don't have a problem with that in principle, but it looks like that'd prevent me from using things like std::distance, since it expects both iterators to be the same type. (?) &gt; - Since `choose` has a `choose(begin, end)` and a `choose(range)` overload it would be nice to add a `pick(begin, end)` overload for interface symmetry. I'm open to being persuaded, but the point of `pick` is to be a function that you can call without knowing anything at all about iterators. If you know about iterators, writing *choose(begin, end) shouldn't be such a burden. &gt; - I think that right now `pick` and `choose` require `ForwardIterator`. I do not think that they work correctly for `InputIterator` because `choose` calls `std::distance(begin, end)` (which traverses and exhausts the range), but afterwards it calls `std::advance(begin, pos)`on an already exhausted range. I am not sure, but maybe it is possible to reformulate `choose` to traverse the range only once for `InputIterator`s, and every time the iterator is advanced maintaining a `x%` chance of returning that element. Maybe reformulating `choose` in this way while maintaining `choose`s semantics is not possible. In that case, `choose` can be constrained for `ForwardIterator`s using e.g. `enable_if`, and a different function can be added that pursues the single traversal `x%` strategy and also works for `InputIterator`s. We need to know _how many_ things we're chosing from to get the probabilities right. An InputIterator doesn't tell you that. 
I found Herb Sutter's monitor&lt;T&gt; and concurrent&lt;T&gt; to be helpful in so many situations. This is one of them: template &lt;typename T&gt; class monitor { mutable T t; mutable std::mutex m; public: monitor(T t_ = T{}) : t(t_) { } template &lt;typename F&gt; auto operator()(F f) const -&gt; decltype(f(t)) { std::lock_guard&lt;std::mutex&gt; _{m}; return f(t); } }; // thread safe cout static monitor&lt;std::ostream&amp;&gt; out{std::cout}; See: &gt; http://channel9.msdn.com/Shows/Going+Deep/C-and-Beyond-2012-Herb-Sutter-Concurrency-and-Parallelism Oh, and take a look at std::ios_base::sync_with_stdio.
&gt; I don't have a problem with that in principle, but it looks like that'd prevent me from using things like std::distance, since it expects both iterators to be the same type. (?) Yes. The ranges-v3 proposal deals with that by re-specifying `std::distance`. &gt; We need to know how many things we're chosing from to get the probabilities right. An InputIterator doesn't tell you that. You can use [algorithm R](http://en.wikipedia.org/wiki/Reservoir_sampling) to pick one item from a stream of unknown size. It's slower than just picking an index if you do know the size, so you'd still want to specialize for ranges for which you can get the size.
Do some bloody research yourself, mate.
But even `pick` returns a reference, which this version wouldn’t be able to do. I do think it’s a cool idea, but to me it feels like it’s its own thing. Probably it’d be best to implement it as a variant of `sample` so you can choose how many items to grab (probably under its own name, although I’m open to ideas what that would be).
&gt; The problem is that choose returns an iterator, and with an InputIterator, your only chance to read it is before you increment it. Unless I missunderstand the standard here, this is not correct: `*it++` is required to have the semantics of { auto tmp = *it; ++it; return tmp; } (see table 107 in 24.2.3, paragraph 2 of C++14). Basically that seems to imply that you must store the value in the iterator (not that I'm saying that this is a good thing, though it is relatively nice for the *users* of the iterators (much less so for those who implement them)).
My point was that once you get to the next statement, you’re SOL. You certainly can’t go back and re-read an iterator from six increments ago. As for the technical point from reading the standard, as I see it, that’s really all about the return value of the post-increment operator. It can, for example, return some special object that gives you one last chance to get at the value.
I totally see where you are coming from, but I have some issues: * `uniform_int_distribution` takes a closed range, while `uniform_real_distribution` takes a halve-open one. That is already bad, but in your proposal those are hidden behind the same method, making that even easier to screw up than it is already now. * You still force all users to create their own RNG-objects (on purpose, I know), which still means that the 95%-case is still more complicated than in say python or with the `randint`-proposal. I would go as far, as saying that those proposals might work well together. Especially if the global prng would use your extended interface. * A few things I noticed about the implementation: * You are using `ALL_CAPS` for normal constants. I know this is quite widespread, but there once was a great overload-article that made great arguments against that style (it boiled down to “`ALL_CAPS` is for macros, because they are dangerous, normal constants are super-safe however and using `ALL_CAPS` for them might even increase the risk of clashes). I'm not saying that it is terrible, especially since it's only inside the implementation, but you might want to consider this. * `template&lt;typename T&gt; void fun(const T&amp; arg){std::uint64_t(arg);}` is quite dangerous, since it performs a C-style cast (yes, it really does!). Calling it with `"foo"` will compile and use the address of the ‘f’. Please consider using `static_cast` instead. * I'm very sceptical, whether I like `local_entropy()`, as opposed to just using `random_device` multiple times and filing bug-reports against implementations that don't provide a high-quality implementation of it. Maybe provide a macro to switch the implementation (something like if `RANDUTILS_BAD_RANDOM_DEVICE` is defined, do what you are doing now, otherwise just use random-device). \[Edit: to implement `local_entropy()`\]
Would you be willing to provide a single header that just provides one or two PCGs without all the stuff around it? Your current C++-implementation really appears to be written well, but if I *just* want to use one high-quality PRNG, it appears like extreme overkill. Maybe make it contain the best that doesn't require gigantic state (EXT2?) and a good faster one.
Interesting feedback, thanks. &gt; I totally see where you are coming from, but I have some issues: &gt; &gt; * `uniform_int_distribution` takes a closed range, while `uniform_real_distribution` takes a halve-open one. That is already bad, but in your proposal those are hidden behind the same method, making that even easier to screw up than it is already now. I get that, and I think that `uniform_real_distribution` has an unfortunate design (I like [Taylor R. Campbell's take on it](http://mumble.net/~campbell/2014/04/28/uniform-random-float) [[PDF](https://gist.githubusercontent.com/flaviut/902f9a0ad03655b19a24/raw/floats.pdf)]). But a half-open real range can be seen as being virtually indistinguishable from a closed one. The odds of getting *exactly* the end value are typically really low, so almost no one should be actually hoping to get the end value and disappointed that it isn't there. One way to consistently view `uniform&lt;T&gt;(i,j)` is that it produces the closed range [T(i),T(j)-T(ε)], where ε is some implementation-defined very small real (which becomes zero for integers). &gt; * You still force all users to create their own RNG-objects (on purpose, I know), which still means that the 95%-case is still more complicated than in say python or with the `randint`-proposal. I would go as far, as saying that those proposals might work well together. Especially if the global prng would use your extended interface. If you want a global RNG, it's trivial to make one. I also think that a little bit of explicitness is very much in the character of C++. We don't have to copy _everything_ from Python ([thankfully](http://en.wikipedia.org/wiki/Global_Interpreter_Lock)). If we all must have a global RNG, I'd argue for making it something like this: template &lt;size_t n = 0&gt; whatever_rng&amp; global_default_rng() { thread_local whatever_rng the_rng; return the_rng; } That way, it'll only come into being if someone actually asks for it (and if it's never used, it won't even waste any space in the code). Otherwise forcing an unnecessary global variable into everyone's code violates the zero-overhead principle. &gt; * A few things I noticed about the implementation: &gt; * You are using `ALL_CAPS` for normal constants. I know this is quite widespread, but there once was a great overload-article that made great arguments against that style (it boiled down to “`ALL_CAPS` is for macros, because they are dangerous, normal constants are super-safe however and using `ALL_CAPS` for them might even increase the risk of clashes). &gt; &gt; I'm not saying that it is terrible, especially since it's only inside the implementation, but you might want to consider this. I'm happy to take patches. Bikeshedding about my coding style is an okay pasttime—I'm glad you care. &gt; * `template&lt;typename T&gt; void fun(const T&amp; arg){std::uint64_t(arg);}` is quite dangerous, since it performs a C-style cast (yes, it really does!). Calling it with `"foo"` will compile and use the address of the ‘f’. Please consider using `static_cast` instead. Point taken. &gt; * I'm very sceptical, whether I like `local_entropy()`, as opposed to just using `random_device` multiple times and filing bug-reports against implementations that don't provide a high-quality implementation of it. Maybe provide a macro to switch the implementation (something like if `RANDUTILS_BAD_RANDOM_DEVICE` is defined, do what you are doing now, otherwise just use random-device). All my seeding stuff came into being solely to work around the bizarre requirements of _Seed Sequences_ and the crazy specification and implementation of `std::random_device`. I'd love to see these issues repaired in the standard and have us all just write std::default_random_engine my_rng_engine{std::random_device{}}; That's not the world we live in right now. But having written it, I do see something neat in not putting all our eggs in a single entropy basket. It also turned out to be faster, which was unexpected but is quite nice. 
Absolutely. It’s actually already somewhere on my to-do list.
;-) Cute. Actually, it’s funny that you say that because /u/F-J-W was [just saying](/r/cpp/comments/34yqxa/announcing_randutils_a_single_portable/cqzwh1e) that we should be “just using `random_device`”, but with the GNU libstdc++ implementation, that class uses Intel’s RDRAND, which [some people think has an NSA backdoor](http://arstechnica.com/security/2013/12/10/we-cannot-trust-intel-and-vias-chip-based-crypto-freebsd-developers-say/). More seriously, if you’re doing crypto, you should use a good crypto library. If you’re writing a crypto library, you’ll make your own choices on how to seed, etc. Generally, you’ll use well understood tried-and-true techniques, not something just posted to the Internet by a random college professor.
I currently program C for a living, but was always interested to learn more about game design. I graduated in Computer Science and learned C++, Java, Perl, ... I can't promise to take it on as main hobby, but am willing to contribute.
&gt; It would be nice if the library would support ranges for which begin and end return iterators of different types (like the ones in range-v3). This is a non-breaking change. &gt; I don't have a problem with that in principle, but it looks like that'd prevent me from using things like std::distance, since it expects both iterators to be the same type. (?) Right, you are totally correct, sorry I missed that. I can only think of too complex solutions for this (range-v3 handles this with its own `ranges::distance`), so I'd rather handle that at my end. &gt; I'm open to being persuaded, but the point of pick is to be a function that you can call without knowing anything at all about iterators. If you know about iterators, writing *choose(begin, end) shouldn't be such a burden. I was thinking that sometimes one just has iterators and nothing else (e.g. Boost.Iterator::counting_iterator). Of course using a e.g. Boost.Range::counting_range is nicer, and of course using `*choose(begin, end)` is not too much of a burden. So I sadly lack a better argument than "why not?", it doesn't complicate the library excessively, and it helps those who might need it. &gt; We need to know how many things we're chosing from to get the probabilities right. An InputIterator doesn't tell you that. I can submit a pull-request (PR) to constrain it to ForwardIterators. Do you happen to have a `.cpp` file that tests the library somewhere? I would feel more comfortable if I can avoid embarrassing myself by sending a PR that breaks the library somehow :) &gt; We could indeed use reservoir sampling if we were returning the selected item by value, because we could store it until we return it, but that’s getting pretty far from how choose normally works. `InputIterator`s can be dereferenced multiple times. `choose` can thus dereference for probing, and then return the iterator itself as long as it doesn't advance it further. `pick` could just return whatever the `InputIterator` returns when dereferenced. I think this depends on the particular `InputIterator` at hand, since it might be a reference to something, a value, something convertible to the `InputIterator`'s `value_type`... The standard is pretty vague here. &gt; Probably it’d be best to implement it as a variant of sample so you can choose how many items to grab (probably under its own name, although I’m open to ideas what that would be). This is a different alternative that I think is worth pursuing on its own. Motivation: i'm very interested on `InputIterator`s because sadly the current iterator categories in the standard are very strict with respect to what an iterator returns when dereferenced. The only iterators that can return e.g. a value instead of a reference when dereferenced are `InputIterator`s. This means that if I have an array `[0, 1, 2, 3]` and map it to the random access sequence `[1, 2, 3, 4]` by using a `transform_iterator` (or a e.g. `view::transform`) with the function `[](int i) { return i + 1; })`, the iterators to this random access sequence are `InputIterator`s because they do not return a reference to an `int`, but an `int`. 
I do have some test code, but it’s not especially beautiful. Most of my testing was making sure the seeding stuff worked. Much of the `random_generator` library is such a thin wrapper that it doesn’t need a lot more testing than the examples I give in the article.
&gt; once an InputIterator i has been incremented, all copies of its previous value may be invalidated. If an `InputIterator` is dereferenced multiple times _without being incremented_, it is required to return the same value. This means, in practice, that this value _might_ need to be cached somewhere. When this is the case, it typically happens either inside the `InputIterator` or inside the `InputRange`. Maybe I understood your point wrong and we are talking past each other :/
I've constrained `choose` and use ADL everywhere for `begin` and `end` since they are customization points (like `swap`): https://gist.github.com/gnzlbg/efbacf7c668f783cd021/revisions There are some issues with supporting range-v3: - it has its own iterator categories, and it translate them to the STL iterator categories, which means that e.g. `view::iota(0, 10)` has random access range-v3 iterators, but input iterators when used with the STL. - advance is a customization point in range-v3, but not in the STL, and not in the STL2. - distance is not a customization point, so if this is allowed only `ranges::distance` should be called. - begin and end might have different types... All in all I think that one needs different code for the STL and range-v3. So even tho a macro could be used, one ends with 2 versions of the library within the same file that might need to be supported. From reading the code in the library, I think it might be enough to replace std::begin, std::end, std::distance, and std::advance with its `ranges::` equivalents and use different template parameters for each iterator. So maybe it is not that much work. However, it is up to you if you want to support that. The MIT license allows other to adapt the library for their uses, so it shouldn't be a problem anyways :)
I speak about the compilation within visual studio. This is the title of the topic. I really Wonder what you are testing. The flag you mention are not usuable in Visual C++. BTW, the Windows installer Fromm llvm is still postfixed by win32. So for me there is no mystery. With Visual Studio 2013 only 32 bits is working. So please DO Not SPREAD wrong information 
Nice work - I'll be sure to have a closer look at it when I get home from work. A few nitpicking comments now - the comment says that the seeder does not perform dynamic allocation, but it does use malloc to mix the address into the entropy. You say you don't care about race conditions, but technically any data race causes undefined behavior - or in Herb Sutter's words "there is no such thing as a benign race". You should use an atomic here - if you're worried about cost, you can remove the dependency if the user defines a " I know what I am doing " constant before including. Your complaint that libc++ and stdlibc++ return 0 for the entropy is targeted at the wrong people - the definition of the function in the standard does not make much sense in my opinion, the limitation to log2(max()+1) does not make sense in combination with the footnote). All comments are complaining at a high level though, it's certainly better than what the standard provides.
One problem with using half-open for ints is that there is no way to specify a random that covers the entire domain of ints, which is useful if what you really want is pure random binary data.
... and it doesn't even express the same logic as the original. Very confusing... 
Well spotted! I didn't bother reading quite so closely, just filed under "unnecessary use of templates" and moves on.
I hope so, but strongly suspect overzealous use of templates syndrome. 
&gt; GCC's output is 308 lines long. WTF? Which version or options are you using? That code on gcc 4.9.2 is only 33 lines long on default settings. Even if I turn all the filtering off, gcc only gets to 238 lines, while clang goes over 300?
`with Qt-power` seems pretty bold :p
Yep, just like how trains can drive on city streets.
Thanks so much for the feedback! Dynamic allocation: `seed_seq_fe` doesn’t perform dynamic allocation, but yes, `auto_seeder`’s `local_entropy` function does. I could make that configurable so that people who really don’t want want that don’t have to have it. But people who care _that_ much probably want to do something else for seeding (which is totally possible and configurable—`random_generator` doesn’t have to use `auto_seed_256`, the second template argument let’s you set it to anything you like). Race conditions: You’re right, of course. I could sputter about “show me a platform where it’d be an issue!!!1!”, but I’d be backing the wrong side of the argument. Friends don’t let friends rely on undefined behavior. zero `entropy`: I agree that it’s poorly specified, and possibly _can’t_ really be specified in a meaningful way. Nevertheless, I don’t think returning zero is the right choice. Returning 32 is at least as sane to me, for reading from ‘/dev/urandom`.
[Only if you spend the necessary time giving it infrastructure, and by that point it's probably not worth it](http://en.wikipedia.org/wiki/Tram)
Good points. The nice thing about the `random_generator` template is that if you default construct, it uses nondeterministic seeding, but if you provide a seed, it gets handed off to the engine as usual, giving you nice reproducible results. It’s worth remembering though, that if you can provide highly unpredictable random numbers _cheaply_, then that’s obviously much better highly predictable random numbers. PCG, for example, is way cheaper space-wise and time-wise than the Mersenne Twister, but is much more unpredictable. I wouldn’t rely on them for crypto myself (I’m happy to throw some extra cycles at security), but some of them probably are, in my biased opinion, _really_ hard to predict. 
There is a very similar project: https://github.com/ocornut/imgui "ImGui is a bloat-free graphical user interface library for C++. It outputs vertex buffers that you can render in your 3D-pipeline enabled application. It is portable, renderer agnostic and carries minimal amount of dependencies. It is based on an "immediate" graphical user interface paradigm which allows you to build user interfaces with ease."
Thanks for these. Unfortunately, `thread_local` is can’t be relied on in portable C++, since on OS X with Xcode, you get this: tl.cpp:1:1: error: thread-local storage is not supported for the current target thread_local int x; ^ 1 error generated. (this error is particularly annoying because it’s fixed to work properly in the non-Apple OS-X Clang 3.6; it’s just that Apple hasn’t removed their home-grown disabling of the feature, which they added back when `thread_local` was broken [i.e., before I reported the bug and got it fixed]). I’ll probably want to mull over just how I’d like to handle the sentiment “just use `std::random_device` for nondeterministic seeds”. Probably I need to give several options, depending on (a) how much people want to call it (some people do apparently care about not having programs repeatedly read system entropy; I don’t agree, but…), and (b) some people may not want to put all their trust in something outside the program. 
That's vertex-based. Kiui is vector-based and looks much better.
No, not really. But you can write program that can use both CPU and GPU. There exist technology that is based on DirectX that allow this [C++ AMP Overview](https://msdn.microsoft.com/en-us/library/hh265136.aspx) If you want to be portable then this is the better chose. [OpenCL](https://www.khronos.org/opencl/) 
Thanks! BTW, by streams I meant in the RNG sense. A separate stream is like a whole different RNG sequence. In essence, if you have 2^63 streams, it’s a lot like turning your RNG from having a period of 2^64 to having a period of 2^127. I think 2^127 is a minimum to keep some people from worrying.
Thanks! This looks like a copy-paste-o: template&lt;class It&gt; auto end_(It&amp;&amp; it) -&gt; decltype(begin(std::forward&lt;It&gt;(it))) { return begin(std::forward&lt;It&gt;(it)); } 
&gt;Can Gpu be used to run programs that run on Cpu See other comments. &gt; like getting input from keyboard and mouse Actually... yes they can. See [here](http://www.cs.columbia.edu/~mikepo/papers/gpukeylogger.eurosec13.pdf). &gt; or playing music Given that you can open a file and page it into memory and from there move it onto the GPU there's no reason the GPU couldn't play it. Since HDMI carries sound there may be a way to put the data out that channel. That said I don't know how to do this so I can't help you much. &gt; or reading the contents of a text file using Direct3D and OpenGL Api? This one is much easier. There's well known D3D and OpenGL interop for OpenCL and you can use the same processes to write text to a texture and display it that you normally do. Now, that said none of these are running purely on the GPU. There's nothing that runs purely on the GPU. Everything is run from the CPU through the graphics (or compute) drivers and offloaded to the GPU. In the case of OpenCL this means you can run the same source on both CPU and GPU just by telling it not to offload to the GPU. Kinda handy for debugging.
I can echo the sentiment of "just use the operating system's randomness API". However, as usual, the C++ standard does not make things easy. `std::random_device` is not required to be nondeterministic, and in libstdc++'s case (on Windows, where `rdrand` is not available) it isn't: `random_device` there is simply `mt19337` with a hardcoded seed (5489). My general workaround is to use `boost::random_device`, which is either [nondeterministic or not implemented where that would be impossible](http://www.boost.org/doc/libs/1_58_0/doc/html/boost/random/random_device.html).
And why is that important? It also run in a browser. But you are right, it looks better. http://floooh.github.io/oryol/ImGuiDemo.html 
You can purely run on the GPU. First of all you can launch a single kernel with a single thread and and run your program. You can also do dynamic kernel launch from within this first kernel launch. You would only require the CPU to launch the first kernel. 
Except that you are still using the CPU to launch that first thread. This does beg the question - could you use a GPU as an embedded CPU and actually run something without the CPU at all? I'm curious now. Oh, and at least on NVidia hardware under OpenCL you still can't do dynamic dispatch. 
Mostly because it looks better (when using NanoVG at least). Don't get me wrong, the functionality looks neat. It just doesn't look too good to put in a game. Even the designer says it's designed to be used for debug tools. I think it certainly does the job fine for that.
Can you clarify? I might be dense but it seems like the behaviour is the same.
Unless *I'm* being dense, boring(2) -&gt; f(4) wrapper(2) -&gt; f(1)
Trams are so worth it. I guess you live in a city without them :-)
Are you drunk? 
Yeah, I mentioned the issues with `std::random_device` in [*Everything You Never Wanted to Know about C++’s `random_device`*](http://www.pcg-random.org/posts/cpps-random_device.html) including the fact that Boost shows how it _ought_ to work. But “just use Boost” isn’t an answer everyone likes, since that sometimes feels like a bit of a heavyweight commitment.
FWIW, given all the RNG engine choices out there, there is pretty much no reason to ever use an underlying engine where the output range isn’t a power of two (specifically 32 bits or 64 bits). If you’re doing that, the output from the underlying engine gives you a nice bitstream without your needing to do anything fancy. 
Can you please move some people from the library team to the language team? Some of these lacking features have been missing for nearly two decades, for example two-phase lookup. It's well-specified and not difficult. 
Ah. OK. You're pointing out that his &gt; should be a &gt;= in his template example? That's fair. I wouldn't quite characterize that as not expressing the same logic though; more in the class of off-by-1 errors. 
Seeing the code examples, no (or else it's very well hidden beneath)
You're right, and thanks for the "nice-ification". I tend to be very direct and honest with my feedback. This is what usually makes it useful. No beating around the bush. If people just want to hear "Oh yea it's nice", they shouldn't post it in places where feedback can be given (or not downvote if they don't like the feedback). I think I was objective, to the point and not rude, so I would welcome an explanation for the downvotes. And, while your paragraph sounds nicer than mine, it changes the meaning of my feedback. What I said was that in my opinion, a GUI framework should be built from the ground up with keyboard input in mind. What you phrased is "It's nice as it is, you should _extend_ it with keyboard input".
Is it a problem if more than one person writes articles on the same subject? I haven't seen one that's exactly the same as this, and it always gives a slightly different perspective anyway. I think it's great to have more people writing about C++ because it means reaching more readers. I'm also not sure what nice formatting has to do with ignorance. I think it's great when people actually care about how they are presenting their thoughts. Looks like this is just a WordPress theme anyway.
It's not that bad for an in-game UI. Plus it's skinnable with stylesheets.
[The most important thing you should know is that the RaspberryPi is a strange beast where the ARM CPU is the not main CPU - it's only a co-processor to the VideoCore GPU. When the RaspberryPi starts, a GPU blob is read from the SD card to the L2 cache and executed. This code then brings up all the important peripherals (RAM, clocks etc) and starts the ARM CPU. Then the 2nd stage bootloader or some operating system itself can be run on ARM CPU.](http://raspberrypi.stackexchange.com/a/7126) But basically if you want your gpu to be the one running everything than it is the bios that has to be written in such a way. BIOS are created by motherboard manufactures to work with their specific motherboards and the components that plug into them. There are some open source bios but they are few and far between with an extremely small number of supported motherboards. Coreboot is the most common as it is used in all chomebooks due to it's quick boot time.
a side note: it is in fact not possible to shoot yourself with move semantic. if move is not possible it defaults to copy. from logical and semantic point of view your program is always correct !!! that is no blowing!
&gt;Is it a problem if more than one person writes articles on the same subject? &gt;[snip] &gt; I think it's great to have more people writing about C++ because it means reaching more readers. As a general answer to your question, if what's being written is of mediocre to poor quality then having lots of it is a **very** bad thing. 
sometimes semantics are broken fundamentally in the case of IEEE float/double and the operator == 
IMHO it is neither overloading nor custom defined operators the culprit, but it is: implicit conversation. For one thing I hoped we can have almost any character available to be defined as user operator. You can always have broken semantics with or without overloading. That's the whole point of abstraction and the ability to talk with a language of the domain , no!?
meetingcpp: Kiui looks like it started from scratch by following some of the features and demos of ImGui as a loose guide and toward becoming it's own thing (you can see traces of ImGui examples in Kiui). The code and architecture and features are extremely different. Disclaimer: I am the author of ImGui so obviously biased. Personally (== my taste) I think it evolved the wrong way. Kiui syntax is longer, weirder, more C++ ish (not a good thing in my view; not inclusive), the benefit of an IM approach are lost, it doesn't look like it cares about performance in the same order of magnitude as ImGui did. Among the good things it support plenty more layout features than currently available in ImGui (also still in development and planned eventually but god knows when). It is sitting in a weird gap. On one side, it may not be as efficient or inclusive for most users to provide large amount of unintrusive quickly engineered embedded tools for AAA quality game on a &lt;1 ms budget. On another side, it's not standard and feature-full like QT and no-one wants that sort of UI for end-user (I wouldn't use Kiui in-game the same way I wouldn't use ImGui). So it's sitting in the middle there, which may be a nice spot or not depending on how you see it. It's certainly usable and competent, if you are only working on PC the performance may not be much of an issue. I'll watch it to see if there's ideas or features I could borrow from it. Either way the more choices the merrier. At the end of day, your own familiarity with one or another style will drive your desire to use one or another. Some people are turned off by some aspects of ImGui that I think are qualities, so there's ample room for variety. &gt; "That's vertex-based. Kiui is vector-based and looks much better." That sentence doesn't make sense. They are both using similar technology, aka creating shapes out of triangles, not black magic here. There's a branch of ImGui that supports anti-aliased shapes and it's only a small set of modification, adding a fringe of transparent vertices to provide anti-aliasing. The reason it's not in trunk yet is that I'm overly caring about performance and want to keep optimising it before it goes to trunk (it will). If you load a "smooth" font instead you get a different result. https://cloud.githubusercontent.com/assets/8225057/7023421/f47d7f3c-dd2c-11e4-9d27-937a37b3e9b3.PNG That is to say, the "look" isn't due to a technological barrier but just a matter of style and implementation requirements. 
ahhh if only i got 1e-6 bitcoins for each post asking on C++ advice on pure C code :(((((((((((((((((((
A better wording would be "Gutting semantic". But I don't think that could make it into the standard :)
Rather it highlights a particular feature or idea is not easy teachable, and too much "expert friendly". Move &amp; Rvalues are inherently hard, and the wording confusing.
Sure, I was talking more specifically about posts like this one, which I think is a perfectly fine contribution.
on that note (about seeding), is it (or can it be efficiently made) possible to get the current seeded value? That would be useful to recreate scenarios which occurred during testing or in the 'wild'. 
Shame, I really love the idea of: std::gutted(customer); 
I don't get how moving a const can make sens to anybody ! Declaring a "variable" const not only means the internal won't be edited but also that the symbol will stay "attached" to the object. If you where to move a const, the symbol would no longer refer to the same object but would rather point something potentially invalid. Who would want that ? Would it also make sens to you to swap two const objects ? It doesn't to me !
&gt; It should be taking a non-const rvalue reference, but it takes const X&amp;&amp; just accidentally because of its similarity to copy constructor. And guess what, all the type checks are passing, the program prints “move”, as you’d expect, but the vector m_v is copy-constructed, not move-constructed. Well, I was lucky to spot the problem early, but this kind of mistake can be really sneaky! I am not convinced **at all** by this argument. To me, it boils down to: **const &gt; move semantics**. The thing is const, it can't be moved off, so a copy will happen! C++ is a language that does not hold ones hand, always has been.
The confusion is taking a real world concept like moving and assuming it applies to the computer world. Doing that is very naive. Though even at that, I wouldn't consider an object moving around in the real world to be all that *constant* anyway.
Yep.
 LargeObject lo = GetLargeObject(); foo(std::move(lo)); shootSelfInFoot(lo);
Must be a British thing - we refer to someone as feeling gutted when they're extremely disappointed. As in "I was gutted that Labour lost the election".
The language uses "move" in a different sense than the user expected. A series of rants not worth reading results. Imo, cpp MUST be learned from a decent book.
As I wrote here: http://www.reddit.com/r/cpp/comments/355iir/c_curiosities_one_does_not_simply_move_a_const/cr19xx5 you don't need move semantics for shooting yourself in the foot this way. A `foo(LargeObject&amp;)` that leaves `lo` in an "unspecified but valid state" has the same problem. With move semantics you need to write `std::move` explicitly to break your code, since otherwise it won't compile, or a copy will be performed.
I'm glad you liked the formatting, I'll take that as a compliment :) On ignorance -- we are all learning, and I'm just describing the learning process I had, and the mental model that stood in the way. Maybe my choice of words is not sufficiently clear, because people seem to think that I'm proposing to make `const` objects movable. I'm not. From what I see in practice, rvalue references and move semantics is perhaps the most difficult topic in C++11, it doesn't look like it is explaned *enough*.
There is potentially a big difference in performance between vector move and vector copy. If I'm explicitly requesting a move, and it can't be done, I'd rather prefer the language to raise a warning...
What would you recommend to use in a game then? They're doesn't seem to be any middleware that does quick but good looking ui. Kiui seems to fit the quick and OK looking ui. Imgui seems to be super quick but excidingly ugly. As you say, it's a matter of balance.
Depends on the game really. Most games don't need a lot of UI of that sort and are better off with custom code imho. Look like my opinion of what looks ok and what-not won't matter here.
That last example would be undefined behavior though, right? const_cast isn't meant to be used that way.
Makes perfect sense to me, and in fact moving const/immutable objects is common in many other languages, the problem is C++'s conception of move semantics. In other languages, when you move an object, the original one becomes unavailable, it's just gone for good, and the compiler either enforces this with an error if you try to use an object after a move, or moves are only possible in situations where the original object becomes inaccessible like in a return statement. C++ already makes an exception about const objects losing their const when an object gets destroyed. For example, destructors are not const and so when a const object invokes its destructor, the destructor may freely mutate the internal state of that object. Of course we don't generally take issue with that because the use of a destructor implies that the object isn't being referenced by anything else and hence any mutations to that object are unobservable from the outside. Well a similar line of reasoning applies to move semantics in most other languages with native support for move semantics. A move always destroys the original object and so any mutations that are carried out are unobservable. The only issue with C++ is that in C++ moving an object does not invalidate that object, the compiler really doesn't know anything or treat a move as anything special. Move semantics in C++ are basically a convention that comes about from the use of r-value references in a certain way. In other languages, move semantics are a native part of the language and the compiler enforces their semantics. As such I think it's natural that people may be confused about it.
I don't understand -- why do you need "future" boost versions to work on XP when prior versions still work? I'm not being flippant -- I'm on the other spectrum -- I would love to have a fully C++14 version of Boost without any support for past (or non-conforming) compilers.
But the donation argument still stands. Surely you're using boost because of the high quality of the libraries provided, not because it's free (though of course nobody minds that). I personally am not a maintainer of a boost library, but I i'd were, XP support would go away. The OS and its APIs are simply way too old. About market share: The numbers I've seen suggest that they're way down. Around 16% or so. Where do you get your numbers? 
Yes, you just have to the initialization it in two steps so that you don’t put the seed data in a thrown-away temporary. auto_seed_256 seeds; mt19937_rng {seeds}; and then at any point in the future… uint32_t store[seeds.size()]; // size is a constant expression (8) seeds.param(store); and then later auto_seed_256 repeat_it{store, store+8}; or, since you’re not using any auto-seeding seed_seq_fe256 repeat_it{store, store+8}; 
According to [StatCounter](http://gs.statcounter.com/#desktop-os-ww-daily-20150407-20150506), about 10% of the people browsing the sites running their tracking code use XP. [NetMarketshare](http://www.netmarketshare.com/) gives a higher number, about 16%. This is still hugely dwarfed by Windows 7, at over 50% on both sites. &gt;Windows XP has more market share than Windows 8 or OS X, Linux and Windows Vista combined. OSX is an (in many peoples eyes) overpriced platform, no one in their right mind still uses Vista since it was so crash prone, even more so with OEM software, and Linux is (sadly) still a niche OS. You know what they say, ["lies, damned lies and statistics"](https://en.wikipedia.org/wiki/Lies%2C_damned_lies%2C_and_statistics).
At some point in time it will be possible to drop XP. Lagging several versions behind will result in a rather painful upgrade to the then latest version (I've seen this happening before). Having a C++14 version of Boost is completely orthogonal to this since even the next version of Visual Studio still supports XP (thanks /u/STL).
const is not a property of the object, it's a property of the symbol representing it. A const obj and i'ts non-const brother are the exact same in memory, and that means const_cast is so trivial. We you allocate an object it is neiter const nor non-const. It just IS ! And then you have a symbol represent it and give it thoses cost properties at compile time. That's juste for good coding behaviour and to prevent you/a user of your API do do something stupid. When the descructor is called, the object (is suppose to) has reached the end of it's lifetime. Fact is you should never have to access it ever again, It might even have never existed, so you shouldn't even have to consider whatever the compiler/system does (except the garanty that the memory is made freed) C++ is not like Python or other langages where you have a full runtime with introspection and all those (nice) features that kills the performances. It's, like C (not everybody will agree on that but that's my opinion), just an abstraction to help you build good assembly code without actually doing assembly. And I believe it should remain that way ! So go back to the head/stack and think for one second what an object is at runtime, and what it is at compile time ... because attributes like const only make sens at compile time
If you are still using XP, than there is a huge idiot somewhere in the decision-making. It is not boosts task to support huge idiots.
**tl;dr**: You cannot change const objects and that rule doesn't have any weird special-cases in the context of moves. No shit, Sherlock!
There: Windows XP - 16.94%. Now, true, if you are in an industry that hasnt moved from XP, that 16% doesnt mean anything to you. To you, usage is 100%. But then, if you can't get them to move, just pay up. 
The ability to delete an overload for `const T&amp;&amp;` can be useful.
The release notes have been updated. We're also in the progress of fixing other omissions (e.g. many STL features are missing; I maintained my feature tables for my post, but forgot to ask if anyone needed them for the VS-wide notes).
Don't underestimate static code analysis! I'm using LLVM's static-analyzer every now and then together with Clang's -Weverything (and sorting, filtering, categorizing reports) every now and then and you would be surprised as what you find with half an hour effort. Example projects from the last months where I found issues and undefined behavior include: Z3, osm2pgsql, openh264, fish-shell, ceph and more. From undefined behavior to tautological compares, there's everything out there. Please invest a few hours to learn and use such tools!
expired on March, 22nd. nice move boost.
How did I miss this one? Now linked from http://en.cppreference.com/w/cpp/links
Join the Bjarne Stroustrup club. The article could have been two lines. Don't use const T&amp;&amp;. Because it makes no sense to have a const temporary. Simple rule. C++ is complicated enough without obsessing over the trivially easy ways to avoid foot shooting.
Have a look at Rust, in Rust when you move an object you can no longer access it through its previous binding, doing so is a compiler error: https://doc.rust-lang.org/book/ownership.html Another language with move semantics is D, but in D the choice of whether a move or a copy is performed is done by the compiler, not the programmer. Basically as a programmer you simply pass values around and the compiler will determine syntactically whether to perform a move or a copy. Nim also follows this approach of leaving the choice of whether to move or copy entirely up to the compiler. Other than those languages which are similar to C++, you have pure functional programming languages with linear types like Clean and Mercury where move semantics are available through the use of uniqueness types. I mean all objects in those languages are immutable, and yet they have move semantics which are type safe. The common element in all of these other languages is that moving an object destroys that object, which is why it can be performed on immutable/const objects, any change to the immutable object is completely unobservable and hence is type-safe. But C++ doesn't know anything about move semantics, and hence the compiler is unable to enforce any guarantee about object destruction on a move operation. Without that guarantee it is not type safe to move a const/immutable object because the object may still have a visible binding. This is ultimately why one can not move an immutable/const object in C++.
try char letter; scanf("%c\n", &amp;letter); ... &amp;&amp; (phrase[i] == letter) there's probably a new line left in the buffer. 
&gt; the compiler will determine syntactically whether to perform a move or a copy. I'm not well-versed in D or Nim, but just by that description, that sounds to me less like move semantics and more like copy elision. Could you explain a little more exactly what it is they're doing?
Anyone know how well it works with uninstantiated templates &amp; modern C++? This worked awesome for regular C/C++ libraries I built a few years back but I've never tried with templates. My guess would be that it works for simple cases but not so well in the general case as determining API compatibility between two templates is likely a turing-complete problem.
 #include &lt;ctype.h&gt; char letter; // occasionalumlaut is right scanf("%c\n", &amp;letter); for (i=0; i&lt;strlen(phrase); i++){ if (phrase[i] == letter &amp;&amp; cont &lt; 1) cont++; //else if (phrase[i] == ' ' || phrase[i] == '\n' || phrase[i] == '\t' || ...) else if (isspace(phrase[i])) { word++; aux += cont; cont = 0; } else cont = 0; // otherwise, you'd probably want to reset cont? }
Especially with the forced HTTP -&gt; HTTPS redirect.
This is a very good point. I just want to add that wether you can write to read only memory is operating system dependent... even if the compiler puts some data in some region it considers to be "read only", the operating system might still let you write to it (yay!...). For things like a `static const int`, or string literals, things are simpler. But.. Consider e.g. a `static const` object, with an internal mutex that synchronizes read operations. Every time you read from it, you implicitly get the mutex (and thus modify the object), but it is `static const`! Anyhow I think that the important thing is that, as you argue (with compiler optimizations enabled) it is really really hard to tell if some particular case is not UB, so in my opinion the only thing sane one can do is "don't do that".
I don't agree with this: &gt;This pushes the problem of checking for error conditions and interpreting error codes onto the caller, which is okay if a little potentially buggy if the caller doesn't catch all the outcomes. Note that code calling this function must still be exception safe in case bad_alloc is thrown. One thing which is lost however is semantic meaning of the result, so above we are overloading a null shared_ptr to indicate when the function failed which requires the caller to know that fact instead of instantly being able to tell from the API return type. I would argue that the user of the API function isn't supposed to check the return value for nullptr, and instead should always check the error value. Baking the error value into the return value with std::expected is only a syntactic/semantic difference. The user of the API call still needs to check various error codes before trying to use the expected result - which is a reasonable demand. So all you have done is placed more weight into the *notion* of a return value - which is a style preference. Or am I missing something?
I think this boils down on your own view of defensive coding. I think everyone can agree that defending against a human error is always the wrong thing to do. So the question remains; how easy can your situation occur in a non-programmer-produced error, and can you recover from it?
look at this: http://channel9.msdn.com/Shows/Going+Deep/C-and-Beyond-2012-Andrei-Alexandrescu-Systematic-Error-Handling-in-C now you don't need to introduce something fancy just for small part of your app but use it cross-app: Expected&lt;T&gt; where you get either T or exception
These things (expected and optional) represent a "potentially valid" result. They allow you to not care as long as the result is valid (e.g. no error happened). You can just use the result as is. No checking. Just like exceptions. I guess this is the main difference. However: &gt; If an error happened, trying to use the result will propagate the error (e.g. rethrow), so the error won't be lost. When you do care about _some_ errors, you can handle only those, and let the rest propagate: maybe_result_maybe_error.if_ok(use_result(...)).otherwise(handle_error_a(error_a...)); As opposed to exceptions, they offer significant advantages: You can call two functions that might error, and combine their errors results into e.g. a different one, and propagate that (having two exceptions in flight is a std::terminate call). You can transport these types easily and share them between threads. They make reasoning about what errors can happen easier since all the possible errors that can happen are encoded in the return type of the functions. That is, at the end you must catch them all, but you cannot catch errors that cannot happen, and you cannot forget catching an error that can happen. One could argue that with exceptions, too much happens behind the scenes. You cannot really ask the compiler if something can throw, and if so, what can it actually throw. The compiler doesn't know. You must assume anything can throw anything. `noexcept` can at best tell you when something does not throw. But otherwise it only tells you that something might throw (even when it will never throw). These types use the type system (and very ugly return types) to make it more explicit (wether is really better is debatable). With C++14 auto-deduced return types, this gets much nicer (and you can always `dump&lt;decltype(foo())&gt;` to ask the compiler whats the return type of something is). For these to be really useful (e.g. not having to write `.get()` or `.unwrap()` everywhere) C++ needs syntax sugar. Otherwise these types are a pain to use (`optional&lt;optional&lt;optional&lt;optional&lt;T&gt;&gt;&gt;&gt;`).
the only benefit i find is: heap compaction in-between collection cycles the usual alternative in C++ is object/mem pools :( it works but is ugly and always sub-optimal :(
~~Yes you invoke undefined behavior. And yes, you might be writing to read only memory.~~ However, read only memory is not a feature of the language, but of the compiler + linker + operating system, so its behavior is typically well defined (the invocation of undefined behavior is to allow the compiler to use read only memory when available in a given architecture). What I meant with "implicitly getting the mutex" is: #include &lt;mutex&gt; struct A { mutable std::mutex m; int a = 3; int get() const { std::lock_guard&lt;std::mutex&gt; lock(m); return a; } }; static const A a{}; int main() { return a.get() == 3? 0 : 1; } So in a nutshell, ~~language wise you invoke UB, but~~ platform wise what happens is well-defined: you might get a segfault, or you might be able to write to read only memory and adquire the mutex (which is what happens in MacOS and Linux). EDIT: this actually isn't UB, see answer below.
Wrong subreddit, go to [/r/cpp_questions](http://www.reddit.com/r/cpp_questions) in future. As for the code, it looks like C. C++ should look more like [this](http://ideone.com/bOsWKy).
Don't forget std::contains_if 
I'm not sure I can think of a place where you would need ownership semantics and would be able to use a reference. If you are using references currently, can you not just continue to use references? I'm probably misunderstanding.
Prefer a **reference**, as opposted to a **pointer**. If it can't (shouldn't) be `nullptr`, pass it by reference. No need to touch smart-pointers for it. So a function expecting a number for example, could have the signature `void set_my_number(int &amp; my_number)`. This is if the function requires an actual number as input, ie it shouldn't be null. If you want something where you *can* pass around null, you want to use pointers/smart-pointers. Doing this prevents accidents like this void set_my_number(int * my_number) { *my_number = 5; } This is obviously bad if you pass in `nullptr`. Using a reference clearly states (and mostly enforces) that you can't give it null.
how should I go about it then?
I don't know of a licence, but one that doesn't require you to do anything to use it, as in, no attribution, or have the license in the header file and that is all? Not sure.
Thanks for the reply. I'm not thinking so much about ownership semantics of a reference, I'm thinking more about the equivalent to references when we replace pointers with smart pointers in my idiom above. I'm trying to come up with examples, but they're admittedly mostly contrived. Imagine a function that accepts a pointer to an int, but the function assumes that the pointer is not nullptr. I can apply my idiom and make that a reference to int. I've now changed the type of the function to express the contract of the caller. If, for some reason, the same function takes a smart pointer to an int, is there any way that I can express the contract of the call in argument type where the function is assuming the smart pointer points to non-nullptr? 
&gt; Using a reference clearly states (and mostly enforces) that you can't give it null. Exactly. What I'm looking to do is create a parallel between how I might modify pointer arguments to become references to express the contract, and how I might modify smart pointer arguments to become ??? to express the contract. 
You can write custom classes that are non-nullable versions of smart pointers. I've done it before for the pimpl idiom. [A quick search reveals Unreal Engine's version: TSharedRef.](https://docs.unrealengine.com/latest/INT/Programming/UnrealArchitecture/SmartPointerLibrary/index.html)
If you have a smart pointer, and a function that takes a reference to the pointed-to type, you can just deference it to pass it in, so from my example above auto my_num = std::make_unique&lt;int&gt;(0); set_my_number(*my_num); std::cout &lt;&lt; *my_num; // 5 In other words, you change your functions that take smart pointers in the same way you would the ones that take bare pointers.
Realistically you're never going to write `set_my_number(nullptr)`. If you're passing a heap-allocated number, then you would most likely do something of the sort: unique_ptr&lt;int&gt; my_number; set_my_number(*my_number); set_my_number(my_number.get()); // pointer version Both cases will fail when my_number doesn't hold anything. Which to use is a matter of preference. I honestly prefer to use pointers for heap-allocated objects. It sort of implies that it's external data, whereas the dot operator means more of a local object.
Thanks. Yeah, I thought about this as the recommendation. It's rare that I have smart pointers in my parameter list. Mostly, I'm thinking about this idiom in terms of expressing the contract of the call in the parameter types. The (mostly contrived) examples that I came up with would be a function that takes a smart pointer reference, expects it to point to an object, and then optionally reseats the smart pointer reference to point to a new object. I think that's rare enough to be a contract expressed in documentation, not in code, and potentially enforced at runtime by logic_error throws. Also, my search for a parallel in this case admittedly breaks down because this doesn't map to my original T*/ T&amp;, in that the parameter is deliberately reseated to point to a new object. Like I said, it's contrived. 
Not sure this really answers the question. However, to add to this, I can't stand it when a library keeps a reference to my objects and makes me dance around trying to keep my objects alive. References are non-owning, so should only be kept while you *know* the object is still alive.
But that would create a copy.
Honestly, I manage to write most code without ever using `nullptr`. I simply ignore the fact that smart pointers can be null and don't consider it part of their interface. For example, I treat `unique_ptr` like it's a "unique owning reference", not a "unique owning pointer". There are better alternatives for most situations that use `nullptr` - default arguments, overloads, `std::optional` or `boost::optional`, throwing exceptions instead of null return values, etc.
Which is usually perfectly fine (and allows for a move when possible). I treat copying as a mechanism for passing values around (objects are just somewhere to put values), while references are a mechanism for passing objects around (even const ones). I do, however, have no problem with using references to avoid copies in cases where it's shown to have a significant impact on performance (at the expense of a less expressive interface).
&gt; I sincerely doubt there is actual performance difference. Moving an std::vector is a constant time and space operation. Copying an std::vector is a linear time and space operation. Generally speaking that results in an ENORMOUS difference in performance.
Well of course... If the function needs a copy of the object then you copy the object, not pass by reference.
I have a bucket load of uncontrived examples because pretty much every time I use a smart pointer, I'm treating it as a smart reference.
doesnt work with adblock turned on. oh well, lost a visitor then.
This is not Windowsphobia, but my opinion based on over a decade of professional software development on multiple operating systems including Windows. You should start to accept that there are people that have other views than yours =). And yes, IMHO Windows is not a good platform for software development.
&gt; The first big caveat is that the expected&lt;T, E&gt; implementation in Boost.Expected is very powerful and full featured, but **unfortunately has a big negative effect on compile times** I was not aware of this. What about expected&lt;&gt; causes so much compile-time pain (as opposed to, say, optional&lt;&gt;)?
Just use the move-and-swap idiom. T&amp; operator=(T t) noexcept { //swap each member with t return *this; } Pros: * Serves both as move-assignment and copy-assignment, if there is a copy constructor. * Reuse the code from the move-constructor * Can be marked noexcept (provided that the swap is noexcept, that is in 99% of the cases). * Automatically protects you against move-self-assignment (provided that the swap can handle self-assignment, that is true in 99% of the cases). Cons: * Might be less efficient, but you should code for clarity an profile later if it is a bottleneck (unlikely). My opinion on your matter is that an rvalue-reference should imply "I am the only reference that points to that object". I say should because obviously it is your responsibility to ensure this invariant.
I have a dedicated dumb pointer class that is never null. If you want a nullable unowned pointer, you have to use `Option&lt;Borrowed&lt;T&gt;&gt;`. https://github.com/themanaworld/tmwa/blob/master/src/compat/borrow.hpp https://github.com/themanaworld/tmwa/blob/master/src/compat/option.hpp
&gt; and I'll admit, taking a const reference when you want a value isn't that bad It can be if you could have moved.
I just need to flush.
&gt; 15. DESIGN: Consider making (more) use of C++ 11 namespace composure as a design pattern What in the example that followed was C++11?
Use the Unlicense license: http://choosealicense.com/licenses/unlicense/
I would get a prototype working on a pc first, it sounds like you have lots of giant unknowns. I haven't used TBB but it is unlikely that you will need that to overcome a bottleneck of some sort. I'm not sure if you can compile embree with straight C++ but I thought you could. That would be something to try first also. If you are looking for a game and interactivity you should realize that embree isn't made for that. The first thing to try is to see if you can update your acceleration structures to trace against effectively. Embree isn't set up (to my knowledge) to iteratively change the sorting of geometry. 
&gt; Smart pointers are for ownership. That's true, but I'm fairly sure that's not at all what he's asking. He wants something like a non-nullable `std::shared_ptr`... - which unfortunately is probably not possible using just `std::shared_ptr` (move semantics means that you have to have a state for your shared pointer after it has been moved out of...) You could fairly easily write a wrapper for `std::shared_ptr` that didn't allow moves. However, you'd need to decide what happened when one of the methods that needs a pointer gets `nullptr`...
I think it only works if it's a link-library (whatever the term is), ie a .lib that is neede to link to the respective .dll file. Like msvcrt.lib.
Did they remove it? I can only see C++ Primer on that list? (not _Plus_)
Same. After a segue into Scala for a job, my C++ interfaces are all Expected (an option like thing) and Im not using null at all. Granted, theres so much legacy its obnoxious, but its not _too_ hard to wrap things. 
Yeah, I think a lot of people are moving to this style. I use Alexandrescu's Expected cause I like the idiom a bit more than option for general case. 
&gt; My opinion on your matter is that an rvalue-reference should imply "I am the only reference that points to that object". I say should because obviously it is your responsibility to ensure this invariant. Equally valid would be that assigning to self results in the ownership being released (e.g. self-assigning an r-value unique_ptr could cause it to release the underlying memory)
Don't really understand the point your trying to make. Aren't all software errors by definition programmer-produced?
I appreciate the honest feedback. I'm still new at this and hope to get a bit better with each episode. That question was a bit of a dud in retrospect. Prior to that listener feedback I had not heard of Sean Parent, shame on me I guess but that's the truth. I do this show for my own benefit as much as it is for the community. If I already knew everything about C++, and what all the luminaries and authors had to say there'd be no point in me doing it.
Stick with const ref. The caller needs to do *(foo.get()) (or something like that) but that's not the end of the world.
Never, ever, ever pass by non-const reference. It makes it impossible to reason about the behavior of a function if it can mutate reference parameters. bool okay = true; foo(okay); assert(okay); In C and if you follow the rule above, you know `okay` is unchanged. If I have to look at the definition of every function to figure out what happens to its parameters, it becomes very difficult to reason about a whole program without already knowing how all of it works. 
Far from it. Would you define a broken network connection as a programmer-produced error? Or a sudden tremor (from a child jumping) that causes your driver to miss a BluRay read? So, your network library should probably be able to handle the connection dying in the middle of a transfer, recover from it, and how the user of the library some kind of error. However, your network library should probably not be able to handle your user sending in nullptr instead of a string containing a valid IP number, when starting a connection. See the difference? So a more clear example: If your broken move happens only in a situation your caller did not produce; such as a network error, a faulty file read, or similar, then protect against it. If not, then only consider guarding against it if it is *very easy* to do - this rule has served me well over the years.
Agreed, that was my point as well, only modified. If your normal operating logic allows for a self-move to happen, or any other kind of recoverable error, deal with it. However, if the self-move is produced by faulty use of your library, then there is no reason to guard against it - but this is of course my opinion.
Agreed, although I still argue there is little difference in use between the two scenarios. Especially if you work in an environment where exceptions are a strong no-no and never used. In that case, both use types will be identical: * Call function and store value * Check error code for all possible, manageable, error codes * Use value or recover from error
Ah - I clicked the very first link in the post (the one above the amazon links) and it leads to [this](http://ws-na.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&amp;MarketPlace=US&amp;ID=V20070822%2FUS%2Fmeetingcpp-20%2F8003%2Fb23ca1ce-f4ed-4abc-a218-b560bf76a25e&amp;Operation=NoScript), which is probably a static list created by meetingcpp. And that one doesn't have Primer Plus on it.
I will pass by non-const &amp; when my T is big enough. For types that have value semantics, I totally agree with you. For larger things, like domain objects that are do retain state and are composed of many value types, I will pass by mutable &amp;. 
Hah. I also prefer to use T&amp; for something I will call methods on. The syntax is cleaner, esp if T overloads operators like [].
I've been using Qt for about a month, but I don't think I've ever used KDE. What is it? &gt;KDE Frameworks are 60 addon libraries to Qt which provide a wide variety of commonly needed functionality Can anyone expand on this, or redirect me to a FAQ or something?
not breaking code anymore a do while isn't required tho, since it's only one instruction for each macro All I did was drop the semicolon to enforce the usage of it
an IDE should be suggesting the macro names for you otherwise feel free to look at the .h to see which order is required
I wonder this as well. Also are you allowed to have more than one line of code?
Not specified. I updated with another way to do it via comments.
I thought about that last one, but apparently `/` is not allowed.
I believe KDE stands for the majority of Qt development.
it works, but you cant' use /, already tried it. About operator overloading it was my first guess, but it can't fit, and i don't think you can overload the integer ones (though i've never used the overload of operators, so i'm no expert in the field)
doesn't compile, i tried it already
it is specified where you should add it, just at the beginning of the main 
Yeah this one works!
Doesn't compile: http://coliru.stacked-crooked.com/a/ea0e0774ae4a23c4
Beat me to it. Nice one.
This appears to work and meet the requirements: #define x\ Edit: Oh, I was [beaten to it](http://www.reddit.com/r/cpp/comments/35e3a5/challenge/cr3jwu9).
It does when properly indented. So depending if OP is allowed to indent the code or not this solution is the correct one. http://coliru.stacked-crooked.com/a/b8892ff126dc0f18
I see, I think I understand now, thanks.
Agreed. But at least the original code is not indented.