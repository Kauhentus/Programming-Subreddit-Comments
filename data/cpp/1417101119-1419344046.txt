Took another look; the ambiguity is addressed right at the end of **[dcl.fct]**: &gt; 14 - There is a syntactic ambiguity when an ellipsis occurs at the end of a *parameter-declaration-clause* without a preceding comma. In this case, the ellipsis is parsed as part of the *abstract-declarator* if the type of the parameter either names a template parameter pack that has not been expanded or contains `auto`; otherwise, it is parsed as part of the *parameter-declaration-clause*. The "or contains `auto`" was added between C++11 and C++14; I'm guessing that gcc and clang missed that when adding generic lambdas.
I don't thik that the OP wants to verify the correctness of the queue, but I did use Relacy Race Detector too. When you say lock based counterpart are you implying mutexes? A queue can by blocking without using mutexes... A lock-free double-linked list? What for? It's going to have a lot of contention...
I've filed bugs: * gcc: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=64095 * clang: http://llvm.org/bugs/show_bug.cgi?id=21684
When I skim the manual, I see an awful number of `new`s that I would have to use. If a library forces me to use allocating new, it is almost by definition not modern.
I don't know how I missed that--I must have gone over that paragraph multiple times when looking into this. Thanks!
You will get a better response from /r/cpp_questions and perhaps /r/gamedev Good luck! I find game development in c++ very rewarding.
Check out lazyfoo.Net. If you don't understand a programming concept Google it or look it up at cplusplus.Com, or ask here on reddit. Happy coding! 
&gt; std::rand replacement Good, the new random interface in C++11 is way to fine grained and expert friendly. There should be some kind fast and simple default interface, for people that don't care enough to learn about it (seeds, generators, distributions, engines, etc). 
I'm not sure I figured out which myth was being debunked here.
but really, if you're OK with stuff being 3 times slower, maybe you don't need c++ in the first place.
In case the video wasn't clear enough. What are co-routines and why do I need them? I found this paper very helpful: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3964.pdf Edit: Also http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4134.pdf Co-routines, as I understand it, are about good old school multi-tasking. You can use them to multi-task even on systems with only one thread. It has always been possible to do multitasking (without co-routines) in a C-callback-style. The problem is its very cumbersome to write, read, and debug. You have to split your program logic into these tiny partial functions. You use a callback event loop, to step through them. The multitasking happens with the interleaving of these partial functions. You get a partial bit of one problem done in this callback, and then a partial bit of another done in the next callback, a bit done in another. But its no longer easy to follow imperative programming style. With (asymmetric) co-routines you don't have to bother with any of this convoluted design (no visible callbacks or event loops). It looks just like your good old imperative programming, yet it still multi-tasks. You just sprinkle in some yields. And it then works by magic. I might be wrong. Please tell me. 
My preferred path to optimizing allocation is not allocating at all. Luckily, this is where C++ **really** excels. 😉
I know a lot of C++ programmers that believes that one should use custom memory allocator if application needs to create a lot of small objects. This is a myth, modern general purpose allocators like jemalloc and tcmalloc works really good in this case.
Agree. But sometimes memory allocation is unavoidable.
Try to first let it build until it fails, and then restart the build with the Ninja equivalent of -j1 - ie, run only one task at a time. It's most likely that there are a few files that take 2GB of ram, where if you compile 5 of those at a time you need &gt;8GB. However, the chances of actually hitting that is not too large, and if you compile one at a time you should be ok. May take a lot longer though. Source: work on a large product with same problems, also have 16GB of ram in my laptop.
Coroutines would be great, there are certain programming problems that can use them to great advantage, i.e. to greatly simplify the code!
Being naive? I have an exercise for you: implement a Yatzy simulation by applying concepts &amp; techniques from EoP and the above book. Write a short document describing what you applied and why. 
That said, I'm actually looking forward to this. It will make working with external C API cleaner and safer.
Pretty cool.
Care to elaborate? I'm not exactly sure what the problem here is though. 
C++ (and C) allow for a good control over memory use compared to other languages. In particular, free store/heap is expensive to use (it is expensive finding free memory areas to store data and freeing it subsequently). For example, in Java, everything except primitive types is on the heap. That means **a lot** of allocation, and very frequent. JVM can avoid heap allocation when it can prove that the object is local to a function, which is great, but this is nowhere nearly enough. In C++, programmer has options of using the stack (which has 0 cost) to store data, or embedding datums within each other (which also has 0 cost).
So using the stack is cheaper than using the heap?
Is it possible to force logger to write all the data to disk synchronously? There is a problem with async loggers - when program crashes unexpectedly it loses everything that wasn't written to disk. One of the possible approaches - log everything based on severity level, if message is a TRACE or DEBUG message - write it asynchronously, if message is an ERROR or WARNING - write in synchronously (or just wait until it will be written to disk). Another useful scheme is when you don't write log messages at all, just accumulate last N messages in memory until your program generates ERROR or WARNING. This message triggers dumping of all accumulated messages. This is very fast (you don't need to write anything until something goes wrong) and informative (you always have context of the error).
There is no stack vs heap alternative. Size of the stack is limited, if you don't know in advance how large your data-structure is - you're only choice is heap allocation. 
Also C++ offers things like placement new, overriding a class' new operator, etc. which allows the programmer to use the heap allocating sintax but actually be using a pool, prealocated memory region or some device's ROM.
If you use jemalloc or tcmalloc heap is not that expensive. Every thread has thrad-local memory cache that can be used to allocate memory and it is super fast. Largest performance hit that you can expect using jemalloc is contention on allocator arena when memory allocation is done in one thread and deallocation in another.
What's the difference between this and boost::context or boost::coroutine? I wrote a wrapper around libuv and boost::context that lets me write imperative code that seems to block but in fact yields to another coroutine when it would block.
It is certainly possible to implement a synchronous call on top of the asynchronous ones by just making the caller to spin/yield over some atomic variable until the writer modifies it. The change can have side effects e.g. if the hard disk becomes full or some unrecoverable IO error happens, in this case the caller threads would block forever. A very long timeout could fix it though. I'm no very sure of implementing the feature, I wll think about it. Be aware that there is the "terminate" member function in the frontend class, this function causes the logger to empty its queues nicely and shutdown the log thread. It is meant to be called from signal handlers after shutting down your producers. The problem is that there are signals that bypass the signal handlers.
So the wrong alloc is used to test *and* 5 times slower isn't considered significantly slower? I'm sure all those gamers will think 12 FPS is just as fine as 60.
jemalloc can allocate all available memory on my machine (16Gb) by 4-byte chunks and go OOM in less then 10 seconds. And yes, for general purpose memory allocator being 5 times slower then memory pool can't be considered significantly slower.
What is "this"? The first half of the talk is about using Boost.Coroutine, and the second half is about things that build on top of it...
I believe they are much the same. At first it looked like we would "simply" get boost::couroutine into the cpp standard. A library based solution where you pass the context as a parameter to functions. But now we are getting a keyword based solution. So the context becomes implicit, kindof like the this pointer in method calls. I'm still a bit fuzzy on what fibres will look like in the standard. Fibres are stackful co-routines, or lightweight threads. They will be more expensive than regular (stackless) co-routines, but cheaper than threads. I think it will look much like the std::thread interface. Again I might be wrong. Tell me. Edit: More about fibers. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4024.pdf
Yes, but there's generally less of it, so it's a trade-off.
The link to the article: http://blog.biicode.com/template-metaprogramming-modern-cpp-haskell-metaphor/
What does it do wrong?
There are some efforts made for skipping the FFI and calling C APIs by embedding clang. Maybe one day we can call C++ API directly from a foreign language. Here is the link to the talk (on recent LLVM meetings). http://llvm.org/devmtg/2014-10/#talk18
http://boost.2283326.n4.nabble.com/pool-Calling-all-library-designers-The-future-of-Boost-Pool-td4633163.html is a decent explanation by one of the people that maintained it for a while. The TL;DR is that it's a combination of feature creep and being designed around what was fast a decade+ ago rather than what's fast today (and the feature creep makes it impossible to update in a backwards-compatible way).
"malloc is slower than memory pool but not drastically. On my machine it’s five times slower than memory pool if deallocation time was taken into account and only three times slower if it wasn’t " in my book, 3-5x slower *is* drastically slower. 
N4165 UFCS would restore my long lost faith in humanity. bouncing between methods &amp; functions is my single biggest gripe with C++ (whilst others may claim the language has bigger problems, this is a high point on pain caused vs simplicity of fix.. the point being the pain caused is completely uneccasery.) 
Now, please show me a compiler that is able to proove that the while loop does not compile :)
I think this is unfair on C++: If you know the language and write it in a modern style it still gives you a lot of great features that you won't get in most other languages, even if you don't care about performance. Just compare it's type system to Java or even all the scripting languages; I will never get the amount of compile-time-checks there that C++ gives me. Or RAII: I don't have to do anything to release any of my resources in an exception-safe way. Most of the usual alternatives don't give me that for anything but memory. Then there are `const` and non-null-references, two invaluable features that many languages lack basically without any justification. And finally there is the thing that at least I know C++ several times better than any other language: I can write in some of them too, but I would never say that I know them better than most other people, which I do think is fair to say about C++. Therefore I will use C++ even in situations where some other language might be somewhat better, because I can just write it down without having to check the documentation to often.
Also a good [read](http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2009.04.05a.pdf) (pdf warning).
BTW, "mpsc_hybrid_wait.hpp" had 3 dumb bugs before, it is fixed now.
&gt; Is it deliberate malice on the part of the standards committee or something... Actually it's much, much worse than that. They are specifically out to get *you* and make *your* life miserable.
Much of everything in life is a question of priorities, which themselves are a matter of the perceived ROI. Much of what you're complaining about is not a priority e.g. for me. Much of what you're saying, to me, has relevance of "... pffffffft, whatever". C++ changed a lot with 11 and 14, and IMHO, the changes are generally more important than the changes you seem to want. About what you can do: whine to the standard committee, surely (I am sure some members thereof are reading this, so you already started).
The first thing I would say is that you should write up proposals for the things you really want or look through the C++ discussion list. Forward-declarations mitigate the header problem, but only a little bit &amp; in a very round-about way. They violate DRY which makes refactoring far more annoying. Additionally, the compilation unit itself still ends up needing the header anyway, so you're still back at square one. Personally, the header order isn't a particular problem I have, although that comes from experience of knowing how to write C++ headers properly (I learned it independently the hard way, but I believe there's lot of great guides out there that describe the pitfalls well). I imagine on some codebases, especially if care was done up-front, this can be trickier. With respect to the points you raised, none seem to address the header problem at all: [1] It does encourage a more functional-style programming technique (&amp; can be done transparently). It does let you move more things into free-standing functions which can be forward-declared without headers, but that still doesn't solve the problem. Additionally, if it's a header-only function, you still have to include the header somewhere (&amp; you'll potentially run into symbol visibility issues depending on whether the function is inlined or not). [2] Same issue. Forward declarations don't solve the header problem. The help mitigate the recompilation avalanche due to an over-inclusion of headers which is a separate issue. [3] Doesn't address the header problem but does let you hide implementation-details better. Another one you didn't mention that isn't being addressed is the one that makes the private member variables opaque (i.e the compiler knows type X is of size S but guarantees the memory layout is private, thereby removing the need for PIMPL &amp; reducing incremental compile times). Again, this improves several things, but still doesn't address the header problem. Modules are difficult because everyone wants them &amp; everyone wants modules to do more. Moreover, there are going to be conflicting ideas "because it's so easy &amp; every other language already has it". Additionally, the committee needs to consider how to make modules fit in a backwards-compatible way, how to build it as an evolutionary, not revolutionary, system so that adoption is easier &amp; how to leave room to incorporate future improvements &amp; lessons learned from the first iteration. I highly recommend you read the proposals for modules. While I may not agree with the decisions, they do a good job laying out the reasons behind the design choices. I bet you'll also disagree with some design decisions &amp; I bet your set will be different than mine. Now imagine how hard it is to get consensus amongst the many committee members who are all extremely sharp &amp; language &amp; tool design domain-experts. It's going to come &amp; will only improve with time (there's enough focus &amp; attention that it's now a matter of when not if). My only hope for the initial version is that it drastically cuts down compile-times. With respect to Rust, AFAIK there is no garbage collector. Are you confusing this with D? Rust has several different types of native pointers, but they're no different from unique_ptr/shared_ptr except the compiler enforces safety. You could also try Nim (formerly Nimrod). As someone pointed out, it's more a sense of priorities &amp; what are the features that are meaningful enough to implement. Also note that C++ has never been on the bleeding edge of language features nor does it promote one style over another. It's more of a Frankenstein approach: take the tried &amp; true concepts other languages have proven to be useful &amp; patch them into the monster. Modules just happen to be a particular difficult concept to retrofit. My bet is that UCFS will make it in for C++17. I hope modules make it as well.
 **Pure Stockholm Syndrome and Pedantic Cultism, aka "Priestly Caste"**. If the standards committee actually fixed the fundamental problems with C++ instead of cherry picking low hanging fruit as they have done over the last number of years, there wouldn't be the need for a whole industry of ISV's, consultancies, businesses, and C++ lifers that derive their core competency/profit by working around its problems. At this point there is actually a very high profit interest in _not_ fixing the problems with C++. As someone who has worked in several languages beyond C++, I'm also going to call bullshit on the "backwards compatibility" motive, when contrasting its cost. You should not be down-voted the way that you are, and this only reinforces my argument about a certain dominant &amp; nasty element in this community. I'm being totally serious here.
thanks for the reply to my rant ; i'm not confusing rust with D; rust is a contender because it has no GC. its' been interesting to use but in some ways, crazily, C++ is actually more 'open'/ 'adhoc' in a way that I like... rust is restrictive in other ways. In C++ you have the closed classes &amp; open overloaded functions.. but in Rust they remove the latter, open the classes a little more but only if you define traits. They also have compulsory deep namespacing of everything - it would be nice as an opt-in but it gets excessive .It begins to feel like #including individual functions. I have always liked the fact C++ is multi-paradigm I mention the 'header reducing' ideas because I remember how I worked in C, for me its' really the way headers interact with classes that is the problem. In C headers really are your interface - its like the act of putting it in the header makes it "public".
I thought you were saying Rust has GC. My bad. I haven't actually tried out Rust yet, so I can't really compare them. I think I'll probably get around to trying it out within the next year or two after it gets a little bit more mature.
&gt; there wouldn't be a need for a whole industry of ISV's, consultancies, businesses, and C++ lifers that derive their core competency/profit by working around its problems I don't really see this as a C++ problem. All popular languages have this. There's just no such thing as a "perfect" language. &gt; At this point there is actually a very high profit interest in not fixing the problems with C++ I see a vast number of real problems solved by C++11 (&amp; even more refinements with C++14). Backwards compatibility is very real. If you doubt that, look at the adoption of python 3. C++11 adoption by contrast is drastically easier &amp; can be adopted by incremental refactoring without ever breaking the existing code or removing functionality.
So in the C++ authoritative mind-share, the cost incurred by the development world of something like unparsable and unrefactorable syntax (and no, llvm really doesn't count yet), headers, and declarations is less than the cost of a language flag switch, and automated conversion of code-bases? I'm sorry to sound trollish, I'm just someone that came back to this language after several years and I'm noticing just how little it has progressed, and how much of the same philosophy still remains, that just doesn't make sense today.
right - I'm glad its' not just me that's noticed it. It is possibly one of many symptoms that in this overcrowded world we have a labour surplus, so its' often more profitable to *make* problems than to *fix* them. 
just imagine a pragma after which your compiler is at liberty to find definitions out of order. a pragma to allow out of class prototypes to be accepted. seriously there are so many little things that could help. jfeltz seems to have spotted it aswell - there are people out there who really are just nasty.
Thank's Rafa, I've been using Relacy and "Intel Studio" which is able to detect races. Yes,by lock-based I meant using mutexes. It's more of just a proof-of-concept project mainly for myself ( I wanted to practice writing lock-free data structures after reading Williams' book on it). =)
Could you provide more info about other such tools? :) 
I think you have to search the boost-dev mailing list for details. I never had the time to get those tools running.
Yes, there are obviously mitigation strategies to help reduce how many types you transitively include via headers. My point was that if in the compilation unit itself you use the type (I.e the .cpp) you have to include the header anyway. Moreover, none of the STL types can be forward-declared, and those will be the most complex and largest headers you will have (that's why there's an iosfwd). The point is that with textual inclusion is you fundamentally have an O(m*n) problem. You can try to mitigate it by reducing m (or n), but you're not going to affect those constants very much.
Pragmas are compiler extensions so they have nothing to do with the standard. I suspect that you're actually hand-waving away how complex this problem actually is. Not in general, but to retrofit into C++. If you feel that strongly that these are simple changes and give a lot of bang for the buck, feel free to write up a proposal or even hack clang/GCC to have this feature. Also, I don't see why you would need pragmas. This is just relaxing what would otherwise be invalid code anyway.
Can you describe one major language that has successfully used tooling to migrate code to a new, backwards-incompatible, version? Why do you say that clang doesn't count? There's a whole library that lets you parse and work with the C++ AST very easily. There's even Python bindings. Google, I believe, is working on releasing a rich open-source indexer built on top of this that would allow refactoring tools to be built. What backwards-incompatible changes are you looking for the committee to address?
one avenue I might pursue with 'my experiment' is something along the lines of the SPECS proposal. Imagine an alternate syntax (with a few more sugars) driving the same compiler middle. My language is merely a clone of bits of C++ and rust. Although not quite the same, for reference see how apple have objective-C and swift interoperability (i realise these are different ASTs but are capable of interoperating in the same source base using the same interfaces to a greater extent than languages coming together via the C abi)
How about [Emscripten](http://kripken.github.io/emscripten-site/index.html) / [asm.js](http://asmjs.org/) and JS? It is: **write once, compile once, run anywhere**. And the performance is claimed to be native x2, pretty impressive if you ask me.
Since we’re talking about modern interfaces, I’m wondering about the use of a class here. I mean, I get that an object is required for the implementation – but logically, the user wants two functions `encrypt` and `decrypt` that work *on data*, not functions of a class. Meaning, as a user, I’d be more comfortable with: template &lt;typename CryptoContext&gt; void encrypt(bytearray&amp; data, CryptoContext&amp; context); template &lt;typename CryptoContext&gt; void decrypt(bytearray&amp; data, CryptoContext&amp; context); (Of course I realise that it’s trivial to provide these wrappers on top of your class. Oh, and my functions throw exceptions, not return a boolean status. I’m puzzled that Qt makes you do this but I’ve never worked with Qt.) --- Another thing entirely, since this crypto class holds sensitive data, it would be nice to have the destructor explicitly zero out the memory of the PW, IV etc. – This isn’t fool-proof of course, but it’s still a good thing and often overlooked.
Heh... Cool 
I wouldn't use xxd to embed it by hand - the Qt resources system lets you embed files automatically using rcc, then access it using QFile much the same as you access a real file on the filesystem (which also lets you use search paths to enable overriding it with an external file, without need to recompile or even change any configuration). https://github.com/gamecreature/QtAwesome is someone else's code for much the same thing.
"Unspecified" has a frighteningly high amount of votes. If not undefined, at least make it well-defined.
They probably wouldn't. But you might write v[i++] = j++, where j is an alias of i and you don't realize it.
What would make sense to me is to emit a warning if there aren't any sequence points between accesses/modifications. Maybe there's a way to make it consistent without precluding a lot of optimization, keeping the language consistent, but I don't consider myself a compiler expert.
What's the difference between unspecified and undefined? If something's UB then a compiler _could_ do anything it wants, no? Saying it's UB _or_ thing 1 _or_ thing 2 doesn't seem different than saying just UB. Eg, nothing's stopping gcc from guaranteeing that all nullptr dereferences will throw some exception, even if the standard says this is undefined, is there?
What does it do anyway? My first thought going through is 01. 
Unspecified would mean the compiler has to specify something, I believe. Undefined means that the behavior could be inconsistent even across the same compiler.
I went with 10. I expected the behaviour to be something equivalent to this: std::vector&lt;int&gt; v = { 0, 0 }; int i = 0; int&amp; x = v.operator[](i); i++; x = i; i++; std::cout &lt;&lt; v[0] &lt;&lt; v[1] &lt;&lt; endl; 
But could the compiler specify "undefined" for something that's unspecified? ~~That's what the poll seemed to indicate.~~ nvm, reread the poll
Yes, aliasing is not entirely detectable, which is one reason it isn't reasonable to expect the compiler to distinguish every instance. Although, I'd guess that a lot of instances of missing sequence points between accesses/modifies aren't aliased. It still doesn't seem like a good reason to require consistent behavior though. Chris Lattner actually wrote a few really [good](http://blog.llvm.org/2011/05/what-every-c-programmer-should-know.html) posts on undefined behavior that may be worth reading. edit: after reading the comments, I think I side with crying britney fan (among others)
No. Unspecified behavior means that the compiler has to do something reasonable, but it doesn't have to be documented or consistent. Famously, in a call like f(g1(), g2(), g3(), g4()), the order of evaluation of gN() is unspecified and can be an arbitrary permutation, but the compiler can't make the world explode. (Also, it is guaranteed that none of the gN() calls are interleaved, and they all finish before f() is called.)
Thanks for sharing! Fire also looks very interesting to me.
Which is perfectly fine...
I guess the important part is: &gt; Now you should know that pointers are moved in **insert** and **emplace** methods independently of they were added or not which is obvious is you understand move semantics but the author felt it worth advertising for those who don't.
&gt; optional&lt;T&gt; is LessThanComparable (whenever T is LessThanComparable) Somewhat topical since the OP also recently commented about the awkward use of operator&lt;: https://akrzemi1.wordpress.com/2014/08/08/on-operator/ I wasn't overly sympathetic to his original thesis, but here in this case I find the support of operator&lt; on optional&lt;T&gt; highly questionable. `nil` values are not comparable and it is purely ad hoc to try to make them so. There will always be a case where it does the wrong thing. 
`operator&lt;` of an optional should return `optional&lt;bool&gt;`¹, `tribool` or be `=delete`d completely. The current behaviour is counter-intuitive. ¹ this would also allow other operators, like `operator*(optional&lt;int&gt;, optional&lt;int&gt;)`
if we transform it into regular functions: assign(nth_elem(v,post_inc(i)), post_inc(i)); Looking at it that way, I don't see any reason that this case should be treated any way other than how it already is: _unspecified_. Just because it involves operators doesn't mean we should suddenly start introducing new ad hoc rules about how it should be evaluated.
Agreed, I was surprised to find that Boost defined relational operators for optionals when I first read the documentation. I don't think that there's any "natural" way to define them. Using these operators carelessly can easily result in subtle bugs due to the unintuitive behavior when comparing uninitialized optionals.
I think (and someone please correct me if I'm wrong!) that this is not a valid comparison with the code in the poll. The example you give with functions introduces sequence points before and after each function call. In his example, specifically here: v[i++] = i++; I think the two post-increments are unsequenced (or indeterminately sequenced? I'm not sure what the precise terminology would be for them). His example has a variable being modified twice between sequence points, whereas your example with functions does not. The order of evaluation for function arguments is unspecified, but modifying a variable twice between sequence points is undefined. Transforming it into explicit functions would be valid if "i" were a class with an overloaded operator++, since the implicit function call still provides a sequence point.
I feel like C++ and Python share some common philosophy even though their goals are very different. Both languages give the programmer a lot of tools to write expressively and don't try to force a particular design methodology. I was going to say that Python's deep integration of iterators was probably inspired by C++, but [this mailing list thread on the iterator PEP](http://www.gossamer-threads.com/lists/engine?do=post_view_flat;post=40719;page=1;mh=-1;list=python;sb=post_latest_reply;so=ASC) doesn't contain the string "C++" even once. Iterators are central to both languages and allow expressive code without allocating a lot of temporary storage. Python feels like a hard sell these days. Many other languages have similar big libraries and get close on expressiveness, while adding static typing, compilers, real threads, etc (C#, Go). Still, Python is my personal standard for beautiful syntax. Even if mainly serves as a syntax demo/proving ground for other languages to copy, that's fine by me :)
I welcome this. It's been really easy to be expressive in c++11 while still maintaining performance. 
Since v[i++] = i++; invokes undefined behavior, it theoretically does anything the compiler writers want it to do. He's asking what *you* would want it to do.
That's called a list comprehension FYI.
I would argue that the problem is not the comparison operator, but the implicit conversion. Implicit is the enemy of the programmer, doing things behind your back when you would least expect it. It's slightly more verbose to be explicit, but at least you see what's going on.
That new "pythonic" stuff seems so unnecessarily wrist-breaking.
FWIW, std::transform is something like Python's apply: std::vector&lt;double&gt; result; std::transform(numbers.begin(), numbers.end(), std::back_inserter(result), [](double x){ return std::sqrt(x); }); Should become more concise with the upcoming [ranges](https://github.com/ericniebler/range-v3/blob/master/doc/D4128.md) proposal.
 template&lt;typename F, typename Cnt&gt; auto map(F f, const Cnt &amp;c) { Cnt ret; for (const auto &amp;x : c) ret.emplace_back(f(x)); return std::move(ret); } squareroots = map([](float x){ return sqrt(x); }, numbers); // can't pass std::sqrt directly because it's overloaded The above could be read similarly: "map sqrt(x) for x in numbers".
I never liked C and welcome C++ with open arms back in 1993, and it has been one of the languages I used most alongside JVM and .NET eco-systems, but that C subset.... C++11 and now C++14 make many of those warts go away, when one is allowed to make full use of them. I just got disappointed by the amount of CppCon presentations where the subject was how much restrictions are imposed on C++ devs in terms of language features that actually make C++ way safer than C.
Isn't that essentially just what functional languages call a map? map(math.sqrt,numbers) ...or in OCaml: List.map sqrt numbers (take a list of numbers and return a list that's the square root of each of those numbers)
No
That's true, but you could also say it has become more lisp-like. &gt;So suppose that Lisp does represent a kind of limit that mainstream languages are approaching asymptotically... -Paul Graham
I agree. Chandler's talk [here](https://www.youtube.com/watch?v=YJIaGRDIyEE) goes deeper into potential future directions for C++, with a focus on ~~compostability~~ composability. 
I've run into this mentality elsewhere in my career. It's always a huge, HUGE mistake. It's also rather unforgivable since all of the containers that need comparison allow you to override how that's done.
I'm kind of both ways on this. The part of me that forgives it is influenced by my math background, where the operator &lt; is defined by whatever math space you're working in and can be used in group/ring theory to define all kinds of crazy things. So from that background, I don't look at `&lt;` as the "less than" operator as much as the "ordering" operator. However, I think a much greater part of me comes from a computer science background, and looks at that type of thing and goes "well that's going to be confusing for the next person who looks at this". Although, I agree with the commenter above...while the comparison operator is "fairly evil", I think the worst part of it is the implicit conversion.
Actually its list comprehension (and dict, set and generator comprehension, depending on what you want to get out) and it is generalized version of map+filter.
&gt; compostability I think you meant _composability_... or maybe you didn't. ;)
Have you never encountered decaying C++ code? But thanks for that catch. 
OTOH, if optional&lt;T&gt; didn't implement a dubious operator&lt;, you also would see what's going on.
That use case is specious.
Hmm, I wonder if this could be cleaned up by simply taking the container by value and then using std::transform, std::for_each or a range-based for loop directly on the container.
I used Python for what is now called devops in a couple of places in the early 2000 decade. Never could see the value beyond scripting and application glue. Maybe it is an age issue.
Not in this case though. [The name comes from mathematics.](http://en.wikipedia.org/wiki/Set-builder_notation)
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Set-builder notation**](https://en.wikipedia.org/wiki/Set-builder%20notation): [](#sfw) --- &gt; &gt; &gt;In [set theory](https://en.wikipedia.org/wiki/Set_theory) and its applications to [logic](https://en.wikipedia.org/wiki/Logic), [mathematics](https://en.wikipedia.org/wiki/Mathematics), and [computer science](https://en.wikipedia.org/wiki/Computer_science), __set-builder notation__ is a [mathematical notation](https://en.wikipedia.org/wiki/Mathematical_notation) for describing a [set](https://en.wikipedia.org/wiki/Set_(mathematics\)) by stating the properties that its members must satisfy. Forming sets in this manner is also known as __set comprehension__, __set abstraction__ or as defining a set's __[intension](https://en.wikipedia.org/wiki/Intension)__. Although some simply refer to it as *set notation,* that label may be better reserved for [the broader class of means of denoting sets](https://en.wikipedia.org/wiki/Set_notation). &gt; --- ^Interesting: [^Center ^\(group ^theory)](https://en.wikipedia.org/wiki/Center_\(group_theory\)) ^| [^Extension ^\(predicate ^logic)](https://en.wikipedia.org/wiki/Extension_\(predicate_logic\)) ^| [^Cartesian ^product](https://en.wikipedia.org/wiki/Cartesian_product) ^| [^Kernel ^\(linear ^algebra)](https://en.wikipedia.org/wiki/Kernel_\(linear_algebra\)) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cmjaqug) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cmjaqug)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Good catch. [N4279](https://isocpp.org/files/papers/n4279.html) aims to fix it (or rather clarify the behaviour) by adding try_emplace and insert_or_assign to map and unordered_map interfaces.
I know this is context sensitive, but in this case, since the weight should return a positive number, instead of returning an optional, you can return a negative number (-1 is popular among C programmers). I would prefer never to use things like boost optional anywhere, because of the implicit conversions, which causes comparisons to fail in subtle situations.
It is not that obvious when you realise that move is nothing more than a cast. 
Dict comprehensions are awesome too, they really let you stay very functional when you have to do manipulations of related data: mapping = {-num: num for num in range(10)}
Ah okay, that makes sense. Cool, TIL! :) My problem is that I suck at names too, but I'm also picky, so sometimes I get stuck not writing a function I should be writing until I can come up with a good name, whatever meaning of "good" I'm in the mood for that day, and I waste time.
Yes, since I'm pretending that `f` will never change the value type, though in this example, since `numbers` and `squareroots` represent two separate lists, copying the original container before applying `sqrt` would be inefficient.
I always thought of it as comprehension as in comprehensive. The list is comprised of the elements generated by the loop. 
Right, but that allocates new memory every time which will often be unacceptable. Even Python has generator expressions to avoid allocating extra memory when not needed. `std::algorithm` provides a lot of tools with similar power to Python's list comprehensions and `itertools`, but the syntax is much uglier. I often give up and switch to a raw loop when I try to do something complex with std::algorithm. The iterator bookkeeping and lambda definitions pile up quickly. I think (hope) Eric Niebler's work on Ranges will be a big improvement in this area. 
You're right that map works well for that example, but when you're not just applying a function, the comprehension is a bit cleaner and more readable: vals = [math.sqrt(x) + x for x in numbers]
`std::set` uses `std::less` for a reason. It lets it compare any two pointers to `T` and still have such comparison be UB (unless in the same array/object).
Neither of which work for me. ASAN throws an error any time I use a program with threads, &gt;==16274== Shadow memory range interleaves with an existing memory mapping. ASan cannot proceed correctly. ABORTING. thread throws about a billion erros on compile time. Where does one file these bugs? 
Neibler offers transform(numbers, std::back_inserter(squareroots), [](...){...}); [link](https://github.com/ericniebler/range-v3/blob/master/include/range/v3/algorithm/transform.hpp#L75-L81) or auto squareroots = view::transform(numbers, [](...){...}); [link](https://github.com/ericniebler/range-v3/blob/master/include/range/v3/view/transform.hpp#L112-L118) Though, the latter returns a non-owning range adaptor. I'm a fan of the syntax, but adaptors can be tricky.
Python has a map function as well as reduce and filter
I guess the fix is to delete the unnecessary operator. i.e template&lt;X, enable_if_X_is_anything_other_than_optional_of_T...&gt; bool operator&lt;(X&amp;&amp;) = delete; 
Looks like they are free functions. I guess the following would be better. template&lt;class T&gt; // This is the original inline bool operator &lt; ( optional&lt;T&gt; const&amp; x, optional&lt;T&gt; const&amp; y ) { return less_pointees(x,y); } template&lt;class T&gt; inline bool operator &lt; ( optional&lt;T&gt; const&amp; x, T const&amp; y) = delete; 
Well, the issue described by OP for a nil weight, which is: &gt; In this case the optional on the right-hand side is never “empty”, while the one on the left-hand side sometimes is, and in this case the comparison returns false, which means “aircraft is not too heavy” would still happen if the returned weight is negative, so in this context, returning a negative number is just as bad. Add to that the risk of some smartarse programmer casting weight to `unsigned` because "how can weight be negative", and you've opened up a whole new category of bugs.
A big reason you need a less than operator is for containers in stl (like std::map, I believe), where the comparison operator is there for nothing more than to determine how to insert the class into a tree structure or similar.
This article seems mostly wrong to suggest that Python had a major influence over C++11. It justifies this position with some fairly shaky examples. Although many of these features might appear superficially similar to features in Python their semantics are quite different due to the nature of static vs. dynamic typing. Instead, I think the ML family of languages bears a much closer resemblance. To give one example, it is just plain wrong to compare variable assignment using the new C++ `auto` keyword with variable assignment in Python. About the only thing they really share is the syntax. By contrast, the type-deduction (via. `auto`) in C++ very closely resembles type-deduction in ML.
Yes, but it comes off as CYA back-peddling when the article starts off with: &gt; Modern C++ lends itself to a whole new style of programming – and you can’t help but feel Python’s influence on this new style. Well, I'm sorry, but I absolutely can help but to feel Python's influence since I feel it hardly at all. The entire premise of the article just strikes me wrong. The similarities given are superficial, are mostly syntactic, and are shared by a dozen other languages. My strongest impression from reading that article is that Python and C++ are the only two languages that the author knows.
&gt; std::vector&lt;double&gt; result; &gt; std::transform(numbers.begin(), numbers.end(), std::back_inserter(result), [](double x){ return std::sqrt(x); }); &gt; why not just: std::vector&lt;double&gt; result; std::transform(numbers.begin(), numbers.end(), std::back_inserter(result), std::sqrt); or would this not work. I think it should, since std::sqrt is a function that takes a double. there shouldn't be any reason to wrap it in a lambda. 
Unspecified hardly makes it much better to have in your code than if it were undefined. It just acknowledges that there really are a certain set of outcomes from this evaluation, which is just being honest. No compiler has any reason to manipulate the expression in anyway that would lead to anything but these particular outcomes.
That's true. insert and emplace could decide to not move from the provided objects if they can't be inserted. However, the general rule is that if you've done std::move() to something then you're calling something that takes takes an r-value ref and so you have to assume that your object is moved-from. We could have a special case in the specification of these functions but I think there's a lower mental load to not do so.
Python says write the code and tests, then profile. Then those parts of the code should be written in a static and compiled language. Unfortunately this part of melding with c++/c is more difficult than it should be. (You'll see some comments after me saying it's easy and I shouldn't complain). The level of difficulty **should** be like jython and java integration (you can just import a java class in jython like you would any module). That is about as easy as your going to get. I feel like java/jython is an unappreciated treasure. Jython and Cpython should be kept in lock step (development wise) in my opinion and pushed as the first choice for places where python is going to be profiled then optimized. I know I should put my effort where my mouth is and help develop Jython. 
&gt; Python says write the code and tests, then profile. Then those parts of the code should be written in a static and compiled language. I know, but other languages offer the same developer friendliness as Python, while having native code compilers in their toolchains, e.g. Lisps, MLs, Dylan. No need to switch languages. Hence why I never saw the value beyond scripting and application glue.
Yea, in boost, you can do: auto squareroots = numbers | boost::transformed([](auto x) { return sqrt(x); }); In [Niebler's range proposal](https://github.com/ericniebler/range-v3): auto squareroots = view::for_each(numbers, [](auto x) { return yield(sqrt(x)); }); In [Linq](https://github.com/pfultz2/Linq): auto squareroots = LINQ(from(x, numbers) select(sqrt(x))); 
This http://qr.ae/lxN7L should be useful
Writing code and building up your box of tricks that solve real problems Too easy to go round in circles with all the 'theoretical' advice out there Booky stuff: www.gameprogrammingpatterns.com has some nice (but possibly too basic) advice - not just for gamers Stroustrup's Programming Language book - a bit of a 'reference' text but lots of good content Also get better at debugging and supporting technologies (like database/scripting lang/gui toolkit perhaps)
As the author notes, there are similar tools in `gperftools` and `libmemusage.so`. However, more options are always nice :-). Although I've never used libmemusage, I've come across segfaults when using gperftools before that I wasn't able to trace down, so having an alternative is great. Thanks for the work! I'm definitely going to try it out.
I second /u/slededit's advice...just start writing code. I usually tell people that coding is sort of like carpentry...you can only learn so much from books. Eventually you have to start making shitty chairs before you can make a good one. In terms of your book list, I'm not sure if A Tour of C++ is for you. Don't get me wrong, it's a FANTASTIC book; we have it here in my office. But, it's mostly what it sounds like...a brief tour of all the features of C++. I think it would be less helpful for someone who is familiar with the language (like your self) and best for people who are already coders but aren't familiar with C++.
Why?
I wish C++ would adapt python's &gt; There should be one-- and preferably only one --obvious way to do it. C++ seems to have 10 ways to do even the most basic things, like initializing member variables: http://www.learncpp.com/cpp-tutorial/101-constructor-initialization-lists/
I really like the carpentry analogy, and I'm stealing it, because I've needed a good way to get that point across for a while now.
That is very specific to `optional&lt;T&gt;` though, whereas the implicit conversions are a general issue; which is why I would rather focus on them.
64bit OS, g++ 4.8.2
See also: https://isocpp.org/files/papers/n4228.pdf
&gt; For you professional C++ developers, do you think being a "good" C++ programmer translate into securing a good position? No. Absolutely not. It's the soft skills that translate more into getting a good position and *keeping it*. Get good at politics and programming *people* to do and give you what you want. You can be the shittiest developer on the planet but if you can reach into your boss's skull and flip switches you'll climb the ladder anyway. The opposite is true also--you could be a fucking genius at design and development but if you can't play the people you're fucked. Even if that were not true though, most C++ projects are 10-20 years old and full of cruft and rot. A great many C++ teams are in some sort of *transition* into agile development. This means that you spend most of your time spinning over misconceived/misunderstood notions and tons of meetings. Most of the work is boring as hell and requires next to zero C++ expertise--comprised primarily of fixing bugs that are pretty obvious and other times you're just fighting an ancient, immutable architecture. Even so, it's pretty hard to demonstrate your skills outside of a face to face interview. In my experience employers don't give a fuck about your github. Truth is maybe they shouldn't. When you do dazzle a potential employer it can be about the most surprising things. One I had asked me to count the occurances of each letter in a string and give the one that happened the most. In the case of a tie it was whichever one was found first. So I iterated through the string with a reverse iterator and let it grab the one that happened last (this is mind bogglingly simple). Minds were exploded. Other interviewers ended the session because I couldn't recall the order notation of quicksort off the top of my head. Maybe I should be able to but I've just never needed to spend the memory space in my brain to retain that information--references are legion if I even give a fuck (usually I just want something sorted and that part never turns up in a profile so the defaults are fine). So in other words its a crap shoot. Most employers I would say don't even know how to tell a good dev from a mediocre or even bad one.
&gt; Other interviewers ended the session because I couldn't recall the order notation of quicksort off the top of my head. Maybe I should be able to but I've just never needed to spend the memory space in my brain to retain that information--references are legion if I even give a fuck (usually I just want something sorted and that part never turns up in a profile so the defaults are fine). This really upsets me, because as a programmer (except for very specialized positions) your ability comes from your fundamental understanding, not what random pop quiz trivia you happen to be lucky enough to be able to pull out of your ass. The rest of this seems very sad and also very true. It is extremely depressing that the same old high school bullshit is often more important than your actual skill and ability to work in a good team.
Yeah, it's an upsetting realization when you notice that the business world is pretty damn irrational. You'd expect people to be judged by results and for a business to be motivated to make itself money. Problem is that in both cases humans are involved and humans are pretty damn irrational. You and I are too, it's not just the idiots. So pick up some books on human psychology. _Influence_, by Caldini is a pretty good one. _Mistakes were made_ is another. Learn what motivates humans even if you can't build the skills, or get past the ick feeling, to manipulate them.
Thanks very much.
Most of the talks restrict C++ features to a simple Better C, instead of what is now known as Modern C++. For example no STL, no templates, no reference parameters.
And sometimes it's actually Worse C when they manage to pick a bad enough subset.
I think you've misunderstood my question (possibly my fault), these do not belong in languages today: * headers, * declarations, * unparsable and unrefactorable syntax I also want to mention that your point about clang is patently false. Parts of python clang are simple, but clang is one of the largest, complex, side-effectual, and idiosyncratic API's that I've ever seen[1]. The community is also full of the same sort of design-failure excuses like "it's spagetti because C++ is spagetti". Stop the shilling. Your suggestion about clang, alone, reveals your nature. I don't understand why people still feel the need to, after 20 or so years, make excuses about C++ when the right thing to do is just admit what the state of affairs is: cultism and greed. Your point about backwards-incompatibility is in many cases a ludicrous strawman. py2to3 is good, I've used it with minimal fuss. Irregardless, to compare that kind of issue with the astronomical cost of training and tooling on the above items, aggregated out to the community at large, is both *insane* and indicative of *cultism*. 20 years is long enough to draw a conclusion about the real reason C++ is the way it is. [1] clang "Sema": http://clang.llvm.org/doxygen/classclang_1_1Sema.html
My goal was to highlight the similarities without insisting Python was the entire reason. But I think you're right, that sentence failed at that; also that it's incorrect to tell people how they feel. So I changed it to, "and I couldn't help noticing it has more of a Python flavor." I'm still not 100% happy with it, but what the hell. The article is an excuse to overview a few C++ changes while having a bit of teasing fun.
&gt; In my experience employers don't give a fuck about your github Granted, I don't speak for the whole industry, but I always look at the candidates' githubs if provided, and other programmers on the team seem to do that as well. Doing interviews for advanced C++ positions is boring, but interesting hobbies and side projects make it a little bit less routine.
Discussing how to achieve a particular effect in otherwise dissimilar languages is a fairly time-honored way to compare the relative merits of programming language features. Personally, that is how I would have framed the discussion. It's a worthwhile topic, particularly for people who know only one of the two languages being compared. So, Python is known for being friendly and flexible - here are ways to achieve similar usability in C++. Incidentally, the guys at Cpp-Next wrote an [article](http://web.archive.org/web/20120926025355/http://cpp-next.com/archive/2011/11/having-it-all-pythy-syntax/) on this very topic if you have not yet seen it.
Thanks for the filing the bugs. A patch has been submitted for review (http://reviews.llvm.org/D6520) and this should be fixed soon in clang.
I see nothing wrong with the `obj2` behaviour. For `obj3` perhaps it could be specified for `map` and `unordered_map` to check if key is in use already, though I'm not sure the exhibited behaviour is wrong.
A license file would be nice for packagers :-)
aa a f
I typedef such things the moment I need to type it out for the second time and don't look back. there is always the second time, C++11 or not.
Can we just deprecate operator++(int) and be done with it?* *Yes I know we can't do that. It sure would be nice, though. There's just no call for it anymore- all of the (dubious at best) optimization arguments are no longer true, and it make iterator implementation a huge pain (for input/output iterators, without the multi-pass quality).
Unspecified sounds fine to me. There's no reason for it to be undefined- it seems to fall into the same catgory as order of function argument evaluation.
Do you have to assume that? I think the whole point of the cast is that you don't, necessarily. You think it will probably be moved, but it's no guarantee. You could check, hypothetically, but your destructor should be prepared to take either case. The callee, on the other hand, can assume that the caller won't do anything with the parameter after the return besides destruct it, so it's safe to steal the pointers for yourself. That's always been the key thinking point for me.
Unfortunately due to backwards compatibility issues, that ship has sailed. While the committee is now working on removing things like `auto_ptr` et al, I doubt there will ever be one and only one way to do things in C++.
tl;dr, anyone?
New Features: [03:16] - Generalized constant expressions in template arguments [07:09] - Nested Namespaces Removed Features: [07:58] - Trigraphs [10:21] - Some relics from C++98 (auto_ptr) New/Modified Libraries: [12:04] - Fundamentals (string_view, array_view) (example given of windowing into long strings) [15:51] - Transactional Memory [16:25] - Parallelism/Concurrency Fixes: [17:04] - Uniform Initialization (example given was initializer lists in auto variables were read as type initializer list of foo, rather than just foo) [19:00] - What's Next for the Standards Committee (waits for natural concurrency, potentially fixing the undefined order of evaluation of function arguments)
I'd like to suggest CppCode. It's the first and the only offline C/C++ IDE &amp; Compiler on iOS. No jailbreak required, no internet connection required, no ads, free(mium) app. App feature list, screenshots and video on Vimeo/Youtube and even quick start at http://cppcode.info Video: https://www.youtube.com/watch?v=yKMQAE-DAJw AppStore: https://itunes.apple.com/app/cppcode-offline-c-c++-ide/id936694712
Thank you - I'll have that open on iPad so I can learn to code, while typing the code and running it on C4droid. C4droid seems to be able to do much more, but CppCode looks great! :)
Black magic to say it all.
I hope not. That'd mean the ranges library would require three versions of every similar function depending on whether you have a `back_inserter`, want a non-owning range, or need another container back. I'd rather see the non-owning ranges implicitly convertible to every single `std::` container, though user-defined containers wouldn't benefit from that design choice.
&gt; Obligatory comment about Microsoft finishing C++11 support first...
Worse.
Ah, the joys of wrapping well-written C APIs with RAII C++ sugar. It has *always* been a win for me. =) I'm eagerly anticipating N3677 that adds {scoped,unique}_resource. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3677.html
Ahah: https://github.com/ericniebler/range-v3/blob/master/include/range/v3/action/transform.hpp You probably read my post right, I just don't like where this innovation is heading, tripling the size of the STL and adding gotchas (like returning a range adaptor to a temporary) and pitfalls (like writing a generic function that works on range adaptors only to find you need entirely parallel interfaces to work with containers). It really bugs me. &lt;rant&gt; But I have to admit, I'm biassed. I wrote a library called [Pure](https://github.com/splinterofchaos/Pure) and my solution was to overload [`map`](https://github.com/splinterofchaos/Pure/blob/master/List.h#L479-L522) several times depending on whether the input is an rvalue and the result is the same as the input (uses in-place version) or the input is an `std::array` (uses `constexpr` version) and defined how to remap an `std::vector&lt;T&gt;` into an `std::vector&lt;U&gt;`. I placed the function as the first argument and didn't need a `projection()` function because I defined a generic [`compose()`](https://github.com/splinterofchaos/Pure/blob/master/Functional.h#L461-L483), and that also allowed me to define `map()` for a variable number of inputs. So I have my own solution to this, which I feel is in ways more generic and obvious (at least, to me), but also overly-engineered. I just wish Niebler's ideal could be achieved without so many parallel implementations of the same functions spread across parallel files, and parallel namespaces. I feel sorry for the std c++ libraray providers who will have to implement this.
Playing around with the extremities of a language is very instructive. There's a good chance that person is now better at templates for having done something so ridiculous...and probably had fun doing so. If everyone just staid in the comfort zone no progress would ever be made. You gotta have people willing to do completely stupid things to pave the way for changes in practice that will actually improve our lot.
&gt; There are people out there writing Game of Life at compile time in templates. Look how clever we are with our mastery of this tool. &gt; sure, I see the value of experimentation , I do it all the time. i am merely pointing out - how the hell can a language that can implement Game Of Life in templates not find definitions out of order. How if we've got programmers with time to implement Game Of Life in templates, can we not have time to add little tweaks to C++ to make it easier to work around the header problems ( like being able to extern constructors without seeing the whole class definition) etc. It seems these limitations are not about a lack of programming time in this world. 
It was a good read to get me thinking about a usage of unique_ptr that I haven't had to use yet. One question, is there any consensus on what is more idiomatic between what is done in the blog and the below? I believe this specific template specialization in namespace std is permitted under the standard, but correct me if I'm wrong. EDIT: I am wrong, as grumpy_wolfberry notes. The standard says the effect of calling `operator()(T *ptr)` on the `default_deleter` is calling `delete` on `ptr`, which the below does not do. namespace std { template &lt;&gt; class default_delete&lt;git_repository&gt; { public: void operator()(git_repository *ptr) { git_repository_free(ptr); } }; } git_repository *ptr; git_repository_open(&amp;ptr, "./testrepo"); std::unique_ptr&lt;git_repository&gt; repo(ptr); 
I'd say the best thing you can do is to read good code, in addition to continue coding and doing what you're doing. Find a project by a well respected c++ programmer (not sure which one, maybe whatever John Carmack has open-sourced? Doom 3? I read somewhere that Google Chromium was nicely put together), and try to understand the whole program. That's my $.02. Good luck.
academic work tends to be more self contained than real world projects. be able to talk to the rest of the world. make sure you understand linkers, libraries, and DLLs. be able to download a library and incorporate it into your project, communicate over sockets, manipulate the file system, read and write binary files based on the spec, listen to the mouse/keyboard, etc. I didn't really know any of that stuff when I left undergrad. it might not be the most sexy for interviews but it will really help on the job.
also, it's a little sad but learning old school c idioms like `set_callback(void (*funcptr)(void *), void *)` style callbacks is probably more useful on the job than learning a lot of C++11 stuff. being a younger person who's up to date on the latest C++ features has paid off for me, but don't turn up your nose at straight C too much because any old C++ codebase will contain plenty of it.
I feel the same way about python. In python there are many non-obvious ways to achieve things, and some of them are better and (faster) than the "pythonic" way which is often completely idiotic. Shorter code is not always better.
Too much black-magic but then again python developers don't give a shit about performance, just ease of "writing the code" and staying "pythonic" What is squareroots? a vector? a list? a hash table? 
I'd use a lambda as custom deleter: std::unique_ptr&lt;git_repository&gt; repo(ptr, [](git_repository * ptr) { git_repository_free(ptr); }); 
No, this is not permitted. Many specializations are allowed in namespace `std` but *all* are required to meet the requirements for the original template. The following specialization is permitted, though pointless. namespace std { template &lt;&gt; class default_delete&lt;git_repository&gt; { public: void operator()(git_repository *ptr) const { delete ptr; } }; } 
I usually remove the boilerplate and just leave `thing_` public.
You don't need to define both of them. So there's no need to repeat one or the other if you don't need one of them. In most cases, if the function's purpose is to obtain the value of `thing_` data member, then the second function "`const Thing&amp; get_Thing() const;`" is all you really need. The first function is usually used when you want to set the value of `thing`, for example: x.get_thing() = Thing(); which seems to not make sense calling it "`get_thing`".
It looks like this proposal has been updated a few times since then and is now [N4189 - Generic Scope Guard and RAII Wrapper for the Standard Library](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4189.pdf).
That won't compile as you need to write the lambda type in `std::unique_ptr&lt;git_repository, *HERE*&gt;`.
&gt; Okay, how about: &gt; Thing &amp; operator[]() { return this-&gt;thing_; } &gt; const Thing &amp; operator[]() { return this-&gt;thing_; } &gt; Better? I think you mean: const Thing&amp; operator[](int x) const; otherwise, you will get some compile error because both functions only differ on return type. (Also, overloading operator[] requires it to have 1 parameter). In any case, just like I said, you will not need both of them. A class containing just `const Thing&amp; operator[](int) const;` without the other will work fine (unless, of course you want the setter function). If you, however, decide that you only want the one that returns a non-const reference (the `Thing&amp; operator[](int);` version), you can only use this as a getter on non-const instances. For example: X x; const Thing&amp; t = x[0]; // assume X only provides the non-const "Thing&amp; operator[](int)" function, this is fine The main reason why both const and non-const versions are usually implemented is because the non-const version cannot be used as a getter if the instance is const. // assuming again that X only provides the non-const "Thing&amp; operator[](int)" function const X x; const Thing&amp; t = x[0]; // compile error because "const Thing&amp; operator[](int) const" is not provided. This is why, in general, the const version alone works.
For simple `thing_`s I do the same thing. This is for, like... If you're wrapping a vector or other STL container and don't want to make it public.
Why do you have to declare these twice? I cannot think of too many scenarios where you would need both of them. Accessors tend to break the law of demeter; you are better off looking at what data you get from Thing in client code, then implementing those operations as methods themselves, and disgarding the first (and maybe the second) getter implementation. If you really do need both, this means you need direct RW access to this-&gt;thing_, which means you should put it as public and do away with the accessors all-together.
The second example and I have no idea what's going on: cpp &lt;&lt; EOF #define VERSION 123 // ... later ... printf("Version: %d\n", VERSION); EOF What is this cpp &lt;&lt; EOF ? What is this EOF token in the end? nvm, figured it out The first line is a command in bash shell.
Reposting here, since we might have a more focused discussion than on /r/programming. I think C++ could really use a type along the lines of Rust or Go's string slices. [Ranges](http://ericniebler.com/2014/10/06/counted-ranges-and-efficiency/) will be nice if/when we get them, but they're an implementation strategy for a non-owning string class, not a full solution. Certainly it's something I've (re)invented more than once. EDIT: A little Googling suggests I should probably be asking about the status of [N3442](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3442.html) or its descendent.
Hell, array slicing in general would be great, not just limited to strings. To be fair here though, the opinion on that google group seems to be that it's more of the fault of the codebase (25,000 allocation for one keystroke?) then c++ itself.
"design methodology" meaning OOP vs. functional vs. procedural. From what I can tell, Pythonic basically means "use list comprehensions and itertools a lot, and woe befall he who uses an explicit loop index variable." it's about style on a micro level rather than overall program structure. compare to Java's religious OOP or any pure functional language. PEP 8 only contains one rule whose scope is broader than a single line/block, and it's "don't break public interfaces" which is uncontroversial and still doesn't mandate any overall structure.
You shouldn't have had to look that up - It's a really funky way to do this. Even for experienced BASH authors, that syntax isn't used all that often. The author could have used `gcc -E`, boost wave, mcpp, or something else that would take a source file and performed just the pre-processor pass (no C++ needed).
Even prior to C++11 you could have encapsulated the enum in an otherwise empty struct to explicitly give it a name. Although using a namespace was probably a common solution, which justifies its place on the list.
cpp stands for The C Preprocessor in this case, not C++
I'm using boost::string_ref until we get std::string_view.
You're right, I had a `shared_ptr` in mind.
That's just pretty right there. Thanks for posting it. 
You were looking for the const std::string&amp; overload, I don't get how you found const char\*. You are, further, likely guilty of the first offence in the list.
char s[1024] 4 life
char s[4] 1024 life. D'oh!
Yes, but if you don't, you really should have a look at what happens with these string literals later. If your clients copy them into a string, chances are you should have given out a string (watch out for temporaries!). If they call e.g. strlen, you should have given out a string. Etc.
I wish we had ranges, these algorithms would look so perfect.
Don't know what exactly you expect to see but you could try to generate the assembly (with source code comments,) that might give you some ideas what's going on.
Clang's libc++, at least, has some optimizations around std::string. Smaller strings (IIRC up to 23 bytes?) repurpose internal pointers and don't do any allocations at all. Not sure if other libraries do this. 
maybe in 2017 (when we, hopefully, have C++17 with ranges) I'll update this post :)
It's better to use a struct anyway as you can template on it. 
Sounds like a use for [metashell](http://abel.web.elte.hu/shell/metashell)
You can also use [MNMLSTC Core](https://github.com/mnmlstc/core)'s `core::string_view`which is *much* closer to the v7 specification than `boost::string_ref` (such as passing a position to all the find functions, like you would with std::string), however it doesn't permit the mutable case which was recently added. Also, not every function is marked constexpr because the library targets C++11 for the moment. I should also note that `core::string_view` is one of the few headers in MNMLSTC Core that does not depend on any of the other headers found within it, and can be extracted to another project without issue. ok, I'm done self-plugging :v
yeah, I looked at that briefly before (actually at templight) -- will look again thanks! 
Imo `string` is by far the worst component of the standard library. The fact that every string algorithm (find, find_if_not, rfind, etc.) is a member function encourages to construct a string just to run a simple find on it. Add the fact that half of those functions use iterators, the other half indices, and every function has a bunch of overload to compensate for it, and you get this horrible mess.
Why not use something like [HH's short_allocator](http://howardhinnant.github.io/stack_alloc.html)? For reasonable strings you would never allocate. I have started following this in all the new code I write, for fun and profit.
The point is that you provide two overloads: void f(const char*); void f(const std::string&amp;); Now when you call: f("hello world"); It calls the const char* overload and avoids any copies, or heap allocations. If at some point there is an actual need to make a copy, or modify the parameter, or actually use it as an std::string, then and only then will the copy be made. And if you already have an existing std::string and want to pass it to f, well you call the const std::string&amp; overload and once again, no copy is made.
&gt;This stuff makes me want to cry I don't get this reaction at all. Chrome is still a very widely used program (the most widely used?) and it's written in a language that you and I know and understand! That's awesome. It's also awesome that despite this success there is much further improvement to be made. &gt;There must be some insane breed of C++ programmer out there who thinks it's better to allocate and free a few hundred bytes over and over again instead of keeping a big buffer around and reusing it. I think it's much more likely that there's a breed of programmer who has decided that eliminating these allocations will be time consuming and risky. &gt;More practically, I have some ideas on using thread_local memory to manipulate arbitrary-sized strings without allocating constantly. Basically a "big stack" for every thread. Definitely more practical, I hope I didn't take your missive too seriously :) IMHO using more thread local memory isn't a silver bullet. This greatly inhibits thread level multi tasking, which is important and something that C++ does horrifically at the moment. If I had to choose between the standard library doing odd things with thread local memory and stackless coroutines (in my head the two conflict) I would choose the latter. &gt;OTOH, I'm amazed that a big text-intensive project like Chromium would use std::string instead of their own string class. It's a gutsy decision, and I respect them for it. Someone needs to use std::string or it will always be awful. Honestly, if the video game industry had used it in the last 20 years instead of just implementing their own string libraries over and over again, maybe this wouldn't be a problem!
For a hello world application you should only have one project. What happens when you try to run it? You should be able to just click the green play button in the toolbar.
What I mean is, before I can even type any codes, I have to make a project. Which one do I pick? Blank App, Hub App, Split App, Unit Test Library App. I don't want to run an App. But there are no other choices.
Agreed. `string` and `map` are the only STL classes I've seriously rewritten my own version of, and the `map` one is just a wrapper to deal with the quirks of `operator[]`/`find`/`insert`. More info on my `string` stuff in [my post in /r/programming](https://www.reddit.com/r/programming/comments/2ocmvb/stdstring_is_responsible_for_almost_half_of_all/cmm60r4)
You could actually almost do it, except there's no language feature that let's you specify const &amp; non-const: auto&amp;&amp; operator[](size_t) const_or_mutable { return foo[x]; } Of course you still have to account for &amp; vs &amp;&amp; specifiers too. So something more generic might look like decltype(auto) operator[](size_t) &lt;const | mutable | &amp; | &amp;&amp;&gt; { return foo[x]; } Has anyone looked at this for a language proposal? It's not common, but it happens &gt;1 times &amp; it's annoying to have to duplicate the function signature a bunch.
You could try `clang -emit-llvm -S` to get slightly-higher-than-assembly code. But clang tends to generate much worse code than gcc without optimization, and if you do enable optimization all bets are off.
**for** 1-4 are all the same reason.
Ahh that explains a lot. Thanks.
&gt; Foo f(Bar()); &gt; It might just as well be the definition for object f of type Foo, which has a constructor that takes type Bar. No, it may not as well be. It will never be. It may be what the code author intended, but the compiler will quickly correct that misconception. This is the most vexing parse and the language standard defines away the ambiguity by telling us that's a function declaration. It takes as parameter a function returning type `Bar`: http://ideone.com/prRHAo You might still pass an interview with me getting this wrong. I myself forget it on occasion, though now use `{}` instead to avoid that issue. It'd still make me cock my head. BTW, if you ask me how many piano tuners there are in the city, or how long it takes to window wash a skyscraper, or anything like that I'll just say 42 and be done with it. There are legitimate reasons why this is the correct answer in that context but mostly I'll have decided I probably don't want to work under you.
&gt; Why do you think using thread local memory greatly inhibits thread level multi tasking? I'm presuming you want to use thread local memory to remove contention on some memory, but if there are multiple coroutines running on a single thread they will violate that contract and the benefit of the thread local (no contention because it's only accessed from one thread) will be lost. &gt;I definitely wouldn't mess with the standard library Why not? strings should be implemented once and that implementation should be used 99% of the time. The C++ community is unique in its willingness to reinvent these basic constructs in each project, and that cultural convention inhibits adoption of the language. If your solution is not good enough for the standard library, is it really good enough for Chrome?
As for "production whitespace trimming", I'd prefer this take (with benefit of more flexible definition of whitespaces): string trim(const string&amp; str) { const char* cWhiteSpaces =" \t"; // or #define it if you like const auto first = str.find_first_not_of(cWhiteSpaces); // left margin if(first == string::npos) { if(str.size() &amp;&amp; str.find_first_of(cWhiteSpaces)!=string::npos) // string consists of whitespaces only { return string(""); } else // no whitespaces { return str; } } const auto last = str.find_last_not_of(cWhiteSpaces); // right margin const auto range = last-first+1; return str.substr(first, range); } ~same # of lines, just one function, 3 non-trivial calls when there's something to trim, 2 call when there are no whitespaces. And IMO it's quite readable
Gcc has the ability to spit out a mostly C-ish representation of its IR (GIMPLE), but I don't think that would help you much, because by that point most of the C++-ness is lost; too much lowering has occurred. I'd imagine that the situation with LLVM is rather similar. The problem is that generating C++ source code that resembles the original template source but with template parameters substituted in just isn't something that is done by the compiler. It's not comparable to the preprocessor, because instantiating templates is much, much more involved than simple manipulation of textual tokens, since it involves a deep level of interaction with language concepts (e.g. type deduction, overload resolution, etc.) It is that interaction that is essential to understand, and even if there was some option to show an instantiated class or function you'd still not be able to understand important concepts like SFINAE by looking at the instantiations, because seeing the end result doesn't explain the journey that resulted in that outcome. Template meta-programming is essentially the act of writing programs that run at compile time, and you'd only be seeing the final output of those programs. It would be like looking at solved sudokus when trying to understand how code for a sudoku solver works. Maybe it would be better to just ask about things you don't understand?
From the 4 points mentioned, it sounds more like a case of programmers who don't know what the hell they're doing than a problem with std::string. If they worked for me they would all be fired by now.
Does RTTI actually cause overhead when you have LTO? I would think the compiler gets it all back as soon as it can see all the types you'll ever invoke it on, no?
OK, point taken. I should probably temper my enthusiasm for `thread_local`. But I disagree that "strings should be implemented once." `std::string` conflates memory ownership with string semantics when they are in fact independent. You can't use `std::string` without allocating on the heap, and if you write your APIs to take `std::string` parameters there's no way to, say, pass in two different substrings of the same large string without allocating more memory. In contrast, C's `char *` based APIs, primitive and flawed as they are, make no assumptions about memory ownership semantics. It would be better if the standard library provided `string_view` and classes for multiple compatible ownership styles: heap, stack, static, copy-on-write, etc. I don't think we should have one class that intelligently multiplexes between the different ownerships either. (Well maybe it should exist, but it should be one more option built on top of the fixed-strategy allocated strings.) C++ is not supposed to manage memory for you; it is supposed to help you write correctly and expressively once you have reasoned about the memory management you want. My solution, which is just an idea in my head, would be for the specific case of strings that live for exactly as long as a stack frame. Stepanov understood the importance of separating ownership from algorithms when he designed the STL. That's why we have iterators and custom allocators. The standard string should be similarly decomposed.
You don't want /clr as a beginner.
We have hideous macro machinery for spamming out all combinations of cv-qualifiers and ref-qualifiers (12), times non-Standard calling conventions (ugh).
/clr activates C++/CLI, aka the managed flavor. That isn't relevant to beginners at all. You do want an empty project, just not anything saying CLR.
Keep in mind that function pointers have more overhead than functors. The reason is that empty functors are compressed to have 0 overhead whereas using a function means that unique_ptr stores a pointer to the deleter function.
Blank project-&gt;create new source, main.cpp int main() { return 0; }
LTO can reduce the overhead, yes. But it can be very difficult to completely remove it because it's rarely possible that the compiler can prove it is never used. The compiler has to be fairly conservative otherwise it can break code trying to optimize it. 
I appreciate that. I have this hunch though that if you just track all the types typeid/dynamic_cast is called on &amp; just pin those inheritance hierarchies &amp; remove everything else, that gives you 90% of what people are looking for. Of course, I'm sure I'm over looking something about RTTI that makes it more challenging.
There's any number of ways you could slice a hypothetical syntax. The nice thing about the | is that you could omit stuff too. With the auto syntax, you'd probably end up have to duplicate the signature &amp; = delete on the ones you want to omit.
the point (or hope) of the hypthetical is that you could manage (select / omit) this by allowing decltype(*this) to be used for sfinae. prolly not feasible because of obvious reasons i am not aware of and don't understand. [half the battle](http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_defects.html#1207) has been going on for a while it seems. couple this with a mechanism for letting the qualifiers of *this at the callsite propagate to the member function, and i think you would be in business.
Actually, this is something that I've been grumbling about for a while - the Standard is defective and should be fixed, although I don't know how to phrase the fix yet (if I did, I'd submit a Library Issue). The Standard says, and definitely should say, that specializations must depend on user-defined types (no hijacking of stuff the Library might want to instantiate for itself). But when the Standard says "meet the requirements for the primary template", it doesn't really *mean* that. What it means is, behave close enough that the rest of the Library won't care. For example, std::less&lt;T&gt; is required to use op&lt;, so a Library implementation can't do anything else for the primary template (duh). But stuff using less&lt;T&gt;, like set, doesn't actually care what it does. It just expects a strict weak ordering. Same for default_delete - unique_ptr doesn't care what it does, it just wants the object dealt with, in whatever way default_delete sees fit.
So while standard doesn't allow it, it shouldn't break unless something is seriously wrong with the implementation?
I rolled my own "string view" and "data view" classes independently of this, after getting tired of having my code end up with multiple overloads for `std::string const &amp;` and `char const *` for many functions. My string view also has a function to do a unicode conversion on the view, so that a function can be called with both a narrow view and a wide view. My codebase primarily uses UTF-8 with std::string but this is handy for interfacing to Windows API. 
The tradeoff is speed for stability. Once you start introducing `string_view` or equivalent, it permeates its way through the code and you start risking lifetime issues (e.g. a `string_view` still exists while the underlying string that it views has been destroyed). You could fix this by creating a new string class that maintains `shared_ptr` to all of the current views that are open on it, but by this stage the overhead is getting quite high. Finally, "25,000 allocations per keystroke" may sound horrible but allocations are fast these days; it's not 25,000 system calls, the allocator is local to the process. This is probably much less than the amount of time spent rendering each frane. 
iostreams is one of those things that seemed like a good idea at the time, but in hindsight, it got out of hand. They promise of automated localization was never quite realized; even to this day, doing Unicode with iostreams doesn't work properly on any platform. The iostreams are slow compared to other I/O because they have a localization layer. (to cut a long story short) 
How do you think that a graph would be useful in this situation? Can you make an example? We can start from there.
Seriously WTF? Each of those examples is a small, self-contained, self documenting piece of code. They are the epitome of good code. A comment probably wouldn't go amiss, but if you know you the standard algorithms inside out then there should be no difficulty in understanding them without help. And you **should** know the whole standard library inside out.
I don't know what a word ladder is. If I give you these words: "cute" and "bird" What would the word ladder be? If you need to visualise it, draw it on a piece of paper if needed and snap a picture, but also explain to me how you built it.
If you're relying on that, you don't need const&amp; in the first place. A string ref/view/range/etc type class guarantees no allocations. That said, personally I think it's pretty lame that we need two different classes to do pretty much the same thing.
I strongly disagree with the philosophy behind your last point. the existence of slower workloads in the program does not give you a license to be inefficient. apply this philosophy repeatedly and your program dies from a thousand small cuts of inefficiency. I do not believe the spirit of Knuth's premature optimization advice extended to allocating 25000 blocks of heap memory per keystroke.
Each node of the graph should be a word, and the edges of the graph should signify the act of changing one letter. Then, in order for you to get from one word to another all you need to do is find a path between the node of the first word and the node of the second word.
So if you gave me those two words, it would return the word ladder for them, it would link the two words, printing out each word between them by changing one letter at the time from the begging word to the ending word: for "cute" and "bird" a possible word ladder is: cute → cure → curd → burd → bird They all need to be real words 
Yeah, That's a way I was thinking about it, but I need to use all these words as a data base: http://www.scrabble.org.au/words/fours.htm and I can't imagine how I can organize the words in a graph. Every node would have thousands of edges for all the different possibilities.
If you represent the dictionary as a graph where words are nodes and edges are operations changing a single letter, the problem becomes finding a path between any two given nodes. For data structures, an adjacency list can store your graph. You'd have a map from a word to a vector of words.
You filter by actual words. Not every possibility is an actual word. e: Just used my implementation to calculate average degree for this wordlist. It's not so bad, only 13.24
What /u/jedwardsol said. This is, I think, the best way to do it -- at least, it's the most intuitive. There are a few different ways to implement the graph, so you have various time/space trade-off issues you need to consider (unless you have an implementation handed to you by your professor), but I am having difficulty imagining a better way to use a graph for this problem.
Your work in the hard real-time embedded world has helped you derive a lot of the constraints on HFT systems. It's refreshing to come across well considered questions like yours, I'll provide some insight. **Userspace** You already worked this out: an HFT system is a *user-space* system. At no point will any time-critical component invoke a syscall, allocate memory, or block. A lot of development work is simply to avoid context switching into the kernel and the non-determinism that follows. Linux is a operating system of convenience, mostly because of the development tooling but also because it's fairly easy to make it get out of your way. We boot with CPU isolation (the scheduler is disabled for a subset of CPUs) then manually place threads/processes. *Everything spins*: there's no sleeping, no waiting on a condition variable or futex, no wakeup delay from blocking in epoll(). No page faults because we've already allocated, pre-faulted, then locked all the memory the program is going to need. You pretty well summed it up when you said *"[c]an't imagine writing a hyper-optimized C++ trading algorithm, only to hand it off to some heavyweight OS's scheduler &amp; pray for the best."* **IO is via kernel bypass** A typical system is inundated with network traffic. Delivered via UDP multicast (for a majority of exchanges) or an API library (in some oddball cases). There is also internally generated network traffic as the trading strategies talk to each other about their activities, and to components that connect to the exchanges to send orders and receive order executions. Vendors of high-performance 10gig and 40gig cards like [Solarflare](http://www.solarflare.com/1040GbE-Flareon-Server-IO-Adapters), [Exablaze](http://exablaze.com/exanic-x2), and [Mellanox](http://www.mellanox.com/page/ethernet_cards_overview) ship a kernel-bypass library with their cards. The bypass library intercepts recv(), send(), epoll(), etc and replaces them with user-space versions that DMA or PIO directly to the underlying hardware. Various library tunables allow one to trade off how long and aggressively you want to spin waiting for your IO. The libraries take care of the housekeeping necessary to update Linux kernel data-structures so both bypass and "vanilla" code can seamlessly co-exist on the same server. Some of these libraries are open-source if you're curious. Two popular ones are [OpenOnload](http://www.openonload.org/) and [libvma](https://code.google.com/p/libvma/). 
This is awesome. I had been looking for something like this for a while. 
do you think that we modularize to avoid collisions, and not to enforce the modularity? And do you think that the primary goal of anonymous namespace is to avoid collisions?
Yes it could be better, but namespaces still used also to resolve the enum issue.
If a user specialization achieves the "moral requirements" for the component, I cannot imagine how a Standard Library implementation could break. And I am a devious Standard Library implementer who is constantly imagining how to do sneaky things without users noticing, and how to avoid being subverted by sneaky users.
&gt; Random access iterators are a refinement of input iterators, as are forward iterators. The distinction between forward iterators as a refinement of input iterators is an important one; the former guarantees you can start over in the range. I think you are missing the point entirely. An input iterator can have random access traversal and be multipass as well. A simple example using boost: std::vector&lt;int&gt; v = { 1, 2, 3, 4, 5 }; auto squared = boost::range::transform(v, +[](int x) { return x*x; }); auto it = squared.end(); std::advance(it, -2); // BLOWS UP!!!! That is because the iterators to `squared` are input iterators. However, `it -= 2` is valid, because the iterators have random access traversal and are multipass. &gt; This confused requirement not to use the existing categories is what turns your tag dispatching code into a massive mess...well, it's a primary reason anyway. Also, I was trying to demonstrate a more general principle outside of iterators. The reason you can use the iterator category like you've shown is because it was explicitly specified by the iterator, which I mention in the blog. So when you are creating your own tag-dispatching concepts you can either make it explicit by the user or try to deduce it somehow. I dont see any other way. &gt; Even this overly-complicated tag finding metafunction only needs to be written exactly one time and then can be used in a multitude of dispatch functions. In your first example though this exact logic must in fact be done time and time again as you create new functions that work on these concepts. This is actually really bad in cases when you might change the tags because then you have to hunt down all uses and make sure they're dispatching correctly based on the new hierarchy. That is a good point. Ill try to add it to the blog. Although when I mentioned the 'dispatching boilerplate' that was not what I was referring to. 
&gt; An input iterator can have random access traversal and be multipass as well. Is it that you just don't understand the refinement relationship? It's pretty much like inheritance except that it's about concepts rather than types. struct input_iterator { virtual ~input_iterator() {} }; struct random_access_iterator : input_iterator {}; void fun(input_iterator const&amp; i); You are arguing that categories are no good because an input iterator could be a random access iterator. The equivelent of that is that `fun` is no good because `input_iterator` could be a reference to a `random_access_iterator`. This is an upside down viewing of hierarchies that fails to recognize the truth in LSP. In both cases `input_iterator` is not a `random_access_iterator` but in fact the is-a relation is the opposite. In your example vector's iterator is a random access iterator, which is a *refinement* of input iterator but not input iterator itself. So you're right. I'm missing your point because you don't seem to be making one that makes any sense at all. What I can gleam of your point appears to be based on some rather serious misconceptions. &gt; Also, I was trying to demonstrate a more general principle outside of iterators. So you chose to use the most complicated method you could think of to do it and then say, "As you can see, this has problems." &gt; Although when I mentioned the 'dispatching boilerplate' that was not what I was referring to. Then I guess I'll leave what you meant by that an uninteresting mystery I'll never try to solve. I'm the type of person who expects the writer to express their intended meaning, not the reader to try wrangle it out of them when they've said something else.
&gt; Is it that you just don't understand the refinement relationship? It's pretty much like inheritance except that it's about concepts rather than types. I do understand. You don't understand as can be seen by your code snippet. Random access iterator is a refinement of both input iterator and output iterator. It should be written like this: struct input_iterator { virtual ~input_iterator() {} }; struct output_iterator { virtual ~output_iterator() {} }; struct random_access_iterator : input_iterator, output_iterator {}; So if I make a read only random access iterator that inherits only from input iterator: struct read_random_access_iterator : input_iterator {}; At most it could be an input iterator since the iterator categories don't support this concept. However, there exists iterators like this(like in the example I showed). &gt; You are arguing that categories are no good because an input iterator could be a random access iterator. No, thats not it. I'm saying that an iterator could have a most refined category of input iterator, but could have random access traversal and be multipass. &gt; In your example vector's iterator is a random access iterator, which is a refinement of input iterator but not input iterator itself. In my example `v` has random access iterators, however, the iterators to `squared` return by value when dereferenced so they can only be input iterators and not output iterators. Since a random access iterator is a refinement of both input iterator and output iterator, they cannot be a random access iterator. However, the iterators to `squared` do have random access traversal and is multipass(which is not necessary for `std::advance`) in spite of being only an input iterator and not an output iterator. &gt; So you chose to use the most complicated method you could think of to do it and then say, "As you can see, this has problems." What are you talking about? I show two ways to do it. Explicitly specify the traversal, like what the standard library does for categories or deduce it. What other way is there? &gt; Then I guess I'll leave what you meant by that an uninteresting mystery I'll never try to solve. I'm the type of person who expects the writer to express their intended meaning, not the reader to try wrangle it out of them when they've said something else. I was referring to the extra function that needs to be written for tag dispatching, because you write `advance` and then `advance_impl`. Sorry for the confusion, I'll try to make it more clear. Thanks for the feedback.
I think I see what you're getting at with your example. You seem to be claiming that the return of `transform` is an iterator that has the function definitions of a random access, multi-pass iterator but that if you actually use it as such you'll have a bad time. I'm really quite bothered by that if it's true. I'd be one to say that `transform` is then broken in a very bad way. The static type system is supposed to protect us from crap like this. I am very much hoping that you're completely wrong about this. I'm also confused as to why you think it matters to what you're doing. You're not solving the problem in any way that I can see. All of your examples are still going to mistakingly use the advancible interface even though doing so--by your claims, I don't know that it's true--will cause bad thing to transpire.
&gt; I think I see what you're getting at with your example. You seem to be claiming that the return of transform is an iterator that has the function definitions of a random access, multi-pass iterator but that if you actually use it as such you'll have a bad time. No, thats not what I am saying. I am saying that `transform` returns an iterator that has random access traversal, but is not an output iterator nor a forward iterator nor a random access iterator. The example blows up because `std::advance` tries to move backwards on an input iterators, instead of calling `it -= 2`. &gt; I'm really quite bothered by that if it's true. I'd be one to say that transform is then broken in a very bad way. Transform is not broken. The iterator categories are broken(or rather lacking). Unless you think that `transform` should not allow functions that return by value? That just seems like a bad idea as well. &gt; I'm also confused as to why you think it matters to what you're doing. You're not solving the problem in any way that I can see. All of your examples are still going to mistakingly use the advancible interface even though doing so--by your claims, I don't know that it's true--will cause bad thing to transpire. If you use the `advance` function as defined in the blog my example will work properly since it uses the traversal and not the iterator category. 
&gt; Your information is dated. See cppreference: http://en.cppreference.com/w/cpp/iterator I guess it is outdated, sorry. Either way a forward iterator is defined to have this true(as shown [here](http://en.cppreference.com/w/cpp/concept/ForwardIterator)): value_type&amp; temp=*i Since in my example the `transform` returns by value, it can't be a forward iterator nor a random access iterator, only an input iterator. &gt; Your example shows none of this. First, you're wrong about it not being possible to be random access because it's not output--that defect in the standard has been fixed. Second, nowhere in your code do you use it as an output iterator yet you claim it blows up. Whatever point you were trying to make with your snippet you didn't. What are you talking about? It blows up because you try to go backwards on an input iterator. However, doing `it -= 2` will work, because the iterator has random access traversal. It can't be a random access iterator because it returns by value. &gt; Default to looking in the type for a specific typedef. First, I am not using the iterator category. I want it to work based on traversal not category. Secondly, I want to show how someone would go about defining their own tag hierarchies. So either make it explicit like what the standard does for iterator categories, or deduce it. I show both for iterator traversal.
OK, then yes you are stuck having to use your own tags. Boost solved this problem by inventing a different set of concepts with a translation layer between them and the standard categories. Not sure how boost does it but I would approach it something like so: BOOST_MPL_HAS_XXX_TRAIT(traversal_tag); template &lt; typename T &gt; struct traversal_ { using type = T::traversal_tag; }; template &lt; typename T &gt; struct category_to_traversal; // mapping from standard container categories to traversals template &lt; typename T &gt; struct traversal_tag : eval_if&lt; has_traversal_tag&lt;T&gt; , traversal_&lt;T&gt; , category_to_traversal&lt;T&gt; &gt; {}; // traversal_tag&lt;&gt; overloads for T*... User could then implement new iterators in three different ways: struct my_iter { using iterator_category = random_access_iterator; }; struct my_iter { using traversal_tag = random_access_traversal_tag; }; struct my_iter {}; template &lt; &gt; struct traversal_tag&lt;my_iter&gt; { using type = random_access_traversal_tag; }; The first two could be used together in the same type. There's a bit more to it than this because you'd want your new tagged types to work with standard functions. This is pretty darn far from the norm for the situation though and it's not something you solved in your blog either. You could alternatively solve the problem by telling the user to inherit from an adapter, as boost recommends. Then you can perform some work to decide whether that adapter's tags translate to, or literally are, standard iterator category tags. If so you add `iterator_category` to the iterator so it works in standard iterator functions (can be done through inheritance). Finally you simply write new functionality using your traversal tags rather than iterator categories and all is well. I left `category_to_traversal` out because the implementation depends greatly on the traversal concepts and how and when they map from categories. It might be as simple as an mpl map, or it might be a monster. Goal though is to take any standard category and give a traversal for it. How that happens doesn't matter to the dispatch bits.
A small change I prefer: struct status { enum Enum {ok, error}; }; That way you can refer to the type as 'status::Enum': status::Enum doSomething(const std::string&amp; command); std::string errorToString(status::Enum status_val);
I don't know enough about whether you're right or not, and your tone is a aggressive, but man good hustle following through with your criticism and being crazy constructive about it. 
for a python Programmer is there a new book on the latest CPP programming? All I find at Barnes &amp; Noble are the C/C++ style cookbooks.
&gt; The iterator categories defined in C++98 are extremely limiting because they bind together two orthogonal concepts: traversal and element access. For example, because a random access iterator is required to return a reference (and not a proxy) when dereferenced, it is impossible to capture the capabilities of vector&lt;bool&gt;::iterator using the C++98 categories. This is the infamous "vector&lt;bool&gt; is not a container, and its iterators aren't random access iterators", debacle about which Herb Sutter wrote two papers for the standards comittee (n1185 and n1211), and a Guru of the Week. See [here](http://www.boost.org/doc/libs/1_57_0/libs/iterator/doc/index.html). **TL;DR**: Iterator categories design is flawed at the heart, and for some reason in the past 10 years no fixing proposal has been accepted.
You're right. Being a bit aggressive here. I was tired and this isn't the first time with this guy. Last one he turned functions into templates just so he could check whether int had 4 or 8 bytes. He never did explain why anyone would ever want to do that. He's got some good ideas but some of his stuff is just downright teaching wrong things. Complexity just for its own sake. I find it quite frustrating. Also, in previous discussions I've suggested tag dispatching. This is the first he's added it to his blog and it seems to me set up specifically to make it look like the bad choice. If that's the case then he's being intellectually dishonest and I find that enormously frustrating in an engineering/scientific field of discussion (anywhere really, but especially there). So yeah, my anus itches a bit and I'm probably being more *aggressive* than warranted.
&gt; Analyzing the type to tag it from the outside is overkill and doesn't actually get you enough to warrant it. The user can still screw up by making functions that exist but don't do what the concept defines. This is one of the major flaws with concepts lite. It will try to deduce the type requirements which could be wrong, however, there is no way to specialize the concept so it works correctly. However, in my post, the `get_traversal_tag` can be specialized if it deduces the wrong tag. &gt; The general pattern of tag dispatching is to put the tag in the class and look for it there by default. That pattern should be strongly preferred--first off for its simplicity. For tag-dispatching, I agree. However, for writing templates, I believe that checking type requirements should be preferred. Since, not checking type requirements is what leads to long and confusing compiler errors. Also, it can be clear from the function what the type requirements are, which makes reading the code easier.
Clang seems to be close to your ideal implementation. &gt; zero-initializes to empty string, because performance Clang's default ctor zero-initialises the object: basic_string&lt;_CharT, _Traits, _Allocator&gt;::basic_string() { __zero(); } &gt; uses nearly whole footprint for the small string, because efficiency Clang uses 23/24 bytes of the string, which allows you to store a string of length 22 (+ null char). &gt; takes no more than 16 bytes, because why should it use more On x64 `sizeof(CharT*) + sizeof(std::size_t) + sizeof(std::size_t) == 8 + 8 + 8 == 24`. Can we make this smaller? &gt; empty-base-optimization for allocator Clang uses an equivalent to `boost::compressed_pair` to store the data + the allocator, which I think leads to more readable code. Using your implementation, if I have a string of length N + 1 (which would heap allocate), then I call `pop_back`, your implementation would have to then move to SSO. I would find it strange that iterators would be invalidated at this point, but I can't find anything in the standard that says this can't happen. The closest section I found was this. &gt; **21.4.1 basic_string general requirements** &gt;6 References, pointers, and iterators referring to the elements of a `basic_string` sequence may be invalidated by the following uses of that basic_string object: &gt; * as an argument to any standard library function taking a reference to non-const basic_string as an argument.237 &gt; * Calling non-const member functions, except `operator[]`, `at`, `front`, `back`, `begin`, `rbegin`, `end`, and `rend` Using the Windows API to eliminate capacity is a cool idea. Are there any downsides to this that you know of?
I would prefer the name `value` imho, but whatever.
Slicing in C++ just got a whole lot better. Check out [this blog post](http://ericniebler.com/2014/12/07/a-slice-of-python-in-c/). Disclaimer: I'm the author. I'm also the author of [the range proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4128.html).
Who needs index variables when you can enumerate(list) and then iterate over that? ;)
Impressive, and portable! I've written my own, highly unportable, 22 char solution in the past. I exploited the fact that pointers on x86-64 only utilize 48 bits of virtual address space. In userland, where processes are mapped in to low memory, the two most significant bytes are always zero due to sign extension (bits 48 through 64 have to be the same as bit 47 or the CPU will fault). As it happens, because x86-64 is a little-endian architecture, this gives you two full bytes to abuse in the final word, one conveniently placed for null-termination, and one in which to store length. Simply storing a pointer in to the final word (the heap pointer) changes the string to the 'big' form by virtue of a length byte of 0 signalling a big string. union Rep { struct Small { char str_[22]; // data() bytes char nul_; // 0x00, null termination unsigned char len_; // (1, 22) when Small } small_; struct Big { size_type size_; size_type capacity_; union { pointer ptr_; struct { unsigned char x[6]; // never accessed via this reference unsigned char nul_; // always 0x00 unsigned char len_; // 0x00 when Big } ptrbytes_; } buf_; } big_; }; You still get constant time size() and binary safe small strings, no bit twiddling decode, and only a check for zero in the final byte (len_) to determine the strings status. This is, of course, still pretty evil :)
Here is another site from a reddit post that might be interesting http://www.codingame.com/ 
Actually, going back to the SSO would typically be considered wasteful for the same reason that containers typically don't release capacity until the destructor (or the new shrink_to_fit API call). You don't want to release your heap memory just because you went down to 23 bytes. What if you're at the threshold, removing &amp; adding 1 character? For the majority of applications, retaining the allocated memory is the correct behaviour. If you need to actually shrink to the requested space, there's now APIs that let you accomplish that more elegantly than in the past.
Out of curiosity, is there anything in the standard that says they must support strings/vectors up to the maximum size allowed in the address space? Why don't containers internally use uint32_t? My guess is that it simply doesn't matter, performance-wise, because you're going to end up passing most of the data in registers where the size difference is irrelevant. According to Wikipedia, you're first 6 words (i.e. 48bytes on x64) are "free" in that they get passed as registers. On AArch64, it looks like you have 8 registers (i.e. 64-bytes). Do you know if that is that the reason?
This is what I did for the last year. good to see others try and get their hands around it. 
You seem to understand the std iterator categories in detail, but somehow missed Boost.Iterator which uses similar (but way better) iterator categories. I recommend you to read [1-2], one is the final standard draft about Boost.Iterator categories. The other is a new paper for C++17 about a range-based standard library using concepts (there is agreement that a concept-based standard library doesn't need to be backwards compatible and thus a lot of things can be improved/fixed). I think that without knowing about these, the choice of iterator categories on the blog post is a bit hard to follow, but it is hard to blame the author here since his blog posts are very advanced anyways. [1] New Iterator Concepts (N1297, N1477, N1531, N1550): http://www.boost.org/doc/libs/1_57_0/libs/iterator/doc/new-iter-concepts.html [2] N4128 Ranges for the standard library (3.3.7 and 3.3.1.2) http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4128.html
Stupid question: what is a "TSS arena"?
On x64 your theoretical string will still have `sizeof(string) == 24` because of the alignment requirements. You don't save any memory by using something smaller than `std::size_t` here.
I'm surprised he talks about all the missed optimization opportunities and then uses an assert to ensure a number is non-negative instead of declaring it unsigned.
TSS = Thread Specific Storage. So, one global pool per thread to allocate objects from (simple ShortAllocator is not thread aware)
Highly unportable is just a synonym of super fast! I didn't know that only 48 bits are used in x86-64. You've got a nice, readable solution here by using those 2 free bytes. I guess I've not seen something like this used in any of the standard libraries because it would double the amount of testing required for `std::basic_string`.
The problem is that if you declare as unsigned and someone passes you negative integer, you get HUGE unsigned number, which might or might not be valid... Basically, implicit conversions are a PITA as usual.
The issue with this trick is that future CPUs are expected to start using those bits when needs for them arises. And once OS starts handing out such addresses all bets are off. I am pretty sure that Windows will introduce some automatic shims or address space clamping unless your application has specific manifest or whatever to yet again ensure compatibility with this kind of software, but others... not likely.
Do not most compilers give warnings for this? Also I though that uniform brace initialisation meant that the arguments will never be narrowed. Or does signed→unsigned not count as narrowing?
... and if you think about it, because you can never have more than 48 bits of consecutive virtual address space, neither size() or capacity() can be &gt;48 bits either. The standard requires that std::string be contiguous. This actually means current 24 byte implementations on x64 can already be compressed to 18 bytes, which would allow us, in principle, to cram an extra string object in to a 64B cache line.
Agreed. I like Elliots solution better. That said, I hope me and std::string (although perhaps not x86, which Jibbers the great lobster god has decreed is eternal) are long dead before your everyday mallocator needs to provide &gt;256 terabyte chunks.
From the Google C++ style guide: &gt;You should not use the unsigned integer types such as uint32_t, unless there is a valid reason such as representing a bit pattern rather than a number, or you need defined overflow modulo 2^N. In particular, do not use unsigned types to say a number will never be negative. Instead, use assertions for this.
&gt; You seem to understand the std iterator categories in detail, but somehow missed Boost.Iterator :P smh &gt; ... it is hard to blame the author here since his blog posts are very advanced anyways. You think so?
[I knew I'd seen that python code before.](https://docs.python.org/3/tutorial/introduction.html#lists) (Seventh box down)
I worked in this space for 10 years, this hits it on the head, so much so in fact, I am curious if we had the same previous employer. The only thing I would add is that market data is handled by an FPGA based system, Exegy is currently the leader in this space. It is generally delivered from the box via RDMA over infiniband. The math is generally quite simple- because you don't have time to do math. In fact, any complex calculations are generally done outside the system, and then delivered as a simple value like other market data. You do as much work as you can up-front so that just some fairly basic logic is invoked at order generation time. This means caching all the static data you could possibly need, allocating memory pools of objects that will later be re-used (and pre-populating those objects, orders for example al have the same boilerplate fields that identify the firm/traderID for example). 
This is a concern of mine too, but I am finding my PhD quite boring anyway (working alone rather than part of a team) and if I decided to stay in academia the salaries are very low. I'd like to be a dev in a company whose primary operation is writing software (google / facebook level if possible) working as part of a team on a high impact project doing something that would otherwise not happen. In contrast, how many people are actually going to read my research? My PhD will be from Cambridge so I'm hoping this helps with getting a job at an interesting place with a good salary. I'm sure what I want to do with my life but I would like to earn some money for a few years while I decide and being a C++ programmer seems like the best way to do that given my skills / education. I'm open to suggestions though!
Thanks for the tips. I agree about academic projects being self contained but I have incorporated some external libraries into one project which was a good experience to have. 
Thanks for the advice, I saw the source code reviews for Doom 3 so I will likely read those. 
Thanks for the information. Do you think that (Get good at politics and programming people) is still the case in companies whose primary role is writing software such as Google / Facebook? I can imagine working in the dev department of some large company is not fun and is not optimum for hiring / actually writing code but I hope that isn't the case for completely software based businesses. 
Except that this code doesn't meet Google's standard in various other obvious ways, so that's not at all relevant. No other C++ coding standard/guide makes such a recommendation.
Be that as it may, the widespread use of size_t (being an unsigned type) throughout the standard library is generally regarded as a mistake, mathematical correctness notwithstanding. Bjarne himself has stated as much. Conventional wisdom suggests unsigned types should be reserved for bit patterns, not _numbers_.
I use signed integers in the article, and in my range interface, because I want to be able to detect when my interface is being used incorrectly. An interface that is sprinkled with signed and unsigned integers is asking users to do casts that require range-checking that nobody does. Signed/unsigned compiler warnings are so common people dismiss them without thinking. An assert is harder to ignore.
Yep Bjarne and Chandler Carruth talk about this point around the 12min mark of [this video](http://channel9.msdn.com/Events/GoingNative/2013/Interactive-Panel-Ask-Us-Anything). And Scott Meyers has a paper on it [here](http://www.aristeia.com/Papers/C++ReportColumns/sep95.pdf). This issue drives me up the wall because my team has overruled me in favor of unsigned types everywhere.
I'm not disagreeing with that, I'm merely pointing out that GSG should be the last argument you should use when it comes to C++.
Thanks, that's a good, if sad ("signed/unsigned compiler warnings are so common people dismiss them without thinking") point. I still wonder though, isn't it preventing some interesting optimizations opportunities on the compiler part (beyond just the assertion checking)? I wish there was a #pragma for forcing signedness ambiguities into errors. This part of the type system would be more useful if it was more sound. Maybe it is possible to leverage on signedness to get both the optimization and the hard failure? Or to automatically transform it into from_end?
For compile-time index ranges, you can be devious and abuse floating-point user-defined literals: template&lt;char...Chars&gt; constexpr decltype(auto) operator""_x() { // .... implement range logic here .... } std::cout &lt;&lt; ints[2.5_x] &lt;&lt; std::endl; // ints[2:5] std::cout &lt;&lt; ints[2._x] &lt;&lt; std::endl; // ints[2:] std::cout &lt;&lt; ints[.5_x] &lt;&lt; std::endl; // ints[:5] However I don't see how to make it work with negative indexes. 
You could probably cut it down to 14 bytes if you compress the ptr into 48-bits (i.e. share some bits with size). I don't know if the cache miss argument though is worth it though. You'd have to have a lot of string structures lying around for that to matter.
Kind of yes. He writes about tricks that he learns writing some of his libraries, two of which (TICK and FIT) are in queue for Boost review. So I expect his audience to have an advanced level and with that a familiarity with Boost. For that kind of audience, the flaws of the std iterator categories are clear and need no explanation. For a different kind of audience I am not going to speculate. Im just happy he wrote the post as I found it to be an interesting follow up on Xeo's post about ranking overloads, and a "mini" introduction to FIT.
Filing that one away in my "sick and evil but potentially useful" folder.
Still, I would favor a dual interface: from_end operator-(decltype(end), int) = delete; would immediately alert the user that he should not be using a signed integer (well, actually you would need the overload to be slightly more subtle). Of course the user might still cast without checking, but that's another issue...
&gt;Signed/unsigned compiler warnings are so common people dismiss them without thinking. An assert is harder to ignore. You could `=delete` a signed overload of the slice operator. That would solve the _ignoring warnings_ issue, not the _unchecked casts_ one... 
#pragma warning(error: 4018) I think that should work in MSVC, though I haven't tested it. Think there is also some project level settings for this /WX compiler flag can set all options as errors /we4018 might be the one for command line? 
It's an interesting suggestion, but I really do want `rng[{1,5}]` to compile, and integer literals are signed. It gets pretty annoying to have to say `rng[{1u,5u}]`, and the compiler error for trying to use a `delete`d function isn't going to be terribly enlightening.
Most of the developer job listings I've seen that look really interesting and exciting require a Ph.D. Every job I've worked at, co-workers with Ph.D.s were doing the really interesting part while I was hooking up their work to fucking buttons and sliders. Sure, they accept equivalent work experience too, but it's hard to get that experience.
&gt; I wish there was a #pragma for forcing signedness ambiguities into errors. This part of the type system would be more useful if it was more sound. You can do this in gcc and clang using `-Wsign-conversion` (or `-Wconversion`) and `-Werror`, but in the very general case, types are implicitly converted.
Devil's advocate here: and what if we used only pre-canned capacities? The standard does not require that the user may set the capacity directly, only that he may ask for more. By using pre-canned capacities you would thus be able to compress the representation of the capacity: - if power-of-2, then the capacity is actually `1 &lt;&lt; str.capacity` for example - or using a table, then the capacity is `table[str.capacity]` (allow to use a more fine-grained approach) The idea is to only use 8 or 16 bits for the capacity, and therefore end up with: struct string { char* ptr; std::uint64_t size : 48; // or 54 std::uint64_t capacity : 16; // or 8 }; which brings back `string` to a maximum size (and thus capacity, as afterward it's useless) of at least 2^48 characters. An alternative would even be: struct string { char* ptr; std::uint64_t size : 48; std::uint64_t capacity : 8; std::uint64_t heap : 8; // 0 if SSO, 1 if heap }; which is arguably the most straightforward implementation I could think of, with `heap` playing the role of the NUL character in case of SSO strings.
This thread has been linked to from elsewhere on reddit. - [/r/rust] [In case Short String Optimization looks interesting to Rust... \[x-post from r/cpp\]](http://np.reddit.com/r/rust/comments/2oo8t0/in_case_short_string_optimization_looks/) *^If ^you ^follow ^any ^of ^the ^above ^links, ^respect ^the ^rules ^of ^reddit ^and ^don't ^vote ^or ^comment. ^Questions? ^Abuse? [^Message ^me ^here.](http://www.reddit.com/message/compose?to=%2Fr%2Fmeta_bot_mailbag)* 
&gt; I guess it is outdated, sorry. Either way a forward iterator is defined to have this true(as shown here): &gt; value_type&amp; temp=*i This is not true for const forward iterators. 
&gt; Random access iterator is a refinement of both input iterator and output iterator. This is incorrect. `const int*` is a random access iterator but not an output iterator.
&gt; the widespread use of size_t (being an unsigned type) throughout the standard library is generally regarded as a mistake Why? I'd really like to see some in-depth discussion about this.
Excellent write-up!
See Eric's explanation above: http://www.reddit.com/r/cpp/comments/2om5yk/a_slice_of_python_in_c_eric_niebler/cmovdr6
I'm not sure I understand. Copying a random access iterator yields a random access iterator. Copying `*i` where `i` is a random access iterator probably doesn't yield an iterator at all, but it could yield... This would: vector&lt;vector&lt;int&gt;::iterator&gt; v { ... }; auto i = *v.begin(); // i is a RAI 
See [/u/cozmorado's](http://www.reddit.com/r/cpp/comments/2om5yk/a_slice_of_python_in_c_eric_niebler/cmovrgb) reply.
On that note, I've occasionally wished that you could do `=delete("do this other thing instead")`.
I watched the video. There's only guidance given, no reasons for it. I'd like to know the reason -- other than "because Chandler and Bjarne say so".
I think that one of the advantages to using this kind of syntax is that it's more composable: some::slice::type slice_bounds = {2,5}; auto result = v[slice_bounds]; AFAIK, C++ doesn't really have a clean `.apply()` equivalent, so this is as good as it gets.
The part I don't understand is that if the ranges accepted `size_t` instead of `int`, wouldn't that fire a signed-to-unsigned conversion warning/error if negative values were used? That coupled with the `end` type should handle the major iteration cases while making it hard to screw up.
For some values, wouldn't decimal to floating-point conversion errors cause some erroneous results?
Well, starting from the recommendation that you should always default to `int` and only use `unsigned` when you need it. Then one reason why `size_t ` being unsigned is a mistake is that it keeps popping up in all your nice signed arithmetic, causing conversions and other nastiness.
Not everyone turns this warning on, signed/unsigned mismatch warnings are so common they tend to be overlooked. Asserts are much harder to ignore.
Good example. It's one of the many reasons why the use of unsigned integers in the standard library was probably a mistake. `std::string` is a textbook example of a great many anti-patterns and design flaws. I believe this unsigned offset problem and others were because the offset-based interface of `std::string` was designed *before* the STL was air-lifted into C++98. The iterator interface was bolted on later. Iterator distance is always signed, hence the impedance mismatch.
But what's the big problem? Why would you want to specialize `less` if you can just implement `op&lt;`?
I'd rather recommend people to buy a good book, like Scott Meyer's 'Modern Effective C++'.
But they *can* be easily caught at runtime. Better than nothing.
No; you get the actual characters of the literal in `Chars...`, so there is no conversion made.
Thanks for the recommendation! I heard about this book more than once, so it must be good. But I'm still looking forward to an improved Learn X in Y minutes article though. ☺
This is awesome! I think this is really really great. It's one of the few things of Matlab that I miss when programming C++. It's sooo super handy. And now we got it in C++. I wish that would get into the standard library :) Thank you very much, this totally made my day today. 
I suppose the issue is, to those who already understand the advanced features being used in this article, they are also likely to understand all the flaws in this post and how this is a really really convoluted way to solve a problem that has already been solved using a far superior approach. The problem is that those who don't understand said features and could potentially stand to learn something, they will be learning some rather obscure and incorrect info and won't be in a position to know any better. That's why it's relieving to see someone point these errors out. Also any library can be submitted for review by Boost, it's an open and transparent process. Being in a queue for review is not indicative of whether a library is advanced or even functional for that matter.
Gotcha. I completely missed the `char...Chars` expression. :)
&gt;but potentially useful You're a generous sort... :)
Learn Modern C++ in 10,000,000 minutes!
Yes. I looked through the patch and while it certainly is a big improvement, I am still not entirely satisfied with it, as it is much more conservative that what we discuss here. But maybe just my wishes are outside of what is allowed by standard or feasible for other reasons. Anyaway it uses 16 bytes of local SSO capacity, sharing it with just the 'capacity' member (as we discussed nearby). size_t size is a normal member variable and so is the data pointer (hidden in struct derived from allocator to employ empty base optimization) which points to local buffer when SSO is used (.data() is then very straightforward). Thus this structure always uses 24 (x86-32) or 32 (x86-64) bytes whatever the char_type is, leaving SSO capacity of 15 chars, 7 u16chars or 3 u32chars not including NUL character. 
15 years and I still don't know what a vector is. 
I actually find that *usually* (but not in this case), the second part is actually misinterpreted. "Make interfaces easy to use correctly and hard to use incorrectly" gets interpreted as; "Make interfaces hard to use incorrectly". Which further becomes; "Make interfaces impossible to use incorrectly". Which leads me to say; "This interface is hard to use." The point is, I think it's important to focus on the first part, and to not sacrifice it in the name of the making it impossible to screw up. Your example is, I think, perfect with regards to this. Just assert 100% of the time. Perfect. It might be possible to come up with a way to enforce this at compile time, but you would end up with an interface using &lt;&gt; it would require constants. This is better. EDIT: Grammar
I am saying the iterator when dereferenced returns a value: std::vector&lt;int&gt; v = { 1, 2, 3, 4, 5 }; auto squared = boost::range::transform(v, +[](int x) { return x*x; }); auto&amp; x = *squared.begin(); // Compile error And because this fails to compile, it cannot be a random access iterator. That is why boost sets the iterator category to `input_iterator_tag` and not `random_access_iterator_tag`. Futhermore, because `std::advance` relies on the iterator category tags rather the iterator traversal, it breaks at runtime. 
Vectors transmit viruses. This is true in more ways than one!
&gt; this is a really really convoluted way to solve a problem that has already been solved using a far superior approach It isn't a far superior approach to rely on iterator categories that are flawed. Futhermore, it is very problematic having the user arbitrarily pick the iterator category without checking its type requirements. As we can see from this discussion on the requirements for iterator categories here, its very possible people would pick an iterator category that does not fulfill its type requirements.
A lot of those language features do not result in fewer bugs. On the contrary, writing very simple, minimalist C++ code often results in few bugs and excellent performance.
yeah but you'd have the option to use 7 bytes for `size` and 1 byte for `capacity` which would drop you back to 16 bytes total.
10 days later, still couldn't grasp pointers. I have seen some stuff telling me not to use pointers though
&gt; There must be some insane breed of C++ programmer out there who thinks it's better to allocate and free a few hundred bytes over and over again instead of keeping a big buffer around and reusing it. ... eventually ending up writing your own malloc/free operating on the big buffer? Underway losing debugging facilities offered by the OS (page protections &amp; range checks [look up Intel MPX]), runtime library (debugging versions of malloc/free) and instrumentation &amp; profiling tools (valgrind). Sure, allocations in a tight loop are bad. But omnibox, intended for interaction for humans? Not worth optimizing, even if it's 25k news/deletes per keypress, as long as the latency is below of what humans can detect (say, 1/100th of a second). 
&gt; Also any library can be submitted for review by Boost, it's an open and transparent process. Being in a queue for review is not indicative of whether a library is advanced or even functional for that matter. Even when a library does get accepted it doesn't mean a whole lot. The process to get a library in doesn't exactly weed out the useless. It just takes a few people who decide it should be included--there's no real criteria. Some of the libraries in boost are actually rather poor quality with really shitty documentation. Some are abandoned pretty much the day they're accepted. A better test of a library is whether it's actually used by people. This is a test I sometimes wish was part of the boost review process. But boost is meant as a testing ground for ideas--and some of those ideas are bound to suck pretty hard. As far as that goes, I think the approach to concepts here has merit. I see some issues--like I can't find anything that lets me use these concept checkers as traits (that would be really easy to make though)--but it has a lot of potential. The application of it though in these blogs, and the things he says about other approaches, are kinda whack and are things I don't like to see in real-world C++ code. What's more bothersome is the author's responses when people show him that there are other ways that address the things he's doing, when what he's doing even has any use at all, that require much simpler constructs that are easy to teach and easy to understand. Like his claim that it's hard to introduce nice error detection and messages to tag dispatching--it's a fucking static_assert, what's so damn tough?? But he just claims it as fact that it's complicated in his blog. An advanced C++ developer IMO knows this stuff and knows when NOT to use it. They apply it where it's needed in ways that are easy to maintain; as easy as can be done anyway. Guys like Eric Neibler are advanced C++ developers. Seems to be that Paul Futz is still a bit green by comparison (so am I honestly)--but he shows a lot of promise. Maybe if he wasn't trying to recommend doing it this way I'd have no problems. I too like to do completely useless, or near useless things in C++ and blog about them (Crazy C++).
Thanks!
OK. So because Chandler and Bjarne say so.
I'm also too tired (and it's too 1 AMish) to write up a detailed analysis, but I agree with Crazy__Eddie. As a professional template metaprogrammer, I can say that tag dispatch usually lends itself to the cleanest, most straightforward solutions. It's the tool that I reach for first, reserving more powerful machinery (like struct specializations) for special occasions. There is also a shibboleth here that only experienced metaprogrammers will notice. When tag dispatching, you literally don't care about slicing, so tags are ideally passed by value. Taking const Tag&amp; is pointlessly verbose, and an indication that someone is not familiar with the technique. That's fine for a beginner, of course - but someone who is not experienced with techniques should not be explaining them to others, either as an example to follow or an example to avoid.
Definitely. I finished "A Tour of C++" a while ago and am now reading "Modern Effective C++". Allthough you already should now C++98 (as I did) or other programming languages to go this way
How about using this function `not_negative` to "prove" to your compiler that you know what is best in this situation? template &lt;typename T&gt; typename std::make_unsigned&lt;T&gt;::type not_negative(T num) { static_assert(std::is_signed&lt;T&gt;::value, "T can never be negative"); if(num &lt; 0) throw std::logic_error{"Negative number passed to not_negative"}; return static_cast&lt;typename std::make_unsigned&lt;T&gt;::type&gt;(num); } std::string s = ...; std::string::iterator it = std::find_if(s.begin(), s.end(), []{...}); std::string subs = s.substr(not_negative(std::distance(s.begin(), it))); If you don't want the run-time check then you can remove the `if(num &lt; 0)` line or change it to an assert. Signed to unsigned conversions aren't exactly the hardest thing to deal with in C++ if your compiler can warn about them.
When I can get the page to load, the code font isn't terribly readable. Grey on lighter grey.
Click on the Readability button, which will guide you to this: https://www.readability.com/articles/ghq9lnk6
Somehow their code font is dependant on Javascript.
Well they give justification for the "recommendation", and follow-up is basic reasoning. Which bit exactly do you still feel isn't being explained?
&gt; I'm also too tired (and it's too 1 AMish) to write up a detailed analysis, but I agree with Crazy__Eddie. As a professional template metaprogrammer, I can say that tag dispatch usually lends itself to the cleanest, most straightforward solutions. Have you used conditional overloading as well? I find it in my programs to be the easiest and cleanest. &gt; reserving more powerful machinery (like struct specializations) for special occasions. Well you have to use specializations of some kind when you cannot change the class definitions. &gt; When tag dispatching, you literally don't care about slicing, so tags are ideally passed by value. Taking const Tag&amp; is pointlessly verbose Thats a good point. I'll update the blog. &gt; That's fine for a beginner, of course - but someone who is not experienced with techniques should not be explaining them to others, either as an example to follow or an example to avoid. But yet no one here has shown a better and cleaner way to do it. At first they suggest using the iterator category tags which are broken, and then I could rely on boost traversal tags, but it is not a general solution as it only works with boost iterators. If there is a simpler and cleaner way to accomplish the tag dispatching, I would love to learn about it.
Somehow? Seems like an acceptable way of doing syntax highlighting.
In 1983, Bjarne Stroustrup designed the C++ language. Ever since, he has been explaining to the world why it's not C. For real though, it seems every other article I read from him, or about him, he's mentioning how people need to stop teaching that C is a prereq to C++. For the record, I'm not knocking him for it either, I can imagine it being frustrating for him, I just find it funny. On another note, I'm not really a C programmer, is there a bug in his C implementation? I feel like there is to prove a point, but I can't find it.
&gt; is there a bug in his C implementation? Potentially. If `name` or `domain` are not null-terminated, this function could end up copying random data (including sensitive information like passwords) into the result string. No idea if this is actually intentional on the author's part or a rather fitting oversight.
`malloc` will return NULL on error, which the C code doesn't check for. Apart from that I don't see any bugs, but my C experience is limited as well. 
I agree with Bjarne that you don't need to know C to learn C++, but if you want a job programming C++ you need to understand C too. I would be surprised if there is even one exception to this rule. I strongly agree about OOP and virtual functions. I imagine people in the 90s were like "oooh, I wanna write code like that cool example I saw in my Java book!" and spread way too much positive gospel about virtual functions. Meanwhile "templates are hard and advanced." We are now recovering from that mistake. I am also shocked by his inconsistent spacing after commas.
The alternative is something like pointer, length pairs; but even then there's no guarantee that the length (or the pointer) is correct. Even the C++ version, though much safer, could receive unsafe string objects through accidental undefined behavior or general mischief. In any case it's dangerous, but I'm not sure I'd call it a bug, given that it's more or less idiomatic C code and the alternative involves disavowing the standard string library and switching to something not *that* much safer. 
There's a bug in his Myth #2 code: the lambda expression won't capture `int r`.
Very true, good call. On the same line, the C++ version has the possibility of throwing a bad_alloc exception, that's a bit better than the segfault of the C version, but not much.
It is much better since it is defined behavior and can be handled, if you really want to. The NULL-version is a waiting time-bomb.
Is there any chance to deprecate those implicit conversions? Removal will of course be out of question for ages, but since they really only cause problems…
I don't see this; where?
Regarding having to know C for a C++ position: I suppose I was fortunate to learn C before C++ because evey C++ codebase that I've worked on that was already partially or fully built by other people before me contained significant amounts of C code mixed in with the C++ code -- everything from C-based binary file I/O to low-level C-string manipulation.
Ah. I thought auto-capture extended to this. Guess he missed an `&amp;` or `=`. I'd really have hoped Bjarne would compile his examples. I was looking to see if this changes in C++14/17 but it doesn't seem like it (nor should it change thinking about it).
&gt; You mean, constraining with mutually exclusive enable_if's? That's like killing a fly with a thermonuclear weapon. I am referring to the overloading that I do at the end of the post. And I don't see how it is overdone. First, you, as a library writer, should always check type requirements for templates(especially at the interface level). With overloaded functions there could be overlapping type requirements, Conditional overloading provides a mechanism to order the preference for the functions to avoid ambiguities. There is no extra infrastructure that is needed, whereas tag-dispatchig there is. If any case, it seems like tag-dispatching is more like the thermonuclear weapon. &gt; SFINAE is powerful because it can add or remove functions to the overload set based on arbitrary criteria, but when it goes wrong, it goes really wrong (stuff vanishes, and the compiler diagnostics get confusing) You get nice clean messages from `enable_if`. Perhaps, some compilers could improve their diagnostics. &gt; Tag dispatch also encodes preferences Yes it does, but so does conditional overloading. They are just at different times. Tag dispatching encodes the preference during definition of the tags, which is useful for relationships that are used over and over again(like iterators). Conditional overloading encodes the preference at definition of the functions, so the relationships can vary by function. This is useful for traits that are unrelated but overlap. &gt; The STL's iterator categories are perhaps confusing and suboptimal, but they work, and have worked for 20 years. It may have been that way for 20 years. Iostreams has been used for 20 years as well. It doesn't mean we should shouldn't strive for something that is not "confusing and suboptimal".
It'd be acceptable if the default color was readable. It's so close to only using JS for presentation, but they missed the simplest part...
If you want to be good at c++, you will also have to learn c. Simple as that.
&gt; but I don't think that's considered an exploit because the data sanitation should be occurring at some place before this function is called I prefer to do data sanitation at every single point I touch a string. I assume all my C strings are improperly terminated and that my personal SSN# lays 1 byte in memory after any buffer I have been handed. Because, well, paranoia now saves on 2am bug hunting later. :)
yes, that is what I meant. remember that recent article about all the raw `realloc()`s in Firefox's code base? I'm guessing it's the same in any big C++ project.
If I ever do a C project that manipulates strings, I'll define struct NullTermStr { char *s; }; to at least make it explicit when code expects an already-sanitized string. of course nothing is ever really safe. you can always cast a `std::string` to bytes and mess around with the length field.
This hides the bug elsewhere and throws it down field, and again, it's not so much that there is a bug, it's that the string you are being passed is already "JohnSmith821-78-1205\n"
I feel like an idiot for using C++ for years (including writing my share of iterator types) without ever realizing that you could implement operator++ as a non-member override.
Doesn't C++17 relax constexpr expressions in templates? So you could now have: template &lt;int from, int to&gt; constexpr slice_bounds make_slice_bounds() { static_assert(from &gt; 0 &amp;&amp; to &gt; 0); /* implement logic */ } constexpr decltype(auto) operator[](std::array&lt;int, 2&gt; bounds) const { return slice(make_slice_bounds&lt;bounds[0], bounds[1]&gt;()); } decltype(auto) operator[](std::array&lt;size_t, 2&gt; bounds) { return slice(...); } NOTE: I have no clue if the above would compile.
IMO, your team made the correct call. While Bjarne &amp; Chandler's talks are very much correct with respect to STL design if it was happening now, the problem is the ship has sailed. If you don't use unsigned types &amp; you use the STL (which you should), then you have casts all over the place wherever you interact with the STL (you have -Wall -Werror enabled on your project, right?).
I actually have to disagree with that. Sure, localization sucks, but there *is* an elegant I/O library hidden somewhere in there, and the way that buffering logic is handled has some major advantages compared to most libraries. I have yet to see an actually *good* I/O library, but iostreams aren't the worst.
&gt; Learn Modern C++ in 10'000'000 minutes! Fixed that for you (that is, if you have access to a C++14 compiler.)
That sounds like something you should ask the people who write memory allocators, not the people who write libraries that use memory allocators. It is certainly true, however, that most memory allocators can be asked how big the allocation is. But it is *not* always as simple as looking at a hidden word before the allocation - `free_with_size(ptr, n)` is cheaper than `free(ptr)` even though the information is available anyway.
There are several, but that was the point of his example. C is easy to get wrong.
No, the arguments to a function are never constexpr.
Thinking about it some more, I think a less evil alternative is to use UDLs plus the comma operator: decltype(auto) operator""_x(unsigned long long x) { .... } std::cout &lt;&lt; ints[2_x,5_x] &lt;&lt; std::endl; std::cout &lt;&lt; ints[2_x,_] &lt;&lt; std::endl; std::cout &lt;&lt; ints[_,5_x] &lt;&lt; std::endl; This also lets you safely negate indexes and safely control what that means, i.e., the logic of `-2_x,_` can be decided with `operator-`. Of course, the comma operator can get confusing, since it looks like accessing individual elements in a 2-dimensional array. However, we can use another combo, like `---` or `--&gt;`: struct range { size_t a; size_t b; }; struct literal { size_t x; constexpr literal operator--(int) const { return *this; } constexpr range operator-(const literal &amp;b) const { return range{x, b.x}; } constexpr range operator&gt;(const literal &amp;b) const { return *this - b; } }; constexpr decltype(auto) operator""_x(unsigned long long x) { return literal{x}; } auto r1 = 2_x --- 5_x; auto r2 = 2_x --&gt; 5_x; Yes yes, I know, take me out back and shoot me :)
I feel like there may have been some truth to Myth #1 before C++03, but then again I only really started plumbing the depths of C++ circa 2005. Certainly it's no longer true with C++11 and C++14 out, and C++17 on the way. That said, I think there is value in knowing the memory allocation scheme (of any language you use, not just C++), and learning C happens to be one way to do that. So it's a lazy/easy way to say that. Also, _especially_ now with C++XX, the language is just getting really complex.
I'll be interested to read #3. For the most part I agree with it, but I also know there are some lock-free data structures that are much complicated by lack of GC.
There's no way to solve that issue though. To test if it's null terminated you have to look for the null terminator. Even if you require a length be passed in, that only helps if the length is less than or equal to the index of the null terminator. C strings suck.
Not quite. -Wconversion is not enabled as part of -Wall or -Wextra. That's the crux of the problem- interfaces that use unsigned types are too easy to misuse and the compiler can't detect the errors. At least with a signed input you can assert on the value being positive.
 &gt;I strongly agree about OOP and virtual functions. Really? Am I the only one that disagrees here? You have OOP available, but it's not enforced like Java. C++ was considered OOP before java was a thing if I remember correctly. I don't see why we should stop considering it OOP just because you don't have to use it and there are more strongly enforced OOP languages. It's still a wonderful feature and it says a lot to people who want to learn it.
How do you read an entire article and manage to miss the point? 
You might find my CppCon 2014 presentation, [STL Features And Implementation Techniques](https://www.youtube.com/watch?v=dTeKf5Oek2c) to be an approachable introduction to template metaprogramming in the real world (production code, not toy examples). Like runtime programming, template metaprogramming can get very complicated (I mentioned tuple_cat() in the talk). But unlike runtime programming, most template metaprogramming is hilariously simple once you learn to see through the strange syntax. The example demonstrated in the talk is the compile-time equivalent of: if (IsRandom(Iter1) &amp;&amp; IsRandom(Iter2)) { DoCoolFastThing(); } else { DoSlowFallbackThing(); }
Responding to #2. The C++ version, in theory, involves at least 4 memory allocations, where the C version only has one. He notes that the small string optimization means there won't be any heap allocations, however that only applies to small strings (and there is also overhead in deciding whether to use the SSO!). For a long name and address there is a lot of extra overhead. The C++ standard does allow the C++ code to be optimized to a single allocation but no compilers actually do that. [This allocation overhead is a real problem](http://www.reddit.com/r/programming/comments/2ocmvb/stdstring_is_responsible_for_almost_half_of_all/). Fortunately `std::string_view` is on the way to help. 
You're right. -Wconversion isn't enabled by default but I have it on in my project (which is why I thought it was covered by -Wall). On clang, you can use -Weverything. In any case, enable -Wall -Wconversion -Werror.
Sorry. Maybe something more like: template &lt;std::array&lt;int, 2&gt; bounds&gt; constexpr decltype(auto) operator[]() const { return slice(make_slice_bounds&lt;bounds[0], bounds[1]&gt;()); } I know that C++17 relaxes the constexpr-in-template usage, but I'm not familiar enough yet with the syntax. Is it possible at all? It would look something like: f.slice&lt;{0, 4}&gt;(); Not quite sure how to get constants in the template to be deduced from arguments (I guess you can't).
Quite good! It fixes the complaints I had about its UI support on Android. Where desktop widgets were being shown. After writing a few JNI wrappers on my own after my initial disappointment with the 5.3 version, I rather use Qt and share the effort with the community, while being able to target all mobile platforms. 
I write C++ for living. If you dont know C idioms and style, you will not do well with the code from others (when it comes from C people).
There is a Windows 64-bit VS 2013 OpenGL though.
Yeah!
`boost::ptr_vector&lt;T&gt;` is completely obsolete if you are using C++11 - you should use `std::vector&lt;std::unique_ptr&lt;T&gt;&gt;`. The article correctly points out that the copyability is an issue and results in the slicing problem. Since `std::unique_ptr&lt;T&gt;` is movable but not copyable, it does what you want without having to change the base class (which you might not be able to modify). There's also the very strong advantage that all C++ programmers know `std::vector` well and it has very specific performance guarantees and has benefited from decades of examination and optimization. Overall, you should never make base classes that you inherit from copyable, precisely because of the slicing problem. Making the class pure virtual (as in the article) kinda works but: 1. You might actually need to instantiate the base class. 2. It's an indirect solution to the problem. Instead, you should just directly make it uncopyable! In C++11, you do it just by deleting the copy constructor and the copy operator: class Base { public: Base(Base const&amp;) = delete; Base&amp; operator=(Base const&amp;) = delete; }; (In C++98, you can still do it by declaring those methods private, and then never actually implementing them.) 
With Qt 5.4 there is now a dynamic switch that chooses between the two at run time. In general, ANGLE is more likely to work. The reason is that graphics drivers provided by Microsoft (think vanilla Windows installation or Windows update) will often only include the Direct3D portion of the driver and not supply OpenGL acceleration. For the OpenGL bits you often need to get the proper vendor driver.
;( WebEngine Doesn't even seem to have the ability to render the page to an arbitrary surface
How about auto complete for unique_ptr? Still not working?
&gt; I think the slogan “Resource Acquisition is Initialization” is a misnomer in certain ways. I agree. RAII is an essential tool in C++, but "Resource Acquisition is Initialization" is such a severe misnomer that it interfered with my ability to learn the concept.
A popular slogan is "The Big Six", meaning that if you write a class, you make a *careful* decision about each of these functions: type () type (type const &amp;) type (type &amp;&amp;) type &amp; operator= (type const &amp;) type &amp; operator= (type &amp;&amp;) ~type () When in doubt, I use = delete I do this religiously, and RAII pretty well takes care of itself.
I've actually never heard of that term before. Usually it's called the rule of 3, or since C++11 the rule of 5 or better actually rule of 0.
As somebody wanting to get started with Qt coming from Visual Studio 2013 what the hell do I download? I can see MinGW, etc. for 32-bit but what about 64-bit? I am a little confused :/
It's the rule-of 3 pre-C++11 and rule-of-5. The default constructor is not involved in RAII in any way. The implicitly default functions are ( as you have them): copy constructor move constructor copy assignment move assignment destructor Also, you're advice isn't the best. Better advice is the rule-of-0. Either = default all of those functions or omit them altogether. If you define any of them, you're violating the rule-of-0 because your class actually deals with a resource of some kind. Then you define all of them (either provide an implementation or = delete). You cannot use =default on any of them. The reason is that this lets you compose objects from RAII classes &amp; not worry about those operators. The compiler will default them to the lowest common denominator. In other words, if your type has a non-movable member &amp; a different non-copyable member, your composed type is non-movable &amp; non-copyable. I have not seen a case where conceptually the compiler was wrong.
My head just exploded. 
I didn't realize that kind of performance... I'll look more into it 
I think the distinction is between "X language supports OOP" and "X is an OOP language." The latter implies that OOP is the language's primary mechanism for building abstractions. It's the same reason people don't call Python a "functional language" even though it supports first class functions, lambdas, and closures.
Hopefully when the new qtcreator reaches Debian Jessie 64, it doesn't lockup and crash on start.
This is my favourite post.
You want to use remove_if, example can be found here: http://en.wikipedia.org/wiki/Erase-remove_idiom // removes all odd numbers v.erase( std::remove_if(std::begin(v), std::end(v), is_odd), std::end(v) );
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Erase-remove idiom**](https://en.wikipedia.org/wiki/Erase-remove%20idiom): [](#sfw) --- &gt; &gt;The __erase-remove idiom__ is a common [C++](https://en.wikipedia.org/wiki/C%2B%2B) technique to eliminate elements that fulfill a certain criterion from a [C++ Standard Library](https://en.wikipedia.org/wiki/C%2B%2B_Standard_Library) container. &gt; --- ^Interesting: [^Sequence ^container ^\(C++)](https://en.wikipedia.org/wiki/Sequence_container_\(C%2B%2B\)) ^| [^List ^comprehension](https://en.wikipedia.org/wiki/List_comprehension) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cmr93i9) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cmr93i9)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
A co z zerem? Normalnie zero nie jest ani parzyste ani nieparzyste.
You can mutate the container *only* if that won't invalidate the iterator you're currently using, or if you immediately `break` from the loop (so you won't use the just-invalidated iterator). Note in particular that you can *never* erase the element you're currently pointing to (unless you `break`). Only a few containers offer `erase` that does not invalidate: list, set, map, multiset, multimap (any element but the current); deque (only first/last, but never the current).
SBRM
If you expect that the condition will be true most of the time (i.e. you're going to be removing most of the elements) and you're using `std::vector` or something with similar characteristics, then consider copying the desired elements to a new container. std::vector&lt;T&gt; new; for(const auto &amp;item : items) { if(wanted) { new.push_back(item); } } items = new; or std::vector&lt;T&gt; new; std::remove_copy_if(begin(items), end(items), back_inserter(new), [](const auto &amp;item) { return /* not-wanted condition */; }); items = new; Edit: upon further reflection, just use the erase/remove idiom. This won't really save anything. 
Remember that erase-remove works in-place for a vector, allocating zero memory. What you suggested was not only copying to a second vector (with geometric reallocation), but *copy-assigning* back! In C++, it's a mistake to furiously micro-optimize everything, but you should be aware of the high-level operations that your code is requesting, and seek to minimize them, at the same time as trying to write elegant code. (Oh, and `new` is a keyword, heh.)
Yep. Also, my [Uniform Container Erasure](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4273.htm) proposal was accepted into the Library Fundamentals v2 Technical Specification, and is a likely candidate for C++17. This allows you to write `erase_if(v, is_odd)`. If you want to manipulate a container in some other way than erasing the elements you don't like, you should *absolutely avoid* modifying the container while traversing it. That's exceedingly dangerous, likely to result in incorrect code or skipped elements. For complicated transformations, it is better to build a second data structure, then move or swap the result into place.
It's 3 &amp; 5. The default constructor has nothing really to do with RAII.
Clarification: So I just meant that back in the day I used to be told to always have 4 things in a class. I wasn't speaking from an RAII perspective. Sorry for the confusion. Indeed, the default ctor is barely related with RAII.
Ah. Yeah. That's bad/outdated advice. The better advice is you define 0 of the default functions in a class. If there's any exception to that, your class is managing exactly 1 resource &amp; defining all 5. The default constructor only needs to be defined if you have any custom constructors (which presumably you would to acquire the resource in the first place) &amp; you need special initialization: if you basically are just allocating memory &amp; just have 1 member variable like ptr = nullptr; declared, then you can just = default your 0-arg constructor).
Hello Stephan, now that you say about uniform container erasure. Does this go into algo header? I always had a concern: this is the only algo that manages memory. I follow with interest Eric Niebler's blog and I saw in one of its posts he makes a customization point for erasing that can be used inside algorithms. Don't you think that would be a better solution to the problem? For example you could unique or remove_if and it would also deal with the real removal making use of the customization point. Seems more general than an algorithm only for that. Was just a quick thought. 
Each overload goes into the corresponding container's header. They are container-based algorithms, not range-based algorithms. I intentionally designed this feature for maximum simplicity. The need to uniqueify a container is much less common.
&gt; Better advice is the rule-of-0. Either = default all of those functions or omit them altogether. If you define any of them, you're violating the rule-of-0 because your class actually deals Whilst zero sounds like a good options as and when it's possible, it's not always possible. Consider any class with a `unique_ptr`. For some reason it has to be a UP and not placed on the stack, maybe it's expensive to construct, or is allocated from a library. Now I need my copy ctor to alloc a new resource and copy the value of target of the original UP. I would say making a wrapper class simply to handle that use case over kill. 0 is an ideal, not a reality in many cases.
At the time of C++17, I wonder if it would be better to standardize something like Niebler's style (I am not sure at all of this). It works as a customization point and later you don't need to do anymore anything. This would go into the range algorithms, I guess, and not the iterator-based, for backwards compat. But it seems to me that a customization point is more general than a specific container algorithm, but they still achieve the same thing. What do you think?
&gt; I would say making a wrapper class simply to handle that use case over kill. That's a clear sign that you actually missed the whole point of the rule of zero. First off, such a wrapper class can handle *all similar use cases*, not just this one. Then, either your class is meant to *be* the resource, or to use it. If the former, well, this *is* the wrapper class you're actually writing. If the latter, you are violating the SRP just because you have some class quota or something. If putting a little bit of behaviour in its own class is overkill to get proper resource handling, I'd dare say your definition of "overkill" is wrong.
Range algorithms are completely different and unrelated. Erasure is special because it is a service provided by containers, modifying their sizes.
Well, then I would say that unique_ptr is the wrong class for you to use. The STL-provided pointers are not the end-all-be-all of smart pointers. Here are 3 alternatives: 1: Your member variable can be stored in boost::optional/std::optional/boost::any instead. 2: shared_ptr - are you sure that it actually makes sense to copy it? maybe reference counting is better? 3: hand-roll your own copying_ptr that on copy duplicates whatever it is holding. I would say though that I have never encountered a need for a copying_ptr (except maybe if you don't have access to optional). 
Maybe RRID? Resource Release In Destructor? :D
Now it's rule of zero. If you class isn't managing resource, then you should not define these methods. And in most cases it isn't.
He included default constructor to this set, that's why 6.
Hm, default constructor is also implictly generated if you haven't any. But right, it isn't tangled with RAII in any way. About rule of zero, I'm not sure if destructor always means dealing with resource. What if I want to call some function on destruction, for example that writes something to log file? btw. I'm not sure - defining destructor will block move constructor &amp; assignment generation? Or defining copy constructor/asisgnement will block it?
If someone wants to write one up... implicit return in main modern for loop lambdas enum class prefer auto smart pointers =delete //maybe too new namespace a::b::c {} prefer {} initialization a lot of stuff is too advanced to fit the format but this stuff is pretty quickly demonstratible. the point of the site is sometimes you get thrown in the deep end with some code and need to get the gist of what a language does without formally learning it. it's a reality thing. a book isn't a suitable alternative
Defining any of one of the 5 causes the compiler to omit the rest of them (hence why they're intertwined whereas the default constructor is not). In the case of your log case you have two choices: 1. Define your destructor &amp; then explicitly = default all the default 5. Put lots of comments on why you have an explicit destructor but = default the rest. 2. Create a RAII wrapper for your log message &amp; just add it as a member. I like option #2 the best if it's a tracing-like thing since you don't have to modify a lot of code (i.e. add 1 member function).
Hm, creating wrapper that calls desired function, passed by parameter, on destruction would probably be best solution. #1 is too much work :D
Interesting topic, but the language seems heavy-handed and the descriptions a bit rushed.
3,5,6,0 ? Why don't they just say Rule of rand(0,9)?
&gt; boost::optional/std::optional/boost::any My use case wasn't that a resource may-or-may-not be present, but that I've been handed the life time in the form of a pointer, no doubt with it's own free or close function. &gt; hand-roll your own copying_ptr Possibly, but as I said that would probably be overkill to make a class when it'd be a couple of lines in the copy ctor/assignment op. 
&gt; Maybe I should add your quote to my article, if you don't mind Possibly, but feel free to remove the spelling and grammatical errors I've no doubt left in there to test the readers patience.
No I fucking get the rule of zero. It's really not that complex. But like all things in many cases being overly pedantic to meet an imaginary rule, even if it's best practice, is just over kill. Like over normalisation in databases. I get it, maybe I might want to use this `copy_target_ptr`. But lets say it's a network handle or something like that. Then I'd have to provide to the copy_target_ptr not only the code required to clean up the resource but now also callable to copy it. So now imagine your a new dev at my place of work, instead of just looking at the copy ctor and going, oh copy the target of that ptr, you now have to go and figure out what that wrapper type is and why that was down rather than putting the code in the otherwise empty copy ctor and assignment op. 
It's not overkill. If you don't do it this way, your code isn't exception-safe. Also, what happens when you have a second such resource in a different class? Or, even worse, in the same class? The point is that the compiler can generate all the code for you correctly, so let it. Also, if you have a resource in the form of a pointer with it's own free/close function, how are you going to copy it? Does it really make sense to copy? The point is that the rule-of-0 is so important is as follows: 1. 99% of the time, you never think about resource allocation. It gets inherited from the properties of your member variables. 2. If you do think about resource allocation, you have to think very careful about the exact rules for the resource. Once you've defined them, this type is then re-usable in any context without needing to worry about the rules. The point is that the extra 2 minutes of typing to write your wrapper class is worth the hours in debugging &amp; peace of mind it saves you.
What? Of course it's exception safe. The following is does not abide the rule of zero but is exception safe and is exactly what I am suggesting. class t { std::unqiue_ptr&lt;MyT&gt; mt; //probably would have it's own deletor too in the real world. //other stuff... op=(const t&amp; lhs) { mt=std::unique_ptr&lt;MyT&gt; { alloc_MyT() }; setup_mt_from(mt, lh.mt.get()) } }; Pseudo code obviously. But you want to add a class to do those four lines in op=? &gt; Also, if you have a resource in the form of a pointer with it's own free/close function, how are you going to copy it? Does it really make sense to copy? You don't have to interop with system and C libs often, do you? &gt; The point is that the extra 2 minutes of typing to write your wrapper class is worth the hours in debugging &amp; peace of mind it saves you. 2 extra mins? Get real, a new class, with a new file, dealing with the shitty build system that absolutely every company seems to have. Also that shit needs peer reviewing before it can be checked in to any decent commercial code base. I am all for the 'rule of zero' but it's just not always practical.
&gt; You don't have to interop with system and C libs often, do you? Yes actually I do. For example, file-descriptors make more sense as a move-only type even though you can fdup. I don't think it's safe to jump to assumptions &amp; I don't understand the hostility I work a lot with CoreFoundation on OSX too, so I wrote a generic deleter for use with CFTypes (I only ever use them with unique_ptr even though the underlying type is reference-counted). If I wanted semantics consistent with CoreFoundation, I would write my own wrapper class for them. The custom deleter was really easy &amp; works quite well. The custom file-handle wrapper was slightly more complex, but that's because I wanted very specific API semantics that are hard to misuse accidentally (i.e. distinguish open writeable from open or create from open read-only): in other words C++11 enums instead of int flags. I also wrote RAII wrappers &amp; abstraction for sqlite. &gt; 2 extra mins? Get real, a new class, with a new file, dealing with the shitty build system that absolutely every company seems to have. Also that shit needs peer reviewing before it can be checked in to any decent commercial code base. It takes me 5 seconds to add a file to my build system. CMake, Xcode, Visual Studio, etc all make it very easy to add a file to a project. I'm shipping to hundreds of millions of customers, so I think I'm working in a decent commercial codebase. A new file in a code review adds no trouble: we have automation so I just push my branch &amp; a review automatically gets opened with the diff in ReviewBoard &amp; automatically tested.
Good read, both articles, but I have to complaints: * This guy clearly knows what he's talking about; he can't call himself a beginner, * I had to turn on javascript to display code boxes. Even using it to prettyify it is silly (because how on Earth is doing it for every user every time they reload the page better than doing it once), but this is just... beyond. Next step would be hosting it on blogspot and disabling it for non-js users entirely :/
You failed to address the code snippet I provided. Rule of zero really wouldn't have improved much there. &gt;For example, file-descriptors make more sense as a move-only type even though you can fdup. Yes I agree file descriptors should be move only. But that doesn't mean that every class WITH a file handle of some kind should be move only. Consider a primitive class that logs to a temporary file with a unique name. I might want to make that class copyable. but I would want a new handle opened on a new temp file. That logic fine for op= or a copy ctor.
&gt; But that doesn't mean that every class WITH a file handle of some kind should be move only. Yes, it does if you're representing that type with a move-only class. In the case you're describing, you would have a IndependentTemporaryFile or something like that with the semantics you described. Then you have a member variable IndependentTemporaryFile. Presto: no need for writing your own copy constructor. No chance for anything to go wrong.
But of course still no full C++11 support. What utter bullshit, do the MSVC team have any idea what the word "priority" means? They are single-handedly holding back everyone from being able to write modern cross-platform software.
Splitting definitions and declarations is not as bad as you might think. It lets you hide implementation details.
Yes, you are getting close, but...you're so far behind gcc and clang that writing modern cross-compiler software is frustrating at best. Standards exist for a reason and if MSVC can't FULLY implement a standard after 4 years and 4 releases (msvc 2012, 2013, 2014, 2015) then what more can I say? This also begs the question of why are C++1z features are being implemented. It seems like the MSVC team suffer greatly from [appeal to novelty](https://en.wikipedia.org/wiki/Appeal_to_novelty) and favour cheap, easy PR wins rather than sitting down and conforming to the standards like everyone else.
There was no VS 2014 RTM release.
There was no chance of anything going wrong in the first, it'd have simply been as case of: class t_with_logger { std::ofstream out; //the other stuff... t_with_logger(const t_with_logger&amp;) : out { get_temp_file_path() } { } }; That's it. For the one line, for a component that I am probably not going to use else where (otherwise it might make some sense). It's less code, it's exception safe, it's obvious what it does. And I would have to access the file via a wrapper every time I want to use it. Anyway, I am done arguing about this.
I don't mean the private thing, which is right, it exposes things even if private and this adds a dependency. For hiding that you need pimpl, which is annoying. Yes, you have to go to two places, one for the definition. This keeps your code hidden in a library. Keeping the interface and the implementation separate is not stupid. For example, you can switch with a compile-time flag complete implementations. Without separation, you cannot do that, or you would do it cluttering your files with #ifdefs or similar. That is a use case. I am not defending headers, of course you can do that in modules also with alternative techniques, but, essentially, you will end up having code split in several places to hide things. Modules are really better for compilation times and symbolic export, though. But what you meantion I don't think it is the main purpose of modules, since many times you will still have to split in some way implementation for interface. I voted you down because you defend your position in a very negative view, almost insulting others.
BTW, did you ever consider inlining, headers, linkers, macros, backwards compatibility, etc and their interactions? Maybe it is not as simple to solve this problem as you might thing. There was a proposal in C++11 for modules and it wasn't even accepted. Maybe if we have expert people like you, we can get part of your spare time and you can illuminate us on how to solve this problem. FWIW, Gabriel Dos Reis and Doug Gregor have been working on modules currently and before. I wouldn't say they are rookies...
&gt; C++09 09? Huh? You mean 98, right? 
Ok, I am now imagining I am a new dev at your place of work, and now I'm looking at the copy ctor and going "wait, why is this class that does whatever else the one that knows how to copy network handles?", and now I have to go and figure out if there's another special way to copy network handles that other classes that need it use and if I write a new class with network handles do I need to do the copy in another special way, or if they all use the same and if they do all use the same then I'll wonder why someone didn't just make one single class that knows how to copy network handles instead of requiring every class that will ever need to copy network handles to know how to copy network handles.
&gt; 2 extra mins? Get real, a new class, with a new file, dealing with the shitty build system that absolutely every company seems to have. Which build systems make it such a nightmare to add one damn file? &gt; Also that shit needs peer reviewing before it can be checked in to any decent commercial code base. I hope there isn't a hidden implication here that if you don't add a class the code doesn't need peer reviewing.
Most C++1z features which are implemented in VS are because the proposal author is a Microsoft employee (H.Sutter, STL..etc..): they think this is a very important feature to have for programmers (more than some C++11 features), and it also shows feasability/usefulness of the proposal. 
No, chances are there is a function or the like which 'knows how to copy' handles. That function is simply used from within the copy ctor. It's not as though some complex bitbashing logic is going to be implemented there. It really is a case of how far do you go when 'normalizing' code. Between being idiomatic and reusable and amount of code (in lines if you like). The rule of zero is great ideal, but I am not going to loose sleep if I don't make that ideal.
&gt; You've never worked somewhere where someone's had the bright idea of writing their own build system? Or had a horrible oversized make based system. No, I haven't. It's not every company, and it's not even every in-house build system. Anyway, it seems to me you are arguing that the rule of zero is not practical when you have an unreasonable environment&amp;dagger;, which I don't argue against, as I find it a moot point. &gt; No, but it's a lot easier to peer review 1 line of close (which as I show elsewhere is really all it is) than a whole new class. No, you don't review one line of code in isolation. You have to review that one line of code as part of all the other unrelated code it is bundled with. Making it a new class separates it at the cost of some 3-6 lines depending on how generous you are with whitespace. If those 3-6 lines are the overkill you were going on about at the start, yes, your definition of "overkill" is still wrong. --- &amp;dagger; I hope you won't try to convince me that a build system where adding a file to the build is such a nightmare is actually reasonable.
&gt; consider inlining can be done using IR &gt; macros, if you use macros thats fair enough but what if you don't. &gt; backwards compatibility, &gt;almost insulting others. yes. we have this stupid problem because people resist fixes on principle, *conceptually*. They come up with all sorts of justifications why its better to have them, then they insult you if you *dont* like them as if its a problem with *you*. UFCS would ease the pain a little - because you could declare adhoc free functions outside the class but still have user code 'in the right format' if you do need vtables or private access or whatever. And people our there *resist* UFCS. or 'extention methods' if you could extend the non-vtable methods 'outside the class' directly (invent some syntax .. class Foo+={...} .. or class Foo extend {..} whatever ). Or you could have the format of declaration &amp; definition identical so you can at least make a header generator. Its this stupid asymmetry that shouldn't exist, and the syntax makes fixing it more awkward than it should be. a.foo(b) foo(a,b) and bouncing between them, and stupid people claim its got some magical properties and thats how the world should be and you have to update headers forever
It definitely works in VS2013: http://pastebin.com/piUJNF8h
Only assuming they are contiguous in memory, which in case of a std::vector is a valid assumption, but if it's a linked list, it is not. Additionally, you would have no way of identifying the last item. On the last item, you would point to invalid memory. Edit: care to explain the downvotes?
Yeah, that's why I was talking about an array (which is guaranteed to be contiguous, just like `std::vector`), and not about collections in general. And I certainly wasn't proposing this to be used in real code. But if you did, yes, you would need to worry about that last item.
It's all kinds of messed up. I can't think of a reason why it's allowed, but it certainly compiles. ~~Obviously, this isn't something that anyone should use. It'll "do the right thing" by treating `this` like a `void*` and perform the appropriate pointer math to get you an address. The problem is: most of the time, `this[0]` points to a v-table. Who knows if there's padding or anything else in there before your first field. No fields in your class? Well, I hope something's next to you in the heap because that could be a segfault.~~ Edit: obviously got this wrong. I stand here, miraculously, at 1 vote. So thanks for adding to the conversation instead of turning my erroneous comment into a crater on this page.
I think it's definitely rabid code for production, but it's a nice piece of trivia. Nice find! 
&gt; If this refers to an element of an array, it will return a pointer to the following element in the array Not necessary. Consider an array of `Derived` and the `this` pointer in the `Base`...
&gt; Who knows if there's padding or anything else in there before your first field. Why would that matter? If you're in `class C`, then `this` will be just `C*` (or rather `C* const`, but that doesn't matter here) and will behave like any other `C*`. So, `this[1]` should point to the following `C` in the array and accessing its members should work fine.
&gt; It'll "do the right thing" by treating this like a void* and perform the appropriate pointer math to get you an address. `this` won't be treated as a `void*`, it will be a pointer the to type of the object who's method you are in. As far as I know, `void*` is the only type of pointer in which you *can't* do pointer arithmetic. &gt; The problem is: most of the time, this[0] points to a v-table. It doesn't matter if the v-table is put at the beginning of an object in memory. When you call `this[1].member` the compiler will apply the same offset to that member as it does when you call `this-&gt;member`. &gt; Who knows if there's padding or anything else in there before your first field. No fields in your class? Well, I hope something's next to you in the heap because that could be a segfault. All classes have a non-zero size in C++. Even if they have no fields. The actual issues here are that you have to guarantee that your object is contiguous in memory and has at least one object after it. ~~You will also have issues if you have `std::vector&lt;Base&gt;` and you use `this[1]` in a virtual method in a derived class. The `sizeof` these classes could be different and you would end up with `this[1] == (*char)this + sizeof(Derived)` when you need `this[1] == (*char)this + sizeof(Base)`.~~ (see /u/Raphael_Miedl 's response to why this won't happen) EDIT: Made fixes suggested by /u/scatters, /u/Raphael_Miedl, and /u/OldWolf2.
What? This is completely incorrect... "this" is of type `T*` or `const T*`, not `void*`, and the expression this[0] would yield a reference to your object not "point to a vtable". Try it out. `struct A { void UseThis() { this[0].PrintStuff(); } void PrintStuff() { printf("Stuff..."); } };` 
I've seen this[1] used to refer to data that is packed after a header, but this + 1 makes more sense IMO. For fun you could write that as 1[this] too!
Wouldn't this issue be solved if `this` was a reference, instead of a pointer? Or is there some situation where `this` being a pointer is useful? I can't think of any at the moment.
This shouldn't be too surprising. It's just simple pointer arithmetic. This would work in ANY sane compiler on any system. "this" is just an implicit first parameter to every member function of a class. It simply represents some arbitrary address in memory where the member object lives. Ergo, yes, if "*this" is some element inside an array, then doing this[1] will ALWAYS get the next object in the array. It has nothing to do with what the spec says about the behavior of this' interaction with indexing, and everything to do with the fact that "this" is just a pointer like every other pointer (albeit a compiler-introduced prvalue pointer). If "*this" is not some element in an array, then using this[1] will treat whatever memory is resident at the address (this + 1) (or alternatively) reinterpret_cast&lt;off_t&gt;(this) + sizeof(*this) as an object of the same type as "*this". Obviously, 99% of the time doing so will indeed result in undefined behaviour. In summary, like any other pointer in the world, you can index against this: (this[1]) perform explicit pointer arithmetic on this: (*(this + 1)) etc. Edit: Formatting.
Did you Google for why "this" is not a reference? Stroustrup addresses this in his FAQ. http://www.stroustrup.com/bs_faq2.html#this
screw that. do THIS instead: 1[this]
There's so many things you can do to hurt your code. Do you feel compelled to do them, or...? 😉
Except that you'd get slicing instead of polymorphic behaviour with a `vector&lt;base&gt;`. Meaning all objects are of type base, the same size and everything still working fine. If you got `vector&lt;base *&gt; pv;` instead you're only guaranteed that the `base*` are contiguous not the objects being pointed to anyways. So nothing special here either. In this case `pv[0]` might point to a contiguous block of derived objects and `pv[1]` might point to a contiguous block of base objects. Every contiguous block is guaranteed to be of objects of the same type. There are ways to abuse it but they aren't as trivial as a vector of base objects. If you want to abuse it chances are you're already playing with fire on purpose in some way.
If you got a derived class that could through a base class function access `this[1]` (this being `base*`) then the whole thing is broken and can't safely be used in polymorphic context. I'd say that accessing `this[1]` behaves exactly like any other pointer indexing with the one exception that you should mark classes using such things as `final`. Or document it with a big warning that derived classes mustn't access those functions and use their own ones. But probably always `final`.
it's evil and wrong. but it's real!
Neat. Would be cool if it got integrated with clang-format.
Found this out the hard way-- Once, I didn't create a memory pool for classes with no member variables and ended up fragmenting my heap in an hour under heavy load and the kernel couldn't find any more memory for me...
No, but I like to know the boundaries of the language I'm using. It's useful on the off-chance I would need it (very unlikely in this case) or when debugging (e.g. if you have a collection that overloads `operator []` and you write `this[x]` instead of `(*this)[x]`). Also, I prefer to use languages that behave the way I expect. I did not expect to be able to index `this`.
&gt; There are too many stupid things that no one will ever do intentionally... Actually there really isn't any at all.
&gt; aren't as trivial as a vector of base objects It's as trivial as a vector of derived objects where the "this[1]" statement is used in a base class function (virtual or not).
What does it all mean?? (is that for people without [] keys?)
Update your expectations. `this` is a pointer, and pointers can be indexed. 
`this[1]-&gt;member` would be an error. You meant `this[1].member` which is fine iff `this[0]` (aka. `*this`) is a member of an array.
Yes
Yes. There are a number of trigraphs (which are all `??` followed by a third character) that are recognized by the preprocessor (not the compiler!), and all of them are characters that do not appear on some early keyboards. Those kinds of keyboards are long obsolete, and the trigraphs are so unknown that there's no reason to keep them in the preprocessor.
I guessed it, I was trying to be humorously rhetorical. Thanks for the explanation though, someone appreciates it :)
My favorite WTF is the "Rocket down to" operator. int i=10; while(0 &lt;=~~-- i) { printf("%d\n", i); } 9 ... 0
Out of curiosity, do you know how this compares to the recent LLVM work in this space (http://www.cs.berkeley.edu/~dawnsong/papers/osdi14-paper-kuznetsov.pdf)?
That isn't really a "WTF is going on" as much as it is a "why the fuck would you do that?" kind of thing. There's nothing really surprising about the behavior.
This might help: `0 &lt;= (~(~(--i)))`.
Is there a generally accepted modern C++ identifier style? Between Win32's SUPERSHOUTYSTYLE_EX, std_lib_style, and what I'm used to in C#, I have a little bit of a crisis when working on my engine in C++.
I think the general conventions are UpperCamelCase for classes and type names, snake\_case for free and member functions, and YELLING\_A\_LOT for constants. There's no real agreement on member variables (mHungarian, trailing\_underscore\_, nothing\_special), and plenty of Java-infected groups useCamelCaseForEverything.
'this' is just as much of a pointer as anything else. It's not protected or anything (Whether it's the compiler, the CPU, or the OS), and I wouldn't expect it to be. From what I remember, you can even use: "this[0]" or "*this" to dereference the object.
Interesting talk! I've always thought that the committee should resolve some of the issues Scott highlights backwards compatibility be damned. History teaches us that languages either evolve or die. Minimizing the rough spots in C++ could give it a much longer lifespan. 
I think that everyone has its own preferred style. I find lower_case for everything more easy to read in general, but I feel lonely on this side. The purpose of this tool is to make sure that a project has a consistent style across all the source files. For every file that is parsed by Clang, the tool looks for style configuration in the corresponding folder and any parent folder. So it should be able to differentiate declarations in a third-party header from the declarations that are part of the project. I'm thinking about making it possible to automatically convert the identifiers from a given style to another, but I'm not totally sure how useful that would be...
So they just cancel. Knowing takes the fun out of it, heh.
So my style isn't too far off then I suppose. Member variable naming style is interesting to me though. In C# you can sometimes tell what language a developer grew up on by how they name their member variables. Personally I prefer the camel case style, but I can see why the various styles exist especially in C++ because depending on your editor of choice you might not have a pretty GUI like Visual Studio that puts an icon next to the name so you instantly know what it is. If you were reading C++ with no editor to help you, certain styles will help readability much more than camel case, especially if your public members are also non-upper camel case. Actually I guess that kind of makes all of the various styles make sense. I always wondered why. 
Yea, although it should be `1??(this??)` for it to 'work', which doesn't look as cool.
Sending `i` to space.
&gt;`while (1);` Uuuhhh.....
`*this` is used a lot. How else are you supposed to refer to the current object by value/reference?
whoa, glitchville! Thanks, corrected.
Heh, just order of operations really. `&lt;=` is less than or equal to. The `--` is a decrement, so `--i` means every time it analyzes the condition it decrements i, (prefix decrement). The `~~` is a double `NOT`. `NOT` means binary `01011` becomes `10100`, so you do that twice and it reverts back to what it was. So it's only decrementing, doing two pointless NOTs, then checking the condition. Acts like a `for` loop basically.
For anyone curious why &gt; The definition of the subscript operator [] is that E1[E2] is identical to (*((E1)+(E2))). But mostly it's an anachronism. I've only seen it used seriously in very old code that built a hex string: char x = n["0123456789abcdef"];
It's not that surprising really. When programming in something like C++ or C you're better off thinking that all you have is raw memory bytes and CPU instructions, and all the rest (even function calls) is just a set of ephemeral "conventions". Once you really internalize this mindset, things like this stop being "weird".
I'm pretty close. I do PascalCase for classes/typenames, camelCase for functions, variables, and YELLING_A_LOT for constants, enum types, etc. It's mostly just because that's what I learned and that's what I stick to. The important part isn't what convention that you use, just that you have one and that everyone uses the same one on a single project.
Thanks. For RTM I'll be writing another VCBlog post about all the stuff we've fixed in the STL for C++11/14 conformance. Then I might finally have time to film some more videos.
Its just based off the "goes to x" 'operator': int x = 10; while( x --&gt; 0 ) // x goes to 0 { printf("%d ", x); }
I believe it's because /u/georgeavazzy wants to keep the vs output window open, but of course he should use int main() { ... std::cin::get(); return 0; } instead of an infinite loop.
Well, the `-&gt;` operator is typically used instead of dereferencing `this` and then using the `.` operator, right? If I'm not mistaken, `A-&gt;B` is functionally equivalent to `(*A).B`. Edit: I guess if you need to pass the `this` pointer to a different function or something instead of just accessing a member of it, you need to dereference. I just mean I very, very rarely write `*this` and it seems to me to be a code smell.
I just use `system("pause");`
what do you return from `operator=`?
I was about to say that isn't cross-platform and then I realised you only need to do this on windows haha, whatever works!
They're used in many operator overloads, such as: Point &amp; operator += (const Point &amp; p) { x += p.x; y += p.y; return *this; } Going through my code I've also found at least one legitimate use. I have a list of `Chunk`s that are created by `Region`. I need to keep a reference to the parent `Region` inside the `Chunk` so I call its ctor like: chunk = new Chunk(*this, {x, y}); 
It would break the language if `this` could be any of the derived types in the hierarchy. It couldn't have any actual consistent meaning (accessing protected/private members, derived members, `sizeof`, etc...). There's the issue of emitting proper code as well.
&gt; I feel lonely on this side. I'll hold you company!
Loops and blocking for input and system calls are all philosophically wrong, though they obviously work practically. They treat a symptom instead of the problem; and there is barely even a real problem. Here are the options I suggest: * Run from the command line directly (like console applications are meant to be run). * Run without debugging (Ctrl+F5 in Visual Studio by default). * Set a breakpoint (one of the main features of running with a debugger). Don't write code to work around your tools. Learn to use your tools.
Me too. The rationale for me is simple: I will do whatever the stdlib does in a language and consider everything else wrong. Since I use few other libraries the result is that I get very consistent code, which is worth a lot more for readability than everything else.
&gt; YELLING_A_LOT for constants There was a very nice article a while ago that did a great job of arguing against that: Basically a constant is the safest and least-problematic thing in the whole language, so it is kind of stupid to give it a screaming identifier that says “use me with care, I am dangerous”, because some time long ago we used macros for those things. BTW: The newer parts of the stdlib use normal snake_case for constants which alone should shut down that other style.
Or use an OS that doesn't treat the terminal like a second class citizen.
Windows 10 even has 25% fill for 4 windows
Not really. _this_ is not necessarily of the type pointer to actual object. If you don't realise why : think about derived and bases classes...
And as counter to the argument of "it beaks legacy code," don't recompile your legacy code using a modern compiler. If, say, c++17 were to do away with some inconsistencies at the expense of breaking legacy code, then don't compile that code using c++17 standards. 
void ;)
I tried that, but went back to PascalCase for class name, just to avoid some collisions.
I always follow the simple rule of *do whatever the standard library does*. Since every C++ developer knows the std lib (and Boost) convention, stick to it and no one will complain (EDIT: that they cannot follow your style).
I expect there are ways of discontinuing support for some bits of the language without silently breaking code. Refusing to compile is important.
System pause was _designed_ for this. Visual Studio itself uses system pause after your program is done running (unless you're in debug mode). &gt; Run from the command line directly (like console applications are meant to be run). Having a console does not necessarily mean that the application is a console application. I have a normal windows application with which I allocate a console for debugging purposes (using `AllocConsole`). Running it from the command line will create another console window which will still close if I don't use system pause. &gt; Run without debugging (Ctrl+F5 in Visual Studio by default). Same as above, doesn't work if you allocate your own console. Also, considering using a console is mostly for debugging purposes most of the time, 'run without debugging' isn't really a solution. &gt; Set a breakpoint (one of the main features of running with a debugger). So you'll require every developer in your team to set a breakpoint at the end of the program's code so that they can diagnose its final output? It's much easier to just use system pause, since as I said there's literally nothing wrong with this and was specifically designed for this. Also, doing things 'philosophically correct' doesn't always work in the real world. Sometimes you don't want to look for 'how to properly use your tools' because what you're doing already works and there's absolutely no need to change. The `while(1);` though... I'd imagine any sane programmer would think that there would be a better way to do that than to use 100% of the CPU core while waiting. Heck, even just `while(1) { sleep(1); }` is miles better.
^(still not a real os) :P
&gt; Plus, it doesn’t seem to make much sense to have hierarchal relationships, because a range is not a refinement of a fusion sequence, and if we had another overload, we might have to restructure the entire tag dispatching. smh...
&gt; The rationale for me is simple: I will do whatever the stdlib does in a language and consider everything else wrong. "When in rome, do as the romans do" is a good guideline.
Your frustration is widely felt. Going on github and even here on /r/cpp and seeing people work on new modern C++ libraries that have the disclaimer that it doesn't work with MSVC is very demoralizing. Thankfully Clang is working on providing an actual C++ compiler for Windows that will work as a drop-in replacement for MSVC. That way you can use the IDE but have a fully functional C++14 compiler.
I suppose I was making some assumptions based on the parent comment where a command line program was implied. Yes, if you don't have a command line program, running from the command line would be weird. I did assume a command line application in that argument. Yes, if you allocate your own console then dealing with it separately makes sense. &gt; System pause was designed for this I'd argue it was designed to pause a program when it made sense for the program behavior, not when it was convenient for the person debugging. It obviously can be and is used for both. I won't presume to know the mentality of whoever created it; perhaps they did intend it to be used for both. &gt; considering using a console is mostly for debugging purposes most of the time, 'run without debugging' isn't really a solution Seems to me a console can be used with or without the debugger itself running. But if you are running the debugger, breakpoints and variable watches and whatever else the debugger gives you are, in my experience, vastly more effective than trying to compare output to code and construct the program state in your head. Why not just look at the program state while its paused in the debugger? If you need to look at a sequence of prior events and/or state, that's what log files are for, and they work for production troubleshooting too. &gt; So you'll require every developer in your team to set a breakpoint at the end of the program's code so that they can diagnose its final output? Yes. I wouldn't want the way I debug to govern how someone else debugs or vice versa. If they want to use `system("pause")`, fine, so long as it isn't forced it upon me. As for diagnosing final output, I'd again argue for the superiority of log files to console output; any reasonable logging framework would also allow logging to a console for the people who like that. I generally believe in letting the code be for the program, not for me, and only go against that when I have a strong reason. I do not count reviewing console output as a strong reason when I have what I consider better options readily available. &gt; Also, doing things 'philosophically correct' doesn't always work in the real world. Do you have an example? Not knowing or wanting to learn the philosophically correct way doesn't imply that way doesn't work. Even if the philosophically correct way were highly inconvenient, it would be an argument to not use it, but not an argument that it doesn't work. &gt; Sometimes you don't want to look for 'how to properly use your tools' because what you're doing already works and there's absolutely no need to change True enough. Inertia and habit are hard things to overcome, especially if the alternative provides no perceived improvement. I didn't intend to start an argument and I acknowledge that what I consider appropriate for console application debugging may not apply outside that domain. Different programs and architectures may absolutely require different techniques.
When I used to work on C++ at my previous company we used ```_memberName``` and ```_member_name``` for member variables, although I understand that this can be problematic I never encountered a situation where this caused an issue. I've also seen code bases where the member variables were ```memberName_``` and ```member_name_```
100%. In Java camel case, in C++ lower case and under score. I wish more people would do this. My pet hate is the mix when you have something like: std::unordered_set&lt;MyType&gt; myTypeSet; //... myTypeSet.emplace_hint(myIter, myVal); it just looks confused. What worse is when people use it as an excuse to use home rolled (or god forbid Qt) containers.
I've heard another rationale: if you use camelCase you can difference code that is part of the standard library or Boost and code that is not part of them more easily.
His point still stands though.
Yep it's not there yet, but I am almost certain it will be usable before MS completes full support for C++03 (ignoring export template).
Ummm, I'm running it right now...? Unless you meant that as a joke, in which case yes, it still has many of the flaws previous Windows versions had
Very possible. I'm excited for the day when I can drop it in as a replacement, even if it's just for testing purposes. Ideally my team would be able to test with a variety of compilers on whatever platform their developing on, but right now we're MSVC only due to some dependencies I haven't sorted out for other platforms yet.
Sorry, what I tried to say is that no one will complain that they cannot follow your style, since they have to be able to follow it anyways in order to use the std library or Boost.
I think that this is one of the most stupid justifications for something that I ever came across: Why would I want for other libraries to stand out that strongly by having completely different styles. The fact that almost every single language these days has very clear rules regarding names shows that nobody actually wants this. Also: This might be some justification for application-developers to diverge, but not at all for other library-developers, because they either don't create that distinction or create a completely different one. 
It's frustrating when people have different naming conventions for different kinds of identifiers. Like `_t` postfix for typedefs, or distinguishing variables and functions with `camelCase` vs `snake_case`--which is a functor? Naming conventions that distinguish scope also are at best dubious. https://crazycpp.wordpress.com/2013/05/17/a-case-against-naming-conventions-based-on-type-or-scope/
&gt; I can only hope that people who read your blog will eventually learn how and why pretty much everything in it is wrong. That seems like pretty strong language, and you seem like the only one critiquing it for it being completely "wrong". &gt; On the quick here: your tags are not following any concept hierarchy I point that out, and that it doesn't really make sense. You think I am wrong? How else would I encode preferences for the functions using tag dispatching that would make sense? 
&gt; I don't think you tested any of your examples. Also, here is the code I used to test it: print("hello"); print("3"); int i = 3; print(i); std::vector&lt;int&gt; r = { 3, 3, 3 }; print(r); auto t = std::make_tuple(3, 3, 3); print(t); boost::variant&lt;int, std::string&gt; v1 = 3; print(v1); boost::variant&lt;int, std::string&gt; v2 = "3"; print(v2); std::vector&lt;std::string&gt; rs = { "hello", "world"}; print(rs); boost::variant&lt;int, std::vector&lt;int&gt;&gt; v3 = r; print(v3); std::vector&lt;boost::variant&lt;int, std::string&gt;&gt; rv = { 3, "3", 3 }; print(rv); auto m = std::make_tuple(3, r, v1, v3, rv); print(m); 
It was sort of a joke. I personally don't understand how anyone on this sub could willingly use such a programmer unfriendly OS. My point being that it doesn't even have the some of the primary component that in my mind constitute an OS, such as a package manager and a decent terminal emulator. (the Appstore and power shell/cmd do not count).
Please note I use Linux almost exclusively, it's only sometimes that I use Windows. Not sure why powershell doesn't count, it's really quite good. I personally haven't found a scripting language I can use without smashing my face into my keyboard, including bash and powershell. Once you get your dependencies worked out Visual Studio is a real delight to use. There is Nuget which is basically Microsoft's package manager, but I'm not sure if it works with native code, its mainly aimed at .NET.
&gt; I don't really like IDE's Aahh, that's where we differ :) perhaps that makes me more inclined to be less critical of Windows, because IMO VS (along with Intellij Idea) are the two best tools to develop software with on the planet. But that's just me, opinions may vary :) &gt; A package manager really needs to be a first class citizen (IMO) to be worthwhile In the .NET world, Nuget is just about as first class as you get. It is deeply integrated into VS and the .NET development workflow.
Well, your code doesn't work and your test is incomplete. You never tried a fusion sequence, such as fusion::vector. The major issue here is that your concepts are confused. They don't specify the actual requirements put on the concept. This probably caused your confusion with the hierarchy, making fusion sequences a refinement of runtime sequences, and opened the door to a trivial but serious issue in your code. As I mentioned earlier, your concept hierarchy is all kinds of messed up. You admit this but then proceed to recommend it anyway, even to the point of asking, "How else could I do it?" (answer: anything else!) So lets talk about this problem first. *Note: In the below I had the relation inverted to the relation in the blog. Doesn't matter though, the concepts share nothing in common. If anything the relation in the blog is worse.* *Note 2: Actually, the code is inconsistent. Ranges don't have to be Sequences nor visa versa, as far as the concepts go, but then all the functions are written such that Ranges are Sequences are Streamables. To fix the hierarchy `is_range` would have to extend `is_sequence`...and then no range would match.* In what way does a fusion sequence refine a runtime sequence? For example, what is the same between a std::vector and a fusion::vector? The answer really is: nothing whatsoever. They don't contain things the same way, you don't iterate them the same way... So why are you treating them as if they're related? My guess is that at some point you realized that fusion sequences matched your `range` concept. This is interesting because it should have led you to write the tests that would have pointed out the flaws in your code and your reasoning. So the fusion sequence concepts start with the base concept ForwardSequence: http://www.boost.org/doc/libs/1_57_0/libs/fusion/doc/html/fusion/sequence/concepts/forward_sequence.html As you'll note, this concept has `begin` and `end` functions. This doesn't however make ForwardSequence a refinement of "Range". The functions in these concepts share the same names but do utterly different things. But, since you didn't treat ForwardSequence and Range as unrelated concepts you wrote a concept checking routine that matches both Range and ForwardSquence, when in fact the latter cannot be used in functions that require the former. Fusion sequences don't work in range based for loops. On top of this you added bad logic in your concept checking and tag generation. Since implementations of ForwardSequence match both that concept and Range it is never true that `is_fusion_sequence&lt;T&gt; and not is_range&lt;T&gt;`. Thus you eliminate the ForwardSequence specializations from the equation leaving only the Range specializations. Since by your reasoning ForwardSequences are Ranges, the Range specialization is available and gets used. This then results in things like: BOOST_AUTO_TEST_CASE(fusion_vector_is_sequence) { using fusion_seq = boost::fusion::vector&lt;int,double&gt;; using tag = get_print_tag&lt;fusion_seq&gt;::type; // passes BOOST_CHECK(boost::fusion::traits::is_sequence&lt;fusion_seq&gt;::value); // fails BOOST_CHECK((std::is_same&lt;tag, sequence_tag&gt;::value)); } And also this code: BOOST_AUTO_TEST_CASE(derp) { boost::fusion::vector&lt;int,double&gt; vec{42,4.3}; print(vec); } Resulting in this error: error: cannot increment value of type 'boost::fusion::vector_iterator&lt;const boost::fusion::vector&lt;int, double, boost::fusion::void_, boost::fusion::void_, boost::fusion::void_, boost::fusion::void_, boost::fusion::void_, boost::fusion::void_, boost::fusion::void_, boost::fusion::void_&gt;, 0&gt;' for(const auto&amp; x:r) print(x); You see, you so convoluted topics here that even you couldn't keep track. It should be noted that most of your example code can be replaced with a very simple implementation since all but Range types are also streamable. Unfortunately the implementation of the stream operator may not be what the user wants. There's really no good answer for this that uses these types directly. Attempts to use an overridable default that defers to `&lt;&lt;` are all going to require some pretty severe funkiness. The best I can think of is a trait `use_streaming` that defaults to `is_streamable`. With that done you could implement the functionality in your blog with: // assume is_range has been corrected: template &lt; typename T &gt; typename enable_if&lt;use_streaming&lt;T&gt;::value&gt;::type print(T const&amp; t) { std::cout &lt;&lt; t; } template &lt; typename T &gt; typename enable_if&lt;is_range&lt;T&gt;::value&gt; print(T const&amp; t) { for (auto const&amp; v : t) print(v); } Why did I use SFINAE here instead of tag dispatching? Because there's no hierarchy here. There's still problems. For example what if a type has both a print overload and a stream operator but nobody bothered to set `use_streaming` to false? The other issue is going to be another rare case where `is_range` might also be `is_streamable`. You shouldn't try to address these issues. You simply cannot address all potential issues with most things and the cost vs. benefit is high on the former and negligible on the latter. Simple with a few odd cases is way, way better than complicated and complete, let alone complicated and still has odd cases. Frankly, I think the best implementation does none of this stuff though. It would be a print function in namespaces and that's it. Whatever overload matches the type by both the overload pattern and namespace would then be the one used.
What do you do if you're dependent from a large framework, whose maintainers decide it's too much hustle to migrate their old code base? Then you would be doomed to work with some old compiler, too! The problem is you can't make an isolated decision about what "flavour" of C++ to use if not 100% of the source code is under your control - which is basically never the case for any sufficiently large program. AFAIR this was the problem with python where a newer standard (version 3) broke backwards compatibility with the effect that still most programmers are using version 2.
&gt; You never tried a fusion sequence, such as fusion::vector. I did try `std::tuple` which is a fusion sequence. &gt; As I mentioned earlier, your concept hierarchy is all kinds of messed up. You admit this but then proceed to recommend it anyway I don't recommend it. I mention the hierarchy as a problem with using the tag dispatching approach in the blog. &gt; In what way does a fusion sequence refine a runtime sequence? Its not, and I say that it is not also in the blog. &gt; For example, what is the same between a std::vector and a fusion::vector? The answer really is: nothing whatsoever. Yes there is nothing the same between them. However, an array and `boost::array` are both a range and a sequence. &gt; So why are you treating them as if they're related? I don't treat them as related, just that there are types where they overlap. Even though they overlap, they are still unrelated, however, in the function I want avoid having ambiguous overloads in those cases, so I just prefer to use the type as a range instead of a sequence. There is no refinements here, just preferences. &gt; Resulting in this error: The error occurs because the `is_range` trait is underspecified. I tried to simplify it for the post, I see now it is a mistake as `boost::fusion::vector` is being treated as a range. I'll update the blog. If you change the trait to this: TICK_TRAIT(is_iterator, std::is_copy_constructible&lt;_&gt;, std::is_copy_assignable&lt;_&gt;, std::is_destructible&lt;_&gt;) { template&lt;class T&gt; auto requires_(T x) -&gt; tick::valid&lt; decltype(*x), decltype(returns&lt;T&amp;&gt;(++x)) &gt;; }; namespace adl { using std::begin; using std::end; template&lt;class R&gt; auto adl_begin(R&amp;&amp; r) -&gt; decltype(begin(r)); template&lt;class R&gt; auto adl_end(R&amp;&amp; r) -&gt; decltype(end(r)); } TICK_TRAIT(is_range) { template&lt;class T&gt; auto requires_(T&amp;&amp; x) -&gt; tick::valid&lt; decltype(returns&lt;is_iterator&lt;_&gt;&gt;(adl::adl_begin(x))), decltype(returns&lt;is_iterator&lt;_&gt;&gt;(adl::adl_end(x))) &gt;; }; It will fix the error. &gt; You shouldn't try to address these issues. Why not? We shouldn't strive for writing more robust software? &gt; You simply cannot address all potential issues with most things and the cost vs. benefit is high on the former and negligible on the latter. Simple with a few odd cases is way, way better than complicated and complete, let alone complicated and still has odd cases. It is complicated using the traditional approaches such as tag dispatching or SFINAE overloading. However, using conditional overloading, like I show, is very simple and concise and enables libraries to easily write more flexible and robust generic functions, instead of just leaving it as broken for some cases.
You made an account just to post this? Why?
Const and non-const overloads are very common for any class that acts as a container... Sounds like your experience is not very broad
&gt; Frankly, I think the best implementation does none of this stuff though. It would be a print function in namespaces and that's it. You mean rely on ADL lookup for `print`? That would require the user to create a `print` function for every container and sequence. Thats a lot of code duplication and it completely misses the point of generic programming. Futhermore, it won't work for anything in the `std` namespace, because you can't add functions like that in the `std` namespace without having undefined behavior. Also, if later we wanted to add `print_json` and `print_xml` we would have to duplicate a large amount of code again. It just doesn't scale. Using conditional overloading is a simple and robust solution to the problem.
So why is a Croatian wiki page for a common programming concept just thrown in here?
good to know, thanks!
Can i ask why you left? I've always wondered what it'd be like to work for a fund (more so as quant though but still curious about dev).
I read that book, and found it neither rigorous or comprehensive. It is good for beginners, but if you have a genuine interest in the topic I suggest you give it a miss.
I do understand that backwards compatibility is a concern in real life. It puts a lot of barriers in real code bases. So there is always a compromise and I think breaking code is a deal breaker for many people. It happens in Java with Generics, in C++ with this... life's like this. Breaking clean includes to implement modules would allow conceptually better things, but... there are real consequences with this choice, like concerns about code migration. For me, you have your point, but there are things that can't just be done, because if you fix something the "ideal" way conceptually, many people will consider migrating to something newer, just because, anyway, some code must be rewritten. Look at what happened with Python2 vs 3... Many libs were there for a long time. The only way: backwards-compatible. Not easy IMHO. 
Puhlease: the C++ examples are very outdated and unfair. Nobody codes like that. If you want apple-to-apple comparisons, use modern (C++11/14) features such as `auto` and `std::unique_ptr`.
Even the Rust ones are a little outdated
I think there are many things that could alleviate the situation without breaking compatibility: imagine if you could specify 'template ident;'(ident needs template params) 'extern ident;' (ident is not a typename) 'typename ident;'(ident is a typename) anywhere as hints to the parser - then you could always build an AST for a file in isolation, then a compiler could use that information to resolve definitions out of order. these annotations would be needed for cases where syntax is ambiguous, not necaserily everywhere .. there's times when local information is sufficient to determine that &lt;..&gt; is intended as template params I think there are subtleties of SFINAE that could break legacy code? but a whole program analyser should warn you if you have anything that nasty going on
&gt; Therefore, the argument that printf is old and cout is modern doesn’t fly. The petrol engine is old, the steam engine is older. Therefore it shouldn't matter which we use? Cout was made to address the short comings of printf; it did that and still does that. Perhaps not in a syntactically graceful way but it does. &gt; Here’s a slide from my 10 Practical Techniques to Power Your Visual C++ Apps course where I examine the performance of searching and sorting text. Well clicking on the link took me to a page where I needed to sign up. Personally I don't think performance should really be all the much of a concern for console IO, at the end of the day if you REALLY care about output performance you'll manually buffer it up. The graph listed that shows printf being much faster than cout gives no indication of what optimisation level was used (which of course is very important for streams which uses operator overloading vs a compiled stdlib function. Secondly, there was no mention of whether was called, std::cout.sync_with_stdio(false); And whether outputs where terminated with std::endl or std::flush (they shouldn't be in performance critical scenarios). My real beef with people using printf is that it just creates more shitty C++ in a world where have enough of that. This is not good C++ std::printf("your name is %s, your address is %s", person.get_name().c_str(), to_string(person.get_address().c_str()); That's really better than \s std::cout &lt;&lt; my_class; And if your C++ isn't compartmentalised into class structures and similar, then you're probably writing shitty C++. If you really don't like iostream interface, then do yourself a favour and just wrap it in a variadic template interface. You could also fuse it together with boost format to get printf like formatting on the cheap with type saftey and the convenience of support ADT properly.
I have never bothered to learn iostreams at all and it never caused me any ache. Check out [my Printf extension](http://emphasize.cz/trunk/Resources/Resources_Printf.hpp) (wchar_t and Windows-only though, and the implementation needs major cleanup ...someday). 
Tried to find out what the graphs are about, got hit by a pay-wall instead. Since this means I can't argue about performance it leaves usability. So can I print a myVec3 with printf or do I still need cout for that? 
I think what C++ needs is a modern, type-safe version of printf. C#'s [String.Format](http://msdn.microsoft.com/en-us/library/system.string.format%28v=vs.110%29.aspx) is very nice and it inspired Python's [format\(\)](https://www.python.org/dev/peps/pep-3101/). Perhaps it would be something for the Library Evolution Working Group to look at?
Well, outdated here for C++ means 3-5 years old. Outdated for Rust means 6 months :).
There are actually two heavy downsides to streams: 1. locale overhead 2. formatters (you have to constantly mutate the state of the stream to get the formatting you want) If you're using std::ostream, you have these issues. However, you can always use your own stream-like type that doesn't have this overhead: there's nothing implicitly slow about the &lt;&lt; operator.
This is not so much a defense of printf as an attack on cout.
&gt; locale overhead It's not the overhead that sucks about locales, it's that they suck to use and write code with, you basically have to have the doc open and even then you're probably doing it wrong. But it's still worth it in my mind for ADT support and type saftey. &gt; formatters I don't really see that as that big of deal; really, not enough to overcome it's positives. 
&gt; In fact, printf is in principle slower since it needs to parse its formatter arguments at runtime. Not to mention that unsynced (as they should be) streams can buffer too.
I actually wanted to read this article because I have been following Rust since its inception. But the article basically begins saying so yea C++ sucks and here is a reason it sucks (proceeds to give code from a compiler error competition)... Dropped it right there because I knew it wasn't even going to be fair.
Dont get me wrong, I love Boost::format, but the % chaining bugs me a little bit. Kindve wish it could just accept variable input arg lengths to a function like Pythons format. 
Compensation was flat, stress levels and responsibility were ever increasing. It got to the point where I was personally responsible for engines trading around $5 billion a day, on every future and equity market in the world, 24 hours a day, six days a week. It is a brutal environment and the space is overcrowded, layoffs were a constant threat, the industry as a whole is still in decline after the crisis, and it was well known that there were hundreds of people willing to take the job as well because its "so sexy." The race for speed got kind of old and boring after awhile, I yearned for the days when we actually tried to trade smarter, not faster. But anyway, the summary is that my hours (so many weekends at the end) and responsibility increased greatly, while compensation stagnated. And what really made me leave was that while this was going on since the crisis, the race for talent out in Silicon Valley raged on, and I was able to secure offers for considerably more money from those firms, that were not based on any discretional component, any variable compensation was based upon publicly published revenue goals. 
I'm sure that's a library *somewhere*. Of course, I see your point: it would be nice to have that in the standard lib somewhere.
"C++ programs have been compiled with gcc-4.7.2 in C++11 mode" ... "I know that there are a lot of changes in C++14 as well as in latest Rust release.". It seems that author don't know what is C++11 and C++14 as the later don't have so many changes compared to C++11 (and they are not even related to compared topics). Also there are none C++11 features used and almost no C++ code (is more google famous "C with classes" coding style). But for majority of people who still think that C++ is all about manual memory management, ugly template errors and pointers everywhere this is an excellent comparison between two languages that further prove their point.
&gt; Forcing everything into an object model is shitty code in any language. I didn't mean to imply that. But because SOME structure will naturally fall into objects means that printf will not work consistently well. This is multiplied when objects are themselves composed of other objects. (such as address in person). In the same way that not everything should be an object, it's even more true that not everything should be POD's in function scope a'la procedural programming. After which, printf just gets ugly. 
If you have numerical outputs, cout is much, much worse than printf. Consider this example code from cplusplus.com : int main () { double f = 3.14159; std::cout.unsetf ( std::ios::floatfield ); // floatfield not set std::cout.precision(5); std::cout &lt;&lt; f &lt;&lt; '\n'; std::cout.precision(10); std::cout &lt;&lt; f &lt;&lt; '\n'; std::cout.setf( std::ios::fixed, std:: ios::floatfield ); // floatfield set to fixed std::cout &lt;&lt; f &lt;&lt; '\n'; return 0; } Compared to the analagous printf code for the key part of the above: printf("%5g\n%10g\n%10f\n",f,f,f); The advantages of printf are : (1) consise and readable (2) no formatting state in i/o stream --&gt; fewer bugs (3) faster to write (4) faster to execute All cout has as an advantage is better type safety. But newish compilers do well at catching printf type and number-of-argument bugs, so that is mostly even these days. 
&gt; (1) consise and readable I strongly disagree that the printf-version is readable; the readable version here is definitely the cout-version. Which is btw. written in an unnecessarily ugly way: double f = 3.14159; std::cout &lt;&lt; std::defaultfloat &lt;&lt; std::setprecision(5) &lt;&lt; f &lt;&lt; '\n' &lt;&lt; std::setprecision(10) &lt;&lt; f &lt;&lt; '\n' &lt;&lt; std::fixed &lt;&lt; f &lt;&lt; '\n'; The above does the same thing and is arguably much more readable; yes it is still not perfect, but it is much better then the mess that printf needs for that.
On many of these teams, the line between "quant" and "dev" is always a little blurry, I did work writing models. Then again, the barrier to be in the quant group has never been higher- a PHD from a top school is more or less a requirement these days, whereas say 10 years ago you had a chance of getting in through the backdoor, by working with and then in a quant group (and back in say 2004, their may not have been an official quant group, just a few guys who focused on specific kinds of problems). Part of what I was alluding to is that models in the HFT era are not really all that complicated- the focus is on speed. Pure arbitrage is about making money with zero risk, the more you are "thinking" and the more complicated your model, the more you are really making guesses about where you think the market might head, as opposed to knowing that if the SPY etf is trading out of alignment with the actual prices of the basket of securities it tracks, there is a risk-free profit to be made there. Back in 2009 total comp could be north of 400k. I would be really surprised if more than a handful of people in a handful of firms are still making that. All of my friends at prop funds have told me that comp is way down- the jig is up, the techniques are pretty well known at this point, and the life of a successful strategy seems to keep compressing. I have no hard data on this, this type of data is very tightly held, but based on things I saw the average life of a strategy has decreased from a year+ to just a few months over the last few years. Anyway, to answer your question, if you aren't currently using C++ professionally, its going to be very difficult for you to learn at a level that would get you into one of these groups. I do know though that at least one firm is actually using Java though. Read the common books and really know them front to back, and read every blog you can find- the boost guys are a great place to start, and anyone who writes about low level stuff like cache coherency and multithreaded programming. Also read books about system programming for *nix. Advanced Programming in the Unix environment is a good place to start. I used to try to read the gcc, clang, LKML and network mailing list, but the signal/noise ratio is just horrific there. Boost is better, but still kind of niche. The current focus is away from OOP and more towards generics. So books like Modern C++ design and C++ Templates: The Complete Guide are still great even in a C++11/14 world. The rest you have to work in the industry for really. I don't know how/why I would have learned about Infiniband or Melanox/Kernel Bypass without having worked on these teams. Really you just need tons of experience writing code, and to really know everything there is to know. At one time or another, I have been asked to write a smart pointer implementation, every type of major sort and data structure, including multi-thread safe containers, etc... on a whiteboard or piece of paper and was expected to do so without any serious errors. I hope that helps. 
Thanks. I appreciate the advice. Well wishes on your new job in the valley.
Dropping by from /r/rust: we also think this post is pretty poor, overlall. It's also quite old: it's a translation of an article in Russian from June.
Okay, to be honest the printf version I gave was optimised more for conciseness than readability. Optimising for readability: printf("%5g\n",f); printf("%10g\n",f); printf("%10f\n",f); Still significantly shorter than the cout version, and easier to understand since the whole type for each format specifier is right there, not hidden in the state of the stream. 
Very disappointed about the article: what is *reliable* about dangling pointers, dangling references, out of bounds access, etc...? &gt; #3 For reliable software, you need Garbage Collection seems quite a grand title just to herald RAII (which could really use a better name).
&gt; However, you can always use your own stream-like type that doesn't have this overhead: there's nothing implicitly slow about the &lt;&lt; operator. That's what I do ;)
Nice article. Working with C++ every day, I never miss not having a garbage collector.
Nothing against Rust but: am I the only one who is more than a little confused by the many symbols for declaring pointers?
Even with C++11/14 it's still entirely possible to write C++ in this way because of backwards compatibility. New languages don't have the constraint of legacy code and can thus prevent classes of problems in the language itself. I think that's interesting. People seem to view this article as a beat up on C++, I don't understand why.
&gt; (1) consise and readable (2) no formatting state in i/o stream --&gt; fewer bugs Wtf am I reading?
Care to elaborate that into a coherent comment? I can't tell if you are saying "I disagree!" or "I don't understand what you wrote." or something else entirely.
The effective C++ series is full of excellent tips to improve your c++: http://www.aristeia.com/books.html Herb Sutter and Andrei Alexandrescu, C++ Coding Standards: http://www.gotw.ca/publications/c++cs.htm 
Of course you do not - that's why you still work with C++ all day long ;-) SCNR
Been there, done that. After being bit a few times too often warnings as errors and svn blame are the only way to stay sane.
So its worse than the C++ FQA ?
And cout is in principle slower because it has to make a bunch of virtual function calls that stall the CPU execution pipeline. My point is that I don't think you can make any kind of theoretical argument that one should be faster than the other. It depends on usage context, hardware, compiler and iostreams implementation.
Since you mentioned embedded systems (my area of work), you can find good materials regarding C++ for embedded systems by Steve Dewhurst, Dan Saks, and Scott Meyers. Steve Dewhurst has a couple books and some conference presentations/papers, Dan Saks has a column over at embedded.com and Scott Meyers actually has materials and presentations specifically targeted towards embedded systems. None of them talk to you like, "OK, here is a Point class with an X and Y data member..." Topics like template usage, placement new, memory-mapped I/O, etc.
Please put some units on those axes, man. 
What do you think about [this](http://adityaramesh.com/ccbase/format.html)?
Using the small [formatting library](http://adityaramesh.com/ccbase/format.html) I wrote, this would be cc::println("${prec(5)}\n$1{prec(10)}\n$1{fixed, prec(10)}", pi). I wrote the library because I was unsatisfied with the unintuitive syntax used by other formatting libraries, and still wanted the benefits of type safety.
C++ does not reliably avoid dangling pointers/references. Sure, C++11/14 make some big improvements but it's still easy to accidentally leave a reference dangling by e.g. invalidating an iterator. (Of course, there are other languages that demonstrate that GC isn't necessary, but I don't think C++ is the best example in this space.)
Overloading on true_type/false_type is still tag dispatching - indeed, it is the simplest, most common form. Dispatching on iterator strength, or anything that's multi-way instead of two-way, is less common. Note that your static_assert does not lead to ultra-clean error messages, because the compiler will typically try to keep going. To achieve maximum prettiness, you need to direct bogus inputs into something that will static_assert and do nothing else that will explode. (I don't do this in production yet.) Overall, a good article. I recently realized the "just overload it when you can" bit while rewriting &lt;functional&gt; - I had been tag dispatching on whether something was a std::function (so I had to write a trait to recognize that) when I realized that I could just overload for that, while still tag dispatching for other things (I had to recognize PFs and PMFs, and that definitely requires traits).
&gt; Overloading on true_type/false_type is still tag dispatching - indeed, it is the simplest, most common form. The more I consider my reason for making this distinction in the article the more I convince myself it was ill-founded. Tagging via a metafunction is still tagging. I'm going to add a prefix note update.
The Standard has a bit that allows compilers to reject static_assert(false, "BOOM") on sight, instead of delaying it until the first instantiation (which is what you'd want). In general, early diagnosis of templates that can't possibly be well-formed is desirable to permit - it's just that for a hardcoded false, you want delayed diagnosis. Someday I might write a small proposal to permit this (although I'm not good at Core wording). Until then, the workaround is to static_assert on something that will always be false, but the compiler can't know until instantiation. An always_false&lt;T&gt;::value helper will do the trick (the compiler can't diagnose early, because it has to keep its mind open to the possibility that the trait will be specialized to be true; at instantiation time it finds that the user hasn't specialized it, so it goes boom when you want). We use this in the STL.
I was wondering if it wasn't something like that. Thanks for the tip.
You advance function doesn't work that well at all. Take the following code: std::vector&lt;int&gt; v = {1, 2, 3, 4, 5}; auto squared = v | boost::adaptors::transformed([](int x) { return x*x; }); auto it = squared.end(); it += -2; // Prints out 16 std::cout &lt;&lt; *it &lt;&lt; std::endl; This code works and prints out 16. However, if I try to replace the `it += -2` with your advance function like this: std::vector&lt;int&gt; v = {1, 2, 3, 4, 5}; auto squared = v | boost::adaptors::transformed([](int x) { return x*x; }); auto it = advance(squared.end(), -2); // Prints out 16 std::cout &lt;&lt; *it &lt;&lt; std::endl; I get a compile error. If I change the ForwardIterator `advance` function to an `std::inputer_iterator_tag` like this: template &lt; typename ForwardIterator &gt; ForwardIterator advance(ForwardIterator it, int n, std::input_iterator_tag) { assert(n &gt; -1 &amp;&amp; "Can only move a forward iterator forward!"); while (n--) ++it; return it; } Then it compiles, however, now it crashes with the assertion. Rather, its better to build the function around simpler type requirements instead of relying on iterator categories. You can define the type requirements like this in the [Tick](https://github.com/pfultz2/Tick) library: TICK_TRAIT(is_incrementable) { template&lt;class T&gt; auto requires_(T&amp;&amp; x) -&gt; tick::valid&lt; decltype(x++), decltype(++x) &gt;; }; TICK_TRAIT(is_decrementable, is_incrementable&lt;_&gt;) { template&lt;class T&gt; auto requires_(T&amp;&amp; x) -&gt; tick::valid&lt; decltype(x--), decltype(--x) &gt;; }; TICK_TRAIT(is_advanceable, is_decrementable&lt;_&gt;) { template&lt;class T, class Number&gt; auto requires_(T&amp;&amp; x, Number n) -&gt; tick::valid&lt; decltype(x += n) &gt;; }; Then you can use tag dispatching to overload on the refinements of each trait: template&lt;class Iterator&gt; void advance_impl(Iterator&amp; it, int n, tick::tag&lt;is_advanceable&gt;) { it += n; } template&lt;class Iterator&gt; void advance_impl(Iterator&amp; it, int n, tick::tag&lt;is_decrementable&gt;) { if (n &gt; 0) while (n--) ++it; else { n *= -1; while (n--) --it; } } template&lt;class Iterator&gt; void advance_impl(Iterator&amp; it, int n, tick::tag&lt;is_incrementable&gt;) { while (n--) ++it; } template&lt;class Iterator, TICK_REQUIRES(is_incrementable&lt;Iterator&gt;())&gt; void advance(Iterator&amp; it, int n) { advance_impl(it, n, tick::most_refined&lt;is_advanceable&lt;Iterator&gt;&gt;()); } Also, a `static_assert` could be used instead of `enable_if` or `TICK_REQUIRES`, however, using `enable_if` has much cleaner error messages in this case. 
Maybe I am just bias, but the following: const constexpr auto print = fit::fix(fit::conditional( FIT_STATIC_LAMBDA(auto self, const auto&amp; range, TICK_PARAM_REQUIRES(tick::trait&lt;is_range&gt;(range))) { for(const auto&amp; x:range) self(x); }, FIT_STATIC_LAMBDA(auto self, const auto&amp; sequence, TICK_PARAM_REQUIRES(tick::trait&lt;boost::fusion::traits::is_sequence&gt;(sequence))) { boost::fusion::for_each(sequence, self); }, FIT_STATIC_LAMBDA(auto, const auto&amp; x, TICK_PARAM_REQUIRES(tick::trait&lt;is_streamable&gt;(std::cout, x))) { std::cout &lt;&lt; x &lt;&lt; std::endl; } )); I find is much cleaner and easier to follow than this: struct streamable_tag {}; struct range_tag {}; struct sequence_tag {}; struct try_streaming_tag {}; template &lt; typename T &gt; struct select_print_tag : mpl::eval_if &lt; is_range&lt;T&gt; , mpl::identity&lt;range_tag&gt; , mpl::if_ &lt; is_sequence&lt;T&gt; , sequence_tag , try_streaming_tag &gt; &gt; {}; template &lt; typename T &gt; void print(T const&amp; t); template &lt; typename T &gt; void print(T const&amp; t, try_streaming_tag) { std::cout &lt;&lt; t; } template &lt; typename T &gt; void print(T const&amp; t, range_tag) { for (auto const&amp; v : t) print(v); } template &lt; typename T &gt; void print(T const&amp; t, sequence_tag) { fusion::for_each(t, [](auto const&amp; v) { print(v); }); } template &lt; typename T &gt; void print(T const&amp; t) { using tag = typename select_print_tag&lt;T&gt;::type; print(t,tag{}); } Also, the latter has this problem as well: &gt; if there ever were a Sequence that was also a Range we’d get a compile failure because there’s no overload to accept it. So I guess I won't be able to use your `print` function if I am using an array. 
&gt; You advance function doesn't work that well at all. Take the following code: &gt; &gt; std::vector&lt;int&gt; v = {1, 2, 3, 4, 5}; &gt; auto squared = v | boost::adaptors::transformed([](int x) { return x*x; }); &gt; auto it = squared.end(); &gt; it += -2; &gt; // Prints out 16 &gt; std::cout &lt;&lt; *it &lt;&lt; std::endl; &gt; &gt; This code works and prints out 16. However, if I try to replace the it += -2 with your advance function liek this: &gt; &gt; std::vector&lt;int&gt; v = {1, 2, 3, 4, 5}; &gt; auto squared = v | boost::adaptors::transformed([](int x) { return x*x; }); &gt; auto it = advance(squared.end(), -2); &gt; // Prints out 16 &gt; std::cout &lt;&lt; *it &lt;&lt; std::endl; &gt; &gt; I get a compile error. If I change the ForwardIterator advance function to an std::inputer_iterator_tag like this: &gt; &gt; template &lt; typename ForwardIterator &gt; &gt; ForwardIterator advance(ForwardIterator it, int n, std::input_iterator_tag) &gt; { &gt; assert(n &gt; -1 &amp;&amp; "Can only move a forward iterator forward!"); &gt; while (n--) ++it; &gt; return it; &gt; } &gt; &gt; Then it compiles, however, now it crashes with the assertion. You don't know what you're doing, dude. You're like those guys who I tried to tutor through college that copied each others' work and then fumbled around changing things without a clue. Everything you're complaining about there is fully expected. &gt; Rather, its better to build the function around simpler type requirements instead of relying on iterator categories. And you don't even know why. This guy :p
&gt; And you don't even know why. I do know why. Iterator categories can't be used to detect traversal because a forward iterator is required to return a real reference(ie `std::iterator_traits&lt;T&gt;::reference` must be an actual reference). As such, the iterator to `squared` can at most be an input iterator, even though it has random access traversal(ie `it += -2` is valid).
&gt; So I guess won't be able to use your print function if I am using an array. Well, to be honest my functions all have a major flaw: they use your concept checkers. This was lazy of me but I didn't make sure your stuff worked. I should have tested it...so yeah, my bad. `is_range` fails to identify arrays as ranges. For this reason, no it won't work right unless it's a char[] with null terminator when we want it to be treated as non-range. Arrays get treated as non-range, non-sequence types. `is_streamable` grabs int[], which I find surprising but I'll examine that later. `is_range` fails to recognize arrays because of the copy assignment requirement most likely. I'll have to remedy this situation later. I'll admit, it was a silly assumption in light of history. Not sure why you think arrays don't work because the latter version fails to address types that are both Sequence and Range--such constructs are impossible given the two concepts. Total non-sequitur. If the concept checker for ranges worked right then an overload for char[] would need to be created to deal with static strings for the same reason as a std::string overload was needed. I did recognize that this wasn't needed and why, but failed to recognize the implications of that.
No, silly. It's because you passed a negative `n` to a function expecting non-negative. If the assert wasn't there the darn thing would loop into oblivion. The advance I wrote works just fine for the concepts it was meant to except that: * The match should be on InputIterator rather than ForwardIterator (doing this wrong was on purpose and is mentioned in the blog). * There should be an overload for BidirectionalIterator to accept negative n where that's allowed by the concept. * I might have missed something else...don't think so, but it wasn't meant to be complete of course. It obviously would still not work for your example because well, you're violating its interface. Your use of `advance` is illegal--as you pointed out negative n is not allowed for the standard concept your iterator implements, which is InputIterator.
&gt; is_range fails to identify arrays as ranges. This is because the array is decayed to a pointer in the `tick::models` class. I am planning on merging some breaking changes to the library that will fix this. For now, you have to specialize it for `is_range`. &gt; is_range fails to recognize arrays because of the copy assignment requirement most likely. The copy assignment is on the iterators not on the range. &gt; Not sure why you think arrays don't work because the latter version fails to address types that are both Sequence and Range--such constructs are impossible given the two concepts. Arrays(including both `boost::array` and `std::array`) are compile-time sequences and can be adapted as fusion sequences as well. 
&gt; It obviously would still not work for your example Nope it still won't work. &gt; because well, you're violating its interface. An interface that is suboptimal and confusing.
&gt; C++ does not reliably avoid dangling pointers/references. The easiest way to do that is not to return references from free functions; methods may return references to members, but it might be worth the idea to explicitly delete or override this for methods of rvalues: class my_class{ public: my_class(std::string str): m_str{std::move(str)} {} const std::string&amp; str() const&amp; {return m_str;} std::string str() &amp;&amp; {return std::move(m_str);} std::string str() const&amp;&amp; = delete; private: std::string m_str; }; my_class get_rval() {return my_class{"foo"};} const my_class get_const_rval() {return my_class{"foo"};} int main() { //auto str1 = get_const_rval().str(); // Error auto str2 = get_rval().str(); // works safely auto instance = my_class{"bar"}; auto&amp; str = instance.str(); } Also: try to avoid passing mutable references around, prefer to return your results. I am aware that this is more of a goal and less of a coding-guideline, but I am sure that I you reach it, you won't have a lot of problems with dangling pointers/references.
even if not official libs, these two came to mind, but there are others around as well: - https://github.com/krig/k11 - https://github.com/c42f/tinyformat
I think you guys are talking past each other a bit. You are showing tag dispatching using the std iterator categories, while pfultz2 is being a bit offtopic and mixing at the same time his view on overloading with improved iterator categories. While it seems that your interest is to show how easy and clean tag dispatching is (which I think is an awesome thing to do and blog about), it seems that pfultz2 focus is on showing why the iterator categories are flawed and why implementing better iterator categories with tag dispatching can be sometimes painful. Anyhow, a transformed view of a vector (which provides random access iterators) should provide random access traversal. This is AFAIK not possible with the STL iterator categories. Only forward traversal is possible due to the input iterator category. We should not be satisfied with this aspect of the STL (so I think pfultz2 has a point). At the end of the day, however, which approach to choose to write generic code (tag dispatching/overloading on concepts/TICK/sfinae...) depends on a lot of things. Whenever I hack in some code that uses SFINAE, I always feel bad about it. Everytime I've rewriten it using tag-dispatching the solution has been cleaner and simpler, so IMO tag-dispatching is the preferred way right now for doing this. Still, if you want/need concept-based overloading you either use TICK or eric niebler's range-v3 CONCEPT\_REQUIRES/CONCEPT\_REQUIRES\_ macros which are almost the same thing. With concepts little the need for these solutions will hopefully disappear, but concept-based overloading will still be there, and I can see why it is in a lot of places exactly what you want, so I expect tag-dispatching will become a hack of the past as well.
&gt; If you have numerical outputs, cout is much, much worse than printf. No. First, you have written the std::cout example expanded on multiple lines, making the code unnecessarily larger. Second, you are assuming familiarity with printf when you state cout is much much worse. I have worked in a few projects using printf over the years; these are some of the issues I had with printf: - wrong format for the variable type (compiler yields a warning, but only if the format is specified in the printf call; if you generate the format dynamically or pass it as a parameter and call printf internally, invalid formats fail silently - after teaching you to rely on the warnings). - I had to look online in the printf documentation to figure out the correct format to use (by the way, what does %g do? I know %d, %f, %l, %u, %x and %p; Also, is it %ul or %lu? I never remember this); This is not a big issue (I had to do the same with std::ostream a few times), but your "concise and readable" printf call is concise and readable because you wrote it many times, not because the interface is good. - I had to go over hundreds of warnings after changing a variable type (i.e. change x from DWORD to std::size_t in a porting project, recompile, have your build output full of printf format warnings); Again, it is not a bit thing for one variable, but in a porting project, you have thousands of variables to change. - application crashes (enough said) Third, your faster to execute code is only faster to execute if you do not use std::ostream::sync_with_stdio(false). &gt; All cout has as an advantage is better type safety. - and support for custom/extended format specifiers - and support for custom types - and exception support - and a common interface for all stream specializations (this is a big one when you want to write testable code - you can just inject the correct type of stream into it) - and composability &gt; But newish compilers do well at catching printf type and number-of-argument bugs, so that is mostly even these days. Counterexample: void print_custom_x(char* fmt, const X&amp; x) { printf(fmt, x.a, x.b, x.c); // fmt is not hardcoded here } struct X { int a; int b; double c; }; X x{ 10, 20, 30.5 }; sprintf(fmt, "%s", "%d, %d, %p"); // this line thinks x.c is a pointer print_custom_x( fmt, x ); Compilers use static analysis to match printf format with parameter types; In case the format is not static, the warning is not generated. This is not "compilers do well" - it is compilers catch _some_ of the errors (i.e. "compilers do badly").
&gt; I think what C++ needs is a modern, type-safe version of printf. That would only work as long as you don't write type information in the format string. Adding type information in the format string is a recipe for difficult to maintain code.
Its fun to write, you should give it a try. Its a fun weekend project. 
And I absolutely agree with your point. I’m just always annoyed by people who run obviously flawed benchmarks and draw premature conclusions from that.
Yeah, but printf provides no option at all for custom types.
Yep, because you are specifying the type in 2 places (once, the actual type and once in the format string) - this opens up the possibility that they will disagree.
 Matrix(int nr, int nc) // constructor: allocate elements :elem{double[nr*nc]}, nrow{nr}, ncol{nc} { for(int i=0; i&lt;nr*nc; ++i) elem[i]=0; // initialize elements } Is this missing a "`new`" (in `elem`'s initializer) or did I miss yet another feature of C++?
Already posted at https://www.reddit.com/r/programming/duplicates/2n2yw3/c14_for_qt_programmers/
elem is a std::vector, so its calling its constructor with the number of elements it will contain. The new call part is inside std::vector constructor
I've always liked [cppformat](http://cppformat.github.io/), which imitates Python's format: fmt::print("Hello, {}!", "world"); std::string s = fmt::format("{0}{1}{0}", "abra", "cad"); // s == "abracadabra"
I love the syntax. At work so I didnt look too closely, any drawbacks to highlight? I think this is the cleanest alternative Ive ever seen to printf
That looks very nice indeed.
&gt; Whenever I hack in some code that uses SFINAE, I always feel bad about it. Why is that? SFINAE is the only way to properly constrain a template, which helps make it clear to the user of the function that they have broken the contract. &gt; Still, if you want/need concept-based overloading you either use TICK or eric niebler's range-v3 CONCEPT_REQUIRES/CONCEPT_REQUIRES_ macros which are almost the same thing. Both the tick library and eric niebler's range-V3 library support tag dispatching based directly on the refinement of the concepts.
Yeah, you are correct, it lacks the "new" keyword. It should be new double[nr*nc]
&gt;&gt;Whenever I hack in some code that uses SFINAE, I always feel bad about it. &gt; &gt;Why is that? SFINAE is the only way to properly constrain a template, which helps make it clear to the user of the function that they have broken the contract. Well I think we disagree on the "make it clear to the user that they have broken the contract part". With tag dispatching, either you can compute the tag or not, and either you find an overload/ambiguous call/don't find anything, but the compiler does help you there. This saves a lot of time when users make mistakes. With SFINAE you are just adding/removing functions from the overload resolution set at will (and in most compilers you cannot inspect it/query it at compile time for a given function call). If the function that you expected to get picked is not (for whatever reason) you are in for a lot of debugging fun, and the compiler won't help you there at all. So I agree that SFINAE and constraining functions using concept-like SFINAE libraries is powerful and leads to clean library designs. Still, I also recognize that when things go south no amount of `static_asserts`will prevent users from wasting their time understanding what went wrong. Tag-dispatching is clear when things don't go as expected, and for this reason only I think it should be preferred to SFINAE whenever possible. The only good reason I can see right now to use TICK and related libraries is if you are preparing a library for Concepts Lite, and want to have it ready for when compilers roll the TS out, as hopefully that will improve the error messages significantly.
this wouldn't be hard to put in the language, would it?
&gt; Tag dispatching is easier, simpler, cleaner, For me personally, I dont always find tag dispatching easier, simpler and cleaner. Unless I make the tags explicit(which I usually don't), I usually need to do some metaprogramming to calculate the tags(like what is shown in the blog for the `select_print_tag`), which I find to be uglier and more complicated. Whereas with conditional overloading I just order them logically based on preference. I find this easier, simpler, and cleaner. &gt; Clang is getting better with the error messages but sometimes it still happens that you call a function, no function is found But wouldn't the same thing happen with tags, that there is no tag found? &gt; you have no easy way in modern compilers to make queries about the overload resolution set for a specific function (without a clang plugin) Clang does have a problem reporting subtitution failures through decltypes. The Fit library works around the issue with `fit::reveal` which will report the error for the leaf functions. &gt; Either the tag can be computed or not: clean error Its not a clean error. The error will be in the function rather than call site. However, the function is not the problem, its how the user has called the function. As such there should be an error pointing to the call of the function. Using SFINAE, the function should still check that the minimum type requirements are met. In the blog post here, he checks the minimum requirements using a `static_assert`, however, `enable_if` would be better. &gt; Either there is an overload for the tag or not: clean error This is an error in the function so it should not be handled by SFINAE. So the error messsage is appropiate.
[Direct link](http://blog.biicode.com/tiny-metaprogramming-library/)
The last bit... Instead of assert the function should return the vector. The guy is telling you that there's no case for the lvalue parameter optimization. Otherwise the assert doesn't help the situation unless the function actually fails if the vector is non-empty. If the function won't explode under that condition, let the caller decide if they want to append values to existing values or not. You don't need to defend yourself against the client doing what the client wants. You need to defend yourself against the client doing something that will violate preconditions. Just "expecting" that input is going to be this or that doesn't make a precondition. A precondition is a condition that must be true or your function can't be depended on to make accurate results.
I just use `-j` in my invocation of make.
There is at least one proposal to add it to the language: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4172.htm I haven't heard too much about it, so I don't know what chance it has of being accepted.
&gt; If there is a chance your code will divide by 0, then someone, including you, will eventually do the "will not happen" thing. Dividing by zero is a clear case that will result in the same end state as having an assert. There are plenty of cases where a "soft" failure mode may be far more desirable than having the program abort because a precondition wasn't met. Whether it should never happen is almost a moot point, because as you stated it will probably happen eventually anyway. How the software handles it is far more interesting to me. I'm sure I under-utilize assertions (which is to say, fail to use them at all), but it's unclear to me that peppering code with them is a good thing in software where crashes have huge consequences (e.g. hours of lost time restarting multiple subsystems if a critical component goes down, irreversible data loss that effectively costs a lot of money, etc).
Same position recently and I needed my old MFC books back! If you search, you will surly find, as I did. It took me a couple of days browsing old source code before it all came flooding back.
&gt; unless the function actually fails if the vector is non-empty From my reading of that section, the empty case is considered an error.
I sometimes feel named parameters are a hack just as much as some of the C++ solutions that float out there. Languages that don't have strong type safety use named parameters, but C++ does offer strong type safety, and it can do better than that.
If the software shall crash, it's better when it crashes closer to where the error actually occurs, or somewhere that could make sense to the client code : "this function has a precondition you did not respect, nothing good will ever happen from there". Moreover, assertions only crash in non-Release mode(s). They are meant to help us find bugs in development and tests phases (and hopefully, some day we may even check contracts statically -- check the discussions/papers around C++17). Assertions are not meant to crash in Release mode. On the contrary, if a program passes all assertions in dev&amp;test phases, it's more likely to work without crashing once released. Of course we could do some defensive programming instead doing some designing by contract. But in the end, the code will be much more complex, and we may not be able to return pertinent runtime error messages to the end-user -- without doing what should have been done by the client code in the first place -&gt; checking the preconditions. See for instance the [3 codes §III.1](http://luchermitte.github.io/blog/2014/05/24/programmation-par-contrat-un-peu-de-theorie/#iii1--prsentons-la-programmation-dfensive) in my post (in French, sorry)
Are you saying named parameters have no use in C++ at all? Because I would respond to that explicit is ALWAYS better than implicit. 
I'm not prepared to debate quality and such, but as somebody who's written *a lot* of C++ and ObjectiveC, while I prefer C++, I absolutely love ObjectiveC's named/interleaved parameters. It pretty much enforces self-documenting code. Sure, you type more but it reads beautifully. And in my experience I spend at least as much time reading code (mine and 3rd party) as writing it.
I generally agree with you apart from this part: &gt; Moreover, assertions only crash in non-Release mode(s). That depends on how you have implemented assertions. If you use the standard C assert() it is only disabled if you define NDEBUG on release builds which you may or may not. I'm sure you're aware of that, just saying that your assertion that assertions are disabled in release builds doesn't necessarily hold (pun intended). But what I disagree with is, that assertions should only be enabled in debug/test builds, because what should happen if an assertion fails in a release build? The assertion was put there for a reason, and if it fails the program might crash somewhere else later or even worse just do something completely unexpected. That's not really any better for the end user anyway and will just be harder to debug when a bug report is made. The only reason for disabling assertions I can imagine is because of performance reasons, which might be a good point if the assertions are in a place where the *very* few clock cycles wasted on testing them might have an impact. That is very really the case in my experience. Enabling assertions in production as warnings written to stderr or similar is really terrible in my opinion. If the program can run just fine when an assertion fails, then it's not really and assertion but just a warning and should be handled as such. Just my opinion, more than willing to be corrected of course.
Instead of downvoting I'm going to wait for you to explain your statement. 
What are the rules for order of evaluation, if any? As I recall C function arguments are evaluated in an implementation-defined order, which is usually right to left. Correct me if I'm wrong.
Thanks, I'm glad that someone else agrees with my sense of aesthetics =) The formatting library is a lightweight shim over IOStreams; any attribute between the {} corresponds to a manipulator. I was careful in avoiding dynamic allocation aside from what's done by IOStreams itself, so the performance should be similar to using vanilla IOStreams. If you already use IOStreams, the only drawback is that this library requires C++11 support.
boooo! hisssss!
I certainly agree a GC is not necessary to avoid dangling pointers and dangling references... ... however smart pointers alone do not solve the issue either. template &lt;typename T&gt; T const&amp; id(T const&amp; t) { return t; } int main() { std::string const&amp; hello = id("Hello"); std::cout &lt;&lt; hello &lt;&lt; "\n"; } Not a single (user) heap-allocation and yet we hit undefined behavior! For now, the only language I know that solved the issue without a GC is Rust (and perhaps Cyclone before it).
Agreed. They were a shock at first but after a few days I got used to them and started to fall in love with the idea.
As expressive as the language is, parameter descriptions are the most difficult to guess when the actual arguments don't give much context. I'm all for it.
Yeah, add more useless junk to the language. Why the heck not.
This was great until it was a page on the biicode website calling for everyone to make a TMP library with biicode.
That's the point. The assert let's you know that it's an error case.
Forgive my slightly incorrect verbiage but any order as long as it respects sequence points (most commonly `;`). At least that is the general rule. 
now I must ask are you Team Bjarne or Team Andrei (for ppl who dont know what I am talking about: static if ) 
I'm working on my own such library. Turns out that C++11's variadic templates makes it reasonably possible to implement a good typesafe print library, but it also turns out to carry a lot of syntactic overhead.
This is the kind of thing that an IDE should display in the code without you having to write it. When you type a function call, most IDEs will show up the arguments as you type along. The key here is that this argument name display should stick into the code, while having a different style and being read-only (they wouldn't really _be_ there, just a display from the IDE). There are quite a few things like this that get coded into the language when really it should be the IDE doing it.
Sometimes the *need* for interleaved parameters hints on a deeper flaw. For example, if your function takes one parameter, do you miss interleaved parameters? If it takes two parameters, is it that much a huge thing if you could specify them in any order? Sometimes a function takes way too many arguments, and when people long for named parameters they actually long for daddy to patch up their bad signatures *by changing the language* no less. Sometimes making use of the type system will solve this and many other flaws: call(destination { 911 }, from { my_phone }); And sometimes okay, you need more parameters; but often you can design your interface to make it intuitive or idiomatic without named parameters. For example, this is not necessary: std::sort(first=begin(c), last=end(c)); Nor is changing the argument order: std::sort(last=end(c), first=begin(c)); Because there is a "meta-language" or a culture or unwritten agreement in the STL by which we know the first two arguments are [b, e) iterators, and if there are other iterators they immediately follow, and if there is a function object it immediately follows after that. Named parameters simply aren't missing in the STL. If named parameters are for making C++ programming more idiot proof then I'm not in this camp. I reckon in the real world we live in things aren't that perfect, and it took about decades to design the STL. I just feel that named parameters are often a patch, a shortcut, to allow for bad design. Sometimes it's nice, but that's it.
I'm not sure that I agree. How about types then? Should we just let the IDE do that as well? 
&gt; I can't really fathom where you're getting that. I got it from the conversation. If the non-empty case is perfectly fine then the colleagues response would have been to that effect, and the story itself would likely never have been included. Instead the response is both defensive and avoids the function in question, focusing rather on the caller. That implies the colleague realises that the non-empty case would be an error but can't admit it they should have tested for it.
That's a LOT of assumptions, but OK. I myself would expect something in the code that would pose a problem if the vector wasn't empty...which was sorta my whole point. Much of the function is cut out but since the words used were, "You probably...," I would guess the meat is included--plus that's pretty standard for blogging, you don't generally gut the relevant stuff.
Does it support any number of inputs?
With GCC on linux, using -O3 and then stripping out debug information, I get: 6352 bytes for the printf version and 6392 bytes for the ostream version. So, I think this depends heavily on your compiler and switches. And, no offense, but "how large the binary is" is a really weird thing to use to determine your programming style.
Yeah, it’s time to remove all those implicit casts from C++, and those implicit selections occuring with overloading.
This would be soooo good for this Win32 functions that take 17 arguements
Oh sweet, I got hit by the limitation just the other day. Note that it *does* already work for pods though.
As much as I like named parameters, working around terrible APIs is really not the point.
&gt; That's a LOT of assumptions, There is only one assumption: that the colleague is fairly normal. After that I'm only saying that within the confines of the scenario presented, the response given would not be a normal response when non-empty isn't an error. Whereas it is perfectly normal if non-empty is an error. &gt; that's pretty standard for blogging, you don't generally gut the relevant stuff It's a fine balance though, if you read [The Old New Thing](http://blogs.msdn.com/b/oldnewthing/) for example, every time Raymond suggests a hypothetical scenario, it's the scenario that the comments debate about, not the actual point of the article. I agree the author should probably have explicitly stated in this case that non-empty is an error, but getting into a debate on *why* it's an error would be off-topic. The safest thing is usually is to leave it out.
No, but it is an advantageous side effect
Ocaml has named parameters and they are often useful. They open up quite a bit of power when combined with optional parameters. If you have void func(int arg1=1, int arg2=2, int arg3=3, int arg4=4); and you want to call `func` with `arg4=5`, named parameters would let you only supply that parameter.
Its hosted on biicode only because I work for biicode. biicode is a great tool which makes easier to use C and C++, that's why I will be using it on the examples. And hosting this series on the biicode blog is a way to get good traffic, compared to host the series on my personal blog which nobody knows. biicode is not the point of this series, the point is having fun with metaprogramming. Biicode is only to make easier share and run the library. I will give you an example: As I said in the post, I developed a metaprogramming library previously, Turbo. Turbo was originally developed and released using git/github. I was using Turbo in most of my personal projects, including it as a git submodule. And that was a pain. Imagine what happened when multiple projects, each one using Turbo, were included as deps in a bigger project. Having Turbo dependencies up to date was going crazy! When I started to use biicode, this never happened again, since it manages dependencies for you exactly as pip does in python. Going up with Turbo, adding features when needed in other (multiple) projects is a pleasure, compared to when I was using git submodules. 
And destructors.
&gt; Even if a function is just an utility, it’s better to add it in a class as static to group utilities by category. Isn't this what namespaces are for?
&gt; Namespaces were introduced to the C++ Standard in 1995 Uh, what? It's hard to call this "modern" C++ since it's all C++98. That's not a bad thing; I think C++98 is very powerful and (reasonably) well understood now. It's just not news.
Yes.
I didn't pay very much attention to that proposal, because tag dispatch isn't obnoxious for me.
What were the lessons learned?? Read the whole thing hoping to find one but all I found were some assertions as to what to use. Not even any reasons, and some of them certainly warranted some reasoning behind them because I couldn't think of any at all. Example: *"Even if a function is just an utility, it’s better to add it in a class as static to group utilities by category."* What the fucking fuck? Why?? This was a terrible article. Lessons learned would have been stuff like: * We found this made shit a lot easier... * We found this was unworkable and people didn't understand it... * We found this technique caused more overhead than we could justify in a device library... You know, some shit they learned using modern C++...not just a regurgitation of what they thought they learned modern C++ is.
Pretty much every construct in "modern" C++ was available since 98. There wasn't any boost::shared_ptr but you could have made one just fine and plenty of people made shit like it. Expression templates were discovered a long time ago. RAII also was well known ages ago. Seems to me that "modern" C++ is just using C++ the standard way because you're no longer afraid your compiler is implementing the language wrong. You're for example not avoiding namespaces because you compiler has no idea what they are (or are targeting a general audience that might use such a compiler). You can use exceptions if you want because you're confident everyone has a compiler that implements them in a non-stupid way. You can use templates because you're confident most uses won't crash the compiler. Shit like that. This is pretty new as far as the history of C++ goes. C++ has been around what, 30 years? The microsoft compiler stopped being total shit only 10 years ago...in fact, VC++ 2003 was really easy to break. The first actually good one was 2008 I think. I was crashing 2010 and making it generate bad code even then through use of things like MPL or even boost::signals2.
static members also don't get to join in on the ADL party.
No. That would not help with the case of having several optional arguments and only specifying the value of one or a few.
I've found that at least a recent release of clang does a decent job of helping you resolve issues when an overload isn't found. This is true of both tag dispatching and `enable_if` style removal. Compiler tells you no viable overload for `xxx`. It provides the arguments used. Here clang shines because in addition to saying something like `some_check&lt;int&gt;::type` it'll tell you what `type` was. Then it gives a list of options it tried. Granted, it's not the easiest thing in the world to figure out, but it's getting better. I don't recall if VC is any help here. What's harder to figure out is when the compiler resolves the WRONG function. Then you're sorta stuck going, "Why the fuck did it pick THAT?" IME this is harder to figure out with `enable_if` style code, let alone that kind of thing stuffed behind a bunch of macros. Even worse is when it *sometimes* picks the wrong overload. ADL can get you here. ~~I think pfultz2's last blog could be an example of this. The `begin` and `end` functions for fusion sequences only exist when particular headers are include, which is why his check on tuples appeared to function.~~ Actually that's not why. The reason is that ADL doesn't find the fusion versions, which are in the fusion namespace, for tuple because it's in the std namespace. So header inclusion wouldn't matter--only adding a using clause would have made the issue apparent. Here in the comments he also mentions that certain array classes have fusion wrappers so they can be both ranges and sequences (true)--if you included THAT header all sorts of shit could start going wrong. You would have to be very, very careful to keep them from stomping on each other. The other important quality to tag dispatching is that it's WAY easier to teach people. SFINAE is a rather crazy language feature that people find hard to understand. FFS *I* sometimes don't understand it and I'm apparently a member of the "advanced" illuminati (a sort of dude standing in the corner new-guy member). Overload resolution rules can be a bitch (see [here](https://crazycpp.wordpress.com/2011/03/28/name-resolution-and-overloading/) and [here](http://stackoverflow.com/questions/4704567/function-with-parameter-type-that-has-a-copy-constructor-with-non-const-ref-chos/4704741#4704741)) but the ways tag dispatching uses them are easy to understand.
&gt;To manage allocation, the oculus development team defines its reference counted class OVR::RefCountBase What's wrong with std::shared_ptr? 
Koenig seems like a guy that knows how to party too. Some of the shit he posts on facebook make me really want to hang out with him.
I assume that they're simply using an invasive smart pointer. If you're sure your class must always be in a shared pointer of some king this is actually a really nice option. There's no spare counter object floating about and you have control over how the reference is counted--can be a non-atomic for example if you aren't using threads. Shared_ptr is really for cases when the class could be used as a value, may not be shared, etc...and you don't want to have shared semantics on something where they're wasted (why have an int sticking around, taking up cache room, that's not being used if you put it in a unique_ptr for example). That and the counts can be hard to get right when you're not 100% sure the damn thing is being counted. Edit: in fact I just checked the article and this is what they say they're doing. They're also overriding the freestore I guess.
I agree. But in some cases size does matter. Which version of GCC are you using? I did a quick test on QNX 6.5, which uses GCC 4.4.2, using -O3 and stripping, gave the following results: 7164 bytes for the printf version and 16620 bytes for the cout version.
That is a terrible singleton implementation.
 window = new Window { xPosition = 10, yPosition = 20, width = 100, height = 50 }; Whats wrong with this?: window = new Window{Point{10, 20}, Dimension{100, 50}}; 
Many developers, specially in the game industry, avoid to do anything with the STL.
Shouldn't that be `printf(params)`, but even so a simple text substitution is fine in this case tbh. Also for OP: /r/badcode, /r/shittyprogramming
I agree that if you *require* a precondition, you should `assert` it, however I would prefer to minimise asserts by weakening the preconditions. This is in keeping with the rule of "be liberal in what you accept, strict in what you output". If I had to choose between assert ((x != 0) == (dx != 0)); if (x == 0) return 0; and if (x == 0 || dx == 0) return 0; I'd pick the second almost always, particularly if the function is part of the public API. The assert makes sense, for me, only if it is *absolutely essential* that `x` is `0` whenever `dx` is `0`, rather than "that's what it should be". Note also that Andrei's assertion has a subtle bug. The precondition is dx == 0 ==&gt; x == 0 while the assertion is that dx == 0 &lt;=&gt; x == 0
&gt; whether or not appending to a non empty vector is an error depends on the semantic of the populate function in the greater scheme of the program. I disagree. This is the error that the blog author is talking about. In the greater scheme of the program there's no error because nothing ever does it. It's a common but flawed view of software development, especially in the modern age where programs are HUGE and massively complex. Preconditions, postconditions, errors, etc... should all be based on the local semantics of the entity being created. 
I write a lot of Win32 and more abstract UI code, where something like Graphics::GetCurve(int degree, int nLevels, size_t someBullshit, float etc) are common, and sometimes I lose track of what exactly each parameter does in the 100th function I've dealt with that day. Named params would really help.
I'm guessing that's why work on D began. C++'s speed and hardware access with C#'s easy syntax.
The good thing (maybe the only good thing) about this solution is that the expressions passed to the "printf" function will not be evaluated. Is there any way to do that in C++ without macros? I can think of some lazy evaluation with lambdas but it would still require some cost (also, very ugly).
Is that because of performance?
Usually the two main reasons are performance and templates. Most game studios use C++ as a C with improved type safety, with limited use of anything C++. Check the game studio talks at this year's CppCon http://channel9.msdn.com/Events/CPP/C-PP-Con-2014/Data-Oriented-Design-and-C-P-P http://channel9.msdn.com/Events/CPP/C-PP-Con-2014/CPP-in-Huge-AAA-Games http://channel9.msdn.com/Events/CPP/C-PP-Con-2014/How-Ubisoft-Develops-Games-for-Multicore-Before-and-After-CPP11
&gt; "Even if a function is just an utility, it’s better to add it in a class as static to group utilities by category." Can only share your sentiment, especially since they mention that directly after namespaces. C++ classes are overkill for grouping functions, nested namespaces have all of the upsides and none of the downsides. 
The topic of the headline would have greatly interested me. I have my own ideas on what "modern c++" should result in, but I've not personally seen it in production. I've served instrumental roles in modernizing a few shops, but I've always ended up leaving for whatever reason before the real results became apparent. The one I spent the most time at I get rumors from time to time, and it sounds good, but what actually happens to a shop that uses and sticks with "modern" C++ techniques is something I've not seen. I've also not seen what really happens when a company that used "unmodern" C++ switches to "modern" C++. I've seen parts of it, and the in-fighting that happens between the old crew and the new crew, but the actual results...nope. So, some company adopting the practices and telling us what they learned from doing so would be of great interest to me. I left this article VERY disappointed.
Ohhhh.. I see. Thank you. I guess there's no excuse for this macro then :P
I would probably make it a global function and ifdef the internals, that way I step into it and it is easier to debug.
 #ifdef ACMEINC_JAKE_DEBUGPRINTF #define debugprintf printf #else #define debugprintf(...) #endif
EDIT: Hey guys, before you downvote some more: * I know macros are the way to go right now for a serious solution. * I'm using printf because the original problem uses printf * You guys need to lighten up and try new things sometimes. Just because you think something's going to be suboptimal doesn't mean you can't just have fun trying it. This is an exercise in programming silliness, not an optimal solution. &lt;3 ********************* ORIGINAL POST: The most efficient I can come up with in 3 seconds is: static const bool USE_DEBUG=true; //false template&lt; bool useDebug &gt; struct DebugPrintf; template&lt;&gt; struct DebugPrintf&lt;true&gt; { static int printf ( const char * format, ... ) { va_list args; va_start(format, args); int result = printf(format, args); va_end(args); return result; } }; template&lt;&gt; struct DebugPrintf&lt;false&gt; { inline static int printf ( const char * format, ... ) {} }; //... DebugPrintf&lt;USE_DEBUG&gt;::printf("some error"); (I may have used the variable list incorrectly, it's not a thing I'm familiar with. You should be able to get the idea though.) EDIT: Okay, I can totally simplify this with `std::enable_if`, if you have c++11. Not any more efficient, but cleaner static const bool USE_DEBUG=true; //false template&lt;bool test = USE_DEBUG, typename std::enable_if&lt;test&gt;::type * = nullptr&gt; int debugPrintf(const char * format, ...) { va_list args; va_start(format, args); int result = printf(format, args); va_end(args); return result; } template&lt;bool test = USE_DEBUG, typename std::enable_if&lt;!test&gt;::type * = nullptr&gt; inline int debugPrintf(const char * format, ...) {} //... debugPrintf("some error"); And, of course, the c++14 version would use `std::enable_if_t`.
Cool. I'm using something similar in one of my projects, and it works fine for me. But it would still evaluate (I believe) the expression inside the "print" function. That's what I thought the "//" in the macro would eliminate. My "solution" to avoid evaluation would be something like that: http://coliru.stacked-crooked.com/a/bf18eab4edec34e3 Can someone destroy my idea? :) *Edit: Better example.
GCC 4.9.2 (latest) gives me 5.6K for the printf version and 6.8K for the cout version. Compiled as g++ -O3 -s main.cpp
Ah I see what you're saying. You're right, my version would still evaluate the arguments, where as a normal macro wouldn't. (as a small aside, it reminds me of how many release-mode bugs I've written where I've absentmindedly done `assert(something_critical())`) Yours still has a the performance impact of constructing the lambda (assuming the compiler doesn't optimize it away), but you're right, it doesn't do the thing inside of it unless debug mode. Is there a reason I'm missing you chose to use a variant instead of function overloading? template &lt;&gt; struct Log&lt;true&gt; { static void print_int(FuncInt f) { cout &lt;&lt; f() &lt;&lt; endl; }; static void print_int(int i) { cout &lt;&lt; i &lt;&lt; endl; }; }; ********** Overall though, I think macros are still probably the way to go. Yes, I know they're "evil", and should be avoided whenever possible, but sometimes, they're still the best tool for the job :-)
&gt; Is there a reason I'm missing you chose to use a variant instead of function overloading? Your solution is better for this example. I just used "boost::variant" because that is what I would use for a more complete solution. Like passing a "std::initializer_list&lt;MyVariant&gt;" to "print", where "MyVariant" is a variant that I could use to create a heterogeneous list. * but taking an extra 30 seconds to think about it, it may be bad design because would make it hard to extend the solution.
Okay, I deleted my last comment because it was dumb. For extensibility, I would probably just throw the single interface out the window and do this: http://coliru.stacked-crooked.com/a/540d6beef7c2aa84 There's no way to do a single interface this way as far as I can tell since there is probably no way to distinguish between a function object which you want to execute and some other object with an `operator()` that you just want to print out...so we have to specifically distinguish with different function names. Not the end of the world since the caller has to know the difference anyway
&gt; inline static int printf ( const char * format, ... ) {} Redundant use of inline. Also, why bother using templates in this case? It doesn't give you any further safety and the preprocessor solution is a lot easier to implement imho.
Nice, this looks better than my approach. But, one can always use a system breaking alternative: http://coliru.stacked-crooked.com/a/5857b46d59746189 I'm pretty sure that is one reason why Haskellers hate cpp :P And it still only viable if lambdas are free.
With variadic macro parameters: #ifdef ACMEINC_JAKE_DEBUGPRINTF #define debugprintf(...) fprintf(stderr, __VA_ARGS__) #else #define debugprintf(...) {} #endif 
&gt; How can that happen? Either you can compute a tag, or you cannot. The problem is you don't exactly know why the computed tag failed, just that it didn't compute the tag. In some cases it is obvious, in other cases it is not. Is it an error in the metaprogramming logic? Or is it an an error by the user? &gt; With concepts lite we'll get that. With C++11/14 emulations of concept lite, the error you get is still IMO a mess when compared to a tag dispatching error. Just as a comparison. If I give a wrong type to the tag dispatching overloads in post here, I get this: overloading.cpp:30:58: error: no type named 'iterator_category' in 'std::__1::iterator_traits&lt;int&gt;' using tag = typename std::iterator_traits&lt;Iterator&gt;::iterator_category; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~ overloading.cpp:39:15: note: in instantiation of function template specialization 'advance&lt;int&gt;' requested here auto it = advance(1, 1); ^ overloading.cpp:32:5: error: static_assert failed "Can only advance ForwardIterators and their refinements." static_assert(std::is_base_of&lt;std::input_iterator_tag, tag&gt;::value, "Can only advance ForwardIterators and their refinements."); ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ overloading.cpp:34:12: error: no matching function for call to 'advance' return detail_::advance(it, n, tag{}); ^~~~~~~~~~~~~~~~ overloading.cpp:10:17: note: candidate function [with ForwardIterator = int] not viable: no known conversion from 'tag' (aka 'int') to 'std::forward_iterator_tag' for 3rd argument ForwardIterator advance(ForwardIterator it, int n, std::forward_iterator_tag) ^ overloading.cpp:19:22: note: candidate function [with RandomAccessIterator = int] not viable: no known conversion from 'tag' (aka 'int') to 'std::random_access_iterator_tag' for 3rd argument RandomAccessIterator advance(RandomAccessIterator it, int n, std::random_access_iterator_tag) ^ This is not bad. Just that all of the errors point inside of the function, but the note to function is first one. Of course, this can easily be fixed by adding an `enable_if` to the function. When using the conditional overloaded version, I get an error like this: overloading-1.cpp:227:5: error: no matching function for call to object of type 'const fit::detail::static_function_wrapper&lt;fit::conditional_adaptor&lt;&lt;lambda at overloading-1.cpp:179:5&gt;, &lt;lambda at overloading-1.cpp:183:5&gt;, &lt;lambda at overloading-1.cpp:192:5&gt; &gt; &gt;' advance(foo(), 1); ^~~~~~~ ../../../github/Fit/fit/function.h:62:10: note: candidate template ignored: substitution failure [with Ts = &lt;foo, int&gt;]: no matching function for call to object of type 'const fit::conditional_adaptor&lt;&lt;lambda at overloading-1.cpp:179:5&gt;, &lt;lambda at overloading-1.cpp:183:5&gt;, &lt;lambda at overloading-1.cpp:192:5&gt; &gt;' auto operator()(Ts&amp;&amp;... xs) const FIT_RETURNS ^ This is someways shorter(except the function object type is longer). The error points directly to the user code, which makes it clear, the error is in the way they are calling the function. However, it doesn't give much info to the user why the function can't be called. So Fit provides the `reveal` adaptor that will dig up these functions, and produce these errors: In file included from overloading-1.cpp:6: In file included from ../../../github/Fit/fit/lambda.h:29: In file included from ../../../github/Fit/fit/function.h:44: ../../../github/Fit/fit/reveal.h:74:26: error: no matching function for call to object of type '&lt;lambda at overloading-1.cpp:179:5&gt;' typedef decltype(std::declval&lt;F&gt;()(std::declval&lt;Ts&gt;()...)) type; ^~~~~~~~~~~~~~~~~ ../../../github/Fit/fit/reveal.h:80:8: note: in instantiation of member function 'fit::detail::failure_check&lt;&lt;lambda at overloading-1.cpp:179:5&gt; (foo &amp;&amp;, int &amp;&amp;)&gt;::check' requested here struct failures ^ overloading-1.cpp:228:25: note: in instantiation of function template specialization 'fit::reveal_adaptor&lt;fit::detail::static_function_wrapper&lt;fit::conditional_adaptor&lt;&lt;lambda at overloading-1.cpp:179:5&gt;, &lt;lambda at overloading-1.cpp:183:5&gt;, &lt;lambda at overloading-1.cpp:192:5&gt; &gt; &gt; &gt;::operator()&lt;foo, int&gt;' requested here fit::reveal(advance)(foo(), 1); ^ overloading-1.cpp:179:25: note: candidate template ignored: disabled by 'enable_if' [with $auto-0-0 = foo] [](auto&amp; it, int n, TICK_PARAM_REQUIRES(tick::trait&lt;is_advanceable&gt;(it, n))) ^ ../../../github/Tick/tick/requires.h:62:5: note: expanded from macro 'TICK_PARAM_REQUIRES' (tick::detail::param_extract&lt;decltype(__VA_ARGS__)&gt;::value), \ ^ In file included from overloading-1.cpp:6: In file included from ../../../github/Fit/fit/lambda.h:29: In file included from ../../../github/Fit/fit/function.h:44: ../../../github/Fit/fit/reveal.h:74:26: error: no matching function for call to object of type '&lt;lambda at overloading-1.cpp:183:5&gt;' typedef decltype(std::declval&lt;F&gt;()(std::declval&lt;Ts&gt;()...)) type; ^~~~~~~~~~~~~~~~~ ../../../github/Fit/fit/reveal.h:80:8: note: in instantiation of member function 'fit::detail::failure_check&lt;&lt;lambda at overloading-1.cpp:183:5&gt; (foo &amp;&amp;, int &amp;&amp;)&gt;::check' requested here struct failures ^ overloading-1.cpp:228:25: note: in instantiation of function template specialization 'fit::reveal_adaptor&lt;fit::detail::static_function_wrapper&lt;fit::conditional_adaptor&lt;&lt;lambda at overloading-1.cpp:179:5&gt;, &lt;lambda at overloading-1.cpp:183:5&gt;, &lt;lambda at overloading-1.cpp:192:5&gt; &gt; &gt; &gt;::operator()&lt;foo, int&gt;' requested here fit::reveal(advance)(foo(), 1); ^ overloading-1.cpp:183:25: note: candidate template ignored: disabled by 'enable_if' [with $auto-0-0 = foo] [](auto&amp; it, int n, TICK_PARAM_REQUIRES(tick::trait&lt;is_decrementable&gt;(it))) ^ ../../../github/Tick/tick/requires.h:62:5: note: expanded from macro 'TICK_PARAM_REQUIRES' (tick::detail::param_extract&lt;decltype(__VA_ARGS__)&gt;::value), \ ^ In file included from overloading-1.cpp:6: In file included from ../../../github/Fit/fit/lambda.h:29: In file included from ../../../github/Fit/fit/function.h:44: ../../../github/Fit/fit/reveal.h:74:26: error: no matching function for call to object of type 'fit::conditional_adaptor&lt;&lt;lambda at overloading-1.cpp:192:5&gt;&gt;' typedef decltype(std::declval&lt;F&gt;()(std::declval&lt;Ts&gt;()...)) type; ^~~~~~~~~~~~~~~~~ ../../../github/Fit/fit/reveal.h:80:8: note: in instantiation of member function 'fit::detail::failure_check&lt;fit::conditional_adaptor&lt;&lt;lambda at overloading-1.cpp:192:5&gt;&gt; (foo &amp;&amp;, int &amp;&amp;)&gt;::check' requested here struct failures ^ overloading-1.cpp:228:25: note: in instantiation of function template specialization 'fit::reveal_adaptor&lt;fit::detail::static_function_wrapper&lt;fit::conditional_adaptor&lt;&lt;lambda at overloading-1.cpp:179:5&gt;, &lt;lambda at overloading-1.cpp:183:5&gt;, &lt;lambda at overloading-1.cpp:192:5&gt; &gt; &gt; &gt;::operator()&lt;foo, int&gt;' requested here fit::reveal(advance)(foo(), 1); ^ overloading-1.cpp:192:25: note: candidate template ignored: disabled by 'enable_if' [with $auto-0-0 = foo] [](auto&amp; it, int n, TICK_PARAM_REQUIRES(tick::trait&lt;is_incrementable&gt;(it))) ^ ../../../github/Tick/tick/requires.h:62:5: note: expanded from macro 'TICK_PARAM_REQUIRES' (tick::detail::param_extract&lt;decltype(__VA_ARGS__)&gt;::value), \ ^ So there are 3 errors for the 3 overloads that can't be called. And there is a note why it can't be called. The only thing is each error is little more verbose than the tag dispatching errors, and the reason for not being able to be called is the third note. I would like to find a way to produce terser errors for this. &gt; Clang, e.g., will still try to compile your code after the error, which can result in pages of errors inside the function that the user just shouldn't see. Are you referring to SFINAE? Because on Clang, GCC, and MSVC, the compiler does not keep on compiling the function when there is a substitution failure. That is the advantage of using `enable_if` over `static_assert`.
It *may* be. That's a fairly personal decision someone will have to make. I recently decided to drop out of my program. I wouldn't go recommended it to everyone else, some people learn better in a school environment. On top of that, I think a lot of CS people could really do with a college experience - social skills can be very lacking in this field, and college can help.
&gt; Pretty much every construct in "modern" C++ was available since 98. :-o Move semantics? `auto`? Smart pointers that actually work right (don't tell me you could just build one - `std::unique_ptr` would be impossible without move semantics, and `std::auto_ptr` was critically flawed)? Lambdas? `std::function`? (I thought those were just fanciness until I started to use them - with lambdas they give you amazing capabilities to do all sorts of things that before would have been done with inheritance, badly - like mix-ins.)
&gt; There's no spare counter object floating about `std::shared_ptr` does this fine with `std::enable_shared_from_this`. &gt; and you have control over how the reference is counted--can be a non-atomic for example if you aren't using threads. This is true but my guess is that the Oculus is a heavily-threaded system by its very nature. &gt; That and the counts can be hard to get right when you're not 100% sure the damn thing is being counted. I don't quite understand what you're talking about - when does `std::shared_ptr` get the counts wrong? How is the Oculus' counting strategy at all different?
Singletons are often a terrible idea, so it's a match made in heaven. :-)
I guess you misunderstood me. That isn't my opinion, I was just stressing was the usual argument is. Just check the videos. I fully agree with you. Actually since the mid 00's I only use C++ on the side, as my employer decided to focus on other languages. However on those side projects I use what is nowadays known as modern C++. I was pretty dismayed to see still so much CppCon talks arguing just for better C dialect. 
IIRC Oculus has a C API, so the ability to ref/unref a pointer directly would make the glue code simpler.
Thanks for the preview / review in this post &amp; the previous... I would have had the same expectations as you, based on the title. I'm not sure I'll pass on reading the article now, but I might back-burner it. I've been involved in similar situations (trying to modernize / improve legacy C++ code), only in my case, sometimes it's just bringing up to best practices pre-C++11 (essentially C++03). All of the platforms I work on are deeply embedded systems, and C++11 compilers aren't always even available. But there is still plenty of ground to plow... for example, lots of naked pointers flying around, no use of RAII, lots of crazy macros when templates would be superior, etc. That said, I'd like to know what the costs/benefits/sticky points/victories/defeats/interesting facts are when moving to C++11/14, even if anecdotal... sigh...
Until someone writes a multiline call to debugprintf.....
I agree. Named arguments were discussed by the committee before and were rejected. The reasoning was that they encourage functions with lots of parameters, which is bad. I'm inclined to agree with the committee on this.
Not in C++ :/ (afaik) Edit: In C++ actually, _and_ supported by visual (must have been just my earlier bad experience with complier support).
http://stackoverflow.com/a/4786671
I recommend trying to avoid asserts. Having code that has different observable control flow in debug &amp; release is a bad idea. I strongly prefer to use unconditional exceptions. if (!(some condition)) { throw std::logic_error{"this is wrong"} } Which can be wrapped into something like: Preconditions::checkState(x != 0 &amp;&amp; dx != 0, "We don't allow this becase ... x = ", x, ", dx = ", dx); Which will also include the values into the exception message. It's readable at the callsite, you'll never forget the assertion is there &amp; you can write the rest of the code more simply (i.e. no defensive programming). Moreover, you can write negative unit tests to exercise the behaviour of this codepath, whereas assert, even if always enabled, just calls out to abort immediately which is untestable &amp; non-composable.
You're optimizing for the wrong case. 99% of the time, the cost of the check is cheap &amp; unnoticeable (at least if done correctly). Add in a __builtin_expect if you're super nervous. If you do have a loop &amp; profiling indicates the cost of the check is expensive, you can always provide a fast-path where you guarantee the check has been made - it's OK to assert there. However, in the default case, throwing/aborting unconditionally is the far better behaviour.
The problem with all the alternatives recommended (&amp; the original code) is that there's no preservation of the original code. This means that a piece of code will potentially compile in release but not in debug. What you actually want: #ifdef ACMEINC_JAKE_DEBUGPRINTF #define debugprintf(...) printf(__VA_ARGS__) #else #define debugprintf(...) do { if (0) printf(__VA_ARGS__); } while(0) #endif 
Normally you would want `##__VA_ARGS__`, for the 0-argument case, except that in this case it doesn't matter. The other thing, in the non-debug case, you want to still keep the original expression (but protect it with an if(0)). If someone where to do: debugprintf(56); it would break debug builds which you might not find until later.
&gt;&gt; There's no spare counter object floating about &gt; std::shared_ptr does this fine with std::enable_shared_from_this. I think you may have misunderstood what enable_shared_from_this really is. The correct answer is use make_shared. The counter is then placed directly beside what you are allocating.
What if you have a function like this: doit(bool cond1, bool cond2, bool cond3). or doit(int value1, int value2) The normal workaround is to use `enum classes` which are great (if verbose). However, it ignores the maintenance aspect (i.e. existing code). Being able to fix up call-sites as you encounter them would ease the maintenance burden. Also, don't forget interop with C functions and existing libraries that you can't modify.
 Graphics::getCurve(degree deg, level lev, ...
If you keep reading down the comments you'll note that wrapping it in a lambda is what we came up with.
I was using printf because the original problem used printf. If I was writing this myself, I would probably use macros to begin with, and then use streams not printf. Given that I was using printf, I was simply duping printf's parameters so as to pass them as unmolested as possible.
Could we have a discussion in this sub where /u/Crazy__Eddie and /u/pfultz2 don't have a pissing match?
&gt; What? An invasive pointer by definition puts counter in your object regardless of where it lives. Yes, you understood correctly. That is what I was saying.
Move semantics can be faked pretty well in C++03 (see boost.move). `std::function` doesn't depend on any c++11 functions (and in fact *significantly* predates it, as `boost::function` and `std::tr1::function`).
...Yes, I know how parameter packs work. I was attempting to simply mimic printf's signature to be as clear as possible what was going on there. As I just mentioned, if I was actually writing this I would have done it completely differently anyway.
How's va_crap clearer than a simple parameter expansion?
You seem to making a very big deal of something that isn't one. The first error message contains a note indicating exactly where the user made the invalid call: overloading.cpp:39:15: note: in instantiation of function template specialization 'advance&lt;int&gt;' requested here auto it = advance(1, 1); Your second example gives no useful information at all, which you admit, but for all the additional vomit you created in the third, it's not really providing any added value over the first. In all three cases a greenhorn is going to need some training to read. Someone that knows what `iterator_traits` is and what it's for will fairly quickly note, "Oh shit, I passed something into a function expecting an iterator that wasn't an iterator." And then there's this: overloading-1.cpp:192:25: note: candidate template ignored: disabled by 'enable_if' [with $auto-0-0 = foo] [](auto&amp; it, int n, TICK_PARAM_REQUIRES(tick::trait&lt;is_incrementable&gt;(it))) I can totally imagine some frustrated newb screaming at the monitor now, "WHAT THE FUCK YOU MEAN `int` ISN'T INCREMENTABLE???" In fact, none of those errors actually indicate what the real problem is. The first example could probably be improved. Add static_assert or an enable_if blocker that checks if the incoming iterator actually is an iterator before proceeding. Obviously you could do this also but at that point you've needed to add the "boilerplate" function you seem to hate so much. Either that or implement some base, entry check in your fit::conditional construct. And of course if you changed the names of your construct to introduce more clarity it would fix some of this. Change `is_incremental` to `is_incremental_iterator` for example. This type of thing I think is just way, way more important than the rest of this stuff. I don't know man. I am just not seeing any of the benefits you are. Your version is massively more complex, making it more likely something is going to go wrong, making it harder for people to understand, taking longer to compile most likely, etc... Cute as it is seeing the concept in the error message, it's just not giving the information one would really need to fix the problem: please pass this function an iterator not some other dumb thing. This is actually I think paramount to the discussion. All the messages you've generated would perhaps help the author of the function figure out why the hell it's not working on iterators, but they're not really relevant to the function's clients. By the time it gets to them it should work and the only important part is that they pass in an iterator. If they do then all that other crap should just work...if it doesn't there's a bug in the function (or the concept library, or the macros...you really have introduced a lot of shit to go wrong here). If they don't do you really think it helps them to know that they're not matching the various sub-concepts? I don't. Then it also requires that I code in this ungainly macro language, which does simplify the task but it's still painful to look at...I'm not at all afraid of macros but I'd hate using this syntax. And you say that your version errors out at the call site but I'm not even seeing it in that third vomit listing. Nothing seems to say, "Because you passed a bad argument in the call you made here." Where is that line? Is listing 3 an extension of listing 2? That's the only way your claim makes any sense to me. I guess it could just be that I've been doing this for several years and am quite used to the first listing...but it seems quite clear to me and your alternatives really don't. I find myself wondering how the hell you can see that as clearer. I look at it and say, "Yeah, clear as mud." Even just the formatting of the first error message, that's really possible due to the simplicity of the function, makes it way easier for me to read. Yeah, I really don't see it. I just don't.
Performance ? Unless this would be happening hundreds of thousands of times a second it is an non issue.
Wrong is a strong word. In my experience, there is no right and wrong, only constraints that you try to optimize against. You can optimize for anything that's optimizable; performance, safety, etc, but there's always a cost to it. In this case, the cost is performance and possibly software maintenance because it harder to understand error handling than a simple assert. Depending on where this code lives in a software stack, that may or may not be appropriate. That being said, I do agree that generally it's better to not optimize for performance until one needs to, and in that case, provide a fast path.
&gt; Performance ? Unless this would be happening hundreds of thousands of times a second it is an non issue. That's what computers do. Lots of stuff, really fast. 
&gt; Normally you would want `##__VA_ARGS__`, for the 0-argument case Unfortunately, it depends on the compiler. MSVC doesn't want the `##` there and automatically removes a comma before an empty `__VA_ARGS__` instead. I believe LLVM goes both ways on this issue. EDIT: After testing, everybody seems happy with `##` in there. GCC and Clang by default require it. Regardless, it's non-standard.
+1 for `do...while(0)`
Clang follows GCC on this AFAIK.
I have been fooling around with allocators and memory pools for the last couple of weeks. My most recent experiment turned out to reveal std allocation patterns. I thought this was interesting so I decided to brush it up a little and share it here. 
#ifdef ACMEINC_JAKE_DEBUGPRINTF # define debugprintf printf #else # define debugprintf(a, ...) #endif
dynamic libraries with C++ interfaces can suck due to undefined ABI. same compiler version must be used for application and library/plugin. and of course 32/64bit must match. not a big deal with open source but can be a huge pain in the ass when either is closed source. zeromq was written in C++, exposed a C interface, and then distributed with a header-only C++ wrapper. lol. interprocess communication fixes these problems but makes everything more complicated.
I was trying to find documentation on this and then I realized that I have clang installed... You are correct: Clang 3.4.1 follows GCC by default. But with `-fms-compatibility` it takes either syntax. And actually, MSVC takes either syntax...
Could a modern attempt do COM+/XPCOM "right"? 
You may be interested in an implementation of [polymorphic memory resources](http://en.cppreference.com/w/cpp/header/experimental/memory_resource), and [an implementation of an entire standard library which uses them](https://github.com/bloomberg/bde). In the BDE library, a `memory_resource` is a `bslma::Allocator`. The interesting part about a *pmr* (polymorphic memory resource) is that the concern of allocating memory is divorced from the concern of providing space/time guarantees about storing objects. In the traditional STL, both of those concerns are tied together in the type of the container. btw, I'm a huge fan of 'coliru', it's way better than 'codepad' for example.
I think a modern attempt will definitely be much better. One of the things I see is auto generating the "messaging", and registering of properties by parsing the c++ class and then generating the appropriate C api and etc.. all automatically. One issue though once this is done adoption will be very slow as existing XPCOM implementations is very widely used. Especially that there is an already large existing code base. A modern implementation will need to respect that, which unfortunately force non-modern design decisions. In regards to doing it "right", I think there needs to be more people to experiment with different ways of potentially doing it "right", then we can filter out all the good ideas, and implement COM/XPCOM very "right". 
NSXPC is really slick but of course it's Objective-C based. For pure portable C++, Cap'N'Proto is shaping up very nicely. 
Very nice post. Btw, it seems like you forgot to delete the module objects. Shows that it would be safer to use unique_ptr. 
I'd prefer the hourglass interface approach. It was posted on reddit [here](http://www.reddit.com/r/cpp/comments/2mx1mm/hourglass_interfaces_for_c_apis/) . Slideshare link [here](http://www.slideshare.net/StefanusDuToit/cpp-con-2014-hourglass-interfaces-for-c-apis).
Thank you very much! You're right, I'll fix sample code as soon as possible. I always try to use modern C++ facilities, but in this post I wanted to use only things which we know from C++03. I'm going to present more professional application in second part of article.
If the new standard introduces something like this, I'd be happy: int a = 1; float b = 2; char c = '3'; auto result = foo(name1:a, name2:b, name3:c);
This is an interesting project. Does it support multiple concurrent reader?
Yes indeed ! it is possible when you create a ReaderUnit per Reader. (ReaderUnit is the engine that will connect to a reader, wait a card and after it will provide you the chip detected)
It takes a while to get interesting but eventually he starts talking about some of the technical items in his book which is interesting.
Interesting question. I did a little comparison here: http://coliru.stacked-crooked.com/a/3699225d0cc5def9 Apparently libc++'s std::set only requires 32 bytes per node (which I assume means 3 pointers (parent node and two child nodes) plus the padded `int` value). I wonder why stdlibc++ requires 40 bytes. Also libc++'s std::deque seems to allocate larger chunks. Which I like.
I wrote a little bit about it being caused by proper implementation (IIRC std containers cannot rely on their allocators returning aligned memory (even though its stupid) and as such cannot steal lowest bit of a pointer for the bookkeeping) but then I remembered that 3*8 (ptrs) + 4(int) + 1(bool) &lt; 32 so... no idea, have to read implementation I guess. :-) Also you should add whether deque resizes allocation chunks based on size of T, or whether it always allocates max(constant, sizeof(T)). (I could test it for myself, but if you do it, it will be kept for posterity. ;-) )
[Here I use a sizeof(T) = 5000.](http://coliru.stacked-crooked.com/a/db827eff1aa49558) GCC allocates 5000-byte chunks. Clang allocates chunks of 80000 bytes (which is `16 * sizeof(T)`).
Good to know :)
So basically libc++ deque is sane, unlike libstdc++ or MSVC++ deque. (Both of which just start allocating per item for large items)
Why would I use biicode instead of just cmake? I have started my first "bigger" c++ project yesterday which uses 5 external libraries and the cmake file is only 15 lines of code at the moment. It also cross-platform, downloads and builds the source automatically. To be fair it took me around 5 hours to figure everything out. 
I would be fine with that as well. It's one of the nicer features in Swift. 
A dependency manager installs missing libraries for you, so that cmake can then find and use those libraries.
I love his talks. Always informative and super funny (like [why C++ sails when the Vasa sank](https://www.youtube.com/watch?v=ltCgzYcpFUI).)
Having looked at the code of libc++ a number, I can say that Howard Hinnant has taken a lot of care about minimizing memory usage. In numerous places the attributes have been carefully ordered to minimize padding and whenever possible the Empty Base Optimization has been leverage so that "empty" types take 0 bytes (such as in the `__compressed_pair`). As such, it is no surprise to me that libc++ only allocates 32 bytes here, but it does surprise me that libstdc++ allocates 40 bytes.
Scott Meyers is the best. I eagerly await the release of the Scott Meyers Anthology on Blu-ray.
You could make a good argument that the structure should be filled out in order of its members. Much like member initialization as part constructors. /u/F-J-W: The reason that ordered argument evaluation is undefined is to permit C to be adapted to the system's native calling convention, which is important when you're linking to system libraries. 
Huh. Nutty.
Blocks are hosted on biicode servers, and they are maintained by the users that published them. It is basically the same idea as some other languages deps managers, they host a copy of the code. We at biicode upload and maintain some of the blocks too. BBDD is actually DBs, thanks for noticing the typo. About versioning, very recently we introduced version tags, that allow to match biicode versions (incremental integers) to original release versions. So in the new biicode.conf file, it could be written: [requirements] erincatto/box2d @2.3 If the uploaded code had used the version tag. But some code that is now in biicode was published before version tags were introduced, so they are missing until new versions are updated with them. The unresolved dependencies means headers that biicode is not aware of. We can check typical headers as "stdio.h" or "iostream", and also headers corresponding to code that is in biicode. Any other headers that you might have installed in your system, biicode marks them as "unresolved". That doesnt mean that it will not work. Everything will work as always if those headers are there, but biicode will not manage them. Thanks bitplonk for the feedback, really helps, will try to improve site and explanations.
https://bugzilla.redhat.com/
Try using pointers to the base class instead of the class itself. 
thanks, I'll test 'er out and report back cap
Retuning deque is on my todo list, but we didn't have time for 2015, sorry.
you mind elaborating a little please?
It's a space-time tradeoff. VC uses 1.5x, which is somewhat more space-conservative but definitely reallocates more frequently. I don't think the theoretical considerations about 2x being unable to reuse blocks ever really matter in practice.
A `map&lt;string, Base *&gt;` where you say `m["meow"] = new Derived(args);` is bad because you're virtually guaranteeing that you'll leak memory. A `map&lt;string, shared_ptr&lt;Base&gt;&gt;` where you say `m["meow"] = make_shared&lt;Derived&gt;(args);` is structurally unable to leak. The trick to C++ programming is writing your code so that whole classes of bugs are simply impossible, and any remaining potential bugs are as obvious in the source code as possible.
Why so much arrogance ?
thanks much
Can biicode install dependencies purely for local consumption without interfering with or affecting global state e.g. another project on same server using a different version of boost - built in parallel. I also need an offline mode where I use a local 'repository' whether git-based or chocolatey or another
Polymorphism in C++ always has to be implemented with pointers or references.
+1: Qt is most probably the best choice.
Sounds like what you need is Qt. Check it out! 
This "C++ Inheritance Problem" is called slicing. Take a look: http://stackoverflow.com/questions/274626/what-is-object-slicing
&gt; I did some quick compile timing tests (all using eight jobs only to make sure the build wasn't IO constrained). If he was trying to avoid IO bottlenecks, why would he even use parallel jobs at all?
You need qt. The package has tons of examples 
metaFFT ------- Template based C++11 Fast-Fourier-Transform implementation. Idea: * Completely unroll all loops at compile time with the help of templates. * Calculate all numerical constants at complile time by using 'constexpr'. * Use policies for different implementations (complex, Fortran like C, SIMD). Speed: Simple Cooley–Tukey/radix-2 implementation with about 100 lines of code is 'only' same factors slower than FFTW: $ ./bin/radix2_sse2_speed N = 2^ 2 = 4: FFTW/metaFFT = 1.1 N = 2^ 3 = 8: FFTW/metaFFT = 1.2 N = 2^ 4 = 16: FFTW/metaFFT = 1.5 N = 2^ 5 = 32: FFTW/metaFFT = 1.7 N = 2^ 6 = 64: FFTW/metaFFT = 2.0 N = 2^ 7 = 128: FFTW/metaFFT = 2.0 N = 2^ 8 = 256: FFTW/metaFFT = 2.3 N = 2^ 9 = 512: FFTW/metaFFT = 2.8 N = 2^10 = 1024: FFTW/metaFFT = 3.2 N = 2^11 = 2048: FFTW/metaFFT = 3.3 N = 2^12 = 4096: FFTW/metaFFT = 3.4 Build: * CMake based * pass -Dlarge=1 to enable large FFTs, this will stress your compiler! License: * GPL2 with linking exemption. Links: * http://anthonix.com/ffts * http://nr.com * http://www.drdobbs.com/cpp/a-simple-and-efficient-fft-implementatio/199500857 
temporary objects in function calls used to compute the return value are afaik rvalues or at least turn into rvalues when the function returns. It's a common example from Bjarne Stroustroup himself. struct Vector { float x, y, z; Vector operator+(const Vector &amp;other) const { Vector ret; ret.x = x + other.x; ret.y = y + other.y; ret.z = z + other.z; return ret; //ret is moved out } } Bjaren Stroustroup has a similar example in his [Five Popular Myths about C++ (Part 2)](https://isocpp.org/blog/2014/12/myths-2) Article under the point *4.1 Transferring Ownership: move*.
could someone please elaborate the remark about emplace_back not respecting explicitness to me? Afaik "explicit" is designed to prevent implicit conversion. But in the case of emplace_back, there is no conversion happening. I guess you could interpret emplace_back as converting a pack of parameters to a object of type T and in the case of a single argument it really looks a lot like a conversion. But still, emplace_back explicitly calls the constructor so no conversion is happening here. Is there something that I'm missing here or is it just that under the hood what is really happening is close enough to an actual conversion that you could consider emplace_back a hack that ships around the explicit keyword?
I'm not sure if you're joking or not because this is both a common attitude and also the single biggest cause of bugs in my experience. I would not allow code like this to pass code review for several reasons, but the biggest is that it will cause hard to find bugs. 
Slides: http://stellar.cct.lsu.edu/pubs/Plain_Threads_are_the_GOTO_of_Todays_Computing_MeetingCpp_2014.pdf
If you know Excel you can use https://xll.codeplex.com to hook up C++. See http://xllblog.com for what I'm up to with the latest version and other random musings. Feedback welcome. Excel is not the greatest tool for graphics but it will get you up and running quickly.
Original is http://www.viva64.com/en/b/0280/ which I believe makes this a repost.
Do you have a plot showing a performance comparison of your library vs. FFTW? As someone who writes a lot of image modeling/image processing, a faster FFT is always of interest!
No, I only calculate the relation of the measured GFLOPS. It' s the number FFTW/metaFFT in the Readme.
The part where he says that a kernel running on the GPU being one thread (and basically just SIMD) is not really true, an individual "thread" on the GPU may sometimes have its own PC per-thread, sometimes not. Oftentimes it's organized so that one "warp" or "wavefront" of thread shares one PC, so that each individual member of the wavefront does not have its own PC, but each wavefront group does. This also depends on whether the GPU architecture used is ILP-based or TLP-based (like ARMs midgard architecture where every thread always has its own PC) but in general it is up to the implementation to do whatever.
I see that performance is always faster, sometimes up to three and a half times as fast as FFTW So... why not just contribute your code to FFTW so that they can improve their stuff? That way people using FFTW can still get the fastest fourier transforms in the west on platforms where your code works, and still get the fastest fourier transforms in the west on platforms where your code doesn't.
Looking at listing one in the drdobbs link, it looks like you compute roots of unity on-the-fly. Have you thought about pre-processing them?
No, the ratio is the other way around.
Not sure what you mean with on-the-fly. But all the variables declared as 'constexpr' are calculations done at compile-time, so there is no calculation done at runtime for these values.
There are unfortunately only 2 talks on their [youtube page](https://www.youtube.com/user/MeetingCPP/videos) so far. I sure hope they'll post [more](http://meetingcpp.com/index.php/schedule14.html).
Yes, FFTW is always faster. But this is no surprise for the most-simple FFT algorithm (radix-2). But there is a lot of room for optimizations: * split-radix is faster, but SIMD is missing * FFTW uses avx which is not implemented * specializations for small FFT would also help a lot
Cool, that's good to hear. Great job by the way. I'll certainly be staying tuned for updates.
&gt; Completely unroll all loops at compile time with the help of templates. That sounds really interesting. Would you know of any links that explain how it's done?
Well, maybe you should read the post first... Talks are coming by January. Keynotes are up already, also you'll find at the channel the interview with Scott Meyers and Hartmut Kaiser. Slides are up since yesterday evening.
Learn about [slicing](http://en.wikipedia.org/wiki/Object_slicing). Student, huh? Persevere! 😉
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Object slicing**](https://en.wikipedia.org/wiki/Object%20slicing): [](#sfw) --- &gt;In [object-oriented programming](https://en.wikipedia.org/wiki/Object-oriented_programming), a subclass typically extends its superclass by defining additional member variables. If a superclass instance is assigned its value from a subclass instance, member variables defined in the subclass cannot be copied, since the superclass has no place to store them. This is a natural and unavoidable consequence of assignment by value from subclass objects. The term *object slicing* is sometimes used to refer to this aspect of assignment by value to a superclass instance. &gt; --- ^Interesting: [^Chop ^Chop ^Slicer](https://en.wikipedia.org/wiki/Chop_Chop_Slicer) ^| [^Cross ^section ^\(geometry)](https://en.wikipedia.org/wiki/Cross_section_\(geometry\)) ^| [^Backlash ^\(Marc ^Slayton)](https://en.wikipedia.org/wiki/Backlash_\(Marc_Slayton\)) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cmzvv36) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cmzvv36)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
It sounds like you need to use a templated map class. ~~map&lt;string,Base Class&gt;~~ something like: map&lt;string, typename T&gt; I think the problem might be that you're telling the map class that it will be using an object of type BaseClass, so even though you're giving it a derived type (child#) with its own implementation, it typecasts the child# type to a BaseClass type and uses that print function. Using a templated map class will allow the program to use the print function that is specific to the derived class you pass it. edit: as /u/hcspel mentioned, this is called object slicing and is a common problem.
Ah, ok, I see! That's an interesting way to deal with computing the roots of unity. Nice.
Great stuff, nice to have the presentations up. One funny thing: all but one of the slides were in PDF. The only PPT file gave an error "PowerPoint found unreadable content in Presentation.pptx. Do you want to recover the contects of this presentation? If you trust the source of this presentation, click Yes." The topic of that talk: "When dependency hell freezes over". Had me chuckle. 
Thanks for noticing. I have to convert that to pdf and reupload it.
I think everything from isocpp.org is.
Honestly, who the hell programs in C++ without a debugger?
Is this actually guaranteed by the standard or is this merely a compiler optimization?
Would it be a good idea if the first allocation would grab, say, 16 bytes instead of just 1? Or does the standard not allow this?
One of my reasons for creating another FFT library is to see if it is possible to write readable and fast code, and how new compiler features could help. It would have been completely boring to use plain C, because there are already myriads of other implementations. metaFFT is also a nice place to become familiar with SIMD coding (first time I wrote SSE code). Next most interesting step concerning speed would be to implement split_radix_ctran.h with AVX, or AVX2 (Haswell only). 
As always with templates&lt;&gt;: it is done with recursion. In case of a loop, all the loop counter variables need to be integer template parameters which could be calculated at compile time, for instance see radix2_complex.h, remaining&lt;K+1, End&gt;::steps(d);
Only advantage over FFTW atm is the code size (header only, easy to add to your project) and the license. Another question is how useful a CPU only FFT is in times of GPU/Cuda/OpenCl programming.
Does anybody know a easy-to-use SIMD library which could help in supporting latest CPU features? I already found: * http://code.compeng.uni-frankfurt.de/projects/vc -- lightweight, easy to integrate * http://nt2.metascale.fr/doc/html/boost_simd.html -- heavy, very actively maintained 
&gt; To be fair it took me around 5 hours to figure everything out. It woud take you 5 minutes. That's (on of the) the difference.
It's guaranteed. C++11 &amp;sect;12.8/32: &gt; When the criteria for elision of a copy operation are met or would be met save for the fact that the source &gt; object is a function parameter, and the object to be copied is designated by an lvalue, overload resolution to &gt; select the constructor for the copy is first performed as if the object were designated by an rvalue. The paragraph prior to that one lays out the criteria for copy elision, which says that in the case of `return ret` the compiler may optionally skip the copy/move and construct `ret` directly in its final location (even if there are side-effects), but if it doesn't opt for that it must treat `ret` as an rvalue so that a move constructor, if one has been declared, will be called.
Interesting that ICC isn't all that hot here, even on an Intel chip.
I feel that is largely irrelevant to the overall point he was making.
At the moment the 48 bit restriction is enforced by the CPU, at least on AMD. Without more than 4 levels of VM tabling, or increasing the page size, you just won't be able to use more. In any case, if you look at the sizes of RAM over the last few decades, I don't think 48 bit will become a problem in the short term.... and if it does, i'm sure OS's will provide compatibility by providing 'low' 48bit mapped memory. Even so SSO-23 is still the cleanest solution.
It is, but it was still an incorrect/inaccurate statement.
When thinking about it this way, your solution no longer seems that unportable.
Maybe once LLVM starts supporting OpenMP in the current version I'll start using it. Seems to produce some fast code.
comments and critics are very appreciated
The video is 112 minutes long, and the pure C++ content is 38 minutes long (from 19:40 to 57:40). That's 34% pure C++. But the 112 minutes includes 24 minutes of questions, and I had no control over the topics addressed there (some of which were C++). If we exclude the Q&amp;A part of the video, we're left with a presentation of 88 minutes, and the pure C++ part is 43%. Of the remaining 57%, not all is publishing, because I had some introductory comments. In round numbers, the talk is probably about 50% hard-core C++ and 50% about presenting technical information in written and presentation form ("publishing"), which is what I was shooting for. That may be less C++ than some people had hoped for, but it's far from only 20% C++ content.
wow, that was very meticulous. That shows how my perception was biased. By the way, the presentation was pretty interesting and I enjoyed watching even the parts about presenting technical information in written and presentation form and I hope that more people in the C++ community (and others) follow your advice. Definitely going to read some of your books once I start grasping the basics of c++.
Wooo new blend modes! I really really wanted these back when I was working on an art class project a couple years ago. I think I ended up having to dip right into the OpenGL code, which was super unpleasant.
&gt; Another question is how useful a CPU only FFT is in times of GPU/Cuda/OpenCl programming. Errr... very. Examples of systems that lack a GPU capable of programming include: * Raspberry pi and other small systems * Cheap laptops * My workstation at work Given how widely used FFTs are, there are probably more applications of them on systems without GPUs than with.
Many are raw for loops using .size( ) method of some container assigned to an int. Usually the for loop is the bad smell and can be moved to an algorithm or range/iterator based for loop. 
Perhaps. But in this context your comment is irrelevant; it does more harm than good, as though to discredit the speaker when he's actually got an important message to convey (one I wish more people would take heed on). I mean if you knew anything about the HPX project, then you'd know that the speaker without doubt knew the finer points of your argument but CBA'd to dwell on it.
The claim that `push_back` is safe because it uses copy-initialization internally sounds wrong. The example given is: std::vector&lt;std::regex&gt; regexes; regexes.push_back(nullptr); // compilation error regexes.emplace_back(nullptr); // compiles but UB Using `push_back` results in a compilation error because `nullptr` is not implicitly convertible to `regex`. The call is not viable, so the internals of the function are irrelevant. It is no different than attempting to call `push_back(1, 2, 3)`. The overall point of the different behavior is solid, but I fail to see how direct and copy initialization are related. It seems to me it's simply a matter of implicit vs explicit conversions.
The Standard mandates asymptotic behavior only, so implementations can do whatever they want for small numbers. VC's std::string plays funny games like this (for reasons I don't know), while vector doesn't. In general, you have to know what your allocator's going to do in order to exploit its behavior.
This problem was solved by TR1/Boost bind(), which you are reinventing in a weaker, less useful form. bind()'s trick (shared with std::function, etc.) is that it considers pointers to member functions (PMFs) to be invokable like ordinary function objects. bind() has been thoroughly superseded by lambdas, but in the absence of lambdas, bind() made sense.
I prefer wxWidgets over Qt ;)
Yeah I was surprised by that. I couldn't find a link. ICC best feature is it's auto vectorisation. I couldn't find a link to the code so I can't really make any comments on, but if the design had been 'overly' object orientated then this will have an affect on ICCs ability to auto vectorise. Secondly, the really cool feature of ICC is to produce report of what was blocking it from auto vectorisation. It would seem unfair to be to just compile the code and not make use of that feature.
Not to be an ass, but get yourself a spell checker and grammar checker. Way way to many spelling errors many probably simple typos. So many I ended up not reading the post. I say grammar checker because that might catch some of the typos that might pass a spell checker. Understand that I post a lot on the net from an iPad that can do horrible things with auto correct. I cringe deeply if I read my post days later and see these errors and transformations. That is as much my fault as it is iPads as it is best to read your messages before posting. 
I quite like what you've done, here but I think you've put your focus in the wrong place. You shouldn't be writing a special functor here, you should instead use a special iterator. For instance, if you wanted to copy all of the IDs of your objects, your functor couldn't do that. I would suggest using `boost::transform_iterator` in this case (I've just used a `std::pair` to define your `A` class for brevity), #include &lt;iostream&gt; #include &lt;iterator&gt; #include &lt;utility&gt; #include &lt;vector&gt; #include &lt;boost/iterator/transform_iterator.hpp&gt; int main() { typename std::pair&lt;int, std::string&gt; A; std::vector&lt;A&gt; v; v.emplace_back(2, "foo"); v.emplace_back(7, "bar"); v.emplace_back(2, "foo"); auto make_name_iterator = [](auto it){ return boost::make_transform_iterator(it, [](auto const&amp; obj){ return obj.second; }) }; // We just use a std::find rather than a std::find_if auto it = std::find(make_name_iterator(v.begin()), make_name_iterator(v.end()), "foo").base(); if(it == v.end()) { std::cout &lt;&lt; "not found" &lt;&lt; std::endl; } // We could get a list of all names too if we wanted std::vector&lt;int&gt; names{make_name_iterator(v.begin()), make_name_iterator(v.end())}; std::copy(names.cbegin(), names.cend(), std::ostream_iterator&lt;int&gt;{std::cout, " "}); } I would aim to write a wrapper around `boost::make_transform_iterator` so that it would call member functions, giving you a cleaner syntax while doing so. It would look something like this (warning, not compiled this, I'm sure there are errors). template &lt;typename Iterator, typename MemberFunction&gt; auto make_mem_fn_iterator(Iterator it, MemberFunction f) { return boost::make_transform_iterator(it, [](auto const&amp; obj){ return obj.f(); }); } With this, then the `std::find` becomes auto it = std::find(make_mem_fn_iterator(v.begin(), &amp;A::getName), make_mem_fn_iterator(v.end(), &amp;A::getName), "foo").base(); (edit: couple of typos) (edit2: changed `std::find_if` to `std::find` and added appropriate `base()` function call)
Read books and practice. Then practice and then practice even more. Between reading a book and watching a video, it's up to you. The important part is to actually code.
alrighty,thanks.
Books. The videos I like to watch are the conference stuff. I'm personally not a big fan of video tutorials for coding.
I can see how you'd interpret my comments in the talk as saying that push_back uses copy initialization internally, but that's not what I meant to convey. The copy initialization takes place (or would take place, were it legal) when initializing push_back's parameter, i.e., prior to actually calling push_back. The net effect is that push_back behaves as if it used copy initialization, but the call fails not due to anything inside push_back but instead due to the invalidity of initializing push_back's parameter.
sweet, thanks for that.
Reading other people's code is also a good way to learn (provided you're reading good code). You can get the best out of what you see and choose your preferred method.
No such thing as doing harm by telling the truth. If you do not want to be discredited, don't say things that are false. I don't think it discredits the speaker either way. Also, if you watch the talk, you'll see that the HPX project does not relate in any way to GPUs; so there is no conclusion to draw that the speaker does indeed know anything about GPUs based on that he has worked on HPX. If anything, his statements that GPUs are like SIMD is a common way of thinking of GPUs which programmers who only ever use CPUs have.
You can also do that with CMake by default. This looks like it is more for running custom commands rather than producing targets from dependencies.
I find the lack of full mobile support discouraging. Have been waiting for them to support it for over a year.
It's written in C++ with all of the horribleness which is associated with C++ programming which is a massive difference.
i am xposting on the offchance someone wants to improve the c++ implementation (currently behind nimrod on x86 ?!).
 int getLongestPath(const vector&lt;node&gt; &amp;nodes, const int nodeID, bitset&lt;T&gt; visited) I believe that passing `bitset&lt;T&gt;` by value might require a lot of copying. A simple `bitset&lt;T&gt;&amp;` would go a long way.
Hmm, the sample graph has only 16 nodes. So a bitset of 16 is created and result in a two byte copy or one word depending on architecture size. It's not going to be as good with a reference as the current implementation. I had already suggested a [change](http://www.reddit.com/r/programming/comments/2pvf68/armv7_vs_x8664_pathfinding_benchmark_of_c_d_go/cn0iub1). It's a start but could be better. :) I think a way we have not to loop over every visited note would be a good approach. But that's an algorithmic problem not one of the language. An other thing is to align the data more cache friendly maybe. A vector for every node might be problematic?
Ah, you're right; given the penalty of using an indirection, one would have to tune the threshold at which to switch to a reference. It is interesting that switching to a local boolean would increase performance when generally you would wish for the least possible memory footprint. I suppose that the size of the reference data-set is small enough that cache size does not matter yet.
There are still places where using bind() is just terser and less error prone than writing a lambda. Anywhere you're just removing, adding or reordering bound arguments it still has the edge.
i5-2430M, Win 8.1 x64 ---- ~2x speedup (2633 vs. 1297) in VS'13 by changing the way the bitset is accessed: template &lt;int T&gt; int getLongestPath(const vector&lt;node&gt; &amp;nodes, const int nodeID, bitset&lt;T&gt;&amp; visited){ visited.set(nodeID); int max=0; for(const route &amp;neighbour: nodes[nodeID].neighbours){ if (!visited.test(neighbour.dest)){ const int dist = neighbour.cost + getLongestPath&lt;T&gt;(nodes, neighbour.dest, visited); if (dist &gt; max){ max = dist; } } } visited.reset(nodeID); return max; } The bitset is passed by reference to prevent stack overflow (no perf. impact). ---- Edit: ~2.25x speedup (2633 vs. 1152) template &lt;int T&gt; int getLongestPath(const vector&lt;node&gt; &amp;nodes, const int nodeID, bitset&lt;T&gt; visited){ int max = 0; visited.set(nodeID); for (auto&amp;&amp; neighbour : nodes[nodeID].neighbours){ if (!visited.test(neighbour.dest)){ const int dist = neighbour.cost + getLongestPath(nodes, neighbour.dest, visited); if (dist &gt; max) max = dist; } } return max; } Note that the bitset is passed by value again. Needs ~5MB of stack on x64 (Windows default is 1MB). ---- Edit: [3.5x speedup](http://pastebin.com/3P87jQQM) (2633 vs. 749). It's 803 w/o the bit_set&lt;16&gt; specialization. Caches are funny. ---- Edit: [3.5x speedup](http://pastebin.com/cRHF4MXU) (2633 vs. ~~770~~ 740-757*). Added atomic_thread_fence() to prevent low-level CPU magic. The results are much more consistent between re-runs now. *) The longer runtime was an effect of turbo. I think I'm pretty much done with what can be achieved by micro-optimization. ---- Multi-threaded &amp; GCC 4.8.3: [7x speedup](http://pastebin.com/bP7FAgpS), 375ms. Cache thrashing only has an impact when it's single-threaded. ---- Back to the single-threaded version. GCC -O2 -mavx -fomit-frame-pointer and switching bit_set to unsigned int got me down to 699ms, that's 3.7x ---- Time for algorithmic improvement. [Implemented this](https://news.ycombinator.com/item?id=8778618). Got 17ms, aka 154x speedup. I'm not 100% sure if this is real time from HPET/TSC or OS ticks.
Different to GCC 4.7.2 on my PC. With your change the runtime increases from 2.6 to 2.85 seconds. The way the bitset is accessed doesn't change anything here. Still at 2.85. Well, it depends heavily on the compiler and options used, as always. :\
Can you try it again with this quick'n'dirty bitset implementation? template&lt;size_t N&gt; struct bit_set { static const size_t Bits = sizeof(size_t) * 8; bit_set() { memset(m_data, 0, sizeof(m_data)); } void set(size_t idx) { m_data[idx / Bits] |= static_cast&lt;size_t&gt;(1) &lt;&lt; (idx % Bits); } void reset(size_t idx) { m_data[idx / Bits] &amp;= ~(static_cast&lt;size_t&gt;(1) &lt;&lt; (idx % Bits)); } bool test(size_t idx) const { return ((m_data[idx / Bits] &gt;&gt; (idx % Bits)) &amp; 1) != 0; } size_t m_data[(N + Bits - 1) / Bits]; }; Edit: fixed bit_set
It's worse. Raised to 2.97 seconds. But: template&lt;size_t N&gt; struct bit_set { bit_set() { m_data = 0; } void set(size_t idx) { m_data |= 1&lt;&lt;idx; } void reset(size_t idx) { m_data &amp;= ~(1&lt;&lt;idx); } bool test(size_t idx) const { return ((m_data&gt;&gt;idx)&amp;1)!=0; } size_t m_data; }; Reduced runtime to 2.2 s. Edit: Your fixed bitset equals the GCC bitset implementation. Runtime is the same. 2.6s on my machine. With all your changes.
Interesting. My fixed version of bit_set is as fast as std::bitset on GCC 4.8.3 (Cygwin) but the old one was worse, too. Your bit_set is faster than both (987) but that's because it's fixed size. Edit: I used -O3. With -O2 my bit_set is always faster (881) than std::bitset and almost as fast as yours (861).
Great! Nice performance here too. You should push it to GitHub. Another possible runtime reduction could be achived by removing looping over already visited nodes at all (inner hot loop). But I've no good idea how to do this at the moment. :)
sent an email a while back, no response yet -- prob cause it's Sunday...
Ah ok, I get it now, I think. Thanks!
Is there a Mac version? I just see Windows/Linux.
hi thanks for posting this, just a broad question I'd appreciate if you could answer, it is possible to use this library with an android phone to simulate a RFID (HID/pcprox etc) ? many thanks!
Unrolling a little bit gives me speed up of a few percent (970 vs 945): template &lt;class BS&gt; int getLongestPath2(const vector&lt;node&gt; &amp;nodes, const int nodeID, BS visited){ int max = 0; visited.set(nodeID); for (auto neighbour : nodes[nodeID].neighbours){ if (!visited.test(neighbour.dest)){ visited.set(neighbour.dest); int sub_max = 0; for (auto sub_neighbour : nodes[neighbour.dest].neighbours){ if (!visited.test(sub_neighbour.dest)) { const int dist = sub_neighbour.cost + getLongestPath2(nodes, sub_neighbour.dest, visited); sub_max = dist &gt; sub_max ? dist : sub_max; } } visited.reset(neighbour.dest); const int dist = neighbour.cost + sub_max; max = dist &gt; max ? dist : max; } } return max; } Anyway, great work!
Until you have to explain to somebody why bind() presents bound arguments as lvalues, or why it inhibits inlining of function pointers, or why its compiler errors for misuse scare even library implementers. I will say that my feelings towards bind() warmed slightly after I rewrote it from scratch to eliminate bugs, but only slightly.
Considering it ends Christmas eve, likely a Christmas day thing however if they have received alot of requests possibly even longer, They potentially would have been better having an online form to fill out. 
What CPU do you have? It's 15-20% slower for me :D
I've to admit my CPU is really low end: :D model : 28 model name : Intel(R) Atom(TM) CPU D525 @ 1.80GHz stepping : 10 microcode : 0x107 cpu MHz : 1795.552 cache size : 512 KB 
I'm getting the C++ Primer this Christmas and after reading it or at least some, I'm going to pick one of Scott's books. I don't know which one to begin with and I wonder if I'm going to lose time learning the stuff in "Effective C++" when I'm programming for C++11.
&gt; We just saw what can happen when you optimize for an archaic architecture ;) Good point. ;) &gt; Ack. But honestly, I don't really care much about the other languages and just like to have some fun with C++. Yea why not. Have fun and find the limits. :)
The cost of an atomic refcount is pretty small. A single cache line invalidation for each new or destroyed copy of a `shared_ptr`. If your object is allocated with `std::make_shared`, and the data members you manipulate in the object don't share a cache line with the reference count, the overhead is essentially nonexistent. You also get inter-thread coherence, which you can't guarantee with non-atomic refcount operations. (And looking at the article, nothing is said about their implementation of their reference class.) Looking briefly at the GCC implementation, it appears that it places the pointer and refcount in a single cache line and manipulates them with standard atomic CAS, so I would hope that other implementations follow a similar strategy. (It's worth noting that this library's `std::weak_ptr` implementation uses a mutex for the `lock()` method, so one should be aware of that overhead.)
No Mac version. But vmware fusion (or even virtualbox) is a decent investment if you're developing on a mac - there are useful dev tools that only run on windows or only on mac or only on linux. (My laptop SSD is a bit full, so I have windows and linux dev environments installed on USB3 thumbdrives - the fast ones from SanDisk - and they work great). 
It is just that `emplace_back` allows the use of explicit ctors, while `push_back` doesn't; there is nothing wrong with either way, but you should be aware of this fact. For an example where it might be disputable whether calling explicit ctors is a good idea: auto times = std::vector&lt;std::chrono::milliseconds&gt;{} ; times.emplace_back(3); // Don't call me convinced that this is the right thing to do using namespace std::chrono_literals; times.emplace_back(3ms); // clearly better in this specific case
i think there might be a single threaded requirement. are you making pull requests? edit: did not see your last edit
Visual Studio Community 2013?
I don't follow on the lvalue thing. Using move-only types with lambas still seems to be pretty painful. I'm using make_shared&lt;std::promise&lt;...&gt;&gt; in a tonne of places in my code because ASIO keeps trying to copy lambas that have captured move-only types.
Yep. Came here to mention Doxygen. It's such a delightful piece of software for applying to an inherited code base. Even if its not instrumented such that Doxygen can pick up the comments correctly it does a great job at crossreferencing everything and sending that graph data to graphviz. 
Given meow(unique_ptr&lt;int&gt;&amp;&amp;), you can't say bind(&amp;meow, move(up)). Your unique_ptr will be moved into the bound functor as you wanted, but it'll be given to meow as an lvalue, which won't compile. As for things trying to copy movable-only functors, that would be the library's fault. (The STL notably reserves the right to copy almost all functors, with a few exceptions like for_each().)
Not entirely sure what this was compiled with, but in Visual Studio 2013.4, using a function has little to no effect (other than in 'classic'): Classic: 5750328us Moved: 1848105us Function: 1855106us IIFE: 1846105us Smarter: 3998228us Strangely, the vector constructor ('Smarter') ends up being rather slow, I suspect because it ends up using around double the memory for some reason. Anyway, as usual, don't assume some way is automatically faster than the other. If you need performance, profile. I certainly agree with security aspects of it though. If you're going to use std::move on something, it better be when you're sure it won't get used again. But the existence of RVO means the need for move happens very rarely (in my experience at least).
Yes, biicode installs dependencies inside a "deps" folder inside every project, for pure local consumption. In that way, different projects can handle different versions of libraries very easily, or even the same version but built with different options for that project. Furthermore, for large projects as boost, that are not hosted in biicode, there exist hooks, which are also versioned. Those hooks typically (they are just scripts, implemented by users) install those frameworks in the user environment folder ("biicode_env"), so they can be used by all user projects in the same machine, and use different folders (e.g. biicode_env/opencv/2.4 and biicode_env/opencv/3.0). After that, the CMake scripts actually involved in the user project (in the "deps" folder) will point to the specific version transparently. With this approach it is avoided to rebuild such large frameworks per-project, and different versions of them can be managed exactly as any other biicode dependency. Biicode can indeed work in an offline mode. Once you have the project, the source files are retrieved in the "deps" folder, the CMake scripts are also inside the project, the layout easily allows to work. You can forget about biicode and build with "cmake --build" or with your IDE if you have created an IDE project: http://docs.biicode.com/c++/building.html#maintaining-independent-builds You can checkin the whole project (typically ignoring "bin", "build" folders) into version control if you want, and work from there. But, please note that if you change the structure of the project (add, remove files, add libraries, change relations between files), you might need to edit your CMake files at hand, as usual, if you are not using biicode. I would recommend and I use myself a workflow in which the repositories under version control are the blocks inside the projects, not the whole project, and the project is something temporary. In any case, any other external sources are always allowed. You can of course build and link against libraries in your machine, even if they are not managed by biicode, you can use other managers, everything can be configured using CMakeLists.txt files. 
To die, it must first live ;)
optional lite, a single-header header-only library ala std::optional for C++03 and later.
Ho ho ho VC6, now we are talking about some serious issues here...
Because virtually all modern HDDs and SSDs achieve higher throughput when they have multiple outstanding commands in their queue. E.g. doing random 4K reads on a SSD might give you 5 MB/s with a single thread and 50 MB/s with 10.
It's been living for far to too long, it's been kept on life support and making devs life hell.
It's a scam of some sort. I just heard back from a person called Emma, she was wanting numerous pieces of information including a phone number and address as she puts it: "in order to emit a valid license file" 
The next thing you're going to say is that gcc 2.x that some embedded chips ship with as their compiler must die. Sheesh!!! /s BTW... get some sleep! We need you to keep pushing for a new for syntax and making both the next standard and next MSVC better!
It's weird though, because the blog and email address are on their official domain. Literally within 10 minutes of hearing back from them with this exact request, I got a spam message which made it through the junk filter. Seems like an unlikely coincidence...
`std::move` is a clear case of “only use it, if you know what you are doing”. It isn't very difficult to understand that however and you are basically safe if the argument is a local variable (or a by-value argument to the specific function) that isn't mentioned in the scope later on. Aside from that there is only one place that I can think of where I would use it, is relatively advanced: In getters of rvalues.
Oh come on, template metaprogramming isn't 80% of the language...
Nice try, micros...oh.
I didn't mean it that way, sorry to be unclear. I meant that I don't have an exhaustive knowledge of the other parts of the language, so the total percentage of what I know probably adds up to 20% or so (I haven't tried to quantify it). I probably know 75% of C and its standard library, maybe 50 to 75% of the OO features (I use operator overloading only infrequently, so I probably only half understand it, and I've never really used polymorphism for anything, so, although the concept isn't really hard to understand, I'm putting it in the "don't know it" category). I doubt I know more than a few percent of templates or the C++ standard library.
&gt; Not entirely sure what this was compiled with, Clang 3.5 (shown on the Gist) but he linked with GNU stdlibc++, which botches the results due to its non-standard copy-on-write implementation of std::string. $ g++ -std=c++14 -DNDEBUG -O2 iife.cpp $ ./a.out Classic: 1023011us Moved: 842311us Function: 652079us IIFE: 663907us Smarter: 167790us $ clang++ -std=c++14 -DNDEBUG -O2 iife.cpp $ ./a.out Classic: 1010173us Moved: 783221us Function: 640994us IIFE: 640477us Smarter: 165010us $ clang++ -std=c++14 -DNDEBUG -O2 -stdlib=libc++ iife.cpp -lc++abi $ ./a.out Classic: 1511505us Moved: 886437us Function: 665326us IIFE: 651101us Smarter: 1202059us I'd like to know what Clang and GCC are/aren't doing for the "Moved" case that MSVS isn't/is doing.
I have tried writing similar tools in the past, but ended up scrapping them and going back to lambdas. if C++11 is available, I think it's worth the verbosity to avoid weighing down those who read my code with more custom stuff to understand. I agree with other poster who said special iterators are a good tool. C++ should make it easier to define custom iterators. Looking forward to Ranges as an improvement in this area.
Don't understand the hate. I only rarely have a chance to pick a compiler at work. If someone is stuck with an old compiler, libraries like this one are a blessing. Not releasing it would convince nobody to move to a new compiler.
Is doing `return std::move(nextvec)` considered unnecessary because return value optimization is pretty much guaranteed?
Yes. It's worse than that I believe, since doing that will force a move rather than allowing it to be elided entirely even where the compiler is capable.
&gt; bind() has been thoroughly superseded by lambdas, Except that a bind will take any number of arguments up to some maximum amount. AFAIK that can't be recreated with lambda syntax.
What compiler options / optimization level did you set on VS2013? As the other comments pointed out, I used clang++3.5 with the default Ubuntu C++ library.
I'm also curious how the "smarter" function performs with -O3 and the clang stdlib. I find it shocking how much worse the "construct it all in place" version is doing with that stdlib.
All the move oriented versions seem to improve with -O3. "Smarter" doesn't benefit $ clang++ -std=c++14 -DNDEBUG -O2 -stdlib=libc++ iife.cpp -lc++abi $ ./a.out Classic: 1263832us Moved: 890699us Function: 612443us IIFE: 613164us Smarter: 1034573us $ clang++ -std=c++14 -DNDEBUG -O3 -stdlib=libc++ iife.cpp -lc++abi $ ./a.out Classic: 1219556us Moved: 792564us Function: 544110us IIFE: 547182us Smarter: 1056762us GCC with GNU stdlibc++ doesn't gain at all from -O3, which is odd, but different optimisation sets I guess.
Hey, how's it going. I am researching this as well. I'm not sure how familiar you are with the subject, but here's what I've gleaned in the past few days. For [several years](http://forum.xda-developers.com/hardware-hacking/nfc), there have been people like you and me trying to make this work. There have been a few proof-of-concept apps, but nothing that I have personally found usable. The core of the issue is that while making the phone act like a reader is normal, having the phone emulate the card is significantly more difficult. This is how Google Wallet works, and it uses a technology called [Host-based Card Emulation](https://developer.android.com/guide/topics/connectivity/nfc/hce.html) (HCE). In short, the card is not just a dumb piece of memory. It contains some amount of memory, plus [a tiny microcontroller](https://www.youtube.com/watch?v=HRXb-FZ6WFM) that handles communications with external agents via the antenna. Conceptually it is physically possible, but the code so far has not been written, at least not in a particularly public form. Thus far there is more success with the dedicated contactless readers, though the dream remains to read and emulate these cards with Android. The links above pertain more to contactless payment cards. For a great video about physical access cards and fobs, check out [Black Hat 2013 - RFID Hacking: Live Free or RFID Hard](https://www.youtube.com/watch?v=pNCeN1tZbAI) tl;dr probably not, but the question is on people's minds. 
awesome project! thank you for sharing. :D
Just for fun, here's what happens when you do something crazy like use GCC with LLVMs libc++... $ g++ -std=c++14 -DNDEBUG -nostdinc -I/usr/lib/clang/3.5.0/include -I/usr/include -I/usr/include/c++/v1 -O3 -c iife.cpp $ clang++ -stdlib=libc++ iife.o -lc++abi $ ./a.out Classic: 1249831us Moved: 711108us Function: 495563us IIFE: 490369us Smarter: 1031945us $ clang++ -stdlib=libc++ -std=c++14 -DNDEBUG -O3 iife.cpp -lc++abi $ ./a.out Classic: 1237922us Moved: 772877us Function: 540317us IIFE: 542606us Smarter: 1041177us Again a constant factor win for GCC (8 - 10%) in the middle move-heavy tests, but the "Classic" and "Smarter" tests are still unchanged. 
Every release of Visual Studio breaks backwards compatibility, and since it's often idiomatic on Windows to release libraries in a proprietary format, that means a lot of libraries from back then were distributed to work with VC6 and only VC6.
It does not seems to be a scam at all. When I got the mail to send them my information, I quickly thought about it, but then went ahead. Around half a day later I got a nice email from Emma with a license id and file. I just tried it, and it works - awesome! The information you give them is stored in the license file - so I guess it's just regular information they collect from their customers, which I think is pretty much okay.
Both [Wiktionary](https://en.wiktionary.org/wiki/performant) and [Google Ngram](https://books.google.com/ngrams/graph?content=performant) seem to disagree with you.
What's missing though? I've built fully functional, albeit rather small, applications for Android using SFML.
I'm on vacation, having checked in my &lt;functional&gt; overhaul (fixing lots of bugs for 2015 RTM) before I left. Vacation means browsing Reddit and playing video games all day! Which is... kind of similar to not being on vacation.
In fact, VS 2005 is the oldest supported version. 2003 (7.1) is unsupported now, much less 2002 (7.0) and VC6.
Your professors are bad and they should feel bad.
I don't know whether the ability to drop arguments on the floor (which is unlimited in the variadic templates era) is a feature or a bug. I tend to think it's a bug. Basically all the time when you're writing a functor, you know how many arguments it'll be given (even if you don't know their types exactly), and writing a lambda to ignore arguments in specific positions is easy (even easier with generic lambdas). While reimplementing bind(), I encountered several questionable design choices. For example, it's supposed to have cv-overloaded function call operators, while the Standard ignores volatile everywhere outside &lt;type_traits&gt; and &lt;atomic&gt;. (Even tuple get() does, which makes bind() harder.) bind() is also the only place in the Standard Library that I can easily think of, where you can multiply-move-from arguments without writing clearly bogus code (this is because nested bind expressions forward unbound arguments, which can be inspected elsewhere). Obviously not intended due to its TR1-era history.
Furthermore, even if RVO wouldn't be implemented or wouldn't take place, compilers are actually *required* to first try move constructor overload and then copy constructor if move is not suitable (ISO/IEC 14882:2011(E), p. 12.8-32). Without this mechanism you wouldn't be able to e.g. return a `unique_ptr`. This move/copy can be of course elided so what we usually call *copy elision* is in fact *move and copy elision*. That makes moving return values not only silly but also redundant.
Huh. I've done this several times throughout my codebase. I guess now there's an official name for this style. It can be overdone though &amp; it's pretty ugly. Using braces is sometimes better - provides more limited scope. The best application of it in my experience has been if you have complex conditionals: you can just early return from the lambda.
Within the context of a variadic template I can see an at least tempting use for bind: template &lt; typename ... T &gt; void something(T &amp;&amp; ... t) { bind(somefun, _2, _5)(forward&lt;T&gt;(t)...); } Probably best though to just never do anything like that. Even if you're needing the _42 placeholder you'd be better off writing all those T0, T1... It would be sorely tempting to write it like the above though. What I can't do is come up with any legitimate reason why this would be needed. Who knows though. Maybe there's a use for it that wouldn't make me vomit huge buckets of blood.
It would be simpler to get() from forward_as_tuple(), which is what the placeholders are going to do anyways.
Fair is fair, let's also update the other versions to use pre-sized and emplaced construction: jason@jason-VirtualBox:~$ ./a.out Classic: 2790319us Moved: 1242240us Function: 1116370us IIFE: 978202us Smarter: 250165us I'm showing numbers closer to this with both clang 3.5 and gcc 4.8. MSVC doesn't seem to care and none of these transformations seem to affect it. Sorry a couple of formatting diffs sneaked in https://gist.github.com/lefticus/04c644db41e0668ca6c4/revisions IIFE seems to always be at least no-worse-than and often better than the other options.
You forgot to add in the reserve(num_vecs) for the external vector for Function and IIFE. I'm not sure where the 10% edge is coming from for IIFE but if you add those reserves in it vanishes (IIFE degrades to Function). **Bottom line though, RVO seems to be adding a decent 30-35% speedup over the dumb loop with std::move** I'm not sure where that's coming from... i've tried various variants, including ranged for loops and doing away with i and j entirely, and it's still slower. Baffling. Object alignment maybe. I'll do a rewrite and disassembly tomorrow if i have time. 
I have been developing [Oovcde](http://sourceforge.net/projects/oovcde/)
&gt; MSVC doesn't seem to care and none of these transformations seem to affect it. Indeed, I tried all these in MSVC earlier. I replaced everything with emplace_back, but it had no effect. The reserve is useless because num_vecs is 1. Only one allocation will be performed. I'm really confused at how you're the only one in here which has a rather significant increase in using IIFE.
The default settings with O2. Ox only had a minor increase on all of them equally.
It's computer jargon. You could argue that a lot of other jargon words aren't in the dictionaries. Truth is, nobody is going to say "has higher performance" instead of "is more performant." I fail to see how this is 'marketing speak'. The meaning is pretty obvious. Something that is performant means it has high performance.
&gt; compilers are actually required to first try move constructor overload and then copy constructor if move is not suitable Yup, but VS2013 doesn't comply with that in every situation yet.
To me at this point, the most interesting question is why is MSVC *not* getting a gain from RVO in this case. Perhaps @STL has some insight?
No.
Same story with me. No problem at all. Don't think it's a scam - they're just asking for the normal information you'd give if you were to buy their product.
Well, I hope you have a great vacation and a happy holiday season! :)
I learned something interesting from OPs comment and am glad he made it. Technical discussions don't have to always be about discrediting people or some pissing contest, sometimes it's just nice to share knowledge or clarify certain interesting details.
&gt; Way way to many spelling errors many probably simple typos. Ahem...
Dunno. /FAs will reveal the codegen.
I think it's because this is the version of the compiler the platform sdks shipped with for the longest time.
What an asinine concept - why not write it in C++? 
Turbo C++ is a not a valid C++ compiler. 
I find it somewhat interesting he suggests looking at an industrial strength qsort, but not at std::sort. Particularly as if you do look at the latter, you'll find a dreaded pointer or two...
Turbo C++?
But not a void pointer. His point was that the compiler can optimise better if it knows what it's operating on (I.e. an array of doubles).
Just checked glibc/libstdc++: The code for `std::sort` is several orders of magnitudes nicer (though that is partially because qsort is 108 lines long with a cyclomatic complexity of 26) and ok to read, even though everything is `__uglified` in it. Pointers are btw. not used in `std::sort` since it has to work with *all* random-access-iterators.
I agree that casting void *s about isn't great for humans or for compilers. I was specifically referring, though, to &gt; There isn’t a pointer, cast, size, or a byte in sight. which is certainly true of the interface, but at least not true of libcxx's [&lt;algorithm&gt;](https://github.com/llvm-mirror/libcxx/blob/master/include/algorithm), which has the indecency to use `std::get_temporary_buffer`, passing around bare `value_type* __buff`s and `ptrdiff_t __buff_size`s :) (edit: markdown is hard)
What CPU do you have? I ran my tests on my i7-3930K and I'm still about 50% slower than you. Care to share the exe?
True. He did say that, which is a bit much. Pointers can be used appropriately.
weird. so now i have the build system dependency right in the source code? hmmm..... not sure i like it. 
03? Wont this work with 98?
Keyboard too loud. Background fan noise too loud. Your voice too low.
This build tool for c/c++ is written in go. This would be less of a problem if there were binaries, but so far there are none. So you need go to compile this, in order to compile something with c/c++. I agree, pretty weird...
Whenever I need a particular algorithm, I post it as a problem in http://codegolf.stackexchange.com/, then use the top entry. This has saved dozens of bytes of hard drive space.