 co_real_final1_&lt;=&gt;
How? I’m not saying you’re wrong, I’ve just honestly never heard anyone say that before.
Can you explain to me why you think Linux/Mac is superior to Windows? The only thing that comes to my mind is package management. The kernels are same capability-wise, userland is the same (if not, in fact, significantly in favor of Windows). Are you just conflating your lack of familiarity with Windows with a supposed lack of power of Windows? I am forced by the nature of my work to spend some time in Ubuntu; coming from the utterly powerful comforts of Visual Studio, FAR Manager and the like, the barren Ubuntu console, with the stellar choice of `nano` and `gedit` as the available editors, feels utterly impotent to me. Trivial stuff like being unable to clear my console input by pressing ESC, or sometimes getting weird escape characters in the console (*what year is this???!*) just adds to the feeling. But I know this is only because I am unfamiliar with the environment (and not inclined to learn it); there are people who wield it expertly and tastefully like a fine sword. Is it the same for you and Windows? Why diss it then?
A major portion of pythons most popular libraries stuck to python 2, because 3 broke backwards compatibility. Only in the last few years or so have most libraries upgraded to be 3 compatible, 10 years after the release of Python 3. The various features which made 2 and 3 incompatible still aren’t really considered worth it to break a language with a immense ecosystem, and it was only end-of-lifeing Python 2 that forced many to switch. 
&gt; One thing I really dislike about the Cargo team's philosophy is that "it isn't meant to be a general build system." Agreed, especially in light of the fact that they're trying to compete with C.
&gt; I wrote both C and C++ professionally and personally for years, and I firmly believe that Rust has the best cross-platform support of the three by such a long shot that it isn't even a fair comparison. What? That has not been my experience. In addition to `gcc` targeting more architectures, I've found it *far* easier to cross-compile C for raspberry pi. Rust libraries will sporadically break on various platforms for no good reason. Have a look at [rhis](https://travis-ci.org/vmchale/project-init) versus [this](https://github.com/vmchale/illiterate/releases), for instance. 
Yeah awful package management by default (that everyone seems to love?) + a low-level community = not really my cup of tea. 
I see. Thanks.
It would happen a lot faster if the core team wasn't always on reddit.
I specifically mentioned Windows and Linux, so I was talking about OS platform portability. I also think LLVM's architectural portability is more than sufficient. There are plenty of less-than-useful platforms that _could_ be supported better, but why? If you're developing for servers, Rust/LLVM supports x86(_64), ARM, and PowerPC which are the only real players there. If you're developing for desktop, Rust/LLVM supports x86_64 and ARM, which are the only real players there. If you're developing for mobile, Rust/LLVM supports the only player there, which is ARM. If you're developing for deeply embedded microcontrollers, Rust/LLVM supports the ARM Cortex-M stuff great, which is probably the most popular range of architectures in embedded electronics. There is experimental support for AVR and some others, and that's a limitation to be aware of. On the first link you posted, two of the failures were related to MUSL, and MUSL is buggy enough on x86(_64) as it is that I don't think it counts that MUSL is even buggier on other platforms. One of the others was SPARC. Is SPARC a valuable target in 2018? If so, why does LLVM not support it better? If there were _any_ money around SPARC, someone would be supporting that backend better. The final failure was related to building for the Redox OS, which is a highly experimental OS written in Rust. Does that one even matter? Actually looking at the Travis CI logs for those failures, two of them were caused by C or C++ dependencies failing to compile. I thought you were talking about how great gcc's portability is? One of the failures was either because `xz` is apparently so broken on that architecture that it couldn't even uncompress a file, or the `deb` file was corrupted somehow. Only one of the failures was actually an assertion failing, and that was on SPARC, where trying to configure signal hooks in the process resulted in the OS returning an error. So again, I was not talking about architectural portability, but I think the current architecture support is more than sufficient. If it isn't, support can be added in LLVM, and in **ZERO CASES** was it "Rust libraries will sporadically break on various platforms for no good reason" which is such BS fear mongering.
It'd be nice if you had a filesystem that automatically computed the hashes for the files it stores as a matter of course. BTRFS does checksumming, but that's insufficient of course.
I use both windows and linux every day. Abhor Windows, strongly prefer Linux. I have nearly identical capabilities with both systems, but Linux is much easier to understand and analyze what's going on under the hood than windows. Also, Linux is free, and windows phones home to it's masters?
NPM is absolutely terrible, sorry. Left-justify ring any bells?
It was a well-presented talk, but I think not new ideas. He's basically describing performance gains from reorganizing data to do vectorized computations, and using the name "Data Oriented Design" to mean program design allowing vectorized computations by storing all the data for one (vector) operation together. Typical Object-Oriented design is kind of the antithesis of this, generally storing all the data relevant to an instance of a thing together, rather than storing the data for one operation (across many instances) together, so that the data feeding vector operations across many instances are diluted by other instance properties not relevant to the current operation. He also pointed out: • that deep or complex object hierarchies make very branchy code that is not good for instruction cache locality, but easy to overlook because the code doesn't show an if-block. • that code with objects that take actions tends to interleave many different systems together to complete the action for a single object, dumping out all the instruction cache for each system along the way, rather than data pipelines that handle each stage completely with one system's code, before moving on to the next stage for the next system with that system's code. As he said in the talk, all this is old news for graphics programmers. I was a little disappointed; in his intro he said he gave the talk because he didn't find any real-world examples that weren't about graphics, but his example in the talk was about... animations. I'd really like to hear about examples of pipelined, vectorized code outside the graphics domain, and practical ways of finding vectorization opportunities.
They are indeed complete crap. No other language has compilers this slow. Why should C++ compilers be this slow? The answer, of course, lies in gigantic template-filled header files and the awful design of 'just include headers multiple times and hope they have header guards'.
If you wanted to only work out of something like a FUSE filesystem for a project, you could have the filesystem compute hashes at write time (rather than writing out, and then having to have a separate process read it back to do the hash.) It could be written with a guarantee about hash metadata always being in-sync with the current state of the file, and work on top of any filesystem that you wanted to use for the actual storage of the files.
&gt;an you explain to me why you think Linux/Mac is superior to Windows? It's superior in absolutely every single way. I'm not kidding. Every time I use Windows it's incredibly painful. It's slow, it's insecure, it's completely featureless, it's difficult if not impossible to customise, it's spyware, it's unstable, it's just terrible. &gt; The only thing that comes to my mind is package management. That's the first of many, many things, but it's also enough reason on its own to never use Windows. Not having a proper package manager in 2018. Wtf. Linux has had proper package managers for decades at this point. &gt;The kernels are same capability-wise They certainly are not. The Windows kernel and low-level APIs are utter dogshit. Starting processes takes forever. You have to rewrite software that works perfectly on every other operating system because Windows doesn't support `fork` and other standardised system calls that work on every other operating system in common use, and because the Windows process model is bloated. The low-level APIs in Windows are awful. Building an API around UCS-2 and never really fixing it to work with modern Unicode is just... bizarre. Windows only *barely* even supports UTF-16, let alone UTF-8. And don't give me this 'oh but they adopted Unicode before UTF-8 existed'. Sure, they did. They've had ample time (decades at this point) to deprecate the old interfaces and create new ones. They haven't done so. It's not like they don't deprecate things all the time. Windows backwards compatibility is a complete joke. Every time they release a new version of their operating system they break loads of software that worked on previous versions. They're not as bad as OS X but they're still pretty bad. In comparison I've *never* downloaded software for Linux that hasn't worked due to backwards incompatibility. I can run Windows software that's only a decade old better on Wine than I can on modern Windows. There are some good things about Windows, like if your graphics driver crashes it can just restart and not affect the rest of your session. I've had games keep playing and only experience a minor graphical hiccough when the driver has crashed and restarted. That's cool. But these little things are not worth all the issues with Windows. When I used Windows, whenever I had an issue with my network, it was impossible to debug. I just had to do things like restart my computer, log out and log in, etc. I couldn't just look at the logs, find the error message, and google it, finding the fix on a forum within a few minutes. No, instead I have to use the built-in 'troubleshooter', which literally never fixes anything that can't be fixed by just turning off the wireless card and turning it back on again. Oh, and not to mention that on Windows if you want drivers you have to download them yourself. Why aren't they just built in? Linux has more device support, for more devices, and for 90% of them they're just already there, in the kernel, ready to work, and 90% of the rest are in the distro package manager. &gt;userland is the same (if not, in fact, significantly in favor of Windows). Lol, what? Are you joking? Userland in Windows is terrible. Want to change your environment variables? Here's a dialogue box where you're expected to edit your environment variables in a tiny text box in a window you can't resize from being about 200 pixels wide and 100 pixels high, an interface that hasn't changed since Windows 98 or something. Want to change some sort of variable? Hope you like opening regedit. Want to just edit a well-commented file full of explanations as to what configuration variables do and what options they have and such, in your favourite text editor? A text file you can copy to another computer and have just work? Sorry, no can do. You have to use regedit or some other registry editor tool to change a value with no in-place documentation. Whoops. Want to use a tiling window manager? Sorry, no can do. Find a bug in a program that came with your operating system? Go download a freeware or free software replacement. Can't just fix the bug and recompile. Can't even really file a bug with the developers unless it's one of the few open source tools Microsoft has. Don't like explorer.exe? Tough, can't replace it. Your file manager crashes for some reason? Tough, that's explorer.exe, that crashing means your entire DE crashes. Does it automatically restart? Maybe. Or maybe you have to just know that to fix it you have to hit ctrl-alt-delete, new task, type 'explorer.exe' and then your computer works again. Don't know that? Shit outta luck. In terms of third party programs, Windows is just bad. A lot of it is small things: most third-party programs draw their own completely unique UI. Nothing fits together, it feels completely jumbled. Even programmes written by Microsoft all have their own UIs these days. Install a program from your motherboard manufacturer? It looks like some teenager's fantasy of the kind of programme a 'leet hacker' would use. http://www.legitreviews.com/wp-content/uploads/2016/10/msi-afterburner.jpg Why there is no standard style that all programmes use is quite beyond me. But there are big things too. Programmes all update through their own mechanisms. Lots of them phone home, with no way to tell that that is happening. Programmes put their data in completely unknowable locations. Is it in Appdata? Local? LocalLow? Roaming? Program Files? ProgramData? In a folder in my documents? Who knows? On Linux it's pretty much always in `~/.config/program-name/` or if it's an older program that doesn't follow the XDG standard, in `~/.program-name/`. &gt;I am forced by the nature of my work to spend some time in Ubuntu; coming from the utterly powerful comforts of Visual Studio Visual Studio is, in my opinion, slow bloated garbage. Whenever I express this opinion, people say 'just upgrade your computer lol'. I have a recent, powerful computer with 16GiB of RAM and a good processor. I had it installed on an SSD. I didn't have any extensions installed. It still took minutes to start up, it took **hours** to install, it was just ridiculous. Once it was open, I was presented with a billion little icons and umpteen menus, configuration dialogues and shit I didn't need. Literally all I want is to write code, and for it to be compiled. I don't need integration with a billion Microsoft services. All those little features should be addons or extensions. Bundled with it, optionally? Sure. Turned on by default? Preferably not, but if you insist, sure. Able to be turned off? PLEASE MICROSOFT. PLEASE. That being said, there are plenty of good alternatives to Visual Studio. It's hardly the only IDE on the planet. There are loads of others, and pretty much all of them run on Linux. Eclipse, the Jetbrains products, whatever KDE's one is called, etc. etc. &gt;FAR Manager I can't tell if this is a joke or not, but two seconds of googling would tell you that this is a clone of Norton Commander. Norton Commander has a free software clone called midnight commander: `mc` is in pretty much every distro's repositories. &gt;the barren Ubuntu console Again, is this some kind of joke? The barren Ubuntu console? The terminal on Linux is absolutely fantastic. It's incredibly featureful, it's what the entire operating system is built around. Windows is built GUI-first, and the terminal is an afterthought. Linux is the other way around, and it shows. Everything you want to do, that is able to be done, you can do through the terminal. What is barren about the terminal? Come on, you're just pretending at this point right? &gt;with the stellar choice of nano and gedit as the available editors, feels utterly impotent to me. Holy shit you have to be joking. Vim? Emacs? Every open source text editor that runs on Windows runs on Linux, basically, and a whole lot more run on Linux without running on Windows. &gt;Trivial stuff like being unable to clear my console input by pressing ESC Press Ctrl-C to clear the console input. &gt;or sometimes getting weird escape characters in the console (what year is this???!) just adds to the feeling. I've never got 'weird escape characters in the console'. Maybe you should learn how your tools work instead of just slamming your fat fingers into the keyboard until things work. &gt;But I know this is only because I am unfamiliar with the environment (and not inclined to learn it); there are people who wield it expertly and tastefully like a fine sword. Is it the same for you and Windows? Why diss it then? Windows is fucking garbage. Sorry, it just is. There are issues with Linux, plenty of them, but they're being fixed gradually. I could understand someone saying Linux was unusable when you had to write an Xorg config to get a GUI, or when sound and wifi would just randomly not work half the time for most people, but for more than a decade it's been way more stable, way more featureful, way more performant and just way more *understandable* than Windows. You never get into a situation on Linux where something just doesn't work and you can't figure out why. Like any system, sometimes things don't work. It doesn't happen very often, but if it does, there are logs, and error messages, and forums and IRC channels full of people willing to help you diagnose and fix any problems you encounter. Oh also Windows update is fucking terrible. It's 2018 and your operating system takes hours to start up because it's installing updates. WTF. Just install the updates while I'm using the computer and make the kernel updates take effect when I restart. I haven't had to wait for a computer to update while it's starting up for years now. It's fantasticly freeing. No more worrying that if I restart my computer I'll have to wait.
It was added after the page was forcefully pulled down from github due to mass flagging of it, the way it's worded is stupid but that doesn't make the complaint less valid.
Package management shouldn't be the compiler's job, while standardized package management is nice and all, it's annoying when you want to use a different style. NuGet is great in it's regard, it (with the .Net ecosystem) allows for one to pull in assemblies from anywhere, but it doesn't limit you how to pull in these assemblies, it just works^tm for the assemblies it knows about and if it doesn't know about it you don't have to do much extra work (although this is due to the nature of the .Net IL anyways), NuGet is only one way of package management, it's not *THE ONLY* way, it doesn't create a single dependency on one server that if it goes down everything else goes down.
I have had a hard time explaining this concept in the past, but this is a really good summary, thanks. 
The compiler doesn't do any package management. Rustc is a different tool than cargo. You could completely bypass cargo if you like and replace it too, there just hasn't been a need to. Cargo lets you pull dependencies from many locations to so it's as flexible as nuget. You may want to revisit the tooling to better understand each unit.
&gt; vectorized computations I think focusing too heavily on this is a misconception. The principle overhead in traditional systems is memory latency, not execution throughput. Even when execution throughput is bottlenecking you, hoisting branches and centralizing logic has performance impacts that hold regardless of whether the compiler can use SIMD operations. Vectorization is more a cherry on top than the core of the philosophy.
&gt; The compiler doesn't do any package management. Rustc is a different tool than cargo. In this case, the package management system is also the build system is also the repository system is also the default tool to use the compiler with, I'm using the terms wrong here intentionally because the only way you need to use rustc is indirectly through project managment. It's fine for awhile, however the fact that cargo is essentially the only way and will be the only way (comes with rust, only way to currently pull in most deps, standardized by way of being language-implemented) is an issue in of itself because its own flexibility and need for backwards compatibility will kill it eventually (just as other package management systems before nuget). &gt;Cargo lets you pull dependencies from many locations to so it's as flexible as nuget. NuGet is better used in the sense that it's design was catered to the ease of IDE use, where you can see all options laid out immediately, and that's where any and all "flexibility" of the tools here can come out into play.
I'm not sure I understand your complaints. Yes cargo comes bundled. It doesn't mean you have to use it . You can choose not to and can call rustc directly if you like. You can also choose to use cargo for only downloading dependencies or only to build if you so choose. It's not forced on you and all the parts are optional. 
LOL... every time I hear OOP is dead I always laugh and think... so, what is that thing called you just used the "new" keyword on. Oh, right... AN OBJECT.
You're right, I used the wrong word. What I meant was processing data in a vector, in order and without branching, as graphics pipelines do. Not SIMD vectorization.
Tuple itself could also be implemented with similar techniques, avoiding recursion in a lot of places. I wrote a proof-of-concept and gave a talk about it in the C++ User Group in Aachen quite some time ago. A small test program with a bunch of `tuple_cat` calls took **70s** and a template instantiation depth of 514 to compile with Clang and libc++, my version took **1.7s** and a depth of 15. Link: [https://github.com/taocpp/tuple#rationale](https://github.com/taocpp/tuple#rationale)
1. Is manually allocating and freeing memory fashionable again? It probably shouldn't be. 2. I can `new` an `int`, is an `int` an object?
On 2... it is when it gets boxed so you can call a method on it.
Well then it's not an `int`
I aslo look for this, but I hope to read a real project ,not a demo
Hey David, I get a Proxy error when trying to visit your ADP 
That's like saying "LOL I see *functions* everywhere, Functional programming must be the *only* correct way to write software." Obsessing on making software to be constructed in a particular pattern without regards to context is bad engineering. Not using OOP isn't stop using Objects, it's not using **only** Objects. 
Am I understanding you correctly, that your teacher prefers not to use STL functions instead of hand-rollen complexity?
No, this is silly. You want the `abs` in `cstdlib`, rather than `cmath` (prior to C++11), but the standard library authors know how to write functions like this and second-guessing them is silly. There are *cases* where it's important to write things manually, but that takes expertise and experience, and it's certainly not for this.
I think this is now suited for /r/cpp_questions . That being said, the second version seems horrible and inefficient to me. The standard library is your friend (better us std::abs). It expresses your intent much better and will likely only change a single bit in the negative case and only one check without any computation in the positive case. While your version always does some non trivial computation (not sure how much the compiler can optimise away).
Almost guaranteed the compiler will optimise better than you for most situations (as you can see [here](https://stackoverflow.com/q/2639173/7064452)). The `abs` implementation will be efficient and the function will likely be inlined. Not to mention that your version is completely unreadable. No one reading your code can see what it does quickly (what are 'i' and 'j'???), and they must trust you by your one small comment that it works perfectly. Meanwhile `abs()` is instantly understandable by name, and everyone knows that it's extremely likely to work since it's from the Standard Library. So method 1 is a million times better. Please do not ever write code like method 2.
&gt;They are indeed complete crap. No other language has compilers this slow Rust compiles slow as well. &gt; Why should C++ compilers be this slow? The answer, of course, lies in gigantic template-filled header files Yes. &gt; and the awful design of 'just include headers multiple times and hope they have header guards'. No, if a header doesn't have an include guard it won't compile. And the overhead of them is negligible. 
I've just spent a lot of time to convert some C-style code (struct with public members declared in cpp file together with a bunch of free functions to operate on the struct, and then a header file with the function declarations and forward declared struct) to a proper C++-style class (class declared in header with private members and public member function declarations together with a cpp file with all the function definitions) just so I can use unique_ptr to manage the heap allocated objects instead of the previous solution of raw owning pointers.
I strongly recommend *against* doing this. Benchmarking well is already a dark art, and nanobenchmarking is an order of magnitude moreso, and you need to learn how CPUs and compilers work *before* you can get anything of value out of the latter.
The second example prints 0 if the value is negative. The integer representation of `false` is 0, not -1. Even if it were, multiplication by -1 will not possibly be faster than simple negation. If the compiler was smart enough, it might optimize it for you, but if not, that'd be an asm `mul` call, which takes many more cycles than negation. In short, whoever wrote example 2 didn't even test the code for correctness, and has no idea what they're talking about for efficiency
Haven't seen the talk, and glad to see another bulgarian presenting it, but coming from gamedev - Mike Acton, and his https://www.youtube.com/watch?v=rX0ItVEVjHc video should be for everyone to see.
FYI: [`std::abs`](https://gcc.godbolt.org/z/SSs4Ga) - Note the lack of `std::abs` in the assembly at all. Compilers know how to inline. [hand-rolled](https://gcc.godbolt.org/z/yqIu1g) - Note the lack of branching, but more instructions. Is it faster? Can't say just from some assembly. Is it worth having no idea what the code's doing until studying it thoroughly? Probably not. Speaking of that, this is just one compiler, Clang. GCC compiles `std::abs` to a branchless version with fewer instructions than your hand-rolled version.
I am sorry for the incorrectness of the code, I tried to abstract it from a project I am working into a simpler version and left off an important part of it...the current edit is proper.
Ah alright. It's now correct but definitely less efficient. 
It's possible the second piece of code changed since you wrote this (I had to change it from `i`s and `j`s to put it into godbolt). However, the version in the post right now works fine for negatives, ignoring `INT_MIN` and the unbalanced parentheses. `-1 + 2 *(value &gt; 0)` is `-1 + 2*0` = `-1` if the value is negative, which is then multiplied by the value to produce a positive result. 
Let's compare these two https://godbolt.org/z/oMaAzT https://godbolt.org/z/Jvz2Ln As you can see, the generated assembly is exactly the same. Compilers do optimize the code and inline the code if they know it will make the execution faster. Your teacher has the old mindset, thinking he'll optimize the code better than the compiler. And if he doesn't know about inlining then I've no idea how he became a teacher in the first place, this is not even a junior programmer level of knowledge.
`cmov` isn't a branch, and is very fast.
Those examples are wrong since `value` is constant and gets inlined.
This is an awesome solution! Is there some example implementation of this? I will try coding something similar right away!
I am curious as to what this dark art consists of...I can intuitively imagine that just testing runtime using a difference between two timepoints to test the runtime is unreliable because there are other factors affecting runtime like how much of my cpu is being allowed for my code during runtime. I have seen from experience on a weaker computer like my raspberry pi how doing simple things like changing windows, clicking around etc slowed down execution of a program...is this why you say it is useless to nanobenchmark without knowledge of how CPUs work?
Never mind me, it's late...
Yes, in this example. Of course this is only a part of his overall thinking...There are other things he requires us to do that seem even more ridiculous than this in the opposite direction (like doing a bunch of conversions so we can use some built in function even though there is a simpler solution). Perhaps in examples of this type he is wanting us to think differently and be clever. Interesting guy overall.
&gt; I've never got 'weird escape characters in the console'. Maybe you should learn how your tools work instead of just slamming your fat fingers into the keyboard until things work. &gt; &gt; Hipocrisy at its best 
Thank you for all of your inputs into this post... This is a lot of what I am curious about. I will look into your article and go from there.
&gt; What I meant is, article OP's aim is to have a generic solution that works regardless of the container, What *I* meant is that the problem in itself ("generically finding index of element in container") is artificial and the solution is horrible. Why is the problem artificial? Because there exist containers for which it makes no sense to talk about any kind of ordering (`hash_set`), but the proposed generic solution will still return some nonsensical result. I.e., it is a problem that does not need a generic solution. 
Fair enough, missed this one. The point still stands. 
Too soon :) 
It's definitely not new in the gaming or graphics industry, but as a code structuring technique I don't think it's that popular overall - though I suppose it's partly because Javascript and Python offer limited control on memory layout. A big plus of structuring code this way is that it's very easy to make it functional: you easily get classes that are responsible for handling their internal state correctly and static functions for actually working on them. It's good for code clarity, threading, and performance, so it's pretty much a huge win-win.
Alternatively, you could give it a more practical name than "c" (seriously, how is googling "c" supposed to be easy ?). Like "Stranger things" or "game of thrones ++"
The Canadian Aboriginal Semantics workaround for no generics in any langiage written in UTF-8 chars.
I heard swift dropped classic for loop and i++ expression. So there is at least a trend. And I personally find myself not needing those in my c++ code.
With modules you no longer share a textual representation of your code between translation units, so in principle, different translation units could be compiled according to different syntactic and semantic rules, as long the fundamental constructs can be expressed and understood in both versions. So let's say, you want to make const the default and require `mutable` if a variable may change or for non-constt member functions. With the current model, even your newly written code usually has to include headers from older code, which wouldn't work under these new rules. With modules however, you could write a new module under the new rules, the old module could continue to use the old rules and the only thing that got exchanged is if a member function is const or not and not by which rules it was determined. It's a bit like linking object files (or llvm-ir or microsofts cil for that matter) that are generated from different languages: As long as the ABI is compatible, it doesn't matter what the source code looked like and if it was even the same language. 
ah, sorry, I read ABI-incompatible in your earlier message thus my confusion
&gt; You have to rewrite software that works perfectly on every other operating system because Windows doesn't support `fork` I would argue that `fork` is a good idea at all.
I believe it is still unsound.
C is a great language for data oriented design.
I might get shit on for saying this but I think everything C can do c++ can do better.
So I wonder: In what ways is data-oriented design different from functional programming? 
Well, in computational physics I couldn't do with them.
Everything C++ can do, C++20 can do, but in a sensible, generic way, because you can use concepts
What's wrong with it is that game developers seem to think they're much better than everyone else and that they work on harder problems than anyone else. You don't. You make toys. What you make doesn't matter.
Rust is similarly crap. &gt;No, if a header doesn't have an include guard it won't compile. And the overhead of them is negligible. Incorrect. If a header doesn't have an include guard, *you don't include it more than once*. Simple as that. It's really not difficult to only include things once, you simply don't include headers inside other headers.
Functions programming tries to hide or avoid mutability, but data oriented design doesn't have that hangup 
[Wiki](https://en.wiktionary.org/wiki/hipocrisy) I don't think many consider wiki to be a good source or not. And there are 2 meanings take whatever suits you. But if you make decision based on people spellings, Then that's the end of debate for me. Plus not everyone's gonna spellcheck every word typed by them on a mobile phone
No it wouldn't, this guy doesn't actually do much coding at all, he writes docs
Yes, technically you can work with headers without include guards. But in practice you don't. And as I said, include guards have nothing to do with compile times.
I don't care about the feature and I don't use Rust. No other language implementation has found this feature difficult, so I don't know why Rust is taking so long.
So the answer is no, you don't know what hypocrisy is. Here's a clue: it makes absolutely no sense for what I said to be hypocritical.
&gt;Yes, technically you can work with headers without include guards. There's nothing 'technical' about it. You can work with headers without include guards, and you should. &gt;But in practice you don't. Yes I do. You might not, because you don't care about compile times. I do. &gt;And as I said, include guards have nothing to do with compile times. Wrong. Include guards allow people to include headers multiple times. The primary reason that it's so slow to compile C++ is because compilers have to deal with megabytes of code in every source file due to headers included hundreds or even thousands of times (e.g. string included in nearly all of your headers, and then those headers all including each other recursively, etc. etc.).
Because the compiler stores the exact size of the array during type checking. You need to change it to allow for an arbitrary variable size. This actually needs to type check so if you declare something of size N the compiler must be able to prove that every N is the same size. But also you may want to be able to do N + M, otherwise the feature is kind of useless (can't merge arrays or anything). Or things like N &gt; M. Of course you can release features one at a time, but you need to know how far you are going with it. Are you shooting for dependent typing or just a few arithmetic operations?
&gt; I'd really like to hear about examples of pipelined, vectorized code outside the graphics domain, and practical ways of finding vectorization opportunities. One example is data analysis. For example, in high-frequency trading (HFT), they've been doing this for ages now. They have a different name for it - Columnar Database or Column-Oriented Database. But it's the same thing, a structure of arrays, rather than arrays of structures. By structuring things this way, if one function wants to detect a spike in volume, it can operate on a cache-friendly array of volume numbers and ignore all of the price data, time data, etc. I think this advantage applies in any high-performance simulation application. Some of those might be operating in real-time, like self-driving cars, robotics, etc. Some may be offline simulations that take a long time to compute, like cosmology, CFD, and so on. I think finding opportunities to use this approach are fairly straight forward. Whenever you have heavy computational loops that only access a subset of each item's properties, you have a good candidate for arrays of properties.
Functional programming is primarily about building programs by composing functions. This is rarely the case in DoD, which is happy to use imperative loops, mutate memory and expose the physical layout of data directly. For example, functional languages prefer collections to be defined in a structurally recursive way, because that's the *semantically* cleanest way to hold your data when your primitive operations are destructuring and recursion, so most have linked lists as their principle linear collection. DoD prefers to lay out the data such that the most common iterations on that data are performed over contiguous regions of memory, and does not mind using stateful variables (eg. pointers) to traverse down that data. Theses are very different approaches.
In 2035 I will use C++35 and I won't ever care about older compilers. 
So is this the typical Struct of array vs array of structs talk, then?
`register co_real_fina1_&lt;=&gt;`
I came here from /r/programmingcirclejerk but you guys are outjerking us here
I think that technically `int` is an object, but I get your point
Something form JetBrains?
I skimmed the talk; for me it's the usual DOD stuff: - lots of claims about how OO is bad in every way; performance, maintainability, etc - lots of concrete stuff about the performance aspects of it - nothing even close to concrete about the claims that DOD is easier to maintain, test, etc I'm still waiting for a DOD talk that has anything interesting to say that's not basically summarized by: memory layout is important to performance and typical OO doesn't always yield optimal memory layout. We all know that; let's take it easy on the horse?
Wait a minute this isn't java?
This mostly only applies to offline data analysis, which is far less performance critical. Most production HFT algorithms simply don't have a step in the critical path where they iterate over the entire universe game dev style. They are processing events that apply to one or a handful of symbols, as quickly as possible, not iterating over all data. I'm not saying that extracting out arrays of properties from objects is never useful in HFT; it is sometimes but it's very occasional.
Your idiotic comment isn't even worthy of a response. 
Being large doesn't make them complex. You said that they were more complex. You are *incorrect*. 
Fair point. I guess I was considering the research side more than the actual run-time side. I only have experience with amateur algo-trading, and haven't worked on an HFT system myself. It sounds like you have. I assume everything is streamed through some kind of queue, which is probably implemented as a fixed-size circular buffer, to avoid allocations. If so, in your experience, is that usually a single queue of ticks or multiple queues for each tick property?
&gt; Actually, what we should do is stop using raw text files to store source code. A database would be a far better choice. I agree that a database would have a number of advantages. On the other hand, a database would also have a significantly higher bar of entry. Today, if I am looking for an error message appearing in the logs, I can just `rg 'error message'` at the root of my code repository and within a second or two I am good to go (CLion is much slower at scanning...). I can also, interactively, pipe/slash/etc... the output to extract stuff out. I can even fire up a simple Notepad++ or Sublime Text to just edit a file. Programmers/hackers have been developing tools for manipulating text in myriads of way for a very long time, leaving us with a large ecosystem. On the other hand, your database of code would have a specific format for the specific problem it aims to solve, essentially running into the same problem that any new language runs into: all the tooling has to be reinvented/adapted. And since people would have different ideas, you'd end up with multiple databases each with their own tools ecosystem, their own flaws, etc... That's a significant chunk of disadvantages; sufficient enough to detract from the purported advantages as far as history has proven.
CppTaskflow looks cool. The CppTaskflow examples seem to focus on using out-of-band data exchange between node functions (or no data exchange at all in some examples). I have a data-flow application which relies on a graph edge being associated with a queue for node-to-node data exchange in additional to the edge asserting precedence. In CppTaskflow is data exchange left to the developer or is there some mechanism for "edge as data queue" that I miss? Thanks!
I guess Java really *does* run on everything, even C++ development.
The accepted RFC allows that, and in Rust, the compile-time constant kind (`const`) already accepts any type. What's tricky is: * "constructing" the compile time values: you need a constant expression for that, and while `const_fn` (and miri) can do a lot of things at compile-time, the version being initially stabilized (`min_const_fn`). * `where` clauses constraints on `consts`: there is no RFC for this, it is just a tough problem. 
That's why I mentioned that the ecosystem isn't there. Of course, having a filesystem like access to the database would already unlock it for use by all the existing tools. Anyway, if you think about it, the current methodology is really terribly flawed: for each translation unit, we build a partial copy of this very same database in memory, from scratch, again and again and again, at very high computational cost. We have complicated rules to ensure that each partial copy is consistent with each other. Why not just make it persistent? Modules are in some ways a step in this direction, I just don't think the scope is ambitious enough. Instead of having a translated module (=partial database) per translation unit, we should really look into the possibility of having one per library or executable. 
&gt; Do you cross compile when you develop or are you targeting a particular host platform? Do you have any visibility in targeting mobile or console platforms with the rust toolchains? Not the OP, but I cross compile Rust every day and tests apps on ios and android without issues. I use a `cargo` subcommand for this called `dinghy` on MacOSX, which cross compiles to all ios/android targets, and can run tests locally in the iOS simulator and the Android NDK emulators. It also detects any connected devices, and can run the tests or binaries in the devices themselves. It's as easy as `cargo dinghy test` (instead of just `cargo test`).
&gt; PowerShell instead of bash. I've been mostly using `git bash` on windows to avoid learning PowerShell. Do you think it was worth the effort? Can you share any good resources for learning PowerShell when one knows bash?
&gt; It's superior in absolutely every single way. As a Linux user, I really like that Windows does not have over-commit and actually use it under Wine to test applications for unreasonable memory request. It has discovered many bugs that would have been hard to discover on Linux.
In 2035 I'll probably be using RedHat 10 with GCC 7 for that sweet C++17 support. :(
I don't know what's "typical" -- I haven't heard this talk before.
&gt; The principle overhead in traditional systems is memory latency, not execution throughput. Is it truly? I feel this view is heavily influenced by the popularity of databases or doing small computations on huge amounts of data. In all the computationally intensive stuff I've personally done for the last 15 years, the computation time is almost entirely dependent on latency between successive operations.
&gt; for your shit database format. Can just use an open-source DB like sqlite... it's already used in plenty of offline cases. You don't really need a super high performance DB for this. &gt; make the compilers faster Oh, easy!
because '++' ? is that it ?
No, that's only mentioned as a brief 30-second aside at the end.
&gt; nothing even close to concrete about the claims that DOD is easier to maintain, test, etc Quite a few concrete points were made, including: code size stats; code samples from Chromium where indirection was hiding logic and the comprehension costs of that around hidden state and lifetime challenges; and a comparison of how easy it is to parallelize these. Stoyan clearly isn't taking these from nowhere; they only built Hummingbird after working extensively on their Chromium-based product. On top of this all, "how OO is bad in every way" is just untrue, since Stoyan goes out of his way to say a lot of positive things about OOP.
Because I've measured it. The currently operated on data easily fits into moderate size caches and the readout speed is not fast enough to benefit more than at most maybe ten percents from faster memory.
You don't need a database at all! &gt;Oh, easy! It is easy every other language manages it.
I agree. Like there are a few interesting problems inside their own little contained area such as the puzzles of packing things in texturemaps/atlas , reprojecting UVs for intelligent loss of detail where allowed or efficient streaming of assets but the size of these files isn't really their main obstacle. Its the amount of files and their influence/relation that is challenging, which is not necissarily where I'd say game asset content pipelines are the worst. A lot of assets are kind of independant but of course if they are not and you are in an environment with ongoing changes... Files and folders allow for a lot of flexibility and options when prototyping or just churning things out which can lead to a lack of process and the lack of process can lead to problems. While naturally you can fill up harddrives usually the problem here isn't the filesize but the discoverability and consistency of files, a lack of overview. At which point you try to make tools retroactively and it becomes very hard to express logical rules to create these neat independant units considering the bespoke spaghetti that already exists and is needed in ongoing production. Again the big challenge here to me doesn't seem like software engineering or algorithm design (which you still both need) but requirements engineering with you artists and their buisness needs. [Riot found itself in such a situation and had the resources to work on a solution](https://engineering.riotgames.com/news/cleaning-data-debt-league). The pain was switching existing material to the new system after figuring out what a sytsem should do in the first place... which was solved with ceating other systems helping with the conversion. But the core system itself isn't overly complex and the whole point is that it is easily extensible and flexible but not 'uncontrollable growth flexible' as random files used to be. Now changing an asset doesn't launch a cascading avalanche of changes(bugs) in other assets it used to have. I think what needs applause there is working with their internal artist-users to make it all happen smoothly inside regular patchcycles. The only way size factored in here is if they had done things willynillily or narrowmindedly in a way that would have caused artists to re do work or undo their own work that was already deployed... it would have caused an excessive amount of large patchfiles to the end-end users: the players of the game. So yes they had to keep this in mind but by planning the buisness process of switching to the system the actual size of the assets wasn't as much of a big deal. So I think there are much 'scarier' and challenging situations to solve outside of gamedevelopment like idunno one that spooks me is reasoning about the collective functioning of eclectic combinations of industrial control equipment that needs to maintain safety somehow by coordinating.
I'm not suggesting that. I'm talking about static free functions, not member functions. Sorry if that was unclear. Maybe I'll edit it...
When a PL gets enough unsoundness bugs, unsoundness stops making any sounds.
I will just quickly touch on a few, not all, points. Perhaps a more thorough reply later... `mc` is the "same" as FAR insomuch as a Ford Model T is the "same" as a Ferrari -- they both have 4 wheels, a gasoline engine and a gearbox. You're like someone who googles "emacs", sees some fugly out of the box screenshots, and decides that emacs is garbage. Visual Studio is definitely preloaded with lots of shit I don't need, I just turn it off and forget about it. Team Explorer? Server Explorer? Etcetera etcetera, that shit just gets turned off, leaving me with a lean mean code slinging machine. Name a better debugging environment? I don't think you've used an IDE for serious, everyday work if you say: &gt;Eclipse, the Jetbrains products, whatever KDE's one is called Honestly, you simply do not have the awareness of how completely on a different level VS is compared to this garbage. Yes, Windows using UTF-16 internally was a huge mistake. Now we're stuck with it. There are many other design mistakes and shortcomings, like the way it uses the pagefile *always*. No one is saying you should use the built-in environment variable editor. It's an API, there are tools to use that API. That goes for everything else that comes out of the box, e.g. image viewing, watching video, listening to music, internet browsing, registry manipulation, etc. Don't conflate the bundled shit which is aplenty, with what Windows is. Don't you think `fork` is retarded in the first place? Who thought it was a good idea to copy (and mark as copy-on-write) a process's *whole memory*, only to never touch it again? Anyway, the NT API has a call that enables that, for what it's worth. You can use ETW to trace everything that happens on your live system if you're so inclined.
The main problem with simd instructions are alialising problems. Assume you have the following function: void scale_vec(double * in, double * out, size_t lenght, double factor){ for (size_t i= 0; i&lt;length ; ++i){ out[i] = factor*in[i]; }; return; } Can the compiler vectorize the function? If in and out point to different memory areas then yes. If in and out point to the same memory area then yes again. But what if out points to in[1]? Then a vectorized loop would load in[0-3] multiply them and store them in out[0-3] (aliaised to in[1-4] ) but a non vectorized loop would correctly load in[0] multiply it, store it in out[0] (in[1] ) load in[1] multiply it again and store it in out[1] ... The output would contain in[0] times potencies of factor. Normally the compiler has to take the unlikely case of this happening into consideration and can't vectorize. If you annotate with #pragma OMP SIMD you guarantee that this case of alialising doesn't happen.
Your project is just amazing! I used it to build a cross platform C++ and WASM based application with dear imgui. So nice to find something well documented, well written and have it just stay out of the way.
&gt;Or dead from global warming. That'll probably come sooner honestly. Now there's the optimism I like to see!
Very cool. It took me way too long to realize that magic numbers `202301L` and `202601L` were supposed to represent C++2b and C++2c.
C can offer you a few ways to shoot your foot with. C++ can't offer just a few.
I would think a good benefit of comparing strings this way is to be able to sort a list of strings alphabetically with ease.
This manner of comparing strings is called [lexicographic ordering](https://en.wikipedia.org/wiki/Lexicographical_order) and is defined in math. IIRC Java compares strings the same way, except that it actually finds the numeric difference between the first two different characters and returns it (or 0 for equal strings). 
Other languages don't have headers. And complex templates. And many other things in the language that end up making C++ slow to parse.
For a language that claims oop improves code reuse, it is a pain to import libraries to actually reuse code.
Because lexographically, "ac" is "greater than", ie *ordered after*, "abzzzzz". It's about alphabetical order. Order does not always have to rely on numerical value.
Your way, abzzzz == azbzzz, or involves additional logic. It's also much less efficient. Comparing abcd...xyz and bacd...xyz your way involves an accumulation across two arbitrarily-sized strings and some unspecified additional logic to handle reordering; exiting at the first mismatch compares exactly two characters.
ah. I forgot about listing strings alphabetically and that would explain why C++ comparing strings the way it does. Is there any other use to comparing strings other than listing alphabetically?
They have aliases for bash commands, the biggest adaptation is “rm -r -Fo” because f on its own is ambiguous. I mostly just google stuff when I don’t know how to do it and it’s worked out. I think being “native” is worth it.
But my question is why are they compared this way? what's the purpose as opposed to comparing the sum of each strings components? Someone above mentioned it's to compare strings alphabetically, and I hadn't thought of that and it makes total sense? Are there other reasons for comparing strings or is alphabetical listing the only reason?
Yeah, but they are not always synchronous. And don't confuse mtime with ctime. You'll not that even ccache has a note about corner cases where it will not pick up a changed file.
I agree with the latest standards, unique_ptr alone makes C seem crazy to use to me now
Thank you for replying. What you said makes perfect sense. It didn't occur to mean, with my logic, how would C++ compare abzzzz and azbzzz, which aren't the same but the sum of their ASCII codes would be. Other than listing strings alphabetically, is there another use for comparing strings?
This is the answer I was looking for, thank you for clarifying! Is there another reason for comparing strings or is alphabetical order the only reason?
[Yes](https://youtu.be/j9tlJAqMV7U?t=438)
Entirely depens on what you're doing. If you've got a database and require unique entries then you need string comparison; if you've got some collection mapping a name (as opposed to an ID) to some set of data you need string comparison, and so forth. Where I work we have a large number of model variables that can hold the same name and the quickest hack is to shove them into an unordered set on construction and in the event of a collision add an integer to the end of the name in a similar way to filesystems with duplicate filenames. (The unordered set will actually hash the string, mind you, so it will take into account the whole thing and only use lexographic ordering in the event of a collision.) It's just another datatype - there will always be times with any datatype you end up wanting to compare two instantiations.
He may mention in brief in some places that OO is ok at something "like quick modifications". But his basic thesis is that OO is worse than DOD for: performance, scalability, modifiability, testability. He says this early on and then digs into each one. That's exactly what I wrote (modulo etc) in my original bullet point. Chromium vs Hummingbird comparisons suffer from rewrite syndrome. Chromium has been maintained and modified over a longer period of time, has a larger feature base, code base, far more people working on it of more varying skill levels, etc. Showing samples of Chromium code that are worse doesn't impress me. Comparing DOD to sub-optimal OO is also an extremely common thing to see in DOD talks. I wonder how a DOD codebase will look after a decade of continuous maintenance from hundreds or thousands of different developers? I'd guess a good deal worse. I found some of the discussion just extremely biased and with very little concrete backing it up. The slide on testing is especially egregious. For an actual good talk about trade-offs between software engineering choices and performance, the keynote from the fellow with the movie making software is far better. 
Your post doesn't really match your title. An actual discussion about what people find illogical is fine, but your post is a question - /r/cpp_questions 
I do love me some Romanian and Bulgarian speakers. This was a great talk imo.
I apologize if this isn't the right sub for my question, but I'm still interested in what people find illogical about C++ or where they feel improvements could be made to the language itself. I'm actually very interested in hearing what people would say
Sure, I wasn't trying to be mean if it came across like that. I'm bad at coming up with particular examples, but sorting strings by length instead of by lex order can have its uses. The Windows Explorer actually has a very particular implementation of ordering for file names that generally goes lexicographically, but compares continuous strings of numbers as "one unit", so that "picture 10.jpg" comes after "picture 1.jpg" or "picture 9.jpg" instead of in front.
A lot of inlining in this example: https://godbolt.org/g/26viuZ 
Given your self proclaimed mathy-ness I’m surprised. This is called a lexical comparison and it’s all over the place. When you compare polynomials, you compare the degree, not this arbitrary sum of monomial degrees. For string data, it is by far the most natural type of comparison. 
I'm humbled by your response. Your point about comparing polynomials is an apt analogy and didn't occur to me. Sometimes I suffer from tunnel vision
There's an infinite number of reasons to compare strings. All depends on what your strings represent and what you're trying to accomplish with them. A great many use cases care about string _equality_ but not necessarily ordering, for example. e.g., we're looking for a particular string but don't know or care what comes before or after it in any ordering. Sometimes we want to order strings by non-alphabetical criteria. e.g., to your point, maybe we want to sort strings by length so that we can display the 10 longest words in the dictionary, or maybe we want to sort strings by associated data... e.g., sorting player names in a game by their high scores. Strings might also represent arbitrary data _encoded_ as a string. A great example would be something like numeric data; you might want to sort numbers like "27 Apples" vs "9 Apples" vs "11 Pears". The standard lexicographical sort would make "9 Apples" the greater string and would put the pears between the two sets of apples (which might not be what you want). Sorting by just standard numerical qualities would still put the pears between the sets of apples. You hence might want a string sorting algorithm that sorts by units, then magnitude, then significant digits; e.g. you might want the ordering to be "9 Apples", "27 Apples", "11 Pears".
Thank you for replying! I'm still amazed that redditors take the time and effort to provide well-thought out replies. After reading all the comments I'm humbled by how little I know and how many possibilities there are for things that I never even thought about. I'll keep your comment in mind as I continue to learn.
**Absolutely it does, though with caveats.** Both MSC and Clang already do such an optimization in many cases. C++14 is allowed to elide or fuse certain classes of allocations in general and coroutines are no exception. That said, part of the motivation for the [Core Coroutines paper, p1063r0](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1063r0.pdf) is that while Gor's proposal _allows_ inlining and allocation elision, it is not guaranteed at all and it may be impossible in some other cases (e.g. `virtual` functions returning generators).
Huh, compiling that with "-Os" prevents inlining. That's somewhat counter intuitive I feel.
I agree. I also think the default C++ aliasing rules are a bad choice for high performance code. ISPC does not assume aliasing, neither does Fortran, by default. __restrict gets around the issue in C++, but feels like a hack.
Right. That would certainly be a way to do it. Then you wouldn't need to re-hash the files at build time. The build system I maintain at work does use hashing, and its extremely slow. Takes longer to do the hashing than to run the actual compile jobs (I am working yo improve this. Of course)
It makes sense. -Os optimizes for size, which can make a program more cache-friendly and often will run faster than an inlined equivalent that results in larger code size. This varies from program to program -- some programs run a lot slower with -Os compared to -O3. The only way to know is to measure the execution speed of both on a per-program basis.
That's not the fault of the compilers. That's the fault of the language. Place the blame in the appropriate place.
If you want to get more technical, C++ also has a notion of weak vs strong orderings for supporting things like partial sorts and stable sorts. I come from a math background too and plenty of concepts map over, and while thinking critically about what you learn is good, you may want to accumulate 3-5 years of experience before actually trying to criticize a concept haha
You may be interested in Rust's take on this. Part of the build artifacts is a dependency graph between the *items* (functions, structs, ...) inside a library/executable code. So the database is there, and its input is compiling text. This lets the user interact with text as usual, with all the tools they wish, and only require the compiler to access the database (which also means there's no stability required; the format can evolve as necessary).
Thanks for the anecdote. I'll check it out the next time I can!
I noted in the article that boost::hana uses the numeric literal template to provide \`\_c\`. But since you commented, I updated the post with a brief implementation of the user defined literal operator.
The compiler presumably thinks that inlining would just makes the program bigger and is not smart enough to realize that inlining in this case opens up the doors to a host of optimizations that actually make the binary significantly smaller.
https://stackoverflow.com/questions/13130708/what-is-the-advantage-of-using-universal-references-in-range-based-for-loops/13130795#13130795
Ah, thanks! Very cool talk!
First, I am hard pressed to think of a mathematical aggregate object that is conventionally ordered by summing in the way you describe. Neither of sequences, vectors, sets, nor matrices, are compared in such a way. In fact, in general, there is no "default" ordering for any of these objects, and if you do need to sort them in some way for purposes of proof, you must be explicit in what you mean (if it is important). In fact, off the top of my head, I can't think of any time that anything \*except\* the lexicographic ordering has been useful. Second, programming is not math. It is better thought of as a kind of engineering -- the goal is to construct programs that do something, and the building blocks that languages provide are chosen not for their abstract purity, but because they are useful for carrying out tasks. The primary uses for comparing strings are (1) testing for equality, and (2) sorting. Comparing sums isn't good for either. A system where "ab" compares as equivalent to "c" is not broadly helpful. Do note though that viewing lexicographic ordering as "alphabetical" is misleading. "Alphabetical order" is a construct of human language, and varies wildly by language. Implementing alphabetical ordering of text is surprisingly difficult.
FYI, the presenter is the commenter who provided a link to this godbolt example.
2035 and still using macros :-( May be we can use modules in C++2d
One example I use frequently at work is when using ranges that consume elements as the range is iterated over.
But I want a prototype and I want it *now*!
As others are pointing out; sorting is probably the biggest benefit to this approach. What use cases do you see for basically summing the values? I'm not seeing a lot of practicality to this; as strings are really only for text. There's not much that I find myself doing with strings other than sorting, matching, substring comparison, and parsing. Certainly not math!
Awesome
Yep! [C++ Weekly](https://www.youtube.com/user/lefticus1/playlists) Highly recommend incorporating what you learn before moving on. I find it goes in one ear and out the other, if I do not do this.
In algorithms we say find_if (or other ifs) then iterators/range and lambda. It always bothered me to no end. std::find_if([](int a){return a&gt;5;}, group); Looks much more readable.
Not in video format but there is text summary for [C++17](https://github.com/tvaneerd/cpp17_in_TTs) and [C++20](https://github.com/tvaneerd/cpp20_in_TTs) 
Dunno.. I just wrote an ``EnumeratorIterator&lt;Iterator&gt;`` utility that dereferences into a ``std::pair&lt;Iterator,size_t&gt;``, a proxy ``EnumeratedContainer&lt;Container&gt;`` that wraps a container and adds EnumeratorIterator as iterators, and was done with it. But with the extra complexity of adding eg.: ``.first, .second`` to the accesses, i just found myself going back to ye olde external counter variable. That simply put never fails.
The standard doesn't restrict any type of optimization as long as the program created acts "as if" it is doing all the steps. 
Can someone repost? Twitter always says I'm rate limited and refuses to show me content.
Could the C++ community at least standardize on a format for declaring dependencies, similar to Go and Rust's \*toml\* files? This way, even if we can't coalesce the C++ dependency managers into one, at least the packages can be interoperable between the package managers. Baby steps, yeah?
RHEL8 isn't officially out yet, at least last I checked. I haven't seen any information about it since apparently the beta was under NDA. I would be surprised if it came with GCC 7, since RHEL7 is only at 4.8. GCC 5 or 6 is more realistic.
I'm going to say Conan is pretty good here. If you can get Python running, you should be able to run Conan. There's some things about Conan that irk me, but it seems to be pretty good.
Any reason these are preprocessor things instead of constexpr?
I really like SlickEdit. It has very fast performance, especially with very large code bases. . 
Hunter.sh 
The simpler your tests are the better. If you're doing file IO and parsing text, etc., then that's a lot of things that could go wrong and lead to false positives or (worse) false negatives. It's best to just test expected values and show errors directly in your tests. You can do that just fine in a short program you write from scratch, or you can use one of the many unit test frameworks. Here's what gtest tests look like: https://github.com/google/googletest/blob/master/googletest/samples/sample1_unittest.cc
That's because turning off overcommit in production is stupid. GHC, for example, allocates about a terabyte of virtual memory but commits almost none of it. This is just how they do some of their memory management.
Conan sounds okay, but I no longer have patience for pulling in dynamic languages like Python, Ruby, Perl, or Tcl to manage systems language projects :P
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
`-Os` turns on `-finline-small-functions` but not `-finline-functions` so that large functions don't get copied everywhere and increase the binary size. That's probably the difference, for whatever reason it falls on the wrong side of that divide.
What's the problem? Just use 5 other scripting languages to manage C++ dependencies. It's not even that big of a download (and that's all that matters)
I’m pretty happy with vcpkg for Windows + macOS (targeting win32, winrt, ios, macos and droid).
I have a similar problem but in for\_each and sometimes, transform, especially when needing to iterate / transform two related containers of the same size. What I end up doing is std::for_each(i_begin, i_end, [o_iter = other_container.begin()]() mutable { // do some work o_iter++; }); but this obviously suffers from the same problem with indices, you could accidentally increment the iter more than once in the body of the lambda. Is there a better way to do this kind of operations?
A serialized syntax tree with whatever semantic annotations are convenient to produce at edit time. The editor would look and generally behave like a text editor but would actually be working on the tree data structure, not plaintext. (Some DSL workbenches do this already.) To ramp up adoption, you also store the plaintext source separately, but users of the plaintext source don't get to have the benefits of the syntax tree format so are motivated to adopt. But I don't see this ever happening. Plaintext is too simple and convenient, and any alternative would require too much infrastructure.
The as-if rule isn't applicable to the original question by itself. Allocation and `new` invocation are observable side effects within the abstract machine and hence elision thereof violates the as-if rule. Allocation and copy elision are examples of explicit exemptions to the impositions of as-if.
I mean, I get what you're saying, but Python is basically the new bash. It's about as ubiquitous as scripting languages get. 
On my phone and can't test, but I wonder if making the functions in an anonymous namespace or static would fix that for this example. The compiler generally has to assume that someone might use any function with external linkage so it has to keep a full version of it in the object file in addition to any inlined code. Making it static would allow the optimizer to see that it's only used in the one inlinable case.
I liked [this article](https://kyren.github.io/2018/09/14/rustconf-talk.html), which talks more about the maintainability aspects of this (albeit from the perspective of games).
I've thought that -Os "plays well with others." Another thing is build times. In a quick test, -O3 is over 50% slower than -Os. 
Excellent point. I've got so used to SSD's + today's c++ compilers handling massive template libraries efficiently via compiled headers that I sort of forgot that compile times can still be a limiting factor on large codebases.
I agree, OOP is not dead. However, I talking was that about your comment the "new" keyword being used in conjunction with objects would result in **object**-oriented programming. This is incorrect. OOP is not about having the concept of objects present in your code. OOP is about thinking about your software **only** in objects. Which IMO is the same as saying "functions --[results in]-&gt; functional programming"
I agree that maintainability is something that we will have to see in the long run but the points given on the performance, scalability, and testability looks very obvious IMO. 
Me too, I can't call myself a C++ package manager expert, but Vcpkg+CMake is a solid combo. Windows+Linux for me.
I don't believe I am. How do you think I am confused?
You mentioned that Functions results in functional programming is flawed Yes it is flawed. That's the point I was trying to make. In the first comment you said that OOP is not going away (being dead) because there's a "new" operator that is used for creating objects. This statement is flawed. Because I can use objects in my programs but that doesn't make my program objects-oriented. 
I think I'll try staying on top of CppCon after catching up on core language features. Thanks. :)
These are very helpful too!
&gt; In the first comment you said that OOP is not going away (being dead) because there's a "new" operator that is used for creating objects. Ah... I understand your confusion now. My referring to the "new" in "newing" up an object is that in most OO languages you can't avoid objects. That's all. OOP isn't going anywhere unless there are new languages that come along without objects. I think a lot of the confusion that people have is that in an object language OOD was the "common way of doing things" for a long time so people conflate OOD with OOP. There are other design paradigms that are used in OOP like DDD (Domain Driven Design). Just as you can have a language that supports functions but not do "functional programming". &gt; Because I can use objects in my programs but that doesn't make my program objects-oriented. Yes, by definition, it does. When you use an object (or create one... even if it has no parent but the global object)... you are object oriented. That is the definition. It is not a requirement that you use inheritence, polymorphism, or any of the other pillars. But they are there. Not using them doesn't mean you aren't still object oriented. 
&gt; new invocation are observable side effects within the abstract machine and hence elision thereof violates the as-if rule. Doesn't this show otherwise? https://godbolt.org/z/NuaRMH
Then you haven't seen the talk above. And our definition of OOP isn't allign. 
With the standard library, out-of-the-box – no. But any ranges or iterators library will provide some sort of `zip` functionality for exactly this, or you can write a zipping iterator in ~30 LOC.
I haven't seen a benchmark showing Os performing faster than O3 in a decade.
Maybe this is a weird question, but do you know if there is some place where we can see the list with a description of what all those libraries are, instead of that each library was updated to version x? I'm curious what's actually there, but not so curious that I want to google a couple of hundred libraries one by one... 
Not a weird question, really. I don't know if there's an exhaustive list anywhere, but you can get one by running "vcpkg search" or "vcpkg search &lt;package&gt;". I created a pastebin [post](https://pastebin.com/6L135qWT) with the search results, just now. Maybe that helps? 
&gt; One action you can take today to prepare for C++2a is to audit your codebase’s include directories for any text files named VERSION and move those files elsewhere! This is perhaps the most important thing, at least until 2020 :-O
&gt; This hasn't strictly been true since N3664 was incorporated into C++14... Which is why I said, "Allocation and copy elision are examples of explicit exemptions to the impositions of as-if." :)
Which directly contradicts your first paragraph. I guess I should have quoted... ;-]
I intended to quote your first paragraph when I replied and decided not to, as I misread your second paragraph. Understood now, and agreed.
As a data point: Build2 is preferably installed by running a script that relies on a C++ compiler and git to be available (by default). It downloads all it's sources and build itself. (On Windows, it also downloads some specially provided bash tools to be sure to be using the tools it needs). So as long as it's on a platform with a compiler and a network, I suppose it should work, or at least you can try it. I suppose that any tool that propose bootstrapping install will be the same. The only other build system I know to do the same is b2 (Boost Build 2 based on bjam, have nothing to do with Build2)
This.
There's a third option which is sometimes applicable: static polymorphism via the linker It may not be relevant or the best option for your case, as it's certainly not the best choice for every case. I would prefer it over anything that imposes templates in public headers where it does fit nicely, though, because compile times matter. The basic case is also a poster child for the PIMPL pattern in general: class file_parser { public: file_parser(); file_parser(file_parser const&amp;) = delete; ~file_parser(); void parse(); private: struct impl; unique_ptr&lt;impl&gt; _impl; }; file\_parser\_windows.cpp: struct file_parser::impl { /* windows implementation members */ } file_parser::file_parser() : _impl(make_unique&lt;impl&gt;()) {} file_parser::~file_parser() = default; void file_parser::parse() { /* windows stuff */ } file\_parser\_linux.cpp struct file_parser::impl { /* linux implementation members */ } file_parser::file_parser() : _impl(make_unique&lt;impl&gt;()) {} file_parser::~file_parser() = default; void file_parser::parse() { /* linux stuff */ } Only compile the .cpp files appropriate for the target platform. The linker ensures the right implementation is chosen, and the fact that there even *are* multiple implementations is entirely hidden from the public interface. Compilation stays very lean. If you don't have implementation-specific members, you can get rid of the PIMPL stuff and its accompanying allocation. I find in most cases (where your class isn't doing too much) your platform-specific members mostly boil down to an OS resource handle which can be encoded into a `inptr_t` (since both POSIX `int` handles and Windows' `HANDLE`/`void*` handles fit) and no additional allocation is necessary. e.g., an example of a network handle wrapper I've used tends to look like: class Socket { public: Socket() = default; ~Socket() { close(); } Socket(Socket&amp;&amp; rhs) : _handle(rhs._handle) { rhs._handle = -1; } // condensed example, doesn't handle self-assignment correctly Socket&amp; operator=(Socket&amp;&amp; rhs) { close(); _handle = rhs._handle; rhs._handle = -1; return *this; } explicit operator bool() const { return _handle != -1; } static Socket open(string host, int port); void close(); void write(span&lt;const byte&gt; data); int read(span&lt;byte&gt; buffer); private: Socket(intptr_t handle) : _handle(handle) {} intptr_t _handle = -1; }; // socket_linux.cpp partial implementation Socket Socket::open(string host, int port) { int handle = ::socket(...); ::bind(handle, ...); return Socket(handle); } void Socket::write(span&lt;const byte&gt; data) { ::send(_handle, data.data(), data.size(), 0); } // socket_windows.cpp partial implementation Socket Socket::open(string host, int port) { SOCKET handle = ::socket(...); ::bind(handle, ...); return Socket(reintpret_cast&lt;intptr_t&gt;(handle)); } void Socket::write(span&lt;const byte&gt; data) { SOCKET handle = reinterpret_cast&lt;SOCKET&gt;(_handle); Send(handle, data.data(), data.size(), 0); } The platform abstraction is entirely hidden inside the singular TU, there's no additional allocations or platform-specific state, etc. Introduces exceedingly minimal compile time compared to straight C code while still providing OS abstraction and the C++ RAII safety.
Hunter should, theoretically, work everywhere the recent versions of CMake works. At the very least, it includes Windows/MacOS/Linux + iOS and Android cross-platform compilation under any of those OSes. I think FreeBSD will work too, but not sure about the rest of them (I see a platform file for Haiku in CMake's official repo, so I guess it should work there?).
It's not stupid when the OOM killer starts killing random processes and you start having reliability issues.
Thanks! This is very helpful.
you have to exclude the "not used" implementation from compilation too, or am i wrong (not just from the linker)? since otherwise your compilation does have 2 different definitions for the same declaration?
`git submodule add`
The linux version won't compile on windows; the windows one won't compile on linux. So, no problem.
Yes. link-time polymorphism. You would have to use the preprocessor or build system, because by definitions you want to include different non-standard C++ headers depending on a static condition. Also, have a look at '\_\_has\_include', [https://en.cppreference.com/w/cpp/preprocessor/include](https://en.cppreference.com/w/cpp/preprocessor/include)
 # Pseudocode of build script if(WIN32) add_subdirectory("file_parser/windows") elseif(UNIX) add_subdirectory("file_parser/unix") else() message(SEND_ERROR "Unknown OS. No file_parser implementation is chosen.") endif() 
In general, I would keep the system-dependent stuff as far down as I could. Certainly I wouldn't want to see it at the application level. You can use `#ifdef` inside file_parser to separate Windows-specific code from Linux-specific code as appropriate. 
&gt; I would be surprised if it came with GCC 7, since RHEL7 is only at 4.8. GCC 5 or 6 is more realistic. RHEL 7 was released just after GCC 4.9 was released (with beta vailable eve nbefore that). It couldn't possibly have had anything newer. 
Dr. Robert Ford: Wasn't it Oppenheimer who said, "that any man whose mistake takes 10 years to correct, is quite a man?" Mine have taken 35. Barney Starsoup: sigh... 
keep it simple: don't go overboard with all the features c++ offers. Think critically about interfaces, make sure each function or class does one thing. 
What would you consider a more refined one?
Huh, you are correct. At work we are only now transitioning to RHEL 7, though part of that is probably the controversy over how the admin tools changed.
Don't use __has_include for that. You want to make a decision based on the OS? Make it based on the OS - not based on the ability of some header.
&gt;I'm trying to figure out what are the proper design pattern for the situation, when to write code or look for a library, and making sure the components are working in a modular (orthogonal) fashion and aren't interdependent on other components. The design pattern comes after you've written a first draft of your code. Let the pattern naturally come to you as you write, don't go looking for one or imposing one. And all design patterns are just fancy usages of lambdas or function objects. If your organization and policies allow, always look for a library first. Learn from the libraries you use what their approaches to modularity are and what makes them work or not work orthogonally. And again, there's no better way to break interdependency than with a lambda or function object.
Stay up to date with what's happening with the language and work with the direction it's heading. Ie try to make good use of new features (where appropriate). A lot of people seem to think C++11 or 14 is modern C++ and stop there.
I won't claim to be an expert after few years of using C++ but here's some advice that may be useful to you: &amp;#x200B; Design patterns are often overdone by beginners, don't try to focus too much on them and fit code into some specific patterns, rather think about the design first and see what patterns arise "naturally". Read books by Scott Meyers and Herb Sutter, they deal with some tricky details of C++, some are about older standards but much of it still applies. If you ever need to write code where performance is critical, learn about caches and how to write cache friendly code. Don't think about the compilers as magic tools that can fix any problems you have, learn what they can do and what they can't do. Learn about advantages and disadvantages of STL containers and data structures behind them. &amp;#x200B; Don't overuse exceptions, stack unwinding is costly. &amp;#x200B; Avoid raw new and delete, prefer smart pointers (most of the time std::unique\_ptr), avoid pointers in general until you need them. Understand RAII, move semantics. Avoid macros, if you have an alternative you can use, choose it over macros. &amp;#x200B; Learn C++ idioms like erase-remove, pimpl. &amp;#x200B; Compile with high level of warnings, treat warnings as errors. They are often very important in C++, which is not the case in all languages so some people tend to ignore them. &amp;#x200B; And this is more general OOP than C++ specific but: prefer composition over inheritance. [https://stackoverflow.com/questions/49002/prefer-composition-over-inheritance](https://stackoverflow.com/questions/49002/prefer-composition-over-inheritance) &amp;#x200B; And to be clear, by "avoid" nad "prefer" I don't mean "never use".
IIRC the initial ranges proposal was just the core of ranges, they're currently working on adding all the other stuff as a separate proposal.
&gt; there's no better way to break interdependency than with a lambda or function object. Can you elaborate on this? I've used lambdas before and assigned them to function objects, but I'm not seeing the full pictures. 
**Do "real word" projects, even if they are hobby ones.** This will force you into solving problems yourself, which is what programming and engineering in general is all about. **Refactor** Learn to destroy and create anew. This is unique to programming - an engineer can't do this - take advantage of it. **Interdependency == Complexity** Create class and functions which depend on each other as least as possible and have the smallest possible public interface.
&gt; Design patterns are often overdone by beginners, don't try to focus too much on them and fit code into some specific patterns, rather think about the design first and see what patterns arise "naturally". Thanks, this is a relief to here. This was leading to a bit of confusion for me, as many mentors have suggested learning design patterns and I have gotten asked about them in interviews. I was definitely heading in this direction. &gt; Read books by Scott Meyers and Herb Sutter, they deal with some tricky details of C++, some are about older standards but much of it still applies. Scott Meyers is a great writer for sure. I have seen Herb Sutter's talk at the most recent C++ con, great guy! I'll definitely look up his books. &gt; If you ever need to write code where performance is critical, learn about caches and how to write cache friendly code. Don't think about the compilers as magic tools that can fix any problems you have, learn what they can do and what they can't do. Learn about advantages and disadvantages of STL containers and data structures behind them. One of the most popular talks in the cpp con youtube channel is about a game engine developer talking about how expensive reads are due to cache misses! I typically use the STL by default, and I should learn when NOT to use them. &gt; Don't overuse exceptions, stack unwinding is costly. Great, I'll need to read more on this. &gt; Avoid raw new and delete, prefer smart pointers (most of the time std::unique_ptr), avoid pointers in general until you need them. Understand RAII, move semantics. I'm just starting to play with this. I was designing a factory class that used smart pointers and I had to call std:move quite a bit to store and do things with the smart pointer. Should a user of a class ever see the smart pointer, or should it be wrapped in something else? Otherwise it might look something like: my_ptr-&gt;get().my_func() whenever I want to use it. &gt; Avoid macros, if you have an alternative you can use, choose it over macros. &gt; Learn C++ idioms like erase-remove, pimpl. I'll google these &gt; Compile with high level of warnings, treat warnings as errors. They are often very important in C++, which is not the case in all languages so some people tend to ignore them. I do this a lot! I should look for more useful warning. I just started using clang-tidy warning in my code, how strict are you about the LLVM coding standards? &gt; And this is more general OOP than C++ specific but: prefer composition over inheritance. https://stackoverflow.com/questions/49002/prefer-composition-over-inheritance Will read &gt; And to be clear, by "avoid" and "prefer" I don't mean "never use" or "always use". Gotcha!
Right, I guess I haven't looked too deeply into c++ 17 and beyond since cmake doesn't support anything past 14 yet, but I pick up some things watching lectures. What are you preferred news sources?
C++17 is already out and has been for a while, you should be learning and using its features where appropriate. Specifically learning earlier C++ versions and ignoring the latest is misguided and probably a waste of time. As for news sources, stuff like this subreddit is good for exposure to new features. Also if you're writing C++ often and using [cppreference](https://en.cppreference.com/w/) for reference, you'll inevitably see (confirmed) new features there.
Good to know! I’m glad CMake has become a de facto standard for building C/C++ projects. In practice, it seems to support tons of environments. The very few that CMake doesn’t have basic OS packages in are really obscure systems like the community maintained 32-bit CentOS variant and Plan 9. Maybe AIX, HP UX, Amiga have a CMake gap, but I can’t even get those setup in Vagrant so who knows.
Yeah, I’m impressed that Microsoft officially supports vcpkg on Linux and macOS as well as Windows. For my purposes though, I want my systems language projects to be buildable even further along the obscure OS spectrum. Any word on FreeBSD support for vcpkg? Illumos? Haiku?
I see, this makes sense. The library and the caller should be able to have a conversation solely through the interface alone. I use transform quite a bit, and a few other functions from algorithm. So I can definitely appreciate this. 
&gt; I'm just starting to play with this. I was designing a factory class that used smart pointers and I had to call std:move quite a bit to store and do things with the smart pointer. Should a user of a class ever see the smart pointer, or should it be wrapped in something else? Smart pointers are about ownership, only move the unique\_ptr around if the ownership is meant to be changed. (that's what you're doing when moving after all) Otherwise you can pass a reference to the object the pointer points to, and the user doesn't need to know it's managed by a unique\_ptr. So in your case you may return a unique\_ptr from the factory method, but once it's passed to the owner just pass around the reference. For example suppose you have a function f that takes a reference to some class X, and my\_ptr is a unique\_ptr&lt;X&gt;. You can pass it to f without moving or copying like this: f(*my_ptr); &amp;#x200B;
&gt; Don't overuse exceptions, stack unwinding is costly. &gt; &gt; Great, I'll need to read more on this. If you're working in an mpi world, and presumably you are if you're running on clusters, for the most part c++ exceptions simply aren't used. 
If it has a name it isn‘t a rvalue.
Note that if you do this you lose the best feature of static polymorphism, which is the inlining. For I/O glasses this is unlikely to matter though.
&gt; Avoid macros, if you have an alternative you can use, choose it over macros. This, however people need to learn when macros are required, creating something that is constexpr is great &amp; all but when you need to define an enum that also needs to have data (e.g. map enums to strings) macros are invaluable to do so.
I thought that it would make the reference itself an lvalue, not what it refers to?
Nice! I wrote some ad-hoc scripts to allow our CI to generate web pages with plotly charts from google benchmark json, but this is much nicer for manual comparison. Reminds me a lot of massif-visualiser. A suggestion: I found it very useful to plot each individual run time for each benchmark along with the average time and standard deviation as error bars. It's a dumbed down version of what Bryce Adelstein Lelbach suggests in his CppCon 2015 talk on benchmarking, but still quite valuable.
Write something! Come up with a real problem that you want to solve, and solve it by writing code. You could try some katas, too. These are small little problems to practice on. But basically, get your hands dirty. Theory is great, but so is experience. 
Make the boring stuff second nature so it will never keep you from doing it. Don't cut yourself too much slack when starting off when it comes to hack-y solutions without examining why you're doing so. For example, if you're making something that you want to separate out into a lib, *then do it,* and if you don't think it's important enough to do then either it shouldn't be a library, you've got a serious time constraint, or your priorities are off. Splitting off code has a bunch of administrative tasks to it, creating a new project, make sure it conforms to your folder structure, track it on source control. Don't let that stuff get it your way, work it into your muscle memory.
I also can fly to US, buy a gun, and shoot myself.
`co_rrect&lt;=&gt;` yourself before you `co_rekt&lt;=&gt;` yourself
I see. I never thought about de referencing it. Where can I read more about ownership? I thought I understood the concept, but maybe I don't. I'll search through this subreddit as well.
&gt;I guess maybe they back ported the behavior as a vendor extension. That's interesting. I still hope that vendors back port string\_view to 2011 C++.
Yep, I currently have a project I want to work on. There are macronutrient/calorie trackers, but many of them don't track micronutrients. I want to create a software that will solve this problem. In a sense, someone with have a caloric goal with certain macronutrients. This person will also have their favorite foods/recipes. They can track their calories and the software will mention what kind of macro nutrient deficiencies they might have and what studies say are the long term implications of it. I'd ideally like to collaborate with examine.com, nutritiondata.self.com, and maybe even get input from some researchers. 
As long as you have a C++ compiler you should be good to go. You may need to do some manual fix ups if those OSs differ wildly from a plain Linux environment; and of course the packages themselves need to be build able on your platform / architecture. For example I had to do some fix ups in boost context to properly build on iOS arm64, because it makes heavy use of assembly and it was picking the wrong files to build.
How would you recommend I go about testing my software? I haven't looked too deeply into this yet since the code base at work has its won internal testing with bash scripts being called with make test. I was thinking of doing something such that cmake will do its testing thing and could write a C++ program that includes a header file, and I test every function using asserts. This program then gets called, and I would have a testing directory with a bunch of tests stored in sub directories. Although this is really a place where I have a deficit in. 
Thanks, I haven't created my own libs yet, but that sounds like something neat. I do have a bash script that generates a directory structure with a basic cmake lists folder, as well as turning it into a git repository. Git and source control is ingrained into my psyche haha. I can definitely appreciate working it into muscle memory. It sucks after a while when you that muscle memory atrophies and it takes that much more effort! So maintaining that skill and improving it is something I'm striving for. 
\- Just dont use raw pointers, its not worth it. unique\_ptr and shared\_ptr (created with make\_shared(...) !) will do your thing and the compiler optimizes then nearly away \- Have a look at &lt;algorithm&gt; there is alot of great stuff in there which saves you much time ([https://www.youtube.com/watch?v=2olsGf6JIkU](https://www.youtube.com/watch?v=2olsGf6JIkU))
Using [gtest](https://github.com/google/googletest) is probably the most popular way to unit test your C++ code. I'm not up to date on any resources on unit testing, but I recommend reading about Test Driven Development (I'm not recommending that you switch to test driven development, just that the skills you learn will help you write better unit tests.) I attended a 3 day lecture by the author of this [guide](http://misko.hevery.com/code-reviewers-guide/). It's what started me down the path of unit tests. But looking at it, it seems a little advanced for an introduction. As far as what to do with the gang of four book, I'd say you're doing the right thing by prioritizing other books first. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9s4pyw/how_to_learn_c_for_an_experienced_developer/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Not everything needs to be a class. Stateless operations should just be a function. 
Would putting these into a namespace be okay?
When i go for this approach, i just add all the implementation files in the build script, and file_parser/unix has a #ifdef _COMPILER_PROVIDED_PLATFORM_DEF around the whole file 
Dunno how familiar you are with mpi, but the programming model generally follows the single program multiple data paradigm. It doesn't *have* to be this way, but most parallel numerical codes like you'll find running at national labs are. There's an underlying assumption there that every process is executing the same instructions at the same time; everything follows the same execution path. If an exception is thrown on one process but not all the others, that assumption gets broken and processes took divergent paths. It's not often clear how or if you can recover from that in a distributed environment, hence people don't usually use exceptions. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9s566e/please_help_me_understand_what_i_did_wrong/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
MyFitnessPal does this I'm pretty sure. Maybe your idea could work on data that has been exported from MFP?
&gt; it's spyware, it's unstable, it's just terrible. I like linux but people are not going to take you seriously when you say things like that.
**Write your tests!** Testing it not for QA to do, it's your job to ensure that your code is tested. Not only does it ensure that you shipped something correct, but it also gives you *sooo* much more freedom to improve and refactor because the tests have. you covered ** Write testable code ** Writing code that exposes the right seams is critical for being able to test it. For instance, dependency injection lets you swap out mock behaviors for external frameworks or even servers. ** Write test harnesses ** Interact with a server? Write a mock version of that server, even just one that spits back static data you captured from the real server. Interact with a piece of hardware? Write a mock version of the hardware, even one that just spits back data captured from the real hardware. ** Use the test tools ** You should be able to quickly view your [code coverage](https://clang.llvm.org/docs/SourceBasedCodeCoverage.html#id7). Use additional runtime sanitizers like UBSAN, ASAN, valgrind, et al to make sure your tests are running in maximum-pedantry mode. ** Test adversarially ** Think of all the things the "other end" (whether it's a user, some other software, a server, a piece of hardware) could do if it was pathologically trying to make you fail. Note: this includes things totally violating the relevant documentation/spec. You don't have to handle such pathological cases well, but you. do have to say 'this server gave me X, it's wrong because Y, bail'.
- https://simpleprogrammer.com/powershell-tutorial/ - https://www.tutorialspoint.com/powershell/index.htm These both look decent for intros. The first one is a bit verbose before it gets started.
Excellent point, one I forgot to mention, thank you. Aside from a few concurrency-related things though, I've found most platform abstraction to exist at boundaries where inlining isn't especially important, like you said. Whole program optimization for final release builds also of course can help even in those cases.
&gt; Should a user of a class ever see the smart pointer, or should it be wrapped in something else? Otherwise it might look something like: &gt; &gt; &gt; whenever I want to use it. Never ever do my_ptr-&gt;get()-&gt;my_func() Since the same can be accomplished by my_ptr-&gt;my_func()
Many things can be implemented in a simple way by using the tools given to you in the standard libraries (and any other libraries you are allowed to use) - there's no need to reinvent the wheel. Where you can't write simple code, abstract the complexities away so that the rest of the code that depend on the complex abstraction is still simple.
I've been really busy this weekend, but I put together a 5 minute from-scratch walkthrough of setting up VS Code with Rust: https://streamable.com/ronq9 I used the GNU toolchain because I didn't also want to spend time installing Microsoft's Visual C++ stuff that's necessary to get the `link.exe` that's needed to link MSVC executables. Hopefully this helps.
&gt; Supported values are 98, 11, 14, 17, and 20.
This is good advice. You will encounter people who fear moving forward, fear new features, libraries, tools, etc. Those people are a drag on progress in general, largely due to their own personal inadequacies -- and the worst part is that they think they are blessings. 
&gt;Barney Starsoup
Learn other languages. You can learn from them and bring those techniques back to c++.
HTTPS is working now :) http://cpp.al
We are still working out all of the details!
Hmm, I disagree! The C++ Alliance official position on open source licenses is to prefer "permissive" licenses such as the Boost Software License, which allows usage in commercial software without the requirement to make everything open source. Compare this with the GPL (which we prefer not to use) which "infects" anything it is mixed with. Just because we are supporting open source, does not mean that we discourage closed-source (we just don't fund it).
&gt;Don't overuse exceptions, stack unwinding is costly. Actually there were some benchmark tests on C style error handling vs exceptions. Results were very interesting. You can not easily say one is better than another. [http://nibblestew.blogspot.com/2017/01/measuring-execution-performance-of-c.html](http://nibblestew.blogspot.com/2017/01/measuring-execution-performance-of-c.html) &gt; Avoid raw new and delete, prefer smart pointers (most of the time std::unique\_ptr), Instead of completely avoiding new and delete, I think favoring smart pointers is a better approach. &gt;avoid pointers in general until you need them. I just love my pointers man.
&gt; pimpl This one has always confused me a bit, is PIMPL strictly a means to speed up compilation times, or is there something else behind it?
avoid pointers seriously
Small nitpick: `std::make_shared` is C++11.
The C++20 one is obviously lacking - PRs welcomed. C++20 looks to be big, so lots to do!
Years ago I used unique\_ptr and std::string more than I do today. [https://stackoverflow.com/questions/38780596/how-to-handle-constructors-that-must-acquire-multiple-resources-in-an-exception](https://stackoverflow.com/questions/38780596/how-to-handle-constructors-that-must-acquire-multiple-resources-in-an-exception) &amp;#x200B;
Really, I swear I thought I read it only supported up to 14. Dude, I'll make sure to look into this. 
Thanks!
I've never taken real analysis or topology. I've taken numerical methods/analysis and linear analysis (theoretical linear algebra). My degree is Computer Science &amp; Engineering, so I didn't get to take as much math as I'd like. I will be going back to school though since I get a fully funded master's where I work, so I'll definitely take more math courses.
Watch this talk about the topic: https://www.youtube.com/watch?v=WLDT1lDOsb4
Pick a test framework and build with that. I would recommend against gtest/gmock, and go with [Catch2](https://github.com/catchorg/Catch2) and [Trompeloeil](https://github.com/rollbear/trompeloeil). There are some other alternatives like [Lest](https://github.com/martinmoene/lest) and [Doctest](https://github.com/onqtam/doctest), but i just prefer something supported out of the box in IDEs, Catch mostly is. 
&gt; Learn C++ idioms like erase-remove, pimpl. Can you explain the benefits of pimpl or point me to a resource about it? At my workplace, we have some code to be consumed (internally) as though they were external libraries, so we program to public headers, and the implementation is pimplized. But some people pimpl code within their own section of the code, and I don't really understand why it's necessary to separate the implementation from the interface in these cases 
It's to hide the implementation details (such as private member variables) from the user. It also has the added benefit of reducing the number of files you need to recompile.
Don’t go to Internet forums for validation.
How are exceptions different from if/ else and other conditional control flow mechanisms in that regard? Exceptions are used to signal errors (for various definitions of errors). If you don't use them, you need other mechanisms to deal with errors which will also lead to a divergent control flow. On the other hand, if you don't handle errors at all, you don't use exceptions anyway. 
Just clarifying it should be simple to understand and maintain, not fast to implement. A simple design can take a few code iterations and rewrites to achieve.
Most important advice buried deep down again. Sometimes you are good to go if you can write barely functioning code. But relations with coworkers and superiors are way more important in all settings.
I really recommend real analysis for someone in your position who has the time for the class. It really shows the power of a few abstractions; open sets, limits, convergence of functions under different metrics, or even metrics for that matter. Real Analysis also shows you what to watch out for and to think carefully about obvious things. Some things that seem obviously true are true but it's not obvious why and takes work to actually show it. Some things that are obviously true are not, such as the existence of a continuous function that is nowhere differentiable. How does this apply to programming and software engineering? You'll be creating abstractions to make the programming easier. Often the abstraction doesn't end up being the right one or doing quite what you want or it doesn't fit nicely in your system. Classes like the ones I mentioned show you some good abstractions at work in a different context to give you a sense of what nice abstractions are like. Other times you'll come up with an abstraction and it doesn't quite work right because there's a corner case that you didn't consider that comes up. It's useful to get experience with these. Limits of continuous functions are an example here (depending on how you take the limit determines whether or not the limit of a sequence of continuous functions is continuous itself). Enjoy!
&gt;Actually there were some benchmark tests on C style error handling vs exceptions. Results were very interesting. You can not easily say one is better than another. Then there's this: [https://www.reddit.com/r/cpp/comments/6an103/exceptions\_performance\_again/](https://www.reddit.com/r/cpp/comments/6an103/exceptions_performance_again/)¯\\\_(ツ)\_/¯ &gt;Instead of completely avoiding new and delete, I think favoring smart pointers is a better approach. I think it should be both, people coming from languages like Java often overuse new or dynamic allocations in general when they don't need them, and that kind of thing should be avoided when there are no benefits over automatic storage.
Some basic stuff I wish others has told me: **default to references over raw pointers** unique_ptr can be complicated to learn early on, so just default to references, until you need to know pointers, and then learn unique_ptr first instead of raw pointers. **reference collapsing rules** Eventually you'll get to the point where you're playing with functions and you start exploring pass-by-value vs pass-by-reference. Just about every new C++ programmer comes to a point when they're using references and everything explodes. It will not compile. They then try brute forcing the problem adding another &amp;, removing a &amp;, trying to add a *, and all sorts of other combinations just to get the dang compile error to go away. Instead, do yourself a favor, and learn reference collapsing rules, and never have confusion about this common pitfall again. **rule of 5 (and rule of 3) idiom** Usually one starts learning idioms after they've mastered a language's syntax, but I think this one is the exception. When first learning to create a class, try to master the rule of 5, maybe around the time of the second or third class you've made. It is a bit more of an advanced subject, but early on I ran into a lot of unexpected behavior when creating classes until I learned to put `= delete` in front of things like copy constructors, even if I had no intention of ever using them. Exploring this subject will allow you to have an easier understanding of move semantics and copy semantics, making it easier to learn smart pointers later on. **beware of implicit conversions** This isn't something that is important to learn early on, but most of the run time bugs in C++ come from three things: implicit type conversions, unhanded exceptions, and threading issues. Implicit conversions are the easiest to deal with. Compilers like gcc have flags like `-Wconversion` which will catch it for you, saving a lot of future headache. **Learn testing!** This is less a C++ thing and more an any language thing. Learning how to write systems tests and unit tests is important. If you're serious about going into the industry, learn it, love it, and become a role model. Testing is a clear indicator if a mid sided project is a good well kept one, or a polished turd. This rule of thumb is not 100%, but it's a valuable indicator worth keeping in mind.
I know this is for teaching purposes but I really hope people use `auto p = std::make_shared&lt;T&gt;(...);` instead of writing `std::shared_ptr&lt;T&gt; p = std::make_shared&lt;T&gt;(...);` 
My biggest tips are generally in the realm of software development and not overly specific to c++: * Focus on writing clear, meaningful code. * You can hide the details behind meaningful method names. * Corollary: The compiler is smarter than you. * See the past cppcon talks from Matt Godbolt "What has my compiler done for me". Trying to be clever makes the compilers job harder and likely is slower than the clear code. * Understand the machine. * There's lots of material on "Data Oriented Design", also see Chandler Carruth's talk on efficiency and performance. * If you need a container, there's a good chance you want vector. * If you need performance, have a benchmark. * If you think that something clever will be faster than something obvious, prove it. * Keep the benchmark in your testing suite. If you upgrade compilers in the future and the winner changes, you may want to revisit past decisions. * You mention knowing when to write something and when to search for a library. * If something seems like a common task, there's probably a library for that. * If something is specific to the domain you're solving problems in, the odds are much lower. * Don't try to push functionality up the stack. * When maintaining common components, it's frequent for users to file feature requests to push functionality into the library. This often leads to bloat and has limited use. As you move to more core functionality, it becomes important to say "no" to these requests. There's probably a bunch more if I think about it.
Good article overall. Even though there are some errors here and there.
Whoa, half way through that talk and it's really freeing my mind hehe.
Keep it simple.
Just curious why? Both are correct, one is a little more verbose but that is it. What does *auto* do other than define a data type? 
They're facts.
Write the simplest code that will get the job done. Do not feel like you have to use language features for the sake of it. Example - my first major project I used an inheritance hierarchy that I now regard as completely pointless and it would have been simpler just to have a member variable differentiating the behaviours. 
It is separation of interface and implementation. Unfortunately C++ can't do this natively so the pimpl hack is the only way to achieve it. The client who wants to use your class has no reason whatsoever to know about private functions and variables. 
If else flow control is part of normal operation, so when you're writing mpi code you account for that -- collective operations, barriers, communication, that stuff either can't be conditional, or you work out some guarantees that every process follows the same path. Exceptions are by definition *exceptional* and in a distributed environment it's highly unlikely you can recover from them anyway without just aborting, which is what is typically done. 
That makes sense. When learning about pimpl, the whole time I was thinking, "wow, this seems pretty hacky", but I guess if it's a standard way to do it... it's not? haha
There are other drawbacks to pImpl , mainly around the fact that it means 2 allocations are needed for every object creation; mostly what happens is that people avoid it and just deal with the fact that private members have to be mentioned in the header.
Same with `make_unique`
[Don't Repeat Yourself](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself) principle. 
Can you post some example code? There's probably some error with lifetime
So just syntactic sugar so you don't have to type the variable type information a second time, but no other value?
You could put it that way; avoiding re-typing things makes the code easier to read and reduces the possibility of errors. 
 class Customer{ public: string Item; int Quantity; int TotalPrice; string AcctID; int CardNo; string Email; }; static Customer ID; (ive changed it back to how it was for reference.) ID.TotalPrice=z; ID.AcctID=name; if (ID.AcctID=="alex"){ if (ID.CardNo==23456789&amp;&amp;ID.Email=="alex@ttu.edu"){ printf("verified\n"); printf("confirmation sent to alex@ttu.edu"); } else printf("not verified\n"); this was part of my verify funciton, and the function to input the data looks like: Customer CustomerInfo(Customer ID){ string x; int y; float z; string name; string email; int cardNum; cout &lt;&lt; "Please enter your account name: "; cin &gt;&gt; name; cout &lt;&lt; "Please enter an item value: "; cin &gt;&gt; x; cout &lt;&lt; "Please enter amount: "; cin &gt;&gt; y; cout &lt;&lt; "Please enter email: "; cin &gt;&gt; email; cout &lt;&lt; "Please enter card number: "; cin &gt;&gt; cardNum; ID.Email=email; ID.Item=x; ID.Quantity=y; ID.CardNo=cardNum; if (x == "note"){ z=6.667*y; } if (x=="book"){ z=20*y; } if (x=="pencil"){ z=2*y; } cout&lt;&lt;"total cost is: " &lt;&lt;z&lt;&lt;endl; ID.TotalPrice=z; ID.AcctID=name; returning ID after both. This is also just a bit of my code.
I got burned by FakeIt's [lack of support for verifying mock function calls taking parameters by const reference](https://github.com/eranpeer/FakeIt/issues/110). I'm curious as to why you recommend Trompeloeil over gmock. Gmock looked more mature the last time I compared the two, which was a while ago.
Sure. You might also consider static functions in a class if you have related methods.
In some cases it does like in the example above where you know explicitly the data type for **p** because the right hand side spells it out. But using it like auto p = someReturnType(); hides information so you don't really know what **p** is.
 Customer CustomerInfo(~~Customer ID~~){ &amp;#x200B; You are creating a local copy of ID here. Every change is only applied to it and not the static global ID. I'd recommend not doing this static Customer thing at all. Just create Customer Objects and pass them around either by copy or reference.
ahhhh, yes i think that is correct. Thanks!
That’s for v3.13. 
Hey thanks for this. A recent API I used utilises smart pointers.. really needed a good understanding ;)
I would definitely recommend using Catch2 over gtest. It's a complete joy to use, is extremely easy to set up and let's you test in much more expressive way that makes use of C++'s scope system.
I've never heard of Catch2. Looks interesting!
I worked on a project a while ago using gmock quite heavily and the compile and link times for the unit tests were insane. Seems we were paying more than we were gaining from it to be honest! This was maybe 5-6 years ago, so maybe they've improved it since. In my current project we use Catch2 and write our own fakes manually. It really doesn't take any time at all to write them.
If you want to make that argument compelling, the example should have _good_ variable and function names instead of generic ones. It really shifts focus away from your point.
Create a shared pointer holding a raw dynamically allocated array? This seems like a terrible thing to encourage a beginner to do. Why not just create a dynamically allocated std::vector wrapped in a shared_ptr if you need an array with shared ownership semantics? Maybe the author was just trying find a justification to use a custom deleter, but still... they just got done explaining why using raw pointers was dangerous. I really can't understand why this was used as an example. Another nit: &gt;but it shouldn't make the code slow unless you continuously create and destroy smart pointers. This has less to do with raw pointers than the fact that it's the allocations and deallocations that are slow, not the smart pointers. Granted, if you don't use make_shared, a shared pointer has to make *two* allocations, which would exacerbate the issue significantly. 
&gt;I would prefer the free function since C::bar would also have access to member2. This is a very good point for when we are creating a function specific to a method. It's relationship is to that method and not the class so it keeps what is essentially the content of methods out of the class header file.
Looking at things others didn't cover: * Computers are fantastically fast. Billions of operations per second. This means not to optimize before you have to. If your code is slow at any point there is probably some architectural optimization that can be done. For instance, it is often faster to get data of another computer on a fast network than it is to get it from the internal HD. * Unit test the crap out of your code. Once you are writing code that depends on previous code any unknown bugs in the previous code will potentially look like bugs in your new code. This slows your new code development down. Thus unit tests not only reduce bugs but more than pay for themselves in speed. * Make sure you are using newer C++. If you are using new/delete then there is a good chance that you are using something old. If you are using things like malloc then you should give my regards to Shakespeare as you are so far back in time. * Look up technical debt and then study its various forms. There are many forms of technical debt and they each have their reasons, preventions, and cures. This last is critical. If you are writing some code for a homework assignment you probably don't need to think much about technical debt. In a larger project your goal is to mitigate technical debt as it inevitably builds up so that it doesn't overwhelm you before you are able to finish. This last is how so many projects fail or go massively over schedule/budget. They don't manage technical debt, it manages them. 
All you need is `_start`.
i don't want to downvote, but i think this is a weak argument in the general case. redundancy has it's upsides! * to visually scan code. it' usually enough to scan the center/left for variable name+type, but when auto is involved i have to look over to the right also. (not a big issue, but i remember it bothers me sometimes, esp. when the right is a function call) * `for(int i = 0; i &lt; 3; i++)` here `i` appears 3 times. still short, and gives us incredible flexibility again, not saying let's put redundancy everywhere. but i don't think we need or even want to reduce it to zero either. 
1st point is weak. You could argue just the same that such useless repetition makes the code scan/reading harder. Don't see how the 2nd point relates to the problem.
Unless you're changing your enum all the time, you're often better off writing a script in a sane language that will generate the map you want and copy that in your code. Sometimes automating this with macros is not worth the potential trouble.
You only need 2 allocations if you don't use a placement new on reserved storage of the main class. For your main class you put a `std::byte[MySize]`attribute. In the pimpl you add a `static_assert(MySize==sizeof(pimpl))` You will force some recompilation when changing the size, but you avoid the double allocation. You may have to consider alignment in some cases but that's the idea.
The real evil thing to do is define C++ to do C--
Well rust allows to link C code so well no reason it couldn't link rust of a different version.
Sorry about that. It's also posted on LinkedIn, if that works: [https://www.linkedin.com/jobs/view/883171574/](https://www.linkedin.com/jobs/view/883171574/)
!removehelp
Please read the sidebar: &gt; For C++ questions, answers, help, and advice see /r/cpp_questions or [StackOverflow](http://stackoverflow.com).
Internationalize it. I'm an expat living in Eastern Europe. There are a lot of medical conditions here that I think are pretty uncommon in America, particularly musculoskeletal and digestive. I struggle constantly with micro-nutrient deficiency with the local diet. I can tell magnesium because I start getting cramps in my legs. The only good sources seem like frozen broccoli, which is expensive and low quality, or dark chocolate (and vitamins).
I like that Hunter doesn't require anything besides CMake.
That's why you disable exceptions in such programs. It's too easy to introduce a new throw anywhere which bubbles up and crashes the program.
It's like Dewey Decimal where there's a dot after each letter. Or, like digits to the right of the decimal point of a floating point number. 
I'm honestly quite amazed that, given this disastrous web of ambiguities already, they are still able to push the language forward with new features. At the same time I then wonder whether a "fresh start" wouldn't be a good idea either. Kinda a C++ 2.0 that drops a lot of the accumulated cruft and forced backwards compatibility.
I have no idea what problem you're trying to solve, and when you say "grouped as so", I look at your code and I have no idea how it's grouped Could you provide us with more details? What project are you working on? What recurring problems are you trying to fix? What are you trying to make easier?
 **Company:** [Loki](https://loki.network/) **Type:** Full Time **Description:** Loki is an open source, fully funded project aiming to develop a censorship resistant mixnet with an end-to-end encrypted messaging service built on top of a privacy centric cryptocurrency. We are mostly comprised of C/C++ developers who work on the core of our product. We are looking for a Senior C++ developer with experience in project architecture aswell as a strong understanding of Blockchain, a research or Mathematics background is also a plus. The right candidate for this position is experienced, creative, and is passionate about privacy preservation. Particular proficiency in any of the following areas is desirable, but not a requirement: * Strong Mathematical or Computer Science background * Large project experience (especially in architecture) * Experience with Distributed Networks * High level of working C++ experience (5+ years) * Low level understanding of ECC systems, High level understanding of Ring signatures, RingCT, NIZKPs, SIDH * Mixnet development * Open Source Projects/git **Location:** We have our office in Melbourne, Australia and have a strong preference for relocation of any candidate to our Melbourne office, we also have the ability to sponsor or relocate the right candidate as part of their employment contract. **Remote:** No **Visa Sponsorship:** Yes **Technologies:** We have a wide breadth of technology, mostly we use C++ and work on the Cryptonote code base, projects outside of Cryptonote are still C++ and networking heavy like Lokinet our internet overlay protocol. **Contact:** PM me on reddit
CRTP is still weird to me, as it goes into some level of meta-something, yet not clearly stated. It's like the "trick" phone spammers are doing by calling you from a phone number that starts like yours. The tagging, or /u/SeanMiddleditch 's version sounds about right, and very easy to grasp on. 
This actually sounds way more useful than a Qt app. Are these scripts available anywhere?
You are assuming a contiguous allocation, or at the least random access (`stable_partion`, and hence `gather`, only require bidirectional iterators). A range denoting a position will have a length of 0 (or you get into the problem of specifying a position after the end or before the beginning). The common argument for a range only based system (one without access to iterators) is that iterators are dangerous because there is a precondition that cannot be verified in code, and lives external to the local construct. In general, you cannot allow disjoint ranges to be joined in a system that strives for this level of guarantees, or allow comparisons between two ranges. Note that your comparisons above between ranges make the assumption that each is part of a larger subrange. If that is not true, comparing the pointers is UB (in both C and C++). Even systems that carry information about the originating range do not solve this issue because there is a requirement that the second position follow the first. Knowing that both positions are part of the same larger range doesn't guarantee that the result of joining the two positions will be a valid range.
&gt; Exceptions are by definition exceptional That purely depends on what you use them for, but yes, signaling exceptional events is their primary purpose (with various different definitions of exceptional). My question is: What are you using instead of exceptions, if such exceptional conditions occur? Just because you don't use exceptions doesn't mean you suddenly don't have to deal with errors anymore, do you? &gt; collective operations, barriers, communication, that stuff either can't be conditional, or you work out some guarantees that every process follows the same path. What's stopping you from doing the same in the presence of exceptions?
C++ can also link c code. The question is: can c link to arbitrary rust code (which isn't possible with c++)? 
You hide everything behind a pointer. Small disadvantage is that everything has one more pointer indirection. Biggest advantage is that you can change a binary library without breaking any kind of ABI!
Exactly. This makes it difficult to find where a certain class is used in a huge code base + reading the code takes more time.
I haven't touched GMock in a bit, but last i checked it didn't have anything like LR_SIDE_EFFECT ? There are other niceties like compile-time verification of all returns, no default 'uninteresting calls' etc. Also just the general pain of having a compiled library instead of a header. 
We've all seen code like in that example. It happens and I agree that using auto usually makes it harder to read in these cases.
a simple way to get this is by making a wrapper program around your compiler. create the object files with a .temp extension and then diff the .o and the .temp. if they are the same, you can delete the .temp and end that branch of compilation. if they are different then mv .temp to .o and continue
A lack of interoperability was the biggest issue there in my opinion. And probably poor mechanisms for compiler issued deprecation warnings. Here, I’d like to see breaking changes that makes everyone’s lives better that still allow code to interoperate when linked to libraries compiled with older compilers or flags. 
Most likely std::sort
Vector uses move if noexcept when applicable, so it is notable when, for example, you are pushing back into a vector of vectors. 
Expanding a `vector&lt;vector&lt;int&gt;&gt;` gets much faster if you can move the inner vectors. With copy semantics you need to copy each inner vector, which involves allocating new memory, copying each element, and deallocating the old memory. With move semantics you need to move each inner vector, which involves copying the pointer to its data.
And I'd *much* rather write `for (int i : 0...3)`
I agree with /u/flashmozzg, and additionally, I think we should avoid regular for-loops whenever possible in modern code. You say that `i` gives us flexibility, but how are you using that flexibility? You're just iterating from 0 to 2. There's probably a more expressive *and* less redundant way to write that.
I could've sworn std::rand() % produced results that were noticeably flawed when filling a 2D grid in some way to visualize it. 
Keep in mind that the extent of the non-uniformity depends on `RAND_MAX`. When it's 32767 like the MSVC stdlib in his talk, you have 5461 sets of 0-5 and then an extra 0 and 1. Therefore, you expect that with a uniform distribution over [0, 32767], you'll encounter a 1/5462 bias toward 0 and 1 combined. Compare this to other stdlibs that use a `RAND_MAX` of over 2 billion, where the bias would be much lower given a uniform distribution from `rand()`.
Yeah I tested my `RAND_MAX` and it was 2^31 - 1
Randomness is about much more than an even distribution of numbers. You could just count up from 0 to 960,000 and would get a perfectly distributed result. That being said, mt19937 is certainly not the fastest high quality random number engine there is (even the standard library provides alternatives), but I'm not enough of an expert to feel comfortable with giving you a recommendation. If you search a bit on google you'll find a lot of blog posts about that topic.
Oh yeah the thought of ordering never even occurred to me...
KISS and YAGNI should be foremost in your head all the time. Don't write code you don't need. Don't write generalizations that only have one implementation. Write the implementation, generalize afterwards if needed. When you're thinking about a design for a project, create the simplest you can come up with. Use inheritance when you need polymorphism only. And deviate from the rules when applicable ;)
There is an example on wikipedia for the 3D case (iirc), but I don't remember if that was based on an actual implementation or just showing an extreme case.
Inclusive or not?
Good to know the proposal will be well discussed, so I can stop worrying. It's a pity it hasn't had enough time to target C++20, though. Static exceptions are a great step forward in any case, and I'll be happy to use it, if I'll still use C++. I wish you strength for pushing the proposal through the standardization process!
Using a modulo gives a larger probability to smaller numbers, if the original range is not evenly dividable by the divisor.
Must have missed that. Thanks
This isn't the case. Models.hpp only includes standard library stuff and my own vec3 class
In ray optics computations I've written , rand would generate noticeable patterns on sensors. Another time when I tried to get 3d Gaussian distributions with it, the result seemed alright at first until I rotated the points cloud. Then it would seems all the points were contained in specific planes. It doesn't seem suitable beyond 1D.
It's only redundant if you know what type make\_unique() returns. On this occasion you probably do, but in general you'd have to look up the function. Hence it is less readable. It's also liable to go wrong if someone edits the function to change the return result. So this redundancy is actually useful. In general, redundancy often makes language easier and quicker to understand and helps avoid mistakes. I appreciate I am going against the flow of the C++ std community, but it has been my experience. If T is a long name, there are other ways to shorten it.
depending on your field, range based for loops are almost useless. you can't really access the previous or next (needed for all types of interpolation problems), you can't start in the middle and wrap around, you can't easily combine two arrays to one, you can't walk with stride, etc. etc. 
There's a bias, but it's very small. With a `RAND_MAX` of 2^(15)-1, there are 32768 possible numbers. That's 5461*6 + 2, so 0 and 1 have a 5462/32768 chance and 2 through 5 have a 5461/32768 chance.
of course the first point is weak, that's why i wrote: "not a big issue". the 2nd is meant to show that there's a trade-off in compactness and power. often having slightly lengthy code (w redundancy) gives good flexibility. 
`rand` and `mt19937` are both designed to give you a certain number of random bits (which you can interpret as a number in the range [0, 2^(num_bits)). It's adapters like `uniform_int_distribution` and `%` that translate that output into the range of numbers you're looking for.
&gt;drops a lot of the accumulated cruft and forced backwards compatibility. No thank you. I don't want a Python 2/3 problem for C++. Also, if you want to drop backwards compatibility, then you might as well develop a new language.
std::vector&lt;&gt;::insert. Basically anything that does moves rather than copies when copies are much slower than moves.
You could plot r&lt;sub&gt;n+1&lt;/sub&gt; against r&lt;sub&gt;n&lt;/sub&gt; where r&lt;sub&gt;n&lt;/sub&gt; is the nth random number. This can help at showing correlations. 
You should look up standard tests for pseudo random number generators (PRNGs). What you do is a very basic test and flawed as pointed out already (e.g. simply outputting a sequence will make your test pass). What is important is high-dimensional randomness. E.g. interpret the values of the PRNG as coordinates and plot them (e.g. 3 at a time for 3D) and you WILL see patterns for low-quality generators About speed: Pretty sure `std::rand` uses a LCG, which has a small state and just a few ADDs and ANDs. The Mersenne Twister (mt...) has much more state. This hints at an additional advantage of the latter: When will the PRNG loop/produce the same sequence again? This is highly dependent on the size of a state (Think: For a given state we produce the same sequence. How many different states can we have?) And finally: One of the biggest flaws of `std::rand` is that it is a GLOBAL STATE!!! (sorry, have to make this very clear) and hence is completely useless when used in a multi-threaded environment. Also for testing etc. it's not good to have a global state.
If you want to assess the quality of a given PRNG I would advise you to take a look at the BigCrush test suite of the [TestU01](http://simul.iro.umontreal.ca/testu01/tu01.html) framework which seems to be a de facto standard for empirical PRNG analysis and good at finding systematic flaws. In case you are looking for a high speed _and_ high quality PRNG I would recommend the [xoshiro256**](http://xoshiro.di.unimi.it/) developed by David Blackman and Sebastiano Vigna. They do provide a quite in depth statistical analysis and comparison on the linked site (xoshiro256** is the successor to the xorshift128+ PRNG which namely is used by chrome, firefox, ...). The only downside is the lack of integration into the standard library facilities, i.e. you will have to write a suitable adapter (which is rather straight forward). HTH 
&gt; What are you using instead of exceptions, if such exceptional conditions occur? Just because you don't use exceptions doesn't mean you suddenly don't have to deal with errors anymore, do you? For the most part, you abort all processes and kill the program. That's what I meant by "if you use exceptions in an mpi context,it's always localized" because the result of practically any catch is going to be an mpi_abort. And even that has issues. &gt;What's stopping you from doing the same in the presence of exceptions? Every process in any mpi program is a completely separate process, and they only communicate with each other through explicit calls. To create a parallel barrier where every process waits till all processes reach it, every process has to call mpi_barrier *once and only once*. Zero or two times gives you a halting problem or a race condition. Similar for any communication. A send operation from one process to another requires the other process to call a corresponding recv operation. So if one process throws an exception, how does it notify other processes? You could construct some awful conditional logic where processes are constantly communicating that they indeed didn't throw an exception, but performance would suck. But more importantly what would you actually do with the information if something does throw? If there's no viable way to resume normal program operation, and for a numerical code running on thousands of cores there almost certainly isn't, then elegant exception handling doesn't really buy you anything because you're just gonna abort everything anyway. 
On one hand, sure, there is stuff that we would be better without. On the other hand, whenever I hear someone talking about systematic breaks in the standard, all I can think about is the double barrel rifle called python - you can shoot out of only one barrel at a time and you always end up trying to shoot out of the wrong one. And, as Titus said, backwards compatibility got C++ this far. Maybe not only backwards compatibility, but I strongly believe it's one of the key factors.
&gt; exception handling doesn't really buy you anything because you're just gonna abort everything anyway. I'm not saying it does. I know wie a few non-mpi programs that use exceptions, but still just terminate when one is thrown (usually after displaying or logging an error message ). I guess what I tried to understand is that when you said exceptions are not used are you saying - we don't handle errors at all (just call std::terminate /mpi_abort), so we'r don't need a way to signal errors up the call stack anyway - we use a different error reporting mechanism (e.g. return codes) because we don't want to pay the runtime overhead or we don't know how to make our program exception safe. The latter is what most people mean when they say "we don't use exceptions". In your case it sounds more like the former, which is i'f course legitimate but doesn't translate to other applications that do want to handle errors in one way or another (even if by nothing else than writing to a log).
Any modifying algorithm that runs on moveable type (type that allocates and has significantly cheaper move than deep copy).
One thing about higher math (i.e. above engineering math) is that's all about abstracting things as much as possible, and in the best way. And the same is true if you're writing generic code, either as templates or programming against an abstract class. Learning some higher math will definitely build skills to help your generic coding. Category theory is probably the ultimate area of math for dealing with abstractions--you'll see it come up a lot in functional programming circles--but that would be diving in to the deep end. Real analysis and topology, as suggested above, are some typical early courses in higher math. Though abstract algebra would be my recommendation for carry-over to programming: monoids, groups, rings, and fields are the building blocks of most all higher abstractions (and sometimes even useful for real-world programming).
Ok. But even then using the mersenne twister with %N would seem more comparable... It is often better to only change a single disjoint thing when comparing alternatives.
Is there an actual bias (certain numbers occurring more often than others)? Or patterns?
What do you mean? If you say "what if you can't use any libraries", then yes... you must write all the code from scratch. But otherwise you just find a library which does what you want, just as with any language. How do you go about creating an application if you can't use any libraries?
Lower number have higher probability if use use the modulo operator.
I agree with your comments on good names, I was just reusing the argument definition from the initial comment. But even if the function name was more informative it may not be sufficient to provide details of what the data type is. So following your suggestions we might have something like: auto listOfPerson = getListOfPerson(); Now is *listOfPerson* a **std::list&lt;Person&gt;**, **std::vector&lt;Person&gt;**, a simple **Person[]** or is it a shared pointer? I have no way of knowing without reading the docs and/or source of **getListOfPerson**. 
I'm just a but lost with how people actually do it. Is it actually a case of open up your favourite IDE, create a C++ project and then Google for a library that gives you your basic windows etc and then finding your go to library for input management? 
Yes, it is. For anyone interested, [this blog](http://www.pcg-random.org/blog/) has a great number of articles related to RNG's and to uniformly generating them in a range. splitmix and Lehmer's mcg stand out as being fast and good. This [post](http://www.pcg-random.org/posts/some-prng-implementations.html) provides links to implementations that play ball with the distributions in &lt;random&gt;, while this [post](http://www.pcg-random.org/posts/bounded-rands.html) provides alternative implementations of uniform_int_distribution's (much faster than the std::implementations). I did [some work](https://github.com/degski/uniform_int_distribution_fast) on the subject, it's for now unfinished, as real life caught up with me.
is there a reason why you prefer static free functions over free function in an anonymous namespace?
Well yeah, isn't that basically how it works with most languages? I guess the thing with C++ is that it doesn't have things like graphics built in (yet), you have to use platform specific stuff. But a combination of C++ built-ins and platform specific APIs and you can do basically anything, just as with other languages.
It should be possible to get bindings working (even with C++), since it's all llvm under the hood.
Oh no. Please don't look u/stl.
&gt; Are all C/C++ users incredible badasses who produce everything from scratch? well, if you go to engineering school that's what you are taught to do. So by that metric a lot of people are "incredible badasses", but the truth is, it's as easy if not sometimes more especially when you have weird requirements not covered by your big framework.
Well whatever is appropriate. A lot of people use QT for graphics. There's also Boost, which provides a lot of different functionalities. Or maybe a platform specific API like on Windows or Linux. Whatever gets the job done.
Perhaps that is what I am after. Do you have a preferred set of frameworks ? If so do you have any examples I could check out?
Just search what you want and there will likely be heaps available. [Here](https://en.cppreference.com/w/cpp/links/libs)'s a list to start with.
Jeez louises! Ok inspiring! I will think of a project idea and then piece together some of these and see where that gets me! Thank you!
https://en.wikipedia.org/wiki/Spectral_test
I remember using this wrapper for xoroshiro https://github.com/morinim/xoshiro256ss
There's a lot of libraries and abstraction layers "below" the game engine level. If you don't have an existing game engine you still have some graphical libraries to use. People often write their own stuff with DirectX/OpenGL/Vulkan (that's what existing engines like Unity and UE4 use too), there are also simpler libraries for 2D graphics like SDL and SFML, for GUIs there's imgui, but they use above APIs as well. You always have some existing technology to build on unless you write an operating system of your own. For example I'm writing a renderer in DX12 now, and even though I have to manually manage low level stuff like command lists, fences, barriers etc, it's still a lot of premade code that talks to the GPU for me so I don't work literally from scratch.
Time to update the code to include autocorrelation.
I recommend against Vigna's series of generators. Vigna's generators have not been particularly robust historically, and [xoshiro256** looks fishy](http://www.pcg-random.org/posts/a-quick-look-at-xoshiro256.html). In contrast, the PCG generators have a straightforward argument of their strength, were developed in a principled matter, and I've never heard of a statistical flaw in any one of the family, sans the "`_insecure`" members. I've even done some testing of my own, and I've only found good things. 
Seriously? Learn to code in Rust, not just C++ - and try to use/advocate for Rust and not C++ in new, greenfield projects. C++ is a horribly unwieldly, memory-unsafe language that I just cannot see as being "future proof" in the way that Rust will most likely be. At a bare minimum, learning Rust will give you good coding habits even for C++.
Thanks for clarifying. My answer to that is simply that most significant programs are operating on data in the gigabyte range, not the hundred-kilobyte range, and you should count yourself lucky to have so little memory pressure. I will add that I'm curious about why you think you're execution latency, as opposed to execution throughput, bound. Low IPC normally means you've got a lot of branch misses or such, rather than totally-linear dependency graphs.
i wholeheartedly agree. maybe it's age, but in my experience typing a few more words here or there is never the limiting factor in how much i can achieve. i don't care so much if it can be done in 50 or 80 chars of code. clarity is bliss! 
hypothetically
DRY is just that, a vague principle. it's not a god given requirement. you can and need to bend the rules a little sometimes to make room for other important principles: clarity, conciseness, flexibility to name a few. here is one take on this: http://joelabrahamsson.com/the-dry-obsession/
&gt; At that point are there any actual shortcomings to std::rand()? Cuz the speed tradeoff sounds pretty good by itself You're not considering the different use-cases. It's like how you can use a screwdriver to hammer in a few nails. Sure, it _works_, it might even be faster than going to the tool shed to get the hammer, but the occasional nail will bend out of shape and that could be important if you're putting up a shelf, but maybe you don't care because you're building some rustic wood art. What I'm getting at is that you've pretty much discovered that rand() is _fast_, but it's not cryptographically secure. If you're not working in a security domain, does it matter? Probably not. If you're writing a game engine and want the AI to make a random choice, rand() will probably do you just fine. However if you're dealing with people's data, encryption, hashing, anything like that - you _probably_ want something that's a little harder to guess. Then you realise that &lt;random&gt; comes with a _selection_ of algorithms that suit different use-cases and it's just the same discussion - *use what makes sense for your use-case*. When it comes to performance, speed matters the most. When it comes to security, speed is secondary.
&gt; And now, despite the lack of `noexpect` keyword, `static_assert(noexcept(area(square{})));` passes. IIRC `noexpect` is only valid `std::spanish_inquisition_t`.
The code is there. They're using a single 32-bit to seed the whole thing, which is the wrong way. /u/debugs_with_println, you should try again with proper seeding. I do it like this: template&lt;class T = std::mt19937, size_t N = T::state_size&gt; auto SeededRandomEngine() -&gt; typename std::enable_if&lt;!!N, T&gt;::type { typename T::result_type random_data[N]; std::random_device source; std::generate(std::begin(random_data), std::end(random_data), std::ref(source)); std::seed_seq seeds(std::begin(random_data), std::end(random_data)); T seededEngine(seeds); return seededEngine; }
I'd say one of the most important use cases is embedded development. If you have to write a driver or something comparable on a very limited hardware (mc, dsp, ...), sometimes you will need a very efficient memory handling. If the cpu-power is very limited you also need a very good low level algorithm with as few instrcustions as possible. You can't do such things in C#/Java. These hardware components have often limited resources to reduce cost, power consumption or size.
Its possible the CMake version in your package manager is outdated, but C++17 has been supported since 3.8~
Its possible the CMake version in your package manager is outdated, but C++17 has been supported since 3.8~
Thank you, I realized this after reading the comments. This was a mistake on my part!
&gt;Things I'm currently doing to improve myself: &gt;.... What a good boy! Seriously! I hope you will always get challenging and interesting job with smart colleagues (it is harder than it looks). P.S. It is "Qt Creator", not "QT creator"
What would be an example of an application that does not involve a GUI?
&gt; cmake doesn't support anything past 14 yet CMake is almost a standard nowadays in C++ world, but I still would recommend to try other build tools, for example [QBS](http://doc.qt.io/qbs/).
&gt; My answer to that is simply that most significant programs are operating on data in the gigabyte range But are they? Maybe in server space but _most processing is not done in servers or clusters_. Just consider how many mobile devices are in use that all perform things that would have been considered "high performance computations" just a decade or two ago. Execution latency is what determines throughput when you have "recursive" computations (that is, you need the result of previous operation to calculate current one). In my case I'm doing (often non-trivial) signal processing where almost all problems come down to recursive computations.
I'm gonna be the contrarian here and say, for 99% of the use cases, rand() is perfectly fine. Just be aware that it has potential flaws that might be exposed in certain cases.
You mean pushing into the front right? push\_back() is the fast one.
wiki link?
All your standard command line tools for example. Or Git (even though it's implemented in C if I'm not mistaken)
All your standard command line tools for example. Or Git (even though it's implemented in C if I'm not mistaken)
Yes, but he was talking about `std::vector&lt;std::vector&lt;T&gt;&gt;`.
There is no push_front in std::vector, but you can insert to any position. I was thinking he meant when a vector runs out of capacity to hold more elements it has to grow.
I am pretty sure that most software is written without GUI: Kernels, compilers, webservers, versioning tools, core utils, networking stacks, virtualization software, package managers, crypto libraries, ... can go on for ages like this.
It's also the reason why pimpl should always stay a last-resort thing. 
[RANDU](https://en.wikipedia.org/wiki/RANDU) exhibits this behaviour.
IMO those people exactly violate the first principle above: don't overuse design patterns. Pimpl is like Voldemort splitting his soul into seven parts: it gets you to your desired goal, but you irreparably damaged the code base in the process. VERY rarely pimpl is necessary to create a kind of "compilation firewall" in order to speed up compilation times.
&gt;**Refactor** &gt; &gt;Learn to destroy and create anew. This is unique to programming - an engineer can't do this - take advantage of it. Word of wisdom, right here. Reality is, in an actual job, your code goal is a moving target because of the changing business needs of your company. Write your code so you can easily tear it apart and rearrange it for the new business need. 
Huh, TIL there's a rather bitter feud between the PCG and Vigna camps. 
Your libraries can remain ABI-compatible with older versions even if you change the implementation, if you care about such things. Qt uses it's "D-Pointers" mainly for this reason.
Why they ever started down that path of replacing qmake with yet another internal build system that it was pretty obvious would never be used when cmake has so much momentum behind it - I'll never understand - but at least they made the right choice eventually
Haha ! Fixed !
Why?
Thank you for your insightful comment! You've given me useful ideas to consider and think about.
There is a motivation for that in repo. Yet there are two main reasons: 1) It was fun to explore it, as I was not aware about that possibility. It's always told that C++ does not allow it in most/all cases. And there is a section in the standard that says that in this particular case we are not taking care about it. 2) I am aware that one shall write code in the way that he can then test it, or just do TDD. But there are situations which I personally had while doing outsourcing job that there was already huge code base written in the way that it was very hard to test it. There was no enough time to redesign some parts of the code and make it more testable, so some suggestion was to use dirty way of \`#define private public\`, we have omitted that in different way. But if one really wants to access private data member and does not have proper interface/structure for that it's better to use this library than straight \`#define\`. I would address this library only to special cases in unit tests. 
They did drop it. which is very very very sad. It seems that cmake has won and we are forever stuck in a local... minimum, really.
There hasn't been any public announcement that they are dropping it at any particular point, and the work to use CMake to build Qt is still a prototype. I'm holding out hope for the future of QBS.
Try to nemcpy into a new variable and check the assembly to see if the nemcpy as been elided.
I would vote for meson as best solution. Cmake as the pragmatic.
http://blog.qt.io/blog/2018/10/29/deprecation-of-qbs/
&gt; It seems that cmake has won and we are forever stuck in a local... minimum, really. well, I disagree. More projects using CMake means more incentive and chances for CMake to improve. e.g. a lot of core CMake devs would *like* better language frontends for cmake to exist, they just don't have the contributors to actually write the code or review the existing proposals. 
Shall be marked as "Do not try this ~~at home~~ in production code" ;)
If you feel the need to test private function, either your class design is flawed, or your tests are flawed, or the mix of the two. Also, free your functions.
What a sad day ( QBS is quite beautiful. On a bright side it means that CMake will absolutely dominate in C++ word for foreseeable future. One build system to rule them all.
I'll need any sort of justification. I'm seeing that it might be unideal for cross-compilation, but there's no way you can say it's "absolutely terrible" unless you're also fine suggesting everything C++ has is absolutely terrible (discloser: haven't tried vcpkg or Conan but I am just about certain they're not better than Cargo). It's among the best package managers I've ever seen. The package management story for C++ is atrocious. Install dependencies globally with no way of replicating in CI or on new machines aside from shell scripts. Pray the versions work out right (does this package version in the name, or do they just release new versions under the same name? totally depends on the package). Pray you don't need to use a different/conflicting version in a different project. Alternatively, copy the entire thing in as a git submodule or separate file. This is, of course, relatively a nightmare. Make sure the files and library paths are in your CMakeLists! There are 10 different kinds of paths you'll want to configure and five different ways of configuring them, so best of luck learning an entirely new kind of language as well as understanding the C++ linker. By comparison, with Cargo you can just put the dependency in your Cargo.toml (a simple markup file any newb can understand the basics of in under 5 minutes) with the version string and run `cargo build`. No makefiles, no crazy build artifact strategies involving `cd`ing to multiple directories, no obtuse shell scripts involving 5 commands with 8 options each. It's just `cargo build`, or even just `cargo run` to run the binary.
How has it been solved?
&gt;I am aware that one shall write code in the way that he can then test it, or just do TDD. But there are situations which I personally had while doing outsourcing job that there was already huge code base written in the way that it was very hard to test it. There was no enough time to redesign some parts of the code and make it more testable, so some suggestion was to use dirty way of \`#define private public\`, we have omitted that in different way. But if one really wants to access private data member and does not have proper interface/structure for that it's better to use this library than straight \`#define\`. &gt; &gt;I would address this library only to special cases in unit tests. Agree, but that is mostly what I have said ;), yet there are situation where you shall pick lesser evil. Plus as I said it was fun for me to explore it
https://en.wikipedia.org/wiki/Linear_congruential_generator#Advantages_and_disadvantages
I also just start out with CMakeLists.txt so users can generate projects for their desired platform. I have a tiny project here: [https://github.com/sandboxgod/AlembicReader](https://github.com/sandboxgod/AlembicReader) For game projects I would start out with something like Unreal but for something smaller, I start off with CMake. If I need test cases I would use Catch. Logging- I would use something like spdlog (see github). Basically, I try to find all the pieces that are already done in some form and pull them in. If I need a UI, I'd probably go with Qt. At work, if I have scripters that use Python or something I let C++ handle the backend (Controller) while the frontend GUI may use the scripting language.
&gt; You should look up standard tests for pseudo random number generators (PRNGs) [DIEHARD](https://en.wikipedia.org/wiki/Diehard_tests)
&gt; If I need test cases I would use Catch. Logging- I would use something like spdlog (see github) so do I - here's what I mostly use : https://github.com/OSSIA/libossia/tree/master/3rdparty .
Imagine your client feels the need to test his shitty, untestable code and you get paid for that.
In some cases, a function should definitely be private, but also testable. Function might need access to private stuff, so it cannot be freed. `friend` can get ugly with forward declarations. Sometimes, it just makes sense. However, the approach I use and recommend is simply making the function public and prefixing its name with an underscore. It solves the problem elegantly, by adding a single character. It's like `namespace detail`, but at class scope.
Yes, there's nothing wrong by doing exploratory libraries. I learned a lot of stuff by doing it. I didn't wanted to discourage you For the tests, feeling the need to test private functions or having to test an untestable class is often the ideal time to refactor it and make it testable. Of course, in a corporate setting, it's not always an option.
You seem most interested in UI, so I’ll address that. Back in the day, I wrote GUI applications directly to the Mac &amp; Windows APIs. When doing embedded development of a tool that consisted of many individual systems, we used CORBA to communicate among the systems. The systems I worked on didn’t have a UI of their own. The UI system was written in Java. Other embedded development I’ve done has had a CLI that used a 3rd party framework (which I don’t think is around anymore) and a web UI that was essentially just a simple C REST server for the JavaScript front-end. In other cases we used the GNU SOAP tools to provide APIs for an external management system.
I understand why they decided to keep cmake (huge userbase). But why qmake? Why not go with mayzone? It seems like the all the cool kids are switching to it: https://medium.com/@germandiagogomez/getting-started-with-meson-build-system-and-c-83270f444bee 
I believe you can work around this by compiling with /bigobj. It switches the compiler to use 32-bit section IDs internally. We're using that successfully with some truly gargantuan generated source files. 
[https://build2.org](`build2`) is alive and kicking so not everything is lost.
&gt; I understand why they decided to keep cmake (huge userbase). This isn't about build system for Qt projects primarily, this is about building Qt itself. You can't use cmake to build QT itself.
I'm sad to see you go QBS, our affair was brief, but I'll always remember you. You took my list of files and made me an executable instead of another list of files that makes an executable. You let me write the Rules i needed to do strange things and you didn't complain, you welcomed it in clear language. Sure sometimes you'd disable all my targets and leave me a strange little error note, but we always worked it out. I will probably get back together with CMake, even though we didn't get along in the past, everyone tells me it has changed, its doing better now. Maybe one day I'll take another risk on a better build system, but for now, I'll make the easy choice.
Seems interesting but 'all the cool kids are switching'... Is a bit too much
Given the metaphor you are using: Because we would prefer to move faster than at walking speed. ;-)
#define private public #define class struct #include foo.h
&gt; More projects using CMake means more incentive and chances for CMake to improve. But a lot more existing stuff to retain compatibility with, increasing the inertia for any major changes. QBS is the only build system I ever used that I actually *liked* the syntax of. CMake is the sort of syntax that started as an ad-hoc config file text format, and sort of grew accidentally into a scripting language. The declarative syntax of QBS was originally designed for QML UI's, and then used for a build system after it was successful. So I think it's a much nicer base of a language to build on as a foundation over time than CMake. It's a shame it never caught on. I guess it was a few years too late to the party, or just not widely promoted enough as something that could be used independently of Qt.
And do not forget your friend Meson ;)
build2 provides a unified interface for options to various stages of compiling and linking. However, the options themselves are not abstracted, correct? You don't say that you want the Eigen library, you actually pass "-I/path/to/eigen/include", which would be a different flag on Windows. Correct?
Trampolining. E.g., [https://eli.thegreenplace.net/2017/on-recursion-continuations-and-trampolines/](https://eli.thegreenplace.net/2017/on-recursion-continuations-and-trampolines/) &amp;#x200B;
Everything looks terrible about headers ... until you need to ship a security fix for a library without recompiling thousands of projects that depend on it.
Most CMake criticism isn't really warranted. It kinda has the same problem than C++ in that you see plenty of "old code" that is the bad way to do things instead of the much more clean modern way. If you look at the article, you can see they kinda were surprised how well it worked with CMake. &gt; Given that background, we’ve done some more research on using both Qbs and cmake to build Qt. Both projects did give us good results but we were actually surprised on how far we got with cmake in a rather limited period of time. There is that perception that cmake is terrible. It's not, it's actually pretty good when you go at it cleanly.
FWIW if you ever want to experiment in the future, try out Meson. Seriously fantastic. 
As others here have noted, the current statistical analysis is insufficient to determine the quality of randomness. However, there is also a problem with the benchmarking code: function-local statics are thread-safe in C++11. I also recommend putting each test in its own translation unit so that the optimizer doesn't fiddle with your benchmarks. [Google Benchmark](https://github.com/google/benchmark) with [`DoNotOptimize`](https://github.com/google/benchmark#preventing-optimisation) is your friend. :) &gt;Another thing to note is that the new way was about 4x slower than the old way. That's because the `getRandNum_New` function uses four locks and `getRandNum_Old` uses one. It is well-known that `&lt;random&gt;` is slower to initialize because of the large amount of state that must be generated (particularly for `std::mt19937`). I would re-write this without function-local statics to get rid of the global locks.
You're performing only one test of randomness. Random number generators that have flaws can past many tests. That doesn't imply the absence of tests they fail. This is why their are large test suites like TestU01 and Diehard. Of course these suites also aren't exhaustive, but much better than a single test. The main flaw you're likely to be able to detect with your existing test is bias due to your use of `%` rather than anything in the generator itself. With a small divisor like 5 that bias won't be very much. Much of the benefit of `&lt;random&gt;` is that distributions are done correctly for you instead of relying on you to write them correctly. You're also only testing one implementation. Part of the benefit of `&lt;random&gt;` is that it's much better specified so you can rely more on its results across different implementations. `rand()` on the other hand differs vastly between implementations, sometimes having okay quality and other times not. `mt19937` is indeed going to be slower than many other generators. Unfortunately `&lt;random&gt;` doesn't yet include one of the fast, good, modern generators. If performance really matters their are libraries that add better performing generators into the `&lt;random&gt;` framework so you can still benefit from distributions.
Meson is just a better CMake (or so they claim). It is still the same bankrupt idea of relying on the underlying build systems, which is a race to the bottom, to the lowest common denominator. See my [CppCon talk](https://youtu.be/cJP7SSLjvSI) for a more detailed discussion.
C# in Unity is an abysmal and unforgivable nightmare for performance. It’s great for ensuring you have as many heap allocations as possible and your generated code gets optimized poorly by the backend compiler. To make things perform reasonably, you pool objects and basically avoid the built in gc at all costs. You actively need to fight the compiler who will do stupid things like boxing your value types as objects to do equality comparisons etc silently. The built in containers are somehow worse than c++’s containers. C# was, like Java, created at the zenith of man’s collective Moore’s Law hubris and has no place in a low latency real time application. /rant
Incorrect. You say `import libs += eigen%lib{eigen}`. See [Target Importation](https://build2.org/build2/doc/build2-build-system-manual.xhtml#intro-import) in the build system manual for details.
Great news for C++! CMake is the biggest game changer since the 80's for C++ and the more projects that switch to it the better.
I too hope they can find a good way, because all I can think of is the way HTML did it with a header declaring the type (HTML 5).
That link isn't working for me right now, but I've followed their discussions in the past and O'Neill responded [here][1]. [1]: http://www.pcg-random.org/posts/on-vignas-pcg-critique.html
You forgot the /s at the end. Just letting you know.
Vigna's response is weak, and in places borderline dishonest. O'Neil responds here: http://www.pcg-random.org/posts/on-vignas-pcg-critique.html. The only thing I'd add is that the justifications for wanting a challenging to predict generator aren't really outlined in that post (or anywhere I know of, actually), and it's commonly misunderstood. The basic argument is this: the *point* of a randomized algorithm is that its statistical properties are invariant of the transformations you make on the data. An untruncated LCG has weak low bits, but it's entirely plausible that an algorithm will take the lowest bit and use it in some calculation. Similarly, it's not implausible that a user of a random stream will want to multiply the values it receives by some constant. Vigna's response attack isn't relevant as a counterpoint for two basic reasons: firstly, it attacks a generator explicitly called `_once_insecure` (big surprise it's insecure, eh?), and secondly it uses a 31-bit brute-force of the key. *This is unlikely to accidentally correlate with plausible transformations*, whereas being weak to a simple multiplication means the xoshiro256** generator is *structurally* weak in ways that may become visible with routine handling.
np. I've done my fair share of similar things, no judgment from me. :)
Is there a page that shows what syntax such as `%` and `{}` mean?
What about abstracting things like the platform's threading and OpenMP?
&gt; Hardware is cheap, people are not. Which is all the more reason to not do this. Say you have a 6 core i7. In theory splitting your single TU into 6 files that can be compiled independently in parallel will speed you up by a factor of 6. Throwing out an 8700k and replacing it with an 8086k will cost you 500 dollars a developer, will take a day of IT time to reimagae a machine/set up the developer PC and begin working on the new hardware, for an 8% perf gain. My project takes about 15 minutes to build from scratch running on a build farm through incredibuild. Normally that runs about 40-50 files in parallel. We would never accept a 50x slowdown. Swapping to a single TU would also break other workflows and tools (everyone working on one file in source control will inevitably cause more conflicts, loading a 100000 line monster file into Vs/sublime will be slow) 
cabal, off the top of my head. system package managers are better than cargo in many ways. 
Why do you care if it is `operator+=` or not?
&gt; E: What I'm getting at is that "the principal overhead in traditional systems is memory latency, not execution throughput" is a naive and biased view caused by the assumption that "computation" is only the domain of HPC clusters or servers. I agree that counterexamples exist. I just don't think they're comparatively common. If your space is primarily signal processing on a tiny amount of data, for sure DoD probably isn't for your case (though probably nor is OOP).
I lack a reference to Johannes "litb" Schaub, the inventor of that technique.
Even with intrinsics you have to be careful ((old example)[http://www.virtualdub.org/blog/pivot/entry.php?id=188] that has probably been fixed). And I'd only expect these issues to get worse with time. My go to solution in these cases (when an unacceptable performance difference has been measured) is to use #if COMPILER_VERSION &lt;= x.y.z // Tested and checked UB code #else #if !UNKNOWN_COMPILER #pragma warning "Please retest with the new version!" // or whatever #endif // Standard version #endif
In what way is cabal superior to Cargo? It's also not really "solved", it's just solved for Haskell. As someone who professionally uses C++ and thus system package managers (by which I assume you mean aptitude, yum, etc.), I wholeheartedly disagree. System-wide/global package management is awful to work with, especially when it comes time to actually link to your programs. Maybe you could describe the ways in which you believe system package managers are better than Cargo?
How do headers help in this scenario? Aren't you confusing them with DLLs? &amp;#x200B; &amp;#x200B;
The value in a build system isn't just in the quality of the tool. It's in the whole ecosystem around it, and what that enables. Integration with thousands of other projects, support from people the world over, hundreds of people contributing features and fixes, and you being able to take advantage of that and also participate in it. CMake has a good number of well known design flaws and implementation defects. Its bug tracker is a good source. That's part of the price of being popular, having to commit to backward compatibility indefinitely to avoid breakage. But it does have the policy mechanism to allow behaviour changes, and in the few years I've been using it (and contributing to it), it has continued to improve at a steady pace. I'm sure that a lot of the problems will continue to be solved. It's likely it will get alternative DSLs to replace the horrible scripting language. In short, I think that right now, CMake is the pragmatic choice, and I don't think it's a bad choice, and I think it will continue to be a good choice as it continues to develop.
And today they officially announced the deprecation of Qbs: http://blog.qt.io/blog/2018/10/29/deprecation-of-qbs/
Would it be possible to run the compilation process in two phases: one that extracts all the definitions, and another that uses that information to do the actual compilation without requiring further parsing of headers? Obviously headers could be eliminated in this scenario, since all definitions would be universally valid. Are there any deep reasons why this cannot be done? &amp;#x200B;
Thanks for taking my comment in jest, as it was (half-) intended. I will say that you are willing to give away a lot of freedom for the convenience of some increased speed. Are you sure that that's the way you wanna go?
Thanks for the link and the updated context; I haven't followed the debate since the beginning of May as it currently isn't directly relevant for me.
You pay that freedom dearly: less confidence in your code, less robustness, need for the STL to be this `__Fungly` mess, and, more finally, crappier tools that you can't trust 100% (even for simple things as renaming a symbol). The freedom you seek can be achieved by better constructs integrated into the language (aka resulting in AST nodes)
Does build2 handle D out of the box? Helps with Rust? I havr mixed C++ and D successfully and it was a breeze. The cross-compilation is quite better also. The documentation is light years ahead. The language is not confusing. As a user that tried CMake, that has the door open to use D and needs cross-compilation I must say that Meson is already quite better than Meson used to be.
Correct, sorry for omitting that. I'll update the repo later today with reference to his blog post http://bloglitb.blogspot.com/2010/07/access-to-private-members-thats-easy.html?m=1
I think there is some irrational hate against Meson. At least votes show me that. Because I hope it is not that article you linked what adds to the negative points XD
Sooooooo....don't do anything in C++ for another 2-3 years, realistically another 5 years. Gotchya. 
Lol we just had to do autocorrelation in my real-time DSP class. Unfortunately I had no idea what was going on so I better hit wikipedia...
I think you are painting a picture that is intentionally darker than it truly is, and it plays on the emotions of everyone who felt frustration with the compilation and linking process at one point or another in their careers. But it is hard to actually agree with you because what you are proposing is to invest our trust in (additional?) tools that would build an abstraction (modules) out of and on top of the headers of today. An extra level of indirection and a closed lid on a black box. How do you propose to make that abstraction and those tools better, less buggy than the underlying source code they are based on? Because right now the only improvement, and it seems like a given, is that it's gonna be somewhat faster.
Now that just sounds like a challenge. 
I do as well. I'm having trouble with the Android stuff lately, but that seems related to Android NDK switching to clang and not gcc. Hunter is brittle, but that's just because it doesn't have the critical mass that Conan or vcpkg or others do. 
&gt; We could change Meson to run compiler invocations itself if there ever was a need for this. I don't believe a native build system written in Python can ever be fast enough. So far the Scons experience confirms this. &gt; Thus far this has not been needed. This will likely change with C++ modules. 
&gt; Does build2 handle D out of the box? Helps with Rust? No, it does not. But not because it's impossibly but because nobody needed it so far. The fundamental conceptual model is there. In fact, if you wanted to, you could implement your own C/C++ compilation rules if you didn't like the ones shipped with `build2`. Of course, this misses the point I was making: in `build2` we control everything and are not limited by ninja/etc. But to put it in your terms, does Meson have a plan for supporting C++ modules? 
How much time do you have to spend linking those TUs together? A lot of the single translation unit speed ups comes from reducing link time and other optimizations that occur at link time. &gt; loading a 100000 line monster file into Vs/sublime will be slow ? You can obviously split up a single translation unit into multiple files. It's just that the compiler after the preprocessor is done sees it all together at once.
Reminds me of the bad old days of C, storing pointers to functions in structs. If you really wanted to be serious about it, all the functions in the C file would be static, limiting the scope of those functions to visible for that file only, with a single non-static allocation function that would return a pointer to your "object." Managing inheritance could done but was best avoided. Your code would look a lot like C++, but wouldn't actually be.
It doesn’t matter if it is nicer. It is yet another build system. 
I tested every standard library rng while doing Monte Carlo integration for boost. It basically is the fastest and the best. Regrettably, it is far from state of the art. Somebody needs to get on adding modern RNGs into C++20 random. I’ve heard people saying good things about the PCG generator, but haven’t tested it myself.
Wow, really nice page as a whole! Cleared up a few concepts I didn't have really clear.
Nice. Now I understood what a k-dimentional test means and what that PRNG property means
header/source split makes rebuild slow but incremental build fast
&gt;Your code would look a lot like C++, but wouldn't actually be. Agreed, partly :-) I'm ok with you concerning the "classes", but I would differ concerning generic programming. I like the concept of having free functions instead of methods; since they are more composable, and hence more adapted to generic programming (no need to use `std::bind` and/or `std::mem_fn`)
Just a note to everyone who thinks `#define private public` is enough: you would also need to `#define class struct` to get around default access, but that macro explodes once `template &lt;class T&gt;` is reached.
Shame QBS is going - I found it simple and elegant. But I understand going with cmake, and while I don't think it integrates with QtCreator as well as either QBS or qmake, I'm glad the time I've invested in it won't be wasted. I'll be glad when qmake is gone, it's too limited and inflexible even for some of my relatively simple code bases.
The link he provided explains exactly that. A short summary: packagename%lib{ libraryA libraryB etc }
It's also supposed to be the default in recent versions in 64bit if my memory is correct.
http://blog.qt.io/blog/2018/10/29/deprecation-of-qbs/
Well, the reasons why people use CMake are adoption and that it can do enough out of the box. In that sense Build2 is still in disadvantage, though I have a high respect for your talks and your effort to improve the ecosystem. As far as Meson goes, mixing languages and cross-compiling are already better than in CMake IMHO. So from a practical point of view it serves me even better than CMake. As for build2, I did not try it but I am genuinely curious about it. I am not sure it stands a chance, though, since CMake became kind of a standard and Meson is becoming the "linux" standard. &amp;#x200B; &amp;#x200B;
Surely a module system also gives you fast incremental compiles?
&gt; I believe you can work around this by compiling with /bigobj it's not enough, the 65535 limit is still here for .lib / .dll : https://developercommunity.visualstudio.com/content/problem/220174/fix-msvc-65535-symbol-limit-in-lib-files-lnk1189.html
Hm. This smells like a pattern. It seems somewhat similar to [flyweight](http://wiki.c2.com/?FlyweightPattern) or [strategy](http://wiki.c2.com/?StrategyPattern). Actually if I were classifying it, I'd tentatively say it's an implementation of strategy where you can swap the strategies at run time.
Yep... very sad day
On a somewhat related note: I'm fairly certain that every major CPU these days (ARM, Power9, Intel, and AMD) have an accelerated AES-128-bit function. I've always liked the idea of using the AES-128 bit function as a RNG, and I've had success in the past writing up some silly RNGs using it. Its trickier to use as an RNG than most people think, because one operand is a simple XOR, and the other operand is a simple permutation. So you need multiple AES rounds to get good "mixing" of bits. Still, ~2 rounds in a feistel cipher for a 256-bit RNG should be good enough for non-cryptographic purposes, and is fully accelerated on all major CPUs today. Just some thoughts.
&gt; std::function&lt;cv::Mat(void)&gt; grab; you are just hiding `virtual` behind a wrapper. 
Adding C++14 would be very much appreciated.
No, I'm explaining why people argue against headers, and why that argument is ultimately wrong. The real problem is that neither "loadable object" nor "exported symbol" are first-class objects in the C model.
No "complete" module system currently exists.
Infinitely big source code? Infinitely big compiled program? Or a program with an infinite run-time ie. a program which never terminates?
Infinitely big source code
The claim appears to be that headers let you ship a security fix for a library without recompiling thousands of projects that depend on it. I'm sorry, but that's just BS and I have no idea where the OP got that weird notion from. As for the idea that headers somehow make incremental builds fast - no, they don't do that either. Incremental builds are fast because you are only updating a small part of a larger number of translation units, it doesn't require a split in headers and source files to work. Headers are a crutch, nothing more, and one we should strive to get rid of ASAP.
Shoud do but I predict that there will be some time span before first working module-based build implementation and optimized module-based build implementation.
That's sort of asking why we cant have an infinitely large number. You just... cant? Just from a language perspective, the grammar of a programming language defines a infinitely large collection of syntactically correct programs (hell, lets we could generate an infinite number of valid programs). But each of those programs has a finite (if large) size. Even if you let a non-terminal stay a non-terminal in order to describe an infinitely large class of programs that the partial program could derive, it would still be a finite text.
I just tried the following: &gt;echo #include "inf.h" &gt; inf.h &gt;gcc inf.h -o inf.exe and got the following error from gcc: inf.h:1:18: error: #include nested too deeply #include "inf.h" ^ No idea if it's the standard telling it to abort after so many nested includes, or if that's a gcc implementation thing. Doesn't really answer anything but it surprised me that it self-terminated instead of just bringing my PC to its knees.
You added a failure mode (grab not having been assigned) and potentially a memory allocation (in std::function), and increased the size of every object instead of adding a single pointer to the class definition, and you still have a virtual function call in std::function so you're not winning in that sense either. But for the rest it looks great ;-)
Too late, gotta claw my eye out.
Thanks and agreed! There is effectively something similar to a virtual function call, and this implementation is definitely not optimized for memory consumption, but more for composability and generic usage. It might be adapted in order to consume less memory, but I suspect that a lot more of template gibberish would be required. &amp;#x200B;
&gt;I don't believe a native build system written in Python can ever be fast enough. Meson has also been designed so that the Python implementation does not leak in the build definitions. It could be implemented in any language. In fact I was told that there is a guy doing a reimplementation in C. I don't know why or if anything will ever come out of that, but it's possible. &gt; This will likely change with C++ modules. That is possible. We shall see.
Your suggested code is doomed if n is larger than RAND_MAX which is easily possible.
I don't think there's anything *requiring* an infinite program to be ill-formed, but an implementation is certainly *allowed* to reject one. See [http://eel.is/c++draft/implimits](http://eel.is/c++draft/implimits).
Annex B is informative (non-normative), but it expresses a clear opinion in [implimits]/1: "Because computers are finite, C++ implementations are inevitably limited in the size of the programs they can successfully process." Sounds like a Culture ship name: LSV Computers Are Finite.
In C++03, the standard prohibits infinitely long source files, by specifying that it must have a last character: &gt;... If a source file that is not empty does not end in a new-line character, or ends in a new-line character immediately preceded by a backslash character before any such splicing takes place, the behavior is undefined. — [N1804](https://wg21.link/n1804) § \[lex.phases\]/1/2 C++11 removes this restriction: &gt;A source file that is not empty and that does not end in a new-line character, or that ends in a new-line character immediately preceded by a backslash character before any such splicing takes place, shall be processed as if an additional new-line character were appended to the file. — [N3337](https://wg21.link/n3337) § \[lex.phases\]/1/2
What is the "value" of a "component" in a string?
The comment was about RNGs in general not just the RNGs in the standard library. I thought there was also a faster o e in the standard library, but I didn't check. 
If the whitespace is not semantic, then its not part of the program, and does not make an infinite program.
 Deep in the forest, *there dragons will* be. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9sicp5/need_help_on_this_assignment/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I really disagree with you on whether int area(square s){return width(s)*width(s);} int width(square s){return s.width;} should compile: As a human I start reading at the top and the current model ensures that I will have come across every function that is used so that even when I didn't read it, I know where I can find either it or at least it's declaration which will often enough already tell me everything I need to know. The model of the other languages that everything can be anywhere in the module takes that away for no real benefit. And while some of it's implication are indeed not the greatest, I believe that it works really well that way. 
sorry, are you saying that waf is fast ? every time I've had the "pleasure" to use something built with it it took *ages* for a fairly small number of files
After watching that I find myself agreeing more with the Abseil style guide. Uniform initialisation just trades one form of gotchas for another, especially if you don't have the luxury of always using the latest C++ standard. One thing is certain: initialisation in C++ is uniformly terrible. Something that fundamental shouldn't be a puzzle.
Not going to lie, your requirement sounds like something stackoverflow said was "the best thing" rather than something required by your architecture. 1. Consider a simple key-value/multimap store if you just want keywords. 2. Consider elasticsearch or similar for fuzzy searching. 3. Consider using bloom filters for "blazing speed".
Are you confusing it with scons? Scons is terribly slow, and waf was written to fix that (among other reasons). I use waf every day, and the time to start building projects with over a hundred files is not even noticeable. The configure step is not instantaneous, but it seems comparable to cmake and autotools.
I find the multi-signature feature surprising, when would need something like this over simply having multiple signals?
Well, it's not so much need as a quality of life thing. For example, I'd like my interface to have a single `onInput()` handler that other parts of the code can pass their own struct rather than setting up multiple signals. Maybe more of a personal preference thing.
Simply said, less boilerplate code. Exposing N signals means writing and calling N connect() functions, as well as declaring N connection variables.
Before I started using cmake on my projects, my experiences with it were all about trying to massage some random find package script into finding the package I'd already installed. That sucked. We just don't use that feature, set up link paths appropriately, and it's the best c++ build system I've used. Which isn't saying much, but it's tolerable.
I don't know if such library exists, but you can probably write your own container traits (see container concept https://en.cppreference.com/w/cpp/named_req/Container) and `static_assert` them.
static\_assert would be worth looking into. I don't know any test suites that would ensure that things fulfill the STL requirements
Videos like this do not help me with my imposter syndrome, that's for sure! It will help me remember that there's more than meets the eye when I run into any funny, unexpected behavior, though. Thanks for posting.
Good!
We use cmake heavily where I work. We're not fans. The syntax is awful and its design encourages overly complex code in the build system. No-one in the team wants to work with our cmake build system because it's reasonably large and that seems to translate into horrific cmake code. It's hard to believe that somehow they could come up with a replacement for makefiles which was harder to work with than makefiles, but somehow they did it.
I just had fun imagining a situation where that would work. Here's my take: The program must start with the main function, and all functions that are invoked must be compiled on the fly. You have to ensure though, that the compilation of functions runs faster than your code execution path. For that matter, that reminds me of JIT compilation: one could generate an infinite sequence of functions that are JIT-compiled and immediately invoked. I'm not sure if that would count as an "infinite program" though, because the original program size would still be final. For more fun with this idea, we'd probably have to more rigorously define what an "infinite program" is.
&gt; One thing is certain: initialisation in C++ is uniformly terrible. Something that fundamental shouldn't be a puzzle. Amen.
Bigger than the size of the universe?
For most applications passing 3 dimensions is good enough and you won't see patterns appear.
GCC had support for nearly all C++17 features before it came out; I don't see why it'd be any different with C++20. I'm excited about concepts because I've actually used them (GCC compiles something with slightly different syntax but the same functionality as will be in the standard). And they're really awesome - instead of writing a function to take a vector, I can write a function to take a Listable (something with a beginning and an end) and it'll also work with std::map, std::array, std::unordered_map, std::string, std::string_view, and all my own custom implementations of iterable collections 
I think this question is actually somewhat relevant if you're writing an interpreter for C++.
That is usually not related to the algorithm, but the object on which it runs. Any object that carry a container, by value, will want to use the std::move because most containers have heap allocated objects that don't need to actually move to change ownership. Even for copy-on-write objects which have a copy designed to be almost free, using std::move when applicable is removing the reference counting, but more importantly, the free check (which can annoy the branch prediction), and is therefore beneficial. Something that do a lot of object movement, like std::sort or anything based on std::swap would then be invariant of the size of the objects. Note that providing fast comparison and hashing (even caching the hash value in the object) can be beneficial in those case too.
I think the author is confusing how modules are implemented in clang with the modules spec. The shared use of the file format that is used for precompiled headers and precompiled modules is a compiler specific implementation detail and does not mean that modules are simply standardized precompiled headers. The code they specified should not link since they are never actually compiling the function f() in m1.cppm. Running --precompile simple generates the PCM, which serves two purposes; it is the source by which a second TU can import and perform name lookups as well as a binary AST that can be compiled to an object file. This is done for performance reasons to allow a build system using clang to begin compiling dependent modules concurrently with the PCM. The concerns about the inability to isolate the "internal" changes to a module are also due to the use of the pch file format that contains ALL the information that the source module compilation requires. The MSVC modules implementation (which is not perfect either) took a different approach and instead generates the object file and a BMI file format that only contains the exported symbols (ifc). Also, a major reason for modules is that they DO provide isolation from macro definitions. A macro definition does not pass through a module import declaration since it is a part of the language itself instead of a simple preprocessor injection.
If you like pretending you're a Javascript developer using fifty layers of dependencies with dubious licenses, unknown quality and duplicated versions across different recursive dependencies be my guest.
Yes, infinite.
I liked to use libuv async more, I mean this is just goroutine right?
What's the modern way to use precompiled header with cmake? What's the modern way to compile with /MT for visual studio (which is pretty important)? These two things are done with horrible hacks 'til this day. Even regardless of cmake syntax or other issues, some problems just never got proper resolution for some reason.
How could it go so wrong? I understand why the C legacy is why it is, but everything that was added later. Sigh.
What it's got going for it is the long period, statistically it's not that great either (as tested with Practrand). You [we, mere mortals] obviously cannot change the standard, but the MS-STL could be much better in respect of the [uniform_int_distribution](https://www.reddit.com/r/cpp/comments/9sb3rj/is_random_really_better_than_stdrand/e8nm9h3/).
I mean when vector runs out of reserved space, he should copy all of its contents to a new buffer. However, if he can (noexcept) move each item, he does. vector&lt;vector&lt;T&gt;&gt; is just an example of a vector whose contents are cheap to move and not so cheap to copy. 
There are a lot of situations where swap is cheaper than move. For example, all our node-based containers, and even vector/string in debug mode.
`a..b` for inclusive, `a...b` for exclusive.
On the plus side I've moved about half our build system to meson. It's beautifully clean and neat by comparison. The build system code is maybe a half or a third the size of cmake and it's so much easier to read and maintain. I'm so impressed that I've moved all my personal projects to meson as well.
Your argument makes no sense.
First you would need to solve the issue of finite amount of disk space in the world. 
Where in the standard is disk space mentioned? The standard defines the abstract notion of a "well formed program". I'm not asking whether there *could* be an implementation of the standard that accepts an infinite program, but simply whether the standard prohibits these programs innately 
I think they made the right decision on this one. 
the difference in probability is so tiny... I'm sure there are times where you need that extra bit, but I have yet to need it
Or also [nano signal](https://github.com/NoAvailableAlias/nano-signal-slot). Iirc, there are also comparing benchmarks. Might be interesting as well.
still not as clear to me. and I'm already worried I'm going to mess up incrementing the i if there's breaks/continues
&gt; As a human I start reading at the top As a human working on a large C++ code base, I rarely need a whole C++ file, much less read them sequentially from the top. I jump to a definition, look at it and the code surrounding it, and if I need to know more, like what `width` does, then I just jump to that. I don't think anybody working on million LOC codebases (e.g. Chromium, Firefox, ...) reads files from the top every time they need to use something. That would be a huge waste of time.
http://gcc.gnu.org/onlinedocs/cpp/Implementation-limits.html &gt; Nesting levels of ‘#include’ files. &gt;We impose an arbitrary limit of 200 levels, to avoid runaway recursion. The standard requires at least 15 levels.
What if you are providing the storage to a C interface? If you don't expect the storage to grow our shrink you can just use a smart pointer a capacity and a size, and you don't need to specify the size of the storage in a call to reserve.
It's not the fault of `auto`, it's the fault of you are subtracting an unsigned int 0 by 1. 
Being a meta-build system is why it's popular though. It solves real-world problems people have. I can build on Unix with regular Make or Ninja, while Apple devs can use Xcode, and Windows developers can use Visual Studio project/solution files for their specific Visual Studio version. Or they can use CLion. Or whatever tools and IDEs they prefer. When I adopted CMake for all my work projects, this was after evaluating all the current build tools of the time (5 years back or so). We were all developing primarily on Unix and MacOS X, but had to support Windows for various Visual Studio versions. CMake met that need. There's nothing wrong with being a "proper build system". But CMake is the glue which lets it fit into all sorts of places a proper build system would not have. And while that means it's a bit quirky and more complex in some places, I'm happy to pay that price for the huge flexibility it brings.
Can anyone please explain to me what the purpose of any of these except the first two are? I don’t see how the legacy C initialisations are in any way flawed or less good than the more modern ones, and I for one find the legacy ones much easier to read and interpret. If I want to assign a value of zero I could just do ‘int i = 0;’ , and it’s much clearer than the ‘modern’ way? Please correct me if I’m wrong!
I use callbacks all the time, but not as you advertise it. You see, the biggest difference b/w class ICamera { public: virtual ~ICamera() = default; virtual cv::Mat grab() = 0; virtual double get_contrast() = 0; virtual void set_contrast(double v) = 0; }; and struct CameraFunctions { std::function&lt;cv::Mat(void)&gt; grab; std::function&lt;double(void)&gt; get_contrast; std::function&lt;void(double)&gt; set_contrast; }; Is the fact the latter can be implemented by multiple classes. In other words, if a class cares only about grab, it can implement only grab, a separate class can implement the other two. This gives extreme composability in the form of partial interface implementation. So, don't try to bundle these together, mimicking abstract classes and a monolithic interface - take advantage of the loose coupling and grater granularity. 
Correct. And Wextra would have told you the problem with the infinite loop. Actually I also expected a mismatching sign comparison warning... BTW: The guideline is "use auto when you don't care about the type or be explicit on the RHS"
And disabling warnings; `unsigned &gt;= 0` typically generates a warning.
I don't use PCH much so I don't worry about that :P But for /MT I admit I just let vcpkg deal with it. Since the flag needs to be in sync with the precompiled libraries I depend on it does make sense.
You don't happen to know how the review is going? I haven't seen anything about it since it was announced here on r/cpp some time ago.
teaching unique_ptr without immediate discussion of move semantics seems less than ideal. The problem people have with unique_ptr is they don't understand why it causes errors all over their code.. but shared_ptr just works... 
Badly written loop condition aside, a sensible set of compile switches should catch this... With clang `-Wall -Werror -Wextra`: error : result of comparison of unsigned expression &gt;= 0 is always true [-Werror,-Wtautological-unsigned-zero-compare] With MSVC `/W4 /WX /analyze`: warning C6295: Ill-defined for-loop: 'unsigned __int64' values are always of range '0' to '18446744073709551615'. Loop executes infinitely.
&gt; so as I'm learning C++ I view everything with the same mind or framework that I do as I'm learning math You should try Haskell. C++ is cribbing plenty of ideas from Haskell with each successive standard anyway.
Well, I know what I'm doing for the next hour
Another philosophical question: Is this a conforming C++ compiler: &amp;#x200B; \`\`\`C++ int main() { volatile unsigned int v; while(true) { v++; } } \`\`\` &amp;#x200B; In other words: is a compiler that never terminates on any input a valid compiler, or does the spec specify that it needs to produce a result in a finite time? &amp;#x200B; Other question, Is a compiler that always generates a program that runs an infinite loop, a conformant compiler.
Well, that's true, but at least it will not add any bias to the random numbers. ;P
I am struggling to see in your point more than a minor inconvenience but the example you provided looks more like you wanna throw the baby out with the bath water.
Alas, vcpkg doesn't deal with it at all. It *does* automatically use the /MT switch when building libraries with a static triplet (such as x64-windows-static). But when you come to build your application with CMake, and pass in -DVCPKG_TARGET_TRIPLET=x64-windows-static flag to choose those libraries, you still get the /MD library linkage, causing a broken build. You need to specify /MT manually, either with hacks in your CMakeLists.txt or by passing an override on the command line; either way, you need to re-specify *all* compiler flags, not just the one you want to change. See the note buried in [this official vcpkg blog post about static linking](https://blogs.msdn.microsoft.com/vcblog/2016/11/01/vcpkg-updates-static-linking-is-now-available/) (search in the page for "CMAKE_CXX_FLAGS") and [this vcpkg issue about the problem](https://github.com/Microsoft/vcpkg/issues/3807).
Not irrational hate. Inertia, and investment into tooling. Switching build systems is a massive undertaking, and as such the gains from the switch have to outweigh the cost of the change. This is non-trivial for big, established projects. I've done several conversions of big projects from GNU Autotools to CMake. They were big undertakings which in some cases took several months. But the gains in portability, flexibility and maintainability made it worth it. Getting intimately familiar with a new build system takes time and effort. It took a couple of weeks to learn the CMake fundamentals and use it in a small project. It took months to fully master it and use it in a really big project. If you were to ask me if I'd switch to Meson now, I'd have to justify throwing away all that hard won knowledge for an unknown. It doesn't matter if meson is incrementally better in some respects; as I said in another post, a lot of the value is in the ecosystem surrounding the tool, not the tool itself. As CMake has become the de-facto default cross-platform build system for C++, there is a huge amount of value in being part of that integrated ecosystem, and a cost to pay to not do so. The other factor is meson's origins. It's used primarily in a rather insular set of projects, and hasn't been as exposed to the wider world with rather broader requirements and goals. There are many build systems which purport to be simpler and easier to use, and they are for the simple case, but for more complex real-world use, they are not up to the job. CMake has been battle tested by thousands of very projects, and has many contributors who have filed off all the rough edges and made it do all sorts of neat things. The chances are if I want to do something, someone has already done it, or done something similar I can build upon. I would no want to switch, only to find some critical functionality wasn't present. This is not in any way a criticism of meson itself, but rather trying to explain that being technically better isn't in and of itself sufficient to displace other tools. There's a whole host of other dynamics at work. Look at the dominance of the GNU Autotools for decades, despite being an overly complicated mess. They had deep value despite the mess, even when there were a number of technically better alternatives.
Now try `#include __FILE__`.
&gt; If you feel the need to test private function, either your class design is flawed, or your tests are flawed, or the mix of the two. Also, free your functions. So you are saying that private functions do not need to be tested? What kind of BS is this. You should be able to test your functions, independently of whether they are private or not. 
I disagree on the lack of useful implications. If you manage to implement a REPL for C++, you'll have what amounts to lazy evaluation of a potentially infinite program. Implementing a REPL for C++ is probably hard but it should be possible.
How about `auto const x = { 42 };` ?
About the error messages, you may want to check the presentations of Roland Bock about his library sqlpp/sqlpp11, for some ideas. The library is template heavy and in his presentations he describes different techniques about giving short and helpful error messages to the library user. Here are two of the presentations that may be helpful: [https://www.youtube.com/watch?v=afGv7A9gvmc](https://www.youtube.com/watch?v=afGv7A9gvmc) \- Pruning Error Messages From C++ Template Code [https://www.youtube.com/watch?v=wTmAJAk7WV4](https://www.youtube.com/watch?v=wTmAJAk7WV4) \- How to test static\_assert
What about it?
[https://i.imgur.com/3wlxtI0.gifv](https://i.imgur.com/3wlxtI0.gifv)
Now this is very interesting!
Indeed the distinction between CMake-the-scripting-language and CMake-the-functionality is a good one! I'm looking forward to having a less stringly-typed CMake frontend!
This is a wise advice. The code in my example forces the implementers to group together the different interface implementations. This is less surprising for developers who are used to class polymorphism, but this also leads to abandon some of the freedom associated with free functions. &amp;#x200B;
Why was this a suprise?
I would like to ask - what advantage of signal/slot system over event system? They looks very close... The only difference is that Event owns slots (delegates), if I understand things correctly. Event system looks easier to use: Event&lt;int&gt; value_chaned; value_changed+=[](int i){ std::cout &lt;&lt; i }; value_chaned(12); vs fgl::signal&lt;void(int)&gt; my_signal; auto slot = [](const int value){std::cout &lt;&lt; value &lt;&lt; '\n';}; auto connection = my_signal.connect(slot); my_signal.emit(42); 1) It's shorter. 2) You don't have to own slot/delegate. And this may be important from usability side. &amp;#x200B; I always thought that signal/slot system as in Qt was surpassed by events (in C#'s sense of word). &amp;#x200B; I made a similar event library [https://github.com/tower120/reactive](https://github.com/tower120/reactive) (look at Event). *It may have some issues in multi-threaded use, I didn't have real need in multithreadeding, so I didn't investigate that.*
That comes from C89 :-) Also, remember that you can also call a function pointer directly: `pf();`
&gt; As a human I start reading at the top the fact that every other language out there works like this and people manage to be fairly productive in these languages - if anything, generally arguing that they are more productive than in C++ - shows that this is not true. If that's what you want just put it in your code formatting guide.
I would say that it's `.size()` fault. It should return a number (`int`) and not a 32 bit arithmetic value with build-in overflow mechanism!
That doesn't make Cargo terrible. That means you don't like bringing in dependencies. You can do the same thing in C++. It's just way, way harder, just like everything else. Using Cargo doesn't mean you have to add dependencies, and it definitely doesn't mean you have to add dependencies without checking their subdependencies. This is actually made easier considering they're added in the manifest.
Back from what? C#, Java, Rust? What is better then C++? Seriously. &amp;#x200B; I personally don't see **real** alternatives to C++. Despite all this horrors, this is one of the most powerful languages. Not ones I missed const-correctness, templates, multiple inheritance, deterministic destructors (true RAII without "using") in C#/Java. Despite they claimed as more "safe" languages, in C++ it is possible to have much more compile-time checks, and be much closer to "if it compiles - it works". 
Oh, their loss. 
You'd get the same if you don't use pure virtual functions.
Using \`auto\` is not an excuse to forget about types. You should always understand what is the type of your \`auto\` object even if you don't spell out that type explicitly. Knowing the type gives you the idea of what you can and cannot do with the object, and certainly helps to avoid mistakes like the one in the article.
Right, I'll have to look at how I setup my builds because I don't look much into it once it works ok. I guess I just gave up in /MT. I don't think it's really recommended to do this anyway. For sure I still see most apps asking to install the visual C++ redists rather than not.
Promoting a tool I like and use and that I find more useful than CMake, because I do know cmake well, is not putting a knife on the neck of anyone and saying: just try it instead of cmake! XD I think it is a valid alternative, I am not asking for people to switch build systems, I just open the door to other tools that certainly do a few things better out of the box: &amp;#x200B; \- cross-compilation \- unity builds \- pre-compiled headers \- mixing languages \- the DSL is easy to learn &amp;#x200B; As a fair point, CMake code generators and tool integration (XCode and Visual Studio) are really good and useful in real work environments. &amp;#x200B; I can agree that people do not find it worth to do a switch. But I do not think that deserves negative votes. Negative votes should go to negative comments or to comments you disagree about IMHO. However, anyone is free to vote the way they find it cool. I do know CMake has become the standard. But Meson is a \*very\* competitive alternative whether people that use CMake try to boicot it or not :) Just my two cents. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
It's the same 3 core lines of code, they're essentially the same thing with different names. The callback isn't owned, it's copied into the signal. He just wrote multiple lines for clarity. The connection returned by connect looks like an RAII type so you can automatically unsubscribe when it goes out of scope. Which is handy to avoid callbacks after destruction. I think C# handles this automagically so you don't really think about it, but you do need to consider it in C++. 
I find your lack of Rust disturbing...
\&gt; I think C# handles this automagically ... Not really - it automagically leak memory if delegate captured non-weak objects. &amp;#x200B; \&gt; It's the same 3 core lines of code... So signal, internally holds std::vector&lt;std::function&gt; ? I thought it just stores function pointers... At least as far as I remember, Qt does. If so - indeed Event just a better name for the same thing.
Some things to consider when making your own signals/slots/observers/etc - how do I find a slot (ie for disconnect or is_connected(), etc) - is there a unique id? - what happens when I disconnect from inside the slot? - what about threads? I did a talk on this: https://www.youtube.com/watch?v=RVvVQpIy6zc It is called "Thread-safe Observer Pattern: You're doing it wrong", but there is a lot of non-threading gotchas mentioned as well.
The container type you use for storage should be a customization point. Can think of 3 sufficiently different implementations that you may want to offer with the library: * Optimized for lists when you care about speed of insertion/deletion. * Optimized for number of listeners using container like vector, deque etc and deleting based on the address of the callable or some other mechanism that doesn't rely on iterators that can be invalidated. * One that uses limited size stack buffer. At this point this just seems like a very simple abstraction / interface over a container of function\_ref's. &amp;#x200B;
I don't write a lot of C#, I just remember seeing a lack of unsubscribing from events in code I looked at, so I assumed it was handled for you. I'd argue Event isn't a better name for this concept, it's overloaded with the OS-level synchronization object -&gt; [Win32 Event](https://docs.microsoft.com/en-us/windows/desktop/sync/event-objects) and [Linux event](https://linux.die.net/man/3/event), which have different mechanics: They are usually kernel objects so they can be shared cross-process, etc. 
I was referring to studying the source code, not using the editor.
Rest assured, I **do** see your point. Anyways, your username got me to visit Catch2 repo. Pretty neat.
Bias from using `% N` comes from the fact that 2**32 isn't evenly divisible by N. The last integer below 4,294,967,296 that is evenly divisible by 6 is 4,294,967,292: the difference between the two is 4, so there's a higher chance that you'll get a value in the range of 0..&lt;4. But how much bigger is that chance? The probability that you'll get a biased result is exactly 4/2**32, since that's the size of the incomplete range. With 960,000 attempts, the probability that you even rolled a biased result was 0.0894%, so of course it doesn't look like there's a bias towards the lower values: it is overwhelmingly unlikely that there was one. You need some combination of a much larger range or a much higher number of attempts for it to register.
 if(r &gt; RAND_MAX) std::terminate(); fixt.
Once you've used bazel (ex-googler here), and I guess gn, buck, pants, please.build, etc. everything else seems overly complicated. Maybe it's a condition, maybe a diseases, but I have bazel-ites... Still don't want to sell it to our team, as we are heavily vested in MSBuild, though some of us like cmake, others premake, then some FASTBuild and the plethora of choices there.
By overly complicated - I mean the user-side, much like C++'s std is easy to use, but not easy to write/maintain. Same goes with bazel, it's very easy to use, not so (at least to me) to dig and write .bzl extensions - but possible. CMake on the other hand - throws you to do the complex stuff all the time. 
A few, and am also involved in GCC and Clang development. Instead of trying to reach for an argument to authority, perhaps you could explain how having headers makes it easier to prevent 'recompiling the world' (when it is quite obvious that it makes it *harder* to prevent)? When a dynamic library changes a *source* file, I don't have to rebuild my software to use the change, because the change will be brought in during the dynamic link. When a dynamic library changes a *header* file, I have to rebuild because I likely used said header file to act as a declaration of interfaces.
And don't forget to manually pass the *this* pointer 
https://github.com/LiveAsynchronousVisualizedArchitecture/simdb/blob/master/README.md You can check that out - it is a fast lock free 0 dependency key-value store. It is memory mapped into shared memory, although I'm not sure that is something you need unless you are sharing data between processes. Memory mapping won't make it go any faster, but is useful for shared memory.
Any different to the CPPCon talk?
 for (auto i = bits.size() - 1; ++i &gt; 0; )
Forgive any code formatting errors... Wordpress seems to love making my templates disappear
This is low-quality code that is more harmful than helpful for beginners. 
Assuming that was supposed to be `--`, then this is shorter and signedness-agnostic: for (auto i = bits.size(); --i; )
ElasticSearch is a bulky JVM mess that needs a 3-server cluster to even begin performing well. Plus tuning that sucks. And I need 10% of the features. Right now I'm using https://github.com/luceneplusplus/LucenePlusPlus but the index read/write speed is terrible.
This is a great talk, imminently shareable with coworkers.
An infinite program is fine. Step 1, write an OS or game or whatever, some app that never ends. Step 2, instead of just executing that app, have the app write C++ _code_ for whatever it wanted to do. Step 3. Write a C++ interpreter. Note that an interpreter is a valid implementation of the standard - it doesn't need to "compile". Step 4. Set the output of your infinite app to be the input of your interpreter. Step 5. Profit (?) 
The best way I can describe it is that it's like programming in math.
Of course, I had to forget that. But also, that way fails for an empty container.
&gt; But also, that way fails for an empty container. No, it doesn't.
Doesn't seem like it 
Actually, /u/tower120 is right: * keeping the instance of connection alive is mandatory; * the slot isn't copied into the signal. Let me explain this with an example: struct slot_type{/*...*/}; //function object using signal_type = fgl::signal&lt;void(int)&gt;; using connection_type = signal_type::connection&lt;slot_type&gt;; signal_type signal; slot_type slot; connection_type connection = signal.connect(slot); `connection_type` defines a private static function `void on_event(void*, int)`. Because it is a static function, its type is `void(*)(void*, int)`. On its side, `signal` stores: * `pf`, a `void(*)(void*, int)`, which points to the static function defined by `connection_type`; * `pvslot`, a `void*`, which points to `slot`. Calling `signal.emit(42)` calls `pf(pvslot, 42)`, which then calls `slot(42)`. `connection_type::on_event()` is able to cast `pvslot` into the actual type of `slot` because it knows its type. (Because of the multi-signature feature, the reality is a little more complicated than that, but the idea is the same.) &amp;#x200B; To answer your question, /u/tower120: Deep-copying the slots into the signal (which is what sigc++ and boost::signals do, if I'm no mistaken) would require the use of virtual-table-based type erasure (as used by `std::function`), which is much slower than void\*-based type erasure.
This is nice!! Hope to get SSL support soon. Now I wish I had completed my work on [Cpp-Hypertext](https://github.com/arun11299/Cpp-Hypertext) :)
Good point. I'll think about a solution. &amp;#x200B; &gt;At this point in time the library just seems like a very simple abstraction / interface over a container of function\_ref's. That's exactly what it is. I'd like to keep it as simple as possible, to follow the "don't pay for what you don't use" principle. Of course, if I can make it safer and nicer while keeping it fast, I'll do it.
Of course, the fact that neither of us wrote this thing correctly the first time just goes to show that it's complicated and we should really just find a range based way to do it instead. 
&gt;how do I find a slot (ie for disconnect or is\_connected(), etc) - is there a unique id? I can't see a use case where an object (other than the slot itself) would need to disconnect the slot or check the connection to a slot. Do you have any example? &amp;#x200B; &gt;what happens when I disconnect from inside the slot? Yes, that's definitely a point I need to address. Either by emitting an assertion failure, or by actually managing this use case, provided it doesn't cost anything. &amp;#x200B; &gt;what about threads? I don't plan to make fgl::signal thread-safe, because I don't want to make the user pay the cost of a thread-safety they might not need. Thread-safety can (should?) be managed at higher level (by using active objects for example). However, a fgl::signal\_mt (for multi-thread) variant could be considered. But I'll watch your talk anyway :).
I probably should have actually read your code before I replied, just assumed it made a deep copy ¯\\\_(ツ)_/¯. I would find that a bit too tedious to keep around so many variables for both slots and connections. You can flatten it a little bit by using a generic variadic lambda for your slot, and then some if-constexpr to do your actual dispatching inside of it based on the parameters passed in. But you can only differentiate based on parameter types (unless you start adding tag types, blah). So the multi-signal breaks down once you have multiple signals with the same type, no? Then you would have to create M signals, and the subscriber would have to hold N slots and N connections around. Where M is [1, N] depending on how many signals share the same types. In the past I've also used type-erasure to keep a collection of connections so I don't have to keep adding fields to a class for every event I subscribe to. Usually for our purposes we wanted to be subscribed for the entire lifetime of the object and unsubscribe in the destructor, so you never had to access that collection again. This left me with a single collection for connections, slots were inlined using lambdas/std::bind (which were deep-copied into the signals), and signals were provided by other dependencies. So for N signals, I hold onto 0 slots, and 1 type-erased collection of connections. Perf vs. convenience... thankfully C++ gives us that choice. 
This is by no means a comprehensive guide on ODR \*or\* how to fix them. I think that would be a book! I had recently violated ODR myself...for the Nth time (hence the title), so I thought I'd a refresher post was in order. There are some SWIG-specific things in that post when I could have used more generic C++ code, because I wanted to throw out a little warning to other SWIG developers along the lines of "hey, make sure you understand those SWIG macros!"
Next year, they need to rename the conference "Sea++".
&gt; yeah, why make new and better things when we already have 1 of something. We wasted all this effort making cars after we already had perfectly good trains. Think how awesome our trains would have been by now. are you saying this sarcastically ? because the current trend (at least in europe) is certainly towards more trains &amp; trams and less cars.
cotire mostly works, however I couldn't use it one time trying to compile with clang-cl. I've tried other solutions from github and they had some other issues. Eventually I've decided to support only msvc-like targets with writing two lines of compile flags by hand. But I mean that's the problem with external solutions, it's hard to tell are they up-to-date with newer cmake features or not. Also it's not always easy to discover them if you are inexperienced.
That's great but damn it is expensive.
&gt; clang-cl. I don't think that this one supports PCH in any released version yet : https://reviews.llvm.org/D46652
Thanks!!!
I like the usage and syntax, but that source code is crazy. We should make every member of the C++ standards committee write that code by hand on paper as punishment.
Well yes, it was sarcasm, but i don't think in the way you are interpreting? The point was they both may solve the same problem of 'land-based transport' but are not generally drop in replacements for each other. The existence of one doesn't preclude development of the other. Typically, options are good; competition is good; choices are good. I'm not sure why -very different- build systems are dismissed 'since we already have CMake'. &amp;#x200B;
&gt; The existence of one doesn't preclude development of the other. no, but if in 100 years we end up without cars, which is notimpossible, there will still have been a lot of money wasted on cars - and infrastructure to accomodate cars - that could have gone on train and bus development.
[http://eel.is/c++draft/intro.compliance](http://eel.is/c++draft/intro.compliance) says that &gt; If a program contains no violations of the rules in this document, a conforming implementation shall, within its resource limits, accept and correctly execute[2](http://eel.is/c++draft/intro.compliance#footnote-2) that program[.](http://eel.is/c++draft/intro.compliance#2.1.sentence-1) I guess your program does not accept and execute all valid programs, and not because of resource limits, and is therefore non-conforming, and for the same reason - neither is @ShhTinyBanjoPurr's tape dispenser. &amp;#x200B;
The code is actually quite disciplined and 100% covered by the unit tests, which allowed a great many people to contribute to the library.
If you see anything that could take greater advantage of your library, I'd be very keen! Thanks for your continuous amazing work on the Beast library!
I fall in love with Qbs on first sight. I discovered Qbs while I sketched a design for a new build system myself. Qbs covered like 95% of my own design, but had many more features I never imagined possible. I use it for all my projects whenever I can. I teached it to pupils, students and professionals. Everybody I could convince to use it, loves Qbs now. But adoption takes time. To completely abandon it from the Qt project now is the worst decision the Qt project could make. For me it seems that something has corrupted the Qt project. Maybe the Qt company is now driven by a short sighted managers, where improving the world is no longer a worthy goal. Only because 90% of the people drive a fossil fuel powered car and most of them are happy paying customers, it does not mean you should abandon the development of new electrical cars, to focus all resources on fossil fueled cars. The Qt compary swallowed this [3D Studio](https://blog.qt.io/blog/2017/02/20/introducing-qt-3d-studio/) software from NVIDIA, that required a full rewrite to make it a somewhat usable native Qt tool. And now they complain that this little Qbs project takes too many resources? From the [Git log](https://code.qt.io/cgit/qbs/qbs.git/stats/?period=q&amp;ofs=10) it seem most of the work is done by just two guys. Compare this to the [Qt 3D Studio](https://code.qt.io/cgit/qt3dstudio/qt3dstudio.git/stats/?period=q&amp;ofs=10) \+ [Runtime](https://code.qt.io/cgit/qt3dstudio/qt3d-runtime.git/stats/?period=q&amp;ofs=10) … or [QtCreator](https://code.qt.io/cgit/qt-creator/qt-creator.git/stats/?period=q&amp;ofs=25) Please give Qbs and QtCreator a chance… free those projects from the Qt company! Allow them to succeed as great open source C++ toolings.
That's great to hear! I'm currently working on SSL/TLS support, just experimenting with the best way to implement it.
Thank you! I notice your library follows the pattern of having public interface headers, detail, and implementation separations. Have you come across any good resources that explain/discuss that type of design?
Cool! Can it use GCC's linker plugin for LTO? 
You've yet to actually explain how using headers helps. Even if headers rarely change (debatable), you'd still have to relink if you're statically linking, and dynamically linked objects aren't impacted unless you change the interface prototype. The main difference is that executable code in a header can be inlined, but I fail to see how that helps, and LTO accomplishes similar in regards to static linking... and in regards to dynamic linking, having actual code in headers makes them more likely to change.
What was the reason to make updateposition pure virtual? Right, none.
&gt;I don't think it's really recommended to do this anyway. The problem with doing it is that most developers fail to understand that if you want it, you have to do it for every library you use, which means taking full control of building your entire dependency chain, which can be a serious undertaking. If you're willing to do so, though, or are completely dependency-free (or at least only header-only dependencies), you can get binaries that are completely self-contained and very easy to distribute. Ninja is a good example of this.
Nothing like good old-fashioned contradiction to imply intellectual honesty.
I'm still going through all the results and writing up analysis text (spreadsheets and assembly -- the boring part of the work). &amp;#x200B; Biggest result is pretty well known: Windows console is really, really slow (someone thinks it should act like a teletype instead of a virtual window into a text buffer like every other OS). Second most obvious is that iostreams are a good bit slower than stdio routines -- also fairly well known. Posix IO is slow due to less/no buffering - should be well known. Loop fusion optimizations seem to be lacking, despite the important papers on the topic being old enough to vote now. bitarrays and std::bitset aren't well optimized by anyone. And histogram optimization is kind of mixed.
It's just based upon how asio or some of the other boost libraries have tried to implement.
Delete this and write the title correctly
Beautifully written. This is something I'll keep in mind. It's interesting that you bring up units. I literally just started working on implementing a united library to handle units and unit converting. I'll do some research on dimensional analysis. My team lead recommended looking at this library http://nholthaus.github.io/units/ I was just about to play with it. I'm doing work in computational physics and there's so much unit conversion and checking. 
But do the unit tests have unit tests that also have 100% code coverage?
There's nothing to be "wrong" about. "It's not safe to bring in unwanted dependencies" =&gt; "Cargo makes it perfectly possible to audit your dependencies and it's always possible to bring in 0 dependencies. CMake or similar systems make it difficult but not impossible to bring in any dependency you want with no regards to whether it is safe or not. It is always possible to bring in 0 dependencies." =&gt; Cargo is strictly superior, at least in this particular regard. If you're going to contradict, the least you can do is come up with a single counter example of where you can accomplish something (even something like "not bringing in an unnecessary dependency") with a C++ build system that you consider better than Cargo that you cannot accomplish with Cargo. 
Sorry but Cargo just does not do dependencies right. That's all there really is to it. If you want a decent package manager look towards go's package manager. It's far better.
Well, ok "signal" is not a bad name, "slot" - is.
Why don't you explain why you think so? Go's dependency manager is very similar to Cargo. The primary difference is that Cargo uses crates.io and Go uses GitHub, and Go utilizes the filesystem differently. Either way, C++ is lightyears behind both of them.
CppDroid can be pretty usefull.... By the way, I don't recommend coding on your smartphone, I tried it before, it's not the most pleasant experience....
\&gt; I can't see a use case where an object (other than the slot itself) would need to disconnect the slot Well - I do. When you have a TextBox widget, and it subscribes to wall clock tick event to show time, and then die, you must unsubscribe TextBox's from receiving event first: ``` Event&lt;int&gt; time_changed; struct MyWidget{ void setText(const std::string&amp; msg){ cout &lt;&lt; msg &lt;&lt; endl; } }; auto widget = std::make_shared&lt;MyWidget&gt;(); time_changed+=[&amp;](int time){ widget-&gt;setText(std::to_string(time)); }; x = 10; widget.reset(); // somewhere, somehow x = 20; // runtime error here! widget is nullptr now! ``` I found it useful, to self unsubscribe slot/delegate when it detect that object it interacts dead. Like so: ``` time_changed+=[widget](auto unsubscribe, int time){ if (!widget) { unsubscribe(); return; } widget-&gt;setText(std::to_string(time)); }; ``` In this way - you don't have to bother with unsubscriber in destructor, so you don't have to modify your objects to be event-friendly. I wrap this into helper, see [https://github.com/tower120/reactive#bind](https://github.com/tower120/reactive#bind)
Because it's much smaller, easier to integrate and faster to compile. If your needs are simple, there's no need to use something huge (and its dependencies). For example picobench is small enough to be a part of your repo and it's a great way to provide simple benchmarks without having to resort to packages or sumbodules.
&gt; For an actual good talk about trade-offs between software engineering choices and performance, the keynote from the fellow with the movie making software is far better. What's the title of the talk if you don't mind?
That's a lot of mircos.
BTW it's "micro", not "mirco".
Did you consider using a templated function for your print method? It would avoid dozens of lines.
last time i used a templated function inside a non-templated class the linker completely fucked itself over (it was in the same header, by the way) but yes, that worked amazingly. i just put the template in the class definition and deleted all the functions (except for the one that takes function pointers for stream manipulation) and added the template and it works. i'll commit it in soon. thanks
 class Sprite { public: Sprite(); const vec2&amp; Position() const { return m_Position; } void SetPosition(const vec2; NewPosition) { m_Position = NewPosition; } void UpdatePosition() { ... } void HaveCollidedWith(const Sprite&amp; OtherSprite) const { ... } private: vec2 m_position; vec2 m_size; vec2 m_velocity; vec2 m_acceleration; scalar m_mass; }; class Sprites { public: Sprites(); UpdateSpritePositions(); private: std::vector&lt;Sprite&gt; m_SpriteBodies; }; Is it just "data oriented" because they used a struct instead of a class, or something?
Its a great lib, so im very thankful for it
Probably just working `/FI` was enough for my case.
&gt; that source code is crazy What do you mean exactly? Too much template abuse?
Since you mentioned Groovy, there's also a [Kotlin DSL for Gradle](https://blog.gradle.org/kotlin-meets-gradle). Syntactically, it can look a lot like Groovy in places, but it's a statically typed language, including not making everything nullable. CLion added [Gradle support](https://blog.jetbrains.com/clion/2018/07/clion-2018-2-clangd-gradle-compdb-sanitizers/#gradle_and_compdb) somewhat recently.
My focus was not performance, and there are also faster libraries than RapidJSON. However, it would be great if the benchmarks on the site would be updated. However, a respective issue is open since February: [https://github.com/miloyip/nativejson-benchmark/issues/100](https://github.com/miloyip/nativejson-benchmark/issues/100)
I think this is a fantastic library. Out of curiosity, are there design decisions in the library that make it difficult/impossible to achieve better performance or is it just that you have decided not to put as much development time into improving it?
FWIW it uses the standard containers as default so I am pretty sure that customizing the containers amd allocators in certain scenarios could boost performance, but not sure :)
I feel an itch to try to throw a data oriented design at it and see what happens. But I certainly don't have the time for it. 
it is not
You seem to have missed the bit in the middle... struct rigid_body { vec2 position; vec2 size; vec2 velocity; vec2 acceleration; scalar mass; }; class Sprites { public: Sprites(); UpdateSpritePositions(); private: std::vector&lt;rigid_body&gt; m_SpriteBodies; }; In this version, the methods can be geared towards working on sets of data, rather than individual sprites.
I think we leave a lot of performance on the road as we use an object for each JSON value. In addition std::vector for arrays and std::map for objects may not be the most efficient ways to build the hierarchies. I always wanted to define an API/concept for each of the types and provide a default implementation for the currently used types, while then allowing to replace each type with something user-defined. But yes, this is a lot of work... &amp;#x200B; PRs welcome :-)
The benchmark says it's 2.0.3 and we've got 3.4.0 now. That's worth taking into the consideration. Best option is to benchmark it yourself for your specific use case.
CMake generates rules for backends when its run, so if there is an error in CMakeLists.txt it would tell you right away and fail to generate makefiles.
Try `yes '// Hello infinite comments!' | gcc -x c++ -` Will still run out of memory though.
Nice library on top of beast :-) you seem to have to set this to get it to use more than one thread. app.websocket(false); app.threads is an int so when I try to use std::thread::hardware\_concurrency() which returns a unsigned int it throws a warning. Any reason why its not unsigned i cant imagine -1 threads is very useful. code was very useful to read to learn thanks for that. &amp;#x200B;
Hi, first of all, great work! The code looks clean and I love the fact that it has no external dependencies. However how does it compare against other libraries like [celero](https://github.com/DigitalInBlue/Celero), [hayaii](https://github.com/nickbruun/hayai) and [Google Benchmark](https://github.com/google/benchmark) ? Can we trust the results? 
Yeah I know but you have to actually run `cmake`, and the result only tells you if the build description is valid for the current configuration. I'm looking for something where the editor can provide immediate feedback as you type that is applicable for any configuration not just the current one, like with a statically typed programming language.
I will make some benchmarks in webassembly i hope i can use your library rather than rapidJson
Thanks. It's simpler. It has fewer features especially compared to Google benchmark. It's output and reports are bare-bones compared to other libraries. On the flipside it's much smaller and much faster to compile. With it I wanted to make a small and simple library which you can just add to a project for basic benchmarking without worrying about dependencies and repo bloat. It doesn't use fancy CPU counters but std::high_resolution_clock (QueryPerformanceTimer on windows) which IMO makes it adequate for most use-cases (though not all) as a bonus it works out of the box on practically any platform: desktop, mobile, browser...
This isn't an issue for fgl::signal, because MyWidget would hold a instance of connection that would automatically disconnect the slot when it's destroyed.
I think I could write a signal::any\_connection class that would be a type-erasing container for any signal::connection&lt;\*&gt; instance. Virtual call would occur only at destruction, so the cost would be reasonable. And it would still be possible to use signal::connection directly if the cost isn't considered acceptable by the user.
And you actually have to run the compiler as well for other languages, same thing. So what you really want is a plugin for your editor that runs cmake for you and shows the errors.
We went with SWIG because we publish bindings in other languages too, and SWIG allowed us to share wrapping code. If we only had Python we very likely would have gone with Boost.
`cmake` parses all the build files and executes them with the current build configuration as input and outputs the Makefile etc or returns an error. The analogue to that in a programming language is running the program, not compiling the program. Effectively CMake is a dynamic language and `cmake` is the interpreter. I'm looking for a statically typed build language.
&gt; Might be worth the slow down since the API for nlohmann is amazing compared to rapidjson. dunno about this, I spent only a few hours coding the part of my software which needs JSON with rapidjson, and now me and my users are enjoying great performance 100% of the time. would have I been able to code it in a few minutes with nlohmann ? I doubt it. But gaining half an hour of coding wouldn't make it worth it.
I wish there was more control over memory allocations when serializing. For example, `to_msgpack()` currently returns a vector which means it allocates every time. If for example there was an overload that gets a reference to a vector these allocations could be avoided.
No. If you mistyped some variable name, it will just ignore it and continue executing. So it doesn't try to detect errors right away.
I see your point. Let me phrase it differently: Creating a new build system from scratch and making business with it is really hard. They once learned that with qmake - and qmake was never really adopted outside of Qt. In other words, if Qt decided to go with Qbs, the vast majority would still go with cmake, meaning that Qt would have to support both Qbs and cmake. This was not a decision on a technical level, instead, this was a decision on business level.
&gt; because MyWidget would hold a instance of connection The point is to make solution non-intrusive: ``` struct MyWidget{ void setText(const std::string&amp; msg){ cout &lt;&lt; msg &lt;&lt; endl; } }; MyWidget&amp; my_widget = *(new MyWidget()); // somewhere latter... signal&lt;int&gt; time; auto slot = [&amp;](const int time){ my_widget.setTest(std::to_string(time)); }; time.connect(slot); // more latter... time.disconnect(slot); delete &amp;my_widget; ``` What you mean, I suppose, is this: ``` struct MyWidget{ void setText(const std::string&amp; msg){ cout &lt;&lt; msg &lt;&lt; endl; } Slot slot; }; MyWidget&amp; my_widget = *(new MyWidget()); signal&lt;int&gt; time; my_widget.slot = [&amp;](const int time){ my_widget.setTest(std::to_string(time)); }; time.connect(slot); delete &amp;my_widget; ``` It is safe indeed, but: 1) you need to know beforehand Slot type 2) you need to modify widget type, which may be impossible
Kinda, but not really. If you have a good IDE, you can get error information in realtime as you type. Sure, the IDE is doing similar things to the compiler in that case, but you don't have to actually compile everything.
u/nlohman: I once read the discussion by you asking for feedback about getting json into the C++ standard. Do you in general (and also with this release) still work towards this direction?
I guess this is useful, but... better abstraction would be more useful in general.
post this request to his github repo
If we had a standard way of doing type punning that didn't rely on `memcpy`-like functions, there would be much less motivation to even make pointers alias in the first place. Most of the strict aliasing violations I encounter are people basically trying to use pointers as a type punning mechanism. Network libraries are notorious for this. Of course, that doesn't do anything to help the decades of broken code written that have effectively ignored the strict aliasing rules...
Great article, thanks for shring. 
Just FWIW, `int i6 = {42};` is also valid in C: [WG14 N1570 6.7.9/11](http://port70.net/~nsz/c/c11/n1570.html#6.7.9p11): &gt; The initializer for a scalar shall be a single expression, **optionally enclosed in braces**. (Though C++11 rewrote the rule in the hope to catch overflow at compile time.)
[Fake](https://fake.build/) uses F# and [Cake](https://cakebuild.net/) uses C#. Both provide what you're looking for.
It's either a variant of ANSI C or just ANSI C, I can't tell. Either way it's not C++.
I've gotta be missing something here all right... Isn't rigid_body just a Sprite object with a different name?
Terse lambda syntax seems nice, but what I want to say is that I love your "bad auto example" example. I grew tired of seen those.
I wrote this to be able to add tests to a legacy C codebase, and I definitely didn't want to write the tests themselves in C. My opinion is that nobody should need this for a greenfield project.
They come up *in every discussion* of whether `auto` decreases readability. It’s infuriating. Even otherwise highly intelligent people fall for this. Once I fill in proper names most people are quick to concede that `auto` doesn’t seem to decrease readability after all. (To clarify: I’m firmly in the “really, almost always `auto`” camp. I use types where spelling them out makes sense, but I maintain that it rarely does.)
In fact, there are two more overloads, see [https://nlohmann.github.io/json/classnlohmann\_1\_1basic\_\_json.html](https://nlohmann.github.io/json/classnlohmann_1_1basic__json.html). They all use the concept of an output adapter, see [https://github.com/nlohmann/json/blob/develop/include/nlohmann/detail/output/output\_adapters.hpp](https://github.com/nlohmann/json/blob/develop/include/nlohmann/detail/output/output_adapters.hpp). A vector is one implementation thereof, but basically you could use anything as long it has a write\_character and write\_characters function.
Mmmh, ok, I can see the need. I'll see what I can do to make this kind of non-intrusive case more usable :).
Author here! AMA.
Wouldn't std::bind cover most of the proposed use cases ?
 For those who don't realize the fuckery afoot, read: https://github.com/Droogans/unmaintainable-code Your ancient tomes aren't ancient enough, there isn't enough multithreading and closures and enterprise annotations in your hello world example.
That would be a great thing to include in the top of your README.
Not at all. You cannot `std::bind` an overload set, nor member access (the `.` operator).
&gt; This syntax is terse and novel, therefore it is bad. Try a bit harder next time.
&gt; nor member access (the . operator). std::bind(class::method, classInstance, param1) ? 
I'm not aware of anything quite like that. It sounds like a combination of a custom-designed build system language and a real-time static analysis engine running in an IDE.
Lambdas are broken by design. Seeing them in production is like seeing turds on the sidewalk. Quarantine, Cleanup, and make friends with the programmer who wrote it, so that I can have the information I need to get him laid off for whatever reason is easiest. This isn't a conversation. So stop treating it like one.
I’m in favour. Lambdas are awesome - maybe my single most used feature of c++11 onwards.. I also like the terse template class syntax. Unfortunately as you noted, terseness is often shunned by the committee. Often with well reasoned arguments, but they don’t always apply to me personally...
What exactly are they losing?
These glorious days, we'd probably just expect a Language Protocol Server mode for CMake so _every_ (LSP-supporting) IDE can get that support for (nearly) free. :) That is roughly what the cmake-server tool does, only it uses a bespoke CMake protocol instead of the more universal language server protocol.
Right now, I think this is the happiest tradeoff w.r.t. `auto`: std::vector&lt;data::person&gt; people = get_people(); std::sort( people.begin(), people.end(), [](auto&amp;&amp; lhs, auto&amp;&amp; rhs) { return lhs.name() &lt; rhs.name(); } ); The return type matters a lot, or is at least a courtesy to future readers. Though it's probably obvious what the element type would be, so this would be nice: std::vector&lt;auto&gt; people = get_people(); Or even this: std::vector people = get_people(); Or this: std::vector people = get_people(); I wouldn't want to just put a concept name either, because obviously when I write the code I know it's returning precisely a `std::vector&lt;data::person&gt;`, but people looking at the code after the fact won't know immediately, and sometimes (frequently) Visual Assist and Intellisense just give up. But overall, strong agree. Well-designed terseness is lovely. I'm not really hurting with the verbosity of lambda syntax (begin and end calls are the biggest contributors to verbosity IMO), but shorter syntax would be nice. If there was a way to still incorporate optionally giving the arguments names, that would be ideal. Not every lambda is a comparison function with obvious meaning. This is what was so nice about C#'s lambda syntax, you could get rid of all the type annotations but still have argument names which usually convey enough info about the type on their own. Even single letter variable names imply a lot more meaning for non-std algorithms. // this: auto csv = mapWithIndex(people_by_ssn(), [][ fmt::format("{},{},{}", &amp;1, &amp;2, &amp;3) ]); // vs this: auto csv = mapWithIndex(people_by_ssn(), (k, v, i) =&gt; { fmt::format("{},{},{}", k, v, i) });
Does that work for data members?
Except your claim is easily refuted by experience. When I read other people's code that I'm not familiar with and which use type inference everywhere I find myself having to constantly query the type in my editor/IDE. To use the example in the article, in a real codebase there will be many types representing 'persons' and knowing which one it is makes it significantly easier to read the code. Overuse of 'auto' makes your own code more readable but other people's code less readable.
&gt; terseness is often shunned by the committee. Indeed, but there is hope! Remember that C++17 finally has `namespace foo::bar {}`. I'm also fairly happy with how terse C++ lambdas came out. If the design methodology for `template` were used when designing lambdas, our lambdas might have come out something like this: lambda&lt;by_reference local_val, by_value some_value&gt; int (const std::string&amp; str) { return do_algorithm(local_val, some_value, str); }
std::bind also adds type erasure, so it's hella penalyzing perfomance
But this syntax reads to me, not that i6 has a value of 42, but rather that i6 is an array of ints using an implicit cast from int [1] to int with a single element with a value of 42, and that’s just gross. Even if it is valid, and while the compiler may not read it like I just did, I see no benefits in defining a single value in this fashion.
Without -march=native, the results are stuck on sse1/2
There is a repository (https://github.com/nlohmann/std_json), but I do not work on this. You should ask Mario (https://github.com/nlohmann/std_json/commits?author=mariokonrad) on the state.
The "fat arrow" syntax without the lambda introduction `[]` requires quite a bit of lookahead. I also prefer using the `[&lt;expr&gt;]` to really emphasis where the returned "expression" begins and ends, and to distinguish it from a regular lambda body with `{}`. For example, this: std::algorithm(items, [](k) =&gt; k, v); is technically ambiguous because of the horrors of the comma operator. Being able to delineate the start and end of the expression is helpful to both the human eye and compiler author.
`std::bind` does not necessarily erase the type. The return type of `std::bind` is "implementation defined." What it _does_ do is generate egregious error messages and balloon compile times.
I think that statically typed build system to be too much. Maybe a linter on top is a better idea but I did not think how that would be accomplished. &amp;#x200B; CMake uses strings basically (now targets in Modern CMake). Meson is strongly typed but dynamic. I am more familiar with C++ so basically this is what I use.
&gt; When I read other people's code that I'm not familiar with and which use type inference everywhere I find myself having to constantly query the type in my editor/IDE That just seems like a complaint about either poor tooling in the C++ ecosystem, or your choice to use poor tooling if good tooling exists. I can only speak to other languages, but certain editors like IntelliJ Rust will add phantoms in the code that contain type annotations, [looking like this.](https://i.redd.it/1er3hcxevvmz.png) The `elem` and `vec` bindings were not written with explicit types, but IntelliJ Rust is automatically inserting phantoms (which look like code, but they're not actually part of the code) to show you the types. We shouldn't make programmers do a tool's job. If *more typing* is the answer, then why let the compiler do anything at all? In fact, using functions or classes seems to obfuscate code in your world view. When you call a function, how do _really_ know what it's going to do? When you have two objects and you add them, how do you know what that operator is _really_ doing? Just knowing the types doesn't help you unless you're already familiar with those types.
&gt; The return type matters a lot Does it actually? What matters is the *contract*, and that’s evident from its subsequent usage. The actual type in this case almost certainly doesn’t matter — after all, this is the fundamental insight behind [“program to an interface, not to an implementation”](https://softwareengineering.stackexchange.com/q/232359/2366) that’s been best practice for decades. Same with templates: we emphatically *don’t care* what the precise type is, all we care about are its capabilities (and sometimes it makes sense to hint at them, hence the various proposals for concepts).
Is there a reason (syntactic ambiguity?) to require braces around the expression lambda? That is, instead of [][&amp;1 + &amp;2] can we get away with [] &amp;1 + &amp;2 ? Granted, in this example I’d be tempted to use parentheses around the expression anyway, to make precedence clear. But for a simple function call, I’d rather not write redundant braces: [] do_work(~&gt;&amp;...)
&gt;class&lt;T, U, int N&gt; some\_class {}; YES!
[Yes](https://gcc.godbolt.org/z/ZzzU5e). `std::invoke` also works with data members. This is why we'll be able to use `sort(people, {}, &amp;Person::name)`, using the projection argument. (Given the ugly default comparator, you could also make `sort(people, by(&amp;Person::name))` work under the same principle. In the spirit of the article, I've had the pleasure of `people.sortBy {it.name}` and now it's hard going back.)
&gt; class&lt;T, U, int N&gt; some_class {}; &gt; Whoa… that’s not C++! &gt; Sure, but it could be, if someone were convinced enough that it warranted a proposal, but I doubt it will happen any time soon. IIRC the original syntax proposed for templates by Bjarne looked like this but some people on the committee were apparently afraid that it would not look "different enough" from real functions and thus introduced `template&lt;...&gt;`. 
&gt; That just seems like a complaint about either poor tooling in the C++ ecosystem, or your choice to use poor tooling if good tooling exists. Yes maybe. I occasionally try Visual Studio but it's never good enough and a massive chore to use so I end up back in Vim + cquery/clangd/YouCompleteMe which at least is robust and fast and allows me to query types easily. &gt; I can only speak to other languages, but certain editors like IntelliJ Rust will add phantoms in the code that contain type annotations, looking like this. The elem and vec bindings were not written with explicit types, but IntelliJ Rust is automatically inserting phantoms (which look like code, but they're not actually part of the code) to show you the types. This looks pretty sweet. I've recently started writing Rust and I find myself constantly querying the type using RLS in Vim, having them inserted like in your screenshot would make things easier. &gt; We shouldn't make programmers do a tool's job. Some people will prefer more annotations, some people will prefer fewer. If you explicitly write types into the code, you're making that decision for everyone. If you let the tool add the annotations, each reader can have as many or as few annotations as they want to see. This sounds good and all but it's the line-length argument all over again. It sounds good on paper but fails when reality kicks in. Maybe in the future when tooling is better, but today limiting the environment where you can read the code to a select few IDE's which suit only a minority of developers sounds like a poor choice. &gt; If more typing is the answer, then why let the compiler do anything at all? It's not about typing, it's about encoding the relevant information in your code. Usually I tend to prefer terse code over verbose Java-esque code. &gt; When you call a function, how do really know what it's going to do? Yes absolutely that can be a problem. But if you know the types involved it's a lot simpler to deduce at a glance what the function does.
That's a strange way to read it – braces do not imply an array, in C or C++. If anything, it looks like simple, everyday aggregate initialization.
Not sure where the negative vote stuff comes from. I typically only downvote things which are grossly inappropriate or factually incorrect.
Wait, `std::cout` is slower than `printf()`? I thought the latter has to format the string before printing?
Is it awkward to prefer a whole opt out?
/u/nlohmann Have you ever considered writing a python wrapper for your json library? What are your thoughts about something like that in general?
Terrifying! That things could be worse is easy to forget ! Thanks for reminding me 😂
What about Number 5: class X { public: int color() const { return color_; } int&amp; color() { return color_; } private: int color_; }; &amp;#x200B;
&gt; Does it really? What matters is the contract, and that’s evident from its subsequent usage. The actual type in this case almost certainly doesn’t matter It absolutely does matter. If you're writing performance-sensitive C++ code you *do* care about the type of that container. You do program to an implementation because *it matters* in the real world. [CppCon 2014: Mike Acton "Data-Oriented Design and C++"](https://www.youtube.com/watch?v=rX0ItVEVjHc) If you want to "program to an interface" then maybe a higher level language is a better fit. 
This would be people getting stuck on the "learning curb," where it's really easy to learn the what the new syntax means, and you never have to worry about it again once you know it.
We can dream.
There are two ways it matters. First, interfaces can't express things like iterator invalidation rules. This doesn't matter for things that resemble std::vector, but it does for maps (think map or unordered_map vs flat_map). It's a courtesy to future readers to indicate what's happening without requiring them to cross-reference a return type. Second, is when you are getting an application-specific type. It unquestionably aids readability since a person reading the code is able to see patterns between variables of the same type, and is able to defer or even avoid looking at the type's declaration in order to trace a part of the code. If you intend to manipulate that type, you'll probably look at the declaration anyway, but this is for situations where you are looking at code surrounding what you're looking on. Code is supposed to be a human-readable. That's why there are so many style guides. Using a shorthand is useful in many cases, but auto everywhere just makes code hard to read. My personal guidelines are: - Always use auto for loop iterators. The usage makes it obvious, typing out template names is annoying, and excessive use of typedefs is annoying. - For ranged-for loop variables, you usually want to specify the concrete type. - Always use auto to avoid redundant mention of a specific type (e.g. for a cast). - More auto is usually good in templates so you can widen the contract and avoid implicit conversions. - If the function whose result you're initializing is declared nearby (in the same source file, at least), then maybe auto is ok. - If the type is a gigantic monster of angle brackets, auto is ok. But also consider a `using` alias. - Otherwise, just specify the type. It's not that onerous, future readers will appreciate it, and having a bunch of code break at initialization sites when you change a return type is a positive thing IMO.
&gt; C++17 :O Imma use that in my pet projects now. Thanks!
When I see 'coding' 'coding conventions' and getters and setters, it screams inexperience and putting too much emphasis on things that don't matter. Java is academic poison. Almost everything about Java is the polar opposite of what someone should shoot for when architecting software.
Oh right, the comma operator &gt;_&lt; I got no beef with the lambda introduction, and being able to omit braces around the expression in C# isn't a huge deal to me. I'm guessing they did that to clear up their own syntax ambiguities. Does this: std::algorithm(items, [](k)[k, v] ); have any issues?
&gt; you can't use binary `operator+` on a closure object, You can: define a free `operator+` between an arbitrary type and your own type. Similar to Andrei Alexandrescu's SCOPE_EXIT: struct my_type {}; template &lt;typename L&gt; auto operator+(L const&amp; lambda, my_type const&amp;) { do_something_with_lambda(lambda); } 
`public` data members are not an anti-pattern. There are only so many features that can be added to a getter and setter, without breaking contracts that the caller expects. I think `paint` sounds like it has an immediate effect on the program's output, which `set_color` does not. Unless `X` implements live objects in a library interface, just expose the data and refactor later if needed. Otherwise, #3 offers a getter which looks like the data, and a setter which can be most easily deprecated when the class outgrows its trivial specification.
It's _possible_ that it will work, but requires some lookahead. The prefix: `[](k, v, i)` is ambiguous until you see either `[` or `{` as the following token. If you find `[`, it is the name of three `auto&amp;&amp;` parameters. If it is `{`, it is three unnamed parameters to a lambda, with parameter types `k`, `v`, and `i`.
Oh that’s terrific, thank you for the reply! A shame that clicking `to_msgpack()` only shows the vector overload though.
I generally prefer a fluent variant of option 1 ``` class X { public: int color() { return color_; } X&amp; color(int c) { color_ = c; return *this; } private: int color_; }; ``` I tend to really prefer data accessor methods to exposed data members because I find I semifrequently incorporate adaptors to classes defined in external packages. (Unlike in Python) API's that expose direct member access are difficult implement in terms of multiple third party implementations. 
The range algorithms use `std::invoke` for all callables
Hrm. Aight, final attempt before I give up and accept shelly numeric arguments: std::algorithm(items, [](&amp;k, &amp;v, &amp;i)[i, k, v] );
GetColor() / SetColor(). Because I don't like snake case. 
I guess it works? I can't immediately think of why this wouldn't, but I feel like it might be a stretch. Maybe just permit this: std::algorithm(items, [](auto&amp;&amp; k, auto&amp;&amp; v, auto&amp;&amp; i)[i, k, v]); But I think its coming full-circle now.
I generally prefer my methods to be named as verbs, so I tend to use the Get/Set naming convention when I need getters and setters. When it makes sense I just use public data members, but getters and setters can be useful for enforcing constraints or running other actions when the member changes.
&gt; auto foo = frombulate(); Don't think I've chuckled at a piece of code like this in a while lol
See also [Stroustrup's Rule](https://thefeedbackloop.xyz/stroustrups-rule-and-layering-over-time/): * For new features, people insist on LOUD explicit syntax. * For established features, people want terse notation. 
 template &lt;typename T, typename sudo , int N&gt; class some_class { x/k Q££££template &lt;typename T, typename U, int N&gt; class some_class {}; Pretty straightforward, right? Now consider this: class&lt;TI J G M U !template &lt;typename T, typename U, int N&gt; class some_class {}; Pretty straightforward, right? Now consider this: &gt;class&lt;T, U, int N&gt; some\_class {ZSH}; &amp;#x200B;
Well sure, but if you find your performance bottlenecks by scrolling through code looking at stack variable types, consider you may be doing it wrong. I feel auto lets the names appear with less noise, allowing you to grok the code and zero in on the code you'd like to modify. At that point, the type information is at your fingertips if you use the right tooling. &amp;#x200B;
thank god
Can't read the snippets on mobile. They don't wrap at all...
Well, that depends on your compiler (and somewhat on the OS).
Both have to do some formatting. Look at iostreams.cpp, then run it for yourself.
Avoid using the prefix **get** that is often too generic. Any computed property that is **not** accessed in **O(1)** time, should get a hint prefix as a verb. 
I can prevent bad code from even entering the code-base if I can *actually* understand it at code-review time. It's not only about performance, it's also about finding bugs before they even exist. That `.name()` function they used in the sort could actually be returning a `char const*` and now you're sorting by addresses not a by the actual strings. I can immediately identify that bug in a code-review if I have all the context. More `auto` == less context. 
It's funny how it is a complaint about foo/bar being too simplifying, but uses trivial tutorial examples like "person". Until I see someone writing auto row_major_float_jacobian_3x3_map = jacobian(); I must insist that auto hides important details your trivial example doesn't cover. And no, "use a better IDE" is also no argument if you often look at diffs on your phone. Can't we just acknowledge that we are a diverse community that doesn't insist on avoiding auto just to make your life harder?
I think what you're missing is something that isn't made explicit in the article: In real-world code that uses the OOP technique, each Sprite object will likely have a separate allocation, or involve virtual function calls on each loop iteration. On top of this, you might have other similar loops operating on different classes. This can lead to hard-to-follow branching code paths that have non-obvious performance and are difficult to debug. The data-driven approach puts the vector of data and the loop as the primary focus, making the logic and performance readily accessible and more localized. If the program needs to use polymorphism, that is usually done at a higher level than the system that holds the data. The fact that it's a struct isn't really relevant, it's just that when you tear all the logic out of your class and put it into a higher-level system, you're just left with data, so might as well make it a POD struct.
N.b. `high_resolution_clock` is only acceptable if `high_resolution_clock::is_steady == true`; otherwise you should use `steady_clock`, even if there is loss of precision, IMO.
This speaks volumes. The degree to which backward compatibility mandates clouds imagination poisons the industry.
[https://www.reddit.com/comments/9ss2az/new\_crucial\_p1\_ssd\_fast\_capacity\_for\_less/?instanceId=t3\_q%3DCgADBwgHYqFQ2vsKAAUenYcVeABN6AgABwAAAAEKAAwHCBWbXBsSsQA%3D%26s%3D95Rz2AadXw5c0vTPs-Zxs9qHub4-V8rE4Kvx9v-uodM%3D](https://www.reddit.com/comments/9ss2az/new_crucial_p1_ssd_fast_capacity_for_less/?instanceId=t3_q%3DCgADBwgHYqFQ2vsKAAUenYcVeABN6AgABwAAAAEKAAwHCBWbXBsSsQA%3D%26s%3D95Rz2AadXw5c0vTPs-Zxs9qHub4-V8rE4Kvx9v-uodM%3D)
I'd use it, but you're right in that it does sort of feel redundant at that point 🤷
a linter seems like the obvious answer
I've noticed this, but I can't seem to make it work no matter how much I poke at the CSS. Uggh...
when does the lambda end
Fair enough. As someone who maintains a C++/Python project that heavily uses json, I'm not too happy about the python's standard json library performance. There are alternatives, written in C that are fast, but are not maintained (I might have missed something). Either way, I might give writing python bindings for your library a try.
Huh?!? Do you really think calling std::cout for, say, int won't do formatting? &amp;#x200B; &amp;#x200B;
Oh god why.
In all honesty, can someone explain this to me? I can imagine useful things like compiling shaders or regular expressions at compile time, but why is it such a popular thing to do right now?
RTX ON
I'll quote the answer I gave on Hacker News when this unexpectedly popped up there yesterday :) --- It actually started out as a learning exercise -- I didn't (and still don't) know much about ray tracing, and so I thought it would be good to study a simple example by translating it from a language I didn't know (TypeScript) to one I was more familiar with. This involved writing a simple vec3 class, and it seemed natural to make that constexpr. Then as I went through I realised that many more functions could be made constexpr too. And then if I hacked together some (admittedly very poor) replacement maths functions, even more of it could be constexpr... At this point, it became a challenge to see whether I could make the whole thing run at compile-time. The only tricky part was avoiding virtual functions -- I'd originally naturally translated TypeScript "interface"s into C++ abstract classes. I ended up using two different approaches: firstly using std::variant and std::visit (the any_thing class in the source code), and secondly using a struct of function pointers (for the surfaces) -- because while virtual calls aren't allowed in constexpr code, calls via a function pointer are just fine. In the end, I was pretty satisfied that I'd managed to push constexpr as far as I could take it. I had intended to blog about it, but never got round to it ... and now 18 months later someone has saved me the job by posting it to HN anyway :)
For the sweet sweet upvotes.
See [https://gitlab.com/chriscox/CppPerformanceBenchmarks/wikis/iostreamsAnalysis](https://gitlab.com/chriscox/CppPerformanceBenchmarks/wikis/iostreamsAnalysis) &amp;#x200B; Ubuntu shows the best results (as long as you don't use posix IO routines), MacOS ok but has problems, and Windows.... has a lot of problems to fix.
what's a good reason to have such a cheap coroutine?
Why not? 
&gt; but why is it such a popular thing to do right now Science! For most people it seems to be curiosity. There's a (relatively) new toy to play with in `constexpr` (at least it makes it easier than template meta-programming), and others have done some cool things, so how far can we take it? Imo it's great; the more heads we have tackling its limits, the more battle-worn and theory tested it becomes for late adopters. It will also help compiler writers address problems with C++17 features (like in the OP github here, they mention how GCC wrecks your RAM)
I see the point but this could be disambiguated with sensible operator precedence rules. To wit, I feel that most infix operators should have higher precedence than expression lambdas. The comma operator probably (almost certainly?) should have lower precedence. Same for assignment (otherwise `auto x = [] 1 + 2` would be (auto x = [] 1) + 2`). But, yeah, probably more confusion than it’s worth.
&gt; If you want to "program to an interface" then maybe a higher level language is a better fit. We’re talking about free abstractions here; your argument is a red herring. For what it’s worth, I am working in a high performance codebase. If the exact type in context matters for performance, then use it in code. “Almost always `auto`” isn’t some absolutist edict, it’s about common sense. Again, I’ve found that the exact type matters a lot less than people assume up front.
First off, I'll paraphrase Alexander Stepanov: &gt; If your members have trivial getters and setters, just don't have getters and setters in the first place.
##### [Tom Thistlethwaite](https://www.facebook.com/tom.thistlethwaite.is.me.c6?__tn__=%2CdC-R-R&amp;eid=ARCQWFyTuvO1H_W5dWN9tH4z1dn8KQfT3S6_ohDdWB_tGZ-jjGu7q6b8wzozuvBEa71EGZkJdWP9B9vQ&amp;hc_ref=ARSjOMwC36fKk5luaqVFlRw6H5j1uSkpAZ4R26YfMnOwCRZiLNnEvbtyDUDJk4035uk&amp;fref=nf) [Julio 25](https://www.facebook.com/tom.thistlethwaite.is.me.c6/posts/365856073947387) · as a generalization of personalities, females lie more about smaller details than male archetypes. {\\displaystyle a\^{n}+b\^{n}=c\^{n}} {\\displaystyle a\^{n}+b\^{n}=c\^{n}} if n is an integer greater than two (n &gt; 2). Previous partial solutions for specific integer exponents Between its publication and Andrew Wiles' eventual solution over 350 years later, many mathematicians and amateurs attempted to prove this statement, either for all values of n &gt; 2, or for specific cases. Proofs were found for values of n up to around 4 million, first by hand, and later by computer. But no general proof was found, nor even a hint how such a proof could be undertaken. The Taniyama–Shimura–Weil conjecture
In the limit T0 → 0 this expression diverges, again contradicting the third law of...§§1§3§321§USODODODSAOAIDIODSIODASOIOImit T0 → 0 thisexpression diverges, again contradicting the third law of thermodynamics.q point qed n- adic S ( T , V ) = S ( T 0 , V ) + 3 2 R ln ⁡ T T 0 . {\\displaystyle S(T,V)=S(T\_{0},V)+{\\frac {3}{2}}R\\ln {\\frac {T}{T\_{0}}}.} S(T,V) = S(T\_0,V) + \\frac{3}{2}R \\ln \\frac{T}{T\_0}. (13)
I guess it feels a bit like they're critiquing a narrow strawman of OOP (i.e. inheritance- and polymorphism-heavy, 'enterprisey' code from the 90s, with not much thought given to performance), rather than what's more broadly implied by the term. It doesn't seem to me like DOD and OOP are mutually exclusive. You can be conscious of how your data is laid out and also use encapsulation and high level interfaces etc.
Should the phone screen really be considered as a target media for which C++ readability should be optimized? I'm also not sure how will longer type names improve code, since the best you can do is move part of the name to the type leaving it just as long: math::3by3_map&lt;float&gt; row_major_jacobian = jacobian(); these are also words which are only necessary because your example has an undefined scope, and no context. in a reasonable piece of code, this line would appear in a block of code where you have enough context to infer much of the properties, allowing a more succinct name, as well as being short enough so that you can refer to the creation context (if tooltips etc are unavailable) &amp;#x200B;
Getters and setters of raw properties are an anti-pattern for things that are not pod. The names of the functions themselves should have semantic meaning (and whether this is a simple set or get under the hood is an implementation detail). This is exhibited for example, when invoking `std::vector::size` to get the size of the vector or `std::vector::resize` to resize it (which in this case performs other necessary side effects). As far as the user is concerned, we do not know what the implementation of `size` is (could be a member variable read, could be a pointer subtraction, etc). Nor should it matter. This is the distinction between "interface" and "implementation". Raw member variable access, in my opinion, should be restricted to POD.
I agree that the article doesn't do a good job of setting up a good example of exactly when DOD would be better than OOP. It's difficult to explain the benefits with a simple example, because DOD usually helps more with the overall structure and design of the program, rather than isolated code chunks. It's not entirely about performance. It might seem like DOD is just another word for "cache-friendly OOP," but speaking from experience working with game engines (both OOP and DOD styles), it feels completely different. For games, DOD is usually the only style that makes sense. OOP style game engines tend to be much more rigid and difficult to work in.
Very nice work! Have you considered a client library as well?
Would SQLite FTS be an option?
bind doesn't perform type erasure.
2062: The schism of the century. A few million Armsmen broke away from The Standard and its economies to develop and maintain *Neo Standard*, a variant that supports `__restrict`. Despite being twenty Earth-standard years behind The Standard tech, inscriptions written in *Neo Standard* yield performance that's on par with The Standard counterparts. `__restrict` has been ruthlessly taken advantage of to maximum efficiency. It has taken the Neo Standard men only thirty standard years to rewrite and annotate *everything* that might warrant `__restrict`. This was only possible via the heavy use of focus drugs; with the first of such drugs emerging, in desperation, from within the domain of the Neo Standard men. Without such cognitive enhancers, it would have taken no less than a hundred standard years for the great rewrite. Perhaps the development of highly potent and reliable cognitive enhancers is inevitable. However, its development may never have accelerated to such an extent without the increasing competition between the two set of economies born out of the schism.
Just make the field public. I've actually never seen useful, i.e. non-trivial getters/setters in realworld code. And if you do need to change it later that's what tools should do for us: https://developercommunity.visualstudio.com/idea/351366/refactoring-c-automatically-generate-getter-and-se.html
1. Yes it should. Or in other words, IDEs should not be assumed. You might think otherwise, but then I might just ignore your PR due to practicability reasons. 2. Moving the name to the type is the whole point, since no one writes the name. 3. How does the matrix order have anything to do with the scope? The order might be important at a significantly different scope than the assignment. "Block of code" is a way to narrow context and frankly naive. Honestly, look through e.g. the codebase of eigen or pcl, substitute any similar type definition by auto and *then* try to understand what is happening...
Can C++17 &lt;charconv&gt; be used to improve the performance of reading and writing floating-point numbers?
I also like the idea that you could use concepts instead of auto, but it seems that it won't make it in C++20. It'd be awesome to write `RandomIterator it=foo.begin()`, since it will fail to compile if it's not the kind of iterator you want, and you didn't have to use the full name either.
Yay! A lambda operator. I hope we can overload it too.
Unlike the others that made no checks at all either?
What _is_ number 2? Is it "find a different, but similar name, and use that for `set`, and hope users understand"? Is it "find a verb"? Like everyone else is saying, if there really is no code inside the set/get functions (ie no checking of input, etc), just make them public. If your get/set functions actually maintain invariants or something, I'd go with `colour()` and `set_colour()`. (Spelled the proper Canadian/British way.) If your get function does "work" name it something, like `findX` or whatever it is doing. ie get functions should be O(1) complexity. Anything worse needs a different name. 
It has a certain elegance, but now if you have a blinking light it leaves behind a trail of light objects to be destructed.
1.30 AM on Halloween day. I write a code snippet, but something feels... Wrong. I stare. I stare. I doze off. I stare some more. Something is wrong, but I can't figure it out. Something... Nope! It's perfect! *Posts to the internet*
&gt;The template syntax, despite being an expert-friendly feature, uses a beginner-friendly syntax. Very well put. &gt;\[\]\[&amp;1.name() &lt; &amp;2.name()\] I think I would prefer `$1.name` over this syntax: ampersands are already used in many places and using the same symbol with different meanings doesn't help readability. It is also not completely obvious why numbering should start with 1 instead of 0. I find Groovy to have the best closure syntax and they use implicit `it` as first argument. &amp;#x200B;
Not being part of C++ isn't enough?
Potentially Large Arrays in runtime stack ,which is stored little space, can be dangerous.
use a vector?
What, just because they are antithetical to C++ design goals? They have runtime performance problems that can be quite severe, they are not portable, and they open security holes in your application. There are other things, like they're C and not C++, even in the C world they are considered a mistake. Frankly, I can't see trading all that for minor convenience gains. 
They're allocated on the stack, not the heap. You can always create an array of variable length on the heap using new. (You should really use std::vector, but I appreciate that a beginners' C++ class might not allow them, at least at first.)
Right, but with the disadvantage that you can't easily put a breakpoint on the code that mutates this variable.
What do you mean? They're part of C++. When i run Code::Blocks however, it works but when I activate the warnings my professor told me to turn on it says that ISO Forbids this to happen.
The language standard says that they aren't allowed. Your specific compiler adds that as a language extension by default, but it's not guaranteed to work with another good compiler.
Thanks - I wrote a lot of this before Windows 10 was around. Hmm, is there a simple API that will avoid the bogus answers?
&gt;ISO Forbids this to happen ISO in this case is the International Standards Organization, which is the overarching organization that oversees C++ (among a great many other standards). They literally define what C++ is. If they say your code isn't legal C++ then your code isn't legal C++ and that's that. C++ is ultimately just a text document published by ISO. That's it. You will not find VLAs anywhere in any published version of that document. We talk about "C++ implementations" which are, roughly, compilers and their accompanying standard libraries which _attempt_ to implement the full set of rules and requirements laid out in that document. These implementations tend to support non-standard C++ constructs (like VLAs); sometimes because of bugs but often as intentional "value adds" for end-users (e.g., allowing C99 constructs like VLAs in permissive C++ mode). At least one of the three major implementations does not support VLAs _at all_ in C++, no matter what flags or options you use. Testing your code in multiple implementations - and using any flags or options to enable the strictest standards compliance modes and warnings - is a very useful approach to ensure that you're writing real C++ and not some non-standard C++-like aberration that just so happens to work with a particular compiler. TL;DR: just because your code "works" doesn't mean that you're actually writing real legal C++ as defined by the appropriate authoritative standards body. PS: so far as _why_ C++ doesn't support VLAs, it's mostly just because C++ was "forked" from C89 and VLAs weren't even added to C until C99. While C++ is rooted in C, it is not a pure extension thereof, and C++ does not "rebase" itself onto newer C standards. There have been many proposals over the years to import VLAs into the C++ standard but these have all been rejected for a variety of reasons; one of the biggest is that we already have `std::vector` and it does everything a VLA does and more (albeit via heap allocation instead of the stack).
I would use none of those. I'd either make class color that I'd use with simple operator overloads, or more often just make that int a public member, especially since neither the getter or setter are doing anything of value.
Not that I know of. Some people use the version information from kernel32.dll, but that's more work and more dubious than just turning off the shim with a manifest. Since you're building from command line instead of an MSVC project, the quickest way is to put this into a manifest file (declares 8.1 and 10 compatibility): &lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt; &lt;assembly xmlns="urn:schemas-microsoft-com:asm.v1" manifestVersion="1.0"&gt; &lt;compatibility xmlns="urn:schemas-microsoft-com:compatibility.v1"&gt; &lt;application&gt; &lt;supportedOS Id="{1f676c76-80e1-4239-95bb-83d0f6d0da78}"/&gt; &lt;supportedOS Id="{8e0f7a12-bfb3-4fe8-b9a5-48fd50a15a9a}"/&gt; &lt;/application&gt; &lt;/compatibility&gt; &lt;/assembly&gt; ...and then link with `/manifest:embed /manifestinput:compat.manifest`. With this change, GetVersionEx() returns 10.0.17134 or similar instead of 6.2.9200. 
Now someone please make a compile time raytracing game with 1/12000 frames per second xD
In case you don't know them: Data breakpoints might help to some degree (not quite the same)
Why? He said nothing about UpperCamelCase... 
As far as I know, compilers never deallocate memory, hence the extreme memory usage. This and number of steps are going to be the most limiting factor for the `constexpr`\-based code.
Local variables are stored in the stack along with any passed in variables. The stack space is quite small and it's better to stay small so it can remain the cache and not have cache misses when using said variables.
Yeah, I've been reading up on the problems. Apparently the file version info is also shimmed now and reports old versions. Ditto for the verify version function and version "helper" functions. The problem with a manifest: it won't support new OS versions until you know the GUID and add it for each new OS version. Super lame. You'd think someone at Microsoft would at least research the problems before hamfisting their way through all the version APIs (ie: there should always be an API that correctly reports the version for documentation purposes). 
hmmm. I didn't even think to specifically test endl -- I assumed it just outputted a literal '\\n' (or "\\r\\n" for strange OSes ;-) ).
Yeah, cool, now we need GPU accelerated compilers!
i know its not apparent from the code, but from what I have seen reading frm the file takes very very less time compared to loading time of the widget 
Pedagogically speaking I do not see the issue with this. To me this exposes the guts of vectors, and by manually doing things it allows students to develop a feeling as to why it's a bad idea to push_back everything, what resizing and copying implies and so on. Well, I'm a physicist and physics is taught that way so there is that. You start with Newton's equation, not with Hamiltonians.
Aere you sure? As they are going through the same cache system, I'm surprised that it should make a difference if the data is on the stack or on the heap. On the contrary: It is usually beneficial, if you have all your data close together. 
Having recently been taught C++ this way and now having a job working on a fairly large code base, I’m glad I was introduced to the standard library gradually. I’m sure this is true in most professional settings: the code you’ll be working on is a mix of old C with classes-style code that “just works” so no one wants to update it at the risk of breaking it, and newer code that uses modern features. When familiarising myself with a codebase like this, I’m glad I know what this old code does, why it’s written the way it is, and why we no longer write code like this. This also means that if I need to fix/update something in the older parts of the codebase, I can spend more time fixing issues instead of scratching my head, which gives me some extra time to modernise the code while I’m in there. 
I see you're enjoying CSS, but might I suggest a second lovely poison: JavaScript &amp;#x200B; ⋋| ՞ ‸ ՞ |⋌ &amp;#x200B; Since your blog is so code-focussed you might spring for one of the more serious "embedded code editor" js libraries (e.g. [Ace](https://ace.c9.io/)). You could apply a "no edit mode" or perhaps let people play around along with a "reset" button. More aspirational, it would set you up for interactive examples-you'd just need [an interpreter](https://github.com/felixhao28/JSCPP)!
I'm not against teaching new and delete or how to implement vector / sort and whatnot yourself . On the contrary you need to know those things (at least the principles) to be a good c++ programmer, but the order and the priorities are wrong. See one of Kate's "Stop teaching c" talks, she explains very nicely what I'm talking about. Btw.: some of the code bases you are working on might not need fixing if the first thing every c++ programmer learned wasn't how to implement a linked list from scratch. Again, not saying, you shouldn't know how to do it, but I want students to first learn when and how to use one in your program (and in particular, when not to use one), before spending time to implement one that might or might not outmatch `std::list` or `my_companies_utiliy_lib::list`. I've seen too many c++ programmers focusing on some minor implementation detail of their code instead of recognizing the higher level design issues. Sometimes you can replace whole sections of your code if you take a step back and think about what your code is doing instead of how it is doing it, but that kind of thinking is a problem for students who have spend most of their education on a level of abstraction between pure c and std::vector. Another talk will work seeing in this context is c++ seasoning by sean parent. 
Is there another meta-programming language that is as flexible and comprehensive as C++? I know template syntax is as ugly as hell, and the error messages are currently horrendous, but the stuff you can do with can be utterly amazing. Rust for instance, does not currently have an equivalent to integer template parameters, which are vital for a lot of uses. Go doesn’t have generics, Java does but I only see people complain about them (in a different and worse way to C++), I’m not sure Python’s duck-typing counts, and that’s about the extent of my knowledge.
There is nothing wrong with explaining students how a vector works internally but you shouldn't start with that low level stuff. Also, your analogy actually shows the opposite of what you are saying: Solving a problem using std::vector is the equivalent of using Newton's equations. It is simple and most of the time good enough, which is why you learn it first. Later you learn that there are more advanced/fundamental/general techniques (like Einstein's general relativity theorem) that you need to use in certain circumstances. You've also probably not been teached assembler before your first highest level programming language (depending on your age of course). I'd highly recommend watching kate gregory's talk stop teaching C
Both are bad. https://arvid.io/2018/06/30/on-cxx-random-number-generator-quality/ https://arvid.io/2018/07/02/better-cxx-prng/
Use `std::vector`
Only in theory. https://arvid.io/2018/06/30/on-cxx-random-number-generator-quality/ https://arvid.io/2018/07/02/better-cxx-prng/
`sort(people).by([]x=&gt;x.name())`
How do you mean? As in the `X&amp;` return value on the setter? As a reference, no destructor is called when it goes out of scope. Consider the following: ```c++ #include &lt;cstdio&gt; static constexpr int red = 1, blue = 2; class X { public: int color() { return color_; } X&amp; color(int c) { color_ = c; return *this; } ~X(){ std::puts("nontrivial destructor\n"); } private: int color_; }; X foo(){ return X{}.color(red).color(blue).color(red); } ``` In the [Compiler Explorer output](https://godbolt.org/z/NcIBtm), you can see the `X` destructor is called only once in the definition of `foo`.
Who downvotes an opinion presented as opinion?
I agree to this. I think it's much better to teach how to solve real problems using the tools at hand first, and then open the lid and show how those "magical" tools actually work afterwards.
The difference is in the way you access data on the stack vs data on the heap.
&gt; it does everything a VLA does and more (albeit via heap allocation instead of the stack). Is that not a big deal? I guess `std::vector` with a stack allocator serves the same purpose?
For the record, I didn't say I agree to what I wrote. I simply explained the other point of view on teaching C++. There are compelling arguments in favor of "opening the lid" later, but as someone who has been taught C in college and learned C++ on my own time, despite the struggle I had with constantly thinking "too low level", I'm not sure the "open the lid later" approach is that beneficial. Reason for that is that I know how many people have no clue how things work, despite being taught, but because they were taught later. They had studied for the exam and then threw that knowledge away. &amp;nbsp; I might be totally wrong, but I'm glad I learned C first.
&gt; I can only speak to other languages, but certain editors like IntelliJ Rust will add phantoms in the code that contain type annotations. I don't think you want this in C++ as templates types can be very long. In a good IDE like VS you can get the variable type by hovering over variable name which I find sufficient. However, this post is about lambdas (not variables) and in this case his point about autocompletion holds (at least to some degree), i.e., consider`[](auto person) {person.metho... }.`
And I am working with way too many people with the opposite problem - despite having access to C++11 and boost, way too many poeple seem terrified of modern C++ and instead write horrible low-level C code for no reason at all. If they had learned to write C++ first, and then later learned what was actually going on under the hood, I'm sure their code would be 10 times better. Also, I'm sure less people would find learning C++ as intimidating if they learn to use std::string for text and std::vector for collections of things first, instead of pointers and heap allocations.
It also flushes the stream. https://en.cppreference.com/w/cpp/io/manip/endl
Can you give a run down of how it works so people don't have to look through the guthub link to figure out if it is nonsense?
Shake is written in Haskell, reggae can be written in D. I'm not sure I'd recommend either, and I wrote reggae but I prefer to use it with Python.
&gt; albeit via heap allocation instead of the stack Which is a pretty important difference.
Thanks, I'll add that.
Yes, if there are functions called ut_xxx. This can be mitigated by using an even more obscure naming convention in the implementation, but I doubt it's going to be common to find ut_xxx functions in the wild.
Isn't it technically legal for an implementation to allocate large VLAs outside of the stack?
Oh, now I get it. I normally associate "return *this" with making a copy, but you're passing a reference to "*this". I thought you were making permanently coloured objects, but you're indeed changing the colour/state on just one X and then returning a reference to it. This was entirely my misunderstanding. Good solution! I'll have to remember that idiom.
The actual article then goes on after it's nonsense title and states that modules won't magically give better tooling. It also lists the number one benefit as 'feels more modern'
How many times do people have to repeat: Modules are not *modules*, they are mergeable precompiled headers. The current Modules proposal really should be called **Precompileds** (I have asked for this name change, and I was told no) People *are* on what to do next after we get Precompileds. Indeed, one of the WG21 papers I am currently writing has this lovely paragraph in its Introduction: &gt; Indeed, it is hoped that future C++ program binaries could be no more than just a few kilobytes long, consisting purely of a manifest of object ids with which to dynamically assemble and optimise a particular running program. Such a program could be LTO-ed on first run for the host hardware, and automatically re-LTO-ed if a dependent Module were updated due to a security fix etc. Missing dependent Modules could also be securely fetched from a central internet database of C++ Modules, thus finally bringing to C++ the same convenience as most other major programming languages have had for some years now. This paper will be numbered P1027 and it will be called *Low level object store*. Expect it for the Cologne meeting, and lots of rounds through std-proposals and probably /r/cpp before that.
IMHO modern C++ is as easy to learn as Python.
What‘s the reason you prefer VLAs over std::vector?
Sure. The main idea is to replace 64-bit pointers with 32-bit or 16-bit integers, which can be mapped back to the pointers. The lib defines Pointer, Allocator classes which do exactly that. Any STL container respecting C++11 pointer\_traits may benefit it. 
&gt; And I am working with way too many people with the opposite problem - despite having access to C++11 and boost, way too many poeple seem terrified of modern C++ and instead write horrible low-level C code for no reason at all. I believe you. I've been one of those who write "horrible low-level C", depending on your definition of horrible - it certainly wasn't pretty and sometimes it wasn't the most efficient either. &gt; If they had learned to write C++ first, and then later learned what was actually going on under the hood, I'm sure their code would be 10 times better. &gt; If they had learned to write C++ first, and then later learned what was actually going on under the hood, I'm sure their code would be 10 times better. They would have been using STL. Their code would have been more efficient. You would have been happier with the end result. Would they still have learned the low level stuff? In the place where I first worked, understanding pointers was absolutely necessary. &gt; Also, I'm sure less people would find learning C++ as intimidating if they learn to use std::string for text and std::vector for collections of things first, instead of pointers and heap allocations. No arguments there.
Coding conventions aren't limited to jobs. They've existed in every single project I've worked on, whether it be C, C++, Java, C#, Python, JavaScript, TypeScript, PHP, you name it. Getters and setters [definitely have their uses](https://stackoverflow.com/questions/1568091/why-use-getters-and-setters-accessors). Have you ever used a mocking library before? If the only one for C++ wasn't broken, I would trade my soul to have it in C++.
You don’t need to know thw wohle language to use it. In fact, people allways use a subset - choose the right one.
I forgot if we will be able to use constexpr function parameters with C++20. If so, won't it be possible to use directly `my_tuple[0]`?
How long will it take to implement such a thing though? At the current rate of progress it will be a couple more years before Modules is in the standard, and if this proposal takes as long as Modules did we probably won't see it until the late 20's.
I'm entirely with you. I've stopped teaching static arrays in my C++ class: I only show students vectors. I first want them to write clean, high level, code that expresses application concepts. They can worry about marginal improvements in efficiency later.
which is frankly fine if you know that you are only going to have ~100 elements
The preprocessor doesn't care what the underlying name means. It will replace functions, variables and class names disregarding any namespaces. 
The preprocessor doesn't care what the underlying name means. It will replace functions, variables and class names disregarding any namespaces. 
I have to disagree. Preconpiled headers don't allow to implement non inline functions in the header and don't allow for private imports, and cannot adjust the linkage of exported/non exported entity and help with ODR. This is I think the three major upsides of modules. 
*Low level object store* is very doable as an `&lt;experimental&gt;` for C++ 23. It's actually quite a simple proposal, and it's not like WG21 can bikeshed on it much as it wraps the proposed industry standard SNIA Object Drive TWG *Key Value Storage API* specification, so basically they can choose to either take it or leave it.
I'm saying all that stuff should be ditched. We keep the mergeability of Precompileds. Otherwise no language or isolation changes as it seems to me we are currently on course to make lots of mistakes in the design of that, as we are rushing it.
In this case, actually pretty easy. The `auto&amp;&amp;` variables can just be hardcoded at the beginning if the lambda
If you mean the compiler to request allocation for the VLA outside the stack then it depends on the compiler and tbh I find it unlikely since it means the compiler is interfering significantly with the code. An 'example' similar to this; is `std::vector&lt;V&gt; vec;` The object itself and any attributes are stored in the stack but the array itself is stored in the heap.
Okay, your point of view is more than reasonable. I personally like working on low level code on fairly tightly constrained systems. That's probably where the "would they still" question came from - I keep thinking that C++ developers should understand hardware enough to know how abstractions they use actually work.
No. You can allocate up to 2\^15 elements for 16-bit mode, size of elements doesn't matter.
Javas generics are not C++ templates. They are syntactic sugar around a class that operates on the equivalent of void pointers (or pointers-to-base), with some automatic casts-to-derived written for you at input and output.
&gt; you're saying that like it's a minor annoyance. If you work on real-time code you most of the time can't use heap allocation at all because there's always the risk of a priority inversion somewhere in the system malloc code Custom allocators and `vector::reserve` are touted as the solution there. We can also write custom containers that lively purely on the stack but - unlike VLAs - can enforce some hygiene around maximum capacity as well as ensure we have the other niceties of standard containers. If that's not enough, you might need to write a paper that really explains with excellent examples why so, because that's the only way you'll convince the committee. :)
It's worth noting that it only depends on Boost.PP, which is one of the few Boost libraries with no other dependencies. It's not too bad to just grab the Boost.PP headers, and at least vcpkg and Conan allow you to only depend on Boost.PP
Thanks, I might actually use this in my project. I love the trick with `not_a_parameter{}`, it took me a while to figure out why the lambda body still compiles when called with fewer than `TL_MAX_PARAMS` arguments.
Nice talk, actual C++ details start in the second half.
&gt; EDIT: There's a paper by Niall Douglas titled "Large Code Base Change Ripple Management in C++" (search for it, I don't have the link). Have you read it? How does it compare? /u/14ned _is_ Niall Douglas. :)
&gt; The introduction is already too broad in scope and opens for bikeshedding Maybe. The object store gets opened with a URI, as per SNIA's specification. The URI can point locally, remotely, anywhere really. &gt; CENTRAL archive? Who's going to maintain that? Standard C++ Foundation. &gt; Who's going to maintain that? Who maintains pypi.org? &gt; EDIT: There's a paper by Niall Douglas titled "Large Code Base Change Ripple Management in C++" (search for it, I don't have the link). Have you read it? How does it compare? I wonder who this "Niall Douglas" is? 
Can't say I recommend using this in actual code. It's a good recipe for writing code readable by only yourself. However, if you wait a couple days, I'll be pushing a repo to github with this, which also solves the noexcept / SFINAE problem
Aww, you ruined it! Anyway, to answer the OP, I'm busy proposing the papers to implement that exact paper above. The proposed Object Store is one of many moving parts. My final, and hardest to write part, is the new memory and object model for C++ to tie the whole thing together. Next year, definitely next year ...
`struct X { int color_; };` see [C.131: Avoid trivial getters and setters](http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rh-get) and [C.2: Use class if the class has an invariant; use struct if the data members can vary independently](http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rc-struct)
TL;DR: Supporting modules in the CMake model (with its project generation step) will be hard therefore modules suck.
&gt; Pedagogically speaking I do not see the issue with this. That's simply an outdated understanding of pedagogy. Generally, and especially in programming, top down learning is objectively, empirically a lot more effective than bottom up learning. Your physics analogy isn't appropriate, since it's not contrasting top down vs bottom up.
Surely the library introduces new overhead, did you benchmark anything, or is it all just about memory-usage?
Is it possible to elaborate on how you would make such a custom allocator (or a link to a github repo perhaps)? Because I'm not convinced it is possible. As far as I know, the only stack allocation you can do in (standard) C++ is where the size is known at compile time. Therefore, the memory footprint of a pure stack container is going to be fixed. This is a real difference to what variable length arrays are.
Is it possible to elaborate on how you would make such a custom allocator (or a link to a github repo perhaps)? Because I'm not convinced it is possible. As far as I know, the only stack allocation you can do in (standard) C++ is where the size is known at compile time. Therefore, the memory footprint of a pure stack container is going to be fixed. This is a real difference to what variable length arrays are.
If you know you need to put breakpoints on it... sure. But making getters/setters for every variable just on the off chance that you'll need to put a breakpoint in it is going to cause a bigger disadvantage of bigger and messier code (which means more chances of bugs), longer compilation, lower (debug) performance... Definitely not worth it.
We use same philosophy when teaching C++ at work. It’s very rarely we get memory related bugs nowdays. Big contrast to my previous workplace.
Like what?
I'm saying that I find everything to do with isolation and "ownership" is being rushed and not fully thought through. I think we are making design mistakes which we will regret. I see exported templates happening all over again here. To be precise about what I specifically want for Precompileds, I'd take all the C++ language changes in http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1103r1.pdf (latest Merged Modules paper) and remove all of it except for "2.3.2 Legacy header units". So the only new thing added to the language is this alone: import "&lt;path to C++ source&gt;"; Everything else in the proposed language changes I'd drop. I'd retain the ability to import arbitrary C++ source, and that's all. Now some may ask what's the difference here to `#include`, and the answer is **intentionally nothing** apart from being able to import multiple Precompileds, and the compiler needs to merge the ASTs (so we are merging ASTs, not appending to the AST). We kick all the compartmentalisation and visibility and reachability and partition stuff off to later standards. Obviously my opinion has exactly one person agreeing with it on WG21, but I have hardened on this opinion ever increasingly as I watch Modules evolve.
Read the post?
You just argued with yourself.
I would say that in practice `std::mt19937` will probably always provide better pseudo-randomness than `rand()` as well, and I don't see how the articles would refute this. There are indeed better PRNGs, but the original question was about `std::mt19937` vs. `rand()`. Also, the statement from the blog that you should not use `std::mt19937` at all is somewhat exaggerated in my opinion, as its randomness should be sufficient for a lot of use cases. Of course, if you need non-predictability or better statistical randomness for more iterations, you should consider other RNGs.
It's interesting to see Titus criticizing CTAD. To me it looks like the possible disadvantages could be similar to disadvantages of auto that is reduced clarity to non-authors (so you will see it's std::vector but you won't know vector of what). But that could be said about using concepts for declaring variables as well. Given that there are already 3 language features behaving similarly I don't see it as a new problem. Am I missing something here?
isnt vector dynamically allocated in the heap though?
I work with option #1. Especially if the interface is important ant consumed by many projects that can't be updated easily if a change is required. (Need to cache something, insert a mocking layer or set/clear dirty flags.) Also, I do use plain old structs if carrying data is the goal or if the class is does not have invariants. For instance, a math Vector type that allows access to x,y,z directly.
I would love the industry to drop all meta build systems on the floor and move on. I have little faith this will happen. But some of the complexity applies to all build system as modern as they are, you wrote more on the subject than I did! The solution I offer in the article is to encode the name of the module interface in the file that declares it. It certainly would not remove all complexity, but it would remove some of it, especially for tools that are not building systems. IDEs, etc. Of course, I have little hope this is something wg21 is interested in (it was discussed and rejected afaik). I believe you are a very few people who actually did implement modules as part of a build system. So my question is, should we not try to reduce the complexity and build times as much as possible?
Maybe xpost to r/emulation and r/emudev
I don't see a problem w/ the fact that they are runtime determinate, just about every other language in the world supports VLA's as a feature, including C++ which is imho, the main reason not to use them. Use a vector instead, it's explicit. As far as security, it opens up another pathway to the same class of bug that has always existed. I don't really get the security argument, seems like the same class of bug that's always existed and isn't any different than all the other bugs you need to avoid, including security issues related to using the heap (double free, use after free, ect.) 
Oh, no, it's definitely not possible to just allocate with run-time sized _capacity_ on the stack. Assuming you preallocate the upper-bound though, you can certainly keep your `vector` completely on the stack. I'd point out that VLAs have an upper-bound capacity too, only it's implementation-defined and hence completely unreliable in portable code. :) There have been proposals to add a VLA-like stack allocator to C++, but the motivations have thus failed to convince the committee.
There are two main problem with supporting module in a build system: discovering the set of module names imported by each translation unit and mapping (resolving) these names to file names. I would say (based on our experience with `build2`) the first is 90% and the second is 10% of complexity. What you are proposing would help with the 10% but that's arguably not the area where we need help the most. The reason the first problem is so complex is because we need to extract this information from C++ source code. Which, to get accurate results, we first have to preprocess. Which kind of leads to the chicken-and-egg problem with legacy headers which already have to be compiled since they affect the preprocessor (via exported macros). Which the merged proposal tried to address with a preamble. Which turns out to be pretty hard to implement. Plus non-module translation units don't have the preamble, so it's of no help there. Which... I think you can see this rabbit hole is pretty deep. One way to address this would be to ask the use to specify the set of module imports in a separate, easy to parse file. That would simplify the implementation tremendously (plus you could specify the module name to file name mapping there). It is also unpalatable for obvious reasons (who want to maintain this information in two different places). So to answer your question, I agree it would be great to reduce the complexity (I don't think build times are an issue), but unfortunately, unless we are willing to sacrifice usability and make the whole thing really clanky, we don't have many options. I think our best bet is to try to actually make modules implementable and buildable (see P1156R0 and P1180r0 for some issues).
Well, I happen to disagree (I've some experience with teaching c++ to electrical engineers), but that probably comes with the domain. In any case, I was talking about c++ beginners in general, which may or may not be novices to programming. 
I read that remember FORTRAN paper and I wonder how other languages handle these cases?
`calculate_perimeter()` rather than `get_perimeter()`
They just bite the bullet and do it. Look at Rust and its crate/module system as an example -- you still specify the submodules your crate contains in Rust source files which means a build system has to extract this information (for example, to know when to re-compile the crate). Of course, they don't have to deal a preprocessor which I bet helps a lot.
Mapping is 100% of the complexity for other tools. I agree that extracting imports from files seem Ridiculously complex, but most of that complexity comes from legacy thing. A clean design (macro less, legacy less, just import and export), would be much simpler. I don't think we would lose much ``` export module foo.windows; #ifdef WINDOWS export bar(); #endif ``` is morally equivalent to ``` #ifdef WINDOWS import foo.windows; #endif ``` Yet simpler and cleaner. I don't have hope to convince anyone that we should try a clean design before considering legacy modules and macros in preamble. It makes me sad. I will also agree with you that any solution based on an external file would be terrible. My assesement (and I haven't really try to implement modules besides some experiments with qbs - who proved unsucessful because their dependency graph system was really not design for modules) so please correct me if I am wrong, is that 80%+ of the complexity comes from legacy headers and macros / includes in preamble, and in some regard the TS was simpler. There is a huge difference between lexing the first line of a file with a dumb regex versus running a full preprocessor on the whole file :( 
That's what my rant is mostly about: If you first teach people printf, new/ delete, pointers, native-c arrays, c-style strings and so on, creating a simple program becomes ridiculously compllicated and dangerous. If you use what c++ has to offer from the start (and by that I don't mean c++98, but the latest standard) and throw in a couple of good libraries, learning c++ as a first language isn't all that hard. Sure, there are still many more things that can go wrong than let's say in python, but lots of that can be easily avoided at the beginning if you don't start with c and don't let people use any standard library facilities until the second semester. 
They specifically use the compiler to depend on other module partitions within a project, and one gives cargo a set of modules that the compiler depends on, and cargo passes all of those modules to rustc.
Yes, for external crate dependencies, everything it simple. I am more interested in the crate being built: cargo got to extract the set of its constituent files to know when to re-run `rustc`. Surely it doesn't run it every time it needs an up-to-date check, or am I missing something here?
&gt; What's amazing is that Java and C# have had this for 20+ years now, Both are platform-independent languages that don't care about the hardware below them. Doing such a thing as mentioned with platforms that you have no idea nor control over is not only terribly inefficient, bad, and stupid, but physically impossible due to the need for backwards compatibility.
Let me look... I have no idea how cargo deals with not running rustc.
&gt; Mapping is 100% of the complexity for other tools. We had a long discussion about that at the Bellevue ad hoc meeting and the consensus (from my observation rather than official voting) is that other tools should just ask the build system (e.g., via something like a compilation database). &gt; that 80%+ of the complexity comes from legacy headers and macros / includes in preamble, and in some regard the TS was simpler. Yes, legacy headers definitely complicate things. But, realistically, both the TS and the merged proposal require preprocessing. I don't think "dumb regex" parsing is a viable approach unless we want to go back to the dark ages of build systems "fuzzy-scanning" for header includes. 
Why does it apply nore with VLAs than a normal array?
Not at all. They should be used when is necessary to hide implementation details, not just to follow a cargo cult. 
So you have some "classic" stack variables and some big array either on the stack or the heap. Both, stack and heap live in the same memory, using the same address space and the same cache. How is the access pattern different (from the perspective of the memory system)when classic stack variables and the array data are in the same virtual memory region compared to when they reside in two different virtual memory regions. If anything, having two separate regions should be negatively impact performance. 
In addition to the security concerns, there's no way to detect errors on VLA allocations, so you can trivially clobber your stack. Have fun debugging that...
&gt; due to practicability reasons. &gt; &gt; the supreme pragmatism of reviewing PRs on the shitter
&gt;Now some may ask what's the difference here to &gt; &gt;\#include &gt; &gt;, and the answer is &gt; &gt;intentionally nothing &gt; &gt; apart from being able to import multiple Precompileds That sounds an awful lot like extending #include to simply function as if it were a linker as well as an in-liner.
Stack access is trivial. Heap requires you to dereference a pointer.
I'm not an expert or anything but, could CMake implement it by parsing and keeping the list of dependency and location of interface files? And are legacy import really that problematic if the compiler can give back the import list of a file? Here how I imagine it could go: The meta build system (CMake) outputs to the underlying build system a new command like `make modules-deps` which will make the underlying build system create the list of dependencies to give back to CMake. CMake ship with a small executable that implements the module mapper protocol and read that file. There you go! If the compiler don't support that module mapper, then CMake could simply output the file in whatever format the compiler need. To get the dependency of a module, I would simply ask the compiler about it. It would run the preprocessor for the file and output what imports are needed. Much like how build2 is doing to get the header dependency graph! And what about legacy import? Nothing special! Legacy import are nice for one thing: the compiler can find the file by itself. So it can run the preprocessor on the header just to get it's state after the import and continue preprocessing the current file, and give back the import set of a module. I could bet that in a world where legacy import are uncommon and mainly used for C libraries, that process of invoking the compiler for the import graph would be even faster than getting the include graph like we're doing today, simply because there would be less preprocessing.
Stack access also dereferences a pointer (the stack pointer).
Maybe just because optimization is hard and msvc is a relatively primitive compiler?
Possibly. I know that SafeStack puts variables on a parallel stack to avoid Return Oriented Programming, which uses stack buffer overflows to overwrite the spilled programmed pointer.
&gt; you still specify the submodules your crate contains in Rust source files which means a build system has to extract this information It's actually been requested multiple times to just depend on the filesystem, rather than having to explicitly list submodules. I think the primary objection is that a file could accidentally linger around when reverting checkouts, leading to potentially puzzling issues. &gt; Of course, they don't have to deal with the preprocessor which I bet helps a lot. Rust still has macros, and worse, procedural macros; the latter is a short-cut for "compiler pluging", the code of the procedural macro must be in a separate crate so it can be compiled ahead of time and is loaded as a plugin by the compiler to do the code generation. There's been a move to push more and more capabilities into regular macros so as to remove as much reliance as possible on procedural macros, ... This is, arguably, even more difficult for other tools than the C pre-processor which at least is fully specified and fully independent of the code. 
It will be possible, though it would work more like the templated version. The interesting thing I found and its why I wrote the article is because i acheived the accessor method through overloading.
So, cargo deals with it as follows: rustc runs, and as part of that process, it produces a file which contains all the files that the build depended on. Then, cargo can look _just_ at those files for changes, since in order to introduce a new file into the build, you'd have to edit one of the old files. For example: src/main.rs mod foo; fn main() {} src/foo.rs fn blah() {} rustc would create a `main.exe` file containing the executable, and a `dep-info` file containing the size, hash, and location of every file used in the build.
Fingers crossed for C++20 modules.
That attitude prevailing in the community is the reason why we still don't have nice things that java and net do have. 
Is this specification in use anywhere right now? Would it be something that current package managers could adopt?
&gt; Is there another meta-programming language that is as flexible and comprehensive as C++? *D programmer twitches*
Sorry if this is a duplicate, I just hadn't seen it on r/cpp, and wasn't even aware it was up, so I figured I'd post it. If it is dupe I'll take it down.
For a project I've tried both RapidJson and nlohmann JSON, I don't feel the performance difference but I have to say nlohmann JSON is amazing in API design, compared to RapidJson who enforces passing allocator in every function, accidentally moving objects by invoking the copy constructor, and such. I don't think JSON should ever become a runtime performance bottleneck, since no matter what IO is going to be slower than RAM, the performance sensitive path would be based on in-memory objects anyway.
Can't we just fix the actual underlying problem, which is that templates are instantiated at compile time rather than link time? With that fixed, headers could be reduced to interface definitions (modulo private members, but PIMPL solves that), which could be precompiled.
I am not involved in CPS in any way, but the only practical use of it I am aware of is in the drake, in which all the dependencies that are built by bazel export cps files (see for example [Eigen](https://github.com/RobotLocomotion/drake/blob/cbbe135c83bf86c8b303cf60b429b645ab775677/tools/workspace/eigen/package-create-cps.py), [fmt](https://github.com/RobotLocomotion/drake/blob/97d930a7865990276075340433d0ec0d30239ce2/tools/workspace/fmt/package.BUILD.bazel) and [drake itself](https://github.com/RobotLocomotion/drake/blob/5227beeed932b56a0d1e64de6aded0936ceb993a/tools/install/libdrake/drake.cps.in) ) that are than converted to CMake config and pkg-config files using the script provided in [pycps](https://github.com/mwoehlke/pycps), but I am not aware of any build system that is able to natively consume cps files. A more in-depth discussion is contained in this paper: http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p1313r0.html .