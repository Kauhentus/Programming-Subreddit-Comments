Sounds like someone was accidentally constructing a temporary string object and then searching in that one.
No, I could absolutely believe a difference like this. At least on our implementation, `strstr` is handwritten assembly, while `basic_string::find` is `memchr` followed by `memcmp`, because `basic_string` can have embedded nulls. I can open the can of worms (with intrinsics, for example) to implement what `strstr` does for `basic_string::find`, but before I can do that I need a benchmark showing that the extra complexity is worth it. I would expect a minor difference but not 50+%
Same for the first Ariane 5. The [report](http://www.math.umn.edu/~arnold/disasters/ariane5rep.html) is highly interesting (see Sec. 2.1). The root cause for the loss of the rocket was re-using source code of Ariane 4 without adapting it: &gt; The value of BH was much higher than expected because the early part of the trajectory of Ariane 5 differs from that of Ariane 4 and results in considerably higher horizontal velocity values. 
Former automatic flight system (AFS) software engineer, but it's been awhile. DO178b level A. I can't remember if we used floating point or not. I suspect we used fixed point arithmetic. Many of the regularly used math functions (e.g. limiters, comparison) were our own libraries. Level A software development is tedious by necessity. The work to add a sanity check for zero before every division is small in the big picture.
&gt;I think for many projects it's much better to drive the MSVC compiler directly from CLI as it does rather than try to emit a project file like cmake does. Making it work entirely from command line makes it work much better with appveyor CI. You can compile the project from the command line using the .sln file. I don't see what's the difference for AppVeyor.
Folly? ASIO? HPX? TBH, the 'enterprise CPP' world is more where you write your own framework instead of gluing together bits in someone else's. ;-]
Could you, please, provide links to that libraries / frameworks? :) Thanks!
&gt; * common libraries (guava and Apache java commons equivalent) [Boost](http://www.boost.org/) is often seen as the C++ equivalent of Apache Commons. &gt; * testing framework Personally, I prefer [GTest](https://github.com/google/googletest). &gt; * mocking framework/library No experience with it, but GMock works well with GTest. (now an integrated part of GTest, see above) &gt; * swagger contract driven REST service stubbing (during build a header file would be created from a swagger contract) Last time I checked, there was no official swagger generator for standard C++, but there is one for Qt. &gt; * dependency management There are a couple of solutions out there, but I'm not sure if any of them are mature enough already to be used in production. &gt; * other.. ? * [CMake](https://cmake.org/) for build files. * Visual Studio CE or Qt Creator for good free IDEs. * [Qt](https://www.qt.io/) is the de-facto library for writing cross-platform GUIs. * [Crow](https://github.com/ipkn/crow) is a micro web framework inspired by Flask (haven't used this myself yet, though). Let me know if I missed anything!
Wait, I already love C++17! Modern C++ is in general so, so much better than C++03 - it's like night and day. I drifted away from C++ for several years - even, wince, went to Java - but since C++11 I've been firmly back in Stroustrupland... That said, the article is somewhat vague and general. Tell me stuff I didn't know, eh?
Yes, a lot of features slated for C++17 were pushed to C++20. 
With C++ on the "train model", and clang/gcc/visual c++ very actively implementing the latest features, active projects should start tracking standard conformance. It is no longer necessary to run on decade old compilers (as with c++98, when it took 5+ years to get conforming compilers). With almost any conforming code, installing the latest compiler and running at the latest standard (e.g. `-std=c++1z` on clang/gcc), very little code should break. Here's a list of breaking changes for [C++11](http://stackoverflow.com/q/6399615/819272) and [C++14](http://stackoverflow.com/q/23980929/819272). After that, one can add new features in the codebase as one pleases. My favorite features are those that increase code locality (`auto` for avoiding intermediate typedefs, lambdas for avoiding defining functions, C++14 `constexpr` for localized constant initialization using regular functions, and `if constexpr` for localized template specialization). 
&gt; Making it work entirely from command line makes it work much better with appveyor CI. You can do `cmake --build .`, all from the CLI. No IDE/GUI required.
Out of curiosity, did you use boost prior to C++11? edit: Why the downvote? That wasn't a knock on C++11, though I did use boost prior to then and am curious how that experience might be different someone who hadn't.
I really wish the standard library would embrace policy-based class design rather than trying to cater to either the lowest common denominator or the most general possible use-case. Too much historical baggage there now, of course, to start rolling out a new paradigm and radically changing interface design, but maybe in `std2`...
I'm someone who used Boost extensively, and I'd say that even with Boost, writing C++98/03 was somewhat miserable. Things like move semantics and lambdas and auto make a huge difference in modern C++ to the point where I actually enjoy using the language.
It was postponed for C++20. Specificlaly, the paper that made the first steps towards integration of string_view into the C++17 standard library [p0254r1](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0254r1.pdf) says, under the heading "Future work" &gt; The codecvt facilities [conversions.string] all take input parameters as both const char * and string (or wchar_t and string). Those could be string_views. 
Are there any technical reasons why it was postponed, or is it simply the result of it being a more obscure part of the standard library? Because unless I'm missing something, it should be fairly simple to implement.
Executable size was an issue as recently as the PS3. Typically, both RTTI and exceptions were disabled.
You should use the enter/return key from time to time, it is hard to read As you see it is not that dificult to do Even you can make tons of paragraphs if you want
You mean concepts?
Would it be possible making tagged_union&lt;Ts...&gt; be a literal type (i.e. constexpr-able) if all Ts are literal types? I've been experimenting with [Eggs.Variant](https://github.com/eggs-cpp/variant) which seems to pull this off. Instead of using std::aligned_storage it uses a recursive union. 
I published this recently: https://github.com/Orphis/boost-cmake It can build most of Boost on the major platforms and be integrated directly within any CMake project. I'll add Appveyor CI for Windows coverage soon and I'm working on adding some tests to check that everything links properly now. Sure, it's external to Boost, but it saves so much maintenance for developers that I see that as negligible. I wrote about it some time ago on the cmake-dev mailing list explaining how it saved my company Spotify so many hours when upgrading Boost or to align build flags by integrating it like this. Feel free to give feedback or contribute if you feel like it!
The thing I haven't been happy with in variant is v.get&lt;typename&gt;(); It serves just fine for type safety, but I often come across situations where I'd like to make a variant between a uint32_t and a size_t or something of that sort. It of course can't compile on certain platforms because size_t is a uint32_t on them. There are options to solve this problem in stl, of course, but I don't like them all that much because they often feel like duplicating the effort variant was meant to solve. My company uses a code generation library for protocol types which has a concept similar to variant called a Choice. The choice allows for named, tagged unions. For example: typedef Foo choice 0 bar int 1 baz int end Will end up generating a struct with functions int&amp; SetBar(); int&amp; SetBaz(); const int&amp; GetBar(); const int&amp; GetBaz(); It makes the code using the type a lot more readable, because I'm not just getting an int, I'm getting an int that has a name. I can have shorter variable names that way as well. I'd like to have that kind of behavior from std::variant, but not sure if this is possible without resorting to Macros, unfortunately.
some parts of Boost do not compile in C++17 because of removed stuff from C++. For example unary_function and binary_function are used in boost/functional/hash/hash.hpp but are deleted. They are no longer part of the Standard Library
By the Tic Tac Toe project, do you mean with a very simple AI, or strictly input by me?
concepts, ranges, modules, parallel STL, networking library, the list goes on
Heh. Interestingly, in a few talks that Stroustrup gave after the committee had finished their voting, you could clearly see the anger and disappointment. In one of his talks, he did hit upon the very fact that he was unhappy that the committee was focusing on details instead of trying to get in more useful (but substantial) changes.
&gt;I am looking to pursue knowledge the C++, C#, Java, Java Script, Python, and Linux languages in the order listed, so that means that I am starting with C++. 
Does your high school offer programming courses, if so try to take them. But if I were you I would take programming courses in the summer at the local college. Even learning Java or Python/JavaScript is a good way to learn how to first program. I find it that starting with a related C language is better, before jumping into C++, however there are many tutorials and guides for C++ nowadays. I strongly recommend learning C# first, before going into C++, why not learn how to use Unity? Pm me, and I can throw some resources on your way.
Thankyou, that cleared up abit
&gt; Garbage collection and memory safety are good things. Meh. If you absolutely need garbage collection, you can implement it in a library but it's really not necessary with RAII. Regarding memory safety, `unique_ptr` and `shared_ptr` make the situation much better. Folks shouldn't be using `new` and `delete` anymore unless they're writing framework code. 
I don't think I see how a variant type can be truly useful without language-level support to unpack them and require unpacking them correctly. This just seems... tedious. 
I think that C++ takes the reasonable approach here. For example, consider the following code. class Base { }; class DerivedA : public Base { }; class DerivedB : public Base { }; void func1(std::vector&lt;Base&gt;&amp; vec_obj) { Base obj; vec_obj.push_back(obj); } void func2(std::vector&lt;Base*&gt;&amp; vec_ptr) { DerivedB* ptr = new DerivedB; vec_ptr.push_back(ptr); } int main() { std::vector&lt;DerivedA&gt; vec_obj; func1(vec_obj); // Compile-time error, cannot convert std::vector&lt;DerivedA*&gt; vec_ptr; func2(vec_ptr); // Compile-time error, cannot convert } Each function is correct. They take a vector of specified type and append something of that time. However, the runtime type that is being passed in is a vector of child type. In `func1`, it attempts to add an object of type `Base` to a vector of type `DerivedA`, which is clearly incorrect. You can't even solve the problem by switching to a vector of pointers. In `func2`, you can add a `DerivedB*` to a `vector&lt;Base*&gt;`, but not to a `vector&lt;DerivedA*&gt;`. Therefore, since there is something that can be done to a `vector&lt;Base*&gt;` that cannot be done to a `vector&lt;DerivedA*&gt;`, it would be incorrect to convert to the `vector&lt;Base*&gt;`. In Java/C#, this results in a runtime error. I would much rather it be caught at compile time, rather than leaving it to runtime.
My understanding is that this was discussed for `std::variant` but was rejected because the committee wants variant to be a "vocabulary" type.
https://en.wikipedia.org/wiki/C%2B%2B17 (If I understood the question correctly.) 
Just FYI: my variant doesn't, because the library provides `tagged_types`, i.e. ways to make the same type different.
Adding `string_view` overloads to existing standard library interfaces is fraught with danger of breaking existing code -- for example, the first attempt to add `string_view` to `basic_string`'s interface broke C++14 code (by creating overload resolution ambiguities). Hopefully this will be simpler with interfaces that aren't as heavily overloaded as `basic_string`. Keep in mind that `string_view` is at most an optimization. It doesn't really allow you to do anything "new," since passing a string_view to a function with a `const string&amp;` parameter works fine. (`codecvt` (at least as used in iostreams) is effectively broken anyway and I would avoid using it whenever possible -- it assumes there is `1:N` relationship between the internal character set and the external character set, which is not true in a Unicode world http://eel.is/c++draft/locale.codecvt.virtuals#3 )
If you want the "it must be empty first" `std::variant` then just make one of the members `monostate` and ensure you always engage `monostate` before making any such transition. Then the move constructor mess described is impossible.
I'm new to writing Reddit posts and this sub, so honest question: Why?
I think the cppcon talk is the one that I referenced in the beginning. If not, could you point me to the talk that you are referring to? The term "state machine" referees in my head to something such as http://www.boost.org/doc/libs/1_62_0/libs/msm/doc/HTML/index.html which has a very different syntax and I think also promotes a different way of thinking about the subject.
Would you mind elaborating on why the manual transformation is extremely brittle? My hunch is that you would mostly run into compiler errors of the type "goto cannot bypass initialization of variable X", which indicate that you forgot to move the definition of X into the class. Are there more severe problems that I am not seeing?
thanks! that's what I was looking for :)
We have Premake, which is similar to this: generates project files for you. It can spit out makefiles for GNU make, or Visual Studio projects. It uses Lua, so you're not forced to follow any rules - you can make your own ones. It's also self contained, meaning it comes as a single executable, without any dependencies. While I think this is definitely some valuable experience for you, I think yet another build system is the last thing C++ needs. So I wouldn't put much more effort into it (unless it is for educational purposes). [Premake Github repository](https://github.com/premake/premake-core)
Cool! It's a really neat thing to be able to have a compile-time array of things with different types. I have written a simple StaticMap&lt;K, V, N&gt; which is to std::map kinda like what std::array is to std::vector, i.e. a stack allocated non-growable container. Then being able to store Variants inside that is just super convenient. 
Ditto on Unity as a way to learn basics of programming. Graphics is just more fun, and Unity is actually used quite a bit.
Mostly because of syntax highlighting. Reddit isn't well suited for posting large code. Also you benefit from GitHub features like versioning of the code and people can contribute there with better tools.
I briefly skimmed the Premake wiki. It seems like it has good cross platform support. However, I do not know see why it fits the requirements. How does Premake infer from the C++ source code what executables and libraries to build and what objects to link into what? The tutorial at https://github.com/premake/premake-core/wiki/Tutorial:-Premake-example-with-GLFW-and-OpenGL creates a configuration file per library and executable. That is precisely what I do not want to do. The problem that I have with every build system that I have seen is the following: If there is a cpp file with a main function, then obviously I want the system to make an executable out of it. What else could I have meant? Why do I need to specify this?
It is true in the standard-compliant Unicode world, where wchar_t is 32 bit. It is also not really relevant in a thread about wstring_convert, which does N:M conversions.
typical C++'er.. abstraction to pointless levels ;) first blog post i see is a blog post about blog posting. 
Thanks for introducing pybind
Well, the problem is: not every application has an actual main function. Or it is not called main, at least. Windows windowed apps have WinMain, for example. Android NDK uses ANativeActivity_onCreate as some sort of a main function. Not to mention that it is also possible to alter the main function and specify your own. Those kind of projects wouldn't work with such a build system (unless those names are hardcoded, but then there's the problem of having to keep up to date with all these kinds of platform nuances). P.s.: and there's also the fact that you can actually put your main function into a library, link it to your executable, and it will work. Not sure how is the compiler support, but it definitely works with MSVC and a static library.
 for(auto&amp; c : container) hnnnng
Parallel algorithms _are_ in C++17.
Very true. I've been mostly wasting for it to become more Linux-friendly. It runs the, now, but the tooling wasn't that good, last time I checked.
metablogging?
Yeah, I've used that as well. My complaint with that pattern is that when reading the code, std::variant&lt;a, a&gt; v; // setting v.get&lt;1&gt;(); I'm not well informed on what the meaning of that is. I need to read more into the code to figure out the meaning of each. My personal goal is to write code that is so clear it needs no comments. 
BlogPost&lt;T&gt;
This proposal is written by people who do not understand the meaning of linear color spaces and how alpha blending should be performed.
XML? Ouch...
NFD is irrelevant (to the meaning of internal charset and wchar_t). It is not a character set, it is an encoding of one (or transformation of an encoding, if you will). By wchar_t definition from [lex.con]/6, a single wchar_t represents any member of execution charset (and also a single c-char aka UCN aka \U hex-quad hex-quad). If U+00C5 is a supported member of exec charset and allowed in string/character literals, it has a single-wchar_t representation in standard C++, whatever its NFD transformation is. Likewise U+1f34c and everything else. As for codecvt, if basic_filebuf were to permit N:M codecvts, it certainly wouldn't be bad.. Last I tried, libstdc++ and libc++ work with such codecvts in practice, but for input only.
 template&lt;Blog B, Bloggable Subject&gt; B::blog_post_type generateBlogPost(const B&amp; b); MyBlog myBlog; myBlog.emplace_back(generateBlogPost&lt;MyBlog, Cpp&gt;(myBlog));
How should alpha blending be performed?
Why would sign matter for a character? All that should be important is that you get the required space and 8 bits allows you to have 256 values. It is how those values are interpreted is what matters. And if you look at the extended ASCII character set 128 is € and 255 is ÿ. That matches the UTF-8 basic Latin character set.
STL maintains a MinGW distro? And a love for Deus Ex? What other awesome stuff don't I know about?
Thanks and thanks for the feedback - fixed the code example font size. It should be more readable now.
UTF-8 should be thought of as a data stream. it's not a bunch of 'characters', and hence not an array of 'char' (in the academic sense). it might be implemented as an array of char (in the technical sense), but that's just co-incidence.
Thanks, /u/STL. Your distro is the definitive way to use minGW.
Thanks for posting this. &gt; There's one kind that still doesn't work, and for which I do not have a solution (suggestions, anyone?) Can't you parameterize `wildcard` over a type that you don't want to allow implicit conversions to, and fill it in with the type you're trying to construct? http://coliru.stacked-crooked.com/a/a57057f574fe5770
I didn't know about this, thanks
&gt; And if you look at the extended ASCII character set 128 is € and 255 is ÿ So, on a platform where `char` is signed what values do they have?
Make me.
No Concepts, no modern C++.
Just merged [a PR][1] and now users may choose between Boost.Asio and vanilla Asio via a compilation flag `USE_BOOST_ASIO`, which is not defined by default and uses vanilla Asio. [1]: https://github.com/liancheng/amy/pull/8
Why `-fno-exceptions`? Because https://twitter.com/MalwareMinigun/status/809606314787643394
I'm perfectly happy with other people submitting my distro releases. I generally submit a link to my distro once per year, when there's a new major version of GCC. Using my distro means accepting my judgment about what's good and simple. I intentionally disable mingw-w64's 32-bit targeting ability, since I consider it to be bad and complicated. All programs should be 64-bit now. However, if you want to build your own distro with such an ability, I have provided my full build scripts and environment.
Glad you like it! Sincerely, blind2ndeye
There's this thing called VS 2017 containing my thoroughly rewritten `vector&lt;T&gt;` implementation...
I've maintained my distro for over 11 years without selling anything, serving ads, or accepting donations. All I ask is: if you like my distro, look at my [GitHub issues list](https://github.com/StephanTLavavej/mingw-distro/issues) and see if you can help with anything. For example, [#6](https://github.com/StephanTLavavej/mingw-distro/issues/6) affecting grep is probably pretty simple, it's just a bit beyond my ability (and free time) to debug at the moment.
So your answer is that I can't do UTF-8 in C++ with things like `std::string` and the `u8` literals then because I can't read the values from `char`. That's been my fear, but it seems incredible that we're further standardising on that basis.
Do you have any details about your rewrite? I'd love to learn how you have improved it!
My question isn't about how to opaquely deal with UTF-8, it's about how to decode it. Can it be done portably with `char` buffers?
Which is a fine point, but the u8 literal type has already been standardised as a `char` array, so is it even possible to decode it in a portable manner?
It sounds like you're really asking if converting a buffer of chars between signed and unsigned is safe and defined. [This link](http://stackoverflow.com/questions/50605/signed-to-unsigned-conversion-in-c-is-it-always-safe) seems to answer that for the C Standard; I'm pretty sure the C++ Standard is the same in this regard. From one of the answers: &gt; For the two's complement representation that's nearly universal these days, the rules do correspond to reinterpreting the bits. But for other representations (sign-and-magnitude or ones' complement), the C implementation must still arrange for the same result, which means that the conversion can't just copy the bits. **For example, (unsigned)-1 == UINT_MAX, regardless of the representation.** It definitely looks like this behavior is defined as the same even on non-two's-complement hardware, ie. in terms of UTF-8 string encoding/decoding you can just cast between signed/unsigned as needed (though you may have to pay attention to performance issues on really weird and ancient hardware). [edit] Note that technically a conversion from unsigned to signed, where overflows occur, is implementation-defined (unlike the reverse), but if the original char data was signed to begin with, an overflow is impossible. In practice, I don't see this mattering.
&gt; All programs should be 64-bit now. You should tell this your colleagues who argue that a 32-bit Visual Studio is far superior. 
I rewrote almost every member function to fix multiple problems with correctness and performance. Specifically, we now correctly handle aliasing (e.g. `v.emplace_back(v[0])`), iterator invalidation, and EH guarantees. We also perform fewer operations when inserting and doing other operations.
It doesn't matter which it is, the 8 bits in its memory matter. UTF-8 needs to parse bits out of the bytes and combine the bytes regardless. It's just that all of the byte handling in the existing language is done with char.
Thanks for the release, and a happy New Year. I've lost track, does the newest version of gcc etc on windows support the full standard libraries such as thread and chrono, or do we still need to fall back to boost? Link to discussion in the 14.0 release comments: https://www.reddit.com/r/cpp/comments/4ln0ms/mingw_distro_140_gcc_610_and_boost_1610_for/?limit=500
On mobile chrome it seems like editing the text inserts characters the compiler doesn't expect. Escaped newlines, htmlencoded stuff etc. 
But that's on windows wgere x86 exceptions are subpar
I am totally aware of this - have you really read the first comment *and* the corresponding code? A factory **function** (read: **not** a *method*!) always leads to transfer ownership - and that's why you shouldn't use a raw pointer there.
First of all, thank you for the great distro. I've upgraded to the latest version without many issues. Is LTO usable nowadays on Windows? I remember earlier versions having issues with it.
No.
It's supposed to be usable, and I'm enabling it now. However, I haven't tested it recently.
You still need Boost. This is [#26](https://github.com/StephanTLavavej/mingw-distro/issues/26) "libstdc++ doesn't natively support multithreading on Windows". It sucks, but I consider Boost.Thread to be more reliable than this winpthreads stuff I keep hearing about (and otherwise know nothing about).
I just tried adding `-flto` in my project and it results in each object file complaining as follows: `plugin needed to to handle lto object`.
not sure where i do that. sf? i can't even log into to sf anymore.. i just get server errors.
Libc++ does one better and provides `std::variant&lt;Ts...&gt;` as a trivial type when all of `Ts...` are trivial types. Meaning it provides constexpr copy and move constructors as an extension. 
by taking into account color spaces, so you need the whole ICCC handling to be in it too.
apart from modules, there are already ways to use all this at least in GCC, which is on all platforms. Parallel STL has been in GCC for ... maybe decades ? Ranges are just a library that you can download, and the networking library is basically boost.asio in namespace std. Concepts are available in GCC since v6.
You can also specify the build type, e.g. `--config Release` or individual targets, `--target INSTALL`. (that's from the top of my head - hope that's correct - if not, then the actual commands are very close ;) ). It's pretty useful.
Conversion from `signed char` to `unsigned char` is well defined, no matter the sign. `-1` signed will yield `std::numeric_limits&lt;unsigned char&gt;::max()` unsigned. On the other hand, conversion of unsigned to signed char is undefined for all unsigned char values which can't be represented by signed char (for example `std::numeric_limits&lt;unsigned char&gt;::max()` doesn't have to be converted back to signed char with value of `-1`.
Very cool! That solved the build issue. It seems my resulting executable is crashing, though. Thanks for the tip.
Simplicity of installation would be one reason.
asio with some serialization format to build your rpc framework. If you prefer http/rest, there are boost.http and boost.beast, although still in long term review. For service discovery, distributed application coordination, use something having a rest api, e.g.: etcd, consul
Yes you can have a valid (but not very useful) compiler with EBCDIC exec charset and 8-bit wchar_t. In "Unicode world", which set off this thread, each code point needs to fit in a single wchar_t by definition. There were no standard codecvt facets until C++11 at all, and somehow i had no problem going between Unicode and non-Unicode encodings; GB18030/char &lt;-&gt; UTF-32/wchar_t &lt;-&gt; UTF-8/char works just fine where wchar_t is correctly sized and libc is complete. PS: I'm not saying C++ doesn't need more Unicode support - I'd love to see classification, normalization, or "just" a grapheme cluster iterator for strings! - but as someone who lived with five competing encodings and adoption of Unicode, I find it jarring to hear that it doesn't work in C++, or C for that matter.
There are some great tricks in this article, and it's the first C++17 feature I've seen that I think might be useful. However it also highlights some of the glaring holes in std::, like an insertion operator for vector/array/tuple etc. Would have made my life so much easier over the years.
&gt; For every file src/X.cpp that contains a main function sounds pretty unreliable. What if your `main` is a macro ? What if you're in a platform without a main ? e.g. win32 with `WinMain()`. Will your parser handle `int main()`, `main()` (which is valid C but not valid C++), `int main(void)`, `int main(int argc, char** argv)`, etc. ? &gt; If a file src/X includes include/Y/Z.h, if the regex ^ *# *include *&lt;Y/Z.h&gt; finds a match in src/X. Good luck using some advanced boost libraries that depend on Boost.Preprocessor to generate include names or stuff like this.
The only place where this gets you is even more fragmentation.
God knows we need more C++ blogs
The term microservices makes me want to set my face on fire
They have the values of 0x80 (128) and 0xFF (255). A char is probably best thought of as a binary value that maps to a glyph and not a signed or unsigned integer. I would guess that having signed and unsigned characters are a convenience for the compiler and runtime.
Good job!
UTF-8 defines a variable length mapping to glyphs. So you have single bye characters 0x41 for A. Two bye characters 0xC480 for Ā. Three bye characters 0xEA9C80 for ꜀. And etc. 
&gt; All programs should be 64-bit now. If there was a Windows equivalent to the [x32 ABI](https://en.wikipedia.org/wiki/X32_ABI), would you support that?
Agreed. I started using it a few years back when I was stuck with a Windows box, hadn't messed around with C++ for a while, and needed to get right back on the horse. Trying out msys2 and getting it to work correctly was a right PITA. Luckily, I chanced upon nuwen.net following a Google search (I didn't know it was your site until I actually visited it the second time!), and it just worked like a charm. I've been using that ever since (on a Windows VM on my macOS box now). Thank you for your all your effort and time! I really appreciate it! :-)
I completely understand UTF-8 encoding and don't have a problem with that. My question is about what the standard guarantees in the processing of the byte values.
&gt; They have the values of 0x80 (128) and 0xFF (255) I think I understand a bit about what that means now, but 0x80 (128) certainly doesn't look like a number that I can put in a `char` if `char` happens to be signed on my platform -- what guarantees do I have about how these numbers are interpreted? 
It should be performed in linear color space, not directly in sRGB. [Here is a long article](http://blog.johnnovak.net/2016/09/21/what-every-coder-should-know-about-gamma/) about this and other things. 
Try r/cpp_questions.
They are binary values sign doesn't matter. Perhaps this will help. #include &lt;cstdint&gt; #include &lt;cstdio&gt; int main(int, char**) { int8_t int1 = 126; uint8_t int2 = 126; char char1 = 126; unsigned char char2 = 126; std::printf("for values = 126 because 127 is non-printable\n"); std::printf("int val: %hhd hex: %hhx \n", int1, int1); std::printf("uint val: %hhu hex: %hhx \n", int2, int2); std::printf("char val: %c dec: %hhd hex: %hhx \n", char1, char1, char1); std::printf("uchar val: %c dec: %hhu hex: %hhx \n", char2, char2, char2); int1 = 128; int2 = 128; char1 = 128; char2 = 128; std::printf("\nfor values = 128\n"); std::printf("int val: %hhd hex: %hhx \n", int1, int1); std::printf("uint val: %hhu hex: %hhx \n", int2, int2); std::printf("char val: %c dec: %hhd hex: %hhx \n", char1, char1, char1); std::printf("uchar val: %c dec: %hhu hex: %hhx \n", char2, char2, char2); int1 = 255; int2 = 255; char1 = 255; char2 = 255; std::printf("\nfor values = 255\n"); std::printf("int val: %hhd hex: %hhx \n", int1, int1); std::printf("uint val: %hhu hex: %hhx \n", int2, int2); std::printf("char val: %c dec: %hhd hex: %hhx \n", char1, char1, char1); std::printf("uchar val: %c dec: %hhu hex: %hhx \n", char2, char2, char2); return 0; } 
[removed]
References do no such thing. It's just people trying to enforce "clever" coding standards that want to assume that references are non null. Realistically you will always have a mixture of references and pointers in a code base, so any time somebody has to convert from a pointer to a reference you will inevitably end up with a null reference.
Just use tagged types: using Bar = tagged&lt;int, struct Bar&gt;; using Baz = tagged&lt;size_t, struct Baz&gt;; And then you can have a `variant&lt;Bar, Baz&gt;`. I personally prefer to have *meaningful* types rather than bare `int` or `std::string` which carry no semantic description and allow doubtful operations (what's the meaning of `user_id + 3`???).
&gt; any time somebody has to convert from a pointer to a reference you will inevitably end up with a null reference **No** A well-designed codebase will have a small amount of these conversions, and they will all either be checked for null, or trivial to check for non-null by a simple code inspection. You're inventing a problem where needs no be one, not compared to "I can **never** assert this is not null". You're throwing the baby with the bath water. 
I think this illustrates the problem, because `std::ratio&lt;1&gt;` doesn't have a name, and its not quite the same thing as `std::ratio&lt;1,1&gt;`. Although why you want to use the later is beyond me.
The C++ standard could guarantee that `vector&lt;T*&gt;` and `vector&lt;U*&gt;` have an identical layout and allow casting between `const` references thereof, but that'd be an awful specific and very limited bit of special wording to put in place for just a single template in a very particular circumstance. :)
Let's take a problem like this: struct Vec3 { float x, y, z; float length() const; }; inline float dot(const Vec3&amp; a, const Vec3&amp; b) { return a.x*b.x + a.y*b.y + a.z*b.z; } inline float Vec3::length() const { float lenSq = dot(*this, *this); // is this safe? return (lenSq &gt; 0) ? sqrtf(lenSq) : 0.0f; } Is this bad design? Can you think any way that this could fail with a null dereference? 
Yeah, they're literally the same thing (ask `is_same`).
The slides are great, I wish I knew Spanish so I could watch the video. Elements of Programming fundamentally changed the approach I take to programming...
I think it depends on what your trying to learn. If your already know a bit about systems programming, or just want to build software ASAP, then jumping into C++ is probably the right approach. But if you actually want to learn how to be a good systems programmer then starting with C is the way to go. I've seen students who can "get by" in C++ without understanding a lot of really fundamental stuff (ie "really" understanding pointers, stack/heap memory, their operating system). Everything is abstracted in C++, If they started with C then they would have to understand the basics of how their computer works to do anything.
We briefly considered giving `std::ratio&lt;1, 1&gt;` a name, but decided to stick with the scientific community's list of prefixes: https://en.wikipedia.org/wiki/Metric_prefix .
stop shitposting nonsense
So you think that \*this is potentially unsafe? Why!? \*this is 100% correct, good design, safe, you name it. It can **never** fail on its own, it can **only** fail when something else was written in a way that can cause UB. What is **not correct** is someone calling length() with a nullptr, e.g. void whatever(Vec3* v) { // stuff auto x=v-&gt;length(); //**badbadbad** // stuff } The problem is **always** he who used a pointer without checking it for null where it legitimately **can** be null. The problem is **never** he who uses a reference. "this", BTW, is practically a reference, it is a historical mistake in the standard that it is a pointer type. Gcc even recently added an optimisation exploiting the fact that this is never nullptr, relnotes were discussed here on Reddit.
Make sure there's a space between angle brackets, otherwise your compiler may interpret &gt;&gt; as an operator.
Not since C++11!
To my understanding GB18030 has the "UTF-16 surrogates" problem but not the "complex scripts/combining characters" problem, and as such does not trigger the M:N mapping issue, as all characters in the external character set are transformed into a single code point (assuming you're targeting NFC instead of NFD). Of course, if on the Unicode side you're given combining characters, the assumption breaks down even for latin-1, as 2 code points U+0065 U+0301 need to become 1 latin-1 character 0xE9. My understanding is (although I haven't implemented such mappings myself) that there are legacy encodings for which 1:M is never correct -- where combining characters are required to represent something in Unicode but not in the legacy encoding. (Maybe it was TIS-620?) I'm sure if everyone had a time machine to go back to when COM, NT, Java, JavaScript, and friends implemented Unicode 1.0, we would be in a UTF-8 and UTF-32 world. But that's never going to happen. VC's "extended character set" is going to have to be UCS-2 
Before C++, people would write this: struct Vec3 { float x, y, z; }; float Vec3_dot(const Vec3 *a, const Vec3 *b) { return a-&gt;x*b-&gt;x + a-&gt;y*b-&gt;y + a-&gt;z*b-&gt;z; } float Vec3_length(const Vec3 *v) { float lenSq = dot(v,v); return (lenSq &gt; 0.0f) ? sqrtf(lenSq) : 0.0f; } This works 100% identically to the c++ version. And if somebody did this: void whatever(Vec3 *v) { Vec3_length(v); }; ... and it crashed, this is identical to the reference version dereference. So where does the bug lie? Is this a lack of using references? Of course not because the bug is the same. The bug is the same in both: misunderstanding of global state somewhere up the callstack. That is why I say you are trying to use references as a coding standard to determine what should be null checked up the stack earlier. But to me it is irrelevant because the crash is the same no matter what you use, and the fix is also the same, evaluating the global state and inserting the check at the point which is valid. It's also never so simple that you can ever assume this sort of issue can be turned into a references vs pointer situation. Let's say you had this: class Obj { std::unique_ptr&lt;Vec3&gt; v; void something() { whatever(v.get()); } }; Obj o; o.something(); This would crash. But is the issue that o.something() should never be called before being initialized, or is the issue that o.something() should null check v and handle gracefully? This is entirely based on your program and cannot be reduced to a simple references vs pointer argument. Hence why I think this is all misguided. Maybe I am an old C programmer, but it seems you are thinking code is more important than data. All that matters is the higher understanding of data, which you cannot see when trying to build things from small pieces. 
The `print` function should be replaces with a `forward_to_tuple` function. Then implement `print` using it. It is elegant and simple. As a bonus, ADL means non-simple structs can now use your `print` machinery for free with a simple overload of `forward_to_tuple`. `_` is a bad name, and you should feel bad. Rename `wildcard` to `wildcard_t` and `_` to `wildcard`. Traits (can forward to tuple, as tuple element types) are useful. Reading now consists of another trait (can you be constructed from your tuple element types?), then writing from tuple. 
Unit tests do not solve UB. Compilers are free to pass all your unit tests and optimize other code away. char x = (unsigned)-1; bool b = x&lt;0; std::cout &lt;&lt; (int)x &lt;&lt; ":" &lt;&lt; b?"true":false" &lt;&lt;"\n"; This can print `-1:false`. And the same is true whenever you convert from unsigned to signed. The level of insanity optimization and UB can generate is so large, you cannot reasonably reason about it and produce unit test coverage.
I fixed some of the grammar issues if there something left mention it and ill correct it.
I agree with you. All these posts that came up in the last weeks declaring C++17 to be "not that bad" smell like post-rationalization. Certainly there are many improvements (for example `std::optional` and `std::variant`); but those are nothing compared to the important features that *didn't* make it: - Modules. A sane compilation model would finally improve compliation times. - Concepts. These should have been in the language *decades* ago! - Networking. A major programming language without networking functionality in the standard library. Okay. - Coroutines. There are many non-obvious applications, like for example generators (take a look at python). Defining a new range could be as easy as implementing a coroutine that yields the appropriate values - instead, one still has to implement custom iterators. - Ranges. To me, C++17 is a major disappointment. 
&gt; This causes people to pick up pythonic habits that can be very hard to break when moving to less dynamic languages once they get very good at Python. I actually think the best language to learn first is *Haskell*, but only if you are strongly mathematically inclined. This does have the disadvantage that you may get very frustrated with other languages though. I don't think a C derived language is the right place to learn about type systems though.
So for example 515 out of 650 people voted to get Modules into C++17, but yet it didn't get in? I'm still not sure I understand the numbers :-) PS: A new typo, "participatns" ;-)
Actually C# does the wrong thing here. [Here](https://blogs.msdn.microsoft.com/ericlippert/2007/10/17/covariance-and-contravariance-in-c-part-two-array-covariance/) is a blog post by Eric Lippert on why this broken in C#. From the post: &gt; Unfortunately, this particular kind of covariance is broken. It was added to the CLR because Java requires it and the CLR designers wanted to be able to support Java-like languages. We then up and added it to C# because it was in the CLR. This decision was quite controversial at the time and I am not very happy about it, but there’s nothing we can do about it now.
Why are there No static reflection on this list ? 
Why is there a static rational class in the standard library but no run-time rational class? Boost rational is fine and all, but I'm kind of curious now!
&gt; (OTOH, I don't think this guarantees roundtripping unsigned char through signed char is safe.) This is correct. The purpose of vanilla 'char' is for the platform's natural character type. For instance on Linux ARM 'char' is actually unsigned by default. If you had a platform which had 'char' as unsigned and didn't use 2s complement representation for signed types then it's highly likely that conversion between signed and unsigned char wouldn't work.
We needed `ratio` for `chrono`, and we really needed `chrono`. So that forced `ratio` in. A rational number library has been proposed in N3611 (http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3611.html). I'm not sure what the status of that proposal is, but I'm sure the author would be happy to tell you.
Thanks STL. I like having your distro around as its just 'there' setup ready to go. I'll probably keep msys2 around as it has openmp enabled which for me is a big deal. I'd love to try and convince you to put it in. I think it would be enormously beneficial for people leaning c++ as it allows beginners to get great performance from it and it is used heavily (at least where I work in the VFX industry) . I tried building it using your scripts but there were a few stumbling blocks with configuration. Also the other benefit of using msys2, it that after setting up the PATHS, you get ls, cd, mv, rm , etc, ldd, etc from within powershell. Its like having linux without having to install the subsystem. I currently have vscode as my main editor with the integrated terminal being able to run g++ is now pretty much the same cross platform for me which is of most interest to me for teaching and showing a consistent experience. Much appreciated.
And then things like structured binding ships without much thinking, which offers nothing more than decoupling a struct/tuple only. I'm really sad that there's no thing such *ignore*, nested binding or even a simple pattern matching. You can argue that the committee will think about it in the future, but the design of it is already decided. `auto [a, b, c]` doesn't look like pattern matching. There should be a change that these three variables have their own type, while auto is deduced to the whole expression's type, so things like `Foo [a, b, c] = Foo{1, 2, 3}` could be a thing. This even plays nicer with concepts, where Foo would be a concept to match against the result of an expression. Also, if you needed to bound specific fields, that would work as well: `Foo [Bar [a], ..] = something()`.
Seems overcomplicated (as compared with e.g. [this](https://gist.github.com/tomilov/0cf10f110a8e1a0b486603bba500640a)) and usless at the end. One don't need a print, but one want to get n-th element for general purposes.
Structural bindings is not suppose do be "pattern matching for C++". Rather saner way of returning a getting multiple values from the method/function. And as Go developer I can say that this feature is very handy. As for pattern matching - this suppose to be evolution of variant type. There were some development is that area, including saner pattern matching - but I'm unsure what status it has now. 
At least there should be a way to ignore some fields, instead of declaring a bunch of unused variables.
I'll try to enable OpenMP in the next version, tracked by [#32](https://github.com/StephanTLavavej/mingw-distro/issues/32). I still have no interest in it, but if it's a single configure option and doesn't cause trouble, I can do that. (Too much was changing in distro 14.1 for me to be comfortable adding OpenMP - I added the ISL library to activate GCC's support for Graphite loop optimizations, and I switched back to an in-tree build of GMP/MPFR/MPC/ISL for simplicity and better bootstrap verification.)
They are pretty similar in my opinion. Some may say STL's is slimmer than msys2. I personally use only msys2 but I admire STL's work. In my opinion, msys2 is as slim, you can install what you need on demand - and it includes lots of packages that STL's dont, *if* you need them. Some things don't work in msys2 I think, like a local X server and X forwarding, so you need XMing or CygwinX and basically two distributions that do the same - quite annoying. Not sure STL's mingw can do that either though.
&gt; for the most errors I had encountered the reasonable thing to do was just to close the app with an error You can do that easily without using exceptions. You could write a `void close_app_with_error(const char * message) [noreturn]` function and call that. When you have code that throws lots of exceptions it becomes very hard to reason about the possible control flow, and very hard to understand if a function is correct as written. Static analysis tools are not always able to determine if a function could throw an exception -- in a large code base it may be very difficult to figure it out for sure, and you need to know that. When you have `-fno-exceptions` the code flow is easy, and always local. Too much exceptions creates spaghetti code, like with goto. It usually takes more typing and thought to do the error handling without exceptions, but it's easier for users of your library / maintainers of your application. Agree that `unwrap()).unwrap(). do_something().unwrap()` sucks but this seems like an extreme example to me. Usually it ends up more manageable than that in my experience, and even if it's longer, it takes less time for me to figure out with certainty what it will do. Maybe with more experience I'll see your side of the argument. Right now my take is that `std::bad_alloc` is basically the only exception that's worth it, and I usually try to do `-fno-exceptions` anyways.
References in C++ are a game changer **exactly because** they let me assert what cannot possibly be null. In C, (and Java, anc C#, and...) I have **no idea whatsoever** is whether some pointer can be null. Obviously, nothing can stop me from making a mistake and passing null where a reference is required, but there is a world of difference between making a mistake and not being able, at all, to design a non-null requirement.
With an error - by that I meant that I want to have some sort of explanation of what went wrong. More importantly I want resources to be closed (or, at least, my app should try to close them). Exceptions allow me to do that. As for exceptions - I think it's all about documentation. Same goes for any kind of error, to be honest. Handling errors is never easy I agree - in some situations I would prefer to have variant with error type - in other (like clear violation of contracts by me) exceptions sounds logical. I like having options. As for unwrap - its not bad per see. You could get used to it, after a while. Yet I don't see any reason to do so, because if I'm ignoring the errors - I do know what I do. So to put it correctly - I think this kind of "ignore it, I know what I do" should have a more elegant solution. And no - macroing things do not solve this problem. 
Which is exactly what I'm arguing against.
&gt; these three variables have their own type, while auto is deduced to the whole expression's type Are you arguing for this or against this? Because this is basically the current design. Another way to put it: `auto [a, b] = std::tie(c, d);` copies neither `c` nor `d`.
&gt; flat_set for instance... If an exception is thrown while shuffling values around By moving constructor, which is specified as MUST NOT throw an exception and should be entirely possible because it only moves data and does no allocation? I think if a type violates the requirement it's allowed for a container to break some invariant. &gt; Let's not even get started on what led to C++17's variant and its valueless_by_exception state. Why not? Yes there has been a problem by you just mentioned an existing solution. &gt; Of course, if some code has these sorts of types, it's not a big deal if it's compiled with -fno-exceptions. So far don't see what could lead to this conclusion. &gt; Basic exception safety guarantee and data loss Merely refers to previos section without adding anything. Argument from repetition? &gt; Foreign function interfaces at any level This might be valid point. When we are making a library we must make sure we do not throw more than we declare, and there is no way to guarantee this, especially what we call another library which throws something it did not declare. &gt; -fno-exceptions to the rescue How would it help? If a thirdparty library (which is build without -fno-exceptions) throws an exception it would not disappear but rather pass through our code, as far as I understand. Or would it be std::terminate()? Same applies to any allocation and move failres. Actually, this is question what I would generally ask. C++'s exceptions are bad (yes they are), but if we just disable them will it help to resolve any issue at all?
Is the goal to have only msvc 2017 be C++17 compatible? or where possible will MS be back-porting things to 2015? In short is 2015 indefinitely closed?
We're done with VS 2015. New features will be added to VS 2017 in Updates, and it will be binary-compatible with VS 2015 (you should still build everything with the latest version to activate all correctness and performance fixes).
&gt; Can't we have both? I understand that for performance critical code exceptions might be a big no-no. Exceptions are actually faster as long as errors are rare, since you don't have all the mandatory conditional error checks in the fast path busting your icache and BTB entries. They can add to the overall binary size but that's an upfront cost, not an ongoing cost which increases with each function call.
Pretty cool. I do think a (more advanced) version of this is needed. Something that lets users define their own templates for code generation that can use user-defined attributes, for example, so we can spit out serialization or UI or script binding code without needing to walk reflection metadata at runtime (or even just to be able to generate the complete reflection metadata we'd need to be able to do it at runtime).
I think the difference is, instead of using `ubiq` object which is implicitly convertible to everything and fairly complex, he uses this `aggregate_arity` template which is like 25 lines of code struct filler { template&lt; typename type &gt; operator type (); }; template&lt; typename aggregate, typename index_sequence = std::index_sequence&lt;&gt;, typename = void &gt; struct aggregate_arity : index_sequence { }; template&lt; typename aggregate, std::size_t ...indices &gt; struct aggregate_arity&lt; aggregate, std::index_sequence&lt; indices... &gt;, std::void_t&lt; decltype(aggregate{(void(indices), std::declval&lt; filler &gt;())..., std::declval&lt; filler &gt;()}) &gt; &gt; : aggregate_arity&lt; aggregate, std::index_sequence&lt; indices..., sizeof...(indices) &gt; &gt; { }; Maybe `filler` is the vestigial `ubiq` here.
I like your idea I'm also thinking something like this but static reflection such as Reflect&lt;class&gt;::fields will return a special type list Fields with members like Field::type and Field::name I hope your idea or something like will be standardised 
Sounds likea great opportunity to use gperf.
That is very interesting indeed. Can you perhaps give an example for a scenario (and perhaps some pseudo-code)? Because one can, today, do: Class&lt;MyClass&gt;::IterateFields() (see https://github.com/chakaz/reflang/blob/master/tests/class/fields.test.cpp)
Is there any way to do it selectively for some classes? I wouldn't want to generate reflection data for my whole codebase, but I would definitely like to use it to serialize some structs.
&gt; The only language operation that is explicitly noexcept by default is the destructor and nothing else. This is extremely misleading. It's true that an explicitly-declared destructor is noexcept _even if not declared as noexcept_ as long as the definition never throws, but you make it sound as if other special member functions are only ever noexcept if you explicitly declare them as such, which is _not_ true. C++14, [except.spec]/14: &gt; An inheriting constructor and an implicitly declared special member function have an _exception-specification_. If `f` is an inheriting constructor or an implicitly declared default constructor, copy constructor, move constructor, destructor, copy assignment operator, or move assignment operator, its implicit _exception-specification_ specifies the _type-id_ `T` if and only if `T` is allowed by the _exception-specification_ of a function directly invoked by `f`'s implicit definition; `f` allows all exceptions if any function it directly invokes allows all exceptions, and `f` has the _exception-specification_ `noexcept(true)` if every function it directly invokes allows no exceptions. [ _Note:_ It follows that `f` has the _exception-specification_ `noexcept(true)` if it invokes no other functions. _—end note_ ] [ _Note:_ An instantiation of an inheriting constructor template has an implied _exception-specification_ as if it were a non-template inheriting constructor. _—end note_ ] and [dcl.fct.def.default]/2.2: &gt; [ If a function is explicitly defaulted on its first declaration, ] it is implicitly considered to have the same _exception-specification_ as if it had been implicitly declared. So if you're composing types that are nothrow-moveable/assignable, then your type gets nothrow-moveability/assignability _without_ explicitly asking for it. To put it another way, _all_ special member functions are noexcept by default until you define one as not, or compose a type whose corresponding member isn't. The rule-of-zero would be useless otherwise. EDIT: formatting
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0095r1.html It is a shame that build-in sum types didn't make it into C++17. Instead we get the usual library hacks like std::variant.
Really good stuff, congrats! I've been working for a year or so in https://github.com/Manu343726/siplasplas, a reflection library for C++ very very similar to yours (Even the API is very similar). My roadmap is a bit different than yours though (I'm currently rewriting the parsing tool as a thin C++ libclang wrapper, hope to take some time to post here about it...), but as far I can see yours is more feature complete (For example, I don't currently handle function overloads in the dynamic reflection api) I love to see others approach to the same problem, and also help with my own experience if required ;) Just one question: the main difference I noticed between siplasplas and reflang is that you don't support static reflection ,(yet? I couldn't see it in your roadmap). In contrast, siplasplas API is built around static reflection, and then provides dynamic reflection on top of it. Do you have plans to provide an static reflection API? I'm sure there will be a lot of people here that would love to have it through your lib too. Again, congrats. Glad to see I'm not the only one that crazy
Thanks! I was not aware of your effort, perhaps I would not have started :) I'm not entirely sure what you mean by 'static reflection API', but if I had to guess I believe it's something I already have, for example: Class&lt;MyClass::Subclass&gt; metadata; MyClass::Subclass c; metadata.GetField(c, "field").GetT&lt;int&gt;() = 10; REQUIRE(c.field == 10); Is this what you are referring to? See: https://github.com/chakaz/reflang/blob/master/tests/class/subclass.test.cpp https://github.com/chakaz/reflang/blob/master/tests/class/subclass.gen.hpp
&gt; I feel like this is eating up a lot of the benefits of having a spin lock. You are performing a system call to get the time (cheap, but far from free) Note that on many modern systems (x86_64 wth RDTSCP; recent Linux/macOS, likely others) `std::chrono::high_resolution_clock`doesn't require a system call. Instead it uses the *read timestamp counter* (RDTSCP) instruction and applies a per-calculated ratio to convert to time. On my machine (OS X 10.11, Haswell) the following program gives a result of ~~100~~ 40 nanoseconds when you ignore the first value (setting up the correct ratio): #include &lt;chrono&gt; #include &lt;iostream&gt; using namespace std::chrono; int main() { auto t1 = high_resolution_clock::now(); auto t2 = high_resolution_clock::now(); auto t3 = high_resolution_clock::now(); std::cout &lt;&lt; duration_cast&lt;nanoseconds&gt;(t3 - t2).count() &lt;&lt; "\n"; } *Edit: Updated benchmark numbers and program to ignore first call to chrono::now*
Now, what would be awesome is to go a step further than reflection and provide easy ways to create new types at runtime, by modifying existing ones (copying their vtable, etc) and then monkey-patch them.
while this sounds awesome (really!) I consider it beyond the scope of Reflang :)
http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2016/p0194r0.pdf
I’m not sure I understand your question. There would be no pointer dereference to find the static_vector, but that would be true for a local std::vector too. Many operations on the elements of a static_vector would likely use a pointer, but that would probably be true for std::array too. In any case, some experiments with the compiler explorer would be the best way to answer any questions.
How about c++ 11, do you use that ?
I'll start by maximizing the usage of the stl. Before implementing anything search the reference to see if it's already been implemented in the stl. Little by little you should also gain confidence with the new language features. 
I would say the major thing is to learn how to use the STL algorithms, to minimise the code you write and help with maintainability. With lamdas they algorithm library is quite more powerful, than what it used to be. 
What is the purpose of this? template &lt;typename T&gt; bool IsT() const;
Copying from another reply... I do use a reasonable amount of STL in my codes, especially for data structures (vector, array, algorithms etc). My biggest source of confusion comes when people use templates and use the typetraits header to do some stuff. I hope I'm clear with this. Do you have any suggestions?
Meyers' "Effective Modern C++" book is probably what you're looking for. 
Indeed, type traits are often crucial to _implementing_ generic algorithms, but I wouldn't say that generic algorithms are limited to libraries. Really, understanding type traits is just a matter of understanding C++'s type system thoroughly, and that's something that applies to **any** non-trivial code that gets written.
A lambda would be fine there; the operator-wrapping functors in `&lt;functional&gt;` were far more important pre-C++11 when there were no lambdas in the language, though the comparison functors are still extremely useful for associative containers.
OK. But it does pique my interest for me to learn about it :) 
I would disagree, because few people can wrap operators transparently (and even if they can, it's verbose). `plus&lt;&gt;`, `multiplies&lt;&gt;`, etc. are more terse than lambdas can possibly be, and they're properly transparent. As my original paper argued, this is important for many separate reasons (avoids truncation/sign mistakes, respects move semantics, etc.).
It was [N3421](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3421.htm) which was accepted into C++14. Note that the transparent operator functors later gained `constexpr` (which wasn't present in the original paper because I didn't understand `constexpr` at the time).
"Effective Modern C++" is written *explicitly* for someone in your position. No "hello world"s, only "here's what's different now". 
Fixed, and thanks! I figured I would try putting the \*\*formatting\*\* into the template as we always have some posts that copy/paste from the OP post and don't add formatting. I couldn't find a way to add new lines to separate the sections without going to a code block. Maybe I'm missing something?
That's a very welcome improvement. https://www.reddit.com/wiki/commenting explains "Inserting a Blank Line" which basically cheats with a non-breaking space. It looks like this: &amp;nbsp; Meow.
There is a reference implentation for the proposal on Pierre Talbot's [github](https://github.com/ptal/expected).
this looks similar to an old paper that claimed you can't design a exception-safe stack :-)
I thought about comparing std::array here, but that is more targeted towards containers that do not change size. One of the goals of this project is to work towards a library that has resizeable matrices, meaning that std::array is not a good fit. It would be interesting to see where that lies though, as the framework provides should work for a matrix based on std::array, feel free to add it and submit a pull request!
Student here. I was hoping you could answer a few questions about your audio programming roles. To what extent is python used in your audio pipeline? Would it be possible for you to list some example tasks an audio programmer would be assigned? Would it be possible to talk to someone about my future career development in that specialization?
I looked at the links and I understand how the first one is relevant, because my matrix sizes are relatively small, so testing with larger matrices may lead to different results. I'm not sure if the second link though is relevant here, as I also test on matricies whose sizes are not related to powers of two (ie something like 27 by 27). If there is anything I'm misread, please let me know. I am tempted to do tests with larger matrices, do you think that would significantly change the results? 
The issue is _alignment mod_ powers of two, not size of powers of two. And that's alignment of the allocation, not just alignment of the type. Types with a 2^n size are just a lot more likely to encounter the issue.
Ah-ha! Alright, formatted it better now. EDIT: Hrm, apparently that was not needed.
A very minor nitpick but one I always like to make: all macros names containing a double underscore, or beginning with an underscore followed by a capital letter, are reserved for the use of the implementer. See [lib.global.names]. Therefore using `#define __MATRIX2D_HPP__` in your own code is undefined behaviour. I am sure people have good reasons to do it but since this is a pedagogical article I thought I would remind other readers that the code may in principle not be portable. 
Thank you, I've heard that before, but never got over the habit, I plan on kicking it asap!
Pretty sure in one of his talks he says there is an implementation in Facebook's Folly library.
I've been kicking a similar idea around in my head for a while now, and reading this post got me inspired enough to hack up a 0.1 version: https://github.com/mtklein/ob. It requires Python 2.7, Git, Ninja, and GCC or Clang. It doesn't do quite everything you're looking for or in quite the same way, but it may be fun to look at. Basically, it builds your project in one of five different modes (default, debug, release, ASAN, TSAN) and runs any unit tests it finds. Using Ninja under the hood means builds run in parallel and incremental builds are efficient. I wrote and tested that on a Mac with XCode's clang and gcc 6.2 from Homebrew. Linux and other similar systems might work, probably after a little coaxing. If you're familiar with Python it shouldn't be hard to hack at. Some follow up ideas I'm thinking about: - MSVC support; - Android NDK support; - static and shared libraries; - built-in benchmarking harness; - dependency tracking based on exported symbols instead of header includes; - a way to learn about external libraries and how and when to link them.
I implemented one for WebKit as well: https://github.com/WebKit/webkit/blob/master/Source/WTF/wtf/Expected.h
It would be interesting to compare this to matrix from [Eigen](http://eigen.tuxfamily.org) library.
Python is used for the build system only, but that is still a critical component of the engine as everything is data driven (like most game engines). If you have used Unreal, their cooker is like our build system. Since audio content is data, you'd have to understand it. Audio programmers work with sound designers who make the content, so you work with them to make their lives easier or invent new features. For us that means: * Upgrading to newer FMOD versions * Making existing features easier to use / fixing bugs * Adding new engine functionality * Writing DSPs An example task might be "make vehicle wheel noises sound better/work at all". This will require learning more than you ever thought there was to know about wheel physics, and then providing a way that designers can make good sounding content, taking into account different ground materials and vehicle types, all while maintaining an inexpensive runtime cost. The acceptable runtime cost is also going to depend on the game. If you were making a racing game then your wheel audio budget is going to be pretty high. If you want to pursue audio programming as a career it's a relatively difficult position to fill so you would be in high demand across the industry. But it's fairly hard to specialize in, you have to get familiar with every part of the game to do it effectively (like the wheel noise example above). The ideal audio programmer is really a gameplayer/engine programmer who cares a lot about audio. For more details feel free to PM me or just reply to this thread.
What exactly were the assumptions that these results challenge? Perhaps I'm misunderstanding, but it seems like everything checks out: with release-level optimizations, the overhead of the STL container disappears as it's designed to.
An allocator should make that easy-ish?
Networking isn't "just code" in that it requires hardware/os support. Wrapping some set of common C APIs in a single cross platform set of C++ types is "just code". 
Not just macro names, but any identifier.
I also have some questions that I hope you're able to answer. When you're hiring a developer, how much does side projects weigh when deciding who to bring in for an interview (and ultimately to hire) compared to actual work experience? I'm planning to move to Skåne later this year and I'm hoping to find a job at a game studio there but I'm very anxious about the fact that I don't really have any personal side projects to show. I studied game programming at BTH so I do know some 3D programming and I did some bigger 3D game projects there as well. I've also been working as a C++ programmer at a company making slot games for the last 3 years so I'm very familiar with the whole process involved. Do you think that's enough for me to have a chance at a AAA game studio or should I start working on side projects as well? I understand that it's very hard to guess what other game studios' look for but it would be very helpful to get some insight on how it is at Avalanche. Edit: For some reason I assumed that you were working at the Stockholm studio but I realize now that you might be working at NYC. I was kind of hoping to get some more insight at a Swedish game studio but any answer would still be great. 
Thank you for sharing. That's an amazing article - very detailed and methodical with interesting results!
I can't speak for Avalanche but when I first started in the industry my coding ability and side projects / open source contributions (openttd) were more valuable than my games programming degree. After that first job people only looked at experience. Also investigate what game engine (UE4/Unity etc) is used by whichever companies you are looking to apply to and get experience with it if possible. Part of my original portfolio was Unreal Tournament _modding_, which gave me UE2/3 experience, which was great when I was applying to a UE3 studio. If they don't use an open engine, but they have games with a modding API, try it!
Yeah, yeah. Except that C++17 was expected to be a major release. We can have argue about whether not being a major release is better or not in the long run, nothing wrong with that. But it is normal that right now a lot of people feel [disapointed](https://www.youtube.com/watch?v=Djlc6uHTVmY) about it. 
Creates a constexpr [`std::string_view`](http://en.cppreference.com/w/cpp/string/basic_string_view) with length 11 (not 12).
Thank you for the answer. I actually have played around quite a bit with both Unity and UE4 but never to the point where I actually have something to show. I think most of the studios I've been looking at use their own engines but modding actually sounds like a great and fun idea!
Now it has a readme, and the commit messages are in English! :)
Did you actually use concepts? Maybe I'm just lacking the experience in how they should be used, but so far they've far less of a magic silver bullet than people usually claim them to be. A nice addition for sure, but they don't save you from thinking very hard about your template code.
std::vector does add additional level of indirection. It does not matter if the pointer to data is a member or not. Here's a simplified Compiler Explorer piece to illustrate the concept: https://godbolt.org/g/xOzC6l Notice how in the vector case the pointer has to be loaded into a register before it can be used? This is the definition of indirection. The array can be accessed directly as it's offset in the object is "known"; in this case it is 0, so it has same address as the array object's address. If there was member data before the array a constant offset would be added to the address. x86 has optimization in the encoding; if the offset is 0, the constant does not need to be stored but that's just trivia. In practise it doesn't make much difference in a toy benchmark as the same memory is hammered repeatedly. In a more dynamic environment like live software the data would come from different cachelines and the vector case, especially with smaller data, would suffer for every access to every vector. Especially small matrices with fixed-size should be using the array form, definitely. 
Pretty much what TheThiefMaster said across the industry. I'm in NYC so I can't really speak for the Stockholm office. (I can only represent my views too, not the NYC office in general. I'm just a dev here not management). Projects that you make for school are fine, if you show some creativity and passion in those. Working on slot machine games has valuable transferable experience too. We have hired many people with similar experience levels, so yes there is a chance. Working on side projects will just improve your chances. And if you make a really good side project, you could sell it and skip the whole working for other people stage entirely.
You should do a block delete in the array destructor: delete [] data; Yes, of course those would be identical as your "Array" is more like std::vector, not std::array, or array of any sort; it is using dynamic allocation. std::array uses intrusive storage so it does not have indirection to the data.
Could any one post a tldr please? Don't really have the bandwidth to go through the entire video!
This works for doubles, but not `std::complex&lt;double&gt;`, as the default ctor of the latter also zero-initialises the object. Hence while it is possible to match the behaviour of `new[]`, you don’t actually want that behaviour if you really want to avoid the initialisation.
&gt; The advice &gt; &gt; ... &gt; &gt; On GCC 6, compile with -D_GLIBCXX_CONCEPT_CHECKS Didn't know such a thing existed in GCC! Unfortunately, the [libstdc++ documentation](https://gcc.gnu.org/onlinedocs/libstdc++/manual/concept_checking.html) states that: &gt; the checks are based on the requirements in the original C++ standard, many of which were relaxed in the C++11 standard and so valid C++11 code may be incorrectly rejected by the concept checks. Additionally, some correct C++03 code might be rejected by the concept checks, for example template argument types may need to be complete when used in a template definition, rather than at the point of instantiation. There are no plans to address these shortcomings. Sad :(
Yeah but the person I linked to calls his own library 'naive', does that mean he does know there's a better solution?
A naive implementation is an implementation that has taken shortcuts for the sake of simplicity or by lack of knowledge. It will not take account for all the possible uses cases or don't try to fit in every situation.
This is one of that words that means different things for different people. I usually understand it as: simple, trivial, ordinary, not fancy
I was there. Great event which I definitely recommend. It takes place in Wrocław, Poland (beautiful city!). I'm not saying your statement is not true, but in my opinion everyone was just trying to pay attention. It was quite early in the day and in the middle of the week - people were just warming up :) 
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/5lmxiy/how_to_make_game_in_c/dbwuyfx/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Personally I've stopped caring for conformance and I just use `#pragma once`...
But I dont get how that works from a syntax point of view, you say "typename T" but then you dont use T anywhere? What does T refer to?
Even testing against different versions of the same compiler picks up a decent amount.
**Company:** Optiver **Type:** Full time **Description:** At Optiver, a proprietary trading firm, we need the most advanced technology and continuous innovation to remain successful as a global market maker. We build high-performance software that is used by our own traders to trade a variety of financial instruments on exchanges. Our story begins in 1986, with a single trader on the floor of Amsterdam's options exchange. Today, we are at the forefront of trading and technology, employing around 1000 Optiverians of 40 nationalities across offices on four continents. ****Jobs @ Optiver**** * [Graduate Software Developer](http://www.optiver.com/amsterdam/careers/jobs-and-events?gh_jid=510831&amp;gh_src=6c0pe11) * [Software Developer](http://www.optiver.com/amsterdam/careers/jobs-and-events?gh_jid=510832&amp;gh_src=7karyx1) * [Trading Software Engineer](http://www.optiver.com/amsterdam/careers/jobs-and-events?gh_jid=510825&amp;gh_src=d0gtnc1) **Location:** Amsterdam, Netherlands **Visa Sponsorship:** Yes **Remote:** No **Technologies:** C++14 on Linux, next to that C#, Python and Lua and FPGAs also form part of our technology stack. **Contact:** Please e-mail Jan Bernhart or Cátia Sousa at recruitment@optiver.com for any questions. For more information about our jobs and events, click [here](http://optiver.com/amsterdam/contact/jobsevents/).
Not sure if this is the same issue you have, but if I modify the text I get this as an output: ERROR: Parsing Failure: line 4 (column 2): std;\nint main() {\n \xA0cout &lt;&lt; "Hello Worl -----------------------------------------^ Expected "!", "&amp;", "'", "(", "*", "+", "++", "-", "--", ".", "/*", "//", "0", "0X", "0b", "0x", ";", "L", "R", "U", "\\U", "\\u", "_Bool", "_Complex", "__attribute__", "_stdcall", "auto", "break", "case", "char", "const", "continue", "default", "do", "double", "enum", "extern", "false", "float", "for", "goto", "if", "inline", "int", "long", "register", "return", "short", "signed", "sizeof", "static", "struct", "switch", "true", "u", "u8", "union", "unsigned", "void", "while", "{", "}", "~", [ \n\r\t\u000B\u000C], ["], [0-9], [1-9], [A-Z], [_] or [a-z] but "\xA0" found.
Because then you're testing against different versions of the standard?
It's in the LLVM code base as well. (Or a variation anyway). 
'Naive' is the correct word. It has nothing to do with 'native'. The actual meaning in programming isn't terribly concrete, but essentially it refers to when you use a very straightforward, simple approach to a problem that either doesn't take advantage of that problem's unique parameters or doesn't account for the problem's unique pitfalls. It's not specifically a C++ term, it can show up all over the place in programming and theoretical computer science. To illustrate, consider the problem of making exact change for a given amount of money with as few individual coins as possible. When I actually do this with canadian money, it's easy: I take out as many of the largest denomination that fits as I can, and keep doing that with successive denominations until I hit pennies. (Well, we don't use pennies anymore, we just round everything to 5-cent increments, but you get the idea.) For instance, if I had to make $4.87 in change, I'd start by taking out 2 toonies (to get 87¢), then 3 quarters (to get 12¢), then a dime (to get 2¢), and finally two pennies, for a total of 8 coins. So if I were writing an algorithm to do this for arbitrary amounts and arbitrary sets of denominations, I might have the algorithm use that same technique, just count down the denominations taking out as many of each as possible. That would be the 'naive approach'. As it turns out, while this always works for actual canadian currency and many other real-world currencies, there are possible sets of integer denominations for which it *doesn't* always work. If I had denominations of 119¢, 80¢ and 1¢, making $4.87 in change using this approach would take 15 coins (4x119 + 11x1), but better possible answers exist (e.g. 6x80 + 7x1 for only 13 coins), so the naive algorithm fails. If you google 'naive algorithm' or 'naive programming' you'll probably find more discussion of the term.
Since the reflection data is accessed at runtime (dynamic reflection), and C++ is a statically typed language, you have to wrap the values returned through the reflection API in a kind of heterogeneous type-erased value wrapper type, i.e. std::any. The method isT() is there to be able to check if the underlying value has a given type. For example: struct Foo { int bar; }; Foo foo; // Take a "pointer" to Foo::bar member variable auto&amp; field = reflang::Class&lt;Foo&gt;::getFieldByName("bar"); // Take the value of field Foo::bar of object "foo" auto value = field.get(foo); assert(value.isT&lt;int&gt;()); std::cout &lt;&lt; value.get&lt;int&gt;(); In the example above the compiler doesn't know the type of the field value, since the Field type and the values Field::get() returns are heterogeneous. What Field::get() does is to return something similar to std::any. Then we check that the returned value has the type we expected (int) with value.isT&lt;int&gt;(). What isT&lt;T&gt;() is doing under the hood is to check if the given type matches the current type of the value. The easiest way to implement this is to tag your value wrapper with std::type_info/index and do _type == typeid(T) or something like that (You don't usually do that since nobody wants a building block type such as any relying on RTTI...).
&gt; Smart pointers are about triple the space and take slightly longer to follow This is untrue. `unique_ptr&lt;T&gt;` has (always in practice, although not formally guaranteed) the same space and time costs as `T *`. On the other hand, `shared_ptr&lt;T&gt;` is the size of two raw pointers (again, de facto) and pays an additional space/time cost for the refcount control block. It imposes zero overhead when dereferencing, though.
Fair enough. The "about triple" was from me doing some quick-and-dirty tests with shared_ptr where most of the pointers were unique, thus each having their own control block. I'll make sure to remove any indication of my expectation of the costs and have the students measure these directly for shared_ptr, weak_ptr, and unique_ptr (the last of which I agree should not have overhead.) Thanks!
Unless you're using MSVC, even the 2017 RC or the daily Nuget package. _\*cough\*_ /u/STL _\*cough\*_ ;-]
And also remember that `make_shared` decreases the overhead significantly (with an extra bonus when the We Know Where You Live optimization is implemented).
Ah -- this I didn't know, but it makes sense. I'll add it as an extra aspect that the students can choose to test. 
That stuff was *just* voted in. Be a little patient! As we've marched towards 2017 RTM, I've actually focused most of my energies on things other than C++17 conformance. Notably, I took over a month to thoroughly overhaul `vector`, and more recently I've been auditing the STL for warning cleanliness with the help of libc++'s tests. This is important stuff for the long term, but it doesn't fill C++17 feature checkboxes.
A naive algorothm is one that is simple and obvious in description and execution. Nothing tricky, nothing fancy, nothing particularly wise. Claiming an algorithm is naive is not an insult, but it may sometimes be used as a baseline to a more complex and optimal solution. It is staring that you are making no claim it is optimal, nor was a lot of effort put into checking if it is optimal. As an example, I might write a naive std function that always heap allocates, or fails the strong exception guarantee, or doesn't optimize for stateless functions that match signature exactly. These are all "corner cases" or fancy optimizations that a less naive implementation will cover. Understanding a solution that does all of that will be way harder; the naive implementation is actually the correct one for most problems!
It's not to help the implementor, it's to help the user who theoretically gets a much improved error message when they pass an invalid type. (It helps implementors who have the burden of committing to good error messages with current tools, but that's not really the point.)
TL;DR: `__TIME__` is the seed. Other than that, it's not surprising that a deterministic RNG can be implemented as constexpr.
Not to my knowledge (and from reading &lt;array&gt; in VS2015), plus [CPPReference](http://en.cppreference.com/w/cpp/compiler_support) also disagrees with you. (search the page for N3470)
Not to your knowledge what? Disagrees with me about what? Non-const `std::array::operator[]` isn't constexpr in MSVC; it is in C++17.
Are you quite sure about that? `std::array` looks to have been constexpr since VS14.0 came around - it's part of C++14 after all.
[P0031R0](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0031r0.html) added more constexpr to array for C++17, which we haven't fully implemented yet.
Aaaah, OK, my mistake, absolutely.
Yes, of course. I wasn't aware that it was the C++17 additions specifically that were lacking.
Yep, I was basically comparing the access times for those two implementations!
Looking at the etymology, naïve and native actually come from a common source. And given the meaning, it makes sense - naïve is being ignorant of a topic as a result of not having encountered it yet. In other words, your 'native' state at birth.
And that is never going to change unless someone invents a time machine to go back to 1993, when Unicode 1.0 was implemented and `wchar_t` was set at 16 bits in our ABI. This is not an issue we have the luxury of fixing. If you want UTF-32, use `char32_t`, which (I'm assuming) was created specifically to address this time machine problem. I don't see what this has to do with `codecvt`'s 1:M assumption beyond making issues more likely to occur with `wchar_t`. But since the issue occurs attempting to output the world's second most common legacy encoding (latin-1), I don't really see ABI limitations as the serious problem here. ICU is widely regarded as the gold standard of Unicode handling and it uses UTF-16 internally -- this is a solvable problem. But I don't think it is a solvable problem within the framework of iostreams' explicit and standards-mandated internal character by internal character buffering.
Note that your `auto c = L'💩'` example breaks down if you replace 💩 with P̯͍̭. Even UTF-32 does not allow you to operate on a character by character basis in a Unicode world.
This. Buddha know this as well. ;}
I agree, GC is a big negative in my book.
Not sure why someone would downvote Boost, as many of Boost's features have now made it into the standard.
For testing header only vs header+code, it would also be good to test with whole program optimisation turned on/off.
char32_t everywhere would indeed solve the problem (at the cost of migrating code), but the Portland 2006 LWG decided that streams, facets, and regex don't need it. basic_filebuf's (not codecvt's) 1:M assumption works in Linux and does not work on Windows. There are no issues with Latin-1. There would be an issue with that imaginary codecvt facet you brought up, yes, but I am talking about the code that works now.
These are all interesting topics, but I wouldn't classify most of them as "algorithm engineering" Most of them seem like investigating the tradeoffs of implementation-specific constant factor speedups. Maybe I don't know what the syllabus says the class should cover, but based on the title I would look at things like comparing hash functions and hash table algorithms (round Robin vs linked list), various algorithms for stuff like DP problems and writing heuristics for NP complete problems. Compare strassens to naive matrix multiply, radix sort and fast selection. Compare different kinds of trees and tries
Thank you for posting this!
Amount of instructions / speed. Example: B-trees take a lot of code to implement properly, but they're the fastest trees out there. How does a way bigger amount of instructions result in a faster data structure?
maybe string vs custom implementation that allows slicing? Something like copy on write would be useful.
The ptal repo is very out of date. The up to date reference implementation for LEWG expected&lt;T, E&gt; can be found at https://github.com/viboes/std-make/tree/master/include/experimental/fundamental/v3/expected. Closely related to expected&lt;T, E&gt; is proposed Boost.Outcome which ought to land in the Boost peer review queue before ACCU 2017 in April. Its documentation is a mess, but at least it has some unlike the expected&lt;T, E&gt; implementations and you can find it at https://ned14.github.io/boost.outcome/. outcome&lt;T&gt; (or rather result&lt;T&gt;) quacks quite like an expected&lt;T, std::error_code&gt; and ought to be typedef swappable in 98% of code. Outcome is however a family/factory of mongrel monad types, unlike expected&lt;T, E&gt; it's policy driven and has all the power and template fun you'd expect of a Boost library. It's also SG14 (low latency/gaming/trading) friendly, unlike expected&lt;T, E&gt;. See its docs for a lengthy explanation of the differences, and yes I'll be rewriting those docs entirely before the review submission, it's the last todo remaining.
Is it correct that the sanitizers still do not work on windows? At least the main page still shows them as being not supported although i did find a windows port which states it doesn't support C++. I am already using clang-format and clang-tidy already and they work great.
 string_view sv = ... int num; auto res = from_chars(begin(sv), end(sv), num); `std::from_chars` only accepts `const char*` as parameters and `decltype(begin(sv))` is implementation-defined.
Why don't you create one? Simply specialize the `std::hash` struct in `namespace std`.
I figured they were just going to use a const as the seed.
Absolutely right, thanks for the clarification. This example was based on the implementations of begin/end on clang and gcc. On MSVC it does not work, indeed.
http://stackoverflow.com/questions/8157937/how-to-specialize-stdhashkeyoperator-for-user-defined-type-in-unordered
&gt; it tends to only talk about ‘acquiring memory’, not actually constructing objects. fixed (if you were talking about [vector#Template_parameters](http://en.cppreference.com/w/cpp/container/vector#Template_parameters) )
I thought about this for a while and decided not moving elements to the front in the access methods would make the lookup faster. Also often "LRI" is actually good enough or preferable. I was hoping people would share their thoughts. I could also add a boolean switch to make it optional.
Thanks for recommending Meyers' book. I've found it quite useful. 
IIRC you must not specialize anything in namespace `std` unless that specialization depends on a user-defined type. i.e. `hash&lt;pair&lt;int, int&gt;&gt;` must not be specialized as it does not depend on a user-defined type.
Correct. Get off my lawn.
Good idea. It's easy to accidentally disrupt (or just not make use of) NRVO, plus many of the students might not be familiar with it but *should* be.
We won't be covering image processing in this course, but some of the students should have taken it. I can easily imagine having a set of special topics that they can choose if they're familiar enough with the background. That said, many of these filters could be applied to other types of data matrices as well, and the principle shouldn't be too challenging.
Another link with a more specific implementation: http://stackoverflow.com/a/19740245 But keep in mind that, as STL mentioned, the standard's intention was not to allow specializations that do not contain a UDT. The actual meaning of UDT (user defined type) is a bit ambiguous, though. 
Do you mean VC 2012 (IDE version 11) or VC 2013 (IDE version 12)? (Yeah, MSVC's version numbers are confusing.)
LRI can easily fall into pessimal usage patterns. It'll periodically evict the most used items, which kind of defeats the purpose of a cache. Also it makes your post have a clickbait title as it's neither LRU or feature complete. LRI is easy to implement. LRU is much harder to do right. I guess using a linked list would speed up the moving up to front phase (with pre-allocated nodes of course), so you don't have to change your design too much. 
Oh my god, I needed this.
**Company:** [Christie Digital](http://christiedigital.com) Yes this post is just like last quarter and the previous etc - because people keep asking us to do impossible things and we keep delivering, so they of course ask for more, so we continue to expand... **Type:** Full-time **Description:** We make digital projectors based on DLP technology. But the real interesting stuff is projection mapping - taking a bunch of projectors and stitching them together to make a single canvas, and projecting onto screens, buildings, 3D models... [almost anything](https://www.youtube.com/playlist?list=PL7CBEC9E4CFDB1FD9). Basically, [we paint with light.](https://www.christiedigital.com/en-us/projection-mapping) We are looking for experienced C++ devs that like pixels and math, machine vision, machine learning,... But really, the most important thing is just _good coders_. Coders that can make abstractions and write clean code. (maybe "we are looking for C++ devs who like _functions_ and _classes_" wow!). I assume you can figure out the domain-specific stuff once you get here. **Location:** Kitchener-Waterloo, Ontario, [Canada](http://www.usnews.com/news/best-countries/quality-of-life-rankings) **Remote:** Unlikely. **Visa Sponsorship:** Unlikely. **Technologies:** We are currently mostly using C++11/14 under Windows (MSVC 2015). As we now have a member of the C++ committee on the team (that you get to work closely with! - even less exciting than it sounds!) we are pushing forward towards the latest standard. We also like Boost (of course). And OpenGL and other 3D technologies and open source libraries. And I have to admit (sorry) - knowing Javascript wouldn't hurt either. Seems to always be a web angle somewhere. **Contact:** check out our [job postings](https://www.christiedigital.com/en-us/about-christie/careers/canadian-careers); in particular, the [Projection Mapping](https://apply.hrmdirect.com/resumedirect/ApplyOnline/Apply.aspx?req_id=435003&amp;source=435003-CJB-0) posting. For imaginary bonus points, figure out the email address I use on the boost lists, and email me at that address. Or some other email address of mine (I have plenty), besides my all-too-obvious gmail one.
My point is that in a Unicode world you cannot operate on a code point by code point basis. Doing so will chop combining characters in half. Since Unicode already gives up on fixed-width characters, you may as well use UTF-8.
There are Linux implementations that turn U+0065 U+0301 into latin-1 é?
You can move nodes between lists without allocation via [`std::list::splice`](http://en.cppreference.com/w/cpp/container/list/splice). Also, I think you mean *intrusive* containers. There's a convenient implementation in [Boost.Intrusive](http://www.boost.org/doc/libs/1_62_0/doc/html/intrusive.html).
The idea is that iterating using something like `IterateFields` is a _runtime_ enumeration of fields, rather than a compile-time one. It also means that every single type needs to have this runtime metadata baked in rather than only compiling in the actual functions necessary. Given that a lot of us mandate `-fno-rtti` in our projects, adding in a huge chunk of runtime reflection metadata when all we need is serialization support for a few dozen classes is just a non-starter. :) For instance, I might want a template like so (using a terrible template language we've used before, because there aren't any good off-the-shelf ones for this use case that I know of): ## for type in types where exists(m for m in type.members where m.attributes[serialize]) void serialize({{=type.qualified_name}} const&amp; value) { // all public serializable fields ## field for field in type.fields where field.public serialize(value.{{=field.name}}); ## end // all member functions marked as a property getter ## func.attributes[property] for func in type.functions where exits(func.attributes[property]) serialize(value.{{=prop.getter_name}}()); ## end } ##end A real example would likely be a fair bit more complex, but that's the gist of the idea. The process for compilation might then be: 1. generate a list of metadata for all type in a separate file 2. run a template processor over those inputs to generate new sources 3. compiler those sources 4. link the objects from hand-written and generated sources together There's all kinds of ways to make the above work. For instance, instead of the "iterate over all types and see if they're serializable" approach I've seen before, what I'd _really_ like is something like: template &lt;typename T&gt; [[reflection::generate("serialize.cpp.tpl")]] void serialize(T const&amp; value); The big advantage there is that all existing IDEs that support templates and C++11 attributes would recognize that as a declaration of a function and so provide proper autocomplete/refactoring support. The reflection system can then use it to know which types to generate the function for (based on the instantiations of that function), and even use it to provide additional metadata from the attributes or name (for instance, the referenced `serialize.cpp.tpl` file might use the function name of the declaration rather than hardcoding it, so the user can decide if their serialization function should be called `serialize` or `Serializer::operator()` or whatever they want.
[Link to part 1](https://blogs.msdn.microsoft.com/oldnewthing/20170102-00/?p=95095)
Code that self-modifies data structures has all kinds of problems aside from the "it doesn't work" part. One of those problems is that it makes optimization a lot harder, e.g. offloading to threads or to a GPU. For the specific example of particle systems given in the article, for instance, I'd almost certain recommend instead that you have two buffer - a read-only `current` and a write-only `incoming` - and that any add operations push into `incoming` and that all particles in `current` must be pushed into `incoming` as well unless they are to be intentionally lost/deleted. Afterwards during a clean synchronization point, swap `current` and `incoming` and reset the new `incoming`'s write position to the head. That makes iteration _super_ cheap and matches exactly how the buffers should behave for GPU overloading, as well as being efficient for CPU multi-threading as it requires only a single atomic variable and no locks. In general, I'd say that if something is as intrinsically problematic as mutating containers during iteration, you probably shouldn't paper over it - you should just stop doing it. :)
The compiler that comes with Visual Studio 2013. I might have gotten mixed up with that Visual Studio 2013 version 12 cl 18 stuff. :O
**Company:** [FireEye, Inc.](https://www.fireeye.com) **Type:** Full time **Description:** We are building the endpoint agent platform that powers threat detection and mitigation across Windows, OS X, and Linux endpoints. **Location:** Charlotte, NC **Remote:** No **Visa Sponsorship:** Negotiable **Technologies:** Our product is comprised of C (kernel code), exception-denying C++98/03, C++98/03 using libraries like Boost, and C++11/14. We are focused on C++11/14/17 and modern libraries as we move forward. Python 2 is used extensively for test code. Other tools we use regularly are git, CMake, JIRA, and Test Rail. **Contact:** Feel free to PM me here if you are interested or have questions. [Apply directly](https://www.fireeye.com/company/jobs/jobdescription.html?gnk=job&amp;gni=8a78824757ad01950157af090af350c8&amp;jobtitle=Senior%20Staff%20Software%20Engineer&amp;loc=United%20States%20Charlotte%20NC%2028202).
Yeah. Static reflection like theirs has an important place in the language ecosystem, but it's not a solution for everything.
Effective C++ was released in 2005. From what I remember, it covers most of what you need to know up to C++03. Effective Modern C++ was published in 2014 and covers C++11/14 features. Both are excellent books, the latter is just more relevant than the former. 
It's not garbage, but you do have valid points. Your points will weigh more if you don't insult the article/person.
OK so you mean 'newer' version, not 'different'.
This seems interesting, can you share the code?
But then you have more levels of abstraction to grok.
&gt; Take abstract factory as an example, in what case do we indeed require such a complex structure just to create an object? Let's say that you are writing a 3D app, like 3DS max or Cinema 4D. In this app, you define a number of base shapes that the user can use for their designs : cubes, spheres, cylinders, etc. So you have this nice little menu "Shapes" with the list of shapes in your system, you click on the name of the shape and it adds it to the 3D scene. A shape has a very simple interface : struct Shape { virtual void draw(Screen&amp;) = 0; }; In the `draw` method there are generally some OpenGL calls. Now, you want to allow your users to add new kinds of shapes, through a plugins, and maybe even make a plug-in marketplace where users can just go to a website, see all the available shapes, like "bridge", "fluid simulation", etc. where you sell plug-ins to have some nice income. So you have to : * Load a class from this plug-in * Have this class add itself to the "Shapes" menu so that users can instantiate it by clicking on its name. * When the user clicks the button, an actual Shape instance has to be created. This is what an abstract factory does. You have : struct ShapeFactory { virtual std::string name() const = 0; virtual std::unique_ptr&lt;Shape&gt; create() const = 0; }; and for instance in a plug-in : struct FluidShape final : public Shape { void draw(Screen&amp;) { ... } }; struct FluidShapeFactory final : public ShapeFactory { std::string name() const override { return "Fluid Simulation"; } std::unique_ptr&lt;Shape&gt; create() const override { return std::make_unique&lt;FluidShape&gt;(); } }; Then, at some point you have to know the list of all available shapes so that you can show them in your menu : struct ShapeManager { ShapeManager() { /* Load the ShapeFactories from all the DLLs */ } std::unordered_map&lt;std::string, std::unique_ptr&lt;ShapeFactory&gt;&gt; shapes; }; And the user, well he just clicks "Download" on the plug-in marketplace, the dll goes to the `plugins` folder of your software, you `dlopen` it and the new `Shape` can even add itself to the menu at runtime. 
I use the term 'naive' to differentiate between code I wrote 'to just work' or 'just for fun' without researching about better or more optimal algorithms I could implement... It just means I don't expect it to perform well in your data centre running massive computations. In other words, it's not 'production quality' but more 'hobby quality' so don't come back complaining when you misuse it...
Huh, TIL.
adjacent_find is still clumsy, because you still have to apply it in a loop to count the total. `count_if` with overlapping ranges is a better answer, IMO.
Thank you :)
&gt; I recognize that since C++11 functors have mostly been replaced by lambdas but here we need to give a name to the thing. auto FartherThan = [](auto&amp;&amp; cities){ return cities.first.getGeographicalAttributes().getLocation().distanceTo( cities.second.getGeographicalAttributes().getLocation()) &gt; MaxDistance; }; Behold, a named lambda! &gt; Doing this elegantly with a lambda requires a bit more work Nah. In fact, you don't even need a lambda; a regular function would work just fine, since `MaxDistance` is global.
I always had the LRU implementation ready, I had no bad in mind. The order is maintained in a linked list of references and I splice nodes, so there's no data duplication and moving to the front is fast.
&gt; Except that linked lists tend to be allocation-heavy Really? Moving a node's position inside the list should be O(1) with no allocation. Actually, once you've got the node wrapper for your data element, what allocations need to be made? I mean, I'm sure some *are* made in the `std::list` implementation... but algorithmically, I don't see that it's necessary, or that it's a property of linked lists themselves.
**Company:** [Microsoft Visual C++](https://www.visualstudio.com/vs/cplusplus/) **Type:** Full time **Description:** The Visual C++ team builds compilers and libraries for the Windows platform, but also is building a great IDE experience for every platform from Linux to Android and iOS. With the [Visual Studio Code](https://code.visualstudio.com/) editor (and C++ plugin), we’re also now focused on building a great code focused editor experience for C++ that runs on Windows, MacOS, and Linux. We aspire to make the best development tools for *every* C++ developer. Our team has several positions to fill on several crews. We need a new developer for our Static Analysis team, which develops the /analyze compiler switch, the new C++ coding guideline checkers, and guideline support libraries. We also need developers to work on our IDE scenarios including our new CMake experience, our Linux and IoT targeting tools, fast and scalable IntelliSense, and the VS Code C++ extension. Since we have a few positions to hire, we can be a little flexible on experience level, but we’re mostly looking for 4 years of professional development experience or higher. **Location:** Redmond, Washington **Remote:** not at this time, sorry **Visa Sponsorship:** yes **Technologies:** C++ (latest) and some C#. We do a large portion of the development work on Windows as you’d expect but there is enough cross-platform work going on now that knowledge of other OSes can be quite beneficial. **Contact:** PM me and I’ll route you. 
Yes, I have a preference for SFML, but SDL remains poplular despite being in C. It has been promoted by Valve employees which may be one factor.
**Company:** [Akamai Technologies](http://www.akamai.com/) **Type:** Full Time **Description:** Akamai operates a [large content delivery network](https://www.akamai.com/us/en/about/facts-figures.jsp) of ~220,000 servers in ~120 countries connected to &gt; 1500 networks serving over 30 Tbit/sec of traffic. Additionally we have several other products which take advantage of our size and reach. The positions I'm most familiar with are in the mapping group which writes the software used to identify and load balance users using a modified stable marriage algorithm. Of particular interest at the moment is a position working with BGP. I believe there is also a DNS position as well. The other positions are more general. The ideal candidate is a senior level person with 5 years experience, 3 years and a masters or a PhD with relevant experience. Applicant does **not** need to be a computer scientist (there's a chemist, a few physicists and any number of mathematicians of various educational levels). **Location:** Cambridge (Boston) MA, US. **Remote:** No **Visa Sponsorship:** Unsure **Technologies:** C++ with a lot of work transitioning into C++11 (and some C++14/17), mostly GCC on Linux. Plenty of boost usage. **Contact:** [Akamai Jobs](http://jobs.akamai.com) is the jobs portal but you can PM me for details specific to the mapping positions. Jobs in the Mapping group will be identified in the job posting. If something else looks interesting feel free to PM me and ask away, I can share what I know. 
i think you missed the point of a mutex library; if i have to chose between 4 different mutexes, then i'm still doing all the work a library should be doing.
You're right, that was uncalled for. I changed it.
I think you may be writing higher level C++ code, because there is no one-size-fits-all when it comes to synchronization primitives. Different platforms have different costs associated with locking. Also real-time, time-critical applications really benefit from different mutex implementations.
As someone currently learning the ins and outs of C++, this is really interesting and educational. Thank you.
It's four classes. A tiny amount for a library I'd say.
What is there not to understand about input UTF-32 U+0065 U+0301 needs to be mapped to latin-1 `é`? Operating on a codepoint by codepoint basis would produce `e?`. Any string manipulation which wants to, for example, split a Unicode string in half, must verify that it isn't splitting a character like that in half. The first half will have the wrong character, and the second half will be outright invalid.
I just checked the Redis code base and it uses an interesting approach to LFU (uses a logarithmic counter) and it should be better than the LRU approach that was in use earlier. 
Thanks for your comment. This useful insight made me realize that using a global constant was wrong: MaxDistance needs to be visible only within the computeNumberOfBreaks function, so a static local constant is much more adapted. In this case the job can no longer be done with just a function as opposed to a lambda/functor, although you were absolutely right about the code with the global constant. Anyway thanks for your valuable insight, I updated the post accordingly. As for named lambdas, I'll be happy to pursue this discussion. Let's talk about it on Jan 20th we the dedicated posts comes out.
(I use the cutting in half example because that's what iostreams wants to do; but even simple find and replace is broken by this -- A user asking to replace e (U+0065) with x (U+0078) given input U+0065 U+0301 must produce U+0065 U+0301 (unchanged), *not* U+0078 U+0301 (which is what you get with codepoint by codepoint operation) -- which UTF you're looking at is a tiny tip of an enormous iceberg)
In general I agree with you - that is why this was added as an extension and not in the main library. :) However, I think the basic erasing case still benefits from this iterator method: https://github.com/dtrebilco/Taren/blob/master/Articles/EraserProfile.md Jonathan Blow probably explains it better than I can. https://youtu.be/-UPFH0eWHEI?list=PLmV5I2fxaiCKfxMBrNsU1kgKJXD3PkyxO&amp;t=2017 
No offense, but you are a bit naive about thinking that the std library, or any other library, can offer a *universal* solution. I have a similar experience to the author of this post. To make it short: * yes we can get better performance by using custom mutexes. * the best solutions are not the same on Windows / Mac. * during spinning, I call SwitchToThread() on windows, and usleep(1) on Mac * All that was related to thread pooling: the number of threads is also to limit to the number of hardware cpus, not logical cpus. Disclaimer: the above is in no way general rules, but empirical rules to solve my particular problem. And even with that, I have to check on more machines. The goal being: best speed, because this is critical, and no optimal CPU utilization. 
unless the classes interact, the number is irrelevant. i nknow it sounds pedantic, but that's exactly what coding is.. being pedantic about everything, otherwise it's just academic.
Dude, it's just a bunch of contextually related classes, like std::mutex.
on modern hardware a volatile read/write to main memory costs hundreds of cycles... you could literally draw a picture of dog in that time whilst waiting; benchmarking code is irrelevant; the only thing you're "benchmarking" is your choice of mutex.
Basic interval arithmetic can't do that, but take a look at [Taylor models](http://magix.lix.polytechnique.fr/magix/magixalix/slides/magix_berz_makino.pdf) as they can address this problem quite successfully. I don't know of an open source C++ implementation unfortunately; I've got a toy matlab implementation up [here](https://github.com/iansheret/TMProof). On a related topic, automatic differentiation is definitely also a useful application of a custom real-number class. [Ceres Solver](http://ceres-solver.org) is a good example of real-world code which uses the technique.
&gt; I don't see anyone else besides you calling this a library did you even read the blog?!?
You can't rely on volatile for thread synchronization. On the other hand, volatile avoids storing values in registers, not in the cache hierarchy. Whether you are using regular pthread mutexes or spin based, you are going to pay the access to memory if the variable hasn't been used in a while.
in a while? caches don't get evicted on a magical timer.. they get evicted when something else wants to replace them. it's got nothing to do with time.
I get that you were probably abused by a narcissistic mentor in the beginning of your career, but that's no reason to pass on this asinine attitude. 
**Company:** [Applied Research Associates (ARA)](https://www.ara.com/). See our [careers page!](http://careers.ara.com/) (Note: We've just [1/1/2017] switched vendors for our recruiting/openings page, hopefully everything is going smoothly.) **Type:** Full time, internship **Description:** With ARA’s Advanced Modeling &amp; Simulation Systems team in Raleigh, NC, you will support our growing business in the areas of GIS, physics-based simulation, and geometric modeling. Our team focuses on modeling a diverse range of phenomena including weapons effects, blast modeling, structural damage, collapse, equipment response, and sensor systems. C++ developer specialties within the team include 3D graphics, artificial intelligence, GIS, databases, big data, and geometric modeling among other skills relevant to modeling and simulation. **Location:** Raleigh, NC is the primary office hiring C++ developers. **Remote:** No. **Visa Sponsorship:** No. Due to the nature of most of our work, employees must be US citizens with the ability to obtain a security clearance. **Technologies:** We code in C++11/14 (legacy C++98/03 code exists but is upgraded as it is encountered.) We work primarily on Windows with Visual Studio's toolchain. We control our versions with Git and state our statuses in an agile/scrum fashion. Familiarity with *nix development and other languages (e.g. Python) desired. **Contact:** If you have any specific questions about any positions listed in the above company careers page, please PM me and I'll try to find out what you need to know!
These are the exact sorts of comparisons I was looking for. Thanks! 
This problem seems basically an application of 'zip_with' and then I think it could be coded in terms of inner_product: const auto nBreaks = inner_product(begin(cities), end(cities)-1, begin(cities)+1, 0, plus&lt;&gt;{}, [maxDistance](auto&amp;&amp; c1, auto&amp;&amp; c2){ return c1.getGeographicalAttributes().getLocation().distanceTo(c2.getGeographicalAttributes().getLocation())&gt;maxDistance; });
Have you filed a [bug report](https://connect.microsoft.com/visualstudio) (or at least sent a "frown")?
&gt;Get help from our community supported forum Doesn't look like a proper bug tracker to me. So that's why I asked.
I must have missed it, but I didn't really get an impression that the author is trying to create a mutex library. I thought the whole point of this post was to benchmark different types of mutex. On the other hand, I don't think a library is defined by its ability to make decisions for you. For example, if there was no standard random engine in std random I would still call it a library, even though I would need to specify what engine I am interested in based on my statistical need.
If I have a function that returns a some_variant&lt;int, string&gt;, which variant should I return? If the differences between the variants are subtle, there is a good chance that I choose variantA, whereas your code tends to use variantB, and you grumble that my function is hard to use in your code. Are the different variants "completely different" or are they subtly different. If they were completely different, then the should have different names. If they are only different in esoteric edge cases that never happen (like a move constructor throwing because you couldn't allocate 32 bytes) then I think it is subtle. Which means users will choose the policies somewhat arbitrarily. And you are left with arbitrary incompatibility. But I don't know. Maybe they are distinct enough and their uses are different enough, and it is not subtle? To be clear - the differences between the variants is not subtle, it is clear. But by _usage_ are they mostly the same? How much code would the average user write where they ignore which variant type they actually used?
Yes, did you?
Just make an aliasing `shared_ptr`, and create a `weak_ptr` from that?
Very interesting! I haven't really thought about the mechanisms behind it all, so I vaguely assumed that there is some reason why there is no aliasing constructor for a weak pointer. But if what you say works, then it seems like an oversight to not have just built that into the weak_ptr class.
Well I think that Visual Basic is the best place to start if you are just getting into programming. It let's you actually see how things go together and it works better for jumping into C++. Visual Basic shouldn't take a month to learn, then proceed directly into C++ after you think you have the hang of it. If you need somewhere to learn then go to "Buckys C++ Programming Tutorials" on YouTube. They're simple and explain most things decently well. I agree that Python will give you some bad habits if you start with it. And in the kids defense he did say "Linux languages". He probably meant shell script. I would put off Java until you work with HTML and CSS. It makes more sense after you know a thing or two about how those flow. I personally have never touched C#, so I have no advice on that.
I did mean intrusive, thank you. As for splicing... that's only half the story. The `unordered_map` is allocating for each element inserted much like the `list` is allocating for each element. That's two allocations per element, whereas with intrusive nodes it could be a single one per element... or even a single array of such elements. Now, in *this particular case*, this might not be an issue. But in general for composing containers it helps. With `Boost` on the table, however, one can jump directly to Boost.MultiIndex for composites :)
For splitting in half, if your use case (and it's not everyone's use case) requires that some particular *text segments* are preserved, you would have to examine the string (in terms of code points, if anything else you'd have to get to code points first) to locate the desired text segment boundaries. Your decsription is unclear as to what actual text segmentation you have in mind, but my wishlist for a C++ Unicode library certainly includes EGC iterators for strings, as the most programmatically sensible and "recommended for general processing". They would keep your 2-character sequence together (but so would glyph iterators, etc) as for basic_filebuf, it is not splitting or replacing, it is only encoding/decoding characters represented externally as byte sequences. It could be an interesting mental exercise to imagine it performing additional text transformations (like that NFD you brought up) on top of this mapping, but it's not what the thread is about. Today, it does its job where Unicode support is not frozen in pre-1996 state. It's not "broken".
Visual Basic is a seriously terrible place to start (even the .NET version). Python is a far better option, though Haskell is best so long as you aren't scared of maths.
In his defense he said "Linux languages". I think he meant shell script.
(sorry, was reading too much Unicode specs at once and slipped to their terminology: s/2-character sequence/2-code point sequence/ and s/characters represented/code points represented/ to avoid further confusion with your meaning of "character")
hi. on it. more later.
Write `eraser` to seamlessly work with `parallel_for` or CUDA with a decent speedup over the approach I outlined previously and then I'll be convinced. ;)
From what you write, the scheduler must outlive the scheduled object. Member function is a red herring. If so, the correct thing to do is to keep a reference to the scheduled object in the scheduler. If, for some reason, you want the scheduler to own the scheduled object which is on the heap, use the unique ptr. Why do you think you need shared/weak here at all?
That's only a problem when the abstraction is incorrectly named (which happens a lot -- more often it starts out named correctly, and its behavior changes behind the scenes).
I always thought attributes were one of the strongest features of C# and I was excited when I read they would be in the C++11 standard (maybe 14? I don't recall). Unfortunately they seem compiler-specific and not usable in the fashion C# uses them. Unless I'm mistaken (which is quite possible!) Instead C++ had to rely on macros, which I never liked. 
Hi, The generated code is technically using Qt's framework that's true. What do you think is could else a more overhead? 
Qt ain't got file_api_dll_wrapper_jni.java.maybec#.cpp.
Weak pointers don't count as a reference, so wouldn't that create an object with 0 references and then immediately deallocate it?
&gt; Seems you would exclude all the code in std &lt;algorithm&gt; on that reason! (no std::remove_if for you :) ) As of C++17 there is support for execution policies for `remove_if` including `std::par` (parallel execution). :) Though even now without C++17, I use `remove_if`with multi-threaded algorithms all the time. Specifically because it doesn't require mutating during iteration so I can call `remove_if` on a collection after all the tasks have joined. Pass over the data to update or consume and then a second pass to sweep. &gt; Also if dealing with memory limited environments (like games) a duplicate array may not be practical if large enough. Anywhere that improves speed is the exact place you want to "spend" your limited memory budget. e.g., your particle engine. :) &gt; There is not one best approach for every circumstance. Very true. I concede. :) I do think you should explore the version that internally double-buffers the collection in your benchmarks. It should be an easy test, too, since algorithmically it's identical to `eraser` - just put the non-erased elements into a separate buffer from the one being iterated over. All that said and my complaining aside, I do like the implementation of this algorithm you've got here. Good job. :)
Someone proposed it fairly recently and it was rejected by LEWG, so it's intentional design rather than oversight.
Just store the member function along with the weak_ptr?
Right now my code is using std::shared_ptr to remember all the callbacks that have been scheduled. Adding a weak pointer (to what?) doesn't seem to provide anything. If the primary pointer to the object the callback points to is destroyed, I have the situation I currently have: the shared_ptr in the scheduler keeps the object alive. Instead, I need to explicitly request that the thing I'm trying to kill off must first check any of its callbacks and unregister them, and once that is done, then I can null out the primary pointer and that will cause the object destructor to be called.
Thanks for the suggestion. I have only the most superficial grasp of C++ lambdas, so it seems I need to study that a bit before I fully grok your suggestion.
Thanks for writing this! Are you going to continue writing on this topic? I definitely bookmarked this.
If for example I'm making this Text-Based RPG Game, and I wanted a command to execute after I've walked into the "lair" how to make that ?
Each proprietary OS has to have its own preferred language and sometimes protocols (btw, browser is like an OS too). They need it for the "competitive advantage". We pay for if with our time when dealing with that nonesense: I've got a team and a 6 months long project just to change the protocols to be compatible with the browser, no new features added.
This seems pretty easy to just implement yourself, but would add unnecessary overhead to std::shared_ptr which is probably why it isn't in the standard library.
&gt; Though even now without C++17, I use remove_ifwith multi-threaded algorithms all the time. Specifically because it doesn't require mutating during iteration so I can call remove_if on a collection after all the tasks have joined. Pass over the data to update or consume and then a second pass to sweep. If this is what you are doing, then you can easily use eraser() with your existing code. Just put it where you are using remove_if(). I don't see how in this case mutating the array while iterating would be a problem? (not that eraser() does that anyway - it's destructor does the single erase() call on scope end) I was not aware of parallel remove_if - I don't yet trust the "auto threadding" of the standard library yet to produce consistent/optimal results. I updated the article with the array copy example. I tried to be as fair as possible. Using push_back() was much too slow so I had to go a bit manual to get decent performance. https://github.com/dtrebilco/Taren/blob/master/Articles/EraserProfile.md Check the code for yourself at: https://github.com/dtrebilco/Taren/blob/master/Tests/Iterator_Profile.cpp#L137 
This is pretty cool, and well-written! Excellent intermediate-level blog post, not too easy but also not full of TMP-wizardry :-) Thanks very much for the article, very enlightening!
Scoped enums are fantastic. No namespace polution and strongly typed? Great! Although, I have seen my share of static_cast abuse with scoped enums to decay them to their underlying type.
There are surely good reasons to use patterns. What's bad is to blindly apply patterns where a simple solution would be enough. Or worse, implementing java style patterns in C++. If the only tool offered by the language is OOP, then everything will look like an object. That's not the case in C++: In order to create an object of type ```DerivedClass``` at runtime, but only depend on ```BaseClass```, the simplest way is pointing a function pointer of type ```BaseClass* (*)()``` to an implementation that returns ```new DerivedClass()```. Anything far more complex than that is the result of only having and thinking in OOP.
I don't get how you apply a permutation.. but ok Microsoft whatever you say
The polymorphism provided by factory inheritance is equivalent to a function pointer. Alternatively check out my creator class that would allow ```std::unordered_map&lt;std::string, Creator&lt;Shape&gt;&gt;``` where ```Creator&lt;Shape&gt;``` can be created from ```Creator&lt;FluidShape&gt;(/*pass FluidShape ctor parameters here*/)```. Writing a ```class ShapeFactory``` for ```class Shape``` is as bad as implementing a trivial ```class ShapeVector``` instead of using ```std::vector&lt;Shape&gt;```. Not just abstract factory, but for almost every design pattern there is a better equivalent in C++ that doesn't unnecessarily repeat the type name and increase complexity / coupling. Builder: std::bind Observer: std::function / signals Singleton: static or local static variable Strategy: std::function and so on...
I'm not following. The lock call is needed to dereference the weak_ptr, not to construct it. It seems like if I can do: Foo myfoo(constructor,arguments,here); auto sp = std::shared_ptr&lt;Foo&gt;(myfoo, &amp;myfoo.member); auto wp = std::weak_ptr(sp); There is no lock call and no possibility of failure (other than the same exception that would result if the allocation that occurs for any shared pointer).
Well... it's a quick and easy way to treat an array as a map I suppose.
I suspect there's a subtle reason that an aliasing constructor for `weak_ptr` would need to lock, and it's the same reason that casting a `weak_ptr` needs to lock: virtual inheritance ([see this comment by /u/STL](https://www.reddit.com/r/cpp/comments/47d3tu/a_static_cast_is_not_always_just_a_pointer/d0c2ai1/)).
I'm pretty sure that the meaning is actually conveyed quite nicely right now in my real-world use. instructions[static_cast&lt;u8&gt;(Instruction::CLEAR)] = &amp;Interpreter::clear; instructions[static_cast&lt;u8&gt;(Instruction::RETURN)] = &amp;Interpreter::ret; In my opinion this is quite straight-forward. That said, what would even be the appropriate helper function name here? `instruction_to_index`?
&gt; generate a list of metadata for all type in a separate file &gt; &gt; run a template processor over those inputs to generate new sources &gt; &gt; compiler those sources &gt; &gt; link the objects from hand-written and generated sources together I'm working exactly on this algorithm to instance C++ templates at runtime, something like: // template.hpp template&lt;typename T&gt; class Template { ... }; // foo.hpp class Foo { ... }; // main.cpp using namespace cpp::dynamic_reflection; int main() { Runtime runtime{ ... }; Class&amp; c = runtime.template_("Template").instance("Foo"); } What this is supposed to do is: 1. Take static reflection info of Template and Foo 2. Fill a dynamic reflection runtime with that info 3. Generate a header that includes template.hpp and foo.hpp, with a `Template&lt;Foo&gt;` explicit instantiation. 4. Take static reflection information of the generated header. 5. Load the info (This could be done by importing the generated code and its info as a dynamic library, see https://github.com/Manu343726/siplasplas/blob/master/examples/reflection/dynamic/plugin.cpp) 
Sorry, my initial reply was meant to be to the post that you were replying to, i just noticed. In this case i usually use a namespaced enum. It has the same features as an enum class except it implicitly converts.
Gotebe, In my current scheme, my Scheduler class is self-contained, and isn't in any way specific to anything in my emulator. The callback is passed via std::function, so that the callback could be to any function type (or functor, I believe). With your change, it restricts the callback only to classes which are derived from runnable. As it is, my Cpu class and my IoCard class (both users of the Scheduler), aren't derived from anything, so it would be possible to declare a runnable class and derive these two from it. But that seems like coupling things more, rather than less. And if I tried to use this type of coupling for some other reason, then it seems like I end up having to use multiple inheritance, and from everything I've read, that is the road to ruin, especially for someone like me who only dabbles in C++.
Yeah, I think this might be the way to go unfortunately. I've went in and added a TODO to that section of the code, so I can clean it up sometime soon.
If the methods of the Factory class are static then the class really is just there as a unit of organization (almost like a namespace). Why would a function pointer be any better than a static method call? Sometimes you just need to encapsulate the constructor dispatch to a method so you have the freedom to start with a switch case and migrate to std::unordered_map or std::map as needed. No need to expose the user to your implementation details. It seems to me that factories are about type erasure. You don't want the user to have a dependency on the implementation details. C++ had classes first... don't let Java spoil them for you. :-D 
You can't in Rust. Instead, you have to implement Index for your enum in order to provide something like that, which makes more sense.
I would use a switch here. It's more verbose, but it better shows your intent.
Your `ArrayCopy` is slightly not what we actually use, in that you are reallocating on every run. You want to "double-buffer", e.g. keep both arrays around and then swap their pointers after each iteration. This is akin to what you'd do if this was offloaded to a GPU; you wouldn't reallocate the GPU buffers every frame. &gt; If this is what you are doing, then you can easily use eraser() with your existing code. Just put it where you are using remove_if(). Very true. And your updated benchmarks even make a decent case for doing that when there's few elements being removed, though it would be interesting to see if the allocation overhead is the problem (and microbenchmarks w/ allocations are _hard_ so we'd likely need to test this in production code). Still, very nice. :) &gt; I don't see how in this case mutating the array while iterating would be a problem? (not that eraser() does that anyway - it's destructor does the single erase() call on scope end) The destructor would be invoked on multiple threads, causing them to start fighting over the output location. A fix here would be to use a reduce operation, so each thread uses `eraser` on its local slice of the larger array, and then a second pass after the tasks join to condense the slices into the larger array. Unfortunately, it will still be broken for multi-threading if there's links between the chunks since the index fix-ups are thread-local, and individual slots aren't atomically updated. e.g., transform tree updates.
I think a switch might be a bit too verbose, if you have a lot of enums and corresponding functions. I currently have *only* about 25, but I expect that number to rise by quite a bit in the future, as I finalize the functionality.
`ReadOnlyArg` sounds good, until you realize that template argument deduction sadly doesn't work with it, which is the only sensible use case for this utility... [wandbox example](http://melpon.org/wandbox/permlink/38y98B8a3vWBO3K9)
Yes you're right. I missed that since my main usecase was something like this :( `template&lt;T&gt; class Foo {..... T func(ReadOnlyArg&lt;T&gt; x) {...} };`
We use a struct rather than a namespace so that you can template on the enum and still be able to access the values inside.
&gt; And your updated benchmarks even make a decent case for doing that when there's few elements being removed Thinking about it a bit more, though, this is kind of pointless to do, if your STL implementation is good. `remove_if` can already be implemented with the exact same underlying algorithm as `eraser`. From [cppreference](http://en.cppreference.com/w/cpp/algorithm/remove)'s second example implementation: template&lt;class ForwardIt, class UnaryPredicate&gt; ForwardIt remove_if(ForwardIt first, ForwardIt last, UnaryPredicate p) { first = std::find_if(first, last, p); if (first != last) for(ForwardIt i = first; ++i != last; ) if (!p(*i)) *first++ = std::move(*i); return first; } If you can measure a speed improvement in your `eraser` over `remove_if` then it possibly just means that your STL has a different and sub-optimal implementation. You could just drop in the above implementation as a replacement. In fact, the above `remove_if` is identical to `eraser` if you do your mutations in your predicate: size_t index = 0; // same value as item.index() from eraser thingies.erase(begin(thingies), remove_if(begin(thingies), end(thingies), [&amp;](auto&amp; item){ ...whatever_update_code_here... // returning true is equivalent to item.mark_for_erase() in eraser return item == value; })); And it then becomes arguable whether `eraser` or the algorithm approach is the more pleasant syntax. Keep in mind how much cleaner the above will be with the Ranges TS and the proposed `erase_if` algorithms, too! // one-liner with Ranges TS + erase_if algorithm size_t index; erase_if(thingies, [&amp;](auto&amp; item){ return whatever; }); You can remove the "icky" manual counting of `index` with a small wrapper for your predicate if you really want: template &lt;typename Func&gt; class counted { public: counted(Func f) : func(move(f)) {} template &lt;typename... A&gt; decltype(auto) operator(A&amp;&amp;... vs) { return func(index++, forward&lt;A&gt;(vs)...); } private: Func func; size_t index = 0; }; And the mildly simplified one-liner: erase_if(thingies, counted([&amp;](auto index, auto&amp; item){ return whatever; })); ... and I think I've rabbit-holed on this enough now. :)
In addition to what Sean said, you need to also consider what `some_function()` does - in particular, how many (non-inlined) functions does it call. ie double some_function1(Foo const &amp; a, Foo const &amp; b) { return a.x * b.y; } double some_function2(Foo const &amp; a, Foo const &amp; b) { auto temp = f(a.x); temp *= g(b.y); temp += h(a.z); temp += etc(b.z); return temp; } In the second function, the compiler needs to reload `a` and `b` after each function call - because, even though const from this pov, `a` and `b` may not be const from those subfunctions. `h(a.z)` can change `b`! (because programmers suck and use global variables, shared_ptrs, etc and make impure functions....) And maybe a and b are the same variable! These are just a few examples of the _aliasing problems_ that occurs with references. So the cost of the copy vs reference isn't just the cost of the copy vs the cost of passing a ref, it is the cost of how the references are handled within the function. Which has nothing to do with the signature. I would love some kind of ReadOnlyArg - in the language - that just "did the right thing", because these are details that an optimizer should solve, not a programmer.
Can you please indicate where I re-allocate? I do not see where that would happen as I was careful to have all allocations outside of the profiling code.
Good point, definitely a valid reason!
I have run into the same with units and types as well. Microsoft have some awful macros which pollute globally: PASCAL VOID HALFTONE and a whole bunch more, which really cause trouble.
In this case, available outside AT&amp;T, where C++ was developed. You shouldn't use it except for historical or entertainment purposes: it is over 30 years old, and C++ has changed a lot since then.
&gt; Contact us to become pilote partners. Does anyone proofread these days? Even red squiggles detect this one.
Sorry about misleading, I just meant that it could be conceptualized as a map. An array with enums to index is about the fastest I imagine it could get. Here's a little golfing I did on your example (focusing on access cost): https://godbolt.org/g/uy9uf0 In fact... thinking about why the thought of an array as a map works. An enum can be thought of as a sort of hash (unique values for each name, unless you fiddle with it).. https://godbolt.org/g/wOHEPf (spoilers: didn't help much to specialize std::hash&lt;Test&gt;)
You should call `std::this_thread::yield` and your standard library should do the right thing to call `SwitchToThread` or `usleep`. Yes I know that we weren't calling `SwitchToThread` a while ago but that's definitely fixed in the next major libraries version (where I rewrote MSVC++'s entire Clause 30 implementation).
&gt; Microsoft have some awful macros `min(x,y)` and `max(x,y)` are particularly egregious examples that pop in from &lt;Windows.h&gt;. It's put me in the habit of writing `(std::max)(a,b)` to defeat the preprocessor. However my favourite example of macro abuse is a case where one of my predecessors had redefined the meanings of `true` and `false` to be integer constants instead of booleans via preprocessor macros in a global header file. It caused a very subtle type bug in some template instantiation logic that took me weeks to figure out.
CFront (probably much later version than 1.0) "instantiation" of templates is the stuff of nightmares.
My favourite example is `near` and `far`. We all know about `min` and `max`. They come up all the time. What happens when you play around with DirectX? class SomeCameraThing { float _near; float _far; // ... public: SomeCameraThing(float near, float far, /* ... */) : _near{near}, _far{far}, /* ... */ {} }; Gee, I wonder why nothing is rendered. Could it possibly be a number of things all coming together into one glorious bug? 1. `near` and `far` are both defined to be empty (`#define near` and `#define far`). 2. C++ allows omitting parameter names (`SomeCameraThing(float, float, /* ... */)`). 3. C++ allows omitting the initializing value between `{}` (using `()` is equivalent in this case, too). In both cases, this value-initializes `_near` and `_far` to 0. 4. Nothing breaks. With a near and far plane of 0, there's nothing to render. Good lord, did I have fun with that one. I was lucky to even realize that the winapi defined these. I certainly wasn't programming yet when 16-bit Windows was common (I was only in high school when I ran into this), so it's a good thing I had heard about them, probably from The Old New Thing. For anyone who doesn't know, back in the 16-bit days of Windows, you used to have a distinction between near and far pointers. These annotations were what you'd attach to the pointer declarations. That should be enough to get a good Google search.
The way I woukd solve this is to think of a generic broadcaster/listener case. The `broadcaster&lt;Args...&gt;` holds a vector of weak pointers to `std::function&lt;void(Args...)&gt;`. When it broadcasts, it filters out empty weak ptrs, copies the list, then `.lock()` and calls each one. To register, we have: using token=std::shared_ptr&lt;void&gt;; token register( std::function&lt;void(Args...)&gt; ); void register( std::shared_ptr&lt;std::function&lt;void(Args...)&gt;&gt; ); Where the first has the registered function's lifetime be described by the token, and the second uses the shared_ptr lifetime. Now to solve your problem, I'd either have the devices have a vector of tokens (when destroyed they auto-unregister), or if I was going to commit to them being shared_ptr managed give them a std::function member variable and use the aliasing ctor of shared_ptr to register it. Whichever. Neither of these approaches require an aliasing weak ptr. 
The way I woukd solve this is to think of a generic broadcaster/listener case. The `broadcaster&lt;Args...&gt;` holds a vector of weak pointers to `std::function&lt;void(Args...)&gt;`. When it broadcasts, it filters out empty weak ptrs, copies the list, then `.lock()` and calls each one. To register, we have: using token=std::shared_ptr&lt;void&gt;; token register( std::function&lt;void(Args...)&gt; ); void register( std::shared_ptr&lt;std::function&lt;void(Args...)&gt;&gt; ); Where the first has the registered function's lifetime be described by the token, and the second uses the shared_ptr lifetime. Now to solve your problem, I'd either have the devices have a vector of tokens (when destroyed they auto-unregister), or if I was going to commit to them being shared_ptr managed give them a std::function member variable and use the aliasing ctor of shared_ptr to register it. Whichever. Neither of these approaches require an aliasing weak ptr. 
Is there somewhere I can get a list of the features CFront supported?
what are the dependencies of it?
One thing that's interesting is that it looks like as of this release, the double colon had yet to be invented; instead, a Java-style dot was used: // In file dcl2.c gen.gen(char* s) { char * p = new char[ strlen(s)+1 ]; base = OVERLOAD; strcpy(p,s); string = p; fct_list = 0; } I wonder when and why this was changed.
D&amp;E covers this in 3.11.3. It says it had been the source of "some minor confusion" and shows an example of syntactic ambiguity when a variable has the same name as its type. The only timeline given is "during the transition from C with Classes to C++".
libsqlite3 only. You can use amalgamation source if you code for mobile https://www.sqlite.org/amalgamation.html
From TFL: &gt;#Requirements &gt;- C++14 compatible compiler (not C++11 cause of templated lambdas in the lib).
Some tweaks are needed for VS2015. And it seems like that the user have to call `sync_schema()` before he can do any CRUD, which is unintuitive. BTW, I suggest putting the header into a `include` folder instead of `src`, and add some self-contained examples.
Source for 3.0.3 is also there, including [template.c](http://www.softwarepreservation.org/projects/c_plus_plus/cfront/release_3.0.3/source/src/template.c/view). (Despite the `.c`, it's coded in C++.)
this is interesting. It goes the similar path as a dbms used extensively in my past company. You can probably take some inspiration from there - http://www.garret.ru/gigabase/GigaBASE.htm f.e. your storage class corresponds with dbCursor and db schema is also compared with schema in code upon startup. Personally I find gigabase 10x better than sqlite unfortunately it's not nearly as popular. This project is interesting bcoz it tries to bring intuitive gigabase api on top of popular sqlite. It would be interesting to see it going beyond CRUD e.g. add selectByKey then add array and structured fields support (preferably incl. COW optimization as in gigabase). I would be willing to help with it if you are interested.
I personally prefer not to give up the strong typing as much as possible by using classes along the lines of TaggedEnumValue&lt;Enum&gt; for just value conversion and ArithmeticEnum&lt;Enum&gt; for arithmetic ops on top of that or BitwiseEnum&lt;Enum&gt; for bitwise ops on top with some convenience functions like arith(Enum) or bitwise(Enum), since I find I generally only need a small subset for any given variable, but it's definitely a bit more complex than absolutely necessary. I'll also sometimes cheat and use a namespace I call enum_ops (you can guess what it includes), but I find that I don't need it very often with those few templates. I do absolutely love std::underlying_type and std::is_enum (along with concepts) for making those templates or even enabling operators wholesale nice and simple.
Thanks so much. Damn Apple discoverability.
That's whar is frustrating about those enums. Every time I use them, I need indexing or iteration. And it doesn't work. They feel half-baked.
`std::copy(employees.begin(), employees.end(), std::back_inserter(employeeRegister);` Just heads up, that's a syntax error. I know what you meant, just calling attention to it. Edit to add: Just finished reading it, nice write up!
`instruction_to_index` is a good name. If you use several scoped enums in your project you might also overload `to_index` for improved consistency. However, I would not go for a generic templated approach, as suggested by another poster, since not all enumerations represent indices. My point is that if an enumeration is meant to represent an index, converting to index should not be considered an "exceptional" operation, so using `static_cast` does not reflect the intent. Just my opinion. 
Nice write-up. It is indeed a great tool which gives us many interesting possibilities. *shameless plug*: I've used `libclang` to implement [semantic syntax highlighting](https://github.com/JBakamovic/yavide/blob/master/docs/services_framework.md#syntax-highlighting) for C++ code. 
 * TBD ... * 3) Add something to lalex to handle x&lt;y&lt;int&gt;&gt;. Currently parsed * as a right shift rather than nested template instance. That bug stuck around for rather a while... (It was only fixed in C++11, although some compilers handled it, non-standardly, earlier.)
I might be mistaken but, don't compilers optimize switch statements to lookup tables when the values are consecutive? Doesn't that apply in this case?
I'm not sure that this is the best example, given that the algorithm-ified version introduces a new, unnecessary temporary std::map in which objects are inserted. (and every time i benchmarked something related to inserting into a map, it always took way longer than i had assumed)
Thanks for taking the time to expose all this. The map instead of multimap in the set_difference example is indeed an error, which I have corrected thanks to your remark. As for the rest I need a bit more time to ponder how I can take this into account.
I agree about `include` dir instead of `src`. About `sync_schema`: user doesn't need to call it if he/she already has db file with correct schema. `sync_schema` is created as migrations replacement. I mean once you need to add column into table. You either open sqlite file and write `ALTER TABLE ...` and modify `make_storage` call or just modify `make_storage` call and fire `sync_schema`. Please provide error in VS2015. I use Xcode on OS X so it will be helpful
Thanks for response. Actually I was inspired by this code `https://int64.org/2009/05/18/cpp-orm-framework-for-sqlite/`. It also uses member pointers - very powerful and static-friendly feature. I will take a tour in GigaBASE - interesting thing. Also I'm gonna add raw select (select id into std::vector&lt;int&gt; for example or select several columns into std::vector&lt;std::tuple&lt;...&gt;&gt;) and conditions. Conditions gonna be like this: storage.get_all&lt;User&gt;(where(gt(&amp;User::id,5))); // maps to `select * from users where id &gt; 5`
commercial, but the licensing fee scales with the project. One of the implementation is for a research / academic project.
The counterexamples almost feel like they were written in bad faith. No `auto`-deduced iterator or iterator-pair types, and no range-for loops, artificially inflate the code's verboseness. You can drive home the point perfectly well with a *reasonably* written alternative implementation. Even without artificially making it look scary, it's clear that the manual implementation of the cache insert is more error prone than two standard library calls. The first example is particularly bad, as a simple for loop would actually be shorter than the `std::copy` version and wouldn't need to repeat the `employees` identifier.
I have no idea what happened to N4172, but I also have a [draft](http://jamboree.github.io/designator-draft.html) about unifying designated initializers and named parameters. The draft is a bit out-dated now, the improved one will allow templated named parameters forwarding as well. It's a lot of work, I hope I can make a concrete proposal someday.
Thanks, I shall fix it in next commits. I would be nice if you create issue with this text. Thanks
[EWG 150](http://cplusplus.github.io/EWG/ewg-closed.html#150): &gt; Discussed in Urbana. EWG found various problems with the proposed approach, and didn't think it's feasible to try solving the problem, as it has been tried many times and every time it has failed. 
At 50:48 there is this comment: &gt; The person representing Czechoslovakia will be there. This is very unlikely as Czechoslovakia has not existed as a country since 1993. Things move slowly in the ISO standardisation committee, but not _that_ slowly.
For an official reference, this is [24.2.5[forward.iterators]6](http://eel.is/c++draft/forward.iterators#6) &gt; If a and b are both dereferenceable, then a == b if and only if *a and *b are bound to the same object. And yes, "same object" implies same address: "object occupies a region of storage".
Ah I see. Gotta write some articel about the spaghetti method. 
The newest edition of "Programming: Principles and Practice using C++" by Bjarne himself. 
i'd recommend "The C++ Programming Language" (2013) or "A Tour of C++" (2013) both books by Bjarne.
That paper as-is would likely be good to take to the committee. Complete wording and whatnot often comes in follow-up papers for anything that's not super trivially. Just doesn't always make sense to beef up the standardese if the core premise of the paper doesn't have buy-in in the first place.
In the `ArrayCopy` code you `reserve` a brand new vector before doing the single pass transformation, iirc. I may have misread it slightly. If so, apologies.
In short, they run afoul of C's function declaration rules. Any given piece of code can declare a function that is defined in another .c[pp] file. /* image.c */ int max(int, int); /* matrix.c */ int max(int lhs, int rhs); /* int_math.c */ int max(int a, int b) { return a &gt; b ? a : b; } In this completely ridiculous example, there are no parameter names at all in the declaration of `max()` in `image.c`, they're called `lhs` and `rhs` in matrix.c, and they're defined as `a` and `b` in the definition of the function in `int_math.c`. That means `image.c` couldn't use named parameters at all, code in `matrix.c` would refer to them as `lhs` and `rhs`, and code in `int_math.c` would have to use `a` and `b`. It seems silly in this example, but in the standard library there are no standard names. Sometimes and iterator parameter is named `In`, other times it's `__M_In` or something similarly inscrutable. This means that code wouldn't be portable across implementations of the STL, which is really bad.
Why not just use the names used by the declaration visible to the caller? If there are multiple forward declarations, use the last or warn about multiple differing declarations.
If we were to allow declaration of (anonymous) types in parameter lists and any-order struct initialisation (ala C99), then struct-based "named parameters" becomes possible, e.g. /* Declaration */ void foo(struct {int a, long b = 7, std::string c} args); /* Call */ foo({1, .c = "Hello world"}); Sure, it means the function has to access its parameters like `args.a`, but it's simple, uses existing syntax and adds virtually no extra "baggage" to C++. Only disadvantage is that functions wanting to use "named parameters" are declared differently from ones that don't.
The "Same object" wording also has ramifications for lifetime: destroying and recreating another object at the same address is not sufficient to be the "same object." Effectively, this means that the objects denoted by a range of forward iterators need to persist while some algorithm is operating on that range; references to objects must be valid whether or not some iterator currently exists and denotes an object. This consequence of the "same object" wording is fairly obscure, but it's necessary to make things like `reverse_iterator` work that use references obtained from iterators out-of-lifetime (e.g., `return *std::prev(i);`).
I suspect that the vast majority of algorithm implementations will work with this almost-forward iterator; it's rare to bind references to temporary forward iterators. Without having performed any actual investigation, I suspect that any failures you *do* run in to will be silent &amp; nasty. You may actually have better luck using a *less* conforming iterator that returns `char32_t`*by value* from `operator*` instead of by reference: that will increase the likelihood of errors happening at compile time instead of at run time.
Oh sure, just audit every codebase in the universe that's providing an interface for which there are multiple implementations to make the parameter names fixed. Don't think that's practical.
That reasoning would have called it The Sausage String. 
It adds terrible codegen in debug and probably release too.
&gt; You can also pass the parser as an argument to functions which expect parsable types ...as long as you don't care about the order in which those arguments are parsed from their input stream(s), since the order of evaluation of function arguments is unspecified in C++.
Gah, of course, I've added a note, thanks.
&gt; Oh sure, just audit every codebase in the universe that's providing an interface for which there are multiple implementations to make the parameter names fixed. You're so grumpy you've misunderstood: Just standardise the stdlib. It's not hard to go through the stdlibs and make the parameter names match the spec. That's the only issue that makes it non-portable. 
OT: I've never fully understood this part of the standard - why aren't STL authors allowed to use proper names for template args, parameter names, and even local variable names? Will there ever come a point where c++ gets sane name-scoping rules which would allow STL authors to not use _'s for everything, even local var names in methods? Will Modules help? What else would be needed? Why doesn't a large lib like Boost have to as well?
So long as we have the preprocessor the STL is going to need to be resistant to it. I don't know if modules will help but I hope so. Boost has just decided to not be as compatible with users doing crazy things as the standard library.
It is before the TIMER_START so outside the profiling code. Also it is more than a single pass - the internal array code in ArrayCopy executes 100,000 times before TIMER_END
I think that giving the same exact talk multiple times is only a good idea when the conferences are major and geographically distant from each other *(e.g. one in Europe and one in the USA)* - that way many more people have a chance to attend the talk live. Otherwise, I'm confident that repeating the talk requires some major changes/innovations from the previous sessions... *(which may come from the received feedback)*.
This is my favourite conference. Both as a speaker and as an attendee. (In fact I started speaking because it was a cheaper way of attending. shhh.) - best location - Aspen! Simply beautiful and serene. - best audience - extremely knowledgeable. (Sure that means they (Sebastian) will compile code from your slides in their head and point out the errors in seconds, but they are nice about it.) - best topics - lots of bleeding edge and cool stuff, but also lots of practical I-wish-I-knew-that-yesterday stuff. - best atmosphere - 90 minute talks, lots of time for questions. Lots of time between sessions to discuss with others. Easy for speakers and attendees to interact (smaller conference means more direct interaction!)
 **Company:** TESLA Motors, Inc. **Type:** Full Time **Description:** We design, build, and create some awesome Electric Vehicles and Power Storage devices, among other things ;-) Full Job Description on Linkedin posting (below). **Location:** This position will be located in our Hawthorne, Los Angeles Design Studio south of LAX, directly adjacent to SpaceX. **Remote:** Not usually. **Visa Sponsorship:** Unlikely **Technologies:** C++, mostly Windows based dev, some experience with Autodesk Maya strongly preferred. **Contact:** Please apply to our Linkedin posting below! https://www.linkedin.com/jobs/cap/view/245004816?pathWildcard=245004816&amp;trk=job_capjs
&gt; I would love some kind of ReadOnlyArg - in the language - that just "did the right thing", because these are details that an optimizer should solve, not a programmer. The compiler could treat `T const &amp;` as meaing "read-only argument", after checking that the function never attempts to cast away const and write (which is valid if the argument was non-const -- an unfortunate wrinkle of the `const` system). According to the as-if rule it would be permitted to optimize small objects into value copies and so on.
I don't really understand - why for local variables and template arguments? A local variable is really always just in the local scope, isn't it?
It's defense against user macros, which care nothing about scope.
That's pretty evil... Do you have an example of what such a macro would do or look like, that could potentially influence STL includes (if they weren't using `__`'s)?
Although there are new search algorithms like Boyer-Moore.
Assume `std::max` has parameters `lhs` and `rhs`. Some programmer `#define lhs []` Now the compiler sees template&lt;class __T&gt; __T max(__T[], __T rhs) and things break. Other than defined tokens, the `std` can only use reserved names safely.
I have given the same talk at multiple conferences; but I try not to do so. When I do that, I add a bunch of new stuff for the second presentation.
I think the proposal would even be useful if the standard library could not use it for now (!). At least custom code and future libraries like the ranges (stl2) one could use it. Better to have a good solution for some cases than a perfect solution for no cases at all. Later on the names in the standard library could also be standardized, even if they contain two underlines. Edit: and to avoid portability issues compilers could warn if this feature was used for the standard library.
So it is. Good work then, excellent to see the benchmark results. :)
if the topic is interesting to people; it doesn't matter if it's 200 times
Nothing is accepted until it's been voted into the Working Paper. (WP reverts are possible but rare.)
thx for the advice
&gt; auto benchmark = [](auto f) { ... }; wow this language is changing fast. The jump between c++11 and c++14/17 surprises me every time I look.
**Company:** [Epsilon Systems Solutions Inc. (Warrenton Group)](https://www.epsilonsystems.com/) **Type:** Full time **Description:** Epsilon provides digital training solutions to our military customers. We are looking to add an additional programmer to the team for an in development custom LMS and future projects. The LMS is a Client-Server application for managing and tracking school house SCORM courses, students, and equipment. **Location:** Warrenton, VA **Remote:** No **Visa Sponsorship:** No, and due to the nature of the work, you must be a U.S. citizen and able to obtain a security clearance **Technologies:** The main project for this position, the custom LMS uses: C++11, Qt 5.7, Qt Creator, PostgreSQL 9.6. Other projects we work on use: Unity, C#, Visual Studio 2013, NGRAIN, Android (Java), iOS (ObjectiveC). General tools: svn, JIRA, Jenkins **Contact:** Messenger pigeons is the preferred method contact, but if not available to you, feel free to PM me with any questions (Lead Dev) and apply here if interested: [Position](http://chp.tbe.taleo.net/chp04/ats/careers/requisition.jsp?org=EPSILONSYSTEMS&amp;cws=1&amp;rid=3614) 
[removed]
That one was approved by EWG twice, then CWG once, but wasn't voted on at plenary due to C++14's finalization (a dumb rule). When it was brought at next plenary, it was rejected. Plenary votes down papers every so often. Much more probable than WP reverts, which are extremely rare (old concepts, and the upcoming default_order_t revert).
I paid out-of-pocket to go alone last year, and it was totally worth every penny. If you're interested in attending, do it! I plan to be back this year.
Sorry for being off topic, but what is the "official" opinion about using universal references like this (because I see it often): template &lt;typename TF&gt; void f(TF&amp;&amp; x) { x(state); } Personally I'd prefer a const lref here, since we're not allowing the compiler to optimize rvalues anyway, and so I find the universal reference somewhat deceitful. If I was gonna use a universal reference, i'd at least make it read template &lt;typename TF&gt; void f(TF&amp;&amp; x) { std::forward&lt;TF&gt;(x)(state); } on the off chance that TF is a hand-crafted Callable with an overloaded `operator() &amp;&amp;` or in case C++20 adds some automagic of that sort to lambdas.
What happens that makes the code gen terrible? It seemed like a clever solution to me, but I believe you since you write the STL and have seen The Dark Side :-)
~~In release, passing the struct makes the struct on the stack, whereas passing parameters is happening through registers: https://godbolt.org/g/0est7P~~ EDIT: Apparently I'm reading assembly backwards this evening. In debug, well.... https://godbolt.org/g/gaAEwT
I'd tell them at submission where and when you have given the talk before, and if there are any changes in content or format (e.g. if you have further developed the subject matter, perhaps based on feedback from prior talks, or have a shorter or longer timeslot) and let the organisers make that decision. 
Huge necro, but any idea how to do this if I want to use it with auto as the functions return type? I keep getting instances with mismatched types: error: 'auto' in return type deduced as 'boost::expected&lt;std::__1::basic_string&lt;char&gt;, std::exception_ptr&gt;' here but deduced as 'boost::unexpected_type&lt;std::__1::basic_string&lt;char&gt; &gt;' in earlier return statement
I've been doing some benchmarks and sometimes doing a copy is faster (for stateless lambdas for instance)
That's what I intend to do. I'm looking for an existing project because I'd like more than microbenchmarks.
`[macro.names]` says a program is not allowed to do that. http://eel.is/c++draft/macro.names
msvc is a bit disappointing on [this one](https://godbolt.org/g/BhrtuQ). (check out only the main proc and callees assembly code)
&gt; Passing by value is suboptimal because the generator can be expensive to copy (e.g. std::mt19937). More importantly, you typically really *don't* want to copy it, even ignoring efficiency reasons.
Thank you for you kind word! Yes, writing such library is really helpful for self-education and understanding of language. I would recommend each programmer to try to write at least few general purpose, stl-like classes. Regarding support of old MSVC, Im going to stop support of MSVC 2013 as soon as MSVC 2017 is released. My experience shows that people usually don't hurry to update compilers, so I want to support both latest version and one version before the latest. And regarding your side question. Unfortunately I didn't understand it well. Variant works similar to builtin `union`, so it has size enough to store all alternatives (actually size of the largest alternative) Isn't it linear scaling? And I'll check your callable traits with pleasure. Will be interesting to understand them. Thank you
Reference? (After the amount of argument that resulted in removal of variadic lock_guard over ABI concerns I would find this extremely surprising)
As I say in the edit, I think it was a name mangling change. I guess that isn't strictly part of the ABI? Edit: Here is the clang about the compatibility: https://llvm.org/bugs/show_bug.cgi?id=23529 It was certainly a real pain. Clang was effectively useless on the latest Ubuntu LTS for many months until it got backported.
My advice is to start with the Qt approach: asynchronous event-driven programming. This means having good idea of how the event loop works, how to use signal slots and how to work with QObject. This will help you to write good asynchronous code. After that you can start on learning your preferred option of making UIs. 
I see, thanks! In my opinion if someone defines something like that and then includes an external header, they deserve to be punished. Macros should be used only locally and #undefined after use.
Do you have the specific code snippet? Also this thread is near death (5 months old)
How does the STL defend against #define push_back scooby_doo ? How is or would this be different from standardized function parameter names?
Really cool! I'm a sucker for header-only convenience libraries.
&gt; universal references The official term is ["forwarding reference"](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4164.pdf), "universal references" is kind of a deprecated term. --- &gt; Personally I'd prefer a const lref here Then `f` wouldn't be able to accept `mutable` lambdas. --- &gt; If I was gonna use a universal reference, i'd at least make it read [...] Adding `std::forward` is completely correct *(as it is a &gt;forwarding&lt; reference, after all)* - I didn't bother because none of the callable objects I used had an overloaded `operator() &amp;&amp;` or was being passed to any other function *(i.e. no moves/subsequent references are happening)*.
Could you share those benchmarks? I find it hard to believe that the compiler doesn't optimize `T&amp;&amp; x` and `T x` to the same assembly for a captureless lambda.
&gt; if constexpr(!std::is_callable&lt;T(TArgs...)&gt;{}) &gt; { &gt; static_assert(dependent_false&lt;T&gt;{}, ....); &gt; } else { ... } There is a difference in the length *(and clarity)* of the produced error. Let's change `function_view`'s constructor to this: template &lt;typename T&gt; function_view(T&amp;&amp; x) noexcept : _ptr{std::addressof(x)} { #if defined(USE_IF_CONSTEXPR) if constexpr(!is_callable&lt;T(TArgs...)&gt;{}) { static_assert(dependent_false&lt;T&gt;{}, "The provided callable doesn't have the correct " "signature."); } else { _erased_fn = [](void* ptr, TArgs... xs) -&gt; TReturn { return (*static_cast&lt;T*&gt;(ptr))(xs...); }; } #else static_assert(is_callable&lt;T(TArgs...)&gt;{}, "The provided callable doesn't have the correct " "signature."); _erased_fn = [](void* ptr, TArgs... xs) -&gt; TReturn { return (*static_cast&lt;T*&gt;(ptr))(xs...); }; #endif } --- When `USE_IF_CONSTEXPR` is defined, **g++ 7** reports this error: In file included from prog.cc:3:0: function_view.hpp: In instantiation of 'function_view&lt;TReturn(TArgs ...)&gt;::function_view(T&amp;&amp;) [with T = main()::&lt;lambda(int)&gt;; TReturn = void; TArgs = {}]': prog.cc:9:39: required from here function_view.hpp:63:13: error: static assertion failed: The provided callable doesn't have the correct signature. static_assert(dependent_false&lt;T&gt;{}, ^~~~~~~~~~~~~ --- When `USE_IF_CONSTEXPR` is undefined, we get this one: In file included from prog.cc:2:0: function_view.hpp: In instantiation of 'function_view&lt;TReturn(TArgs ...)&gt;::function_view(T&amp;&amp;) [with T = main()::&lt;lambda(int)&gt;; TReturn = void; TArgs = {}]': prog.cc:6:39: required from here function_view.hpp:74:9: error: static assertion failed: The provided callable doesn't have the correct signature. static_assert(is_callable&lt;T(TArgs...)&gt;{}, ^~~~~~~~~~~~~ function_view.hpp: In instantiation of 'function_view&lt;TReturn(TArgs ...)&gt;::function_view(T&amp;&amp;)::&lt;lambda(void*, TArgs ...)&gt; [with T = main()::&lt;lambda(int)&gt;; TReturn = void; TArgs = {}]': function_view.hpp:78:23: required from 'struct function_view&lt;TReturn(TArgs ...)&gt;::function_view(T&amp;&amp;) [with T = main()::&lt;lambda(int)&gt;; TReturn = void; TArgs = {}]::&lt;lambda(void*)&gt;' function_view.hpp:78:20: required from 'function_view&lt;TReturn(TArgs ...)&gt;::function_view(T&amp;&amp;) [with T = main()::&lt;lambda(int)&gt;; TReturn = void; TArgs = {}]' prog.cc:6:39: required from here function_view.hpp:79:43: error: no match for call to '(main()::&lt;lambda(int)&gt;) ()' return (*static_cast&lt;T*&gt;(ptr))(xs...); ~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~ function_view.hpp:79:43: note: candidate: void (*)(int) &lt;conversion&gt; function_view.hpp:79:43: note: candidate expects 2 arguments, 1 provided prog.cc:6:36: note: candidate: main()::&lt;lambda(int)&gt; function_view&lt;void()&gt; fv([](int){}); ^ prog.cc:6:36: note: candidate expects 1 argument, 0 provided In file included from prog.cc:2:0: function_view.hpp:79:49: error: return-statement with a value, in function returning 'void' [-fpermissive] return (*static_cast&lt;T*&gt;(ptr))(xs...); --- `if constexpr` allows the code in the `else` branch to "not be instantiated" by the compiler. The result is that the error message stops at the `static_assert`, which I find nicer. I assume the same result could be obtained by using `enable_if` on the constructor, but it is way less readable/intuitive than `if constexpr` in my opinion. [**wandbox example**](http://melpon.org/wandbox/permlink/m44h9Y6Thml0V8Z0)
Fair enough, although it seems like this is a QOI issue with GCC (it could and should bail out after the `static_assert` has fired, rather than continuing to try to instantiate the lambda), and I'm not sure it's worth cluttering the code just to work around this. Just my opinion though :-) As an aside, I look forward to the day when we can just decorate the constructor with requires Callable&lt;T(TArgs...)&gt; and get both concise code *and* good error messages...
So what rule protects `string` from `#define string stringW` ? Are all class and method names used in the std namespace reserved?
&gt; What are your recommendations for a newbie like me? Should I start with a book or random tutorials on YouTube? The most important, is to give yourself a small project to do with some directions fixed from the beginning. For instance, an image editor, a chat program, etc. This way, you can have well definite steps in your project such as "how to display text", "how to react to a pressed button", "how to show and hide an image", which you can easily search on the web. You will learn much more like this than if you try to read all the docs (hint: you can't, and most wouldn't be relevant to the application you will be developing anyway) If you need inspiration, you can look at the numerous examples (in the Qt installation folder) and try to rebuild one of the simpler ones for instance.
You would rather the error stop and not give the extra information about what actually fails? I mean I get that a clear english error is awesome, but blocking the generation of the actual reason why there is that clear english error seems only useful to experts and beginners, not to people in the middle who know how to parse errors but are not such an expert in your framework that they can deduce from your english error message the actual problem. Imagine the problem was they had a non-const `()` yet passed a `const` instance. With the second error message, eventually the compiler generates an expression you could rewrite and substitute values into withnthe exact same types and see concretely what is going on. You could improve the first error message, where you exhastively find such "oops" cases and generate custom error messages for each case, but that is hard to do perfectly. In short, it seems like UX polish that hides useful error information because it could scare users.
Why `decltype(auto)`? I cannot naively see a reason to return a reference here.
I see, thanks. It can be hard to keep track of standardization sometimes.
It has to check that, *and* check that no other mutation through any other code path modifies those values. This is basically impossible without LTO if you call any non-local function, and often difficult in that case. If any function modifies any `int` by pointer during your call, that pointer might point at an `int` sub element of your `const&amp;` structure! Proving that isn't the case is *hard* in general. 
Chromium Embedded Framework has a large amount of pure virtual classes, if I remember correctly.
Downvoted: As so often, it is not "nonstandard C++". Instead, it is vanilla/standard/iso/&lt;younameit&gt; C++. You are simply talking about some C++ macros. You could write the meta object information yourself - or use the meta object compiler (moc) to do this. Moc itself also produces standard c++ btw. :-)
Just submit the proposal and let the moderators decide. If you given it before in a place not well known, I'd says it makes the talk better. If you given it before in a well known conference and it was a huge success, I'm guessing that would be fine as well. Otherwise, I'd expect the moderators to reject it. Of course, you don't know what the moderators are going to think so just submit your best effort and forget about it.
Maybe to measure the performance hit induce by the [vtable].(https://en.wikipedia.org/wiki/Virtual_method_table)
I was aiming for genericity - I cannot think of an example either, but I suppose there could be some monad whose implementation of `bind` returns by reference...
That's why I said `function_view` is fine. I like it. 
This is a good point. I'll think about this and see if I come up with something better, otherwise I'm inclined to think that you may be right - even if a "plain english" error is nicer 99% of the times, it could bring a lot of wasted time and frustration in rare cases *(where a more complete error would help figure out the problem)*. 
Ah sorry, totally misread your post. Missed the &gt; over the others :(
It's not your usual use of `forward` with a forwarding reference, but it serves a similar purpose, i.e., forwarding the arguments of `operator()` into your lambda and then into the user-provided function object while preserving their value categories. The only difference is that instead of the original value categories being deduced, they are specified by `TArgs...`. Nonetheless they need to be forwarded onwards. For a concrete example, consider what happens with `function_view&lt;void(unique_ptr&lt;int&gt;&amp;&amp;)&gt;`.
Does it need to be pure? I mean, sfml has a fair bit in their drawable stuff, but the hierarchy is usually only one layer deep. There's also the synthesis toolkit, which is also a shallow hierarchy. I think you might have a lot more luck with something implemented using a visitor pattern, maybe something like an implementation of an interpreted language. I can't think of any suitable examples off of the top of my head though.
Not reserved like `_String` is reserved (i.e. reserved for _all_ identifiers), but it is indeed illegal to define a _macro_ with the same name as a public interface in the standard lib and then include a standard lib header.
Everything I can find on this issue was the result of supporting "semi intentional" ABI changes made in C++**11**, not 14 (for example, prohibiting COW strings).
Can't the vtable be optimized away if you don't actually have inheritance?
True, but there can also a price incurred by the virtual inheritance itself (as in "class whatever : public *virtual* other). Not normally discussed with devirtualisation, but OP wording is... peculiar ?
I would dump the data to stdout or a csv file and use R/Matlab/Python/etc. to plot it. 1) because those tools make it easy to tweak the plot interactively without recompiling a C++ program 2) because any data worth plotting, is worth saving to a file anyway, because you might want to make a different kind of plot from the same data later. Sorry if this is useless for your goals.
Yes with the help of various facters like complexity etc
is it necessary ??
Lol yes it is
It's not unhealthy to talk to yourself, but creating separate Reddit accounts to do so is taking it a bit far... In other news, obvious spam is obvious.
Wow nice formula
Algo + data structure + comman sence = program 
Time complexity 
Anybody know about space complexity? 
I might miss something, but is there any C++17 specific code in your std::function_view?
`std::is_callable`
Nice catch!
&gt; Well, by merely adding #include &lt;string&gt; to header.hpp the output size is 1.51MB. Would have been useful if you showed a way to skip certain #includes
As dodheim said, `std::is_callable` is C++17 *(even though there's a C++14 implementation in `function_view.hpp`)*. I also really recently updated the article to [fix some important issues](https://www.reddit.com/r/cpp/comments/5mgyf2/passing_functions_to_functions/dc483gm/). There was an `if constexpr(...)` in the earlier version :)
Sounds like this requires dozens of people to architect and maintain. 
Are you actually shitting on my dick when you say that std::copy(employees.begin(), employees.end(), std::back_inserter(employeeRegister)); is expressive whatsoever? First of all, as you said, begin and end is just noise, bla, bla, but then read this: back_inserter returns an *iterator* that has operator++ which does *nothing* and derefing it just returns a *reference to it* (*derefing an iterator returns a reference to that iterator*), and also assigning to it actually pushes an element back into a vector that this iterator was created for. What the fuck. You picked the worst possible example I could imagine. I'm not saying our standard library is bad, I'm saying couldn't you have picked an example that actually makes some fucking sense Also yeah I'm saying that this particular design decision in the library is insanely questionable on so many levels
Thanks man
All this is why we can't have nice things. STL should just go the Boost route and have people deal with it :) Especially since the above is just a suggestion - or will compilers one day actually outright reject the avobe? If it's not allowed, make it not allowed... It also makes Intellisense and compiler error spew less than useless...
[removed]
Your post has been automatically removed because it appears to contain profanity or slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/5kytlk/garbage_collection_no_thanks/dc5442u/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
[removed]
Why is "for performance" part of the article's title and conclusion if it performs worse?
It generally requires less people than maintaining spaghetti code. In reality the layers are quite thin. If your core code architecture is well designed (which it should be anyway - even if you use w.g. SWIG), the rest of the layers are often pretty straight forward.
That was sloppy of me. I have updated the post with numbers from gcc in addition to the clang ones. There an increase is very obvious.
In addition to mentioning the non-owning aspect when having views as members of a class, you really need to highlight this as part of general API design as well, in particular using them as return values (unfortunately). Consider the following, very natural, invocation of your split function: std::string GetStringToSplit() { ... } auto tokens = split(GetStringToSplit(), " "); // sigh: tokens is useless at this point because the string returned was a temporary and is now gone What is the consensus and recommendation of returning views?
So you never left a file open and blocked? I doubt but if you say
Yes, and then you'll have big trouble loading these binary formats in Python or Matlab...
[Mine if you want](http://github.com/OSSIA/i-score), roughly 100k sloc. I try to only have one or two levels of inheritance max (e.g. an interface + implementations). You can run cmake with `-DISCORE_CONFIGURATION=static-release` to get the benefits of LTO on the whole code base compiled statically, to give devirtualization the most chances to happen. With GCC it also enables `-Wsuggest-final-types`.
Wow, that looks like an awesome plugin! Nice work. 
Also &gt; The purpose is to reduce code bloat [snip] Performance is secondary consideration. Though I suppose it could still happen to be blazing fast in spite of that not being a priority.
What would you say the tradeoffs are between your library and Eigen?
take the following with a grain of salt. I am no expert in Eigen. I am also skipping the obvious stuff like "Eigen is much older so there is much more functionality and code". For example Remora does not support Complex arithmetic, simply because I am not an expert to judge whether everything works the right way or what algorithms to use etc. The most important trade-off is the one of brain vs speed. Eigen is faster, it is from the core designed so that all its operations can be maximum performance (e.g. everything is based on SIMD operations, even stuff like elementwise exp etc). It is in principle not impossible to implement Remora the same way, but time constraints limit what I can do. Remora in turn is designed so that it is easy to do rapid prototyping with it. It does the thinking for you. When you have a sparse matrix A and write B = A+A.transpose() in eigen, the compiler tells you that you just did something it can not handle and the documentation tells you, you should write B= A; B +=A.transpose(); instead. Remora comes to the same conclusion but does the transformation for you, so B = A + trans(A); is just fine. This mechanism is not just sugar coating. it comes very handy with iterative algorithms, like CG. if you want to solve a system of equations A^T Aw = b with CG, you can write w = inv( trans(A) % A, conjugate_gradient(1.e-9)) % b and it will just do the right thing and treat trans(A) % A as implicit matrix.
Excellent, thanks. And FWIW consider me one vote for more permissive. I'm liking what much of the rust ecosystem is settling on, which is dual MIT/Apache
Now _that_ is a useful bit of information that should go on your documentation page!
Error 512: Django Unchained :) What's your talk on? Boost.hana is near the top of my list of libraries to learn.
Hard to read on mobile since the code examples require horizontal scrolling while the horizontal swipe gesture has been hijacked by a next / previous article navigation feature.
Well not really a difference but observation. LGPL has GPL in it and BSD, MIT and especially Boost not. So LGPL appears to be too close to GPL to as any other library. This was if one is starting private project that could become something serious then simple avoiding anything with GPL seems to be a good idea. 
Seems to be somewhat broken. A doubled quote mark inside a field should be interpreted as only one quote mark. For example, if you're given input like: `"He said: ""the more, the merrier"""`, it should be parsed as one field containing the text: `He said: "the more, the merrier"`. You're parsing it as a single field (good) but leaving the embedded quotes doubled (not so good).
Thanks :) Great range of applications we have with libclang library.
Why introduce virtual functions (and shared_ptr?!) where they aren't needed? If storage to that persistent storage is undesirable and it has no parameters on its own (why? It sounds like it itself is untestable), it could have been a policy or a constructor argument, 
He never said it was correct, just that it was 'blazing fast'.
&gt; It is in principle not impossible to implement Remora the same way, but time constraints limit what I can do. Have you ever considered going in the opposite direction: Incorporate your ideas into pull requests for the Eigen repo? Sure, you might lose some sense of individuality by having your work get consumed into a much larger project, but on the other hand your work would *very* quickly become orders of magnitude more impactful since you'd be contributing to a project that is already widely used and has been exhibiting a continually upward trajectory.
Can anyone explain how does this work with statefull lambdas - I mean we're essentially casting our lambda to void*, so how we don't lose the pointer to values? Or I'm missing something? My second question is - could this be used to call lambda from another thread provided that caller will outlive lambda execution?
Wasn't the specific proposal suggesting that std:: be disallowed from supporting named parameters? EDIT: Also, it would be possible to standardize the names using reserved identifiers since only conforming programs aren't allowed to define macros as such (e.g. _Left, _Right, etc).
Exceptions are dubious on performance but my issue with them is not even that. They are a special tool for making your code more implicit and obfuscated, besides turning explicit localized handling overly verbose. They have grown on me as one of the worst tools on error handling there's. [It's sad that construction of objects in C++ is set upon the premise of exceptions](https://www.reddit.com/r/cpp/comments/5msdf4/measuring_execution_performance_of_c_exceptions/dc73osi/).
I tried playing around with every optimization flag I could think of, including `/Ox`. EDIT: I didn't know godbolt had MSVC support, that's pretty cool. I would suggest adding `/GS-` to those compiler flags to clean up the output a little.
Hahahahaha!
The new compiler version in VS15 RC is MSVC14.1, being only a minor version number jump (last version with a non-zero minor version number was MSVC7.1 in 2003). Only things that changed are better code generation for `for` loops, better debug guards and even faster linking with `/debug:fastlink`.
Okay, MSVC14.0 was what I saw for 2015 with a quick google search :P
The LGPL has a bit saying, "you have to be able to modify the library and use the modified version in the program", which means either dynamically linking the library, or statically linking plus distributing object files for any closed-source component. Consider what this means for header files - you would have to distribute source files for the rest of the program. The LGPL is not a useful license.
&gt; I mean we're essentially casting our lambda to void* We're casting the address of the lambda to `void*`, and assuming that it will be alive at that specific memory address when we call `function_view::operator()`. --- &gt; so how we don't lose the pointer to values? A lambda is essentially a compiler-generated `struct` with an overloaded `operator()`. Here's a huge simplification example of what `function_view` is doing: struct some_stateful_lambda { int a = 5; auto operator()() { cout &lt;&lt; a; } }; template &lt;typename T&gt; void simulate_function_view(T&amp;&amp; x) { // `caller` is stored in a real `function_view` auto caller = [](void* ptr) { // Type information is erased here! (*((T*) ptr))(); }; // `erased_ptr` is stored in a real `function_view` void* erased_ptr = (void*) &amp;x; caller(erased_ptr); } int main() { // Prints "5": simulate_function_view(some_stateful_lambda{}); } --- &gt; could this be used to call lambda from another thread provided that caller will outlive lambda execution? Yes: * as long as the `function_view` is accessed in a `const` manner * as long as the lambda's call operator is thread-safe. * as long as the lambda lives enough for every thread to call it through the `function_view`.
I don't see why this is being downvoted, because I think a lot of people would agree.
Thinking back through things I worked on that sent things over a network.. it would have been more work (and not possible in one or two cases) to introduce some sort of virtual sockets just so a test could error out of a 45th send. Design for testability does not mean runtime polymorphism.
Okay, so it was a different meaning behind "almost sorted" and I stumbled into a bad case instead, thanks :)
Use static polymorphism via templates.
Probably because a lot of people don't agree?
Exceptions were an attempt to separate the "concerns" of the main happy path from the deviations from the path. Code that uses exceptions looks much cleaner because there are fewer branches. In beginner/example code, there is frequently little error handling necessary, so this looks even better. However, in the real world, there can be lots of error handling code, and exceptions can lose the context necessary to properly handle errors.
It was its main selling point (sometimes even more than discuss the exceptional/non-exceptional condition dichotomy), but it ended up mostly as a false promise.
Now, your example of drop-merge sort gave me some insight about a data distribution that I didn't think of when testing mergesort: having only a couple of inversions that split a sorted collection into runs big enough for the vergesort layer to take advantage of them. To check how it fares, I made vergesort fall back to drop-merge sort, and we indeed have a data pattern where raw drop-merge sort is noticeably faster than drop-merge sort with vergesort on top of it: https://i.imgur.com/EFjOav6.png Thanks for that insight about inv-adaptative algorithms. I didn't think of them before.
I can't help wonder if this is measuring the implementation priorities in current compilers, which is of course very relevant, but can still change over time. A while ago, I watched a video about Visual Studio which discussed (probably among lots of other issues) the fact that exception handling was done differently in 32-bit vs. 64-bit code. Unfortunately, I have no idea where to look for that video, or what version of Visual Studio it referred to - it could be as old as 2010. Therefore this is from fallible memory which has already failed to remember enough to find the source. Anyway... The method used for 32-bit code was said to be more appropriate for contexts where exceptions weren't all that exceptional, and were potentially used as "control flow". The scare quotes are because of course exceptions are control flow, they determine the flow of execution, that's what control flow is, but it seems like there's control flow and there's control flow - that we're not supposed to use exceptions for control flow in C++, we're (imminently) supposed to use `std::optional` etc instead. Certainly it has always been the case that there's "errors" that you don't handle as exceptions because they're expected to happen (e.g. a search that doesn't find a suitable item will yield the end iterator as a return value rather than an exception value) so counted as "control flow" rather than as errors. The method used for 64-bit was said to be much more appropriate where exceptions are much rarer - it had much smaller costs provided exceptions weren't thrown, but much larger costs for handling exception throws. IIRC there was an asymptotic big-O difference, though I don't recall any mention of what precisely the `n` in the `O(f(n))` represented. I'm pretty sure the video suggested that these issues were affected by language cultural biasses - that using exceptions for "control flow" was normal in some languages, but considered smelly in others, with C++ primarily in the smelly camp - and that was why the exception handling changed. I assume the reason it's decided based on 32-bit vs. 64-bit divide is mostly because 32-bit is locked into an ABI, but 64-bit code-gen (when first designed, probably closer to 2000 than 2010 - the AMD64 instruction set dates back to 2000ish) could start fresh. Basically, it's probably no surprise to compiler designers that code using exceptions performs relatively well when they rarely happen, but relatively poorly when the exceptions happen even just a bit more frequently. It's not that exceptions *couldn't* be written to give exactly the same performance as explicit error checking - obviously they could be by applying code transforms to mimic the style of code a C programmer would use. It's a deliberately chosen design trade-off based on assumptions about normal use. [**EDIT** On second thought, I'm over-reaching with that code transforms claim - IIRC it would be a whole-program transform, and if you limit it to within single compilation units, that's not going to give exactly the same performance as a system designed from the ground up to not use exceptions.] Possibly related but I can't be bothered checking - there are choices for exception handling for MinGW-w64 GCC - `sjlj` (`setjmp` and `longjmp`) is available for both 32-bit and 64-bit (a last resort IIRC), `seh` refers to Windows structured exception handling, and `dwarf` is a from-outside-Windows 32-bit-only scheme. Those choices are mainly about choosing what ABI you want your code to be compatible with, but there are certainly performance consequences - I don't know if those consequences reflect priorities WRT frequency of throwing exceptions. 
&gt; and exceptions can lose the context necessary to properly handle errors One answer to that I guess is that you do exactly what you'd do for other style of error handling - if you can't handle the errors where you understand what they mean, translate them as they propagate through the abstraction layers, so each layer sees errors in a form it understands (which might also wrap/reference the untranslated errors as underlying causes). 
This is great...except do you have any suggestions for how to fix GCC so that is does produce a constant?
&gt; Whenever a discussion on C++ exceptions occurs, there is That Guy who comes in and says "C++ exceptions are slow, don't use them". "Dubious on performance" is not that far off from exactly what the article called out, and gave lots of data. Most notably on clang 4.0 exceptions are always fast for 0 error rate; this likely means that if you *don't* care about the performance of the error path, which is very common, then exceptions are a good choice and have a good future. They are very good error handling tools when error handling is not localized. Sure for local handling they are moderately verbose. But if you encounter an error that you know will need to be handled many layers up the call chain, throwing an exception is a very nice way to handle it. It allows middle layers of code that can neither generate nor handle a particular error to stay oblivious to it. Separation of concerns. I highly recommend to people who are jumping on this bandwagon to watch https://www.youtube.com/watch?v=fOV7I-nmVXw&amp;t=128s. A great talk that shows that really the different methods of error handling are really not all *that* different. What makes code obfuscated is just, well, having to handle errors at all. It's hard. Exceptions are in better shape than ever, given that it's far easier to write exception safe code than ever before. Also, using algebraic data types can give users the option of error code style or exception style error propagation: optional&lt;foo&gt; get_me_foo(); auto my_foo = get_me_foo().value(); // throws if problem, can't handle this problem locally if (auto maybe_foo = get_me_foo()) { // do stuff with maybe_foo.value(), which will not throw } else { // handle error locally }
There are such mechanisms, but whether or not they're "better" very much depends on how locally you can handle a given error.
It's not surprising that people don't follow the rules, but those _are_ [the rules](https://www.reddit.com/wiki/reddiquette): downvote offtopic or inflammatory (or otherwise nonconstructive) comments, upvote comments you agree with, and simply _don't touch_ the comments you disagree with. The number of pedants in this subreddit who cannot follow such simple rules is **way** too damn high.
error handling *not using exceptions* is _always_ much better when explicitness is enforced when it's being dismissed or enforced through language constructs.
This use case is not supported. Quotes within quotes must be escaped with other text. Generally, we do not care what is stored in the file, unless the application to read csv file is not using the blazing library.
It's not really [csv](https://tools.ietf.org/html/rfc4180) then, merely superficially similar.
Ok, I'll fix this when I get home.
But they actually are not rules. And to be fair it says that you should upvote the comment as long as it contributes to the discussion even if you disagree with it.
I can tell you why *I* down-voted it--because it's clearly false, and almost certainly knowingly and intentionally so. While it may be open to some argument that there are at least circumstances under which exceptions lead to code that's obfuscated, there's absolutely *no* question that this was not the intended result. Therefore, claiming that "They are a special tool for making your code more implicit and obfuscated" is a fairly blatant falsehood. Regardless of exactly *how* the author had formed his opinion, this is still taking his own opinion, and stating it as a fact--but his statement runs directly contrary to the actual facts that apply to the situation. In addition, I'd guess the author lack the experience necessary to have truly informed opinions on the subject in any case. That means that even if it were correctly stated as his opinion rather than falsely claiming it to be a fact, it would remain a fairly useless opinion. Finally, the way the statement was made clearly is inflammatory, and almost certainly deliberately so. As such, downvoting is clearly the proper response, precisely in accordance with the rules.
Worse, on many systems OOM is essentially impossible to handle intelligently inside the program anyway--for the obvious example, when a Linux system runs out of memory, your code will *not* normally receive a failed allocation attempt--rather, the OOM Killer will run, and one or more processes will get killed, so either the allocation will succeed, or else the process will be killed without warning. Either way, the code gets no chance to do anything intelligent about the allocation failing.
In the case of 32- vs. 64-bit code generation, there's another fairly important point: although most of the code involved is never used (so on a demand-paged system, it's normally not even loaded into RAM), the "no overhead" implementation of EH typically results in generating quite a bit more code. Even though it doesn't map to actual RAM, it does have to be mapped to *addresses*, just in case it's ever invoked and needs to be paged in. With 32 bit addressing, the amount of address space devoted to EH could have imposed fairly significant limitations on your code/data size, that were avoided with the methods that were used. A 64-bit address space essentially eliminates that as a concern (at least for the next several years).
&gt; Actually they are more like guidelines, not rules. [Thought of this.](https://thisiswhylife.files.wordpress.com/2014/02/tumblr_lzwm2hkmgx1qhkwbs-1.gif) I'm contributing to the conversation... right? :-)
Every performance measurement I can find says using them is as fast or faster, provided the throwing case is rare (which it should be) and a modern zero cost implementation. If you don't abuse them for control flow and only for actual errors they don't obfuscate anything. In fact they move error handling code to the place where something can be done about and it and make the main case easier to read.
&gt; Worse, on many systems OOM is essentially impossible to handle intelligently inside the program anyway That "impossible" is just flat out incorrect. A Linux system will only display that behavior if you have over allocation on, which it is by default. You can change this behavior and handle OOM intelligently, I have colleagues that have run servers like this and their programs have recovered from OOM and it's all groovy.
"provided the throwing case is rare (which it should be)" C++ provides no uniform mechanism for dealing with _non-rare_ failing object creation, it just provides exceptions as its main idiom, but as you said, exceptions are for rare fails, not frequent ones. What happens is that, it's impossible to state upfront whether failing creation is rare or not in general, but C++ has solely grabbed the idiom for rare fails and turned it the only mechanism constructors are able to signal fail. It's a design smell for me, just like in java, where because everything is an object, let's make you unable to declare a free function. I know I can circumvent what's usual, that I can make constructors private, return C++__2017__ std::__experimental__::optional, and such, or even code C style, but nothing of this is the usual C++ coding idiom around, it's not what's used in the standard library, and the way it's done is not a strict one like one set by the language or stdlib, it varies widely, which turns translation between ad-hoc error handling mechanisms the norm.
I think I remember that scene, is that when she asks for a parley? lol.
Wouldn't be "error" case for monadic error handling almost always be annotated as cold code though (so at least you can possibly get branch prediction and a less thrashed instruction cache)? It would still require a branch check, but wouldn't exceptions that are caught as well need that? Or does C++ do something cleverer in terms of where to send control flow (sorry, I admit I know Rust better than C++ so my knowledge of the internals of it has holes) 
Thank you so much for setting me straight on this. The point about returning a const reference makes a lot of intuitive sense to me, as that is usually what I would expect to happen as a programmer. 
Ah. That is fairly obvious and SO MUCH easier on the old fingers. Thank you, sir. 
The largest text section I've ever seen (for a C program) is 16 megabytes. Even on 32-bit systems, text size isn't an issue at all, except that it dirties more cache.
For a C++ program using the "no overhead" version of exception handling, the (theoretical) text size can be *substantially* larger than that. For a quick example, a (fairly old) version of Photoshop I have handy uses ~230 MB of address space for code modules immediately after load, with no file opened. Likewise, MS Visual Studio shows around 477 MB of code modules mapped. So yes, adding a substantial percentage to that really would start to make a noticeable difference in available address space. No, not it's probably not so huge that it's immediately guaranteed to be untenable, but for a large program it could certainly be enough to give some people second and third thoughts.
On mobile presently, but http://stackoverflow.com/a/13836329 is a starting point (and the referenced TR). I'll edit with details later if warranted.
&gt; on many systems OOM is essentially impossible to handle intelligently inside the program anyway This is... nooo... * Neither C nor C++ standard specify OOM killer behaviour, he who relies on it writes platform - specific code, not cool * OOM killer can be turned off, he who relies on it writes subsystem-specific code, not cool * address space fragmentation can make allocation fail without OOM killer kicking in * it can be that the program needs to make an allocation it can't fullfil at that point in time for some reason (say I am an editor of some fashion and the user pastes in too much for my current state; I certainly can tell them "whoops no can do" in lieu of crashing) * malloc on Windows, a major platform, was *never* subject to overcommit OOM killer has positively **crippled** whole generations of programmers. Not cool at all.
The initializer codegen bug reminds me of [something similar on gcc](http://stackoverflow.com/q/37260097/4885801).
Very interesting, thanks! I wonder what would happen if you used constexpr instead of const, to enforce static initialization. Of course you won't get better result than with const, but I would expect the compiler either to not get confused or to emit an error message that would make its bug apparent. UPDATE: just checked with your "fit-in-a-tweet" example. Replacing the outert const with constexpr actually moves the symbol a from section 3 to section 2 even if you keep the inner const.
*I never thought I would write a comment like this on /cpp ever but you look so nice*
640kB was never enough for "anybody", IIRC IBM originally planned for a clean 512kB / 512kB split between ram and device memory but they knew that that wasn't going to be enough so they squeezed as much ram space out of the address space as they could. 640kB was just the most they could manage with Intel's 1MB address space limitation on the original 8086/88. I'm sure Intel's weird overlapping high/low address words scheme looked good at the time but retrospectively it was insane.
Note that x86-64 doesn't actually get 64 bits of addressable space, rather 52 bits for physical memory and 48 bits for virtual memory (IIRC).
Well, that's pretty unexpected, but thanks :)
His github bio: "I like stuff. Maybe even you." :D:D:D
The section 3 of LGPL3 states: &gt; The object code form of an Application may incorporate material from a header file that is part of the Library. You may convey such object code under terms of your choice, provided that, if the incorporated material is not limited to numerical parameters, data structure layouts and accessors, or small macros, inline functions and templates (ten or fewer lines in length), you do both of the following: a) Give prominent notice with each copy of the object code that the Library is used in it and that the Library and its use are covered by this License. b) Accompany the object code with a copy of the GNU GPL and this license document. Doesn't this cover header-only libraries?
The book is not bad, but aside from the games context it doesn't offer anything groundbreaking. It's very much a beginner's book, if you know about variables, loops and classes I'd look at something more advanced.
So vergesort is much faster at sorting random data. I think that deserves mentioning in the readme. Since both algorithms are designed for the same use case, it would probably be useful to compare them directly.
So /DELAYLOAD:ws2_32.dll? What could be the reason behind delay-loading this particular DLL?
&gt; C++**2017** std::**experimental**::optional Just to correct your "scare bold": C++17 will have `std::optional`, spelt just like that. The Library Fundamentals TS, published in 2015, contains `std::experimental::optional`. Both are based on `boost::optional`, which has been around since at least 2003 going by the copyright date. 
We have had this discussion on SG14 (low latency/high performance ISO C++ study group) on quite a few occasions now with people running benchmarks. Apart from x86 MSVC, all the main compilers have very good C++ exception implementations which are very competitive with C error codes. We generally came to the conclusion on SG14 that the biggest gain from turning off C++ exceptions by far was on **reduced debugging effort** which means better quality code delivered sooner with fewer surprises in the hands of the customer. And there are next generation C++ 14 error transports coming soon (expected&lt;T, E&gt;, Boost.Outcome) which specifically aim to reduce the effort gap between mixing C++ exceptions on and off code in the same program. That way, you can mash up STL using code with C++ exceptions disabled code very easily, unlike the pain it is right now. 
Nice, thanks
Does seem a little odd to "dirty" the code that way to shave off some megabytes of executable size.
**Company:** [TomTom](https://www.tomtom.com/careers) **Type:** Full time **Description:** The TomTom Navigation Engine is used on numerous devices such as smartphones, in-car dashboards and your web browser. Determining the quickest route and best navigation experience for human and automated drivers is all about calculations with lots of variables. Having strong algorithmic skills is fundamental to be successful in this job. As a C++ Engineer you are involved in improving the routing, the guidance or the visualization of the Navigation Engine. In all cases, you would be working as a part of a scrum team. **Location:** Amsterdam (English spoken), Berlin (English spoken), Łódź (English spoken). **Remote:** No, only on-site. **Visa Sponsorship:** Yes, we sponsor visas. **Technologies:** C++98/03, transitioning to C++11 very shortly. Development mainly on Mac/Linux. We're looking for all experience and seniority levels. **Contact:** [Apply using our Careers page](https://www.tomtom.com/careers), send us a private message on Reddit.
More than vergesort vs. timsort, it would be a choice of some other sorting algorithm vs. the same algorithm augmented with vergesort, for example when you know you can get either almost sorted data, but also totally random data. If you know that you'll have somewhat sorted data and that comparison operations are expensive, you would choose timsort; if you've mostly got random data and that comparison operations are not that expensive, timsort is probably not the good algorithm for the job. A vergesort with a pdqsort fallback could be an intersting choice if you've got no idea whether the data to sort will be sorted or not: if it is, vergesort takes the job and that's fine, if it isn't, it quickly gives up and falls back to pdqsort, which is performant with random data.
**6** Initializing Dependent Object Members https://godbolt.org/g/D5O8OP I don't see a problem here?
I have added the double quote escape.
**Company:** [TomTom](https://www.tomtom.com/careers) **Type:** Full time **Description #1:** The TomTom Navigation Engine is used on numerous devices such as smartphones, in-car dashboards and your web browser. Determining the quickest route and best navigation experience for human and automated drivers is all about calculations with lots of variables. Having strong algorithmic skills is fundamental to be successful in this job. As a C++ Engineer you are involved in improving the routing, the guidance or the visualization of the Navigation Engine. In all cases, you would be working as a part of a scrum team. **Location #1:** Amsterdam, Netherlands (English spoken), Berlin, Germany (English spoken), Łódź, Poland (English spoken) **Technologies #1:** C++98/03, transitioning to C++11 very shortly. Development mainly on Mac/Linux. We're looking for all experience and seniority levels. **Description #2:** Realize innovative in-car navigation solutions by porting TomTom's in-car navigation suite to different automotive platforms: QNX, Linux, AOSP, Tizen. Also make it collaborate with other in-dash components like the heads-up display, entertainment- and Bluetooth system. **Location #2:** Eindhoven, Netherlands (English spoken) **Technologies #2:** C++98/03, C++11, knowledge of different OS's is a plus: Linux, Tizen, QNX, Android, WinCE **Remote:** No, only on-site **Visa Sponsorship:** Yes, we sponsor visas **Contact:** [Apply using our Careers page](https://www.tomtom.com/careers), send us a private message on Reddit or reply below for questions
I am not sure about the method you have used to do the measurements though: `time.time()`? When I do the measurements from Python code I usually use `time.clock()` which according to the [Python docs](https://docs.python.org/2/library/time.html#time.clock) seems like a right thing to use. Moreover, I believe `perf stat` might give more insight on actual code performance with more information it can give, such as number of cycles, number of instructions, ratio of instructions per cycle, branches (and its misses), cache references (and its misses). Just to name a few.
By being a free function, you can implement your own adapters for third party code. For example, if you're using a library that has its own containers that support iteration, but not in the same way as the standard library, you write a specialization of `std::begin` for that type which adapts the library's concept of iteration into something compatible with the standard. As a bonus that also means that you can now use that third party container in a range-based for loop just like arrays and standard containers. All without having to modify the library to add a member function. Edit: actually you'd probably define it in the namespace of the library, not as a specialization of `std::begin`, as the range-based for loop does the lookup using ADL rules. But it would still work the same as described.
_Construction_ in whatever situation can only fail through exceptions. If one wants to do otherwise, it would be deviating the usual idiom provided by the language. Want a worst example? Why the hell I'd be wanting to deal with exceptions on interactive user input? Still `std::stoi`, `std::stol`, `std::stoll` does exactly that. Why? because the native idiom to fail construction available is exception.
This is not C++...
I didn't say it had standard iterators. I said it supports iteration, but not in the same way as the standard library. It could be a library with a C API, for example. 
I classify your tone as Ad Hominem, won't even waste my time to argue over.
More context: On user interaction `invalid_argument` can happen in several places, so do I bend to the exception scheme and put a global enclosing `invalid_argument` catch and become unable to report to the user which specific case it has done wrong input, since on catch I just get `invalid_argument` for all possible invalid argument locations? Or do I put localized try-catch all over the place and for effect, make them work just like if statements to provide local reporting? Or will I have to mix different error handling mechanisms depending on the kind of input I'm handling, because in each case one given API (stdlib or other) will do it its own way, with exceptions or not. Or better, what about wrapping every present and future error condition into my own deep exception hierarchy for which I can produce beautiful catch statements?
This works: http://ideone.com/q0SkZd
Correct and you probably realize I know it. Yes these are the options right now in __2017, january__ for C++: std::__experimental__::optional or drag boost into your codebase. Yes _it's_ scaring, I've done both in the past, and will still do it sometimes, but won't endorse anyone doing so, just inform of their existence and hide.
I think motivation is the general reasoning on the subject "free-function vs. member functions". It is detailed in "Effective C++" (Item 23. Prefer non-member non-friend functions to member functions). There are many people around who agree with Scott Meyers.
&gt; On the irrational side, I wanted to see whether I could do it. Au contraire, I'd call it the pinnacle of rationality. You asked a question and provided an answer in the form of an experimental result. You could have spent years analyzing whether you might be able to do it. Instead, you went and did it and thus have a clear answer *and* the job is done, too. Good on you.
I understand it's the only way to handle construction. I was saying I know of no frequent object construction use case where failure is also frequent (which if it existed would make the slow performance of thrown exceptions matter). The string conversion functions are an example where failure is rare (if you're waiting for user input from an error prone human, you're not in a performance critical path). 
I'm talking about the clarity side of things, really not focusing on perf side of things in my wording, I have much less interest in this. My "worst" doesn't refer to performance, but worst situation of contrived/misplaced exception handling code. I think I can't give you from my experience _non-rare_ exceptions in hot code b/c I just avoid them there like the plague. But you can imagine, what if I wanted to do string/number conversion in hot code? It's common enough situation no? when dealing with protocols etc. Would I rely on `std::stoi` there? Most probably no. Why not? Just because they would be throwing gratuitous exceptions (same for `boost::lexical_cast` and co.). So the chosen C++ standard library solutions for such a useful and common task would be useless for me when I care for performance (besides sane code). Notice that "ideally" in protocol handling bad strings numbers are not expected to happen often, but as I'm talking about it _in general_, I can't simply base my programming tools over that speculation. It's not the way I work at least, providing features based on assumptions as "fail-often is rare" hence "let's solely provide exceptions on failing constructors". Notice the difference between "the throwing case is rare (which it should be)" and the assumption "fail often is rare (which it should be)", because not all failing must be exceptional.
**2**: XCode is good for C++, but you do need to use CMake to specify how the project should be built. You create the Xcode project like this: mkdir build cd build cmake -GXcode ../src You can then open the XCode project and run your code, set breakpoints and step through with the debugger, and use the profiler. CMake style varies widely, I'd recommend [this](https://rix0r.nl/blog/2015/08/13/cmake-guide/) guide; also look at [these](http://www.slideshare.net/DanielPfeifer1/cmake-48475415) [two](https://docs.google.com/presentation/d/18fY0zDtJCMUW5WdY2ZOfKtvb7lXEbBPFe_I6MNJC0Qw/edit#slide=id.g16ced1c3a2_0_2) slide decks. You should be able to get self-contained projects working without too much trouble; the real fun (by which I mean pain) starts when you need... **3**: dependencies. For major libraries (e.g. Boost, OpenCV, Eigen), you can use Homebrew to do a system-wide install, and then use e.g. find_package(Boost) in your CMake file. This approach isn't great if you have different projects which need different versions of the dependencies, and as you say this only covers big libraries. For smaller libraries, I usually make an install folder which is local to my project, then download, build, and install to that. That way I'm not messing with any global machine state, I know I won't break other projects, and I can have different library versions for different projects. It's actually possible to automate this whole process within your cmake file using the ExternalProject_Add command. Also, have a look at [Hunter](https://github.com/ruslo/hunter/wiki), this is a package manager built on top of CMake, and it takes care of a lot of the work. If it's got the libraries you need, that might be a good option.
you are welcome
once per conference is ok - you're spreading the message around different folks 
&gt; overcommit is normally turned on by default It's not. "smart overcommit" is the Linux default, which fails malloc/new, just imprecisely. And Windows, with its strict commit accounting, isn't all that obscure either.
In what way does a function call obfuscate? It states very clearly in text that you want to execute a piece of code. When dealing with exceptions, there is control flow happening that you may not see right away, since you have go into a function (or even multiple layers of functions) to see if it might throw. With error codes you only have to look at the return value of a funtion. Heck, one of the big reasons people are using things like RAII, is to fix all the memory leaks caused by the hidden control flow logic of exceptions.
Thank you again, Bruce, for the great investigation, post, and bug report! Sorry you hit that initialization bug but, as you say, compilers be weird. 
Not "most": Windows is a modern OS and does not overcommit, Linux is a modern OS and it would require turning on "always-overcommit" configuration, which is *not the default*. And even then I'd rather not see servers crash when someone puts -1 in the length field of incoming data because their authors think allocations don't fail. 
Very nice! Actually, it's not a "new" thing: on [italiancpp.org](http://italiancpp.org) we have promoted this kind of blogging since 2013, thanks to [Coliru online compiler](http://coliru.stacked-crooked.com). [Here is an example of post](http://www.italiancpp.org/2016/04/20/unicode-localization-and-cpp-support/). We always use the latest version of **clang** (with some work we could support also gcc and VC++).
Yes, overcommit is the most stupid thing I've seen Linux do by default
Compiler dev here. Sorry, our code is a bit weird as we have to work around hardware bugs all the time :)
Ok, I had to research this a little more so I stand corrected. But still, to run out, you would need to (with default settings on Linux) allocate 1.5x the size of physical RAM plus the size of the swap. But you're right, it could fail. 
Windows doesn't over-commit on its own, but it still frequently ends up close to the same--the system runs out of space, thrashes while it tries to enlarge the paging file, the user gets sick of the system being un-responsive, and either kills a few processes or else kills them all by rebooting.
I have measured. While there are probably some circumstances under which exception-based code can be smaller, there most certainly are at least some under which it is larger. For a measurement to be meaningful, you have to measure the right things. In the linked article, he measures only size of executable. That's highly relevant if you're interested in the size of the executable, but *much* less so when/if you're interested in the amount of address space being used.
This seems to work in terms of I am able to define the variable that I need, but it seems that I can only define this data in a function. As a Java programmer, it seems only proper to have data that belongs to a certain class. Is this just a bad habit? Should I be nonplussed to store critical constants in functions? My use case is as follows: I'm creating a class to hold a specific kind of shader, so I am wanting to have static const strings members that store the files where this class's shaders are defined. 
At the risk of further aggravating a touchy situation, I see nothing there that qualifies this as being even vaguely similar to an *ad hominem* argument. An *ad hominem* argument takes the form: "this person's argument should be ignored because s/he is an evil person". It can be expressed in many different ways, some of which express the "evil" part quite subtly, but it still always comes down to a claim that facts and evidence should be ignored because the person advancing them is evil. There's nothing similar to that here at all, so if there's a fallacy in the argument, it's some *other* fallacy, not ad hominem.
evil =&gt; uneducated. Definition: "(of an argument or reaction) directed against a person rather than the position they are maintaining." =&gt; "If you think code is more obscure with exceptions, it is because you lack the education (yes, education!) to read it"
Yeah.
Very cool. How much do your readers enjoy the code interactivity? [KLIPSE](https://github.com/viebel/klipse#community) community enjoys playing with code in the browser: the evaluation is done on the client side. Therefore it is even possible to have graphics and animation e.g. [Fractals with python turtle](http://blog.klipse.tech/python/2017/01/04/python-turtle-fractal.html).
&gt; unable to realize what call sites are responsible for which catch statements That is exactly the lack of education I am talking about. By and large, I could not care less which call is responsible. When a call fails, vast swaths of code that follows are dead in the water, regardless of what exactly failed before. Do not trust me, have a look at your own code and you **will** see the same thing. When code fails, bar cleanup and informing the user, nothign happens in a **vast** majority of cases. Cleanup is dealt with by the C++ runtime (destructors are called), and user is informed somewhere in some catch high up the stack once all is finished. In a rare case where I do need to stop and do something exactly when something fails, I need to write that try/catch. But that need, compared to the number of cases where I need to do diddly-squat, is **exceedingly** small.
&gt; that way, you can mash up STL using code with C++ exceptions disabled code very easily, You what?! Unless the interface of STL changes, no you cannot. All modifiers of STL containers can't unform you they failed unless they are all changed. How do you even suggest to change them, when they need to inform of the e.g. element copying failures, as well as their own failures (e.g. oom)?
Well, here are some alternatives: * Conflagrantly quick. * Flamingly rapid. * Sizzlingly swift. * Dazzingly zippy. * Searingly supersonic. 
You can follow a more informed discussion [here](https://www.reddit.com/r/cpp/comments/5msdf4/measuring_execution_performance_of_c_exceptions/dc6r7we/?utm_content=permalink&amp;utm_medium=front&amp;utm_source=reddit&amp;utm_name=cpp) instead of insisting on lack of education, experience and other wide assumptions.
Yes, I stand by that, without wanting to attack you, and will explain else-thread if you are up to it. (I started, see my other reply to you). I wanted you to provoke you, not so much to insult. I do not mind being explained stuff, nobody knows all. 
You can do this: $cat test.cpp #include &lt;iostream&gt; class MyClass { public: const std::string filename; MyClass() : filename("../../foo") {} }; int main() { MyClass myObject; std::cout &lt;&lt; myObject.filename &lt;&lt; std::endl; } $g++ test.cpp $./a.out ../../foo Edit: That didn't answer your question about static const members; those are handled like this: // In the header (.hpp) file: class MyClass { public: static const std::string filename; }; // In the implementation (.cpp) file: const std::string MyClass::filename = "../../foo"; 
There's a balancing act, yes, and I feel a slight tailoring to the various audiences is all that's needed. Worst case, the moderator green-lights you and a few bozos in the crowd leave in favor of a lunch-break. When it's on youtube, the world just has a higher probability of finding your ideas. 
thanks! repo updated now
&gt; Do you ship different DLLs for each version of C++? Yes.
**Company**: [PDT Partners](http://www.pdtpartners.com) **Type**: Full time **Description**: PDT Partners is a boutique quantitative asset manager with a 20+ year history of positive returns **Location**: NYC + LN **Remote**: No **Visa Sponsorship**: Negotiable **Technologies**: Primarily C++ and Python. We also have a significant HPC grid. Due to the nature of our work, I can't go into too much detail :-) **Contact**: Feel free to PM if you are interested or have questions. Apply directly to either [NY](http://grnh.se/f8sg5l1) or [LN](http://grnh.se/i8c6wa1)
It's a mistake to equate _failing_ to _exceptional_. _Exceptions_ are rare per definition and etymology, hence the same should be replicated in code (not only to avoid _confusion_, but also because from implementation standpoint that's what they are meant cover). While _failing_, not necessarily (rare). Constructors as of now are constrained to _fail_ through _exceptions_.
If I recall correctly, it may or may not exist if you're targetting an old OS, or something like that.
IMO if you "do not care about value semantics", you're going to be swimming upstream by using C++ in the first place.
Benchmarks in the README are only there to show off. The really interesting benchmarks are the ones comparing several sorting algorithms with the same algorithms when used as vergesort fallbacks: https://github.com/Morwenn/vergesort/blob/master/fallbacks.md This page does mention the standard library version used for the benchmarks, and does admit that I only produced benchmarks for std::vector&lt;int&gt; of one million elements; the « fast fallback » would most probably be slower on ascending/descendng sawtooth patterns with non-branchless comparison operators, such as std::string's one. EDIT: reading the README again, I even mention that « These benchmarks have been compiled with MinGW g++ 6.1.0 -std=c++1z -O2 -march=native ». Without any more precisions, couldn't libstdc++ be assumed anyway since it's MinGW?
It's intended for more than just arrays. Non member overloads can be defined for user-defined classes as well. So adding a special case for native arrays might not be the right way to go. Interesting idea though.
They will be _candidates_ for being used; whether or not they're _actually_ used depends on overload resolution ranking, just like any other function call.
I'm sorry, what's EDG? 
[Edison Design Group](https://en.wikipedia.org/wiki/Edison_Design_Group), famous pre-C++11 for having a very thorough compiler front-end.
Nope, I've already explained why from start and don't want to get circular: verbosity plus (despite Bjarne's comment) C++ exceptions __are__ a tool tailored for frequent success, not frequent fails. My discurse explains that with many details and examples.
And the ending conclusions (and testament) of that quote are: - __C++__ _exceptional_ doesn't mean "almost never happens" or "disastrous": a digression. - It is better to think of an exception as meaning "some part of the system couldn't do what it was asked to do": just equating it (C++'s exceptions) to any _fail_. I already know it works like that in C++.
First turtle here, sorry, the problem is caused by the turtle below me.
&gt; Would I rely on std::stoi there? Most probably no. Why not? Just because they would be throwing gratuitous exceptions This is a wrong consideration. What matters is: can you continue if that conversion fails. If your number is e.g. the number of elements, the length of your request or some such, you can't, so you should better throw to let the code bail out in the most easy way. Otherwise, you might indicate a partial success and let it continue. Gratuitous, exceptional, blah blah - all irrelevant. It's about code clarity.
If there are disagreements between the declaration &amp; definition or conflicting declarations, I believe the compiler were supposed to error on that as part of the proposal. The STL problems mentioned are with respect to macros I think &amp; that doesn't really apply to code outside the STL which tends to be in good control of the macros (not to mention a very common convention is for macros to be all upper-case which tends to not conflict with identifiers in the first place).
Aborting on memory allocation failure rather than throwing eliminates the vast majority of the places where the STL needs to be able to report failure and in many domains has the same end result.
"Only boring posts on /r/cpp today..." &gt;Compile Time Maze Generator (and Solver) :3
Check [this](https://www.reddit.com/r/cpp/comments/5msdf4/measuring_execution_performance_of_c_exceptions/dc7nmnk/) and beware of the misidentification fallacy. I dunno what strawman you're referring to because I'm backing everything I'm saying with explanation and cases of my point of the contrivement of it in the language. [Are you sure everyone?](https://www.reddit.com/r/cpp/comments/5msdf4/measuring_execution_performance_of_c_exceptions/dc7m89y/)
&gt; a char (commonly 1 byte) Actually the standard guarantees that `sizeof(char) == 1`, so I guess is more than "commonly" :P
Fair enough! What it should say is 1 byte, commonly 8 bits, though that wouldn't be really relevant there.
~~But since the user-defined `begin` and `end` match the arguments exactly they will always be preferred over the templated `std::begin` and `std::end`. ~~ EDIT: As was pointed out below, this original reply was incorrect/imprecise. You can't actually overwrite existing behavior reliably with this mechanism. The idea of these free functions is to *add* missing functionality to classes that you can't change. One particularly important example where this is used are range-based `for` loops: If a class/type already has member `begin` and `end`, then it works automatically since `std::begin` and `std::end` will call them. If, however, you have very old (pre-STL) containers or some other weird library where the containers don't have member `begin` and `end`, you can just add the free function pendants and then range-based `for` will also work since ADL selects the free functions. 
If you are doing literally that loop, you don't need to extract. Just do compare, and, and-not, or as 4 simd ops and you'll do a masked copy of all 16 bytes in 4 in-register instructions. Or, better yet. Use _mm_maskmoveu_si128 and do it in one op from reg to mem.
I usually push for the array syntax since `sizeof` will give you the length of the string (+1 for the '\0') instead of `sizeof(char*)` constexpr char STR[] = "mystring"; //sizeof STR == 9
And also the front-end that powers Intellisense in Visual Studio (which is why we run all the STL tests through it on a regular basis).
I saw the comment you made on the bottom of the article, and I don't know if the author is OP, so I figured I'd post the author's comment from there. You know, for posterity or something. &gt;I love constexpr and it bothers me that the C++ committee designed in such a way that I often cannot use it. Look at the change in https://codereview.chromium.org/2608823002 for example – in that example a const array is defined in one translation unit and use in another. constexpr does not support that. You cannot go “extern constexpr”. &gt;The reason why is because constexpr means “available at compile time” even though I often wish that it meant “generated at compile time”. There is no way in C++ to require that something be generated at compile time without requiring that it be available at compile time, so enforcing my wishes for these arrays is, in general, impossible. &gt;That said, there are some places where I could have used constexpr. I think I tried that and hit internal compiler errors😦
The /r/learnprogramming automod gives you a warning for mentioning it. It doesn't do that for any other tutorials. That should tell you something about how well it's regarded.
**1** The constexpr syntax can be weird because it follows a different rule about what it refers to than `const` does. I'd recommend: constexpr char STR[] = "str"; If it's a static (global) then it will implicitly have a `static` applied to it. **2** You can distribute c++ code to people who don't have to worry about having a full-fledged IDE. I tend to use `scons` for my personal stuff. If you're just learning for fun and want to understand how building actually works, learn how to write a `Makefile` **3** Yeah this is a nightmare and varies wildly by platform. **4** `inline` doesn't really tell the compiler "inline the body of this function." The compiler will decide whether or not to do that on its own. Instead, it's telling the compiler/linker "I am declaring this inline (in a header file) and it may show up multiple times when you are linking, be prepared to merge those multiple definitions if you see them." It let's you define functions in a header file. **5** This is a pretty heavy question and the second part is largely opinion based. `const` (unlike java's final) means that a particular variable will not change. **C++ uses value semantics** where as python uses reference semantics and java uses value semantics in a weird way that acts like reference semantics. This means when you pass an object, you are copying the object, not passing a reference. When you are taking a reference to something you don't intend to modify it makes sense to mark the reference as const // return the number of times `c` appears in `str` int count(const std::string&amp; str, char c); though you should note you can always just copy a const object. const std::string s = "hello"; auto s2 = s; // copies all of s (doesn't copy a reference) s2[0] = 'a'; // s is unchanged This is true for returned objects, it would be weird to write const std::string f(); because the caller is going to (conceptually) create a copy of whatever `f` returns, the copy may or may not be `const`, regardless of what `f` says it is returning. If you want to return a `const` *reference* that makes a little more sense class Person { public: const std::string&amp; name() const { return name_; } private: std::string name_; }; The above lets someone look at a `Person`'s name, in a way that doesn't allow them to modify the name, and doesn't create a copy of the `name_` in the process (though the caller can create a copy if they choose). **6** It's not unusual to do what you have. Any decent compiler will warn you if you have listed the objects in a different order than they will actually be initialized. They will be initialized in the order they were declared. Keep doing what you're doing. **7** Destructors are meant to free resources that your class owns. When an object is destroyed, it will run the body of its own destructor (if user-defined), then destroy each of its data members in the reverse order that they were constructed, then invoke the destructor(s) of its base class(es) if any. Destruction of objects happens at well-defined points unlike python or java. A `std::string` is implemented using an underlying dynamically allocated array of `char`s. When it is destroyed it needs to delete it. A `std::ostream` needs to close the file that is open. A `std::unique_ptr` needs to delete the object it owns. There are other ways to leverage destructors. For example, if you have a mutex, instead of m.lock(); critical_section(); m.unlock(); You can use a `lock_guard` which will lock the mutex on construction, and unlock it on destruction. This handles early returns, exceptions, breaks, etc. { std::lock_guard&lt;std::mutex&gt; guard(m); critical_section(); } This leveraging, and destructor/constructor pairing in general is known as RAII and is probably the **most** import concept to using c++ well as opposed to writing java in c++
True, point taken. My wording above was incorrect/imprecise. However, this is an example where the `int_range` already has an STL conformant interface and there is no need to implement the free functions at all. If you intend to use a class with the STL or other generic algorithms then both member and non-member `begin` and `end` should do the same thing (if both of them exist), thats what the writer of the generic algorithm expects. As always: If you violate implicit contracts that the library you use imposes on your code you can expect weird behavior.
I was trying to make a point about expectations regarding ADL, not specifically `begin` and `end`. And in my example, member and non-member `begin` return different types where only the latter (non-intrusively) implements the expected interface.
Making globals `const` is commonly overlooked. I don't know how many times I've seen code like: const char *g_bla = "abc"; which has declared a non-const variable `g_bla` and so it goes in the modifiable data area or whatever. Working in embedded development and regularly inspecting linker maps, I'm keenly aware of this but it's easy to see how it could fly under the radar for others. Better would be `const char *const g_bla = "abc";`, or `const char g_bla[] = "abc";`. ---- In theory it should be possible for implementations to detect, in some cases, when a variable was not declared `const` but could have been, and issue a warning. 
It's an unfortunate reality: real-world programming diverges from idealized programming occasionally. I don't like having to write the following code (pseudocode here), but practical concerns dictated it: #ifdef COMPILER1 #define STATIC_ZERO_INITIALIZED = { 0 } #else #define STATIC_ZERO_INITIALIZED #endif LargeStruct bla STATIC_ZERO_INITIALIZED; One compiler would leave global variables uninitialized if they had no initializer. Another compiler would correctly initialize globals with no initializer, however it would bloat the executable with a huge block of zeroes in the data section's initializer if you did put `= { 0 }` ! 
Agree. I never use `const` member variables, it just makes the code less efficient and makes move semantics difficult or impossible. Same goes for reference members. There probably are a small number of valid use cases for those things but I feel that they are over-used in general.
I feel the language could benefit from a way to mark a private variable as only writable during construction or assignment. On the other hand, for classes that don't use pImpl, that's yet another implementation detail exposed in the header which is none of the business of the class user. 
How do you declare a function specialization to handle a templated parameter type? 
NP. The difference between an overload and a specialization is a common point of confusion though.
There are embedded chips where the smallest type is 16 or even 32 bits. sizeof(char) is still 1 on them even though it's not an 8 bit byte.
The clarity of both success and the error path. [An example](https://www.reddit.com/r/programming/comments/5laqwd/keep_disabling_exceptions/dbxp2bs/?utm_content=permalink&amp;utm_medium=user&amp;utm_source=reddit&amp;utm_name=frontpage) The happy path is trivial to read, it's right there in front if your eyes. The error path is **also** trivial to read (and this is what you don't seem to be able to understand). It is trivial because it reads like this: * any errors are dealt with (most often, merely reported) in a rare catch block * any resources are cleaned up and partial state is rolled back here: --&gt; ***}*** That's it. It **is** trivial compared to reading the usual forest of conditional logic, obscure patterns to deal with failures of which everyone and theirmother has a slightly different personal favorite (do/while with break galore; gimme a break!) gotos and whatnot (goto, while shite, is still the best). Problem with error-return is, always has been, that the failure modes of reality are many and diverse. When you put them all at display, you positively destroy legibility.
I read the one with a protocol, and addressed it, but you failed to defend your point further or refute mine. That's because you don't have what to refute with and are trying to wiggle your way out. Yes, there are situations where using exceptions is less expedient. But those situations are **rare**, and it is trivial for you to see that. A simple inspection of whatever code **you** write will show you that in a vast majority of error cases, your own code just bails out. Exceptions are facilitating that. Do you have something publicly available? Let's have a look together. Unless it's something trivial, what I claim **will** be true. Your opposite examples are attempts to throw the baby with the bathwater. It's dishonest.
The term *method* has the same meaning in every object orientated programming language I ever have gotten in touch with. COM is not a programming language, so it is no big deal to be aware of the different meaning as it refers to a different context. To be honest I have never read the term *member function* in the context of Java or Scala. Even in Python *method* is commonly used term. In the context of C# I am not sure anymore... So what's left? Perhaps someone could say something about the term used in Ruby, Groovy, C#. I think we would have covered then the majority of commonly used OOP langs? On the other hand perhaps you could provide a counter example?
&gt; why not just add begin(), end(), size(), etc as methods on array objects? First, arrays aren't "objects" at all. You couldn't just glue this in, you'd have to do major surgery. But more - it's better to have these as external functions, because it's often useful to allow Koenig resolution to pick the function you want. Typical example: template &lt;typename T&gt; void someFunc(T&amp; x) { using std::begin, std::end; for (auto i = begin(x); i != end(x); ++i) { // .... So if you have declared your own `begin` and `end` functions that match, those are used - otherwise, the `std::` versions are used.
&gt; First, arrays aren't "objects" at all. What..? [dcl.array]/1: "*An object of array type contains a contiguously allocated non-empty set of `N` subobjects of type `T`.*"
That's the thing, ws2_32.dll is always there since Windows 98 and I don't believe Chromium targets Windows 95.
From [Wikipedia](https://en.wikipedia.org/wiki/Salami#Etymology): &gt; **Etymology** &gt; The word *salami* in English comes from the plural form of the Italian salame. It is a **singular** *or* **plural** word in English for cured meats of a European (particularly Italian) style. 
Libraries / Dependencies The whole abundance of libraries comes from the C traditions of the Free/OpenSource movement. The GNU-autotools made easy to build and install, then GNU/Linux distributions like Debian has made easy to uninstall and manage versions and dependncies. So, preferred way is the language-independent package manager of your OS distribution. You use package manager to install all dependencies, then CMake stops complaining about missing libraries, and builds your code. Normally, you make your library or program opensource. Then, if it's useful, there are people that turn it into a package for their favourite OS distribution (like Debian, Arch or Mac OS). The package contains a built version of the software. They push it to the main repository of that OS (apt for Debian, brew for Mac, etc). Here the dependencies are managed. That way the users don't have to use a dozen of language-specific package managers (pip, npm...). Also, there is some kind of quality assurance from the package maintainer. Maybe a pain for a developer and slower releases, but it's good for the user.
I know author will not read this, but he needs to understand that committee ( that I think is failing quite hard, but lets not get into that...) is that C++ can not have any feature that somebody might find useful. You need to prove that it is really useful to a huge number of people and worth the effort to add it and for devs to learn it.
[removed]
You are both right; arrays are not objects in the sense that they are not instances of classes, i.e. they are not some sort of "smart entity" with member functions and variables (pardon me for the made-up word, but I had to since it's the words themselves being discussed here). They *are* "objects" in the broader sense, which is how this passage uses them. I think the standard favors the term "instance" for this reason.
&gt; This is incorrect. OOM is recoverable, it's just difficult. I agree, this was poorly worded. But most out of memory handlers just log and abort. If you don't have exceptions the easiest thing you can is just call a handler function and abort, instead of having to deal with nullptrs all the time. &gt; Neither true nor helpful. I was referencing something Bjarne said at the keynote of Meeting C++: https://youtu.be/DvUL0Y2bpyc?t=10m53s
&gt; you have put up trivial code samples to demonstrate RAII and exceptions at its best ... Well, yes, benefits of exceptions are visible starting from trivial samples, but where this actually shines is exactly at a scale. But more importantly, you should note that this sample is applicable not only for "external " resources (e.g. a file handle or some such), but also for all sorts of intermediate state changes, for which one most often needs the so-called strong exceptions safety, making the need for such code much more pervasive. But even if there is 0 side effects, even if it's a simple get-a(params), get-b(a), make-c(a, b) return c code clarity still benefits from exceptions compared to tbe above being intermingled with "did I get a? Report this error to caller! Did i get b? Report that error to caller!..." On an unrelated note... funny how C++ people came up with those exception safety terms, when in fact those things apply to error-return code **in exactly the same way**. Tells you something about how exceptions bring... *clarity* in thinking ;-)
And as if by necessity, make function has a bug - doesn't pass "ec" parameter to resource creation function :-). I participate(d) in the linked discussion - shame on me! :-)
Euh, shouldn't I really always want my move ctor to be non-throwing, exceptions or not?
set_union can actually choose elements from set B, even if an equivalent element is present in set A. The case arises if there are more copies of such element in B than in A. In fact, the library doesn't make the set-theoretic assumption that elements in set A and B are unique (modulo equivalence).
I disagree. The definition of "object" is provided by the C++ Standard and there's no "broader sense" or room for interpretation. Arrays are objects. Period. Objects of class type are "objects of class type".
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/5n6o8k/help_in_reading_a_ppm_file_in_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
A number of people on the C++ committee do read /r/cpp. And the committee is well aware of the tradeoff between functionality and complexity. Complexity and "teachability" are frequently brought up during discussion of proposals. Thank you for the feedback, though. It's important that developers reach out to the committee on topics like this. 
&gt; However, if it's not aligned, by definition the data is spread across two words, requiring the CPU to read from two addresses, each contain part of the data. Actually, unaligned data is Undefined Behavior. Some compilers allow it in a restricted set of circumstances (notably with packed representation), but having unaligned is otherwise bad news. While the x86 family of CPU can load misaligned data, at a cost, there are CPUs out there that will simply crash if you attempt to do so. And of course, since we are talking about UB, remember that the compiler *expects* data to be aligned. This may lead to surprising optimizations! Those optimizations have for example shown up to people trying to optimize comparing byte arrays by using `reinterpret_cast` to larger integer types. The compiler accepted the cast, but deduced that the resulting pointer was necessarily correctly aligned and removed all the code to handle potentially misaligned data. &gt; When optimizing for memory performance, it is a good idea to order members by decreasing size. Size and alignments are unrelated. The best example is that `std::array&lt;unsigned char, 16&gt;` is 16 bytes, but 1-byte aligned. To optimize for memory size you can start by ordering members by decreasing *alignment* requirement. However that is not the full story either. Why, just today I had an issue with a simple case: // sizeof(X) == 112 struct X { std::uint64_t a[13]; std::uint32_t b; }; // sizeof(Y) == 136 struct Y { X x; std::uint64_t a; std::uint64_t b; bool flag; }; Isn't it frustrating to miss the double cache line size (128 bytes) by just 8 bytes? But what can I do, I'm already following the order by alignment guideline! Well, turns out that there *is* an optimization remaining: a child class may make use of the padding of its parent class to stash some of its own members! Thus, changing the definition of `Y` to: // sizeof(Y) == 128 struct Y: X { bool flag; std::uint64_t a; std::uint64_t b; }; allows the compiler to stash `flag` in the unused padding at the end of `X`, thereby reducing the overall size of `Y` by 8 bytes! &gt; When optimizing for memory performance, it is a good idea to order members by decreasing size. On another note: performance is a vague word. I advise you use "memory footprint" instead. Indeed, another way of optimizing memory layout is to split the *hot* fields from the *cold* ones. The general idea is that you should seek to avoid polluting your CPU cache with useless (not read/not written) data. If you are interested in such splits, you might want to read about SOA: Struct of Arrays, which advocates using a struct of array rather than an array of struct, in some situations. (I see that you touched upon that in your Offset calculation section: note how the magic number was 128, aka two cache-lines) 
Great insights, thanks! I'll make sure to update my post accordingly. I knew about the SOA types but they seemed a little out of scope, but maybe I should mention it. I didn't know about the child class optimization though, that's actually really interesting!
What makes it difficult is how you recover from the user prospective. Recovering such that your app keeps running isn't difficult, but recovering in a way that isn't just "oops, sorry can't do that" can be exceedingly complex (unless you're in a very targeted scenario like `inplace_merge`). Also note that a very popular platform overcommits by default, and in the event of physical memory exhaustion just starts arbitrarily killing programs. Physical OOM is unrecoverable on such platforms, and virtual OOM should cease to be a thing once we're in a 64 bit world.
Absolutely. Reworked the article a bit to take your point into account. Thanks!
The way I tackled this problem at work with the objects whose constructors could fail was to save a member boolean called something like `create_success`, set to true if no errors and false otherwise, and made the object convertible to bool: operator bool() { return create_success; } then Foo f(args); if (f) std::cout &lt;&lt; "The operation was a success." &lt;&lt; std::endl; else std::cout &lt;&lt; "The operation failed." &lt;&lt; std::endl; That seemed a lot more idiomatic than any other options, if you don't like exceptions?
The short version is that some STL implementations have plenty of throwing moves. I would _strongly_ prefer that move operations be _required_ to not throw. Sadly, for back-compat reasons now, that can never become the rule in C++. :(
Now you should also implement a vtable while you're at it, and then maybe in a few years someone will come up with c++++ on top of it which will add a `class` keyword or something like this where you can put function implementations inside also, for hell's sake : [switch to 17 on line 27](https://godbolt.org/g/HnrNlp) (and first look at that sweet sweet line 5 in the assembly code)
The question was, whether the term *method* and *member function* (from the C++ context!) are interchangeable. As *method* is the language aware term for the C++ called *member function*, the answer should be *yes*, the terms are interchanagable. Of course the discussions here are always located within the global context of C++, but that does not mean that one should close his eyes when it comes to fundamental concepts and their terminology.
&gt; virtual OOM should cease to be a thing once we're in a 64 bit world. It is a thing when dealing with untrusted data: `std::vector&lt;int&gt;(packet-&gt;size);`
From the pure technical pov, yes. But they behave almost like free functions known from other languages like C++. The same is true for Scala, which also must model free functions internally as objects (probably all JVM based languages must do something like this - but that is more an implementation detail imho)
&gt; Don't see how it can be false when the word "method" has no meaning in the language. It is the universal, language agnostic term for the C++ish name *member function* - so, yes, it can be false to use this for a *free* function in C++.
Hm... in combination with a lambda it looks like a function if you ask me: Func&lt;string, string&gt; convert = s =&gt; s.ToUpper(); Of course the compiler will (probably) convert the lambda into an anonymous object that implements an interface, but to the client it does not feel like a method.
True. But hopefully you aren't blindly allocating as much memory as some untrusted data told you to?
right, 0 is the default, it fails mallocs that "for sure" can't be satisfied. It does give a sizeable window, true - a sucessful malloc does not guarantee memory availability. "always overcommit" or "malloc never fails" or "malloc only fails when running out of address space" that I often see mentioned by people who should know better, is mode 1. In that mode malloc fails by exceeding current rlimit, by exceeding virtual address space, and by (glibc) malloc's own sanity checks (requesting -1 does that). 
D:
why isn't `std::nth_element` similarly guaranteed to be `O(N)` worst case?
You know, "FU" just hasn't meant the same the me ever since we added the [Name Forced #using File switch](https://msdn.microsoft.com/en-us/library/81ex1b0a.aspx) to MSVC. But I get what you're saying here. I personally voted against the co_ rename, but I accept that the committee reached consensus for a variety of reasons. I don't think you're a random Reddit jerk, though I haven't seen you around /r/cpp much. And I agree that there are a few C++ TSs that I wish could have made it into '17. But that's the nature of committee. Lastly, if you want a scientific poll, asking MSFT devs about co_ keywords probably isn't the way to do it. I think that would come down heavily in favor of the original keywords. But MSFT C++ developers are a small percentage of all the C++ developers out there. 
Yay for not that trap, but boo for those of us writing death test harnesses where we need to recursively invoke ourselves :) https://gist.github.com/BillyONeal/5e039b62d5bbbe1155ee60f8c75d6eb9
cppreference.com and www.cplusplus.com and the two biggest c++ resource the I know bu I use cppreference.com more now as is is update to the latest standard but www.cplusplus.com might be just enough to get you caught up
Check which standard library you are using you might be using libstdc++ or you might be using windows standard library implementation since the code is templated it still might be using libstdc++ but try with other standard library implementation like libc++ or visual C++
As you mention in your article, the term "set" in a C++/STL context has a specific meaning that's different from the usual mathematical meaning. To avoid confusion, can I suggest using a different term, such as "collection" or "sequence"? 
I am not sure whether that is possible.
Cute idea, but it really needs a motivating example that isn't insane.
Yep, sounds like an oversight to me.
How many subreddits are you going to spam to? Now it's five.
The intention of this post is to show how a behavior can be attached to an object dynamically using lambdas. It is common practice in some dynamic functional languages, e.g javascript. But, i agree that this post fails to present a convincing example that has some practical value. Thanks for shooting it down. It deserved that. 
I'm incredibly new to the world of C++, so I was just doing a solid to author by making sure that his response was seen. It looks like iaanus updated with a continued thread as well. I can't speak to the nature of changes and the committee at this point. :/
[removed]
&gt;In a C++ codebase you're more likely to find COM than C# or Java. ;) In a *Windows* C++ codebase. 
&gt; I think that would come down heavily in favor of the original keywords I am shocked, shocked to learn that... :) With MSFT I just meant that you are in position to do that, Caruth and Wong could do it in their organizations... And yes not even those organizations are truly representative, but if MSFT came with 90%, IBM with 70%, Google with 95% ISO would need to turn Occam's razor into a wooden cube to claim that those developers are so out of touch with your average Joe. But anyway that ship has sail... I mean train has left the station. Thank you for your vote of reason. :) 
Eh... The number of times I've seen settings to prevent that and users cranking sengs up to 4GB or some other unreasonable value...
&gt; recovering in a way that isn't just "oops, sorry can't do that" can be exceedingly complex True, but I would say that a mere "ooops can't do" is huge WRT user experience and troubleshooting ability. I would also guess that a sudden huge request where there is memory otherwise isn't all that unfrequent. I usually blame the OOM killer for people failing to think and go down the "bah, don't care *at all* because OOM killer" route.
[removed]
This is a new paradigm - NOOP (Non-Object Oriented Programming). Main feature is that state and behavior are separated from each other.
Don't listen to people who say not to get this book and read something like c++ primer instead. Its completely idiotic. This book is great for beginners to get a fee for programming. Once completed, then move onto c++ primer for a more in depth view of the language. Starting with a reference book is such bad fucking advice and I see it all over reddit.
I hear your suggestion, it's true that this double meaning between std::set and std::set_difference can lead to confusion. I'll try to think of rewording this
* Slides: http://www.srl.inf.ethz.ch/workshop2016/Su.pdf * Video: https://www.youtube.com/watch?v=x4JUUlO9XGY * Project Homepage: http://web.cs.ucdavis.edu/~su/emi-project/
Why not use your own frontend?
Yes, basically. But it also has some sugar around it.
&gt; They have grown on me as one of the worst tools on error handling there's. Propagation of error information **using error codes** up the stack, is a lot more messy than exception handling, due to the following two reasons: - it is repetitive boilerplate code - it can be ignored in client code, implicitly (you implicitly ignore the error, not implicitly fail because of it) Additionally, the effort to keep the application state consistent in the presence of errors is the same using exceptions and using error codes. People usually miss this aspect, as most people teach you for example, that this is the code to write a string to the console (in C): printf("%s", your_string_here); ... when in fact in projects that need to keep consistency in the presence of errors, the code ends up looking more like this: int rc = printf("%s", your_string_here); if(rc &lt; 0) { // printf failed completely; // TODO: return an error code speciffic to output errors, so // the client may choose a different way of retrying the // operation in some retry dialog (printing to a file for example) } else { int size = strlen(your_string_here); if(size != rc) { // printf failed partially; different error handling strategy, or // return code may apply here ... } } In the most simple cases you just need to check the result for success; nobody bothers to do even that, to the point where you will see 99% (source: made up statistic :) ) or more of printf calls running unchecked (in tutorials, books, examples, etc).
I'm actually surprised that something like a satellite driver would use memory allocation after initialization. Wouldn't it be safer to grab all of the needed memory up front and then split it into pools for each system?
Why not beheader? ;)
I realize it, it's a good point indeed. What's is interesting though is how the proposition of having language constructs for enforcing/expliciting _non-exceptional_ error checking is [the most downvoted comment here](https://www.reddit.com/r/cpp/comments/5msdf4/measuring_execution_performance_of_c_exceptions/dc6gx57/). Maybe the reddit audience don't care whether there're gonna be checks or not? It baffles me. Anyway. I advice you to check error handling mechanisms in other languages, different languages, like rust, [purescript](https://pursuit.purescript.org/packages/purescript-exceptions/1.0.0/docs/Control.Monad.Eff.Exception#v:throwException), [haskell](http://book.realworldhaskell.org/read/error-handling.html), etc, there're some good alternatives for not appealing to exceptions (worse with _C++_ exceptions) as default mechanism for failing. There's still one good thing that basic return error handling do that C++ exceptions don't. They can be in the prototype. On your second bullet you talk about how C++ exceptions can't be ignored. Yes, they can't be ignored at runtime when they get thrown, but they do can be ignored while coding when simply calling a function and not knowing what it may throw. And worse, this can compose, in the shadows. Exceptions could have been used judiciously, but they got/get entrenched where they shoudn't + more flaws that leads to \^ If you want to read more arguments, [check this ](https://www.reddit.com/r/cpp/comments/5msdf4/measuring_execution_performance_of_c_exceptions/dc8qc2b/) and the accompanying references.
I must say I was a bit disappointed by the SG14 paper trails on this subject.
I can't agree more.
Yess, we need even bigger hammer for that screw.
Well, modules will be out anytime now... 
That makes sense, thanks for clarifying :)
came to comment the same thing lol
In *any* C++ codebase. C++ compilers can't compile C# or Java.
My extremely limited understanding is that in 2010 (when the current Intellisense frontend was put in place) C1XX was not in a place where it could provide the kind of data the IDE needs. It is/was focused purely on code generation.
Not for a loop with multiple exits, then it's not implemented in LLVM. A find loop has two exits -- either the element is found, or the iterator has reached the end. *LLVM cannot unroll loops with multiple exits* https://llvm.org/bugs/show_bug.cgi?id=27360
&gt; What's is interesting though is how the proposition of having language constructs for enforcing/expliciting non-exceptional error checking is the most downvoted comment here. I didn't downvote this, but I see why one would. Without some elaboration, it is rather an empty assertion. &gt; check error handling mechanisms in other languages, different languages, like rust, purescript, haskell Yeah, perhaps. In my opinion, only Haskell brings something interesting (really good in fact, due to pattern matching). Rust, for example, just makes error-return somewhat more palatable, but it's still the error-return maze I don't care for. &gt; there's still one good thing that basic return error handling do that C++ exceptions don't... I find this complete paragraph ass-backwards. In C and C++, error-return gets ignored extremely easily, being in the prototype doesn't help all that much. As for exceptions, most of the time, I do not care if a function y out of some x-y-z sequence failed. I only want to know the failure details, which an exception can give me. From there, I can inform the user if the situation is out of my control (dominant case), or I can use error information to take corrective action. Example: I want to read a CSV file into a vector of records. So the code needs to open, read stuff, deal with I/O and parsing errors. But the user (caller)? No he doesn't. No code cares whether file open failed, nor why, or that the the text-&gt;record conversion function failed. The important thing is only the error information, not the exact function who failed. Bar a rare situation where you can ignore the error, and therefore a throwing function is inconvenient, why do you think you need to know if a function can throw?
I tried it not too long ago, and it's changes cause my project to fail to compile. There might have been something obvious that I should have changed, but I came away with the impression that it's not a "safe" operation.
no mention of `std::variant`, `std::any`, or `std::optional`?
Very cool! Am I the only one that feels it's kinda awkward supplying overloads in the std namespace? Does structured binding not use ADL when it looks for the tuple_element &amp; tuple_size?
if I'm correct those things you've mentioned are in the Library Fundamentals 1 TS. I probably need to expand that item to be clear.
Conclusions are relatively short, yes, but meaningless without justification.
They _were_ in the TS; they're in §20.7, §20.8, and §20.6 respectively in N4618 (current C++17 draft).
Nice! The GCC team has managed to get C++17 complete two time!
Congratulations to the GCC C++ team including their library team because they are also advancing at a good clip. Filesystem and Parallelism TS implementation/integration are the major missing parts there. Clang/LLVM is close too (although I haven't checked on their library in a few months). I recently moved an embedded project over from Gcc 4.4.1 onto Gcc 6.2 and saved 51 kb in code size while passing an exhaustive test suite and real-time testing in the first try. At this point quality is so good the actual switching of release versions usually just reveals a few new warnings or errors that we fix and then we fire it off to our test systems (a full run takes a few days).
Fantastic news. For reference, here is the corresponding [C++17 status table for libstdc++](https://gcc.gnu.org/onlinedocs/libstdc++/manual/status.html#status.iso.201z).
What sort of app is it that a full test run takes a few days? That sounds interesting.
Probably stress testing. God knows how many bugs the "Repeat this a million times and then ship the log to the hardware guys" tests have uncovered.
I'm glad all C++ code is written in your exact field to handle your exact use case. There are good reasons to use exceptions. There are good reasons to not use exceptions. There are good reasons to enforce this with -fno-exceptions. You didn't make a single point in favor of exceptions, or highlight why -fno-exceptions is a bad idea. Frankly, you sound like the worst kind of person to have to work with. 
You assume people use exceptions properly all the time. 
Got me there, should have specified graphically intense AAA games. Eg Unreal Engine doesn't ship with exceptions enabled. This is their explanation: https://answers.unrealengine.com/questions/264921/cannot-use-try-with-exceptions-disabled.html
The SDK for one of the major consoles (like, yeah, one of those ones) uses exceptions extensively. Source: I've been working on console games for over 10 years. It's more complicated than "never use exceptions" or "exceptions are fine, use them whenever". The implementation of exceptions depends on hardware and compiler. But it is possible to have code that uses exceptions with "zero" cost except when propagating exceptions, and on modern compilers on x86 that's probably what's happening. The good part about C++ is that you can make this choice yourself, after *doing your research and determining what makes sense for your application*.
If there is a finite set of possible string values that you want to switch on, maybe they should be converted to an enum value? I don't see the point in retaining the string representation when there is only a small finite set of valid values. Throwing the strings away asap would help with separation of concerns. This also makes it easy to modify the list of valid strings later. Interesting idea nonetheless.
Who?
well, STL said to make sure there was only one posting per "company" and I'm only recruiting for the one bit of a very large entity. Didn't want to preclude other MS parts from posting. 
``convert`` is the function name; you would call it like convert("foo"); looks like a function call, doesn't it?
Eric Niebler, Beman Dawes. Dave Abrahams is still my first vote though!
Nice introduction to type erasure and `std::function`! It might be worth noting the overhead to these techniques; I see many people using `std::function` all over the place because they're not aware of the cost of using it over templates.
Chandler Carruth is always interesting. So is Andrei Alexandrescu. Have you contacted Scott Meyers ? I thought he did not want to remain involved with C++.
I don't doubt it. However, for S.Meyers, it's a complete different story I think. Sadly.
Alex Stepanov
Howard Hinnant, STL (the man, not the library), Louis Dionne.
yes, re Dave Abrahams, especially the Swift vs C++ comparisons, what has he learnt that could benefit C++.
Best comment, /r/cpp, 2017.
Sure this must hurt then: vector&amp; operator=(vector&amp;&amp; _Right) { // assign by moving _Right if (this != &amp;_Right) { // different, assign it _Tidy(); this-&gt;_Move_alloc(_Right._Getal()); _Move_from(_STD move(_Right), _Disjunction_t&lt; typename _Alty::propagate_on_container_move_assignment, typename _Alty::is_always_equal&gt;{}); } return (*this); } Any chance you will see a doctor about reusing the existing buffer if the moved-from buffer cannot be stolen?
My vote goes to Eric Niebler and Andrei Alexandrescu. Also to the people suggesting STL, doesn't he hang out here all the time anyway?
You've got to be a bit careful: you can remove a header, still compile and get different behaviour. For instance if you're unfortunate enough to have template specialisations or overloads living in different headers. I guess it could warn you if the emitted object code is different.
Your Latin motto would then be ["nomen est omen"](https://en.wikipedia.org/wiki/Nominative_determinism). 
I am looking at VC15 RC1 (14.10.24692) and see pretty much the same code. Just has `noexcept` stuff added. Has the implementation changed in RC2?
Thanks! Fixed.
John carmack Tim Sweeney Sean parent Jon Blow Casey muratori Matt pharr Most of the names people have already put have been people that already speak at conferences all the time and are C++ specialists. It would be cool to get very experienced programmers who might not be 100℅ C++ to see what they think and mix it up a bit. I think with the same people it ends up being more of an echo chamber.
Second that. John Carmack would be neat even though he is not 100% C++ oriented. Would be nice to know what he thinks of the language now and the directions it's taking (if he ever keep tabs on that).
It was illegal to overload `get` within `std`; you are only permitted to specialize templates for your types (with rukes), any other injection into `std` makes your program ill-formed. The ADL solution is legal and the correct way. The `tuple_size` specializations are awkward, but are the only way as well.
Aren't you looking for something akin to [gperf](https://www.gnu.org/software/gperf/) ?
It has been demonstrated time and time again that there is no performance problem with exceptions on modern hardware. They are actually often faster than traditional error handling methods because the separation allows the hot path to be branch free. 
Sean Parent talked about something like this one year earlier, too. Here are the related talks: The 2012 talk ["Value Semantics and Concepts-based Polymorphism"](https://www.youtube.com/watch?v=_BpMYeUFXv8). It's a good talk with poor audio quality. The 2013 talk ["Inheritance is the Root of All Evil"](https://channel9.msdn.com/Events/GoingNative/2013/Inheritance-Is-The-Base-Class-of-Evil). 
And clang status for comparison: http://clang.llvm.org/cxx_status.html#cxx17
llvm's libSupport has a nice approximation of this: http://llvm.org/docs/doxygen/html/StringSwitch_8h_source.html
Some more interesting people who weren't mentioned yet: Kate Gregory, Mike Acton, Stephanie Hurlburt and Sean Barrett
Wasn't 4.0 supposed to be for March this year?
+1 to all of your suggestions :-) As for the GCC folks -- I'd also love to hear from (well, OK, not strictly restricted to GCC): * Andrew Richards // Codeplay * Jakub Jelínek // Red Hat; the GNU C Library * Jan Hubička // SUSElabs; x86-64, PDO, IPO, LTO, devirtualization * Jason Merrill // g++ maintainer * John Regehr // compilers correctness :-) * Jonathan Wakely // GCC maintainer * Marshall Clow // libc++, std. lib. for LLVM * Nick Clifton // Binutils chief maintainer * Torvald Riegel // concurrency, parallelism, toolchain * Ulrich Drepper // for the old times' glibc sake :-) 
I don't write all that much code for public use, and I write even less that uses template magic, so hit me with as much criticism as you can - I want to learn!
Distributions should be relatively cheap to instantiate. Have you checked the generated assembly *(or profiled)* to check if adding `thread_local` is beneficial/detrimental?
&gt; Go get a brain and learn to talk through your mouth instead of your ass. if you have nothing smart to say, just learn to shut up.
I haven't profiled yet - thread local was part of the randint implementation that I carried over. I'll definitely check it out though! As long as my logic is sound, using thread local over static should ensure that multi-threaded code with non-determinable execution ordering remains predictable.
Bug, though maybe "implemented at a time when the thing [wasn't fully specified](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0512r0.pdf)" would be a better description (note that godbolt's GCC7 snapshot rejects `vector v{1,2,3,4,5,6,7};` completely). The current wording says overload resolution is done as if initializing a hypothetical object of a class type whose constructors are synthesized from the implicit and explicit guides, so for list-init you do the usual ritual of trying `initializer_list` only first.
Well he has [retired](https://www.reddit.com/r/programming/comments/3yyenk/scott_meyers_to_retire_from_the_world_of_c/) in fairness.
&gt; I don't feel like gong through the "good vs bad" talk again. This has been talked through so many times on this website, and repeating terrible arguments for disabling exceptions (IN A DEFAULT DESKTOP SITUATION) does not make those arguments less trash. So then why did you post anything? You aren't adding to the conversation, you are throwing out an opinion without any backing, and on top of that you are trying to make it sound like it's a completely white and black issue when it really, really isn't. Even on modern desktops, there are application areas where you easily could make a well reasoned decision to forgo exceptions. These type of decisions are design trade-offs, and there are always pros and cons to each side; neither side is 'trash'. 
Niklas Frykholm has some good original ideas 
I considered making the engine manually selectable but chose not to because of the idea that this was meant to be minimal and consistent. I feel like the "default"_random_engine performing badly is a fault that should be resolved by the libstdc++ team surely? 
&gt;When the compiler sees vector b{a.begin(), a.end()};, it instantiates the deduction guide with int* as the template argument This is inaccurate. Actually the type of the expressions `a.begin()` and `a.end()` is `vector&lt;int&gt;::iterator`, which may be different from`int*`. (For instance, it's definitely not a pointer on Microsoft compilers.)
Alex Stepanov retired a number of years ago, though that doesn't necessarily count him out.
I'm looking at yesterday's daily build (v19.10.24911), and yes, it's quite different. ;-]
You can always make an appropriate choice on behalf of the library user.
Sorry you are right. The branch is happening today for the upcomming release. I was referring to [this](http://lists.llvm.org/pipermail/cfe-dev/2017-January/052104.html). But yeah you are right 4.0 is comming in [march](http://blog.llvm.org/2016/12/llvms-new-versioning-scheme.html)
Any default case may collide with one of the strings you are explicitly looking for, but be not the string you are explicitly looking for. A matching hash does not imply equality.
Syntactically, yes; semantically, no. `convert` is an object and becomes the "this" parameter. Free functions have no "this".
Wow, that's a bug! (An obscure performance bug, to be sure, but my vector overhaul wasn't supposed to contain any of those.) Filed as VSO#367146 "&lt;vector&gt;: Move assignment should reuse the buffer when possible". It's too late for me to fix this in VS 2017 RTM, but I'll look into it for future Updates when I get a chance (it's easy, we've just got a lot of stuff to do). In the meantime, please accept some reddit gold. The issue, which I missed and nobody else noticed during code review, is that I was too aggressive in reusing code between move construction (which lacks an old buffer, obviously) and move assignment. `_Tidy()` destroys all elements and deallocates the buffer, but there are rare situations in which we can reuse it. When we're POCMA (so we can move-assign the allocator to make it equal), or allocators are always equal at compile-time, or allocators happen to be equal at runtime, we steal the source's buffer (in which case tidying the old buffer is correct). However, when we're non-POCMA non-equal, then `_Move_alloc()` does nothing (so we don't need to drop the old buffer for it), and if the source is small enough, we could reuse the old buffer. Instead, because I aggressively tidied it too early, we allocate a fresh one (using our allocator which isn't changing). I just need to conditionally tidy, and rework `_Move_from()` accordingly (possibly splitting it for construction and assignment). My copy assignment operator is unaffected: vector&amp; operator=(const vector&amp; _Right) { // assign _Right if (this != _STD addressof(_Right)) { // different, assign it #pragma warning(push) #pragma warning(disable: 4127) // conditional expression is constant if (_Alty::propagate_on_container_copy_assignment::value &amp;&amp; this-&gt;_Getal() != _Right._Getal()) { // reload array _Tidy(); } #pragma warning(pop) this-&gt;_Copy_alloc(_Right._Getal()); assign(_Right._Myfirst(), _Right._Mylast()); } return (*this); } There, I'm tidying only when necessary (POCCA non-equal means that allocator copy assignment is going to dramatically change the allocator, so we need to get rid of our old buffer while we still can). Then, `assign()` is careful about reusing storage.
Fair enough :)
~~Tim Sweeney is a C++ specialist? That's news to me!~~ Edit: d'oh! Nvm, misread the original comment.
Tim Song.
As Max_yask mentions, that's part of JPL's C standard for all firmware in flight hardware (particularly that which is part of the control system of any given mission) Its an intimidating but nice set of standards that can be an interesting read: http://lars-lab.jpl.nasa.gov/JPL_Coding_Standard_C.pdf I've attempted to program to this standard when working on the low-level firmware for a CubeSat, and I agree that not dynamically allocating memory would be wise. In the case of self-driving cars, you face critical system failures at points that could result in loss of life or property. In the case of satellites, you usually just face the risk of losing your satellite 
Sean Parent * (unsigned) 0xffffffff
It's debatable if calling that a 'byte' is sane, even if it's the size of a char. There's a lot of gray area when you get to a corner case like that so I won't say it's wrong. But it is very likely to cause a miscommunication. Even I only call it a byte if it's basically 6-10 bits, and I am pretty liberal because I'm not in the camp that says byte is exactly a synonym for octet. That said, a size-agnostic definition of byte I often see is 'the size of a character in the local character set' so if you are doing UCS-32 text processing on that DSP, it's harder to argue against it being the size of a byte...
No, that's a tiebreaker that happens [fairly late in overload resolution](https://timsong-cpp.github.io/cppwp/over.match.best#1.6): only if they are equally good otherwise does the deduction guide get preference. The `initializer_list`preference comes in extremely early, [while forming the set of candidates](https://timsong-cpp.github.io/cppwp/over.match.list#1). At that point, the function template synthesized from the deduction guide isn't even a candidate.
Well, this statement seemed to ignore the hardware bit. &gt; Games don't use exceptions because they will literally drop below the minimum acceptable framerate due to their use. Possibly this used to be the case, but I can't think of a single platform where this is still true. Even ARM for 10 years has supported 0 cost exceptions. 
Have you seen [randutils](http://www.pcg-random.org/posts/ease-of-use-without-loss-of-power.html)? It's my goto random lib.
I used something similar in the past for message IDs. I used 64bit integers with strings up to 9 ASCII characters and I was shifting them by 7 bits each and adding them. No collisions this way.
Yes /u/andralex do you have time? :) Also, has Chandler a reddit account? 
ping /u/eric_niebler
most others named are also already on Reddit, pinging /u/HowardHinnant/ /u/louis_dionne/ /u/zygoloid/ /u/bstroustrup/ and /u/hpsutter/. /u/andralex/ already [did an AMA](https://www.reddit.com/r/programming/comments/1nlaok/andrei_alexandrescu_is_doing_an_ama_in_riama/)
Why not instead : struct myClass { std::vector&lt;int&gt; theInts; // const when a myClass instance is const, not const when it is not }; 
To be fair, 99.999^99^99^99 % of the time the moved-from buffer can be stolen :)
&gt; so for list-init you do the usual ritual of trying initializer_list only first. https://godbolt.org/g/bVphX6 
That doesn't fix the problem at all!
You basically invalidate the argument by providing both const and non-const getters. He also didn't suggest exposing all member variables that way.
There isn't only one argument.
You don't have to expose them all, but offering a const / non const getter and setter is functionnally equivalent to just providing access to the member variable.
uh... nothing particular, I just found the ICE fun.
Consider the case where the member variable in question is a pointer, however the constructor (or other method) establishes the invariant that the member variable must always be non-null. In this case it seems natural to use accessors. In addition, accessors allow additional functionality e.g. altering a mutable variable. Again, this is well-trodden territory...
Yup, no-one get notified if there are 4 or more (iirc) summons in a post/comment.
this code is supposed to put 4 lines in the .csv it should look like: username password site name (separator) instead it looks like: username password site name
I have to ask... Is it correct to use operator&amp;(_Right) in the move constructor and not addressof like the copy constructor does? 
I follow Stephanie on twitter. I'd like to see this too.
+1 for Chandler Carruth. He is very good at explaining how various C++ constructs affect a compiler's ability to optimize.
The `operator()` is a problem, but you still can do it without duplicating code (see below). Note : I'm not advocating particularly for this (I would certainly not in my own code), I just want to point out that the language already gives us the tools. #include &lt;vector&gt; struct ints { private: std::vector&lt;int&gt; m_ints; int d = 2; public: struct { ints&amp; self; int&amp; operator()(int x, int y, int z) { return self.m_ints[x * self.d * self.d + y * self.d + z]; } } functor{*this}; }; int main() { ints i; i.functor(1, 2, 3); } (or, if you want to save 8 bytes at the cost of UB : `ints&amp; self = *static_cast&lt;ints*&gt;((void*)this - offsetof(ints, functor));`)
Since it's so easy to have UB, why not warn whenever it occurs? (Beyond the obvious reason of there is too much UB to make listing them all meaningful in any way)
True AI
They both use addressof now (I audited this for 2017 RTM). The issue is that ADL can find a non-member operator&amp;(), although such a thing is particularly virulent. As of right now, our STL is pretty hardened against finding op&amp; through ADL. However, a globally visible operator will still explode (as it does for every other STL).
I wish, but ADL cares about template argument types.
Didn't Andrei do one already? Though maybe not focused on C++.
C# uses value or ref semantics based on the type, so it's nice and succinct. C++ can't do this, and you'll at the minimum need `auto` vs `decltype(auto)` for the getter, and potentially even more of a mess for the setter argument. We've lost the succinctness; it's no longer a feature.
The images are great to visualize the operations. To improve on this idea, I think you could use the same names for the sets both in the images and in the code excerpts.
Looks like my basic_string overhaul is also affected :(
What about something like: std::vector&lt;int&gt; _left; std::vector&lt;int&gt; _right; std::vector&lt;int&gt;&amp; GetRelevantData ( ) { if ( _someCondition ) { return _left; }else { return _right; } } const std::vector&lt;int&gt;&amp; GetRelevantData ( ) const { if ( _someCondition ) { return _left; }else { return _right; } } /u/seertaak does this contrived example demonstrate the problem you're talking about?
Congrats to our friends and colleagues on the GCC/G++ teams! (I look forward to the day when we can make a similar post!)
&gt;but offering a const / non const getter and setter is functionnally equivalent to just providing access to the member variable. It isn't, because the getter and setter could have other code in them other than just getting/setting. For example acquire a lock, or log a message, or perform some validity check.
More often than not undefined behavior is simply the absence of defined behavior, and proving a negative is impossible.
I'm never going to forget my first standards-body-ish thing and MW was messing with the room with the adjustable light colors on his laptop -- making it turn red and blink when he was unhappy about something, for example.
Story time: At one point I worked on AIX, IBM's Unix flavor for PowerPC. PowerPC has virtual address 0 as a perfectly valid address, and in the kernel it was the beginning of the kernel text segment. We had other addresses that corresponded to other parts of the kernel. At one point in development we added a feature that, among other things, required shuffling the addresses we gave the linker for some of the kernel bits. I, being a sensible programmer, wanted to ensure the addresses of various fields ended up where expected, so I wrote some asserts of the form `assert(&amp;foo == val);`, where `val` was probably a `#define` for the address we expected, and `foo` was the symbol we had forced to be at the beginning of the section. One of my asserts kept failing. It was the one for the magic symbol that was supposed to be at the beginning of the kernel, at offset 0. The compiler was trying to be clever, and it saw the code `assert(&amp;foo == 0)` and decided this could never be true, so it replaced this code with `assert(false)`. So even though it's perfectly legal on AIX to dereference a pointer with value 0, you can't assert that the address of your variable is there, since the compiler assumes it can't be.
Appreciated :)
Thank you for pointing that out! Its always good to find out that I'm wrong somewhere. I've changed it to abstract base class rather than virtual base class, and while concepts don't add anything new, the ability to constrain it, I think does make it easier on the programmer to use templates as a type of polymorphism.
Expanding on that... If you look around [cppreference.com](http://en.cppreference.com/w/Main_Page), you will already find concepts used to explain the requirements of templates - e.g. for [std::sort](http://en.cppreference.com/w/cpp/algorithm/sort), "RandomIt must meet the requirements of ValueSwappable and RandomAccessIterator." etc. `ValueSwappable` is a concept which defines a requirement that the iterators you pass to `std::sort` must reference values that can be swapped. That has always been a requirement since ancient times because most sort algorithms (on arrays) work by swapping values. In the past it was implicit - since the template swapped items, if it was instantiated using iterators that didn't support that, things would go wrong somewhere and the compiler would report all the resulting inconsistencies. For some time now, the language of concepts has been increasingly used to describe that requirement, as on cppreference.com. But when concepts are adopted, those requirements will be stated using concepts explicitly in the template source code, so compilers can give clearer error messages (and probably some other benefits). Templates will still do what they've always done, just with some extra features (more library than language IIRC) to do the job more robustly and with better error messages. BTW - concepts also allow requirements to be specified and checked that, in the past, wouldn't have been detected as compiler errors at all, but would have resulted in run-time bugs. That's because e.g. checking that a required function exists, spelled a certain way and with certain argument types (which existing C++ can check), doesn't necessarily ensure that that function has the right properties. You might have a template function that assumes `a+b = b+a`, which makes sense if you're thinking of numbers, but then someone calls it for strings - `operator+` still exists but "hello "+"world" is a bit different to "world"+"hello ". **EDIT** On second thoughts, "because most sort algorithms (on arrays) work by swapping values" is pretty confusing - `std::sort` is generic, and applies to any container that allows random access iteration - whether or not that can be considered an array. The point of using iterators is to abstract away most details of the data structure. However, irrespective of C++, there are what I think of as "array sorting algorithms" and "list sorting algorithms" - just my personal way of thinking about them. The two kinds are somewhat associated with arrays and lists, but not actually tied to them. They're not even necessarily different algorithms - e.g. merge sort on arrays is in the first class, merge sort on lists is (probably, but not necessarily) in the second. The first class work by rearranging the values within the data structure. The second class work by logically re-ordering the data structure cells - usually by changing pointers. So the first class imposes requirements on the values (for `std::sort`, the `ValueSwappable` requirement) that the second class doesn't (because in that case, the values themselves aren't moved or swapped). A more abstracted way to look at it - I can sort a sequence of numbers either by moving the numbers themselves, or by re-drawing the arrows that tell me which order to visit the numbers in. The C++ standard library has some support for both approaches, but support for the second class is specific to particular containers - e.g. [std::list::sort](http://en.cppreference.com/w/cpp/container/list/sort). There's ways to make generic versions of the second class that work for different container types too, but probably not that practical - certainly the way C++ iterators are currently specified doesn't support it. Iterators can support moving/swapping values between referenced cells, but can't "redraw the arrows". 
Got it. Thanks. 
Of course, but there are plenty of cases where you want all 4, mostly in generic code. The only argument for `const &amp;&amp;` that I know is correctly forwarding the right reference type in generic code.
I would keep it analogous to `noexcept`: `std::vector&lt;int&gt; &amp;get_ints(); // non-const` `const std::vector&lt;int&gt; &amp;get_ints() const; // const` `const(false) std::vector&lt;int&gt; &amp;get_ints() const(false); // non-const` `const(true) std::vector&lt;int&gt; &amp;get_ints() const(true); // const` `const(auto) std::vector&lt;int&gt; &amp;get_ints() const(auto); // inherit from *this` The nice thing is that you could use an arbitrary constant expression which evaluates to `bool` in there.
In CUDA and OpenCL shared memory, null pointers are represented with the value -1, as 0 is a valid address.
You can get exception safety and terseness by stopping the clock in a destructor. There was a correctness issue where `auto` return type doesn't handle return-by-reference. Use `decltype(auto)` instead, for the return type and for any named return variable (such as `t` in your code). template&lt; typename t &gt; class sentry { t o; public: sentry( t in_o ) : o( std::move( in_o ) ) { static_assert( noexcept( o() ), "Please check that the finally block cannot throw, and mark the lambda as noexcept." ); } sentry( sentry &amp;&amp; ) = delete; sentry( sentry const &amp; ) = delete; ~ sentry() noexcept { o(); } }; template&lt; typename t &gt; sentry&lt; t &gt; finally( t o ) { return { std::move( o ) }; } template &lt;typename Callable, typename ...Args&gt; decltype(auto) timed_invoke(Callable&amp;&amp; callable, Args&amp;&amp; ...args) { auto t0 = high_resolution_clock::now(); auto &amp;&amp; guard = finally( [=]() noexcept { auto t1 = high_resolution_clock::now(); std::cout &lt;&lt; (t1 - t0).count() &lt;&lt; "nanoseconds.\n"; } ); return std::invoke(callable, std::forward&lt;Args&gt;(args)...); } I didn't test this… [Here's](http://stackoverflow.com/a/17356259/153285) the SO post on the `finally` utility.
can't u can compare this to the generics C# is using? void foo&lt;T&gt;() where T : IComparable { } now foo only works with types which include this interface. The concepts however, will be lighter in terms of, type T doesn't need to derive said interface, but just need the same functions. (correct me pls)
`std::optional::value()`, `std::get({std::tuple, std::varaint})` I don't know of any use cases where explicitly knowing your object is `const &amp;&amp;` helps. I could come up with a contrived example where it makes a difference. But library code should have this overload, especially if it can't be easily changed, in case a real use case comes up in the future.
I think this is a somewhat reasonable example that shows why a `const&amp;&amp;` overload might be useful. https://godbolt.org/g/H4AUyR
Hmm, if you can use a template, then that kind of std::function, shouldn't have a cost?
I'm not sure what you mean. `std::function` will always have some overhead over a bare template which perfect forwards the function-like object, as `std::function` needs to type-erase the object to store it.
Nope! [Here](http://melpon.org/wandbox/permlink/2Fvy2jFuw8wvhvDw) is an example of how it can fail without it
I am not super experienced with C++. I have been using it for university stuff the last couple of years and I am currently contributing to clang codebase with C++. But I am not what I would call experienced. But I have a masters degree in Computer Science, so hopefully I would be able to catch up rather quickly. Would that have any interest? 
Yes, that's the last I read from him. Wow, has it been 5 years already?
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp. 
[removed]
What about debugging? If you're stepping through the function, it would have to show you the const version, which may be misleading.
You can do that with the literal operator taking chars and parse the number.
Yeah good idea! Integrated this in the code.
You can also check out Mozilla RR: https://github.com/mozilla/rr and http://rr-project.org/
Semantic versioning only makes sense for libraries or when exposing a stable API. According to http://blog.llvm.org/2016/12/llvms-new-versioning-scheme.html?m=1 every release is API breaking. 
If both clang 4 and gcc 7 happened to have full "c++17" from the get-go, it would be awesome : C++17 almost everywhere before the end of Q1 2017
This have nothing to do with inheritance, it is more like conditional keyword (like noexcept for example).
This is actually proper semantic versioning. Clang / LLVM have a very poor record at maintaining a stable API. That is, as it actually changes at almost every release, it makes sense to bump the major version number at each release. The other alternative would be to have a properly documented stable public API (which would be much better for external projects), but that is probably too much work. That is also why it is so hard to work downstream of LLVM / Clang.
That make sense. I've never thought of distinguishing between run-time and compile-time polymorphism. 
Would you say that £100K in London is same as £50K in Edinburgh?
Clang/LLVM is not just a compiler. Its a library.
In this case they would be the same implementation. This is primarily useful for getter functions in styles where those are common. Overloading on const to return exactly the same thing is hugely annoying.
I think this would be great for a new language. However, I think -- and this is only a gut feeling -- that the C++ committee would be unlikely to adopt such a syntax, even though it introduces only one new token, because it is relatively new and orthogonal. For my part, I can't detect any issues with the syntax, because you can't put expressions (e.g. ternary if-expr) inside a method declaration...still... The "= default" syntax has the benefit that it is close to existing syntax. The same can be said of the "const(auto)" conditional syntax proposed elsewhere on this thread.
I like this, because it reduces even further the amount of typing you have to do.
We have a stickied thread for job offer
The committee doesn't fear "new and orthogonal" syntaxes, as long as they serve a purpose and don't preclude potential language evolutions. We wouldn't have lambda expressions or return value deduction if it weren't so. The `const(auto)` syntax is more verbose and it's not that straightforward to describe in standardese, let alone to implement. However, my proposal has a simple and direct implementation: just synthesize two copies of the function with and without `const`, using the same function body. For consistency, the "?" operator could also be applied to `volatile` or even as `const? volatile?` to quickly produce all four overloads.
Also, don't use smart pointers until you really understand how to properly manage memory. I've found that if I had started to use smart pointers instead of raw ones like a lot of people suggest early on, I would of missed out on a lot of learning opportunities. 
Please post job offers in [this thread](https://www.reddit.com/r/cpp/comments/5lflfj/whos_hiring_c_devs_q1_2017/). Thanks.
Sure, but the example there does not do that.
&gt; [N.B. there is a longer/better paced version of that talk online somewhere that Sean gave at another conference, but I can't find the link at the moment -- can anybody help me out?] "longer/better paced" implies BoostCon/C++Now (1.5 hr talks instead of 1hr). So probably one of the talks listed here: https://www.youtube.com/user/BoostCon/search?query=sean+parent I recommend all of Sean's talks, so just watch them all, and (polymorphic) value types tends to come up often. In particular, maybe this one: [Value Semantics and Concepts-based Polymorphism](https://www.youtube.com/watch?v=_BpMYeUFXv8)
I'm approving this because it has accumulated some interesting discussion, but in the future, please refrain from posting content-free links with content-free titles.
The Going Native talk I linked to is just 25 minutes, which isn't really enough to cover all the material. &gt; [Value Semantics and Concepts-based Polymorphism](https://www.youtube.com/watch?v=_BpMYeUFXv8) That's the longer version I was looking for, thanks :)
&gt; The other alternative would be to have a properly documented stable public API (which would be much better for external projects), but that is probably too much work. Note that Clang comes in two flavors: - the C++ libraries are completely unstable - the C library is (supposed to) be stable, albeit is lagging behind and incomplete The choice of having unstable C++ libraries is of course to avoid bogging down development. Not being able to add new nodes to the AST would prevent implementing new language features, for example, which is rather undesirable. So, yes, indeed from a semantic versioning POV, each release of Clang or LLVM is a major release.
That's because 5.0 is the trunk version. When the 4.0 was branched, the "Release Note" document remaining on the trunk was cleaned-up to its outline, to be filled up at leisure during the development of the 5.0 version. There won't be anything interesting there until it's actually developed.
Use LoadLibrary call for opencl.dll, it will load appropriate DLL either 32 or 64 bit. Static linking is pain. If still wanted static linkage - install cuda, AMD or Intel ocl SDK, to get all DLLs and libs for your platform. 
I mainly reacted because yesterday I could read the 4.0 release notes at the very same URL, but today it was 5 (indicating a shift).
This is off-topic; you want StackOverflow.
The Rust language effectively already has concepts via a thing called "traits". Rust devs are encouraged to do all polymorphism via traits, and as a result almost all polymorphism is done at compile time. But despite that, the language does support runtime polymorphism and virtual calls, because sometimes you just can't avoid it. So the answer is no.
Because it is in general very hard or impossible to know for sure if it actually occurs or not. If the compiler would warn every time UB is just possible, it would warn for a perfectly valid code (every for loop with an int index, as /u/doom_Oo7 already pointed out)
In most cases UB is a runtime thing, not compile time. For example, given this function: void foo(Struct *s) { s-&gt;x = 35; if (s == nullptr) { doSomething(); } } Is there an undefined behaviour? We cannot know (neither can the compiler). We can tell the UB is in general possible. We can also tell the check is useless. (so the compiler can optimize it away). But if the compiler would issue an error for this function, if would reject valid code (if, for example, nullptr is actually never ever passed into this function). 
Thanks! Here's a thread I started on another forum with all my details trying to get the bottom of it without success. https://handmade.network/forums/t/2006-clang-cl_and_microsofts_link.exe/2#10383
The example program has, as it stands, also no problem with the default case, so I'm not sure what the point is then.
The clear intent of the example program is for "tutu!" to be printed if and only if the input is "tatatututoto", which is false.
Clang 4 will not have "full C++17". At the very least, it will ship before the C++17 standard is approved (and maybe before it is finalized).
That was my suspicion. Thanks man!
why MIT license out of curiosity? vs the unlicens: http://unlicense.org/
Maybe the "RMS's gdb Debugger Tutorial" to be able to do basic things. Then assume that GDB can do anything, so just use google-fu to find answers to the questions that arise in the process of the debugging (searches usually land in the GDB manual or StackOverflow).
I have a good memories about [Art of Debugging](https://www.nostarch.com/debugging.htm). Have an e-book, PM me your email if you wish a copy (NoStarch publishes DRM-free books, so it is allowed).
I don't think libstdc++ provides full C++17 conformance yet.
Relevant links: * [Clang Implementation Status](http://clang.llvm.org/cxx_status.html) * [Libc++ Implementation Status](http://libcxx.llvm.org/cxx1z_status.html) 
While this is definitely a nice way around the code duplication, surely it proves OPs point that it would be a nice-to-have at the language level to obviate the need for the trickiness?
I think it will all end up in clang-tidy in the end.
I think I'm going to rule this as off-topic for /r/cpp, but it looks like you got a few answers already.
It might have been if there was anything to read in the link.
He did an update to his original refactoring talk a couple of months ago: https://www.youtube.com/watch?v=cX_GhJ6BuWI 
Perhaps you're thinking of [clang-rename](http://clang.llvm.org/extra/clang-rename.html)? [clang-include-fixer](http://clang.llvm.org/extra/include-fixer.html) is also pretty awesome.
I've found rtags to work very well for me: https://github.com/Andersbakken/rtags
Can you refactor a class name or member functions across multiple files? I use vim, though am considering switching to emacs + evil mode.
Seems like that's what I wanted.
Also wxWidgets, Gtk+.
* https://github.com/ocornut/imgui * http://nanapro.org/en-us/ - https://github.com/cnjinhao/nana * http://neogfx.org/ - https://github.com/FlibbleMr/neogfx Another example would be ImGui and SFML (https://www.sfml-dev.org/): https://eliasdaler.wordpress.com/2016/05/31/imgui-sfml-tutorial-part-1/
I'd recommend Qt too
Not sure I would recommend wxWidgets or Gtk+ APIs to a first year programming student (also as is evident from OPs post they're still very much a beginner!). Qt might also be too daunting at this point, but OP could try. I'd recommend nana (see mttd's post below for links).
It can apply fixits, so it's not only linting.
https://wiki.qt.io/Basic_Qt_Programming_Tutorial
&gt; I want to add super simple graphics so that I can save it as an actual program and people can boot it up in their computers without having to look at my code. You don't really need a GUI for people to run your code without having to build it themselves. Just compile it and distribute the binary (assuming you're on Windows, this is the `.exe` file).
Or [tiny file dialogs](https://sourceforge.net/projects/tinyfiledialogs/).
You might be in the wrong sub.
Console applications and GUI applications are both compiled to .exe binary. That binary file is what you send to other people. Making a GUI is a lot of work for sample applications, and you are almost certainly better off compiling a console application that deals only in text. 
We just put a Qt browser around it ;)
[QtCreator](http://doc.qt.io/qtcreator/creator-editor-refactoring.html) has some useful refactorings which certainly use Clang's code model as a backend
Yes, but optional is already designed to handle two states, so you save on duplicating that.
&gt; when I run it nothing comes up actually, it certainly comes up and disappears right after.
D&amp;E §16.5 says that RAII was "the central point in the exception handling design"; specifically, "if a function grabs a _resource_, how the language can help the user to ensure that the resource is correctly released upon exit". The example given contrasts file opening and closing between RAII and C-style error handling/cleanup. It calls the C-style approach "verbose, tedious, and potentially expensive".
Here's a solution to capture the parameter to a integer literal operator as an integral constant. #include &lt;type_traits&gt; template &lt;unsigned N, char ...Chars&gt; struct accumulate_int; template&lt;unsigned N, char C&gt; struct accumulate_int&lt;N, C&gt; : std::integral_constant&lt;int, (10 * N) + (C - '0')&gt; {}; template &lt;unsigned N, char C, char ...Rest&gt; struct accumulate_int&lt;N, C, Rest...&gt; : accumulate_int&lt;accumulate_int&lt;N, C&gt;::value, Rest...&gt; {}; template &lt;char ...Params&gt; struct to_int : accumulate_int&lt;0, Params...&gt; {}; template &lt;char... params&gt; auto operator ""_c() { return to_int&lt;params...&gt;(); } 
It just struck me... Anyone here knows what they would do, it's trivial... But looking at the question, it is **painstakingly** obvious that giving a good answer is daunting... For example, this: &gt; . I want to add super simple graphics so that I can save it as an actual program reveals a mountain of possible misunderstandings OP might have, and I wouldn't even know where to start explaining. Probably a back-and forth exchange would have been best, e.g. why do you think that you need graphics "to save as a program"? What do you even mean by "save as a program"? I havea similar thing with juniors (college graduates, mind). So speaking with one, I realized he **really** doesn't understand pass-by-value(reference), it's all a blur to him. He is doing ~~trivial~~easy work for months now, and this popped up for the first time, and... **So** happy I got out of academia :-).
Web "applications" actually a very popular idea. Downvotes are because they are also a very bad idea: a barely functioning hack on a hack on an awkward VM that "everyones got now". People should realize the actual nature of things, especially while they're learning (like the creator of this reddit thread).
The `generate_uniform_int` function from [Boost.Random](http://www.boost.org/libs/random/) will work for any integer-like type as long as `std::numeric_limits` is specialized for said type.
Are you fixed on using that bigint library? GMP has uniform random number generation functions.
Qt is love. Qt is Life
If you want to build a GUI program I recommend Qt. It's probably the simplest to get started with and it's cross-platform. However, I'm not sure if you're asking the right question. You don't need a GUI to distribute your program as a compiled binary.
&gt; (of course i'm checking the return value of entropy method) That's largely pointless, the definition of entropy() is kind of broken and so typical implementations just return 0.
I wrote all of my code with it. So yes. 
_Engines_ are for generating bits, not distributions; indeed, every engine in `random` fulfills the [`UniformRandomBitGenerator` concept](http://en.cppreference.com/w/cpp/concept/UniformRandomBitGenerator).
Webapps are not the solution for everything. 