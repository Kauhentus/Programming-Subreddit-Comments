what about SDL? SFML? Allegro? they're pretty lightweight.
modules would make creating and using a unicode library easier. 
"Your parents are going to be very upset when they see these short, ambiguous variable names young man!"
That could be said of anything. Modules ARE coming, I am sure of that. Probably c++17 will have them. I am not against modules. But not real UTF support is joke.
In my opinion something like 2D Graphics or 3D Graphics (or even audio) shouldn't be part of C++. It seems for me at least that std::graphics is going to be more complicated than the std namespace now. At "Optional default game loop" I didn't know anymore whether he's serious at all. It makes sense for other parts of C++ to be part of the standard, as it's a core language feature the compiler knows everything about how to optimise it (STL, for example). For graphics, there won't be that much freedom so std::graphics should stay in a library where it belongs. If you're going to use std::graphics, it's likely you need other GUI parts as well (except render-to-texture)
Though I like the idea of a standard, simple graphics library. I also agree that the standard library should be small, concise, and powerful. How useful a 2D graphics library is to general systems or even engine programmers? Not especially. What would be very useful however, is a linear algebra library. The inclusion of matrix and vector mathematics would be extremely useful. I'd rather them include [GLM](https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;ved=0CCwQFjAA&amp;url=http%3A%2F%2Fglm.g-truc.net%2F&amp;ei=ya1JUqPIE-KQyQHswYG4Dw&amp;usg=AFQjCNE2Po14N13kL5f_iuC_tE7E23hysg&amp;sig2=U0iAMXGueYwGDfyBhJusew&amp;bvm=bv.53217764,d.aWc) instead of the 2D drawing library as it has a larger use in many applications, not just computer graphics.
http://utfcpp.sourceforge.net/ The iOS 7 SDK has some C modules support http://lists.cs.uiuc.edu/pipermail/cfe-dev/2013-September/032086.html Modules is not experimental in clang repo: https://github.com/llvm-mirror/clang/commit/86e0468a6cf88353e43c23cdc1d7eea8f6c25332#diff-6c8187563fedb1b05818df4aa049883c
The sad thing about this library is that it will be the first in the standard where a single developper cannot create the implementation from scratch: the basic access to simple gpu functions relies on closed source driver or open-source retro-engineering. The works on Nouveau, Gallium3D and Mesa are excellent, but with a standard that will be supported through a decade, an minimal official hardware documentation should be provide.
I could optimize my program to the cache line, but not send a piece of code to the gpu, by the standard ? That is a depressing thought, and that always been a major drawback from the pc compared to the video game consoles (see every year, the rant from camark on it).
I was under the impression that static variables in a function were guaranteed to be initialized in a thread-safe manner in C++ 11 anyway. So all the post needs to do its: T const &amp; get Thing() { static T t; return t; } Edit: but I should mention that the blog post is very well written from the perspective of wanting to understand DCL in C++11
Your impression was correct.
std::graphics will be über-useful on server apps. And, oh man, think about the possibilities in kernel development! A wireless driver with std::graphics support? FUCK YES. Seriously, why should something as specific as a graphics library be a part of std? I don't know, maybe I'm misinformed, but wtf?
I agree with your assessment. In addition, there is the issue that std::graphics would have to be portable; so it would have to be specified in such a manner that it can run both on systems that support an GPU-accelerated API like OpenGL, and those that do not. While that is by no means impossible, it would mean that performance would vary drastically between those implementations that would chose to implement it in hardware, and those that would not -- and for things like real-time graphics (which is presumably the main target here, seeing how they are talking about the game loop) unpredictable performance is about the worst thing you can have, much worse than even really really bad performance. So unless this is somehow taken care of, it'd probably end up as one of those "things that exist, but you probably don't want to use them."
It is. It's also guaranteed to be destroyed at the end of the program unlike the `new` version.
How else are we going to display our kitchen sinks?
What are the guarantees regarding destruction besides "it will happen"?
Show me a language that has proper Unicode-support and you show me a language that is most likely one or two orders of magnitude slower than C++, if it comes to string-handling. While I like the idea of having it optionally available, I very much doubt that it would be used by many people in (and most of them wouldn't use it correctly). Unicode is a great example for a technology that is over-complicated as hell but still the best thing we have. If you don't believe me, look up things like ‘combining character’ and ‘Unicode-normalization’ (tl;dr: even if you know exactly the number of codepoints (O(n) with utf-8)) you know almost **nothing** about the length of the string (well, you have an upper bound, but that is all; and even if you know that two Unicode-strings consist of entirely different code-points, you definitely cannot say that they are different; you must normalize both of them in (O(n_1)+O(n_2)). Implementing 2d-graphics might be **easier** than doing Unicode correctly.
If a program seriously depends on that: Rethink the logic of it.
It shouldn't be on the standard, though... Otherwise, we'd make tutorial libs for everything and put them in there "for the good of the newcomers". Nah, just make a cross platform library and use that.
Could we get `std::network` first?
Although something like Boost's GIL would be somewhat useful- the math for manipulating graphics, but maybe not the graphics themselves?
"Show me a language that has proper Unicode-support and you show me a language that is most likely one or two orders of magnitude slower than C++, if it comes to string-handling." **Go** and **Go**
Yes, because nowadays C++ developers write iostream classes from scratch all the way down to the hard disk controller, after implementing the hard disk on a week-end project.
It would certainly be an welcome addition to the standard. In the late 80's and 90's Borland compilers had BGI, which was quite nice way to do graphics programming, before one started implementing their own stuff in Assembly. 
As part of the new C++ Working Group, WG21, there are a number of standard library proposals. 2D was one. Networking is there too, among others: http://www.open-std.org/jtc1/sc22/wg21/ Also see Herb's talk about the subject: http://channel9.msdn.com/Events/GoingNative/2013/Keynote-Herb-Sutter-One-Cpp 
At time of this comment, documentation incorrectly says that for (auto i : range(10)) { cout &lt;&lt; i &lt;&lt; '\n'; } prints 1 2 3 4 5 6 7 8 9, checking source code reveals that the loop will in fact correctly print the expected output: 0 1 2 3 4 5 6 7 8 9
Well, the ATA standard documentation is published and with it, I can communicate with the harddrive. Thanks god, I don't need to recode a driver and a filesystem upon it: but if I have to I can, from the hardware and finished with a standard complete C++ lib. It should be the same with new standards, at least to ensure a stability and consistancy across every systems, old and new (and it's a 10+ years old technology...).
Yeah I am well aware of all of that stuff. What I am after is for it to be standardised.
Ah good, I was about to get all angry about this :P 
I, too, was outraged. What's the usefulness of a range if you can't use it to iterate the elements in a collection?
The classical approach is to convert a set of regular expressions (for the tokens recognised by your lexer) to a set of Nondeterministic Finite Automata (NFA) using Thompson's Construction (http://en.wikipedia.org/wiki/Thompson's_construction_algorithm) The NFA can then be simulated directly, by maintaining a stack each entry of which is an NFA state. The NFA can be multiple NFA states concurrently. Alternatively, the NFA can be converted to a DFA which can be simulated more simply, but typically occupies more space. There are plenty of online references to this, but the coverage in The Dragon Book (http://en.wikipedia.org/wiki/Compilers:_Principles,_Techniques,_and_Tools) is the best I've seen yet. This also covers building the DFA directly from the set of rules, which would be my favoured approach.
ustring and QString may have some nice properties, but real support of unicode is not among them. There is a lot more to that than just supporting 16-bit characters or even complete codepoints.
And that's a fuck load more than std::string does. 
No, not really. Utf-16 is the union of the disadvantages from utf-8 and utf-32 without any of the advantages and I am truly curious what advantage it has to be able to random-access codepoints (most advantages that people may think about aren't if you look closer). And btw: C++ already has std::u32string and std::u16string, so you are free to use these.
The problem with such libraries is always that while *using* an iterator might be nice and easy, *writing* an iterator is a pain and requires lots of boilerplate code. For a real nice to use `yield` mechanism you need language support or serious black magic like setjmp/longjmp.
Well like I said earlier, UTF8 is the important one. Also std::u32string is as much a utf32 tring type as std::string is a uft8 string. It's just a std::basic_string with a std::char32_t as it's `char_type`. It's nothing like the proposed (so it's hardly off the table) std::ustring.
I've updated the post to include this approach. I had originally left it out because this post is about DCLP, and the standard doesn't guarantee that the implementation will use DCLP. However, it's obviously the best choice, and it just so happens that some (most?) compilers do. 
`std::move()` is badly named. Nothing moves. Literally it's a cast to an r-value. However, it would most accurately be named `std::cast_to_an_erasable_reference()`; but that would be ridiculous of course. 
Or you could use two threads, and `std::future` to synchronize them.
This looks really cool. A couple of things. Why doesn't `enumerate` return a tuple like it does in python? And why doesn't zip return a tuple? I don't understand why `zip_get` is used.
Actually you should `std::declval` instead, thats what its therefore. It should be written as: decltype(std::declval&lt;Container&gt;().begin()); &gt; However, isn't that what std::result_of is for? `std::result_of` is to mainly get the result of function objects. Although it might work for member functions, it would look pretty nasty(it has to be written using a member function pointer) and it would be problematic(because of the member function pointer) especially in the presence of overloads or templated functions.
My earlier comment aside, this does look quite nice.
There's nothing in the C++ spec that says it interacts with an ATA standard disk.
I have to be honest, I would guess most of these are going to be slower than the traditional approach (still same big O of course), I personally have not been trying to optimize the code too much but just to make it as readable and usable as possible, perhaps later we may go through and really try to optimize everything. The only advantage I could see for our code is that in some cases (especially the combinatoric generators) you can avoid highly nested for loops and perhaps get better branch pred 
Go is most of the way there, but Go's string handling does not have any concept of a character (no, runes are not characters).
&gt; but I wrote zip_get because zip returns a tuple of iterators (to make it simple to return references Ok I see. Generally zip returns a tuple of what gets dereferenced from the pointer rather than a tuple of iterators. Its not difficult to return a tuple of references. I may take a look at it today and possibly send a pull request if you like.
&gt; because tuples in python are wayyyy friendlier than c++'s Well, you can use `std::tie` to access tuples easier, like you do in python. However, it can't be used in for-range loops. You can use it with `BOOST_FOREACH`: std::map&lt;int, int&gt; m; int key, value; BOOST_FOREACH(std::tie(key, value), m) { ... } 
Agreed, your post was well-written from the perspective of explaining how to use DCL in C++11. And then suggesting never using it. ;) There may be some value in a DCLSingleton&lt;void()&gt; class template but meh, who cares.
I only answered your two questions. I think Go is capable of handling unicode. The persons who invented utf-8 (Ken Thompson and Rob Pike) are also the Go creators, together with Robert Griesemer. So they thought about it. And about the string handling speed, I think it's close to C++, but you need to benchmark the code of course to get exact results. That said, Go by itself is a language with a small set of (well thought) features. Strings are just an array of bytes with a pointer pointing to the start of the array and an integer telling the length of it. There is a [unicode](http://golang.org/pkg/unicode) and a [utf8](http://golang.org/pkg/unicode/utf8) package that help you with the unicode "deciphering". There is also a [strings](http://golang.org/pkg/strings) and [strconv](http://golang.org/pkg/strconv) package that help you with string handling. However, strings are read only. If you need to manipulate strings intensively, it's better to use a byte slice, otherwise you do a lot of copying. There is also a [bytes](http://golang.org/pkg/bytes) package, which works roughly the same as the strings package. For a first impression of Go, please follow the [Go tour](http://tour.golang.org/#1). And you can ask questions on [reddit-golang](http://www.reddit.com/r/golang) and the [golang-nuts](https://groups.google.com/forum/?fromgroups=#!forum/golang-nuts) user group.
See my answer to F-J-W. The concept of a character is implemented in the [utf8](http://golang.org/pkg/unicode/utf8) package.
 &gt;I highly recommend you watch Herb Sutter's Key Note during Build 2013. He basically asks why do we still use cout &lt;&lt; "hello world" as an example? Because it gets people started without a lot of distraction by things not related to compiling and running a program. I think Herbs problem here is that he has literally years of experience and probably lost touch with what is to be a student absolutely new to programming. That hello world program is trivial because many students will spend considerable time grasping the editor, finding the command line tools and other wise just getting a workable executable. This may not be apparent to those of use that started hacking at an early age and gradually ramped up our skills set. &gt;He later goes on to talk about a graphical hello world using Cinder. He even demos a 200 loc Pac Man ish game at about 1 hour into the speak. It is pretty interesting and honestly I have to agree with him. I think he misses the point, that trivial program isn't about teaching students programming or computer science, it is rather to get everybody on the same page with the mechanics of generating an executable. It really doesn't matter what the code does, it could be a loop that counts to ten, the goal is to build a executable for the first time. In that regards the "program" needs to be as simple as possible. 
We don't need a library to implement GTK, Qt or any other ancient GUI / drawing package upon. Rather what we need is a new, modern, C++ native library that isn't just low level code but rather a complete system that delivers a lean 2D system, and the higher level constructs upon that. Otherwise what is the point, we already have dozens of 2D libraries and probably a dozen different GUI libraries to choose from. I don't want to offend Herb or anybody else involved in this effort but the last thing the C++ world needs is another half assed 2D library that is part of the standard. Frankly the little bit I've heard so far about this library implementation it is in fact a half assed project. If the community wants a 2D library then it should be done in such a way that it is best in class and is a basis for higher level GUI components. Frankly to do 2D right you are talking about a project as big as C++ it self or at least as big as the standard library. So in a nut shell I see this project as focused on the wrong niche which seems to be game programming, and simple graphics for educating students. Neither of these should be the focus of a standardized library. If the standards committee is going to support a 2D library it needs to be a professional quality library suitable for most imaginable uses including implement an entire GUI tool kit. A standard 2D library should reflect the high quality seen elsewhere in the C++ standard. 
Bad timing with your post - Github's having problems right now, as shown on their [status page](http://status.github.com).
I realize that boost did half this stuff before me, but * ours looks almost exactly like pythons whereas boost's does not * boost does not use variadic templates (yet...) * join only works with 2 ranges not an arbitrary amount like ours * I did use one boost dependecy boost::optional, but I figured it didn't matter since c++14 has std::optional anyway * BTW combinations has nothing to do with zipping ranges together, only operates on one range Truthfully there is really no competing with boost and it's hard to find a niche they haven't covered
I mirrored README.md on pastebin: http://pastebin.com/hjPDbugB
I can't help you with this one. But if you want your question answered, ask it on [reddit golang](http://www.reddit.com/r/golang) or on the [golang-nuts](https://groups.google.com/forum/?fromgroups=#!forum/golang-nuts) user group.
As a game developer, the only things I would want standardized: * Vector2 * Vector3 * Vector4 * Matrix3x3 * Matrix4x4 * Quaternion But for UI development, you would also need: * Size2 * Rectangle * EdgeBox (think margin, padding and border properties in HTML) I don't need an `std::graphics_context`, because that's going to be platform-specific anyway. But my kingdom for libraries that would use `std::vec2` as a standard interface! Standardizing on those types would be *super duper*, because it's really annoying to convert them from one library to another. [GLM](http://glm.g-truc.net/0.9.4/index.html) is damn close, but it's designed to match the OpenGL API and doesn't have the size types needed for UI development.
Yeah it might be a good idea to have zip and zip_longest just have references instead of iterators, when I was writing it the iterator way seemed simpler, I might want to have both versions. I think the zip_get is kinda nice as one of the goals of c++11 is making code more readable. As for the second comment I have been pretty much avoiding boost 
Take a look at this [code](http://play.golang.org/p/tTCeDSgQY7) (and press the "Run" button). However, if "fi" are 2 bytes, I don't think it will work. 
Note: you may not have to use `std::declval` if you actually have a container at hand, and with late return it is normally the case. template &lt;typename C&gt; auto enumerate(C&amp; c) -&gt; decltype(c.begin());
My last use case for casts are: static_cast in CRTP base classes const_cast as described in Scott Meyers Effective C++ to avoid duplication in const and non-const member function. Are there better ways of doing either of the above?
exactly. I can at least see some sense in user defined literals, but number seperators? Come on... I would really like to see where they motivation to standardize that comes from...
what do you do, if the file is on an usb drive? or ide? cd? floppy? - good luck on trying to implement that all on your own and making sure it works. 
it's terrible(( std::optional is very cool feature.
&gt; Yeah it might be a good idea to have zip and zip_longest just have references instead of iterators You can't just have references, some iterators don't return a reference. &gt; I think the zip_get is kinda nice as one of the goals of c++11 is making code more readable. `std::get` is just as readable. The thing is, it changes the interface, so now its difficult to use with things that expect tuples, such as a `fused_adaptor`. &gt; I have been pretty much avoiding boost Why the aversion to boost?
Looks as if boost is still going to be extremely useful in the C++14 world.
&gt;I may take a look at it today and possibly send a pull request if you like. Feel free to do so, if your zip looks good I'd be glad to incorporate it (all you really have to do is change the dereference operator a bit), we're also nearing the end of python's itertools but i'm sure there are other interesting functions to create, if you had ideas I'd be glad to hear them. Also note that anything you can do to zip prolly applies to zip longest. &gt; I have been pretty much avoiding boost Why the aversion to boost? Because they already beat us to most of it, it would be too easy with boost. I did use boost::optional but only because next year it will be replaced with std::optional anyway
Also: Why some programs take time to shut down. Exit-time destructors should be used with caution. Sadly, some types of resources cannot be automatically reclaimed by the OS when the process terminates, and which can or can't be depends on the OS in question. If the only resources your program uses are memory and OS-level file descriptors and sockets, you're generally safe to not call destructors on exit, which is a good thing. As far as I'm aware, there's no good solution to this problem, save for encoding "auto-reclaimability" in the type system somehow.
Too much? They are almost the same.
std::optional was taken out of C++14 standard ; - ;
Except that dynarray doesn't resize after construction and has no push/pop functionality. If anything, dynarray is a mostly light-weight wrapper around new[] that provides iterators and the ability to know the size.
I can understand `std::dynarray`, but how could `std::optional` get voted out? It's such an insanely useful feature. I'll just stick to using my own self-written `Nullable&lt;T&gt;` I suppose...
The fact you called your version `Nullable` suggests it's basically a smart pointer. Why not use `std::shared_ptr` or `std::unique_ptr`? I can think of a few possible reasons - the name better expresses the intent, wanting value (rather than shared/unique reference) semantics, possible performance advantages where it's a good match for the requirements and not providing unnecessary abilities. But I'm not familiar with it, so that's just vague speculation. 
&gt; A smart pointer reference counts and gets memory for its managed object from the heap. A smart pointer is a pointer with smarts. *ANY* smarts. That includes a smart pointer that implements value semantics, acting only as a pointer as a performance optimisation to manage copying overheads. A raw pointer doesn't need to do reference counting, neither does a smart pointer. A smart pointer with value semantics might have move semantics as its only copy-avoiding smarts. As for getting memory from the heap - I don't know how `std::optional` works, that's why I'm asking about it. The term "nullable" is commonly a reference to null pointers - that's why I thought "Nullable" suggested a smart pointer. 
http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2013/n3765.pdf lists some problems (both design-decisions that are non-obvious and real quirks) that optional has. It is the only paper in the pre-Chicago-mailing on optional, so I would assume, that it is possibly related.
Even more of a valid reason as to why vector and dynarray aren't practically the same thing.
Where can I find information about the reasons? The WG homepage still seems to refer to pre-Chicago papers and drafts. I can understand that `std::dynarray` was removed because it is designed to be implemented by the compiler and not the library. But `std::optional` is a pure library feature and looked like a good design.
But those issues are all fixable. I don't see any blocking issues or basic design flaws.
`std::optional&lt;T&gt;` creates an array of size `sizeof(T)` on the stack and then does a placement `new` on it, it doesn't use the heap.
So optimization for expensive copies is limited to return value optimizations and whatever T implements to optimise its own copies. OK, if it's valid for the non-optional type it's just as valid for the optional - my pointer speculations were wrong as this isn't a pointer in terms of abstraction or implementation. Actually, I use a similar type in a container library. It lacks the actual point of `optional` - it doesn't know at run-time if it contains a constructed value or not - but does the array and placement new stuff. It's used for allocating correctly-aligned space for items in data structure nodes, so the data structure is supposed to know what is constructed and what isn't. One thing I liked about C++11 derestricted unions was that the implementation of that could be a lot simpler, but I haven't done that change yet. Besides, the whole thing is old code - probably there's a library replacement I should be using, and the containers don't follow standard container conventions and lots of other annoyances. 
the one dependency on boost kills me too haha. We should look into replacing that with a more simplified version of it now that c++14 dumped optional (and dynarray -_-)
Everything in boost tends to compile many times slower then standard library implementations though :( I cringe every time I have to include a boost header inside one of my own headers.
I'm actually a self-taught engineer now working full time professionally. I have to disagree from personal experience. I found the "standard" introductions to C/C++ pretty underwhelming and jumped to Sam's Teach Yourself DirectX. Now I've spent probably the last 5 years of my life trying to undo the damage but at least I started immediately making something interesting. Outside of academia I believe this is a major problem with C/C++. Many other languages such as C# and Java include windowing libraries and graphical libraries as part of their standard implementation. You still get the console simple hello world but there isn't a huge leap like there is in C/C++ to get into more interesting application by requiring you to search for a graphical library to do even basic graphic applications.
boost.range's `index` unfortunately doesn't work with range-based for (since it adds the index to the iterator, which you don't have access to).
 &gt;I'm actually a self-taught engineer now working full time professionally. I have to disagree from personal experience. I found the "standard" introductions to C/C++ pretty underwhelming and jumped to Sam's Teach Yourself DirectX. Now I've spent probably the last 5 years of my life trying to undo the damage but at least I started immediately making something interesting. Would it be safe to say you had an interest in graphics before even getting started? You may not realize it but the vast majority of C++ code out there doesn't even have a inking of a need for 2D graphics. &gt;Outside of academia I believe this is a major problem with C/C++. I'm not arguing that a 2D graphics library is a bad idea, what I'm saying is the motivation here is completely wrong. The impression I'm left with is that it would be a lib good enough for games and teaching. That in my mind is crap, if you are going to do a 2D lib do it right and make sure it has a future and remains viable way down the road. If the lib is built around drawing pixels on screen they have already failed. &gt;Many other languages such as C# and Java include windowing libraries and graphical libraries as part of their standard implementation. You still get the console simple hello world but there isn't a huge leap like there is in C/C++ to get into more interesting application by requiring you to search for a graphical library to do even basic graphic applications. It isn't a huge leap and options are very important for a syStems programming language. In any event I'd like to touch upon something I mentioned above, the library needs to be built around a real world measurement system. A call that specifies a 5mm line should produce a 5 mm line on screen. Pixel based libraries are a waste of resources at this point. It is interesting that herb didn't list iOS in his list of example implementations. 
Not that I know of. I, too, use both.
&gt;Would it be safe to say you had an interest in graphics before even getting started? You may not realize it but the vast majority of C++ code out there doesn't even have a inking of a need for 2D graphics. Of course and I definitely agree there are higher priority libraries that we need in the standard. I just think it would be pretty nice to have and could help attract more developers such as myself. You are right that there are plenty of libraries that are good enough but there isn't really a standard method. The apis can be so different that I feel like you may need to unlearn what you know to switch from one to another at least when you are first learning. I feel you actually touched upon this at the end of your reply talking about how libraries aren't based around real world systems. They are all non-intuitive and honestly I hope that if any implementation of std::graphics ever comes about that they put significant effort into a smart logical system that doesn't JUST expose the raw power of hardware.
Sadly, std::dynarray can't be implemented as purely a library (as tr1 was). std::optional can pretty easily, though.
Currently c++ has a wonderful central website [isocpp](http://isocpp.org) where you can find a lot of materials (video talks, slides, blog posts...). With the background of java and plain C you will have to spend some more time to learn C++ in its latest standard C++11 (probably even the future one C++14).
&gt; I am very proficient in Java and relatively proficient in C. There are two fatal mistakes that C++ beginners tend to make: program in C++ like in Java, and program in C++ like in C. Both result in shitty code. To avoid those traps: - Never, ever, use `delete`, `free()`, or any manual resource deallocation. - Try to make a whole nontrivial program without using `new`. C++'s strength is in static polymorphism and stack variables. (Sure, when you reach a more advanced level, you'll probably need to use stuff like `unique_ptr&lt;Base&gt; b= new Derived`, but that happens far less often than you'd think, especially if you come from Java.) --- To answer your question more directly: I'm not sure there are good starting guides (i.e. made by people who actually understand C++) online. Heck, [Accelerated C++, despite its age, seems to still be recommended.](http://www.cplusplus.com/forum/beginner/103352/)
optional and polymorphic lambdas were the only exciting features in c++14. Any idea if polymorphic lambdas have survived the slaughter?
Well luckily for us, official and freely published specifications are available for each of these hardware (google quickly finds these). A group of talented dev can implement a complete driver, create unary tests and debug implementation knowing the entire problem.
Why do you need `alignas` and `alignof`? Just use a union and the compiler will align it properly for you.
Oh, I misread your line. I thought it was "show me this and show me that", but in fact you said "show me this and than ...". Sorry for the miscommunication.
Yeah maybe they voted out everything that still had open library issues. But then again they voted in new stuff including library extensions http://isocpp.org/files/papers/N3783.pdf I hope we get to know the real reason soon.
It is not that easy: vector allocates way more memory than it currently needs in order to provide cheap (=amortized O(1)) push_back and pop_back. And to be honest: I don't care where my data are exactly, as long as everything works and is fast enough, so that part is fine. I agree however, that vector is great 99% of the time.
One issue with single ownership is that it encourages unnecessary duplication of memory, e.g. with (possibly immutable) strings.
Last week the Library Evolution Working Group decided to explicitly specify where these headers will be found for TSes, so this won't be a problem for the new stuff.
Standards committee member here. There was enough discussion around optional, in particular around comparison operators in general and heterogeneous comparisons specifically that it was deemed not ready to ship. When we've made last minute adjustments in the past, bad things usually happened. The C++ standard has a very high bar for backwards compatibility. On the flip side, a TS is the perfect location for optional at this stage. I expect it'll get broadly implemented very quickly, and we'll sort out the remaining issues in a matter of months. It will likely get merged into the C++17 working draft long before C++17 is finalized.
Extra interface means extra maintenance checks. There are places where we really don't want that extra interface get used. I usually make a wrapper around vector. But it uses raw memory and constructs objects manually. Afaik new[] operator does similar things but in debug mode the vector becomes really slow. Plus "Everything that's syntactically legal will eventually wind up in your code base." - John Carmack Plus http://en.wikipedia.org/wiki/Single_responsibility_principle Therefore I see unneeded extra interface like a landmine.
Yea, this is what I was worried about. I don't want to bring the wrong habits over to C++ which is why I'm looking for something other C++ programmers would recommend. I'll give Accelerated C++ a whirl. Thanks.
It should actually be relatively easy to implement it as library, since we now have dynamically sized stack-arrays (don't mix the to up); unless of course they removed them too. But even then: There shouldn't be a problem to implement a heap-based dynarray until we can do better.
&gt; a heap-based dynarray vector...
Why allow more interface than what's needed? It'll just end up getting abused by someone else down the road in ways that the original author never intended.
In general, I'm okay with new libraries spending sometime in TS land. Most common implementations would be just as fast to add the TS libraries as new core libraries, and it gives those implementers a chance to run headlong into issues with the specs and work with the committee to correct or improve them before setting things in stone. It's a good middle ground between independently-changeable Boost and we-have-to-support-this-forever standards.
To be fair, C++14 was always intended to be a _minor_ revision -- or as Herb says "it _completes_ C++11". C++-the-next-one (nominally 17) is slated to be a major revision, similar to C++11. All of the current TS work should be ratified then.
This llvm blog post sheds some light: http://blog.llvm.org/2013/09/libc-and-c1y.html (bulleted list near the end)
No, vector isn't exactly that, because it can require way more memory (on GCC it can be almost twice as much). vector needs this because chances are that it will grow (and you don't want to reallocate and move all elements on every push_back). If you start with an empty vector and do n push_backs, every element will be moved about once on average and you'll only have O(log(n)) reallocations. Which is great, but if you stop pushing back directly after a reallocation, you will waste huge amounts of memory.
If you pass the size to the constructor or to reserve()/resize() (before inserting any items) and never go over capacity(), you will never have any reallocations and you won't waste any memory (besides the double bookkeeping of size() and capacity(), which is 8 bytes per container max)
I never checked it myself, so this has to be taken with a grain of salt, but as far as I know, libstdc++ will allocate even in the cases you mentioned allocate more memory than needed. If someone is able to proof the opposite I would be interested.
Some unsolved problems were brought out: http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2013/n3765.pdf Many discussions, no decision, so it was moved to a TS and hopefully by gathering user feedback it'll be polished up in time for C++17.
&gt; http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2013/n3765.pdf Unsolved issues brought out and not solved yet. By moving it to a TS it allows implementation for those we want, and real users feedback. Personally, I would agree with having *every* library feature start in a TS before being set in stone (see `std::vector&lt;bool&gt;`).
&gt; [std::dynarray is a sequence container that encapsulates arrays with a size that is fixed at construction and does not change throughout the lifetime of the object.](http://en.cppreference.com/w/cpp/container/dynarray) It doesn't really start "empty", just uninitialized (unless you pass it an `initializer_list`). It differs from `vector` because it can't be resized, and it differs from `array` because the size is not required to be known at compile time.
There are some real difficulties that were raised for dynarrays though. 1. Whenever a `dynarray` is embedded into a `struct`/`class`, should the `sizeof` the class become unknowable ? Or should `dynarray` revert to dynamic allocation ? Or maybe should we prevent embedding at all. 2. As return types: `std::dynarray f = func();` stack allocation seems impossible (unless `func()` is `constexpr` ?) ... There was a discussion between Howard Hinnant and Marshall Clow (of libc++) and Richard Smith (of Clang) and there are a number of issues with regard to allocation that do not seem easy to solve; the only thing they could think of was to just always allocate on the heap (uh ?). Actually, given those issues, it is unclear to me if `dynarray` could even make it to C++17. Not so surprising I guess when you consider the issues with VLA and tail-padding.
[Here](https://github.com/akrzemi1/Optional/blob/master/optional.hpp) is the reference implementation. Actually it uses both an "alignas" approach for non constexpr optionals and unrestricted unions for constexpr optionals.
FWIW, the implementation shipped with MSVC will allocate the exact amount with reserve unless the vector is already too large. (In which case, shrink_to_fit will fix that.) But resize will allocate extra space and the constructor calls resize.
OK, thank you for checking. &gt; If you never checked, then how would you know? A friend of mine ran into problems related to that and told me about that. But from what you say it was probably the part about increasing by less then 100% or something like that (or libstdc++ changed their implementation in the meantime (though unlikely)).
I know. But if you initialize a vector with a size and do not push_back past the size, it will be OK. Neglecting the overhead and that it is heap based. But yea, its nifty, just need to be careful not to blow the stack:)
I just checked MSVC 8 again (newer versions could be different, but I wouldn't expect that), and it too grows to either the desired size() or 150% of the old size, whichever is bigger. So for an empty container it will be exact, just as libstdc++.
Is the title to this a joke or a lie? The article clearly says that unoptimised Go runs ~200% **slower** than equivalent C++. I.e. 22.8s (the fastest run before the author starts changing the code) versus 11.8s for C++. After this even the author admits "Was this a apples-to-apples comparison anymore? Well no, but it was never meant to be." Mind you, he still continues making comparisons, so he's pretty deceitful himself.
I am willing (infact looking forward) to rerun the comparisons with a properly optimized C++ version... sadly I would be the wrong person to attempt something like that (particularly the multi threading bits) Would it ever be an apples-to-apples comparison though?
I did compile the C++ version with: c++ -o3 Looks like I will have to read up multi threading in C++ after all and post a follow up!!!
Can anyone elaborate on the transformation from MyClass(const std::string&amp; name) : name(name) {} to MyClass(std::string name) : name(std::move(name)) {} My C++11-foo on std::move is pretty weak -- what's wrong with the first snippet and how does the second one fix it?
The first version uses copy constructor while initializing MyClass::name, so the parameter string is always copied. In the second case the copy is done implicitly while calling the constructor, so the compiler is allowed to perform [copy elision](http://en.wikipedia.org/wiki/Copy_elision) to avoid the copy if an rvalue is passed as a parameter.
Ok I feel bad now for being so harsh. Benchmarking different languages is very difficult and unless one is an expert in both, it's nigh impossible to get right. The best one could try is take some already highly optimised C++ code, then code that in Go. Even then there are loads of ways to mess up and leave the benchmark meaningless. BTW, this ray tracing code was never meant to be optimised for speed, it was optimised for code size. So benchmarking it isn't really fair in first place.
This title should be changed. Its misinforming. 
wtf.
To elaborate, optional&lt;&gt; needed to go in. It is easily fixable. waiting three *more* years just so we can finally have Maybe makes us look backward, because we are.
In the first case the constructor of `MyClass` will always invoke the copy ctor of `std::string`, when constructing the member `name`. In the second case, the constructor of `MyClass` will always invoke the move constructor of `std::string` and the caller *may* invoke the copy-ctor of `std::string`, but it may also not. So, all in all, "may copy" is better than "will copy" :) 
I wish Chandler Carruth gave more talks. I find his style very interesting and compelling.
*"The cost of complexity is exponential"* I thought that was a great quote. The clang/llvm stuff seems to have a good focus on being a stripped down, modular set of development environment tools.
I would recommend checking out fgrep: $ fgrep -e keyword1 -e keyword2 -e needle /path/to/haystack &gt; /path/to/output/file
Last check the target. If the language can't match the arch its worthless.
Of course, it'd be best to have both: MyClass (const std::string &amp;n) : name (n) {} MyClass (std::string &amp;&amp;n) : name (std::move (n)) {} 
Sidebar: &gt;Discussions, articles and news about the C++ programming language or programming in C++. For C++ questions, answers, help and advice see /r/cpp_questions. Please read.
Would anyone care to summarize his more interesting points?
I'm getting really annoyed by this PVS guy. Yes, bugs happen - but that's no reason to be an asshat about it. LOOK LOOK THIS IDIOT MADE A TYPO AND WROTE 2 INSTEAD OF 1! HE MUST BE TOO DUMB TO TIE HIS SHOES ON HIS OWN! WHAT A MORON ... BETTER BUY MY PRODUCT! Insulting your potential customers isn't good marketing ...
doubling up constructors, etc ends up with more testing and maintenance headaches. just keep the single MyClass(std::string name) : name(std::move(name)) {} 
Or just `std::movable` (or `std::as_movable`). Still fairly accurate, and readable. Andrei uses the former one in his code, I think. I might go over to doing the same.
You can select other format options, but it's a bit silly that silverlight is default (although, I guess it is an MS site) 
I'm sorta annoyed by the aggressive marketing campain this Andrey_Karpov_N dude does here and elsewhere about his product. 
All that does is eliminate a trivially-elided move construction, and in some cases will be slower due to that it's harder to optimize (watch Chandler's other talk for details on that).
Kudos to you. Last time I used CLANG it provided a ton of bad advice, but if they really solve that problem it could be very useful.
&gt; Last time I used CLANG How long ago was that? CLANG is evolving at a great pace and is now the default compiler for Apple, used extensively in Google, and is being used by more &amp; more OpenSource projects. I'm really excited for it as they have managed to tackle a lot of the complaints about C++ error messages and are building better compile-time checking, free static analysis tools that work, refactoring tools, and the dynamic analysis tools. There's still a lot of work to do, but it is currently considered to be a production-ready compiler. GCC still beats it in some benchmarks (Anything that uses OpenMP, but CLANG is fixing that soon) but CLANG beats GCC in some benchmarks, especially compile-time ones.
Personally I don't understand why bool should have a special treatment; we've given a special treatment to `vector&lt;bool&gt;` and it's bitten us in the .... I am more interested by the discussion about operators though.
This will grow exponentially if you start adding more parameters to the constructor
What's this, a DDOS?
Early documentation is at http://www.boost.org/users/history/version_1_55_0.html
It's a C++ library
Yes, based on a commit messge in the commit removing mention of arrays of runtime bound (ARB) from the C++1y section on the clang C++ status page I believe they completely removed the built-in ARB along with dynarray. Really I think a standardized version of alloca() would be sufficient for the people that want the efficiency that can be gained in certain circumstances with stack allocation. Though there might be problems with alloca too.
That's a lot of TS's.
Yes, polymorphic lambdas are still in. 
of course 
right which is going to mean general uptake is not going to be as good as if they were all bundled in something called c++14... however this or no nice things? i'd rather have nice things :D
My PhD is on Real Time Ray Tracing and I'm due to hand it in in a few months. I know this article is more about compiler performance rather than ray-tracing, so I won't critique the algorithms too much. First an anecdote: I don't know *anyone* who works in my field who doesn't use C++ or C. Some random notes: Compilers are still terrible at auto-vectorization. We make *heavy* use of SIMD instructions. GCC (and other compilers) fully support SSE. Operators are defined for the see data type so you can do a simple a=b+c rather than using intrinsics. Const correctness can really help a compiler out. This piece of c++ contains the const keyword once, for the char array. Const correctness is not only good programming style, it also gives the compiler a helping hand with const-propogation. He's passing copies of the vector struct around. The general rule is that if it can fit in a register (or is smaller than a pointer), this is perfectly fine. If it can't, then pass a const reference. 
His current repository seems to have some threads mixed in, see: https://github.com/kid0m4n/gorays/blob/master/ref/rays.cpp Still far away from the idiomatic and beautiful C++11 I'd like to see. But reading the article, it's not an surprise at all: &gt; Since its been a while (7 years) I went knee deep into C++, I had left it upto more experienced hands to properly optimize the C++ version. Evidently, it was wishful thinking. And then: &gt; I spent the last couple of hours applying the optimizations learnt from the Go story to the C++ version Apples and oranges -- indeed.
isocpp.org is all 404 to me at the moment.
I didn't try to insult you. You might be mistaking me for the poster above :).
But even this code could be improved vastly. In the article the graph shows no difference between the single and multicore versions, so comparing isn't really possible.
Whoa sorry thought you were that dick. Love you :D 
"First an anecdote: I don't know anyone who works in my field who doesn't use C++ or C". Not defending Go, but that's a really bad argument. It's the same as saying: I don't use *nix because anyone uses Windows. But, the whole topic annoys me. It's not a comparison, not even close. The intention of the C++ version was to get it on the back of a business card. The Go version is now highly optimised, but the Go compiler is still young. It's not even comparing apples with bananas. If you want to optimise your software, profile and benchmark it (and use assembler or C++ for your small routines). Or, even better, don't optimise at all and just add hardware. I like Go, I like it way more than C++, but let's get serious. This showcase is a very bad example.
I feel like the C++ subs are turning into /r/fuckcppusegoibegyou 
Here are a couple of problems I have with this mentality: 1. I don't give a damn about GO or any other half baked language that offers little over what we currently have. It amazes me that Google with all their talent could have come up with something a lot more advanced and ground breaking than GO. GO does not move us forward. 2. If you can't write decent C++ code! that expresses comparable behavior why bother? In any event the GO community reminds me of a five year old showing off is latest trick. Adults watching of course have seen this all before. In the same manner we have all seen people promoting their fresh net pet language with contrived performance examples that do more to document the programmers stupidity than anything. GOs problem is that no matter how good it appears, there are entrenched languages similar enough that there is little reason for the rest of the world to adopt GO. 
There was a presentation on channel 9 about using xyz structs vs 3 arrays for each value. Due to vectorization xyz structs version got blown out of the water. This code used xyz stucts so i bet given vector code it would easily be comparable.
I agree that it's a bad argument, that's why I didn't state it as one and explicitly said it was an anecdote, not even an observation. Profiling and benchmarking is always a good way to optimize. I always argue that choosing the correct algorithm is also very important. After all, there's no point in throwing everything at a O(n^2 ) when an O(n log n) solution exists (except of course in certain special cases). One thing I forgot to mention is that optimization of a ray-tracer (actually in this instance, a ray-caster) was a project I gave to a 3rd year University course I lectured. The students were allowed to use SIMD, multi-core and tweak the supplied code, but where not allowed to change the algorithms or add data structures (kD-Trees, BVHs etc) The baseline was single threaded SISD. The best speedup a student achieved was ~11x using SSE on a core2 system with 4 hardware threads. Not bad! 
Whilst I agree, he does says it's been 7 years since he used C++. Certainly, if you have time, do produce an optimized C++ version (without assembly). I'd love to see a clean C++11 implementation.
Any technology worth it's salt should be able to stand up to scrutiny, no matter how entrenched it may be. I, for one, welcome these cross-language comparisons, lest we all labor under some misapprehension that we're using the right tool for the job.
&gt; general uptake is not going to be as good as if they were all bundled in something called c++14. That seems like a pessimistic view. It's not like compiler and library writers will give you all of C++14 in one chunk anyway. If implementation is going to come in pieces, I don't have a particular problem with the spec doing so too. Also, I doubt most of the TSes would be ready in time for '14 anyway so at least this way we get them before 1y. It also looks like all the TSes will get bundled into '1y anyway, so it'll be mandated soon enough. **Ninja Edit:** And I'm actually mostly excited for the TS's. They all look like solid and useful library improvements.
Then perhaps there should be a subreddit for that. I -- for one -- come here to read about C++. Not Go.
I think this message came too early. I'm ill and my colleague said he won't go alone.
This doesn't seem to be valid C++, these ALLCAPS identifiers like ENDIF and DISPLAY aren't legal C++. 
I think you forgot a semicolon.
Have you tried logarithms?
No I have not, I am not really sure what I need to be doing, my professor asked us to do this and the book doesn't elaborate very much on the quadratic formula or factoring or anything of that sort. He said to do research
Not trying to be rude, but you have no idea what you're doing here. It looks like you just copy pasted some stuff from the internet. The people who act like they're being helpful, are in fact, just making fun of you.
So what do you need to do to attend those mettings?
Just attend, those user group meetings are usually open to everyone.
&gt; I was hoping to get some clarity from the reddit community How about you give *us* some clarity. Your topic is called "*HELP!!!!*" for heavens sake! You tell us that you have 3 errors, but you don't tell us which errors. And where did you get that code from? Did you write it yourself? If so, are you *sure* you even have to write in C++? Because I only see two lines which should *not* give an error. If this isn't about C++ then you're in the entirely wrong subreddit. Well, even if this were about C++ you'd still be wrong. We have [r/cpp_questions](http://www.reddit.com/r/cpp_questions) for questions. I can believe that you're genuinely looking for help, but right now you're coming across like someone who hasn't done his homework or any research and didn't even bother to read the description of the subreddit you're posting in.
&gt; 2+x+"&amp;lt;&amp;lt;b;
PIMPL is annoying, but people tend to be way too scared of virtual functions. Outside of tight loops in absolute performance bottlenecks in your application, chances are everyone is going to be fine without that header file implementation. Modules would be the superior solution, though. :)
It could be if there's severe macro abuse. I'm thinking something like: #define DO do #define IF if( #define THEN ){ #define ENDIF } #define ELSE } else { I can't think of any macros that would work with DISPLAY or INPUT, though.
I apologize for coming to this subreddit for help I have now mostly solved my problem thank you for you'lls time. 
The point is C++ **IS** the right tool for the job, but comparing well written GO program to very poorly written C++ version doesn't scrutinize anything.
Which I really hope will bring modules
Part 3 follow up: https://kidoman.com/programming/go-getter-part-3.html tl;dr results: https://kidoman.com/images/512x512-3.png, https://kidoman.com/images/2048x2048-3.png, https://kidoman.com/images/4096x4096-3.png C++ is now twice as fast as the optimized Go version
Does const really have any impact on code gen? Any references to back that up? It would be useful argument against const naysayers.
4.9, according to the mailing lists.
One of the libstdc++maintainers had [a great post about this on Quora](http://stackoverflow.com/a/12665408/2057542). "Unless someone volunteers to finish it (or pays someone else to finish it) it's likely to stay that way for a bit longer, the libstdc++ maintainers have more important things to work on." 
awesome
Finally!
 const int a = 2; const int b = 3; foo(&amp;a, &amp;b); cout &lt;&lt; (a * b); Propogate the consts, knowing that foo() cannot modify them. const int a = 2; const int b = 3; foo(&amp;a, &amp;b); cout &lt;&lt; 6; This applies if foo is an external to the current TU. Of course, with LTO you can get this behaviour sometimes. 
Are both implementations functionally identical? And I don't just mean do they produce the same output, I mean do they arrive at the same output through the exact same steps? [edit] I note you say &gt; Some of theses changes need to be ported back to C++ (not that it needs them); but I haven’t had time yet. I just don't understand why you keep admitting that these two implementations aren't the same in the small print, while leaving the title and graphs implying they are. That's just very **very** deceitful.
&gt; Some of theses changes need to be ported back to C++ (not that it needs them); but I haven’t had time yet. In general, people who publish language-versus-C++ benchmarks have no idea how to optimize C++. I this case he openly admits optimizing the Go version without optimizing the C++ version.
It's not even the compiler doing the elision. It's encoded in the way the value is passed — if an rvalue is passed in, it is moved all the way into the internals of `MyClass`, but if something else is passed in, it will be copied at that point. :)
&gt; I am pretty sure the Go version will get closer and closer as the compiler gets more mature. And with a sufficiently advanced compiler, C++ would be faster than hand-written assembly. 
Improving the current version: https://github.com/kid0m4n/rays/blob/master/cpprays/main.cpp in F() maybe use resize for the vector before doing all the push_backs, also could use emplace_back in current standard. Eliminate the copy in for(auto obj: objects) in T(...) Use std::thread_group instead of std::vector&lt;std::thread&gt; (but that will bring no gain I guess). Thats what I could find in the current version.
This is a really cool series of articles, thanks much for putting in the time, man.
It's because the original implementation was optimised for code size - [ray-tracing back of business card](http://fabiensanglard.net/rayTracing_back_of_business_card/index.php)
Ah ok, serves me right for not looking at part 1.
Hey, that isn't me. :D But I guess when you let the code be vectorized, performance will be even better then now.
&gt; It saves time because it's easier to understand [and] less complex Is it? These example are nearly identical; they're approximately the same length (though C++ has edge) and for the most part are equally easy to read. But the few place where they do differ, for example t := a.Scale(rnd(seed) - 0.5).Scale(99).Add(b.Scale(rnd(seed) - 0.5).Scale(99)) in Go versus C++'s vector t=a*(R(seed)-.5f)*99+b*(R(seed)-.5f)*99; the C++ code is vastly clearer. Mind you given this program was optimised for code size, it does take operator overloading a bit too far, eg using "!" for normalise. Regarding assembly. Well I've done plenty of assembly coding the the past and really loved it. But nonetheless the point here seems to be comparing two HLL. C++ allows you to code at an abstract level without paying for it at runtime, Go clearly does cost you a lot. With Assembly you either have to write code at a very low level or you use abstractions which you will pay for at runtime because things like function inlining isn't done. C's `qsort` is a classic example of paying for abstraction, you either write a different `qsort` for every different data type you need to sort, or you use the library `qsort` and pay for the comparison indirection because C doesn't support generic programming.
Have you recently changed the labels on the diagrams in part 2? I could swear that yesterday C++ was yellow and Go was brown (and thus Go was faster).
Looking at your example you are right. However, when you do math, most of the time you use float64 or int and for those types Go has the standard operators. As I said before, I think assembler should only be used for small pieces of code. Because it's not portable (and abstract), easy to mess up and hard to debug. Let's not complain. C++ is a very powerful language. And I doubt Go will ever get that fast, it's designed with a different mindset.
It has it's warts (mostly from retaining the C-like subset) but overall it's a well-designed language. I give major kudos to the standards committee for not only keeping it modern, but ensuring that older code still compiles and runs (with some very niche exceptions.)
I'm so sick of reading all this bullcrap of people comparing languages, especially picking C++ to make their language look better. Honestly, I don't like that bullying towards C++ from people don't understanding it (few exceptions though) and writing up stuff why in xyz C++ sucks in the way they would like it to suck. 
I love/hate it. But the evolution is increasing my love, and decreasing my hate xD. Give me modules+concepts, network lib, and 3 standard-complete compiles (gcc, clang, and VC) and I'll be happy.
Anyone remember the Gorilla vs Shark post on the StackOverflow blog? I feel that still counts, even for two languages that are seemingly very similar.
You want networking api within the standard library. Why?
As tiny as it is, if you cant run a specify to run a single test if you like, its kind of useless. I like the simplicity so i hope they keep improving it. 
C++11 is a solid step forward, so yes, coming from older compilers it feels really nice to use. However, if you go back and forth from something like Go ( I do that all the time because I have a server in Go and a client in C++11) you'll start to feel the pain again.. and it's a BIG one. Go is a joy to use from whatever angle you are looking at it.. that's why many people are "trying" to evangelize it, they (me too actually) think a world where Go replaces C++Whatever would be a nicer place to live for programmers.. that's all. 
Windows support would still be awesome to have :(
&gt; Gorilla vs Shark Link for the lazy http://blog.stackoverflow.com/2011/08/gorilla-vs-shark/
how much of the today C++ code around the world can be categorized as "carefully optimized"? And how much of that subset actually needs to be "carefully optimized"? I am asking, I dont really know the answer although my guess would be for a very low number. 
But that's exactly my initial claim: The argument you bring is performance, not that using C++ is fun because it is a great language. Concerning go: The article from Rob Pyke nailed some reasons, why it is still valid to think that C++ can be nicer. An important one being: Garbage Collection. I dislike it because it has several weird semantics, not because it can be slow. Another one is the lack of generic power. Templates are a great invention and a language that doesn't provide them is just no contender to C++ in my eyes. It may be a good language for scripting, but If I want to write a serious program, I want my templates. Another thing that I really like about C++ is the fact, that containers in C++ are pure library-implementations of enormous quality: std::vector beats the shit out of what some other languages offer as their arrays. And while the low-level stuff exists, it's only use is implementing fast high-level algorithms and data-structures (or code where the programmer is willing to sacrifice his family for another safed cycle) so that most programmers don't even need to know about them.
I don't know either but I have used enough Java-based IDEs to know that I categorically hate Java-based IDEs (though I haven't tried JetBrains' products). While premature optimization is certainly unproductive I think there's a tendency to forswear obvious optimizations because "they're non-issues because of hardware." I think that's just as bad. Better hardware was never an excuse to write slower code.
Jetbrains' IntelliJ IDEA has some warts, but performance and responsiveness are NOT one of them :D
It's always better to have a standardized API, no?
Yes - it does seem to - I think the original is the previous entry in the blog
&gt; So a change in the implementation can still cause a recompilation of all users One of the greatest (if not only) advantage of PIMPL isn't even there. while the code snipped seems like half-decent hack for stack-allocating forward-declared classes, I don't really see the connection to PIMPL. Overall I'd say include the necessary files and let the compiler do it's job rather than engaging in such brittle hacks in the name of "header cleanliness".
Well, you DO avoid the need to expose various headers (which might include others and so on) used by the implementation also with this PIMPL-approach.
As long as it isn't utter crap. But I'm positive that the committee won't fuck up that much. 
I disagree that compile-time should be a major concern if you write huge parallel programs, since these are exactly the kind of programs where runtime-performance can make the difference between needing one or two data-centers. I agree that there are situations where compile-time really is an important concern and that go might have it's application there. My argument is however that go might be a contender in a special use-case , but if you need something that is truly general purpose and strong in almost every niche, I fail to see how go is in any position to take on C++ there.
Now a few more years to add the C++11 Unicode stuff from the &lt;codecvt&gt; header and libstdc++-v3 will catch up to MSVC 2010
I've never been a fan of the pimpl style. While I agree that it gives a clean interface/header break - I don't see how that's any different from using a pure virtual class plus factory method.
Talking about huge parallel programs, I think Google is a major player in this scene. Why do you think they are investing in Go?
The author does not know about string processing and does not know tries? http://nerds-central.blogspot.com/2012/04/user-injected-high-speed-benchmarking.html no! 
It's not possible for client code to directly inherit from a class which is hidden behind a factory method. Furthermore, it's not possible to stack-allocate an instance of such a class (making it impossible to have, say, a member variable of your class' type which is initialized without any user intervention). Both of these can be fixed with clever use of smart pointers and forwarding methods, but if you're writing a library, you want your API to feel as "natural" and "C++-like" as possible.
Also note that tries are only super effective (as you say) where the strings occupy less than the full 8 byte space of a normal character. Otherwise storage requirements start to be dominant and cause problem with the caches on modern hardware. I suspect you overestimate your own expertise in this area. It is easy to think you know it all when you don't know very much.
Don't get me wrong, I am not saying that go doesn't have it's niche in parallel programming (especially since C++ still has to win ground in this area), I am only saying that in their context long compile-times don't matter that much. The reason why google invests in go are probably others than advantages at the compiletime - that is probably more thanks to Rob Pyke and Ken Thompson who wanted this. I am also not saying that big compile-times are something good, only that sometimes you want to pay this price in order to get better optimized executables. I do not dispute that C++ wastes much time with it's terrible include system.
Well, the startup-time is still terrible…
Ok, that's a good point, thanks. Although I don't think I'd run into that in my own designs.
I am not an insider too and in addition I cannot say that I know much about go with a straight face, but let me guess: The undisputed strength of go is concurrent programming, which is clearly what google needs. In addition to that go throws away much of what many people would call OOP. As a result go has a good chance of enabling average programmers to write good concurrent code which is currently clearly more difficult in C++ (I expect enormous improvements at at this side of C++). The other side is this nice effect, that if you throw away some garbage that resembles the core of enterprisy code, there are always some really good programmers who will take any job where they can use that language (has been true for both python and go). Aside from that, my impression is that they are usually relatively open to try new things. So I guess they do it becuase of a mixture of all of the above and some other reasons.
The Pimpl idiom is useful as a last resort to reduce compile times on very large projects. You should strongly prefer other tools such as PCH, forward declarations, libraries, and removing superfluous #includes. Those other tools are cheap. Pimpl requires writing more code, maintaining more code, and debugging more code. All of this can have bugs, and cost you far more time than you save. Use Pimpl as a last resort only.
If the key is a string then wrapping the key _is_ wrapping a standard container. Maybe this is where the confusion comes from?
+1 for random woman
Another blog incapable of displaying **text** without javascript...
Good point, it does seem possible to interpret the original article in both ways. So I could be very wrong. In truth the original article is needlessly specific in talking about strings and/or containers. Really the underlying issue is that any time it's slow to generate a hash for a type versus a "less than" comparison, then `unordered_set/map` lookups may be slower. Also, for what it's worth, my quick test on VC++ 2013 showed `unordered_set` was faster than `set` for strings averaging ~256 chars in length. That's quite contrary to paper linked by the article which suggests that for strings as small as 35 chars, `set` should win out. Mind you the paper is 5 years old so things may have moved on a lot since then.
Whoever did the webdesign for that blog should be smacked. Scrolling is completely broken on my tablet and the post is nothing but text! Why the hell do we need javascript just to render some simple damn text again?
Interesting. Well I may be excused for thinking so since this article, where it would be highly relevant, makes no mention of it at all. All the more surprising that his characterisation of string maps is so incomplete and – partly – outright wrong.
Funny - reddit does not work on my tablet properly! I think the layout is done by Google (blogger).
"Header cleanliness" can actually be a big deal if you're writing a library and don't want to force your users to install -dev headers of libraries you depend on. Additionally, just including some headers (*ahem* boost *ahem*) can increase compile times, so containing them in a compilation unit can be a plus. 
Variadic templates are such a brilliant idea and I don't think I've seen any other language with such powerful generics.
His performance characterisation is wrong. Hash tables are a pretty decent way to handle string lookup in practice, and where they aren’t, general search trees are *not* the solution (tries are). As I’ve said in my original reply, &gt; A search tree (an ordered map) is more or less never appropriate for use with strings. That’s pretty much the opposite of what the article claims.
I think the de-facto standard data structure in those cases is the [patricia trie](https://en.wikipedia.org/wiki/Radix_tree), although a naive trie implementation where each node holds an unsorted vector of characters (or prefixes) for the branch pointers (which is searched linearly in the lookup step) is surprisingly efficient in practice. The idea of the patricia trie is: You don’t have to use character boundaries for your nodes at all. For instance, you could divide each (variable-length) character into chunks of four bits each, and have each node maintain a lookup table of 16 items. This increases the depth of the trie but makes the lookup at each node fast. There was a paper about implementing a trie with a two-dimensional array, rather than a tree, but I can’t find the reference now. This is also often done for DFAs on limited character sets because it provides the best cache locality, but once again it can be generalised to large character sets by dividing characters into smaller, non-overlapping fixed-size chunks.
Yeah the test was just to satisfy my curiosity, it wasn't as rigorous as the paper. But nonetheless the results were so different for the paper that it suggests a new up to date study is warranted.
Won't that cause a copy when you call the constructor? The parameter is still a value.
It's a Blogger-blog, so probably not the authors fault. I am however in favour of sending those who are responsible for a TEXT-site not being viewable without JS to undefined-behaviour-land for the rest of their lives.
I'd be all over this approach if you didn't have to manually type in a size and alignment. As it is there'd have to be a *huge* benefit over a smart pointer PIMPL.
I don't have a problem with that. The fact that he's trying to make money does not mean it is all about the money- it could mean the converse, that it's all about the graphs for him, to the extent that he wants to make a living out of it so he can focus on it full-time.
&gt;not that using C++ is fun because it is a great language. I think using C++ is fun because it is a great language. Seriously most of the classical C/C++ headaches are easily eliminated by using more modern C++.
false dichotomy. I'd argue that reading many books might actually help in writing many programs (and I'd argue it about A LOT of languages).
False Dichotomy: Presenting two alternative states as the only possibilities, when in fact more possibilities exist. ^^Created ^^at ^^/r/RequestABot ^^If ^^you ^^dont ^^like ^^me, ^^simply ^^reply ^^leave ^^me ^^alone ^^fallacybot ^^, ^^youll ^^never ^^see ^^me ^^again
Manually supplying the size is the whole point, though. If you could automatically get the size without including the relevant headers, pimpl wouldn't even be a thing to begin with.
This is totally useless. If I want to know something, I'll Google it. You could just as easily write a bot that pops in and gives a definition for any word longer than 9 letters. It's just noise.
Yes but there are things that you would only want to build in C++ from the get go. If you are going to load a massive pile of data into memory in an optimized data structure for rapid real time noodling then that is a from scratch thing only. 
The author chose to publish on blogger. He's just as guilty as blogger itself.
If the size of your class changes, then everything including it needs to be recompiled. You can pimpl to avoid that, but if you want to avoid putting on the heap then it cannot be done. &gt;&gt;Turns out that the code example from the beginning of the post is actually incorrect, because the btRigidBody class is 64 byte aligned for reasons unknown and unenforced &gt;That's the second problem. And it's a big one: I'm not sure there's a way to predict the size of a class: it may vary depending on the compiler, the platform, or the compiler options. The only way is to use the definition of the class. Oh, wait...
Owing to C++'s ABI rules, it's also the only surefire route to [binary compatibility between releases of C++ libraries.](http://techbase.kde.org/Policies/Binary_Compatibility_Issues_With_C++) 
Nope. Been that way since I first published it. I did correct a typo in the summary sentence though 
There's *static_assert* in implementation file to ensure this number is correct. The assert, however, is better written as: static_assert(sizeof(...) &lt;= 786); static_assert(sizeof(...) &gt;= 786); This help to find out which way to change the magic number.
&gt; Forward declarations with smart pointers Um, that's PIMPL?
Interfaces have always worked for me.
Interfaces have a cost though, notably dynamic allocation. With the inline pimpl, you get memory locality.
Actually, given how the assert is written, you should see the instantiation of `compare_size` or `size_comparer` with its parameters' values explicitly in the diagnosis; and thus get the expected size for free.
This is indeed an issue. It is not tremendous, as you could most likely add the support for new compiler/platform, but it is an issue. When I had posted an equivalent on SO, I used a "window" check to try and alleviate this `Expected * 0.9 &lt;= Actual &lt;= Expected`.
[I think this is even better.](https://github.com/Drainedsoul/optional) Sorry took me so long to get back to you, been a busy week...
great talk and http://softwaremaniacs.org/media/alenacpp/cppmap-2012.png is the map he talks about - well worth a look
Well, for live streaming, SL and Flash (especially) are used on enough devices to cover a large percentage of viewers.... All sessions are available in either WMP or MP4 or MP3 formats for on-demand viewing (or just listening). Also, the event's name is GoingNative :) 
Well, that's where we're going; that's not where we are.
There was a two part blog post from last year regarding HFT that got considerable attention on [Hacker News](https://news.ycombinator.com). I am not into this field myself, but it looks like a good starting point. - [A High Frequency Trader's Apology, Pt 1](http://www.chrisstucchio.com/blog/2012/hft_apology.html) - [A High Frequency Trader's Apology, Pt 2](http://www.chrisstucchio.com/blog/2012/hft_apology2.html)
Those are both very interesting articles. They give a lot of information on the basics which is great, thanks! Along the same vein is also : http://hackingnasdaq.blogspot.com
Yes, but the const reference constructor also copies: "name (n)" 
It won't be easy to jump into, mostly because the finance industry hates to hire people who aren't already working in the finance industry, especially in it's most competitive positions, and HFT is what is "hot" right now, so every bozo wants that job, qualified or not. You may want to consider studying for the CFE exam to show you have some financial understanding. Maybe look at the financial engineering courses on coursera just to have a taste of finance math. You probably also want to be in New York or London. And network a lot, don't ask me how, it's not my strong suit. Maybe consider taking a job in finance IT even if it is not HFT, just to get your foot in the door, and learn a bit about the finance universe. But if your resume is "meh" it is going to be tough going. As far as how C++ is used, there really isn't much standardization across finance, or even in any one finance company, as far as development technologies. Don't necessarily expect to be blown away with how professional the whole thing is, because finance houses tend to be a bit hack and slash, though I'm sure there are exceptions. Honestly, it's a tough hiring market all around at the moment, a lot of financial pressures on all the finance houses as regulation is up and margins are tight. So good luck, you'll need it. Source: I am in Finance IT (but not in HFT)
Come up with an alternative then.
I didn't think it was that cut-throat.
Do they implement the entire trading strategy on FPGAs, or just the order entry/market data layers?
you are too late to the game. HFT's time has come and gone; most of HFT firms are not doing well: http://www.wallstreetandtech.com/high-frequency-trading-loses-its-luster/240152043?queryText=luster
HTML5? 
Only saw slides (so far) but this is pretty good stuff. There is way too little articles/talks about design in C++ and "bigger picture" view of development in C++ in general. 90% of what is out there is about low level implementation details, newest and coolest hacks and (often incorrect) optimizations.
Yeah, the point is that you can't get around C++11 features if you want to implement a portable `optional` type. :)
If you're using C++98/03 at this point I can't feel sorry for you. 
I'm not. I'm saying that your alternative involves a C++11 feature anyway, so you might as well go for the one that's less "ugly", which in my opinion is definitely the non-union-based one. :)
How is type punning an array of `char` less ugly than an anonymous union?
Usually, it goes something like this: typename std::aligned_storage&lt;sizeof(T), alignof(T)&gt;::type storage; T* ptr = reinterpret_cast&lt;T*&gt;(&amp;storage); It's less ugly to use `reinterpret_cast` than to use a union because it's apparent in the code when you expect the object to be present/constructed and when you don't. It can even be constructed without `reinterpret_cast`: new(&amp;storage) T; (but you'd of course still need a separate flag to keep track of its state in an `optional` type) 
You're literally saying that reimplementing unions is better than using unions. Anonymous unions are explicitly for type punning/manual lifetime shenanigans.
I don't disagree, but reality seem to. Flash, Java and SL has a wider user base, and HTML5 isn't technically released. I can think of many reasons to not use HTML5, as well as reasons not to use the others. But you're just an asshole if you think everyone should use your preferred format/VM/etc. Deal with it.
You have strange ways of interpreting my words :) What the OP presented is an inline pimpl: no pointer chasing. However because it is templated on the actual type it behaves like a smart pointer for users (a smart pointer which deep copies its pointee). You seem to be forgetting that PIMPL is also known as **Compilation Firewall**. It *can* be used for ABI stability when you just use a pointer; however it remains useful even as *just* a compilation firewall. But frankly I don't care if *you* do not want to use it: do as you wish. As for my priorities: to each its own ?
Huh? What sort of parameter were you expecting to pass to it? It returns a random long value. 
I'm sorry, it's been a while since c++ and python has spoiled me. Whenever I generate random numbers in python, it's over a range like: 1-9. What sort of range does this Random() have? 
Released or not, every major browser -- even IE as of 9 -- supports HTML5 video. 
Right?! I thought I was just overlooking some obvious thing. I thank you for trying to help me though. I'll just try to see the professor before it's due. 
Did you find "Random"? Having that implementation might be helpful. I hate to discourage people from learning anything, but I hope that Python isn't the only language you've learned. 
 I'm an idiot. it would have helped to have told you about ["rngs.h"] (http://social.msdn.microsoft.com/Forums/vstudio/en-US/01f73f6c-2f3a-4fb9-9777-94db240e454d/c-error-help-stuck?forum=vcgeneral) I'm really sorry for wasting your time man. But thanks for trying to help!
Well, that's just what I found after realizing that I never even considered what was being included. And yes sir, university :/ But I think they are just reusing old code and want us to get some practice "translating" the concepts and algorithms into a different language. 
You're assuming people update their browsers.
&gt; You're literally saying that reimplementing unions is better than using unions. Yes, I'm saying that avoiding unions for a clearer and safer alternative, that's guaranteed to work across platforms, is preferable to using unions in a potentially dangerous way. Unrestricted unions are not "unrestricted" because they're suddenly safe, but because it was an awkward restriction in the C++ compiler, considering how liberal it is with other unsafe practices. This is not a case where an unrestricted union fits the bill. For one thing, an unrestricted union will still cause the object to be constructed automatically, which is not what you want in an option type.
&gt;For one thing, an unrestricted union will still cause the object to be constructed automatically Unless GCC is wildly non-standard confirming this is not the case. I've done tests with my implementation of `std::optional` -- which uses a union with one member of type `T` -- on a dummy object that does nothing but print when it's constructed/destructed, and the constructor is **not** called when the `std::optional` is default constructed.
COM is back, baby. 
A class and a struct are basically the same thing. The only difference is that struct members are public by default, and class members are private. 
There's actually a second difference. When a class or struct derives from a base without an access specifier, e.g. class Derived : Base ... struct Derived : Base the relationship between the derived struct and the base is that of public inheritance, and the relationship between the derived class and the base is that of private inheritance.
&gt; C++/CX is a non-standard C++ extension aimed at making WRL/COM easier just make sure not to use it in your core application. I wish the speaker had spent more time on this point. I've seen Windows applications that uses C++/CX all over the place and they really shouldn't - C++/CX is intended strictly for the thin boundary layer between your application and the OS. Most of your application code is supposed to be regular, standard, ISO C++.
While it's a valid criticism that clients prior to Win8 can't make use of WinRT libraries like wrl.h, at a certain point Microsoft needed to do something to revitalize Win32. You can't build upon that incredibly old API forever. Sure, clients older than Win8 can't use it, but the same goes for the DirectX versioning. Once upon a time, Win32 was brand new too. At a certain point, something would have had to replace it or at the very least supplement it, and Win8 seems like the perfect time in the Windows evolution to add a completely new API. And really I'm all for anything that makes using COM easier. Fuck COM.
Backwards compatibility with C, if nothing else. 
In response to people who are commenting that changing the size of the impl type would break the abi compatability - remember that one can use this technique to store any size *greater than or equal to* the size of the impl type. Suppose I am writing an API that I know I will need to support, without breaking ABI, for a long long time. I can give each pimpl space enough room for one additional pointer. If I absolutely have to add space later, I can either fit the new state into a word or I can use that last spare word to do traditional pimpl. This is definitely a valuable technique if your ABI needs to remain stable for a very long time and you can afford to spare they bytes.
Leaving aside programming conventions, don't these two differences make struct a better option than class in most cases where class is used? 1. I want my public stuff at the top of the class definition where it is most visible. struct eliminates an extra keyword and visual cruft. 2. Inheritence relationships are almost always public. Again, struct reduces typing and visual noise. Other than convention, is there any reason to use 'class' rather than 'struct'?
Structs are basically used as aggregate types, thus public-by-default makes sense. Structs are just used for conveniently holding data together in one place. Since all they do is hold data, it makes sense to expose that data Classes on the other hand have actual design and modeling. The only things that should be public in classes are parts of an interface. Raw data should almost never be exposed in a class. Classes are interfaces representing something being modeled, thus their insides are private by default, and only a carefully chosen interface is exposed. Considering these philosophical differences and their historical conventions, the default rules make sense to me. They're just safer (and more pedantically pleasing). Yeah, structs would make things a bit less typing in a lot of cases (just throw in one `private:` after all of your public methods), but the "public by default" isn't worth the risk. A mistake might be made that exposes a much broader interface than was desired. If something was made private and it should have been public, it will be noticed very quickly, and can be fixed very easily. If something was made public and should have been private, it might not be noticed for a long time, and if someone unknowning has used it... Well, have fun with that. Also, at a style level, `class` and `struct` mean different things to me. It's always jarring to see a `struct` that is essentially a `class`. (This point is basically moot though since theoretically over time this preconception could change.)
What you say makes a lot of sense and describes the historical reasons why we are where we are. And, as you imply, there are conventions and expectations associated with these things. However, I'm not so sure that having to type 'public:' at the start of every class definition does a great deal to protect anyone from anything. You almost always have to type it so you always do. I have never had to think about whether or not I'm going to type it. Neither does this address the strange choice of making private inheritance the default. I think that classes may have private access by default because the first C++ programmers put their private members at the top of the class definition. It only later became best practice to emphasis the interface by putting public members at the top. 
&gt; And really I'm all for anything that makes using COM easier. Fuck COM. Ummm... what about not using COM? That makes a lot more sense, no?
What should you use instead of COM then? 
Well daa. Microsoft doesn't own HTML5..... yet.
And in a more generic situation, you can use the [`std::call_once`](http://en.cppreference.com/w/cpp/thread/call_once) function. And the article mentions that DCL is a case study in lock-free programming, but the pattern shown is not lock-free.
The standard carves out a special place for anonymous unions **that are direct members of a class** -- as in an implementation of `std::optional`: §9.5.5: &gt;[...] For the purpose of name lookup, after the anonymous union deﬁnition, the members of the anonymous union are considered to have been deﬁned in the scope in which the anonymous union is declared. [...] §9.5.8: &gt;A *union-like class* is a union or a class that has an anonymous union as a direct member. A union-like class `X` has a set of *variant members*. If `X` is a union its variant members are the non-static data members; otherwise, its variant members are the non-static data members of all anonymous unions that are members of `X`. Therefore, by the standard, it is sufficient for a class containing an anonymous union as one of its direct members to have a default constructor et cetera for the anonymous union to contain a non-POD -- the anonymous union itself does **not** have to have a default constructor, since the non-POD in the anonymous union is considered a *variant member* of the class itself.
How else can I manipulate the Windows Task Scheduler (or a litany of other things) via C++ without invoking COM?
TIL. I still think using raw unions is a vastly inferior solution to using `std::aligned_storage`, both in the case of optional types and tagged unions such as `boost::variant`. The only upside of using unions could be better debugger support in some environments.
Has anybody ever used his asmlib and gained any performance?
You're trying to generate an exponential distribution using an uniform distribution as input. Your Random() function is returning a value between 0 and 1. Looking at [the python docs](http://docs.python.org/2/library/random.html), it seems that you can call random.random(). You can also read about [the exponential distribution](http://en.wikipedia.org/wiki/Exponential_distribution#Generating_exponential_variates) where you will encounter the same formula.
indeed. `operation.mt_count` is of type `int` and `count` is `off_t` which is *at least* `int`, but might be wider type. 
That makes sense. Also, I realize now I didn't give any context for the involved data types. Sorry about that. It's only strange that it doesn't do anything in case there is an overflow. Only refuses to act.
OK, thanks. I just don't see how this code would be any different if it were C++. The `(char*)` cast, sure. But other than that, I have the impression that the `if` test would be exactly the same. Edit: or am I missing something here too? Please let me know.
It was more of a general concern, since I encountered the “C++ is just C with some useless additions”-attitude some times to often. Even if we take the above code for example, it is nice C, but clearly suboptimal C++ (you noted the casts, in addition to that: errno is terrible C++ - in C I would say: ”you are really checking it, great!”). If we go further: My answer clearly has relevance for C++, but none for C. Nevertheless: It is a somewhat interesting question which is why I just noted it (I didn't downvote) and gave the answer after that. I don't want to encourage people to come with questions that are clearly only relevant for C (which yours is not, but it could lead people to think so) to this subreddit.
I couldn't agree more that C and C++ are separate languages that are getting more and more different with each new standard. But it's just that I have found more the other opposite type of your: people who say that codes with any instance of `printf()` or `(void*)` are of absolutely no interest to a C++ group. And since my issue was actually related to the expression, I was confused for a while. But I understand what you are trying to achieve here and respect and agree that. Thanks for being very clear and straightforward.
C++ is a first class citizen in Windows Runtime world. C++/CX is a language extension aimed at simplifying COM programming. It is intended for non-COM programmers and COM programmers who dislike COM. wrl.h is a C++ header used in exception-free WinRT programming. It's aimed at COM programmers who like COM and would prefer extension-free C++. Windows authors their WinRT components in C++. They like C++/CX given it's productive qualities and can crank out C++ WinRT components with efficiency. wrl.h can be hard to work with in certain scenarios. WinRT is written in C++. One of WinRT's requirements is to natively support multiple languages/runtimes. C++ is the right tool for that job. Ales loves C++ developers.
[Intro to Algorithms : Cormen](http://www.amazon.com/Introduction-Algorithms-Thomas-H-Cormen/dp/0262033844/ref=sr_1_1?ie=UTF8&amp;qid=1381378370&amp;sr=8-1&amp;keywords=data+structures+and+algorithms+cormen) While the title is Introduction to Algorithms, this book covers data structures as well. However, this book isn't explicitly targeted at C++ (I used it for C++ just fine). The material is probably going to be difficult if this is the first time you've seen some of this. Don't let that turn you off. 
It's still Microsoft, whaddaya want?
open data structures in C++ is basically MIT intro to algorithms with modern C++ code. Personally I find it a bit daunting at times. Coming from a student where C++ is taught as C, looking at their radixsort is horrifying.
P.S. What is a vulnerability? [We regularly find new bugs](http://www.viva64.com/en/examples/). What errors are the vulnerabilities? :)
Let me translate that for you: &gt; ~~C++ is a first class citizen in Windows Runtime world.~~ We use C++ because we couldn't make the world not use it and use our proprietary tools. &gt; ~~C++/CX is a language extension aimed at simplifying COM programming. It is intended for non-COM programmers and COM programmers who dislike COM.~~ But we are gonna make one more effort to lure you into our proprietary programming languages. &gt; ~~wrl.h is a C++ header used in exception-free WinRT programming. It's aimed at COM programmers who like COM and would prefer extension-free C++.~~ It's so shitty that we hope you use C++/CX, trying to lock you into our proprietary software once more. &gt; ~~Windows authors their WinRT components in C++. They like C++/CX given it's productive qualities and can crank out C++ WinRT components with efficiency. wrl.h can be hard to work with in certain scenarios.~~WRL is so shitty, that we admit it, because we don't want to hear any complaints. &gt; ~~WinRT is written in C++. One of WinRT's requirements is to natively support multiple languages/runtimes. C++ is the right tool for that job.~~We didn't dare write it in .NET because .NET is not as efficient in C++ after all. We have hoped C++ would have gone away by now, but it has not. &gt; ~~Ales loves C++ developers.~~ Ales loves people who migrate to Microsoft's proprietary software. Microsoft does not want you to compile your Windows programs on other operating systems/architectures. Facts that support this statements are: * Win32 GUI apps had the non-standard entry pain WinMain() instead of main(), preventing easy migration to Unix or other O/S. * MFC is an abomination. Visual Basic seemed a much better tool. Developers flocked to VB, and C++ was left the dust. VB run only on Windows. * Microsoft took Java, altered it and created J++. They didn't want Java apps on Windows that could run in other platforms. * Failing that, Microsoft developed .NET. They standardized the C# language so as that compatible implementations could be written for other platforms, but not the GUI libraries. So C# outside Windows was not an option for GUI applications. So if you wanted to use C# to write a GUI app, your only choice was Windows. * Even that strategy failed though, so Microsoft is back to its games with another trap: They offer "C++" for WinRT, their later system, but it's so much tied to Windows, and it's so shitty and cumbersome to write for. C++/CX seems a much better proposition, right? but it is proprietary software. **Please Microsoft, stop the vendor lock-in bullshit. Take c++, make good libraries in it, forget COM. C++ is perfectly usable as a tool for writing native applications. C++ is perfectly usable as a tool for writing cross-language code. It doesn't need COM or any other stuff.** 
Thanks for the summary; On another note none of that looks appealing :(
"most of HFT firms are not doing well" Some of us are though. We are hiring in sunny Sydney at the moment, looking for c++ engineers who focus on squeezing the last microsecond out of the software. Financial experience is a secondary concern. See http://www.optiver.com/sydney/careersoptiver/job-opportunities and specifically https://v12.talent2ehr.com/pls/aparbtpp/WK8127$APP.draw_attachments?P_VACANCY_REF_NO=118&amp;P_CALLER_URL=WK8127ZZDOLLARZZAPP.QueryListZZQMARKZZZ_VACANCY_CAT=ITZZAMPZZZ_ORDER_BY=1 
I have. But I called the functions directly within critical parts of the code rather than replacing the standard c lib versions. The performance difference varies by CPU of course but affected throughput in my case by around 1.2
You guys are awesome, but you should read the damn rules: &gt; Reactive patches that merely address a single, previously discovered vulnerability will typically not be eligible for rewards
The only thing written in C++ that seems to qualify atm is the Chromium stack? Hardly something just to throw yourself in to.
I tried to start to grok some of the chromium stack. Without an IDE with a strong language model I was really overwhelmed... there is a staggering amount of code! Any good resources to improve skills in groking large projects aside from an abundance of time and practice?
&gt; Any good resources to improve skills in groking large projects aside from an abundance of time and practice? Yep, smaller projects :P
Yes, that's what I meant by time and practice. Project Euler, for example, is great for honing problem solving skills and understanding how to solve a problem efficiently. I meant something along those lines :-P
Well for this reward program you want to get good at spotting grotty code. As a C++ programmer I'm thinking of things that are easy in C++ but a pain in the arse in C, and then looking at the C projects where you're likely to find those bugs you just wouldn't get in C++. I've already found 6 sloppy coding bugs (probably not vulnerabilities but still unchecked pointers, off-by-one errors, bad memory allocation) in one file in one C project, and few other WTFs where it's clear the programmer was just trying to get something working (but then never went to find a library solution or clean it up).... that's another area I'd look, needlessly reimplemented functionality.
`signal` is a C function. It doesn't understand member functions or lambdas. Pass in a static function. The syntax `this-&gt;resizeHandler` is also not the right way to get a member function address.
This is not c++. This is objective-c. And bad objective-c at that.
You can't do this. The only way to pass a pointer to a member function requires both that you take the address of the member (`void(Screen::*)(int) mem_fn = &amp;Screen::resizeHandler;`) and invoke the function *as* a member of a pointer to an object (`instance.*mem_fn();`). The linkage produced by this kind of maneuvering is messy, and C can't interface with it. Similarly, C++ lambdas don't decay to function pointers if they capture, so there's no way to reference `instance` from within a lambda that needs C linkage. (The standard says lambdas *do* decay to pointers if and only if they capture nothing at all, but not all compilers support that feature.) The only way to pass a function pointer to a C function from C++ is to pass a **static** or **global** function with `extern "C"` linkage. (Actually, I'm not sure if `extern "C"` is required *per se,* but on some obscure platforms, the C and C++ ABIs are different enough that it would probably be necessary.) Like so: class Screen { // ... static Screen&amp; getInstance() { static Screen instance; // ... return instance; } }; extern "C" void *resizeHandler(int signal) { if (SIGWINCH == signal) { Screen::getInstance().measureScreen(); } } // ... signal(SIGWINCH, &amp;resizeHandler);
Ok, here goes: The syntax [object message] is Objective-c. It means send "message" to "object". It's similar to a method or function call. It may or may not return a value. If the method returns another object, the returned object can be sent another message. The code you referenced has several nested messages. self.itemCount.text = [NSString stringWithFormat:@"%d", [[NSNumber numberWithDouble:[(UIStepper *)sender value]] intValue]]; If we start at the inner most method: [(UIStepper *)sender value] We are asking the sender object (a UIStepper control) for its value property. the returned value is a double, and it is being used as input for the next message: [NSNumber numberWithDouble:[(UIStepper *)sender value]] numberWithDouble is a factory method for the NSNumber object. It creates an NSNumber object initialized with the specified double. The next message intValue will return the integer value of the NSNumber object: [NSNumber numberWithDouble:[(UIStepper *)sender value]] intValue]; So up to this point we have: 1. Read a double from the UIStepper object. 2. Used the double value to create an NSNumber object. 3. Read the NSNumber objects intValue. (seems like a lot of work just to cast a double to an int) Next we are taking the newly returned integer value and using it as a parameter to the stringWithFormat message. [NSString stringWithFormat:@"%d", [[NSNumber numberWithDouble:[(UIStepper *)sender value]] intValue]] stringWithFormat is a lot like sprintf(). It's a factory method for the NSString object that takes a format string, and a variable list of params and constructs an NSString object. Finally we take the newly created NSString object and assign it to the itemCount object's text property. self.itemCount.text = [NSString stringWithFormat:@"%d", (int)[(UIStepper *)sender value]]; Would have done the same thing. Although you might argue that the original code has better protection against overflowing.
If I'm reading you correctly, you are saying that the lambda example I posted doesn't work at all and I'd see zero output, but that's counter to what I was seeing and what I am seeing now with the code I just compiled and ran. I am seeing the first function in the lambda that is supposed to print a message to the screen printing that message. The only difference between the function displaying the output and the function that I am wanting to call from the lambda that I can see is that the former is public and the latter is private. Edit: the code I just ran and saw the expected output of: public: bool outputMain(std::string str) { move(0,0); str += '\n'; //append a new line so I don't need to track it normally this-&gt;outLog.push_back(str); int x = 0; for (auto itr = this-&gt;outLog.rbegin(); (itr != this-&gt;outLog.rend()) &amp;&amp; (x &lt; this-&gt;height); itr++, x++) { printw("%d %s",x, itr-&gt;c_str()); } refresh(); /* Print it on to the real screen */ return false; } static Screen&amp; getInstance() { static Screen instance; static bool init = true; if (true == init) { //signal(SIGWINCH, resizeHandler); signal(SIGWINCH, [](int signal) {if (SIGWINCH == signal) { instance.outputMain("Resizing...."); instance.measureScreen(); }} ); initscr(); // init the screen instance.measureScreen(); // get it's dimensions cbreak(); // disable buffering of input noecho(); // input echo off keypad(stdscr, true); // enable special keys } return instance; }
Yes, I too can read. And how do I correctly adjust the signature so that the call takes?
You use the `TYPE_REGISTRY`, `REGISTER_TYPE`, and `MAKE_TYPE` macros in basically the same way as `FUNCTION_REGISTRY`, `REGISTER_FUNCTION`, and `GET_FUNCTION`/`CALL_FUNCTION` from the example. Type registries are defined by a base type, so all registered types have to derive from it. When you call `MAKE_TYPE` it produces a Base* to a new'd object. Interestingly enough, when I first started this project it was just a type registry, but since the type registry implementation is just a layer over a function registry, I ended up implementing both. Now it turns out that having a function registry like this half removes the need for a type registry, because half the point of a type registry is to get access to the virtual method polymorphism.
Nice. Would you write an example which uses all the features of your library? it will help me get a better idea.
Scary. 
As an aside, this does the same thing: signal(SIGWINCH, [](int signal) {instance.resizeHandler(signal);}); It calls the function and I see the first function call in the resizeHandler() function called, but I don't see any of the following ones called.
default implicit behaviour is one of the scary things about c++. Try to avoid these situations wherever possible.
You don't. The C function requires `void(*)(int)`. But the closest you can get with a member function is `void(Screen::*)(int)` *which is a different signature.*
Implicit does not matter here, because there are other function overloads which suffer from the same issue.
PLEASE don't use auto in your examples. Part of the reason for examples is to help people understand what's going on and what types are being passed around.
resizeHandler has to be a static function. Either make it a non-member function (C style function) or make it a static member function of Screen.
Which compiler then would you recommend, as GCC 4.8.1 is so wrong?
and thusly any member function it calls would also need to be static, correct?
BTW, why do you keep mentioning Lambda Functions that capture. I was under the impression that I was not using a capturing lambda function. http://stackoverflow.com/questions/11468414/using-auto-and-lambda-to-handle-signal
Because your lambda function *captures* the variable `instance`.
I might throw up. I hope Rust or whatever will become a viable alternative to the monstrosity that is C++. And I even usually like the language.
Either that, or call the static function Screen::getInstance() in your static resizeHandler function then call regular member functions on it.
... Wonder if that willl work in the lambda that is currently compiling. I've have to make more public than I want to though. 
Constructing a `std::function` from a `boost::function` or vice versa is horrible - you're paying double penalties. As an STL maintainer, this makes me want to cry more tears than I have eyes for.
&gt; makes using it in member-templates of class-templates with conditions that only depend on the class-template impossible &gt; template&lt;bool bar&gt; struct foo{ &gt; template&lt;typename T, typename = typename std::enable_if&lt;bar&gt;::type&gt; void fun(T){} PJP taught me a clever trick for dealing with a situation like this. Applied to your code, it would look like: `template&lt;typename T, bool Yinsh = bar, typename = typename std::enable_if&lt;Yinsh&gt;::type&gt; void fun(T){}`
I know. Just it works. And People will do exactly this. can I quote you on this?
Scenario 1: I give you a chocolate chip cookie. You eat it. It is delicious. Scenario 2: I give you a metal lunchbox. It is heavy, and takes time to open. Contained within is a chocolate chip cookie, which you eat, and it is delicious. You ask me why I bothered with the lunchbox. I explain that you can have a sequence of such lunchboxes, all identical outside, but containing different cookies: chocolate chip, raisin, M&amp;Ms, etc. Sometimes that is worth the weight of the lunchboxes. This explanation is also delicious. Scenario 3: I give you a metal lunchbox marked "Boost". It is extremely heavy. You take the time to open it, only to discover that it was heavy because it contained a second metal lunchbox, marked "Std". There is a cookie inside, but it is not as delicious as before, because it was wrapped in an unnecessary lunchbox. I could explain this in terms of classes and type erasure, but cookies are more delicious. Bottom line: `std/boost::function` has nonzero space/time costs and nesting them compounds the costs for zero benefit.
Sure. "There is only one Internet." - Tycho Brahe
but then, what is the alternative? Should boost add some magic that its not compiling, or is there a way to interchange the callee between the types without wrapping it into another box?
I strongly disagree. 'Encapsulation', at least as I understand it, is all about helping consumers focus on what they actually need to understand in order to be able to use your stuff. 'auto' is a great facilitator of this principle. Do you demand to see an API implementation in order 'to understand what's going on'? Do you spend the time to understand every last bit of a framework before agreeing to use it? If so, your time and effort have zero value to you. PLEASE (as you put it), at least try to respect the time and effort of others reading your code, and expose (ESPECIALLY in didactic samples) what they actually need to know, not what they might-want-be-curious-of-some-day-if-they-have-the-time-and-patience.
I solved it somewhat different: The relevant condition was a constexpr-memberfunction and I just gave it an unused template-argument: template&lt;bool Bar&gt; class foo { template&lt;typename = void&gt; constexpr bool is_bar() const {return Bar;} template&lt;typename T, typename = typename enable_if&lt;is_bar&lt;T&gt;()&gt;::type&gt; void fun(){/* stuff */} }; Since I needed to create the constexpr-function anyways (it wasn't a bool but an integer that represented bitflags), it was easy to do so. To those of you who wonder about template&lt;typename = void&gt;: template-arguments don't need to have a name, if you don't use them (like functions).. Edit: The code, where I encountered this bug: https://github.com/Florianjw/type-builder/blob/master/src/include/basic_number_core.hpp
The solution is to *standardize* on a single type.
This is useful if you have a base class which you want to be abstract, but don't (yet) have any virtual methods on it. In that case you can declare your destructor pure virtual, and provide an implementation (because your base class still needs a destructor). It works because "pure virtual" really means "derived classes must override this method" which is orthogonal to "does not have a definition".
There are better ways to do this, like making the constructor for the class protected. Most of the time you want this kind of thing what you really want is a mixin more than a base class, which can be accomplished with something like the curiously recurring template pattern. Implementing a pure function is a hack that I think most would argue does not enhance the readability of your code.
I don't see why this is useful. Why not just declare the destructor virtual and provide an empty implementation in the header? class Foo { public: ~Foo() {} }; In particular, you can't implement the pure virtual function in the header - it has to appear in a .cpp file - so it means an extra file that does nothing. Perhaps you want to prohibit people from instantiating a `Foo`. Well, you can do that perfectly easily like this: class Foo { protected: Foo() {} public: ~Foo() {} }; which doesn't require either a .cpp file OR using a "C++ edge case" - so it's clearer. (And why go to the extra work to forbid creating a Foo - which has no behavior? I really don't see how allowing this could ever get you into trouble in the first place...) UPDATE: it isn't even clear that the trick works for destructors - at least on clang and gcc. UPDATE TO UPDATE: Works fine - D'OH! Moron mistake. Thanks, /u/mallardtheduck !
You forgot to link against the C++ standard library (-lstdc++).
[See this GOTW article.](http://www.gotw.ca/gotw/031.htm). Herb Sutter provides three reasons why you might want to implement pure virtual functions in the base class. * Pure Virtual Destructor * Force Conscious Acceptance of Default Behaviour * Workaround Poor Compiler Diagnostics 
&gt; I don't see why this is useful. Why not just declare the destructor virtual and provide an empty implementation in the header? Because then it's not an *abstract* base class. One of the defining characteristics of an ABC is that you can't create an instance of it. &gt; Perhaps you want to prohibit people from instantiating a Foo. Well, you can do that perfectly easily like this: Sure, but since it's a base class you *must* have a virtual destructor anyway (unless you know beforehand that nobody will ever attempt to delete an object via a pointer-to-base). So since you've already got a virtual destructor, simply making it pure virtual gives you an easy way to make your class abstract if you don't already have any pure virtual functions. It also gives you a more informative compile error - "cannot instantiate abstract class" vs. "cannot access protected member 'Foo()'" for example. &gt; (And why go to the extra work to forbid creating a Foo - which has no behavior? I really don't see how allowing this could ever get you into trouble in the first place...) Because your hierarchy design mandates it? You're basically asking "why have abstract base classes at all?" Consider the problem of writing a class to handle web requests. There are common behaviors you want to have for all web requests - for example, someone may want to `wait()` for a web request to complete, without caring what kind of request it is. So it'd be reasonable to define a base WebRequest class, and derived HttpRequest and FtpRequest classes. But what would it even mean to create an instance of a "WebRequest"? If the HttpRequest and FtpRequest classes let you send requests with the HTTP and FTP protocols respectively, what behavior could you possibly define for an instance of a generic "WebRequest"? In this case, you'd want to prevent users from instantiating a WebRequest object because it'd be illogical to do so. And if, for whatever reason, you don't already have any other pure virtuals in WebRequest, a pure virtual destructor is one way of accomplishing that.
He doesn't explain at all why the pure virtual destructor is better than making the destructor `protected`, which seems to be the standard in most code bases I've seen, and is also extremely clear as to its meaning. On the other hand, the "Work Around(*) Poor Compiler Diagnostics" is a stomping good idea that I could have used in the past. (* - Yes, he uses "workaround" as a verb, but I can't bring myself to do that.)
&gt; Not at all. I'm asking, "What practical use is it making this specific class, with a virtual destructor and nothing else, an abstract base class?" You wouldn't. But that's like saying, "what use is shared_ptr if I can just say `int i = 0;` in my for loop?" Just because there exists at least *one* case where you shouldn't use it doesn't mean it's not useful *ever*. It's not like it's particularly difficult to come up with an example where you'd have a base class, without any pure virtuals, but which you still want to be abstract. There are a few ways to achieve this which all have their individual pros and cons, including the use of a pure virtual destructor. &gt; The first is that it requires a extra .cpp file No you don't. Feel free to define the destructor in the header if, for whatever reason, you require a header-only class. I never said that you should use this pattern in every case wherever you can. Obviously, if you have a specific use case for which this pattern is detrimental, then don't use it! If for example you have (for some reason) a specific requirement to be able to instantiate a class even when it doesn't make any logical sense, then don't use a pattern intended to make the class abstract! Otherwise, a pure virtual destructor is one way (with certain advantages) to implement an abstract base class in cases where you don't already have at least one pure virtual function.
Ah, I see the difficulty - we're talking at cross-purposes here. I replied to the original comment where he talks specifically about "a base class which you want to be abstract, but don't (yet) have any virtual methods on it" - and my claim was that this _in this case specifically_ there's no reason to make the destructor pure virtual. _Abstract base classes_ themselves are a perfectly useful technique, one I use myself all the time, and I have never argued otherwise.
&gt; I replied to the original comment where he talks specifically about "a base class which you want to be abstract, but don't (yet) have any virtual methods on it" That's the same thing I'm talking about. You could probably argue that, for complete correctness, that should have read "a base class which you want to be abstract but don't have any **pure** virtual methods on it". But it's still perfectly applicable if you have a base class with no virtual methods but still want it abstract, although this case may be less common than the no-pure-virtuals case. &gt; and my claim was that this in this case specifically there's no reason to make the destructor pure virtual. And I still don't see your reasoning for that. I've said this before, but it's not exactly difficult to come up with an example: struct WebRequest { /* ... */ void Wait() { while (!m_isDone) {} } protected: std::atomic&lt;bool&gt; m_isDone; }; struct HttpRequest : WebRequest { void Send() { /* ... */ m_isDone = true; } }; There are no virtuals here. The purpose of the base class is to enforce an interface - you are able to wait on all WebRequests regardless of what kind of web request it is (http, ftp, etc). But you don't want to be able to instantiate a WebRequest itself because that doesn't make sense. In other words, you *want* WebRequest to be an abstract base class, but since there are no existing pure virtuals you need to either add a pure virtual or make the constructor protected. Each has their advantages but the nice thing about the pure virtual destructor is that it gives a clearer compiler diagnostic and (arguably) signals intent better. Whether that's worth the "huh?" factor when other people read your code depends on you. &gt; Abstract base classes themselves are a perfectly useful technique, one I use myself all the time, and I have never argued otherwise. And a pure virtual destructor is merely one way of achieving an abstract base class if you don't already have a pure virtual!
You can use a lambda instead of a function pointer if the lambda can be rewritten as a regular static function. so no binding and no member functions.
And right now the lambda partially works, but not fully. It seems to hit the if statement and the first function and then doesn't run anything further.
C++: where problems are solved by creating more and bigger ones so that you forget what the hell you were trying to do in the first place.
It's not trickery, it's guaranteed by the standard. See 10.4: "*A pure virtual function need be defined only if called with, or as if with, the qualified-id syntax*". Any compiler that produces code that "bombs out" is nonconforming.
Sounds a lot like Qt's signals, slots, and properties.
Difficult when you've got a heterogeneous codebase. You pick up an XML parser from here, an FTP/HTTP accessor from there, an OpenGL library from over there, and if these components aren't carefully designed you've got a messy combination of incompatible lunchboxes. 
I like GDB but it seems that I can't skip over generic functions in templates. For example I can't: skip function Matrix&lt;T&gt;::something() but I have to do instead: skip function Matrix&lt;int&gt;::something() AND add a skip for all the Matrix-types that exist instead which is annoying (and something not doable). With Visual Studio you can skip with regular expressions, something that can't be done with GDB. 
 boost::function&lt;void()&gt; bf{ [](){ doSomething(); } }; std::function&lt;void()&gt; stdf{ [=](){ bf(); } }; *scnr*
Little coroutine based solution. It compiles, but I haven't tested it because the Arch Linux package is currently not shipping the coroutine lib and it won't link. #include &lt;string&gt; #include &lt;fstream&gt; #include &lt;functional&gt; #include &lt;boost/foreach.hpp&gt; #include &lt;boost/coroutine/all.hpp&gt; using namespace std::placeholders; using line_gen_t = boost::coroutines::coroutine &lt;std::string&amp;()&gt;; void getlines (line_gen_t::caller_type&amp; ret, std::istream&amp; sin, char const delim) { std::string str; while (std::getline (sin, str, delim)) { ret (str); } } int main() { std::ifstream test ("lines.txt"); line_gen_t lines (std::bind(getlines, _1, std::ref(test), '\n')); BOOST_FOREACH(std::string&amp; line, lines) { // Can copy or std::move() here std::cout &lt;&lt; line &lt;&lt; std::endl; } } Can also be used with Boost range_iterator to mimic Erics solution.
Very cool. I was going to say a few words about how complicated it is to define iterators in C++, even with the help of Boost.Iterators, and how C#'s `yield` keyword makes it so trivial. Your solution with coroutines looks a lot like how the C# code would look. Nice.
I added a late observation to the article after I published it, which can be summarized as follows: &gt; If your algorithm runs faster with a cache or a precomputed data structure, encapsulate the state in an object that implements the algorithm, rather than forcing your users to pass the state in. The redesign of the `getline` API depends on recognizing that `getline` falls into this category of algorithms.
Despite the factions, there is a trend. Microsoft is well known for embrace and extend, and they have done this in almost every domain, c++ included.
I actually played quite a bit with value semantics and the passing of out parameters into something like getline after watching Going Native. I actually found some rather staggering results. Namely this one: for (auto i = 0; i &lt; 1000; ++i) process_data(get_data()); Was *faster* than: std::vector&lt;type&gt; buf; for (auto i = 0; i &lt; 1000; ++i) { get_data(buf); process_data(buf); } It was faster even making sure that process_data accepts by value in the former, and const&amp; in the latter. It was not faster by much, only by 1% or so, but to me it just hammered home the idea that you should code for humans first and then worry about performance much, much later. Compilers are just really good at optimizing the most straight forward code--I assume that it somehow recognized that it didn't need a different temporary for each call in the first loop and just reused the same one but I struggle to see how it could have. At any rate, the measure first edict is the most important thing to take--along with recognition that nobody really knows what will be faster than what. I like the bits about asking whether the design is right though. The new interface is more intuitive.
This article gets half-way there. `getlines` shouldn't return a lazy sequence of `string`s, it should return a lazy sequence of lazy sequences of `char`. If you want to put those `char`s into a `string` that's your business, but lots of tasks could be done without *any* heap allocation whatsoever -- map, filter, reduce, print, etc etc.
A very interesting suggestion! Thanks.
What do you mean by a lazy sequence of chars? getline operates on a stream, so any length of n-chars you suck from that stream have to be buffered somewhere. In particular it doesn't seem possible to return a [string_ref](http://www.boost.org/doc/libs/1_54_0/libs/utility/doc/html/string_ref.html), because you've no guarantee that the stream buffer covers a whole line.
He means that instead of returning a `std::string`, the `lines_iterator` should return, basically, and pair of `istreambuf_iterator`s that return individual characters pulled from the stream, up to the delimiting character. Obviously, that would mean giving up using `std::getline` under the covers.
Ah, tbh I had no idea istreambuf_iterator existed. It does seem like that would work but you're no longer returning a random access line buffer, so it's then essentially a different API. I don't think even with sin.rdbuf()-&gt;pubsetbuf() that you can write a getline() function that avoids double buffering. The current (public) istream and istreambuf APIs don't seem to allow enough manipulation? Btw, I just discovered you authored Xpressive, which I'm wholly thankful for. You rock!
&gt; random access sequence This is where we parted ways. Nothing in "my solution" is random access -- it's all element-at-a-time. If you want random access you need memory, but if not everyone needs random access then not everyone needs to use that memory and it's wasteful. This might make a decent motivating example: struct StatsTuple { unsigned lines, words, chars; }; Stats_Tuple wc(string input) { unsigned lines=0, words=0, chars=0; for(auto line : lazy_split(input, '\n')) { ++lines; ++chars;//split consumes one character for(auto word : lazy_split(line, ' ')) { unsigned isWord=0;//don't want to count consecutive spaces ++chars;//split consumes one character for(char c : word) { isWord=1; ++chars; } words += isWord; } } return StatsTuple{lines, words, chars}; } Now, this example iterates over a `string`, but there's no reason this whole example couldn't work with a completely unbuffered input stream. The "trick" is that a call to `lazy_split` doesn't go find the `end` of the next element, it just assumes it's "out there somewhere".
that makes sense to me. It would likely work better if i were to "fill in" the black spots with white as long as the black doesn't correspond to the outline. I'm not sure that is possible, though.
One problem with composing this `getlines` range, is that the reference returned by the iterator cannot outlive the iterator, even though you are returning an lvalue. This can be a problem when used with [`segement_iterator`](http://stlab.adobe.com/classadobe_1_1segmented__iterator.html) from adobe, [`concatenated`](http://p-stade.sourceforge.net/oven/doc/html/oven/range_adaptors.html#oven.range_adaptors.concatenated) from pstade oven, or `select_many` from [linq](http://pfultz2.github.io/Linq/). In general, returning references to member variables should be avoided, since it can lead to seg faults, when composed with certain algorithms. Unfortunately, `boost::regex_token_iterator` uses this same technique so perhaps there should be some kind of category for these iterators, because its not possible to deduce the lifetime of the value from its classification alone(such as if its an rvalue or an lvalue). However, that category doesn't exists yet. A better solution is to use more laziness. This is what is done with `boost::xpressive::regex_token_iterator`, and it can also be done for `getlines` as suggested by repsilat. 
Sorry didn't realize this was x-posted from r/learnprogramming. OK - I think you should probably go with (3) if you are new to programming but let me answer your questions anyway. Method 1. a. You progress down from top to bottom, considering each horizontal line by itself. b. For each pixel in the horizontal line, you can define a symmetry score. c. An example such symmetry score is, for pixel X, the number of "i" on the line where line[X + i] = line[X - i]. Another, looser example of symmetry is count white pixels (to the left) versus count white pixels (to the right). d. Then you use dynamic programming but that will take some time to explain if you are not familiar with it. Basically each horizontal line is an array of symmetry score and you want to traverse this array while achieving the highest symmetry score. It's hard to explain without drawings - maybe look up Viterbi algorithm but again that may end up being overkill. Method 3: yes, you got the jist of it a. Pick a line that goes from top to bottom (not necessarily vertical) - just pick a pixel on the first line and one on the last and draw a line. b. Calculate the symmetry score of that line. What does that mean? It means for every pixel to the left of the line, find what its symmetrical pixel is (using basic math) and check if it is the same color. If it is, just increase the score by one. Then normalize by the number of pixels. c. Do this for every possible line - the best one is a good approximation for your symmetry line. Then to refine it you can just look at the pixels around that line and see if you can fudge them a little bit to increase the score. There's a bunch of stuff you need to take care of but that should get you going. Let me know if you have more questions.
Thank you very much for the great reply! I had one other thing that popped into my head, but I'm not sure if it makes sense. If you notice on the picture, the eyes are a pretty extreme local maxima (as far as pixels apart). Would it be possible to search for the 1st local maxima (and tune it to eliminate very small local maxima) and draw a horizontal line between and then draw a perpendicular line equidistant apart form the marked maxima on each side? The only problem would be the appendages possible screwing up the local maxima, but I suppose I can make it start in the center of the picture and move out until the distance between points is larger than a few pixels 
Probably wanna post this to one of the begginer cpp sub-reddits or /r/learnprogramming. To get you started, !(mincopy%factor) is true iff (mincopy % factor == 0) which means mincopy is divisible by factor. The rest of the code doesn't seem completely correct to me though.
It is mainly a learning exercise/something we wanted to see if we could actually do. I have my plan of attack after I have the line of symmetry, I just overlooked this until now. Thats a very good point, and something you are entirely right about--the frog is not always completely vertical and straight. I will get to work on the third method you mentioned. I can't express how much this has helped.
The suggestions here are good, but I get the feeling they'd take a while. As a pre-processing step, [skeletonize](http://cgm.cs.mcgill.ca/~godfried/teaching/projects97/azar/skeleton.html) your extracted contours, and use lines extracted from the skeleton as candidate symmetry lines. I also remember that the distance transform could be used for finding symmetry, but I don't remember exactly how. EDIT: also just realized you'd need to skeletonize only the outermost contour - I.e. no holes.
This is not exactly cpp specific, but I'll give you the gist if ( expression ) where expression can be anything that can be interpreted as a boolean - a function, multiple functions, and object, whatever. in this case, your first expression is: (mincopy != factor ) &amp;&amp; !(mincopy % factor) your friend is mean. this requires a bit of extra knowledge, in that an int can be seen as boolean (true/false), in that '0' = false, and anything else = true. the 'mincopy != factor' seems clear; the other part is !(mincopy % factor). First evaluate the portion in the parentheses: (mincopy % factor). As you may know, this is the modulus operator, so it returns anything from 0 to (factor -1). Imagine this is a boolean; if factor divides evenly into mincopy, the result is 0, which can be seen as 'false'. by saying !(mincopy &amp; factor), this becomes true, when factor divides evenly into mincopy (i.e., factor is a factor of mincopy). It is logically equilient to: ((mincopy % factor) == 0) which may be easier to conceptualize. bottom line is, that portion is 'if factor is a factor of mincopy'. The other if statement does the same computation, but using the method I described, which to my mind is poor code - pick a style and stick with it!
Microsoft certainly tried to embrace, extend and extinguish Java. When that didn't work, they came up with .NET. C++ is a bit different (it's never had a standard GUI library for a start). - If you are interested in porting Windows GUI software to Linux/UNIX, then really, WinMain is the very least of your worries. - Yes, MFC is pretty bad (particularly by todays standards) - Yes, the Java wars - C# was always going to be a non-starter on any other platform than Windows. Microsoft has neglected C++ for a long time. Their compiler devs are terrified of breaking the nightly Windows build each time they make changes. The best we can hope for is a fully conformant C++14 compiler (and C++17 compliant when that has happened). If that does happen, then there will be a lot more scope for porting tools one way or the other (personally I'm more interested in being able to build Linux tools on Windows - yacc++ for example). As far as cross platform GUI goes, I really can't get worked up about that. For anyone who's serious about that there are libs like QT. Oh, and the notion that C# Dev are all gagging to use C++11 is absolutely hilarious (http://akrzemi1.wordpress.com/2013/10/10/too-perfect-forwarding/ for example).
There is a simple rule: when a method is overloaded as a template and as concrete method taking an instance of a class as a parameter, use enabled_if to rule out the case of selecting the wrong method.
Related: http://www.wired.com/thisdayintech/2010/10/1014cplusplus-released/all/
I think the right way to handle digit separators is to make it so the token string ", " is an argument separator when the grammar is ambiguous. Let's say for example we have the following function: void f(int,int); And we want to call f with the arguments 100,100 and 200,200. f(100,100,200,200); Would be invalid, because it is ambiguous (is it 100,100 and 200,200, or is it 100 and 100,200,200?) f(100,100, 200,200); Would be valid. I think it's important that "," is used rather than something new, because that's the current standard in the US. It's immediately recognizable to most people reading the above what the intention is and it using an existing standard.
Not a convincing argument (1) most of the scripting languages ar dynamic, (2) that code would be 3 lines of python, (3) since when does C++ have a large standard library? Bjarne was just was just saying it doesn't as they don't have a curator for it. Plus there are so many gaps in the standard library. Where are the GUI tools, the unicode support? Don't get me wrong: C++ is an amazing language but it is not, nor was it designed to be, nor will it ever be, a Python. It's very very good at what it does but whatever that is, isn't scripting.
… so why the hell does the code use pointers at all? It’s so un-idiomatic that it requires at least an explanation as to why. Added to that, the whole discussion of the (lack of) runtime overhead of `std::move` is completely irrelevant. Just because `std::move` doesn’t add runtime overhead doesn’t mean that the *move constructor* won’t (although in the case of `std::unique_ptr` that’s of course not the case). And of course `std::move` is completely unnecessary here anyway: safeTgtList.emplace_back(std::make_unique&lt;RawSignal&gt;()); (Before C++14, you’d need to use your own `make_unique` which is just one line of code.)
To allow for polymorphism, perhaps?
The lack of native clean unicode support is particularly frustrating. Since the answer to 'how do you do this right' always seems to come back to 'roll your own, it'll be fine!'.
I really like C++ and I start using it almost directly after bash-scripts, but no, C++ is no scripting-language: The boilerplate it needs is pretty small (compared to Java and alike), but it is still to much for scripting: 1. main-function: Great for any big or intermediate program, but way to much for a three-line-script 2. includes: Almost everything high-level in C++ needs to be included. Scripting-languages usually provide strings and IO without asking for it. -&gt; Again to much overhead 3. braces. Don't get me wrong, I like them. But not for scripting. In that area indentation is clearly superior. Conclusion: All these points could be fixed in a hypothetical dialect that could be trivially translated to C++, but C++ itself is still to heavy. OTOH: The reasons above are part of the reasons, why I think it is a bad idea to implement big projects in scripting-languages.
Sort of but no. The sort of "Top level" code in you're program can certainly be very simple if you compose your programs out of well rounded modern libraries (including ones you written yourself to do the function of the program) That said, the code in the libraries themselves is any think but script like. Even the most modern C++ dealing with memory: auto p=std::make_unique&lt;my_type&gt;(....); is hardly script like.
&gt; With the release of C++11 something quite extraordinary has happened. Its focus on usable libraries, value types and other niceties has turned C++, conceptually, into a scripting language. The supporting example offered differs from C++98 code only in that it uses a range-for loop and auto for the last little bit. The rest of it is the same as what could have been written any time in the last 15 years. It's not really C++11 that has enabled this; It's simply that over time 'idiomatic C++' has changed. Another thing he mentions as being scripting-language-like is a large library. C++11 didn't really add much to the library. Aside from small tweaks all over the place and minor additions like `array` and `tuple`, only threading, atomics, and regexs were added in C++11. Far more still lies ahead; ranges, filesystems, networking, high-level task parallelism, graphics, etc. On the core language side modules ought to help a lot at making C++ more like a scripting language.
I wasn't even born yet.
I agree with (2) and (3) especially. I tried to shorten it but only came up with this: #include &lt;fstream&gt; #include &lt;iterator&gt; #include &lt;string&gt; #include &lt;set&gt; #include &lt;algorithm&gt; using namespace std; int main (int, char **argv) { ifstream ifile(argv[1]); ofstream ofile(argv[2]); ostream_iterator&lt;string&gt; osi (ofile, "\n"); multiset&lt;string&gt; data; string line; while (getline (ifile, line)) { data.insert(std::move(line)); } copy (begin(data), end(data), osi); return 0; } which is just 1 line shorter.
Yeah, I know. I was just trying to keep it comparable to his style (including the pointless return 0). To be fair though you need to check arguments in Python as well.
They've apparently confused "scripting language" and "high-level language".
The situation is improving, thankfully. C++11 now has better native Unicode support in several areas.
I don't think you can really called improved WString handling a reasonable answer to unicode support. The built in types handle everything as binary blobs divided into character sized chunks but has no way of confirming that the code is handling unicode correctly or is even sane unicode. It would be helpful to have an actual std::unicode that reports the unicode memory size, character length, and handles encoding casting (ascii,utf8,utf16,utf32) etc. [The ICU project](http://site.icu-project.org/) tries to fix it but at this point it seems silly not to have standard handling of something that more or less the future of text as we know it.
This is neither the most modern way of dealing with memory, nor usually recommended. The correct way is 99% of the time: my_type p{…}; which *is* somewhat script-like. Aside from that: The complexity of the implementation is never really script-like: You probably don't wont to look into the implementation of python tuples and maps.
You can condense that a bit even without using non-idiomatic constructs, saving three lines: int main (int, char **argv) { ifstream ifile(argv[1]); ofstream ofile(argv[2]); multiset&lt;string&gt; data; for (string line; getline (ifile, line); ) { data.insert(std::move(line)); } copy (begin(data), end(data), ostream_iterator&lt;string&gt;(ofile, "\n")); }
I think pretty much the only missing thing necessary to achieve a basically 3 line version of this program is ranges. With ranges in C++ it looks something like this: vector&lt;string&gt; lines; copy(getlines(ifstream(argv[1])), back_inserter(lines)); sort(lines); copy(all(lines), ostream_range(argv[2], "\n")); Where `getlines` returns a lazy range, `all()` is the range equivalent of `std::begin()` and `std::end()`, etc. And the committee's Ranges Study Group was started earlier than the Graphics Study Group.
Note: if `copy` was specified in terms of range, then `all` would be unnecessary as you would just pass `lines` directly. Note 2: Range (as a concept) already appeared in the range-for loop.
I wish we had int main(std::initializer_list&lt;std::string_ref&gt; args) signature for main. Then you would just say `args.at(1)` and `args.at(2)` and be done with it.
I agree that without support for filesystem manipulations (and I don't mean creating files: I mean listing directories!) it is hard to consider C++ a scripting language.
Nice catch. Initially 'line' was kept outside of the loop for efficiency, but since we're moving in to the set anyway there's no point
... I've been using them.
codecvt_utf8_utf16, codecvt&lt;char16_t, char, ...&gt; etc aren't available afaict. Only the u16string and u32string typedefs and wchar_t based stuff seems to work (wchar_t is implementation defined, 32bit on Linux though). In any case, writing something like the articles file copy code while doing UTF8 -&gt; UTF16/32 conversion in difficult and unintuitive. It should be easy as imbuing the streams.
So, how do folks write open source code with Unicode support?
They don't.
Woah! The templates version of the C++ code just blew my mind.
Ah, I see. I was thinking, you see, of rewriting some of my code to handle Unicode input. I guess I'll have to look into Unicode handling libraries
By the way, there is actually a [C\+\+ REPL](www.youtube.com/watch?v=f9Xfh8pv3Fs)
c++11 noob here, but is your version guaranteed to call the move constructor too? Is there any kind of convention to use `std::move` to perhaps document the intent of the code? Also, does he gain anything by using emplace_back rather than push_back here? ( and could he have just called emplace_back() without parameter to get to the same result with less work? ) 
Even better: they way he uses it inside the for-loop is equivalent to your version. I've never seen it that way before, but I guess, I'll do it that way from now on.
To me, scripting language means * low boilerplate * no compiling, no makefiles, no linking headaches The having a good standard library part is just something that compiled languages have been sorely overdue on.
C++ as a scripting language? In what universe? I mean: how much weed do you need to start writing stuff like that?
&gt; You're assuming people update their browsers. Chrome is about 50% of all desktop browsers now, and it does update itself. Also we're talking about DEVELOPERS here not grandma-afraid-to-click-the-blue-E. Even if they are Microsoft Ecosystem developers and prefer IE for ideological reasons, they aren't likely going to be using an old one. I can see reasons not to use HTML 5 but "old browsers" isn't it.
initializer_list doesn't provide [] and at(). I would however be in favor of int main(std::vector&lt;const std::string&gt;) I know that it will never happen though (and to be honest: It is probably the best to keep the core-language and the library strongly separated).
I agree, but I would argue that "scripting language" is a pretty useless designation these days. 25 years ago when you were choosing between awk and C, the distinction was clear and important, but now we've got things like python and we can't even agree on what's a scripting language anymore, and the thing is, it doesn't really matter.
No shift Sherlock. Who is upvoting you for this? 
&gt; c++11 noob here, but is your version guaranteed to call the move constructor too? Temporary values, in this case one returned from a function, are r-values so the move constructors will be used if it's exists. &gt; Is there any kind of convention to use std::move to perhaps document the intent of the code? I would say not in this case like this no, as there is no ambiguity to document. &gt; Also, does he gain anything by using emplace_back rather than push_back here? `emplace_back` can avoid the need for a move at all. No move is faster than a move.
&gt; is your version guaranteed to call the move constructor too? Yes. &gt; Is there any kind of convention to use std::move to perhaps document the intent of the code? No. `std::move` is exactly equivalent to writing `static_cast&lt;T&amp;&amp;&gt;(obj)`, and as such you only use it when you actually *need* to. All it does is force a named object to be treated as an rvalue reference – and hence a value that can be moved *from*. The name is a complete fuck-up: it should actually be called `std::treat_as_movable` or `std::make_rvalue` (or at least `std::movable`) or something along these lines. &gt; Also, does he gain anything by using emplace_back rather than push_back here? When used with `std::move`: no, nothing. However, I’ve heard that MSVC’s standard library didn’t allow this in some quite recent version (but maybe the person who told me simply had no clue), so maybe OP is using MSVC. Nominally, `push_back` could be used here.
So I actually came up with a way of sort of using gcc for actual (almost) scripting a while back, just for fun. As in making the source file executable in a unix like environment. I was experimenting with C but it's equally applicable to C++. Here's what I came up with... //`which true`; set -e; name=`mktemp -t gXXXXXX`; lf=`pkg-config --libs --cflags sdl`; gcc -xc -pipe -std=c99 $0 $lf -o $name; exec -a $0 $name ${*:1}; ret=$?; rm $name; exit $ret #include &lt;stdio.h&gt; int main(int argc, char** argv) { for(int i = 0; i &lt; argc; i++) printf("%s\n", argv[i]); return 32; } If you paste that into a file and make it executable, you can execute it and it will run the C program with correct argv (including argv[0]) and return code. Breakdown of the "magic": First of all, the reason this hack works at all is because how Unix shells work. With an executable file, in the absence of a hashbang, a shell will first try and run the file as a native binary. If that fails it will assume that the program is a shell script, for legacy reasons. So in the first "iteration" the file will be executed as a shell script. //`which true`; Does absolutely nothing. On Linux it will execute ///bin/true, which will immediately terminate successfully. The reason it uses "which" is for compatibility between OSX and Linux, and the reason it's even there is because it conveniently makes the first line a comment in C99 and C++. set -e; Fail on errors, eg. if a library isn't found or if there's some syntax error in the C code so gcc fails the error will be reported and execution will stop. name=`mktemp -t gXXXXXX`; Create a temporary location to store an executable. The -t stuff is a required template on OSX, but isn't required with GNU. lf=`pkg-config --libs --cflags sdl`; Use pkg-config to generate compiler and link flags for any libraries you use. I just put SDL in there as an example, the code doesn't really require it. The reason it's on its own "line" and not inlined in the gcc call is because I want the script to fail gracefully when a library isn't found, instead of trying to compile without it. gcc -xc -pipe -std=c99 $0 $lf -o $name; -xc specifies that the file is C, so that if the file isn't named .c (which it probably isn't) it's still compiled as C. -pipe just speeds up compilation a bit by passing stuff around between the different gcc programs in a pipe instead of via temp files. -std=c99 pretty self explanatory. $0 compile whatever file used to make this call, ie. this file. $if aforementioned linker and compilation flags. -o $name output to the generated temp file so that it doesn't conflict with any other instances of the program being run. Alright, now we have a binary (hopefully)! exec -a $0 $name ${*:1}; Execute the binary with exec. -a is the magic here, because it specifies that this file ($0) is argv[0] for the binary, instead of /tmp/g1203981 or whatever the binary is really called. $name is the binary and ${*:1} passes the rest of the arguments excluding $0. ret=$?; After execution, save the return value. rm $name; Cleanup, remove the temporary binary. exit $ret Terminate with whatever exit code the C program reported. It also conveniently stops the execution of the "shell script". Which is a good thing, since it's actually a C program after this point :) This was mostly just for fun, and it should be noted that if you actually want to use C (and only C) for scripting, there's a really, really fast compiler called TinyCC that actually supports a proper hashbang for executing C programs directly (#!/usr/bin/tcc -run). The only problem with that approach is that it doesn't support using pkg-config for libraries. And of course that it isn't nearly as ubiquitous on Linux/Unix installations as gcc is.
&gt; Temporary values Ah right.. if it was stored in a local variable as in OP's code, it wouldn't move without std::move, but when it's not, move is a safe default.
There really is no reason to be depressed about this since the fix is so simple. const std::vector&lt;std::string&gt; args(argv, argv + argc);
Of course. The small problem is that it's just another line of boilerplate which is somewhat inconvenient for very small programs. the bigger problem is that most libraries want work well with this one, since it is not there by default.
I strongly suspect gcc would be among the slowest interpreters of any scripting language. But the Ruby folks would finally be able to claim to be faster than C!
Approaching off-topicness, but you can do something like: int main2(std::vector&lt;std::string&gt; args) { //do your main() stuff here return 0; } int main(int argc, char* argv[]) { return main2(std::vector&lt;std::string&gt;(argv, argv + argc)); } You can't overload main(), so I called it main2, but it does what you want without much overhead. 
They likely didn't add it because it's hard enough to get people not to duo c style casts.
You're correct, but your tone is unnecessarily off-putting.
Can't you (mostly) just use plain char and assume utf-8 encoding?
Possibly. Although, what would happen in a console/bash application if the user entered 徳川?
A different approach: try [estimating the rigid transform](http://docs.opencv.org/2.4.5/modules/video/doc/motion_analysis_and_object_tracking.html#Mat estimateRigidTransform(InputArray src, InputArray dst, bool fullAffine\)) from the image to a flipped copy of it. The line of symmetry will be the y-axis transformed by half this transformation.
Just use `new RawSignal` then or write your own (until C++14 where it’s included).
Let me explain why I’m exasperated. Wherever you look – open source code, blog posts, Stack Overflow – you’re wading through tons of appalling C++ code full of memory leaks and without exception safety. Bad C++ is rampant. Even before C++11, using pointers was the exception in good code rather than the rule. With C++11, pointers take even more of a backseat. But still many C++ programmers use them like they’re candy. And the reason? They are *taught* to do so by bad teaching material. So when I see an article which uses shoddy coding practices, I get annoyed. I don’t think my tone is *unnecessarily* off-putting – rather, I feel that after all the work I do trying to correct broken C++ code from newbies (and advanced programmers!) I am justifiably fed up with bad C++ resources. The article makes itself even less likeable by presenting non-copyable *screenshots* of code rather than text. By contrast, you complain about my “off-putting tone”. Do you really think that’s fair? The only vaguely off-putting thing in my reply was the use of the interjection “the hell”. It’s not like I’m calling anybody names or being rude.
Get your lazy ass off the chair and write the two lines yourself. "Not part of C++11" is not an excuse for writing bad code.
As I said, it works in 99% of the time, if you do things right. Let's say 95% but if your program is designed well, it is indeed an extremely rare thing.
&gt; When used with std::move: no, nothing. Unless the compiler elided the moves altogether then `emplace_back` can well be *a bit* faster. Basically a move is faster than a copy, but neither is faster again.
&gt; The reference returned by lines_iterator does outlive the iterator. The string to which it refers lives in the lines_range object. Thats true, sorry, I somehow misread it as the string was a member of the iterator not the range. &gt; As long as the lines_range object outlives the iterator, all is good. That's true of all the standard containers. But its not true of `boost::regex_token_iterator` or `boost::token_iterator`. Even though the original string outlives the iterator, the reference returned by the iterator does not. 
This is never going to run, unfortunately, because this would require memory allocation (one for the `vector` and one for each `string`). It's been proposed and rejected already. The advantage of `std::initializer_list` and `std::string_ref` is that neither require an additional memory allocation. And if it just `[]` or `at()` missing, it should be easily implemented.
I agree (the input/output iterators are just awkward), however it is not how the range-for was defined.
&gt;The only other benefit it confers is it prevents the base class from being instantiated, and there are better ways to do that. What do you have in mind? I tend to favour a protected destructor in conjunction with smart pointers. 
Well anything simple would be small, at least initially. But there's already an incurred complexity when you decided to use C++. Let me know when you can "script" a web page, like in Python, Ruby or Node.js. EDIT: Some googling led me to Wt, TreeFrog and qdjango. Interesting stuff.
TLDR: Don't do this This is a disaster waiting to happen. If your placement new throws an exception you are in a world of hurt (I think you would be in undefined behavior land). The advantage of the old copy and swap idiom was that it provided the strong exception-safe guarantee (provided that swap did not throw). You can also use the swap for implementing your move assignment: just swap with the moved from object. see http://www.drdobbs.com/cpp/object-swapping-part-3-swapping-and-movi/232700458 for more information.
The emplace* methods didn't work in VS2010, and in VS2012 they only allow a limited number of arguments due to the lack of variadic templates. They should work without limitations in VS2013.
While reading the features list of this toolkit I seriously muttered "holy shit" several times. If this does what it says it does I need to learn this ASAP. The claim of graceful degradation is incredible. On top of that I can leverage my past C++ experience. I really can't wait to get my feet wet with Wt.
Wt looks nice but the "widget" part seems tricky. Can it be used as a "normal" web framework (aka Rails, Django, Yesod..) with classic HTML/CSS templates views ?
Isn't `std::function` a drop-in replacement for `boost::function`? If so, why doesn't boost just define it in terms of `std::function` if compiling with a C++11 compiler? I must be missing something here...
I love Wt. I actually created a templating language that uses it as its engine to abstract the C++ and make it easier to maintain, but it only uses a very small subset of Wt's capabilities. Wt is totally worth the extra time it takes to write C++ because you don't have to worry about cross-browser compatability. It's amazeballs.
 /u/cheatatjoes is actually wrong. You can use Wt to make fCGI widgets you embed into other applications like the [simple chat app](http://www.webtoolkit.eu/wt/examples/chat), the chat box that comes up on the main page is based off that example code. You can also use the [WTemplate system to layer templates](http://www.webtoolkit.eu/wt/doc/reference/html/classWt_1_1WTemplate.html) with widget layouts and build pages. I've used that to create the base webpage layout and included links that contain my menu object on the left hand side and an app area on the right hand side. Then I swapped out the widget I was using on the right seamlessly, the page doesn't even refresh. I had been experimenting with a few different things so the menu on the left was just a list of plugins that had been loaded from the plugin directory, when you clicked on them the contents of that plugin app were loaded into the right hand side. I haven't experimented overtly with embedding templates however or lazy loading plugins thou (which should both be possible) and I moved onto some other projects so I never really finished that experiment but what I was doing all worked pretty well.
Exactly the reason I started using [CppCMS](http://cppcms.com/wikipp/en/page/main). I know Wt's philosophy to have a widget kind of model and if you are coming from a desktop app dev background, you'll instantly like it. But from a web framework background, CppCMS is a right fit.
I actually don't feel like there is a lot of Bjarne worship in the C++ community. Certainly not to the degree seen in Perl, Ruby, or even the C community.
Well that would be neat, but a little dangerous too. Is there some C++ project for creating web sites?
licensing is gpl or commercial
You dont' need _raw_ pointers for polymorphism. It works perfectly with smartpoitners and references.
Of course, but otherwise you could just omit the pointers (of whatever kind they are). My answer was for your "why the hell does the code use pointers at all?" question :).
The compiled template model cppcma uses kinda turns me off to it but it is really powerful overall from what I've seen. It also requires writing input checks twice thou instead of once like wt so I'm not a huge fan of that either I guess.
Anybody know if there are any major changes between RTM and RC?
&gt; Likewise, your criticism of storing pointers (smart or otherwise) in a vector is simply incorrect No, I disagree. It’s important, and my previous reply has hinted at the reason: pointers (raw, but also smart) are horribly overused in C++. Yes, realising polymorphism *is* a valid use-case. But like I said, (without any reference to polymorphism) it’s sufficiently non-idiomatic that the author should have *mentioned* this requirement. Just using pointers without any rationale sets a bad precedence. And since I am dealing (on a daily basis) with the fallout from that, I do indeed feel entitled to complain about this. So despite your claims it’s not exactly an “unjustified” sense of entitlement. I maintain that it’s justified by the amount of crap I have to deal with.
Also, there does not seem to be any documented differences between any of the versions/flavors of VS2013, other than marketing speak to "delight" your customers.
Still no full C++11 support, and meanwhile mingw is getting better...
 #include &lt;string&gt; struct b { std::string Texture { }; }; int main() { return 0; } Still crashes the compiler :( And yes I've submitted it.
well, there needs to be, because he has an excellent haircut.
You may want to also check out the [libsimdpp](https://github.com/p12tic/libsimdpp) library. It's much simpler and potentially faster, as most functions map directly to intrinsics and can be optimized better. Also, it seems that support for dynamic dispatch has been added recently: you compile the same source code several times with different compiler flags, link everything into the same executable and the library automatically chooses the best version on runtime. Neither nt2 nor boost::simd supports this essential feature.
Second that. "What's new" without the marketing bluff would be very welcome. Also pricing and content of different "editions" should be clarified (or rather there would be just one reasonably priced version). Now hard to say what features are on the version you will be getting.
Does the following code work without locking up the application on shutdown? This was an issue in the last version of visual studio that gave me much grief. ---------------------------------------------- #include &lt;memory&gt; #include &lt;thread&gt; class Singleton{ private: std::shared_ptr&lt;std::thread&gt; pDoSomething; void DoSomething(){ while(!mbShutdown){} } bool mbShutdown; public: static Singleton&amp; Instance(){ static Singleton instance; return instance; } Singleton() : pDoSomething(std::shared_ptr&lt;std::thread&gt;(new std::thread(std::bind(&amp;Singleton::DoSomething, this)))), mbShutdown(false){} ~Singleton(){ mbShutdown = true; if(pDoSomething) pDoSomething-&gt;join(); } }; int main(){ Singleton &amp;Test = Singleton::Instance(); return 0; } ----------------------------------------------- edit: this is just example code I came up with to demonstrate [this](http://connect.microsoft.com/VisualStudio/feedback/details/747145/) problem.
http://www.microsoft.com/visualstudio/eng/products/compare
Wonderful, but how did you find that - all the links on Microsoft's site led to marketing fluff.
&gt; other than marketing speak to "delight" your customers. Don't forget that most of the time, the people who decide to pay for VS have no idea what a "compiler" is.
GBP 11,235 (USD approx 18K) for ultimate edition with MSDN subscription. http://msdn.microsoft.com/subscriptions/hh442902.aspx I'm sure you get a discount for volume licensing or shopping around.
For a website, a GPL framework isn't really a problem
Try making mbShutdown atomic. Otherwise it is a data race.
In the US its USD $13,299.00 for Ultimate with MSDN.
But MinGW has lower C++11 support and conformance than MSVC. None of the official or forked versions even support &lt;thread&gt; &lt;async&gt; or &lt;future&gt; properly yet, which is a pretty big deal all things considered. The lack of full _language feature_ support in MSVC is the real bummer. I really want constexpr right now.
Are you using the latest builds from the trunk? Last time I compiled boost from their stable (granted, it was before the 1.55 beta), it had many problems with 2013.
I'm building boost 1.54. Yeah I may just avoid 2013 momentarily. A lot of people seem to be having issues with it.
There's been no macro system since VS2012. I'm not sure how you class the extension system as "broken"? Seems to do exactly what it says on the tin without issue here...
Still waiting on the Dreamspark Premium release. Hopefully it won't lag too far behind.
Prepare for the downvotes my friend as the elites rush in to tell you to go to /r/learnprogramming or /r/cpp_questions
oh thank you!
So...they expect me to buy a license, but they fail to provide full c++11 support, while gcc and clang have it? No. Sorry.
Amusing, although the second example seems a bit contrived. We can actually get a recursive lambda without special copy constructor tricks or anything, see [here][1] for the result: // Lame... but ideone chokes on decltype referencing an attribute of the class. template &lt;typename&gt; class Func; template &lt;typename&gt; class WeakFunc; template &lt;typename R, typename... Args&gt; class Func&lt;R(Args...)&gt; { public: using F = std::function&lt;R(Args...)&gt;; Func(): _func(std::make_shared&lt;F&gt;()) {} void reset(F f) { *_func = std::move(f); } R operator()(Args... args) const { return (*_func)(std::forward&lt;Args&gt;(args)...); } private: std::shared_ptr&lt;F&gt; _func; }; // class Func template &lt;typename R, typename... Args&gt; class WeakFunc&lt;R(Args...)&gt; { public: using F = std::function&lt;R(Args...)&gt;; explicit WeakFunc(Func&lt;R(Args...)&gt; f): _func(f._func) {} R operator()(Args... args) const { std::shared_ptr&lt;F&gt; p = _func.lock(); if (p == nullptr) { throw std::bad_function_call{}; } return (*p)(std::forward&lt;Args&gt;(args)...); } private: std::weak_ptr&lt;F&gt; _func; }; // class WeakFunc Usage: Func&lt;int(int)&gt; make() { Func&lt;int(int)&gt; fib; WeakFunc&lt;int(int)&gt; rec(fib); fib.reset([rec](int n) { return (n &lt; 2)? 1 : rec(n-1) + rec(n-2); }); return fib; } At the cost of more attention necessary from the developer, we get a somewhat more idiomatic copy constructor. Given how much bad rap `std::auto_ptr` got, I would favor such a style. [1]: http://ideone.com/Vl7Wtg
&gt; seems like very little bug fixing actually went underway between Release Candidate and Final. That is how a release candidate is supposed to work.
true enough, but when their bug list explodes with nearly 17 pages of new, 2013 RC exclusive bugs - most of which have been confirmed and "passed on", you'd think they would do some work in between to ensure the final product isn't broken. At the very least a general availability rollup patch would be acceptable. Leaving bugs in the compiler is a big deal for Microsoft as they rarely ever fix those outside of new releases of Visual Studio (or CTPs, which aren't meant to be used for production code anyway). Essentially, though this is how a release candidate "should" work, I'm sure it would be fine to make an exception for the betterment of the program.
It's not like it takes a genius to read a side bar...
What does it take to be a smart ass?
Where do I get a release of gcc or clang for windows that has full c++11 support? All the ones I've seen are missing things like std::thread. If there is a fully working version I'd like to try it ( as well as using vc++)
Is it worth moving up from 2010? I managed to get a sweet deal on that a year ago. I'm looking at C++, C# and a little of asp.net development. I'm guessing that the lowest price is going to be quite high for a single developer. If it is, then I might take a look at GCC and a good open source IDE
I don't see what's wrong with just nesting functions: std::function&lt;R(...)&gt; foo(...) { return [=](...) -&gt; R { std::function&lt;R(...)&gt; recurse; recurse = [&amp;](...) -&gt; R { ... recurse(...); }; return recurse(...); }; } No need for that funky func_wrapper.
Mingw-w64 supports all of those. Make sure you download the GCC 4.8 version with the posix thread model.
I believe that the race condition is irrelevant here as the value is only written in the destructor.
I have hit this issue before. There is a deadlock because thread::join tries to register an atexit() handler while the main thread is running the Singleton destructor. The destructor is also registered using atexit(), and the array containing the registrations is locked while the handlers are running.
There was no real reason to have pDoSomething in a shared_ptr. It may have been force of habit, or I was thinking of doing something else when I wrote the example.
http://mingw-w64.sourceforge.net/download.php Just make sure you use a consistent threading model across all your libraries. Most likely you'll want to use Win32 threads unless you need C11 threading support in which case you'll need to use POSIX threads.
Only on windows 8, lets all enjoy our forced upgrade to reap the benefits of C++11. If you are from MS and reading this, kill yourself.
Ya because telling someone who wants to learn something to go somewhere were replies can take days or weeks due to a lower population. Yes lets keep making more and more subreddits specializing c++. That way you'll have to go to ten different subreddits just to be part of a single community... Yay efficiency! I mean come on I understand the desire to have a place to just discuss c++ as a language... But learning that language should be apart of general discourse. You can't really discuss the general concepts of something that you couldn't teach to someone else could you?
@simonask Good solution! The blog solution, however, is somewhat simpler to use because there are no nested lambdas. Nested lambdas get tricky when you have captures and especially when they are mutable. It is easy to loose track of what is being captured and where. For instance, int foo = 20; std::function&lt;int(int)&gt; f = [=](int n) mutable { std::function&lt;int(int)&gt; recurse; recurse = [&amp;](int n) { foo = 10; return (n&lt;=2)? 1 : recurse(n-1) + recurse(n-2); }; return recurse(n); }; std::cout &lt;&lt; f(6) &lt;&lt; ", foo=" &lt;&lt; foo &lt;&lt; "\n"; It prints "8, foo=20". I.e., foo remains unchanged. Although the inner lambda appears to capture by reference, it is really capturing the foo that is a copy inside the outer lambda. The outer lambda must also capture by reference to achieve the desired effect. Further, the recurse object is destroyed when all the recursion is complete. That will destroy any state (capture by value) the recursive lambda has. The solution on the blog can build up state because there is only one lambda closure ever created. 
Thanks! :) &gt; Although the inner lambda appears to capture by reference, it is really capturing the foo that is a copy inside the outer lambda. I think that is a desirable goal, no? I mean, this mimics how a regular function works. &gt; Further, the recurse object is destroyed when all the recursion is complete. That will destroy any state (capture by value) the recursive lambda has Again, I'd say this is how you'd expect things to work. Accumulating state is a different goal altogether. :)
The mingw-w64 builds I try (this one in particular most recently: http://sourceforge.net/projects/mingwbuilds/files/host-windows/releases/4.8.1/64-bit/threads-posix/seh/ revision 5) always seem to leak when using futures like so: #include &lt;future&gt; int main(int argc, char *argv[]) { while(1) { std::future&lt;void&gt; t1 = std::async(std::launch::async, [](){}); std::future&lt;void&gt; t2 = std::async(std::launch::async, [](){}); std::future&lt;void&gt; t3 = std::async(std::launch::async, [](){}); std::future&lt;void&gt; t4 = std::async(std::launch::async, [](){}); t1.get(); t2.get(); t3.get(); t4.get(); } } (Infinite loop just to demonstrate the increasing handle count + memory usage) This does not happen in Visual Studio as far as I know. (Edited in a different example)
I agree with your points and do not like fracturing a community, though I think a learning vs general discussion is a common split on reddit for many things including programming and natural languages. C++ has a large community and it makes sense to make that split in contrast to much smaller subreddits. You are rather caustic in your phrasing, attacking those who would give the arguably good advice of actually going to subreddits focused on learning. So tell me, why should I even consider your original statement when you insult me and don't provide any alternative solution?
/r/cpp is much smaller and less traveled than /r/learnprogramming. And /r/learnprogramming is filled with people who WANT to help, vs people who are mostly lurking. 
Upvote for Wt. Wt rocks.
The support is not yet complete. I personally use the pre-packaged MinGW-w64, supplied by STL (nuwen) and I've yet to be able to get my code compiling without either errors, or stdlib implementation bugs, outside of MSVC (on windows - it works perfectly fine on Linux using GCC) Granted, I haven't tried in about a month, and so I'll try again right now.
definitely. 2010 has barely any C++11 support, 2012 and 2013 are big steps up.
To be fair, I'm not using any of the big C++11 features, but there's nothing wrong with future proofing yourself. Now to take a look at pricing and (probably) cry.
Didn't they implement proper variadic templates a while ago? The original 2012 didn't have it, but I'm pretty sure that they were added in a update.
I agree there is a room for bugfix, but these are coming and maybe faster than MSVC update its C++11 support and fix their own bugs. VS 2013 is also deliver with topnotch debugger on windows, but the clang toolkit are coming: I fear that microsoft move too slow to stay ahead...
http://www.microsoft.com/visualstudio/eng/downloads#d-2013-express Express is free and uses the same compiler. There is hardly any difference between professional and express since VS2012. 
plugin support?
If this is true and you work for microsoft, don't kill yourself yet, I have to test this first.
Well, I highly doubt that Clang is going to magically become stable overnight. There's a lot of work to be done there, but they've taken the first major steps to getting the LLVM toolchain onto windows machines.
Everyone, a quick snip of the reddiquette; '[Please don't] Downvote an otherwise acceptable post because you don't personally like it. Think before you downvote and take a moment to ensure you're downvoting someone because they are not contributing to the community dialogue or discussion.' As elaborated below (above? where exactly will this be posted?) - I also disagree with @bnolsen, but that is not even remotely a reason to downvote. Please, let's keep this place friendly.
YEs because 100k people of the... /r/learnprogramming will want to talk about c++... Just because it has more people doesn't mean you'll get any faster reply rate for a single language over any other. But the subreddit dealing with that language should have a higher reply rate about that language. 
What about equivalent corecursive functions? I'm not at a computer right now, but I was thinking something like this: std::function&lt;int (int)&gt; a,b; a = [&amp;b] (int i) { /* call b */ }; b = [a] (int i) { /* call a */ }; return b; It violates DRY, but it is simple and doesn't require any fancy wrapper classes. Thoughts? Also does this compile?
Same here.
... No, you can run it on Windows 7 SP1. [It says so right on the project page.](http://www.microsoft.com/visualstudio/eng/products/2013-editions)
Grab a copy of [Accelerated C++](http://www.amazon.com/Accelerated-C-Practical-Programming-Example/dp/020170353X) and give it a few hours. You should know whether C++ is for you. 
&gt; if it's the only option in its niche (high level languages with a transparent memory/execution model) AFAIK, that's correct. All other languages are either do-everything-yourself (C, ASM) or garbage-collected. A piece of advice though: if anybody tells you you must learn C before C++, feed his body to the pigs. Whether or not you kill him beforehand is up to you.
the reality is that C++ is many things, which is a strength in some ways and a problem in many ways. I have worked with many people who write C programs and claim that they are C++ programmers. Nothing could be further from the truth. The standard is evolving and the language is actually adding some really interesting new features. Herb Sutter gave a great presentation at Going Native 2013 about where C++ is going (I think it is the one called "One C++"). The standards stuff is interesting, but the key points are where they are taking C++. It is interesting to see how a language that used to be reserved for unwashed nerds with beards is evolving into a true general purpose language. As long as you don't try to write bad C with classes...
Given your experience with F#, you may want to check out the rust project by Mozilla. More at /r/rust and [rust-lang.org](http://rust-lang.org). I'd still urge you to give C++ a fair shake, though. It's quite expressive and not as restrictive as other low level languages.
For highly concurrent server applications, D is a good choice. For embedded, unless you really want to pave your own way with D or rust, you are pretty much stuck with c++. I've looked at rust, and the language has a lot of promise, but it also has it's own complexities, and isn't quite bug free enough for prime time.
FYI, a preprocessor bug was fixed between 2013 RC and RTM that affected Boost.
We also fixed tons of bugs [in 2012](http://blogs.msdn.com/b/vcblog/archive/2012/06/15/10320846.aspx) and [in 2013](http://blogs.msdn.com/b/vcblog/archive/2013/06/28/c-11-14-stl-features-fixes-and-breaking-changes-in-vs-2013.aspx). There are still more features to implement and bugs to fix, but 2013 is way better than before.
I already know C, and I am NOT a fan.
I think the time and effort you put in to learning C++ will pay great dividends. Fabien4 is correct that you don't need to learn C first; though it'd be an asset worth adding at some point if you're seriously considering embedded work.
&gt; I already know C Well then, you'll have to forget it while you learn C++. C++'s main issue is that a C++ compiler can compile most C code. Which means that C programmers tend to use C idioms in C++. Which leads to atrocious code. Avoid dynamic allocation as much as possible, and never manually deallocate memory. (Then again... just read Accelerated C++.) &gt; and I am NOT a fan. I'm not, either. I dislike C, but love C++. ---- Edit: Note that embedded is actually where you'll see the least amount of differences between C and C++, since you have no memory allocation, no exceptions, etc.
So... C, then.
I haven't checked the progress of asio, but I know that the std::min / max breaking change in 2013 was / is causing some issues. The problem can be resolved as detailed in the changes rationale, but other than that - I've had no issues with the compilation of boost (other than the necessary patches for it to pick up the compiler properly)
&gt; never manually deallocate memory Wait what?
Well, yeah, that's the whole point of C++: always make it so that the compiler deallocates resources for you. Stack objects, smart pointers, etc. are made just for that. I suppose you can find edge cases where the adequate solution is to call `free()` (or `delete`, or whatever) yourself. But that's definitely not the kind of things for a beginner. (If you're implementing the standard library, OTOH...)
c++ is a language that gives you a lot more ways to do object oriented design wrong. You have to work hard to learn the do's and don't's. Also you already know some general pourpuse languages. Therefore if you want to tell the mashiene exactly what to do and have only small applications, c is a great choice. It also has much less syntactic features. However, I personally prefere c++ over plain c because many things, especially string handling, are easyer in c++ because of the standard library.
Naked new and delete, google it
Ditto. I worked at Sun Trading (Chicago based HFT shop) and upper level management tried to force FGPAs down our throats; it ended up being a disaster and the only thing we use the hardware for now is data parsing/internal distribution for select markets. 
The state of std::async is getting me more and more worried. I use them a lot in my code and would hate to see them deprecated, especially without a reasonable replacement in sight.
What's the difference between the paid versions and express? 
Oh hi variadic templates! Better late than never!
~~As far as I understand it, they don't want to deprecate async completely, but only some paragraphs. I didn't check, but I am quite confident, that they want to change the requirement that the returned future joins in the destructor, which *is* a big change, but the reason behind it is good:~~ A future currently behaves different, depending on how it was created. See the following function: std::future&lt;int&gt; do_something(); There is no way of knowing whether the returned future joins on destruction, without looking into the code. I totally agree, that something has to be done there, and I also agree that the amount of code that will be broken by this won't get smaller. Edit: apparently I was wrong with the assumption, that they don't want to deprecate async completely.
You'll need to do stupid things to get CPU bound (unless on a low-end ARM system with slow DRAM), and Wt will be more than happy on even low-end (cheap) VPS environments. It's a stateful toolkit which means it keeps things in memory, which makes typical event handling (incremental updates) very efficient, and has the advantage that you can also keep (database) state in memory, but has the drawback that you need to budget for memory. For example if you keep up to 2MB of state around (which is already a fair amount) per active session, you can fit 2000 active users in 4GB. And with haproxy reverse proxy with session affinity you can easily scale up, more so because you can keep (database) state in a session and thus there is much less stress on a database (or other shared resource).
In my opinion in long term C++ as a language is useless. I will explain you why: Languages themselves are only a thin shell for libraries and people (ecosystem). They are neither good nor bad. Derivative of use (program or library) can be good or bad. C++ community brings chaos. This language has so poor and miserable standard libraries that everyone is forced to reinvent their own sooner or later. Why its standard libraries are poor? This language was created 30 years ago. 30 friggin years! As a tool combined with for ex. Qt is even worse. Right now I'm trying to compile my open sourced project previously (3 years ago) written in C++ using Qt4.x on a recently downloaded Qt5.1. I can tell you now how much I'm pissed off. Actually to fix all compilation bugs I will have to start learning Qt from the beginning! I'm not going to do this. Hell no! Do you think this is Qt's fault? Look at Microsoft and their Windows. Yes, Windows is the land of C++. The only thing what is constant in their software is: constant backwards-incompatible changes. C++ is so inflexible that it encourages rewriting instead of evolution. This is the only programming language known to me which is pushing this as a feature. Summary: If you have all your libs written by yourself (including operating system) go with C++, but, if your software depends on someone else's work, be prepared for a war. Choosing C++ you are marrying its ecosystem which is IMO a steaming pile of crap. This is very negative reply, but I think C++ and its community deserves it. If you really need a static typed language go for Haskell or hybrid (Python + C).
Looks like I'll be installing VC express, later today. 
Thanks for the update! 
C++11 is powerful, and with handy ranges it could get closer to D code like this: void main(string[] args) { import std.stdio, std.algorithm, std.string, std.file; args[2] .File("w") .writefln("%-(%s\n%)", args[1] .readText .splitLines .sort()); }
Just make sure it's 'Microsoft Visual Studio Express 2013 for *Windows Desktop*' and not 'Microsoft Visual Studio Express 2013'
What's the difference?
Much better indeed!
Agreed!
[XOR Swap Algorithm](http://en.wikipedia.org/wiki/XOR_swap_algorithm)
c++? hardly.. that is how you do swap in c++: [&amp;](int _a, int _b) { a = _b; b = _a; } (a, b); (:
 std::swap(a, b);
Nope, _a and _b is not the same as a and b - it is copies. They get copied, when the lambda function is executed.
we can use generic programming!! that is we can take the help of templates which can swap different types of data(int, float)!! what do u understand by "a+b overflows" can you please elaborate
&gt; I actually created a templating language that uses it as its engine to abstract the C++ and make it easier to maintain ... Did you made the tool public?
Some feedback for you. Using 'u' for "you", "gud" for "good" (saw an example of this on your website), starting a sentence with a small case letter, comes across as very unprofessional. You may think it "kewl." It isn't. It's childish. 
Thank you for your feedback!! I will consider that next time. I was just concentrating on logic of the program.
If you do not understand what is meant by "what do you do when a + b overflows", please put the compiler down, walk away and pick up some texts and start reading. Recommended would be "Secure Coding in C and C++". Only once you understand why overflow/underflow is an issue and why you should avoid it, you'd understand that the article you submitted is a fine example of bad practice or an anti-pattern.
I assume its for the environment settings sync. A useful feature if you work from multiple machines.
Exactly. I also think OP overlooked the 'Now now, maybe later.' button.
The latter one is for making Windows Store apps. Formerly known as Metro apps. 
Ah, thanks.
Thank you for the good advice. I do understand the concept of overflow and underflow, as i have studied and implemented data structures. i know how integer overflows etc etc.. I just gave an example to swap numbers, it was just for those who begin learning. I think we should not try to make things complex in the beginning. The idea is to move from simple to complex. So, its not bad practice, its your own perspective.
Now now, maybe later... Good title for a song!
a and b are in integers, when they overflow, (when a+b is too big for an int) your algorithm will produce the wrong result. It also fails for floating point numbers.
Not only can you ignore this, but it's extremely useful when working on a TFS.
I understand where you're coming from. But then the article should have managed expectations in the beginning. If the target audience was mentioned before the algorithm proper, you wouldn't have to explain it here - out of context, where a future reader may not venture.
lol, I thought about saying this.
Of course. I'm not saying they're wrong for doing that. It just makes it significantly less valuable to me, which I imagine is their intent.
gcc and clang have plugin support?
Virtually every browser comes with spell check. There are extensions that help as well, such as [after the deadline](http://www.afterthedeadline.com/). There are [chrome](https://chrome.google.com/webstore/detail/after-the-deadline/fcdjadjbdihbaodagojiomdljhjhjfho?hl=en) and firefox extensions, as well as a plugin for wordpress. I've found that even though I'm normally careful about spelling and grammar, it never hurts to have somebody checking for you ;) 
The profiler in the high end versions of MSVS alone is worth the money. That saved me hours and hours of work in optimization. So glad I have that at work.
Github.com/tomthorogood/Mogu :-) 
that's the counter post I was referencing.
Pulling some sources should give plenty to work with. https://www.google.com/#q=bitcoin+miner+github
I have no problem if they're "replacing it", but they're not yet (and unlikely to do so until 2017 at the earliest), which leaves people that need the functionality it supplies out in the cold. Having more people use it as a bad thing, sure, but don't deprecate it. Recommend people stay away from it (for the reasons already mentioned) and deprecate it in C++17 when a proper replacement exists.
Just trying to explain the logic behind the program. That remains same whether you use overflow concept or not.
A funny thing is that if `a` and `b` are unsigned then the result is correct even if an overflow occurs, because you are essentially computing in modulo `2^N` arithmetic for some `N`. Thus you get a correct result modulo `2^N`, which is the correct answer in this case since `a` and `b` were both less than `2^N` originally. The standard guarantees this behavior only for unsigned integers, though in practice this also works with signed integers unless the compiler does something really fancy.
&gt; Recommend people stay away from it Well, technically, deprecation means exactly that.
Just a side question: I read deferencing std::unique_ptr has some cost. Any pointer where can I read more about that? What about deferencing std::shared_ptr cost?
&gt; If you're implementing the standard library, OTOH... And even the std-lib doesn't call new directly, but hides (de)allocation behind replaceable allocators.
The code that tries to demonstrate how the function works uses `std::swap()`, not the custom `swap()` function. :)
ya!! thats what i have done!
Is this new, it's not long since I tried it and it had no working thread support.
They released a CTP update to VS2012 which had variadic templates but it was weird - people reported a lot of bugs in it, and Microsoft never followed up with another update to the CTP like everyone expected them to.
I call BS on this one
Is the link in this submission wrong, or am I misunderstanding how WG21 works? As I'm reading the submission title, shouldn't this link to [2013-10-post-Chicago](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/#mailing2013-10) instead of to #2013-09 (2013-09-pre-Chicago)? I'm sure people are going to scroll down and discover it anyway, but the two together seem to be the complete package of the Chicago meeting (pre+post) instead of the post-Chicago the title mentions.
IntelliSense is not working/showing for me when working on a variadic template class that derives from another variadic template class, and indentation is all messed up in switch cases when using brackets.
If your `$LANG` and `$LC_CTYPE` are set to a utf-8 locale, your terminal will send the appropriate UTF-8 sequence to the shell or program, and the terminal will treat it as UTF-8 as well. Bash is generally well-behaved, but if your terminal doesn't support Unicode, you won't get nice double-width CJK characters. (Or you'll get other weirdness.)
Why?
Here's a riddle for you: What are the initials of Bjarne Stroustrup?
Given that you were such an ass writing this, why not redeem yourself by writing the code here? :)
&gt; If we have only ARBs for stack storage, these problems are not addressed, (pointer,count) interfaces will become more common (and probably “baked into” ABIs), and we will have encouraged a lowering of the level of programming from the use of containers and algorithms to the use of arrays and pointers. This is a topic of major importance because the importance of stack storage (and any other storage that works well with concurrency and doesn’t require synchronization for allocation and deallocation) is increasing. This is interesting. We've gone through a few decades where the heap was being (over-) used for everything (Bjarne blamed the Java programmers in his GoingNative keynote this year!). But now the stack is coming back. Pass everything by value, and let `move` do all the hard work!
The prospect of being able to allocate variable-length members on the stack is very interesting, and is something that I was hoping I would be able to do using C++ for a long time. I hope that this feature will be added to the standard within the next few years, if not by C++14.
The fundamental problem, though, is that stack-allocated memory cannot be moved.
(Clarification: I was not suggesting here that the data that 'backs up' an object can live on the stack. For example, consider the data *pointed to* by the `char *` inside an `std::string` - the `char*` might be on the stack, the pointed data will be on the heap. (If that data is to be 'owned' by moving objects). Ownership of data can transfer from one object to another, no matter where the object itself is. But the *data that is owned* by the object will stay put and should be on the heap.) I'm not sure about this. Even forgetting about these run-time sized arrays, when `move` is used (implicitly) to optimize a `return` statement, it is applied to a local variable on the stack. X f() { X x1; X x2; // initialize them return boolean_expression ? x1 : x2; } The contents of x1 and x2 will be moved from the stack here. &gt; ... stack-allocated memory cannot be moved. For non-array data, it can be moved from the stack. Arrays, dynamic or otherwise, cannot. Have I missed something?
You're not actually using the swap function you wrote, I think you're misunderstanding tejp. Not to be rude, but perhaps you shouldn't be posting code if you make such simple mistakes.
Perhaps because Bjane called his proposal bs_array "basic stack-allocated array type.."
Wt uses Boost - Check CmakeCache.txt and set the proper boost Random Setting depening on your Boost Version. - do not use the current (1.54) Version of Boost. Cmake Aborts the Compile due to a Bug in that boost version. - wt includes boost in the headers. So expect slow compiles.
No, it is not moved. It is copied (ignoring RVO). Only heap memory can be "moved", meaning it stays exactly where it is, instead of being copied back to the caller. What is "moved" is the ownership of that memory. And moving that ownership is done by returning (copying) a pointer. If `X` in your example is a class type with 100 member variables, all of them will be copied (again, ignoring RVO), because the memory where `x1` and `x2` are allocated (the stack) will be reused by the caller as its own stack, and its contents overwritten. Therefore, `x1` and `x2` must be copied. It really has nothing to do with being "array data" or not. `std::move` works only for heap-allocated memory, which (in contrast to stack memory), can stay where it is when a function returns, i.e. its ownership can be moved.
&gt; With the recent bug ridden release of VS2013 What bugs?
express compiler! wrap it with a cross platform build tool and you should be good! cygwin works well with this as well. DLL hell pretty much ensures you are well locked into the MS compiler. Amazing how atrocious their compilation and link models are.
Only 5 developers? You might be able to qualify for [Microsoft BizSpark](https://www.microsoft.com/bizspark/signup/default.aspx), which would hook you up with VS for free :) There's also Visual Studio Express. Personally, I find Visual Studio + Visual Assist X (with some help from Sublime Text) to be the best way to work in C++. [SublimeClang](https://github.com/quarnster/SublimeClang) was looking like a decent replacement, but it's no longer in active development.
Whoa buddy, asking for the actual bug reports wasn't an attack on you. I for one wasn't aware of these bugs either. Thanks for posting the links!
I think BizSpark is for new startups, we've been around for 11 years now. The IDE is not our primary concern (though it has gotten increasingly bloated), the issue is the compiler and the various functionalities such as debugging and PGO etc. I remember a time when independent developers would actually sell products that fixed bugs by patching VS and generally made VS better... coderush. We're really after a modern c++ compiler that supports the new c++11/14 features correctly that can target the windows platform. Clang is a definite option, but I think it's some time away for production use on windows.
Maybe you should wait for a stable release from clang. http://blog.llvm.org/2013/09/a-path-forward-for-llvm-toolchain-on.html google is working on it (last 5 minutes): http://channel9.msdn.com/Events/GoingNative/2013/The-Care-and-Feeding-of-C-s-Dragons It is alpha-quality now, but quickly evolving
I wanted to know which bugs you were talking about, since you didn't mention specifics. Note that neither of your linked bugs are regressions from 2010 - NSDMIs/uniform init are new to 2013 (that one's a compiler bug, by the way - not libraries) and join() was new to 2012. They're still problematic, but regressions are obviously worse. We've fixed lots of bugs between [2010 and 2012](http://blogs.msdn.com/b/vcblog/archive/2012/06/15/10320846.aspx), and between [2012 and 2013](http://blogs.msdn.com/b/vcblog/archive/2013/06/28/c-11-14-stl-features-fixes-and-breaking-changes-in-vs-2013.aspx), so there are compelling reasons to upgrade aside from 2013's major new features. It is true that 2013's STL still has bugs, but very few of them are regressions, and I'm working on fixing them. (I am about to check in a fix for the facet allocation mismatch bug, present since 2006, and the widely-reported clock bugs are a top priority for me.) I wish I could be everywhere at once and fix everything instantly but I just can't. Are there bugs assigned to me that you're especially interested in getting fixes for? I can't make promises, but it is useful to me to have some idea of what people consider most valuable.
Can you elaborate?
I don't understand this reasoning/comparison with g++. The C++ compiler (which is all you get with g++) doesn't cost anything. The express version isn't just for tiny projects either, and comes with very useful tools (like /analyze). It's not a gimped C++ compiler so I don't understand why vendors MUST have the most expensive version or only use it for comparison with the free alternatives.
What is obvious is that MS is struggling with marketing. It is very clear there are very confused people out there. Stephan Lavavej is doing a great job clarifying and explaining things. But it shouldn't be him alone at Microsoft doing this work.
I can definitely agree with this point on the marketing. Case in point on the product page the express edition is not listed in the feature comparison between flavors.
Fair enough. I admit I never quite understood the difference between the paid versions and the free version. OP seemed to be talking about the paid version though, hence my message.
It seems like we might have to go down this 'unfortunate' path as well.
I think MS want to sell expensive stuff to corporate, but also encourage as many programmers as possible (including poor ones) to make Windows-only applications. Add to that that the people who want the former and the people who want the latter are probably different people at MS, and they don't necessarily communicate with each other.
See [my comment](http://www.reddit.com/r/cpp/comments/1omyr1/visual_studio_2013_available_now_visual_c_team/ccugl2q) in another post a couple of days ago. I referred to Q5 in [my big VCBlog post](http://blogs.msdn.com/b/vcblog/archive/2013/06/28/c-11-14-stl-features-fixes-and-breaking-changes-in-vs-2013.aspx)'s FAQ. I choose to ship a greater total number of bugfixes in every major version, than a lesser total number in the same period of time through successive Updates.
You could fairly easily use CMake or something similar to call the VC++ Express (free) compiler. Then use any VS IDE as an editor. Frankly, I think this is a much better solution than maintaining SLN and Project files but depending on the cost of porting your build you may feel differently. The upside to using CMake is that you can change toolsets on the fly and would never feel this pain again though.
if you are really tied to the visual studio gui you are sunk. otherwise you should be able to use the express compiler with other gui interfaces. We do most of our development and troubleshooting on linux and compile on windows release mode only. At this moment we have more customers running our windows versions and they are using our software to certify their hardware (it slams dual socketed xeons quite well and seems to always run several day jobs to completion every time). MS is happy in that they had to put win8 on some boxes to make them stable. I am considering taking a shot at 2013, the 2012 compiler is embarassingly molasses slow, linking is especially bad. Our whole repo compiles ~4x slower than with gcc (also release mode only).
Are you comparing VC with Link-Time Code Generation (LTCG) (aka Link-Time Optimization (LTO)) to GCC without? This is controlled by `/GL` for VC and `-flto` for GCC. In particular, it improves runtime perf, but takes a lot longer to link, because compilation is actually done during the linking step.
i call BS on this. mingw is quite stable as is clang for generating good executables. The issue with library compatability is a serious one. Our usb license dongle libs only work properly with the visual studio compiler. From what I've been able to tell mingw's stl implementation seems to thrash vs 2012's, somewhere in the collections/algorthms/iterators but didn't bother pinning that down. In other areas VS runs better. gcc on linux wins across the board, identical hardware. Add in network storage and linux pulls away by multiples (perhaps isilon and 10G dont work well with windows, but I notice it with any disk IO to varying degrees).
&gt; From what I've been able to tell mingw's stl implementation seems to thrash vs 2012's, somewhere in the collections/algorthms/iterators but didn't bother pinning that down. There's a major difference in `std::string` - GCC is still using Copy-On-Write which was permitted by C++03 but *forbidden* by C++11. VC uses the Small String Optimization which is permitted by both C++03 and C++11. COW results in strange interface guarantees and is hostile to multithreading, which is why it was banned, but it can look very fast in single-threaded profiling. At some point GCC will have to change to conform to C++11 - until then, I strongly recommend against using `std::string` in performance comparisons due to this variation. In release mode, VC's STL should be just as fast if not faster than GCC's, and I would like to see test cases where this is not true. (Note that in debug mode, VC's STL performs exhaustive correctness checks by default. Additionally note that VC used to perform security checks in release mode in 2005 and 2008 but this default was changed in 2010.) There are a couple of exceptions I am aware of: iostreams (notoriously problematic for performance) is sometimes slower for VC, VC's &lt;regex&gt; has difficulty with certain things like large `foo|bar|baz|quux` alternations that Boost.Regex handles very quickly (GCC still doesn't have a final release with &lt;regex&gt; - that's coming in 4.9), VC's deque is tuned for small blocks which we should probably change in the future, and VC's vector uses 1.5x growth which is more space-efficient but less time-efficient than GCC's 2x growth factor.
Try building this with PGO then LTCG, 2012 blows up - though to be honest it blew up on 2010 as well, haven't had a chance to give 2013 a go. https://code.google.com/p/math-parser-benchmark-project/ and yes I've reported it on connect. I know this is not a c++ specific thing and not necessarily your realm, but would you happen to know if there is any work being done on getting better link time performance with msvc? 
We removed all LTCG from our build process as one lib will force it up the chain and our build time went from &gt; 8 hours to &lt; 1 
Well, I saw the BizSpark suggestion, but what about joining the partner network? Contact your local MS office and ask them about the network and their action packs for partners. They are fantastic for small businesses. Edit: accidentally a word.
Did the hash table implementation get any better since VS2008? I had to roll my own closed hashing with linear probing because the one in the VS's libraries has absymal memory characteristics. I also tried declaring an allocator template with sync_per_thread option, and using it in some STL containers and all I got was a hard crash. (That was with VS2012).
Visual C++ is still the best experience, specially if the main audience is Windows customers. Intel and Portland compilers are mainly targeted for users wanting to extract every ms out of the hardware, but you only get the respective compilers and HPC libraries. So you still need to get the remaining SDKs from Microsoft. Embarcadero's C++ Builder is quite nice, but nowadays Embarcadero focus mainly in enterprise customers with the typical enterprise prices.
&gt; Did the hash table implementation get any better since VS2008? We've tweaked it a little, but we haven't rewritten it. &gt; I had to roll my own closed hashing with linear probing because the one in the VS's libraries has absymal memory characteristics. Note that the unordered associative containers must satisfy various iterator invalidation guarantees; this rules out a wide variety of implementations. &gt; I also tried declaring an allocator template with sync_per_thread option, and using it in some STL containers and all I got was a hard crash. (That was with VS2012). I need to see a self-contained repro for that.
 #include &lt;iostream&gt; #include &lt;math.h&gt; template &lt;int n&gt; void print_line() { std::cout &lt;&lt; n &lt;&lt; "\t" &lt;&lt; sqrt(n) &lt;&lt; "\t" &lt;&lt; pow(n,1./3) &lt;&lt; "\n"; } template &lt;int n&gt; struct S { static void f() { S&lt;n-1&gt;::f(); print_line&lt;n&gt;(); } }; template &lt;&gt; struct S&lt;1&gt; { static void f() { print_line&lt;1&gt;(); } }; int main() { S&lt;10&gt;::f(); } &gt; in advanced. No.
&gt; Note that the unordered associative containers must satisfy various iterator invalidation guarantees; this rules out a wide variety of implementations. Are you aware of other, well-tested and supported container libraries that chose different trade-offs than STL? EASTL? Something else? (boost excluded :))
The comments in that post on virtualdub's webpage give a pretty good range of possible answers to your question. Is there anything you feel is not addressed there or [in responses to your last post](http://www.reddit.com/r/programming/comments/lyv54/the_error_in_f_convolutecpp/) on that subject? I agree with the general sentiment regarding (static) analysis there and its potential to point out unclear code (at least when not knowing the full history). Using recent clang or cppcheck would have saved that project from being publicly shamed by you for marketing reasons.
First off, /r/learnprogramming is a better place to post questions like this. Second, this looks like a homework question, so don't expect too many helpful responses. Third, it's nice to show the code you already worked out, but at least include a short description of the errors you encounter. In this case, the problem (which is not even all that related to programming) is obvious, but the lazy way you went about asking for help won't motivate many people to actually help you.
&gt; So you still need to get the remaining SDKs from Microsoft. He already has VS 2010. 
On page 6, I don't believe it is discussing variable-length class members. This new type of array, in the example on page 6, contains normal objects (of fixed size, known at compile time). The number of elements in the array is assigned at run-time. And the array lives directly on the stack as a local variable inside a function. It cannot live beyond the function. This is what C's VLAs do. Bjarne is discussing a better interface, but the underlying concept is the same. (On page 8, there is a suggestion to allow this on the heap, or in static storage. But this array would still not be allowed inside another object such as a class or struct.) When you say "variable-length class members", do you mean something like the following, where one of the members in a class is variable-length, while other members exist? struct X { string s; // a normal member string more[]; // a variable-length member X ( ... ) {} // constructor that decides the length of `more[]` }; I don't think there is any suggestion of every doing anything like this. It is possible to use a trick from C programming to allocate such as object on the stack, where you `malloc` the appropriate size manually and so on. But making this work on the stack would be very difficult.
I have the feeling you are making this more complicated than needed just to prove some point. You could have easily incorporated `print_line` into `S` and avoided the duplicate calls to it. Your implementation obfuscates the algorithm you are using. Also, don't use C's `math.h`, but the C++ header `cmath`. Here's a (I think) much easier to follow implementation of your algorithm #include &lt;iostream&gt; #include &lt;cmath&gt; #include &lt;boost/mpl/bool.hpp&gt; template &lt;int n&gt; struct S { static void f() { S&lt;n&gt;::recurse(boost::mpl::bool_&lt;should_recurse&gt;()); const auto sqr = std::sqrt(n); const auto cbr = std::pow(n, 1./3); std::cout &lt;&lt; n &lt;&lt; "\t" &lt;&lt; sqr &lt;&lt; "\t" &lt;&lt; cbr &lt;&lt; std::endl; } static void recurse(boost::mpl::bool_&lt;true&gt;) { S&lt;n-1&gt;::f(); } static void recurse(boost::mpl::bool_&lt;false&gt;) { } static constexpr bool should_recurse = n&gt;1; }; int main() { S&lt;10&gt;::f(); } 
Yes, but not the new versions of the SDK and only part of them are available for free. The downloadable SDK does not contain the libraries considered enterprise stuff. It is all a matter of what he really needs, of course.
Look at it this way. Moving is an optimization of copying. (I'm ignoring move-only resources such as locks here.) If you return a `std::string` allocated on the stack from a function, the move constructor at the call site may be called. However, the "only" optimization you get is that anything allocated on the heap (the string contents) need not be copied. Everything else (the pointer to data, the length and capacity (both `std::size_t`) still have to be copied in the move constructor. However, if your type has no heap-allocated memory, there is no optimization to perform. To quote myself: &gt;The fundamental problem, though, is that stack-allocated memory cannot be moved. I should amend this. Stack memory being immovable is maybe not the most fundamental problem. The most fundamental problem is that dynamically stack-allocated arrays (ARBs) can, as far as I know, only be implemented with either serious compiler magic or by [breaking the type system is ways, which hugely limit the usefulness of ARBs](http://www.reddit.com/r/cpp/comments/1craw1/trip_report_iso_c_spring_2013_meeting_sutters_mill/c9j9sv9).
I can imagine wanting to create a *non-owning* Handle type with a design such that each piece of raw data can be 'held' by at most one Handle at a time. Therefore the Handle should be movable, but not copyable. In particular, the destructor in Handle is not responsible for `delete`ing the data (that's what I mean by *non-owning*). In this case, it's quite reasonable to arrange for the held data to be on the stack. This data is then moved from one Handle to another by Handle's move constructor. These handles can be passed to other functions and even returned from functions as long as the underlying data still is within its lifetime. This might be a weird design, but the only real risk of undefined behaviour is if somebody attempts to return a handle from the function that created the stack data. This is the same error as returning a pointer to any local object. This might be useful in some contexts. Perhaps it is a strange design in some ways, and maybe I wouldn't even recommend it! It's really little better than passing pointers around, except that only one Handle at a time can hold a particular piece of (stack) data.
interestingly enough the testing i did on linux showed speed degradations with -flto. Yes I do turn on /ltcg on windows it helps with the vs compiled executables.
Clang on windows is not at all stable or complete.
the performance sensitive code doesn't use std::string much atall, not in the core. I have some custom collections with custom iterators that does bit slicing. I noticed differences in use of those classes. Debuggers are not very useful for massively threaded code, these type applications must be runs and tested exclusively in release mode. I did just check and noted gcc is still using cow. Our use of strings is fairly limited in that I recently bought 2 new identical xeon boxes (20 cores/40 threads total) and notice better scaling on the linux side coming from an 8/16 system. Yes I have done some extensive rewriting of some core threading areas just for windows which helped it immensely but I'm certain the difference is in the allocators. Oh yeah turning off as much multimedia and eye candy crap helps as well. Under linux at least I have the luxury of compiling only one or two object files in debug mode and sometimes still retain the error/crash condition enough to actually perform analysis.
&gt; Embarcadero's C++ Builder is quite nice Have you ever used it for more than a toy project? It's the worst compiler and IDE I've ever used. It does not really support boost (comes with an old version that has especially been tailored to compile on Embarcadero, but with hundreds of warnings). It constantly crashes during debug sessions. There are bugs in the 2010 version that have been reported since 2003 and earlier and have not been fixed until today. It seems Embarcadero's focus is Delphi, and the C++ Builder is just some unloved heritage they have not yet managed to get rid of.
I understand why Dinkumware's version is "broken", but how does the Clang version fix this issue? If the hash function throws an exception, how does the library know what hash value to find and remove? Does it have to iterate over the entire collection looking for `value`? I suppose that satisfies the "never throws and always succeeds" requirement.
The last time I used it, it was before the whole Borland/Code Gear/Embarcadero story. I was a big fan of their Pascal and C++ tooling. I really enjoyed the RAD capabilities for GUI applications back in the day. However, like many, I stopped caring when Borland no longer knew where the company should be headed. Just mentioned C++ Builder, because the product still exists and even got a new version out this year.
&gt; don't understand why vendors MUST have the most expensive version That's what Microsoft keeps saying. &gt; or only use it for comparison with the free alternatives. I will bet you good money that most devs don't even know that there is a free version of Visual Studio, or whether or not it is licensed for commercial use. (Oh free VS? That's the one for students, right? - I hear that a lot too).
Projects using the GPL for a library are not unlikely to switch to AGPL at a later point in time. This has happened with iText. 
The function in question is: erase(const_iterator) The iterator gives you the reference to the (linked list) entry but doesn't tell you which bucket the entry maps to. You need the hash value to figure that out.
&gt; So, how does an iterator go from say bucket b1 to b2? The obvious solution of scanning the bucket array until the next non-empty bucket is found does not work, since the average time this operation takes grows as the bucket array is depleted and more buckets need to be walked through to reach the following element, whereas the standard requires that iterator increment be O(1) I don't see this. As the bucket array gets full (i.e. the load factor increases) finding the next non-empty bucket is actually faster, since they get closer together on average. The problem the linked 'Issues List' page talks about is that the total time taken to iterate over the hash table is proportional to the number of buckets, not the occupancy, which I believe makes iteration O(1) with respect to the load factor and O(n) with respect to the occupancy/size() and bucket_size()
As you correctly point out, *average* iteration time is O(1/F) ~ O(1), if averaging is considered for say full container traversal from begin to end. The problem does not happen there or when the table is being filled, but when it is depleted: as erase(iterator) returns an iterator to the element following the one being erased, this takes more time as non-empty buckets get sparser. You can even have quadratic behavior as explained in http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n2023.pdf
Is there a reasonable hashing function that could legitimately throw an exception when called for an existing (valid) element? 
&gt; since it's still a constant factor or O(1) from the perspective of an iterator. You lost me here. Big-O puts a boundary _around_ the function. If a function's time complexity is some function of its inputs, then its complexity is **not** O(1) by definition.
Hmm, thanks I'll give that a read. It wasn't immediately obvious from your link that it was erase() that was problematic. By 'depleted' I assumed you meant used up or filled.
Maybe not, but the standard allows a hash function to throw and a compliant implementation of unordered associative containers must honor this licence.
The load factor of the hash table doesn't change while you're iterating over the table. What I'm saying is then, if iteration is a constant factor of the load factor then all ++iterator ops are still O(1) with respect to the occupancy of the table.
Mostly I see people "helpfully" proposing different implementations that would be forbidden.
I thought about this myself, and then I remembered one of the properties required: - memory stable That is, if you have an `iterator it = mytable.begin();` and then play around: `mytable.insert(vec.begin(), vec.end());`, `it` is *still* pointing to the same element than before although: - it may no longer be the first element of the container - it may have moved from its original bucket (multiple times), and actually the former memory location of its bucket may have been freed Guaranteeing memory stability in the presence of rehashing thus constrains somewhat the design of the hash tables.
There is another advantage to keeping the hash around: you avoid paying the cost of hashing *again* when you re-allocate the buckets (to contend with growth).
&gt; I'm not sure if you're joking or if you're seriously in denial Neither. He didn't mean "LOL what bugs? I don't see any bugs?! har har!", he meant "which bugs are you referring to?".
Having the iterator store a pointer to the bucket array entry does not help. Suppose the iterator points to the last element of a bucket b1 and is incremented over to the first element of some other bucket b2: there is no way you can find out what b2 is only from knowing b1. erase(key_type) is allowed to throw, no problem with that function, it is erase(iterator) that poses the challenges.
Except if B is a constant fraction f of N: f*N/N = f = O(1).
I think the specification should be ignored or changed rather than hindering applications with (spatially) suboptimal structures until the next available ABI break. Especially considering the current implementations already violate the complexity requirements. The linear bucket scan, under reasonable load factors, seems like the textbook use-case. The current problems seem niche and lack usefulness. The pathological case depends on erasure in reverse hash order... something I can never imagine being useful since the whole point of an unordered_* container is that it's, well... unordered. I feel the same way about having a doubly-linked list. Why optimise for reverse-order iteration over something that is supposed to be unordered? So overall I think I favour the libstdc++-v3 implementation with the noexcept optimisation trait. I'll stick my neck out and say most of the time your hash function will be fast, and most of the time it won't throw. At least if you *don't* cache the hash value by default the user can run a profiler and determine that their hash function is being called a zillion times and then read their implementations docs... or even apply their own memoization. 
Off the top of my head normalization requires sorting of combining marks/characters, of which there can be any number after a non-combining character.
Projects using the GPL for a library are not unlikely to switch to LGPL at a later point in time. This has happened with Qt. (solid statistics FTW!)
One reason is that the "express" versions don't allow integration of other build tools. I use WiX for my installer on windows and I therefore have to use VS Professional to get the build process automated (and doing WiX builds by hand is painful). Sure I could find another installer package or set up a build script outside of VS for the installer. But that's time taken away from sound something productive, which just costs me money in other ways.
Sorry again, I did mean page 8. Perhaps I misunderstood some aspect of the paper, but I thought the purpose of the proposed array constructor feature was to allow "ARB data members of unspecified size" to be class members. Indeed, BS writes &gt;Array Constructors &gt; In a message to the –ext reflector, J. Daniel Garcia suggested a solution based on allocation of an array member **in the scope in which its class object is created** [emphasis mine]: &gt; What we need is: &gt; a) Allow an ARB data member of unspecified size. &gt; b) Allow to set the size of the ARB in construction. I took this to mean that if an instance of a class with an ARB member were to be allocated on the stack, then the ARB member would also be allocated on the stack, with its size specified by the array constructor of the class. Did I miss something? I do agree that this feature would be difficult to implement from a code generation point of view.
&gt;I can imagine wanting to create a non-owning Handle type with a design such that each piece of raw data can be 'held' by at most one Handle at a time. Why is that better than allowing multiple non-owning handles? Here is my idea: * ARBs as in N3497 (so no `sizeof`, not allowed as member variables, cannot take address etc) * ARBs (implicitly?) decay to a magic nonmovable, noncopyable wrapper struct, containing a pointer to the data and the length. That way, neither ARBs nor their wrappers can be returned from functions. The only way to use them is in the stack frame where they were allocated, or by passing references to the wrapper to callees. This guarantees no dangling wrappers ever exist.
You are correct. Plus if you did it piecemeal as *notlostyet* is suggesting, you'd probably have to implement it yourself. The `std::hash` I use is: template &lt;&gt; struct hash&lt;String&gt; { public: size_t operator () (String str) const { // Normalize string str.Normalize(NormalizationForm::NFC); // djb2 size_t retr=5381; for (auto cp : str.CodePoints()) { retr*=33; retr^=cp; } return retr; } }; Which seems a lot simpler and less error prone than implementing NFC/NFD yourself just to save yourself the heap allocation. Heap allocation will rarely throw, but it **can**, so it's a compelling reason to allow specializations of `std::hash` to throw.
I haven't tried the recent version, but according to the marketing, in XE2, it seems that they have completely given up on trying to develop a standards complient C++ compiler, and are now using clang/llvm.
That's awesome!, any progress in this area is a positive, I'll definitely have to read up on the new features in 2013. 
FWIW, I love that you're taking time out of your day to answer us, so thanks for that.
I admit your solution is better than mine. I'm ambivalent about the use of Boost though. On one hand, I'm sure it's useful. On the other hand, it's very big, and you end up (indirectly) including lots of headers, for a feature that you can implement yourself in two lines: #include &lt;iostream&gt; #include &lt;cmath&gt; template &lt;bool b&gt; struct bool_ {}; template &lt;&gt; struct bool_ &lt;false&gt; {}; template &lt;int n&gt; struct S { static void f() { S&lt;n&gt;::recurse(bool_&lt;should_recurse&gt;()); const auto sqr = std::sqrt(n); const auto cbr = std::pow(n, 1./3); std::cout &lt;&lt; n &lt;&lt; "\t" &lt;&lt; sqr &lt;&lt; "\t" &lt;&lt; cbr &lt;&lt; std::endl; } static void recurse(bool_&lt;true&gt;) { S&lt;n-1&gt;::f(); } static void recurse(bool_&lt;false&gt;) { } static constexpr bool should_recurse = n&gt;1; }; int main() { S&lt;10&gt;::f(); } 
That's pretty elegant. I had assumed it defined a type that inherited from the type passed as the template parameter. 
That is exactly why we need a professional license. Our application benefits greatly in certain areas from PGO.
We've had a look at the recent C++ builder, it seems like it's come a long way since C++ builder 6.0, but for the options we want, we'd have to mortgage our homes, it's extremely expensive. That said it is a viable option especially now that they're supposedly using clang for 64-bit targets - at the very least one could use normal Boost, rather than the codegear cut down version. 
I think you're right there, page 8 is relevant for that. It should have been obvious to me that you were discussing page 8, I obviously wasn't paying attention fully when I read that page myself! It's an interesting idea - maybe I shouldn't dismiss it so quickly. I'm no expert on this.
to deplete means to empty. I guess you were thinking of it in terms of free space being depleted.
Is there a good place or mailing list to keep up on progress on this front?
Those suggestions for ARB seem pretty reasonable. It's good to keep things pretty strict at first. It's easier to extend functionality later, instead of regretting making things too loose. It might be cool to allowed them as member variables someday, but it seems too complex. People who really want that sort of behaviour can do it manually and deal with the issues themselves. So, yes, introduce in a minimal form. The standards committee have lots of other things they should be working on instead :)
WiX has a plug in to configure and build within the VS interface. I'm sure that if I spent the time to figure out exactly how to build it by manual command line that I could then try to find a way to integrate this into an automatic build with the free tools, but the point is that would take me a lot of time and cost me more than just buying the upgrade to the Pro version of the compiler. 
Unfortunately the parent comment has been downvoted to oblivion at this point due to my careless errors so it's not really going to add anything to the discussion.
&gt; the C++ standard requires that erasure work unconditionally and never throw. Blunt as it sounds, it is my opinion that Dinkuware's implementation of C++ unordered associative containers is broken. I checked today, and I couldn't find such a nofail guarantee in N3797. Can you point me to the relevant Standardese?
I live to serve, and to make cat noises.
&gt;no `erase()`, `clear()`, `pop_back()` or `pop_front()` function throws an exception. §23.2.1.10 The standard carves out an exception for `erase(k)` (i.e. erase which takes a key `k`) for the unordered associative containers: &gt;For unordered associative containers, no `clear()` function throws an exception. `erase(k)` does not throw an exception unless that exception is thrown by the container’s `Hash` or `Pred` object (if any). §23.2.5.1.1 But does not seem to carve out an equivalent exception for `erase(q)` (i.e. erase which takes an iterator `q`). I'm looking at N3337 though.
Got it - I had skipped over the general container requirements. Note that you should distinguish paragraph numbers from sections, and providing section names helps to counteract Working Paper churn. For example, I would cite N3797 23.2.1 [container.requirements.general]/10 (there is no section 23.2.1.10). I actually think this is an oversight in the Standardese - I don't think we should be required to cache hashes.
&gt;Note that you should distinguish paragraph numbers from sections, and providing section names helps to counteract Working Paper churn. For example, I would cite N3797 23.2.1 [container.requirements.general]/10 (there is no section 23.2.1.10). Thanks, wasn't sure. &gt;I actually think this is an oversight in the Standardese - I don't think we should be required to cache hashes. I would argue that the oversight is requiring O(1) for iterator increment. I think that erasing an element -- given that you know its position -- with a no fail guarantee is much more important than possibly iterating over empty buckets as you traverse a container.
&gt; I actually think this is an oversight in the Standardese - I don't think we should be required to cache hashes. You are not required to do so.
&gt; I would argue that the oversight is requiring O(1) for iterator increment. I think that erasing an element -- given that you know its position -- with a no fail guarantee is much more important than possibly iterating over empty buckets as you traverse a container. Discussion of LWG issue #579 was lengthy and, to my taste, rather confusing: http://www.open-std.org/jtc1/sc22/wg21/docs/lwg-closed.html#579 At the end, what seemingly closed the point in 2010 was that *implementation experience was demonstrated that a non-void return type is implementable for both single-linked and double-linked lists without loss of efficiency* I wrote the blog entry partly to better understand the existing implementations and see how much water the quote above holds.
:-) Thanks for the comments anyway.
&gt; But does not seem to carve out an equivalent exception for erase(q) (i.e. erase which takes an iterator q). I'd be really excited to see an example of a real-world hash function that succeeds in hashing a key only once (during insertion).
Yes, and insertion sort is O(n) if the array is already sorted. Does that mean it's a linear-time sorting algorithm?
Hello, I am the author. Thanks for reading!
&gt; Such approach penalizes the performance by allowing for a rare case of simultaneous traversal and modification. That's not really the motivation - it's holding pointers to some elements while inserting/erasing others.
You're insisting on PGO but are willing to switch compilers based on reddit recommendations? I'm confused about what your priorities are...
Ah! I was not aware of this, thanks!
I recommend that you use books as learning material as opposed to online tutorials. As for book recommendations: C++ Primer 5th edition by Stanley Lippman is a good introduction. The C++ Programming Language 4th edition by Bjarne Stroustrup is an excellent reference once you've acquainted yourself with the language. http://en.cppreference.com/w/ is a good online reference as well. SFML and SDL are two popular and free multimedia libraries that can be used to make games.
The current way to do this is to use `alloca()` or your platform's similar function. The main problem is that the safety Stroustrup wants requires compiler support, but you can certainly get the performance benefit without language support.
sadly no im more of an artist trying to start with programming 
University. Start there. EDIT: Yeah, bring on the down votes. OP can write a hundred useless "hello world" programs all by himself. That'll show those recruiters how smart he is!
Okay thank you for the help. I will probably go to chapters later today! 
Honestly you shouldn't start with C++ then. Its an extremely powerful language, but it's by far the least forgiving language. I would start with Python as a complete beginner. Other suggestions could be D ( smaller community, not quite as easy to get help), Java (much more verbose than Python but some people swear by it), or Ruby. Personally I highly suggest Python as a beginner. 
If your ultimate goal is C++ (which arguably is the best language for game development on PC and other platforms) i recommend learning C first, atleast basics of it! C++ contains a lot of wierd stuff that will be really confusing when you don't know the background of C. Whichever path you take, feel free to PM me with any programming questions if you get too confused!
At some point you might want to take a look at the [Cinder](http://libcinder.org/about/) and [OpenFrameworks](http://www.openframeworks.cc/) projects. There have certainly been people who used them successfully without a substantial CS/programming background. You could also try [Processing](http://processingjs.org/), which is a lot simpler than C++, while still being a nice (and visual) introduction to programming. Finally, check out /r/learnprogramming.
If you want to make games I suggest you start with another language like C# and use Unity so you can get started faster.
No!!!!!!!!!!!!!!!!!!!!!!!! You learn too many habits that are bad C++ habits (but good C habits) when learning C. Yes, C++ allows most C code to work for interoperability and for allowing legacy code to compile. But please, please don't recommend people learn C before C++ if they want to learn C++.
Although I agree that C++ can be learnt without C, what's the issue about the bad habits? No one is saying that he should learn hardcore C and all the typical stuff with it, just basics to get started.
Isn't that true for any other language except for maybe D? 
I'd add accelerated c++ as well, once c++ primer finished. I am revisiting programming after 20 years, and even though a steep learning curve gets concepts through very quickly and thoroughly in my opinion.
Thanks! :)
And most of which can be done for free on the internet. Why pay for it when you can try it out for free? 
The proposed array constructors are about allocating variable-length arrays **that are class members** on the stack (read page 8 for more information). No C/C++ compiler currently supports this feature in any form. But the kinds of optimizations that this feature would allow are very interesting. Essentially any C++ container could be constructed using automatic storage duration (say, using a stack allocator called `std::auto_allocator`). This would be similar to what Boost.Intrusive does, but with added safety and a uniform interface for both stack and heap allocation. There are several existing options if all you would like to do is allocate a local variable on the stack. Using the VLA extension (if your compiler supports it) is usually preferable to invoking `alloca`. But the use cases for this feature are essentially limited to auxiliary buffers used by various algorithms.
It would help if you could be a little more specific about what you are trying to do. In particular: - What kind of games are you thinking about developing? - Which platforms are you looking to target? (E.g. iOS, OS X, Android, Windows 8.) As others here have already stated, C++ is a very powerful language but also has a world of hidden complexity that you slowly (think in terms of years) begin to unravel as you start to learn it. Many people will claim that you can learn a small subset of the language that suits your needs. But invariably, some features of the language will depend on others, and you will ultimately end up having to memorize a large corpus of random facts, arcana, and edge cases and exceptions to understand how to do a seemingly simple task "the right way". "The right way" is also very likely to change with each major revision of the language (every 6 years). Personally, I cannot recommend C++ in good faith to someone who is just beginning to learn programming. Many C++ gurus share this sentiment (Alexandrescu, Milewski). You are much more likely to have a pleasant development experience if you use a programming language with a nice toolset available for the platform that you are trying to target. For example, if you would like to target iOS or OS X, Apple has fantastic tutorials and documentation to help you with every step of the process. Developing UIs using XCode is also a very pleasant experience.
&gt; From personal experience, devs who learned high level languages first tend to be afraid of lower level languages, or have misconceptions for how they work. As a undergrad computer science student, i sadly see that happening quite a bit. But overall, that's some solid advice. Thanks for the youtube links, I'll sure be watching those.
Expanding on fuzz's answer, as another professional C++ gamedev/programmer. C++ is a bad choice for complete beginners because it's such a broad language with a lot of surface area, weird legacy things, non-obvious pitfalls, and other such madness to trap an unsuspecting person. This is because C++ is a very old language with no real planning or vision in its formative years and several competing implementations. And C++ came from C (of course) which has very low overhead, and one of the main design goals of C++ is to achieve as low overhead as possible. As a result, in order to reconcile C++ and make it useful, but also keep it speedy, there are a number of constructed which result in "undefined behavior" and other constructs which lead to "unspecified behavior." Unspecified behavior means that the compiler gets to choose what happens, but what happens has to be specified by the compiler (as opposed to by the language committee). Whereas undefined behavior means that anything at all can happen. The compiler could order pizza for you, or delete all of your files, or work exactly as you intend (save for a subtle security hole that's exploitable remotely and winds up causing your clients thousands of dollars in damage). Even worse, what is unspecified behavior and undefined behavior change from version to version. C++ has three official releases, one upcoming release, a few technical reports, and several competing older versions. C++ builds off of C and also relies on the C standard, which also has several official versions. Because of how long the internet has been around and C++ programming has been around, you have different versions being taught by various tutorials, and there's no telling if you're learning C-style C++, C++83, C++98, C++03, C++tr1, C++11, C++14, or some weird hybrid that the tutorial author likes, and unless you know about the different standards, you'll learn one way of doing things, and never about other ways. You might learn printf and then read some stream code and be completely confused. Moreover, when you learn C++ you're learning 4 different languages. You're learning, not just C and not just C++, with their various warts and versions and craziness, you're also learning the C preprocessor and template metaprogramming. [Both](http://stackoverflow.com/questions/3136686/is-the-c99-preprocessor-turing-complete) of [which](http://matt.might.net/articles/c++-template-meta-programming-with-lambda-calculus/) are also [turing complete programming languages](https://en.wikipedia.org/wiki/Turing_complete). That being said, I think C++ is a wonderful language. It's powerful and expressive. Newer versions have enough stuff built into the language to make programming very fast, almost akin to python or other scripting languages. It has lots of language constructs to make managing code and reducing bit rot easier. If you go out of your way when writing code, it can be very safe and difficult to use your code incorrectly. It has very powerful compilers, which historically have printed out very complicated error messages, but are getting much much better about it. But because of the various pitfalls, which I didn't even really touch on in my post (such as object slicing, memory leaks, the inability of helpful tools to handle valid C++ code because of the extensive parsing steps required, out of bounds array access/dereferencing end() iterators, bools and ints being essentially the same thing, most vexing parse, array pointer duality, comma operator, and way more) I would recommend starting with something a little less encumbered and dangerous until you understand programming in a general sense. Have you considered python?
Yup, academic types love them some high level languages. People at the place I work (who have been devs for years) shudder when they say 'native code'. It makes no sense. Oh well. 
I like the idea of learning C first. C is a much smaller language and beginners can get a lot of mileage from learning C before moving on to C++. A course meant for C programmers (beginners not advanced) graduating to C++ might be helpful. Here is one on coursera: https://class.coursera.org/cplusplus4c-002/class
I disagree with the necessity of books, although I'm only a few months ahead of you in terms of C++ knowledge. There's a ton of decent tutorials out there, to at least get your head in the game. Look up the C++ libtcod tutorial, it's a comprehensive tutorial that at least covers how to build a program.
Exactly how minimal do you want? You can just use the GNU compiler and a text editor if that's your preference. 
Emacs
My [MinGW distro](http://nuwen.net/mingw.html) contains Boost, SDL, and a bunch of other libraries. I use this to build my game-engine-in-progress - here's an [old screenshot](http://nuwen.net/img/news2010/stw20100503lg.png). My distro has no installer (I hate installers), no IDE (they get in my way), no debugger (I occasionally use a debugger at work but never at home - it's better to avoid writing bugs in the first place), and no build system other than GNU make. (I really need to write a post about how my Makefile with perfect dependency generation works someday - the information is out there on the Interwebs but it is hard to find.) It does come with source control (yay git), but I assume that you already have a text editor you like (I use Metapad).
It was resolved as fixed in 2010, so something must have gotten dropped on the floor somewhere. It's possible that the fix wasn't merged to the correct branch (I've seen that happen), or that something else broke it, or that it was intentionally reverted because it caused problems elsewhere, or who knows. I'll let the compiler team do the archaeology.
Why don't you want C++ itself? It comes with headaches (many, but not all, dramatically reduced by modern techniques), but it also comes with several great strengths: robust toolchains on whatever platforms you want, compatibility with C++ libraries, and (even more importantly and even less appreciated) compatibility with C libraries.
C++ can be very DRY, especially C++0x11. Add in a reflection library and its just as easy to use as anything else, plus youre close to the metal. 
I would check out the [D language](http://dlang.org/). It sets out to achieve all of the goals you describe here, while also simplifying the syntax. One thing that D does that it sounds like you'll enjoy is that you get manual memory management (with new and delete), but the language is also garbage collected. This gives you the performance of doing your own management, but with a backup just in case you forget to delete something.
&gt;code duplication You're doing C++ wrong.
Can it support RAII? Thats the big issue with most GC language that I dislike. I can build very elegant mechanisms to manage all sorts of resources with it, but GC usually throws that out the window with non-deterministic destruction. 
I recently was going through a very similar thought process and eventually decided to give D a try. It is like C++ with a fresh start. Free of backwards compatability for the sake of backwards compatability. It has many features you'd expect coming from C++ and then some. I always felt that C++ just seemed kinda of not quite put together right, but D feels cohesive. I was initially trying to decide between Rust and D, but I settled on D. Rust just seemed weird to me. But check out both. Maybe one will fit your needs. 
[Rust](http://www.rust-lang.org/) is what you want, but it's not production-ready yet. There's D and Nimrod as well, although I've used neither of them. Writing in C++11 is almost like a new language.
&gt; One thing that D does that it sounds like you'll enjoy is that you get manual memory management (with new and delete), but the language is also garbage collected. Two awful tastes that taste awful together. I use *automatic* memory management - no new/delete and no GC.
Modern C++?
Exactly! *slaps forehead* So that's how the pros do it!
gvim
Windows Phone does, and both iOS and Android support it - it's just not the primary language for the device.
Try out C++11 first. I think it fixes most everything. Further down the road, I would look into Rust as a possible alternative. 
Why do you need runtime reflection? I've never found it particularly useful. Let alone necessary.
Thanks! 
seconded, with a couple of scripts and a good understanding of how to use. 
Check out the One C++ presentation from Going Native 2013 where Herb Sutter talks about a library called Cinder. I have browsed through the documentation and it is not a bad place to start.
Learn Java and JavaScript instead. * Java for Android Dev. Download eclipse for Java developers and install the android stuff for it. Eclipse makes it super easy for beginners to start pseudo-programming on Android. * JavaScript + HTML/CSS is a lot different than C++/Java programming but will make it easy to make 2-d games on the HTML5 canvas without worrying about cross-platform support. 
With all the discouragement I see here, I need to step forward and say: Go for it! We all agree that C++ is hard, too flexible and not the first choice when you think of a language for game developing. But you don't need to understand all the different features of the language and the details of the implementations to get a working program. It may not be an optimal one, but sure it will work and you can always continue learning. Check out [Cinder](http://libcinder.org/) and [openFrameworks](http://www.openframeworks.cc/) two open-source C++ libraries for creative coding. [Planetary](http://planetary.bloom.io/) is an app for iPad written entirely in C++ using Cinder. The lead developer is a self taught amateur developer with a major in sculpture! I think we need to stop scaring people that wants to go for C++. Not everyone is programming concurrent applications in embedded software, and there are a lot of applications of C++ that we sure never thought about. Credit where credit's due: Go watch Herb Sutter's talk [One C++](http://channel9.msdn.com/Events/GoingNative/2013/Keynote-Herb-Sutter-One-Cpp) in Going Native 2013 (the interesting part is around the middle of the talk). The next day he has the results of the final experiment in the middle of his next talk: [My Favorite C++ 10-Liner](http://channel9.msdn.com/Events/GoingNative/2013/My-Favorite-Cpp-10-Liner)
Thanks for the update. If you could let them know to update the connect that would be great, as it claims it has been fixed, but there's no mention, what has been fixed, which version and what the fix is, unless of course it is assumed that the proposed "work around" is the fix, if that's the case, I'd be happy to open another connect.
Forgive my ignorance, but what is DI? 
There's a *tonne* of decent tutorials out there; but not *one* of them has material at the level of quality you're going to find in * *C++ Primer (5th)*, not to be confused with the rather more shitty *C++ Primer Plus* * Scott's *Effective* series * *Accelerated C++* * Lots of praise for Herb's *Exceptional C++* series, great material but I personally find the presentation style terribly distracting Tutorials are mostly going to teach you an antiquated version of C++, or worse, the idea of a Java-like type hierarchy, or worse still, C-with-classes. I won't pretend that there isn't a single good tutorial out there but the signal to noise ratio is very, very high. I imagine it's especially bad for C and C++ for being such old and powerful languages.
Dependency Injection. Basically configurable interface implementations. Say for example you have a game that uses DirectX or OpenGL or NullGraphics. If you have an interface like IGraphics that has various methods DX or GL implement and you pass them into your objects, youve done DI. Its one of those, everyone was doing it, but it recently got a name type of things. There's fancy ways to use config files to bind things automagically and what have you in various languages. 
I concur. C++ is currently supported on most mobile platforms to enable software houses using their legacy code. I would start with Java and maybe [this library](http://libgdx.badlogicgames.com/).
You *should* know (something) about all those bad practices (especially `[const] char*`) but that's not the same as starting there. Pedagogically speaking, learning C is a terrible way to start learning modern C++, and you should learn modern C++ before you learn outdated C++. C++ may be compatible with C but by now the two are very different languages.
&gt; It does come with source control (yay git), but I assume that you already have a text editor you like ... I too like to use `dd` to directly manipulate git objects. `/me` scratches head wondering if STL is just trolling or if I prefer him talking about C++ instead of his toolchain.
You have [an X/Y problem](http://meta.stackoverflow.com/questions/66377/what-is-the-xy-problem). Consequently, this thread is full of advice ranging, in my opinion, from terrible to excellent. These threads usually go like this. The most important thing you have to do is decide what you *want* to do. If you want to learn C++ so that maybe you can have a future in game development, great, go for it. Read other posts for pointers. If it's game development you want to do, and have heard that "C++ is the industry standard for game development," take a step back. The rest of my post assumes this is the case. I'm not a game developer, I'm just pulling shit out of my arse. C++ may or may not be the industry standard (I legitimately do not know, though I imagine it is). If you want a future in game development, certainly *knowing* C++ is going to look good on your CV. But for the feeling of "I did that," C++ just isn't a very good language to start with. Even C++11, which is awesome, will have you jumping through hoops. My first course in Uni, *Introduction to Programming*, didn't have all that much to do with programming. We made spiders chase ants in [Greenfoot](http://www.greenfoot.org/door). The point wasn't really to teach programming but to get students hooked on the idea of programming. I agree with the people that say the best way to achieve this is to show progress rapidly: change a line of code, see something happening immediately (not in the sense of LightTable or w/e that editor is called). It's not so much for you to understand what that one line does as much as it's to show that *you can do this*. It's constant feedback and that serves as motivation. Disclaimer: I'm sure there are people for whom this doesn't work; I'm not an authority on the matter but I think they're a minority. You definitely can do this with C++. There are libraries linked elsewhere here that help with it: SFML, SDL2, Cinder, etc. But you can still do it faster and easier with other languages, which is why they tend to be recommended. In particular, the C++ standard library is very powerful but, compared to many other alternatives, sorely lacking for the purpose of producing graphics (and producing graphics with a library is easier than making a "real" text-only game without a library) -- so then you need to learn linking, too, and maybe the difference between static and dynamic linking, and that's just not important if what you want is to prove to yourself that you can make a game. If what you want to do is learn C++, learn C++! If what you want to do is make games, still learn C++ -- but maybe start with something else first, to affirm that you *actually* want to make games. And finally some concrete advice: start with a [Pong](http://en.wikipedia.org/wiki/Pong) or [Breakout](http://en.wikipedia.org/wiki/Breakout_%28video_game%29) clone or something similar. That'll teach you some important things about (keyboard) input; the game loop; game state; physics; and, of course, graphics. And good luck. PS: Please don't start a relevant degree in university because you think you want a career in game development before you've had a chance to try it out. You'll be wasting time, and in most of the world money, if you burn out in the first six months. By all means, go for it if you get a taste for programming -- or don't, because you can definitely make games for your own amusement without a degree. University will teach you a lot of things but don't expect it to teach you game development (especially not the Computer Science degree, which isn't really about programming at all).
I was going to suggest exactly the same. It is beyond me why your answer (which is exactly the right one as he has no programming background) is being down-voted on r/cpp. Some ppl here should really move to r/java and stop trolling.
C++14.
&gt;I really need to write a post about how my Makefile with perfect dependency generation works someday - the information is out there on the Interwebs but it is hard to find. Please do! I have a sort-of dependency-generating Makefile I use for small projects but it could be better.
&gt; This has changed in C++11. ... &gt; I’ll refer you to [that talk](http://cppnow.org/session/allocators-in-c11/) because it brings you up to date on what is in C++11 and what is being proposed for future standards [...] 
&gt; Look up the C++ libtcod tutorial, it's a comprehensive tutorial that at least covers how to build a program. I assume you're referring to [this](http://doryen.eptalys.net/libtcod/tutorials/libtcod-cpp-tutorial-1/). There are so many errors in the text that it's not even funny. I can find something wrong or misleading in practically every paragraph. For example: &gt; in fact, it’s what is called a precompiler Wrong! It's called the preprocessor. The concept of a precompiled header is a different and unrelated topic. &gt; .hpp files are called “headers” and contain declarations. Incomplete. They can contain many things beyond declarations. &gt; They’re supposed to be included in .cpp files that contains implementation. Extremely misleading and confusing. The header is normally included both by the user of the class and the implementation of the class. But there can be exceptions. &gt; libtcod.hpp contains the declaration of all the functions and classes inside libtcod. Wrong! It includes the *definitions* of classes. That may sound like a nitpick, but declarations and definitions are different things in C++ and you really have to know the difference, because there is a big ugly concept called the One Definition Rule that is a source of much misery and pain. &gt; This is the main function, the first function that will be called when the program starts. The function returns an int and has no parameters. It’s a Unix convention to return an int to indicate whether the program ran successfully (return 0) or not (return another value). For a video game, it does not make much sense and you could make it return no value by replacing “int” by “void”, but some compilers issue warnings if the main function does not return an int. Extremely bad advice. &gt; Here we’re calling the initRoot function to create the game window. [...] initRoot is a static method. Well, is it a function or a method? This is the typical laxity of terminology that plagues most online tutorials. The correct answer is that it's a *static member function*. C++ does not have methods. &gt; It’s pretty much the same as a simple C function like the main() function except that it’s inside the TCODConsole namespace, hence the TCODConsole:: prefix. Wrong! `TCODConsole` is not a namespace, but a class. Namespaces are something else, but they are also used with the double semicolon, and that can be a significant source of confusion. By being sloppy in its terminology this tutorial lays the groundwork for that confusion. &gt; Now this is a bit more complicated. We want to call the printCenter function to write some text. This is not a static function. That means that it requires a TCODConsole object to be called on. TCODConsole::root is a static field in the TCODConsole class. It’s a global variable inside the TCODConsole namespace. It represents a pointer to the root console. Technically, it’s the adress in the process memory of the root console object. Its value is only defined after we call initRoot. We use the -&gt; operator to access a field or a method from a pointer. There are so many things wrong here that I just don't know where to begin. C++ does not have "fields" or "methods", those are terms from Java. Again, terminology matters. And it exhibits the same class/namespace conflation. Moreover, this is supposed to be a beginner's tutorial, and none of these concepts (class, instance, function, pointer) are explained in any kind of logical way. They are just thrown out there as "here is what we're doing" without any kind of pedagogy. ===== This tutorial is completely terrible. All online C++ tutorials are completely terrible. Teaching C++ properly is extremely difficult, and most people are not up to the task. Being a beginner, you are by definition not able to discern when a tutorial is botching the explanation of a concept, extolling myths or half-truths, or advocating poor practices. That is why we recommend books and we recommend that you stay the hell away from online tutorials. 
Wait, really? That's all it is? I've been putting off learning dependency injection for months now but, hey if that's all it is then I've been using it for years already. Thanks for letting me know.
If you need runtime reflection it's a sign that you either are writing a complex library or doing something wrong.
c++0x11 is c++17 in decimal :)
Love the screenshot..
Either Emacs or Vim with GCC and unix. I use Emacs on windows and compile with vc++ (what my company uses) from within Emacs. Coupled with Cygwin (for unix commands) that's all I need, really. (Although I do debug in Visual Studio...)
Is this a blog post where some guy tries to brag about knowing Alex Stepanov? What exactly is he claiming is out of date if the problems are corrected by a standard that is *two years old*... Also I don't know about those claims, does heap allocation always require a lock? Which heap implementation? What about something like tcmalloc? Since when did people assume all memory access was equally expensive? Memory hierarchies have existed far longer than multicore machines..
I gave Rust a go a few weeks ago. My only gripes were that it's obviously still in development, and that the template/trait system does a poor job of writing traits that apply to both managed and owned pointers. This means that moving data around between those two types is a chore, which makes it hard to do some tasks optimally. I'm in agreement that D2 looks *very* cohesive. 
You probably have been - many of us have, by using dll files, so files, xml configuration files, etc. Basically the Java camp wrapped a buzzword around replacing this: import MyORMWrapper; MyORMWrapper.GetImplementation().DoSomething(); With this: @Inject ORMWrapperImplementation implementation; implementation.DoSomething(); The distinction is that with the latter, there's some code that runs ahead of your program that resolves the @Inject annotations via reflection, and loads the requested implementation based on some external config. Edit: I'll add that I've only ever seen this pattern in JEE stuff, like JBoss, where you basically have an entire Java *operating system* running your servlet(s). There, it's basically used for service registration, for things like persistence and logging. If you've been using a language that's closer to the metal, and understand how to write, package, and maintain dynamic libraries, you don't need any of this.
Well... dependency injection is very much how he defined it, it's just that there are very heavy and complicated Dependency Injection frameworks that try to automate things through configuration. Those frameworks happen to be what Java/.NET people think of when someone says DI. "Uncle Bob" Martin has a pretty well worded article on the topic: https://sites.google.com/site/unclebobconsultingllc/blogs-by-robert-martin/dependency-injection-inversion
In this vein, the "Programming -- Principles and Practice Using C++" by Bjarne Strostrup is specifically intended to teach C++ to programming newbies. I'd recommend it highly. It teaches modern C++ without needing to learn C first. I strongly recommend avoiding learning C first - you'll just learn bad habits for C++.
I've detected a hexadecimal color code in your comment. Please allow me to provide visual representation. [#482753](http://color.re/482753.png) *** [^^Learn ^^more ^^about ^^me](http://color.re) ^^| ^^Don't ^^want ^^me ^^replying ^^on ^^your ^^comments ^^again? ^^Respond ^^to ^^this ^^comment ^^with: ^^'colorcodebot ^^leave ^^me ^^alone' 
Does your distribution have std::thread yet? I tried it a while ago and it didn't seem to and I needed it for my application. Other than that though, it's great and I wanted to thank you for taking the time to publish it :) 
Started looking into D the other day, and while I really love most of the concepts in the actual language, it doesn't seem super mature when it comes to compilers, toolsets etc. "Unfortunately" C++ is a bit hard to beat there.
I agree with you there. I would point out that there are three separate compilers (one of which uses LLVM) so there is some compiler support. But other things may seem lacking. Maybe I'm being a bit foolish but I really like the language so I plan on using it. I think that most of the problems with the language aren't the language, so it is relatively easy for things to get better (easier than if the language itself were the problem). Also, D seems to be picking up steam lately. Not sure if it is my imagination or what but we will see what comes of if. Personally I want it to "replace" C++, or at the very least beat Rust. edit: One more thing I just thought of. Any concerns people may have of third party library support, D can us C libraries and all that needs done is a rewrite or the header file(s). 
You can build and run from vim, thats all you really need.
Does the code autocompletion work for `std::unique_ptr`?
Oh I totally agree and I can very well see myself doing stuff using D. For the thing I was investigating it for at the moment performance is really important though, and it seems like the LLVM and GCC based compilers beat DMD in performance quite a lot, and these two compilers are not easily available for Windows (which is my main development platform). Edit: NOT easily
&gt; Foundation process of any kind of programming language always dealt with eliminating bad practices from its predecessors Absolutely. But that doesn't mean you should learn one language before you learn another when your real goal is to learn the latter. Why learn to flip burgers when someone's real goal is to become a financial manager? You can learn a lot of communication and interpersonal skills when flipping burgers, but I would not recommend anyone go flip burgers first before taking classes to learn financial management. &gt; The pick of a language for starters might be subject to another debate, that's for sure but once the decision is C++, I can't think of a better start other than C. C++ seems like a better start to me. ;-)
And Qt 5.2 beta.
Why not C++?
Yes, you can program C++ on Android &amp; iOS, but in general you won't get nearly the platform support that you will for Java/Dalvik and Objective C under iOS. I'm not a fan of Java, but it's where Android programming is at. NDK is generally not recommended for use except under specific circumstances. From the NDK Page: &gt; In general, you should only use the NDK if it is essential to your app—never because you simply prefer to program in C/C++.
Thank you. I will keep this code. I have solved the errors in my codes.
&gt; this has been fixed in 2013 Yay! &gt; That said, now that I have it installed, I've discovered a possible regression in std::string between 2010 and 2013 By the way, please avoid filing Connect bugs as Private unless they truly contain information that you don't want the world to see. I have reduced this to: C:\Temp\vs2013_stdstring_BUG&gt;type meow.cpp #include &lt;string&gt; using namespace std; struct build_string { operator string() const; operator const char *() const; }; int main() { build_string b; string s(b); } C:\Temp\vs2013_stdstring_BUG&gt;cl /EHsc /nologo /W4 /MTd /c meow.cpp meow.cpp meow.cpp(11) : error C2668: 'std::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt;&gt;::basic_string' : ambiguous call to overloaded function E:\binaries\x86ret\inc\xstring(945): could be 'std::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt;&gt;::basic_string(std::initializer_list&lt;_Elem&gt;,const std::allocator&lt;char&gt; &amp;)' with [ _Elem=char ] E:\binaries\x86ret\inc\xstring(881): or 'std::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt;&gt;::basic_string(std::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt;&gt; &amp;&amp;) throw()' E:\binaries\x86ret\inc\xstring(774): or 'std::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt;&gt;::basic_string(const _Elem *)' with [ _Elem=char ] E:\binaries\x86ret\inc\xstring(738): or 'std::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt;&gt;::basic_string(const std::allocator&lt;char&gt; &amp;)' E:\binaries\x86ret\inc\xstring(715): or 'std::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt;&gt;::basic_string(const std::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt;&gt; &amp;)' while trying to match the argument list '(build_string)' This compiles with 2010, but not 2012 and 2013, like you said. The code appears to be incorrect (the conversion is ambiguous as far as I can tell) and I'm not actually sure why 2010 accepted it. I'll have to analyze it further. &gt; The following was first reported in vc7.1, reported again in 2008 and 2010 and is still broken in vs2013 That was intentionally resolved by the compiler team as "Copied to Backlog". They may fix it in the future, but it isn't a top priority.
GCC hasn't implemented std::thread natively on Windows yet. Some people try to get it to work by adding third-party libraries that wrap the Windows API in a POSIX interface, but I haven't tried to do that. I recommend using Boost.Thread instead, which has nearly the same interface and works very well on Windows.
Right... boost... I could do that. Thank you for the reply :)
You are missing the point of what I was saying. I never said University was a bad idea. I went to a University for a CS degree.The nice thing was is that I got some exposure to programming before I spent money on it. I knew I would like it. It's why I used the word try in both my comments.
What's wrong with using `std::transform` directly?
Do you _really_ need reflection for: &gt; Save/load Huh? &gt; networking Huh?? People have done a LOT of networking on C and C++ without any need for reflection! &gt; automated logging. Huh??? I mean, let's take the last one. I use [glog](https://code.google.com/p/google-glog/) for that, which tells me exactly which file and line the message came from, and gives me all sorts of redirection options - and it's light and simple. Methinks you like reflection too much...
Use D. It's the tits.
My C++11 solution: for(auto&amp; p:m) v.push_back(p.second);
Honestly the above poster failed to mention that you can also do RAII with D.
While we are going through listing awesome books: *Effective C++* and *Effective STL* by Scott Meyers are amazing books.
When I said 'the current way to do this' I only meant getting stack allocated memory, not dynamic stack allocated members. When you said that the prospect of dynamic stack allocated members was interesting I sort of assumed you were interested in performance benefits; but stack allocated members aren't necessary if one is purely interested in performance. It's clear now that what interests you is exactly the safety reasons I alluded to, which, as I said, do require language support. Specifically one cannot abstract `alloca()` away into a collection type that hides the details of handling the memory and ensuring type safety. So, yes, stack allocated members are interesting, not because they enable better performance than one can get on non-abstract code using `alloca()`, but, as it's now clear you were saying, because they allow one to use abstractions (like collection classes with stack allocators) to enable safety and readable code while keeping the performance of `alloca()`.
One thing that always bugged me about allocators: pointer allocate( size_type n, std::allocator&lt;void&gt;::const_pointer hint = 0 ); is that I require storage for *at least* N instances, and the allocator *may* allocate more... but I have no way of knowing so. If you think about `std::vector` this is pretty damning: - I ask for 3 elements - The allocator has a bucket for 2 and a bucket for 5, it serves me the bucket for 5 - I push a 4th element: *reallocation!* I vie for having `allocate` be: std::pair&lt;pointer,size_type&gt; allocate(size_type n, ...); where the result `.second` member is **guaranteed** to be superior to `n`.
`auto const&amp;` ;)
Agreed. If `std::get` where a function with templated `operator()` instead of a function template, the code would be beautiful: std::transform(m.begin(), m.end(), back_inserter(v), std::get&lt;1&gt;()); It's even better than with a polymorphic lambda, which would be std::transform(m.begin(), m.end(), back_inserter(v), [](const auto&amp; x){ return x.second; }); Go [here](https://github.com/alnr/cpp/blob/master/alnr_functional.hpp) for implementation of the former (slightly different to be compatible to SGI's STL).
honestly sometimes i just feel like people who complain about c++'s aspects that make people consider it "hard to code in" are being babies
If you're using boost anyway, how about just `boost::push_back(v, m | boost::adaptor::map_values)`.
&gt;most Probably `ed` over emacs or vim. Either that or [C-x M-c M-butterfly](http://xkcd.com/378/)
&gt;superior to n Would you be fine with .second &gt;= n? Or are you requiring .second &gt; n?
… which, incidentally, is the title of a slideshow by the author that OP mentioned (full disclosure: it’s me): [Modern C++](http://klmr.me/slides/modern-cpp) [[PDF](http://klmr.me/slides/modern-cpp.pdf)]
Yeah I think that's one of the pages I used for reference, my main issue has been creating folders for two different sets of object files (release and debug) and still relying as much as possible on the automatic recipes.
Dev-C++ is horribly outdated and really shouldn't be used. There are many alteratives for *nix systems as well, so "biting the bullet" really isn't necessary.
vim + make is pretty damn close to what you are after. you just type make as a cmd in vim and away it goes.
Nope. Edit: I should clarify my comment. The verbosity of the "hello world" example is mind boggling. I don't *want* to write code for my build system but if I have to, it should be in a language I'm mostly already familiar with and which makes the temporary productivity hit while learning the API worth it. I don't believe using Scala accomplishes these goals. That's one reason I'm starting to learn towards CMake: it's such a terrible language but the rules are so simple even a moron (me) could get it.
What is it you're solving? This post deals with the problem of working with STL algorithms that operate on iterators, and trying to convert an iterator for an std::pair&lt;K, V&gt; into an iterator for V. Obviously if you don't need an iterator for V you can just access the value using v.second, but that has nothing to do with this post.
Agreed (somewhat), I've updated the msconnect, as there seems to be some differences between: T a(b); T a = b; That said this seems to be a really old issue: https://groups.google.com/d/topic/comp.lang.c++.moderated/zfitALoIHTQ/ discussion I'm going to make the fix in my code by removing the char* cast. 
MinGW-w64 has it and it works perfectly fine.
I'd go with most people here saying C++11 + best practices + patterns + idioms + modern design. However, if you are willing to leave C-land, then have a look at Haskell. Haskell 1) avoids code duplication and is very abstract and high level 2) Compiles to native code and has been proven to be as efficient (fast) as C 3) Compiles significantly faster than C++ Haskell is not for everyone though. Functional programming is something that requires serious mind bending to get started with, and a lot of idioms/patterns/constructs use terms from theoretic mathematics. Debugging using gdb is also not available (or hardly doable, due to generated code), yet it's seldom necessary, because you can reason quite well about the code itself.
I like using [geany](http://www.geany.org/) which is super lightweight, but has every I need in a text editor, with nice default C++ syntax highlighting, and good customisable options. Also you can set it up with a compiler at the bottom making it an IDE. I prefer to compile in a separate terminal window though.
When using QtCreator 2.x I find that autocompletion for C++11 standard library classes doesn't work unless I add stuff like this to the project.config file: #define __GXX_EXPERIMENTAL_CXX0X__ #define _GLIBCXX_VISIBILITY(...) #define _GLIBCXX_BEGIN_NAMESPACE_VERSION #define _GLIBCXX_END_NAMESPACE_VERSION Is there a better way to fix this?
Null pointers are funny; you can make them with all sorts of constructs. `1 - 1` is a null pointer constant as is `int()`. The last is especially silly. Have you tried making liberal use of `{}` in integer code? The following code sample is ill-formed according to the standard and can help you catch unintended conversions: extern unsigned x; int main() { int y = 10; y *= {x}; } 
&gt; Signed integer overflow is still UB. I guess this is a valid point, but what would expect the behavior to be? Throwing an exception? I'd rather take an extra minute to ensure that I have a correct data type than have to wrap every increment/decrement in a try/catch block. &gt; Implicit integer promotion crap is still here, leading to bogosities like -1 &gt; sizeof(int). There's no denying that C and C++ have lots of ass-biting minutiae, but this particular case is blatently warned about by GCC. If the developer chooses to ignore it then he's made his own shitty bed of buggy code. &gt; the first thing I do on size() is to cast it to signed type This made me cringe. &gt; invalid values (size &lt; 0) If a container is in an invalid state (which I would argue should more or less never be allowed to happen, but IF IT DID), then throw an exception. You can't have minus 3 apples in a box of apples. Containers are about abstraction, and negative sizes is snapping that abstraction's neck to jam error handling down its gullet. Unless you're talking about pure C code, in which case carry on. &gt; bool is still an arithmetic type No it's not (standards lawyers feel free to eviscerate me where I stand). It is implicitly castable from int and int can be implicitly cast to bool, but that doesn't necessarily mean that `bool b = 3+5;` sets b equal to 8. &gt; I've just learned to ignore it That's a poor attitude to have. C++ is a very much a jungle laden with punji pits, but driving a tank over and through everything isn't the best way to traverse it.
Sounds good. How about you helping out these people: http://www.csse.monash.edu.au/~damian/papers/HTML/ModestProposal.html :-)
Both good points, thanks. Will change as soon as I find the time.
&gt; what would expect the behavior to be? It can remain UB, but I'd expect the language to provide a checked cast [throwing an exception when out of range], or a library for performing safe arithmetic. Preferably both. &gt; I'd rather take an extra minute to ensure that I have a correct data type than have to wrap every increment/decrement in a try/catch block. There *is no* correct data type if you're already doing arithmetic on the widest supported integer type. &gt; This made me cringe. Why? Unsigned type is a bad, brain-damaged, leaky, stupid, moronic, etc. "abstraction" for a quantity that cannot be negative. If you need that guarantee, wrap it into a class. You know that you're using the correct data type. I *know with certainty* that casting size_t to the corresponding signed type cannot possibly overflow. (E.g., due to the size of the items in the container and address space limitations of the OS the program is running on.) &gt; If a container is in an invalid state 1. size() could check for invalid state [and throw exception] before returning a negative result. 2. I wasn't talking about internal state of containers. I was talking about external interfaces like .size(), and all functions/methods taking/returning unsigned parameters to denote quantities. By using an unsigned type, they have no way whatsoever of determining whether the passed value is meaningful. (Unsigned arithmetic silently wraps around where signed arithmetic would give a negative number.) &gt; No it's not I may be using "arithmetic type" a bit lax here, but to me it's any type that you can add to one another. &gt; driving a tank over and through everything I (we) tailor it to the form that suits us perfectly; that's what the language is designed for. Unsigned -&gt; signed casts are littering the code here &amp; there, but so be it. 
&gt; D improves this awful situation only a little: Bah. Only Java (no unsigned) and C# (no implicit conversions, signed integers for sizes) have learned from the mistakes of C and C++.
I'm using only #define __cplusplus 201103L for libstdc++ 4.8 headers with QtC 2.8.1 and it can find std::unique_ptr&lt;&gt; and std::tuple&lt;&gt; without problems. Further completion of their members is a different story though.
Since it isn't mentioned before: How about [Go](http://golang.org)? Take a look at golang.org and follow the [Go Tour](http://tour.golang.org). When you have finished the Tour you get a pretty good idea of what Go is. 
if anyone likes this you'll definitely like [this](http://www.reddit.com/r/cpp/comments/1nhulu/python_itertools_and_builtin_iteration_functions/) 
&gt; Why don't you want C++ itself? I guess for the same reasons that people out there prefer to use and work on D and Rust. 
mostly agreed. i would be tempted to go with something like jam but using lua for the scripting part. having to haul around a jvm to comppoile c/c++ isn't very appealing, especially considering I purge anything java off my systems. cmake gets ugly when you start trying to override libraries or have same named source files under different subdirs, etc.
one project i'm impressed by was the TCC compiler. A nominal implementation of a fully working 'c' compiler with not much code. Any new language that is done right shouldn't hinder someone from writing a sufficient compiler. No it won't be as simple as TCC is but should be possible. Yes, yes I understand that a fully optimizing compiler will always require substantially more man effort. Some of D's poor choices come from piling crap into the language itself instead of delegating them to libraries. Very similar to how the algol family ultimately choked itself. I was interested in D initially until I started digging and saw things that just felt wrong.
specs looks reasonable.. these proposals should work fine for me. How c++11 features like rvalue refs and lambdas fit in would be interesting.
That works on the particular problem example I gave, but not in the general case. I've changed the blog post to better reflect what the title says: How to iterate over the values of a std::map. The f now declared naturally arises when one wants to create something akin to subsets: given a set of objects S, create all possible tuples of size n (there are |S|^n such tuples). 
I'm not a huge fan of premake as-is, but it seems like a good base to build off of if you want to do something lua-based.
I don't know, you may be right. I'm not excited about or interested in using Go for anything. 
&gt;&gt; bool is still an arithmetic type &gt; No it's not According to this table, it is: http://www.cplusplus.com/reference/type_traits/is_arithmetic/
How does it compare to using the BLAS on big matrixes? Edit: I mean million x million matrix when I write big matrix.
Since it doesn't use SIMD, it's probably about half as fast as BLAS in double precision on computers with 128-bit vector instructions...
If everyone would think like that there would be no libraries in first place.
His first claim is totally bogus. I tried it and, guess what, not only is the performance exactly the same, the generated assembly code is identical. At least if you use a good compiler. Dont compare it with BLAS, that wouldn't be funny anymore. 100x maybe? There are so many other opportunities that come into play when optimizing matrix multiplication. And this guy went from a nicely readable version to a total mess. For 20% improvement. He hasn't even scratched on the endless possibilites of optimizing Matrix-Matrix, and he just gets 20%. There is a lot of low hanging fruit that easily gives you 100%. This is an undergrad exercise, and they do a much better job at it. Edit: He gives perfomance Values. For the 2000x2000 case, it takes him ~100s: 2000 * 2000 * 2000* 2 Flops/cell / 100s = 160 MFlops. Of the 20 GFlops this machine should have(single core), he managed to get 8% peak performance. The ATLAS library does this task in 0.7s, a typical under grad student assignment yields 1s - 10s.
What if i told you that using algortihms that multiply matrices by blocks will give much better performance through exploiting memory locality and caches? and on a side note: seriously? was it compiled with -O0? 
&gt; The appropriate solution, as illustrated in Figure 1, is: &gt; * declare the double pointer of the type T**, What? No, it isn’t! The author claims that this is how “professional mathematical packages, such as Matlab” implement them and it may well be in the case of Matlab – [although it seems far from obvious](http://www.cyclismo.org/tutorial/matlab/matrix.html) – but it definitely *isn’t* how other professional packages do it, and also not how you *should* do it normally. Why? Because the double pointer incurs an additional, costly indirection and makes the matrix memory non-contiguous. If you can afford it, you should instead allocate the memory in *one* block – i.e. as `T*` (or, rather more appropriate, `std::vector&lt;T&gt;`) and map the matrix on a one-dimensional array. And for reference, that’s how e.g. R does it (a `matrix` is just a view on a `vector`). But the author claims that the double-pointer alternative would be *faster* because “[i]t does not need to perform any index multiplication” – but that’s completely misleading because he just ignores the added cost of another dereferencing. He also claims that it’s more convenient to write `A[i][j]` than writing `A[i+N*j]`. Has the author not heard of operator overloading? And to make this relevant for his algorithm, of course you can use *the same* trick of the auxiliary table when using the single-pointer `T*` representation as with his `T**` representation. (And as others have remarked, his benchmark is pretty dodgy, there are reasons to believe that he compiled with optimisations disabled, which renders his benchmarks meaningless because modern compilers *rely* on these optimisations.)
hmmm... so it is not only me who questioned this `T**` :) this is not good for cpu cache so I would not expect it in real, advanced Math applications.
I'd say there's quite a large section between "hobby" and "enterprise", and for at least some parts of that section VS Express works excellently.
 This article is a very simplistic and incorrect view of the issues regarding matrix multiplication (and memory access). The author seems to think address calculations are expensive, where the real point is spatial locality and cache mis/hit ratios. In Matrix multiplication, it is sometimes useful to first transpose the matrix (easy to do with SSE instructions!). The result allows sequential iteration of both matrices, improving cache performance. Another approach is to use 'tiling/blocking' which can improve locality and minimize cache misses. SSE instructions are designed for vector/matrix operations, ignoring them will never result in maximum performance. 
Exactly, without mentioning BLAS and a comparison to MKL this is actually embarrassing. We won't even go into using using T** as a matrix.
Actually the article is dumb, but there are reasons you might not explicitly use SIMD, that would be if it's cross-arch and not worth you time. Yes, SIMD code vs non-SIMD code yields significant performance improvement. But that is not a realistic comparison; a better comparison is compiler generated SIMD vs hand written S MIMD and for something dense matmul then the performance improvement you'll get isn't actually all that great. Compilers like ICC are REALLY good at generating SIMD.
1 mil by mil doubles? do you have that much memory?
Not to mention any decent BLAS is parallel.
after the core i7 was released i did some testing with row pointers compared with a single buffer. I don't recll the details but i never found a case where any row pointer version was faster. I tried a single buffer, single buffer with row pointers into the buffer and row buffers. A single buffer is most cache friendly, arithmetic for offset computation is faster than memory lookups. The most interesting thing i noted with i7 vs c2q was that column based iteration on the i7 was only ~5% slower or so. the c2q's penalty was much higher.
I compared the T** variant to the clasical [y*width+x] variant for a Possion/Jacobi solver. I really like writing A[y][x], but that variant is 5 times slower...
Yeah, that is almost a Terabyte for on matrix. Which is not unrealistic for a cluster. Edit: Corrected Terra-&gt;Tera, because of SI-Nazi roommate
From the Readme: "You are encouraged to take it from here and change and expand it as you see fit and publish your variant." cheers, Martin
I don't think the author intended it to be comparable with highly optimized codes. Some numbers on my machine, |n|classicO0|classicO3|fastO0|fastO3|OpenBLAS| |- |- |- |- |- |-| |100 |0.014586 |0.002046 |0.009788 |0.002906 |0.000354| |300 |0.370757 |0.148677 |0.252415 |0.148935 |0.005798| |500 |2.22469 |1.16144 |1.28427 |1.07886 |0.028919| |700 |6.96112 |3.62383 |3.62847 |3.08064 |0.080542| |1000 |20.6349 |10.4203 |10.6621 |9.22739 |0.191289| [(quick and dirty)](http://codetidy.com/7059/) ^the ^ifdefs ^got ^a ^little ^out ^of ^hand
&gt; the ifdefs got a little out of hand
Good point! Is it meaningful to say that any attempt to `move` a `std :: array` should be implemented by an element-by-element `move` from the 'old' array to the 'new' one? Can this be implemented more generally with containers? If the contained type is big enough, then it might make make sense. Maybe it's already done? (Update: Already been done. It is possible. http://stackoverflow.com/a/14370753/146041 . But it's not as efficient as moving a `vector` )
On size_t being unsigned: this is bad, and I'll show you why: template&lt;class Container1 , class Container2&gt; int sizeDifference( Container1 c1 , Container2 c2 ) { return abs( c1.size() - c2.size() ); } This looks innocuous enough, right? But: c1.size() - c2.size() calls size_t size_t::operator-(size_t) (*). If c2.size() &gt; c1.size() then this underflows, and returns max(size_t) + c1.size() - c2.size(). What you actually want is the (less obvious): return ( c1.size() &lt; c2.size() ? c2.size()-c1.size() : c1.size()-c2.size() ); * Note to pedants: I know that function doesn't actually exist, but this does the equivalent of calling that function. Thank you for playing.
I am fine with `&gt;= n`, since I needed at least `n`.
As I said there's no denying that C++ (and in this particular case, the STL) has its pitfalls, but this is a rather specific use case which I would argue should not dictate the overall designation of `size_t` or what `size()` returns. And in what context would you need to know the exact difference between the size of two containers? You could alternatively: * know they are not the same (`c1.size() != c2.size()`) * know which one is bigger and resize the other accordingly (`c2.size() &gt; c1.size() ? c1.resize(c2.size()) : c2.resize(c1.size())`) * use iterators instead. Maybe more burdensome but saves you guesswork: `return abs(std::distance(c1.begin(), c1.end()) - std::distance(c2.begin(), c2.end()));`
Well, you don't actually need to store the values to be able to get an average from them. All you really need to do is store how many values you have entered and the sum of those values. You could have something like this(not tested, but seems okay): #include &lt;iostream&gt; int main() { int valCount =0, valSum = 0, temp = 0; std::cout &lt;&lt; "Please enter any number of integers. Entering a value of zero(0) will stop capturing further values." &lt;&lt; std::endl; while (std::cin &gt;&gt; temp) { // Terminates loop if zero is captured from the input stream if (temp == 0) break; valSum += temp; ++valCount; } // If the valCount is zero we will divide by zero, which will cause a fun error. // Note that the result will be an integer, and hence truncate the result of the division. // For more accuracy static_cast it to a float or something. if (valCount &gt; 0) std::cout &lt;&lt; "The average of the entered values is: " &lt;&lt; (valSum / valCount) &lt;&lt; std::endl; else std::cout &lt;&lt; "No values were captured, so no average could be calculated." &lt;&lt; std::endl; return 0; } Please let me know if you have further questions.
I would take this approach if you don't need to remember the values. If you require the values later you can do something like: int main() { std::list&lt;int&gt; l; // Generate some numbers, you can replace you're while loop here. for(int i = 0; i &lt; 10; ++i) { l.push_back(i); } std::cout &lt;&lt; "Mean :" &lt;&lt; std::accumulate(std::begin(l), std::end(l), 0) / l.size() &lt;&lt; std::endl; }
What if you try to average {2,5,3,0,0,1}?
The loop would terminate upon entering zero, so you would get the average of 2, 5, and 3.
Alright. Thank you. I've removed it.
That's what operator overloading is for :P Though, personally I prefer "mtx.get(x,y)" or at least "mtx(x,y)"
Vim + Clang + [YouCompleteMe](https://github.com/Valloric/YouCompleteMe) + GNU tools. Combines the power of a modern IDE with a proper text editor. In particular, YouCompleteMe is the first proper syntax-aware auto-completion for C++ which compiles the code in the background to give up-to-date hints, yet still manages to be lightning fast. And I suggest Clang because it’s the first feature-complete (including the standard library) C++11 implementation, and has got the best (= most readable) error reporting at the moment.
Other bad habits I've seen: not using RAII enough, preferring error codes, not considering exception safety, not using strong types, and actively subverting the type system and type safety.
Interesting, his fast variant is actually faster. But the difference is small for optimized code.
But then don't forget to have the definition in your header or to use flto. The function calls eacht time would kill performance. A builtin 2D array type like in Fortran would be nice.
&gt; cmake gets ugly when you start trying to override libraries or have same named source files under different subdirs, etc. I agree cmake is ugly at times, but what do you mean with this statement. We use many same named files and have no issues.
Transform iterators are nice. Fundamentally, however, I argue that the interface of `f` is wrong. Instead of template &lt;typename Iter&gt; void f(Iter curr, Iter end); it should be template &lt;typename T, typename Ret&gt; Ret f(T&amp;&amp; t); or template &lt;typename T&gt; void f(T&amp; t); That is, `f` should be operating on a single value at a time. Even better would be a functor class with templated `operator()`.
Doesn't even matter. T** is incompatible with LAPACK and BLAS (and all the derivatives and libraries that build upon them) making them effective useless in any sort of serious LA application. You can get the [m][n] notation using ADT like every sensible C++ LA wrapper does like NT2, uBlas or eigen, it's not at all difficult.
Jam it in the header and it'll be effectively (although not guaranteeably) anyway. To add to that all good matrix ADT are templates specialising on precision (float, double, single complex, double complex....) so that happens anyway.
&gt; __forceinline Useless if your compiler doesn't support it. Although simply declaring it in the header + high opt level is pretty damn effective. &gt; std::array&lt; std::array&lt;float, 4&gt;, 4&gt; Matrix4 This can get very mess very fast, think about having to deal multiplying sub matrices with different dimension together. Too much template noise. It's better to have an abstract matrix type is a run time bounded size. 
Where was the just want c++ itself when Microsoft extended the syntax ???
Sure, but a cluster is not a shared memory machine, the code listed in this example is NEVER going to work on a cluster nor is it ever going to be in one machines memory at any one time. More likely, the data is on disk and is spread out to the nodes via MPI and then collated back in at the end storing it back to disk. That is more like scheduling code and is a different challenge altogether. The task shown in this article is a real on and good money goes into "solving" it (see ATLAS, MKL, ACML...) but the techniques in this article are woeful at best.
I said it elsewhere, actually a decent compiler like ICC will do a pretty good job of generating SIMD code for dense linear algebra; hand written will be better but not by as much as you'd think.
Runtime size = runtime cost. Writing size-templated matrix multiplication isn't really that hard (I've done it). Of course, the point of this post is efficiency. The most efficient thing you can do is write for the specific size you're using, which in 99% of cases is 4x4. And it turns out, using SIMD you can do that really elegantly and efficiently! That's what XNA Math does, and it's also what the last math library I wrote did. Doesn't get much faster ;)
&gt; Doesn't get much faster Perhaps (perhaps not) for silly small cases like 4*4. But any larger and integer arithmatic is quickly negated by any Flops. Note that Fortran is still heavily used in Scientific computing because it's straight line speed is better(or at least as good) and it doesn't need to rely on any templates at all. You are also missing a vital optimisation; there is nothing to suggest that your array&lt;...&gt; is going to be properly aligned, and by that I don't mean aligned to what the compiler deems fit, but aligned to a cache line. Allocating at run time using something like intel IPP malloc (IPP = Intel Perf' Primatives) ensures that your data will be correctly setup so that you can do aligned SIMD vector loads which unlocks more perf'. At the end of day, I actually think people should out source their math code to decent libraries like Intels MKL or ATLAS; there are plenty of high level wrappers too like NT2. 
That won't work, because f needs to traverse each possible slot to be assigned recursively. More specifically, f needs to do: if (curr == end) { // one more tuple produced } else { for (int i = 1; i &lt;= 3; ++i) { *curr = i; f(std::next(curr),end); // move on to next slot } You can of course process one element at a time, but you still need a function to traverse all the elements, and assign all possible values {1,2,3}. Once one full assignment has been completed (for example, [3,1,2]), it is printed on screen for simplicity here, and then backtracking must be used to generate all remaining possible tuples. Assuming you use recursion, how do you do it elegantly? The algorithm is not allowed to assume anything about the container. It could be a vector, or a map, or any home brewed exotic container-like structure (say, a Trie). At your disposal, you do have iterators however. I find your argument somewhat strange, as all STL algorithms are based on the idea of iterating containers by using iterators, so as to detach them from the particulars of a container. To therefore want to write one's own STL like function (for something the STL can't do, as it is an exponential time algorithm), and to use it with values of std::map, seems consistent with this line of thought.
There are minor differences between boost and stl, which are things forgotten in the standard (and probably added in c++14) or backwards compatibility to older versions of boost or features the stl committee didn't like. Just doing a sed -e s,boost,std,g will come up with quite a lot of errors. Sadly.
Thanks for taking the time to delve into the implementation of those data-structures. It's amazing to see such algorithmic improvements to "well-known" data-structures.
This series of posts has been excellent and has made me feel a lot better about using Boost.MultiIndex as my go to container for anything more complex than a vector. Especially so after seeing that you've basically put the same introduction in the source code, and that none of this complexity has lead to to any apparent degradation in quality or readability: https://svn.boost.org/svn/boost/trunk/boost/multi_index/detail/hash_index_node.hpp
It definitely looks extremely cool with terse templates and so on. The following code will be a template: void do_something(CopyConstructable argument){ use(argument); } The following will also be nice: Mergable{It1, It2, Out} Out merge(It1 first1, It1 first2, It2 second1, It2 second2, Out output) {...} Concerning that example: In the paper itself is a typo in it (Page 12), but the paper also claims that it is known to be incorrect. Should I write a mail to Sutton?
Yeah you're right. I forgot...
Of course it won't. Just wanted to say that 1 million^2 matrix size is undoable for a consumer systems, but wouldn't be impossible for a small cluster. Efficient distributed memory Matrix-Matrix multiplication needs a lot more work. Never thought about it, but you'd probably need a lot more total memory than necessary to hold your matrices. Are there a lot of applications that do multiplication of big matrices?
I am rather thinking about matrices to represent larger grids, something that is bigger than 1024^2 and known only at runtime. So no size templates. In the end, for the usual numerics stuff on regular grids I do what jasonthe said, and hide the index calcuation in a an operator/function.
The core idea of this is good(predicates and template constraints), but the syntax is a really bad idea. They really should take a step back and see what they are doing and simplify it. Heres how you define and use traits in C++11(which is similar to C++03 without the `decltype` operator): template&lt;class... T&gt; struct holder { typedef void type; }; template&lt;class T, class Enable = void&gt; struct is_readable : std::false_type {}; template&lt;class T&gt; struct is_readable&lt;T, typename holder &lt; decltype(*std::declval&lt;T&gt;()) &gt;::type&gt; : std::true_type {}; template&lt;class T&gt; typename enable_if&lt;is_readable&lt;T&gt;&gt;::type print_value(T x) { std::cout &lt;&lt; *x &lt;&lt; std::endl; } Although this works, its not the best. Its really just a hack built on SFINAE. The biggest problem with this approach is complete lack of meaningful compiler diagnostics. If you call `print_value` with something that is not readable, the compiler will just say `error: no matching function for call to 'print_value'`, which is not very useful. What we really need is native support for defining traits and `enable_if`. So this proposal solves this by creating the following syntax for defining and using traits: template&lt;typename T&gt; concept bool Readable() { return requires (T i) { typename Value_type&lt;T&gt;; {*i} -&gt; const Value_type&lt;T&gt;&amp;; }; } template&lt;class T&gt; requires Readable&lt;T&gt;() print_value(T x) { std::cout &lt;&lt; *x &lt;&lt; std::endl; } Although this is cleaner, it completely abandons C++s way of constraining templates. We now have two ways to define type traits. It even proposes `Same_types()`, which partially duplicates the functionality of `is_same` trait(the only real difference being that `is_same` is currently not varidiac). This just makes even more confusing for beginners. Plus, not every type trait will be rewritten to 'concepts'. So, in real code, you will most likely see something like this: template&lt;class T&gt; requires is_iterator&lt;T&gt;::value &amp;&amp; Readable&lt;T&gt;() print_value(T x) { std::cout &lt;&lt; *x &lt;&lt; std::endl; } Which really is just awful. Furthermore, the syntax is noisy too. Why is there a `bool` and a `return`? It looks like a function but acts like a type trait(I understand that type traits are metafunctions, but a beginner doesn't need to see that to start using them). It would be better to have some syntax like this(just a rough idea): template&lt;typename T&gt; trait is_readable requires (T i) { typename value_type&lt;T&gt;; {*i} -&gt; const value_type&lt;T&gt;&amp;; }; template&lt;class T&gt; requires is_readable&lt;T&gt; print_value(T x) { std::cout &lt;&lt; *x &lt;&lt; std::endl; } This is the direction this proposal should go. The syntax is much simpler, cleaner, and builds on top of the current C++ way of doing things. 
C++ always had multiple ways of achieving the same thing, where one was old and the other new and fancy. The fact that one of these to alternatives requires ugly hacks that rely on things that nobody ever designed to do this makes it pretty clear which one will be used from now on. Also: template&lt;class T&gt; requires is_iterator&lt;T&gt;::value &amp;&amp; Readable&lt;T&gt;() print_value(T x) can also be written as template&lt;class T&gt; requires is_iterator&lt;T&gt;() &amp;&amp; Readable&lt;T&gt;() print_value(T x) since true_type has a constexpr-constructor and and constexpr conversion to bool. (It is always surprising how few people know this.)
&gt; C++ always had multiple ways of achieving the same thing, where one was old and the other new and fancy. The fact that one of these to alternatives requires ugly hacks that rely on things that nobody ever designed to do this makes it pretty clear which one will be used from now on. Yes, of course, the `requires` clauses is the new fancy tool to replace the old SFINAE hacks. And should be used wherever possible. However, I don't see how 'concepts'(as in the proposal) is better than the type traits we already have. In fact, not all the type traits can be expressed as 'concepts'(like `is_bind_expression&lt;T&gt;`) since 'concepts' are functions and not classes. So we will always have two ways of defining type traits, but the new way has no advantages over(and is even inferior to) the older way. 
The new way has two advantages: 1. It is faster than the old one (not that important) 2. The error-messages get better by orders of magnitude: Where you got pages of errors, concepts will produce something like “T does not meet the concept CopyConstructable”, which is a HUGE improvement
This still relies on the information provided in the concept name - 'CopyConstructable' may look for an 'insert' method. More realistically, what if you had 'Insertable', as a concept, but T's insert method has a different signature? As a developer relatively unfamiliar with concepts, what I would want to see is: "type T does not implement `bool insert(const T::value_type &amp;);`". Of course, this would have to allow T if it implemented `int insert(...)` as well, and propagate concept errors appropriately, if a type without concepts relies on types with concepts, but those checks fail. Also, results could still get messy/ambiguous if you had multiple templates with different concepts, all of which failed. For example, if your templated function had 2 variations, one which used `push_back`, another which used `insert`, you would wind up with 2 concept errors. If there are 10 variations, you get 10 errors, with each maybe failing on multiple concepts.
As an aside (the paper is a bit challenging to read) - is it possible to say 'T must be a type that can be passed into `draw()`'? So if I have: `int draw(Square _square){...}` `bool draw(Line _line){...}` `string draw(Circle _circle){...}` and call it via `template &lt;typename T&gt; void my_draw(T _obj) { bool res = draw(_obj); } ` is it possible to describe this with the current proposal? "Type T must be passable to a function `draw` that returns a result that is or can be converted to a bool". So `my_draw(square)` and `my_draw(line)` would work, `my_draw(circle)` would fail (on the concept, not the attempt to convert string -&gt; bool), and `my_draw(triangle)` would fail. I wonder if the syntax to describe this wouldn't get overly verbose if you had the exact same scenario for multiple functions inside `my_draw()`
 &gt; It is faster than the old one (not that important) I don't think instantiating a function is any faster than instantiating a class. &gt; The error-messages get better by orders of magnitude: Where you got pages of errors, You don't get pages of errors when you use `enable_if`, I don't know what you are talking about. &gt; concepts will produce something like “T does not meet the concept CopyConstructable”, which is a HUGE improvement The compiler messages are improved, whereas now the compiler says `candidate template ignored: disabled by 'enable_if'`. Using `requires` it can say something like `T does not fulfill is_default_constructible&lt;T&gt;`. However this advantage has nothing to do with type traits. I dont think I made myself clear. I was asking what advantages do we have defining traits(also called 'concepts' in this proposal) as functions rather than classes? I don't see any advantages and I see a lot of disadvantages. One, being not able to do specializations, which do happen with type traits. So what advantage do I have defining my type trait like this: template&lt;typename T&gt; concept bool Readable() { return requires (T i) { typename Value_type&lt;T&gt;; {*i} -&gt; const Value_type&lt;T&gt;&amp;; }; } Over this: template&lt;typename T&gt; struct is_readable : std::integral_constant&lt;bool, requires (T i) { typename Value_type&lt;T&gt;; {*i} -&gt; const Value_type&lt;T&gt;&amp;; }&gt; {}; If the proposal wasn't trying to reinvent a different version of type traits, it could propose syntax like this perhaps: template&lt;typename T&gt; concept is_readable requires (T i) { typename Value_type&lt;T&gt;; {*i} -&gt; const Value_type&lt;T&gt;&amp;; }; Also, what is the advantage of using these function-based type traits over the class-based ones? This proposes adding a bunch of duplicating type traits to the standard. What is the advantage of using this: template&lt;class T&gt; requires DefaultConstructible&lt;T&gt;() struct foo; over this: template&lt;class T&gt; requires is_default_constructible&lt;T&gt;() struct foo; They really need to take a step back, and reevaluate this proposal. They are making this more complicated than it needs to be. We are already have 'concepts'(as they are called in the proposal) and template constraints in C++, we should being improving their usage by taking advantage of the native support of the `requires` clause, instead of duplicating the 'concepts' we already have, with some new way of defining them which has no real world usage.
Yes. If you look at the example in Section 3.1.2.2, paragraph 3, they do something similar there: template&lt;typename I&gt; concept bool Iterator() { ... } template&lt;typename T&gt; concept bool Range() { return requires(T x) { {begin(x)} -&gt; Iterator; // Iterator } } 
&gt; I don't think instantiating a function is any faster than instantiating a class. I haven't tried it myself. However: Stroustrup said very clearly that concepts is running faster than workarounds (aka enable_if). &gt; One, being not able to do specializations, which do happen with type traits This may sound blunt, but it is just plain wrong. With constraints we can have specializations way easier: advance(ForwardIterator&amp; it, int n) { for(int i=0; i != n; ++i) ++it; } advance(RandomAcessIterator&amp; it, int n) { it += n; } This will automatically pick the right template for every existing iterator. Even better: We can add specializations without having to touch them: advance(BidirectionalIterator&amp; it, int n) { if ( i &gt;= 0 ) { for(int i=0; i != n; ++i) ++it; } else { for(int i=0; i != n; --i) --it; } } Once we add this, every bidirectional iterator will from now on pick this overload.
&gt; I haven't tried it myself. However: Stroustrup said very clearly that concepts is running faster than workarounds (aka enable_if). Yes, of course, using `requires` is going to be faster than using SFINAE, but I don't think putting the trait in a function or class will make a difference in compile time. &gt; With constraints we can have specializations way easier: Thats not the specialization I'm referring to. Im referring to specializing the trait. This is for traits that are explicitly declared by the user, like `is_bind_expression&lt;T&gt;` for example. So how would we define the `is_bind_expression&lt;T&gt;` trait using the function-based traits? We can't without doing some ugly adl hacks, since we can't specialize a function. If this proposal used class based type traits to define 'concepts' this wouldn't be a problem. C++ right now uses class based type traits for 'concepts', and I have yet to see any advantage of switching to function based type traits. All we are doing is bloating the language with no real benefit. 
&gt; Are there a lot of applications that do multiplication of big matrices? Matmul (or GEMM more correctly) is the most fundemental building block of linear algebra. It's not that you'd multiply to matrices together, it's that you'd perhaps do a factorisation, followed by a solve. These thing are generally written in terms of GEMMs because GEMMs (in a chicken &amp; egg manner) are optimised to a T. That sort of LA are the building blocks of many large computer models like financial or weather modelling or computation fluid dynamics.
Now I see what you mean. Nevertheless I do not think that this will be a problem, since it is be possible to define concepts in terms of type traits. (See the last example on page 5)
Well theres no need for a wrapper(like in the example), you can use the class-based type trait directly in the requires clause. And since we use `is_bind_expression&lt;T&gt;` as a class based type trait, and we have already a bunch of type traits already from our projects and from the standard library, we should should just define everything using class based type traits, for simplicity and consistency sake. I see no advantage to using the `concept` keyword in this proposal at all.
go lang
dont know why you are being downvoted, is the cpp community anti-go or something?
I don't really think of that as HTML5, but anyway I would say that's a too new technology to complain about the Going Native conference not using it for their streaming videos. It's not universal and it was only recently implemented by Chrome. Besides, WebRTC is meant more for P2P communication I thought. Using it for web video streaming seems like a hack.
Happy Gopher here ;)
Ok, I only thought about the solvers for simulation codes. On the other hand, the really big matrices in simulation are almost always sparse and often implicit.
Am I the only one find this `Boolean_metaprogram` to just be ugly ? I just do not understand the sudden need to mix underscores and some form of capitalization. The Standard Library has always been using lower-case and underscores, and many people use camelCase or PascalCase, why yet another convention ?
Because the new stuff are template-constraints and it has always been convention to name the template-arguments with uppercase letters. I feel confirmed in naming all my classes in snake_case.
Because Go is in no way a modern C++. It's not even in the same continent, let alone ballpark.
I think you're right. I didn't want to have to come back and change a lot of code due to a design mistake. If I change the "by value" to "by reference" later, can I just recompile? Or do I need to modify every call to that member in the rest of the code base? You mentioned organizational problems, where did you see that I had org problems?
&gt; Am I the only one find this Boolean_metaprogram to just be ugly ? I totally agree, it is very ugly. &gt; The Standard Library has always been using lower-case and underscores And for boolean metafunctions c++ generally follows the convention of `is_*` or `has_*` using snake case.
If you create a vector&lt;&gt; within a function and return it, that should automatically be moved and not copied in c++11. You can use return std::move() to be sure I think. Taking a step back though, thinking of how to organize your program or make it perform is really not as important as you think before you get something working. Get your program actually working, then re-organize it for a cleaner structure and better performance. Working program &gt;= everything else. You won't box yourself into a corner, because until you build your program you don't really know how it will all play out. Trust me, make it work, then refine it from there.
That has been posted many times on many reddits, and it's just FUD against C++ devs in the end. It's not that Go contradicts our world view, it's not that we're stubborn and hateful fellows or anything - it's just Go is not even close to C++'s domain. It's a fine language in it's own right, and it's great as something like a Python replacement, but anyone who thinks that Go could ever replace C++ is, quite frankly, a moron.
The implementation of std::Unordered_map has gotten much slower after 4.6.3. I've read the bugzilla posts but it seems like they've given up on making it as fast as it use to be. IIRC, they made it so that the average performance with different key types is faster at the cost of slower speeds for other types. Anyway, if the license for tbb isn't too restrictive then tbb::concurrent_unordered_map is probably the best off the shelf implementation bar none.
&gt; If you create a vector&lt;&gt; within a function and return it, that should automatically be moved and not copied in c++11. You can use return std::move() to be sure I think. No, you shouldn't ever `move` in the return just *to be sure*. That way you are enforcing that the move constructor will be called, while otherwise your compiler might just use [NRVO](https://en.wikipedia.org/wiki/NRVO) to avoid extra copies.
It's been a long time coming. Glad to see it's finally coming out.
I have just built it myself with Visual Studio Express 2013. Works fine :). A project of mine was compiled with the new Version without any problems. (migrated from 2.9.5)
If you were looking for some practice, I really liked http://www.interqiew.com/tests?type=cpp - the quizzes there really go some less understood concepts, and the code is well written.
One of the more important C++ concepts to grok is templates. They allow you to create abstractions that compile into code specifically for the type they handle, yielding optimal performance. You also need to 'unlearn' a bit of your C behaviors, as you don't want to be managing naked pointers or the like. Study up on C++'s unique_ptr and shared_ptr, as well as RAII. Bjarne Stroustrup has written a bunch on those concepts and resource management in C++. He recently gave a great talk at Going Native 2013 worth watching.
Coming from Java (or many other OO languages such as C#), one of the most important habits to unlearn is creating objects with 'new' all the time. Most C++ classes should be constructed on the stack, by declaring them as ordinary variables, not as pointers with 'new'. To expand a bit: Although C++, like Java, makes a distinction between primitive types (integers etc) and classes, the distinction isn't as sharp as it is in Java. C++ classes don't have reference semantics like they do in Java: assignment in C++ copies the object, just as if it was an integer, instead of just creating a new reference to it as it would in Java. When you do want reference semantics, that's what 'shared_ptr' and 'make_shared' are for. Overusing 'new' is probably the most common mistake made by people coming to C++ from high-level languages like C# and Java. Manually managing memory by explicitly calling 'new' and 'delete', instead of letting smart pointers automate it, is probably the most common mistake made by people coming to C++ from C. 
3 Books I would recommend in order: 1) Effective C++ 2) Modern C++ Design (don't be scared off by the the template metaprogramming, no one expects you to actually understand this) 3) Effective STL Those books are all fairly short, brilliantly written, and contain far more than the average C++ programmer would be expected to know. One of the first items in Effective C++ actually addresses your main question almost verbatim. 
Just read through the standard library. Learn how to move. Understand vtables (you probably already do) and when to use each type of cast. Start using smart pointers immediately. Write your own allocators for containers. Learn the rule of 3.. rule of 5. I'd focus the majority of my time on which stl containers to use to standardize the majority of the code, and try to find the edge cases for all the things listed as best ya can. Good luck. 
I don't know if templates are really that extremely important. They are definitely useful though, if nothing else they [mostly] replace macros if you're coming from a C background. Modern C++ (i.e. C++11/14) style says avoid naked pointers, but we've only just begun to be able to use it. I still work on C++ code written in the 90's and early 2000's, and use gcc 4.1 (feel free to dry heave on my behalf). I dream of the day I get to use smart pointers and can stop investigating numerous instances of stupid memory corruption bugs and leaks. Definitely learn modern C++ style over "old" C++ style if possible, but realize that legacy code is here to ruin all our lives for a while yet. RAII is very understated IMO. As OdwordCollon said, read _Effective C++_. C++ has a LOT of nuances to it, and writing code that won't try to kill your users takes more effort than it might appear to.
&gt; don't be scared off by the the template metaprogramming, no one expects you to actually understand this I keep returning to TMP. I can understand "trivial" examples like Fibonacci, even if it hurts my brain a little. Coming up with that kind of black magic on my own though? I like to imagine that the person who eventually maintains my code knows where I live, and I enjoy my kneecaps the way they are.
&gt;don't be scared off by the the template metaprogramming, no one expects you to actually understand this Uhh, what?
Pointer have been, to the best of my knowledge, something of a building block for the C language. The ability to point to a data location, as opposed to moving the data itself, is integral to most "deep" programming languages.
if you understand 'old style' you have a deeper understanding for the reasons for 'new style'
Pointers, or more generally "data that is the memory location of other data", are important in assembly code, which pre-dates C. They've pretty much always been a part of programming languages. C was originally designed to be relatively straightforward to transform into assembly, so it has many of the same constructs.
Yes, there were even pointers in the B language, which was a predecessor of C. For more detail than you want to read, see [The Development of the C Language](http://cm.bell-labs.com/who/dmr/chist.html).
Yes. Refer to the seminal work: B. Kernighan &amp; D. Richie, [The C Programming Language](http://zanasi.chem.unisa.it/download/C.pdf), chapter 5 "Pointers and Arrays".
B was typeless, so I would say that it had dereferencing, but not pointers. The pointer data type is distinguished not just by what you can do to it (dereference, pointer arithmetic, etc.) but what you can't do to it, like normal arithmetic operations (multiplication, division, etc.).
keep declarations on the stack, meaning new shouldn't be used much. and don't abuse inheritance and "data encapsulation".
i still have never written any allocators. it might be that primarily targeting linux gets reasonable performance unlike the windows memory management train wreck.
templates, polymorphism, RAII are also important.
The following are also really good online C++ quiz: http://www.mycppquiz.com/list.php http://cppquiz.org/ 
I stopped programming C++ around 2010 and moved on to other languages. Frankly, to me this looks gibberish. Many languages are inspired by the braket syntax of C and manage to stay relatively readable while offering good metaprogramming and/or functional-style programming semantics. I wish that C++ becomes easier to read language with some form of modules system to cut down on compile times.
The important part is that it is actually just extremely pure functional programing. As in: Even Haskell is not as pure as TMP (Haskell must support side-effects for IO ans stuff while TMP points to the runtime for these things). Though this will change with C++14, when we get non-functional implementations for constexpr-functions.
Alright, I know you didn't explicitly ask, but I'll answer anyway :) Basically, SFINAE means exactly what it expands to: Substitution Failure (when compilation fails while trying to substitute a template parameter for a concrete type/value) Is Not An Error (we just try to find something else where substitution does not fail!) Okay, that's perhaps not clear as glass. Let's try an example. To fully understand it, you'll need to know a few things about `std::enable_if`, however. The way it's defined, `typename std::enable_if&lt;condition&gt;::type` basically results in a compilation error if the condition evaluates to false at compile time, and otherwise it evaluates to the type `void`. Note the part about how it amounts to a compilation error in some cases? That's the important bit. So, back to the example. Let's say we have these two functions declared: template &lt; typename T , typename = typename std::enable_if&lt;std::is_same&lt;T,int&gt;::value&gt;::type&gt; T foo(T); template &lt; typename T , typename = typename std::enable_if&lt;!std::is_same&lt;T,int&gt;::value&gt;::type&gt; T foo(T); They look very similar--almost identical even, except for an inversion on the enable condition. What that means is that instantiation of the first one will fail with any type other than `int`, and the second version is the reverse. Alright, back to the whole SFINAE thing. void example() { // The compiler will actually attempt to instantiate both versions of foo here, but because // the second version errors, the compiler removes it from the set of viable overloads and // pretends it never tried to compile it at all. That is, the failed attempt at substituting T // for int in the second foo is not counted as an error. auto x = foo(12); // And here, it is of course the instantiation of the first foo that fails, because T=string, not // int. auto y = foo(std::string("Not an int")); } If there had been several foos left after the substitution phase, normal overload rules would have applied. In fact, since the type signature would be exactly equivalent, there would have been an error due to ambiguity. Finally, SFINAE applies not only on templated functions, but on basically anything that can be templated. So you can have several versions of, say, a `struct`, where the correct instantiation is picked at compile time using SFINAE tricks (most likely enable_if).
gcc 4.1 has `std::tr1::shared_ptr`, and `scoped_ptr` is trivial to write. Add an explicit conversion between `scoped_ptr` and `auto_ptr` and use `auto_ptr` only for transferring ownership, and you have a reasonable approximation of `unique_ptr`. Obviously none of this helps your existing legacy code, but even with gcc 4.1 you can use smart pointers for any new code you write.
&gt; Modern C++ (i.e. C++11/14) style says avoid naked pointers, but we've only just begun to be able to use it. Why oh why oh why oh why. This is bullshit. It doesn't matter how much crappy legacy code is out there. RAII is not a new feature. I wish people stopped pretending it is.
You forgot the rule of zero. Much more important IMO.
Sad thing is, Fibonacci is the kind of useless crap no one ever writes. The interesting uses of TMP are the one that deal with types, not arithmetic.
&gt; They look very similar--almost identical even, except for an inversion on the enable condition. FWIW they *are* the same template, but with different default template arguments, which is not valid. This code would not compile. (the rest of the post is fine; it's just your example that is broken) 
It's easy to find on the interwebs, but here goes: template &lt;typename T, typename... Args&gt; std::unique_ptr&lt;T&gt; make_unique(Args&amp;&amp;... args) { return std::unique_ptr&lt;T&gt;(new T(std::forward&lt;Args&gt;(args)...)); } (For old compilers without variadic templates you need to write overloads for different numbers of parameters; five or six should be enough)
The [The Development of the C Language](http://cm.bell-labs.com/cm/cs/who/dmr/chist.html) by Dennis M. Ritchie talks about pointers quite a bit. In the ancestors of C, pointers were just integers and you could just look in to memory at any integer offset.
Why can't you just use `auto_ptr&lt;T&gt; const` instead of `scoped_ptr`?
 template&lt;bool C, typename T = void&gt; struct enable_if { }; template&lt;typename T&gt; struct enable_if&lt;true, T&gt; { using type = T; }; Making `enable_if` is just template specialisation.
A `const auto_ptr` can't be reset to a different pointer. If that's what you want then go for it. `scoped_ptr` is for the case when want a mutable pointer, but without `auto_ptr`'s error-prone assignment and copy semantics.
I used to use your distribution because it was pretty lightweight and decent. However I stopped because unlike the mingw-builds version it doesn't have `std::thread` support and still requires a patch to use `std::to_string` and friends as [seen here](http://stackoverflow.com/a/12975602/1381108). I know you already mentioned that you aren't planning on adding `std::thread` support but has the `std::to_string` issue been fixed yet?
Yes, you are right of course. My excuse is that I wrote it off the top of my head while kind of in a rush. Perhaps not a valid excuse, seeing as I have fairly similar (but working) things in some of my repos just a few clicks away, but it's all I've got :)
Also worth mentioning is that assignment doesn't necessarily mean a copy is made if `operator=` is overridden. Incidentally, with the advent of C++11, rvalue references, move semantics, changes to the stdlib, initializer lists, const expressions, and such are pretty standard in a modern project. Tack on C++ fundamentals like usage of `&lt;algorithm&gt;`, templates, smart pointers, overriding swap without copies and that should cover the "basics." C++ is not easy for the newbie. :P Powerfull as all hell though.
Small point to make, the current best practice in C++11/14 is to avoid **owning** naked pointers.
Also note that regular references are much better than smart pointers if you can guarantee lifetimes.
Thanks to mingw-w64, this works in distro 11.2. C:\Temp\gcc&gt;type meow.cpp #include &lt;iostream&gt; #include &lt;string&gt; using namespace std; int main() { cout &lt;&lt; to_string(1729) &lt;&lt; endl; } C:\Temp\gcc&gt;g++ -Wall -Wextra meow.cpp -o meow.exe &amp;&amp; meow 1729 C:\Temp\gcc&gt;g++ -v Using built-in specs. COLLECT_GCC=g++ COLLECT_LTO_WRAPPER=c:/mingw/bin/../libexec/gcc/x86_64-w64-mingw32/4.8.1/lto-wrapper.exe Target: x86_64-w64-mingw32 Configured with: ../src/configure --enable-languages=c,c++ --build=x86_64-w64-mingw32 --host=x86_64-w64-mingw32 --target=x86_64-w64-mingw32 --disable-multilib --prefix=/c/temp/gcc/dest --with-sysroot=/c/temp/gcc/dest --disable-libstdcxx-pch --disable-lto --disable-nls --disable-shared --disable-win32-registry --enable-checking=release --with-tune=core-avx-i Thread model: win32 gcc version 4.8.1 (GCC)
RAII is one of the most important things to understand about C++. Unlike C and Java, you do not have to manage your own resources. Pointers, file handles, everything is handled for you (assuming the destructors are written correctly). Learn to use and write RAII code and everything else will follow. Use the stack, and heap allocate only when it's really necessary. Heap allocation is not only slower, but it's a lot easier to write clean code if you don't use it as much. Templates are also important, like others have said.
Oh, I didn't realise you could `reset` a `scoped_ptr`. Carry on then!