That guy was not already hired?
&gt; It is a sequence of two code points that is treated as a single processing unit by correctly-written software. The point is: correctly written software must always process strings as strings. If you can deal with multiple code point scenarios correctly then dealing with UTF-8 or UTF-16 is not comparatively that large a problem. UTF-32 is useful inside UTF encoders and essentially nowhere else. The usual claim is that "well wchar_t being UTF-32 lets my application still process things 'character by character' since each code point is the same length" which is trivially wrong for decomposed characters and subtly wrong for special cases in different locales. `std::locale` has assumptions like this everywhere which makes it difficult / impossible to use correctly in a Unicode environment (the most obvious broken being the `ctype` facet, and to a lesser extent the `codecvt` facet when used with `streambuf`).
"If I have seen further, it is by standing on the shoulders of giants".
Only one slide about exporting C++ classes from DLLs: "don't". That's too drastic IMO. On a C++ conference I was actually expecting to see a lot of advice about exactly that instead of low-level details about DLL loading that you'll rarely need.
BW and DQ are the 8/16 and 32/64 bit integer instruction subsets in AVX-512. I’m guessing that on current Skylake X CPUs there may not be a full 512 bit wide ALU for these and they may just be getting cracked into two 256 bit instructions. 
Indeed, with the latest update most of the issues were touched - but the language server is still compiled against a newer version of GLIBC, for a reason I don't know. (Indeed, Microsoft.VSCode.CPP.Extension.linux requires symbol GLIBC_2.18 -- many supported machines only have 2.17. I see that Microsoft.VSCode.CPP.Intellisense.Msvc.linux is ok, works with no problems). [Issue 19](https://github.com/Microsoft/vscode-cpptools/issues/19) still stands, a year and a half later. 
I didn’t say anything about the order of operations!
Is it me or the declaration inline int myVar = 42; is counter-intuitive to its purpose? It supposedly creates a program-wide variable, but the declaration makes it like it creates a copy of the variable in each translation unit. 
Well, a list would be nice. Unless it's simply all the STL algorithms, but taking a range instead of a pair of iterators.
1h+ format really daunting for these talks. Is it a requirement of cppcon? A lot of these talks can be done in 20-30min, which would be more useful for the viewers.
std::any should have been named std::variant and std::variant should have been named std::algebraic_union or std::logical_union. The term 'variant' is traditionally used as std::any types in most programming languages. 
I agree, I mean if it will be in The Standard or at least TS, cppreference and Microsoft would probably provide usable documentation, but for now it's mostly list of views/ list of actions.
Niebler did a couple of talks on ranges in 2016, you can find the list of all the algorithms on one of his slides. IIRC
It's a bad idea to have the ordering of some data depend on the order of the fields declared as opposed to having to specify it explicitly. Tuples might look handy but they aren't the right solution semantically most of the time.
No. Inline in c++ has always meant there is a single definition. Static at that scope has meant one per translation unit. For example a inline function with a function static variable will share that static between all translation units.
&gt; most programming languages Could you name some (other than Visual Basic)?
doesn't the inline specifier says that it's okay to have **multiple identical** definitions (function and variable wise), and the linker shall just pick one of them. otherwise we would get a linker error on the quoted definition in a header file which gets included **more than once** in the programm
I agree. 1hr isn't enough to deep dive nor short enough to stay focused.
I hope there will be a part 2.
I don't see any issue with that, provided one is able to stick with a specific C++ compiler. Nowadays I spend my days mostly on JVM and CLR lands, but I don't remember having any big issue with it. That was how we used to do plugins, before COM took off.
I wrote 'programming languages' above, initially I wanted to write 'platforms', neither sounded good. Perhaps I should have written 'libraries'. Anyway, here are some links: https://msdn.microsoft.com/en-us/library/microsoft.visualstudio.package.variant.aspx https://msdn.microsoft.com/en-us/library/windows/desktop/dd373687(v=vs.85).aspx http://doc.qt.io/qt-5/qvariant.html http://docwiki.embarcadero.com/RADStudio/Tokyo/en/Variant_Types_(Delphi) https://dlang.org/phobos/std_variant.html https://docs.microsoft.com/en-us/sql/t-sql/data-types/sql-variant-transact-sql 
&gt; Inline in c++ has always meant there is a single definition. It doesn't make sense. If a function is inlined, multiple copies of it exist, inlined, in every place that the function is called. https://en.wikipedia.org/wiki/Inline_function &gt; In the C and C++ programming languages, an inline function is one qualified with the keyword inline; this serves two purposes. Firstly, it serves as a compiler directive that suggests (but does not require) that the compiler substitute the body of the function inline by performing inline expansion, i.e. by inserting the function code at the address of each function call, thereby saving the overhead of a function call. In this respect it is analogous to the register storage class specifier, which similarly provides an optimization hint.[1] The second purpose of inline is to change linkage behavior; the details of this are complicated. This is necessary due to the C/C++ separate compilation + linkage model, specifically because the definition (body) of the function must be duplicated in all translation units where it is used, to allow inlining during compiling, which, if the function has external linkage, causes a collision during linking (it violates uniqueness of external symbols). C and C++ (and dialects such as GNU C and Visual C++) resolve this in different ways. Since when inline's meaning changed to mean exactly the opposite?
I don't think so. 
Personally, I would remove some of the things that lead to simple bugs, like: * Implicit conversions of some primitive types like `double` to `bool`. * Uninitialized variables and members. (while adding a special keyword or other construct for cases when this is needed for efficiency)
Good recommendation indeed! If you follow this blogroll and this subreddit, you should be fine. 
Simplify C++ https://arne-mertz.de
It has never changed. `inline` itself doesn't necessarily have anything to do with inlining, it's just about ensuring a single definition of a function to prevent ODR violations for a function defined in a header file.
Compiler inlining is completely unrelated to the inline keyword. The compiler can make as many copies of a non-inline function as it wants, as long as it's not observable. The exact same rule applies to functions marked inline. The inline keyword just allows the single definition of the function to be copied into multiple translation units. Every TU will still see the function as having the same address.
Really good talk, but it seems like a lot of this could be avoided if we stopped trying to accommodate implicit conversions. Am I wrong? Guess I should buy the book.
What's the status of this feature?
Have a look at Rust.
N, I just do tuple&lt;int, string&gt; function(); auto res = function(); No more definition, no naming.
Removal of the input/output library stream globals *as global variables* (`std::cout`/`std::cin`/`std::cerr`/etc.) because it can give the wrong idea to new developers regarding the use of global variables. While we're at it, disallowing the use of `using namespace x;` in header files. I've been pulling my hair out at the inclusion of `using namespace std;` at work in our *production* code base added by new-ish employees which has been causing build errors; specifically, symbol collisions with `std::once_flag` and `llvm::once_flag`. These guys have a primarily C background, so I'm nice about it -- everyone deserves every chance to learn -- but on the inside, I scream. A lot of the stuff I want to change are really just additions, and are still proposals -- such as constraints and concepts, metaclasses (which I didn't know I wanted until it was proposed), and UFCS; none of those really apply here.
An explicit call-site syntax when passing a non-const reference. i.e. there's no way to know whether the line `foo(bar);` has the potential to modify `bar` without looking up the prototype of `foo`. I'd change it to something like `foo(ref bar);` (based on C# syntax) when `foo` takes `bar` as a non-const reference.
Sure, I have used Recast (inside unreal), but I have also used Navpower and Havok AI. I've also worked on projects that have rolled their own nav solutions. The algorithms (Dijkstra and A*) are pretty standard but the internal representation of the graph have been different (didn't have source for Havok AI). When you talk about navmesh as a data structure what guarantees are you making? Sure it is a data structure in the sense of any collection of objects with references between them is a data structure but I can't see a complete description without a mess of template policy classes. In projects I have worked on the nav meshes have had asymmetric edge cost, can be overloaded for more than one traversal type (commonly AI nav and sound propagation), the nodes have been convex n-gons or triangles, the pre calculated cost has lived in the nodes or the edges. My point being the requirements of a navmesh are extremely game dependant (before you start to talk about platform considerations). I tend to think of a navmesh as a strategy rather than an implementation of a general solution.
**No primitive types:** Completely remove primitive types, everything is a proper class in `std`. This way, we can get ADL to work for those formerly-primitive types without polluting the global namespace. There’s also no reason why an integer should be something fundamentally different from a string so this makes sense as well to me. **Allow insertion of functions into `std`:** Right now, if you want to print a `std::vector&lt;T&gt;` to a `std::ostream`, you have to define the `operator&lt;&lt;` at global scope for it to be found. However, if you also have an `operator&lt;&lt;` in a namespace between the calling location and the global namespace, it will be found first and the global one will be ignored. That is, a situation like: // global namespace template&lt;typename T&gt; std::ostream&amp; operator&lt;&lt;(std::ostream&amp;, std::vector&lt;T&gt; const&amp;); namespace A { std::ostream&amp; operator&lt;&lt;(std::ostream&amp;, ClassInA const&amp;); namespace Aminor { void my_function(std::vector&lt;T&gt; const&amp; v) { std::cerr &lt;&lt; v; } } } will find the `A::operator&lt;&lt;` first and stop the search there. Inserting `operator&lt;&lt;(std::ostream, std::vector)` into `std` is however undefined behaviour. So right now if you want to print a vector, you either have to replace all uses of `std::vector` by your own vector or define all `operator&lt;&lt;` for all types only in the global namespace or accept that undefined behaviour (guess what I did…). And finally: **Start class and namespace names with a capital letter:** This of course is a purely personal preference but I much prefer my types to stand out visually and to me, CamelCasedTypes while snake_cased_functions_and_variables leads to the easiest way to differentiate between objects and types.
- I remove pointers, - I remove everything from C, - I change type declaration after the name(e.g. var_ : std::string = "bla"), - every types like std::uint* will be primitives instead of typedefs. 
Tbh, I like the hour long talks. There's more information, and I watch at 2x speed anyway. The 30 minute talks have been kinda short to me. 
This always struck me as strange, especially considering the [`std::hash` page on cppreference](http://en.cppreference.com/w/cpp/utility/hash) specifically gives an example of injecting in to `std::`, but it *is* considered undefined behavior.
I like Rust, and I think that it has a lot of great concepts. But what I would be more interested in how C++ could be cleaned up a bit. It's just daydreaming of course.
No, `std::hash` is fine because you use a user-supplied class.
You can already accomplish that with pointers.
&gt; No primitive types: Found the Smalltalk fan!
So `std::cin &gt;&gt; (ref i)`? That seems quite inconvenient.
TL;DR: - [this is how you implement `view::take_while` in C++ (a lazy algorithm that takes elements from a range while the predicate is true)](https://github.com/ericniebler/range-v3/blob/master/include/range/v3/view/take_while.hpp): ~200 LOC - [this is how you implement it in Rust](https://github.com/rust-lang/rust/blob/master/src/libcore/iter/mod.rs#L1762): ~20 LOC - making references real objects - making the language expression-bassed - pattern matching on... patterns - algebraic data-types - move semantics by default - concepts + concept maps + type-checked definitions for static and dynamic polymorphism - composition-based code-reuse - a sane module system - real macros + procedural macros - monadic error handling - built in tuples and variants - expression-based language - no undefined behavior - no memory errors - no data-races - no diamon-hell inheritance 
I would: - add keyword `self` referring to *this (reference / const reference to current object). - devise a way to interconnect operators for a class (defining `&lt;` and `=` should automatically provide you with `&lt;=`, `&gt;`, `&gt;=` and `!=` for example). - impose a standard ABI and calling convention (affecting all compilers and platforms) - add the possibility for strong typedefs. 
&gt; Compiler inlining is completely unrelated to the inline keyword. The inline keyword is there to inline functions, as per the wikipedia definition. &gt; The inline keyword just allows the single definition of the function to be copied into multiple translation units. Every TU will still see the function as having the same address. How is it possible for a function to be copied into multiple translation units, and aos have the same address (assuming globally) at the same time? It doesn't make sense, these two things are opposite. 
&gt; no memory errors Rust does not provide no-leak memory safety; it doesn’t even guarantee that destructors are run for variables at the end their respective scopes.
That is good news! Thank you for continuing good work; I been using VS since version 6 or so. It's your "fault" that I never learned to use GDB. Never had to so thank you again! :) 
It's very strange to use a word with a specific meaning for something else totally different. 
The way default arguments work. Specifically, disallow adding default arguments after the first declaration, and disallow declaring different sets of default arguments of the same function in different scopes, as shown in https://stackoverflow.com/questions/44818513/c-adding-and-redefinition-of-default-arguments-in-real-world
I rather follow the official releases but it is nice to know that the support is coming so I can work on something else meanwhile w/o having to write the fallback code path and then find out later that I wrote it for no reason. Hate when your work becomes obsolete like that. Thanks for the heads up regardless, much appreciated. Keep up the good work. 
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Is this a new C++ library feature?
- leaking memory is not a memory error per-se, in many applications it is fine or even intended to leak memory (e.g. for performance reasons) - Rust makes it harder to leak memory than C++ though
- Use "better" (less ambiguous and more expressive) syntax - Introduce lifetime annotations and enforce them language-wise - Reflection/meta-programming
I would reorganize the language grammar to remove context sensitivity wherever possible. I love C++, but I've always felt that there's an equally expressive, simpler language just fighting to get out that has its hands tied by C. 
That's truly awful, great point.
Remove pointers!? The best part? No way! &gt;B( 
Ah ha, good to know. All my C++ knowledge is on-the-job training and hobbyist projects (save for one class on it back in 1999) so I tend to miss these sorts of things. Thanks.
Ah, thanks for the link to the Reddit post. That explains the type loophole nicely.
For your second dot, consider searching for "spaceship operator c++" :)
I'd like exceptions to be very different. I'd like the Standard Library to stop trying to throw them all the time and prefer optionals (or expecteds) where possible. I'd like a try operator (which is being worked on in SG14), I'd like an otherwise operator. I'd like a way to specify that a function _only_ throws these types of exceptions and have it statically checked that either the function is throwing those types or a function this function calls does that. If a noexcept function tries to throw (or a function inside of it can throw but it's not handled) it's a compile time error. I think exceptions are ergonomically frustrating, and these changes would make me actually want to use them.
The only way to clean C++ is to add more backwards compatible stuff to it, this is very hard, limiting, and what I would call cleanup (because it allows me to write cleaner code) somebody else would call extra complexity (because it is another thing they need to learn). Anyhow, the way your question is phrased (ignoring backwards compatibility) basically prevents any useful answer.
On the defining relative operators automatically bit, they did use to try to do that (in std::rel_ops namespace or something similar) if memory serves, but... it worked clunkily or something so it got (or is being) removed.
But then you have to / should check for null pointer, and sometimes that hurts performance.
if we can disregard backwards compatibility we can also remove this clusterfuck of `*`, replace it with `ptr&lt;T&gt;` for when you need memory addresses, and have the unary `&amp;` transform something in a mutable reference instead
I would *especially* remove the implicit conversions between signed and unsigned integer types and vice versa!
+100 for changing the experimental pointer notation in C. *That* particular experiment failed bigly!
Welcome to C++!
If you disregard backwards compatibility you're going to get something like D. 
Good talk. The over the top acting and fake phone calls were a little bit too cringey for my taste though.
Well, I'm not a huge fan of the "streaming operators" either, but that doesn't seem too much of a problem. Since the "external" variants of overloaded operators (e.g. `T&amp; operator++(T&amp; a);`) would still need to pass a non-const reference implicitly allowance could be made for streaming; especially if it were changed to use a different syntax from bitshifts.
The pattern where you pass a variable by value to a constructor, only to copy/move it to an identically-typed variable in the class body, seems like something that could conceivably be optimized (in the same way that NRVO optimizes returns). Does anyone know if this is already done by optimizers? If not, would it be possible?
It is. Source: I used to work with C#.
&gt; as per the wikipedia definition The standard has different definition. And even wikipedia lists two "purposes". The first one, "inlinint hint to the compiler", is not normative and almost irrelevant today. The second one, citing wikipedia, &gt; The second purpose of inline is to change linkage behavior; is what relevant for the current discussion, and basically the only meaning of this keyword required by the standard.
Yeah, C++ has a lot of issues...
Hmm, I always use `self` as typedef to class own type, so we have name clash right here :)
making string literals std::string, not const char *, so like auto msg = "Hello World!"; //msg deduced as std::string, no "s" postfix like the current user defined literals 
Ok, I know of the second definition. When used with functions, it sort of make sense (sort of). But when I see the following: inline int x = 5; my mind always goes to something like this: #define x 5 and i suspect lots of developers will have a big ? initially. Anyway, it's not that big of a deal, it is only surprising when you see it for the first time. 
Well `QVariant` is actually weird. In the way it does much more for types for types Qt knows about (acting similarly to `std::variant` on a fixed bunch of types) and becomes simple `std::any` for anything else. In some of links you provided it seems to be the case too. Like Delphi variant holds only integer, real, string, boolean and null.
&gt; &gt; &gt; How is it possible for a function to be copied into multiple translation units, and aos have the same address (assuming globally) at the same time? It doesn't make sense, these two things are opposite. It's the linker who's in charge from keeping a single function when producing a shared library or an executable from many object files
&gt; remove the need for the remove-erase idiom This is [already done](http://en.cppreference.com/w/cpp/experimental/lib_extensions_2#Uniform_container_erasure) in Library Fundamentals TS v2. The feature is called "uniform container erasure"
So that they are not usable within constant expressions? If `const char[N]` is insufficient, maybe string literals should have the type `string_literal&lt;N&gt;`, where `string_literal&lt;N&gt;` is similar to `std::array&lt;char, N&gt;`. One also needs to consider encoding. String literals should probably be always encoded in utf-8, but that means subscription will not work and `size()` of it will be quite misleading.
Yes, but many of us *can't* stick with a specific compiler. We support multiple platforms with several compilers per platform. I was hoping the talk would provide some insights into using C++ with DLLs, but sadly it did not. Static libraries work, but don't cut it for many tasks e.g. plugins, python modules etc. You still run into all sorts of problems like ODR violations. On every other platform, I can create shared/dynamic libraries which allow export of C++ classes and functions, including templated classes and functions, and throwing exceptions across library boundaries and sane memory management. It works transparently and robustly. But on Windows, DLLs are mid-1980s-era tech which is incapable of doing this at all. Rather than restricting myself to a "C" ABI I'd actually like to be able to use standard C++ on Windows, rather than living with all these fundamental restrictions; it's not really a lot to ask, given that every other major platform manages it, and they have done so for decades. A replacement for DLLs which does provide this functionality would be welcome; I note that Windows 10 now provides a native ELF linker for the Linux subsystem, and wonder if it couldn't be repurposed to allow ELF shared library loading for Windows.
std::string should be a language level thing (not a regular class like its current implementation, maybe get rid of the "std" namespace and just make it "string" as if it's a primitive type like "int") if this does happen, so it might still work for constexpr stuff, op asked about modern style and it's how string works in most modern languages 
&gt; main reason C++ devs have a hard time learning Rust: stockholm syndrom In one single sentence, you managed to offend entire community and destroy the rest of your points. This is the reason, why most of us here don't like the mentioning of Rust - because most of the time someone when mentions it, they feel like they are entitled to judge what makes a good language. CC /u/steveklabnik1 - Steve, this is why CPP has good relations with Rust but has bad ones with Rust enthusiasts (not all of them tho). Back to your points: The good C++ dev needs around 2 to 4 weeks to get proficient in Rust. Nowhere near guru level - but enough to write production code. Lifetime system can be counter-intuitive, but because it happens during compile time, it easier to expert and what till it clicks. &gt; making the language expression-bassed Good idea, until people start to abuse it. Explicte returns immediately catch my eye, where something like Ok(Response::Started) do not. &gt; pattern matching and algebraic data-types Agree, tho nothing prevents C++ from having one in the future. We have prototypes. It can be done. On the other hand things like: match err.kind() { ref e@&amp;NotFound(_, _) =&gt; { GrpcMessageError { grpc_status: NOT_FOUND, grpc_message: e.to_string(), } }, ... Are just bizzare in my opinion. &gt; move semantics by default (huge simplification) &gt; monadic error handling (huge simplification for the 99.9% case modulo OOM) The amount of `self.myfield.clone().dostuff().map_err(|err| {...})` makes me disagree with both statements. It's incredibly attention spreading because I see execution flow and not the logic behind it. YYMV. &gt; concepts for static and dynamic polymorphism Traits are nice - I agree. Finding them in the codebase is not nice. &gt; composition-based code reuse (huge simplification) You don't need inheritance until you actually do. *One composition to rule them all* is a lie. &gt; a sane module system + package manager (huge simplification) Agree. Tho I don't like the fact that you can import modules inside scopes. IMHO that removes the ability to overview module. &gt; real macros + procedural macros (huge simplification + infinite usability improvement) I would pick compile-time code execution over macros in the heartbeat. This is one thing D made right. &gt; no undefined behavior / memory errors / data-races / diamon-hell inheritance / ... So - [Pony](https://www.ponylang.org/)? The are also deadlock free.
Basically, the things that were already a hack when C was designed, and C++ was forced to carry them over. * Illogicalities in operator precedence (bitwise ops, the ternary op) * Array-to-pointer decay * Implicit conversions * 0 as nullptr * ...
Make const ref the default - not copy - when passing arguments. range checking on arrays be explicit with owning and non-owning pointers push as much undefined behavior checking into the compiler as possible. push the c++ guidelines into the compiler as much as possible Make -wall the default for the compiler. get rid of headers if possible come with more batteries included - or improve code sharing to be more like python or ruby 
Also removal of implicit conversion from const char * to char[N], it's confusing as hell to newbies cuz it's inconsistent with how pointers and arrays work anywhere else in the language char msg[] = "Hello World!"; //error, cannot convert const char * to array type
I think the first four are more close to C++'s `std::variant` in that they all provide a way to get a number or enumerator that represents the type they hold, similar to [`std::variant::index()`](http://en.cppreference.com/w/cpp/utility/variant/index). I think these types are most similar to `std::variant&lt;/* built-in types...*/, std::any&gt;`. The last one seems just like `std::variant&lt;/* built-in types... */&gt;`.
Pass by reference would require a prefix like pass by pointer. In fact, I'd prefer to distinguish between: "reference that is only read by the callee", "reference that is only written", and "reference that is both read and written." I'd make it possible to optioanlly name the parameter of a function you call for clarity, eg: createFont("Sans", bold: true, italic: false); or if you preferred, createFont("Sans", true, false); Either classes would be allowed to be reopened to add additional non-virtual member functions later on, or it would be acceptable to declare non-virtual member functions outside of class definitions, since they don't change the structure of the class in any way. The priority of &amp; | \^ would be corrected now that we have &amp;&amp; || I would allow subclasses (classes inside of other classes) to access their parent scope implicitly. I would eliminate unsized types like char, short, long, long long in place of int8, uint32, etc. No _t. Even primitive types would allow member functions to be declared on them, so you could create a function called int8::bits() -&gt; uint32 that returns the number of bits set in an integer, then call with var.bits(). Absolutely no undefined or implementation defined behavior. It's not the '70s, most CPUs are pretty consistent. Compiler authors are too clever for their own good and introduce real-world, serious security issues by undermining developer efforts (eg no-opping a memset(0) on a private key.) No strict aliasing. Integers would wrap. I would completely scrap templates and come up with a clean, imperative syntax for template and meta programming. I would also remove the C preprocessor after. Name mangling would be defined by the standard, instead of changing per version per compiler. And probably a whole lot more if this were a real possibility instead of a thought exercise :)
Ok, so you were talking about different phases then.
This is not implicit conversion. It's just [how character arrays initialization work](http://wg21.link/dcl.init.string).
I was super confused why char msg[] = "Hello World" works and char msgs[][] = { "Hello", "World" } doesn't when I first learned C, I think the syntax is poorly designed and ambiguous and needs to be removed 
For delphi, it is this: &gt; In other words, variants can hold anything but structured types and pointers
I was super confused why char msg[] = "Hello World" works and char msgs[][] = { "Hello", "World" } doesn't when I first learned C, I think the syntax is poorly designed and ambiguous and needs to be removed 
For delphi, this is what happens: &gt; In other words, variants can hold anything but structured types and pointers For QVariant, it can hold anything, with the same index of course. VARIANT can take IUnknown*, so it can also have anything. 
It's not like I don't want algebraic data-types in C++, but `zip`: * [in C++ (range-v3)](https://github.com/ericniebler/range-v3/blob/master/include/range/v3/view/zip.hpp): ~100 LOC * [in Rust (std lib)](https://github.com/rust-lang/rust/blob/master/src/libcore/iter/mod.rs#L828): ~200 LOC
The compiler is only able to fill out the first bound. `char msgs[][6] = { "Hello", "World" };` works.
Committee avoids introducing new keywords. But there is already a keyword that has similar meaning, so they reused that. And, by the way, `inline` is not the worst at that. `static` has something like 5 different meanings.
...are you stroustrup?
Whatever, I switched to const char *msgs[] = { "Hello", "World" } shortly after, const char *[] is a much better and unambiguous syntax, it's very clear that msgs is an array of const char *, cuz each string literal is a const char * pointer, what is that pointer to array thing called anyways if it's not a conversion, it looks extremely weird cuz there's no such thing for other types of arrays and pointers, and obviously inconsistent with the rest of the language 
I would remove header files. And probably other ways to make the language less about text processing, like removing macros.
Add copy-on-write optimisation in std::strings.
Properly splitting the `std` namespace (like pretty much every other language with namespaces does), so that `using namespace` became the norm, instead of `std::` everywhere.
Indeed. They should have put in new keywords, it wouldn't hurt anyone. 
almost everything. I would make the syntax like Swift but without garbage collection and embrace the zero-cost-abstractions philosophy of C++ with heavy focus on a sound type system that enables compile-time assertions. 
`view::zip` is only a tiny wrapper over [`view::zip_with`](https://github.com/ericniebler/range-v3/blob/master/include/range/v3/view/zip_with.hpp), which is ~400 LOC... So implementing `view::zip` is ~500LOC in C++, while only ~100LOC in Rust.
&gt; (as oppossed to C++ where destructors can run many times producing memory corruption) No, there is specific language in the standard making this undefined behavior.
Get rid of `const` completely. It's a nice idea in roughly the same way as communism is a nice idea: it sounds very good in theory, but in practice is just adds messy duplication and bewilderment. 
Get rid of the C-style PODs. "How big is an `int` on my current architecture?" What a giant hack. `uint32_t` tells you *everything* you need to know about what I want.
I'd add `union class` as a proper sum type, and make it possible to `switch` over it.
I am flattered that you think so. But no.
How do you change exceptions without changing some of the key philosophies around not paying for what you don’t use...?
"self" could be done easily with a macro #define self (*this) 
alright "not stroustrup", look at the second bullet point [here](https://en.wikiquote.org/wiki/Bjarne_Stroustrup) please
Hence the answer in a thread where backwards compatibility is not an issue.
* Add unsigned integer type with undefined overflow * Fix `std::min` with rvalues But the way language evolves despite backward compatibility requirement is already quite impressive.
More information can be found in the blogpost about the release: https://blogs.msdn.microsoft.com/visualstudio/2017/10/11/visual-studio-2017-version-15-5-preview/.
* Remove unsafe string functions like strcpy and enforce use of functions that take buffer sizes * Make a filesystem API that completely handles file management (std::filesystem only takes care of finding and identifying files, but there's no I/O API that uses it yet, you need to do .u8string() or .string() to use paths) * If we're talking low level stuff, making arrays store length as well so we never have to pass buffer sizes around explicitly unless you're copying a number of characters. * Supporting Unicode properly so you can iterate over complete characters on any platform without worrying about sizeof( CharType ) changing or accidentally iterating over code points instead. Also generic string functions for formatting with any string type * A proper, cross-platform, compiler-change-resistant way to expose and access library interfaces, i.e. exporting functions, classes, interfaces, etc. No more wrapping GetProcAddress/dlsym, fragile interfaces that require manual version checks, maybe type identification that works across library boundaries
&gt; Absolutely no undefined or implementation defined behavior. Some values need to be implementation-defined, e.g. `std::endian::native`.
GCC extension, I guess.
&gt; Explicit returns are a minimal part of an expression based language. `If/`Match`/`if let`/etc. being expressions is a much larger part of it. &gt; The amount of self.myfield.clone().dostuff().map_err(|err| {...}) makes me disagree with both statements. It's incredibly attention spreading because I see execution flow and not the relevant logic behind it. For me it is less attention expreading than C++ code doing the same thing, in particular after having used `std::optional`, `std::variant&lt;T, Error&gt;` for over a year already in production and played a bit with Boost.Outcome and `expected`. There is a difference between errors that must be handled immediately, and errors that can't in general be handled except at the very top level of an application. I don't know a better way of dealing with immediate errors than Monadic error handling (not in Rust, C++, or any other language). The only robust alternative I know of are checked exceptions and they are just worse, and in general, I'd write that kind of code for immediate errors than `try`/`catch` all over the place. Anyhow, it's ok to disagree, this is a subjective issue, I like this way more, and prefer exceptions for close to irrecoverable errors (like OOM). &gt; Finding who implements what in the codebase is not nice. It can at least be done: you can look for which traits a type implements, and then recursively keep on looking for which traits are implemented for that kind of types. For a program with N types and M traits, and assuming each type implements P traits where P &lt;&lt; M this becomes a O(N) problem. It can also be resolved without a compiler by just following impls. With C++ concepts, you need to take all concepts in a program, and feed them your type, and see what sticks. This is inherently O(N*M) and you need a full compiler to check this :/ &gt; I would pick compile-time code execution over macros in the heartbeat. This is one thing D made right. I don't understand this statement. Compile-time execution and text-processing macros serve completely different purpose and D has both (mixins and CTFE). Rust has both as well (macros and `const fn`) but I don't know of any other low level language with better macros than Rust. D mixins combined with CTFE are neither as ergonomic nor as powerful as Rust macros, not by far (Rust macros can start a multi-threaded web-server to query multiple data-base schemas and inject that into your code, at compile-time; D's CTFE cannot even start a thread). &gt; So - Pony? They are also deadlock free. Pony is garbage collected which for me at least is a killer in the domains where I am currently using C++. Also, Pony is deadlock free because it does not support locks. This is also a killer because ilocks are the most performant solution to many problems. Rust locks allow you to opt-in to deadlock detection, but doing so is not enabled by default. &gt; But it's not without downsides and definitely not better than C++. &gt; &gt; In one single sentence, you managed to offend entire community and destroy the rest of your points. Sorry but I am also part of this community, and I was offended by the GP having -6 downvotes when I entered this thread. Somebody ask "If you could drop backwards compatibility, how would you improve C++?", a redditor comments, I would start from a more modern programming language like Rust which objectively many downsides, and improve that instead. That is IMO by far the best answer in this thread because if we could drop C++ backwards compatibility we would had already changed it into something much closer to Rust already (hell if you write code using the cppguidelines it actually feel like writing handicaped Rust).
It's a good advice if the DLLs are used "externally" - i.e. with more than one product, as you don't have control over which compiler/CRT is used to access it. On another hand, if you just want to break your own product into DLLs, exporting classes is fine as long as you link all binaries to the same CRT.
This is an interesting one. I think most would disagree with you.
Ok, that was very stupid of me. `view::zip` works with any number of ranges though.
Remove const and keep constexpr for explicit declaration of compile time stuff
- Copy paste compatibly with C style arrays and strings, including implicit conversions to pointers - null pointers require use of nullptr - C style enumerations (not to mix with enum class) - reduce the amount of UB - require variables to be initialized before use All of them to make C++ more in line with safety. All those use cases are still possible with modern C++ features.
This doesn't compile: https://godbolt.org/g/awVwYh
Technically the comment here is not an attribute specifier, just another way to silence the [-Wimplicit-fallthrough warning](https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wimplicit-fallthrough). nb: Please don't use `-Werror` in build scripts for actual projects.
&gt; metaprogramming meta-template programming
If you had any familiarity with c+++ you would know what minimal change you need to make to compile the code. The example I gave is simply a proof of concept for you.
Actually the Windows DLL model was also the model used in Symbian OS and Aix, before Aix adopted ELF shared objects. Also I clearly remember the days, where UNIX systems had the same issues across compiler vendors, making us select a specific compiler in each platform. 
&gt; reference that is only written What is the use case for this? Would you also have member functions are take an "input only" object reference? &gt; Absolutely no undefined or implementation defined behavior. Would you have compile-time or run-time checks? This would either put a lot of restrictions on the language a'la Rust or degrade efficiency. &gt; Name mangling would be defined by the standard Does this have to break language compatibility?
Is there a way to upgrade from the GUI? I closed an upgrade window and have found the same thing again. Also does this fix the massive compiler bugs that would show up with eigen?
Sorry I'm being a prick. Here is: #include &lt;tuple&gt; std::tuple&lt;int, std::string&gt; function(); int main() { auto res = function(); return 0; } I just meant that's maybe preferable to doing something like: struct Result { int value; std::string name; }; Result function(); int main() { auto res = function(); return 0; } Just one less thing that needs defining, littering the place up.
Then C++ is memory safe because memory unsafety is undefined behavior? I said that Rust guarantees that destructors won't be called twice. C++ defines doing so as undefined behavior, but if you, by mistake, write code that calls a destructor twice, your code will silently compile, silently run, and introduce undefined behavior at run-time. 
Planned, recorded and already in the queue in a few weeks.
Step back looks interesting... not quite as powerful as Time Travel debug but certainly useful in those step-too-far cases...
That's no longer a change to C++, that's a completely new language.
I would love to keep pointers and remove everything else from C, and make it Python with pointers 
&gt; view::zip works with any number of ranges though. When I started learning Rust I really missed C++ variadics in Rust, I think C++ really got them right, and I did not like that they weren't a priority. It turns out that variadics aren't really needed in Rust (they would be nice to have, but are not a must). The reason for this is that rust has builtin tuples and pattern matching, so if you want to zip 3 ranges you just do `a.zip(b.zip(c)).map(|(a_i, (b_i, c_i))| { ...}). Sure, being able to write `a.zip(b, c).map(|(a_i, b_i, c_i)| { ... })` would be nicer, but what we already have isn't _that_ bad.
&gt; add keyword self referring to *this (reference / const reference to current object). Clearly it would be better if `this` were a reference rather than a pointer, but it doesn't seem enough of a problem to justify a new keyword. You can always `#define self (*this)` in your own code if you want to. &gt; devise a way to interconnect operators for a class (defining &lt; and = should automatically provide you with &lt;=, &gt;, &gt;= and != for example). Herb Sutter has a "spaceship operator" proposal which will hopefully make it into C++20. &gt; impose a standard ABI and calling convention (affecting all compilers and platforms) People keep asking for this, and I never understand what benefit it would bring. It's not like I'm going to be able to take a library compiled for Windows and use it on Linux anyway. ABIs are a matter for platform vendors -- and as a matter of fact, almost all of them use the Itanium ABI anyway. &gt; add the possibility for strong typedefs. I really really want strong typedefs, I believe they've been proposed a couple of times but haven't made it for one reason or another. &gt; allow int main to accept a vector&lt;string&gt; argument (or a dedicated command line class type) `vector&lt;string&gt;` wouldn't be quite right, but something like `std::initializer_list&lt;std::string_view&gt;` might do the job. But that's so much typing that people probably wouldn't bother. Maybe a dedicated `std::command_line_args`? &gt; fix the std:: containers and algorithms: &gt; add a utf8 string Yes! 
Templates are Turing complete. Although I cannot wait to write metaprograms the same way I write normal programs.
with auto deduction in C++14 it is: auto function() { return std::tuple&lt;int, std::string&gt;{ ... }; } https://godbolt.org/g/AAFp1n
Even better! Then I guess you need the implementation in the header?
I wonder how you could have an Abi that is performant and work on both ARM, embedded systems and x86, and x86_64
usually it is something local in your code and you have it without including something
why would you do this ? everyone coming from other languages will hurt their head when reading your code. At least call it self_type.
Yes, I'm well aware that it was. But that's a historical detail for today's developers. They used COFF, that's where MS picked it up from after all. But they moved on from it some time ago.
&gt; People keep asking for this, and I never understand what benefit it would bring. It's not like I'm going to be able to take a library compiled for Windows and use it on Linux anyway. ABIs are a matter for platform vendors -- and as a matter of fact, almost all of them use the Itanium ABI anyway. No, but it would be nice to take a DLL compiled on windows with MinGW and run it with an application built with Visual Studio
Yeah nice, didn't know you could do that. Why'd you remove it?
Yes, and I would remove the Turing completeness :) I'm otherwise pretty good at programming, but I can't even get the syntax of template metaprograms right, let alone some complex constructs without having 10 tabs of stackoverflow open.
Currently it's a TS, see http://en.cppreference.com/w/cpp/experimental/lib_extensions_2 Sad, it didn't get into C++17 proper. Maybe C++20? Writing `erase(remove_if(a.begin(), a.end(), predicate), a.end())` is boilerplate and error-prone. `erase(a, predicate)` is much better and readable.
I didn't :)
Well... this is actually being seriously discussed for the `View`s in the ranges TS... so...
who did?
&gt; , cuz each string literal is a const char * nope. static_assert(std::is_same&lt;decltype("foo"), const char(&amp;)[4]&gt;::value); 
&gt; making string literals std::string, not const char *, so like no, std::string_view.
In case you didn't know, this used to be permitted in C++98 (and was implemented that way at least in libstdc++). This turned out to be a performance problem and so C++11 was changed to disallow it. That said, I wouldn't mind a `std::cow&lt;T&gt;` type for opt-in copy-on-write.
&gt;...and no, that language is not Java or C# :]
const by default
No. There's no reason why `msg` should allocate memory here. But if backwards compatibility *really* wasn't an issue, it would be nice if string literals had type `std::string_view`. 
Not the best answer - almost all your suggestions are in fact backwards compatible. &gt; add keyword self referring to *this (reference / const reference to current object). Because your fingers are bleeding from typing all those `*` or what?
It certainly would. But it's a matter for Microsoft to define a C++ ABI for the Windows platform, not the standard committee.
&gt; Sorry I'm being a prick. Here is: &gt; #include &lt;tuple&gt; &gt; &gt; std::tuple&lt;int, std::string&gt; function(); &gt; &gt; &gt; int main() { &gt; auto res = function(); &gt; return 0; &gt; } &gt; I just meant that's maybe preferable to doing something like: &gt; struct Result { &gt; int value; &gt; std::string name; &gt; }; &gt; &gt; Result function(); &gt; &gt; int main() { &gt; auto res = function(); &gt; return 0; &gt; } &gt; Just one less thing that needs defining, littering the place up. 1) I was talking about named tuples, not tuples in general. Try to change your tuple into named tuple and you'll see that simple type definition takes longer to write that just defining a struct. 2) The proper analogue to the first snippet would then be #include "result.h" // or more likely "function.h" Result function(); int main() { auto res = function(); return 0; }
it's just collapsed automatically (there is a link to expand it)
I know what's missing, but I wasn't sure that you understand so I was just trying to leas you to the answer. See my response to your other comment.
Why in the world would you want to get rid of turing complete templates? You would have to remove either, specializations or value parameters both of which are useful outside of template meta-programming. They weren't there originally to support TMP, but to support things like `std::array&lt;T,N&gt;` and `std::unique_ptr&lt;T[]&gt;`, both of which are undeniably useful, (`std::vector&lt;bool&gt;` as well which is not so useful).
C4251 warning (https://msdn.microsoft.com/en-us/library/esew7y1w.aspx) is insidious. Sometimes you can ignore it, sometimes you can't. 
I struggle to think of the last time I used `&gt;&gt;` to get something from a stream. There are many issues with it. `std::cin` has a state, and one that can be changed by other threads or libraries - it's really not thread-safe. It is difficult to properly recover from an error. It's painful to do binary input with strings. There's no great way to set a buffer chunk size. The streaming operators did not work out as well as hoped. `&lt;&lt;` seemed so exciting when I first saw it, but the love affair was over the first time I had to internationalize and realized I had to replace every single instance of it (because all languages have different word orders). In my opinion, you should be using a machine format like JSON, XML or protocol buffers for data interchange, and for parsing and printing human input, you should be using something that takes a format string (if only for i18n or l10n).
Yeah but you still have the overhead of defining it in that other header....
&gt; I would make it so typeinfo(T).name() is guaranteed to be a compile-time resolution. How would this work with plugins? Like, multiple plugins, loaded at run-time, instantiate the same interface and you want to distinguish those? 
Or Rust.
Yeah, that's a bummer, and would get the comment deleted on /r/rust. :/
Other than code using them as identifiers.
I don't know about that. Rust is very different from C++ (especially with that borrow model). However yes, that is the gits of it.
&gt; C++ makes one so used to working around the language instead of working with the language I just feel you don't understand the language. It does take longer to master than other languages, yes, but "working around the language" should definitely not be a big part of your experience if you are using modern C++ with a reasonable degree of mastery. 
It takes most of its syntax and machine model from C++.
"UTF encoders" are not the only thing that works with Unicode: classification, normalization, decompositions and substitutions, collation, case conversion, all boundary analyses (combining character sequence, grapheme cluster, word, line, sentence), are in terms of code points, not units or clusters. Yes, some successful libraries keep units of some encoding in memory and translate back to code points on the fly for processing (I suppose only regex might be sensitive to the loss of random access that comes with this approach), but that doesn't make the standard C++ (and C) approach in any way wrong. Just unimplementable on Windows. `std::codecvt` has no assumptions. From your earlier discussions, you don't like `std::filebuf`'s requirement for (possibly stateful) 1:N mapping between code points and code units, but UTF-8 and all other Unicode transformation formats in existence are 1:N. `std::ctype` is forced to use POSIX character classes and case conversions (whose mapping to Unicode is finally standardized by ISO 30112), which are indeed inadequate. If I were to agree that deprecating library features with no replacement is sensible, `std::ctype` is what should have been been deprecated, not `std::wstring_convert`.
The turing completeness allows for a lot of good constructions, specially in the standard library. Without it, C++ nowadays would be a lot like C++98 (ugh).
True, but as a C++ developer I found Rust learning curve very steep.
The borrow checker is all new, but at least you didn't have to learn the difference between owned and borrowed data, compile-time vs. run-time polymorphism, or RAII at the same time.
Non const globals should be thread local by default with a keyword needed to share them.
&gt; but something like std::initializer_list&lt;std::string_view&gt; might do the job. Program arguments are modifiable, so really `char*[]` is already the optimal choice.
&gt; I would make it so typeinfo(T).name() is guaranteed to be a compile-time resolution. The standard doesn't enforce this, although most compilers do (to the best of my knowledge); I'd like to have that codified, though. This would make it so type names could be retrieved even with RTTI disabled. That seems pretty much like `get_display_name_v&lt;reflexpr(T)&gt;` in [P0194R4](http://wg21.link/p0194r4), or `$T.qualified_name()` in [P0590R0](http://wg21.link/p0590r0).
&gt; ability to rely on that while learning the language I didn't say it's bad. But It's not without downsides. &gt; Using those types is way more verbose than the equivalent Rust code The thing is - I don't see a verbosity of an error handling as a problem. On a contrary - clearly defined error handling blocks, even if more verbose, ARE better. But during function or method invocation I want to have a focus on what matters currently. &gt; With C++ concepts, you need to take all concepts in a program, and feed them your type, and see what sticks. You can judge by used types - the concepts require concrete types to actually implement a said concept. In Rust, you can't make the same judgment because the end types are defined by usage, which in turn defined is by traits which the starting type implements. First and basic example From\Into duality. Of course, once it *clicks* if get a perfect understanding of those transformations works. The problem is - it requires a lot more time than it needs too. &gt; I mean, just compare the documentation tools for C++ with rustdoc. Rustdoc is the blackswan of Rust tooling, nobody works on it, and it is far from doing all it could. Yet since as far as I can remember rustdoc was always much nicer than Doxygen, even though Doxygen had like a 15 years advantage. Doxygen was never good, to begin with. But it works. It was also designed and developed long before "web documentation" became a thing. &gt; FAIK D's CTFE cannot even start a thread, much less open network sockets and do I/O. I'm pretty sure we are going to this from different perspectives. I want the ability to define meta types and behavior without going into something like AST expressions. You want something much more powerful and much more low level. Also &gt; start a thread-pool, download json schemas in parallel, and compile them to a byte string in the static memory segment of your program if you want to This should be explicitly disallowed by any sane production environment. Just a note. &gt; That's like saying that Fortran77 is memory safe because it doesn't support allocating memory. Incorrect. Fortran77 doesn't have something to offer in the absence of allocating memory, which can at least be viewed as better. The Pony type system do in respects to locks. &gt; That makes no difference, the community is already alienated. Independent of the content of a comment or post, if it mentions Rust it gets downvoted to hell. No - there are actually upvoted Rust sumbissions into this sub, and proper discussions. We are open to new ideas. But when people present yourself in the way you did, no wonder people click a downvote button. Do you really expect someone to respect your opinion when you insult them? As for original question - the question was about C++ without a baggage. While Rust and C++ share a some of domain space, and some of the concepts, on the language level they are entirely different. Even language families are different.
GC also makes D very different from C++.
There's a lot more that I dislike about Rust, but we're going offtopic.
* "Declaration reflects use" style of type annotations Even Stroustrup said he would fix that if he didn't need C compatibility.
I guess it should be more intuitive if `decltype(self)` returns an rvalue-reference type when the enclosing member function has ref-qualifier `&amp;&amp;`. class Ty { int f() &amp;&amp; { static_assert(! is_same_v&lt;decltype(self), Ty&amp;&gt;); // should hold static_assert(is_same_v&lt;decltype(self), Ty&amp;&amp;&gt;); // should hold } };
As you do with tuple. Even ignoring all the code you need to support the tuple and assuming that the appropriate header is already included everywhere you need, you still need to define the type or use the `typedef`, which will take longer than defining a struct. I.e. from my other post, compare this: `using test = nuple&lt; $("first"), char const*, $("second"), int &gt;;` with `struct test { char const* first; int second; };` 
&gt; I would also redesign metaprogramming to use a normal procedural language, leaving non-turing-complete templates for generic containers and algorithms. He's not saying to get rid of advanced metaprogramming, he's just suggesting that two facilities should exist, one for simple stuff (declaring generic types for containers), and a full programming language for sophisticated stuff. I'm guessing he means something like constexpr, but with fewer constraints -- like Lisp metaprogramming, maybe, or D's compile-time function evaluation (CTFE). 
"constexpr by default" makes more sense to me. 
That's a great point. Why should I carry the heavy burden of backwards compatibility, even for a totally new project.
Sort of. D is explicitly designed so that it's easy to port C code (not C++) into D -- for the most part, you can copy and paste without changing the meaning of the code. Understandable design choice; but like any backwards-compatibility design, it's occasionally a nuisance.
Ah, got it. But then, how would the two interact?
The Turing completeness of template instantiation is a side-effect of some other useful features. There's no good way I can think of to keep the baby but not the bathwater there. You could introduce another syntax that was like templates, but without the stuff that enables metaprogramming, and that syntax could be useful for writing Java-style generics, but either (a) you remove the existing capabilities, which I like, or (b) you have two separate template-like things, which I would find to be more complex and confusing than what we have today.
whatever dude.
I'm right now working with some third party code that includes it's own bundled copy of an ancient version of boost. The code is littered with things like this. #include &lt;boost/shared_ptr.hpp&gt; #include &lt;memory&gt; using namespace std; using namespace boost; shared_ptr&lt;T&gt; x; Grrrr.
That is probably a bad idea. It would massively increase compilation times and it may even break the library, since defines from one translaton-unit would leak into the next. A much better approach is to use a build system that makes it easy to depend on libraries. 
I'm not the one who asked for it, but: you have a higher-level language, or evaluation context for the same language, where types are first-class values. You can manipulate them using the same tools you use in your regular code (arrays, vectors, conditional expresssions, etc.), just on a different set of values. Functions that take types as parameters, and return types, etc. One approach, among many, would be to use [multi-stage programming](http://okmij.org/ftp/ML/MetaOCaml.html) -- the program is evaluated in multiple passes, with each pass refining the program until the final result is produced.
I would make all C++ member functions and their arguments const by default and you would need to mark them mutable instead if you intend to modify them.
He went into more detail in the QandA. I did a program with C++ dlls once, and if you compile release and the dependency debug it will crash. 
Don't make vector&lt;bool&gt; special, have a mutable container of bits as a separate class.
`explicit` should not be needed as a keyword -- rather it should be `implicit`. Relatedly, implicit conversion between signed and unsigned types, floating point and integer types.
Only write refs is a safer interface to passing references to uninit values.
Or Lambdas.
You can get that behavior now by using the safe numerics library. It's trivial to use. 
What does this do?
I think its possible, but people usually use swift for that now, but it used to be objective-c. Idk much about app development though sorry
&gt; The priority of &amp; | ^ would be corrected now that we have &amp;&amp; || Would you mind writing out what priorities exactly do you have in mind? 
Typo?: .... std::vector&lt;int&gt; vct = { 1, 2, 3, 4, 5 }; std::for_each_n(vct.begin(), 3, [](auto &amp;e) { e += 10; }); // vct: {10, 20, 30, 4, 5} .... Shouldn't it be: e *= 10 to match output comment?
&gt; But during function or method invocation I want to have a focus on what matters currently. I really have no idea about what you mean or how C++ is any better than Rust here. &gt; You can judge by used types - the concepts require concrete types to actually implement a said concept. template&lt;typename T, typename U&gt; concept EqualityComparable = requires(T a, U b) { { a == b } -&gt; bool; }; is a valid C++ concept (C++ concepts are expression-based). Given `N `types, and that single concept, answering the question, which concepts does a concrete type `T` implement requires instantiating that concept against all `N` types. Answering the questions which concepts do all types implement require instantiating the concept `N^2` times. &gt; First and basic example From\Into duality. One is defined as a function of the other. In Rust, types implement traits _explicitly_. If we have two traits, A and B, and a type T, where A is implemented for T, and B is implemented for all types that implement A, finding out which traits T implements is easy. You just ask: which traits are directly implemented by T, followed by recursively asking which traits are directly implemented for types that implement those traits. It is not trivial, but it is a tiny problem to solve compared to C++ concepts where you must brute-force a type (or tuples of types) into all concepts available to check which concepts a type implements. &gt; I want the ability to define meta types and behavior without going into something like AST expressions. You want something much more powerful and much more low level. Macros are text manipulation utilities. Rust macros are great at this. &gt; I want the ability to define meta types and behavior without going into something like AST expressions. This is what Rust macros do, they don't have access to type information, and they don't modify ASTs (at least not the ones from the compiler), they just modify text.
&gt; std::initializer_list&lt;std::string_view&gt; I'm actually proposing this at the ABQ meeting in November.
Funny there isn't a make_new_from_tuple for constructing on the heap. 
In some ways still having most of the old C stuff can be a nice strength of C++. You can use old C libraries. There are occasionally cases where using C style stuff might be a good choice or only choice. (I may have actually used digraphs syntax once!) . But this is rather rare, and using compiler options for warnings/errors to catch some of the more obvious pitfalls or accidental usage of weird old stuff is a pretty good idea.
Boost is something of a playground for things that will eventually stabilize and make their way into the standard library. In this case, both boost and the standard library contain a type named shared\_ptr. They include both, then do he 'using namespace' dance on both namespaces. So that everywhere they reference shared\_ptr, the compiler doesn't know which one to use.
&gt; but "working around the language" should definitely not be a big part of your experience if you are using modern C++ with a reasonable degree of mastery. I write std library like C++ code for a living. Working around the language is how writing the libraries that enable modern C++ feel like.
wow, didn't realize that earlier, so still there's an implicit conversion from array reference to pointer, reference does not exist in C, so I guess it's just const char * from the very beginning in C, and the definition changed a bit in C++, I guess it reduced the inconsistentness more or less cuz array to pointer decay works for any type of array and pointer, but there's still inconsistentness here const int x[] = { 1,2,3,4 }; auto &amp;y = x; // y is const int(&amp;)[4], supposedly similar to the type of "foo" const int z[] = y; // error! 
Let `this` be a reference then! ;)
I would, never in the world, remove undefined behavior. It's really important for performance. Would you introduce a branch with complicated runtime check each time you use a pointer? I don't think so. Also, undefined behavior is important to have so the optimizer can make reasonable assumptions about the code. However, I do agree we should have better ways of detecting undefined behavior, especially in debug builds.
I rely heavily on reference everywhere to wrap functions. So if I want to wrap a function (let's say, make_unique wraps new), I'd have to dramatically change the call syntax only for avoiding copies? Also, imagine two instance of `Point2D`: Point2D p = (ref p1) + (ref p2); And how the copy-constructor would be called? The copy constructor takes a reference. You'd have to type `ref variable` to copy it?
Results in an ambiguous `shared_ptr`, because it exists in as both `std::shared_ptr` and `boost::shared_ptr`.
As I said, I've already done in manually, so I don't have to guess whether it is a good idea or not. When used as a single .h file with the implementation switched on using a preprocessor definition, it can be put in it's own translation unit so that it doesn't get recompiled every time. Not only that, but if it is a C file to begin with compilation will be pretty fast. Then you have the advantage of compiling from source, using link time optimization if needed, including debugging symbols when you want and even putting multiple libraries together into a single compilation unit to build a project out of fewer but larger translation units, which actually decreases compilation time. 
I am way behind on this... still learning C++14
* **new** returns std::shared_ptr or better, some kind of built-in reference type, nullable or non-nullable; shared, weak or unique * single : instead of :: (yeah that would bring so many issue) * math operators: if (a &lt; b &lt; c) get interpreted to if (a &lt; b &amp;&amp; b &lt; c) * try/else or try/default construct * struct, tuple, array, all the same thing, accessing members with operator [] * [[heap]] attribute instead of std::unique_ptr and pointer semantics for local object * (a == true) being equal to (a != 0) * nested comments and so many other stuff, like having function, class and coroutine being the same thing 
These are pretty minor compared to other issues here, but lately I've been very annoyed that `struct` and `class` are different things and when forward declaring one it matters for done reason which it is. I'd either remove `struct` or just make it syntactic sugar for a class that defaults public. I'd also support multiple return types via reference somehow, or at least modify the syntax so that it's clear when you're calling a function which of the arguments you are passing in are modified. Something like `foo(a, b, c&amp;, d&lt;-)` where a and b are read only, c is read-write and d is write only. Some way to "automatically" implement PIMPL or a similar paradigm, where all the privates don't need to be declared in the public header. Lastly, a proper module type system, so making an inconsequential change in a common .h file wouldn't need to trigger a massive rebuild. E.g. adding a member function. 
Both copy constructors and `operator+` should be taking `const` references. Those would be unaffected. The only change is that a variable wouldn't be converted to a _non-const_ reference without the proposed `ref` operator. There would also have to be a few minor exceptions for things like the "external" variants of `operator++`; operators where the C equivlent modifies the operand would not require an explicit "ref". So `(ref foo)++;` wouldn't be necissary, but `foo += (ref bar);` would be, in the unusual case that `operator+=` takes a non-const reference. Also, we're talking "if backwards compatibility was not an issue", so requiring modifications to existing code isn't a problem.
Right, so the 3rd party shipped code that doesn't compile? I was conflicted because I was pretty sure that wouldn't compile, but I didn't see how a 3rd party would provide non-compiling code ... ?
Standardize the ABI. Seriously. If function name decoration were standardized we might not have to extern "C" everything, since the linked name of the function would be predictable, and then C++ functions could be called from other languages. No more silent passing by reference. The caller of a function would have to explicitly pass by reference in the arguments a la C# or Rust. And two smaller ones: also _ as a number separator instead of ', and give fixed width integer types more convenient names like u32 or uint32 for example. Yes I can typedef but I shouldn't have to. 
Also on the front-page https://www.reddit.com/r/cpp/comments/75y2e6/psa_vs_has_support_for_uniform_container_erasure/
&gt; VARIANT can take IUnknown*, so it can also have anything. `std::variant` can take `void*` too
This is a fantastic answer. So many people have never used a language with ADT's and once you do, it feels like a real oversight when a language doesn't have them. 
I guess I don't understand. You want to start paying for things you don't you?
String literals have been arrays since the beginning in C: `printf("%zu\n", sizeof "hello world");`
Ah, thanks for clarifying. Indeed, this could be a nice for knowing when a reference or a copy is sent.
I would have made class and struct differ by more than just default access, with the goal of differentiating more between POD-like things and full classes. Specifically: 1) virtual functions are not allowed in structs, and 2) classes do not get default copy, assignment, etc. If we're also including the STL then I would have added the concept of a simple range (basically an std::pair of iterators with begin(){return first;} and end(){return second;}, and a pointer+size constructor for use with C-style arrays) and then made all the STL algorithms accept a range instead of two iterators. That way the most common case of passing an entire container would be easier and the less common subset cases would still be possible. Also, I'd make (unordered_)multimap::equal_range return a range. It'd be so nice to be able to write something like: vector.insert( vector.end(), mymap.equal_range(x) ); and such a thing would a have been quite possible with the original STL with only the additional concept of a range.
* Parameters are passed as const ref by default. * Extra syntax allows passing by move. * If you really want to pass a copy, you do it explicitly by creating a copy however you see fit before a call. 
&gt; Make a filesystem API that completely handles file management (std::filesystem only takes care of finding and identifying files, but there's no I/O API that uses it yet, you need to do .u8string() or .string() to use paths) That may get proposed in 2018 https://ned14.github.io/afio/. I'm blocked on Expected, Span and a few other thing still to go to the LWG
He said for *non const* references. Your examples all (hopefully) use const references.
Which part? It is well known that one of the main problems C++ devs had when learning Rust is that they try to use Rust as if it were C++ which is exactly what I mean by "stokholm syndrome". I see on IRC all the time cases of "How do I solve this problem in Rust in this complicated C++ way". From my experiences teaching Rust to experienced C++ devs (and answering their questions) they start becoming productive when they "stop trying to write C++ in Rust". I truly belive that experienced C++ devs have no problems with the borrow checker, traits, and other Rust language features. They get those pretty quickly. What they don't get is that Rust isn't C++ and that all those ways that they are used to solving problems in C++ do not translate to Rust. It might be absurd but I even had devs chose as their first toy project in rust to implement "a compile-time list using type recursion" which is a "relatively-common" thing to know how to do in C++ if you do a lot of meta-programming but is close to useless in Rust and not at all a toy project.
The code did compile... back when there was no `shared_ptr` in the standard library. The 3rd party didn't care about future compatibility - or didn't know that `using namespace` destroys that compatibility.
copy, for small objects, is better (for performance) than const ref. And "small" can be actually kinda big. But what you really want is "do the right thing" passing. Whichever is most efficient, and if the function modifies the variable, then you wanted a copy. (That requires inlining or link-time magic, etc)
Do you need to break backwards compatibility to add that? That seems like something you could do without breaking anything. What I *would* do though is go back and retrofit a bunch of existing standard functions to use it. 
&gt; while adding a special keyword or other construct for cases when this is needed for efficiency Would this work for values in a container? That is a bit off topic to what you are suggestion because there is no way now to create a container full of uninitialized values. And I have run into a few cases where the performance hit of unnecessarily zero-ing a large vector of doubles was noticable and problematic (e.g. 100000 values, and after creation the vector is to be initialized for real by passing data() to some c-style function.)
Not in the syntax/code. In msot cases you can just remove any usages of `delete` and it'll work fine.
I'm not a mod, but phrasing things this way is unnecessarily combative, and not helpful. It turns people off, as you've seen above. &gt; they try to use Rust as if it were C++ This is a *much* more helpful way of putting that sentiment than "Stockholm Syndrome", which is insulting.
**Remove reliance on the order of definitions.** As part of this or tangential to it, remove the dependence of the parser on the meaning of symbols, the most vexing parse, the function/constructor/cast ambiguity, and the shenanigans around uniform initialization and initializer_list overloads. This makes the language far easier to parse, leading to a wider variety of tooling that's easier to maintain. It also makes things like modules much easier (see the recent thread on modules in this sub!), and removes a lot of accidental complexity from learning C++. **Make pointers non-nullable by default, and remove references.** If you want an optional pointer, say so explicitly. References are an okay workaround for some situations, but they're not re-assignable, and their interactions with type inference/decltype/overloading/etc. are unnecessarily complex. The best way to do this is probably to bake sum types into the language and redo `std::optional` to be based on them. See, again, the recent thread in this sub about how the current `std::optional` is based on a totally different mental model! **Make compiler-enforced destructive move the default.** For types where copying is expensive (for some definition of "expensive," e.g. `std::vector`) make it explicit rather than including an implicit copy constructor. If this is done right it can replace the entire zoo of copy/move constructors/assignment operators. This leads to a very different mental model, one that focuses on named *values* rather than named *memory locations*. This is important because modern compilers completely ignore most of what your program incidentally specifies about stack memory anyway, after going through SSA form and register allocation. It also makes a lot of things more natural, including all the good move-based techniques C++ has now but also things like session types and other forms of zero-cost logic enforcement. **Move vptrs out of objects and use wide pointers for virtual dispatch.** This is deeply related to things like `std::string_view`, with many of the same benefits. It greatly simplifies object layout, allows interfaces to implemented for new types after the fact, and even allows POD types to be extended with dynamic dispatch. Traditional narrow pointers can be recovered with a wrapper type in the rare cases where they're the better option.
* flip copy and move semantics * more implicit moves (dataflow-dependent move) * proper macro system * borrow some stuff from haskell: * ADTs * destructuring * newtype (same ABI etc but type errors for mismatches) * typeclasses (improved concepts?) 
stub of answer: you sort of can but it's not comfortable as far as I know: you will have to bind it to objective-c in the end through objective-c++. see e.g. [this article](https://www.sitepoint.com/using-c-and-c-in-an-ios-app-with-objective-c/).
The fact that you can't understand something is not a reason to remove or change it.
Require 'unsafe' for certain operations including raw pointers. Get rid of the 'friend' keyword. Get rid of goto and introduce better structured control flow instructions like 'defer'/'finally'/'break' to tag. switch/case wouldn't fall through automatically. Header file/code file separation wouldn't exist, i.e. a more sane linker model. That bloody semi-colon you have to put after class declaration blocks would be right out.
There already is one, and llvm speaks it. This is purely MinGW's fault at this point.
Interoperability for one.
&gt; Either classes would be allowed to be reopened to add additional non-virtual member functions later on, or it would be acceptable to declare non-virtual member functions outside of class definitions, since they don't change the structure of the class in any way. A coworker and I have often discussed how nice it'd be to add private non-virtual functions to a class. They are not part of the public interface and do not affect memory layout and therefore shouldn't need to be declared in the header. Specifically, if the compiler encounters something like: int Foo::bar(int a, int b); and class Foo did not previously declare a function 'bar' then 'bar' is implicitly a private function of the class (preferable with static linkage). No new keywords or additional syntax are needed. 
Just released version 1.2 of **Clang Power Tools**. https://marketplace.visualstudio.com/items?itemName=vs-publisher-690586.ClangPowerTools Lots of improvements and bug-fixes. Thanks for all the feedback. https://github.com/Caphyon/clang-power-tools/blob/master/CHANGELOG.md
I'm actually working on just such a language. Everyone who sets out to create a "C++ killer" ends up abandoning what makes C++ great (primarily compilation to native code). I'd link the repo, but it's just a simple lexer at this stage. It doesn't do anything interesting (yet). * Eliminate #include and #define. Add a proper package/namespace system a la Java/C#. * Use dot operator for everything. No more :: or -&gt; operators. (They can be moved to other purposes though.) * Case statements break by default. Jumps or fallthrough must be explicit. * All variables initialize to default values. Add a keyword/operator to indicate no-initialization. This also applies to return statements. * Support multiple return values. * Lambda syntax closer to that of C#. * Explicitly support int32, int64, etc. Switch the vague int, long, etc. to aliases. * Support better metaprogramming. Stop invading the templating system with complexity. * Support pattern matching and optionals. * Drop exceptions. * If possible, eliminate the pointer-reference dichotomy. There should be one way to work with addresses. * Integrate proper span support. I'd rather specify `int[]` than `int*` and `size_t`.
Hm, probably get rid of a preprocessor in favour of proper macros (like in rust or many other languages). 1st class dynamic arrays (that keep their length and don't decay to simple pointers), i.e. something like slices. And just general syntax cleanup that would be possible without the need to be 99% backwards compatible with `C`. It might've been a big selling point back when C++ was first introduced, but now it's more like a big disadvantage. The only thing that a good native language need is the ability to call and communicate with `C` code with ease, instead of being compilable by the same compiler.
&gt; This is a much more helpful way of putting that sentiment than "Stockholm Syndrome", which is insulting. It is hard because I am a member of both communities and this does not offend me as a C++ developer and I know many that aren't offended by this either. I really do belive that people in this sub-reddit are particularly sensitive about Rust, which i shouldn't be using as an excuse, but as a motivation to be extra careful. I guess it's too late already, but maybe next time.
Yes, I'm referring to `std::symmetric_coroutine` and `std::asymmetric_coroutine`, which are the library-only solutions described in n3985.
Contrary to popular belief about "zero-cost" exceptions, merely enabling them in a translation unit has a runtime cost, even if they're never used. This is the reason `noexcept` exists. Letting every non-noexcept call become a branch inhibits the optimizer and complicates the implementation of things like containers.
Can't say I agree with this one. TLS is often expensive, I think it's well understood that a global is shared by everything. Really, people should just avoid using globals in the first place.
&gt; A proper, cross-platform, compiler-change-resistant way to expose and access library interfaces, i.e. exporting functions, classes, interfaces, etc. No more wrapping GetProcAddress/dlsym, fragile interfaces that require manual version checks, maybe type identification that works across library boundaries. So much this. I was tempted to comment "Remove name mangling and use proper semantic linking" but I wasn't sure this specific issue is related to C++ legacy or ecosystem legacy. 
Some of this points remind me of [D Programming Language](https://dlang.org/).
I'm sorry you got downvoted. This is a tough one, and I wish people would be more open to this. When I first made the leap from C++ to Java/C#, I was appalled at the lack of `const` or anything like it. Marking things `final` or `readonly` protects the variable but not the data it's referencing. Over time, I've warmed up to the idea to the point where I kinda dread dealing with const correctness all throughout C++. I wonder if there is good middle ground here. Like, can we protect data without it being as heavy as `const` was?
No they're not over-engineered. That library solution is stackful. People are complaining about single implicit memory allocation in Coroutines TS, and that proposal suggests to allocate a stack for each coroutine.
Surprised no one said it. I'd remove header files (to be replaced by something better of course). 
That's true, but I think ADTs somewhat conflict with classes in terms of the type system, or at least they add a ton of complexity to reconcile the incompatible concepts. There aren't many languages with both classes and ADTs. Rust, OCaml, and Haskell have ADTs but not classes. Java has classes but not ADTs. And to some extent Python, Ruby, and ES6 have classes but not ADTs, although I would say dynamically-typed classes are different than statically typed ones. Scala was probably the first to have both... I think Swift and C# have both too, but that's about it. So it is only in the last few years that you could get a language with both. The whole point of C++ in the beginning was classes, so it's not surprising that there was no ADT support. 
make const default make references, mutation and overriding explicit remove the preprocessor and header files. add a keyword to allow the compiler to reorder members support "a &lt; b &lt; c" make "a += b + c" equivalent to "a+=b; a+=c" to avoid temporary values allow unwrapping values on for loops "for (k,v : hashmap)" add out parameters to eliminate "A a; f(&amp;a);" add fixed size integers and fix casts, make casts explicit fix vector&lt;bool&gt; probably threading/networking could use a few changes or things baked into the language, probably a standard POD message struct variant like flatbuffers/protobuffers/capnproto 
Boolean vector... 
You could use[ Qt and C++](http://doc.qt.io/qt-5/ios-support.html) for iOS
Nim does all these things except dropping exceptions (pattern matching is a macro tho, kinda)
I had always thought string literals as, they are stored in the data segment in the compiled binary, and the literal gives you the address to where exactly it is store in the data segment, so, an address, which makes it a pointer... I still don't like arrays in C, it's weird how they always make stuff ambiguous with pointers, whyyyyy? arrays and pointers are different things and the syntaxes for there 2 are almost the same in C, not to even mention there's implicit conversion between arrays and pointers, jesus christ... I wish C style arrays could just die in C++ int arr[4]; // sucks auto arr = std::array&lt;int, 4&gt;{}; // rocks I'd rather use "alloca" for low level arrays, at least it gives me VLA so, much more flexible than static arrays, also it's VLA on stack so different from std::vector which is VLA on heap int arr[4]; dumb crap, size gotta be determined at compile time auto arr = reinterpret_cast&lt;int *&gt;(alloca(n * sizeof(int))); smarter choice, size determined at run time I see no point how C++ users might wanna use C arrays
No, that would be /u/bstroustrup
I think we are talking about a few different things: 1. Single-include header file, as described in the article 2. Single-file header-only libraries (where all of the code is in a single .h file) 3. "Unity builds", where all .cpp are concatenated into a single translation-unit (You could also combine 2 and 3) I think that #1 is a good idea when starting on a project, although you should move to specific includes as your code develops. #2 is a bad for compilation times, but if the library is small then you can get away with it. I think you are referring to #3, which is a bad idea in general. It slightly decreases compilation times from scratch, but it massively increases incremental compilation times. It is unsafe to do this automatically because the defines of translation-units might leak into each-other, causing unexpected behaviour. That said, I thought it would be interesting to implement a unity build in Buck, so I made an example here: https://github.com/njlr/buck-unity-build/blob/master/BUCK 
There is a brief discussion in www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4134.pdf . N3985 uses a relatively heavy weight facility (fibers) to emulate coroutines. Fibers are cheaper than threads but still expensive. * memory footprint vs cannot call external code trade off * expensive context switch vs 'ret' or 'jmp [rcx]' for stackless * thread_local access =&gt; UB * complier can optimize coroutines: https://godbolt.org/g/26viuZ * compatibility with the third party code that can get confused when you switch stack underneath * uses exception for cancellation, not usable in environment without exceptions * cost varies dramatically across platforms. highly platform specific facility * some architectures, sliding register windows, very difficult (if not impossible to implement) 
&gt; Rust, OCaml, and Haskell have ADTs but not classes. OCaml has [classes](https://ocaml.org/learn/tutorials/objects.html#Objects-and-classes) too.
Also you have the option to use Qt and QML, and also inject some C++ if you need some extra power, use your library, etc.
&gt; it's weird how they always make stuff ambiguous with pointers, whyyyyy? For backwards compatibility with the B programming language, where `a[10];` simultaneously defined two separate entities: the pointer, and the array. DMR himself mentioned how confusing it is in function arguments: https://www.bell-labs.com/usr/dmr/www/chist.html Someone should make a question "What would you change in C if backwards compatibility was not an issue?"
&gt; I'd either remove struct or just make it syntactic sugar for a class that defaults public. But that's exactly what it is?
Good lucking getting everyone to use it though.
And [Jai](https://github.com/BSVino/JaiPrimer/blob/master/JaiPrimer.md).
These are excellent. I particularly agree with regard to move-by-default. The early days of C++ worked so hard to make things like vector "feel like any other variable", but it turns out that obscuring those heavy operations is bad for everyone. Copying a resource should be highly exceptional.
There are a few languages like this now- D and Nim are close in a lot of ways but add (optional) GC. Rust is like this if you want compiler-enforced memory/thread safety. Jai isn't released (yet?) but it is perhaps even closer. For some applications even Swift and Go would work. Also, as a fellow PL design nerd, some suggestions: * Using the dot operator for both namespaces and object access somewhat entangles parsing and semantic analysis, which complicates the compiler and makes implementing tools harder. * Default initialization is harder to optimize than just erroring on use of uninitialized variables, which is easy to detect with analysis the compiler has to do anyway. * Tuples are more general than multiple return values but just as easy to use. Always fun to see more experimentation in this area!
Yep. A language-based solution works by transforming function control flow graphs and can be implemented with zero allocations. (I'm still not sure why the Coroutines TS requires an allocation- is it just to avoid problems when coroutine objects are moved?)
&gt; Given N types, and that single concept, answering the question, which concepts does a concrete type T implement requires instantiating that concept against all N types. Answering the questions which concepts do all types implement require instantiating the concept N^2 times. The thing is - concepts define a set of constraints on the incoming type. In that regard, they are similar to the Rust traits. But the traits also allow you to define new behavior on existing types - and this when things get tricky. Let's go through the real world example I just inherited: pub fn some_function_with_app(params: StructWithParams) -&gt; Result&lt;()&gt; { // Some code // ... Err(::std::io::Error::new(::std::io::ErrorKind::Other, "app io returned failure").into()) } Why do we need `into()` here and what we kind of type I will get? A quick run inside the Rust Playground shows me that we can use it even without `into()`. But - there is also error_chain! defined. So - what I'm supposed to make of it? &gt; Not really, there might be some, but assuming that every mention of Rust here is going to get with downvoted into oblivion is a behavior that comes from accumulating experiences. Hmmm - [how about this](https://www.reddit.com/r/cpp/comments/6z4l38/unosolo_rust_application_that_converts_c/) for example? &gt; A couple of weeks ago I submitted a post about somebody writing a 100kLOC compiler in C++ as a "toy-project", which I found interesting because few choose C++ for a fun compiler project nowadays. The post was removed because the compiler compiled Rust code (the excuse was that programs written in C++ are not "post worthy" but next to it was a Windows Process Manager weekend-project written in C++ that wasn't removed). Well - I remember this [submisison](https://www.reddit.com/r/cpp/comments/71lax0/mrustc_alternative_rust_compiler_written_in_c/), and it's actually googleable. I'm sorry it's got deleted, but if both STL (who very rarely removes submissions) and cleroth both found it unworthy - I'm in no position to judge them. As for the project itself - the documentation is lacking, There are some notes - but most of them are about Rust language and correct parsing and compiling of it. There are very little for the general auditory of the C++ sub. This would be so much better if it was in the form of the blog post with explanation and quirks encountered. I know there is some discussion about implementation internals in /r/rust post, but I don't have time to go through comments there, sorry. Also - linking another subreddit post directly could affect the judgment.
It would be nice if c++ had a standard abi
&gt; expensive context switch vs 'ret' or 'jmp [rcx]' for stackless User-mode context switch is not expensive.
&gt; if you compile release and the dependency debug it will crash. This is also the case with plain C DLLs.
&gt; Pass by reference would require a prefix like pass by pointer. In fact, I'd prefer to distinguish between: "reference that is only read by the callee", "reference that is only written", and "reference that is both read and written." Check out [Pony's reference capabilities](https://www.ponylang.org/media/papers/fast-cheap.pdf). It seems to work *very* well. At the very least, this vindicates you. :)
If you want C++ in order to make it cross platform, know that the best practice is creating the UI in the platform's preferred language and the engine with a portable language. Cross-platform mobile UI solutions that are built around C++ exist. Qt and Microsoft have two of the most popular ones. But the end result is always an app that's aesthetically mediocre and usually sluggish. The top titles generally use Objective C or Objective C++ for the UI and C++ for the common back end. XCode supports this with no extra tools. Search docs for terms like "calling C++ from Objective C" and you will get you the answers you need.
I would get rid of the old broken C arrays concept. It is crappy that arrays cannot be R-values, and array-to-pointer decay is a crappy workaround that causes more problems than it solves. We should have something that behaves like `std::array` but has the nice syntax of built-in arrays. This can also lead to fixes for a lot of annoying problems around string literals, like them not being template parameters, and them binding tighter to `bool` than to `std::string` in overload resolution. It is a tragedy that we can't really fix this at this point.
Macros ignore scopes of namespaces, meaning the preprocessor will replace this word in places you thought were safe. Plus compiler doesn't see "self" afterwards, making errors more cryptic.
Why? Serious question.
The thread is about not caring about backward compatibility, just make `this` a reference.
I think C++ would be better served with a proper macro system, or with what Herb is pursuing. In Java and .NET we get some of the same features via annotations, bytecode manipulation libraries, compiler plugins and expression trees. While not as powerfull, and a bit more cumbersome, I still find them way easier to understand than any random C++ code making use to type tag dispatch or SFINAE.
"this" being a keyword works everywhere regardless of namespaces, if you want "self" to act like a keyword like "this", it actually should ignore scopes of namespaces, and the macro should be safe with the extra "()", I can't think of any exception cases that this would fail by now
Like in Ada, you have in, out and inout as possible parameter types.
So... let's consider only Linux and debunk your idea that "all of it" is backed by a file... malloc does go to mmap. It does so e.g. like you can see on line 2328 in this file: https://code.woboq.org/userspace/glibc/malloc/malloc.c.html Note that a macro MMAP is used and is defined like so: #define MMAP(addr, size, prot, flags) \ __mmap((addr), (size), (prot), (flags)|**MAP_ANONYMOUS|**MAP_PRIVATE, -1, 0) Note, further what [man mmap](https://linux.die.net/man/2/mmap) says: &gt; MAP_ANONYMOUS The mapping is **not backed by any file**... Do you understand that one can turn swap off? Do you know that people do? You claim that "all of it" is backed by a file, swap file. **How do you reconcile the two?!** Here, some [further reading:](https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Storage_Administration_Guide/ch-swapspace.html) &gt; Swap space in Linux is used when the amount of physical memory (RAM) is full. **If the system needs more memory resources and the RAM is full,** (emphasis mine) inactive pages in memory are moved to the swap space **Kindly show me your evidence that "all of it" is backed by a file.** I honestly think that you have an unbelievably bad understanding of what "virtual memory" means. And the more you write, the more I think that.
You don't need to abandon compilation to native code. Sure it is hard to implement and takes years to have a mature optimizer, but you can always shortcut it, by having a pluggable backend that can integrate into an existing backend or just generate straight C++ code.
&gt; expensive context switch vs 'ret' or 'jmp [rcx]' for stackless Context swith is O(1) operation because number of hardware registers is fixed. Your "'ret' or 'jmp [rcx]'" are in fact at least O(N*N) - depends on size of your state machine. [Here is proof of that](https://wandbox.org/permlink/NoFymxhWcpys0huE) - same computation, same algorithm, same result, but different execution time. How can you explain this with "'ret' or 'jmp [rcx]'"?
Since we're getting rid of backwards compatibility, just remove non-null pointers instead. 
Eh... Qt Windows exports a class or two. Boost Windows binaries do the same and also throw an exception or two. They also (both, I think) export template instantiation or two . Finally, they do not have insane memory management. You can buy my services if you would like to know how they do it :-)
My favorite :-). I try to never ignore it. It ain't fun :-(.
Haha, true! The insidious thing is: it can go a long way working by accident (the worst kind of "it works").
There should be `std::dynamic_bitset`, which is what `std::vector&lt;bool&gt;` is.
WinSXS really is DLL heaven, but the price for it is... well, hell :-)
The advice is simple: homogenous compiler version and C(PP)RT linking (e.g. everybody uses NDEBUG C(PP)RT) for all parties. Or horrible death :-). Or (we're on Windows after all), COM (don't underestimate COM; e.g. WinRT really is in-process COM on steroids).
No, I'd rather have `this` be a reference. No need for macros.
The advice is simple: homogenous compiler version and C(PP)RT linking (e.g. everybody uses NDEBUG C(PP)RT) for all parties. Or horrible death :-). Or (we're on Windows after all), COM. Don't underestimate COM; e.g. WinRT really is in-process COM on steroids; also, process isolation and in-houseremoting with 0 effort (Component services).
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/76580a/can_i_use_c_to_develop_an_app_for_ios_what_do/dobmd2t/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The advice is simple: homogenous compiler version and C(PP)RT linking (e.g. everybody uses NDEBUG C(PP)RT) for all parties. Or horrible death :-). Or (we're on Windows after all), COM. Don't underestimate COM; e.g. WinRT really is in-process COM on steroids; also, process isolation and in-house remoting with 0 effort (Component services).
Yup. I agree. You addressing me? Or the "everyone" I was referring to in my original post? XD I plan to support native compilation.
Yes good point. Although as far as I remember the book Real World OCaml sort of discourages them? I think there is somewhat of an issue of combining the two styles as I mentioned. Personally I think of classes for encapsulation and information hiding, and ADTs for messages / dataflow like a compiler. So even though you can see them both as generalizations of `struct` in C, they are in a sense almost opposites! But that's a good thing, I do think you can have them both in the same language, and use them both productively in the same program. But historically I think that has been hard, and C++ obviously leans towards classes by its nature. I agree it would be nice to have ADTs. I just worry that the language is so big already. Also, I think that this is one of the only suggestions that doesn't require breaking compatibility? As usual, there isn't a problem with adding features, only changing them. 
Because certain operations, like iterating over it with a pointer and such, are undefined. Since you can't take a pointer of a bit inside a byte. 
You also need to consider that context switch of stackful coroutine is typically not inline-able. This can easily make performance difference by an order of magnitude for some use cases such as implementing iterators.
Yeah I don't think you would, but if you have ADTs, then you might use `Maybe` for error handling instead of exceptions. Rust does this. 
C++ developers are by and large very conservative. But yeah I much prefer the C# approach. 
&gt; Default initialization is harder to optimize than just erroring on use of uninitialized variables, which is easy to detect with analysis the compiler has to do anyway. Elaborate. I figured SSA would make this a non-issue either way, and most people (I assume) would be fine with the base value being 0 (or `false`) for most primitive types.
:( My mother says I'm special. jk. `vector&lt;bool&gt;` must die.
Compiler one Error when you throw less than allowed is a bad Idea. The set of possible thrown exceptions is an interface property and should not be bound to the current implementation. That aside, I don't see how returning optionals everywhere would improve ergonomics as you'd have to write checks and error handling code everywhere.
Compiler one Error when you throw less than allowed is a bad Idea. The set of possible thrown exceptions is an interface property and should not be bound to the current implementation. That aside, I don't see how returning optionals everywhere would improve ergonomics as you'd have to write checks and error handling code everywhere.
Several people have said it. To me, it's probably the single most important change a new language would make. The whole forward declaration thing is a mess.
I think the discouragement from using classes in Ocaml was more about trying to break old OO habits in new Ocaml programmers. Many people picking up Ocaml would decide, "I need an abstraction here, I'll model it with classes", like they would in another OO language. But frequently, Ocaml's other data types (or modules/module functors) are more suitable solutions. Classes add power to the language, but serve more of a niche role (e.g., when open recursion is essential).
The thing is, I personally really like it that in C++ everything is copyed, because pretty much every language I know has a ValueType (struct usually) and ReferenceType (class), but that enforces the copy/move behavior on the actual object definition. Rather, I would change it all for a system which is always copy, unless you use &amp; for reference (pointer), and implement either different operator for move assignment or a move operator similar to new and delete, so it would b something like a = b -&gt; copy b to a, a = move b, -&gt; move b's resource to a. (call move operator) 
&gt; Compiler one Error when you throw less than allowed is a bad Idea. The set of possible thrown exceptions is an interface property and should not be bound to the current implementation. I just disagree with you there, at the same time I recognize most folks don't care about this. But many folks I talk to would prefer it this way. I'd like a way to opt into this static checking. I really dislike that random exceptions can just be thrown and I don't know about it. I don't know what kind of things I might need to handle. This would be my primary ergonomics improvement, at least for myself and others like me, the otherwise operator is the other one. The optionals/expecteds are less about ergonomics and more about options. &gt; That aside, I don't see how returning optionals everywhere would improve ergonomics as you'd have to write checks and error handling code everywhere. This would ideally be solved by the otherwise operator. In case of a statement throwing you'd have some default value you can use. Obviously there's no way to completely solve this. Either you're going to do your error checking as it happens, you have a defaultable value in case of the error, or you have a try block. I want to add options for the cases where a default is doable, I'm not saying I'd remove the try block.
&gt; What is the use case for this? Would you also have member functions are take an "input only" object reference? Write-only references are used to support more than one return value, without making copies ala std::tuple. Read-only references are used to avoid object copying. Read-write references are used to update state, eg increment(var) -&gt; var+=1. &gt; Would you have compile-time or run-time checks? As much as possible would be compile-time. &gt; Does this have to break language compatibility? Technically no, good point.
For primitives it's not bad, but it becomes more and more work for the optimizer the more complex the type is. It's also a problem for types that don't have a reasonable default value, like non-nullable pointers.
Sure thing. Start with: http://en.cppreference.com/w/cpp/language/operator_precedence Now move \^, |, &amp; up past &lt;, &lt;=, &gt;, &gt;= and ==, != so they sit after &lt;&lt;, &gt;&gt;. I would also add &lt;&lt;&lt;, &gt;&gt;&gt; for rotate without carry in the same precedence as &lt;&lt;, &gt;&gt;, and null coalescle ?? at the same precedence as ternary ?: (or possibly one level higher/lower.) In my language, &gt;&gt; on signed would be arithmetic, &gt;&gt; on unsigned would be logical. 
&gt; I would, never in the world, remove undefined behavior. It's really important for performance. We have different use cases, I suppose. I'd happily accept my base OS and exposed web services being a full 100% slower if it meant it was many times more secure. Computers are pretty fast these days. In practice, I doubt it'd be more than a 30% speed hit to remove UB, but I don't have stats on that for obvious reasons. High demanding desktop applications could still be written in classic C/C++ for performance. 
Compiler-enforced destructive moves are (or at least can be) just bitwise copies, because they don't have to touch the source object. The compiler just marks it as uninitialized and omits the call to its destructor. So you still get "everything is copied," you just also get "copies don't lead to double frees" if the thing you're copying owns any resources.
Yes, definitely. C++17 was set to add this with Unified Function Call Syntax, but then they gutted it to only global functions which I tried to appeal to Bjarne about and failed, and finally they gutted even the global function variant. D has full UFCS, and it works wonderfully. If they ever get the GC 100% out of the core language, I may seriously have to consider switching.
Remove all the platform depentness and whatnot regarding the different integer types. Why not do the same as Rust? UInt8, Int8, UInt16,Int16,UInt32,Int32,UInt64,Int64 and USize and Size? Also, add Optionals like Swift has them, also add Protocols similar to Swift again. Next, make references default to immutable, but mutable (but not deletable!) by adding mut to them. Similar to Rust. Make copy and move keywords and make Protocols Copyable and Movable. So by default Copy, but move if explicitly called with move. (Similar to operator new and delete), so a = b, actually is a = copy b, which calls b.copy(), and a = move b, which calls a.move(mut b) Also create a default ARC like system similar to Swift so we can leave away the ugly shared_pointer syntax amd integrate it in the language itself. But make this optional for a class (or struct or union) to use by inheriting from a ARC protocol, which has default implementations ofc. Add generic enum types would be great too! And do something about header files and stuff please, it's just too much work. But keep the ability to implement the actual method or function inside another file. Add extensions like Swift! They're absolutely amazing!
Yes, I know. It's just that the way the syntax is now it is not immediately clear for the caller what happens. They have to actually check this, especially when there are function overloads for non movables too. Too much syntax is identical right now. While you get used to it, it's still annoying as hell sometimes
I admit I'm heading into this with little experience in compiler implementation, but I'm enjoying learning all about it. I was just gonna make my design decisions and eat the costs of those decisions down the road. XD I'm sure I'll eventually have to backtrack on a few things, but I wanna see how far I can take it.
&gt;A replacement for DLLs which does provide this functionality would be welcome; I note that Windows 10 now provides a native ELF linker for the Linux subsystem, and wonder if it couldn't be repurposed to allow ELF shared library loading for Windows. You can't use ELF shared libraries, since WSL is Linux. You don't need a replacement for DLLs, you just need a standardized ABI. With MinGW you get better cross compiler (version) interopability, since GCC and Clang use the Itanium ABI. (Though Clang can also use the MSVC ABI now.) With both MSVC 2015 and 2017 no ABI breaking changes have been made though, they might be working towards a more stable (and hopefully publically documented) ABI.
I'm saying that the article is about 1, and I hoped it would be about 2 and 3. &gt; 2 is a bad for compilation times, but if the library is small then you can get away with it. I explained why I don't think this true, and based on my experience so far it isn't. If you have a library as a dependency and you can compile it from source you have the option to either compile it in a translation unit or compile to to a link time optimization intermediary. Either way, it doesn't need to be compiled over and over. I also think that unity builds have a lot of value, though everything in to one translation unit I feel is extreme. With multiple logical cores, I think it makes sense to have that roughly that many fat translation units. If libraries and infrequently changed areas are sectioned off in to their own translation units, you don't pay the price every time you compile. 
Since the comment form throws an error at [Visual C++ Language Conformance](https://docs.microsoft.com/en-us/cpp/visual-cpp-language-conformance): &gt; P0292R2 constexpr if-statementsVS 2017 15.3 G &gt; G Supported under /std:c++14 with a suppressible warning. Side note is wrong: constexpr if requires C++17 and it was not a warning but "error C4984: 'if constexpr' is a C++17 language extension".
Here you go template &lt;typename T, typename Tuple&gt; auto make_unique_from_tuple(Tuple&amp;&amp; tpl) { return std::apply( [](auto&amp;&amp;... xs) noexcept(noexcept(std::make_unique&lt;T&gt;(std::forward&lt;decltype(xs)&gt;(xs)...))) { return std::make_unique&lt;T&gt;(std::forward&lt;decltype(xs)&gt;(xs)...); }, std::forward&lt;Tuple&gt;(tpl)); }
Destructive moves are fabulous. I super want them in my PL.
Thanks. I see the word "stackless" used, but do I understand correctly that the stack frame for the particular resumable function is preserved? The only thing avoided is the parent call stack. So "stackless" doesn't really mean stackless, or am I misreading? Automatic variables still retain their value upon a resume.
They need space to keep the FSM state and local variables.
1. Not sure what your example is illustrating. I am pretty certain that jmp [rcx] or combination of `ret and `call [rcx]` is less expensive than: https://github.com/mirror/boost/blob/master/libs/context/src/asm/jump_x86_64_ms_pe_masm.asm 2. thread_local. compiler backends for architectures where thread_local access is expensive are caching the address of a TLS page in non-volatile registers to be used within a single function for cheaper TLS access. If many function call below, you suspended a fiber and later resumed on the different thread, that cached TLS page value may point into memory that is no longer there.
&gt; it doesn’t even guarantee that destructors are run for variables at the end their respective scopes This is a gross misinterpretation of the issue. When a variable's scope ends, it's destructor runs, period. The times a destructor isn't run are things like: * You put it in a refcounting cycle. C++ also has this problem. * You handed it to a never-ending thread which you lost track of. C++ also has this problem. * You moved it into `mem::forget`, redirecting its scope into that function's body. This is always explicit in the source code and C++ has equivalent functionality, e.g. `unique_ptr::release`. So you're correct that the compiler doesn't prevent leaks, but it's not due to some bogey-man problem with destructors being unreliable. It's just that any sufficiently general programming language allows you to express that a value's scope doesn't end.
Define separate syntaxes for uniform initialization vs. list initialization, so that list initialization does not sneakily take over when one intended for the use of uniform initialization. For example: ``` A a = {1, 2, 3}; // always list-init A a{1, 2, 3} // always uniform-init ``` Heck, I'd be happy if `A a(1, 2, 3)` was just now uniform initialization, rather than 'it's complicated' initialization.
The first half of this talk gives an overview of stackless vs stackful: https://llvm.org/devmtg/2016-11/Slides/Nishanov-LLVMCoroutines.pdf Stackless is used to indicate that coroutine does not own a stack, it is run on the stack of whatever thread has resumed the coroutine, vs. stackful that carries its own stack around and requires to swap in its stack whenever it is resumed and swap it out when it needs to yield control to a different stackful coroutine or yield back to the originating thread. P.S. I dislike stackless vs stackful terminology as it tries to unify two very distinct facilities "generatlized functions" aka coroutines and lightweight user mode scheduled threads aka fibers under a single name. 
Haven't seen this one yet: **I'd make compilation units function similar to C#**. Rather than the current soup of declaration duplication and implementation spread over .h/.cpp, I'd have a single file, with all definitions mentioned only once, no restrictions on definition ordering etc. Extend public/private to also work on top-level functions/variables (default private). Leave showing me the public API of a unit to the tooling, much like in C# (presumably the compiler would output a standardized file format that contains the interface definition, similar to .class (but without bytecode :), which would sit parallel to your .o files). No silly one definition per file restrictions. Others already mentioned: *const default*, nullable types, safe unions.. multiple return values :) Something like *string_view* (and more generally, array_view, i.e. pointer + size_t) as the default way most APIs deal with things that are currently pointers. Maybe as a built-in language feature for brevity. I don't agree with people asking for raw pointers, unbounded arrays, and other C features to be taken away entirely. That is what makes C++ what it is. If you'd remove these things, you're better of scrapping C++ in its entirety and just use Rust (with more C++-like syntax?).
That doesn't require an allocation- it can be done with anonymous types, like closures. Analogously, you only need an allocation for closures if you want to e.g. pass any closure to a non-template function.
&gt; uses exception for cancellation, not usable in environment without exceptions Right, the exception is to force the stack unwinding and destruction of automatic variables. What is the mechanism used in this TS? I didn't see it discussed (maybe I missed it?)
In general, sorry if I misunderstood you.
For sure! Good luck and I'd love to see what you end up with.
Yes. Move is one example. Note that Coroutine TS does not require an allocation. It allows it when needed. 
When non-copyability is a property of the type, and implicit copy/move are both just bitwise copies at runtime, this is not an issue. You can't have separate overloads for copy vs move and you can't accidentally use a value after it's been moved. Instead, you make deep copies explicit with some kind of `.clone()` method and then you're back to knowing exactly what happens just by local inspection of the code.
&gt; Haven't seen this one yet You're neither the first one to make this suggestion nor the first to say "wow no one has mentioned this yet". Yes, moving away from the insanity that is the C/C++ build system would be amazing for everyone.
&gt; I'd happily accept my base OS and exposed web services being a full 100% slower if it meant it was many times more secure No UB != more secure. This is a false sense of security. There no UB in PHP, Java, C# but a huge number of application written in those have humongous security flaws. Security is a matter of quality of implementation *and* quality of design, and thorough tests. For example, global atoms in windows are designed to be insecure (by accident) but has no undefined behavior in them. Also, If you want to completely remove it, expect to double memory consumption and at least 150% to 200% slower, and I'm pretty sure that some hot loops could become easily 1000% slower. If you want to sacrifice efficiency for no undefined behavior, you should try C# or java. They do what you asked for, with the tradeoff you asked for. They'd just need a compiler that compiles down to machine code and I'm pretty sure an OS could be made using those. However I'm curious about why you think C++ need to be like those language in that regard, especially if those language already exists. What would be the use case?
You won't be able to write `Future coroutine(X x);` and use a coroutine from another TU.
Because it's not a vector and does not contain bools. It does not even satisfy Container concept. The class itself is useful, it just should have been names differently.
Null pointer undefined behavior is probably not the greatest example of undefined behavior being beneficial to performance. You can prevent null pointers entirely at compile time just by excluding null as a valid value from the type, and recovering the "optional value" use case with another type that forces *the programmer* to write the checks in only the places they're needed.
coroutine_handle&lt;&gt;::resume() -- resumes the coroutine from the current suspend point. coroutine_handle&lt;&gt;::destroy() -- destroys all of the objects alive at the current suspend point and frees the coroutine frame (if dynamically allocated) LLVMCoroutines talk shows how it is done in the clang/llvm. Conceptually, resume is a big switch jumping to various parts of the coroutine to continue execution, so is destroy, a big switch running different sequences of destructors depending on your current suspend point.
&gt; No UB != more secure. This is a false sense of security. There no UB in PHP, Java, C# but a huge number of application written in those have humongous security flaws. ...but none of those security flaws have anything to do with null pointer dereference, use after free, use of uninitialized values, buffer overflows, etc. That's a huge class of bugs they've eliminated. So yeah, getting rid of UB doesn't make you 100% secure. But it *absolutely* makes you *more* secure.
That is correct. You can provide an allocator that coroutine machinery can use when it needs to allocate and it frees not to use it at all when allocation is not needed. Usually when lifetime of a coroutine is fully enclosed in the lifetime of its caller. You cannot get the "magical lambda" that coroutine machinery has build for you. There were talks of some kind of decltype on a coroutine to get that type back, but, nobody came up with a concrete proposal.
The same problem applies to closures, and the same solutions apply as well: a) Allocate *explicitly* and *only when crossing TU boundaries*, or b) Put the code in a header or module so the type information can propagate.
upvote for deep C++ reference... 
I didn't talk about null pointers at all. I talked about pointer in general. think about this example: auto a = new int{4}; delete a; std::cout &lt;&lt; a &lt;&lt; std::endl; If these three lines are in different TU, and happens only on certain condition, it's really hard to check. If there is no undefined behavior, the program would have to stare a huge dynamic table of all pointers in memory and if they are valid to use with a particular type. That table could take up as much as memory as the rest of your application, only to remove undefined behavior. Also, accessing a pointer would be O(log(n)), where n is the number of all pointer in the memory of your application.
As a rough estimation, you can switch on UBSan and Asan and enjoy slowdown. 
That's truly unfortunate. There's no reason it needs to work that way.
https://github.com/TheBuzzSaw/KellyScript This is where development will happen. Again, it's not functional yet.
get rid of `-&gt;`
That's not the only alternative. You can still *reduce* quite a bit of undefined behavior with the kind of system I described, leaving in use-after-free. Further, you can eliminate use after free with something like Rust's ownership and borrowing system. None of this costs anything more at runtime than the C++ UB solution.
I'm pretty sure use after free is still undefined behavior in rust. The *has a drastically smaller amount of UB* is not that dereferencing a invalid pointer is still UB, but happen less often because of compile time checks. I'd break C++ compatibility to enforce more compile time checks a bit like rust and providing better tools to avoid cases where UB would happen, but removing undefined behavior is preposterous in my opinion.
additionally: if you see something in experimental namespace it means a) it is in Technical Specification, not integrated in C++ b) more importantly - it may not be implemented by other compilers :(
As I wrote in the other thread, I'm pretty sure using after free in rust is still undefined behavior. But rust has compile time checks. I'd break compatibility to add more tool to enforce security a bit like rust, but I would not remove undefined behavior.
There is a reason. :-) The reason is that nobody was motivated enough to find a solution, prototype it and proposed to standardization committee. I initially poked around and was not able to find an acceptable solution. That does not mean that somebody else cannot come with a solution. llvm/clang implementation is open source, C++ standardization process is open as well. Hack away!
"a big switch running different sequences of destructors depending on your current suspend point" sounds an awful lot like the machinery for exceptions. So a user can disable exceptions but the compiler is emitting substantially similar code? Isn't that a distinction without a difference?
[This](https://stackoverflow.com/questions/10779283/when-should-objects-be-used-in-ocaml) SO answer sums up why the use of objects (classes are a slightly different beast in OCaml) is discouraged.
You're right that user after free is still UB, and that it's reduced (and eliminated in safe Rust) by compile time checks. And to be fair, this is probably the most important aspect of it- safe Rust cannot invoke UB on its own. But there are also far fewer things that are undefined to begin with: https://doc.rust-lang.org/reference/behavior-considered-undefined.html * It all fits on a single page. * It doesn't say anything about integer overflow. * It doesn't say anything about evaluation order or sequence points. * It doesn't say anything about not returning a value from a function. * The language itself doesn't include any way to access uninitialized variables. * It doesn't say anything about loops. * It doesn't say anything about initializing statics in functions. * It doesn't say anything about multiple definitions of inlines/templates. There's just a lot of gratuitous UB in C++. Before C++11 it was undefined behavior not to end your source file with a newline!
const(or let)/var instead of const auto/auto 
It isn't related to C++ - it is an OS and specifically Dynamic Linker problem. Name mangling is just a way of making C++ symbols unique while still fitting in the dynamic symbol table for each respective OS. 
When I started using the detector idiom, it really cleaned up the errors for me. Put the guarding static_assert up front. And within the first 1/2 screen usually the nice plain text reason why your type cannot be used is presented.
Fair enough! I'm just speaking from an implementation perspective, and I have seen coroutines in other languages that don't allocate.
get rid of the C preprocessor and substitute it with a sane way to write macros and with a module system to import libraries without using includes and headers. 
Yeah, there was an [article](https://developers.redhat.com/blog/2017/03/10/wimplicit-fallthrough-in-gcc-7/) about it.
Yes! Been waiting for more talks about things like Vulkan: not a whole lot of them yet, and I've been wanting to hear more (just *more* in general) from people using these low-level APIs and what their approaches have been plus, getting the abstract high-level interface in-place for these APIs takes loads of experimentation and work to balance power with accessibility 
I have had to reimplement a few containers/algorithms because of missing constexpr. std::array isn't always all contexpr when it should be. Then things like a vector/stack that is bounded and on the stack. This is mostly C++14 though.
I know WSL is Linux. Linux (the kernel) supports multiple binary formats and linkers (`binfmt`). You can even plug in PE-COFF if you want; it's not difficult. Windows Win32 could do the same for ELF loading if they wanted; the pieces are mostly there. You do need a DLL (COFF) replacement (or improvement on the existing spec). It doesn't support weak/vague linkage, and you need that to avoid ODR violations.
Make the grammar better, IDK how to do that, but D has reasonable grammar and IIRC Alexandrescu said every C++ compiler needs to read every C++ source like 6 times and D only once(he was not talking about repeated includes).... aka it is not just textual inclusion that is the problem
The same problems exist for C++ shared libraries ELF based platforms. You can't build a .so with clang/libc++ with a function that returns a std::string, and expect to load it into a gcc/libstdc++ executable and get that std::string. And you can't build a C++ plugin .so on e.g. Ubuntu 12.04 and expect to be able to load it from an executable built on gentoo. You can't build an executable with -fno-exceptions and expect that the library you linked against which uses exceptions heavily will work properly. I think the reason we don't see more problems is the fact that Linux systems generally only have one copy of libstdc++ to work with, the copy that comes with the distribution, and everything in the distribution was built against it using the same set of distribution-provided compiler options. And that aligns with the comment he made about using DLLs for modularization - as long as you can ensure that you're using the same compiler/runtime/options for all of the modules in your system, you should be OK. In practice library distributors mostly do what he describes in the talk: they build their "debug" and "release" C++ libraries against specific versions of compilers, distribute them, and then cross their fingers and hope for the best. For Windows distributors, that means building against all of the MSVC versions, and for Linux distributors, that usually means building against specific distributions (e.g. RHEL x.y) or noting the version of gcc that was used.
Yep. That is the talk. One is equivalent of: 1: bla1 return; bla2 Another is try { bla1 throw cancelled bla2 } catch (...) { } It would be nice if compilers can optimize the latter to be as efficient as the former, but we are not there yet. 
fix decltype parenthesis [abomination](https://stackoverflow.com/a/3097814/700825) fix decltype(auto) abomination - just because combination of 2 keywords is unused does not mean you can not introduce a proper new keyword maybe replace typename with type and use type as "metafunction" instead of decltype replace constexpr with something shorter, esp now when it is creeping into user code a lot.
I'd go one step further and remove _files_. All that code could just as easily sit in a database, with each entity being a separate record (or actually two: a declaration, and a definition). The database would continuously track dependencies, so the build system wouldn't have to start from scratch figuring out what it is supposed to do this time. We wouldn't need header files, or modules, we would never worry about ODR, and builds would be massively faster than today. 
I am very interested. Can you point to some information about those languages?
I'm a little unclear why an iterator could not point to an individual bit though. Is there a requirement that an iterator _must_ be a pointer? Couldn't it be a pointer + a bit offset? 
 #define this (*this)
In my coding life: if constexpr is having the greatest effect. We're using it to make our code even more "C-preprocessor macro" free and to make compile time choices on type logic. If I could only get modules and metaclasses my life would be so much easier.
That's true. There is too much stupid way to invoke undefined behavior right now where it's completely unnecessary. Also I didn't knew about the new line thing, that one is funny!
&gt;Would you have compile-time or run-time checks? This would either put a lot of restrictions on the language a'la Rust or degrade efficiency. While some are unavoidable without massive performance loss, quite a few can be either avoided entirely, or largely mitigated by proper warnings. 
Absolutely agree. Possibly someone could make a clang plugin for this? Could be an interesting research experiment.
&gt; Is there a requirement that an iterator must be a pointer? The main point of `std::vector` is assurance that elements are stored in contiguous memory. So, for every type *except* `bool`, I can feel confident that `&amp;myVec[i + 1] == &amp;myVec[i] + 1`. But because of the specialization of `vector&lt;bool&gt;` as a bitstring, that invariant doesn't hold. In fact, I can't even do `&amp;boolVector[i]`: boolvec.cpp:16:23: error: taking address of temporary [-fpermissive] std::cout &lt;&lt; &amp;bvec[3] &lt;&lt; std::endl; 
I don't really understand how writing your unit tests for your public methods only is an abuse of access specifier. In my opinion, this is the proper way to do unit-testing. You really shouldn't be testing private members. These are implementation details that are potentially open to changes and these should not affect your public interface. Clients are not going to call private member functions. The answer is in the name: unit-testing is for testing units, not implementation-detail private functions. Otherwise, the process would be called function-testing. I would say that using the preprocessor to work around the issue of testing private members is very bad since that is a definite abuse of a language feature. Unit testing through the public interface is common across OOP languages, whereas unit testing through preprocessor hacks is not.
I'm not sure of it, but as far as i remember it there was some pointer thing that you couldn't do with it. And even then, what if you'd write a generic function which would manually iterate over the vector and dereference the pointer? It's a nasty exception to the rule, and that means it can cause all kinds of issues when programmers don't expect them 
* Member functions default to const, require mutable keyword (like how lamdbas do it) * I'm thankful for the STL but I would change SO MUCH of it. No vector&lt;bool&gt; specialization, more things using Eric Niebler's stateful algorithms, every designed to be very testable (not for the sake of testing but to make every dependency a parameter). * constexpr is finally being expanded to the level I want. I want to never need to generate code that isn't natural C++ (template metaprogramming, whatever code gen tool you use) * The ability to query the compiler about ANYTHING about a type and how it is being used. * Declaration order. I want to put the important functions first without a big block of forward declarations.
While I completely agree with that, I would like to point out that this is UB: int f () {} // UB We could easily mitigate this, by adding an attribute [never_reached], and mandating a diagnostic if the compiler finds a path that ends without a return statement and without the attribute. isspace (128); // UB Seriously? This could be mitigated by a single cast to unsigned char inside the function. Don't tell me that is already too much for your performance-sensitive applications; the next thing it'll do is a table lookup, which if you're unlucky will take ~200 times longer than the cast itself. Actually a non-table solution could very well be (much) faster anyway. i = i++ + 1; // UB Surely the compiler is aware that this counts as UB? Why not forbid it entirely, then? 
I do admire your persistence, but you really need to go study the Linux kernel source code or much better the FreeBSD kernel source code, not glibc. And ignore the man pages for Linux, they are not tightly worded to be entirely accurate. The BSD man pages are much better written when it comes to accurate wording. Furthermore, Linux unfortunately engages in gratuitous overcommit in most distributions, permitting you to commit memory far beyond what is available. But the fundamentals are the same for any unified page cache kernel, and this is what I describe now. The sum total memory available to a kernel for allocation is the sum of the physical RAM, swap files and mapped files minus device allocations for say graphics. When you call `mmap`, the request will be satisfied either from physical RAM, a swap file, or a mapped file. It cannot come from anywhere else. Entirely separately to allocation is *caching*. The physical RAM is used for caching the swap files and mapped files so access to them is quick. As a gross oversimplification, an ordered list of 4Kb pages ordered by most recent use is kept. The less recently used is a RAM page, the more likely it will be for its contents to be replaced with an item in the swap and mapped files which is more recently used. Therefore there is no such thing as a RAM page not mapped from a file. `mmap` always returns cached file data. Always. It is literally the exact same code in your kernel if you kernel is a unified page cache design (Windows, Linux, OS X, FreeBSD at least). You can go check these by studying the kernel source code if you like. Your apparent understanding of things would be more accurate on a non-unified page cache kernel like OpenBSD or QNX. There memory is not always backed by a file, there are separate chunks of kernel code which implement file mapping and it is distinct from virtual memory management. So you are not incorrect for those sorts of kernel. But you are for the major operating systems. Perhaps what confuses you is that the swap file is smaller than the physical RAM size? That's purely an optimisation to save on disc space. It is more accurate to consider the total swap file to be physical RAM + all the swap files. In other words, physical RAM is treated as just another swap file. The kernel VM machinery makes no distinction.
That's for sure ridiculous example of UB. I agree that most of these instances should be removed entirely.
Keywords should begin with a lower-case letter, and identifiers should begin with an upper-case letter. Then when a keyword needs to be added to an updated version of the language, there will be no possibility of name clashes. 
Here's a list of the Core Language papers being implemented in 15.5. (Note: Some may not be present in Preview 1, like noexcept in the type system. Everything should be present in Preview 2, I think.) You can use wg21.link to look up papers, e.g. https://wg21.link/P0003R5 . * N4268 Allowing more non-type template args * N4295 and P0036R0 Fold expressions * P0003R5 Removing dynamic-exception-specifications * P0012R1 Adding noexcept to the type system * P0035R4 Over-aligned dynamic memory allocation * P0245R1 Hexfloat literals * P0386R2 Inline variables * P0522R0 Matching template template-parameters to compatible arguments Here are the Library papers we've implemented: * P0003R5 Removing Dynamic Exception Specifications * P0005R4 not_fn() * P0033R1 Rewording enable_shared_from_this * P0083R3 Splicing Maps And Sets * P0174R2 Deprecating Vestigial Library Parts * P0302R1 Removing Allocator Support In std::function * P0358R1 Fixes For not_fn() * P0414R2 shared_ptr&lt;T[]&gt;, shared_ptr&lt;T[N]&gt; * P0497R0 Fixing shared_ptr For Arrays * P0508R0 Clarifying insert_return_type * P0521R0 Deprecating shared_ptr::unique() * P0607R0 Inline Variables For The STL * P0618R0 Deprecating &lt;codecvt&gt; If you find issues with anything here, please report it *immediately*. By the time Preview 1 is available, we are highly locked down and it is possible but difficult to get fixes in for the final update.
I entirely agree. But proper macro systems (cf Lisp) *are* typically Turing complete (and hard to make non Turing complete without making them artificially restricted).
If you allow developers to add functions into std classes, you'd be blocking any further expansion of those classes by the standard since any function the standard adds would potentially break compatibility with lots of programs. It's the same problem you get with adding new keywords: the global namespace is basically already taken by application code, so the standard cannot add new keywords to it. Giving programmers the tools to cause the same problem in the std namespace is a very bad idea.
I imagine because `this` already behaves like a reference anyway, in that you cannot just reassign it. Besides, 20 years of programming C++ has conditioned me to think of pointers as potential sources of danger (they might dangle, or just be nullptr), while references somehow seem to escape those problems. Yes, I know it's not true, but in practice it usually works out that way... 
I'm pretty sure enabling exceptions does not alter the non-thrown calling path (minus the actual checks before throwing such as `if (index &lt; size()) throw out_of_bounds;` but you'd have those implemented anyway with an optional/expected style). Noexcept exists to solve a different problem which is creating unwind information where it is unnecessary and providing a way for the compiler to know to terminate early instead of unwinding. Zero cost exceptions are implemented by using the `.ehframe` sections and having an unwinder handle the raw exception, then load the frame unwind information for each frame until it reaches the frame with the catch block. This information is not loaded or used until an exception is raised - this is why exceptions are not good for code that needs a fixed runtime because this data is typically not hot and will actually have to be fetched. I can't find the slides yet but this was brought up and explained in the CppCon presentation titled [C++ Exceptions and Stack Unwinding](https://cppcon2017.sched.com/event-goers/9b44c21f27aa816cde0958a0f195f02d)
&gt; People keep asking for this, and I never understand what benefit it would bring. The ability to pass C++ objects across DLL interfaces, for one thing, without immediately requiring the DLL and the calling application to be compiled with the exact same compiler, using the exact same settings. But I'm not holding my breath for that one. It would be massively useful, but unfortunately also massively difficult to achieve... 
I'm familiar with how zero-cost exceptions are implemented. The problem is not the `.ehframe` sections- it's the additional edges in the control flow graph that leave and, especially, *reenter* the non-throw path. Before the optimizer runs, this doesn't matter, which makes it feel fairly zero-cost. But when the optimizer goes to analyze the code, those extra control flow edges invalidate some assumptions it could otherwise make (e.g. load and store optimizations), forcing it to be more pessimistic about things (especially values that could be aliased). The "terminate early instead of unwinding" thing is just another way of putting this. If you know you can terminate early on the callee side, then you also know you can ignore the possibility of branching to a landing pad on the caller side.
&gt;I'd like a way to specify that a function only throws these types of exceptions This was not a great success in Java or in earlier C++. And it makes adding a new exception type, deep in your code, virtually impossible to do.
Earlier C++, and I assume Java, did the checking dynamically. This would be static. It'd be like declaring a new argument and not passing it. Or a return type and not returning it. I'm not saying everyone would use the feature. But I would and I would be happy. As of now I don't use exceptions beyond allowing the program to crash when they're thrown. 
&gt; Not sure what your example is illustrating This is not my example, it is your example and it shows that 1) compiler is not capable to optimize stackless coroutines from stackless coroutines TS; 2) growing state machine does hurt performance, this **never** happens with **stackful** coroutines. With stackless coroutines TS you pay for each level of abstraction. &gt; https://github.com/mirror/boost/blob/master/libs/context/src/asm/jump_x86_64_ms_pe_masm.asm Very impressive indeed. Is it written by someone or just copy-pasted from `::SwitchToFiber`? Is it faster than one call malloc? &gt; suspended a fiber and later resumed on the different thread Seriously? 
C# readonly means that the reference cannot be changed to point to a new object. So C# basically only has `T * const` or `T &amp;`. It is really only a limited form of what C++ provides. C++ provides the additional features such a `T const &amp;` (aka `T const * const` though but again they are completely optional! You could totally write an entire library without the const keyword. I'm not sure why the language shouldn't have a feature just because some people are over-using it (often correctly).
&gt; After C++11, calling empty or comparing size to 0 can be used indifferently. This isn't completely true. With VS, `vector::empty()` produces slightly more efficient codegen than `size() == 0` for arcane reasons. Stylistically, `empty()` is clearer. &gt; All standard containers provide a max_size() method that return returns. &gt; the maximum number an element that the container can hold. of elements. max_size() is the silliest function. It's barely useful within the containers themselves for overflow checks, but I don't think anyone else should call it. &gt; can be instantiated with an custom allocator a. &gt; STL allocators are rarely customised anyway. I wish!!! &gt; (with value-initialization) Nobody knows what this means, in a non-expert-level article. &gt; the resize method, that take a size parameter takes. &gt; Capacity is defined for vector, deque and string. Not in this universe, where `deque` lacks `capacity()`. (It has `shrink_to_fit()`, though.) &gt; For that call the reserve() method before inserting into the container, and pass it the capacity it should allocate for. DANGER - this is the one way to trigger quadratic complexity in vector. Anything talking about `reserve()` should mention this, so people don't go crazy with it. &gt; The solution depends on whether your compiler is C++11-compliant or not. Such outdated implementations are bad and should feel bad. &gt; which consists in swapping of. &gt; Note the use of the vector’s range constructor (the one that takes a begin and an end), and not the copy constructor. Using the range constructor guarantees that only the container’s elements are actually copied, and not the whole capacity. The capacity isn't part of the salient value of a vector, and the copy constructor ignores it. (The Standard doesn't really talk about the capacity during copying, so in theory this isn't absolutely guaranteed, but in practice that's what will happen.) &gt; (this applies mainly for old string implementations using reference counting). Agh, I wish articles didn't complicate themselves by talking about stuff that's 6 years out of date. &gt; template&lt;typename T&gt; void shrink_to_fit(std::vector&lt;T&gt;&amp; v) { std::vector&lt;int&gt;(v.begin(), v.end()).swap(v); } That's buggy.
The one I'm most familiar with is Rust, which has early experimental support for generators. There, a generator is a value of an anonymous type, much like a closure, which contains the current state and the local variables that live across suspension points. These values implement a `Generator` trait with a `resume` method. Each time it is invoked, it accepts as an argument the value for the corresponding `yield` to evaluate to, runs the generator to the next suspension point, and then returns either the yielded value or the final result, using a sum type to disambiguate. Invoking `resume` after the final result has been returned is an error. This means there's no need for a promise/future object (though that can be built on top of this setup), and no need for allocation unless you want to erase the anonymous type and use dynamic dispatch. One issue that arises is how to deal with pointers to local variables that live across suspension points. The current implementation simply disallows this; in the future such generators will likely be marked immovable (and non-copyable). C++ could automatically implement a move constructor that fixes up the pointers.
I found this page to be incredibly helpful https://lewissbaker.github.io/2017/09/25/coroutine-theory I am warming up to this now. I see there are benefits to compiler integration.
&gt; I'm still not sure why the Coroutines TS requires an allocation- is it just to avoid problems when coroutine objects are moved? An allocation is required to hold all automatic variables in the same scope or parent scope of any yield point. If no automatic variables share the same scope or parent scope of any yield point, then no dynamic allocations are required.
I would take the new filesystem API and make it use a filesystem object type with most of the interface as virtual, allowing custom filesystem types. These could, for example, be passed into a library that requires filesystem access to load assets, so that they could instead be loaded from packed data files or a networked filesystem. I would remove almost all implicit type conversion. Exceptions for stuff like casting from non-const to const versions of things, or using some values as zero or non-zero for conditionals. Finally, and something I think a lot of people here would disagree with, is that I would change the syntax of variable declarations so that all of the type is represented before the variable name. For example, when declaring an array of 10 integers, we now use "int foo[10];" but I would change it to "int[10] foo;" or similar. Having the type information spread out over the entire declaration is messy and annoying to parse, imo. It also leads to ambiguity like... "int* foo, bar;" which, to a new user, may resemble a pair of pointers instead of a pointer and an int. This would also clean up function pointer declarations, which right now have the name in the middle of a large and visually confusing declaration. To be fair, I would apply these changes to both C and C++. Obviously the filesystem thing would be totally different, but I would go with the same idea.
Yay, the color icons are back! :-) Also, it produces faster code, faster. That's good too ;-)
constexpr is too strict to have by default.
1. There is a copyright at the top of the file. It has written by Oliver Kowalke, maintainer of boost:::coroutine. That code is not copied from SwitchToFiber. It is what is used by boost::coroutine to siwtch on amd64/windows. It has many more instructions than a simple 'ret' instruction that is used to suspend a stackless coroutine or call [rcx] to resume. Hence the reason for stackless coroutines having much cheaper suspend/resume than boost::coroutine. Other platforms have cheaper switches, but, all of them have higher overhead than suspend/resume of a stackless coroutine. Whether it matters to you or not, depends on the problem you are trying to solve. 2. Not sure what do you mean by 'Seriously?'. In case I was not clear. Consider this example: https://godbolt.org/g/BQXSHq In function `foo`, the beginning of the TLS page is read only in the very beginning and cached into non-scratch registers, after calling a function `function_than_can_switch_thread()`, TLS page address is not reloaded and `r5` and `r6` refer the cached values that point at TLS of a thread that started execution of the `foo`, but, not the one currently running. For all you know that page has already been unmapped and not available. 
unique_ptr needs to be language, not library. shared_ptr also maybe but I think it should not be used often so... unordered_map needs to have shorter name... 
Why array to pointer decay? That's perhaps my favorite hallmark of C. Probably my favorite sugar.
One more thing: I would make what is basically an automatic typedef for a class's parent class within the child class's scope. Similar to Java's "super" keyword. Unreal 4 already adds this in for UObject-derived types as part of its code generator, and it's pretty nice. The idea does have some complexities with respect to multiple inheritance to work out, but multiple inheritance is already something we have to use with care as it stands now.
What's an 'out parameter'? Give an example.
Why would you get rid of the friend keyword? Although it obviously shouldn't be used a lot, it is certainly useful in cases where you only want an internal class to be able to access functions and variables of another class, especially for public libraries and API's. Otherwise you have to do workarounds.
Because if we make a library function that operates on a std::vector&lt;T&gt;, it may or may not be broken depending on if the user provides bool as T or not.
*Replace the iostream library* Doing any kind of string formatting or parsing is painful, and worse than in C. Boost::format makes it much more usable, but there's still lots of rough corners. *comprehensive string conversions* Make it ergonomic to do the simple things that you always need to do, like converting to/from strings and each numeric type, parsing strings, etc. The amount of code needed to perform simple and common operations is crazy, ugly and inconsistent. *sum types* Once you've used this in Haskell or Rust, you'll wish C++ had this too. *const and ref by default* 
There was actually [a really interesting talk about this](https://www.youtube.com/watch?v=NeJ85q1qddQ) at CppCon 2017.
There is a pretty big difference between this and NRVO: First of all NRVO is only possible because after returning the compiler can be absolutely certain you won't touch that value again, in a constructor you absolutely can: `my_type(std::string s): a(s),b(s)` is possible and well defined. Secondly NRVO does not apply to arguments and is explicitly forbidden by the standard. The reason for this is (as far as I know) that RVO works by constructing the returned object directly where the caller expects it. This can be done when the callee chooses where to put it, which it does with local variables, but the arguments are handled by the caller.
* Replace preprocessor with something different. Preprocessor forces configuration into build tools and this puts pressure on the whole ecosystem. * Remove array to pointer decay. * Remove NULL-as-macro. * Lexical values for all types and variables available to compiler and runtime, eg. enum names. * Robust ability to restrict features at compile time, eg. maybe we don't want __FUNCTION__ to ever be used in a shipping executable. Or maybe we want the compiler to be able to enforce a "no lambdas" or "no default parameters" coding standard. * Introspection much like the metaclass proposal relies on. * IIFE-style assign-from arbitrary block by default. * Labeled break and continue. * More attributes. Never null, must be literal, etc etc. Give me as many as you can think of. * Remove silly undefined behaviors (sorry for no specifics here). * Immutability by default. * nodiscard by default. * Option and Result types that aren't underpowered and integrate with the standard library. * Remove class, standardize around struct. * Ability to add arbitrary methods to ~~classes~~ structs (UFCS-style or something else). I'm sure there are a million more. Every week I run into something I wish the language would just let me disallow across my whole organization but even with all the progress of the last 8-10 years we are not there yet.
So you'd rather type (*foo).bar instead of foo-&gt;bar?
Damn fuckers, you are all describing Delphi. 
I'd do whatever it takes to bring C++ back in line with C99 and C11. C++11/C11 did this to some extent, but they didn't do it totally and they even added in a few new problems (like not being able to include C11's version of stdatomic.h in C++11 code). The ironic part of this all is that we're sacrificing backwards-compatibility for another type of backwards-compatibility.
Sorry, I was on my mobile and didn't realize how badly the auto completion had worked. In case that is not clear, what I wanted to say in the first sentence was that:. Having a compiler error, when your function body can't emit an exception that would be allowed by the interface specification is a bad Idea.
&gt; there is no way now to create a container full of uninitialized values Well, there's always [`folly::resizeWithoutInitialization`](https://github.com/facebook/folly/blob/master/folly/memory/UninitializedMemoryHacks.h)...
So... let me get this straight... first, you claimed that "all of it" is backed by a file. Now you changed to "the request will be satisfied ... from physical RAM". If I was you , I would be ashamed of myself. I do not expect you to trust me, hence I provided quotes and sources. You provided nothing of the sort.
Can you give a particular example, which exceptions in the standard library are bothering you? The only common one I can think of at the moment is bad_allocation and when that happens an otherwise operator doesn't help you. As a final comment: I don't like try catch blocks either, but in my experience, you usually have to write only very few of them anyway. The good thing about exceptions is that you need much less error handling code
Get rid of C-style array behaviour; make `[]` declare a `std::array`. Fix `std::string` to have the interface it would have if designed today; string literals can have that type. Revamp aggregate initialization. Replace with something so you can still use the syntax, just not with the awful warts and corner cases it introduces into uniform initialization.
I mean I think I understand what you mean, I just don't agree. As a reference to some nonsense syntax that I'll make up for the sake of the discussion: https://gist.github.com/playmer/26f6cd1a6202688c3e153a85055709c3 I dunno, I'd be happy with more facilities like that.
A database is just a bunch of files anyway ... Continuously tracking dependencies is already possible, it could be an IDE feature. (gcc auto-dependency generation is good enough for most purposes however). 
Your example does not have undefined behaviour in C++14 (it's now implementation-defined) , which makes a bit of a mockery of the rationale presented.
This seems very interesting, but I am not that familiar with all the many aspects of C++, so sorry for any stupid questions Why are there negative ns/block on the graph? Artifact? Isn't callgrind a profiler that doesn't require any setup? What does this profiler offers in comparison? &gt; Working profiler slows your application execution for only 1-2%. Doesn't this heavily depend on the app? If the main thing I do is repeatedly call a very cheap method, wouldn't the cost of the profiling be really high? Just to be clear, if the method costs 15 ns, the profiler would eat up half the running time? Thanks for any insights 
&gt; safe numerics library https://github.com/robertramey/safe_numerics is this it? I see that it's got a whole pdf's worth of docs but I'm surprised theres no readme.
Sorry. I corrected it. Need more coffee...
1. &gt; simple 'ret' instruction This is not what happening. [This code](https://wandbox.org/permlink/NoFymxhWcpys0huE) shows that overhead from stackless coroutiens is unbounded and that you pay for nothing. 2. Let's forget about TLS for a minute. std::mutex m; void function_than_can_switch_thread(); void consume(int,int); void foo() { { std::lock_guard&lt;std::mutex&gt; l(m); function_than_can_switch_thread(); } // POSIX: If a thread attempts to unlock a mutex that it has not locked or a mutex which is unlocked, undefined behavior results. consume(x,y); } What do we do now? 
Can you clarify what you mean in the first example? The program is ill-formed as there's no `main` function , but I suspect you had something else in mind
No that is my point exactly. 
Very timely presentation, as this is a problem I am trying to solve at right now.
Right, the only things I've suggested that might add cost are optional things like adding functions that don't use exceptions. That would be in addition to additions that don't cost anything that exceptions already pay for. A try operator or an otherwise operator don't do anything you can't do with a try block. It's just boilerplate.
IDEs could do this.
&gt;&gt; This is not what happening. Of course it is. I think you misunderstood what I meant by 'ret'. I did not meant that any coroutine vanishes into nothing and optimized into 'ret constant'. What I meant and written *explicitly* multple times that a *suspend* of a stackless coroutine is a `ret` instruction and *resume* is `call [rcx]` and that is cheaper than suspend/resume of a stackful coroutine. If your are curious, you can code up the same example using boost::coroutine as the underlying machinery of the generator and compare the perf. &gt;&gt; Let's forget about TLS for a minute. I shall not. You challenged the statement I made about interactions of stackful coroutines and TLS, I provided an explanation. TLS not working, means that you cannot use nice allocators like TC_malloc in stackful coroutines. One more clarification. My replies on this thread are not meant to bash boost::coroutines which is a fine well-written facility to solve certain class of problems. Vinnie wanted to know: "What do language-based coroutines offer that library-based coroutines do not?" and I offered the list. If one would ask when you should not use stackless coroutines and use stackful instead, I would provide a different list of reasons.
1. The function is declared as returning int, but fails to do so, which is UB. 2. Visual Studio, right up until the version released this week, still throws a debug assertion in debug mode. 3. That's true; not every case can be (easily) detected. Actually, if I could change anything, I'd make it so post-increment (and assignment) was a statement rather than an expression. It wouldn't eliminate the problem, but it would certainly remove most of the cases that trigger it. 4. You sure about this? At any rate, the example would work with a larger type and value. 
&gt; safe Rust cannot invoke UB on its own Actually, there are couple of ways to employ UB in safe rust. Only they are called "compiler bugs". They are supposed to be fixed some time, but given that they existed for many years already, it may not be soon.
The database would do away with forward declarations of any kind (or rather, it would make them implicit for any object that's added). It would establish a single identity for _any_ stored object. And it would compile each object only once, instead of per translation unit, as happens now for (for example) templates. I'd say all of those are good things, and pretty hard to achieve using the current file-based model.
Ok, thanks for explaining.
There's a vast difference between a young language that hasn't gotten around to fixing some compiler bugs, and a decades-old language that has intentionally kept the same behavior around across many implementations. It's also pretty much irrelevant for this conversation because the benchmarks in question don't depend on those compiler bugs for their performance.
&gt; Can you give a particular example, which exceptions in the standard library are bothering you? Sure, although they added overloads to solve this, I would've preferred the optional solution instead, but the exceptions in the filesystem API are...very annoying. There are also things that I don't really care about but I've seen solutions to in other libraries to do the otherwise type thing I've mentioned. Passing a default value back rather than using exceptions or error codes. &gt; As a final comment: I don't like try catch blocks either, but in my experience, you usually have to write only very few of them anyway. The good thing about exceptions is that you need much less error handling code Part of it isn't really just the blocks, although admittedly I don't like them. I just don't really like that I have to read documentation on what's thrown rather than just looking at the signature. I'd much rather it be explicitly and statically checked and have some sort of match syntax for when I want to handle exceptions in the more "traditional" way.
1. it's not UB to define that function. There would be UB if the function were called (and execution reaches the call) 2. Great 3. Detecting all cases would require solving the halting problem. You could get a nobel prize and have your name go down in history if you could do this. 4. Yes I'm sure 
Just a shot in the dark, but have you ever used Rust?
What's the issue with using reserve()? **Not** using it before adding a bunch of things can cause slowdowns due to having to grow the internal array multiple times, but this is the first I've heard of using it being a problem.
Haha, I am a huge fan of Rust and most of these ideas are just Rust in disguise. :)
Appears to be only for managed languages, not C++: &gt; IntelliTrace "step-back" is currently supported for WinForms, WPF, Managed Console applications, and Managed Class Libraries
`std::vector&lt;bool&gt;` is useful. It just needs to be called `std::dynamic_bitset` or something instead.
Suppose you're going to add 1, 20, and 1 things. If you reserve for size+22, then you're doomed if you're called in a loop. That's a loop of +constant reallocation, which is quadratic. I made this exact mistake before becoming an STL implementer. In general, it is okay to reserve exactly once at the time of construction. Later reserves should be inspected very carefully.
And it causes no end of confusion, buffer overflows and other bugs.
&gt; suspend of a stackless coroutine is a ret instruction and resume is call [rcx] and that is cheaper than suspend/resume of a stackful coroutine No it is not cheaper. In the example you can see that with increasing depth of call stack, stackless coroutine works slower and slower and slower. Bigger the stack, slower it works. &gt; I shall not. Please don't. So, what is your proposition regarding this code? Ban POSIX or deprecate mutex? 
I'm really happy that I can compile an aggressively C++14 codebase with 15.3. I need something besides mingw on Windows. I might skip 15.4 for this.
If you're adding 22 items and reserve enough space for those 22 plus whatever's already in the vector, it's at most one allocation and copying, no? 
&gt;&gt; No it is not cheaper. Of course it is. A single 'ret' instruction is cheaper than a pile of code I linked earlier. You are not arguing against my statement that suspend and resume in stackless are inherently cheaper. What I believe you are arguing is that an attempt to emulate threads using chains of stackless coroutines is less efficient than using threads/fibers in the first place and I agree with that. However the example you listed does no such thing and if you code up an equivalent generator sequence using boost coroutines you will discover that it is slower. I would be curious to know by how much, so, if you do, please share the results. &gt;&gt; Please don't. So, what is your proposition regarding this code? This code is an illustration why people want explicit syntactic marker at the point where a function can get suspended and resumed on a different thread. Using stackfull coroutines you have no idea if some function deep below will suspend the stack and get resumed on a different thread. With await, tooling and code reviews can help you discover those places. Usually, it is not a good idea to hold a lock across a blocking call or an await expression, especially if the locks you are using must be released by the same thread as acquired them. 
What the linker does is dictated according to _linkage_, not the presence of `inline`. `inline` is orthogonal with linkage – you can have both `static inline` functions (internal linkage)` and `[extern] inline` functions (external linkage). The rule that a static local variable in an inline function must always refer to the same object _only_ applies to inline functions with external linkage. Likewise, the rule that an inline function must have the same address in all TUs _only_ applies to inline functions with external linkage. Etc.
&gt; If a function is inlined, multiple copies of it exist, inlined, in every place that the function is called. But if it has external linkage it each then the function is guaranteed to still have a single address (C++14 [dcl.fct.spec]/4). &gt; Since when inline's meaning changed to mean exactly the opposite? Since you're thinking of linkage, not `inline`.
&gt; Every TU will still see the function as having the same address. _Iff_ the function has external linkage, which should not be assumed.
`std::forward&lt;decltype(xs)&gt;(xs)...` is a long way of saying `decltype(xs)(xs)...`. ;-]
This is probably controversial, but if backwards compatibility were not an issue, I would change the syntax for Universal References introduced in C++11. I don't understand why they decided to clobber the syntax for R-value references. I think it's needlessly confusing, and creates an unnecessary pitfall for beginners with no discernible gain. Currently: template &lt;typename T&gt; auto function f(T &amp; t) { // t is a simple reference type ... // not for perfect forwarding // won't bind rvalue references, and // std::is_reference&lt;T&gt; will be // false } template &lt;typename T&gt; auto function f(T &amp;&amp; t) { // t is a universal reference ... // for perfect forwarding // will bind anything, and // std::is_reference&lt;T&gt; will be // true } Alternative: template &lt;typename T&gt; auto function f(T &amp;&amp; t) { // t binds to r-value reference ... // T deduced as a non-reference type // similarly as T &amp; t case. } template &lt;typename T&gt; auto function f(T &amp;&amp;&amp; t) { // t is a universal reference ... // for perfect forwarding } Another alternative (new keyword): template &lt;reftype T&gt; auto function f(T t) { // t is a universal reference ... // for perfect forwarding } 
Make programs that would trigger gcc warning `-Wreorder` ill-formed under the standard. That is, it should be an error to specify a constructor initializer list with order different from the declaration order of the fields. I didn't used to think this, but I was convinced of it by a discussion here on `/r/cpp` with @quicknir: [permalink](https://www.reddit.com/r/cpp/comments/70poxv/should_c_have_tagged_initialization/dnc0otl/) This would bring the committee's view on constructor initializer lists in line with their view on the new tagged initialization feature slated for C++20. It would also prevent a lot of insidious bugs in real programs that cause uninitialized values to silently creep in when constructor initializers get silently reordered.
This is pretty cool. I've been messing around with it within my own little engine. I've got a couple of questions though. Is there a guarantee the Entity id will always point to the index of the component container that I'm missing? It seems like ids will get screwed up if I construct an entity between adding components. Entity e1; e1.add_component&lt;Transform&gt;(); Entity e2; // e2 has id == 1 but Drawable component at index 0 e2.add_component&lt;Drawable&gt;(); // e1 has id == 0 but Drawable component at index 1 e1.add_component&lt;Drawable&gt;(); 
&gt; So... let me get this straight... first, you claimed that "all of it" is backed by a file. Now you changed to "the request will be satisfied ... from physical RAM". That's not what I said. You should read what I wrote and take my advice instead of ad hominem attacks because you literally do not know what you are talking about, and are somehow accusing me of ignorantly copy and pasting half baked arguments from man pages when that is exactly what you did, not me. You surely can find on your own the relevant source code files in the Linux and FreeBSD kernels which implement the virtual memory subsystem. Hint: they usually have "vm" in them. But if you don't want to, and prefer to believe whatever beliefs you have going on there, totally up to you. I tried my best. 
Clang 5 and 6 works great on Windows.
Sometimes you want to return multiple things, so you end up pre allocating on the heap, and then calling the function that 'returns' multiple values by passing it pointers to those values. void f(A* a, B* b); To use that you do A a; B b; f(&amp;a, &amp;b); Some languages allow you to declare new locals when calling a function, f(out a, out b); // Use a and b
I find Gor's argument compelling 
Or [Loci](http://loci-lang.org/) :)
Thx, I'm glad it was useful :) So for the ID, I unfortunately didn't go into a "real world" example because of the post length. What you want is to have a static map or static vector in the component, which will map the id to the component position. I currently use an unordered_map. This way, it's also easy and fast to know if the entity has a given component and where it is in the vector. [Here](http://bitsquid.blogspot.ca/2014/09/building-data-oriented-entity-system.html) is an example using a vector with holes instead (the Accessing Data section). I've thought a lot about looping per entity composition (rather than per-component). This would make cache locality better when accessing other components on yourself. I'm guessing that is your use case? You might be able to store entities as tuples inside a static entity vector. But this is compile time bound, so it wouldn't work well with a data-oriented engine (JSON entities or editor UI entities for exemple). That's a pretty advanced use case, so I'm curious what you are trying to do by only updating entities with certain components? Cheers
&gt; std::array isn't always all contexpr when it should be. C++17's is, excepting comparison operators.
What I would change is languages. Look at what removing backward compat has done to Perl and python. What a mess. 
So your cross-platform library renders native platform widgets!? That is awesome! I can't wait to try it out. Cheers and thanks for the screenshots.
Java has checked exception, which doesn't seem very successful.
I appreciate the response! I don't have a real world use case for any of this right now. I'm just playing around with my own engine (building up to pong and other simple 2D games) as a hobby so something like this is complete over kill. But I enjoy the challenge of implementing a data oriented design using cache locality! Mapping the id was kind of what I was leaning toward, this would still get you O(1) look up but wondered if we lose any measurable performance performing an index lookup of the type. As for the more advanced system, again, just for learning, if I had a real world use case of 20,000 entities with only 100 are drawable but all of them can be Positioned, I would only want to perform work in my render system for entities with the Drawable component. But in order to position my Drawable within the scene, I would also need a Position component. Therefore, my system would really only need to perform work on 100 of my entities. So my thought process was, well, maybe I can cache entities with only Position and Drawable components during some initialization step and then on my update step, I'm only hitting the entities that need updated.
yup, but until it is released fully on all compilers I'm waiting. It is an easy class to implement and provides the basis of a constexpr vector. The other thing I wish C++17 did do was put [[nodiscard]] on std::lock_guard. It would explicitly catch the error where you forget to name it every time 
He probably wants `.` on a pointer to automatically dereference it first, so it would be `foo.bar`
It may help to understand why it is called inline. Inlining a function call was always non-observable behaviour in the abstract machine. But prior to link time optimization (which is recent), the only way to inline a function call was to have the definition visible at the point of call. One way to handle this is to use `static`. But then you get actual duplicate functions. Which really isn't always what you want. We could change the rules of C++ and permit a function to be non static and defined in multiple translation units, and discard all but one. But then you get **horrible** bugs. Someone has a function `helper` in two translation units; and one gets silently discarded. Remember C doesn't even name mangle; function linkage is only name based. So instead they added a keyword -- `inline` -- that permits a function's definition to be visible in many translation units and all but one be discarded. Compilers are still free to inline calls even in translation units where the code will eventually be discarded at link time. `inline` also acted as a hint that the function should be inlined. `static inline` removes the linking discard rule, leaving not much beside the hint. And this is why `inline` is mostly about linking and not stitching code into calling locations.
The issue is using it inside a loop, yes. Sometimes it isn't immediately obvious that it is being done in a loop though. Consider a function that adds some known number of elements to a vector it takes by reference. You might use reserve there, but then you have quadratic behavior if that function is called repeatedly. Thus the safest approach is to only use reserve on a vector that you just constructed or called clear() on.
Ah dang it, that's a blocker for me :/
Oh, you mean regular out params. In your original post, you even gave an example. For some reason, I had a brain fart and I thought you meant something really exotic.
Haha that's awesome. I'm pretty much in the same boat working on some cool shaders, going overkill just for fun :) Map vs. vector really depends on the max quantity of entities. Unfortunately with this system, you should be able to support a ton of entities lol, so I recommend a map. My friend used a bitfield for the same thing in his own version. Personally I haven't added it because the perf bottlenecks are usually processing. Though I'll benchmark for sure! I'm glad you explained. Here is how I setup my "events". In a component constructor run once, I check with SFINAE whether the user implements a given event. If so, I hook a callback. If not, nothing is run on the component. You want more granular events instead of per entity loops. For example : pre_update, update, post_update, animate, pre_render, render, etc... You can add as many as you want, within reason. Checkout the great Unity [event graph](https://docs.unity3d.com/Manual/ExecutionOrder.html) for a good inspiration. Then you can if constexpr(has_preupdate&lt;...things...&gt;) engine.hookup_update(muh_update); for example. Or use other techniques of course. In one engine I used a tuple and a compile-time tuple loop for the same result, if that floats your boat ;)
In "the early days of C++" there was no vector. From my perspective the standard library is still new and honestly a pretty mixed bag in terms of the influence it has had on the base language.
Can you guys please fix if constexp. This is a feature everyone can start using tomorrow and is part of the standard and every major compiler have been fully supporting it for a while except you guys. Honestly you should b ashamed. No more silly features until you fix this.
It isn't in this update because it's already supported. I haven't had any problems with it, personally...
Here is a link to Daniel Pfeifer's [Effective CMake](https://www.youtube.com/watch?v=bsXLMQ6WgIk) talk. It does a much better job at explaining how to set things up using cmake. Also, for the first person's question about openssl being in different location. This is already taken care of with imported targets, as `find_package` has to be called again for all downstream libraries, which Daniel explains how to make it transitive in his talk. Pkgconfig works in a similar way. Furthermore, saying to use a package manager doesn't make sense. A package manager takes care of automating building and installing the libraries(and resolving which versions), but if your library can't be built or installed in the first place, its not the package manager's job to fix the build scripts.
Those features in c#, at least, require runtime reflection to do 50% of what you'd do using templates and multiple inheritance in C++, and the remaining 50% is just left to repeating yourself. I'll take the templates, warts and all. Compile time reflection would reduce the situations where we break out the weird constructs, so that'd be a good inclusion
&gt; Remove reliance on the order of definitions. So much this. The C grammar allows for so much weird mess in the language. For example, if you `#if 0` the global `A`, your code changes its meaning: #if 1 struct A { int i; }; #endif int main() { struct A *a; struct A { int i, j; }; std::printf("%ld\n", sizeof(*a)); } Because `struct A *a` could be just a normal declaration, or the `struct A` could be a forward declaration, depending on the parser state.
Being O(1) doesnt automatically make something more performant different complexity. Sleep(99999999999) takes constant time, so would be O(1). Is it now faster than a for loop, because for loops are O(N)?(Assume N &lt; 99999999999)
&gt; Just unimplementable on Windows. &gt; UTF-8 and all other Unicode transformation formats in existence are 1:N. Unicode to literally any other encoding in the universe is not 1:N. Encoding U+0065 U+0301 into Latin-1 should produce 0xE9, not 0x65 0x3F. Even if you only need to translate between Unicode transformation formats, programs that want to speak UTF-8 internally, but need to speak to systems that use UTF-16 (e.g. they're communicating with JavaScript, or Qt, or ICU, or yes, Windows) really need to be able to convert between those two, and UTF-8 &lt;-&gt; UTF-16 is not a N:1 transformation. A codeset conversion system with that restriction is a broken codeset conversion system. &gt; If I were to agree that deprecating library features with no replacement is sensible, `std::ctype` is what should have been been deprecated, not `std::wstring_convert`. FWIW I'm not a huge fan of deprecating things without replacement either. :) I believe these things were deprecated based on feedback from folks who actually implemented the things (not VC++ folks) that parts of the spec were functionally unimplementable, that there was divergence in real implementations, and that what happened for specific kinds of decoding errors needed to be specified in order to process Unicode data securely. I don't remember the specific discussions that happened and I came into the room at the last minute, so I could be misremembering this; maybe Alisdair or Johnathan Wakely or one of the libc++ folks would know better. (Nobody presently on the VC++ team implemented these things and we know our current implementation of `Xxx_convert` is.... let's say *problematic*, but that doesn't mean we don't want to fix them as soon as ABI break will let us do so)
Also, from the `std::string_view` section: &gt; // C++14 void Func(const char* str); void Func(const char str[10]); void Func(const std::string &amp;str); &gt; // C++17 void Func(std::string_view str); The second C++14 overload is the same as the first due to decay; it should be `void Func(const char (&amp;str)[10]);` instead.
I thought ADTs are the mathematical theories and could be implemented with classes.. no? 
My intent with nav meshes was to present their unique conceptual approach to representing the search space and how it is a good solution to the problem they solve. I find it fantastic, whereas the memory layout is messier and less exciting to me. The other three I only think are fantastic when the memory layout is considered - what they do without considering that is otherwise not very exciting to me. You are absolutely right that it is different from the others and its reason for inclusion is not as obvious, so hopefully my explanation has made it more clear for you. I'm glad you liked my talk, hopefully it will come in handy one day!
Come to nyc! The hedge funds here utilize c++ heavily. They’re always looking for hardcore c++er. It pays crazy but I’d guess you’d have to produce impeccable product as well. 
I wish I could work for such a place, being an Indian developer how would someone like me get a job there ?
*shrug* I'd use them, but I don't use Java. 
Have solid resume! Google some hedge fund companies and apply through their career site. Or use few sites like indeed.com to get your resume out. If you have relevant experience they’ll definitely reach out to you. If you don’t have relevant experience you’ll have to build before applying. Usually the companies won’t care about race at all. And if necessary will provide visa. 
Yes, dr. Stroustrup himself works currently in NYC. Unfortunately I am an EU citizen so I do not really know how could I get to work there, but I will at least try eventually, I guess
One way is to find job in EU at large company which has multiple branches around the world. That gives you opportunity to eventually switch teams at different locations 
Nice :) 
&gt; make "a += b + c" equivalent to "a+=b; a+=c" to avoid temporary values Those are not equivalent for floating point numbers. And they might not be equivalent for user defined types. Now if the compiler knew which types it was safe to do that with then that optimization would be good.
Running a program through callgrind makes it extremely slow, so it's hard to use it if you have a UI. Gcc has the -pg flag to output profile data that causes a small slowdown (about 50% for me), but I found it's often inaccurate. From the description it sounds like easy_profiler could be shipped in a release binary, and users could send you back profile data if they experience a performance problem. 
CMake: For people who don't care about build times
I tried to get into building COM components, but the MSDN docs look so daunting :S
Not really in the EU but Zurich is becoming a bit of a hub for very comp-sci based development with a bit of a focus on image recognition and generation. Quite a few C++ heavy startuos in these sectors and of course google, apple and an oculus office of facebook are also here. Gping a bit outward of zurich you can find med-tech and machine industry which is also quite a bit on c++. 
* Delete iostreams. Poorly designed, poorly performing, and the poster child for operator overloading abuse. Needs to give way for a safe, extensible system with printf-like syntax like many new languages support. * Make char unsigned and no longer a distinct type from signed char and unsigned char. 'char' being a distinct type is weird and it often being signed leads to crash bugs with is- and to- functions. * Adopt C#-like integral promotion, so that mixing signed and unsigned types of the same size either promotes or returns an error. (C# allows long+ulong, I would make that an error.) * Virtual methods should be final by default in derived classes unless redeclared as virtual. Often this is not wanted and leads to accidentally reduced performance. * Methods declared within the class body should not be implicitly inline, for convenience. IMO it's weird and an awkward implementation artifact. * Simplify the syntax for forming pointers-to-member-functions to not require the class and allow them to bind directly to actual virtual method implementations rather than the method slot, so fast delegates could be portably implemented. * Make C-style cast syntax use static_cast semantics. The C++ cast semantics are good, the syntax is *horrible*, especially for math-heavy routines. * Float-to-int conversions should round instead of truncating toward zero. I have never once wanted the latter behavior, only round/floor/ceil. * map[] should not implicitly insert. Seen too many bugs from this from programmers used to other languages.
In the same domaon and not far but in france, you've got KDAB and Kitware near Lyon and Grenoble which are both heavy on c++ and computer vision. Also, INRIA
In EU without a doubt it's Sophia Antipolis, a tech pole not far from Nice in the south east. Great environment, best weather, near the seaside. Imagine all your friends working in a city, going back home facing a wall while you can go to the beach, just five minutes away from home.
Bay area and Seattle are pretty serious when it comes to compilers etc. The MS team in the Seattle area, and in the bay area Google and apple are prime movers on llvm/clang. I have no clue how hard those teams are to join, though. If you're looking for interesting infrastructure problems most of the FANG + other companies of that scope are going to have things ranging from high performance data stores to networking to more application specific solutions. If you have a particular area of interest, though, look for which companies are publishing research, participating in open source efforts that you find interesting, or offering products that you think would be fun to work on. If you don't care about making money, you could extend your search to universities. They sometimes have budget for research programmers associated with particular research areas. It won't pay anywhere near as well as industry, but if it's the right job you might enjoy it.
&gt; Virtual methods should be final by default in derived classes unless redeclared as virtual. Often this is not wanted and leads to accidentally reduced performance. Can you elaborate? I wasn't aware of any potential loss of performance with virtual methods. &gt; map[] should not implicitly insert. Seen too many bugs from this from programmers used to other languages. I agree, forgot to mention this. std::map interface is definitely badly designed. Also insert doesn't insert if key already exists. Wtf?
If it is actually backwards compatible, maybe I should write a WG21 paper.
Personally I would completely change the syntax so there is less typing when you directly assign constructor params to members.
I agree, the double &amp;&amp; semantics are bad. The meaning of `auto f(T&amp;&amp; t)` changes depending on whether it's a template function or a member of a template class.
What interface/implementation would you give `std::string` to have string literals be of that type? It would have to be something really lightweight.
&gt; For copy vs move semantics, the more expensive feature (copy) must always be chosen explicitly. You would have to be explicit about move as well, otherwise you'd do it accidentally and later use the undefined moved-from object. Unless you would add Rust-like restriction on using moved-from variables.
Unsigned types should only be used for bitwise operations
&gt; unique_ptr needs to be language I like to be able to use my own implementation of unique_ptr that has uses reference counting to reset dangling weak references or other stuff. Built-in unique_ptr would save a lot of typing though.
Generating the ninja build files using cmake takes a very small amount of time compared to the rest of the build for the main project I'm working on.
&gt; A single 'ret' instruction is cheaper than a pile of code What `single 'ret'` and `pile of code` has to do with stackless coroutines? Nothing. The way you try to present it, is not the way it actually works. Example shows that - there is slow down, there is cost associated with stackless coroutines, it is not just `ret/call[]`. Depending on your calculation, it can be [300% slower](https://wandbox.org/permlink/XzrLfiPiXsBRvmL9). There is no point comparing `ret` and `pile`, they are apples and oranges. There is no `equivalent generator`, you switch context when you absolutely should, like after starting async I/O, you do not switch on every variable increment just for fun. &gt; attempt to emulate threads using chains of stackless coroutines In your example you had 4 variables - `s`, `t`, `m` and `a`. How adding 10 more variables becomes `emulate threads`? &gt; syntactic marker If you want some piece of code to be executed on some other thread, you do this: some_other_thread.post([fiber=current_fiber()](){ ... your code goes here ...; fiber.ready = true; }); yield(); You don't need `await`, `tooling`, `marker` or anything. No problems with `TLS page in non-volatile registers` or `architectures` or POSIX or locks. &gt; Using stackfull coroutines you have no idea if some function deep below will suspend the stack and get resumed on a different thread Can you show one open-source project doing this? 
&gt; A single 'ret' instruction is cheaper than a pile of code What `single 'ret'` and `pile of code` has to do with stackless coroutines? Nothing. The way you try to present it, is not the way it actually works. Example shows that - there is slow down, there is cost associated with stackless coroutines, it is not just `ret/call[]`. Depending on your calculation, it can be [300% slower](https://wandbox.org/permlink/XzrLfiPiXsBRvmL9). There is no point comparing `ret` and `pile`, they are apples and oranges. There is no `equivalent generator`, you switch context when you absolutely should, like after starting async I/O, you do not switch on every variable increment just for fun. &gt; attempt to emulate threads using chains of stackless coroutines In your example you had 4 variables - `s`, `t`, `m` and `a`. How adding 10 more variables becomes `emulate threads`? &gt; syntactic marker If you want some piece of code to be executed on some other thread, you do this: some_other_thread.post([fiber=current_fiber()](){ ... your code goes here ...; fiber.ready = true; }); yield(); You don't need `await`, `tooling`, `marker` or anything. No problems with `TLS page in non-volatile registers` or `architectures` or POSIX or locks. &gt; Using stackfull coroutines you have no idea if some function deep below will suspend the stack and get resumed on a different thread Can you show one open-source project doing this? 
Real code example with real performance measurement vs numbers from your imagination.
Are those jobs "good jobs" though ? My experience with Zurich and most of Switzerland is that companies like Facebook and Google have, mostly, only part of their support teams there (or SRE, or w/e other glorified name we give to the call center guys nowadays) and a few other not-so-technical people. The "heavy movers", as in, the clang and hhvm devs, are all across the pond. As for startups, well, initially I was attracted by the salaries they offer, but taking into consideration that the average salary in Zurich is ~140,000$/year puts them into a rather different perspective. So in terms of local buying power at 200k salary at a startup in Zurich might be equivalent to a 100k salary at one in London. Personally I'd have a look at Berlin, Frankfurt, Munich and Vienna (if you buy into the whole, higher taxes and lower wages but the socialist system works to the benefit of everyone) or Amsterdam and London if you are more liberal in your views on government and taxation.
Just needs a start pointer and a length. The storage can be static if we make string literals be `const`. Current `std:;string` also has a `capacity, which is a bit of a waste for a non-mutable string; so perhaps they can actually be a class similar to std::string but without capacity. 
Ok, so immutable strings. Java has them, and they seem to work well. A string class would basically contain a variant between a pointer to string literal and a reference-counted buffer that was created in run-time.
Reference-counted buffers are terrible . Some C++98 implementations used that for std::string but it was later disallowed (a correct decision IMO). I wouldn't suggest that.
The Google Zurich office is a huge eng office, the biggest in Europe. It's got around a thousand devs, and they work on all kinds of important things (search, you tube). Also, SRE is very much a technical role. They keep the services running. Munich is very nice - Google engineering (chrome, Clang, tooling, privacy), a Microsoft office, siemens, BMW, Mercedes, and a lot of smaller tech companies. Good wages and high quality of life, but Zurich definitely pays better and had lower taxes. London seems a bad deal for devs: lot wages and high cost of living. Parties also has low wages, but send to have a decent startup scene (maybe partly because of low wages). Spanish and Italian devs seen to need to leave their country for a bigger career (just my vague impression).
Why is that? It seems like the fastest way to get copy semantics (without sso).
Yes, I'm a C++ developer in LA, but I came here for a very specific job. I was going to mention both the Bay and Seattle (Bellevue).
Not sure what you mean exactly; every other container class works fine without reference counting (other than shared_ptr of course which is designed for that purpose - you could use `shared_ptr` to a string if you really wanted that behaviour) 
You just have to adopt a style in which &amp; is always const when passing by parameter. If something is going to be modified you pass by pointer, so it is clear at the call site. On the company that I work the only code that doesn’t follow this convention is the STL (e.g. std::swap), but everyone knows these specific cases and they know that the value is being modified.
&gt; Let's go through the real world example I just inherited: What does this example have to do with generating documentation about which Concepts or Traits a type does implement? &gt; Why do we need into() here? let x: T; let other: Other = x.into(); is just a nicer way of writing `Other::from(x)`. If `T == Other` you don't need `into` (nor `from`) but they do still work. &gt; what we kind of type I will get? It's right there, you get a `Result&lt;()&gt;::Err`. The return type of the function is `Result&lt;()&gt;`, which is an `enum`. You are explicitly constructing the `Err` variant of that enum, that is `Result&lt;()&gt;::Err`. And you are constructing that `Err` variant **from** a `::std::io::Error::new(::std::io::ErrorKind::Other, "app io returned failure")`. Since you don't need `.into` I am willing to bet that your `Result&lt;()&gt;` type is an `std::io::Result`, but it doesn't necessarily need to be. However, every Rust IDE already tells you which type it is, editor will tell you which type it is, There is only one `Result` type in that module though, so it is pretty easy to find. Any
If the string class is immutable then there is no point in copying the buffer when making a copy. Incrementing a reference counter is faster. I've heard that there were performance problems with ref-counted std::string, I would gladly learn more. I suspect that it had to do with mutability of the class: even calling the [] to read would cause it to create a copy.
If you make a copy it's because you want to modify it ; if you don't want to modify then don't copy. 
some say coroutines ts could even give negative overhead compared to common callback in asio. Kinda doubt.
My username?
I wouldn't set the required cmake version to as low as 2.8.12 or 3.0 nowadays. Something like 3.3 or 3.4 should be the absolute minimum, better go with higher if you can. The presenter is mixing lowercase and uppercase CMake commands, I think it's recommended nowadays to use all lowercase for commands, i.e. `target_xxx` and not `TARGET_xxx` as presented in the slides. Also at around minute 41 to 44, I'm confused why the target_include_directories command is necessary and the ${BAR_DIR}/include. I thought in the target-based approach, doing target_link_libraries is enough and it will take care of the include paths. Using ${BAR_DIR}/include shouldn't be necessary anymore, all you should need is the `bar` target. I think it's a good talk and I've learned some things for it but Daniel's Effective CMake talk is better. Maybe this talk is better suited for absolute beginners though.
Is there a (Microsoft) expert that can say something about sharing std types across dll boundaries in the microsoft implementation? According to this article (https://support.microsoft.com/de-de/help/172396/you-may-experience-an-access-violation-when-you-access-an-stl-object-t from 2005!) it doesn’t work with certain types that include use static variables inside the dll, eg std::map. I tried and it seems to work now. (All questions assume dlls are build the same version/options) - Can std library types passed across the boundary? - What about allocators and destruction? If I use make shared and pass the smart pointer that should work in all cases? - If a class passed over the boundary includes a private value member from std and that member get only accessed through functions inside the class that should work in all cases too? 
I set my min version to 2.8.12 because my software is used by a lot of big organizations that run versions of redhat where only 2.8.12 is available. It kinda sucks, but I could either piss off my users or stick with 2.8.12.
most unstable version ever 1. random crashes + 800MB dmp files in my TEMP 2. full of unknown exceptions 3. hangs a lot without extensions and codelens + wide analysis too 4. slow solution loading (and they said in the release it's faster) 5. UI unresponsive sometimes and random GPU spike at 80%
Not to mention that you hardly do it every time you build... 
Does the UI update in real-time? How does this compare to remotery? I'll probably give this a go!
How crazy is crazy?
Cheaters Club?
It's totally impossible to afford living in Switzerland though without being offered a high paying job ahead of time first, even if you speak German already.
Yea, that's something everybody has to decide for themselves (or within an organization). It's unfortunate to be stuck on old redhat versions. My philosophy is that I'm providing modern libraries with modern code and build system, and users know and value that, because it leads to minimal and clean code (also in the build system files). Anyone who can't upgrade to an at least somewhat-recent version of CMake and compilers will get left behind. It always goes both ways too, I think you're the author of dlib, if dlib was more modern in adopting C++14/17 and modern CMake (without countless #ifdef's and build system cruft to support 5+ years old CMake versions), I would be much more inclined to use it. And you know, CMake makes it so easy so use a newer version, you can just download the linux binaries from cmake.org, and put it in your home directory, and it works. No compilation, no nothing.
I like the tool a lot. One suggestion: instead of hardcoding the colors ypu should be able to assign a category or a tag and assign the color from the GUI tool. 
Except 2.8.12 is fine and dlib's cmake files are modern. Here is a CMakeLists.txt that compiles a dlib example program: cmake_minimum_required(VERSION 2.8.12) project(example) find_package(dlib) add_executable(svm_ex svm_ex.cpp) target_link_libraries(svm_ex dlib::dlib) What #ifdef's or build system cruft are you talking about? Moreover, what aspects of dlib use do you think would be improved by using C++14/17 in the dlib API definitions? There aren't any that jump out at me. There is also the huge issue that visual studio 2017 still can't compile all of dlib's C++11 code. Who knows when visual studio will have good C++17 support. Yes, cmake is very easy to install. But my point is that there exist large bureaucratic organizations that, for dumb human reasons, don't install new software. There are a lot of such places and part of making a widely used tool is making it easy for a lot of people to use it, in whatever circumstance they find themselves.
`std::atomic`
Perhaps some of your suggestions could be implemented by allowing virtual function pointers to be declared inline in the class (as opposed to leaving it implementation-defined, which invariably means sticking them in a v-table). Inline in the class there would be far less call overhead since the class is likely to be in cache anyway when you are using it. Syntax could be something like `inline virtual f ();`, in keeping with the grand tradition of reusing keywords for as many unrelated purposes as possible ;-) Would this be an improvement, do you think? 
The (Exceptional) Static Volatiles? 
TIL PHP is not a language.
IIRC the cppcast episode on constexpr if also works with 15.3 ... The thing I tried did, anyway
Similarly, I would remove `const` and introduce a `mut` or `var` keyword, or even better a modifier character e.g. `float$`. No, not because Rust did it already but because most of my expressions are constant and I’m really lazy - `const` is a whole 5 characters dammit.
Completely agreed.
This should be coming with the modules system, but it is not coming fast enough.
Does everyone speak English over there?
There is some movement in England as well. ARM is a very strong candidate if what you are looking for is working in compilers or low level tool development. There is also a company based in Edinburgh called CodePlay who also where doing this kind of stuff for HPC. They made a presentation about parallel programming in the last cppcon.
In the office yes, English is the official language. Outside people speak enough English for you not to have problems. Companies usually sponsor French classes. Shall you be interested, pm me. PS. I'm on the beach right now.
The Destructors.
Ditch `std::numeric_limits` and add some compiler magic that lets me write double::inf!
What the hell is the EU? That ain't no country dude.
The "We Don't Read The Rules" Group.
Now that's more i like it 
You mean France right? What is this EU shit?
Are there technical reasons why ADT conflict with classes? My project is pretty object-oriented, I use classes for most concepts, but in implementations I use std::variant a lot for small polymorphic logic. I would really love a built-in variant type in C++, or at least language support for easy matching. Using lambda visitors with std::variant gets tiring very quickly.
Any ideas what good syntax for `union class` and `switch` could look like? I'm implementing them in a toy language, and they're a bit awkward. Should the `switch` be on the union's members or sub-types? I think ideally they would look like a natural extension to `enum class`.
Modifier character gets problematic when you start writing `float&amp;$`, etc.
You're interpretation is a common misconception about what inline does in C++. It doesn't mean 'please inline this', it means 'I intend for there to be one definition of this'. 
Supposedly you can also get that behavior when using an enum class without enum values (as proposed in P0138r2), though I haven't tried it yet myself...
This is true. But I hate taking up unnecessary column width. Try keeping a function that takes more than 4 const doubles to less than 80 characters ☹️ 
CMake doesn't impact build times unless you actually run CMake every time you build. And if you've been doing that, sorry but you've been doing it wrong all this time. 
Wash your mouth before taking about a Nobel prize laureate.
It doesn't matter. You do it once, and then the build scripts re-run cmake whenever necessary, which is probably not that often. People running the full cmake generation on every build run is probably the number one time wasting mistake made with cmake. 
Depends on how good you are. With significant financial industry background you can pull a couple hundred K without too much problem. 
What would that improve?
New York and Chicago financial firms 
I think the switch needs to be on the union members, with some pattern matching, e.g. union class Token { std::string op; std::string identifier; std::string literal; }; Token n = next_token(); switch (n) { case(Token::op) { } case(Token::identifier id) { intern(id); } default() {} } The idea is that you can have switch over multiple members of identical type. Bikeshed away!
That's an interesting way to do it! I've been using `std::forward` for forwarding in every case, I never bothered to think that it might save me typing just writing the cast myself in this case. Thanks!
I'm thining about using cmake for the project I'm working on. I imagine that "whenever necessary" is whenever a file is added/removed (if you add files via wildcards in your cmake files) or any cmake option changes (e.g. compiler switch). How do you determine in your projects whether it is necessary to re-run cmake? With our current system, unless you've been watching the VCS commits like a hawk you can't be certain whether you do or do not need to run our in-house project generation tool so we end up running it every time you get latest. Our project generation tool is not the fastest thing in the world so that's why I've been looking at alternatives.
What the google or facebook office in Zurich does or doesn't do is debatable. Size is not related in any way to projects, what the OP mentioned, which is: "creator of, say, compilers, libraries, real computer science research based on C++", is not part of what it does. Google is a large contributor to clang and libc++ and those people are, mostly, in the US, google create libraries and coding guidelines and the creator of said tools and standards are, again, mostly in the US. At least that is my understanding on the matter from watching talks and batting an eye over the main contributors to google os repos. But maybe times cahcne, who knows. As far as the high housing cost argument in London... yes, I'd have to agree with you. However I'm somewhat in disagreement with the low wages part, as far as my own experience has been it's quite normal for any offers from Dublin and London to be, on average, 30-60% higher than those for similar jobs or contracts from Germany in terms of net income, which offsets the hosing cost. Than again, my view is 99% of the startup market, so maybe it is skewed. However, if there's one place where hosing is more insanely expensive than in London that is Zurich.
New York Seattle San Francisco Bay Area Boston Los Angelos Washington DC Portland Vancouver Toronto
France, not EU. EU is not a country.
So there are several strategies that can be used. First, list your cpp files in your CMakeLists. If someone adds a cpp file, then the change they make to the CMakeLists file is what triggers an automatic rerun of cmake's generation of the build scripts. The downside is, of course, you have to maintain your list of source files in cmake and some people find this tiresome. If you use globs instead, those are only updated when you run cmake, so as you alluded to, you can only be sure that you are building correctly if you constantly run cmake. The benefit is less maintenance burden for CMakeLists. I personally use the second form at work, but this is a tradeoff I only chose because I work in a very small team on a largely header only project, and so addition of cpp files is rare, and easy to spot (the build fails fast, you run cmake, all is well again). CMake also has a relatively new server mode which allows tools to do things like watch directories and automatically update the build files when things change. 
I am very skeptical of that claim. 
sms is incorrect in his statement. suspend/resume are O(1) in both cases. It is just that in stackless it is significantly cheaper. In a stackless coroutine suspend is a 'ret' instruction, compare to a pile of code for the stackful coroutines: https://github.com/mirror/boost/blob/master/libs/context/src/asm/jump_x86_64_ms_pe_masm.asm. Look at the disassembly of useless.resume function which is a body of the coroutine in here: https://godbolt.org/g/X3vU7r . Pasting it here for convenience. generator&lt;int&gt; useless() { for(;;) co_yield 42; } Entire body of useless is: useless() [clone .resume]: mov dword ptr [rdi + 16], 42 ; store yielded value mov byte ptr [rdi + 20], 1 ; ret There is an extra store suspend point number instruction, but, it can be eliminated in this case. 
For game dev, Montreal in Quebec, Canada, is great. We've got a good number of big companies like Ubi Soft, EA, Eidos, Square Enix, Warner, and Bethesda. We also have a large number of start-ups mainly started by ex-employees of these large companies. You said not *only* game dev companies, but the large number of them here have attracted other software companies. Plus, Montreal is becoming an AI research city, with companies like Facebook and Microsoft opening offices here. 
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/762xlu/the_search_for_a_user_management_library/docxg1s/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; Go (~~not~~**always** a problem) FTFY
And why is that relevant for the question?
Thanks for your reply. As long as the CMake version of our project is no slower than the current system I think moving to CMake will be a positive change. I guess I have some investigating to do! I didn't know about the new server mode, I'll look into that as well. Thanks again.
No, Europe is a region of the world. The European Union is an unelected governing body.
Can I ask what you use currently? 
Yeah, "whenever necessary" is mostly whenever a CMakeLists.txt file changes. That includes you changing something manually, or a file changing after pulling from VCS. If you use wildcards to collect cpp files to build you're going to have to manually invoke CMake to pick up the changes. There's a discussion [here](https://stackoverflow.com/questions/1027247/specify-source-files-globally-with-glob) that goes into more detail, but in general it's best to explicitly list the source files you're using so CMake can track when a target's sources change and so you don't do things like inadvertently build cpp files in a directory that you meant to delete.
Wait what the narrow case where narrow is the better option? That forces virtual like dispatch almost everywhere, when I just want some data and simple operation on it. I don't want a branch nor a function table lookup. **That** is the *rare* case? No, that is 99/100 cases, and the cost-freecase at runtime. 
Hmmmm.... I wonder how they'll react? Will it be the 'C++ needs to be stay as close to C as possible to make life easiest for those who need to use both C and C++ in the same project' thing?
I believe it was C that decided C++ compatibility with C was not their problem?
I provided enough information in this thread to illustrate that 1) suspend/resume in stackless coroutines is cheaper O(1) than the stackful O(1). (ie one or two instructions vs a pile of instructions) 2) TLS is busted in stackful coroutines on (at least on arm/arm64) due to caching of TLS page in non-scratch registers and when resuming on a different thread the one that executed initially. I am not sure that I can add more information that I already provided to convince you of validity of the above statements. Remainder of the pasted information from other threads: Cheaper O(1) in stackless: Pile of code: https: //github.com/mirror/boost/blob/master/libs/context/src/asm/jump_x86_64_ms_pe_masm.asm. vs: Suspend from: https://godbolt.org/g/X3vU7r . useless() [clone .resume]: mov dword ptr [rdi + 16], 42 ; store yielded value mov byte ptr [rdi + 20], 1 ; store current suspend point ret 2) An example of TLS page caching that will get busted if a stackful coroutine is resumed on a different thread is here: https://godbolt.org/g/BQXSHq In the sample, in the beginning of the function we load an address of the TLS page in `r5` and `r6` and later access it without reload after a call to a function that can switch thread underneath. 
I don't see how Rust structs are so dramaticallyl different from C++ classes? They can implement interfaces, have private and public data. The member functions aren't implemented inline, but it's pretty similar.
At the end of the day he's still doing a basic stateful renderer. Except memory allocs are cheaper due to the ring buffer. 1. Look into stateless renderers. No one enjoys the state machine mess abstract renderers become. 2. Use a double buffered arena alloc for your commands. This is the high traffic buffer. It's also the most stable buffer in terms of size. 3. Use a separate ring buffer for vertex buffers and textures. These are typically allocated in spikes instead of every frame. I usually have singular buffer allocs bigger than my entire command buffer. Commands should be as tightly packed as possible for memory locality benefits. 4. Why is making a renderer without a mesh god object so hard? I see too many renderers do all of this amazing work only to support a single drawable type that everything has to shoehorn into. No, supporting various programmatic geometries isn't "academic" - it's reality. 
EU is Nobel laureate. Because despite being at war against each other we were able to transcends the meaning of country and state. That's why we call us a community. Did you wash your mouth before saying EU?
My point stands, if you don't want to admit it that is your choice.
&gt; What the google or facebook office in Zurich does or doesn't do is debatable. I work at Google and, for the record, the parent’s description the Zurich and Munich is accurate. In addition to the items listed for Munich, there’s a contingent working on dev infra (e.g., Bazel) though maybe that‘s what they meant by ‘tools’. 
We use an inhouse tool, based on definitions declared in XML. There are many reason why I want to move away from it, firstly it's quite slow (60+ seconds for VS solution/project generation), every time a new version of VS comes out we have to learn what the generated vcproj files look like internally, and update our tool to handle the new formats. Whenever anybody wants to add a new compiler switch in that isn't handled by our tool, we need to update it (because we serialise out the XML node as it appears in the vcproj file, instead of, say, "/O3"). Not having to maintain our inhouse tool is a massive bonus, plus the fact that we can then have the flexibility to move to different build systems as well. If CMake generation is faster than our inhouse tool then it'll make it easier for me to convince people this is the right way to go.
I mean it sounds like you just want C++ to be rust. Destructive move is a cool way to go and it's good for Rust, and so are explicitness about pointers/references, but it has its own set of trade-offs and C++ has others. Rust doesn't have hand-writable move constructors (and it's not clear how that would play with destructive move), and it doesn't have true perfect forwarding , partly because of the reference vs pointer issue (along with variadic). Etc. Non-nullable pointers are intrinsically linked to destructive move. And I have no idea what the vptrs issue has to do with string_view; again it's a set of trade-offs between vptrs in objects and out. There's many things that could be fixed in C++ with no downside if backwards compatability weren't part of it, transformign C++ into a different language with its own trade-offs is not an example of such.
Actually I don't get your point. You said "shit" "EU" "France". And that sounds offensive without you expressing any point. I'm sure you can do it. Try with a language you feel at ease with if English is too difficult.
I don't have experience with vcproj generation personally but a minute sounds slow to me. I currently see ~3 seconds for generating ninja build files for a 100kloc project, with cmake. Good luck! 
Within the EU, there are tech clusters in any of the capital cities of the bigger countries, and most of the smaller ones. The biggest difference from the US is take home pay after tax (about one third to one quarter), but in return you get a much higher quality of life, a strong safety net against misfortune including in healthcare, and the cost of children is heavily subsidised. We did a cost benefit analysis for me as a sole earner with two children of global locations a few years ago and the ordering back in 2011 came out as: 1. Ontario, Canada. 2. Seattle, Washington. 3. Berlin, Germany. 4. Amsterdam, Netherlands. 5. Brussels, Belgium. 6. Malmo, Sweden. 7. Barcelona or Madrid, Spain. 8. Dublin, Ireland. This includes taxes and cost of living, so rent, food, bills, childcare, healthcare, schooling etc. The gap between Canada and Germany was only a few thousand dollars a year, in Germany women are paid to stay at home and look after their children. It makes an enormous difference to the sums. Obviously the above ranking will have since changed greatly as in some of those places the cost of housing has nearly doubled.
&gt; Absolutely no undefined or implementation defined behavior. It's not the '70s, most CPUs are pretty consistent. Compiler authors are too clever for their own good and introduce real-world, serious security issues by undermining developer efforts (eg no-opping a memset(0) on a private key.) I am sorry, what is the defined behaviour you propose when you invoke a function pointer to (A) garbage, (B) a different function with the wromg signature? Or do you propose to make it impossible to have a non-valid value in a function pointer by (A) eliminating raw memory access, (B) making function pointers all be indexes into a bounded table, with runtime checks that the type of the call matches the type of the executed function at runtime, or (C) other? In effect, you require all raw memory access to be gone, or all pointer use to be extensively and expensively checked at runtime. The same kind of issue happens with other things that are hard/expensive to check at compile and runtime, like pointer aliasing and signed integer overflow etc, yet yield large efficiency gains. There are many languages with zero UB; they tend to look like Java, give or take details, because that more than anything else is the difference between C++ and Java. Every one of that family of languages has implementation restrictions that follow from "no UB". 
In the examples I've seen, reserve only becomes an issue if reserving on a vector at any point later than immediately after creating it. Particularly if you've been given a vector as a function parameter, say. Calling reserve on that container could have effects beyond your control if, say, your function is called in a loop or nested loop by some caller not aware of your reserve. If you just reserve right after creating the vector, I believe that you're fine. Adding caveats into an article like this would contradict the other criticisms that the article complicates itself. The advice and example are fine for the level it is aimed at. 
Autodesk is here in Montreal as well :)
Stockholm is quite good in general for IT and startups. When it comes to C++ you have few of the unicorns using that language like Spotify, King, Mojang, Skype... You also have the traditional game companies like EA DICE, Avalanche, Paradox, Uprise, Ubisoft (opened recently a new office). And you also have all the "classic giants": Google, Ericsson, HP, Oracle... Finally you have industrial companies looking for embedded devices devs like Bombardier.
Simply not true: The EU is a Union of states and as such has clearly defined borders, which encloses a certain region of the world, of roughly 4.5 Million square kilometers. As part of the contracts that establish that Union, various institutions where founded (such as the European Council, the European Commission and Council of the European Union), which you could call a governing body (although there is very little they actually "govern")
This is the first preview of 15.5, so I would hope it would get better as we get closer to release. Still, paging /u/timsneath for VS help and /u/augustinpopa for VC++ solution load. 
Coroutines allow to keep async operation context that are heap allocated in boost::asio as temporaries on the coroutine frame thus avoiding heap allocation. Default recycling allocator in boost::asio is very good as long as you issue exactly one new async operation per async operation completed as it allows to immediately reuse the memory that was just freed and stashed in the thread local. If you issue two or more operations per operation completed it will start heap allocating async contexts. In this case, coroutines will have an edge, but, boost::asio can match coroutine perf if you start associating you callback with custom allocators that will use fixed buffers in your state machine object. If you use N operations per operation completed, in both cases you would need to use dynamic allocation for the operation context, so there is no difference in this case. Note that even in the simple one for one case, boost::asio require TLS slot to work which is not needed with coroutine case. Of course, it all does not really matter since all of the overhead is dwarfed by the underlying networking overhead. But, on pure theoretical grounds, yes, coroutines are slightly cheaper.
The United States of America is just a union of states, and the European Union is just a union of European states. It's not the same yet - but from a practical standpoint for someone thinking of living/working there, it's similar enough to consider.
That's not what you said?! [Every single byte of memory returned by malloc() or new is mapped from a file. All of it.](https://www.reddit.com/r/cpp/comments/759uex/cppcon_2017_alisdair_meredith_an_allocator_model/do8ngj4/?utm_content=permalink&amp;utm_medium=front&amp;utm_source=reddit&amp;utm_name=cpp) You are **lying**. Why are you lying?
Cool. Thanks for the info. &gt;&gt; such generators will likely be marked immovable (and non-copyable) Yep. lambda* that powers the C++ coroutines is essentially a non-copyable and non-movable, hence, most uses would involve wrapping it in some usable object, like, generator, for example. &gt;&gt; C++ could automatically implement a move constructor that fixes up the pointers. I will be very interested if someone comes up with the solution for this. As this problem is similar to automatically creating a correct move constructor for an arbitrarily complex class, which, I suspect is not possible in the general case.
Not the same at all. Do you know how the USA was founded? The EU is a joke in comparison. The EU was founded for different motives entirely and has slowly been formed into a governing body that is attempting to be like the United States of America. It is essentially attempting to boil a frog by gradually turning up the heat in order to avoid the frog from jumping out. The USA used a declaration and everything was declared up front and in the open. 
Well, that's the part where I break compatibility. If you want temporals, you can add parentheses
My company has an office in Kista (inner suburb of Stockholm, the Silicon Valley of the Nordics). Most of our devs are in Göteborg, however. C, back end scripters.
String was there, though. Which is at least partly why it's got such a huge and redundant interface. 
Your understanding is an example of brain washing. The United States of America is a country. The EU is a governmental body that tries to control countries through strong arming weak countries to adopt their values for what ever agenda they have at the top down. It was not elected by the people like the United States of America and had no declaration at least in the same fashion as the USA.
Are they still paying you guys in poutine?
Can we just define `int` to be exactly 32 bits, instead? That gives us the full complement up to 128 bits with `long long`.
That's not the platform ABI problem, it's the problem of object layout and implementation. The debug version of std::string isn't the same as the release version, for example. And the gnu and llvm std library implementations are entirely different, but are source code compatibility. About the only way to do this is shipping a single canonical imp of everything. And probably still deal with version issues. 
It said it is cumbersome. However on my daily work I have never had a use case that required to be solved with C++ using type tag dispatch or SFINAE. I share Bjarne's opinion regarding how we are presenting C++ to future generations.
Remove declarations and only have definitions. You'd need some way of exporting the names for use in other units. And the compilers need to be build systems. Java is an existence proof that it is possible. 
Thanks for feedback! &gt;Why are there negative ns/block on the graph? Method of measuring was following - difference between application builded without profiling and application with profiling. Application is simple loop over N iterations in several threads. Negative value frequently appears if count of N is small. I think, real reason is context switch. When there are many iterations in both cases of measuring, average time of context switches is close. &gt; Isn't callgrind a profiler that doesn't require any setup? What does this profiler offers in comparison? @miki151 gave a good explanation! Each block has a couple comparisons and one *asm*-based call of cpu-timer. The main purpose of *easy_profiler* is to have *extremely* small memory usage and low cost of time measuring. 
&gt; Well, that's the part where I break compatibility. If you want temporals, you can add parentheses. Pretty much all the other suggestions in this topic make the language more intuative. This one made it less. a += x is a shorthand for a = a + x. Splitting apart x on various operators it contains just makes it way more complex. A better solution would be something like: a += [1, 5, 2]; for example. You can use () or {} instead of [] depending on what other changes were made to the langage. If you're going to add a list of numbers to something make the syntax show your adding a list of numbers to something.
I never said that the EU is the same as the USA or the EU is "a country". And whatever your grudges against the EU-institutions are (which - in many cases - are imho well earned) doesn't change the fact that the the "European Union" formally denotes a set of states and that was all the OP referred to. Btw: About the election of those "in-charge" of the EU: The situation is not much different then in many member states: First of all, the members of the "European Council" and the" Council of the European Union" are members of the respective member governments, so they have been elected. Second, the European parliament has been elected directly by the citizens. Finally, the European Commission is only elected indirectly by the member government but this is not so different from how many governments in the member states are indirectly selected by the parliament (e.g. Germany) where the government isn't elected directly but by the parliament. Now this is the cpp subreddit and definitively the wrong place to discuss your opinion of the politics or the legitimacy of the EU-institutions, so this will be my last post on the topic, but once again: When the OP names the EU in order to define a certain a region in the world he is interested in, he is completely correct. the EU is NOT an institution itself.
&gt;Does the UI update in real-time? How does this compare to remotery? Real-time update appears in FPS-monitor ( *Frame* means every top-level block - block without parents). For more info see release notes for [v1.1.0](https://github.com/yse/easy_profiler/releases/tag/v1.1.0) Any help with GPU or CUDA will be a very-very good! We haven't a small experience with gpu. Thanks for help!
Just realized not long ago, 15.5 ran without administrator privilege. Now with admin most of my problems are disappeared or just placebo and I'm lucky with it since then.
Huntsville, AL
I didn't discuss politics at first. I simply said vaguely stating the "EU" is a very bad way to describe location. It is vastly different in various COUNTRIES in Europe. 
I can't complain, really. I think our cost of living is lower than many of the popular US cities, so it tends to even out. 
Yes, that's right, we have both Discreet and Softimage here, right?
As a C++ dev who loved in Los Angeles for years: it no longer belongs that high up the list. There's more real C++ work in San Diego.
I don't know Rust but I would be interested too. I suppose Rust has structs that are product types, but not classes? I think it might make it easier to have two aggregate concepts in a language, not 3: 1. sum types (variant, `enum` in Rust) 2. product types (plain structs, classes with behavior?) Rather than three concepts: 1. sum types 2. product types 3. classes I think Rust has just the 2 concepts? But I'm not sure in C++ how you would define pattern matching over objects. I guess it does help that in C++ `class` and `struct` are basically synonyms, so you don't have 4 concepts! Here is a related paper by the designer of Scala: *Matching Objects with Patterns* [1] https://scholar.google.com/scholar?cluster=17799848250383236368&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5 
I addressed this a bit here, e.g. see the paper by Martin Odersky, designer of Scala. https://www.reddit.com/r/cpp/comments/7639sf/what_would_you_change_in_c_if_backwards/dod3me0/ I think it is a soft question as well as a hard one... like not just how you design the type system, but what idioms do people use? People are used to representing ASTs with classes in C++ (e.g. Clang), so I suppose now you need pattern matching over classes, not just ADTs. I agree it would be nice to have both classes and ADTs. I just recognize that it's not a trivial problem and it's not surprising that C++ didn't have it! (being C with Classes from the beginning.) 
You might be thinking of abstract data types. Here, ADT means algebraic data types, which come from the ML family of languages. https://en.wikipedia.org/wiki/Algebraic_data_type 
Why can't I build on Ubuntu and run on gentoo? (Honest question). Provided I am building with one compiler version, against same C(PP)RT and all that jazz of course.
Yeah, I overcooked that. He who ain't old enough to have done it in its heyday shouldn't do it at all. No reason to torture younger generations :-).
Can you elaborate? I heard NY salaries are rather low in comparison to average rent.
"In the EU" has an obvious colloquial meaning, that you'd have to be retarded not to figure out. Also, why are you just frothing at the mouth over the term "EU" rather than providing a valuable addition to the conversation, by pointing out to those who suggest Google in Zurich that Zurich is *totally not at all* in the EU?
Well I'm a developer at a trading firm in Chicago and the pay is pretty decent. I'm not too sure about New York, but I always see C++ jobs posted from big name companies like Bloomberg. 
No, you completely misunderstand. In most cases of pointers in general, narrow is ideal- we agree on this. In the subset of those cases where you *already* want virtual dispatch, wide pointers are usually better. They remove one level of indirection for looking up methods. They simplify object layout, especially around multiple inheritance of interface-like base classes. They greatly increase flexibility by letting you define new virtual methods without modifying the class. The "rare" case I mention is a *further* subset of the above case. For example, you might be storing a ton of polymorphic pointers. This comes up when implementing the DOM in a browser engine. Here, wide pointers introduce a lot of redundancy and it's probably preferable to store the vptr only once, next to the object itself.
You've got a point about the Thirteen (British) Colonies having already had much in common and some cohesion, the whole place being relatively young anyway, and the revolutionary war being a pretty obvious trigger event, with clear incentive for a mutual defense pact, etc. - very different places. I'm looking at it from the standpoint of many immigrants, locals, tourists. Salary, immigration/travel issues, bank accounts, which currency is being used.. these things are often more primary than the cultural things anyway, and the EU goes a long way toward removing those potential concerns.
*Some* of the problems exist *in theory*, but in practice it all works fine; as you say, we only have one copy of libstdc++. We build everything using the system's C++ standard library, and everything works together. Contrast with Windows, where several things are *simply not possible* even under the best of circumstances. You have to make sure you use the same compiler/runtime/options as you say, which makes things compatible, but even then it's *not enough*.
&gt; it has its own set of trade-offs and C++ has others. ...and my point is that this is a better set of tradeoffs. The question is "what would you change," not "how would you preserve the precise set of trade-offs that exist today" - that's nonsensical anyway. 🙄 Since I'm not *actually* proposing that C++ be replaced with Rust, there's no reason this hypothetical C++ couldn't just have move constructors *and* destructive-move-by-default. Move constructors would just no longer have to worry about leaving the source in a valid state. Perfect forwarding is a meaningless distinction in Rust, because it doesn't have references (lvalue or rvalue). Note that in this hypothetical C++ this would *not* preclude supporting both copy and move- they would no longer need separate overloads, though the caller would still be the one to make the distinction. Non-nullable pointers are *not* intrinsically linked to destructive move. C++ already had non-nullable primitives for decades before move semantics even existed. Both wide pointers and `string_view` store metadata about the *true* type of the target next to the pointer. `string_view` uses the length; wide pointers use the vptr. You can store the vptr next to the object; you can also store the length next to the chars (like in Pascal). Both of these limit your options because every pointer to the object has to use the same metadata. So if you have some *specific* downsides to these ideas I'd love to discuss them, but "they change C++'s trade-offs" is not an example of such.
Not in the EU for much longer though ;)
It works for a strictly limited set of exports. No weak linkage prevents some fairly simple things from working. Like exporting a function using a `shared_ptr` or `unique_ptr` specialised for a certain type as an argument. Or a container like `map`. What if I have more than one DLL using that type in its exports? You quickly run into fundamental limitations which don't exist on other platforms. I'd love to see real world examples of this stuff working, should I have misunderstood the limitations, but Microsoft's own documentation suggests some of this is plain impossible.
Okay, I gotta give dlib another try soon! That looks a lot better than a while ago when I last tried (might have been 2 or more years ago). VS2017.3's C++17 support is really good. Yes, there's a few unfortunate C++11 things that don't work yet... but it is very few things. And they're making good progress, I'm just downloading the 2017.5 Preview. I'm actually having less issues with VS's C++17 stuff than with gcc :-) 
Even though it's partly IA-64 specific(which I never came in contact with) I found this very interesting. Very good speaker and a joy to listen to.
ill need to take a look at the video later, but the core issue is that CMake has no namespacing, so any modularity is a joke. You either use *externalproject_add* and lose all the modules' local targets and have to juggle awkward exported variables or you use *add_subdirectory* and hit up against target name collisions in your modules and other issues involving scope when the second method works its really slick and nice to use, but once you have namespacing/scoping issues you're in a kafkaesque nightmare
shorter code is better code... :) people disagree, but I am right, they are wrong. :P
Dlib's cmake files aren't substantively different now than they were 2 years ago. I also just remembered that you and I had basically this same exchange on reddit a while ago (https://www.reddit.com/r/cpp/comments/6f06je/learn_how_to_write_proper_c_code_opencv/dielbi4/). There is a lot of bullshit on the internet about how to compile dlib. But it's always been simple. For example, here is the dlib example [CMakeLists.txt](https://web.archive.org/web/20120525105720/http://www.dlib.net:80/examples/CMakeLists.txt.html) **from 5 years ago**: cmake_minimum_required(VERSION 2.4) PROJECT(examples) INCLUDE_DIRECTORIES(..) add_subdirectory(../dlib dlib_build) ADD_EXECUTABLE(svm_ex svm_ex.cpp) TARGET_LINK_LIBRARIES(svm_ex dlib) 
I thought Robert's comment about how "adding things" to either documentation and/or implementation sometimes doesn't add much, was exactly right.
I constantly am getting recruiters calling about financial dev work in chicago. That plus the decent cost of living compared to some of the other big locations makes it a good spot for devs
Because words matter, as a programmer a slight typo can either make your program not work entirely, or have a very different unintended result that could even expose yourself to a security fault that destroys the entire internet if your application is critical. Definitions especially matter for legal definitions which gives rights to other places/people which you may of not personally intended when we are speaking about things in either a political or cultural context. Intelligent people should always value these things. Freedom requires the informed to look at facts and become educated not just follow the crowd. If it was simply a slip up then just admit it and move on. I won't hound anyone for it. I make mistakes all the time. No worries, but I always expect people to hold me to a high standard. No reason to cry about it. Just fix it and move on. People have often done it to me trust me, at first I may of not understood and and been mad, but now I actually appreciate it because it made me better. I am sure many people will correct me now and in the future. Thanks.
Casey Carter's [CMCSTL2](https://github.com/CaseyCarter/cmcstl2/) is the reference implementation of the Ranges TS, using GCC's Concepts TS support.
There are a lot more features that are really nice in newer CMake versions. For example, generator expressions are really useful and you can turn "scripts" into declarative definitions of your library. They make any type of CMake linting a lot better and easier.
I know. But what does that have to do with dlib's scripts being backwards compatible with 2.8.12? It doesn't stop you from using new cmake features in parent CMakeLists.txt files. \u\sumo952 is making an argument that I should require dlib users to upgrade to cmake 3.3 or 3.4. Why? What is the benefit, to anyone, of doing that? Just breaking backwards compatibility for kicks is not a good idea.
&gt; 1) suspend/resume in stackless coroutines is cheaper O(1) than the stackful O(1). (ie one or two instructions vs a pile of instructions) Changed output formatting for [the bencmark](https://wandbox.org/permlink/RXKKLcvDmPqwFJMr). I hope it is easier to read now. --- Using stackless coroutines: --- Accumulate result: 704982704 result = 4950105.6 # of iterations = 100001 Time: 7.53 ms --- No coroutines: --- Accumulate result: 704982704 result = 4950105.6 # of iterations = 100001 Time: 0.131 ms Stackless coroutines incur 57.3x slowdown &gt; 2) ... stackful coroutine is resumed on a different thread Name one open-source project that does this, please. 
I've been watching CppCon 2017. A comment was made by the standards committee that horrified me. Apparently, module compilation is not automated in any way. In other words, if module A imports module B, it will fail if module B has not been compiled yet. If this is even a little bit true, I've lost 60% of my interest in modules. It's time for a modern C++ replacement. :(
Complete removal of C "strings" and related support functions that just waste performance ( strlen, strcat ). You can still roll your own implementation if you really need them, can't do worse than the standard library while doing so either. However they should not be encouraged in every day code. 
Have you sucessfully used clang on windows using cmake with the Ninja generator?
I don't run with admin privilege. But /u/timsneath would know better than I about this.
I don't use CMake or Ninja for personal work, so no, but I've successfully put `clang++` and `lld-link` through their paces. ;-]
... I work with a lot of folks formerly from Discreet and Softimage, yes.
Since the parent specifically mentioned "tools", IIRC Daniel Jasper &amp; Manel Klimek are basically the manpower behind libclang, clang-format, clang-tidy... and are part of Google's Munich office. 
There are cases of undefined behavior that exists because there are cases where validating it would be really hard. It would be interesting though to test a program for unspecified or undefined behavior with such compiler.
&gt;&gt; I hope it is easier to read now. Yes. Thank you. I understand the benchmark, it nicely demonstrates that the optimizer in clang 5.0 cannot always make coroutine disappear. The discussion in this thread is about benefits of stackless coroutines relative to stackful. Hence the benchmark you posted is not relevant to the discussion. If you were to compare a generator using stackful coroutines to the generator implemented using stackless, that would be relevant. Something like: https://wandbox.org/permlink/W9koRoWAq9Z2sL9u only extended to handle the full example in your benchmark. #include &lt;iostream&gt; #include &lt;boost/coroutine2/coroutine.hpp&gt; using namespace boost::coroutines2; coroutine&lt;int&gt;::pull_type seq( [](coroutine &lt;int&gt;::push_type&amp; yield) { for(int i=0;i&lt;8;++i){ yield(i); } }); int main() { for(auto i: seq) std::cout &lt;&lt; i &lt;&lt; " "; } &gt;&gt; Name one open-source project that does this, please. Why? My point is that stackful coroutines constrain the developer on what facilities you can use in them. TLS being one example. Stackless coroutines have no such constraints. 
I'd watched the version of this talk given at C++Now and I thoroughly enjoyed it. I clicked this one mostly to see if there's anything new, and the, um, wrinkle that the author has added caught me completely off-guard. /u/tvaneerd is some sort of a mad poet and I am very much looking to his book on Postmodern C++ that is unquestionably coming out and wasn't just an excuse for a bit of wordplay.
You could change the undefined behavior sanitizer instrumentation in gcc/clang to do wacky things instead of emitting diagnostics. Usually a compiler doesn't check for undefined behavior, because it's behavior that is determined to never arise in the compilation of a conforming program.
A five year old Ubuntu release and a current gentoo release won't have the same compiler version and runtimes though. You can force it yourself by building the same toolchain on each platform, but in that case you're not really dealing with two different distributions anymore - you're doing the extra work to ensure that the toolchains and compile flags match.
Right, undefined and unspecified behavior exist to make writing a compiler easier. The point isn't necessarily to do wacky things like launch nethack. It's more to see how "broken" a compiler can be and still be technically correct. It could do boring things too like after every addition of a signed integer it could detect if an overflow occurred and call std::terminate if it did.
&gt; Some of the problems exist in theory, but in practice it all works fine; as you say, we only have one copy of libstdc++. We build everything using the system's C++ standard library, and everything works together. Same deal with libc++-based systems. If in practice you can live within a distribution's ecosystem and ensure everything is compiled against your system libraries, then yes, everything is wonderful. But as soon as you do something silly like install Steam on something newer than Ubuntu 12.04 you'll quickly find yourself trying to reconcile the differences between the runtime Steam ships and your host system's runtime. &gt;Contrast with Windows, where several things are simply not possible even under the best of circumstances. You have to make sure you use the same compiler/runtime/options as you say, which makes things compatible, but even then it's not enough. What are some of the things that don't work in this scenario?
Nobody said when :P
Something like this? https://www.reddit.com/r/cpp/comments/6xeqr3/compiler_undefined_behavior_calls_nevercalled/
I'm answering/asking more in the interests of improving my own renderer - so I'm not trying to attack (sorry) and just want to know more :D 1. I think I've avoided this, and one can avoid this, fairly easily with more modern APIs like DX12 and Vulkan so long as you keep your abstractions not *that* abstract and make the interfaces intuitive: an intuitive interface for accessing and modifying values makes it easier to not worry about saving state so much. 2. More resources on this? I'm [using a memory system](https://github.com/fuchstraumer/VulpesRender/blob/master/include/resource/Allocator.hpp) I stole from GPU-Open wherein large objects are allocated, things are bound to sub-regions. Not too fancy. This sounds like an interesting concept, though. 3. I've been meaning to implement something like this for a while. I started work on a circular buffer class, but never quite finished it. I know boost has one, but I don't want to pull in all the boost headers into my current project. Further resources, maybe? 4. This is the one I'd really like to know more about. I've currently got a "[TriangleMesh](https://github.com/fuchstraumer/VulpesRender/blob/master/include/objects/TriangleMesh.hpp)" class intended less a "god" mesh class and more as a shortcut through some of the very common steup tasks. That being said, I've never been happy with such classes in past renderer projects and I totally see why (having to shoehorn things in, not flexible, etc) - so I'd like to understand more about what you mean with "programmatic geometries" and such. Thanks for any responses you care to give, I appreciate them!
context: Know C, trying to learn C++. Why would you do that? In the context of C, I found that a lot of people recommend static by default and I understand why (I guess that's already a thing in C++ because of private as default). 
While interesting, that's sort of the behavior I'd expect a compiler to do. It's logical when you understand how compilers perform optimizations and reason about code. I wouldn't expect it to clear the stack, reset the registers and restart the program. Or delete a random file from my hard drive.
&gt; Can you elaborate? I wasn't aware of any potential loss of performance with virtual methods. Virtual methods have dispatch overhead due to indirection, and also reduce optimization opportunities since the optimizer can't see/assume the implementation. In C++, overriding virtual Base::A() with Derived::A() results in the latter being virtual even if it isn't marked as such; this means that calls to it use virtual dispatch just in case it is overridden, even if it isn't supposed to be. C++11 allows these to be marked as final to prevent this, but you still have to manually add it to each method if you can't just seal the entire class. &gt; Also insert doesn't insert if key already exists. Wtf? Well, unless you're advocating for throwing in that case, that's necessary to maintain the invariant of unique keys. It's a very useful behavior because it allows for try-add with only one lookup, a common pattern when using associative containers for caching. Some container interfaces in other languages require find and insert to be separate operations, which frustratingly involves two lookups.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/76e2nj/multithreaded_for_loop_that_updates_ui_progress/dode4t4/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
That's the opposite, actually -- what I'm advocating is that declaring methods in the class body *shouldn't* imply an code generation change. It's convenient to implement some small methods inline, but right now this also carries everything else associated with the inline keyword even if not intended. This is worse for templated classes where defining methods outside of the class body can require a lot of boilerplate. Most cases I've seen where the virtual dispatch is a performance problem are mainly due to the polymorphism, not the vtable indirection. Manually writing trampolines for the few cases where a direct function pointer would help isn't difficult. That still also wouldn't solve the delegate problem where trying to bind to virtual A::f() results in a pointer to a stub that calls A::f() instead of to the actual method. The language requires the compiler to do this to handle the case where A::f() changes implementation during construction or destruction. 
Jason always does great presentations, one of my favorites, thanks for sharing the video.
Which is what it does with `-fno-sanitize-recover`, and which is arguably just as useful in finding UB as any other "whacky" behavior could possibly be.
Except that removes the big advantage of references over pointers; that (excluding UB) they cannot be "null", making them a "fix" for the so-called "billion dollar mistake". That means that the method has to do an explicit null check at runtime (and thus cause an error at runtime) and the user of the method has to be aware that the parameter passed as a pointer is indeed required (since that convention is very often used for optional parameters).
oh! Interesting! I did not know this compiler flag existed for some reason.
You again? Didn't you already do this elsewhere on this thread? 
Interesting question... There was a somewhat similar question here: [How strict is the Multipass Guarantee in practice?](https://www.reddit.com/r/cpp/comments/5md8ef/how_strict_is_the_multipass_guarantee_in_practice/) Seems like another `vector&lt;bool&gt;` iterator situation (i.e. lying about iterator category), but one unlikely to actually affect non-pathological code.
Not OP but, i do use Clang on Windows with CMake + Ninja, never had any problem.
An example of a "widely relied-upon-but-strictly-undefined-behavior" is: S * s = (S *) malloc(sizeof(S)); This is obviously pretty common in C libraries but it violates strict aliasing rules in C++. In C++ you must use operator new, or placement new on the malloc'ed address. If you don't call an `S` constructor somehow, then an object lifetime doesn't formally begin there, and the optimizer is free to blow your program away. Nevertheless, sometimes people want to compile C code as C++ for various reasons, and "no sane compiler" would break a C++ program that does this. It's also not clear that a compiler that intentionally blows your program away for doing this is all that useful. Maybe if it had a flag to allow this case or similar cases, but catch other situations that are formally UB.
I'm not clear on the question. Are you asking about a specific implementation? The class isn't tagged as a forward iterator, or is tagged such but doesn't actually work? I just tried a simple test and I was able to copy a `sregex_iterator` and use it later, are you saying that's undefined behavior or something? [https://onlinegdb.com/HydlgGeTZ](https://onlinegdb.com/HydlgGeTZ) 
The conflict is in [\[forward.iterators\]/6](http://eel.is/c++draft/forward.iterators#6): &gt; If `a` and `b` are both dereferenceable, then `a == b` if and only if `*a` and `*b` are bound to the same object. [\[re.regiter\]](http://eel.is/c++draft/re.iter#re.regiter) shows that `regex_iterator`'s category is 'forward' but that its behavior does not meed that criteria (because it generates a new value, stored inside the iterator, each time `operator++` is invoked).
First this isn't about "useful". Second, if you want to fix that malloc bug, use this: template&lt;class T&gt; T* laundry_pod( void* here ){ static_assert(std::is_pod&lt;T&gt;::value, "POD only" ); char tmp[sizeof(T)]; memcpy( tmp, here, sizeof(T) ); T* r=::new(here) T; memcpy( r, tmp, sizeof(T) ); return r; } then S * s = laudry_pod&lt;S&gt;(malloc(sizeof(S))); is both defined behaviour *and* compiles down to the same as the `S*` cast in every compiler I checked. `tmp` is optimized out of existence! 
I like how these two posts are out of order.
Undefined behavior allows the compiler to do anything. It can be evil, not just wacky. Truly evil would be to do something almost correct. E.g., change precedence on ambiguous expressions: once this way, then that way. Instead of having quirks, gaslight the developer. 
&gt;If you don't call an `S` constructor somehow, then an object lifetime doesn't formally begin there, and the optimizer is free to blow your program away if you pretend there is an `S` there anyways. How is this different from simply trying to use uninitialized data?
Ah, I see, thanks.
Agner's microarchitecture guides and instruction breakdowns are legendary, but every time I look through this paper I get hung up on it's many, many horribly outdated sections. :-/
Can you explain this? Why do you need to `memcpy` at all if this is intended for use with `malloc`? If the user doesn't initialize their data, you're not saving them from undefined behavior anyway and if they do, the `memcpy` lines are useless. Also, doesn't this fail if `malloc` is used to allocate an array?
I think they're saying that an implementation is allowed to use a constructor call as the *only* indication of the beginning of the lifetime of a non-POD object. So even if you initialize all of the object's data members after the malloc(), if you never call an actual constructor on that object then the program has UB.
Was their anything new compared to his C++Now talk?
How does this "fix" anything? You could as well just not use malloc. Or use placement new.
Thanks, this is fixed now.
I've rewritten all the snippets of the article - hope this looks better now.
&gt; Yes. Thank you. I understand the benchmark Thank God! We benchmarked real code from real life with stackless coroutines in their natural habitat. As I told you already, stackful coroutines should be used when you need some kind of I/O. Like, for example, networking or reading/writing from/to a file. &gt; for(int i=0;i&lt;8;++i){ yield(i); } }); This is not how stackful coroutines should be used. It is like doing: for(int i=0;i&lt;8;++i){ free(malloc(i)); } Nobody does that, nobody asked for that. So I'm asking you to be closer to reality - do I/O in your example with stackful coroutines. Nobody in real life will be using stackful coroutine to count from 0 to 8. &gt; Why? Is this a secret? 
huh?
Before engaging in further discussion, I would like to confirm that you accepted my points that 1) stackful coroutines have more expensive suspend/resume than stackless and 2) stackful cannot access thread local storage safely 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/76fw8t/looking_for_someone_fairly_competent_in_cpp_to/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
This _is_ using placement new, to fix the UB. I don't understand your question.
 static_assert(std::is_pod_v&lt;int&gt;); int* i = (int*)::operator new(sizeof(int)); *i = 0; // this is UB, too!
`memcpy` is incidental; the point here is using placement new to initiate a formal object lifetime. `memcpy` itself is surely optimized out.
`operator new` is not the same as a 'new expression'. I think /u/uptotwentycharacters meant the latter with 'a constructor call'.
This was posted 3 minutes after the other one; you need to sort by 'new'. ;-]
Like I said, out of order.
How is part 2 being posted second out of order..?
Remembering if `long` is 64 bits or not is a lot harder than `uint64_t`.
Before answering these questions I would like to have my question answered (starting from question about POSIX).
&gt; You can't use char32_t on Windows? I wish I could, but except for `std::codecvt_utf8`, no part of the standard library works with it. No I/O, no regex, no collation, no classification. &gt; UTF-8 &lt;-&gt; UTF-16 is not a N:1 transformation. A codeset conversion system with that restriction is a broken codeset conversion system. `std::codecvt_utf8_utf16` does exactly this in C++ today. A potential issue is with `std::filebuf` (although does anyone really want to make it more complicated?), not with std::streambuf or codecvt. &gt; Encoding U+0065 U+0301 into Latin-1 should produce 0xE9, not 0x65 0x3F. First, it's a strawman. It's not related to what has been brought up in this thread before and is not a Unicode transformation. Second, I would strongly prefer an error when this hypothetical conversion from Unicode to ISO 8859-1 (is that what you mean by "latin 1"?) encounters U+0301, rather than a silent renormalization. There's been enough exploits on such things.
This is not really "malicious" but order of evaluation for pretty much all operators is up to the compiler and not part of the standard - this includes the order of evaluation of function arguments in a function call. gcc evaluates function arguments back to front
C++17 fixes this, mostly. See [P0145](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0145r3.pdf) and [P0400](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0400r0.html).
Sorry, god confused a bit by looking at the code and din't notice the `new`. But isn't it still an `UB` in that case? I.e. `malloc(sizeof(S))` return uninitialized memory , so won't `memcpy( tmp, here, sizeof(T)` invoke `UB` by reading it? AFAIK, there was only an exception for an `unsigned char` type.
afaik they have this idiotic system where you need to use visual studio installer to upgrade... just start typing visual studio in start menu on windows and I think you will see it.
`new` initiates a formal object lifetime at `here` (the result of `malloc`); the data that was already at `here` is then copied from `tmp` into the live object, so the object is no longer uninitialized. `tmp` is necessary because there had to be a known-initialized source of data to copy into `here` after `new`ing it.
But isn't &gt; char tmp[sizeof(T)]; &gt; memcpy( tmp, here, sizeof(T) ); Technically an `UB`? Since `here` is unitialized. 
&gt; Delete iostreams. Poorly designed, poorly performing, and the poster child for operator overloading abuse. Needs to give way for a safe, extensible system with printf-like syntax like many new languages support. I agree, but what do you consider to be a better example? C# stream abstract class?
&gt; What I would change is languages. I think this is implied. There are so many breaking changes that C++ needs to go through; it may as well be a new language. However, it frustrates me that any attempt to "beat C++" ends becoming a language that targets some other problem domain. We need a language that can still fundamentally do what C++ does.
&gt; nodiscard by default. What's this one?
Did he say that in a blog or video? I'd like to see that.
It could also initially try to do the expected thing, but check a timer and start doing the worst things a few months later.
`here` is a `void*`, and `memcpy` works with `void*`s – it has no notion of objects, it works purely with opaque bytes, which happen to be perfectly safe to store in `char`/`unsigned char` buffers.
I am actually quite happy with C++ much the way it is (if you include the trajectory of the language over the last 10 years.) What I have been seeing over and over is that other languages or libraries/frameworks/etc do something cool and then C++ adopts it externally and then internally. Using "for" to iterate through container classes would be one tiny example. So for instance, while I love Qt I would not want to see the entirety of it suddenly become part of the standard libraries. Elements, yes, the entirety, no. Also there are improvements that come from things like the IDEs. I recently used an IDE where you would use the . operator on the pointer to a class and it would automagically swap it out with a -&gt; which was perfect. I could backspace and turn it into a . if I really really wanted to. 
Isn't right shift of a signed integer undefined? But most of them do an arithmetic shift? Thank goodness! I think this is a fairly common operation. But a compiler could decide to do a logical shift if it wanted to and then I bet a lot of code would break.
It's implementation-defined if it's negative, but fine otherwise. See [\[expr.shift\]/3](http://eel.is/c++draft/expr.shift#3) for wording.
How do you compile your code? You just need to include the boost headers in the code you write and then pass a flag to the compiler so that it knows where to look. Sublime text doesn't "use" boost --- it just lets you put text into a file.
You are able to copy an `sregex_iterator` and use it later, but what you're not allowed to do is something like this: ``` auto first_match = *iter++; auto second_match = *iter; do_something(first_match); ``` As /u/dodheim mentioned in another comment, this is unlikely to affect non-pathological code, but I was surprised to see this in the standard without at least a passing mention. What I find so pernicious about so-called "stashing iterators" is that when they break, it's at runtime—not compile-time, like most problems with proxy iterators. There is another non-compliant iterator in C++17, `path::iterator`, but the standard explicitly calls it out.
Qt Creator does that.
Do you by any chance mean "how do i get autocomplete for Boost in Sublime Text"? Or, "how do i compile Boost?"
More of the latter, I get the message "No such file in directory"
I've included a test case like the one shown in their tutorial, but I'm guessing I'm missing this flag buisness. How does one pass a flag?
Thanks for the link. I tend to agree with the advice to instead break the "dereference to an actual reference" rule to increase the likelihood of errors happening at compile-time, which is why I was so surprised to see this in the standard without at least a mention. &gt; EDIT: If the iterator's operator== always returned false (except for comparisons vs. default constructed objects), wouldn't that be technically legal? That's an interesting idea! I don't see a requirement that an iterator must compare as equal to its copy. I could imagine a stashing iterator claiming compliance in that way. [\[re.regiter.comp\]](http://eel.is/c++draft/re.regiter.comp) seems to not do that, though, unfortunately.
&gt; what you're not allowed to do is something like this: &gt; auto first_match = *iter++; auto second_match = *iter; do_something(first_match); I don't see the problem with that code. Only `operator==` is affected AFAICT, and then only if one distinguishes between object equivalence and object identity.
For gcc/clang/intel compiler, it is the -I flag. I don't know what it is for msvc. g++ -I /path/to/boost/installation my_program.cpp
Well, that's like saying it's a logical shift except when it isn't. The reason it's defined when it's positive is because there's no difference between logical and arithmetic shift when it's positive.
Ah, you're right. That's normally how I think of the implications though: if a copy dereferences to the same thing, then any dereferenced value should outlive an individual iterator. If I had preceded that code with `auto tmp = *iter;`, it would have been more accurate, since then the reference is required to still be valid.
`auto&amp; tmp = *iter;`, but yeah. :-] (`auto` decays, and a copy here is necessary rather than problematic.)
video, more than 5 years ago iirc, but you can find article by W Bright about this http://www.drdobbs.com/cpp/c-compilation-speed/228701711 Reading what Walter wrote makes me doubt my 6 number, but still... general point is correct. :)
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/76gvc1/how_do_i_use_boost_with_sublime_text/dodzdfk/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/76h09w/what_to_learn/dodze3p/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Internship, not video games.
@mart_n said there is a wrinkle. 
Yes, if it is used to allocate an array, you'd have to write a different function to placement new everything. The `memcpy` is optimized out, but *if the object data was already there*, `laundry_pod` doesn't destroy it due to the `memcpy` back and forth. Which seems polite. 
You can copy from uninitialized data to a buffer of `char`. There are *no* trap representations of `char`. The value of the bytes is *unspecified* by the standard, but reading them (as bytes) is not undefined behavior. Now, reading almost any non-raw-byte type that results is going to be UB (because the standard permits the existence of trap values for most types, and does so by saying it is UB to read it if in an unspecified state, which then leads to it being UB even on systems without trap representations). 
As for "not use malloc", sometimes your data will be `free`d by someone else's code. So you are stuck with malloc. 
Could you please name a few so we can do some further research?
Doh, I actually meant to write `auto tmp = iter;` to retain a copy of the iterator, since I had the idea that keeping a copy around would require any references to remain intact even when the original changes. Upon reading the standard more closely, I'm not sure if that matters though. Of course you're right on requiring `auto&amp;` to prevent decay: I've updated the original comment to do that correctly!
I know you're sarcastic, but this would still require including this definition to every translation unit where 'this' is used to get consistent behavior across the project. 
I am very specific - adding verbiage about outdated Standards is needless complication. Warning about a current potential pitfall of quadratic complexity that developers unknowingly rush into, is necessary complication. Spend your article complexity budget carefully.
I really do hope that concepts are applied to the standard library when accepting them to the standard. What better way to iron out issues than eating your own dog food? For example, string_view is a half-hearted approach, where clearly not enough dog-fooding was done. At least I miss some operations, like string conversions. from_chars, atoi, etc should take a string_view. Now what better way to figure out the concept ABI issues than to use them in the standard library, _before_ it is standardized? Btw. no, I don't plan to write papers. Neither do I have the time, nor am I willing to travel the world to maybe get something into the standard. New features should already be coherent and usable when they are added.
Right, so I suppose I simplified a bit too much in my statement. I didn't mean that there is always dynamic allocation during type-changing operation, but rather that it *can* incur dynamic allocation. In your specific example, the optimization that Boost implements is the following: &gt; If *any* bounded type is nothrow default-constructible (as indicated by `boost::has_nothrow_constructor`), the library guarantees `variant` will use only single storage and in-place construction for *every* bounded type in the variant. Note, however, that in the event of assignment failure, an unspecified nothrow default-constructible bounded type will be default-constructed in the left-hand side operand so as to preserve the never-empty guarantee. That is, since `vector&lt;string&gt;` and `string`'s default constructors are `noexcept` (it would work even if only one of them had one), in the case of an exception being thrown during the type-changing operation, it will default-construct one of the types. You can observe the behavior I describe here: https://wandbox.org/permlink/VMkQAMWjqHbfUMeh The complete relevant details of Boost.Variant can be found here: http://www.boost.org/doc/libs/1_65_1/doc/html/variant/design.html#variant.design.never-empty
&gt;Are those jobs "good jobs" though ? Depends what you see as "good". What you write about google and fb and apple is not true for all the guys I know working with either of these, the closest is a guy working in QA at google and even he does some pretty techy stuff in between. &gt; &gt;As for startups, well, initially I was attracted by the salaries they offer, but taking into consideration that the average salary in Zurich is ~140,000$/year puts them into a rather different perspective. So in terms of local buying power at 200k salary at a startup in Zurich might be equivalent to a 100k salary at one in London. You might want to be careful with these numbers, they seem a tad high for an average. 
I don't know if there is any "malicious" compiler out there, but if you just want to know if your program is portable/UB free, there are two things you can do: - Compiler for "exotic" architectures, like dsps with non-8 bit chars or alpha with its very weak memory model. - Activate the various sanitizers on clang - they will check and report a lot of cases of UB. The main problem with the first suggestion is usually to find an architecture, that is exotic, but should be supported by your program at all (e.g. on a DSP you don't have Linux)
/u/AndrewPardoe there seems to be a large number MSVC bugs on Developer community that have languished in "Fixed - pending release" status for quite a while, is 15.5 the build we can expect them to be 'flushed'? I ask because I've been waiting for [this one](https://developercommunity.visualstudio.com/content/problem/66047/possible-compiler-bug.html) to be fixed since July and it's a show-stopper if I build in x64 :(
Yes, I agree somewhat (to largely :-)). As discussed else-thread, it's about correctly exporting template instantiations, which is not fun. But it can be done. The same thing exported by multiple modules, and random "matching" is a *bad* idea (works by accident at best AFAICanRemember). I think that's what is meant by "plain impossible" (on Windows), yes? 
Ok, that is what I was hoping for :-). Yes, indeed, there needs to be a "match", but that is the case even for one distribution: I can use different compiler versions to build different libs I use, or bork calling conventions, or alignment etc.
&gt; For example, string_view is a half-hearted approach, where clearly not enough dog-fooding was done. I sort of get why they don't like having a null-terminator, but it makes it completely impossible to pass a string_view to any external library accepting const char *. That makes it hard to love...
There is a version of gcc out there that, when UB is invoked, kills all members of the C++ standards committee and replaces them by alien body doubles that are almost exactly identical, except that they have a built-in urge to add more and more UB to the standard. This is how it reproduces.
Looks nifty. Anyone tried this in real projects?
But merely declaring a method does not change code generation; the memory layout of the class remains the same. I guess you are probably thinking of inlining, but in reality there is not much of a relation between defining a function directly in the class (which may, or may not, cause inlining), and defining it in a cpp file (which also may or may not cause inlining). This is all up to the compiler. I cannot think of any performance problems that are caused by polymorphism perse. If there is a performance problem, it is because an additional jump is being made through a vtable which may or may not be in cache. If it calls different functions (i.e. polymorphism) - well, presumably you intended for that to happen to begin with, so there's not much point in complaining about it when it does... 
That first one hits close to home for me, since I work on compilers for targets with: * 16-bit char/short/int, 32-bit long/size_t, 64-bit long long * 8-bit char, 16-bit short/int/size_t * 8-bit char, 16-bit short, 32-bit int/long, 64-bit long long (Yay #1) * 8-bit char, 16-bit short, 32-bit int, 64-bit long/long long (Yay #2) You can probably imagine the difficulty we have in using open source code where they assume size_t/char size (I'm looking at you, libc++)
&gt;Please don't use `-Werror` in build scripts for actual projects. Why? It's a great motivator to improve potentially error-prone code. 
I personally stopped using gmock unless I really have to for legacy reasons. Better to just instantiate my dependencies.
It's hard to answer this because iostreams rolled together so many different layers that are now typically handled separately. The easiest layer is formatting -- clearly inline arguments and keeping formatting state in the stream were a mistake, and with variadic templates making a type-safe printf() interface is not an issue. Many popular languages now have this, C# and Python being two examples. For raw byte I/O, a simple reimplementable stdio-like interface seems fine, as there's not too much reason to get fancy with just reading and writing blocks of data. The C# abstract interface is along those lines. One aspect I haven't seen handled well yet is buffering -- I've seen several stream systems handle this by a buffered stream adapter. It's conceptually simple but performs poorly compared to having the buffer on the other side of the stream interface. The part I'm least sure about and have the least experience with is locale/encoding. Possibilities are to establish a character stream interface or just reuse the lower-level stream interface with UTF-8. 
&gt; I guess you are probably thinking of inlining, but in reality there is not much of a relation between defining a function directly in the class (which may, or may not, cause inlining), and defining it in a cpp file (which also may or may not cause inlining). This is all up to the compiler. Not much of a relation? It is a direct request. The C++ standard says that a method declared within the class body is implicitly *inline* with a preference for inlined code generation regardless of whether the inline keyword is specified. While the compiler is allowed to ignore this in both directions, they can and do still respond to this request, particularly at lower optimization levels that inhibit speculative inlining. &gt; Well, presumably you intended for that to happen to begin with, so there's not much point in complaining about it when it does... You're missing the point. It's one thing to pay for the cost of more expensive dispatch and missed optimization opportunities when you actually need polymorphic dispatch. It's another to pay for it because the overridden method is assumed to be re-overridable in a further derived class unless told otherwise. My contention is that it would have been better to require the override to be explicitly marked virtual. Although we have the *final* keyword now, it is necessary to spam it on every method unless the entire class can be sealed. 
Why do you need to use malloc at all here? Couldn't you just use new to allocate the object to begin with?
So, say I have a class that looks like this: class ubTest{ ubTest(){data = 0;} InitUBTest(){data = 0;} int *data; }; And you declare a pointer {ubTest *ptr;} and instead of initializing with {new ubTest;} you instead call {InitUBTest();} immediately afterward, the compiler knows that the constructor was never called, but it could know that the same thing happens either way. It may be "more readable" one way, but if it's technically the same, why is one Undefined Behavior and the other is not? Sounds like a compiler problem to me.
I think there is an exemption clause for structures with a trivial layout (which include PODs).
That is an interesting observation. How do you know you are "crossing TU boundaries"?
&gt; I really do hope that concepts are applied to the standard library when accepting them to the standard. What better way to iron out issues than eating your own dog food? Unfortunately, it's not really possible to "retro-fit" Concepts into the existing standard library, hence the work on STL2. The good news is that this also provides an opportunity to fix warts in the standard library that we've had to live with for 20-odd years. &gt; Now what better way to figure out the concept ABI issues than to use them in the standard library, before it is standardized? Concepts' main job is to influence overload resolution, either by rejecting overloads outright or by introducing a partial ordering among overloads, working out when one function is "more constrained" than another (rather like the way partial specialisations of class templates select the version that is "more specialised"). Concepts have no runtime representation, and no effect on ABI.
"inline", much to the surprise of anyone who has at least a slight grasp on the English language, does not in fact mean anything should be inlined. It only means that multiple definitions of the function may be present, and that this is not to be considered an ODR-violation. And that's all. The 'old' definition, where inline was a request to the compiler to inline, has been obsolete for some time now. See also here: http://en.cppreference.com/w/cpp/language/inline As for virtual: I do agree on that, and in fact I'd choose to make `override` mandatory as well. Do you really see a big difference in performance though? In other words, are your derived classes calling virtual functions on themselves so often that it actually makes a difference? I did some investigation in my own code a while back and didn't find too many cases where a derived class was calling its own virtual functions.
Wait, I was under the impression that if S is a POD type, then it is safe to static_cast the result of malloc to S. If S is not POD, then placement new on the result will remove UB. (E.g STL's Mallocator - https://stackoverflow.com/questions/36517825/is-stephen-lavavejs-mallocator-the-same-in-c11/36521845#36521845) Is this not the case anymore? (Or has it never been the case?)
The committee is working on making `malloc`, `memcpy` &amp; friends start the object lifetime and make that legal.
Because new compiler versions add warnings (either ones enabled by default or to sets such as -Wall and -Wextra) and extend the scope/quality of existing warnings and suddenly your project will fail to build with newer toolchains when it was fine before.
&gt; "Declaration reflects use" Is that about attaching the `*` to the variable and not the type in variable declarations, and array and function pointer declarations that have the identifier mixed in with the type like `int a[N];` and `void (*foo)(int);`?
No, the standard just defines it to be UB. It's because the standard has to define a clear system in where it is clear to the compiler when object lifetime begins and when it ends. Sure, your example would technically work because the object life time **could** also be defined to begin when `InitUBTest()` is called, but that's just not how it is defined in the standard. The constructor has to be called, otherwise it is UB.
You'd need to require that the function writes to the uninitialized variable, basically treat it the same as requiring a `return` statement. 
Huh. I guess this is why I don't write "modern" C++.
It's been UB since basically forever, not just modern C++ ;)
Yea thanks. Figured. I somehow missed th `char` clause when I read that part of the spec and though it was only possible for `unsigned chars`1 (since that's what represents a `byte`).
Ah I completely misread that sentence.
You can use `operator new`. Same thing though, but more cpp-ish.
Yeah, but I don't really rely on the compiler to fix these things for me. I take on the design responsibility of making sure my code plays nice, and I tend to have very different thinking from the way C++ is/has been going. The idea of "add overhead in the language and let the compiler optimize it out" isn't wrong until the overhead you add is unnecessary. We are getting into relative necessities with C++11 on up. Personally, I find that the added language features are esoteric if you practice good design. They are great for prototyping, but when it comes down to edge cases, you spend more time debugging unexplained/undefined behavior in the new features or because you lack low-level control over your data flow.
If you have `int f();` then you can't just call `f();` and discard the return value. Right now the [[nodiscard]] attribute can be attached to functions or classes.
&gt; but if it's technically the same Pretty sure it's not. One of these calls the new operator and the constructor, the other one only the constructor, and that's a pretty big difference.
Paging /u/spongo2.. 
Sorry to your team I was wrong. At least since 15.3 seems to be working.
Yes, this is the answer I wanted to see here, thanks. If in you example we will add `noexcept` move-constructor to `Y`, we will have zero allocations [again](https://wandbox.org/permlink/5EEGS8fIJ7XUdfjt). Many (most?) of the classes can be `noexcept` move-constructible. So, `Yes` on that slide should probably read as `Rarely, you shouldn't bother`.
My favorite is Yamel.
Very entertaining and engaging talk!
IIUC the mallocator code is not related to this. The mallocator code is returning a pointer to raw memory which it has casted to `T*`. But it is not dereferencing that pointer before new, which would be illegal. Instead, it assumes that the container will use placement new at the specified address, and only then attempt to refer to a T. I don`t know why allocators in C++ return `T*` instead of `void*`. It seems questionable. Placement new works fine with `void*` anyways. I think in some nonstandard container libraries, allocators only return `void*` addresses even for memory intended for a specific type, its just a quirk of the standard library afaik.
Oh interesting. What's the motivating scenario? I'd be slightly annoyed if the compiler told me I had to catch the returned value.
OK, I had written a trivial simple example, but I forgot to include the malloc for the class itself. The example I had in my head was the class above and this: ubTest *ptr = new ubTest; ...vs... ubTest *ptr = malloc(sizeof(ubTest)); ptr-&gt;InitUBTest(); I forgot to include the malloc in the original example, but I was accounting for it when I wrote the comment above.
I'm open to being corrected, but I don't believe this does violate the strict aliasing rules in C++. First, I believe the strict aliasing rules effectively state that there are only specific situations where, given `T* p; U* q;`, `static_cast&lt;void*&gt;(p) == static_cast&lt;void*&gt;(q);`. Those situations are listed [here](http://en.cppreference.com/w/cpp/language/reinterpret_cast#Type_aliasing). I think the important thing is that malloc returns `void*`, so there is no way to access the memory without a cast, so the strict aliasing rule is not violated. Additionally, section 3.8 of the standard discusses object lifetime, and it says that &gt; An object is said to have non-vacuous initialization if it is of a class or aggregate type and it or one of its members is initialized by a constructor other than a trivial default constructor. It goes on to define the start of an object's lifetime as when: &gt; The lifetime of an object of type `T` begins when: &gt; * storage with the proper alignment and size for type `T` is obtained, and &gt; * if the object has non-vacuous initialization, its initialization is complete. Since C structs cannot define a constructor, they always have vacuous initialization. I would say that the behavior you gave an example of is well-defined if `S` has a trivial default constructor. In fact, the footnote to the section on Safely Derived pointers (3.7.4.3), sub-item 2.1 ("he value returned by a call to the C++ standard library implementation of `::operator new(std::size_t);`") says: &gt; This section does not impose restrictions on indirection through pointers to memory not allocated by `::operator new`. This maintains the ability of many C++ implementations to use binary libraries and components written in other languages. In particular, this applies to C binaries, because indirection through pointers to memory allocated by `std::malloc` is not restricted.
&gt; These should be identical things, but the compiler may warn you about undefined behavior for the latter? The latter is always undefined behavior^†, but the compiler is neither required nor likely to give any sort of diagnostic for it. -- ^(†)By the letter of the law, but in practice every compiler _must_ tolerate this for obvious reasons.
No, you're right. I had to (try to) correct a similar misconception a few months back.
&gt; But it is not dereferencing that pointer-to-class-type before new, which would be illegal. It's only illegal in certain situations. In particular the situations that make sense for compatibility with C (POD data where every bit pattern represents a valid value) are *not* undefined here.
You might want to use an object in C++ code where the storage was allocated from a C-based library, for example. So you might not be able to replace the malloc.
Thanks, glad someone else agrees. t seems pretty unlikely that the C++ standard would be written such that there is no way to allocate memory that is conformant in both C and C++.
&gt; it seems "standard layout type" is the important classification Definitely not, in this context. Standard layout types may require non-trivial initialization, which definitely is relevant here.
For example if the function returns an error code that needs to be checked.
What if I can't or won't handle it anyway?
The problem here is this requirement: &gt; storage with the proper alignment and size for type `T` is obtained According to [basic.stc], the **only** way to obtain dynamic storage is via `operator new`, thus with `malloc` alone that criterion is never met.
&gt; Standard layout types may require non-trivial initialization, which definitely is relevant here. Initialization can be done as a separate step with placement new, but you can't run the constructor on the allocated storage if doing so would be UB, no? Happy to be wrong on this but I remember wasting a whole lot more time on this research than I'd wanted.
&gt; t seems pretty unlikely that the C++ standard would be written such that there is no way to allocate memory that is conformant in both C and C++. It shouldn't seem too unlikely, since `std::vector` is impossible to legally implement as specified. ;-] (The value of `vector::data` is required to allow pointer arithmetic ([vector.data]/1), and pointer arithmetic is only legal for pointers that point into the same array; and, of course, `vector` doesn't _actually_ hold an array...)
If you use placement new then there are no requirements on the type, standard layout, trivial, or otherwise. ;-] (Ignoring references and `std::launder` for the sake of this discussion...) I thought the context of this conversation was assuming the avoidance of new..? :-S
Hmm, I'm still confused! (My apologies - I'm still relatively new to C++ and I think I didn't word my reply properly. Basically I'm not sure why `laundry_pod` is needed.) struct S { int x; }; // -- (1) Note: POD type auto s_cast = static_cast&lt;S*&gt;(std::malloc(sizeof(S))); // -- (2) s_cast-&gt;x = 1; // -- (3) auto s_buf = std::malloc(sizeof(S)); // -- (4) auto s = new (s_buf) S; // -- (5) s-&gt;x = 1; // -- (6) Basically, is `(3)` invoking UB? Or must I call placement new before I am allowed to use a POD object (E.g in `(6)`)? As I understand from cppreference, `S` is trivially default constructible, so the lifetime of the object pointed to by `s_cast`should begin at `(2)`. However, `laundry_pod` seems to suggest otherwise.
Hmm but maybe it's still okay. After all, the arena used by `malloc` has static storage duration, no? And `malloc` returns pointers into that arena. So can we consider that the objects formally have a temporary lease on memory of static storage duration for purposes of the standard?
indeed
Your question has two topics. I'll answer both a bit more completely than you need because others will see this. &gt; a large number MSVC bugs on Developer community that have languished Our bug systems work at the VS level. Bugs get triaged and reproed by a VS-level team, then sent to a team that works with MSVC. They figure out what area of the compiler is to blame and send the bug to a dev. Like any system, there are failure points. We're trying to get better. And I think your bug is a good example of how we're getting better. You reported the issue on Jun 7th. It got to Leo in a couple of days. The bug got fixed sometime in the next couple of months. Anna didn't get back to you until you pinged--that's one of the things we're really trying to improve on. We should have let you know as soon as it was fixed. Regardless, the bug was fixed internally when you asked on Aug 15th, and we told you that. &gt; is 15.5 the build we can expect them to be 'flushed'? And that's the other topic. Why, when a bug was fixed sometime between mid-June and mid-August, is it still not released in VS until October? In the bad old days this would be expected. We released VS 2015 and updated it only three times in a year. Compared to older releases of VS, three updates was frequent! But in VS 2017, updates come all the damn time. And most of the updates don't have new MSVC drops. What's up? The MSVC team had a significantly updated compiler drop for VS 2017 RTW--15.0. We did another for 15.3, and again for 15.5 and 15.6. I can't comment--because I don't really know--about the individual release dates, but the answer you want is that yes, your bug fix should appear in VS 2017 version 15.5. So what should you do now? Test that your bug fix is there. How? There are two options: 1. (Preferred) Install the [VS 2017 15.5 Preview](https://www.visualstudio.com/vs/preview/). We're pretty much done with the MSVC compiler for this release. What you see in Preview 1 is more or less what you'll get in 15.5. Your bug should be fixed there. 1. Install a ["daily" MSVC build](https://aka.ms/dailyMSVC) from our NuGet server. These toolset drops install in an existing project or solution and redirect your builds to use the project-local toolset instead of the a system toolset. There are some VS integration issues--it's primarily meant for testing--and I've been promising *forever* to get a real NuGet server (instead of the one we propped up on an Azure server sitting behind the coffee machine in our kitchen) but it works and it's a quick (~5 min) way to test for a bug fix or feature in a new toolset and then instantly (~1 min) revert to a normal, supported VS installation. Long story short: test that your bug fix is there, and I hope you see that we are getting better with our Developer Community issues. Before anyone suggests it, yes, I'd love to have something Bugzilla-like. If you work for a company with a big Microsoft support contract, ask your CEO to send a request to Satya :P
&gt; After all, the arena used by `malloc` has static storage duration, no? Interesting take, but I don't _think_ so... IIUC, in order for something to have static storage duration, that something must be a variable; and, of course, 'variable' has its own formal definition (from [basic]) whose criteria aren't met. :-]
The system is needed for constructors, and it makes sense that it doesn't exist in C, but does in C++.
Yes indeed.
&gt; Basically, is (3) invoking UB? Yes. &gt; As I understand from cppreference, `S` is trivially default constructible, so the lifetime of the object pointed to by `s_cast`should begin at `(2)`. Before initialization, the first requirement for object lifetime is the acquisition of storage, and C++ strictly defines storage requirements such that `malloc` is not a valid source of dynamic storage, _only_ a new expression is. I.e. `laundry_pod` is there solely as a placement-new wrapper so that there is a new expression to bring the _storage_ into existence. Then, because we've used a new expression, initialization becomes an entirely moot point (in general it's not possible to have a new expression without some formal initialization, and `laundry_pod` performs default-initialization in particular).
I like what they did, but the code comparison (in particular lines of code and complexity) is redicolous. The first example was plain, badly written, self-contained c++ code. The second example had some types whose implementation they did not show (e.g. path, request and response) and if I heard that correctly even had a dependency on boost hanna. The functional programming style was imho really the least important aspect of the result.
GCC is maliciously compliant, in my opinion. It's why I neither trust it, nor use it. I do not recommend it, either.
It was the copy on write that was problematic, if I recall correctly. Particularly with multi-threaded code? It has been a while.
No, you can't do that. `new` must be matched with `delete` and `malloc` must be matched with `free`. You get UB (and usually a crash) otherwise.
&gt; According to [basic.stc], the only way to obtain dynamic storage But 'dynamic storage' is not required: only storage with the appropriate alignment and size. `malloc` does not need to return 'dynamic storage' to satisfy this requirement.
&gt; Your code is portable and will behave exactly as you expect it to. It's pretty much impossible to write code that doesn't rely on some implementation defined behavior. For example, the conversion from bytes on disk to a stream of source characters is implementation defined. A compiler could conform by requiring a [png file and doing character recognition][1] to extract the stream of source characters. Maybe you don't want to go that far but there are still plenty of things pretty much any program will rely on. E.g. Annex B suggests a bunch of minimum values for various implementation quantities, such as the number of levels of nesting of compound statements and control structures. How much code is portable to an implementation that supports no more than one level of nesting? [1]: https://stackoverflow.com/q/5508110/365496 &gt; The standard is itself is sane and complete. It's not 'complete' and not intended to be.
Conceptually to you and I, yes; but in the standard there are only four types of storage and `malloc` fails the requirements for static, thread, and automatic storage, too. We are language-lawyering here, after all... ;-]
I'm going to give you the benefit of the doubt and assume you're not just being edgy for edgy's sake. Care to explain?
Two minutes in, and I can't take the awful rhyming. Nope, and nope hard.
I find it easier to read than to watch: https://github.com/CppCon/CppCon2017/blob/master/Presentations/Postmodern%20C%2B%2B/Postmodern%20C%2B%2B%20-%20Tony%20Van%20Eerd%20-%20CppCon%202017.pdf Or try the non-rhyming C++Now version: https://www.youtube.com/watch?v=GPP64opjy_Y&amp;t=3485s 
When you don't have access to the body, and thus type, of the coroutine (cf closure) on the callee side, in order to specify the type of the argument without resorting to type erasure. So I suppose technically the boundary is a little more complicated than just a TU, but it's pretty close.
I'm not sure if I read that section the same way that you do. I believe you are referring to: &gt; A C++ implementation provides access to, and management of, dynamic storage via the global allocation functions `operator new` and `operator new[]` and the global deallocation functions `operator delete` and `operator delete[]`. I don't necessarily think that precludes the use of `malloc`. It specifies how C++ implementations provide access to dynamic storage, but I don't read that as the *exclusive* method of doing so (i.e. I think your "**only**" is incorrect). 2.8.13.5 (from the 14 standard) seems to carve out an exception for `malloc` and the like. As I said elsewhere, it seems impossible to me that there could be such a drastic oversight by the standards committee to somehow make that this code: struct P { int x; int y; }; struct P *p = (struct P *)malloc(sizeof(struct P)); illegal to compile with a fully conformant C++ compiler (without invoking undefined behavior).
The wording I'm referring to is the sentence preceding that one (in C++17, anyway): &gt; Objects can be created dynamically during program execution, using _new-expressions_, and destroyed using _delete-expressions_. [... part you quoted] This doesn't seem as open-ended as the subsequent part with the "provide access to" wording, unless we get hung up on "can be" vs. "must be"... Hard to say for sure. :-S Hopefully someone more intimate with such legalese will chime in at some point.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;\*cough\* /u/tcanens \*cough\*
 &gt;Usually a compiler doesn't check for undefined behavior, because it's behavior that is determined to never arise in the compilation of a conforming program. Lol. At CppCon there was a talk on UB where the author found hundreds or thousands of UB cases in gcc itself. He said there was no canonical list of UB for C++ (unlike in C) so it is very hard to avoid UB even accidentally. 
Oh man. What an odd one. Having used gmock for two years to test a large C++ code-base I sympathize with many of the problem he lists. However, I don't think he brings any real solution to the table and his own framework is frankly ridiculous. It does *nothing* to specifically address any of the real issues presented (the solution for which is just *mock less, write less tests*), and only addresses his dislike for DSL's vs "regular C++". But its functionality is incredibly underwhelming. I'm honestly surprised he wasn't called out on it. Where to start? He goes on about Mocks risking breaking tests and creating tight coupling, but his solution is to write the expected calls as string objects? *strings*?? Which are neither parsed, nor colored, nor auto-completed, nor refactored using the IDE? How does that hold up for tests that need to be maintained? Then he does call and matching via string comparison/regex? Really? How about doing that for methods that accept or return objects more complex than std::string and int? How do I check types? How do I check object properties? And finally his solution to the *non-issue* of assertions happening during destruction is auto generating a static array of vector of strings, so each one of my tests has to repeat `ASSERT_EQUAL(ExpectedCalls, MyCalls[1])`? Maybe I'm missing something here, in which case I'll be happy if someone explains it. He also seems to completely misunderstand the role of DSL's in modern programming. He rails on against it, and mentions it apparently as a sub-bullet for how Java frameworks dealt with the lack of lambdas (What?). Maybe it was idented by mistake? There are very good reasons why modern large API's drift towards DSLs. 1. DSL's exist because no general purpose programming language is expressive enough for the purposes of complex APIs, and we need a more concise and expressive way to express meaning and abstract away implementation details. 2. DSL's also exist as bridges, because it's there's still no pattern matching, and still no reflection, and many other features that exist in other languages and are necessary for complex tasks. DSL's are also btw *regular C++* code. It's the concept of using using meaningful names to abstract away complex implementations. When you havehave domain classes with public API's then it's by definition a type of DSL. I mean, most of the examples he gives is equivalent to the builder pattern, with method chaining thrown in for conciseness. Is it sometimes abused? Sure. But ask any regular developer if builder + method chaining is more *regular C++* than template meta-programming tricks and SFINAE. Does it really need explaining why `expect(turtle, getY()).willOnce(return(100)).willOnce(return(200)).willRepeatedly(return(300))` is better code than 1. Manually checking `getY()` was called called &gt; 2 times 2. Btw, how *do* you assert it was called &gt; 2 times using his framework, , with any number over 2 being a valid result? 3. Manually reimplementing the `getY()` method (and by proxy - the full mocked interface) for each test case, with manually constructed state machines for every simple test scenario And finally, does anyone think `last(fifth(fourth(third(second(first()),foo)))` is more parse-able than `first().second().third().fourth(foo).fifth()last()`? Did I really close all the parenthesis in the first example? For which call was `foo` an argument in the first call? 
It uses undefined behavior to make unsafe assumptions which produce no warnings and create security vulnerabilities. [Example](https://github.com/weidai11/cryptopp/issues/414#issuecomment-323514576). This resulted in a CVE against Crypto++, but was never a flaw in Crypto++. Instead, it was a technical flaw in test code that was not obvious to even advanced, security-conscious developers. GCC used undefined behavior in this code to create a security vulnerability without alerting anyone.
I've already wrote some of them some time ago here https://www.reddit.com/r/cpp/comments/5k8zqq/an_amazing_set_of_resources_for_optimizing_c_and/dbn0eq2/
Looks like he did mention that there might be a performance/code size hit (didn't specify how much though).
There's no evidence of UB there, just a GCC bug. Feel free to dislike GCC, but at least do it for the right reasons. ;-]
My favorite commonly accepted UB case is the classic implementation of 'offsetof' #define offsetof(st, m) ((size_t)&amp;(((st *)0)-&gt;m)) What's the address of obj_ptr-&gt;field, when obj_ptr is 0?
GCC used undefined behavior in the test code to create a fake security vulnerability. They were screwing with the internals of a `std::string`, bypassing the API. If you do unsafe shit, unsafe shit happens. I would rather this occur than MSVC saying "everything is OK" until it suddenly isn't.
Getting informed about new potential mistakes is a desirable trait to me, but I understand your point of view. As for - Wmaybe-uninitialized, if there is a path of code that may invoke wrong behavior in runtime and compiler cannot prove it, chances are that human may also have trouble with it. It's better to safeguard or eliminate such path. 
Conceptually to you and I what? Yes, we're language lawyering, and the specification says that malloc returns storage with the proper alignment and size. And then the requirement in question is that storage with the proper alignment and size is obtained. So that requirement clearly can be fulfilled by using `malloc`. Also, storage duration is not a property of storage: it's a property of objects and variables. Storage, such as storage returned by malloc, need not be classified as having any storage duration at all in order to be 'storage' for the purposes of fulfilling the first bullet point of [basic.life].
It's not a GCC bug imo. The destructor is scheduled to run at the end of the closing block, but if it does not have side effects then by the "as if" rule it's allowed to run the destructor at any point after the last use of the string. They were poking around the inside of a string, for reasons that I actually cannot fathom. Maybe they just didn't like the string API? But at the end of the day it was unnecessary and unsafe, and they got burned.
Where was the UB? I see lots of speculation regarding UB, but no actual UB. Modifying a `std::string` via its internal array is totally fine as long as the string is sized properly (unless they were still using GCC's C++03 ABI, in which case it was a libstdc++ bug rather than GCC bug, but still not UB). What am I missing?
&gt; They were poking around the inside of a string, for reasons that I actually cannot fathom. 100% perfectly legal; why else would `std::string` have a `data()` member function? GCC bug through and through.
C++17 [basic.stc]/1: &gt; ... The storage duration is determined by the construct used to create the object and is one of the following: &gt; - static storage duration &gt; - thread storage duration &gt; - automatic storage duration &gt; - dynamic storage duration Those four durations do not include a mere call to `malloc`; a new expression must still be involved. Indeed, the only example of `malloc` in the whole standard immediately passes the result to placement new. So: yes, 'dynamic storage' is required for `s`, because that's the only possible way of creating an object with the result of `malloc`.
I'm willing to be wrong. But without seeing the code it's difficult to know. He could have inadvertently invalidated the pointer some other way. \*shrug\* But if it's just a simple GCC bug, then why wasn't a bug filed on it?
Unless I missed something it is specific to the Itanium ABI which gcc also uses for x64.
&gt; But without seeing the code it's difficult to know. He could have inadvertently invalidated the pointer some other way. \*shrug\* Agreed. Speculating without seeing the code is a bit silly I suppose. :-] &gt; But if it's just a simple GCC bug, then why wasn't a bug filed on it? I don't know that there wasn't; I'd speculate that there likely wasn't in response to _that_ Crypto++ issue because they thought there was hidden UB and they had their problem fixed, so why bother people upstream?
&gt; I'd speculate that there likely wasn't in response to that Crypto++ issue because they thought there was hidden UB and they had their problem fixed, so why bother people upstream? Fair enough! It does seem really strange that gcc would have missed a valid reference still in use. But I admit the possibility that it's a gcc bug.
Neither the C++ Standard nor the link to cppreference backs your claim of inline no longer implying a preference for inlining. The C++17 standard still has the same wording as C++03: &gt; The inline specifier indicates to the implementation that inline substitution of the function body at the point of call is to be preferred to the usual function call mechanism. Also, here's an actual modern compiler heeding implicit inline in C++17 mode: https://godbolt.org/g/2PLxRt &gt; Do you really see a big difference in performance though? In other words, are your derived classes calling virtual functions on themselves so often that it actually makes a difference? Not huge, but it does appear in profiles. The common case is when a pure virtual interface is derived from twice and methods in the foundational abstract class are used heavily by the concrete class -- for instance, virtual IObject::GetParent() = 0 implemented by ObjectBase and then used by MovingObject. Besides the performance issue, there is also maintenance overhead involved with unsealed virtual methods because any changes have to take into account the possibility of re-overloading. For that reason, I have had the habit of manually sealing methods and classes incrementally in existing codebases to preclude (or expose) this possibility. Re-overriden virtual methods are rarer and it is typically a fragile pattern anyway. This is easier done with a self-contained codebase than with a library that has a publicly exposed API, however. 
Ah that explains a lot. Thanks. ;)
Golden rule, never do it bare bones, unless for learning purposes. Always make use of a higher level C++ library like MFC, ATL, WinRT, VCL, or alternative languages like Delphi and the .NET ones.
I don't think you've justified why storage duration matters at all: storage duration is not a property of storage, but of objects. `malloc` returns storage, not an object, and therefore storage duration does not apply. Furthermore [basic.life] says: &gt; The lifetime of an object of type T begins when: &gt; — storage with the proper alignment and size for type T is obtained, and &gt; — if the object has non-trivial initialization, its initialization is complete. So in order to figure out if we're meeting the requirements for the first bullet we need to know: - has storage been obtained? - does it have the proper alignment for type T? - does it have the proper size for type T? We do not need to know: - the duration of the storage - if the storage even has a property "storage duration" - what storage duration might apply to any objects that might or might not have their lifetime begin as a result of obtaining the storage All of that is irrelevant to determining when "storage with the proper alignment and size for type T is obtained," so I see no reason that anything in [basic.stc] would apply at all.
[intro.object]/1 defines the term _object_ and specifies the four ways one can be created in C++. [basic.life]/1 discusses when the lifetime of an object begins and ends, but it cannot conjure up an object where there is none. This is not strict aliasing (that's a different rule). And the cast itself is well-defined; it's using the resulting pointer to access a nonexistent "object" that is undefined.
I've edited my GP comments, so it's hopefully more correct/sensical then it was when you typed your response. Apologies for any wasted time :-[ (and thanks for pressing the issue in the first place so I could make things correct (to my mind)). &gt; I see no reason that anything in [basic.stc] would apply at all. 0. Storage duration is a property of all objects; if one has not been determined, then there is no object. Any mentions of lifetime that I made previously were incorrect. 0. The only storage duration that permits using existing storage (e.g. that from `malloc`) is dynamic storage duration. 0. Dynamic storage duration **only** comes from new expressions. So if I grasp things properly now, it's only [basic.stc] that applies to this whole discussion and not [basic.life] at all. -- ^(Man, I've really made a mess of this whole subthread. ;-/)
Beside other complaints I just want to say he is wrong about using ON_CALL instead WillOnce. It is important that your function calls DB only once/that your code does not send 2 mails to customer.../
With regards to things like autocompletion inside templates, I would suggest giving Eclipse CDT a try. It's pretty good in that regard, and has been getting even better in the past couple of years.
&gt; Neither the C++ Standard nor the link to cppreference backs your claim ... Search for the phrase "original intent" in the link. The standard contains similar wording to indicate the fact that the use of inline for ODR purposes is mandatory, while it's use as a request for inlining is optional. It's in the sentence after the one you quoted. As for your inlining example, try it at -O3, as well as without optimisation. Now it's an example of a compiler doing whatever it damn well pleases (in both cases). After that extract both functions from foo. Now try again at -O3 - it's once again inlining, despite the absence of any implicit or explicit inline. As I said before, the relationship between inline being specified (implicit or explicit) and the function actually being inlined is tenuous at best. Far more important is the optimisation level, as well as the suitability of the inline function itself. 
You didn't come off as attacking at all, no worries. Check out https://blog.molecular-matters.com/2014/11/06/stateless-layered-multi-threaded-rendering-part-1/ for code snippets and better explanations. 1. Let's say I have a mesh class that only really cares about what blend mode is used. My mesh will only set blend mode blend mode before each draw. Later on, a bug is exposed because other objects rendered before my mesh changed the viewport, stencil op, and cull face. Who should have the responsibility of ensuring state? Does every object need to apply every state to what it expects? Should objects return the state back to some default once they are done? In stateless rendering, every draw command contains the full state for that command. So each object has the guarantee of starting at default and applies only what it knows it needs. This has the added benefit of being a nicely wrapped up package if we decide to send the command to a background thread. We could even create these commands in parallel, now that each command is independent. (For parallel / out of order rendering, you design a sorting key system that dictates the actual gpu submission order)
Ah, actually I think [basic.stc] still doesn't matter, but [basic.life] doesn't either. What matters is [intro.object]/1: &gt; An object is created by a _definition_ (3.1), by a _new-expression_ (5.3.4) or by the implementation (12.2) when needed. The properties of an object are determined when the object is created. An object can have a _name_ (Clause 3). An object has a _storage duration_ (3.7) which influences its _lifetime_ (3.8). [...] _[C++11]_ So an object has a lifetime, and the lifetime beginning is not the same thing as the object being created or existing. [basic.life] is not saying that an object is created when storage is obtained, it's merely defining the _lifetime_ property of an object which is otherwise determined to exist. So we don't need either [basic.life] or [basic.stc]. However, I don't think that quite settles the technical legality of casting the pointer returned by malloc and then use the cast pointer like a pointer to a valid object. C++ specifies `malloc` by reference to the C standard. &gt; The pointer returned if the allocation succeeds [...] may be assigned to a pointer to any type of object with a fundamental alignment requirement and then used to access such an object or an array of such objects in the space allocated [...] Basically C++ is just specifying `malloc` by saying "yeah, you can do that." Then it's up to the implementation to fulfill that contract, which we might imagine it does in the following way. When we write: S *s = reinterpret_cast&lt;S*&gt;(malloc(sizeof(S))); The implementation calls a `malloc` equivalent to: void *malloc(size_t) { return new (nothrow) S; } Or: static S s; void *malloc(size_t) { return &amp;s; } Or anything else that fulfills the contract. So the object's have storage duration and lifetime, but C++ doesn't specify exactly what they are, and instead we just know that they are something which meets the specified contract.
2. check the link in #1. It's basically just allocating big pages of memory to hold your commands in, instead of each being an individual alloc. We know that the memory is free to be freed once the frame is over, so we can reset the pointer to the start and reuse!
I've joked about writing this compiler (and runtime) a number of times. I want to highlight the real fundamental questions - is it OK if my implementation doesn't represent the number 17? ie can I just skip it? Can my char have the values 0 to 16, then 18 to 256? 256 seems so much more useful than 17. etc
For 4, By programmatic I mean things like particle systems or vector based geometries. In your mesh class, the vert is simply a position, normal, and one set of tex coords. You've already said you see the problem when you start wanting more. bone weights and matrixes. multi texturing. custom uniform values. It starts to feel like you need multiple mesh classes. I don't have an answer for this problem, but i keep hoping one of these talks will have it.
If you're familiar with placement new and the idea of using a polymorphic interface for allocators, cache locality, dropping memory without calling all the allocated objects' destructors, you can save time and skip to part 2 where he shows data from their benchmark of a few different allocator types. This part was more intro/review/motivation. Terminology to know for skipping to part 2: - "Wink out" :: release memory without calling destructors of individual objects - Monotonic :: bump or linear allocator - Multipool :: seems like size-segregated free lists (using CS:APP terminology)
Just skimming the first 40 pages or so... Calls clang a new compiler that might replace gcc on OS X, mentions the PathScale compiler, which doesn't even really exist any more, talks about thread local storage and doesn't mention thread_local, talks about wrapping arrays in a class that does bounds checking yet omits mentioning std::array... talks about timings on Core 2 CPUs... It just feels very old and outdated. 
I agree with you re: [intro.object] – it seems so obvious now. ;-] Regarding the rest, it still seems like a hole in the language as your interpretation grandfathers in C's alloc/dealloc functions, but _only_ C's – it leaves no room for OS/custom raw allocators, which seems like something that there should be wording for.
&gt; I simply said vaguely stating the "EU" is a very bad way to describe location Sorry, but as far as I can tell, you never wrote such a thing. First post was: &gt; What the hell is the EU? **That ain't no country dude**.[Emphasis mine] That was correct, but completely irrelevant, as the OP never claimed it was a country. And then: &gt; No, Europe is a region of the world. **The European Union is an unelected governing body.** [Emphasis mine] Which is just plain wrong, as I explained before. And I've no idea what you are fererring to with &gt; It is vastly different in various COUNTRIES in Europe. What is vastly different? Now seriously: Would you have preferred, if the OP listed all 28 member states individually?
Wow, thanks for the very detailed reply! Something I should have mentioned is that I've tried 15.5 and I still get the issue. :( I'll try the dailies and see how I go.
I would rather that the compiler *emit a warning*.
- USA: 3.797M mi² - Canada: 3.855M mi² - Europe: 3.931M mi² - Russia: 1.529M mi² - Ukraine: 0.233M mi² Look at the scale of these and keep in mind that the rest of Europe is smaller than Ukraine. Now think about what you wrote. Now have some shame and stop shitposting.
Really doesn't mean anything. Your implying land size means Europe is a country? I don't get what you are trying to say.
&gt; Getting informed about new potential mistakes is a desirable trait to me, but I understand your point of view. That's way you leave the warnings on. Turning warnings into errors just discourages enabling more warnings. &gt; As for - Wmaybe-uninitialized, if there is a path of code that may invoke wrong behavior in runtime and compiler cannot prove it, chances are that human may also have trouble with it. It's better to safeguard or eliminate such path. Maybe. Making your code warning free is definitely a good goal, but randomly breaking the build on compiler updates for working and well tested code is not very useful.
I also think that a very subtle problem many programs exhibit is that they assume an int can represent a bigger range than -2^15 to 2^15 - especially in intermediate results.
But undefined behaviour is an unsafe assumption in the code. It isnt the compilers fault if you assume undefined behavior is safe to rely on.
I don't understand why everyone gets so upset when you say the EU is not a country.
Afaik, partial specializations has nothing to do with being "more specialized". And of course you could retrofit the existing STL (in particular the algorithms) with concepts. There are already requirements on what operations the iterators have to fullfil - concepts just give you the ability to express those requirements in code. 
Oh sure. It's not like we depend on *tools* for *correctness*. Perhaps we should get rid of the type system as well, and just make *all* errors invoke undefined behavior! */s*
The compiler's job is ultimately to compile valid code; diagnostic gymnastics would be nice, but the standard specifically calls out many forms of error as 'no diagnostic required' because it's understood that the cost of diagnostics would be too high for people to pay during compilation. Tools exist – they're called static analyzers.
Given how often every compiler leverages UB to perform optimization, in a non-trivial program that would literally be thousands if not tens of thousands of warnings that no human being could possibly read through, let alone sensibly reason about.
Ah, that might be concerning. Could you please send me email at &lt;firstname.lastname&gt;@microsoft.com? I don't follow integration dates closely but this one looks like it should have hit 15.5. 
Which it probably was
Thanks Andrew. Will do.
It's hard to tell if he's a genius or just crazy, but it was a really interesting talk and he obviously worked hard on it.
Got it. Thanks!
Would the standard allow a compiler to break this for a POD struct?
I don't think it would break as much stuff as it would prevent stupid bugs.
It should not be implicit, to avoid many overflow errors.
&gt; While we're at it, disallowing the use of using namespace x; in header files I'd do it differently. Every `using` directive must be scoped, so if you want to use it in your header it's ok as long as it's not leaking out. It should be the same for cpp files as well.
Ehm, that's now what I meant, but I see your point. I meant to use untyped `new/delete` instead of `malloc/free` when you need raw memory chunk, but I glanced over the "someone else's code" bit, which is very important. If you really need to interact with some `C` lib which also takes complete ownership of memory allocated by you (which, IMHO, is a sign of a bad design), when yeah, that can't be helped. But it's more like "sad story of C++ in a nutshell".
&gt; If we're talking low level stuff, making arrays store length as well so we never have to pass buffer sizes around explicitly unless you're copying a number of characters. Well you can already ban every use of arrays in your code and enforce `std::array` and `std::vector`. You wouldn't have to break it right away, just make compiler throw warnings for C-style arrays and you can fix your code to use the proper things. Also if you can't change external code, it takes 30 sec to do a `template&lt;size_t N&gt;void memcpySafe(std::array&lt;uint8_t*,N&gt;out,...in){ std::memcpy(out,in,N);}` (casts omitted to save space)
Awesome. Something I should have mentioned in the email is that PhysX is a private repository so you'd have to be a member of their Gameworks program to view the link I gave you (though that's not a huge deal, just a simple email address + password form like any other).
Me too, it's a real pain to deal with. Until I find something better, it works for now - I named it TriangleMesh to at least better reflect that it's not a "god" class: just a convenience when you're using triangle lists. I'm curious if f-rep stuff could be used for better meshing at times, but the functions used get wicked complicated pretty fast 
It's really not implicit. An array is literally a pointer, and I don't just mean in it's backing definition, it's literally a pointer as it's interface. Array indexing is merely an offset notation. I grant that having two equivalent but syntactically different type declaration signatures can confuse people. But that only applies when people lack the proper teachings, which is often with autodidact nature of programming. Learning C/C++ one should learn of Ultimately the overflow problem still happens either way. You can take a pointer and use the index notation and still fudge up your managing of the size parameter. If your really worried you can't handle it toss your arrays behind a class and pack in the size.
I've read this many times but haven't found any article on the matter. Is there something I might read up on it? Or can it be summarized in a few sentences? What makes it impossible (ignoring the `vector&lt;bool&gt;` specialization which I have no idea why not yet deprecated).
&gt; a new expression always initializes the object, even if it's only default-initialization. That's true, but there's no requirement that a new expression also allocates the storage, which is the conversation I think we're trying to reach here. E.g. the Itanium ABI for C++ specifies separate names for both "allocating" and non-allocating constructors to handle those cases. &gt; The source of UB is the lack of any storage duration for s (meaning my GP comment was incorrect): `s` does have a storage duration: once `std::malloc` successfully returns, C++ defines it to have allocated storage that is suitably-aligned for any type. It is possible for this to be UB if the type `S` requires further initialization, so I agree that it *can* be UB. But if it doesn't then `s`'s lifetime begins as soon as aligned storage has been allocated to it. If you look at the comment I link, I reference the section where the C++ standard itself implements a placement new for `int` in terms of `std::malloc`.
Cppreference.com is not authoritative, and there is nothing in the Standard to back up its claim that the intent of the inline specifier with regard to code generation has changed. Yes, the compiler is allowed to override the inlining request, depending on circumstances and settings. So what? Not everyone uses the same compiler and optimization settings, nor does the code generator act the same way in every code situation. I have shown you proof that in-body definition of a method can affect the inlining behavior of the code generator. Your single -O3 counterexample does nothing to invalidate that. Back to my original point, defining a method within the class body implies an inlining preference that may not have been intended, and ideally would not cause this. Only the inline definition semantics would apply. 
In response to 1/2, 1 first: Sounds somewhat like indirect drawing - have you used Vulkan much? (if you have, this is gonna be awkward lol) It's already pretty easy to bounce recording off to separate threads since most of the "state" is going to be psuedo-baked into the graphics pipeline object you create and all. you set most important things there, but can also set "dynamic states" that let you modify some variables while recording commands. since each set of renderpasses (and getting into renderpasses and subpasses in Vulkan is a topic I've still barely approached) now contains most of the state it needs, it's pretty hard to run into bugs like that. Usually I break the pipelines down along class lines, so each .obj model drawn with a similar set of textures uses the same pipeline. Then I just change what textures are currently bound when recording draw commands, and render away things like push-constants are also super neat: intended for usually ~256 bytes max, they let you "push" data into any stage of the shader pipeline and access it from that shader. super useful for sending the MVP and avoiding the need to create another buffer and bind that buffer at drawtime. That and the texture binding used in Vulkan makes sorting things into buckets like the article mentions loooaaads easier. Its something I'm still working on, but I have a few ideas on how to approach it. In response to 2, this is already what Vulkan seems to do when you create command pools. If you specify the `VK_COMMAND_POOL_CREATE_TRANSIENT_BIT` Vulkan assumes most command buffers will be returned to the pool after use, and if you set `VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT` you can reset individual buffers instead of just the whole pool. Since the allocation of command buffers is only performed once per pool, I imagine the implementation does something like what you described. 
`vector::data()` (and `&amp;[0]` and `&amp;front()` for non-empty vectors) are required to return a pointer that behaves like a pointer-to-array, i.e. one that you can perform pointer arithmetic on. But, it's only legal to do pointer arithmetic on pointers that are actually, truly pointers-to-arrays; otherwise it's UB. The problem is that `vector&lt;T&gt;` doesn't have a `T` array; if it did, it woudn't be possible to have `size() &lt; capacity()`, so instead it uses a byte buffer and placement-new. Consequently, it has no real pointer-to-array to return for these member functions. It's up to the implementation to ensure this works, somehow, even though it's "technically" impossible; but obviously, because the storage is necessarily correctly aligned, an aliasing pointer is used in practice and just works.
Thanks! Should've refreshed the page, before editing my comment)
&gt; `s` does have a storage duration: once `std::malloc` successfully returns, C++ defines it to have allocated storage that is suitably-aligned for any type. Storage and storage duration aren't the same; `malloc` provides storage, but for an object to come into existence there must be a variable definition or a new expression (or compiler-generated things like temporaries), and those are the _only_ options. The only way for `malloc`'s result to affect storage duration is by using it with placement-new.
Let me rephrase. I would rather that the compiler emit a warning *in this particular instance*.
Well it works for Visual Studio 2015/2017.
&gt; The compiler's job is ultimately to compile valid code; &gt; Tools exist – they're called static analyzers. This ideology needs to change. I can conceive of no practical use for code that the developer believes is safe, but isn't. Everything is internet connected now. Almost all software has an attack surface. Defensive analysis tools need to become part of the compiler, and the language needs to make this integration easy. That's why languages like Rust are moving in the right direction, whereas C++ is continuing in an irresponsible direction which will have to be outlawed like asbestos and public smoking.
And yet your program can do shit if you forward declare as one and it's then defined with the other. The solution is obviously `#define class struct`
In _what_ particular instance? No UB was actually shown, nor code to look over. Do you have a repo link?
&gt; Storage and storage duration aren't the same; malloc provides storage, but for an object to come into existence there must be a variable definition or a new expression (or compiler-generated things like temporaries), and those are the only options. 3.8.1 clearly specifies that a C++ object whose type has 'vacuous initialization' has its lifetime begin as soon as properly aligned storage is obtained. A separate definition of a variable into that block of storage or an expression that refers to that block of storage is not required, just that the storage itself be obtained.
Yes, we have implemented a string class as a container of codepoints. Following the C++ idiom of "you don't pay for what you don't use," we believe that grapheme processing should be implemented as a layer on top of the base encoding-aware container of codepoints. This grapheme-aware layer is under development. The necessary first step to implementing a grapheme processing algorithm is a container that provides the mapping between codepoints and the underlying encoded representation of the string, which is what CsString provides. As to the current 21 bit limit on codepoints, yes the standard currently specifies that no codepoint will use more than 21 bits. Originally, the standard said no codepoint would ever use more than 16 bits. As anyone who has been in software for a while will know, standards have a way of growing past their original intent.
How about you make the initialization always go in the order of your initialization list? Is there any reason why we can't do this?
&gt; Case statements break by default. Jumps or fallthrough must be explicit. I hope you're considering making empty case fallthrough by default at least? 
I don't see why C-style arrays should even exist. They should all be replaced with `std::array` instead. That makes it easy to solve overflow errors in debug mode because you can add a check for it. For regular pointers, maybe require `//i know what i am doing` or the like before you index them?
You need to post a complete testcase with full output if you want help. Classes and structs are fundamentally identical, except for different defaults. Either can inherit from either. And questions go to /r/cpp_questions, not here. 
Another great talk by mpark! His approach reminds me of the cool [AST matcher](https://clang.llvm.org/docs/LibASTMatchers.html) library built on Clang LibTooling. Really enjoyed his talks this year, and look forward to more from him. 
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/76o52w/can_a_struct_inherit_from_a_class/dofiljk/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
While I am nowhere near finalizing my ideas, this is more what I anticipated doing: switch (x) { case (2, 3, 5, 12) DoCertainThings(); case (4, 19) { DoOneThing(); DoAnotherThing(); } }
I know what inline does in C++. What I am arguing about is that it is the wrong term to be used for this feature. 
I think the reverse happened. They added the inline keyword first in order to allow functions to be inlined, then realized that some inline functions that are in very often included headers bloat up the code size because they exist in multiple translation units, and so since the compiler could ignore inlining because it had more performance indicators than the programmers they decided to keep inline in order to have a function only defined once. 
&gt; But if it has external linkage it each then the function is guaranteed to still have a single address If it has external linkage, it needs to be defined in a translation unit, so it wouldn't have multiple addresses anyway. &gt; Since you seem to be thinking of linkage, not inline. Since the C++ designers thought that inline could be reused to specify one definition. 
void* cannot be queried though and translation to an object of a specific type cannot be automatic. 
The point is that I can have variants replacing my types and the code would still work the same, except that type checks would happen at runtime rather than at compile time. I.e. if you have the following code: int i = 0; int j = 1; int x = i + j; In languages that support variants, the following can happen: var i = 0; var j = 1; var x = i + j; With std::variant, I have to introduce casts to make my code work. So it's not the same at all. 
You have not been paying attention. It's in a parent comment. You do not seem to be a nice or productive person to engage with. I would appreciate no further exchange.
C++ already has a rule that identifiers starting with one (or two?) underscores are reserved for the compiler. They coudl have chosen one with underscores. Even if they didn't though, the chance of creating a problem in the C++ community is non-existent: if there was ever a conflict with user identifiers, a codebase-wide search&amp;replace would solve the problem in a few seconds. 
Random rant: I hate when I go to search for C++ books on, say, AbeBooks and the search engine doesn't understand the ++ so I get a couple of C books and a ton of oddball books.
That actually looks better than current C++ and pretty clear as well.
Gor, using 'fiber' will confuse people ... (fibers are lightweight threads == system level abstraction) N3985 is deprecated, the authors of N3985 suggest P0534R1 : callcc()/continuation. The mechanism of P0534 can be used to implement stackful coroutines (as N3985, see boost) or fibers (userland/lightweight threads). &gt; high memory footprint or cannot call external code trade off (vs just a few bytes for stackless) the stack is used for local data, resumable functions (Coroutine TS) allocates space only for one stack frame while callcc()/continuation allocates a bunch of memory used as stack. The benefit of allocating a bunch of memory is that multiple stack frames will fit in that stack. If you call a sequence of multiple resumable functions you need memory for each single stack frame. &gt; expensive context switch vs 'ret' or 'jmp [rcx]' for stackless callcc()/continuation does only exchange stack pointer (register) and instruction pointer (register) &gt; thread_local access =&gt; UB, in stackless thread_local access well defined why could the mechanism of stackless thread_local access not be applied to stackfull one? &gt; complier has no ideas about fibers, stackless are optimizable callcc()/continuation could benefit from same optimizations if cumpiler support would be added &gt; compatibility with the third party code that can get confused when you switch stack underneath why? for the caller the call stack looks like an ordinary call stack. with resumable functions you can't suspend from within a third party code (callbacks) if not ALL functions the call stack are resumable functions too. &gt; cost varies dramatically across platforms. highly platform specific facility applies to ordinary code too ... the code depends on calling convention and architecture &gt; some architectures, sliding register windows, very difficult (if not impossible to implement) we have had an implementation of architectures using sliding register windows (SPARC)
the resumeable function allocates it's own stack frame if it has to suspend and has local data that have to be preserved (restored if resumable function gets resumed). Inside a resumable function you can call arbitrary functions that use the application/thread stack for their own stack frames -&gt; calling sub-routines generates a call stack (chain of stack frames). But you can not suspend from this deep call stack. All the stack frames have to be unwinded/removed from the application/thread stack before the resumable function suspends. Otherwise the code executed after the resuamble function has suspended/returned would overwrite the stack.
If P0534R1 would get compiler support it could use the mechanism too.
In your code, what about headers for binary libraries?
I'm not sure why you point to an 4 years old repo?! take a look at https://github.com/boostorg/context/blob/develop/src/asm/jump_x86_64_sysv_elf_gas.S 1.) the code you citing belongs to callcc()/continuation and it does preserve the registers that must be preserved between functions calls as the calling convention defines - that's the the code the compiler already generates if you call a ordinary sub-routine from a ordinary routine. Special at this code is only the stack pointer/register exchange and the jump (jmp r10). If callcc()/continuation could benefit from compiler support as resumable functions do, of course not all registers have to be preserved (only the registers that are used). 2.) callcc()/continuation does not use TLS in its implementation. Additionally, if the user code uses TLS and the code (callable) is moved to another thread of course that you get UB. But that is true for ordinary code as well as for resumable functions too. So it is NOT a special issue of stackful coroutines/context-switching.
You can use the preprocessor to handle those cases. Also, the compiler shall have flags to turn on/off certain behaviours, allowing old code to compile with old behaviors. 
1.) The code is from boost.context. Because boost.context has no compiler support it must fulfill the calling conventions defined by MS. That means I've to store/restore the state of some SSE registers etc. If the compiler could proof that SSE callcc()/continuation are not used the code simple doesn't need to store restore the registers == should be the same optimization as resumable functions benefit from.
Gor, this is true because resumable functions benefit from compiler support. As I already wrote, boost.context doesn't have compiler support. If the compiler could inspect the code for callcc()/continuation too, the code could becomde cheeper too.
It could be made inline-able but MS decided to remove support for inline assembler for MS VC x64.
Preprocessor does not fix the use of identifiers as function/structure/classes that are stored in a .dll/.so.
It can change the keywords though to avoid clashing with existing ones. 
Traffic is a nightmare, though. 
I agree, but I have seen much worse than this. I would say this is an average traffic.
Good thing to see people are sill misunderstanding C++. [Bjarne Stroustrup's talk](https://youtu.be/fX2W3nNjJIo) in CppCon 2017 is more relevant than you think.
I didn't see any Fortran 'language feature' in this article that couldn't be done as a library in C++. 
The problem goes deeper than that though. Someone who doesn't understand that in C++ one should use stl containers and relay on smart pointers and destructors is one who is willfully ignorant. Most people that keep on using very old languages (be it Fortran or Cobol or C) do so because they do not wish to learn new languages. The arguments they construct are excuses and if you tare one of them down they will ignore your point of view or construct another. The talk which is actually relevant here is: https://www.youtube.com/watch?v=D7Sd8A6_fYU 
I'd like to think that discussions on the internet with people I don't know and where the outcome doesn't really matter don't upset me (I might be wrong), but what annoys me is that you keep alternating between raising straw mans (neither the OP, nor I claimed the EU is a country) and claiming wrong facts (the EU is not a governmental body and you didn't write what you claimed you did). Oh, and implying that your discussion partner is brainwashed will rarely win him over to you.
I guess if those libraries existed the discussion would look different
&gt; C++ requires the following code: int ** array; array = malloc(nrows * sizeof(double * )); for(i = 0; i &amp;lt; nrows; i++){ array[i] = malloc(ncolumns * sizeof(double)); } *shivers*
Have fun doing astrophysics simulations in python :)
It is amazing how much is wrong with those few lines of code.
"People still prefer Fortran over C++ because when you use a C++ compiler to compile C, the Fortran equivalent of the C code is syntactically simpler."
I worked in a nuclear energy company. They all used fortan and the interns also used fortan. Most of them are proficient in C++ and Python. Well written python code(mostly for IO were as fast as C++). The reason is they have plenty of legacy codes and the developers who wrote those are either retired or left the company. So, many didn't want touch that part. The project managers didn't want to spend money to migrating the entire code base to C++. And, they faced huge shortages of developers and shortage of fund to hire a 3rd party to manage the code.
Worse. Why would a C programmer malloc nrows+1 times when you can just do it once? double *array = malloc(nrows * ncolumns * sizeof(double)); If one really want the matrix syntax `m[i][j]` so badly, totally 2 allocation is enough. double **m = malloc(nrows * sizeof(double)); for (int i = 0; i &lt; nrows; ++i) m[i] = array + i * ncolumns; (Forgive me if it has bug. I am not good at C. Just showing the idea.)
Well alrighty. Great minds think alike/Fools seldom differ* (delete as appropriate)
Afaik the workshops are not recorded. Only the talks and keynotes + lightningtalks. The open session content is also not recorded.
As someone working in an oil company with a bunch of (Geo)physicists, I don't really mind they using Fortran *for maths*, it's really better than C/C++ for vector/matrix operations. What really bothers me is they using Fortran for doing *non-math* stuff. I've got around an high performance I/O library and a heap implementation. It's gruesome.
Or just use a reference...
I'd like to bump this one for Amsterdam. There's a pretty good C++ community out here, mostly fed by the finance and navigation sectors of the industry (I'll leave googling the company names to the reader so as not to turn this into an advert), and there are also quite a large number of start-ups in the region.
This cannot always be done. For example in Qt, an object inheriting from QObject needs a default constructor. In such case you cannot have a reference member; this is where not_null can be useful.
references have a problem though: if you return a reference into an `auto` you will get a copy instead of the reference. with not_null you get the pointer behaviour without (semi-hidden) copies.
Oh hey, it's that lady from Jetbrains who has helped log a bunch of issues in their bug tracker. She does great work.
that's typical over engineering and totally not c++(not even modern). If the function require a non null pointer, just use reference instead, which will force user to dereference his pointer. And if he forgot to check before dereference, he also got a SIGSEGV.
 // my straw-man memory allocations tracker // class AllocationTracker { public: template&lt;typename T&gt; void track(gsl::not_null&lt;T*&gt; ptr); // place pointer in internal storage void stop_tracking(gsl::not_null&lt;T*&gt; ptr); }; This (fictive) class receives pointers when they are allocated (through whatever mechanism) and removes them at a later point. Because they are removed before end of lifetime of the class, _you cannot use references_. While the solution in most cases is "or just use a reference", using a reference and a non-null pointer are different beasts and not (really) interchangeable.
The article name could also be 'why a lot of physicists' code is an unmaintainable mess of spaghetti code'. As a physicist I can confirm. A lot of the time is spent coding but coding skills are not taught extensively enough. It's not that easy to pick it up on the go because a lot of your peers don't care enough to go past the single-file-single-function-with-thousands-of-lines stage. Even more, they are convinced there is not much to gain from proper coding. The physicists that care enough to teach themselves to code properly generally become very good at it though, you just have to love programming enough.
I've been doing some python recently so I typed `if (... and ...)`, hit compile and started testing. A bit later I looked at the code, saw `and` and that it compiled, and was surprised. Note that I like the usage of `and`, `or` and `not` in python, if it wouldn't be such an obscure feature I'd start using this in my C++ code as well.
I am using those keywords in C++ because it is easier on my eyes in between all the *. [&amp;] -&gt; &lt;T&gt;
These are pretty handy with template-heavy code where you have all kinds of symbols everywhere. Way easier to read in that context. I kind of just started using them everywhere after that.
Well, given my understanding of inline, it makes 100% sense to me. What alternative do you suggest?
The other day I saw a bug in production code where `&amp;&amp;` got mistyped with `&amp;` yielding an unexpected result. I wonder if using `and` and `bitand` respectively could prevent that from happening.
I almost always use `not` instead of `!`. I feel that it's harder to miss when reading code, and somewhat easier to grep.
I don't see a reason why it can't look like this: template&lt;typename T&gt; class AllocationTracker { public: void track(T &amp;); // place pointer in internal storage void stop_tracking(T &amp;); }; 
The real question here is if you can have a different override for '&amp;&amp;' and 'and' on the same type
You realized that only 42 minutes ago? I never use &amp;&amp; or ||
Lips?
Works out-of-the-box on FreeBSD 12.0 CURRENT with LLVM 5.0.0. ```sh clang++ -std=c++17 -O3 -flto=thin -c main.cpp clang++ -fuse-ld=lld main.o -pthread -lc++experimental ```