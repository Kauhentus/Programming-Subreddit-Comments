Julia is fucking awesome.. -Kyle;)
Same ;) 
These are very interesting, is there a roadmap for the Julia project anywhere?
JAJAJAJ FEO 
Julia doesn't have any such thing as a Java/Ruby style object. Being a primarily functional language (with some imperative, but no OOP) means that data and functionality are seperated - `int` is nothing but a list of bits, and `print` is just a function which prints. Both are abstract enough to make sense in the global scope. The really nice part about Julia is that you can connect any type of data to any function at any time, which just isn't possible (or at least is much harder) in OO languages like the ones you mention.
&gt;&gt; The really nice part about Julia is that you can connect any type of data to any function at any time, which just isn't possible (or at least is much harder) in OO languages like the ones you mention. Are you talking about the multiple dispatching thing? Cause that's pretty neat. edit: Thank you for the clarification.
Yeah, that's the one - it's really cool, and pretty much unique as far as I know. (Clojure has a similar thing in protocols, but they're less powerful and aren't used throughout the language, and Mathematica's version is more powerful but really slow).
I looked around at the docs to make sure I wasn't missing some low-hanging fruit from the authors of the language themselves but I found nothing. My guess is that they're referring to your ability to rewrite the standard library as you wish because they've exposed it all to the runtime environment. This differentiates Julia from a language like R (as we are always wanting to compare these two languages, for obvious reasons), where a good proportion of the language is actually written in C and is only opaquely exposed to the user at runtime.
That actually makes a ton of sense. Also kind of explains the whole bootstrapping/self-hosting design choice as well!
Good writeup! I suggest trying out [IJulia](https://github.com/JuliaLang/IJulia.jl) for writing Julia code. I'm starting to really like it.
Is there any plan to integrate graphics into the REPL in the Sublime plugin? That's the hardest part of using SublimeText for R and Julia at this point.
Interesting, has anyone tested to see if it still works?
JuliaQuant appears to be an R Quantmod/QuantStrat inspired quantitative trading development framework for Julia. I just learned about it recently and thought I would mention it.
From [Dahua Lin's pull request (#5294)](https://github.com/JuliaLang/julia/pull/5294), which sped up these sorts of operations by 2-16x.
I think so, I think a "killer app" written in the language would do a lot to encourage people to give it a look. The biggest issue with Python most people have is its performance. 
One problem is that people assume that Julia is for scientific computing only. Which is partly true, most of the libs are scientific computing related, but Julia minus the libs is a general purpose language.
I've just started using Julia. Do you get the speed benefits of Julia when you're not doing mathy stuff? For example, if you're working with strings and dictionaries?
I see Julia as an alternative to languages such as Matlab and R. Python, I don't know. Technically it probably could be a replacement. However, culturally, it may not because replacing Python is apparently not the aim of the community. My understanding of Julia is that it tries to be the ultimate language for scientific computing, and to me it looks very convincing at that.
When I started to program in R, I was really annoyed about the indexing starting at 1. Then I was surprised how quickly I adapted and how it really doesn't matter much.
Julia actually has the specific goal of *not* treating the mathematical stuff as a special case. Most of the "fast-as-c" stuff is actually written in Julia (unlike R, python etc.), which means that any custom code you write will be just as fast. So in short, yes.
The language looks like a great fit for much of what I need to do at work and I'll be taking a closer look. I did some trial programming in Python in late '12 and ran screaming from that train wreck. Between the v2/v3 schism and broken package management system I'm not going anywhere near it. I'm currently using R for that kind of thing, and it's a horrid language, but I know that it won't subtly fuck me when I've too much invested to switch horses.
FWIW, I'm starting to experiment with Julia on 10.9 and Ubuntu 13.10.
I find python very productive. I am not sure how the package management is broken. I use the pre-built Enthought package for OS X, avoiding lots of manual installs. I have installed packages on top of that without problems, except for a FORTRAN compile issue I think is OS X related. The 2/3 schism is unfortunate. I am using 2. I am not a real fan of languages that keep evolving anyway. At some point, the language should stop evolving (the libraries should keep growing and improving). Perhaps I'll go to Julia before the need to move to Python 3. 
Julia will never be an alternative to Python, because Python is a general purpose language while Julia is aimed at scientific computing. But Julia could replace Scientific Python (Python with scientific libraries, Numpy, Scipy, Pandas, etc). As for Go; can Go be used for scientific computing at all?
What exactly makes Python better for general purpose progrmming, e.g. for making web applications?
Huge amount of libraries and pre-existing code. 
&gt; Is R packaging system better than python's in your opinion ? My opinion on Python isn't worth much. I've had zero trouble with R's packages and packaging system in a couple years of use. The two or three days that I spent trying to get off the ground with Python 3 were a disaster. I gave up at that point.
You can use the function to_dot to convert graphs to the GraphViz format and then use its dot command to generate a postscript file like this: dot -Tps filename.dot -o outfile.ps dot -Tpng filename.dot -o outfile.png
One of Julia's main goals was that you don't have to use multiple languages (i.e. R for calculations and Python for web backend). One of Julia's creators said that he considers Julia to be a general purpose language. It's just a matter of libs really.
There is a plot function in Graphs which uses graphviz, so you'll need graphviz installed. Edit: It looks like it calls to_dot and tries to pop open graphviz to display it. 
Very nice notebook! By the way, we are working on a [DSP library for Julia](https://github.com/JuliaDSP/DSP.jl). In case you want to play with infinite impulse response filters, take a look :)
Python is heavelly optimized for text manipulation. Most of the standard library is actually written in C and wrapped for Python. That's why it performed so well ; ).
So.... the test was against a 200 ms runtime? And no one thought to ask the question, I wonder how long it takes for the JIT to warm up? 
You're absolutely right, I was still surprised though. I expected Python's function call overhead to be significant. This is the faulty intuition that comes from Python numerics experience. Also, it's not so much CPython's optimization towards text as it its highly optimized dictionary data structure.
Strings and dictionary performance in Python is actually pretty decent.
I didn't think your tone was aggressive at all. You raise really good points. Good points are always welcome. I'm planning to do a multiprocessing test on all of Project Gutenberg soon. Maybe I'll post it up next week. Presumably that would be real-world enough? :-)
I admit, real world is pretty subjective. Usually I only worry about language performance when run times are a potential issue. But looking at it from a multiprocessing standpoint could be interesting. Another way of considering the problem is how clear and understandable are the optimized solutions. In the asynchronous programming world that's a big deal, where sometimes the fast code is impossible to work with cleanly. The Twisted framework is notorious for being ridiculously difficult to understand. I'd love to see node.js included in these tests, just for fun. EDIT: Additionally I think looking at these snippets is a good idea in general anyway. 
I love it. Just try posting to julia-users, julia-dev, stackoverflow with a Julia tag, JuliaLang Issues and see if you don't get a response from Stefan Karpinski within ten minutes. I wonder what happened to his community during the hour he was giving this talk.
Regardless of language, multithreading is not a good solution for I/O-bound problems. The limiting factor is the hard disk throughput, which should be around 100MB per second or better. Do I guess correctly that your directory contains roughly 3GB of data?
Yes, something like 2 GB, but this is just an example, I have bigger corpora of about 20 GB. So a single thread is as fast as I'll get and I shouldn't worry trying to make my functions parallel?
There are *some* ways to improve performance, but I don't think they are useful here: * [memory-mapping](https://en.wikipedia.org/wiki/Memory-mapped_file) the files instead of reading them traditionally can improve performance in some scenarios * distributing the task among multiple nodes which each have a copy of the data. Each node works on it's part of the data, the results are later combined. * using a SSD instead
This is great, looking forward to future posts. Also, does anyone have insight on Julia parallel programming on google vs amazon cloud compute services?
Julia is the language that everyone loves to love. But I still haven't seen anyone put it into production.
~~The Gadfly package can write a graph to file, I'm not sure if it can write to a new window like R or Matlab.~~ Edit: not what he was asking...
Have a look at [Tk.jl](https://github.com/JuliaLang/Tk.jl) - it's got decent documtention in `examples/`
Why not be the first?
[Author here] Thanks! Funny you should ask, I was thinking of branching into parallel programming for my next post. Afraid that I don't have comparison data for parallel programming in particular, though there have been a few blog entries published on speed in general.* *Disclaimer: I'm a Developer Advocate for Google Cloud Platform
To be fair, it is extremely young, and still a moving target. Writing production code in it might be a bit risky at this point in time. However, the Internet is littered with neat little examples, and test projects. 
Memory-mapping the files might be what you're looking for then; Julia has some standard library functions to help with that: http://docs.julialang.org/en/release-0.1/stdlib/base/#memory-mapped-i-o It's more focused on numeric data rather than text, but it might help you.
Each computer gets one REQUIRES file; this lets you say which packages you want installed. Each Julia packages gets it's own REQUIRES files; this lets it state it's dependencies. Your installed packages would be the union of your REQUIRES file with the REQUIRES of each of the packages in it. Pkg.generate("pkgname","license") is useful for creating the basic framework of a new package. I'm not sure it creates the REQUIRES file (I think it depends on your version of Julia). http://julia.readthedocs.org/en/latest/stdlib/pkg/ Pkg.clone("url") will come in handy for your team to install your unpublished package through the package manager -- meaning that it will use the REQUIRES file and install the dependencies. 
Thanks for the message! I'll look into google compute engine more as I haven't used it before. I'm interested in ease-of-use i.e. how quickly I can get a scientific computing project including external libraries up and running on there. Looking forward to a post about Julia parallel programming on gce!
doesn't this method require me to know beforehand how big the file I want to read is?
[**@redrapids**](https://twitter.com/redrapids): &gt;[2013-12-12 12:14:57 UTC](https://twitter.com/redrapids/status/411106899489067008) &gt;Your tentative list, for retweet: Seven Languages, Seven Weeks 2. Elixir, Elm, Mini Kamren, Julia, Factor, Lua, Agda. ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/1wbxgy%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
"the One Programming Language to Rule Them All" &gt; "Bezanson says it’s not exactly ideal for building desktop applications or operating systems, and though you can use it for web programming, it’s better suited to technical computing."
I like the language, but during my first foray into some non-trivial effort (writing a game using the entity-component-system model), I really began to feel the lack of interfaces. The common approach I've seen so far uses macros, which ends up looking pretty ugly and isn't all that convenient. It feels like common lisp.
I'm currently converting a neural network from octave/matlab into Julia, and I'm really excited to see what kind of performance benefits I can get out of it.
I think julia is really promising for nlp/text processing. I hate python for that stuff, and Java is just ugly and verbose.
&gt; Stefan Karpinski &gt; I'd like to clarify that Julia was a group effort from the very beginning, and not my creation as this (very flattering) article portrays it. If anyone deserves the lion's share of the credit, it's Jeff. The business about Julia not being suited to building desktop applications is largely just a matter of ecosystem and libraries – there's nothing inherent about the language that makes it bad for that kind of thing. Operating systems are a different matter – you really want to have manual memory management when you're writing an OS.
Based on my understanding of Docker and how it can be used, I don't think that would be the case, but I really don't know enough about your situation to say one way or another. For what it's worth, the first time I heard about it, it seemed that there was much more complexity intrinsic to using it than I later learned the case to be, though you definitely *could* do something quite intricate and sophisticated with the software.
Wouldn't tail recursion optimization be required to be able to use these collections in a more functional way?
At this point I would not use Julia for any production work. We are at version 0.2. Hence the advice would be Python or, if you want complex statistics, call R from Python.
You should ask this on the mailing list: https://groups.google.com/forum/?fromgroups=#!forum/julia-users. You're bound to get a response there. 
I actually just started. Like yesterday. I'm working on a [controls library for julia](https://github.com/jcrist/Control.jl), and plan on using SLICOT for the heavier lifting. Let me know if you're interested in helping! I've never really done projects with other developers before, but would love to get people involved.
PM sent
Another thing to keep in mind is that julia doesn't covert between scalars and vectors automatically like Matlab does. 
The author mentions, "People who tend to construct novel models and fit them using optimization algorithms will find that Julia is already nearly feature-complete". I am curious, which [packages](http://julia.readthedocs.org/en/latest/packages/packagelist/) is the author referring to?
As far as I know Julia is just about to have precompiled packages (as already happens to the base system), and maybe someday even precompiled user scripts...
Thanks, I 'm sticking to python and Rpy for now. 
I am starting back on Project Euler again, using Julia as my implementation language. If you aren't familiar, you should check it out. The site offers a lot of fun numerical puzzles. Not exactly koans, but still a fun use-case if you are currently lacking good project ideas.
in short: be very careful when monkey patching
Does this actually work? I know that, for efficiency, Julia is wired to call LAPACK, and friends whenever possible. Did they also implement a `solve` in Julia that works for types that LAPACK doesn't support?
Yes, you have a good point, I don't like monkey patching too (although I'm not against having it as an option). However, while in the example I presented I'm kind of doing monkey patching as Array{Float}.^Integer is already explicitly defined in Julia, in this language we also have algorithm specialization, i.e., even if a general algorithm is written to large group of types we are able to specialize it to some types. Anyway, if a specialization is useful for enough people it will probably land on Julia Base itself.
Could you elaborate some? I'd think typed multiple dispatch with the composable abstract classes would make for effective interfaces.
it's unfortunate (imho) that tasks are less efficient than iterators; it would be nicer if all iteration could be done with tasks. having two different ways of doing essentially the same thing is a bit ugly. [i think all other differences come from library support for the two types; if they were unified the differences would disappear. but maybe i am wrong?] [the extra overhead comes from the book-keeping that tasks in tracking the current "thread"]
I am an R developer but I see lots of potential with Julia. I am using it for my ah-hoc analysis tasks, but haven't used it in any production grade applications.
[Iteration Inside and Out](http://journal.stuffwithstuff.com/2013/01/13/iteration-inside-and-out/) is a great write-up on those two different flavours of iteration. Of particular note it will quickly point out how any particular style can express some things the other cannot as easily. AFAICT though that languages typically put forward external iteration (Lisp derived or influenced languages notwithstanding, if I’m not mistaken) has more to do with ease of implementation than anything else. Looking at things like C#’s `yield`, it appears there *is* room for something that looks just like internal iteration but is friendly to the compiler/implementation.
thanks; i'll have a look at that tomorrow.
Strange things to complain about. He's clearly not thought through the tradeoffs required for indexing into unicode strings. Indexing is generally thought to be an O(1) operation, but with UTF8/UTF16 it's O(n). What's cool, though, is that Julia's iteration protocol jumps from valid character to valid character. So `for char in str` only gives you valid characters. If you really just want the `n`th character, you can just ask for `str[chr2ind(n)]`. It's easy to use an O(1) algorithm in the development of more complicated functions… but were it O(n) by default you'd have to be careful how many times you index into the string. If you naively iterated over all the characters like this from str[1] to str[end], you suddenly have ~O(.5\*n^2 ). Julia's solution to use `next` with external state is very simple and lightweight. For a performance-driven language, their choice is a no-brainer. And it's hard to take complaints about interactivity seriously when [IJulia](https://github.com/JuliaLang/IJulia.jl) isn't even mentioned. What does he mean by "lack of a printer"?
Author of the article here. I was probably too critical of Julia's string handling. I understand the time complexity situation of UTF-8, it's just that for such a high-level language it's strange to require the user to worry about the internal representation. It leaves "holes" when accessing the object with `[]` and, as far as I know, is the *only* language to do this. Go and Rust were mentioned in a comment, but neither of these produce errors when indexing bytes between characters, so they don't have holes. Except for throwing exceptions -- which I still think is a mistake -- I now think there are two good reasons to have strings index by bytes in Julia. One is Julia's FFI. It doesn't need to do any string encodings going to or from the FFI, keeping it fast. Second, I think they want the semantics of the `[]` operator to be guaranteed as O(1), and I can appreciate that. Operator inconsistency is one of those things that makes operator overloading work poorly. &gt; And it's hard to take complaints about interactivity seriously when IJulia isn't even mentioned. What does he mean by "lack of a printer"? As /u/pseut mentioned, IJulia is entirely different than what I mean by "interactive development." I mean that I want to define/redefine functions and types while the program is actively running, just like I can do in JavaScript and on any Lisp dialect. It's a really pleasant way to develop software, and Julia is *so* close to supporting it. However, since modules are all-at-once deals, it's not currently possible -- unless you completely ignore module development, which isn't realistic. By "printer" I mean a Lisp printer: a function to which I can hand any practically value/object and it will serialize the value/object into source code that can be read back in later. JavaScript gets this, albeit in an a less complete form, through JSON. Julia currently only pretty prints values in a form that can't be read back in, or in some incomplete way, and so it lacks a printer. This is unusual for a homoiconic language, where code is data. A printer is important in interactive development for examining returned and intermediate values, and even for feeding values back in as code from an editor buffer. A [printer has been on the roadmap for 3 years](https://github.com/JuliaLang/julia/issues/25) but has not been completed yet. 
OP here: I want to learn julia in the near future and exercism.io seems to be the perfect platform to learn ideomatic julia. How to contribute: http://exercism.io/about Where to contribute: https://github.com/exercism Thanks :)
Additional discussion at: http://www.reddit.com/r/haskell/comments/207fk8/julia_has_no_dependent_types/ http://lambda-the-ultimate.org/node/4902
there is a nice overview of [discussions in other subreddits](https://pay.reddit.com/r/dependent_types/duplicates/20bacr/julia_has_no_dependent_types/)
If you haven't already, take a look at http://juliawebstack.org/ 
If your project involves time sensitive/high performance/distributed computation then Julia would be worth considering. Otherwise you might also consider Go or Python. Also look at integration/development with Google App Engine for potentially "easy" scaling with a low barrier to entry.
I love Julia, and think it will have a bright future for of web programming. It is hard to know how your project will benefit from Julia, but it looks like you would benefit greatly from a mature environment that have a more standardized setup. Julia will probably require you to write much of what a framework would give you, and hosting will also be much more difficult. Julia has great performance in some important cases, but it also has some slow features. This is very nice for scientific computing, because usually 95% of the total execution time of a simulation is spent in 5% of the program, and we can optimize that part easily without leaving Julia. Websites typically spend &gt;90% of their total page rendering time, waiting for results from the database. The performance of the programming language does not matter at all! I would recommend that unless you are an experienced developer that have previously used multiple web frameworks and know what to expect from a web framework, that you don't depend on your ability to push the Julia webstack forward. You can always use julia for the cronjobs and PHP's exec() function to call a standalone Julia program for analysis of equations/datasets. 
You should look into Go (/r/golang), this is a place where it really shines.
It's worth mentioning that module aren't really "all-or-nothing", since you can in principle modify a module by evaluating in its context (via e.g. `eval(Base, :(x=5))`). The repl doesn't expose this feature but that's more a tooling issue than a language one. I'm actually working on a Light Table plugin which fixes this among other things, so it shouldn't be an issue for long. Also, can you elaborate on why serialization is needed for interactive development?
Ah, I didn't know that about `eval`, probably because it's not yet documented [in the manual as of 0.3.0-dev](http://julia.readthedocs.org/en/latest/manual/metaprogramming/). Except for being unable to redefine types, which still requires reloading the whole module, eval solves some of the problem. &gt; Also, can you elaborate on why serialization is needed for interactive development? As I mentioned before, it's often really handy to be able to dump a result into my editing buffer as code. I've done this in the past to produce constants, or to manipulate manually and pass back in. I also want a tidy, concise representation to echo in the bottom my editor to get a glance at return values. Julia currently prints arrays in a lengthy, Matlab-style format. But I guess that's my only real complaint about the format, since most other things print well. It also gets hung up on circular data at the moment. a = Array(Any,1) a[1] = a # REPL gets stuck in infinite loop This could be solved by a library, so it's not a huge barrier. JavaScript's JSON printer also gets hung up on certain types of data, and I [ended up writing a replacement](https://github.com/skeeto/skewer-mode/blob/master/skewer.js#L267) for live development purposes. 
That's a good question. Maybe you should ask on the mailing list https://groups.google.com/forum/?fromgroups=#!forum/julia-users I think you're likely to get a response from the developers there.
[Gaston Julia](http://en.wikipedia.org/wiki/Gaston_Julia) or a reference to the [Julia set](http://en.wikipedia.org/wiki/Julia_set) or both?
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Gaston Julia**](http://en.wikipedia.org/wiki/Gaston%20Julia): [](#sfw) --- &gt; &gt;__Gaston Maurice Julia__ (3 February 1893 – 19 March 1978) was a French mathematician who devised the formula for the [Julia set](http://en.wikipedia.org/wiki/Julia_set). His works were popularized by French mathematician [Benoit Mandelbrot](http://en.wikipedia.org/wiki/Benoit_Mandelbrot); the Julia and Mandelbrot [fractals](http://en.wikipedia.org/wiki/Fractal) are closely related. &gt;==== &gt;[**Image**](http://i.imgur.com/1Be4btU.jpg) [^(i)](http://commons.wikimedia.org/wiki/File:Gustav_Herglotz,_Gaston_Julia.jpeg) --- ^Interesting: [^Julia ^set](http://en.wikipedia.org/wiki/Julia_set) ^| [^Pierre ^Fatou](http://en.wikipedia.org/wiki/Pierre_Fatou) ^| [^Mandelbrot ^set](http://en.wikipedia.org/wiki/Mandelbrot_set) ^| [^Benoit ^Mandelbrot](http://en.wikipedia.org/wiki/Benoit_Mandelbrot) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cg8q56p) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cg8q56p)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
1984's [Julia](http://www.imdb.com/character/ch0083505/?ref_=tt_cl_t3)?
Have you tried https://github.com/toivoh/Debug.jl ?
link has nothing to do with julia. i don't think anyone thinks julia *doesn't* need a native debugger. as far as i remember it's waiting on some patch related to llvm. edit: dug out this thread - https://groups.google.com/forum/#!searchin/julia-users/andrew$20cooke$20debug/julia-users/zEqWxn7HDVo/ZTRZh4ziR9kJ with quote "the longer term approach to debugging Julia code is to switch to using LLVM's MCJIT for code generation, which, among other things, supports emitting DWARF debug information, thereby allowing C-style debuggers to work with Julia code."
there's an issue related to this (in which i made some less than smart comments). https://github.com/JuliaLang/julia/issues/4935
Yup. It's a bigger problem than just Julia, too. Lots of work is being done upstream in LLVM and LLDB, too [0]. I'm very excited for the prospects of a very powerful debugger in Julia. (Note that the Julia master secretly works with the svn head of LLVM with MCJIT already!) 0\. https://github.com/llvm-mirror/lldb/commit/2ea2359f488737bac692d64fb29c6a2f0b9e19f1
Stefan Karpinski gives a very good reason for final concrete types in that discussion: &gt; The fact that concrete types are final is crucial. Otherwise when you write `Array{Complex{Float64}}` you can't store them inline because someone could subtype `Complex` and add more fields, which means that the things in the array might be bigger than 16 bytes. Game over for all numerical work.
hi, sorry, just seen this comment. yes, it does, and yes they did (i can't remember the details, and i vaguely remember the julia version may be less complete, but these days the docs at https://github.com/andrewcooke/IntModN.jl include an example of solving simultaneous equations in GF(2)).
No worries. Good to know. Thanks for the answer.
You could take a look at this: http://learnxinyminutes.com/docs/julia/ Also, I think treating [Leah Hanson's blog post on ASCIIPlots.jl](http://blog.leahhanson.us/using-asciiplotsjl.html) as an exercise is a good idea. The codebase for [ASCIIPlots.jl](https://github.com/johnmyleswhite/ASCIIPlots.jl) is well-organized and easy to follow. Some of her suggestions are easy to do once you're familiar with Julia. Also, she's gonna do a followup, which is something to watch out for.
I was thinking more along the lines of something like http://python-3-patterns-idioms-test.readthedocs.org/en/latest/ and https://github.com/faif/python-patterns. Like for instance how would I implement the factory method, the singleton and more in the most efficient and optimized way. Having these resources available will would be helpful for people migrating from other non-multiple dispatch languages. 
a factory method becomes a function in a module. a singleton is a const value in a module. rather than trying to understand julia as if it is a python, try learning about functional programming. and learn to program in c. julia sits somewhere between python, c, and functional programming. imho.
Please, see my comment on the gist.
The xor ($) and or (&amp;) operation is vectorized, so that if you have an array (a = [1:10]), you can just do (a $ a) and get (zeros(Int,10))
i've used this, but always checked that arrays were the same length. not sure what happens if they mismatch.
I guess Julia's *Int* corresponds to c's *long* on your machine?
I've tried long, and even long long on C but the time remains still below 6s. Any other suggestions?
With your code I am noticing the same behavior. I am on a Debian box. GCC-O2, Julia 2.1, and latest git as of writing give similar times. &gt;steve@sjkellyT420:~/research/julia/perf_reg_check$ time ./a.out &gt;real 0m4.248s &gt;user 0m4.248s &gt;sys 0m0.000s &gt;steve@sjkellyT420:~/research/julia/perf_reg_check$ /home/steve/Software/julia/julia ./fib.jl &gt;elapsed time: 10.457418471 seconds (33948 bytes allocated) &gt;steve@sjkellyT420:~/research/julia/perf_reg_check$ julia fib.jl &gt;elapsed time: 10.593696596 seconds (42272 bytes allocated) 
Start with python. Lots of documentation and support available for new comers
I think it would be perfectly possible to learn programming with Julia -- you've got to start *somewhere* and no language is *that* easy if you haven't done any programming before. That said, Julia is not very widely used at the moment. When you're starting out you will probably want to do a lot of googling and asking for help, and that is easy with a more popular language. Python, Java, and C++ are all very popular and would each teach you different, but valuable lessons as a beginner. Python is probably easier to learn than the other two and is still very useful, C++ will be harder to learn but you'll probably learn some deeper lessons about programming from it. Java is nicely in the middle (warning: although I like Java, lots of people don't). At the end of the day, your *first* language may not matter that much, since you can always learn more languages. Python might be a good one because it's quite easy, or Java might be good because it has a very mature and free IDE (Eclipse) which will hold your hand for you a bit.
right now **NO**. absolutely not. the error reports are broken at times (you often have no idea where an error is in a file) and it would drive a newb absolutely crazy (it drives *me* absolutely crazy...). also, support in ides is limited (although light table support was recently announced) which might be an issue. [edit:] and also the community, although surprisingly large and supportive, is mainly experienced academics, which means there's not many "clueless" (as we all have been) people who can help each other out as they learn together. when that's fixed... hmmm. i think the most important thing in learning to program is wanting to solve a problem. if the problem you want to solve is a good one for julia (data analysis, say) then yes. but i don't think there's anything special about julia that makes learning easier. for me, at least, julia feels like a combination of python, c and clojure. so if you learnt those first then i think julia would come easily. but that's not really what you are asking...
Nobody "likes" Java as a Language, people who say they like Java they mean they like the fact that Java is an very reliable language with tones of libraries and that can do most things. But unless you're a bit weird you don't like Java as people like Clojure or Scala or Python.
Is there any date on Light table support? That would be fantastic. I use sublime but an IDE would be nice, at least until we get a decent version of Julia studio.
Light table support was announced here: https://groups.google.com/forum/#!topic/julia-users/rHN-fUmiXRs Relevant plugin is here: https://github.com/one-more-minute/Jewel 
I just tried it, it's not bad, but it still needs a bit of development. Thanks for the info.
I think the C compilers are "cheating" by doing some pre-calculations. Clang refuses to do the calculation at O2 without any side effect. And the performance is significantly different if it needs to parse fib's argument from the command line (much more than the overhead of `atoi` itself). Try using: int main(int argc,char **argv) { printf("%d\n",fib(atoi(argv[1]))); } instead and see if it's different.
You could try [BitArray](http://docs.julialang.org/en/latest/stdlib/base/#bitarrays).
http://www.johnmyleswhite.com/notebook/2012/03/31/julia-i-love-you/comment-page-1/#comment-19510 It doesn't seem like a regression based on that comment. 
Sad this is the same time(ish) as Velocity. Next year!
This was from a while ago, but I think it could still help people (like me).
If you're hesitating, give full-stack JS a try. I personally love Node, Express, Angular and MongoDB. Many many many many more frameworks&amp;libraries to choose from than those though. NodeJS is awesome.
as one_more_minute said, the answer is not at the moment. But in the future, that may not be the case. Recent developments can be seen here: https://groups.google.com/forum/#!topic/julia-dev/qdnggTuIp9s 
I wrote Python for a while, but was put off by this fact. I'm looking to use Julia for my thesis. Being able to compile binaries on one system and running the code on an other would be interesting at the very least :)
Oh, I'm compiling the code I posted manually.
Go does this, easily, by the way.
I'm not sure Go is what I'm looking for after working through their tutorial. Julia seems more like my kind of language, although I have never really used either yet. Why Go for scientific computing?
I don't know how strong Go is on the scientific computing front. I'm pretty sure Python still has it beat there. As a language, though, Go is fairly mature and has an easy-to-use toolchain, including cross-compilation (e.g. compile on Linux and run on Windows). Go is also faster out of the box than Python, Ruby, Perl, etc. Go also some things that might be useful for science computing: complex numbers built into the language, untyped, exact constants, built-in big number libraries, that sort of thing.
oh, man. if you think having to write self.name all over the place is bad, wait till you have to do this everywhere f, err := suspicious_call() if err != nil { // do something } At least when we had do to that in ansi c there were macros to make it less painful and repetitive.
Well, you can always panic and recover your errors if you're into that sort of thing. It's not idiomatic, but you can do it.
you can do this for code you are righting that needs to report errors, but it doesn't help when calling all of the [idiomatic] code that uses the normal return code mechanism. What we're seeing in code reviews is that a lot of times, people just forget to check errors. You might think that sounds bad ("how could they forget"), but it's pretty amazing just how many methods return errors, and in theory you should be checking them all at the point of calling. Event fmt.Println can return an error! There's really no way to determine which errors might be 'safe' to ignore, so you have to be really diligent about checking on every single call. It's not hard code to write (or understand), but it is more 'noisy' and seems to obscure the intent of the code a lot of times.
I have to say, whatever warts the error handling might have (and I'm not convinced that it's a truly bad approach), it doesn't stop me from being productive in the language... and the programs I write feel "tight".
Have you actually used Julia? It is a lot more intuitive for scientific computing than go.
Maybe the ratio is a function of n? In https://github.com/JuliaLang/julia/blob/master/test/perf/micro/perf.jl it looks like n=20.
 results = [] for path in ('path1', 'path2/foo', ...) push!(results, existingFn(path)) end return results or even [existingFn(path) for path in ('path1', 'path2/foo', ...)] 
You can also do just like you did in Matlab with logical indexing (except you need to use the elementwise version of the comparator): D = sqrt(sum(Ri .^ 2, 1)); Ri = Ri[:, vec(D .&gt; 0.0)]; # masks must be one-dimensional vectors when used in multidimensional indexing D = D[D .&gt; 0.0];
[edit: i am not passing judgement on what defines homoiconicity, just trying to explain what julia has and how it works. personally, i don't care how you define the word - i no longer have to pass any exams, thankfully - but i do like it when people understand what's possible.] it has macros, and you can access the AST. so it's like lisp, but mediated by a "complicated API" (compared to just using S-expression). which means that in practice it's nothing like lisp, but fits well with julia's target - you can auto-generate code for specific types which can make some maths code very fast (i was using it just now to unroll some inner loops in a CRC calculation for example (and ended up faster than equivalent c code, very slightly, for some reason that i cannot work out!)). a very cool example of this is tim holy's cartesian package, where he can generate fast code for matrix operations for various (small) dimensions. the same code automatically generates optimized functions for 1-6 dimensional matrices using macros. edit: here's my unrolled CRC code - https://github.com/andrewcooke/CRC.jl/blob/master/src/CRC.jl#L402 - that loop evaluates a macro 4 times, for 4 different sizes of word (16 to 128 bits). each macro expansion includes loop unrolling (8 times) and an unrolling over a loop that accesses a lookup table for each 8 bits of data (so 8 lookups for the 64 bit word case). it works very well for this kind of use case. but it *feels* nothing like lisp.
Already available in Arch Linux with "pacman -S julia"
From Wikipedia "the program structure is similar to its syntax." Julia has an Expression type. Typical values of Expression types are arrays containing other Expressions. This is similar to lists in lisp. The difference between Julia and Lisp is that Julia has syntax. I believe that one of the first things that the julia interpreter does when evaluating code is to parse the code it into Expressions (according to syntax rules.) In this form, Julia is pretty much indistinguishable from lisp. The other relevant line from the Wikipedia page is "The abstract syntax tree of a function may be composed and manipulated as a data structure in the meta layer, and then evaluated." This is one of Julia's main features: http://julia.readthedocs.org/en/latest/manual/metaprogramming/ https://www.youtube.com/watch?v=EpNeNCGmyZE&amp;list=PLP8iPy9hna6Si2sjMkrPY-wt2mEouZgaZ 
Makes sense, thanks for the thoughtful reply.
I believe it is to preserve type stability. If it sometimes returned a real, and other times returned an imaginary, calling code would require more dynamic type checks on the results - hindering chances for optimisations.
Great answer! But why could it not then always return a list of imaginary numbers? That makes more sense to me. 
I was wondering why nobody brought that up in the mailing lists. Good luck to all the students :) ps - I find the descriptions a bit short. Is there a public page for at least some of those projects, with more details?
[Example detail page](http://www.google-melange.com/gsoc/proposal/public/google/gsoc2014/daetalus/5649050225344512). It seems [editing the url](http://www.google-melange.com/gsoc/proposal/public/google/gsoc2014/andrioni/5863987568705536) to include the relevant string from either of the accepted projects results in an internal server error. I guess the students need to [explicitly set the project visibility to public](https://groups.google.com/d/msg/julia-dev/rgm-NluG2KU/g-uP8tJx39sJ)...
It might be productive to open an issue about it. For real values, you probably always want a single root, but for complex values getting multiple roots might be an acceptable interface, rather than choosing just one.
Julia is targeted to the scientific computing community, and having 2^1/3 return multiple values would be cumbersome for those who just need the real root (which is by far the most common case). Furthermore, computing all roots would be more expensive. There may be functions or Julia packages that behave in the way you want, check out the packages list on the Julia website (found within the "community" tab I believe)
Just like generators and ranges yields results as needed, roots should be calculated when needed. Real roots should be automatically cast from the list of roots when needed. This should be a language feature, because that's how multiple roots work. Similarly, (-1)^(1/2) should *not* return ERROR: DomainError, but 0+1im and 0-1im.
I think a single real value for multiple roots should be provided at cast-time instead of at return-time. Roots are defined mathematically to return multiple imaginary values. I agree that a bug report might be more productive, but gathering initial feedback can be useful too. Thank you for your work on Julia!
In REPL documentation is an area where julia is currently lacking. Most functions in Base (e.g. mean) have help that can be accessed through either help(mean) or ?mean like in R. However, there's no way to extend the interactive help system for anything else like functions in modules or entered in the REPL. Some packages have good documentation available. If they do, you should be able to find it in the github repo for the package. A couple other helpful things are typing 'mean(&lt;TAB&gt;' in the REPL, which will list the different type signatures of functions that are defined. For example, I see julia&gt; mean( mean(v::AbstractArray{T,N}) at statistics.jl:16 mean(iterable) at statistics.jl:3 mean{T}(v::AbstractArray{T,N},region) at statistics.jl:30 when there are no packages/modules loaded. The methods function shows similar information. Finally, methodswith can be called on a type to see what functions can be used on that type. For example methodswith(Matrix) 87-element Array{Method,1}: Symmetric{T}(S::Array{T,2},uplo::Char) Symmetric(A::Array{T,2}) at linalg/symmetric.jl:6 Symmetric(A::Array{T,2},uplo::Symbol) at linalg/symmetric.jl:6 det(A::Array{T,2}) at linalg/dense.jl:286 +(A::Diagonal{T},B::Array{T,2}) at linalg/special.jl:88 +(A::Array{T,2},B::Diagonal{T}) at linalg/special.jl:89 ... Those can at least get you started. Hopefully after v0.3 is released, revamping the documentation system will have a higher priority. EDIT: To clarify, I do not mean that the documentation is poor. The documentation for Base is really great, up to date. Most of it is accessible interactively, but the online docs sometimes have more detail. The issue is really that there is no way to extend the interactive documentation for contributed packages.
Yes, a "root iterator" of some sort would be great. 3 * 2^(1/3) could be handled by casting from the "root iterator" to either a real (if there is only one root, and it is a real value) or to an imaginary number (if there is only one root, and it is an imaginary value). If there are several roots, I think there are two viable alternatives: * Calculate all the roots, multiply the real number with each of the imaginary numbers and return a list of imaginary numbers. * Throw an exception, since a real number is being multiplied with several imaginary numbers. A function can be provided for fetching a single root number, or list indexing could be used ("[1]"). I think the latter alternative is preferable. For your example, 2^0.218923794910, there is only one root. It is a real value, so the "root iterator" can calculate and return a real value when being casted.
an iterator is still slower than a single value. this is a core function that some people are going to be using in tight loops. why don't you define your own function that does what you expect? julia make it easy to define and share packages. if there is a demand for functions that work this way then your package could become part of julia in the future.
someone smart doesn't pull such a useless-to-google name for a project out of nowhere. there has to be a reason; saying that there is no reason just means it's an embarassing reason; that it's a woman's name seems unsurprising in that context... one day, when julia rules the world, we'll see a tabloid headline that explains all.
Because I believe this to be a bug. A single value is often incorrect. It is incorrect for 2^(1/3). Why can't sin(x) just always return 1? It's much faster as well, but similarly incorrect. 
Or we define 2^1/3 in a programming environment to mean "the real 3rd root of 2." This is quite common in programming languages. The types of functionality you describe might be nice, but not as the Julia core which needs to be fast for those who need it to be fast. You could even overload the ^ operator and have it work the way you want, if it bothers you that much. 2^0.218923794910 = 2^218923794910/1000000000000 . After reducing the fraction it is clear that there will be quite a few roots. 
I've found Julia Base to be pretty well-documented. The problem is that there's not an extensible system for getting help on other Packages or user code. But when I have a question about the implementation of some function, I simply look at the source. It's remarkably easy, but given the number of overloaded methods on each function, it can be a little daunting figuring out which one to look at. If you're on the .3 pre-release, you can simply prepend your function call with `@edit` macro (e.g., `@edit mean([1 2 3])`) and your editor will pop up at the line where that method is defined. I've found most source to be very well written (and commented, too).
Good points. I edited my post to clarify what I meant. I did not know about the @edit macro. That's really handy. 
One of the points I found really interesting in this article is Julia's ability to work with unicode characters. Unaware of this previous, I immediately opened up an instance of IJulia and started experimenting. Unfortunately, when I set the value of lambda (037bb) to an integer in one cell, I'm unable to call that value in a subsequent cell. Is anyone else having this problem? If not, is any ideas what I'm doing wrong and how to fix it?
Works fine on command-line 0.2 and latest git -- maybe an IPython issue?
Because arch linux is the best 
This is great, thank you for sharing. 
Debugging using an debugger works for some people. That said, it does not work well for me. Debugging a program means that the program somehow deviates from the model in your mind what the program does. It is an task to find that out, like in a scientific research. Like any good research, the progress and the quality of the results depends on the ability to ask good questions. This is complex and nontrivial. Debugging by printf works so that you make a hypothesis about what the code does, and check that., and use the new knowledge to make a better hypothesis. It is very well suitied to go along and check the abtractions a program has. Using a debugger is often very bad compared to this. Sure, you can see what your computer *does*, but you do not see the abstractions any more. It is like I ask you what you are thinking and you say: "the 12934754295738764833587325th hydrogenium atom in my brain has moved a bit closer to the 7768989787873th carbon and might pick up an electrical charge". You miss the big picture. You see too much irrelevant stuff. You are not forced to think about your mental model and where the program deviates from it. And for computing-intensive numerical stuff: You often just get way too much numbers. Debugging by prinftf forces you to understand and look at the big picture. As an addition: For numerical code, "debugging by printf" often means debugging by plotting data. No debgugger does that for you. (My background: About eight years experience with Python and C on embedded systems and four years with Visual Studio and Visual C++.) 
Yes
I am by no means using Julia to solve grant funded real problems that require results. Nor should anyone be at this stage of its development. That being said, i like to code up copies of many of my projects in julia as a hobby and with the hope that it takes off and I can hit the ground running. Its an awesome concept that the scientific community desperately needs. For industrial and commercial purposes, there is just no retiring fortran so far in terms of simulating design processes and solving PDEs/large scale linear algebra. But for good reason, it simply performs faster than python no matter how you go about the problem. Plenty of people are pushing for python use and making great strides, but the performance issue will always be a burden. All the efforts to improve performance in python have been great, but then youre sacrificing portability or robustness in terms of usability to new users of your codes. Julia does a great job at addressing all of those issues. 
Just switched to julia love the parallel capabilities and that you can call R, Python, and C but wish that there were more libraries for GIS libraries and OpenCV ports and neural networks. It would also be great if there was a python library to call Julia.
I use it for corpus linguistics. Mostly advanced regular expression queries with some light statistics. Julia is pretty interesting in this domain. Although it is nowhere near having as much libraries and tools like python or java, it is faster than both in this domain and I can do most basic stuff with it, and multiple dispatch is just great for writing grep functions.
I am using it for some coursework at university (I'm a math major). I've also ported some MATLAB code to use IJulia and PyPlot. My goal is to help get some courses on writing FEM code to use IJulia notebooks next year.
1) Love the username (I'm a physicist --- well a physics grad student at least) 2) Why shouldn't anyone be using Julia to solve real problems that require results? Granted, there isn't a huge set of packages to speed things up, but if your sort of problem doesn't really need specialist mathematical packages that can be found in Fortran or C or the sorts of tools found in Python, why not use Julia? In my case, I'm using it to write a new solver for Ising spin glasses. I chose it because I like the language, I can develop in it pretty quickly, and it's significantly faster than Python (the language I'm most fluent in). Since I'm still in the development stage, don't intend to be solving particularly large glasses, and don't need any specialist packages, Julia strikes a good compromise between easy development and good-enough speed. Maybe later, if I find myself really needing to pinch pennies on core-hours, I'll recode it in C or C++, but for now it's good enough. I've heard your type of comment before, but never really understood why. The language seems stable enough (in that my code will do what I think it will do provided I keep my Julia release version the same). I'm really interested, as I don't know if I may be making some huge mistake because I just haven't thought of something. Thanks!
Former employee of Los Alamos here. I don't think that the author understands what Fortran is used for. Clojure and Haskell? I like them, but in all scientific computing programs I have ever seen you need mutable array updates. Not exactly what these languages are for. Yeah, I know you can do it in Haskell, but it's not very nice. Julia does better here. I am not so familiar with other domains (say, plasma or aerospace), but for compressible fluid dynamics most programs are just a few thousand lines of Fortran (usually written with a lot of modules and other nice things) that call heavy lifting standardized C libraries (FFTW, umfpack).
FFTW and umfpack are in Julia's standard library :) Oh, and the author of FFTW wrote a pure-Julia FFT implementation that works on arbitrary types, performs fairly close to FFTW, but is much more compact and easier to extend, and not GPL-licensed. It isn't merged yet, but will be sooner or later. Those few thousand lines might be a few hundred in Julia, and perform comparably. Though if you're using OpenMP or MPI you probably don't want to switch just yet.
Yes. I believe the word "scope" can be used in some way here.
I probably should have done a better job specifying what people do with Fortran. The main appeal of the language is MPI support. Since the C++ interface is deprecated (last time I checked), its either Fortran or C, and array handling is much better in Fortran. Hence I think that we are stuck with it for now. A Julia version of that Fortran code *would definitely be better in every single way* besides MPI support. Its unfortunate that that's the most important feature. &gt; Oh, and the author of FFTW wrote a pure-Julia FFT implementation I am having some trouble finding this library. Could you provide a link? 
For people running on Top500 class systems (which I have done before, when NERSC Hopper was #8, so you're preaching to the choir), sure. But you also like to test your code on your workstation or laptop, and also just use multithreaded Blas/Lapack or various sparse matrix libraries that are in Fortran, even without MPI. The valid point was made in another thread about this article that you can't build SciPy, Octave, or Julia (and Mathworks can't build Matlab) without a Fortran compiler, for good reason. Technically you can get a bare-bones Julia JIT compiler just using C and C++, but it needs a few Fortran libraries to bootstrap its base system since they're built-in by default. They may introduce a minimal version of the language with fewer dependencies soon, making more of a distinction between the language by itself vs the dependency libraries it's built around for optimized linear algebra on machine types, etc. Julia has its own custom one-sided-communication parallel model that works at a higher level than MPI, people are using it successfully on AWS and GCE instances and mid-sized clusters I just haven't had a chance to play with it yet. There are some distributed array features too, but they're still maturing as with everything else about the language. The pure-Julia FFT doesn't exist as a separate library, rather it's in the form of a WIP pull request to base Julia: https://github.com/JuliaLang/julia/pull/6193
Prototyping games
I'm only just now dabbling in Julia. I wish I could say I'm working on some noble scientific pursuit, but I'm really interested in it for its potential use in a physics engine in games and simulators; its ability to call external C functions without excess glue code or wrappers is also attractive for hooking into, say, OpenGL and/or SDL to flesh out a full game/simulator engine.
Go
You almost always want a single (real) value. If you don't it's easy to get all the roots by multiplying by the nth roots of unity. http://rosettacode.org/wiki/Roots_of_unity#Julia nthroots(n::Integer) = [ cospi(2k/n)+sinpi(2k/n)im for k = 0:n-1 ] nthroots(n::Integer, z) = (z ^ (1 / n)) * nthroots(n)
~~It may not have been officially released yet but by following the download instructions you will download v0.3.~~ Edit: I was talking about the pre-release, sorry guys.
do you mean the pre-release (git trunk) or something else?
Do you need much more than the tickets? If I could pick anything, [these performance regressions](https://github.com/JuliaLang/julia/issues/6112) look pretty significant.
Scratch that, I'm talking out my arse. I did install the pre-release I just didnt realise it.
I think OP was asking about *why* it hadn't been officially released? As a relatively new Julia user, do you know where to find that info?
I can't I'm afraid but I think timClicks might be on the right track.
Oh wow, really? I didn't expect to see that answer. How so?
Wow, they sold out quick! Maybe if enough waitlist they can get a bigger venue? I am still on the fence about going.
I can see why it as an advantage from a certain point of view. Because the language is young we have the opportunity to shape and prioritize the features (within the stated goals of the project obviously).
There's two parts to the code of a game - the game logic and the game engine. There are plenty of high level languages around that let you write the game logic, but then fall flat on their face when you try to make a game engine. Lower level languages, such as C/C++ are great for making a game engine, but become painful when you want to make the game logic. It's sensible then to marry a high level language and a low level language together. Many game engines use Lua for their high level language or even Python sometimes. Julia represents an opportunity to have both the high level and low level components in the one language. The ease with which you can ignore performance by having untyped code until you need typed code in Julia is paramount to this. Prototyping a simple AI system? ..okay, it worked, now we make it fast. "Make it fast" no longer means "rewrite in a low level language" with Julia, but instead means annotating the code with types. Another example is UI layout. Widgets tend to be fairly high level concept thingies and layout is usually poorly done using something like group layout or worse. Constraint based layout using a linear constraint solver that is fast is something that is easy to marry to the high level widgets in Julia, again, without having to combine two different programming languages together. Next we start to explore the idea of signal processing for audio. Once again we can prototype interest audio effects with ease and then when we need it to go fast, there are signal processing libraries available as well as the ability to annotate the code to make it sometimes as fast as the C version you might otherwise have wasted several weeks on. Then we start talking about multicore programming and the efforts by the LLVM team with things like Polly and the simple @parallel macros in Julia, shared and copied objects. Divide and conquer is easy enough to experiment with in Julia that the solution is often the prototype itself. The list goes on.. but Julia is one of the most promising languages I've stumbled across in a long time and it's been a pleasure to experiment with game design in it.
So interesting! I appreciate you taking the time to write it up. I'm very excited (particularly for machine learning) to port some of my C code to Julia. I'm just learning the language now with small sections of code I can write in C to compare them. I wrote a simple &lt; 10 line program to find the greatest prime factor of a number that took 2.667 secs to run. The equivalent C code was a total pain to handle anything larger than the standard data types. I'm impressed. 
(-1 + 0im)^1/2 returns a complex root. This makes it obvious when you're working in the complex numbers rather than the reals. Since your need for multiple and complex roots is the exception rather than the rule in the programming world, it is not the default and needs to be explicitly stated. Otherwise the rest of us would constantly need to explicitly discard values returned by basic mathematical operators.
Only one complex root as the result for (-1im+0)^(1/2) is also the wrong answer. If Julia is supposed to be "a fresh approach to technical computing", at least they could try to get the math right. Complex roots can be used for many things. If you primarily want speed when performing calculations, you can use C or Fortran, like the rest of the people that are primarily concerned about computational speed.
heres one I adapted from python for nano syntax "julia" "\.jl$" color brightblack "\&lt;(begin|break|catch|continue|function|elseif|else|end)\&gt;" color brightblack "\&lt;(finally|for|global|local|if|include|using|require|macro)\&gt;" color brightblack "\&lt;(println|return|try|type|while|module)\&gt;" color brightblue "[A-Za-z_][A-Za-z0-9_]*[[:space:]]*[(]" color white "[(]" color red "[-+*/|=%&lt;&gt;&amp;~^]|\&lt;(and|not|or|is|in)\&gt;" color brightyellow "@[A-Za-z0-9_]+" color brightmagenta "__[A-Za-z0-9_]+__" color brightcyan "\&lt;(true|false)\&gt;" color yellow ""(\\.|[^"])*"|'(\\.|[^'])*'" color yellow "['][^']*[^\\][']" "[']{3}.*[^\\][']{3}" color yellow "["][^"]*[^\\]["]" "["]{3}.*[^\\]["]{3}" color yellow start=""""[^"]" end=""""" color yellow start="'''[^']" end="'''" color magenta "\\.?" color cyan "(^|[[:space:]])#([^{].*)?$" color brightwhite,cyan "TODO:?" just paste this into your .nanorc file
sublime package: https://sublime.wbond.net/packages/Julia textmate (as Sublime)/emacs/Notepad++/others are available on github: https://github.com/JuliaLang/julia/tree/master/contrib
Thanks! I don't currently have nano and Julia on the same machine, but you've made me want to fix that. It's nice to see something so accessible and straightforward.
There is also https://github.com/JuliaLang/julia-vim
Emacs
Most programs have no use for complex numbers at all. If language creators decides to support complex numbers, I think they should add the required functionality not only for operations like addition and multiplication but also for roots. You may not give a damn about the negative root, but that's a non-argument. I don't give a damn about your wishes or needs either. The crux of the matter is that the implementation could be both correct and complete but is neither. Also, a language feature could not be expected to become popular before actually being implemented. I fully disagree with your point of view, and you with mine, so I suggest we just leave it at that.
just to be clear, there's julia.el a file in a contrib directory in the julia distribution (github) - read the comments in that file for how to load it.
I agree that the functionality should exist, but not in the default power operator. I can't think of any mathematical software that returns multiple roots by default when using ^ or sqrt, but many programs do have a special function to find all roots. Without such separation, tasks such as plotting y=2^(1/x) would be painful as the number of values returned for y would vary with x.
Vim https://github.com/JuliaLang/julia-vim
How is Julia studio btw? I've been using Sublime Text 3 but I haven't tried Julia Studio. Also, has anyone had luck getting the build system in Sublime Text working? Mine always acts weird. Thoughts?
Pretty good. I built a project with it easily. It does have one really awesome feature: it has a package control system. You get a full list of the available packages for Julia and you can download and install them with just a click. Very handy.
A point well made.
Another similar resource is the [Learn X in Y Minutes](http://learnxinyminutes.com/docs/julia/) entry for Julia.
Maybe nitpicking or me misunderstanding something that has changed recently, but isn't this a misuse of inner constructors? # types may also contains arrays and dicts # constructor functinos can be defined to easy creating objects # note: in the array definition the type Family name::String members::Array{String, 1} extended::Bool # constructor that takes one argument and generates a default # for the other two values Family(name::String) = new(name, String[], false) # constructor that takes two arguements and infers the thir Family(name::String, members) = new(name, members, length(members) &gt; 3) end Wouldn't it make more sense for those two constructors to be outer constructors, since they really don't need to construct the object using `new`? Based on my reading of the docs, this should be: # types may also contains arrays and dicts # constructor functinos can be defined to easy creating objects # note: in the array definition the type Family name::String members::Array{String, 1} extended::Bool end # constructor that takes one argument and generates a default # for the other two values Family(name::String) = Family(name, String[], false) # constructor that takes two arguements and infers the thir Family(name::String, members) = Family(name, members, length(members) &gt; 3) Source: http://docs.julialang.org/en/release-0.2/manual/constructors/#outer-constructor-methods &gt; It is considered good form to provide as few inner constructor methods as possible: only those taking all arguments explicitly and enforcing essential error checking and transformation. Additional convenience constructor methods, supplying default values or auxiliary transformations, should be provided as outer constructors that call the inner constructors to do the heavy lifting. This separation is typically quite natural.
Cool !
They just want JIT experience. It's not required, and they just want you to know they're hip to cool new things. 
Sure, but it's interesting to see what languages fill the role of hip new things. Long ago it used to be python (barely anyone used it at work but it was a good sign that people were learning new things on their own).
Don't do it, its comcast.
What about just using quotes? julia&gt; a = :(function foo() 7 end) :(function foo() # none, line 2: 7 end) julia&gt; a.args[1] = :(bar()); a.args[2].args[2] = 8; a :(function bar() # none, line 2: 8 end) julia&gt; eval(a) bar (generic function with 1 method) julia&gt; bar() 8
NOTE: might need to scroll down a bit to see the code comparisons.
This is best sent to the google groups for a quick answer. https://groups.google.com/forum/?hl=en#!forum/julia-users
And if you want to jump to the cheat sheet section directly skipping the intro: http://sebastianraschka.com/Articles/2014_matrix_cheatsheet.html#cheatsheet Btw. any comments/suggestions about the format of the HTML table (too big?) I had really a hard time thinking of a better way to present this. I wanted to make the table width smaller, but then you'd have to scroll horizontally and wouldn't see the table as a whole. Since most people have a 16:9 monitor I thought the width wouldn't be an issue!? That you can always zoom out in your browser if necessary. 
I think that is slightly outdated. Check out the install instructions for IJulia here: https://github.com/JuliaLang/IJulia.jl
thanks. I installed IJulia, and i can also run IJulia notebooks, but I actually only wanted to have a small portion of Julia code in my notebook, the rest should be Python / Cython. Unfortunately, I read that magic functions are not yet fully supported: "One difference from IPython is that the IJulia kernel currently does not support "magics", which are special commands prefixed with % or %% to execute code in a different language" Is there a way to run Python code in IJulia notebooks?
You can use [Pycall](https://github.com/stevengj/PyCall.jl)
I use Julia and python and I would like to see julia compared in speed with Lua Torch, C++, Java, and C#. Just to get a better benchmark. The reason is: Torch is used for most neural nets and usually the slow part of the language are the loops Java is used for most of Standford's Natural language processing. So far I like doing parallel processing in Julia but have not used it in a large extent because I am having trouble finding documentation in the libraries which are scattered all over. There is also little help available (except on Github) especially for DataFrames so I am using Python Pandas. I am also using Julia Studio as the IDE and it is missing some features I would like.
This appears to be cross-posted on julia-users. Cross-posting wastes the time of Julia community members who are providing support on their own time, so this is not a good practice.
just use a JSON file. https://github.com/JuliaLang/JSON.jl
I honestly don't know. I've only ever used it when playing around.
The job is in my group at Comcast, and I'm the one who got it put in the job description as a semi-serious joke. I use Julia for some trivial and occasionally non-trivial things at work, but it's certainly not any official company policy.
That's amazing!
While there aren't any published "Learn Julia" books yet, I would first start by looking at [Learn X in Y minutes](http://learnxinyminutes.com/docs/julia/) to get a feel for the language, then take a look at the official documentation. There are also some nice videos on Julia from an MIT workshop about a year ago on youtube that you could check out.
I started with reading the [Manual](http://docs.julialang.org/en/release-0.2/manual/). I also had been out of practice with non-numerics computing for the better part of a year. Looking at other's code has helped immensely in understanding designing software with Julia. The latest Julia REPL is very nice, and makes it really easy to quickly experiment with sections of your code.
My two favorite resources so far are [Julia by Example](http://www.scolvin.com/juliabyexample/) and [Tricked Out Iterators in Julia](http://slendermeans.org/julia-iterators.html).
Here are some useful links I used. http://sebastianraschka.com/Articles/2014_matrix_cheatsheet.html#julia http://math.mit.edu/~stevenj/Julia-cheatsheet.pdf http://bogumilkaminski.pl/files/julia_express.pdf https://github.com/JuliaLang/julia-tutorial https://github.com/JuliaX/iap2014 Also the google groups is great https://groups.google.com/forum/#!forum/julia-users 
I think self-consciously copying the cultural aspects of other languages (i.e. R-bloggers here) is a great idea. It really reduces effort required to discover Julia when you come to it from these different angles.
I saw some poor performance with data frames compared to R which puts me off a little for now. I want quick easy data manipulation and plotting so I hope that improves. I don't use R for performance critical work, but I will seriously consider julia next time. 
This sounds very fishy. NumPy is superbly optimized with Fortran routines at its core. Having Julia run 100 times faster than NumPy means that they're doing something spectacularly wrong with their Python implementation.
When doing various aggregations in data.frames, it seems like dplyr is the new king of the hill. It also has the advantage of being able to more or less seamlessly hook into RDBMSs and turn its expression syntax into SQL which gets fed to the DB. Given that relational databases are pretty good at the sorts of things that I often do with data.frames, I wonder if a suitable data.frame implementation might be based on an in-memory sqlite database, with the option to build an on-disk db, and with dplyr semantics.
Depends which BLAS implementation. Doesn't NumPy use the reference BLAS from Netlib by default on a lot of distributions? Also, iteration. Some things you can express in a vectorized way and interpreted languages will do a bit better, but not all algorithms can be rearranged that way.
I agree on vectorization vs loops, without an explanation of what they're actually doing, all we can do is speculate. A factor of 100x in performance, I'm guessing they're using a loop where they can and should be vectorizing. The post doesn't give me any more information than any other benchmarks which test compiled code against python by using default python loops.
That's the paper that made me switch to Julia for my structural econometrics needs. Still use a lot of R for reduced form regressions and to prepare data. I'm slowly abandoning Python as a result.
Your best bet will usually be to try on stackoverflow http://stackoverflow.com/questions/tagged/julia-lang
I'm only being critical because he gave no details, and post reeks of typical lamguage marketing.
Simple way: julia&gt; f = IOBuffer("1 2 3 4 5 6") IOBuffer(Uint8[0x31,0x20,0x32,0x0a,0x33,0x20,0x34,0x0a,0x35,0x20,0x36],true,false,true,false,11,9223372036854775807,1) julia&gt; arr = readdlm(f) 3x2 Array{Float64,2}: 1.0 2.0 3.0 4.0 5.0 6.0 julia&gt; x = arr[:,1] 3-element Array{Float64,1}: 1.0 3.0 5.0 julia&gt; y = arr[:,2] 3-element Array{Float64,1}: 2.0 4.0 6.0 You could use ArrayViews.view to not copy the data, if you prefer.
I'd really love to abandon python completely. But there are still a couple of things I need it for.
I believe that is actually a normal Julia feature, Julia Studio is probably just making it prettier and clickable.
You might try the [julia-users mailing list/Google Group](https://groups.google.com/forum/?fromgroups=#!forum/julia-users).
I was somewhat expecting this to be more about using Julia to stitch together functionality pulled from C libs. Calling C functions in Julia is pretty killer, I believe, due to everything running on LLVM. To the extent that LLVM bytecode is interoperable, this potentially pushes Julia into a lot of interesting places.
Sorry about that, perhaps 'glue' wasn't the exact right term in this case. Couldn't think of a better description though, using Julia to run routines on 3 different systems. Here's a blog post from the main Julia blog that covers calling C from Julia. http://julialang.org/blog/2013/05/callback/
No! This was a great article, and the glue moniker is perfectly appropriate! I was just musing at how else one might interpret glue. Thank you for the link. Some day when I have a little bit more time, it's been on my todo list to figure out how to wrap [geos](http://trac.osgeo.org/geos/). Well, I guess wrapping it hasn't so much daunted me, as figuring out some idiomatic way of representing geometries in data tables as they do in R or with spatial pandas...
This may work better as a message to the mailing list, this subreddit is still pretty low-traffic. Regardless, it's good to see some overlap in interest of people looking to see Julia improve in a few areas that Rust is very good at (and vice versa http://redd.it/28z6el). I'm not so sure a formal ownership model would be easy to incorporate into Julia for the purposes of memory management. There is however a data ownership model for parallelism, using distributed arrays and (on Unix) shared arrays. I'm not familiar enough with Rust to say how different its unique/borrowed pointers are from Julia's remote references and remote calls. Julia's GC needs improvement and has not been very well optimized yet. See https://github.com/JuliaLang/julia/pull/5227 for some contributed work on an incremental GC, expect it to be merged and the GC to receive some performance attention later in the summer. I believe it's possible today to temporarily disable the GC, but this is likely a use-at-your-own-risk feature. Many calculations in Julia can be refactored without too much trouble to reduce the amount of memory allocation by performing more operations in-place. There's a reason the `@time` macro reports memory allocation, and recently started reporting time spent in GC as well. But for high-level convenience, many very basic operations can result in memory allocation - for example adding two arrays. It's difficult to formally separate operations that are allowed to allocate memory from operations that aren't. The exclamation point convention for in-place operations is pretty wide-spread now, but it's not actually enforced in any uniform way by Julia's parser or compiler. At the moment I think this is best left for manual profiling and refactoring. It's tough to force students and scientific users who just want to get a result to have intimate knowledge of how memory allocation works before being able to use a language effectively. In idiomatic Julia, unless you're interacting with a C library you should never have to worry about pointers directly.
&gt;&gt;But for high-level convenience, many very basic operations can result in memory allocation - for example adding two arrays. Rust's libraries come with chainable iterators.. ('lazy expression templates') for combining operations.. so many operations can be combined in what looks like a pure-functional style, and a final '.collect()' actually allocates once and performs a composed the calculation. Is julias type system up do doing that? It relies on typeparameters, 1st class functions, and lots of optimising by the compiler. Doesn't need HKT, (which Rust doesn't have yet) , although I suspect that would make this sort of thing easier. 
I don't know enough about compilers to say for sure. There are some packages where people have experimented with somewhat similar concepts, see https://github.com/one-more-minute/Lazy.jl or https://github.com/dpo/linop.jl for example. There's a desire to avoid too much laziness and magic in the compiler, just so the execution model of Julia code is relatively transparent and easy to reason about. More scientific code (and libraries) would be written in Haskell if that were the right direction to go in for the type of user and application that Julia primarily targets. You will probably find this thread on the julia-dev mailing list from a few weeks ago interesting: https://groups.google.com/d/msg/julia-dev/CkFimC1pjlw/2qhHXxpcrSYJ Several Julia devs and contributors comment on lazy templates there.
I find myself very spoiled by multiple dispatch after really only a few months of using Julia, and immediately missing it any time I go back to any other language now.
Even if I agree with you, dobkeratops is proposing the idea as an extra feature, not the only way it should always be done. The main problem IMHO is that in this kind of community, if you allow more complex constructs which give more speed, the are gonna use it almost everywhere... 
Click on "open" to get the actual PDF for viewing
Neat, thanks for sharing this! I work in NLP and have been getting to know Julia for fun in my spare time (only in very in small doses so far) in the last couple weeks. These were interesting slides to read through.
Given that Julia can call C, in principle you can do anything C can – including allocating and managing memory by hand. So you could – for example – implement an array type which is allocated manually and requires some kind of `free` call. You could even go further and implement macros to give Rust style compiler support, thus avoiding the GC entirely for a given block of code. You can actually go a very long way without macros when you have multiple dispatch, but I imagine they'll be necessary for full Rust-style support. Julia isn't intended as a C replacement (systems wise) so it's unlikely that there'll ever be "official" support for this kind of thing unless there's a very compelling reason – they've done pretty well without so far. But you could definitely implement this as a library if you were interested.
I figured out a way to do this. using DataFrames, HypothesisTests, StatTests data = readtable("dataset.csv") group_1 = data[findin(data[:treatment], 1),"outcome"] group_2 = data[findin(data[:treatment], 2),"outcome"] pvalue(UnequalVarianceTTest(group_1,group_2)))
This is a really neat package, and is awesome for introductory Bayesian courses where you start by working with conjugate distributions. Relatedly, I've been meaning to kick the tires on the MCMC package for a while now. If they can get anywhere close to the performance of something like Stan, wow is Julia ever less of a hassle.
The complexity cost has nothing to do with it. Just look at the mailing list or in most libs: the code is almost always devectorized and very simple one-liners with non-weird indexing are often replaced by a couple of explicit nested loops. For computational kernels, that may be worth it. But it is used just about everywhere for non relevant code. People just don't profile there code: they state a wild guess on their bottleneck, optimize and optimize again until they reach the actual bottleneck and happily say "ye know, by devectorizing, I could reduce execution time by half from 20 ms to 8 ms on my dataset". That's how it seems to work in this community (which is fine, I'm not judging anyone here and I know I'm exagerating). However, if you put some more complex concepts in the language (which I would really like to see in Julia by the way, I really mean it), you cannot just assume that a Julia user can afford not to know the related concepts. It's a bit like decorators in Python : you can code without them but will find them in almost any lib. You have to understand what they do to understand the code. I'm even going a bit farther, from my first two paragraphs: I'm predicting that if you offer an alternative to gc with less overhead, you'll soon see it virtually everywhere, even where it can hardly be justified. So, when considering adding a thing like smart pointers to the language, please assume that every Julia user will have to understand what uniqueness and borrowing means in computer science. -------------- Implementing a borrow checker for Julia would be hard IMHO: Rust guys did it at the extra expense of explicit lifetimes (that every single user of Julia would have, sooner or later, to understand). In my opinion, concerning gc, Julia needs defered evaluation to allow the compiler to perform optimisations and a gc that can either perform caching at the function level (in loops, for the same kind of inputs) or release heap allocated in the function when it returns (outside or at the end of a loop). But that's not really what is intended by Julia's dev AFAIK: this would be a bit too magical. Maybe Julia needs different optimization levels... 
Yeah, I was very surprised to find out recently that the regexes in Julia don't support backreferences :(
They do, just with $ instead of \1: replace("hello world", r"o", "$1 xx") "hell1 xx w1 xxrld" They're just terribly slow. 
Um.... I think we're misunderstanding each other. Did you look at my example? Take another look, if you don't mind: it's a little contrived, but like I said, I want to surround lowercase vowels (a, e, i, o, u) with curly brackets. That's why they're there. The {} have nothing to with the regular expression at all; they're part of the replacement string. In Perl and Python, you surround the vowel character class with parentheses to put it in a match group, and then you can retrieve that matched string in the replacement with \g&lt;1&gt; or \1. Look at what is returned for both: "hello world" ==&gt; "h{e}ll{o} w{o}rld" This is the behavior that I want (for this example problem). Compare that with the Julia result: "hello world" ==&gt; "h{1}ll{1} w{1}rld" The matched vowels are forgotten and replaced with '1' instead of being retained. I want $1 to refer to the first (and only) match group for each replacement, like in the Perl and Python code. I *don't* want to replace vowels with '1' like my Julia example does, and like your two examples are doing. You don't need match grouping or backreferences to replace vowels with '1'. Your code above is actually showing that Julia *doesn't* support what you're claiming it does. Does that make sense? And did you read the comments on the feature request I linked? Sorry if anything was unclear. 
No worries! :)
Nope, from what I've seen, code optimization is mostly trial and error there. Not for everyone obviously, but usually. For the second point: is it really that hard to understand that readability is just as important on the long term as speed? Just look at how many people were contributing to GotoBLAS and now OpenBLAS. There are always things to improve but if people can't get to understand the code, this is useless. Devectorization should be chosen based on algorithm necessities: it should make the code easier to understand, if it is just for speed, then improve Julia instead of relying on such tricks. Ig Julia really can't provide that, then it's no better than Fortran (well, the REPL is really nice). Javascript has a smart compiler and it's fast. Stephan don't like this kind of magic, well, I understand. But this is the future of computing: expressing what you want instead of fighting with the compiler. If you need to do tricks to gain speed from the most obvious way to write your program, then there is something wrong. If the magic is not good enough for you, then improve it. You don't like the magic? Then contribute to Devectorize.jl and use that. We are in 2014 not in 1974 anymore... 
&gt; Nope, from what I've seen, code optimization is mostly trial and error there. Not for everyone obviously, but usually. You and I are seeing different things. Every thread on the mailing list that starts with "why is this slow" gets resolved by "here's how to profile your code, you can make things faster by doing A, B, and C to address these bottlenecks." Newcomers don't know how to profile yet (hint: they're coming from other languages where profiling isn't as pervasive), but pick up the habit quite quickly from the experienced optimizers. &gt; For the second point: is it really that hard to understand that readability is just as important on the long term as speed? Just look at how many people were contributing to GotoBLAS and now OpenBLAS. There are always things to improve but if people can't get to understand the code, this is useless. I partially agree there. Implementing a fast BLAS is very very difficult. If it was easy, more people would have done it by now, the demand is definitely there. Maybe BLIS will make it a little easier, how things are today is not necessarily indicative of how things will always be. But it's not like all that many people are capable of contributing to Eigen, or GHC, or the lazy templates parts of the Rust compiler either. Line count is a very small piece of readability. I don't mind for loops, so what if it takes a couple extra lines? At least I can still see and understand what the code is doing. And if it makes the compiler's job easier, I'm all for it (no pun intended). User and library code isn't the only thing that needs to be readable. If the core of Julia weren't as approachable and hackable as it is, it would not be catching on as quickly. Julia will learn a few new tricks, I'm not saying it's perfect today. A few more operations will transition to returning views by default instead of copies, that'll help. But Julia's absolutely not Fortran, wouldn't be remotely possible in 1974. It's not trying to directly compete with Fortran at the things Fortran is good at either, much better-funded attempts at that in the past have failed.
&gt;You and I are seeing different things. Every thread on the mailing list that starts with "why is this slow" gets resolved by "here's how to profile your code, you can make things faster by doing A, B, and C to address these bottlenecks." What I'm seeing are people blindly applying random "tricks" until someone says he profiled. The problem is that it takes 10+ messages before going to that and the first things people are saying are "Did you unroll the loops? Did you use BLAS?". What I'm saying is that, most of the time, vectorized code is fine. Agreed for BLAS. A couple of devectorized expressions don't hurt readability. In some cases, it even improves readability a lot! I have no problem with that. But, devectorizing everything has two bad consequences: - Simple expressions such as A.*B .+ C*D - exp(k) are MUCH more complicated to grasp in for loops. Again, it is fine with good comments if it really counts in the total CPU time but otherwise, it should stay as it is. - Devectorization is usually orthogonal with code reuse: Laplacian(E) + Grad(G) cannot be easily replaced with devectorize expressions and each time you would encounter such expressions, you will have to write the same thing. Well, you could write a devectorized function but what if the next expression is Laplacian(Grad(rho)) + Grad(V)? Grad and Laplacian are two quite simple and vzry flexible functions. For each case, a devectorized function has to be written or else, a bigger and very complex function could be written. Whatever the case, readability is close to zero. Whereas if the compiler or a macro package such as Devectorize.jl do all this work for us, the code stay readable, reusable, maintainable and contributor-friendly. Oh andmore code redundancy == more places to alter the code == more errors. Oh and less readability == slower development pace + more errors + less contributors + more useless forks. Regarding Fortran, IMHO we are in the right spot to make the change. This is something that has been missed in the C++ realm. I'm not saying Julia can replace Fortran as it is. I'm just saying it has the potential to do it in the long run and it comes at the right time. Fortran compilers are dumb (but still better than Julia to handle vectorized code). Julia is already quite smart. Make it smarter and you'll see people comming. Fortran people are retiring, give the new generation something to work with. And no, I really don't agree: if you give a valid, clear, straightforward construct to the compiler and if the compiler is slow, there is a "problem" with the compiler, not with the code. And instead of spending times "optimizing" the code, it should be spent optimizing the compiler or a lib such as Devectorize.jl.
&gt; Simple expressions such as A.B .+ CD - exp(k) are MUCH more complicated to grasp in for loops. No, they really aren't. Indexing is pretty obvious. I've spent the better part of a decade replacing colleagues' for loops in Matlab code with vectorized versions to get order-of-magnitude speedups, and despite me constantly nagging at them that their code is slow (entirely as an artifact of the way Matlab/Python/R are implemented), they refuse to write vectorized code. For loops are simple and how most people learn to write code, despite being painfully slow in many high-level languages. Reusable stencils and common kernels for things like PDE's are certainly useful to have in a package. I think I linked to https://github.com/dpo/linop.jl elsewhere which would be good for that kind of thing. &gt; Whereas if the compiler or a macro package such as Devectorize.jl do all this work for us, the code stay readable, reusable, maintainable and contributor-friendly. User and library code maybe, but it makes the compiler or the Devectorize package all the more confusing. Julia has an impressive ability to transparently allow you to examine how the code gets transformed at every step from high-level algorithm description to lowered IR to LLVM to native assembly. I wouldn't want to sacrifice that ability by default in order to make vectorized code run a little faster, since unlike Matlab/Python/R we don't need to vectorize code in order for it to run quickly. If you're used to vectorizing your code in those environments then it feels slightly wrong to un-learn that habit, but plenty of people never wanted to write vectorized code in the first place. Readability is a very subjective thing. &gt; Fortran compilers are dumb Hardly. Perhaps for Fortran 77, but not modern Fortran 2003, 2008, etc with modules, generics, inheritance, co-arrays, and more. Again, if it were easy, there would be more of them available. No production-ready first-class Fortran compiler in LLVM yet, where much of the backend would already be taken care of for you. &gt; if you give a valid, clear, straightforward construct to the compiler and if the compiler is slow The problem is your valid, clear, straightforward construct is *too* valid, clear, and straightforward. You have to change the semantics of vectorized operations depending on their context in order for any of this to make sense. If you have a concrete implementation proposal for how to do this without making the language any harder to use, I'd love to hear it. I'd be all for it if it didn't make the top-to-bottom transformation process of Julia's compiler from high-level code down to assembly significantly harder to understand and predict.
I'm sure the functionality exists in PCRE, if the API is exposed it might be possible to do this via a low-level interface (ccall's if absolutely necessary). Make noise on the issue pages if there are features you would like to see, **especially** if you've got implementation suggestions.
I understand. We won't agree on vectorized expressions. Come on A.+B is always simpler than a explicit loop. I'm not saying that this kind of loops are hard to understand in an absolute sense. I even understand that the use of explicit indices make it clear that we are using a vector or a matrix or a n dimensional array but when browsing Fortran code from various sources, I always found it far easier to dive and alter the code in parts that were vectorized. Really. I'm not a Matlab user, that's not where I got used to vectorized code. I'll just use a very last example to at least have you understand that these are useful: BLAS. People usually don't know how to craft efficient algorithms (no their fault, this is very hard). They are optimizing a o(n2) algorithm while someone already implemented a o(nlog(n)) algorithm for them. The major example with this regard is "dot" vs. double loops. BLAS version is faster because it is crafted to use SIMD units and so that cache misses are avoided, true. But the divide and conqueer algorithm it uses for large matrices make it statistically faster than plain matrix multiplication. I agree that Fortran compilers are not dumb with regard to those features, but the core array oriented part of the code has nothing special (compared to JS). I don't really see the problem with these constructs at run time. Could you please be more specific? I mean, using vectorized expressions is working, don't they? I understand that you like to control how the expressions are converted to machine code. That's fine. What I propose is simple: ise as little magic as possible for the code in general. Use magic mainly for vectorized expressions. If you want a fine-grained control over how data is represented in the computer, juste use devectorized code. Since a computer already can't store a full vector in one memory slot, the vectorized-code user should understand that the LLVM and the assembly code Julia is generating is far from what he wrote, adding a few extra tricks won't matter that much. The advantage of this method is that it let the user choose the level of control it requires over the hardware. Second thing: why not allowing multilevel optimization? (I mean with a command line flag or a special function) If the compiler can prove that extra optimizations won't hurt anything, this should be safe enough. But if you really want the compiler to do as said and avoid optimizarions for a small but important part of the code, you could propose a "verbatim" block in which the code is converted to LLVM IR without that many optimizations. This way, the huge majority of people would just use Julia as usual. For having looking to LLVM IR from Julia as well as ASM, I can't help but saying that usually, while the LLVM IR is pretty close to Julia's code, the ASM code is ALREADY quite different. I wouldn't say unpredictable, but it's already optimized. I wouldn't be shocked if LLVM IR was much more different for vectorized expressions.
&gt; Come on A.+B is always simpler than a explicit loop. Of course. But nontrivial code is never as simple as that. Vectorizing code can often involve refactoring the indexing in an algorithm for sorting, taking unique elements, rearranging, and so on. Data dependencies are rarely 1-to-1. If it's straight-line code doing O(n) work on O(n) data, then vectorization vs a loop are equally trivial, it's a matter of personal taste. O(n) work on O(n) data is also the only case for which magic compiler tricks to make vectorized code as fast as C are really tractable. A good BLAS is exceedingly complicated and well-optimized, and should always be used where possible - especially for BLAS3 operations like matrix multiplication that are O(n^3 ) work on O(n^2 ) data, where the cache really matters. But making your compiler automatically optimize vectorized expressions to the level of performance that BLAS does? That's a herculean effort and not worth the attention of Julia's core developers when you can just use OpenBLAS, and there are so many other things to work on. There are people out there trying to do this kind of thing in Haskell, and I wish them luck, but I'm skeptical of whether it's even possible in any high-level language. Fortran arrays are quite complicated to get right, from a compiler writer's perspective. Few other low-level languages have first-class multidimensional arrays with the same capabilities that Fortran has. Indexing, slicing, reshaping, etc all adds up to more specialness than you'd think. Vectorized expressions work fine, as syntactic sugar and convenience functions. But they are inherently slow because they are syntactic sugar for an operator that allocates new memory for the result of, say, adding two arrays. You can avoid this by preallocating the result vector ahead of time and writing into it in a devectorized loop, or you can use an in-place function like `broadcast!` or `Base.LinAlg.axpy!` which should provide equivalent performance, but there's no easy concise syntactic sugar for basic in-place vectorized operators. &gt; why not allowing multilevel optimization? Well mainly no one has proposed an implementation of that feature yet. Julia's code generation is actually a little on the slow side at the moment, I'm hoping that can be addressed so the first execution isn't quite as much slower than future runs as it is right now. Static compilation of Julia code has been demoed in a rough state, and will be improved upon and made easier to do in future versions. That would be a great context in which to allow different optimization levels and start examining higher-level transformations. &gt; If the compiler can prove that extra optimizations won't hurt anything, this should be safe enough. That's the really hard part. Doing that data flow analysis on anything that's more complicated than a straight-line O(n) loop and proving that the temporaries (or the originals) will never be reused and can be overwritten in-place requires a great deal of careful compiler work. The benefit is faster vectorized code, but fast code is possible right now without doing this complicated work. There are other things to work on (like static compilation for example), I don't blame the core devs for focusing elsewhere. If vectorized code is near and dear to your heart and you would like to see its performance improved, try hacking on the packages that do clever metaprogramming tricks, or start digging into codegen.cpp, familiarize yourself with how the gc works and see if some of that tooling could be adapted, etc. It's open source, things get worked on as and by people who find them important.
&gt; Of course. But nontrivial code is never as simple as that. Agreed &gt;Vectorizing code can often involve refactoring the indexing in an algorithm for sorting, taking unique elements, rearranging, and so on. Agreed &gt; If it's straight-line code doing O(n) work on O(n) data, then vectorization vs a loop are equally trivial, it's a matter of personal taste. Nope, one kind is more verbose. But as you said, in this cases, this is personal taste. For instance, how would you devectorize that? C' * A' * B * C With A, B nxn-matrices and C n-vectors. It's still trivial this way. Is it still trivial with explicit loop? Is it still as fast? If this is more efficient than devecorized code (thanks to BLAS) why would I have then to switch to devecorized code? Well, you could say that with temporaries, this takes more memory than needed and you would be perfectly right. So, *either* optimize the compiler to avoid these temporaries (which should also increase vectorized code speed) *or* do some magic **on the devecorized code** to use BLAS in the background. On this point I agree with you: avoid the magic on devectorized code and put it in the already magic vectorized code. This way, when suitable, one can choose either a vectorized or devectorized form according to his taste/needs instead of choosing it "because it's faster". I also use devoctorized code, but I would rather use it because **I** find it clearer not because in most cases, devectorized code is faster. Do you see the difference? &gt; But making your compiler automatically optimize vectorized expressions to the level of performance that BLAS does? Not at all! :) BLAS is already making use of vectorized code, for this specific topic, I'm implying the exact opposite: *But making your compiler automatically optimize #devectorized# expressions to the level of performance that BLAS does? That's a herculean effort.* &gt; Fortran arrays are quite complicated to get right, from a compiler writer's perspective. Few other low-level languages have first-class multidimensional arrays with the same capabilities that Fortran has. Indexing, slicing, reshaping, etc all adds up to more specialness than you'd think. If you say so ... &gt; Vectorized expressions work fine, as syntactic sugar and convenience functions. But they are inherently slow because they are syntactic sugar for an operator that allocates new memory for the result of, say, adding two arrays. You can avoid this by preallocating the result vector ahead of time and writing into it in a devectorized loop, or you can use an in-place function like broadcast! or Base.LinAlg.axpy! which should provide equivalent performance, but there's no easy concise syntactic sugar for basic in-place vectorized operators. Making +=, -=, *=, ... inplace should help a lot. It would not help that much with dependency checks, operations reordering and function inlining and merging, but it would be a very good start that would make things easier in a whole bunch of problems. &gt; Well mainly no one has proposed an implementation of that feature yet. Julia's code generation is actually a little on the slow side at the moment, I'm hoping that can be addressed so the first execution isn't quite as much slower than future runs as it is right now. Static compilation of Julia code has been demoed in a rough state, and will be improved upon and made easier to do in future versions. That would be a great context in which to allow different optimization levels and start examining higher-level transformations. Agreed. &gt; That's the really hard part. Doing that data flow analysis on anything that's more complicated than a straight-line O(n) loop and proving that the temporaries (or the originals) will never be reused and can be overwritten in-place requires a great deal of careful compiler work. Yes yes yes! That's really tough. I know that it is always easy to criticize and say that a "smart-enough JIT/compiler" could do it. But the **only single thing** that I hate the most in Julia is that spirit of "for loops are really fast, we don't want magic, we don't care if vectorized code is slow". You know, more and more people are used to write vectorized code. Not only because it's more efficient in some languages, but also because these new guys just don't have the same background. Engineers and technical people tend to handle their problem in a scalar way, one value after the other. People from computer science are doing the same because they think scalar ("my struct fits like *this* in memory", "my counter is there, I'm iterating over the individual requests", etc.). For loops are just natural for them. Other people are coming from other fields where we always talk about vectors, matrices, tensors. For them, having to devectorize everything is a real pain in the a@@. They can do it, actually they do it, but usually just to build *that* matrix that should be diagonalized later... It's not just because of BLAS, it's also because if you want to solve the equation of heat or an eigenvalue problem, it's just easier to code and think about these multidimensional objects directly instead of having to devectorize everything. The new thing is that this kind of people are now coding their own stuff instead of asking a computer scientist or an engineer to do the boring work. When I'm talking about readability, I'm talking mainly about this. When I see: C' * A' * B * C I actually see: Let O be an operator such that O = A' B &lt;C| O |C&gt; = C' * A' * B * C This is just plain obvious and readable. If you really tried to devectorize this simple one-liner, you should see that you loose the straightforwardness (is that really an English word?) of this very simple expression. Someone coming from computer science would definitely say that there is nothing obvious in it, that he don't even know what it represents in memory and therefore that the best way to write it would be using explicit loops. But if I wanted to always care about those details, I would have picked up Rust/C/C++/(Fortran) in the first place to get full control over memory. But I chose Python and now with a bit of Julia to be able not to care about that. I'm not saying that you shouldn't care or that the usual Julia user should not care. I'm saying that without fast vectorized code, Julia, from my very own point of view, for my usage, is really no better that Python+Fortran/C. I would really love to see Julia not ending up being a "faster Matlab". I would just love to see it replacing Python and Fortran for scientific purposes. &gt; If vectorized code is near and dear to your heart and you would like to see its performance improved, try hacking on the packages that do clever metaprogramming tricks, or start digging into codegen.cpp, familiarize yourself with how the gc works and see if some of that tooling could be adapted, etc. It's open source, things get worked on as and by people who find them important. As soon as I reach my defense, I've planed to work on it.
&gt; For instance, how would you devectorize that? &gt; C' * A' * B * C &gt; With A, B nxn-matrices and C n-vectors. That's not a straight-line loop, it's O(n^2 ) work on O(n^2 ) data (BLAS2), depending on how you order the operations. &gt; So, either optimize the compiler to avoid these temporaries Would love to. Don't see how. Much easier said than done. The compiler can't read your mind. If you absolutely know that you don't need to use the vector C after this operation, I would ~~make one copy of it~~ edit: preallocate two vectors with space for the results (whoops, `gemv!` with aliasing doesn't work correctly), perform `Base.LinAlg.gemv!` to multiply one copy by `A` and the other by `B` in-place, then take the dot-product of the two results. Slight rearrangement, less clear because you had to know enough to write out `Base.LinAlg.gemv!` rather than `C' * A' * B * C`, but dead simple for the compiler to understand and dispatch to BLAS. If you want your code to run quickly, you're going to need at least a basic understanding of how memory allocation works, no programming language is going to be able to get around that fact. &gt; BLAS is already making use of vectorized code Have you read a BLAS implementation lately? They're written in low-level loops and assembly. There's an unfortunate collision of terminology regarding hardware vectorization (SIMD instructions - SSE, AVX, etc) vs high-level syntax vectorization. BLAS uses a whole lot of the former, none of the latter internally. Julia, Matlab, NumPy etc provide high-level array objects that dispatch to BLAS routines, that's where syntax vectorization comes from. Fortran can do syntax vectorization too, but the result isn't going to BLAS - it's transformed into hardware vectorized CPU instructions by well-optimized, mature compilers. &gt; Making +=, -=, *=, ... inplace should help a lot. There's at least one issue open on that - the difficulty there is you lose generality if += means one thing for arrays, and has totally different semantics for scalars. Currently x += y always desugars to x = x + y, which is very simple to understand. Pretty sure you can do x[:] += y or something to that effect right now, slightly less pretty but it should work in-place without costing operator generality. &gt; But the only single thing that I hate the most in Julia is that spirit of "for loops are really fast, we don't want magic, we don't care if vectorized code is slow". I don't think that quite captures the attitude. It's more that there is finite time and resources, magic is hard, we can get speed without it. That's not a blanket statement of "no improvements will ever be made here ever, deal with it." I believe there is actually some special parsing right now for `A*B*C`, which could be specialized to do things in a more clever order depending on the array sizes involved. I just don't think the cleverness has been written yet. 
&gt;Have you read a BLAS implementation lately? Come on, you know what I meant: from within Julia, if you want to use BLAS, you need vectorized code. You can't call gemm on devectorized code for instance. So you actually don't need to optimize Julia compiler to obtain BLAS-like performance: something already exists to handle such vectorized code, BLAS and its implementation :) If some part of Julia need some work to reach BLAS-like performances, it is where BLAS can't be used: devectorized parts of the code. At least, you seem to understand my point. Yes those are not O(n) operations but I gave only examples of such operations to keep everything simple. If you are wondering, I really do see the point of devectorizing code too. I just wished it would be choosen based on taste/readability and not for performances.
I think you want to look at the MCMC.jl package, but sadly cannot give you any better guidance.
Post back here if you figure it out. 
https://github.com/dmbates/MixedModels.jl Doug Bates is the author of the lme4 package for R. Most of the code in Gelman/Hill is written for both lme4 and bugs/jags/stan. 
This is in no way an answer, but the stan user manual states that &gt; Work is underway to develop interfaces for Stan in: &gt; &gt; * MATLAB &gt; * Julia &gt; * Stata I wonder what state the Julia interface is in.
There's a very long back-and-forth discussion on this from a few months ago here: https://github.com/JuliaStats/MCMC.jl/issues/45 Interfacing to the internals of Stan is difficult because it's all C++, and has no `extern "C"` API. This may become easier in the future, evidently Keno showed some cool C++ FFI work at JuliaCon that I'm eagerly awaiting the videos from. There is an under-development wrapper package here https://github.com/goedman/Stan.jl that looks like it's mostly just calling the command-line executable version of Stan and loading results back into Julia.
Check out the just-registered [Stan.jl](https://github.com/goedman/Stan.jl).
I'd recommend checking out Light Table with the Jewel package instead of using Julia Studio.
I was not successful figuring out how to load Jewel when I tried it a couple weeks back. That said, [their wiki](https://github.com/one-more-minute/Jupiter-LT/wiki) appears to have been updated recently. Time to give it another go! Can you elaborate on your experiences with Jewel? Anything you've found particularly useful? 
Downloaded it and tried again today. Everything worked as advertised. Not sure what the issue was before. Anyway, Jewel looks like a great interactive environment.
&gt;&gt;"The main problem IMHO is that in this kind of community, if you allow more complex constructs which give more speed, the are gonna use it almost everywhere..." HKT is on the wish list in the Rust community - abstracting over pointer-types is a desirable use case. If you had HKT you could make the same algorithms work either with GC , unique &amp; borrowed pointers, or refcounting. However , it would require more information to be specified in function signatures. 
Some details were posted by David Sanders over at [julia-users](https://groups.google.com/forum/#!topic/julia-users/p0BJjzA3NOM). [Here are the IJulia notebooks](https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fdpsanders%2Fscipy_2014_julia&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNGNLZ-d8BO49iIwKrkSnXwjuncJGA) that he used.
If you want to get serious about benchmarks sometime, a great way to do it is to submit a pull request to [techempower](http://www.techempower.com/benchmarks/#section=intro&amp;hw=peak&amp;test=json).
Wow, thanks. This is perfect. &gt;Check out the just-registered [Stan.jl](https://github.com/goedman/Stan.jl). 
Looks like they did it for me! 
Really great tutorial. Thanks!
This is a great! it is kind of in the same spirit as [Bret Victor's Future of Programming](https://vimeo.com/71278954)
Is there any list of changes?
Yes. Here are the changes. https://github.com/JuliaLang/julia/blob/master/NEWS.md
Take a look at [NEWS.md](https://github.com/JuliaLang/julia/blob/master/NEWS.md)
Have you tried Polynomial.jl? https://github.com/vtjnash/Polynomial.jl You can construct each of the terms for which you know the roots as separate polynomials using poly(r::AbstractVector), and them sum all of them (arithmetic operators are overloaded for polynomials in this lib).
I'll give it a shot when I work on it tomorrow, thanks!
Note that its active development has moved to *Polynomials.jl*: https://github.com/Keno/Polynomials.jl This switches the coefficient order to the more sensible (albeit less standard) increasing order. See [vtjnash/Polynomial.jl#5](https://github.com/vtjnash/Polynomial.jl/issues/5) for more details.
there were plans to allow abstract types to define "slots", but i think it ended without consensus in exactly how. might still happen one day (i think it would be a good idea).
This is some awesome analysis. I wonder how this compares to other languages.
A few years old but here is [R](http://librestats.com/2012/05/17/visualizing-the-cran-graphing-package-dependencies/)
and QT (!) https://groups.google.com/d/msg/julia-dev/4kUu2ieWZ9Q/e09X4Z2vS_kJ
There are several good resources avaliable for learning Julia: - Julia Documentation http://julia.readthedocs.org/en/latest/manual/getting-started/ - Julia By Example http://www.scolvin.com/juliabyexample/
I too am excited by Julia, in the long term, but the start-up time is so far the deal-breaker for me. It makes it less fun to experiment and takes me out of any kind of flow. I'm interested in trying again when there's a released version with better start-up time. Being able to work with dictionaries as fast as in Python (yes, I mean what I just said) would also be nice.
Anyone care to elaborate on exactly why this is so cool? Obviously a C++ FFI will be really nice if you need to interact with C++ code, but from Stefan K's response in the newsgroup, he says this capability is unprecedented. Can someone help me understand the full awesomeness of this hack? EDIT: Stefan, not Steven
Basically, all external (non-C++) interfaces to C++ code go through a C-compatible API wrapper layer. This means that libraries which make heavy use of templates and method overloading are either not usable outside of C++ or they only support a neutered C-compatible API without those features. Keno's code goes through the C++ headers, determines templates and the mangled overloaded names, and then dynamically generates the necessary code for the proper types. The fact that it *also* supports some C++-like syntaxes is just gravy on top. Apparently, there's been some work along these lines with Cling, so it's not entirely unprecedented. But it is still pretty darn unique.
Thank you!
I liked it a lot. Took less than an hour to get familiar with the language. I will quote it as howistart.org or learnxiny for Julia whenever i give a reference to someone .
The problem with subject.verb(object...) is it's completely incompatible with multiple dispatch. Every time I try to do operator overloading in Python or Matlab I end up with: function plus(a, b) if isa(a, type1) ... elseif isa(a, type2) ... elseif isa(b, type1) ... and so on, it's just unbearable.
The startup time - at least for self-contained Julia programs - should be resolvable if/when it implements AoT compilation (if it hasn't already; I haven't been paying *that* close attention to things, but I haven't seen any mention of it yet). That removes some of the advantages of JIT compilation, though. That said, it's not *that* bad to me. A bit sluggish, sure, but I sort of expect that for an interactive session (I don't have a MATLAB or Python perspective, however; I'm primarily a Perl programmer with some background in Java and .NET).
All packages available via the package manager are automatically tested both for 0.2 and a nightly build of master (which will be 0.3 soon) by our great PackageEval system (http://iainnz.github.io/packages.julialang.org/). That way, you can be sure that most package developers will keep them working on the most recent builds.
Hi muktabh, I'm anj1 from the NeuralNets.jl project glaksh09 linked above. We are definitely interested in implementing deep learning and denoising autoencoders. One of us (Pasquale Minervini) has done a fair bit of work on deep learning in theano. You might want to chat him up. 
Sure, I will contact him. 
I would not focus on the data structures as much as I would try to understand the typing system. The typing in Julia allows one to create any data structure they want. This combined with multiple dispatch are one of the strengths of the language. Basically you are free to define things you may need as you wish. 
Thanks - that's useful for me. So it's basically "tuples" and "arrays" (not "lists" or "matrices"). And two forms of "dict".
Really, I primarily use 1-D arrays as lists, too. They're extremely optimized, and grow well at the beginning and end. Tuples are mostly good for very small fixed length collections — they're used internally as the argument lists for functions and returning multiple values. They're optimized for this purpose, and are very happy to just sit in CPU registers when possible. There is another important difference between the two: tuples are immutable and cannot be modified in-place.
As far as I know, there's no easy way to remove these dependencies, as they are used in the implementations of Base functions. I don't think Julia would be an appropriate language for embedded computing right now, but it could definitely be in the future. One thing that will probably help is the ability to compile stand-alone binaries, which is being discussed. Another thing that could be an issue for embedded applications is that right now Julia only runs in x86 32 and 64 bit architectures. The main problem are the external dependencies, as Julia code itself is compiled by LLVM which has many other backends. I believe a port to ARM will definitely come up in the future.
&gt; As far as I know, there's no easy way to remove these dependencies, as they are used in the implementations of Base functions. That seems... strange, but unsurprising. Most languages' stdlibs (AFAIK) are able to segregate those advanced math functions (and other "helpful" things) from the core library for this reason, but I figure Julia isn't most languages :) That said (based on a quick glance over the C source, which would be the *major* hiccup to cleaning these sorts of things up, I reckon), it looks like the actual C code seems to depend mostly on the non-math dependencies (libuv among them). That's reassuring, since (if my hopes pan out) it means that one would just have to refactor the stuff written in Julia (split the fancy math stuff into their own packages where they're probably better off anyway, then make sure that nothing deep down actually requires those packages in order to basically function). &gt; I don't think Julia would be an appropriate language for embedded computing right now, but it could definitely be in the future. One thing that will probably help is the ability to compile stand-alone binaries, which is being discussed. Indeed it will, and is something I'm optimistically betting on. For my purposes I don't mind having the `julia` interpreter present, though it would certainly be cool to not even require *that* as a runtime dependency for Julia programs. &gt; Another thing that could be an issue for embedded applications is that right now Julia only runs in x86 32 and 64 bit architectures. The main problem are the external dependencies, as Julia code itself is compiled by LLVM which has many other backends. I believe a port to ARM will definitely come up in the future. That's another big reason why I'd want to cut down on the number of dependencies. Less dependencies would mean a hypothetically-easier time porting to ARM or MIPS or Power or some other non-x86 CPU.
i'm not sure julia is the right language for low resource environments. in particular, it needs the ability to compile code at runtime, so (1) it needs a lot of "stuff" at runtime and (2) the size of an "executable" is not fixed. in fact currently there isn't even any supported way of generating a standalone executable (afaik; admittedly i've been out of the loop a few months). in other words, the llvm is in there, at runtime, by design. you might be able to hack things to get rid of matrix lib dependencies, though. one of the things they're (justifiably) proud of is that support for matrices etc is library-level rather than core language. but i don't think there's existing support for doing so. just reading your other comment here and yes, libuv is baked in. you'd have a hard time removing that. the google groups are very active. questions there will be seen by the right eyes.
Well, without libm, you can't do maths (or you'll have to reimplement everything yourself). Without BLAS/Lapack, you would have to reimplement everything also, but less efficiently... As other said, it might get better in the future though. 
it's not llvm, it's the language. julia compiles new, type-specific versions of code when new types are found *when running the code*. there has been talk of somehow producing an "executable", but that would still need to somehow bundle the llvm, or at least be installed in parallel with it (the language doesn't have full hm type resolution, so currently doesn't "know" what types might exist). at least, that's my understanding...
&gt; Well, without libm, you can't do maths (or you'll have to reimplement everything yourself). That's understandable, then. &gt; Without BLAS/Lapack, you would have to reimplement everything also, but less efficiently... Beyond linear algebra functionality, though? That all seems like something that would be better suited as a discrete, standalone Julia package; I'd be really surprised if the core language really depended on that.
&gt; it's not llvm, it's the language. julia compiles new, type-specific versions of code when new types are found when running the code. Forgot about that; parametric types like Julia has become complicated to implement in combination with non-static typing, from what I understand. Maybe that could be more readily addressed by some way to put Julia in a "static mode" that requires type declarations? On the other hand, maybe I'm better off with Ada for that... &gt; there has been talk of somehow producing an "executable", but that would still need to somehow bundle the llvm, or at least be installed in parallel with it (the language doesn't have full hm type resolution, so currently doesn't "know" what types might exist). Even that's tolerable, for now at least. Having to bundle LLVM for basic functionality is less strange (in my opinion) than having to bundle a bunch of linear algebra and matrix manipulation libraries for basic functionality.
I believe the standard library calls/wraps the math dependencies directly in Julia, so packing a different version of Base should be doable. Did you try asking this on julia-dev? It may be simpler than I think (I am not very familiar with the inner workings of the interpreter/JIT, as I only develop libraries for Julia). I am also betting that Julia will be a great language for embedded systems and had no intent to discourage you from using it, it's just that it is not "production-ready" yet. Please keep this sub-Reddit and/or the mailing lists posted in case you manage to get something running on an embedded platform!
Julia, as it is now, is targeted to number crunching. Pretty much ever library out there makes use of linear algebra. Julia's developers made the choice to implement a first-class and very efficient array class. That's a design choice. Those are real arrays, not just a reccursive collection of pointers and in order to make them first-class, one needs to allow standard operator to seemlessly work on them. Using BLAS just makes sense. In other languages, arrays were included as an afterthought. Some of BLAS or Lapack could be reimplemented in Julia though. I, myself, would prefer to see a bunch of standard lib**s** not overlapping with each other (pretty much like Rust did a few months ago) instead of having the namespace cluttered by a lot of stuff. This would have made the exclusion of some dependencies easier. The namespaces would be less cluttered and that would make the use of the same variable/method name possible when suitable. But they chose to do otherwise and I can understand why (help beginners finding stuff at the expense of everything else). It's pretty much like the 'end' statement: it feels familiar for matlab users but requires 3 characters to write and, more importantly, that requires that you already know which statement opens a block and which don't. Brackets (a la C) or spaces (a la Python) would have required no such knowledge and be easier to parse yourself, but well, again design choice: there is always someone to complain about your design.
&gt; Those are real arrays, not just a reccursive collection of pointers and in order to make them first-class, one needs to allow standard operator to seemlessly work on them. Using BLAS just makes sense. Except [the array implementation doesn't appear to link to any of the linear algebra dependencies as far as I can tell](https://github.com/JuliaLang/julia/blob/master/base/array.jl). Most - if not all - of the array operations involve calls to either the C `memmove` function/library or Julia's `array.c`, which doesn't seem to include a BLAS dependency, either. The linear algebra libraries probably help with abstracting aspects of array manipulation and performing calculations on arrays, vectors, matrices, etc., but the actual "first-class array implementation" seems to (rather impressively) be independent of that. &gt; But they chose to do otherwise and I can understand why (help beginners finding stuff at the expense of everything else). From what I gathered in the [GitHub issue I was referred to when I posed this question last night on the julia-dev list](https://github.com/JuliaLang/julia/issues/5155), it seems like these two things aren't actually incompatible. The current desired approach seems to be that there will still ultimately be a clear separation of concerns within the "standard" base; that way, beginners can have the defaults they know and love and expect, while those wanting to bend Julia to different realms (like myself) can easily exclude what's not needed for a particular application.
When I said first-class array, I was thinking about "*" being the dot product by default for instance ("standard operators"). This is where some kind of BLAS is needed. Otherwise, you have efficient arrays but inefficient array operations. The discussion on github about base split has only resumed a few hours ago but I'm very happy with it. Overall, I'm very satisfied with the current trend, people were not that enthustatic 8 months ago. Julia is on its way to become more general-purposed! Keep pushing with embeding Julia, something very good may come out. (That's not ironic, a general purpose language with 1st class algebra, c++-like performance and python-like expressivity, I'm all in) At first, I was thinking that making BLAS optional would be stupid for a language such as Julia. I still think it's not really a good idea for the JIT-ed Julia (at least by default, why not in custom build as it would be useful to some people such as you). However, when support for standalone binary lands, that becomes far more interesting 
&gt; When I said first-class array, I was thinking about "*" being the dot product by default for instance ("standard operators"). This is where some kind of BLAS is needed. Otherwise, you have efficient arrays but inefficient array operations. That's true, in which case I wouldn't be surprised if someone ultimately - as you suggested - decides to try to create a pure-Julia linear algebra package for at least the basic operations. Maybe it won't perform *quite* as well that way, but given how Julia is billed to be at C/FORTRAN-comparable speeds without the hassles of programming in C and FORTRAN, I'd anticipate it coming pretty close. &gt; Overall, I'm very satisfied with the current trend, people were not that enthustatic 8 months ago. Julia is on its way to become more general-purposed! Keep pushing with embeding Julia, something very good may come out. (That's not ironic, a general purpose language with 1st class algebra, c++-like performance and python-like expressivity, I'm all in) Amen to that. I probably wouldn't be asking these kinds of things if I didn't think Julia would be an awesome language to use for the emerging world of tiny, intelligent, low-powered devices :)
&gt; type-specific versions of code when new types are found *when running the code.* It's perfectly feasible that you could disable this behaviour, though. You could compile the main() function as far as possible with the types you know ahead of time, then compile everything else as dynamic code. It would work, albeit more slowly than JIT-compiled Julia. That said, I'm willing to bet that Jeff &amp; co. have some tricks up their sleeve to get AOT compilation without dropping performance.
Both languages are easy enough to get started with, and more broadly similar than, say, Common Lisp and Fortran. You'll safely blend in with the crowd with Python, which has dozens of books, tutorials, courses, -- and users. With Julia you'll be more of a pioneer, since it's much newer. 
Learn both, if you can. Julia will make it easier for you to convert Matlab/Octave users. Python will show you the world.
You can learn either or both, it's not a huge leap between the two. If you want to just use the language and established packages and hit fewer rough edges, go with Python, unless performance is really important to you. If you want to very quickly transition from user to contributor, this is incredibly easy with Julia. Chances are you'll hit more rough edges or areas in need of improvement since the language is much newer and has fewer users, but just as easily if you speak up about difficulties you run into you're probably quite capable of fixing some of them yourself.
Julia is probably a good first language. I say "probably" because it's still under active development. What you have going for it is the ability to have an interactive Julia session (a.k.a. the "REPL"), which lets you play around with code snippets and immediately see their effects and how they work. What you don't have going for it is that Julia isn't as mature, so there aren't as many textbooks, courses, tutorials, etc. for you to learn from. The documentation is thankfully pretty good, though, so you might be alright. For what it's worth, I vastly prefer Julia over Python (and almost prefer it over Perl; Julia's at a very close second-place position in my list of favorite programming languages).
http://www.juliabloggers.com/ has a lot of examples with code that is more detailed. I would look at the julia news groups for specific things you may want. Also I would check of IPython julia notebooks for more complicated examples.
http://forio.com/labs/julia-studio/tutorials/
https://www.kaggle.com/c/street-view-getting-started-with-julia
Hooray! Here's the GitHub Markdown-rendered version of the release notes, which gives you links to the issue tracker: https://github.com/JuliaLang/julia/blob/release-0.3/NEWS.md 
Surely I wasn't the only one who had to [look up 4GL](http://en.wikipedia.org/wiki/Fourth-generation_programming_language)?
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Fourth-generation programming language**](https://en.wikipedia.org/wiki/Fourth-generation%20programming%20language): [](#sfw) --- &gt;A __fourth-generation programming language__ (__4GL__) is a [computer](https://en.wikipedia.org/wiki/Computer) [programming language](https://en.wikipedia.org/wiki/Programming_language) envisioned as a refinement of the style of languages classified as [third-generation programming language](https://en.wikipedia.org/wiki/Third-generation_programming_language) (3GL). Each of the [programming language generations](https://en.wikipedia.org/wiki/Programming_language_generations) aims to provide a higher level of abstraction of the internal [computer hardware](https://en.wikipedia.org/wiki/Computer_hardware) details, making the language more [programmer](https://en.wikipedia.org/wiki/Programmer)-friendly, powerful and versatile. While the definition of 4GL has changed over time, it can be typified by operating more with large collections of information at once rather than focus on just [bits](https://en.wikipedia.org/wiki/Bit) and [bytes](https://en.wikipedia.org/wiki/Byte). Languages claimed to be 4GL may include support for [database](https://en.wikipedia.org/wiki/Database) management, [report generation](https://en.wikipedia.org/wiki/Report_generator), [mathematical optimization](https://en.wikipedia.org/wiki/Mathematical_optimization), [GUI development](https://en.wikipedia.org/wiki/Graphical_user_interface_builder), or [web development](https://en.wikipedia.org/wiki/Web_development). Fourth-generation languages have often been compared to [domain-specific languages](https://en.wikipedia.org/wiki/Domain-specific_language) (DSLs). Some researchers state that 4GLs are a subset of DSLs. &gt; --- ^Interesting: [^Fifth-generation ^programming ^language](https://en.wikipedia.org/wiki/Fifth-generation_programming_language) ^| [^DBase](https://en.wikipedia.org/wiki/DBase) ^| [^ICL ^VME](https://en.wikipedia.org/wiki/ICL_VME) ^| [^Parallel ^computing](https://en.wikipedia.org/wiki/Parallel_computing) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cjwoamu) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cjwoamu)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Yessssssss! Finally! Thanks to the devs.
Available as an official Arch Linux package. 
Ideally, a Julia Studio developer would confirm this, but fwiw, I've struggled with it myself. I've concluded that `julia-simple` binary that Julia Studio is looking for is some type of modified Julia that works "nicely" with current implementation of the Studio. Once they work out the details in future, it should be possible to point it to your choice of Julia. I tried looking for what has gone into `julia-simple` binary on their site, but haven't found it. If they even mention which library or modifications were needed to create it, I'd be up for compiling every major version of Julia to make it `simple`.
It might save you time and you might be more satisfied with the result if you try IJulia or the Light Table plugin. Or just use the built-in Julia REPL from the terminal along with your favorite text editor.
"Julia is just a Lisp": $ julia --lisp ; _ ; |_ _ _ |_ _ | . _ _ ; | (-||||_(_)|__|_)|_) ;-------------------|---------------------------------------------------------- &gt; 
I definitely recommend IJulia over Julia Studio for the time being. It has just about everything I need in a decent IDE. I think a nice CSS skin to make IJulia look like RStudio or PyCharm or a similar IDE can really help new users see the benefit of IJulia. If you're just getting started with Julia, here's the setup that has worked well for me (on OS X). I have a dedicated iTerm (terminal) window for IJulia launch. I keep it minimized unless I run into some issues for which I need to look at logs. I have a split iTerm window, both running Julia REPL. One of those is to replicate IJulia, to make sure the output/usability is still good for those who don't run IJulia. The other session is to test specific functions or scratch-code. And I have an iTerm window open with the terminal in my code or asset directory. This 1 IJulia window + 2 iTerm Julia REPL + 1 iTerm bash combination has served me incredibly well in last two weeks of project work. It works for 99% of my needs in an IDE including visualization, command line, other I/O, etc.
Emacs + IJulia notebook
Julia Studio
I tend to use emacs or IJulia. That said, I think it would be brilliant to figure out how to get Julia support into RStudio. While some may claim IDEs are less karmic, I've seen how much of leg-up RStudio has been for grad students.
I am on Debian testing/unstable. I do a lot of exploratory programming in the REPL, and am a heavy git user so I always have my terminal open. The latest Gedit(3.12) is very polished. I like to have the file browser extension installed so I can quickly open stuff, and enable the "draw whitespace" extension so my code is always clean. This is my environment: http://i.imgur.com/p5j0aB0.png
I tried Emacs, LightTable, and SublimeText. For me, SublimeText + a terminal is the clear winner. IJulia is nice for writing tutorials or workflow documentation, but not as good for exploratory programming. Regarding Emacs and LightTable: the ESS extension for Julia never worked well for me, and LightTable with Juno is really nice but LightTable is bloated and buggy.
Nothing special about Julia on EC2 versus anything else on EC2. You may find that EC2 doesn't buy you a whole lot of speed advantage depending on where you're performance bounded. EC2 will help you if you need more cores, memory, or possibly disk IO thrown at the problem. But, if you're not running parallel code or running into swapping issues, EC2 is probably not going to offer you single-core gains. Another option for on-demand computing in the cloud is Digital Ocean. I spun up a $5/month instance to use as a VPN last month, and found the process to be pleasantly simple. EDIT: Should clarify, Digital Ocean is another cloud computing option with roughly the same performance considerations as EC2.
I'm actually working on a demonstration of Julia being deployed into a cloud using Juju, and scaling it out using juju too. It's sort of on a back burner, but it's totally possible and relatively trivial to do.
I am not sure it is correct, but I sometime describe Julia as a Lisp with syntax.
Julia Studio - http://forio.com/labs/julia-studio/
Thanks for your comment, I think you're 100% correct that the main key will be figuring out how to write my code to parallelize intelligently. I found out today that my research team has access to three Unix servers, one running 1000 Serial, Single Core, one with 1000 core parallel MPI and one with parallel OpenMP. So figuring out how to send my independent for loops across those cores will be a high priority. Until I can get that to work, I will probably give Digital Ocean a try for some smaller scale problems. That looks like it's a little cheaper than building a workstation from scratch. Thanks!
You have a syntax error in your last "print", single quotes are used to quote character literals, not string literals. But that's not the problem. What version of julia are you using? With 0.3.0 once I fix the first bug, I get the expected "Hello world" output, and nothing else. IIRC multiline comments aren't in 0.2.x.
I had the same problem. I was told to delete JuliaStudio and stick to vanilla command line. Works well for me (for now). Will be checking out IJulia workflow next week.
Turns out I downloaded one of the older releases(0.2.1). Works now.
The comment about parenthesis in Lisp, yawn. If you don't have anything more interesting to say about Lisp, you should better not say anything at all. 
This. I know writing documentation is boring and time consuming, but a large part of the reason people put up with R is as awkward as parts of it are, you can figure out quickly how to do things thanks to the documentation (which individual packages add to). I don't understand why Julia packages can't add to the built in documentation.
Most packages are actually well documented as far as I know, the real problem is (as you also pointed out) integrating the documentation. At the moment is all scattered in the packages pages. As for extending the built-in docs, it's technically possible (PyPlot.jl does it, for example), but there has not been until now complete consensus on exactly how to do it. There is work in progress on that front though, drafts have been proposed, pull requests are outstanding etc. This is certainly something the devs are well aware of. In the meanwhile, there is also a package, [Docile.jl](https://github.com/MichaelHatherly/Docile.jl), which allows you to add doc strings and have them integrated in the built-in system. But not everyone likes doc strings, i.e. documentation interleaved with code (I don't, for example). So there should be a generic system which allows people to choose how they want to provide docs. Other issues, in random order: format (plain text, HTML, markup, rest...?), integration with tools (termnial, IPython notebooks, browsers...), integration of the manual pages (access from the main Julia manual, cross-linking...). The multiple-dispatch nature of Julia also introduces some peculiar problems in this regard. So it's just that people have different opinions, preferences and needs, and everybody would like to get it right.
I took that as a not particularly serious comment which is just meant to signify how alien LISP syntax is with resepct to other more familiar languages such as C++, python etc. Not particularly interesting, but not wrong either. At least that's my interpretation. Perhaps a little more interesing in light of that remark is that ["as everyone knows, Julia is just LISP"](https://www.youtube.com/watch?v=osdeT-tWjzk&amp;t=675) :) $ julia --lisp ; _ ; |_ _ _ |_ _ | . _ _ ; | (-||||_(_)|__|_)|_) ;-------------------|---------------------------------------------------------- &gt; (+ 2 3) 5
this was not special syntax in julia 0.2.1, the # comments the *line* and the =# is a syntax error.
&gt; I took that as a not particularly serious comment which is just meant to signify how alien LISP syntax is with resepct to other more familiar languages such as C++, python etc. Sure, but it's not exactly a compelling reason to pick Julia specifically though. I mean, why not move to Clojure, which has reduction of parentheses as an explicit goal?
That didn't work out too well, though: (defn qsort3 [[pivot :as coll]] (when pivot (lazy-cat (qsort (filter #(&lt; % pivot) coll)) (filter #{pivot} coll) (qsort (filter #(&gt; % pivot) coll)))))
Ha, fair enough - still a reduction from lisp though, and the vector and set notation does help. What would a similar Julia implementation of quicksort look like?
There's a few on github: function qsort_3way!(v, lo=1, hi=length(v)) @inbounds begin hi &lt;= lo &amp;&amp; return; hi-lo &lt;= SMALL_THRESHOLD &amp;&amp; return isort(v, lo, hi) lt = lo; gt = hi; i = lo; piv = v[lo]; while i &lt;= gt elem = v[i]; if isless(elem, piv) v[i], v[lt] = v[lt], v[i]; lt+=1; i+=1; elseif isless(piv, elem) v[i], v[gt] = v[gt], v[i]; gt-=1; else i+=1; end end qsort_3way!(v, lo, lt-1) qsort_3way!(v, gt+1, hi) end return v; 
Thanks, I've seen a few, but I was hoping for something idiomatic like the clojure one.
Here's one roughly equivalent to the Clojure version: qsort(xs) = isempty(xs) ? xs : [xs[xs .&lt; first(xs)] |&gt; qsort, first(xs), xs[xs .&gt; first(xs)] |&gt; qsort]
Lisp is a very interesting an powerful paradigm. Highly influential for the development of other languages and still being used by many despite its age (second oldest high-level programming language). The various design aspects of Lisp combine elegantly and interact in ways that create an enormous depth. To anyone who appreciates the power and elegance of Lisp, the parentheses are a very small price to pay and not worth being mentioned. You could go even further and say that Lisp is powerful in part because of the parentheses.
This is more idiomatic for Julia, at least in that it is likely higher-performance than the shorter version posted by /u/one_more_minute. Note the devectorization, in-place operation instead of allocating temporaries, and the `|&gt;` operator for function chaining has been discouraged by Jeff due to the not-ideal way it's currently implemented.
Can someone who uses a text editor + a terminal tell us about their workflow? How do you run and re-run large sections of code? Where do you plot? etc. I'm using LightTable with the Juno plugin right now, and I do feel that it could be snappier.
You can turn the string into an IOBuffer with iob=IOBuffer(stringvariable), then I think you can pass this to readtable(iob)
Have done this. Works well as long as you're on the 0.3 version of DataFrames.
`include("mycode.jl")` ? Best if you put things in a module so there's less complaining about redefining types, etc. Depends on your OS and what libraries you have available, but Winston and (I think) Gadfly should be able to use Tk or Gtk backends. The ease of plotting with Gadfly outside of IJulia could definitely be improved, hence I prefer Winston for most simple things. But I also came from a Matlab background rather than R so I'm not too picky about ggplot2-style features. If your background is Python, then PyPlot is most likely the way to go for now.
Thank you, I think this is the winner.
What's the difference between this and https://colaboratory.jupyter.org/welcome/? One thing that immediately jumps out at me, is that jupyter links to their source code, and juliabox has no detail of their product besides a few catch-phrases below a big sign-in button. Edit: Who is organising this, can we just trust any website with our login?
&gt; What's the difference between this and https://colaboratory.jupyter.org/welcome/? One thing that immediately jumps out at me, is that jupyter links to their source code, and juliabox has no detail of their product besides a few catch-phrases below a big sign-in button. I'm not quite sure how to get Julia to run on colaboratory. I found this mentioned in an email from the Julia Cambridge group, but it seems to be edited out of the description now. I think it is connected to https://github.com/JuliaLang/JuliaBox
It is the julia team behind it - but it is not yet ready for general public usage, which is why the lack of information. We are using it for a class at MIT currently, with close monitoring and handholding. If you do try it out it in its current form, do drop us a note! When it is a bit more polished and as ready as it can be, we will announce it.
Wow! This is pretty cool. I logged in and was immediately able to install a package. 
This doesn't seem like a good explanation of what it hopes to explain. http://nedbatchelder.com/text/names.html is a good explanation of much of the same stuff for Python, which has the same semantics.
Found this on their FB page: https://www.facebook.com/julialanguage I'm faced with the polyglot quandary, &amp; anything that portends reducing the language spread is a plus. As it stands I'm currently confronted with the possible requirements for PostGIS, R, Python &amp; then in descending order of time overheads &amp; other risks: Go, Jython-JyNI, Scala, C, Python-to-C, etc. Because our project work entails applied optimization algorithms &amp; other machine learning ability, having speed &amp; quality libraries at our disposal is almost an absolute requirement. And if Julia's performance &amp; library interfaces proves sufficiently reliable &amp; robust, esp. if it can serve increasingly in R's &amp; Python's stead, then the dilemma of manifold polyglot interfaces could be substantially resolved. 
Well, [according to the Julia team guy who just posted](http://www.reddit.com/r/Julia/comments/2flf0l/juliabox/ckaxx4x), it's the Julia team themselves who are behind it. Also, nice to see you here, vdZ! Small world. Have you also started learning Julia?
Hey Doc! Well, kind of. I've looked into it, played with it a bit - I love the language design itself, but the applications don't quite match my own usecases just yet. But god, do I love how it is designed and implemented. It's just aesthetically pleasing.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Lattice Boltzmann methods**](https://en.wikipedia.org/wiki/Lattice%20Boltzmann%20methods): [](#sfw) --- &gt;__Lattice Boltzmann methods (LBM)__ (or __Thermal Lattice Boltzmann methods (TLBM)__) is a class of [computational fluid dynamics](https://en.wikipedia.org/wiki/Computational_fluid_dynamics) (CFD) methods for [fluid simulation](https://en.wikipedia.org/wiki/Fluid_simulation). Instead of solving the [Navier–Stokes equations](https://en.wikipedia.org/wiki/Navier%E2%80%93Stokes_equations), the discrete [Boltzmann equation](https://en.wikipedia.org/wiki/Boltzmann_equation) is solved to simulate the flow of a [Newtonian fluid](https://en.wikipedia.org/wiki/Newtonian_fluid) with [collision](https://en.wikipedia.org/wiki/Collision) models such as [Bhatnagar-Gross-Krook](https://en.wikipedia.org/wiki/Bhatnagar-Gross-Krook) (BGK). By simulating streaming and collision processes across a limited number of particles, the intrinsic particle interactions evince a microcosm of viscous flow behavior applicable across the greater mass. &gt; --- ^Interesting: [^Computational ^fluid ^dynamics](https://en.wikipedia.org/wiki/Computational_fluid_dynamics) ^| [^Fluid ^simulation](https://en.wikipedia.org/wiki/Fluid_simulation) ^| [^Lattice ^gas ^automaton](https://en.wikipedia.org/wiki/Lattice_gas_automaton) ^| [^Boltzmann ^equation](https://en.wikipedia.org/wiki/Boltzmann_equation) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+ckbhe2h) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+ckbhe2h)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Ah right, now I remember: you're always working on nigh-impossible fluid dynamics. Great if the language gets out of your way. Haven't played with the languge enough to give you any advice on the parallelism, but if you haven't asked there yet then I guarantee that [the google group for Julia](https://groups.google.com/forum/#!forum/julia-users) will have your confusion cleared up within a day or two. Many of the regulars there seem to know the language down to the metal, and usually they're super-fast in answering questions. How are you using Julia? Command line, iJulia, Lighttable plugin? In the latter two the plotting libraries seem to work better (plus, dat LaTex autocomplete).
Thanks for clearing that up, and good luck with the project!
Based on your earlier comment, I was actually already installing Lighttable and Juno. It looks quite nice as an editor, but I'm having trouble connecting it to the Julia console (the REPL, as they say). I follow the instructions, but it crashes. I like to use a REPL because then I can inspect my variables interactively after running to poke them to see how they look; e.g. plotting my result arrays in various ways to explore the solution my code has given me. Ah well; on the other hand, it looks like I can imitate the REPL by writing the lines that I would be writing into the REPL in the editor instead and executing them line by line using ⌘-Enter.
Well, looks like I have a different problem than that one. On the positive side, PyPlot finally decided to magically start working in the Terminal Julia REPL, so that's nice!
Thanks for sharing! Your lighting talk was great BTW.
I agree. I think In Julia it is even more complicated in some respects, because if an array is Immutable it is identified by its contents: julia&gt; using ImmutableArrays julia&gt; Vector2(2,3) === Vector2(2,3) true julia&gt; Vector2(2,3) === Vector2(2,4) false 
Julia is actually an amazing, fast general-purpose language -- it's a shame it's being marketed as a lowly matlab replacement.
I think it's a replacement for *many* things; coming from a system administration perspective, for example, it seems like it has a chance at replacing Perl for me for server automation. It also shows some promise for replacing C or Ada in embedded work if they'd trim out some of the weird dependencies. Really, though, it's just its own language, so the "Julia is a replacement for `$language`" observations tend to overlap quite a bit.
Any platforms that are actually still relevant, or do you mean Solaris, AIX, S390X, etc?
I agree completely, but bear in mind that however nice Julia is, it's just not that compelling for most users of most languages right now. Technical computing is the one area where Julia really blows everything out of the water, so it's much more valuable to push the language into that niche than to market it to everyone. As adoption and the ecosystem grows that story will change.
A while ago on the mailing list someone was talking about how they should develop a web framework using Julia. I was partly horrified, but thought it was pretty interesting that someone thought it was that useful as a general purpose programming language, but ultimately relieved that it was quickly dismissed as a distraction from continuing to improve Julia as a technical computing language.
Julia is designed in a way that OpenBLAS can easily be switched out for other BLAS implementations, as long as they can be compiled to a shared library. Atlas had to be hacked a bit to make that possible. Ask Jameson Nash, the performance wasn't worth the effort. &gt; on both modern SPARC-based supercomputers Of which there are very few now. I'm sure RIKEN/Fujitsu have their own SPARC-optimized BLAS library for the K computer, which is really the only remaining one of note. http://en.wikipedia.org/wiki/TOP500#mediaviewer/File:Processor_families_in_TOP500_supercomputers.svg (okay, there are a pair of PRIMEHPC FX10 Fujitsu machines lower on the list, that likely use nearly the same set of libraries) What's more important for supercomputing is really good MPI bindings (or being able to integrate Julia's own multiprocessing in standard job schedulers with comparable performance to MPI) so you can scale to thousands of cores. Then worry about running on accelerators, GPU and Xeon Phi. Then lastly figure out how to cross-compile Julia code so it could work on a POWER Blue Gene/Q. Should be possible to replace OpenBLAS with IBM ESSL there, the harder part is the cross-compilation architecture of Blue Gene, and working with different LLVM backends and a different set of compilers for all the non-BLAS dependencies. Julia in space would be awesome. But it's not likely to happen on legacy hardware. An X86 or maybe ARM cubesat, sure. Or perhaps a company that uses off-the-shelf X86 hardware for their avionics.
&gt; Julia in space would be awesome. But it's not likely to happen on legacy hardware. Except that the "legacy" hardware is the only hardware that's managed to be reasonably-proven to survive the rigors of spaceflight. I'm not aware of a whole lot of "off-the-shelf" hardware that's radiation-hardened, for example. Basically, if Julia in Space is to ever happen, it'll need to support the common space architectures, which currently include PowerPC (via the RAD750 and its ancestors, most popularly used on Curiosity), MIPS (via the Mongoose-V, most notably on the New Horizons probe among others), ancient x86 (namely 8086, 80386, and 80486, which were used on the Mars Global Surveyor, is still used as the primary CPU architecture on the ISS, and is now the primary CPU architecture of the Hubble Space Telescope, respectively), and SPARC (via LEON, the deployment of which in ESA spacecraft I'm not nearly as familiar with). The PowerPC-based RAD750 and RAD6000 are especially high-priority, however, given their prevalence in modern spacecraft and the fact that both are still in production (meaning that they'll probably continue to be used on modern spacecraft, though the RAD750 probably moreso). Support for MIPS, SPARC, and pre-Pentium x86 aren't strictly as necessary, but would be a good bonus to Julia in Space adoption/utility.
SpaceX uses off-the-shelf modern x86 (_64, I think) via a rad-tolerant multi-processor redundant design. Many cubesats designed for short lifetimes use standard smartphone-type electronics. Radiation hardening just takes many years to certify, as does the software used on any such long-lifetime spacecraft. Orion MPCV will apparently be using slightly-modified aircraft-grade PowerPC 750's in a redundant configuration: http://www.informationweek.com/government/leadership/nasa-orion-space-capsule-has-surprising-brain/d/d-id/1297427 PowerPC would be a relatively small port for Julia, it's just not widely tested. Old x86 works but has some numerical issues due to different precision when using legacy FPU's. Evidently OpenBLAS does actually have some code labeled alpha, ia64, mips64, power, and sparc: https://github.com/xianyi/OpenBLAS/tree/develop/kernel. But like the corresponding LLVM backends and the rest of the dependencies, no one appears to be actively trying to build and test Julia on those platforms. Might not be too hard to get some of them running, just needs someone who has access to the corresponding hardware to step up and try it.
If your code is short and most of what you need are either explanations or repeat executions, then IJulia is really good, but stay away from it if you need to write more than a few hundred lines.
Yes, I agree. It was an admirable project, but I think Julia has pretty much made it obsolete.
I could replicate. Try clicking on it then scrolling. I think the issue is how the CSS containers work - the main content is in a second container overlaid on navigation that only appears on mobile. It's a little wonky. I wonder if I can fix this with a simple jquery call to set the active scrolling container. 
Here http://learnxinyminutes.com/docs/julia/
http://sebastianraschka.com/Articles/2014_matrix_cheatsheet_table.html Compares Matlab, Numpy, R, and Julia matrix operations
I didn't benchmark it, but all signs point to it being quite quick. You can differentiate between types quite easily, so I went as far as differentiating between signed and unsigned integers in one of my programs. It's also worth pointing out that Julia is just-in-time compiled, so subsequent calls of an unchanged file will run from compiled source. 
See http://www.mit.edu/~mlubin/juliacomputing.pdf - faster than optimization modeling tools in Python or Matlab (Pyomo, Yalmip, etc), not quite as fast as commercial single-purpose tools like AMPL but competitive. And you get to use a modern general-purpose programming language to set up your problem, load data, examine results, etc.
I'd love to see an update of this Matlab/R/python comparison, to include Julia: http://mathesaurus.sourceforge.net/matlab-python-xref.pdf It seems to be more comprehensive than the matrix cheatsheet others have liked to. I'm pretty familiar with Matlab, R and, python, but new to Julia, so this would be great for people like me.
Hey kiwipete, I'm about to noob it up here, but I've got a question about digital ocean. I cannot for the life of me figure out how to transfer a zipped folder (that has all my data and code to run) from my local machine to the instance i'm running on DO. I know this is probably trivial, but i've been working on it for hours now. 
I'm guessing that you are connecting to your remote linux machine via ssh. If so, then you should be able to use the scp command. If you connect with something like: ssh username@instance.digitalocean.com Then you can scp a file like: scp myfile.zip username@instance.digitalocean.com: That will default to uploading it to your home directory, but you can also choose another path like: scp myfile.zip username@instance.digitalocean.com:/path/to/where/I/want/ Check out the scp man page for more details: man scp
it was the colon that was messing me up. Thanks kiwipete, you're the man! Also good point about just parallelizing intelligently. It runs so much faster now. If you care yourself, there's a "shortcut" method to having all cores use the same files and base data that I found very useful. http://juliaeconomics.com/2014/06/18/parallel-processing-in-julia-bootstrapping-the-mle/ 
JuMP is great, particularly if you're doing AML stuff. Which makes problem set up a trivial problem. But don't forget about NLopt or Optim, both work well for problems that JuMP can't handle that well right now (i know they are working on it). Also a very nice thing is Mathprogbase. Using one interface you can access many many solvers and change between them quite easily without drastically changing your code. JuMP included. http://mathprogbasejl.readthedocs.org/en/latest/index.html 
the GLM module might. It has some logit stuff and certainly has binomial possibilities, but I assume you already googled it. Otherwise the guy who runs [this blog](http://juliaeconomics.com/) clearly can do some good work and it might be worth asking him about it.
made in Julia of course! using Image.jl, Gadfly.jl, and faster than CGAL Delaunay (see previous post about that)
Found a new wallpaper :)
here's a 1920x1080 [PNG](http://imgur.com/2v5lGp2) and an [SVG](https://gist.github.com/skariel/25ce7e2cd77e10067c5e) so you can change line type/color and background with ease EDIT: thanks for gold!
Thanks!
It supposed to be very simple to call any Python code, so maybe look at some Python libraries. Using C++ libraries might also be simpler than you think. However I find that Julia image processing libraries are still in their infancy and need lots of work. However don't let that stop you, the basic functionality is there.
Ah okay. OpenCV has python support, so there's my workaround.
The place to look is Images.jl: https://github.com/timholy/Images.jl There is good i/o, data structures, and a small range of basic algorithms. Nothing like OpenCV yet, but enough to get started.
Thanks for posting this! Having a weekly summary of what's going on in the Julia world is really cool.
Agreed. I'm not trying to learn Julia in parallel with my typical daily work in Matlab (boo-hiss), so having a summary of new things I should make sure I learn will be helpful.
Thanks! Looks like a useful tool; I got it working after some work. I get the error "Couldn't connect to Julia. 2014-09-26 12:32:34.521 julia[23504:507] App did finish launching" when first launching, but manually connecting to Julia works. Was this difficult? I.e. if someone wanted to add such functionality to Emacs for example, would it be more on the order of a day or a month of coding, or what? Are there plans to add full interactive debugging to Juno? 
I write the longer scripts and functions on emacs and call them from ipython
there is already a package for Emacs with similar functionality, called ESS (emacs speaks statistics). It was built for R but works with julia as well.
I use ESS all the time and have only played with Juno a little, but I think you're selling Juno pretty short by claiming ESS has "similar functionality." All of the LightTable-type stuff would be pretty hard to add to emacs; inlining graphs probably wouldn't.
[Sublime-Julia](https://github.com/WestleyArgentum/Sublime-Julia) (it comes with plenty of other things too)
As far as I understand Images.jl uses ImageMagick to write and read images to disk. I wonder why did no one try to do that natively in Julia. I could not get ImageView.jl working in linux and it does not work at all in windows.
Open an issue. It should work cross-platform, if it doesn't there's a problem, hopefully a small one, that should be fixed. Can't be fixed if you don't report it.
I would say no. Julia is much like Rust at this point. There are no foreseeable backwards-incompatible *syntax* changes but there are no guarantees that many APIs will be stable. If you have Python knowledge, why not consider one of the many alternative Python interpreters and JIT frameworks, like Numba Pro? They have really good institutional support and decent licensing. 
Most people would recommend a pilot project, small enough to not waste too many resources if it fails, large enough to gain useful metrics for further estimates and to inform decisions. The best way to sell anything is to get into a position where you can show tangible benefits to the purchaser. All languages are evolving, Julia is evolving quicker than most, at present, but fixes and enhancements are also quickly added (open source is more tractable in this regard). It depends which packages you're using too! But of course if you can't make fixes to code in less than x months, this becomes more of a risk and less of a feature...
Python would do the opposite of what OP wants. He wants a speed improvement, not a downgrade. 
Have you looked at the numbers for PyPy and Numba? They can actually match native C++ code nowadays in some cases. 
Overall looks like a nice api. I've found prepared statements in SQLite give a good performance boost when doing multiple inserts - they should be easy to add. The docs mention memory leaks if the db is not explicitly closed - can a finalizer be used to ensure proper cleanup?
After looking into it, I think Numba might be a strong possibility.
Juno is really nice. I've been using it for the past week or two, and I feel very productive when I do. With that being said, it seems as if some of the problem that involve have to do with the limitations of lighttable.
Thanks, I'm kinda proud of it. I'll have a look into it, though I'm currently trying to work on a nice way for users to define their own functions. I did consider finalizers but I wasn't really sure how consistent they are.
You can squeeze a lot of performance out of Python with Numpy. Typically code I've written in Numpy has been orders of magnitude faster than it's vanilla python equivalent with minimal changes and knowledge of Numpy.
I don't think I would call Numba a mature reliable technology either, it's rather restrictive and specific in terms of the type of NumPy code that it's able to optimize well. But institutional support contracts are likely available through Continuum, which may fit better with your needs than where things are right now with Julia. You could of course try hiring Jeff and Stefan on a consulting basis to solve any issues you might hit with Julia, but I think the rest of the community would like to see them spending most of their time on the core language (assuming they're making a living already, Jeff said at Juliacon that he doesn't mind ramen). The question is also awfully vague with respect to the actual processing workload that you're talking about. Primarily numerical? Text processing? Dense linear algebra? Embarrassingly parallel? Without more information it's hard to know whether or not Julia would be well-suited for the task.
what runtime/memory management issues are there?
&gt; Python becomes it is on the same order of magnitude as SAS in terms of processing speed. I think some of the libraries use `cython` which makes the code as fast as C++. The problems are looping slows you down and the parallel processing is a bit difficult.
It's a grab bag of tasks. It starts off with some text scrubbing, to standardize semi-structured fields. This is about 5-10 million new records a month, and 5 fields. In an ideal world, we would like to add another layer of text mining on the unstructured fields, but we are already at the limits of time and hardware with the current list of jobs. After we clean the new data it is a series of data sorting, joins, transformations, and general sanity checks. The final dataset is on the order of 500 million records and 200 fields. From there we move on to about three very hefty regressions; followed by several hefty validation exercises. Just to access the output data with SAS can take several hours. Where does out current stack break down? The parallelization in SAS isn't as strong as it could be and the mainframe architecture has a significant I/O bottleneck. As I mentioned above there is talk of bringing in a hadoop cluster, which should help with the dataset construction and querying, but we're still going to need to optimize our regression and validation script to see the kind of performance increases that we're looking for. It isn't clear if we can do much more to optimize the SAS code, which is why we are looking at other languages. And of course, once we start doing things faster, we'll start looking at our list wish of analytics and add jobs until we max out the language and architecture again.
That sounds like exactly the kinds of tasks that Pandas or plyr are designed to be good at (and SAS as well I guess?), though at a scale that would tax their implementations. The high-level Julia interfaces for doing this kind of thing with DataFrames are under heavy development, but not as well tuned as the more-mature versions in Python or R. Julia mostly excels when you're writing your own custom numerical algorithms, rather than performing standard operations on large datasets for which the equivalent Python or R implementations are probably already in C (as long as every operation is vectorized). Julia would give you the ability to smoothly refactor, within the same language, from high-level concise code to lower-level code with more carefully managed memory allocation. Julia's parallel primitives are also well thought out and should scale pretty well as long as you're careful about data movement (that caveat applies everywhere, not unique to Julia in any way). I think you could try it, and it might work out after you familiarize yourself a bit with typical tricks to get Julia code to perform well, but it would be high risk. I'm going to downvote myself for saying this, but the safe choice would be to write it in Java. It wouldn't be enjoyable and would be almost as time-consuming to write as C++ or Fortran, but if you're considering using Hadoop, it would seem to be the most natural choice. You'll lose out on performance vs C++ or well-tuned Julia since there's no SIMD or value types, but it would work and most likely be faster on a cluster than SAS, Python, or R. I think people are starting to favor Spark recently as a Hadoop replacement, which apparently has API's from Java, Scala, or Python.
I've done high speed parallel numerical processing in java. It's quite fast enough.
A pilot project is a good idea. Something fairly small and self-contained. The language and runtime show a lot of promise at this point, but within 10 minutes of my installing it and trying it out for our application (involving image processing) I ran into issues... I submitted a bug report but thought that probably it was pilot error because I'm so new, but it turns out to have been a real, rather fundamental bug. I really like what I see on Julia's feature list and I look forward to being able to use the language in production, but at this point it seems it's just not ready for anything other than a small pilot project. I think that will change over time but that can only happen if people start using it for less critical tasks and file bug reports as you run into problems. tl;dr: You've gotta be willing to get cut on the bleeding edge a bit, just make sure you're not doing that with critical code.
I take it you're on OS X? I suggest adding Julia to the path – you can do it easily with using Jewel addtopath!() Then unset your path in user behaviours and you should be all set. (FWIW it looks like the problem is linking to the Julia.app rather than the Julia executable, which is inside the app)
I spent the summer doing this for GSoC, so around three months work. A lot of that went into frontend-agnostic code in Jewel.jl (extracting code blocks, evaluation tools, autocomplete etc.) so you could probably set up communication with that and get something going reasonably easily. I don't know elisp that well, but I imagine a lot of the GUI stuff would be harder – being HTML is Light Table's greatest strength in that regard. Debugging is coming to Julia soon, and when it arrives I'll be there ;)
Scala might be a decent choice and is pretty widely used for this kind of thing. But OP didn't say "I want to target the JVM," OP said "I want to get this done and working faster." Would be harder to hire people with the experience to do the job in Scala than just simple boring Java. &gt; if you'd rather use .NET/CLR... great numerical libraries are available for C#/F# Aside from ILNumerics and whatever Jon Harrop's selling? Those are pretty much all just MKL wrappers anyway. Mono's not good enough to make .NET worth using on non-Windows machines, and it makes no sense to run anything performance-sensitive on Windows if you have the choice.
"Big data" guy here and I have built platforms that process billions of rows of data daily for clients... And I agree, distributed processing on Hadoop or Spark is the way to go!
Hey, this looks like great stuff! I'm actually the author of the original SQLite package and coincidentally, am just about finished with an overhaul that's long overdue. (I've been neglecting it for far too long). I think it'd be great to join forces and merge development if you're interested.
Thanks. I'd definitely be interested in something like that, what do you suggest?
This is great, I'd love it to be a regular thing!
I just added you as a collaborator to the quinnj/SQLite.jl repo (since it's already registered as the official package). I particularly like the work you've done with UDFs and the transaction blocks with anonymous functions. I just merged my overhaul into the master branch, so feel free to check it out (it's remarkably similar in a lot of ways to your approach). Feel free to PR some changes/additions and I'll also look at incorporating your work in. Glad to have someone else interested in pushing this forward!
Awesome, I'll get started today. I've not got a lot of experience worling collaboratively via Git so I apologise in advance for any mistakes. It looks like you've made some really great changes, I especially like how you serialized values as a fallback for bind.
Yeah, once I wrapped my head around the BLOB handling, I figured it would be handy to automatically handle Julia types that way. FYI, I just integrated your `transaction` functions; love them! I kept missing begins and commits and when a statement failed I was getting stuck with an open transaction. This is perfect. We can move the discussion over to the repo. Feel free to look at the commit history, source code. Open issues to discuss things or for things you want to change/add.
Thanks, I was never a fan of the Python way where the `begin` statements were hidden from you but you still had to explicitly commit. I thought this was a pretty good compromise.
Thanks! Looking forward to the next one. 
Will this mess with my normal LightTable setup which I use for Clojure?
The Juno plugin described on the install page *completely* takes over defaults etc., so you probably don't want to install that. Instead, you should check out the [Julia language plugin](https://github.com/one-more-minute/Julia-LT), which provides the raw functionality and will behave similarly to other language plugins.
I am very excited about Julia. My next major project will likely be a combination of Python, Julia, and Matlab. It will be very interesting to see how the three compare when used together.
Sometime soon IPython is becoming [Jupyter](http://jupyter.org/) to emphasize that the notebooks can run Julia, Python or R code. I think it would take an unusual combination of requirements for it to be advantageous to use all three of those in a single project, but there is some support for interfacing between them. Julia has it's developing strengths, and I can imagine where R and Python libraries do not overlap, there definitely isn't yet something natively available for Julia. I've only used Matlab in a couple courses where it was the chosen tool. How does it compare to the others?
Matlab does a good job of optimising vectorised expressions - you never read advice to 'devectorize' your matab code for performance. 
One thing I am looking forward to in particular is to be able to use both vectorized and non-vectorized code in Julia, without having to worry about performance. Some operations are best expressed as vectors. Many things can conveniently be thought of as matrix multiplications. Some other operations are best expressed as iterations and branches. These are typically either hard to express or super-slow in Matlab/Numpy. Also, non-vectorized code often uses a lot less memory than vectorized code, which is beneficial when working with large data sets. TL;DR: You never read advice to `vectorize' your C code for performance.
It does indeed take an unusual combination of requirements. But I will have to interface with a large number of algorithms written in Python and Matlab and C, and probably do my own processing in Julia.
How does this compare to Julia Studios? Does it support Julia 0.3? 
It's sort of the opposite, though. Matlab and Julia are very similar for vectorised expressions (since you're just calling out to a C/Fortran library either way) but Julia is much better at optimising non-vectorised code.
You mentioned debugging coming soon? I've been exploring Julia, but this is my biggest hangup. Where can I follow the work on debugging that you are referencing?
It's very much in the works at the moment, and there's not much published about it, but check out Keno's [talk from JuliaCon](http://www.youtube.com/watch?v=Wkw2gmzfm1Q).
Far more trivial, I'm afraid: I'll have to use other people's code. A lot of scientific code is still written in Matlab. I already wrote an interoperability library for calling Matlab from Python, which I designed with another client in mind: Julia. I'm hoping to create an environment where I can delegate tasks to either of these three languages with ease. I am still unsure if it is wise to use Julia as the main host language, though. With its strong roots as a glue language, Python might be a better choice. Then again, it is already easy to call Python from Julia, so this might turn out to not be a big issue.
(I know you know this, but nitpicking...) If said "vectorised expression" happens to go to a BLAS method, then yes. But for many operations, the vectorized Julia version is implemented in the Julia standard library, not C.
Makes for a great resource to compare the same content in Python vs Julia. The Julia examples feel like there is less ceremony importing libraries before getting down to actually writing the algorithms.
Given the response I got two weeks ago from doing this, I figured I'd whip up a GitHub Jekyll blog. It's pretty bare-bones at the moment. Pull requests and collaborators are very welcome! 
&gt;An empty pair of square brackets [] now constructs an empty Any array instead of an array of None. This means that you can now push! elements into [] Finally! Thus make coverting (bad) Matlab code that much easier. Minor change, but will remove so many headaches!
Awesome, thanks for doing this!
Julia 0.3 (I think) introduced workspace(), which clears all variables from your workspace.
I just came across this thread which was posted back in April 2014. It shows how one can manually create a compiled binary. https://groups.google.com/forum/#!topic/julia-dev/qdnggTuIp9s But my version of julia does not seem to support the --build option. 
There is a pull request for caching compiled modules opened a few days ago. This is key to compilation of packages. https://github.com/JuliaLang/julia/pull/8656 So the answer is: its progressing, I guess. As you observer we got precompilation of the standard library in 0.3, and it looks like we will get compilation of packages in 0.4. Blindly extrapolating from there we may get full program compilation in 0.5.
Calling `workspace()` keeps your old variables around in the `LastMain` module. Called a second time, `workspace()` puts an original variable `x` at `LastMain.LastMain.x`. So at the very least, this seems to never clear old memory, even if the variable names may no longer be referenced.
Really interesting and educational. But I don't understand why the compiler can't recognize these cases and devectorize automatically. Shouldn't it be able to tell when all the nested operations are element-wise (like the example exp(-abs(x - y)) ) and optimize it? It seems temp arrays would only be needed if things were not element-wise, like exp(-abs(x - A*b)) where A*b is a matrix or tensor operation, which means it would have to be evaluated in whole before devectorizing the other parts. Even then, only one temp array would be needed.
Because no one has written the code to make the compiler smart enough to be able to do that yet. That kind of thing is pretty commonly done using something resembling expression templates in various C++ libraries or NumExpr in Python, but I haven't seen that kind of approach extend to more complicated cases like your second example. There are simple manual workarounds for these types of optimizations that the Julia compiler can't do automatically right now, so they haven't been very high priority items for the core developers to work on.
You could certainly special-case the compiler to optimise those kinds of expressions (I mean, that's all @devec does) but that goes somewhat against Julia's philosophy of user code and built in code being on the same footing. Of course, if there's a general way to do this which will work for user-defined functions as well as built in ones it would be great to have.
it only supports Julia .3 older version don't work
You can use the quasi-latex modes in Light table, and ipython, where you type \gamma [TAB] and get γ. No need for special character sets on keyboards. EDIT: you can also do it in emacs. I'm pretty sure there is a mode for that.
I agree with Lmagno and Ligature that LaTeX is the right choice for many people.
My guess: there are just way too many Unicode symbols. Sure, you could pick twenty-odd and stick them on a keyboard, but which ones? Some people need all the greek letters, others need APL characters, others still need set operators, etc etc. There's no way you could standardise on a subset useful to everyone. So even after building that keyboard you'd still need to solve the general problem of entering any Unicode character, and once you can do that (via latex input or whatever) you don't really need the keyboard any more.
It's probably some bug in my browser (FF Aurora, Windows), but [the labels on the plot don't align properly](http://i.imgur.com/m7wD9Kg.png). Got a static version?
Looking at the code and how it was run, it appears the Julia numbers include startup and compile time? Running from a warmed-up JIT would probably help the numbers.
I don't think the startup and JIT time makes that big of a difference when the total time is 7 seconds.
Yeah, you're right, nevermind, looks like it wouldn't be much more than 5-10%. But the code does spend 45% of its time in GC when I run it. Would have to see whether BigInt's allow for many in-place arithmetic operations.
It's a somewhat recent feature, I think it got merged to master around May? So first released in 0.3.
Does anybody understand this paragraph? &gt; We’re seeing a significant range of speeds for Scheme implementations. It’s interesting to note that Guile and Racket are JIT interpreters, Chicken is compiled, and Gambit is interpreted (I couldn’t get the compiler to run on my machine). The idea that compiled languages are always faster than interpreted is refuted here. According to the author's results, Chicken *is* faster than Guile, Gambit (interpreted) and Racket in this benchmark. Maybe that last sentence wasn't supposed to be just about scheme implementations and the author is reffering to CPython beating all the scheme implementations by a factor of at least 1.8? 
Check out the Tim Holy Trait Trick (THTT): https://github.com/JuliaLang/julia/issues/2345#issuecomment-55838269 Basically, it's using functions to dispatch on traits instead of using an inheritance tree to dispatch on ancestors. Give it a shot and see if it works for your use cases. I've found it to be pretty powerful and simple.
&gt; "Unlike the Benchmarks Game, we aren’t requiring all the test programs for the same language to be identical. This is a controversial rule..." Benchmarks Game programs for the same language are not required to be identical. Wilfred Hughes has been asked to correct that misstatement.
Thanks!
Wilfred links to [a post from Alex Gaynor](https://alexgaynor.net/2011/apr/03/my-experience-computer-language-shootout/) where his pypy-only implementation was rejected (as it not working on cpython - due to a cpython bug). Is it no longer the case that such a solution would be rejected? (Note: pypy is no longer benchmarked...)
&gt; Is it no longer the case that such a solution would be rejected? It wasn't even the case 4 years ago! *afaict* Within the last year, Alex Gaynor has hidden the comments that provided *factual corrections* to his blog post. See https://news.ycombinator.com/item?id=7233981 I've managed to find some of my 4-year old replies to comments that others made on the blog, but unfortunately without their comments (Alex Gaynor did not attempt to explain his remarks). ---- &gt; Alex Gaynor wrote "It's also not possible to send any messages once your ticket has been marked as closed, meaning to dispute a decision you basically need to pray the maintainer reopens it for some reason." 1) Strangely you can add comments after a ticket is marked as closed - and that still triggers email. 2) You can always open a new ticket. 3) There's even a discussion forum. &gt; Alex Gaynor wrote "After speaking with some CPython core developers, it appears that it is indeed a bug in CPython" 5) You never mentioned in the "full back and forth" any "bug in CPython" 6) And you don't mention here that your "corrected" program then timed out after an hour on x64 7) Joe La Fata's pi-digits code worked first time on x86 and x64, on PyPy and CPython and Python3 and only used ctypes to get to GMP ---- Sometimes there are facts that you the reader can easily check for yourself - Alex Gaynor wrote - "It's also not possible to send any messages once your ticket has been marked as closed, meaning to dispute a decision you basically need to pray the maintainer reopens it for some reason." 1) Not true. You can check for yourself that there's a public discussion forum and people dispute decisions - (Edit: the URL given 4 years ago is no longer correct, here's the current URL instead: https://alioth.debian.org/forum/forum.php?forum_id=2965 ) 2) Not true. (But hard for you to check.) Followup comments can be added to a ticket that is marked Closed in exactly the same way they can be added to a ticket that is marked Open - and adding a followup comment triggers an email message to me whether the ticket is marked Open, Closed, Deleted, … (Actually Alex Gaynor did not even add a followup comment to his Closed ticket.) 3) Not true. You can send an email to anyone who has an Alioth login simply by clicking on the email address in their profile - you don't even need an Alioth login yourself. etc ---- 2 April, Joe LaFata contributed a faster for PyPy spectral-norm program. His program worked first time on x86 and x64, on PyPy and CPython and Python 3. His program was measured and published within 24 hours. Do you get it yet? ---- Alex Gaynor put stuff in a blog post - putting stuff in a blog post doesn't make it into The Truth. ---- &gt; he got a bad experience out of it How much worse do you think his experience would have been if I'd chosen to publicise a blog by writing a post titled "My experience with Alex Gaynor" and pushed it onto every social networking site that deals with programming? :-) &gt; he worked on improving the performance of PyPy in those benchmarks… Over that same few days someone else contributed 3 programs written for PyPy that were accepted and were a success in promoting PyPy. Strangely it isn't the people that have their programs accepted who feel they need to blog, it's those who have their programs rejected ;-) ---- Disparaging remarks like this are not intended to encourage others to contribute - "Overall it was a pretty crappy experience. The language shootout appears to be governed by arbitrary rules. … the seemingly capricious and painful submission process…" One way to respond, after confirming the program doesn't work with CPython because of a CPython bug, would have been to pass along the message that there's nothing wrong with the program, the problem's with CPython, so show my program - what a shame that wasn't done - but then what would that leave to blog about? :-)
Here's a [*written for PyPy*](https://alioth.debian.org/scm/viewvc.php/shootout/bench/pidigits/pidigits.python-6.python?hideattic=0&amp;view=markup&amp;revision=1.1&amp;root=shootout) pi-digits program that was shown back then, is it identical to [the *written for CPython* programs](http://benchmarksgame.alioth.debian.org/u64/measurements.php?lang=python3)? Look around in the old repository and you'll find others.
&gt; What about continuous apps on a server? At this point you should NOT use Julia in production, nevermind PyCall. &gt;Would it be conceivably possible to package pycall functions into an julia exe in the future? I'm not too sure about this but as I understand, PyCall still relies on there being a python library independent of Julia (at least this is what a quick look at the source tells me,) but I assume that in the future, it might be possible to integrate with something like PyPy, but... 
Thanks for taking the time to respond (clearly there are two sides to every story!). It definitely seems a shame that the comments have been removed. &gt;Disparaging remarks like this are not intended to encourage others to contribute +1
Thanks for the feedback, helping me with my decision to either continue with python or fork off to julia. 
&gt; Chicken *is* faster than Guile Maybe the program used with Chicken is *a better program*. The same program was used with both Guile and Gambit. A different program was used with Chicken. A different program was used with Racket. (Incidentally, the only program not taken from the benchmarks game repository, is the Julia program.)
The linked commenter is completely correct that objects are slow *in Python*, yes. But Julia's types are not objects in the python sense, and often are stored contiguously in memory just like a C struct. For example, Julia's complex numbers are defined as composite types and are very, very fast.
With a benchmarks game story the two sides are usually curiosity and advocacy. For sure, my preference was to show PyPy programs that also worked with CPython. How else can we see that optimising a program for PyPy might make it perform worse with CPython (and *vice versa*)?
if i understand what you're asking, the answer is yes. that's because julia is designed to avoid ambiguity in non-abstract types. so the exact amount of memory needed for an array of "objects" is known. so "objects" can be placed in an array in an efficient way (unlike python) and their attributes can be accessed efficiently (unlike python). however, the cost of this is that they are not "objects" in exactly the same way as python. in particular if you are hoping to write python programs in julia you will need to learn some new stuff. disclaimer: haven't actually used julia recently, but i think this is an easy enough q that i am ok. edit: or maybe you are asking whether arbitrary graphs of interconnected "objects" are efficient? then the answer is no (although julia will still beat python) because you're going to keep missing the cache. in other words: you need to put data in arrays (to first approximation) so that they are grouped together in memory, to get good cache behaviour. but in julia those arrays can hold "objects" at no additional cost (unlike python).
You got it, thanks.
Thanks. Is this something that can be ameliorated with Pypy or the numba compiler, or is the memory access still the bottle neck? 
No problem. The thing is that Python lets you do things Julia doesn't, e.g. adding fields at runtime, changing types, subclassing etc. All of these require a layer of indirection – looking up fields in a hash map, checking types and doing dispatch etc. PyPy has some clever tricks to reduce the overhead but there's only so much you can do. In general it's Julia's careful design as a language that *allows* it to be fast, not a clever compiler that *makes* it fast. So while PyPy, numba and friends are amazing engineering efforts they have a massive [whatever the opposite of a head start is] and you're unlikely to get really great performance without relying on array tricks.
Because of python's amazing package infrastructure and my intention not to be a polyglot so I can free up brain space for domain expertise :) So I'm a bit torn here...
The point about packages is very fair. If you can mostly leave the hard work to external packages, Python is a great choice. And I get that if you're more interested in the results than the coding, you don't want to mess around learning more tools than necessary. That said, if you find yourself thinking about faking manual memory management for performance, don't ;) I promise you that learning Julia (or even C, to be honest) will save you a lot of time. If you know Python already the learning curve is fairly shallow, and you can still use Python's packages via [PyCall](https://github.com/stevengj/PyCall.jl), so it's not going to be crazy difficult to get started. My rule of thumb is: Try to find a package that does what you want. If it exists, call it from Python. If it doesn't, write it in Julia.
Take a look at this: http://pseudotrue.com/notes/julia-macros/ Since Julia supports macros, you can automatically rewrite your code to speed up your calculations by avoiding the creation of temporary objects. For example, when I wrote a convex hull function for LuaJIT it spent most of its time creating temporary vectors for operations like ((a-b)^(c-b))*(x-b). Of course, I could and did optimize it by caching edge vectors etc, but in the end I had to resort to rewriting some operations in terms of vector components by hand.
no. python objects are not single, contiguous blocks of memory. they contain pointers to other bits of memory that jump around all over the place. you can probably allocate what is effectively an array of pointers. but it won't be efficient. edit: curious about the downvote. did i misunderstand something? a python object is basically a dict, which is a dynamic collection of fields, and so uses dynamically allocated memory. the only way to force things into a fixed region of memory is to use slots, but that restricts how you use the language...
Ok Julia. Just let me know when you get that "static compilation" -- what everyone else calls compiling -- working. That's when I'll check you out again.
Julia is already JITing down to native. It's already called compilation.
Point being, the user experience is dismal. `using Gadfly` now wait 30s is a deal-breaker.
&gt; Is Julia built in such a way that the sort of object heavy programming in the example is more feasible than even in C++? (other than the JIT compilation) About a month ago, a [talk by Mike Acton regarding OOP vs Data-Oriented design](http://www.reddit.com/r/gamedev/comments/2hxjzq/mike_acton_insomniac_games_cppcon_2014_keynote_on/) was posted on /r/gamedev, with some related links. [Here](http://www.reddit.com/r/programming/comments/2hw0bz/cppcon_dataoriented_design_and_c_video/) is the /r/programming discussion. Not sure how relevant this level of optimising to the metal is relevant for you yet (and Acton is a bit controversial in how he delivers it), but it might be interesting to you. I think most of his ideas translate rather easily to Julia.
Haha! I was sure that wasn't up when I posted this!
Sure! Please feel free to submit PRs and/or point me to cool new packages and features. I cannot survey all of Julialand on my own! So any omissions are just that - things I've missed or misunderstood. GeometricalPredicates is not an area I'm knowledgeable about, but someone submitted a PR for its inclusion and it garnered lots of attention on the list serve. 
Honestly, I haven't seen people using slots for performance, and wouldn't choose to mess around with them myself. Ultimately I think only you can look at the options and know what the right trade off of learning/frustration curve vs. performance is. I do think learning Julia is a good investment, though – even if you solve your current problem with other tools it's likely to be useful in future. Just curious, what are you looking at doing? Some kind of simulation, I guess?
I have to agree. It is really deterring when new users want to utilize a package and are stuck waiting 30 seconds at runtime for a short recipe. However, at the same time you have to understand that Julia is only at v0.4.
&gt; my intention not to be a polyglot A little knowledge of other languages and paradigms goes a long way and is well worth it! Even if you stay in python you have numpy, pandas, cython...
Probably not as there really isn't a procedural way of rewriting code from language to another. It's really a matter of knowing both languages well where you can "mentally map" the structure, syntax, and behavioral elements between the two. 
Ok, well the thing to remember is that Julia doesn't actually run the command through a shell, it invokes it directly via C. So the quotes are only added for presentation – e.g. `cmd foo` and `cmd 'foo bar'` are stored and invoked exactly the same way under the hood, as a command + a string arg. So the problem you're having shouldn't be to do with quotes. The other thing is that because things aren't run through a shell, you can only execute programs. `cd` is actually a special case in the windows shell, so you'll get errors when Julia tries to find it. However, you can emulate the command line by running something like run(`cmd /C echo hello`) This will work if defined as a function: cmd(x) = run(`cmd /C $x`) cmd(`echo hello`) I tried this with `cd` and it wasn't persistent, for some reason, but there's always the Julia `cd()` function for that anyway. Does that roughly clear things up?
The reason it's not persistant is because cmd.exe switched to the directory you asked for and then immediately exited. Your application never actually changed directory only the cmd.exe sub process did.
Makes sense. It must be possible to run the command in the Julia process, since `cd` works in shell mode (unless it's just special cased), but it won't matter for most commands you'd want to run.
Agent Based Modeling and analysis of ~200gb data sets. Thanks very much for your interaction and help- You've convinced me, but now the problem is I cannot find any high level data science or lower level data munging/scripting/networking tutorials with julia...so it looks like I'll have to continue with python anyway and dive back in once I learn more CS or the Julia literature matures. (unless you have any suggestions in this regard?)
That got me further. Running ipconfig goes without a hitch, although run(`ipconfig \\all`) runs and gives a failed process error at the end (it seems julia is very sensitive to the return type of processes. Running a different program (one that I made) dumps me out of julia's REPL all together (I'm guessing because of the return code). In any event it seems messy but that should be enough to write some simple batch stuff in Julia, thanks for your help! 
How about ``run(`ipconfig /all`)``?
....right. Yeah that runs without error, so the error return code makes sense with a bad argument. I'm not sure why the other program closes the REPL window. When run from the actual command line it gives an assertion error on src/uv-common.c Line 83, which doesn't exist in the current code base it seems. 
There are a multiple open PR's making great progress in this direction. One to help make precompiling packages into the system image easier to do, others on caching module compilation results. This is well underway.
You are very brave, sir. 
Indeed, though it's a little bit out of date until I can be bothered to compile a newer snapshot :)
For most basic things I'm starting out with just switching to the shell prompt. When I was originally configuring this, however, I had started without setting the `$JULIA_SHELL` environment variable, which (thankfully) left me at least with the ability to use `run()`, so I ended up using at least that considerably in order to bring up the necessary editors and such to correct the various issues that crept up (said issues would have been nonexistent if Julia included a `-c` argument that automatically passed its parameter to `run()`, but it's understandable why such a thing hasn't been implemented yet). My next step is to reimplement a lot of the typical shell commands (`ls`, `cat`, etc.) as Julia functions, then eventually start using this setup for things like you're describing and eventually transitioning to not having to use the built-in shell prompt at all for day-to-day things (instead encapsulating everything in `Cmd` objects and manipulating them as such, thus taking better advantage of Julia's strengths in that regard).
Your comment inspired me to try this out and wrap the output of ls into a DataFrame. So voila: https://gist.github.com/vchuravy/79cc3164d9109f9237d5 If I had the time I would start a Package collecting those.
There is also this package https://github.com/mauro3/Traits.jl that tries to formalize the THTT approach. 
Showoff ;)
You are welcome :) Let us know when you have your julian implementation of busybox ready :)
The Julia Blog makes a very compelling case for how using typical shells and shell scripting requires a great deal of care to be taken: [Put This in Your Pipe](http://julialang.org/blog/2013/04/put-this-in-your-pipe/) and [Shelling Out Sucks](http://julialang.org/blog/2012/03/shelling-out-sucks/). Those articles changed how I perceived traditional shells utility entirely and realized how inelegant the implementations were, so rather than a madman I believe you are instead one of the few sane people. Of course realizing this utility is not unique to Julia, but it does outline some prerequisites one should take into account when formulating their solutions to problems within a shell paradigm, in particular highlighting how much less friction is realizable through general purpose languages which take much greater care in catching or preventing errors that are common in say Bash for instance. I am using Julia in this same manner myself; it has the advantage of an excellent FFI, so one can interleave excellent packages outside of Julia to great effect with minimal effort.
thank you for this
First of all did you mean showall instead of showarray? at least in Julia 0.3 showarray is not defined. The problem is that multiple dispatch uses the generic show for Array (Array{PolyVector{Intp{2}},1}) which you did not yet override/extend. show{T &lt;: PolyVector}(io :: IO, a :: AbstractVector{T}) = .... 
It might not be exported from `Base` (i.e try `Base.showarray`, which works on 0.4).
Do you have the code online somewhere? Even just a Gist or something would be useful.
I didn't post it before since it's I'm still learning and it is very long and messy, but here is what I've got if you want to read through it. (Any style tips would be appreciated, if you do.) importall Base immutable Intp{p} &lt;: Integer v::Int Intp(v) = new(v%p) end -{p}(a::Intp{p}) = Intp{p}(-a.v) +{p}(a::Intp{p},b::Intp{p}) = Intp{p}(a.v+b.v) -{p}(a::Intp{p},b::Intp{p}) = Intp{p}(a.v-b.v) *{p}(a::Intp{p},b::Intp{p}) = Intp{p}(a.v*b.v) convert{p}(::Type{Intp{p}}, v::Int) = Intp{p}(v) promote_rule{p}(::Type{Intp{p}}, ::Type{Int}) = Intp{p} #show{p}(io::IO, v::Intp{p}) = print(io, "$(v.v) mod $p") show{p}(io::IO, v::Intp{p}) = print(io, v.v) showcompact{p}(io::IO, k::Intp) = print(io, v.v) function multp{T}(a::Vector{T},b::Vector{T},g::Vector{T}) local n,d,j,k,z z = zero(a[1]) n = length(a) n == length(b) || error("lengths assumed equal") n == length(g) || error("lengths assumed equal") c = T[] for j in [1:2*n-1] d = z for k in [1:j] d = d + ((k &gt; n ? z : a[k])*((j-k+1 &gt; n) ? z : b[j-k+1])) end push!(c,d) end for j in 2n-1-[0:n-2] c[j] == z &amp;&amp; (pop!(c); continue) pop!(c) for k in [1:n] c[j-k] = c[j-k] + g[n+1-k] end end return c end function rand_intp(p::Int,n::Int) local a = Intp{p}[] for i = 1:n push!(a,Intp{p}(rand(0:p-1))) end return a end a = rand_intp(2,3) b = rand_intp(2,3) g = [Intp{2}(1),Intp{2}(0),Intp{2}(1)] multp(a,b,g) immutable PolyVector{T} a::Vector{T} nzfirst::Int #for effiencicy, track the first non-zero index var::Symbol function PolyVector{T}(a::Vector{T}, var::ASCIIString) nzfirst = 0 #find and chop leading zeros for i = 1:length(a) a[i] == zero(a[i]) || (nzfirst = i; break) end new(a, nzfirst, symbol(var)) end end length(p::PolyVector) = length(p.a) getindex(p::PolyVector, i) = p.a[i] setindex!(p::PolyVector, v, i) = (p.a[i] = v) zero{T}(p::PolyVector{T}) = PolyVector{T}(zeros(T,length(p)),"Z") one{T}(p::PolyVector{T}) = (M = zero(p); M[1] = one(T); return PolyVector{T}(M.a,"Z");) =={T}(p::PolyVector{T},q::PolyVector{T}) = (p.a == q.a) function paren{T}(p::PolyVector{T}) local m,n n = length(p) m = n for i=1:n if p[i] == zero(p[i]) m = m - 1 end end return m &gt; 1 ? true : false end paren{T}(p::Intp{T}) = false show(io::IO, p::PolyVector) = print(io,p) function print{T}(io::IO, p::PolyVector{T}) if p.nzfirst &lt;= 0 print(io,"0") else for j = p.nzfirst:length(p) pj = p[j]; q = paren(pj) j == p.nzfirst || pj == zero(pj) || print(io," + ") q &amp;&amp; print("(") pj == one(pj) ? (j == 1 &amp;&amp; print(io,pj)) : (pj == zero(pj) || print(io,pj)) q &amp;&amp; print(")") pj == zero(pj) || j == 1 || (j == 2 ? print(p.var) : print(p.var,"^",j-1)) end end end show{T}(io::IO, p::PolyVector{T}) = print(io, p) showarray{T}(io::IO, p::PolyVector{T}) = print(io, p) showcompact{T}(io::IO, p::PolyVector{T}) = print(io, p) a = rand_intp(2,3); u = PolyVector{Intp{2}}(a,"x"); u print(u) v = PolyVector{Intp{2}}[] for i=1:10 a = rand_intp(2,3); u = PolyVector{Intp{2}}(a,"x"); push!(v,u); end vv = PolyVector{PolyVector{Intp{2}}}(v,"X") My next step will be to set up algebraic operations, namely extending that multp to PolyVectors. Eventually my hope is to solve systems of linear equations with PolyVector coefficients.
&gt; I didn't post it before since it's I'm still learning and it is very long and messy Don't worry, we've all been there. I'll probably have a play around with it this weekend, see if I can't figure out what's happening. Can't promise anything though.
The issue is just that the GC implementation is very basic, and an incremental GC is in the works. It is not unstable in any way. The core language has been largely. The base library APIs keep getting tweaked though.
Not exactly sure if this is helpful, but you have to overload display () for your type to get it to work. Search the julia-users forum or github issues for "custom show array". (Sorry to not be more helpful but I'm on a mobile device)
On disk storage. 
My interest in Julia is almost entirely as a general-purpose language and I've found it suffices rather well. The main problem I was running into was the documentation. It was rather incomplete - especially when it comes to matrices. It seems like the semantics of matrices where lifted wholesale from matlab (I've never used matlab, so I didn't know or recognize the matrices), which explains why they're poorly documented. In particular, I wrote a small program to parse and transform files in a rather contrived plain-text file format, and it worked at least as well as Python. I imagine for more complex usecases the lack of libraries will become an issue, compared to the languages you gave as examples. Those three in particular have very rich ecosystems of libraries.
I've been planning on talking about this paper at an upcoming group meeting (comp. astro). Any suggestions for what my talking points should be? My emphasis is going to be that they should keep an eye on the language and play with it a bit.
Why not use pycall? 
Because Python was designed to be glue. It has probably better integration with just about everything than Julia. 
Apart from the initial delay when loading packages, I've found it very capable. I did some Reddit web scraping which was easy enough. Some things are a bit broken at present - Sqlite didn't want to work last week, for example. I'm looking forward to when things settle down a bit. 
Yeah that package loading is a big issue. Probably that and garbage collection will be the big issues for a while. So many other things can be done by independent people wrapping or writing libraries. 
Anyone else get the feeling this is pretty much the quarter-length version of Jeff's thesis?
Wow, I didn't know about that. That is cool.
&gt; codellvm I was mostly confused because on the example website, the author's code compiled into `vmulss` I'm not used to reading llvm code, but maybe you do. Here is the code_llvm result. julia&gt; code_llvm(square_area, (Float32,)) define float @"julia_square_area;21389"(float) { top: %1 = fmul float %0, %0, !dbg !4605 ret float %1, !dbg !4605 } 
Colour me crazy but isn't "mulss" actually the correct mnemonic for vmulss when the destination is the first operand? Source: http://www.felixcloutier.com/x86/MULSS.html *Edit:* to put it another way, "vmulss X, X, Y" is, if I read the linked source correctly, the same as "mulss X, Y".
&gt; 100% a bug with llvm compilation. I am getting the same llvm code on 0.3.2, but my native code is using vmulss, but I'm on windows with an i7. That is about the limit of my knowledge so I have no idea how to help you in fixing it... &gt; good idea.
That seems strange to me though, wouldn't Julia have a huge advantage through JIT compilation that it can always target the host machine?
An array of a particular type? Something like zz = ExampleType[] ? I'm confused as to what you are trying to do.
 type foo x :: Int y :: Int end foo_array = foo[] push!(foo_array, foo(1,2))
In future when you ask for help like this it's usually better to post a short example of what you've tried, code (even if it's incorrect code) will often speak much louder than words.
Yeah sorry. I'm typing from my phone and being lazy cos formatting is a pain.
Oh if you want to use that syntax, you can do foo_array = Array{foo, 1, 2} which makes a 1 x 2 array of type foo 
Those curly braces should be () julia&gt; foo_array = Array{foo, 1, 2} ERROR: too many parameters for type Array julia&gt; foo_array = Array(foo, 1, 2) 1x2 Array{foo,2}: #undef #undef 
I had it wrong, but you can do foo_array = Array{foo, (1, 2)}
Does that syntax require a constructor function in the foo type declaration?
Yes but that is a type definition not an actual array of type foo
No.
Yeah, I just don't think we have it hooked up to do runtime CPU target detection. OpenBLAS does, but I don't think the way we're currently calling LLVM can do this yet. Might be a relatively simple feature to add though.
You can try `Pkg.checkout("Requests")` to see whether the deprecations have been fixed on master of the package. If not, no one has gotten around to fixing them yet. Find the source in `~/.julia/v0.4/Requests`, fix the warning, and open a pull request. There's a small package called Compat.jl that exists so deprecated syntax can be fixed in a way that works for both 0.3 and 0.4. I'm not sure if there's an easier way to suppress warnings than overwriting the definition of `Base.warn`, but if deprecations are really bothering you and you don't want to fix them, best way to avoid them is use 0.3 from the juliareleases PPA.
Possibly via https://groups.google.com/forum/#!topic/julia-dev/qdnggTuIp9s but I couldn't tell you whether it's been done with any complicated examples including packages, ccalls, etc.
I can't speak for Requests or JSON but the master branch of SQLite should be pretty stable at the moment and any deprecations should be fixed. Beware though that it underwent a major overhaul recently with some breaking changes and we haven't yet got round to documenting it properly yet.
We've all been there: not knowing the answer makes asking the question hard as well.
Your best bet, at least until 0.4, is going to be just bundling all of Julia with the `.jl` scripts and a small script that boots `julia main.jl`, or something similar. This is basically the same thing people do when packaging Python programs. If you're able to put together a tool that does this, I bet it would be useful to others as well.
SQLite is definitely the lesser of the issue with deprecated syntax.. there are only three Warnings when "using SQLite": WARNING: deprecated syntax "{}" at ~/.julia/v0.4/SQLite/src/SQLite.jl:36. Use "[]" instead. WARNING: deprecated syntax "[a=&gt;b, ...]" at ~/.julia/v0.4/SQLite/src/SQLite_consts.jl:109. Use "Dict(a=&gt;b, ...)" instead. WARNING: deprecated syntax "[a=&gt;b, ...]" at ~/.julia/v0.4/SQLite/src/SQLite_api.jl:87. Use "Dict(a=&gt;b, ...)" instead. I noticed the changes from the documentation; the README at the github site certainly is out dated, but I found out how to connect [here](http://statcompute.wordpress.com/2014/02/08/julia-and-sqlite/) and have just used "query" to (obviously) make queries and any changes to the db.
turns out most of the warnings are coming from BinDeps package... might start getting into fixing the warnings, but this one has quite a lot... fortunately it's not affecting the code i'm currently working on.
Sorry I should have been more clear. When I said master branch I meant the development version (I think you could have used `Pkg.clone` for this), when you did `Pkg.add` you got the current release version.
Since 0.4 you can parameterise with any immutable type. So arrays won't work, but something like the [immutable arrays](https://github.com/twadleigh/ImmutableArrays.jl) package should.
I made some very naive optimisations [here](https://gist.github.com/Sean1708/0c0fdf9aa62486402b20), there are more that can be done but already it's down to about 45 seconds. Basically you were using too many globals. Any globals you do have to use should be marked `const` including arrays (in your case you can still change your constant array). Also, instead of definining functions which modify global arrays you should pass the array to the function and it will still be modified in place, this is actually the most significant optimisation here. Another thing I forgot to try was putting every thing in a `main` function and calling that, that might provide more speedup. Edit: Also, have a thorough read of the [performance tips](http://docs.julialang.org/en/release-0.3/manual/performance-tips/) there's probably some other simple optimisations you can make.
That's great. Thanks for doing that. I did have daysPerYear and the array bodies as a const but I didn't realise they were reserved and it didn't like the const dec obviously. I had the same trouble with Nbody and solarMass, which I didn't realise were reserved, lol. I've had to change bodies to bods for it to work on my Julia install. Thanks for the tips about passing arrays. I feel like a fool for not trying it, I didn't think it would make such a massive difference. I'm still puzzled by the energy change. I'll keep fiddling with it. Cheers.
Does emacs mode support inserting unicode literals like the repl? As in \gamma giving γ?
Yep. You need to press tab, exactly the same as the REPL.
This was the error I was getting "cannot declare bodies constant; it already has a value", same for the others. I probably misconstrued the error cos Nbody, bodies, daysPerYear or solarMass aren't defined when I just tried them in the Julia console.
Are you using the REPL and `include("...")` to develop this? If so what'll be happening is you'll have defined the variable in a previous `include` then tried redefining it as constant. Try using `workspace()` to undefine all previous variables.
Ah ok thanks, I prob would have made that mistake a few times. I'm using a combination of Julia Studio IDE and command line. 
Yeah, it got me a couple of time too. Try to think of `include` as copy and pasting into whichever REPL you're using. BTW I've found your bug, in `advance` you've written bodies[j].vx += (dx * bodies[i].mass * mag) bodies[j].vx += (dy * bodies[i].mass * mag) bodies[j].vx += (dz * bodies[i].mass * mag) it should be bodies[j].vx += (dy * bodies[i].mass * mag) bodies[j].vy += (dy * bodies[i].mass * mag) bodies[j].vz += (dz * bodies[i].mass * mag) You also made a mistake in offsetMomentum where you put px += (bodies[i].vz * bodies[i].mass) and it should have been pz += (bodies[i].vz * bodies[i].mass) but I think this mistake must have canceled itself out because it didn't change the answer much.
&gt;declared types are the way to go Not so actually, most of the time the compiler's smart enough to figure it out. To quote the documentation: &gt;In many languages with optional type declarations, adding declarations is the principal way to make code run faster. This is not the case in Julia. In Julia, the compiler generally knows the types of all function arguments, local variables, and expressions. However, there are a few specific instances where declarations are helpful.
Declaring types helps to keep the addresses close together in memory. It is important for speed in simulations. This is from several different examples. Explicitly giving the compiler the information is better than hoping it figures it out. for instance... https://github.com/BenLauwens/SimJulia.jl
Ah cool. I'll have a closer look at it. I just ran it and it took 11.4 secs on my PC. That's 9 secs faster than my code, pretty damn good. There must be a small error because the energy isn't conserved though as far as I can tell.
That's great, those fixes conserved the energy. That's the danger of copy/pasting the previous line of code and forgetting to change the x,y,z. On my PC it runs in ~21 secs. Unoptimized GFortran in 49 secs and O3 GFortran in 17.4 secs. Pascal runs in ~22 secs. It's a good result I think.
Fair enough.
Completely forgot about immutables, silly me. I also get a bit of speedup by putting the arrays in the `main` function and not declaring them as constant, is this the same for you? Also, as /u/astrowhiz noted, the energy shouldn't be changing thath much so you've got a bug in there somwhere.
Making those vars local didn't help in this case. I tried it anyway, fixed the bug too. 
Excellent. Makes total sense splitting up that big array into related parts as well.
However, the arguments are Arrays of Immutable not simply Immutable, arrays will always be passed by reference. Immutable loose some flexibility in that you can't update individual elements, but in this case you always want to update x,y,z together, so nothing is lost. For that you gain this advantage ([see here](https://github.com/JuliaLang/julia/blob/master/src/array.c#L19)): static inline int store_unboxed(jl_value_t *el_type) { return jl_is_datatype(el_type) &amp;&amp; jl_is_leaf_type(el_type) &amp;&amp; jl_is_immutable(el_type) &amp;&amp; jl_is_pointerfree((jl_datatype_t*)el_type); } Julia will allocate a chunk of memory so that all of the elements are contiguous, and there is probably some vectorization that can happen too, especially as soon as AVX2 (llvm 3.5) is onboard. 
I'm trying to make a type for elements of extension fields. For example, integers mod p can be defined with ModInt{p}, with p an integer, so that everything gets reduced modulo p. In an extension field, it's the same thing but with elements are represented by polynomials, and everything reduced modulo some polynomial. So you'd need to define ExtInt{p} with p a polynomial (which for computational purposes can just be put into a vector).
heh. iirc, i created the issue that led to the extension in 0.4 because i was writing code for a very similar case. if it's any use the (0.3 compatible) code is at https://github.com/andrewcooke/IntModN.jl edit: although i see the build is failing. that's not a package i plan to maintain/fix any time soon, sorry.
This is one of my biggest issues as well – see [#265](https://github.com/JuliaLang/julia/issues/265). It looks like this is on the list for fixing, at least, even if it's not a really high priority.
Ah, thanks for that. Do you know if there's a workaround at all? I can't see one in that thread.
AFAIK the only thing you can do is recompile `f`. It's not ideal but when I'm using Juno it's just a case of `Ctrl-Enter` in the right places, so that's not too awful.
Followup question, is it possible to run blocks of code like in Juno for lighttable? I have lots of algorithms that literally take hours to run and rerunning the whole program because I forgot a minus sign in the fast aftermath data processing would be horrible. I have wanted to switch over to emacs again after getting frustrated with these "modern" text editors, but this is one of the largest hold overs for me. Thank you in advance, even if you can't answer.
If you are defining these functions in a file, you can use `reload(filename)`to force reloading everything that was defined in that file. Otherwise, you are out of luck and will have to redefine everything in order. Like /u/one_more_minute said, working in IJulia or Juno may help, as then it is just a matter of re-executing the right parts of your code.
Juno doesn't looks like it helps in this regard. While working over the weekend and getting weird behaviour, I realised that Juno was executing previous versions of functions.
Yes, package/module loading is quite slow, a well-known issue. If your script starts by loading a few packages, it will be a few seconds before anything else runs. Solutions include working more in the REPL, and using something like iJulia/iPython. Load a package once, then everything subsequent to that is quicker.
Yes, this is definitely a known issue. Julia currently has to JIT compile all of Gadfly (which, alongside its dependencies, is tens of thousands of lines) every time you load it. It's a good idea to have a go at coding interactively via `include("script.jl")` at the repl, so that you rarely have to boot julia / load packages. 0.4 for is going to have module caching, which will solve this for good. It's not on master just yet but AFAIK work is well underway.
Just curious, what kind of frustrations do you have with Juno/LT? Unfortunately it's true that there's no way we can match something like Emacs' infinite feature set / robustness (at least not for a while), but if there's anything in particular it might help me prioritise. Also, for anyone interested in implementing Juno-like eval in Emacs/Vim/whatever, I'm happy to help you get going with the Julia code analysis stuff I have working.
&gt; Just curious, what kind of frustrations do you have with Juno/LT? Mostly LT. Juno itself has the occasional crash when I try to remove an error, which is sometimes frustrating, but otherwise works fine so I guess that is a big one. LT on the other hand is frustrating in general. The way the console works, inadequacy of the menu, no regex search as far as I can tell, can't find/replace in selected text, workspace is global, no listed shortcuts by default, they have to be discovered, etc. I mean I really like many of the features, but it's one step forward in the right direction, and one step back in terms of basic things. Since LT is not under active development anymore this might be a deal-breaker. &gt;Also, for anyone interested in implementing Juno-like eval in Emacs/Vim/whatever, I'm happy to help you get going with the Julia code analysis stuff I have working. If I wasn't so busy I might have taken you up on this offer...
I use ESS with emacs to make the interactive code in a repl easier. I can edit then run the script with a few keypresses.
Emacs Speaks Statistics supports running code in a Julia REPL, but I haven't tried it myself. ESS currently has its own Julia highlighting support, but I hope to make it depend on julia-mode. Ultimately, I'm deeply envious of Slime for Common Lisp and Cider for Clojure -- interactive programming environments which heavily influenced LT's design. I'd really like to see something similar for Julia.
does this help any - http://acooke.org/cute/WritingCle0.html ?
I believe Emacs and Vim have modes in the `contrib/` directory of Julia itself, and Sublime Text has a mode you can get through the plugin manager. I can also help you get up and running with Juno – if you can give me a bit more info about the problem you're having it'll probably be a really easy fix.
Are you thinking in terms of performance or of managing larger programs?
Sure... For Juno, I followed the instructions on the website and modified the user.behavior file, but unfortunately the example was for windows. It may just be that I have the wrong file being pointed too. When I start lighttable, I get: Couldn't connect to Julia Could not find command: /downloads/Julia_Studio/bin/julia-basic Whereas the windows version wants to point to julia.exe.
for your best experience with emacs and julia I recommend using ESS: http://ess.r-project.org/ It has integration with the repl and the ability to interactively run the code you are editing.
Ok, I recommend trying out the instructions for Ubuntu [here](http://julialang.org/downloads/) – halfway down the page you'll see instructions for installing using the PPA. Once you've done that you should be able to use Julia from the terminal, and setting the path in LT won't be necessary.
Yeah Juno is not simple to get going which is a major draw back, but is great once you can start using it (and get around some of the bugs). 
I stopped using Julia Studio this year since it became slow and buggy. Right now I am using something called [Juno](http://junolab.org/) on top of Lighttable which seems to work fine but the setup might be a bit difficult. Sublime Text is also a good choice.
Julia got me to use Emacs Speaks Statistics again for the first time in a while since switching to RStudio. I'd forgotten how nice ESS is in certain ways. The result has been that I am now doing my R development in ESS. My biggest problem switching between R and Julia in ESS is writing R in Julia and Julia in R. :-)
While you might not know vim, I just want to chime in and say that the julia-vim plugin is really nice. https://github.com/JuliaLang/julia-vim
Out of curiosity, what is it causing the packages to load so slowly?
That's how fast Julia compiles everything in the Gadlfly and related packages from source! Unnecessary really once they become stable but that's how it is for version 0.3. 
Fair enough.
The `T` just declares "some type". So foo{T}(x::Vector{T}) Says `foo` accepts an array which has the element type T. In this case, that doesn't actually do anything, since T could be anything. foo{T&lt;:Real}(x::Vector{T}) The `T&lt;:Real` is a constraint which says that T descends from `Real`. So `foo` still accepts an array of different element types, but only so long as it's Int, Float64, or some other number type.
Thanks Philip; this was useful!
Makes sense. Thanks!
I don't think you actually need the `begin`-block since the function is the smallest full statement anyway.
You're right, thanks! I've updated the gist to reflect this simplification.
Ok, well if running `julia` works in the terminal you should be able to run Juno (including running snippets of code etc.) without setting the path. You've set Juno to look for `/downloads/Julia_Studio/bin/julia-basic`, from the looks of it, but if you remove that it will just try to execute `julia`. Let me know if you get any other errors, though.
Wow 3 backends Julia, C and Cuda. I'm certain once Julia has a good story for targeting GPUs directly it will really take off. 
Really neat real-world examples of metaprogramming. FWIW, if you fancied doing this with macros, it would look like this: macro endpoint(name, path) quote function $(esc(name))(; options=Dict{String, String}()) r = get_oauth($"https://api.twitter.com/1.1/$path", options) return r.status == 200 ? JSON.parse(r.data) : r end end end @endpoint get_help_configuration "help/configuration.json" @endpoint get_help_languages "help/languages.json" 
This is definitely the main issue at the moment, but the set up should see a tonne of improvement before the end of the year.
Thanks for providing this example! I am actually planning on re-doing the whole Twitter package, and using macros like this might be an even better way to do so.
The dream would be having something similar to this: http://www.howardism.org/Technical/Emacs/eshell-fun.html
Not sure but I can say Julia Studio 0.45 is very slow for windows. I would recommend Sublime text or Juno for LightTable as alternatives.
GPU's are more hype than substance right now, except in a handful of applications. Theano and Torch can't solve every problem to the point that they're responsible for Python or Lua "taking off." The PCIe bottleneck and cumbersome host/device distinction means despite some people calling them GPGPU's, they're not very general purpose right now. Ideally the separation in programming and memory models between CPU and GPU will gradually fade away, and new generations of the general-purpose processors that we're all used to programming will gain more of the features that make GPU's fast on certain applications, without losing generality or performance on things GPU's are currently bad at.
Have recently rediscovered Emacs Speaks Statistics and have been digging on that as well. Julia support seems solid.
Can you call rust with C? If so, then it should be pretty simple.
[Looks like you can](http://bluishcoder.co.nz/2013/08/08/linking_and_calling_rust_functions_from_c.html) via a little bit of extra work to use C calling conventions. This has been used to embed [Rust in Ruby](http://bluishcoder.co.nz/2013/08/08/linking_and_calling_rust_functions_from_c.html). 
[You could also do the opposite](http://docs.julialang.org/en/release-0.3/manual/embedding/) if you so wish.
Too early to ~~ask~~ answer this question, since the shape of Rust libraries that people would want to use from other languages is not yet known. This has been done in a few cases with Ruby, see a recent but not very deep example here http://blog.skylight.io/bending-the-curve-writing-safe-fast-native-gems-with-rust/. It sounds from the linked articles that library authors would likely need to be very diligent about avoiding using the rust runtime to avoid conflicts with the host language runtime. Will any libraries go to these lengths? How limiting will this be in terms of missing features? You're not going to be able to express high-level API's through a C interface. If Rust and Julia ever end up using the exact same version of LLVM at the same time then potentially you could dump LLVM IR for the Rust library and try something clever with llvmcall in Julia, but again you'll have to be careful about any runtime library pieces that the Rust code depends on. I suspect most of the Rust community will focus on libraries intended to be used from Rust, but perhaps not all. Similar to how calling Python from Julia works really well right now but embedding Julia in Python still has some kinks to be worked out, simply because fewer people are doing it at the moment. 
I guess the other point, which you've tried to make over in /r/rust is that it's unlikely that Rust will have a large scientific userbase. That will mean that there will only be a smallish number of packages that would be worthwhile to call from Julia.
If you've ever seen anything about Keno's [Cxx.jl](https://github.com/Keno/Cxx.jl) work, you'll know that anything is possible – in the limiting case by getting the Rust compiler to generate code for you. That would give you full interop with Rust types etc. without having to write C wrappers. Also worth noting is that the rust community seem interested in [having a repl](https://github.com/rust-lang/rust/issues/9898) which could make this a lot easier. I think Rust actually stores some metadata about name mangling etc. in compiled libraries, which might just make it possible to call rust without C wrappers *or* a compiler, but I don't know for sure. Would definitely be cool to see it done either way.
There is a sample function in [StatsBase.jl](http://statsbasejl.readthedocs.org/en/latest/sampling.html)
Thanks!
Overall under the [JuliaStats](http://juliastats.github.io/) organization is where you find much of the stats functionality for Julia
Thanks! I'll check it out! 
Try without the space after the semicolon
Probably worth pointing out that there are a few people looking into asm.js compilation via emscripten, which would be really cool to see. There should be some more info about this on the mailing list if you're interested.
This would require full ahead-of-time compilation.
Pandas is also a bit more stable, but I look forward to seeing where DataFrames goes.
Potential ideas: - Serialize or store the data as JLD/HDF5 and then copy it to each client and load it there. - Use a database that,s what they are meant for - Start several long running cluster processes, load the data on the main one and then distribute it to the slave nodes. Use the master node to queue jobs across the slave nodes .
This isn't a bug. Part of the confusion is the order of operations, although your syntax suggests otherwise, power has higher precedence than negation: -(0.1 ^ 1.1) # works, and this is equivalent to the original expression -0.1 ^ 1.1 (-0.1) ^ 1.1 # errors In general a negative float/real to the power of a float/real is not well-defined...
I guess I should add that I solved my problem by using sign() and abs() to do the operation on a positive number and put the sign back on it. I actually have a function I called SignedResult which does exactly this by taking a number and a function, running the function on the positive number and returning the result with the original sign applied.
Also try julia&gt; (-0.1)^1.1 ERROR: DomainError julia&gt; complex(-0.1)^1.1 -0.07554510437117541 - 0.024546092364165543im You only get a complex result if you do exponentiation with complex numbers.
Can you be more specific about the problem you are trying to solve? I think eval is usually not the right tool for the problem.
I second /u/phinux that eval is probably not what you want, but nevertheless a solution that works on the REPL julia&gt; foo = 30 julia&gt; @eval begin bar = 3*$foo end julia&gt; bar 90 
The problem is the eval statement is inside a function and it needs to modify a local variable that already exists. I tried simply stating the variable before the eval statement and modifying it inside it, but that didn't work.
eval always runs in global scope. I don't think what you are trying to do is possible with eval. 
Unless you're doing something very, very unusual, the way to do this is to write bar = f(foo) Where `f` carries out the desired computation on `foo`. No eval required.
It's actually part of something that is just warping points around, so no mathematically soundness needed. Fundamentally the sign is just pointing which direction to go, so the only sound math that is needed is the exponent of the absolute value anyway.
running test() function test() a::Int64 = 1 e::Expr = quote a = 2 end eval(e) println(a) end prints 1, and i want it to print 2. After reading /u/mralphathefirst i would guess the problem is that the a in the Expr e is a global variable, different from the a inside test.
Is there a way to run code in an Expr locally, given that i only know what the Expr is at runtime? 
Thank you very much, this seems like it will do it. But what do you mean by higher level function?
Is there a way to manipulate the functions in fcns? like this: fcns = [tweakfunction(fc) for fc in fcns] function tweakfunction(f::Function) return ? end
My Julia wish list: eliminate temporary allocations from vectorised expressions (like devec), codegen Julia to opencl SPIR and compile programs to static executables. 
Auto-devectorisation is very difficult to do without special casing a bunch of common functions. If someone can come up with a good general way to do it (which works for user-specified functions), great, but I think it will be a very long time before Julia's compiler is that advanced. Static compilation will land soon, though.
Yes. A macro will be able to do it but depending what you want to do exactly a function might be simpler.
Well, it is vital for my program to be able to modify the functions in fcns: not just replace them, but make actual modifications in their code.
But what are you trying to modify? I'm just trying to get all the background information to help me answer the question. Right now I feel like I'm guessing at what you're actually trying to do. Once a function has been defined, you cannot change the function with something akin to tweakfunction. However, you can redefine the function. Consider the following julia&gt; function create_a_function(N) @eval function func(x) x + $N end end create_a_function (generic function with 1 method) julia&gt; create_a_function(2) func (generic function with 1 method) julia&gt; func(3) 5 julia&gt; create_a_function(3) func (generic function with 1 method) julia&gt; func(3) 6
julia --lisp
Some context, from [an answer Stefan Karpinski's gave on Quora](http://qr.ae/lLIJE): &gt; Julia is pretty Lispy. There's even the easter egg that if you start Julia as `julia --lisp` you get a full-featured Scheme prompt. This isn't just there as a joke (or to circumvent [Greenspun's tenth rule](https://en.wikipedia.org/wiki/Greenspun%27s_tenth_rule)): Julia's parser is written in Scheme and various lowering passes are also implemented in Scheme. You could easily put an S-expression front-end on Julia and then it would be a funny Lisp-1 with some fancy features like type annotations (with parametric types etc. – but that exists in CLOS) and functions that are generic by default (i.e. they are multimethods). On the other hand, Lisp traditionally lets you dynamically redefine all sorts of crazy things and it is supposed to keep working – and do the crazy thing you said that it should do. Julia gives up a fair amount of dynamism that was not particularly useful – e.g. once you create a type, you can't change it; function bindings are constant; local scopes are not reified. These restrictions make it significantly easier to generate fast code but do seem to be a departure from the Lisp tradition of total dynamism and being able to change all things at run-time.
Julia [is already considered a lisp--same as Dylan--in some circles](http://p-cos.blogspot.com/2014/07/a-lispers-first-impression-of-julia.html). That said, I was just commenting elsewhere that I don't understand how homoiconicity works without the tender embrace of heaps of parentheses.
I have a question as someone who doesn't really know Lisp. What are the real pragmatic benefits of Lisp that Julia doesn't have? To me the syntax is a huge drawback and Julia includes the things that people love about Lisp without all the nesting.
It's funny, because the big thing for me in Lisp *is* the syntax. Don't get me wrong, it's awful for writing equations in, but for virtually everything else the uniformity and minimalism makes a lot of sense. Plus, when you're programming in a more functional style, you actually *want* to be able to nest things in a natural way more often than not. Julia's `begin`/`end` blocks make this... inelegant. Macros also stick out like sore thumbs, which has its pros and cons. Julia has pretty much everything else you'd want from a Lisp, and for various other reasons it's still the most powerful language I know, but I do miss my SExprs sometimes. The other thing is the point about dynamism mentioned above – e.g. the number one pain point for me right now is [#265](https://github.com/JuliaLang/julia/issues/265). Common Lisp, for example, wouldn't make that kind of tradeoff.
With Julia I have started to write (in Juno btw) some things in a nested functional style with the one line function declaration syntax, which to me feels like I'm getting the Lisp or Haskell style when it will be the clearest way to write something, but then again I've never been able to force myself to write anything real in those languages.
This works fine: a = uint64(2)\^uint64(63) typeof( a ) ---&gt; Uint64 b = BigInt(a) Under the hood it looks like powi is being called in libm although in Base.math.jl I don't see a ccall that uses two 64 bit integers. This might be the relevant part of the underlying library: \^(x::Float64, y::Integer) = box(Float64, powi_llvm(unbox(Float64,x), unbox(Int32,int32(y)))) \^(x::Float32, y::Integer) = box(Float32, powi_llvm(unbox(Float32,x), unbox(Int32,int32(y)))) This would mean even using two integers results in a floating point to the power of an integer, presumably returning the same type as the power, which in Julia would mean Int64. This would explain why the result is signed and loops around. There might not be a better way to get around it than the above, since the current way maps directly to underlying C calls. a = uint64(10)\^uint64(19) BigInt(a) Also works 
I'm not sure if this is new for 0.4 but ^{T&lt;:Integer}(x::T, p::T) is implemented in pure Julia. Edit: [It's in 0.3 as well.](https://github.com/JuliaLang/julia/blob/release-0.3/base/intfuncs.jl#L84) In future you can use edit(^, (Int64, Int64)) to take you straight to the relevent line of source code.
Take a look at julialang.org/learning for some resources. At this point, learning Julia as a first language should be doable if you're fairly intrepid, but bear in mind that there's limited help available if you run into bumps. It might be worth having a go at something like Python to pick up the basics.
+1 I've enjoyed following the development of Julia on he mailing lists and reddit as much as using the language.
Go for it! Ask for help on the Julia-users mailing list when you get stuck. 
Would be very interested in this. I am just starting to dip my toes into the (Julia) water, and having a go-to source about new packages and Julia updates would be awesome. Tons of resources for R and Python, very little for Julia (On a somewhat related note, I'm pretty amazed there hasn't been a single Julia book published yet. The first books I've seen mention Julia is the new edition of the 7 languages book. O'Reilly has a Julia book scheduled to be released mid-2015 but that is still a long ways off)
Do you have any reason why you want to use Julia? I don't want to persuade you otherwise, I'm just curious
There is a book comming out in the near future but [a lot of the developers are dubious about whether this is the right time for one](https://groups.google.com/forum/#!topic/julia-users/U_Li8_XiJZw).
While the syntax of the language is still changing, a non-updateable book sounds like a poor investment. Perhaps for version 1.0?
There's some basic stuff on [wikibooks](http://en.m.wikibooks.org/wiki/Introducing_Julia), but your progress in any language will depend on how quickly you can pick up the basic concepts of programming. Most tutorials assume you know your way around a text editor, know how to use a browser, the terminal, etc. Without some foundation, I wouldn't start with Julia or Python...
Sure we can sticky it. Feel free to PM me/us if one of us doesn't notice it right away. Thanks!
I'm very familiar with teminal because i've been a unix admin some years in my history and wrotwe dozens of shellscript (but I don't name it programming)
Yep, i was looking over it. but beside this i've found the following as useful: http://www.scolvin.com/juliabyexample/ (at the first look)
Awesome, thanks. I'll try making an initial post tomorrow, hopefully this'll take off.
:) well I guess you won't have to learn how to use the terminal then! :)
I use ifttt.com for that
This is a great idea. If we wanted to be clever we could call it "This fortnight in Julia" to reduce the work load. I think this is helpful considering how much Julia changes and how much explanation in needs to new comers. Also usually once a month or so something amazing happens in julialand and we should highlight these achievements.
See https://people.maths.ox.ac.uk/trefethen/barycentric.pdf I have no idea how to start the implementation in Julia evaluate? Vectorize ? 
Similar but with enough differences that copy-pasted example code isn't going to run without some modifications, http://docs.julialang.org/en/release-0.3/manual/noteworthy-differences/#noteworthy-differences-from-matlab covers most of them. &gt; how to start the implementation in Julia evaluate? Vectorize ? You can vectorize if that's more natural to you, but following the for-loops from the pseudocode may be a more direct way of writing it. Focus on getting something that gives the correct answers first. Then if you want to see how changing the code around influences the performance, you can experiment with Julia's profiler: http://docs.julialang.org/en/release-0.3/stdlib/profile/ 
Good idea, probably start fortnightly then possibly adjust to weekly/monthly depending on how convoluted things get.
Nice keep it coming
Ha! I glad that helps. If you need help give me a holler. This is a good idea and great start.
This is so wonderful! Thank you for taking up the banner that I dropped. This may be a better, lower-resistance medium than using Github+Github Sites, allowing more folks to participate in the discussion and add changes. I feel bad about dropping the ball on TWIJ (Conferences, end of semester, and my own local version of issue #8839 have gotten in the way for the past month), but am very glad to see this continue. Here's one thing I was planning to use in a new post once I had time: The number of contributors to core Julia (as Github counts them) has surpassed 300! I think this is a great achievement and represents some of the success Julia has had. I thought it'd be cool to see how this number has grown, so I fixed up the mailmap a little bit to eliminate a few duplicates and plotted the contribution counts (this is still a little higher than GitHub reports, because GitHub ignores entries that aren't linked to an account): [Total number of contributors to Julia](http://i.imgur.com/JdWYjW7.png) [Number of new contributors by month](http://i.imgur.com/dqJFWuq.png)
I'm totally game to help enable this however it is most convenient. That's exactly why I started TWIJ as an independent organization — so we can add many collaborators. But perhaps Reddit threads are a better solution? In any case, thank you!
It's a couple days earlier than Dec 12, but I liked seeing @noinline get added ([#9291](https://github.com/JuliaLang/julia/pull/9291)).
Does this mean there's no need for ArrayViews anymore?
Just a thought. One possibility would be to have a monthly blog that collects material from these reddit posts. It can be done as a PR to the website https://github.com/JuliaLang/julialang.github.com It will likely get contributions from the community too, if you can take the lead to create the PR and get the ball rolling.
Don't worry about it, you're probably a lot busier than most of us on reddit are. Who knows, this enterprise might fail too but I thought I'd give it a shot. A look at the number of contributors might make a nice New Year post, thanks.
Awesome, the best way you (and some of the other developers if they have time) can help is too expand on the posts in the stickied thread since you guys will have a much better understanding of things than we do. But any contributions that you make will be amazing. /u/ViralBShah mentioned possibly doing a monthly blog post on julialang.org but I think we should give this thing a couple of weeks to mature first before deciding.
what would be common functions a computer music library might contain? What sort of things do you have in mind doing with it?
Would say for non-STEM areas, the landscape is still pretty barren in Julia-land. Have been trying to craft something Processing-esque with Images.jl &amp; Cairo.jl for the visual arts, but it's been slipping in my side project priority list. Good luck though, I am sure that Julia will be a great match for synth etc. Recommend bootstrapping from PyAudio or use `ccall` with PortAudio.
Note that you're searching the older package list, you'll have much better luck with http://pkg.julialang.org/
Thanks!
I don't know, everything? Currently I want to do analysis on spectrograms but in the future I might want to be able to represent music like Euterpea in Haskell or something similar
For users who want to rebuild their system image (`sys.{so,dll,dylib}`), either because they're on Windows and want fast startup times, or because they want to include packages into their system image to have those packages available immediately at startup, a new `build_sysimg.jl` script is being shipped with Julia. This script automates the process of rebuilding the system image, and allows you to include a `usrimg.jl` file as well. ([#8074](https://github.com/JuliaLang/julia/pull/8074))
FYI, Update: ['Merge PR #9294'](https://github.com/JuliaLang/julia/commit/e93672dd3f94a8ffe80407f8c8152c5a92a767ae) Pull Request was just merged to support the suppression of deprecated warnings. So I imagine this will be on the most recent or upcoming julianightlies version.
I'm not much of a programmer, but I find Julia very pleasant to work with, fast, powerful, and easy to write in. If anyone's interested, the repo is on [Github](https://github.com/cormullion/spiral-moon-calendar).
Lesson learned! Thank you very much.
Hey [botany_thunderdome](http://www.reddit.com/user/botany_thunderdome), I guess you're not quite far enough along in Julia to compare the in-Julia parallelism with using SGE; is that right? I also use SGE. I don't yet have an answer for how the switch would be between using something like SGE to using tools directly from within Julia.
I get what you're saying but I don't think of Julia and SGE as exclusive. You could have a job script or parallel environment that knows how to start julia across all of the resources in the job request. https://groups.google.com/forum/#!topic/julia-users/WQ9lJr7RLhs It would also be nice to have a Julia DRMAA library to directly interact with job submission API's. http://www.drmaa.org
Happy to help :)
Yes, Julia needs Float80, but it should be used carefully. We don't need more implicit Float64 to Float80 conversion like exists in D.
Thanks for the helpful comment. I just spent a half hour learning about DRMAA and also thinking about the interaction of Julia with SGE. The link was very helpful. 
Is there anything particularly special about Intel's Float80? Julia already supports arbitrary precision arithmetic, and it sounds to me like this is even more useful from the standpoint of the calculations mentioned in the article. Sure this will be slower than hardware Float80 (though I am not sure how much), but how frequently is 80-bit precision the magic number somebody is looking for?
Part of the point is that Intel processors in the vast majority of PCs/servers already include long double arithmetic, and IEEE recommends its use. Even with regular double there is a chance of catastrophic round-off, and the extra bits reduce that chance markedly. Bill Kahan (a developer of IEEE floating point standards) discusses this at length in a [presentation complaining about Java's decision not to use long double](http://www.cs.berkeley.edu/~wkahan/JAVAhurt.pdf). 
But as far as actually getting Float80 support in Julia, there are only 2 holdups: 1. We're at the mercy of LLVM as far as how well code generation of x87 instructions is supported for long double. If it works fine in clang, we can probably use it though. 2. People who want to use it in Julia haven't implemented it with pull requests yet.
My understanding is the the nullable type is key for genericity. Just multiplying by zero is fine until you're working with string data (say) and "foo"*0 fails. The described approach might be useful as an optimisation for numeric data, but if we need to solve the general problem anyway... I'm not the expert, though, and it would definitely be interesting to see what JMW and the other data frames people think of this.
All that you say is true, but one of Kahan's suggestions is not to seek exact reproducibility of results, which is why Java rejected long double. Kahan points out that reproducibility can needlessly slow down code for some processors, and that it's better just to have predictability within known limits. Certainly it's best not to surprise people with unexpected conversions between types, but code should also be written without dependence on exact reproducibility.
I'm a but surprised that R is growing so fast. Is this a well-known phenomenon that I've missed? Is it R itself or statistical computing general that is growing?
I think its more of a case of R users migrating to GitHub. 
&gt; not to seek exact reproducibility of results Sure. On today's hardware that means SIMD and permitting some nondeterminism in parallel algorithms. But primitive scalar operations need to be verifiable and have preferably one portable meaning.
You can run Julia with bounds checking disabled. julia --check-bounds=no
I realized that too late, thanks! 
I'm the main developer on AudioIO.jl, and I definitely have computer music tasks in mind. Currently there are just basic oscillators and array playback implemented, but I'm a PD and SuperCollider user and computer musician, and I'd definitely like to beef up the capabilities for interactive synthesis in AudioIO.jl. The best way to contribute right now would be to file github issues with the sorts of features you're interested in and we can discuss over there. The thing I've been thinking a lot about lately is integrating with Signals.jl for more FRP-style interactions with control signals.
I am using Juno on windows and not running julia scripts straight, so for now I solved this problem by creating a batch file, then pointing Juno to the .bat file instead of the normal julia.exe in the user behaviors file. C:\Users\johnsmith\AppData\Local\Julia-0.3.3\bin\julia.exe --check-bounds=no %* %* Passes the arguments through as you might guess. An '@' at the beginning should turn off the command itself being echo'd back. 
You could remove enumerate() from advance() - perhaps you can just increment j.
One thing I've been trying to get to work is memory allocation tracing. I've used the command line flags, but can't find .mem files anywhere that should show me where my allocations are coming from in my own code.
Check out the comments on the post I started a few months re nbody code as well. Some good tips &amp; I think a clever bod got it down to about 11 secs. [nbody post] (http://reddit.com/r/Julia/comments/2mgrpz/julia_nbody_code_cant_figure_out_whats_wrong/)
One of the features that attracted me to Julia is that it does not suffer from the same kind of fetish-ization of vectorization. My algorithm/logic is not inherently linear-algebraic/vectorizable, so don't force me to jump backwards to shoe-horn it into that form, like in MATLAB or Fortran.
I have nothing constructive to add, but that looks really cool.
That might be broken if you're on Windows. I think there might be an issue on it, if you can't find it then open a new one.
Open a new instance of Julia? I've tried it many times, where should the files end up?
A new issue in the [issue tracker](https://github.com/JuliaLang/julia/issues)
it's a memory leak. No dtor
Check out `finalizer`.
Those symbols could more shortly be written written as [:user_id, :age, :sex, :occupation, :zip_code].
What you've said closely mirrors the reasons why I have started to dabble in Julia as well. I'm a heavy user of R and Python for both data analysis and numerical methods. After rewriting some of my numerical algos in Julia, it is obvious that it has a speed advantage to Python. While I have not yet tried to use Julia for data analysis, the future potential of the language itself is keeping me interested and is driving me to code in Julia alongside Python, so I'm familiar with it. 
You'll probably still need to profile and optimize Julia code to get the most out of it, just like in any language. 
Note that this (currently) only disables bounds checks for Array, not SubArray, or any other array like structure.
That's a nice trick. It might be nice to have a setting in Juno for arguments to Julia – I'll keep that in mind for a future release.
That was my thought too. That along with the memory tracing option would be a big deal for me, so might be to others too. Right now what I am fighting the most is figuring out where memory is being allocated. Figuring out where errors are coming from was a challenge but it seems with Julia 3.4 and an update to Juno this might be better about full stack traces? Not sure which if either changed the error feedback. That and finding out that typeof( int32(2) * int32(3) ) == Int64 :(
I should definitely add some memory tracing stuff to the profile viewer – though you might want to check out ProfileView.jl as well which marks lines that triggered GC. If there are backtrace improvements I can't take credit for them :) Glad that's getting better on Windows though. You'll also be glad to hear that the annoying auto-promotions got fixed for 0.4. I've been doing a bit of crypto stuff and it's a hell of a lot nicer.
That is funny I have yet to run into bugs other than overflows. But I only use Julia for calculations for now.
Reads like a fair observation, and as the author claims, an understandable complaint but not quite a critique either &gt; A small team of highly talented developers who can basically hold all of their code in their head can make great progress while eschewing anything that isn’t just straight coding at the cost of making it more difficult for other people to contribute. Is that worth it? It’s hard to say. If you have to slow down Jeff, Keno, and the other super productive core contributors and all you get out of it is a couple of bums like me contributing, that’s probably not worth it. If you get a thousand people like me, that’s probably worth it. The reality is in the ambiguous region in the middle, where it might or might not be worth it. The calculation is complicated by the fact that most of the benefit comes in the long run, whereas the costs are disproportionately paid in the short run. I once had an engineering professor who claimed that the answer to every engineering question is “it depends”. Is that tradeoff worth it? Maybe. It depends. My interpretation of this conclusion is that right now Julia is a quickly changing language with extremely high ambitions. Having a small core of super-productive, enthusiastic developers is probably the best choice (although it might be a good idea to have a few "idiots" riding along to keep the language understandable to mere mortals). Once Julia stabilizes and really grows, the latter option becomes more appropriate. The transition period might be awkward though, if the core team doesn't plan ahead and anticipate the challenges.
&gt; Having a small core of super-productive, enthusiastic developers is probably the best choice (although it might be a good idea to have a few "idiots" riding along to keep the language understandable to mere mortals). Once Julia stabilizes and really grows, the latter option becomes more appropriate. I'm afraid that by then it will be too late to fix all the damage. I'm sure that after the initial frenzy it will still be possible to fix up the documentation or improve the code review process, but what about the tricky yet scarcely documented code deep down the compiler? For example, take `base/inference.jl` or `src/gf.c`, both of which prime examples of very inaccessible code (to me, at least), yet they are a crucial part of what makes Julia work. 
Looks like it's time for me to start writing tests on base Julia, if that is what it takes to sway some people. 
Well, that's basically why I suggested: &gt; (although it might be a good idea to have a few "idiots" riding along to keep the language understandable to mere mortals) ... where "idiots" is defined relative to the core devs.
I haven't used Julia *that* much, but I never bumped into core language bugs. Packages can be buggy, but that's a different thing.
As a professional Objective-C developer who also happens to love Julia this really blew me away. I am quite excited about the possiblities this might give me. I day dream a bit too often about creating a kick ass app for scientits with beautiful Cocoa interface. Of course Objective-C sucks at writing algorithms or doing data analysis. But combining an awsome language like Julia with what I think is the most sofisticated GUI toolkit out there sounds awesome.
Awesome, thanks. `@code_typewarn` should be pretty useful.
Latest bugfix [v0.3.4](https://github.com/JuliaLang/julia/releases/tag/v0.3.4) was released
I think you need some idiots through the process of making the language. Right now with Rust, it becoming to be a turn off with all the crazy constructs. IIRC, they change a pointer construct so that they aren't needed 90%? Nim/Nimrod is looking to be more tempting compare to Rust... I was in love with Scala for a while but the complexity really did rear it heads out when I got paid to do it and worked in a team. At least for me, it is so complex that you don't get the bigger picture in certain aspect such as functional programming. It really took me a while to grasp functional when I started to play around with Erlang. Erlang forces you to do functional and nothing else so that's the good thing about a focus set of syntax and constructs. Scala let's all all this paradigms and mix them. I'm just hoping that their, creators of Julia, expectation of their user base in term of programming skill isn't that high. But at the same time it's a balancing act, I wouldn't like it if it turns into Go with it's lack of features.
reinterpret(Float32,readbytes(dataFile)) seems to do what you want? I'm not sure whether there aren't better ways.
Huh...learn something new everyday
See https://github.com/JuliaLang/julia/issues/5410. 
Probably easiest to use `reshape`
John Myles White has used the doc system pretty extensively in [CSVReaders.jl](https://github.com/johnmyleswhite/CSVReaders.jl), which might help.
yes: transpose(reshape(simData, 6, div(length(simData),6))) I needed to transpose since I cannot find a way for reshape to give me the desired output directly.
Switch the order of your tuple. reshape(simData, (div(length(simData), 6), 6)) Should do it. 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Composition over inheritance**](https://en.wikipedia.org/wiki/Composition%20over%20inheritance): [](#sfw) --- &gt; &gt;__Composition over inheritance__ (or __Composite Reuse Principle__) in [object-oriented programming](https://en.wikipedia.org/wiki/Object-oriented_programming) is a technique by which classes may achieve polymorphic behavior and [code reuse](https://en.wikipedia.org/wiki/Code_reuse) by [containing other classes](https://en.wikipedia.org/wiki/Object_composition) that implement the desired functionality instead of through [inheritance](https://en.wikipedia.org/wiki/Inheritance_(computer_science\)). &gt;Some languages, notably [Go](https://en.wikipedia.org/wiki/Go_(programming_language\)), use type composition exclusively. &gt;==== &gt;[**Image**](https://i.imgur.com/Wl3DK9B.png) [^(i)](https://commons.wikimedia.org/wiki/File:UML_diagram_of_composition_over_inheritance.svg) - *This diagram shows how the fly and sound behaviour of an animal can be designed in a flexible way by using the composition over inheritance design principle. [1]* --- ^Interesting: [^Inheritance ^\(object-oriented ^programming)](https://en.wikipedia.org/wiki/Inheritance_\(object-oriented_programming\)) ^| [^BaseBean](https://en.wikipedia.org/wiki/BaseBean) ^| [^Liskov ^substitution ^principle](https://en.wikipedia.org/wiki/Liskov_substitution_principle) ^| [^Object ^composition](https://en.wikipedia.org/wiki/Object_composition) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cnf0cd4) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cnf0cd4)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Does this mean coverage may start to be more accurate .. ? (will/should inline be the default for tests?)
Nope, haven't switched back. Still using Julia as my default shell on my laptop.
is `$MKLROOT` already set? If so, your sysadmin has already setup your environment to support building against MKL, and you should be able to just skip the `mklvars.sh` step. Otherwise, you can probably still get Julia to build against MKL by setting the `MKLROOT` environment variable to the appropriate path (something like "`export MKLROOT=/opt/intel/mkl`"). BTW, on my machine that script lives at `/opt/intel/mkl/bin/mklvars.sh`.
thank you kind sir. looks like MKLROOT was set for me.
Good to hear. BTW, I found that by grepping the `Make.inc` file for occurrences of "MKL" to figure out which of the environment variables set by `mklvars.sh` would be needed.
[This](http://www.kaggle.com/c/street-view-getting-started-with-julia) Kaggle competition has a tutorial attached. It's just kNN but it's a start. What I've been doing is using Python tutes but coding what I can in Julia.
You can load Scikit learn into julia. There is also lots of stats libraries https://github.com/JuliaStats What are you particularly looking for? machine learning is a very broad topic
The design decision you're running into is one [explained here](http://stackoverflow.com/questions/17298586/how-to-delete-a-row-of-matrix-in-julia) by Stefan Karpinski. You're basically trying to delete a row with a certain index from your matrix. This is a fairly inefficient operation, as it needs to make a copy of the entire matrix without the row you wanted to remove. Therefore Julia makes you do this explicitly, as in the example provided by Eitan, which selects all the rows you want to keep: A = A[[1, 3:end], :] If performance is a concern, you could look into changing your data structure to a 1-D array of a new type, for which functions such as push!, splice! and deleteat! are implemented. See the following example: type Foo bar::Number baz::Number end x = [Foo(1,2), Foo(2,3)] push!(x, Foo(3,4)) deleteat!(x, 2)
Great suggestion! Thanks. 
And now [v0.3.5](https://github.com/JuliaLang/julia/releases/tag/v0.3.5) is released.
Try to find out what is not available in the existing packages. For example: https://github.com/JuliaLang/ODE.jl :)
I know a lot of ODE solvers exist already in Julia packages, but the goal was to create my own! 
It is not enough. There are more to be done in Julia. And what is already exist need to be optimized. You can try to do something. :3
I'll take a look and see if I can add to Julia's development. :) 
I remembered there is a book talking about numerical methods, whose code is written in Fortran or C. I think you can refer to that. (I will check the name of the book sometime later.)
That is a very good point that I should have thought about before, being very familiar with closures in C++. Is it not possible to use reference counting with automatic Julia style closures? It seems to me that figuring out which variables to close over can be done automatically and that stack variables would be passed by value, while heap values would have their references incremented. I am guessing there are further wrinkles but I don't see them clearly yet.
thanks. is `0is` a typo? (line 3 of rust snippet).
Swift (which is automatic reference counted) has nice closures just like Julia ones, see the example I posted below right from the Swift manual
Sorry I didn't see this before. Yes, for more accurate coverage information, right now you can disable inlining, at the cost of increased run time.
Here are couple I have bookmarked: [Project Euler](http://projecteuler.net/problems): Very much math geared, which is where Julia excels. Just remember that your algorithm matters more than the speed of the language. I've done the first 60 in python, and non of them takes more than 2 minutes to calculate the answer. [Mega projects list](https://github.com/karan/Projects): Huge list of projects that anyone can try solving, covers very broad range of different scenarios. [Simple Programming Problems](https://adriann.github.io/programming_problems.html): Progressively more difficult general programming problems for the beginners to solve. Some are very easy depending on the language you pick, but should be workable in Julia too. I've solved quite many of these in C, because I felt that it was the most appropriate, since some of the list problems only make sense in language like C where there's no ready made list type with methods for manipulation [PuzzleNode](http://www.puzzlenode.com/puzzles): List of general programming puzzles which you can try solving.
How has your workflow changed because of this? do you `run(`\``pwd`\``)` or `pwd()`?
The latter, as well as `cd()`. Most tasks require dropping to the shell prompt, however (my laptop's NetworkManager hasn't been playing nice lately); perhaps I'll eventually figure out some way to let Julia call external programs as functions via macros or some such. For now, my `~/.juliarc.jl` has some functions wrapping common shell utilities like `ls()`, as well as for `bash()` in the event I need to switch back to a more typical shell for a bit (and not have to prefix everything with a semicolon).
Generational garbage collector finally [merged](https://github.com/JuliaLang/julia/pull/8699)
I'm not a gc expert but from reading the issue I think it's like this: the old gc had two "modes": - do nothing - collect all garbage the new (generational) gc has more "modes": - do nothing - collect some garbage (e.g. only take x time doing it) - collect only old garbage (there is some labelling of "old") - collect all garbage What this means: is that where a full GC run previously may take several/tens of milliseconds, you can do several of smaller runs. This means the gc time can be much more stable, e.g. if you're running time critical, like video or audio where you don't want to lose large chunks of time (frames). I think it also opens up avenues for reuse e.g. with BigInts (but that may have been possible before / if that's being done yet).
I'm finding one of the pieces of information I miss the most from ZSH is the PS1 settings telling my about my git repo and my pwd. Have you solved any of these problems?
 A = [1, 2, 3, 4] deleteat!(A, 2) Results in A = [1, 3, 4] in Julia 0.3.4. Remember that Julia uses 1-based indexing.
Oops forgot bout that. But still Idk why it says deleteat! not defined 
You're probably working with a two-dimensional Nx1 matrix instead of a vector. You can convert it to a one-dimensional vector with `vec`. It's a little tricky that Nx1 matrices behave very differently from N-element vectors.
I suck at reddit formatting obviously, but I wrote code that does what was asked, who would downvote something like that? function RunMax(a::AbstractVector, f::Function) local mx = reduce(max, a) for i in 1:mx f(i) end mx end I thought max would give the max value of a vector, but I tried it and it didn't seem to work. extrema() will give you the min and max of a vector however. 
Four spaces creates an indentation for code. max is not a function in Julia, you have to use maximum. That I know. I was just asking how to (optimally) convert the output (an array) to a scalar.
From Julia 0.3.5: julia&gt; a = [1,2,3,99,4] 5-element Array{Int64,1}: 1 2 3 99 4 julia&gt; upper_limit = maximum(a) 99 julia&gt; typeof(upper_limit) Int64
That is weird. I am going to have to try again later. Thanks; I will return.
I think you are right, and lookitsmarc also pointed this out above. Something weird is probably going on, and I mistakenly attributed it to the maximum-function. Thanks for taking your time helping me out. (and thanks for the ary[1]-tip).
So what was the problem ultimately? Were you passing in a multi dimensional array?
I found the reason with all of your help. I am not too used to types, and I was trying to do it on an airplane without internet connection. I have a vec=Vector{Float64}. This is processed, and in the end I apply ceil() to it. This was obviously still Vector{Float64}. maximum of that vector gave me a Float64, which I then wanted to be an Int32. Without an internet connect, I came to the wrong conclusion that Int32[maximum(vec)] was correct. I had the following max_x = Int32[maximum(data[:,5])] which is obviously wrong (and returns an Array{Int32,1}), and now I have max_x = convert(Int32,maximum(data[:,5])) which gives me what I need. :)
Thanks!
Concatenation has been deprecated within vector `[]` lists. `[1:4]` and `[1:2, 3:4]` still return the vector `[1,2,3,4]`, but they now throw a warning that this behavior will change — and all the code is in place to do so. Jeff describes the new behavior very nicely here: https://github.com/JuliaLang/julia/pull/8599#issuecomment-73548075 The plan is to turn on the new semantics before 0.4 is tagged.
Thanks. I eventually went with a somewhat clumsier solution - defining "Foo" as a non-abstract type and adding a variable of type "Foo" to both "Bar" and "Baz" - but these traits look interesting. 
These look like fantastic notes/site, thanks for posting! I know I'm being greedy but is there an epub/mobi version of the book, that'd be amazing (calibre conversion of PDFs sucks for coding books)!
Wow thanks for sharing! Great resource. Glad that there is an accompanying Python PDF book, too. 
Personally I find the code completion/parameter suggestion invaluable in IDEs
Try [Glob.jl](https://github.com/vtjnash/Glob.jl). I found it via GitHub [language search for "glob" in Julia](https://github.com/search?utf8=✓&amp;q=glob+language%3AJulia&amp;type=Repositories&amp;ref=advsearch&amp;l=Julia). Pkg.add("Glob") using Glob cmd = `a.out $(glob("*.txt"))`
Ooh thanks, I missed that merge.
I took one of my purging programs and translated it line for line into Julia. Very good learning experience 
Thanks for the reference... this is a little frustrating, especially when i was so used to the matlab element-wise or behaviors.
Very recently learned of Cython for python which allows you to manually make a lot of the static type optimizations Julia is inferring, so I don't need Julia just yet. Seems like a solid language though, once I get around to it.
Numba is another python option that can provide good performance. But Julia provides a more seamless transition between high-level moderate performance and lower-level high performance code, in my opinion.
yep i also agree with your sentiments. I've started using julia for some pet projects but I'm still more productive in R and can leverage the wealth of packages. I know there has been some solid efforts to call python/R from julia but I'm actually hoping for a robust implementation in the reverse direction. I'd like to (temporarily at least) write certain portions in julia that I can call similar to calling C/C++ to ease the transition into higher performance code, then as julia continues to mature move more over. Frankly, the other thing lacking in Julia right now is an IDE even near the robustness of pycharm/Rstudio. IJulia just doesn't cut it for me when I need to handle debugging or managing larger projects.
Indexing in Julia is done with `[]`. Also, Julia distinguishes between operations on arrays and scalars with a `.` – so what you want here is A[A .&lt; c] = c
You don't actually call the function yourself (at least not in the conventional sense). The function will receive the results of each iteration of the loop, in pairs, something like the following: * Get the first two iterations, pass them to the function to 'reduce' them. * Get the next, pass it to the function along with the previously 'reduced' value to get a new 'reduced' value. * Etc. So what you're looking for is a function that takes two arrays and returns the elementwise minimum, and that function is `min`. So that should suffice for you: @parallel min for i in 1:n (...) end
There's [@timeit](https://github.com/kbarbary/TimeIt.jl)
I'll check that out thanks :)
Perfect, thank you!
Good to know, thanks!
No problem! If you use Jupyter/IJulia notebook there's a builtin @timeit function that you can use also.
Ok thanks! I don't really care about preserving the shape of A (I guess I could reshape it) Now, if A is multidimensional (say a matrix) and I want the functions to take columns of A as argument, would something like pmap(A[j, :] -&gt; f(A[j, :], b, c), 1:size(A)[1]) work?
No, the input to the function will be the elements of the iterable in the second argument to `pmap`. If you have a list of indices in the second argument you have to write a function that will expect an index. Such as j -&gt; f(A[j,:], b, c) If you try writing something like A[j,:] -&gt; f(A[j,:], b, c) in the REPL you will be chastised for invalid function argument names. You can't name a function argument `A[j,:]`... And just for the record, `A[j,:]` is a row, not a column. Also, I think `size(A, 1)` is considered better style than `size(A)[1]`. `mapslices` will do what you want in a cleaner manner, but it's serial.
IJulia doesn't do anything with the code. It just passes it on to Julia, which then treats it as any other Julia code.
Thanks!
0.4 is the "break everything" release, which means everything's a bit up in the air at the moment, but the idea is to get things right now so that they don't have to be changed again. Once 0.4 is out things should be a lot more stable, and 0.5 is likely to be a lot less disruptive (if not completely without breaking changes). That's probably a few months or so away. If you're looking for *absolute* backwards compatibility you're going to have to wait for 1.0, the timeline of which is essentially "we get there when we get there". Actually though, the changes aren't that bad for the most part; at the user level it's mostly just a few syntax tweaks, so it's not like you'll have to refactor entire programs. For my money, having to tweak syntax occasionally is totally worth it to not have to wait to use Julia, but it comes down to a judgement call.
I believe it would be wise to wait for a reasonable debug system before considering a long term commitment. The current debug facility of julia is just a temporary solution. It looks as if developers may need to modify a lot of internals in order to be able to provide usable debugging utilities.
To build on what csp256 said, I guess the sort of competition (games) that Julia programmers are interested in are those such as the following * Competition between languages for the best speed-vs ease-of-use [tradeoff](http://julialang.org/benchmarks/) * Competition to make the best tool for [optimization](http://www.juliaopt.org/) * Competition to simulate quantum systems the [quickest](https://www.youtube.com/watch?v=S3tLgDU74XA)
Julia is optimized for batch processing of large volumes of numeric data, it doesn't guarantee it won't stop and have a short break ro run its garbage collector. For game dev you ideally want a language that gives you tighter control over memory management, since you want to run your update/draw cycle 60 times per second. Nim, for example, allows you to run the GC manually for specific duration, since it was designed with gamedev in mind.
I'm not sure why people are saying that Julia isn't "for" game development. Remember people write games in Python and Javascript. Julia is a compelling option anywhere that performance and ease of use are both valuable, so game development (especially for hobbyists) seems pretty much a perfect niche to me. It's not going to replace C++ in triple-A game shops, no, but GC'd languages like C# are very popular at any level below that. To answer OP: yes, as you say, it's a case of Julia being very new. In general, if you want to do anything outside of numerical stuff right now, you're going to have to implement a lot of the libraries and things you need from scratch. Which isn't to say you shouldn't try! A lot of us are doing exactly that and find it very rewarding (the journey is more important than the destination, and all that). You might even find that other people start to help you out. But if your only priority is to get a game out the door, chance are you want to look somewhere else.
Don't get me wrong, I'm not saying 0.4 will come out and Julia will suddenly be finished, or anything like that. I just want to emphasise that the slightly painful 0.3/0.4 transition isn't representative of all future upgrades. Funnily enough, a lot of the biggest projects have the least user-level impact. e.g. changing array/dict syntax is pretty trivial but breaks absolutely everything, whereas huge internal changes like a new GC or revamping the type system are only going to affect you if you're doing something pretty obscure. I'm sure 0.5 will have a ton of great changes, including breaking ones, but they're much less likely to bother average joe.
Julia would work out really well for game dev in a general sense. It is new though, so there aren't many engines and libraries wrapped with it. You could make something from scratch with OpenGL and glfw, or you could wrap something like bgfx's C interface. 
The painful stuff isn't even done yet, we'll see how much of it will make it into 0.4. Indexing as views? Changing the way transpose works? Changing array literal syntax to not be whitespace-sensitive? Big, breaking, hard to support before and after with the same codebase, still not done.
What platform? As long as your version of git is 1.7.3 or newer and on your path, you should be able to take out the bundled git without too many problems. &gt; If it's not a hard dependency It is a hard dependency in that it must be installed for the package manager to work (eventually it will be replaced with libgit2, but someone needs to make that happen). The exact version number that is distributed in the OSX and Windows binaries is not too critical though. &gt; could the installer have an added option to not install it? If you submit a PR to modify the installer accordingly, maybe. 
here's a thought: don't try to watch programming videos while washing the dishes?
surely a good talk should be understandable in as wide a range of conditions as possible? i'm a native english speaker; perhaps someone whose first language is not english would have similar issues even when not doing the dishes? and that would be a pity because it's a good talk that really shows the important bits of why julia is so useful. also, and maybe i'm being over-sensitive, or can't take criticism when i give it out (in which case, sorry), but your comment seems smart-assed and gratuitous. why the fuck shouldn't i listen to technical talks when doing boring housework?
I have the same problem when doing the dishes / brushing my teeth / riding the bus / walking on the street. Talks and podcasts should aim for stable volume and good pronunciation.
[The talks I listen to](http://longnow.org/seminars/podcast/) aren't very technical, so the audio is enough.
I had trouble understanding her as well.
Maybe not anytime soon in triple A game shops... but using a higher level language, with C-like performance, which can wrap c++ libs, seems like it could be productive. Where's your greed??
Unity is in C++. Mono is just the scripting layer. 
Greed is an interesting take. Why would a greedy video game developer not just use Unreal Engine? It has god-only-knows-how-many thousands of hours of development time behind it... and is free to develop in, with a *very* reasonable licensing schedule. I can't imagine a rational, greedy game developer choosing to start from scratch with Julia any more than I can imagine them mandating their developers work through SICP and code exclusively in LISP. It might be better, with enough investment, but that actor is already in a hell of a local optima...
Whoops, good point. The vast majority of games that use Unity are using it via C# though, not C++, aren't they?
I was imagining wrapping around a C++ lib, e.g. unreal, and writing the game (types/methods) in julia. Of course, you have the two language problem but it may be easier to iterate.
&gt; Why would a greedy video game developer not just use Unreal Engine? Because writing in C++ is a pain in the ass? People generally do it because they currently have no other serious real option (except for the HPC crowd that writes in modern Fortran), not because they want to. There's a bit of a community growing around making game engines in Rust which would be a step up from C++ and avoid the GC concern. I personally feel like Rust doesn't strike a great balance of usability vs performance though, so anywhere you can afford a GC (pretty much anything except the core graphics rendering, really - and I don't think of that as being too allocation-heavy, but it's not my area of expertise either) I think Julia would be more fun to write in. But then quite a few game engines already allow scripting in Lua, which is also pretty fun to use and has a high-performance widely-used JIT implementation. Every now and then I wish that all the effort that's gone into scientific Python libraries over the years had been written in Lua instead, ah well.
[version 3.7](https://github.com/JuliaLang/julia/compare/v0.3.6...v0.3.7) is out
I was thinking of unity, hmmm builds systems could be an issue.
I know I will use it for my research whenever speed is important. For general purpose computing and data analysis, I'll stick with Python for the time being.
julia will really catch on when you can compile your scripts into callable libraries from R or python or whatever.
Fair – don't get me wrong, I'd love to see Julia become that capable in future. The main issue I see is that it's a language problem, rather than a library problem. Libraries will inevitably be written by somebody, but something like a manual memory management story has to be done by the three or so people who know how to (and it's not like they're short for work already). So it's more a case of being greedy in my wants, but cautious in my promises.
http://en.wikipedia.org/wiki/Hype_cycle That the hype has died down doesn't mean Julia has too; just that we've passed the ol' peak of inflated expectations. Julia is a very, very nice language in principle and a really impressive piece of technology on its own, hence the initial hype. But to be generally useful to people you need a huge wealth of libraries and tools. Julia doesn't have that yet, and won't for at least a few years – it's a gargantuan task. But it's still growing at an accelerating rate and I think it will happen. Not only that, but I think Julia makes library development much easier on new developers. Where people are put off by Python's C code and wrappers they'll find Julia's libraries much easier to hack on. That means we'll have more libraries like JuMP which are not only on par with the competition but represent the state of the art. Once that happens it's a no-brainer. Where the best libraries are, the users will follow.
I guess you're on Windows? There's been a fair bit of work on that. You could try is checking out a [nightly build](http://julialang.org/downloads/) to see how much things have improved – if there are any more issues you still have time to complain ;)
I should say that Julia is already catching on for its age. I've met multiple people in person who have heard of Julia, which wouldn't be the same for languages that have been around a decade longer. I think with compile caching, solid multi-threading, and a very good IDE Julia will make a very large impact. If you look at something like Unity, there is no reason that C# couldn't ultimately be substituted for Julia.
Oh, yeah, backtraces should be totally fine on Linux – you won't even need to use a prerelease. Most of the core devs are on Unix-y OSs, so for better or worse support for that kind of thing tends to be better on Linux and OS X first. (That's not to say that good Windows support isn't a really high priority, though.)
I love Julia and I'm using it for my main projects now but I'm still very much frustrated and put off by missing essential functionality, in particular a robust, easy, multi-dimensional interpolation function. The much-touted parallelism is also a bit rough. As long as you can wrap everything into a pmap you're fine, but trying to figure out which variables are available to which worker when is a bit scary.
No
I've been learning Julia so that I'm ready to use it full time once I can and the language is more mature. The big missing feature for me is shared-memory parallelism, and thankfully they're working on it: [ Parallel Computing Planning Issue #9167 ](https://github.com/JuliaLang/julia/issues/9167). *^(Admittedly, I tend to think they should spend more time working on this so I can use it, but that's totally selfish bias :-p )*
I've been developing a simple 2D game engine in different languages and my impression when dabbling in Julia was that it was very well suited for this kind of stuff. I wrote about some of my experiences here: http://assoc.tumblr.com/post/71454527084/cool-things-you-can-do-in-julia Basically multiple dispatch in julia is very useful for the sort of things you do in game programming. You often want to have specific things happen when two object of different types interact e.g. a collision between a triangle and circle. Also a game needs high performance and need to make it easy to experiment e.g. to hash out what a game level should be like. A script language is thus suitable. Usually Game engines solved the problem of needing high performance and interactivity by making the Game engine in C++ and the levels in a script language. With Julia one can perhaps do the whole game in one language.
Don't think adoption is really going to take off until one reaches a 1.0 release.
julia is a far too nice dynamic/scripting language to be relegated as language to write libraries of less nice dynamic/scripting languages (looking at R). 
Julia has been growing, despite the drop in 'excitement.' My impression is that the language is headed towards being the go-to for data-science, but it's just so early in the development phase that very few people are willing to use it for production. Remember: Python is 24 years old now. Julia is only 3 years old. It's still a toddler.
So say you have an array x with elements [1,4,3,4,4] and you want to find the indices where it equals 4 you can do this using the find function. julia&gt; x = [1,4,3,4,4]; julia&gt; f(x) = x == 4 f (generic function with 1 method) julia&gt; find(f,x) 3-element Array{Int64,1}: 2 4 5 You can also do it with an anonymous function julia&gt; find(x -&gt; x == 4,x) 3-element Array{Int64,1}: 2 4 5 You can also do something like this julia&gt; [1:length(x)][x .== 4] 3-element Array{Int64,1}: 2 4 5 
Check the threading branch for the latest work-in-progress.
Yes
As a consequence of thinking about it, I looked into it more and plan on downloading the threading branch at some point and playing with it.
Ahh...yes I think about that. The docs said that ```find``` was used to find the non-zero indices. It didn't occur to me to use a bit array
You have to walk before you run. Building a huge triple A game in julia is not going to happen right now. Someone could though do something like love2D pretty easily and make a very simple API for making and prototyping simple games. That would still be a lot of fun and very useful. Pulling in other libraries would be easier, the game code would run faster, etc. 
Interestingly, the output from typeof is different that the type given by the inline popup in Juno: Matrix Number 32x32 for initialMatrix and Matrix Float64, 32x32 for Hamitonian Here are the outputs from typeof: typof(Hamiltonian): Array{Float64,2} typeof(initialMatrix): Array{Number,2} typeof(t): Float64 As you probably guessed, one of these matrices, initialMatrix, has complex elements.
Wow, yeah that helped. I made everything Complex64 and the execution time went from 12sec to 1.8 seconds. It is now barely slower than matlab. Thanks! On a related note, when I @time my script, it says that 10GB are allocated, is that accurate? I do not even have that much RAM...
Thank you very much! It gives me an insight to the use of functions for finding element!
Note that Complex64 is 64 bits total, it's single precision for each of the real and imaginary components. You probably want Complex128 for double precision of each component. BLAS doesn't have fast mixed-precision multiplication, so most likely there's still some conversion happening to get all inputs to gemm to be the same element type.
Is this also true for arrays, though? Using array comprehension will generate typeof-s that are fairly abstract, for example, and then calling functions on them will be slow. I thought typing stuff was recommended for performance in the manual page on improving performance.
Types on function declarations are for dispatch or error checking, not performance. Types on data (especially fields of composite types), writing type-stable functions, annotating element types of array comprehensions, etc, that's for performance. But on the declarations it's only a statement of function applicability, does not influence the code that gets generated.
April, come Wednesday.
Well this is one area in which I think Julia is doing okay. Julia Studio seems pretty good - better than a lot of options for Python (but not better than RStudio).
Julia Studio is a defunct project unfortunately. Juno is gradually improving over time though.
Julia has a convenient macro @time that will tell you how long it takes to run any piece of code. 
Use `@timed` if you actually want to do something with that time other than printing it the way Julia does.
And how do I use it?
This isn't really an answer, but it's easy to implement a string macro which might help: macro s_str(s) Expr(:quote, symbol(s)) end s"temperature (K)"
Hahah, I actually wrote this exact macro, except I tried to use `:` as the prefix and obviously it wouldn't parse. Because I'm an idiot I didn't think of just using a normal letter...
Yes, see `help(eig)`
A good IDE is a lot of work to create, and won't materialize magically unless someone works on it. And cross-platform GUI toolkits are an absolute pain in the ass to work with. Same with a source-level debugger for a JIT-compiled language. At the moment, if you're unable to get any work done without a professional-quality IDE, then of course Julia isn't for you yet. Everyone recognizes the need for better tooling to encourage widespread adoption. For now though, plenty of people can get work done without needing an IDE (worked fine for Ruby...). If you want it to happen faster, then work on it.
&gt; What I am affraid of is that the same thing will happen to Julia. It is currently being developed without considering the possibility of being interfaced within an IDE. This isn't quite accurate. First, there are already several IDE-or-similar projects that interact with the Julia core in several slightly different ways, including Juno, IJulia, Sublime-IJulia, and a very nascent (and for now defunct) Gtk-based GUI called Julietta. Second, Julia is MIT-licensed, has a decent embedding API, and the line-edit code underneath the REPL is pure-Julia. The embedding API is already used for various purposes including calling Julia from Python and Node, and from C programs. I'm not familiar with the Octave issues, but I would guess that some design decisions were driven at least in part by readline and/or licensing considerations which don't apply to Julia. As far as debugging support, it is coming along. You can step between Julia and C code with (mostly-correct) line information in LLDB or GDB. If you build against LLVM3.6 (or svn), some Julia variables also get DWARF annotation. So that stuff is definitely in progress. Fleshing it out and hooking it up to an end-user-friendly interface will take some more time/effort, but the path to get there is understood.
I've been living in matlab for years, and I have just started using Julia. I'm loving it. (I'm having some teething problems with Juno, but I'll go command-line happily to keep using it...) TheMathWorks should be worried at this point, I think. 
Submission deadline for JuliaCon is next week, the 8th I think?
Interesting point. Most users of R and Python don't have a true need for speed in their own code. If they become power users and get to the point where the performance of their own code limits them, there is then a high cost in switching to a new language.... 
I've now been using Julia for 3 days. It's wonderful. I am never going back to Matlab. Sorry, TheMathworks, I was a loyal customer for many years...but oh the joy of writing for-loops without guilt, a decent Collections library, applicative maps and comprehensions, and speed, speed, speed. The graphics look great too. I'd like to say a big thank-you to all the people who have developed Julia and Juno! Juno is particularly slick. I'm using Winston graphics at the moment: the plotting is really fast. Gadfly looks nice too. I had a problem with packages not loading correctly in Juno at first, but I worked around it by installing command-line Julia, and loading the packages using that. All that delayed me by at most two hours. Some of the packages seem really slick -- Distributions in particular. Others are still immature. I think this language will succeed. 
&gt; but who really uses Matlab outside of academic settings? The vast majority of engineers in the aerospace and automotive industries, just to name a few. Source: am an aerospace engineer. Work with automotive engineers. All use Matlab, pretty much exclusively. Mostly because of Simulink, which doesn't have any decent open-source equivalent for hybrid-system simulation, hardware-in-the-loop testing, and embedded-system code generation.
As my last name even starts with "Con," I find all of this rather unsettling. 
I take this as a vote against the title of the sticky post. 
I don't know if you are allowed to change the csv files (or can make a copy), but I would probably use perl to change the " " in the headers to "_". That would make the julia-part much cleaner.
The multi-threading branch and master are slowly converging: https://github.com/JuliaLang/julia/pull/10623 https://github.com/JuliaLang/julia/pull/10735 
Try `BLAS.gemm!('N', 'T', 1.0, h, v, 1.0, dw)` instead of `dw += h*v'`
Just got me thinking about Julia's emphasis on good language design combined with a simple compiler.
Nicely opinionated presentation.
It may be true that Python has larger head start, but Python is also a popular general language with a large ecosystem. The longer it takes for the Julia community to pick up speed, the more time Python has to entrench itself in science programming (at the cost of Julia adoption).
And, as long as that's the case for others. Julia will never overtake Python. If people have an easier time to general computing with Python, they have no practical reason to switch. Julia may be fast, but Python code can be optimized very well. Not to mention, the Python ecosystem can muster a lot of effort towards speed if that really becomes the defining issue.
SciPy is already killing off Matlab. The question is: can Julia really compete with Python for science programmers who already depend on Python. EDIT: typo.
I understand that when writing code with matrices and vectors that [devectorized](http://www.johnmyleswhite.com/notebook/2013/12/22/the-relationship-between-vectorized-and-devectorized-code/) julia code is faster than vectorized. Is there a consensus as to how devectorized julia code compares to BLAS? 
The paper: http://mrkulk.github.io/www_cvpr15/
Love the extensibility that can come from a flexible fast language. It will be interesting to see how Julia is used as a _platform_ to develop DSLs.
Computer Vision and Object Recognition really seem like tasks that are theoretically possible, but entirely impractical. An yet just today I was playing with Autodesk 123D Catch. It made me wonder how much each of the objects I captured cost them in computing time and electricity. For example, to model a 3-legged stool, I snapped about 100 images. It took 5-10 minutes to process, then returned me something that had even accurately rendered the bas-relief carving on the surface. Similarly, I looked at my parents' house on Google Earth, and all of the trees in the area are modeled in 3D.
It might. But at some point soon, the authors need to stop fiddling with the standard library. People won't feel comfortable building meaningful software when there's an expectation that there programs will break on each language release. While most people here seem to focus on Python and Numpy, Python's a bit player in the technical computing world. It differs from industry to industry, but in many engineering disciplines, MATLAB is king. I would love for Julia to become a serious competitor to MATLAB, but MATLAB's IDE, toolboxes, Simulink, etc., are light years ahead of Juila at this point. Julia won't get a competitive ecosystem as long as we're building on shifting sands.
I've had a similar experience anytime I've tried to do something nontrivial yet parallel in Julia. I hope somebody is able to answer you! :)
True, but that's what 1.0 is for - www.semver.org. That's at least a year or two out.
The idea is to also start creating notebooks showing data analysis on those linguistic data sets using Julia. We'll see if I have the time for that.
This looks really great, thanks for sharing! I'm a grad student in CompLing/NLP, and I've really been enjoying doing small personal projects with Julia on weekends for the last few months. I'm looking forward to trying this out!
at MIT. Here's the actual conference page: http://juliacon.org
Pretty sure that lesson was learned after last year.
I hope so. No one should feel too bad though since it seems to be such a common mistake.
I tried everything I could find/think of to change the pointer. Finally just uninstalled, disconnected from the network to isolate myself from the network drive, and reinstalled. Ran Pkg.update() and Pkg.add() to get IJulia with no problems. Seems the git pointer is on my C: drive where it should be now.
Has anyone here played with "Picture" (the language they've created/proposed)?
Agreed.
https://github.com/moon6pence/Euler.jl
Posting your solutions online is actively discouraged by project euler. Please consider making you repository private and removing the link to it.
They do not have domain over him. He can do what he wants.
The way I've been running it is actually in what I used to know as IPython notebook. It's called Jupyter: https://jupyter.org/ You install IJulia and Anaconda (or equivalent packages), and then you can run Julia in the notebook. I think there is R support in there also, but I'm actually not sure if you can move between one and the other in the same notebook.
Try Processing: http://openprocessing.org/sketch/68716 https://processing.org/tutorials/
I'm 99% sure we are mic'ing presenters this year. Was a big oversight last year for sure.
Oddly enough, it turns out that I tried to add the images package while at work and got the same error again. So, it's not an installation issue because pointers will apparently change depending on whether a network drive is visible or not. ENV["HOMEDRIVE"] while I'm here goes to an H: drive, whereas at home it's on the C: drive. Pretty odd that this is the default behavior.
I'm starting to wonder if this is a Windows variable that is passed to Julia, and not necessarily a Julia issue, per se...
Changed the Pkg.dir() to the install folder (on my C: drive), but the git repository is still pointed at the network drive and still fails. I'm slightly worried that this is going to wind up being a Windows thing, and I'm not going to try to change Windows settings for fear of breaking whatever IT did when they set up this machine. Looking for a workaround.
Try setting `ENV["HOME']` to a local folder on C before doing `Pkg.init()`
I was in your position about 2 years ago, and spent some time with Julia as a starter language because a friend of mine told me it was the up and coming thing for scientific computing, which is what I'm doing - I figured I'm probably only going to be proficient in one language, it might as well be the one that's going to be the best. But when you're learning, you're going to be struggling enough with trying to think programmatically, and with the difficulty of learning any language, you don't want to worry about struggling to find the answer to basic questions. With Julia, it's so new that a lot of the documentation (that's basically the instruction manual) isn't super readable for a beginner, and there aren't a ton of forums where people have asked all the stupid questions. Also, it's new enough that stuff is changing pretty frequently, so if you're googling and you find some old docs or an old forum post that are outdated, it could send you down some frustrating blind alleys. I ended up switching to python as my first language, and I think it was a good choice. Not because python is a better language - in fact, I could probably do everything I'm doing now in Julia, and it would probably be faster. But nearly every single question I've had about how to do something in python could be found by literally googling "how to X in python", and there are like 10 different posts solving the problem in 10 different ways. This is important, since there are often lots of different ways to solve a problem, and being exposed to different ways of thinking is really helpful. Also, there are a ton of beginner resources to get you stated, beginner problems with detailed and well documented solutions in just about any area you're interested in starting. I still hope to come back to Julia (which is why I still subscribe to this sub) once I'm a bit better at programming and Julia is a little more mature - I don't think I'll ever be a good enough programmer to be at he bleeding edge. And the good news is, learning a second programming language is a lot easier than learning the first. But for now, nothing I'm doing really needs to be optimized for speed, and having so many resources a google search away is a life saver.
Alright thanks for the advice. I was along the same line of thinking as you were until I read your post. Also my name is Julia so I was drawn to it XD. I'll start out with python but I really hope I can one day learn Julia too. Thank you all so much for all your advice!
No problem, good luck!
a better query than "how to X in python" in google is "site:stackoverflow.com X python" usually gets better result (of course you can directly query http://stackoverflow.com with a qery like "X [python]")
Wow, a few interesting answers here. Julia is used for mathematics, don't try to use it for learning programming. Instead, go to Codecadamy and take the python course. http://www.codecademy.com/tracks/python
Okay, thanks a lot! It means a lot to me that you responded! I'm a lot less confused now.
Usually the top result is stack overflow anyway.
I had this problem with stuff, I had to use https instead of ssh. This is the command I ran to set up git to use https instead of git:// git config --global url."https://".insteadOf git:// It has worked fine for me on my overzealously firewalled connection since, and it was only the julia git connection that was having issues.
Whoa, support for 6-8 students for a "Julia Summer of Code" courtesy of the Moore Foundation! https://groups.google.com/forum/#!topic/julia-users/bolLGcSCrs0
&gt; git config --global url."https://".insteadOf git:// Had to wait till today to try it out, but it worked! Thanks for help!
The key is the amazing strength of machine learning / weak AI / probabilistic methods. My intuition screaming "bullshit!" to the results of a field have gotten me interested in it before... if you feel like you have a similar itch, check out http://szeliski.org/Book/ and http://www.computervisionmodels.com/
From the first line of the [Julia webpage](http://julialang.org/): "Julia is a high-level, high-performance dynamic programming language for technical computing, with syntax that is familiar to users of other technical computing environments." In other words, the current focus is indeed on academics and data scientists. Also, I don't think you really intended this so literally, but I wouldn't say that "Matlab users have for years and years" been "mostly focused on achieving better computational performance." Matlab is a high-level language for rapidly developing algorithms, some of which run quite fast. Matlab's performance is acceptable to many, but except for code that's mostly linear algebra, there are usually alternatives that can do better. In development time vs. execution time, Matlab favors the former.
Short answer - yes at the moment, but the community tries pretty hard along the way to encourage better software engineering practices like unit testing, version control, package management, documentation, etc. Immutable data structures are a perfectly valid way of eliminating shared mutable state, which is undoubtedly a cause of many correctness bugs. However it incurs a pretty major overhead of memory allocation, so can harm performance quite a bit. Julia actually goes out of its way to provide "consenting adults" in-place mutating versions of most functions, to give expert users a way to reduce memory allocation and extract every last ounce of performance out of an algorithm.
Ah okay, thanks. Then i'll probably use the REPL for development.
The `Pkg.generate` function creates a new package with a specific directory layout (specifically: `src` and `test` directories, and a `test/runtests.jl` file). But this is for packages -- I am not sure if something similar exists for modules which are meant to represent a full package with a `main` function.
This is just my naive assessment of things, so it might not be totally accurate: Its pretty squishy in comparison because the runtime includes an interpreter and a compiler that does a lot of normally up front operations as your code is loaded. Go's package namespace is strongly bound to the filesystem and dvcs. Julia really does not care about the file system natively; it just evaluates definitions and expressions in a top level namespace to build up an environment. However it does have a package manager module that you can use though I am not really all that familiar with how to actually develop a new package with it. Most of the documentation refers to a workflow for modifying and managing existing packages. It isn't really clear from the manual exactly what julia does with local only packages, or if they are even possible. Its really not very intuitive or well documented. Not a gripe, just a casual observation. A less complicated but also less precise method is to have all of your source files in the same directory, with one main module that essentially builds up the namespace by 'using' source files containing modules with the same name as the source file. Along side this you also have a 'test' module that 'import's things and applies testing logic to it with assertions and the 'Test' module that contains a bunch of convenient macros for unit testing. Essentially, there are a lot of options for a lot of different workflows (package development versus script/tool development) but there isn't really a most general system. The julia runtime is more like a smalltalk or erlang vm where you kind of build up an environment of independent components and tie them together in a sort of ad hoc manner. IMO, this is a pretty big blemish on an otherwise stellar programming environment. I usually use a more interactive workflow where I explicitly build up the environment of my program with an initialization script, and then pull in my other code with 'using' and 'import'. I am kind of in the same boat as you looking for clear 'best practices' project structure. Atm I am just going through all the julia packages i can find on github and trying to mimic what they are doing. I hope someone with a better understanding of this stuff will reply as well because I am also interested in a more definitive answer.
Run Julia in a Docker/LXC container? Or you could hypothetically try inserting a filtering layer at the llvm level to turn all c or system calls into errors? Not sure how feasible that would be to implement right now.
Ok. I was thinking more of something at the language level that modifies how the base system is loaded, or maybe being able to explicitly pass an environment to a function invocation ala lua's setfenv() function that does not include the Core or Base module. The idea is to construct a language level containerization rather than relying on OS or llvm level intervention. The whole JIT and runtime code loading stuff kind of suggests a language level isolation solution waiting to be implemented. I was hoping that maybe some primatives for this were already a part of the reflection library or something.
Not yet AFAIK. But if you want to start hacking at things to see if it's possible to "turn off" filesystem access and ccall, I'd say have at it? I don't know how you would run code at all without being able to read from the filesystem, maybe entirely via the embedding API?
Project Euler is a great way to practice programming in new languages. I currently solved about 87 problems out of which I solved 8 in Julia. Planning to increase the count of Julia solutions. When I am figuring out solution to a problem, I start writing python because I am more familiar with it and want to reduce the cognitive load writing code in Julia - I just need some more time getting comfortable I think. My friend key: 253612_b420fdc678a1ed31f6266ba38ff26002
Here's some similar discussion: #[9744](https://github.com/JuliaLang/julia/issues/9744)
Its not a very useful discussion about it though. They say things like 'Julia can do whatever c can do so no' but that is pretty naive. Most of the really low level crap is exposed as functions imported in to your modules namespace at and you can remove modules from the namespace your code has access to. There is even a baremodule construct that does not import core or base by default, so you can essentially whitelist safe dependencies so long as you can restrict the user from loading additional code. I do not think there is much at all beyond using and import baked into the syntax itself that could circumvent this, so you can just refuse to evaluate any code with those constructs in their ast, or proxy the functions they actually call to find things on the filesystem (quite a lot of other syntax also relies on library code). that nobody seems all that interested or knowledgable about these sorts of things while also having extensive knowledge of Julia seems like the real reason. Just having access to the ast and an evaluator alone means you can get in between every Julia language construct and the functionality in the runtime that it calls I to. And that's generally how sandboxing works.
I encourage you to join the conversation on github with any positive contributions you might have :)
Sorry about that. That was an outlash of frustration more than anything. There actually are some very important (if not immediately useful) things about the sort of code isolation I am interested in that RFC. I see some concern that such a thing would somehow be a burden on how the language develops at large while not being something that the community at large cares about. I have some vague ideas as for how it _could_ it self be completely orthogonal to these worries. When those ideas are a little more coherent I will definitely take them over to that RFC. 
That would be awesome.
`A[row, i:i+k] = c` ?
Here's the [blog post detailing it](http://julialang.org/blog/2015/05/jsoc-cfp/).
Same thing here. I solve every challenge exclusively in Julia (and posted a few of the more elegant solutions in the forums) - if anyone interested still comes across this thread, feel free to add me: `690010_e63469c6bdf3c952b9c4ca5d9b139559`
Anyone going on Wednesday?
https://github.com/JuliaLang/julia/pull/10525 merged! 0.4 roadmap now at https://github.com/JuliaLang/julia/issues/11536, starting to check a few boxes off
Use juno, for lighttable, better thab repl.
There is an example package here: https://github.com/JuliaLang/Example.jl
I'm now with Julia but I noticed that this problem doesn't occur when using IJulia, could someone explain to me why that is? My code is simply x = 573; println(x) and takes about 2-3 seconds when I run it through the command line but is instant (as you would expect) when using IJulia.
A nice extension of this would be to implement the iterator methods (`start`, `next`, `done`). It's fairly straightforward and gives a good sense of how interfaces and polymorphism work in Julia – and you get a lot of methods from it for free, e.g. `collect`, perhaps also indexing. Lazy sequences are essentially the same concept, but if you tweak the implementation you can define them in really elegant ways. Treating the stream as data (so that you can map, index etc., as opposed to just traversing once) is also nice. Check out [Lazy.jl](https://github.com/one-more-minute/Lazy.jl) if you're interested.
this is cool, but just in case you didn't know, julia has generators already - http://julia.readthedocs.org/en/latest/manual/control-flow/#man-tasks - which can be used in a similar way.
they seem to be pretty heavyweight - intended more for communicating between threads perhaps? on the mailing list people mention them, then generally say performance isn't great. but they are complete coroutines - you can send and receive - and they do work fine. edit: what i mean is, i have never measured how efficient they are, and i am not sure how to read the comments, since julia users tend to be obsessive about performance, so what may be "slow" to julia devs is just fine to, say, haskell users (no offence intended!)
user zeros(Int8, n) instead of Array(Int8, n). the former sets things to zero. the latter just grabs memory, and sometimes it's non-zero which makes your sieve ignore some valid primes. (posting again so you see this as a reply, as my edits in a prev post were cumulative). it's like that because zeroing likely has a cost, which often isn't needed (if the algorithm sets all entries). it's like the difference between malloc and calloc in C.
Thanks. That makes sense. I was assuming that Array initialized zeroes. I've actually been using Array with this assumption of or the last few days and haven't had other problems. I'm surprised that there are so many zeroes sitting in memory. Thanks for the help.
I *think* modern OSs try to give you pre-zeroed memory where possible and only give you uninitialised memory if there's not enough pre-zeroed memory available. **I'm certainly no expert in this area though so take that with a pinch of salt.**
The [Request](https://github.com/JuliaWeb/HttpCommon.jl/blob/0469d901391ad3a991d5652cbad68629b00eace1/src/HttpCommon.jl#L151-L156) type has a `method` field which should contain e.g. "GET" or "POST". So to respond to POST just check what that string is.
i found #2 more understandable than #1. I completely missed the fact that #1 had a database connection even though i read the line. I only recognized it after reading the corresponding part of #2. Perhaps if you randomized the display of the 2 options this could control for this bias of familiarity that I obtained while reading #1. #2 feels a little clunky and heavier since you have to specify things like the type of database but i felt like a had a better understanding of what is going on. For what its worth, I spend my days writing C++ and Julia and rarely touching python.
If you want zeros, use the zeros function.
This is not at all a Julia question. Just look up the answer. There is a fairly simple linear algebra approach, or you can hardcode the recurrence relations. 
It sounds like your professor is assuming some basic programming knowledge/experience, which you do not have yet. Your best bet is to first try solving the mathematical part of the problem, and then seeking any help you can get from the professor or teaching assistant. As for choosing a language, I think Julia is a great choice. I would stay away from C for now if you have never programmed and are trying to do something numerical.
Thanks for the info. Sadly this looks like more hassle and syntax noise than it is worth.
Main question I had: Anyone up for seeing John Digweed Friday night at the Bijou in Boston? It'd be a late night if you're aiming for the Saturday workshop as I am. I'm from a small town though, and need to make use of opportunities such as this to properly get my groove on. 
See also BioJulia https://github.com/BioJulia
Any live feeds for us poor people from Yurop? :)
I contacted the current organizers and was told that if I'd organize a meetup that Forio would host it :-) I guess that in a week or so it will be relatively easy to get some locals who presented at JuliaCon to repeat their talks for us. If no one else organizes such a thing I'll do it.
* Will videos be posted on Youtube? When? * How many people attended? * What talks from people who are using Julia have generated the most buzz? * What core Julia topics are people talking about * What features of Julia do presenters who are relative newcomers to the language like the most? * Where will Jeff Bezanson be located now? Was there any discussion about Julia Computing? 
i can explain this, if it's not clear what's happening. but the manual does a pretty good job - http://julia.readthedocs.org/en/latest/manual/types/#value-types the reason i like it so much is that the code is very clean. when you write fizzbuzz "normally", there's an ugly wrinkle about either repeating a test, or repeating logic. for example, &gt; it isn't possible to directly and simply represent the necessary tests, without duplication, in just about any commonly-used modern programming language. from http://c2.com/cgi/wiki?FizzBuzzTest
this worked thank you.