Will this ever end!? Python has brain-damaged people.
Most of the comments are in Portuguese, but the source is clean enough to read if you don't speak the language. Tanto-faz.
I'm not a huge fan of the idea, it just looked neat. I've learned to look past the parens. Python makes me crazy...
I don't know; maybe I'm used to all the "nail clippings &amp; oatmeal" (to paraphrase Larry Wall), but I find both [SRFI-49](http://srfi.schemers.org/srfi-49/srfi-49.html) and [Sweet expressions](http://www.dwheeler.com/readable/sweet-expressions.html) unreadable.
Can someone put some names on the faces?
The walls are curved - like parentheses.
Anyone know if video will be made available?
Hm. I dont like mixing up Whitespace-Aware Syntax with Non-Whitespace-Aware ones. Still, seems like this gets it better than most other approaches of mixing both types of syntax. Anyway, if you really want rich syntax, maybe a syntax similar to JavaScript would be the better choice.
Just read the part about threading. Overall I think it is too simple: he just describes the problems any language has with MP and why we need things like mutexes. I think it would have been better to explain why Lisp is good (or bad) at MP, for example describing a data-driven approach (correct term?), where you have a multithreaded map-operator that has to calculate an expensive function for each element in the list. Assume that the calculations can be done in any order we can easily achieve a performance gain. 2nd point is that he is using ACL: he says there is no standard for multi-threading (which we all agree on that there should be one), but there are libraries that work across most implementations. He might as well use that one so people can at least try his examples. Overall a bit disappointing.
Seems odd that the book would devote two chapters to a proprietary library, even given the Express edition of ACL. Edit: only two of the four chapters are about AllegroCache.
I knew the Enterprise ran on Lisp!
Only two chapters are about AllegroCache.
My thoughts: * I dislike the heavy focus on AllegroCache and other Allegro specific details. I think that someone writing a Common Lisp book should use libraries that are portable between implementations. * "Require is a Common Lisp utility for ensuring that a library has been loaded into the current session." Does this mean that he hasn't talked about asdf yet? I would think that that would be a prerequisite for using libraries. * I dislike the O'Reilly style of having tips and exercises inline in the text. * There doesn't seem to be much mention of what makes lisp different. It seems that the more advanced and powerful things that you can only do in lisp aren't really used. I'm not sure that this is a bad thing - maybe I've just gotten used to people having to justify using Lisp all the time. * I like that he talks about memory management. It's not something I've really seen discussed elsewhere in detail, and I think it's important to understand. * This book looks very practical, but the examples don't seem very good. One of my favorite things about Paul Graham's "ANSI Common Lisp" is that the examples were small yet non-trivial programs that did something cool (like Henly and the raytracer). I'm pretty sure I'm being too quick to judge it, though. From the contents, it seems there will be more interesting chapters than these, like the one about GUI development. 
I agree. An AllegroCache license is not cheap last time I looked.
1. Cut a hole in the box. 2. Put your lisp in the box.
Not cheap at all, though the Express edition includes a version that is enough to whet your appetite. Still, I'd rather see a concentration on portable solutions.
Not sure this is the answer (sub-lists seem hard to read), but I don't mind the idea of an alternative syntax for Lisp languages at all. I don't see the problem with having _implied_ parentheses. After all, Lisp already has the special single-quote syntax for (quote ..), as well as special quasiquote syntax. I don't see how that's any different than other possible extensions to the reader. As long as it can be translated directly via regexp into a list-oriented abstract syntax, I'd say it's pretty much on part with (quote). Another idea I had once is that if you have a word ending in an open parenthesis it could be read as if it's inside the parenthesis. i.e., f(1 2) would be read as (f 1 2) In the end, of course, I'm not completely sure there's a huge advantage in going to great extents to avoid the traditional lisp syntax, but just to say, I think there are already a few precendents in the language that allow for it.
I think it lacks useful examples. Especially something that grows. He explains lots of small things but it remains unclear why and when I would need it. I'm not a fan of having another book explaining library features without useful context.
There are many examples of a similar notation to yours: [RLisp](http://en.wikipedia.org/wiki/Reduce_%28computer_algebra_system%29), [CGOL](http://en.wikipedia.org/wiki/CGOL), [Caden SKILL](http://en.wikipedia.org/wiki/Cadence_SKILL), Dylan, &amp;c. &amp;c. They are quite popular, have been around for years and work. I've not seen an indentation-based lisp syntax take off, but I might have missed what other people are doing... Anyone herei actually use an indentation-based lisp (SRFI-49, Sweet Expressions, this, Adenine, &amp;c.)?
What's that toolkit ?
*subscribed*
yet another ...
Neat. I wonder why Corman was chosen. It was my impression that Corman was a little lax on ANSI compliance so it wouldn't be my first choice. Does it have some benefits that made this easier?
I think the value add is the facility to attach/detach to/from running images and be able to install, build and invoke applications/systems with ease.
Well, price could have been a reason. Corman lisp is very inexpensive compared to other commercial lisps. Also, besides ECL, it is also easy to embed in another application. IIRC it is just an in process COM object. I guess they didn't think standard compliance hick-ups are not that important to their purpose. 
Corman works pretty good on Windows, intergrates well with Windows stuff (FFI), is pretty fast, small, embeddable. The only alternative I can think of is ECL, but ECL is more aligned with GNU toolchain rather than with MS toolchain, that could be deciding factor. &gt; little lax on ANSI compliance ANSI compliance is probably last thing to worry game developer. 
He is using LispWorks, so the base is probably CAPI with lots of his own stuff added. For example the mailing program draws to PDF, which then is back imported as graphics.
The video player embedded on that site puts a "Mute" icon in the middle of the viewing area when you mute sound playback. That's a terrible idea. I have other audio going and don't want to trample it -- that's what I use mute for. I don't want to choose between an obscured video and turning speakers off.
&gt; where I have to switch and fix between the source file and slime in emacs, for each error ... Emm, you're doing it wrong. There is "compile file" button in SLIME, it does what you want -- after compilation it pops you a list of warnings/errors, without landing into debugger or anything. You can dismiss whole thing pressing "q", you can go to error locations pressing &lt;enter&gt; while cursor is on error description. Also it highlights forms which caused errors in code. You can also compile individual function via C-c C-c. Typically development cycle is like that -- you make or change functions one by one, using C-c C-c to compile them, and fix errors in process. (C-c C-c also makes a list of errors rather then break into debugger.) Then you save and compile whole file via SLIME. (Can help to find "junk" parts of code.) Then if you think it works, you re-start SBCL and try to compile your file in a fresh version and see if it works. If it works, congratulations -- you're done.
I think Corman is also one of the few commmercial-grade Lisps where they'll just come out and tell you what the price is -- none of this "we'll see what you're doing and the come up with a license fee for it" kind of thing. That kind of stuff has greatly discouraged me from considering the commercial Lisps as seriously as I would like. It's also not that high -- about in the range of a REBOL dev license. 
I never ended up using it, but Scieneer is pretty forward with their pricing; LispWorks was as well, last time I looked into it (although I use the personal version at home...). 
LispWorks has a full pricelist online. For example these are the prices for commercial users in Europe: http://www.lispworks.com/buy/prices-2c.html Prices are quite a bit higher than for Corman CL, but LispWorks also offers more. Corman CL lacks usage, despite its low prices for the IDE. Sometimes you can also read that it is less polished. But with more users comes the opportunity to invest more work to improve the implementation. So, I would wish that Corman CL, as a small and lean Lisp implementation for Windows, could find more users. Examples like this game might help to attract users.
Yeah, I am always in this portability mindset. If you are making a game where you are going to just plop an executable on the users hard drive (which is usually the case) I guess you should just work with what you are comfortable with.
There appear to be lists that this implementation cannot specify. + 1 1 &gt; (+ 1 1) + 1 + 1 1 1 &gt; (+ 1 (+ 1 1) (1)) Try to get (+ 1 (+ 1 1) 1)
"SBCL's old PURIFY functionality would have been perfect, because the dataset is immutable." SAVE-LISP-AND-DIE has the same effect, and if that's unsuitable (GC :FULL T) comes close -- and if you need to, you can actually trick the last generation to become fully tenured, but this reply box is too small to contain the technique. Ask eg. on sbcl-help.
Putting the rules on that site would be a good idea.
The rules are on the same page you play on; it explains everything (or should). Is there something wrong with that description? Maybe I should move it to the front page. (There is no description of the truc game unfortunately.) Wasn't expecting this to get reddit'd as it's very much a work in progress. But thanks anyway lispm! Any help, comments or suggestions very welcome. You can see all the source at http://github.com/vii/teepeedee2 Any ideas/contribs of more games very welcome! PS. Demands were being made sequentially; I fixed it with a new macro with-join-spawn/cc, see http://github.com/vii/teepeedee2/blob/master/src/lib/callcc.lisp PPS. Also now players have timeouts.
I was getting confused by the iterative part of the game. It's a little unclear how it works. Apparently you're tracking the number of coins I have over multiple different, unrelated instances of the game? Let me run through what I think when I visit your page. I click "Nash Bargaining Game" and am brought to a page with nothing to do. (I'm waiting for another player to start a game, but I don't know that). It says I have 5 coins? Where did these coins come from? (Are they so I have coins to pay the penalty if we bid too much?) At some point, the page changes with not much of an indication as to why. The "talk" section of the page is confusing; I'm not sure at first as to who I'm talking to, or why I would want to. I pick 3. I get "Game over. Play again? You have 5 coins." What? Did I win? Did I lose? I don't know. Let's play again. I click on play again. Tired of waiting, I click on "unassigned", but I have no idea what this does. What happens when I click it? Do you assign a random number to my opponent's demand? Is there AI that chooses? I choose the max number. "Game over. Play again? You have 3 coins." Oh, there's a history for this instance of the game on the right side of the screen. I didn't see that before. That's helpful. Why's it right-aligned? Most of the action is on the left; that's where my eyes are drawn. Let's play again. I notice there's a wikipedia link, and open it in a new tab. I read about the problem, and go back to your game. "resigned." What? I never resigned! (change this to "timed out" or something more descriptive of what happened). There's still a "talk" link. Who am I talking to? How do I play again? (The "play again" link is in the upper right corner, small and hard to find. You could put it after the *timed out* text.) I tried to change my name, but there's no confirmation that anything happened until the page changed. I do think this is interesting, although there should be more emphasis on the chatting. I never saw a message from anyone else, even when I initiated a discussion. Moving the chat left, possibly to the large space between "Nash Bargaining Game" and the information about the game itself would help. Overall, it's interesting, but too confusing right now. Thanks for opening up the source, and I look forward to checking it out.
I was mostly confused by the game as well. When you click on the "play" link some instructions come up and a few seconds later it seems like a game begins. I kept reading the instructions to try to understand what was going on and, oops, TIMEOUT! YOU LOSE! Eh, not incredibly motivating.
Hi zck, Thank you for your detailed feedback. Thinking about it, most of your concerns could be fixed with a combination of a status bar and tooltips. I need to revisit the UI, especially for starting the game. You're right, there's no reason to start with more than zero coins. I've changed it in my local copy. The messages box in the middle right tells you what happened in the game. (How much each person demanded, etc.) If you click on unassigned, the website stops waiting for another human player and gives you a robot to play against (Ralph, Nelson or Martin). If you talk to them, they won't respond. Maybe I should take away the Talk dialog in that case . . . Or add some sort of Eliza bot? The timeout functionality and all of this game were added yesterday, and everything is definitely in a state of flux. I want to make the robots play better and to add more games! Any suggestions for a new game?
For some reason, I missed the messages box for a while. I still think it should be moved more towards the action, especially since you're trying to encourage chatting. If you wanted, you could append (bot) to the name, just to make it clear. So it'd be Ralph (bot) or Martin (robot). Or, you could have famous robot names. It'd be kinda cool to have Bender (robot), R. Daneel Olivaw (robot), or Marvin (paranoid android). The robot could respond by saying some catchphrases, or even "I'm just a bot; I can't respond". You could add the [prisoner's dilemma](http://en.wikipedia.org/wiki/Prisoner%27s_dilemma), although it can be viewed as a special case of the Nash Bargaining game. Edit: actually, it looks like wikipedia has a lot of [interesting games](http://en.wikipedia.org/wiki/List_of_games_in_game_theory) that could be implemented.
Is there any http link for LispWorks personal editon ? I can't use ftp, since my university doesn't allow it ...
Not that I know. Just send a mail to the LispWorks guys and ask for a HTTP download. Makes sense to have that.
My thoughts exactly.... ...a derated, non-CL-unification lisp seems like the ideal candidate for embedded systems.
Thanks MrWoohoo, I've increased the timeout to one minute, and put some instructions on the front page.
Thanks zck, I've added the prisoner's dilemma. I'm not sure how important chatting should be. . . 
It adds an interesting component -- you can bargain with or threaten the other player. Although that brings it out of the pure game theory world, adding a bit of psychology.
OpenID is strange "Web 2.0"-Stuff.
The Emacs keybindings have been there for a while, and are such a welcome feature. But alternatively, check out [ViEmu](http://www.viemu.com/)--Vi emulation for VS.NET. (Just trying to help a [fellow redditor](http://www.reddit.com/user/jng/) sell his awesome product!)
Is this the paper on missed compiler optimisations the MSI group [mentioned at ECLM](http://lispm.dyndns.org/news?ID=NEWS-2009-09-15-1) or a separate one?
Another one.
Google suffers major NIH syndrome. First, MapReduce would have you think they invented the technology. Now, they reinvented SunRPC/XDR/DDS/...
The first who says "Clojure" gets a boot to the head.
CLtL3 for example: http://common-lisp.net/pipermail/cltl3-devel/2009-September/thread.html Other than that I would think that some enhancements are more 'social' than technological. For example a code sharing/installing/updating/... story. 
abcl!
xcl! http://armedbear.org
evolution is for imperfect beings. Common Lisp is perfect, thus eternal and immutable. Besides, Common Lisp was created by an ancient and illuminated civilization. We, who live after the Fall, are not able to reach that level of Grace anymore. 
The idea of Lisp may well be the closest to perfection popular computing has gone. There's always lots of things to do on the implementation front.
I am curious, why are you saying "has gone"? Because we live in a postmodern world where the idea of perfection itself has no place anymore, or because that idea has passed from Lisp to some other technology?
I don't see the problem. I've written some network protocol stuff yet haven't heard about SunRPC, nor XDR nor DDS. I do have heard of Protocol Buffers, but only after doing the things I've done and getting sufficiently comfortable with the basics of implementing low level network protocols. Google may well have found them but figured they're not popular enough to embrace. If they've nailed the fundamentals better, that's fantastic.
CLtL3 is a good idea. I hope it won't die by lack of critical mass. For example, this ML seems to exist since april and I've never heard of it until now.
Ideas are invented. Invention happens only once. Lisp has been invented. There has not been ideas that nail the practical concerns and theoretical brilliance in computing better, not in the popular context. Ideas only written down in someone's notes are worthless whatever their brilliance. I don't count amending some overarching ideology (here, Lisp) with minor notes as reinventing it.
The Java bunch still struggles whether it needs closures. Perl 6 is getting more complicated, too complicated? Does it really make sense to extend a scripting language with all this stuff? Just look at the new object model of Perl 6. Python 3 looks relatively conservative. C++0x also looks complex. I see (minus Python) a trend that languages get overly complex and that languages are extended (like Perl) that should not live on. A more regular and smaller language core would be good. I don't think we can learn much from Java (even trivial extensions can't be done in the language itself, since it has no macros or similar mechanisms), C++0x (unsafe base language, complex mechanisms, hard to implement), PERL (mis-designed from the start, now adding all kinds of random features)... A language like Lisp is definitely not for everyone - its main purpose is to provide a programmable programming language - so the user can extend it. This power is not needed by everyone, might be dangerous - it assumes that the Lisp users are willing to learn how to safely/usefully extend the language - the language is not fix. If you want new iterations, new control structures, etc. write them yourself. This makes Lisp useful for people who have a more flexible thinking - you need to learn the mechanisms to extend the language and not only memoize a list of predefined constructs. The Lisp culture was and should be: write your extensions, publish them and see if they are adopted by other people. If the adoption is there we should think about documenting/standardizing them. Bottom up language design. Don't wait for the benevolent dictator or for the committee. 
Common Arc
I am a longtime perl user, but I always had the impression that, more than the famous "TIMTOWTDI", the perl motto should be "WIBCI" (Wouldn'It Be Cool If..."), because that seems to be its driving force. The result is that, if lisp is elegant, perl is kitsch. But, I do not understand how is it possible to create, as you say, "A more regular and smaller language core" for CL. Isn't that a recipe for Scheme, sort of? In the CLtL3 ML, Daniel Weinreb also says that &lt;Common Lisp is left with a legacy of not distinguishing clearly between what is the "language" and what are "already-loaded standard libraries"&gt;. Still, this is what ANSI CL is. Are you suggesting a new "thinner" CL, different from ANSI CL?
Common Lisp has an unfortunate design history. It is based on MacLisp and its descendants. MacLisp at the time before CL acquired extensive OO capabilities in Lisp Machine Lisp in the form of Flavors. Basically Common Lisp is a simplified and improved Lisp Machine Lisp. For example Common Lisp uses lexical binding by default - that is a huge win. But **Common Lisp was designed in a two stage process**: 1) design a core Lisp without object-oriented capabilities-&gt; CLtL 1 2) extend Common Lisp with some more features and an object system -&gt; CLtL2 -&gt; ANSI CL So the object system was first removed, much of the language designed and later the object system was added. But much of the language remained unchanged from CLtL1 and was not redefined based on CLOS. The variation from Flavors to CLOS is from a user point of view extremely small for most uses. Flavors did classes, instances, methods, multiple inheritance, etc. already. CLOS has an improved design and the MOP, but for everyday programming there was little progress compared to Flavors. Why are streams, conditions, pathnames, hash tables, ... not CLOS objects? They are in implementations, in various ways, but not in the language as defined by CLtL2 / ANSI CL. In Lisp Machine Lisp much of the stuff were Flavors already. The whole Lisp Machine operating system incl. window system, network stacks, file systems, database etc. was written using Flavors. **Redesign Common Lisp, like it had CLOS from the start** It would be useful to remove structures and replace all use of structures with CLOS, by adding the efficiency of structures to CLOS (class sealing, single inheritance on demand, etc.). Redefine all places in the spec that leave it open whether CLOS or structures (or something else is used) to use CLOS. This allows then to have user extensible streams and stream operations defined in terms of CLOS (what most implementations do anyway). All the special data types which are not extensible (like hashtables) should be replaced by CLOS classes. The new language then would look like a more powerful and more dynamic version of Prefix Dylan. With macros, runtime compilation, the condition system, ... **Compare**: [Lisp Machine Lisp](http://common-lisp.net/project/bknr/static/lmman/toc.html) - use Firefox to browse. - MacLisp modernized for the Lisp Machine. [Common Lisp](http://www.lispworks.com/documentation/HyperSpec/Front/Contents.htm) - ANSI standard, defined in more than ten years of work (1982-1994). Mostly a redefined/modernized LML. [EuLisp](http://tkb.mpl.com/~tkb/software/docs/defn-0.99.pdf) - nice design based on CL mostly, from Europe [Prefix Dylan](http://lispm.dyndns.org/documentation/prefix-dylan/book.annotated/annotated-manual.html) - nice design based on Scheme with CLOS, done by Apple [ISLISP](http://www.islisp.info/Documents/PDF/islisp-2007-03-17-pd-v23.pdf) - simplified Common Lisp mostly 
Someone just has to make a "killer" app or library that brings a lot of [the right kind of] people over to CL. It already has so many features that other languages only dream about. While Java is trying to decide if people are smart enough to use closures (!!), perl is trying to convince everyone it's still relevant and C++ is trying to convince everyone that adding even more complexity is the answer; Common Lisp is enjoying the best set of features of any language and adding more all the time. Here's a few of them: 1) Condition system - resumable exceptions would be good (hello Smalltalk) but this goes beyond that. Truly letting developers build robust systems and decouple error detection and potential recovery (low level concerns) from recovery strategy (application level concern). This is a superset of every other exception system in existence and no other system gets close to it. 2) Macros - Allowing the language to extend itself via controlling evaluation time (and potentially modifying code before it is ran). DSL possibilities are endless. More powerful than C++ templates for compile time coding and much easier to use. Note that much of the gains of this feature can also be accomplished with delayed evaluation (e.g. Smalltalk blocks or Haskell's lazy evaluation). 3) CLOS - The OO system for people who *hate* duplication. Override a method to decorate it? Fine, but in Lisp we're not doing to type out the call to super every time, we'll just invent the :before and :after methods. The chain of responsibility pattern? We just call that an :or method. If the GOF pattern book had been implemented with CLOS the whole thing wouldn't have filled a single page.
What is "the right kind of people"? I suspect that currently most of CL users are smart and/or experienced programmers that can see the potential creative uses of certain things that CL has (conditions, macros and CLOS are good examples). For the rest of us, I think that a book like "Practical Common Lisp" did more for the popularity of the language than any killer app. Conditions, macros and CLOS make the language very flexible; but for a humble programmer coming from other backgrounds it is not always very obvious how to make good use of all this flexibility. In my opinion, we need more literature of this kind, more best practices, patterns, etc. "More Practical Common Lisp" would be welcome.
I must say that I wish ISLISP was more popular; At least [OpenLisp](http://eligis.com) makes a great system. SDF makes use of ISLISP via OpenLisp extensively (thxmoo, &amp;c.). 
I have been learning lisp for months. I love lisp and its parenthesis. I also believe it is superior to most of the languages out there. But, I would rather code in java or python than in lisp for my serious projects. These are the reasons. 1) My incompetence in lisp. Really, you can't do anyth about it. 3) Batteries not included. I know there is a lot of cl libraries out there. But downloading each of them, sorting out the dependencies and installing is a really pain. Why python is more popular than lisp, while the latter is more powerful, and faster? I don't really think python could be this popular if it doesn't contain any lib by default. 4) A good IDE, which is not emacs. Yeah, I know emacs + slime is exceptional. The problem is I , representing the normal programmers, am not the kind of clever hackers, like most of the lisp programmers. I would like to code in an environment like VB Studio, Netbeans, with all those GUI fancy staff. Besides, learning emacs took months if not years. I am not patient enough to devote that much time just for an editor, which also is said to be an OS. PS: I am discussing about free ( for any purpose ) lisp implementations.
Distributed Common Lisp?
this Redesigned Common Lisp would be great. But it is a much more radical approach than, say, CLtL3. It would be a leap more similar to Perl6 perhaps (which btw has been often accused of being too ambitious and too late; time will tell). Has the CL community sufficient manpower and will to do this?
Your supposed incompetence in list-based matters shows also from the fact that point 2 is missing :-) About 3 and 4, you may or may not be right, but I think they do not qualify as "next big thing"...
I don't think it is a leap. It is a simplification and redesign. Much of the design is already done in existing CL implementations, since CLOS is widely used under the hood. There are two approaches to move on from CL: **CLtL3** * Repairing mistakes, ambiguities, and minor ommissions n ANSI Common Lisp * Extensions outlined in the CDR (including the MOP) * Multiprocessing and Concurrency * Foreign Function Interfaces * Extensible Streams * Extensible Sequences * Networking * OS and Filesystem access * Editing and Introspection **Object-Oriented Common Lisp / OOCL** as outlined above CLtL3 is more conservative and should/would make sure that existing portable Common Lisp code does not break. OOCL would possibly break lots of existing code. So I don't give it a real chance.
They are not going to be the big things. But, they sure are the things to attract more programmers towards lisp or simply to make lisp more popular. Why java is the most popular language out there, despite not having a closure?
There is a plug-in for Eclipse called [Cusp](http://bitfauna.com/projects/cusp/) which may be more of what you had in mind. I know you're primarily thinking of free (no $$$) implementations, but some of the commercial lisp implementations have nice GUI IDEs: * [Allegro CL](http://www.franz.com/downloads/) * [LispWorks](http://www.lispworks.com/downloads/index.html) As for libraries, I've found [asdf-install](http://www.cliki.net/ASDF-Install) to be really helpful, no, it isn't a perfect solution, but it works pretty well. Mudballs is also a project in this area, but it looks like the site is down atm.
Because it does not have closures. Java was designed to be a simple, straight-forward object-oriented language for batch use, in the tradition of C, C++ and similar languages. It is for industrial use where the programmer can be more easily cloned with less training and more predictable outcome. Lisp is quite a bit more complex and its use is also more complex, since it allows to modify complicated running software, it allows to change the look&amp;feel of the language radically, etc. - Things like this make companies nervous. They want to outsource work and have it as cheap as possible. Most of their problems are relatively easy but large in size (like relatively simple user interfaces, but plenty of CRUD screens).
"despite", you say... My impression is that CL is simply more complex and sophisticated than Java. This means that it will probably attract less programmers anyway (maybe of a different quality). For example: compare the size of a decent explanation of CL condition system vs. one of java exceptions. Also, I think that lisp programmers like Emacs not because Emacs itself contains a (rather archaic) lisp, but because the two things have the same philosophy: flexible and powerful, but requiring a certain investment. Likewise, learning to write lisp macros is not difficult. Learning to do interesting things with them is much harder. Which is why, in another comment of this thread, I hoped for more books, rather than more tools.
AFAIK mudballs is [orphaned](http://groups.google.com/group/mudballs/browse_thread/thread/15755f04ff62629c) at the moment.
&gt; But downloading each of them, sorting out the dependencies and installing is a really pain. Yes, but you need to do it only once, basically. &gt; Besides, learning emacs took months if not years. I suspect you're doing it wrong... I do not like learning new editors either, but XEmacs or Emacs with CUA mode have sane keybindings by default, so you can just use it. As for the rest, there's only about a dozen of useful Emacs-specific keybindings, learning them should not take that much time. So maybe your problem was that defaults are not good, but that is pretty easy to fix. But if you don't like Emacs, that's ok, there are other editors too.
One very simple thing that I would like: a real index for common-lisp.net, with descriptions and dates. Currently there is only an alphabetical index which is only useful if you already know the name of what you are looking for. There should be a categorized index, like CPAN has. At the moment, it's impossible to browse for interesting things; also, it's impossible to see what are the recent additions.
&gt; OOCL would possibly break lots of existing code Perl6 too. [this](http://dev.perl.org/perl6/faq.html#___top) is their solution. However, I think the main problem is social rather than technical. There is (at least so far) *one* perl, with a single community, and has a history of new releases from time to time. Instead there are *many* CLs, so the resources are fragmented. And their only common ground is the spec, which is a monumental effort which we know will never see a revision. In this sense, I see CLtL3 as an interesting project in creating a new kind of consensus.
One of reasons I like Common Lisp is that it is fairly stable -- I do not need to learn new and trendy CL2009 each year, I can focus on writing applications. So I hope it will continue to get gradually improved rather than jumping to "the next big thing". Almost all improvements can be done via libraries, and I think that is the right way to do that. People usually complain about incompatibilities between implementations, lack of platform support, lack of consistent set of libraries and stuff like that. Implementation vendors and open source library writers can resolve this issues without touching language itself even a bit.
semi-automatic translators have been used in the Lisp world for a long time. It is still a lot of work. Especially the code that generates other code cannot really be automatically translated. Symbolics Genera has several conversions in Zmacs, for example from Zetalisp to Common Lisp. Genera also provides the compatibility mode (being able to run three different object systems and several Lisp dialects in the same image). The latter is better than the former, but still I would prefer not to provide such a thing - I'd really think an implementation should benefit from the unified Lisp and not keep the baggage using two languages around. 
Very cool. It might also be useful to have a 'Common Lisp Implementors Workshop (CLIW)' at some point. There is currently enough implementor activity that it might make sense to share...
The next big thing would be some kind of Common Lisp "platform of libraries" which works across all platforms and all Common Lisp implementations. For example, [Lispy](http://common-lisp.net/project/lispy/) and [LibCL](http://libcl.com/) are efforts in that direction.
I am dreaming: please decide for a couple of "included" libraries like drakma, cl-ppcre, clsql, ... get permission from the authors and distribute an additional sbcl-variant with battieries included! :) (yes I know, you could argue, it is not the business of an implementation to care for libraries, but look at ruby, python, ...)
You can do that today by creating and managing "PowerSBCL". Go for it!
I don't understand. Given what I read also [here](http://www.reddit.com/r/lisp/comments/9p2sq/what_is_the_next_big_thing_for_common_lisp/) it seems that this "lack of batteries included" is perceived as a major problem with lisp. I agree that asdf-install is not very pleasant, but it's not so terrible even, for a typical linux user. Maybe the real problem is that the "assembly instructions" are a bit sparse. Anyway, things like [libcl](http://libcl.com) should help.
With clbuild, you can setup a fully working lisp environment very quickly.
Hopefully, a bit more centralization with regards to library management. I have no problem ASDF-Installing things but I think it's hard not to acknowledge that Hackage\cabal has its advantages. There are a lot of **great** libraries that are on github or bitbucket or off in the great beyond somewhere *which are ASDF installable*. I'm mostly concerned with community\social aspects, rather than technical ones. ASDF seems *good enough* to me though I am open to advancement from XCVB, mudballs, etc. Aside from trying to emulate cabal\hackage a bit more, I'd love to see libCL or something similar get traction as well as updates to something like Lispbox or Lisp in a Box. I do think there's something to be said for making it easier for folks that want to try lisp to get off the ground. Then we would have a starting point for both libraries a la the Haskell Platform and solve the supposed "oh no, so many choices" wrt lisp environments (compiler + editor). Besides, there already seems to be a consensus on the [starting materials](http://gigamonkeys.com/book/), reading-wise.
Yeah, but clbuild's model was (last I checked) kinda broken--it doesn't appear that it works at all with package management, which is pretty bad.
Yup. Protocol buffers seem an unnecessary reimplementation of ASN.1. Why?
I agree, I learned enough Emacs to be efficient in a single day.
Is this project still alive? Looks like not much has happened since 2008...
I hope that there will soon be some referable document which contains function descriptions for extensions like gray-streams and sockets, and which contains a list of deprecated features from cl, which shouldnt be used anymore. I know there are such documents, but none of them really made it to be accepted by the most of the community. And I hope that there will be a good UI-Toolkit in the next years. Instead of cffi-ing something, maybe a toolkit written entirely in common lisp would therefore be a good thing. But dont know. The hype is with clojure. Not with Common Lisp.
asdf-install is obsolete, use clbuild &lt;http://www.cliki.net/clbuild&gt;.
&gt; The problem is I , representing the normal programmers, am not the kind of clever hackers, like most of the lisp programmers. One isn't born a hacker, one has to become one. If one has low ambition, it becomes a self-fulfilling prophecy. &gt; But downloading each of them, sorting out the dependencies and installing is a really pain. Get &lt;a href="http://tehran.lain.pl/stuff/clbuild.el"&gt;this&lt;/a&gt;. Then «M-x clbuild RET clim-desktop» does the trick.
&gt; Why java is the most popular language out there, despite not having a closure? Because most people are idiots. Similarly, Christianity is more „popular” than atheism. Also, intelligent people are forced to use Jabba by idiots in the management. The most important criterion for the bourgeois management types is not language expressibility, but programmer replaceability. 'Nuff said, the point has been reiterated thousand times already.
That's because any CL packages are usually horribly out of date. There is no useful way to integrate with these packages. Besides, there is no reason to integrate with package management since everything is installed locally rather than system-wide.
The '90s!
Yeah, for hackers, maybe. But, for noobs like me, it took like 3 days, just to set up emacs + slime + Hyperspec.
Cusp is kind of dead, the latest version is from 2007. I am afraid it doesn't work anymore on eclipse 3.4/5.
First of all, asdf-install is not "obsolete". It's shipped in sbcl, ccl and several other lisps as I understand it. It's a very useful tool. Second of all, clbuild is not a cross-platform tool and while it is definitely useful and quite good at what it does I don't see it as a long term solution. Finally, my post was less about our installation tools than the infrastructure they connect to. In this sense, I'm whining about the fact that all asdf-installable lisp libs aren't neatly packaged on cliki or elsewhere. If you meant to point out that lisp developers are reasonably decentralized and that expecting all work to migrate to one place was unreasonable, you've got a point.
No, it's just moved here http://code.google.com/p/cusp/
Reminds me of friends who have been spending the last week or so refreshing ratemyprofessors.com . 
Thanks ;)
Sorry, this is crap. I don't know who this guy is but he sounds... new, to say the least. Here's a tip: when you wander into Lisp and discover something is different than the toy language you sort of know, before you decide that it's crap/legacy/whatever, try to find out something about it. Maybe everyone else is actually wrong. That does happen you know. In this case, some investigation might have revealed that Lisp dynamic variables *are* global variables done right, and about the only language around that has it. You know all those people saying "global variables considered harmful", "every time you use anything remotely like a global variable someone brutally slaughters a seal", etc.? They're saying that because they have *lexical global variables*. So good work bringing the problems of inferior languages to Lisp. The problem with global variables (and by "global" I mean any variable that can be read by more than one function/method and modified by one or more function/methods) is that when it gets changed you have a hard time figuring out *where*. Suddenly the variable has a value that you thought was impossible, and there is no trace of the culprit. Well, in Lisp you don't have that problem. The culprit will be there because if he were gone his bogus value would be as well. And his comment about naming conventions is complete rubbish. Everyone does this. Camel casing, case by scope, etc., etc. Or maybe since this guys programs never get past 10 lines he doesn't mind looking up every bloody reference to see if it's a member, class member, global, function parameter, etc. If the rest of his blog is like this then it'll be a good place to point people for anti-patterns. 
41 upvotes, 2727 /r/lisp subscribers - what is missing to make this the best environment in a matter of days?
&gt; That's because any CL packages are usually horribly out of date. There is no useful way to integrate with these packages. Then why [does this work](http://yum.octopodial-chrome.com/)? &gt; Besides, there is no reason to integrate with package management since everything is installed locally rather than system-wide. That's colossally bad practise, and completely antithetical to actually have Lisp software installed on your machine, rather than working for a particular user.
Wow! You may be right (or wrong) in what you say, but the way you said it you come across as a total jerk. Not someone I'd consider a reliable source of information. Yikes!!
I come off as a jerk? Did you actually read this blog post? The guy basically trashes everyone who worked on the Common Lisp standard as either not knowing what they were doing, or being lazy. And the worst part is he says this about a feature that is really good! If he had actually managed to *find* one of CL's many warts it would be more acceptable, but this was just embarrassing. So tell me, how should I come off in that case? EDIT: Also nice to know that you only consider polite sources of information as reliable.
Sorry ytinas, but Ron Garret is rather famous. Look him up. Why do you think he sounds new? You seem to have completely missed the point of his post. Some people explicitly avoid using defvar and use (declare (special *x*)) to work around the problem he identifies. And to reply to your comment below, I think that everybody appreciates the Common Lisp standard was a lot of hard work and a good compromise. But nothing is perfect. 
Even better, look up Erann Gat
Now with Unicode!
sick
&gt; Second of all, clbuild is not a cross-platform tool and while it is definitely useful and quite good at what it does I don't see it as a long term solution. clbuild is a bash(1) script. The GNU Bash shell is available not just for Unix platforms but even for Microsoft Windows. Too bad it's not written as a POSIX shell script, though. I know a couple of Microsoft Windows programmers and they say it's awfully hard to do any actual work without having a full Cygwin environment installed, which incidentally includes bash(1). Symbolics Genera is one noteworthy platform that doesn't have a Unix shell. But there's the possibility of copying the systems/ and source/ directories over. Oh wait, Genera doesn't support ASDF either. clbuild has the advantage of being able to compile a CL implementation by itself, which wouldn't have been possible if it was written in Lisp. Besides, all it really does is call external programs anyway, so a shell script looks like the most elegant solution. I've seen comments on #lisp expressing annoyance at asdf-install quite often. „Web of trust” sounds like a good idea, but no one really built a toolchain of trusted committers and shared it, so one is left to figure out how gpg(1) actually works. I never did, and kept invoking the SKIP-GPG-CHECK every time. It's like reverse lottery, fortunately clbuild was created before some malicious fellow decided to do some damage. Some relatively important systems aren't clbuild-installable, but at least I have to play the reverse lottery less often. And clbuild has an important advantage -- it's not a problem to maintain local patches, unlike with asdf-install. Unless conflicts arise, the horror, the horror. Also, developers don't have to release tarballs :) &gt; I'm whining about the fact that all asdf-installable lisp libs aren't neatly packaged on cliki or elsewhere Well, by definition, every asdf-installable system has to have a cliki page containing a link to a tarball.
You seem to have me with regards to clbuild. As for &gt; "all asdf-installable lisp libs" I meant all lisp libs with .asd system definitions. My mistake. I guess I just wish there was a more centralized source of information on lisp libraries, their status and their quality as well as starter kits for noobs, a la Lisp in a Box and LibCL. Until then, there's always google. :)
 1 The Clojure Way 2 The Clojure Environment 3 Defining Symbols and Functions 4 Data Types and Structures 5 Sequences 6 State Management 7 Namespaces and Libraries 8 Multimethods 9 Metadata 10 Working with Java 11 Parallel Programming 12 Macros &amp; Metaprogramming 13 Appendices (Overview of Clojure tooling and environments, overview of Java) 
Does anyone know how the Alpha Book program works? Will I have to pay more to get the final book or what? 
No. &gt; It is an Alpha Book and so is in an unedited unfinished pre-release format. The full book isn't available yet, but when it becomes available, you will be able to download the full eBook. (source: click "buy alpha book" it shows this page.)
I'm 15 years old; home schooled; I've been programming for just over 2 years, and I have little to no practical, professional experience. All projects I do are of my own making, and I don't consider myself very knowledgeable at all.
This is Ron Garret? Perhaps Eric Naggum was right about him then. His complaint about defconstant is valid, but his bitching about lack of lexical global variables sounds like the complaint of someone from an inferior language pissed that their bad programming habits aren't easy to do in Lisp (this is why I thought he was new, and I couldn't find his identification on the site in 30 seconds of checking, so...). Lisp *shouldn't* have lexical global variables. If you ever reach for a lexical global variable just stop. Stop and look at every bloody book on best practices for the last 10 years. defvar works as it should. Ron has nothing invested in Lisp anymore, his sole contribution seems to just be to hurl mud. There are things that need to be fixed in Lisp. There are things that other languages actually have better than Lisp (e.g. libraries sensibly organized instead of just a huge blob that everything is in and the names could be any of 3 or 4 different naming conventions). But we certainly shouldn't be adding *bad* features of other languages.
Can you be more specific?
more specific how? go [here](http://cybertiggyr.com/articles-title.html), search for lisp
more so, if you don't know what I'm talking about, [this](http://cybertiggyr.com/whlpo/) might help plus some web archiving site.
Ok. That doesn't really help narrow down which articles were part of lisp-p.org, and almost everything else is garbage.
Ah, here is the useful one: http://cybertiggyr.com/80-closminded/
Don't miss next year's workshop - http://arts.ucsc.edu/wacm/index.html
Only VIMists use clojure. An evil thing, therefore.
gms was an interesting person to talk to in COMmode as well...
Maybe i am a little off topic here, but anyone ever use readers/accessors? I have i tried them, but it was always access once, access twice, WITH-SLOTS. So i ditched them completely, using just slot-value if once, and with-slots if more then once. And if you need the slots of multiple i use this macro: (defmacro with-mod-slots (mod (&amp;rest slots) object &amp;body body) "WITH-SLOTS, but requires something to be prepended to the\ SYMBOL-MACROLET's, this allows you to use two or more objects with\ convenient symbols at the same time." (with-gensyms (obj) `(let ((,obj ,object)) (symbol-macrolet (,@(mapcar (lambda (slot) `(,(intern (format nil "~D~D" mod slot)) (slot-value ,obj ',slot))) slots)) ,@body)))) And if it all becomes too nested, i just [denest](http://www.reddit.com/r/lisp/comments/9ijq1/before_you_start_learning_lisp/c0cxop0) it. (I really need to put the latest version on the web.) Of course denesting too much means it needs to be refactored. Edit: Good point on the downmods, i mean, this comment is really getting in the way of important heated discussion!
CLtL3
Thanks. I'll have to update my bookmark.
Of course, I use accessors. Slots are usually an implementation detail and accessors are usually the public interface. Slot names are often not exported. Also, accessors are used like normal functions: you call them, pass them to other functions etc. Functions provide regular interface to functionality. Also, can you #'mapcar a list of objects and collect their properties with slot-value?
With CLOS, I usually think about the generic function protocol and define the classes accordingly. Accessors are shorthand for defining methods on the GFs easily, but the fact that they're slots is a convenience, not the most important thing. Objects aren't just buckets of slots.
Maybe i just haven't used CLOS intensively enough to actually encounter a case where i couldn't use the slot as generic accessor/reader. Also, one could just write a macro WITH-ACCESSORS and WITH-NAMED-ACCESSORS. (The name i gave WITH-MOD-SLOTS is kindah bad.) Anyway, converting on to the other isn't that much work. &gt; Also, can you #'mapcar a list of objects and collect their properties with slot-value? Yeah trying to pass a function but having to just fill that one argument can be annoying. I haven't -in practice- ended up doing this, though. (Probably i should.) (defun curry (fun &amp;rest curry-args) (lambda (&amp;rest args) (apply fun (append args curry-args)))) (defun curry-l (fun &amp;rest curry-args) (lambda (&amp;rest args) (apply fun (append curry-args args)))) (declaim (inline curry curry-l)) And then hope it gets optimized. Edit: untested, and tried to make compiler macro, but it cannot get around not knowing how many arguments are 'left on the lambda'.
He not entirely right about defconstant. Not having the behavior defined allows implementors to implement it as constants, so the name is appropriate. However, i think the spec should have specifically asked to produce an error when you try to set it, and it should say something about what happens if you use LET to change the value. (Think it shouldn't act like defvar in that case!)
&gt; DEFCONSTANT doesn't actually define a constant, it defines a global variable with the less-than-useful property that the consequences of attempting to change its value are undefined. This leaves Common Lisp implementors free to **implement it as a constant**. However, i think the spec should have specifically asked to produce an error when you try to set it, and it should say something about what happens if you use LET to change the value. (Think it shouldn't act like defvar in that case!) Further, **i fucking love** special variables. I often use them when it would become cumbersome to pass them as arguments to functions. It also allows you to make a program with 'global variables' into a function, just by picking up all the variables involved. An alternative would be to pass one argument and make that a structure, however this would also be more cumbersome: 1) You'd have to pass that argument. (Whereas with special vars you don't have to pass any) If you want to alter that, you need to call change-class, or some function like it you made for it. 2) You'd have to make that structure/class. (Lets say class) 3) You have to call the accessors/reader/slot-value/with-slots 4) You'd have to make a new class and derive from the old each time you want another variable. No it is actually worse then that. Say you have a base class, and you want to get two 'equivalent to defvar' variables a and b, that you can use separately and together. Now you have to make *three* classes: base-with-a, base-with-b and base-with-a-and-b, and if you are extra fastidious, you make one add-a, add-b class to make those too. Compare this to just (defvar *a*) (defvar *b*) Correct me if i am wrong on how to make these classes. I guess you *could* make just base-with-a-and-b, however, if my code doesn't use that one variable, it would irk me to have it in the class i am passing. It's meaning wouldn't fit what it does. (Whereas defvar doesn't pretend to add meaning.) This, of course is not to say it doesn't have disadvantages over defclass, but it can have advantages over it. Note that, as lnostdal4 points out, sbcl has regular global variables. I do think the specification should have also defined these. (Just to give people the freedom.) &gt; And if you're still unconvinced that Common Lisp's pervasive special declarations are a bad design, consider the rule that all global variables should have named that are bookended by asterisks. That is a good point! Maybe accessing lexical variables should be explicit. Maybe symbols surrounded by \* should be converted to \*symbol\* -&gt; (special-var symbol), then we can get error when the special var doesn't exist and such, and the criticism given here wouldn't be valid anymore. However, we'd probably want to make it more general. Maybe a 'symbol-reader-macro', for whenever the first and last character as the same then we can have the same rule for constants +symbol+ -&gt; (constant symbol) He might be famous and smart,(as radddit says) but that doesn't mean he is entirely correct. He might simply not have used variables in this way because he is used to doing it with classes.
In [Golgonooza](http://unknownlamer.org/darcsweb/browse?r=golgonooza;a=summary) I use methods on a few things that are logically accessors to implement useful behavior. E.g. the [query-view](http://unknownlamer.org/darcsweb/browse?r=golgonooza;a=headblob;f=/src/query-view.lisp) component has a *logical* slot `current-items`. This is either generated from a database query if the ephemeral cache is invalid or simply returned from an internal cache slot if it is valid. Logically this slot exists in the object, but it has no physical slot associated with it. With accessors you note that a slot is part of the protocol for the class; subclasses can override or add advice to them. E.g. in UnCommon Web an `application` has a logical slot `request-context-class` that returns the superclasses of the `request-context` instances created by the `application`. It does not, however, actually exist in the object, but is instead a a generic with the `list` method combination. The `standard-application` class returns a sane superclass, and subclasses specialize the `request-context` method and return any additional superclasses they need.
pitiful.
&gt; If you ever reach for a lexical global variable just stop. Why? &gt; Stop and look at every bloody book on best practices for the last 10 years. I don't put a lot of stock in books about best practices. Many of those books are just collections of hacks to work around deficiencies of other programming languages, with "Design Patterns" as the poster child. 
I needed software to iterate over a sample of N random elements from a set as efficiently as possible, and ended up spending a few days writing about 35 (!) functions for random sampling, with the help of macros. Then I spent another few days carefully documenting everything, because I'll be damned if I do all this work and nobody else can or wants to use the library due to lack of documentation. And then I realized my application doesn't need it at all. Grumble. (I was going to use it to emulate condition variables that support notifying several waiting threads at once, but I realized that calling BORDEAUX-THREADS:CONDITION-NOTIFY several times on a normal CV should work just as well.) Oh well. Hope it makes someone's day!
Okay look, people have been using computers to create music literally since the 60s and even before. We have to stop pretending it's new and amazing every time, with titles like "stirs controversy". It is not controversial. It is, however, art, and that is _something_ in and of itself.
ACM account required :-(
Somehow my link was changed. Try to download it from here: [LFP 82](http://210.102.99.71:42435/toc.cfm?id=800068&amp;coll=ACM&amp;dl=ACM&amp;type=proceeding&amp;idx=SERIES288&amp;part=series&amp;WantType=Proceedings&amp;title=LFP&amp;CFID=13660249&amp;CFTOKEN=97465428)
I'm not talking about just books. Books, blogs, meetings, pretty much anywhere you meet professionals they will pretty much all have the same advice: do not use global variables (just to be clear: I'm talking about mutable values, if it isn't mutable then I wouldn't call it a "variable"). And the reason why they have this advice is because the language they use only has *lexical* global variables. Having globals be dynamic removes most of the problems.
thanks!
but your blog doesn't.
 &gt; (human-not-equal Rainer-Joswig John-Fremlin) &gt; T
From the article comments: &gt;In response to your observations about Java interop (2 and 3): think of the interface to Java as Clojure’s FFI. Whenever you interface Lisp to a non-Lisp language you end up with a capacitance mismatch that makes the interaction a bit awkward: you can say the same thing (for example) in Clozure Common Lisp’s Objective-C bridge. I find that okay for things like GUI libraries that can be wrapped or otherwise isolated from the "pure" Clojure code but it is common to see things like Math/sin called from Clojure code and that worries me a bit. When using other lisps I don't need to make FFI calls to get such a basic functionality.
Sure, and one could argue that Clojure should ship with all kinds of wrappers around functionality provided by the Java runtime: (defmacro sin [x] (Math/sin x)) But I actually don't see this as an issue. In the case of static methods in java.lang.Math I just see the use of Math/sin as being no different than if I had a "native" Clojure function in a Math namespace. 
thanks! ;-)
Well, for one thing it looks ugly. And it is annoying when I have to go and lookup things in the Java API (with SBCL I don't usually need to have POSIX or Windows documents open when working on trivial things) and it is always not clear how things map between Java and Clojure. For example; does Clojure support full numeric tower? If yes then do the Math functions do the right thing with bignums and fractionals?
You may not have the POSIX or Windows documents open, but I find the Hyperspec is usually open when I'm writing CL. But I'm also pretty familiar with the Java libraries and less so with all that is available within Common Lisp. WRT the numeric tower and the conversions for the Java Math functions, I honestly don't know the answer to that. Finally whether it looks ugly or not: beauty is in the eye of the beholder. Since access to a static method uses the same syntax as accessing a symbol in another namespace, there is a consistency here that makes sense to me. Perhaps it is just familiarity. 
I wonder if about cost of using reflection APIs if things as basic as sin are essentially FFI. Lua wrote a follow-up to his post talking about optimizing (http://blog.bestinclass.dk/index.php/2009/10/brians-transient-brain/) and he mentions adding type annotations to reduce the reflection cost.
&gt;For example; does Clojure support full numeric tower? If yes then do the Math functions do the right thing with bignums and fractionals? Yes, and yes. Clojure also adds a ratio type not provided by Java. user=&gt; (* 10 Integer/MAX_VALUE) 21474836470 user=&gt; (type (* 10 Integer/MAX_VALUE)) java.lang.Long user=&gt; (/ 3 4) 3/4 user=&gt; (type (/ 3 4)) clojure.lang.Ratio If you want to trade off correctness guarantees for performance, you can do things like convert to primitives, or use math functions like [unchecked-add](http://clojure.org/api#toc574). For example: user=&gt; (* (int 10) (int Integer/MAX_VALUE)) ; primitive operation, but checked for correctness java.lang.ArithmeticException: integer overflow (NO_SOURCE_FILE:0) user=&gt; (unchecked-multiply (int 10) (int Integer/MAX_VALUE)) -10 
Well it is tpd2 running behind lighttpd on a very small box :-) The reason the blog was down is a bug. Namely it was eating all CPU doing this: /home/john/Env/ClozureCL-1.3/lib/case-error.lisp:f1770: %ASSERTION-FAILURE: SETF-PLACES-P = NIL TEST-FORM = (NOT (TEEPEEDEE2.LIB:MY TEEPEEDEE2.IO::FULL)) STRING = NIL CONDITION-ARGS = NIL /home/john/Programs/teepeedee2/src/io/con.lisp:f3079: (INTERNAL MY-CALL MY-CALL MY-CALL RECVLINE): /home/john/Programs/teepeedee2/src/io/con.lisp:f3079: (INTERNAL MY-CALL MY-CALL RECVLINE): /home/john/Programs/teepeedee2/src/io/con.lisp:f2852: (INTERNAL MY-CALL RECVLINE): /home/john/Programs/teepeedee2/src/io/con.lisp:f3079: (INTERNAL MY-CALL MY-CALL RECVLINE): /home/john/Programs/teepeedee2/src/io/con.lisp:f1317: (INTERNAL MY-CALL CON-RUN): /home/john/Programs/teepeedee2/src/io/con.lisp:f1317: CON-RUN: First time I saw this problem and I will have to investigate why it wasn't handled like a normal error (closing the socket). Guess this demonstrates that tpd2 needs a lot more work :-)
It was just a cheap sarcastic comment, you shouldn't pay attention to these :)
&gt; [...] and he mentions adding type annotations to reduce the reflection cost. You can do the same thing in Clojure.
Good link, but I prefer the PDF: easier on the eyes. http://www.paulgraham.com/onlisptext.html 
notice that the page lets you choose different color schemes...
But not fonts, and the default font used for EUC-JP sucks ass, IMHO. Anyway, it's nice having an HTML version of the book, was just supplementing the post with a link to the nicely formatted version.
Kind of tacky to not cite the author whose copyright you are violating, no?
A wonderful book. If only ANSI Common Lisp (his other Lisp book) was available online; it's even better.
Well, it's still [in print](http://www.amazon.com/ANSI-Common-LISP-Paul-Graham/dp/0133708756/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1254883648&amp;sr=8-1). And it's worth getting.
sicp is fail?
I didn't see it in this subreddit and when I was looking for books to read on lisp I first searched here. Maybe it will help somebody else like me in the future. Plus reviews and recommendations never get old. 
&gt;I searched around a bit and found an FFI (Foreign Function Interface) wrapper around the FFTW library. After fiddling with that library and the wrapper for about two hours, I bailed on it and wrote my own Fast Fourier Transform library entirely in Lisp. Heh, heh :) 
Any idea how the performance compares to fftw?
So would you write us a review or recommendation? Right now we just have a link and a title.
I enjoyed reading it, yeah. But get Practical Common Lisp. Much better in many ways.
You are missing the point. The problem with CL is not that it provides dynamic bindings. That is indeed a good thing. The problem with CL is that it conflates two orthogonal issues, namely: 1. Whether or not it is possible to dynamically bind a mutable cell 2. Whether or not it is possible to lexically bind a given symbol The problem with CL's design is that it is impossible to create a dynamic global without making it impossible to lexically bind the symbol naming that dynamic global. This was intentional. It was done to support legacy code from dynamically scoped dialects of Lisp. But this is no longer a valid concern. Note by the way how I phrased point #1. Dynamic bindings can theoretically be applied to *any* mutable cell, not just global variables. So if you really believe that global lexicals are bad, you must believe that (globally) mutable cons cells are bad because they amount to exactly the same thing. The fact that the CARs and CDRs of cons cells (and the elements of arrays, and the slots of structures and class instances) are not dynamically bindable must be considered a horrible design deficiency for the same reason that global lexicals are bad. 
So you're saying that if I have a global variable which is dynamic then I can't have a lexical variable with that same name later in a function? That is indeed odd, but given the naming convention it doesn't really matter. And I personally believe strongly in variable naming conventions. When coding in the large, these conventions save time. One just has to avoid over doing it (e.g. the abomination that is Hungarian notation). As for you other comment, first let me define what I call a global variable: A global variable is a mutable variable that is implicitly passed to one or more functions (i.e. it's not in the call list but the function requires it). Given this definition, I like lexical variables for all non-global variables because then I can see in the source code what the value should be. But I like dynamic variables for all global variables because I *can't* see from the code what the value is, that depends on the call order. Therefor, I prefer that the variable can only be modified by something that is currently on the stack, so I can see it. So yes, I do wish that class slots were dynamic. OO is just a way of organizing code so that global variables have a smaller scope, after all. But the pain is not so bad in CL: If I need this I can just make a package global variable to serve the purpose.
Well every time that my blog gets a plug for tpd2, someone figures out how to screw it up (the first time it was that I didn't realise code-char could return nil for chars under char-code-limit), and this time I can't reproduce what they did -- somehow overflowing the buffer correctly causes the connexion to be closed for me instead of this loop :-( I think this is actually a really serious issue. tpd2 is starting to grow up from just being a hobby project, and DoS on malicious input is definitely a huge embarrassment. It shouldn't happen. I apparently made stupid mistakes coding it, and it demonstrates that I need to do some proper testing (fuzzing).
&gt; So you're saying that if I have a global variable which is dynamic then I can't have a lexical variable with that same name later in a function? That's right. &gt; I personally believe strongly in variable naming conventions. I personally believe that the number of rules a programmer has to remember to follow is inversely proportional to the quality of the language. &gt; A global variable is a mutable variable that is implicitly passed to one or more functions. Not unless your language is call-by-reference. A function can change the value of a global variable so that the resulting change is visible to a calling function. In a call-by-value language (which includes all common languages in use today) a function cannot change the value of a passed argument in a way that is visible outside that function. (It can mutate the value, but that's not the same thing.) &gt; So yes, I do wish that class slots were dynamic. In CL you can get your wish. Pascal Costanza has developed an extension to CL that does exactly that (can't remember what it's called right now). &gt; OO is just a way of organizing code so that global variables have a smaller scope, after all. No it isn't. You can have OO without global variables at all. The two have nothing whatsoever to do with one another (except insofar as both are ways of managing persistent state). 
The thing I dont understand is that I checked the mailing lists and forums, and nowhere could I find anyone else complaining that it wouldn't build. So I just assumed I was doing something incredibly stupid and went on about my life without ecl... It seems I wasn't alone, and there was something broken... *shrug* (I guess I should have reported my issues, so that someone else doing the same as me didn't think they were alone, too)
I had build problems with ECL for quite some time. Especially since the transition to Mac OS X 10.6. ECL has a bug-tracker where you can enter your findings. ECL 9.10.2 is the first version that builds on Mac OS X for quite some time now. This version looks good.
This is an excellent version of ECL for Win32. As well as the embedding working as expected, it features: - Improved error handling - I just let the built in debugger kick in when there is an error instead of handling it on the app side - With some massaging so the lisp source files aren't too big, lispbuilder and cl-opengl can now be compiled, whereas before they could only be loaded as source. (The bottleneck is the visual studio compiler, which doesn't allow static strings larger than 64Kb) - Multithreading - The multithreading works beautifully for changing functions at runtime - I used (mp:process-run-function ...) in emacs, and it works. I find ECL's build process a thing of beauty. It builds ecl_min, then uses that to compile all the lisp source files to build ECL itself. This makes it hugely customisable - among other things, the debugger, stepper and compiler are written in lisp, and can be modified. Fortunately, the code is very clean and well written, which makes things much easier when you need get your hands dirty. To build a debuggable ECL in Win32 for instance, you need to comment out calls to (delete-msvc-generated-files) in cmp/cmpmain.lsp. Suffice to say, I am a huge fan of ECL. Juan is a legend. 
Indeed, apart from Lua, ECL is the only multithreading friendly embeddable language in Windows. Something like luabind (it is a boost based C++ FFI framework for Lua) for ECL would be fantastic.
Man, those fire hydrants musta had it coming.
Very impressive, indeed.
Could someone give an example of what this thing could be useful for?
Get both, but yeah, PCL is a better first book for learning the language.
Very nice, thank you.
Cool. I'm glad the author got permission from Peter Seibel for this derived work.
If only the link would work
Have a mirror: http://xach.com/lisp/pcl-distilled.pdf
thanks. 
A CL candidate could be [ECL](http://ecls.sourceforge.net/). Also check out [OpenLisp](http://christian.jullien.free.fr/), which is an implementation of ISLisp. ISLisp is similar to Common Lisp, but a bit smaller/simpler.
You may be interested in Gambit Scheme and Termite. They don't cover all of your bases, but most.
Is this site really news to people who use SBCL?
I just need a starting point. I'm just worried if I start with a scheme as a template, it will be difficult to add in the second namespace. Have you ever heard of anyone doing anything like this? Or would it be simpler to start from scratch?
I like ECL, but I'm concerned about creating an executable from it. But it would make a good starting point. EDIT: ECL uses a native C compiler. I guess I could roll my own and use that instead.
I really don't see the point. The sandbox is not trivial. I would take a long hard look at ABCL, ECL, SISC, and Clojure before deciding that none of them met my requirements. You seem to be under the misimpression that Scheme is not a Lisp. Separate variable and function namespaces is not what makes Lisp a Lisp and Scheme something else. And many people who've come up to speed in Scheme after Lisp find in the end that the Lisp-1-ness of it is preferable because it removes a lot of cruft (funcall &amp; #') that you have to put up with in CL. We don't need any more languages that are sort of like Lisp. That's Scheme's niche after all. :-)
Clarification: The upcoming Allegro CL 8.2 will check type declarations at **runtime** (for some optimization settings) - similar to CMUCL and SBCL See the SBCL manual: [Declarations as assertions](http://www.sbcl.org/manual/Declarations-as-Assertions.html). SBCL * (proclaim '(optimize (speed 1) (safety 3))) * (defun foo (a) (declare (integer a)) (* a 3)) FOO * (foo 12) 36 * (foo (read)) 1.2 debugger invoked on a TYPE-ERROR: The value 1.2 is not of type INTEGER. ... That is what Duane was talking about. This is a feature on its own. This feature is not defined in ANSI CL and not implemented by all Common Lisp implementations. 
I've been using SBCL, but common lisp seems to have, as you say, a lot of cruft. Also, strange things like not having easy access to simple Unix function calls. What I want is a lisp designed to work with *with* unix. And a sandbox. 
I don't know what your end-goal is, and what your hard requirements are, but if I were doing what you are doing I would browse through the Gambit source code and see how easy it is to read. If you are able to follow the code without too much trouble then I would think it would be easier to start with a working scheme then to build one from scratch. According to [this page](http://egachine.berlios.de/sgachine/), there's only one or two schemes that have sandboxes, so maybe that's where you start.
I think ECL has also a byte-code engine and a byte-code compiler.
SBCL does not have easy access to simple Unix function calls? I can't believe that. Like [sb-posix](http://www.sbcl.org/manual/sb_002dposix.html#sb_002dposix) ? Much of POSIX should be available in there...
Check out SIOD (Scheme In One Defun) if you really want to do this. http://www.cs.indiana.edu/scheme-repository/imp/siod.html
Yes, but doing simple things like opening a file I need to know about text encoding and the like. It seems to have a lot of gotchas.
A lot of this is just my ignorance as to how to do it. (Which is one reason I posted it) Right now I have been convinced to use scheme and forget the whole lisp2 part of my requirements. Then I have very little to worry about. As for using a browser, it's an interactive 2D/3D application. Think Emacs and Blender with some nice data management tools. In the future I want to execute scripts, but I don't want to trust them, so that's very far down the road.
How come I never heard about the function VECTOR?
Do you know about the literal syntax? CL-USER&gt; (type-of #(1 2 3)) (SIMPLE-VECTOR 3)
Compile time type checks is really a whole different thing. Unfortunately compile-time type checking based on type inference has its limitations in SBCL. (defun foo (x) (length x)) (defun test (x) (let ((a (foo x))) (values a (hash-table-count x)))) If you expect SBCL can infer this, as it looks similar to your example, it does not. Which kind of makes inferred static compile-time checking more like an optional goody, working for some easy cases. But, the feature Duane talks about is really about deriving runtime checks from type declarations. Also compare this: **Case 1** (defun foo (bar &amp;optional (bar1 (1+ bar)) &amp;aux (bar2 (1+ bar1))) (declare (integer bar)) (+ bar bar1 bar2)) **Case 2** (defun foo (bar &amp;optional (bar1 (1+ bar)) &amp;aux (bar2 (1+ bar1))) (check-type bar integer) (+ bar bar1 bar2)) In Case 1 the type declarations are associated with the actual variables. These type declarations can also queried with the usual interface (similar to the interface in CLtL2). The type checks can be done before binding a variable with the argument. In Case 2 the type check happens AFTER the whole argument processing, thus computations in the parameter list are NOT protected by the check-type runtime type check. Plus there are no type declarations associated to the functions' interface. 
You're doing it wrong.
Literal array syntax is mostly useless for programming (because you almost certainly either want to modify the array in question later, or want to initialize it with non-constant values).
Did you know about REVAPPEND?
WTF is REVAPPEND?
Don't tell me you don't use REVAPPEND (and NRECONC) all the time!
Ahem. Haskell is not **not** ML. So, Haskel is ML. Right?
Only in a classical logic, where you have double negation elimination (~~a -&gt; a). In an intuitionistic logic you can only say that not Haskell is not ML, since you can use a devil's bargain to obtain ~~~a -&gt; ~a. It is all quite confusing.
Well, what good is a JPG of the title page?
He's the professor teaching me Lisp atm :) He has a lab in france where he does tests with languages and robots. Basicly robots are placed in a room with some objects (a yellow and blue square for example). One robot says something (in robot-language) and the other one has to point towards that object. The first robot then has to say if his partner pointed at the correct object. This is done a lot of times and after x iterations both robots have made 'their own language'.
You need to do way instain mother.
all hail gigamonkey!
I think it would be a good thing to create some kind of public repository for clbuild, as there is for asdf. Actually, I myself am more convinced about clbuild than I am about asdf, because I like more current versions of packages.
Is there a reason they renamed to Clozure? Surely *somebody's* going to get it confused with Clojure.
I think the company Clozure was there quite a bit before Clojure the Lisp. OpenMCL was renamed to Clozure CL at some point to reduce confusion with MCL, which now is also free and open source.
Does it work with SLIME? 1.3 for Windows doesn't like it too much.
Ah. I was under the impression that Clojure came first. My mistake.
'Clozure Associates was founded in 2000 by Gary Byers, Jeremy Jones, and Gail Zacharias.' The renaming of OpenMCL to Clozure CL happened quite a bit later - 2007 or so.. 'Clojure' was released first two years ago...
It does work well with Slime, don't know about Windows.
That's what I get for not looking it up, I suppose.
That's what the InterWeb is for. ;-)
Really? I've mistakenly been using it for porn this whole time. Whoops.
I concur. A happy birthday it is. Here's to many birthdays ahead!
That posts gives a great "spiritual" introduction to debugging under lisp, but in terms of a step by step I found this post from the same thread totally awesome: http://groups.google.com/group/comp.lang.lisp/msg/8317e7376a9571c8 However, to get full access to the features listed I also added: (declaim (optimize (debug))) to the top of my file, under sbcl. 
Do you have an ideao how would that be possible. Just drop an idea on mailing list, and if more users find it workable it might be implemented. AFAIK, ECL now use libffi for foreign calls, but I'm not sure if it supports c++
Juan is one of the Slava Pestov kind ;) Great guy. I wish there were more people like him in open source community.
Direct support for C++ is not necessary, C support is enough. Boost and the luabind code supplies the rest of the required template magic . Once it is done, if your classes and functions are simple enough, you barely have to write any glue at all. You declare your interfaces in specific (pretty declarative) format and the compiler does the rest. My C++ template-foo is nowhere near good enough to understand what goes on in luabind, let alone adapt it to ECL :-( 
For comparison the Allegro CL 8.2 (almost)beta case: cl-user(1): (defun foo (a) (declare (integer a)) (* a 3)) foo cl-user(2): (proclaim '(optimize (speed 1) (safety 3))) t cl-user(3): (compile 'foo) foo nil nil cl-user(4): (foo 12) 36 cl-user(5): (foo (read)) 1.2 Error: about to bind function argument a to 1.2, which is not of type (integer * *). [condition type: type-error] Restart actions (select using :continue): 0: store the value anyway. 1: Return to Top Level (an "abort" restart). 2: Abort entirely from this (lisp) process. [1] cl-user(6): 
If you set sb-ext:*derive-function-types* to true, SBCL should be able to deal with your example.
yes, it should, but I can't get it to do that. It does not work for me. Btw., \*DERIVE-FUNCTION-TYPES\* use the backslash to escape the \*
I found no changelog and no docs in the tarball... I'd like to know if this version supports compiling recursive functions (the previous one did not). Lush is nice conceptually, but has some weird problems: compiled and interpreted Lush are different languages, to a degree that makes me feel uncomfortable. Tail recursion is only supported in interpreted mode; type declarations are used in compiled mode...
Is this a significant blog? Is the spread of programmers representative.(What do we want it representative for?) Not sure if i am that impressed by 264 votes.
Whoa!
What's the use of holding and then reporting on a poll if you're going to dismiss the reported #1 barrier to using Lisp with hand-waving and circular logic?
&gt; Is the spread of programmers representative. 44% said they use lisp, at least sometimes. Hell no, it's not representative. Even if it was Java or whatever the 'most used language in industry' is these days, I'd still argue it wouldn't be a fair representation if nearly half of the respondants use it 'at least sometimes'. What negates the poll the most, however, has to be the very vague and broad categories for the responses, 'libraries, threads and similar', yeah, that pretty much sums up why I prefer scheme over C++ :P
It provides him (Kazomir Majorinc) emotional support for his perverse attachment to a retardedly-broken, non-standard, interpreted-only so-called-"dialect" of Lisp. That, or simply drives traffic to his blog.
I trust that Lush-3 will come with a hip techno beat.
It makes me lose faith in society every time I hear someone complain about Lisp's syntax. This link made me want to cry.
It's confusing at first. Admit it. I found the syntax really obnoxious when I first started trying to learn Lisp, but I loved the REPL so I kept trying to learn. Then I stopped when I sold my soul and took a .NET position to get a paycheck.
What's the advantage of Lush2?
Lisp wasn't confusing in the slightest bit when I started learning it. I'm sorry, but that's just the truth. It might be to others, but not to me.
it wasn't confusing after I used it for a couple of days, but prefix notation was awkward at first. Never minded the parens, it was always the prefix. Like how you had to rethink the arithmetic you'd been doing the same way all your life. For a lot of people that's a turn-off; to suddenly seem to lose an ability you were so sure you had. 
It was just awesome to me. Like I said, I don't speak for the majority. These are just my observations, and mine alone. 
One thing that I found confusing at first was not the parenthesis or prefix syntax, but the ease with which QUOTE converts code into data; until you are used to it, it can be difficult to see where you have created literals where you wanted executable code. Algol-family languages (and even BASIC and assembler) don't have this kind of beginner trap.
Well, the only thing I've seen thus far is that it compiles on Mac OS X nicely, without requiring me to muck about in misc. files and the switch to LGPL for the source license. The read me alludes to some PSU Lush changes being merged in, but I'd have to look closer before I can really see how much of a change this is.
I wonder if the PSU Lush changes make any difference in these regards; I haven't played with lush for some time, due to the compilation weirdness that you mention, so I'm curious to try this beta out. Besides, testing &amp; kvetching can only make it a better product, and I'm happy to do both. *edit*: I mean to say that I'll peruse my old code &amp; test out some of the notes I marked as **weird**; I've already compiled &amp; installed it :D
I haven't seen this blog posted on anything outside of newLisp-specific discussions; I think [sickofthisshit has it right](http://www.reddit.com/r/lisp/comments/9wapw/why_you_do_not_use_lisp_the_results_of_the_poll/c0era8z). *edit*: clarity
well, to be fair, the blog is pretty much a newLisp blog, so it might just be polling the number of people who actually *use* newLisp at all...
I see. I really like the idea, but haven't had the time to try it out.
It definitely is an interesting project, especially if you have something like Octave or Matlab that you need to work with, but prefer something more lispy. Besides, it can never hurt to try it out &amp; kvetch to the author when something breaks :D
Lisp syntax is not confusing. It is unusual, and therefore _seems_ confusing. And it is PITA to convert traditional numeric expressions into prefix form, but if you really work with lots of math, perhaps Lisp is not the best language for you. OTOH, say, C syntax does not seem confusing. But it is in fact confusing as hell. That's why this makes me lose faith in society too -- people believe too much in what it seems, in prejudices essentially instead of doing unbiased try. This sucks.
Homoiconicity, bitches! Recognize!
Newlisp. Fexprs, dynamic scope, functions identical to their definitions and mutable. 
&gt;Lisp syntax is not confusing. It is unusual, and therefore seems confusing. ...that's exactly what I was saying. That it's uncomfortable *at first*, so you start out with an awkward first impression. First impressions go a long way. honestly if the results of the poll make you lose faith in people, you need to get out more. The fact that Lisp's syntax is a turn-off for so many people should be immediately obvious to you if you know what people are actually like.
&gt; ...that's exactly what I was saying. That it's uncomfortable at first, so you start out with an awkward first impression. First impressions go a long way. No, it is very different from what you're saying. You said: &gt; It's confusing at first. I interpret it as that programmer who starts learning Lisp has problem with syntax. I do not think it is the case -- I had absolutely no problem with syntax when I started learning Lisp (I instantly thought it is totally awesome!) and I think other people have no problems either, because Lisp syntax is as simple as it can get, if anyone has problems WITH THAT, he shouldn't be programming, really. Lisp syntax might seem confusing BEFORE one starts learning Lisp. That is, when one sees Lisp code from a distance, and without trying to take a closer look start whining. BEFORE is different from AT FIRST, and AT FIRST does not happen at all if BEFORE make bad impression. &gt; honestly if the results of the poll make you lose faith in people, you need to get out more. The fact that Lisp's syntax is a turn-off for so many people should be immediately obvious to you if you know what people are actually like. Well, I did not any faith in people in the first place, sure. It just kills all the hope that people have a chance to be better than that, something like that. It was more like a joke. A sad joke... 
Your going through your first little bit of Lisp and you just start getting used to prefix notation, and then you hit an "if" statement and you're all "how did the inner expressions not get evaluated?" and now you've got to go straight to learning about the macro system, which could be completely new territory depending on your background. Coming from a C++ background, it was new territory to me. Your hand-waving "it's trivial" is just regular run-of-the-mill programmer condescension, and its attitudes like that that turn people off to good technologies (like Lisp). A lot of the worst technologies have friendly people that are willing to answer even the dumbest of questions, even if they don't know what they are talking about. Is that a *good* thing? Well *good* is subjective. For a neophyte that just wants to see something happen and doesn't care about the internals, yeah, it's a good thing. For someone who wants to invest a great deal of time into learning a black art, no, it's not a good thing. It's one thing to say "I like Lisp, here's why", but it's another thing to say "if you don't get it you're stupid". I don't know a lot of Lisp and I wish I did, I just can't use it at work and I have too little time to learn another technology in my spare time. I see it as a lost art and a truly amazing thing. But the attitude of superiority held by so much of the Lisp community isn't doing it any good. Oh and just to clarify as I had said in another post, I too thought it was awesome at first, but that's because I saw instantly where it was going in the long run. But it took getting used to, and that's a turn-off for a lot of people. So many people learn one or two languages and then stick with what they know. 
Oh I definitely liked it right from the start, I just thought it was a little confusing to get used to. Since I was almost finished with my computer engineering degree and had dicked around with a few technologies, I could see instantly why the syntax was good. It just took some experience to think about how to write certain things.
&gt; then you hit an "if" statement and you're all "how did the inner expressions not get evaluated?" and now you've got to go straight to learning about the macro system, which could be completely new territory depending on your background. Coming from a C++ background, it was new territory to me. It is not a syntax. It is semantics. Learn the difference. With lazy evaluation semantics it does not require any special treatment, but it is represented in same way, syntactically. &gt; Your hand-waving "it's trivial" Syntax is trivial (mostly!), semantics is not. Common Lisp has some non-trivial pieces of syntax, e.g. backquote, but it is not what people usually complain. While semantics is not trivial, it is rather easy, comparing to other languages like C++. &gt; its attitudes like that that turn people off to good technologies (like Lisp). This is the standard whining about "social problems of Lisp". I do not think it is true. Lisp community was always very helpful to me, when I was starting learning Lisp too. E.g. one can write about stupid problem he has to comp.lang.lisp, and get a multiple superb, detailed explanations. I haven't seen any other communities which are that helpful and friendly. E.g. on comp.lang.lisp you can get explanation from Kent Pitman himself, he posts very insightful comments on deep details of language design, Lisp history, etc. Can you imagine getting Bjarne Stroustroup replying to you? I betcha not. By the way, I still have a C++ question which is not answered for years. I asked in comp.lang.c++, in IRC channel, here on reddit -- no real response. For lulz, if you consider C++ community helpful, I can hand you this question, and you can try to find someone who can respond. Usually people who complain are people who like writing rants. There are a lot of Lisp advocates who like writing rants too, so clashes are inevitable. But why do they complain, it is like they are asking for it... 
your pedantry is tiresome. I'm bored of this.
When I started using Lisp, I wasn't really attached to any specific syntax. That, I'm sure, is a major part of it.
Quote is a little confusing anyways.
You are right, zemo, Lisp community as a whole is socially bellow the average. There are the reasons for that, but it is boring topic to discuss. However, it is not true for all Lisp communities - for example, PLT Scheme is extremely helpful community, and they have tools made for easy start, good IDE, literature. They did alot to make things easier to beginners. You cannot miss with PLT. Newlisp - that is what I use - community is also good one, but it is much smaller community, and not mainstream dialect. But I like the dialect the most. Both dialects are easier to learn than CL. Maybe other people have some other recommendations. You are also right that Lisp is hard to start. It was hard to me, and it was hard to two best programmers in real life I knew. It is especially hard for not full time programmers, for scientists, engineers. Whatever the reason, people are simply not hooked for that syntax, it doesn't make click. Killerstorm appears to be an exception. So, if you decide to go back to Lisp, pick carefully your community and good luck. 
Oh I'll definitely be going back to Lisp when I've got the time. I'm at the office eleven or twelve hours a day, so it's not possible at the moment. When I do pick up Lisp, I'll keep your recommendations in mind. Thanks for watching the thread.
yeah, like people who talk bad about other communities. That's why I dislike you.
Yeah, like your remark here, which is definitely socially below average, even though you think that your community is above average.
Clozure Common Lisp used to be called OpenMCL. It began as an open-source fork of the closed-source MCL. "MCL" is short for "Macintosh Common Lisp", a very good Common Lisp product for pre-OSX Mac systems that was available from about 1987. That Lisp was originally called "Coral Common Lisp" (or "CCL"), because the company that created it was called "Coral Software." A distribution deal with Franz caused its name to be changed briefly to "Macintosh Allegro Common Lisp", or "MACL". Shortly after that, Apple's ATG decided to buy Coral Software and its assets, including CCL/MACL. When Apple took ownership of the Lisp, it changed its name to "Macintosh Common Lisp", or "MCL". Later, Apple divested itself of most of what it had bought from Coral Software, including MCL. A new company, named Digitool, was formed to market MCL. During the Digitool era, a deal with JPL prompted the creation of the open-source fork, or "OpenMCL". For some years, "MCL" (a commercial product from Digitool) and "OpenMCL" (the open-source fork) coexisted. Clozure Associates was formed by some of the programmers who wrote the original Coral Common Lisp, and maintained it over the years. Their business is writing software for clients. They maintained OpenMCL and used it as one of the major tools in their toolbox for making clients happy. Fairly recently, Digitool finally wound down and dissipated, and it released MCL as open source. That created some potential for confusion, in that there were now two open-source Lisps derived from CCL: 1. OpenMCL, forked in the 90s from MCL, and maintained for years as an open-source Lisp running on many platforms. 2. Open-source MCL, a venerable commercial product running on the Mac, now newly open-sourced. Open-source MCL versus OpenMCL seems like an unfortunate couple of names, especially for two substantially different Lisps that are, confusingly, derived from the same ancestral codebase. So Clozure decided to rename OpenMCL to "Clozure Common Lisp". A very minor benefit of that renaming is that the name of the CCL package, which contains a lot of the implementation-specific stuff, and which was named back when the Lisp was called "Coral Common Lisp", now stands for the name of the Lisp for the first time since the late 80s.
The author posted on [Hacker News](http://news.ycombinator.com/item?id=850156). Doesn't look like it. He says it may get reincorporated into something else.
I was hoping this was about something else...
Same here.
I find that most people who bitch about the syntax or semantics of Lisp are those who are too lazy to change their way of thinking even a little bit, and pick an obviously eccentric aspect of the language to complain about so that they don't have to learn it. Think about it. Every time you hear someone complain about... * Python's use of white space * Lisp's use of parenthesis/prefix notation/macros * Haskell's use of monads * etc. Have they really ever bothered to shut the fuck up and try to change their train of thought, even just a little bit? Of course not. Ultimately they're lazy, and they assume what they use is sufficient and everything else is just weird or even useless; Paul Graham wrote about this. The thing is, the more people over-emphasize things that they collectively deem as hard about a language, the less people use that language. Unfounded FUD is spread like wild fire, and it's part of what keeps powerful, (relatively) unused languages unused.
I have a vague memory of this chump being annoying as hell on comp.lang.lisp
I agree with everything you said. Another thing that really bothers me is when people wont use a language because nobody uses the language. What the hell is that all about? Am I the only one who has noticed that people actually have to use a language in order for there to be people using the language? I mean c'mon.
For the same reason really good books exist unread, costing almost nothing, while mediocre books are consumed by the masses while costing an arm and a leg: most people thrive on some sort of herd evaluation. In turn, the mouthpieces of the herd stay relevant (and thus important) longer if they can recommend to the rest of the herd something that is comfortable and easily palatable for even the least intelligent/experienced of the bunch. Thus, the mouthpieces need to stay in power and thus recommend boring, mediocre ideas while the herd doesn't want to have to force themselves to think and instead turn to validation from the mouthpieces. Take reddit, for instance, where if you walk into a community-wide circle jerk of complaining, and attempt to make any observation which might cause the group's opinions to fall into question, you will be down-voted to the status of the "ILLUMINATI 9/11" and "4CHAN LOL" crowd, while anyone else who posts a comments along the lines of "LISP/PYTHON/WHATEVER SUCK!!1111" will instantly be voted up for vindicating the herd's ideals.
This is not confusing if the reason *why* this works--lisp code being composed of list literals--is explained right off the bat, as it usually is.
I think it might in fact be *more* difficult because it is explained very early on in the learning process, while one is still getting acquainted with the superficial differences (prefix notation, etc.) One is still getting used to the properties of the cons cell, including the CONS, CAR, CDR, LIST, etc. Almost immediately you are creating lists of symbols; now we have a very deep difference---in Pascal/C/BASIC the variable names are not usable as data. In Lisp, you have to very carefully distinguish between the use of a symbol as a name where it represents a value and the use of a symbol as a primitive data type. Likewise, you have to be careful when QUOTE is introduced, particularly because the quote character is only itself a shortcut for a list beginning with the symbol QUOTE. Merely reading "Lisp code is represented by lists containing symbols and other data" does not actually get one used to *dealing with* code which looks like data, particularly a data structure that one has just met.
Calling FFTW from Lisp does a 1M-sample array in 0.22 seconds for me. The same array takes my library 0.72 seconds. 
Holy shit, it is 20 minutes already and he haven't started yet to describe what Sheeple is. Are you people really *that* patient to watch 100 minutes of this? I've found some code snippets at page 68 of [the slides](http://sykosomatic.org/sheeple/sheeple-talk-22-10-09.pdf), but there are too few of them to understand how is it different from other prototype-based OOP frameworks. 
Yeah, a big part of the talk is focused more on trying to explain what the big deal was with prototypes, less so on Sheeple. If you want to jump straight to Sheeple instead of all the hand-wavy "this is why this concept is awesome", you should probably skip the first half or so of that video. You can also check out actual examples [here](http://github.com/sykopomp/sheeple/tree/devel/examples/). EDIT: nicer hyperlink
Thanks, good examples.
[You sick bastard ;-)](http://github.com/sykopomp/sheeple/blob/devel/examples/elves.lisp)
fusss: &gt; you can reverse-engineer \[the $90 book\] from [the code](http://www.qrg.northwestern.edu/BPS/directory.html), if you have some PAIP chapters under your belt
Note also that there is a companion book [$38] which contains the code listings (only), though it appears to be out of stock: http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&amp;tid=5373
Has anyone worked through this book? How good is it (both in terms of the concepts covered, and how the concepts are taught)?
Thanks for this well written and handy tutorial.
I wish I'd had this a few days ago. I was going to blog about ECL compilation myself but this is quite good. The only note I'd make is that it may be easier to generate standalone binaries by writing an appropriate ASDF system definition and then running (asdf:make-build :system-name :type :program :monolithic t :epilogue-code '(main))
 (setf *debug* nil) (seed-knowledge) (time (generate)) takes ten minutes on my Mac using SBCL, assuming that the whole code is saved in a file, compiled and loaded. 
This is excellent. It walks you through his thoughts and his process as he was coding this, and its well written.
That code is pretty bad. * initialize all special variables with DEFPARAMETER before you use them * use #'equal and #'equalp for hashing comparison of strings. It is not ANSI-compliant to use #'string-equal * using COND instead of WHEN is stupid * SETQ is deprecated by SETF * too much repetitive code in general. Use macros or helper functions. &gt;WHAT DO YOU GET WHEN YOU CROSS A BUG WITH A RELATIVE? &gt;ant I... don't get it!
Your ant is married to your uncle.
A sourpuss, I presume.
there are even more problems * EQ to compare numbers and characters is wrong * substring is SEARCH, mostly during the AI boom, when lots of researchers in 'natural language processing' were using Lisp, you could see a lot of this code. Some of that is still printed in books...
Does SBCL complain that string-equal can't be used as a :test parameter for make-hash-table? I needed to change it to equal (instead of string-equal and string=) for CLisp and ECL.
* string-equal -&gt; equalp (case ignored) * string= -&gt; equal (case not ignored) yes, SBCL complains 
Thank you. This [hyperspec entry](http://www.lispworks.com/documentation/HyperSpec/Body/f_mk_has.htm) is relevant. Edit: Somehow, I missed [Grue's comment](http://www.reddit.com/r/lisp/comments/9xzn5/what_do_you_get_when_you_cross_a_cat_with_a_lemon/c0ezm1n) which would have answered my question.
note that the SBCL website still reports 1.0.30 as latest version.
The lisp source code is perhaps not something to take good example from: no earmuffs on specials, setq galore, indentation, ...
I haven't looked at the code much, but the lack of earmuffs at least is in line with the style actively promoted by his book.
He's the author of Let Over Lamda which uses some atypical conventions.
:frameworks
Hunchentoot and libraries
UCW (bare)
Lisp on Lines
Weblocks
Antiweb
teepeedee2
I've used Arc, but mainly as a way of learning Lisp, not for any public, usable website.
Well, I took a look at a few frameworks. UCW doesn't do URLs properly (it encodes state in them, instead of using [cool URLs](http://www.w3.org/Provider/Style/URI). Weblocks looks smart, but was glacially slow when I reviewed it. KPAX doesn't look very well supported or documented. I ended up rolling my own on top of Hunchentoot and CL-WHO. Kanamit sounds interesting--I just discovered it
No packages(!! wth !!), no documentation strings. I kindah hate side-effects... Should only be effect external of a function when that function is defining something, or as transparently as possible when memoizing. And i love using specials as specials, not as global variables. I see them as arguments that you pass without having to retype that you want to pass them all the time. Also, he got a little crazy.. (but don't we all?) ; lisp (#~s/,// ; /\ THE GOLDEN TRIANGLE (#~s/0x/#x/ ; / \ \ (#~s/'/#\/ ;.----. perl \ (#~s/',// ; || \ (#~s|/[*].*?\n|| ; || THE HOLY TRINITY / \ ; C / \ 
Where can be found more examples on Antiweb? It certainly looks interesting.
hu.dwim.wui from http://dwim.hu/
This StackOverflow question (and the one it links to) seems relevant to the discussion: http://stackoverflow.com/questions/540953/best-web-framework-in-common-lisp
Kanamit is definitely the most advanced.
allegroserve
No frameworks should have less than zero votes.
I downvoted just to spite you. Not because I hate you, but because of the lulz.
UCW (modified)
Doesnt it build? Does it make sense to upgrade?
Kanamit, heh. Whoosh. There goes your credibility.
It's usually released once a month, so if 30 days have gone past, there's probably a new version for you.
still on 1.0.30 and liking it.
I'm not sure when you tried it last but [this thread](http://www.mail-archive.com/weblocks@googlegroups.com/msg01700.html) describes some compelling performance improvements made by Leslie Polzer and the addition of profiling tools specifically for weblocks. Might be worth having a look again. :)
UCW does URLs just fine. You create entry points into your application as cool URLs. Any dynamic behaviour beyond that is then managed with the encoded state. These dynamic URLs still contain the cool URL, so a request 6 months down the track will get you to the same place anyway. For my own stuff, most of the dynamic behaviour is called through ajax. For browsers without JS they will get the uglier URLs when a dynamic action isn't part of a form (the state is in hidden form inputs).
this code smells bad
CL-USER&gt;(lisp-implementation-version) "1.0.29.54.rc5" :)
&gt; There goes your credibility. Why?
I always want to ask people who use HT/templating directly: how many pages does your site have, approximately? And within a page, is there a lot of interactivity (and if so, is it scripted through lots of javascript, or some other mechanism (html-forms with hunchentoot callbacks?))
For users of arc: 1. if you've used other frameworks, is it very different (more basic?). 2. is it rest-focused, or "embed actions as closures" focused? 
&gt; Redirect Loop &gt; &gt; Firefox has detected that the server is redirecting the request for this address in a way that will never complete. I disable cookies for sites that I don't trust. Though I suspect I'm in the &lt; %1 that does this [1], the default behavior of the site doesn't fill me with faith. 1. [SWAG](http://onlineslangdictionary.com/definition+of/swag)
allegroserve seems to be getting a lot of hate, especially given that people are voting it up because "[No frameworks should have less than zero votes.](http://www.reddit.com/r/lisp/comments/9ymg7/lisp_web_frameworks_poll/c0f1zhk)" (Including myself, as I agree.) However, there aren't any comments about why allegroserve *deserves* to be voted down. Please add some?
Core server
dwim.hu is v0.1, the codebase under it is at the last phase of a big refactor. ...and yes, detecting that cookies are disabled is not among the top10 entries on our TODO.
It's been updated to 1.0.32 now.
Try http://arclanguage.org/forum
Heh...I was being honest--I had _just_ discovered Kanamit. After actually looking at it, I discovered it was a joke. Oh well:-)
Kanamit appears to be a joke.
My site has about 157 pages. There's no interactivity right now--all it does is display database entries in a pretty fashion. I keep on meaning to add CUD to the R, but haven't gotten a round tuit.
Well, it looks like a joke for which I don't understand the punch line.
Meh, state encoded in Base64-encoded binary blobs is a code smell IMHO.
We must be talking about a different UCW. The state isn't actually encoded into the URL, rather you have two pointers to a continuation. Every time you load a page through an entry point a new frame is pushed into your session state on the server side. Whenever you create a new continuation, an action is pushed into the current frame (as an action). The id of the frame and action are the state in the URL (or hidden form inputs). You'll also find that in the context of AJAX, the action/frame id ends up being the equivalent an action token for defending against XSRF attacks.
You know, taking those uppity lisp nerds down a peg.
There's also a Toronto meeting that day. Decisions, decisions...
Sorry about it, but you will need both cookies and javascript enabled to make it work.
Though the English translation is not perfect and the PDF has some problems, it is still easier to read than the Japanese version : http://cl-www.msi.co.jp/solutions/knowledge/lisp-world/tutorial/compiler-eval.pdf At least for me. ;-)
&gt; "Oh man was I wrong! Why would the difference be so big? A profiler would come in handy" you think?
that's quite damning. has there been a response from the lisp community?
&gt; The state isn't actually encoded into the URL, rather you have two pointers to a continuation. Which is...state, encoded into a continuation. &gt; You'll also find that in the context of AJAX, the action/frame id ends up being the equivalent an action token for defending against XSRF attacks. That's cool, but putting it in the URL is ugly and IMHO wrong.
A few remarks: The numerics of Common Lisp is quite different from what a C programmer expects. Declarations are a mixed blessing. You can declare a function that adds two numbers to take two fixnums and to return a fixnum. But that is lying. Generally adding two fixnums either returns a fixnum or a bignum. So the declaration is not a type declaration, but a 'type restriction', an instruction for the compiler?! But then it is changing the semantics of the program. Before adding two fixnums could result in a bignum. After the declaration you may get a different result, but not a bignum. CL-USER 172 &gt; (foo most-positive-fixnum most-positive-fixnum) 2305843009213693950 CL-USER 173 &gt; most-positive-fixnum 1152921504606846975 Now the optimized function FOO with FIXNUM declarations: CL-USER 174 &gt; (foo most-positive-fixnum most-positive-fixnum) -2 Now we have a different result. Then there is the issue of tagged numbers. A single function that needs to extract the values has some overhead. Interesting is also the case where a larger function with multiple expressions should be compiled such that this 'boxing'/'unboxing' is minimized. LispWorks needs another declaration to generate unsafe fixnum code: FIXNUM-SAFETY. Lucid CL (aka Liquid CL) had the following strategy: there is a relatively dumb interactive ('development mode') compiler. It is fast though. There is a also 'production mode' compiler. The compiler works in 'production mode' much slower, but generates (much) more efficient code. The 'production mode' kicks in when COMPILATION-SPEED is 0 (and one optimizes with SPEED 3 and safety 1). 
What, no PLT? :-(
Eh. There is two different CL implementations where several people are working full time with. There are at least 3 other implementations where 1-2 people are working with their language implementation and consulting customers. Then there is many open source implementations with fast compilers. I would say that there is several Shuttleworths in Lisp scene. 
Here is my response. I do numerical compuations in CL, [just like others](http://www.lispworks.com/success-stories/raytheon-siglab.html) Why CL? All numerical computing systems call libraries written in C/Fortran to do the most of the number crunching (nowadays even sending stuff to GPGPU) However, using portable assembler to write your whole application is not ideal. You want as high level language as possible with minimum speed penalty. There is lots of [competition](http://en.wikipedia.org/wiki/List_of_numerical_analysis_software). Matlab is the most known, but, there is lots of alternatives to choose form. Most recent newcomers are numeric computing libraries written in Python. None of these is as fast and dynamic as CL. Matlab has tons of libraries but the language sucks small planets. R is cool and all but it's slow as hell. CL hits kind of sweet spot of being extremely dynamic and allowing low lever optimization. Yeah, Implementors have still room for beating the shit out of the compilers, but CL is already the winner. You still call C libraries for most intensive number crunching, but you can write most of your stuff in high level language with acceptable speed penalty. --- ps. Intresting post from Ross Ihaka (one of the persons behind R-language): [Ross Ihaka's reflections on Common Lisp and R](http://old.nabble.com/Ross-Ihaka%27s-reflections-on-Common-Lisp-and-R-td17100237.html#a17100237) &gt;We started work on R in the early '90s. At the time decent Lisp implementations required much more resources than our target machines had. We therefore wrote a small scheme-like interpreter and implemented over that. Being rank amateurs we didn't do a great job of the implementation and the semantics of the S language which we borrowed also don't lead to efficiency (there is a lot of copying of big objects). R is now being applied to much bigger problems than we ever anticipated and efficiency is a real issue. What we're looking at now is implementing a thin syntax over Common Lisp. The reason for this is that while Lisp is great for programming it is not good for carrying out interactive data analysis. That requires a mindset better expressed by standard math notation. We do plan to make the syntax thin enough that it is possible to still work at the Lisp level. (I believe that the use of Lisp syntax was partially responsible for why XLispStat failed to gain a large user community). The payoff (we hope) will be much greater flexibility and a big boost in performance (we are working with SBCL so we gain from compilation). For some simple calculations we are seeing orders of magnitude increases in performance over R, and quite big gains over Python. There is lots to do. We're experimenting with syntax and making a start on assembling quality numerics libraries. Creating a fully-featured system will require buy-in from the statistical specialists who can contribute implementations of their methodology, so we also thinking about issues associated with community building (eg. licensing). 
Why would a report presented at the [European *Common Lisp* Meeting](http://weitz.de/eclm2009/) present PLT?
though it would be interesting how the 'better' or the 'popular' Scheme compilers compare
Win32 binary releases for latest versions have been made available at h**p://ntemacs.sf.net for those too lazy to compile or without access to MinGW/MSYS build system. PS: These builds are unofficial. 
Damning in what way? Lots of language implementations don't fold constants particularly well or do common subexpression elimination and that hasn't hurt their adoption. The open-source response is "Go forth and code." However, since the commercial vendor compilers don't do some of the optimizations mentioned in the paper, I'd guess their customers are pleased with the performance/don't do matrix-multiplication numerical computing/etc. etc. It's also worth noting that some of the language implementations Redditors think are the bee's knees don't do these optimizations either: O'Caml, IIRC, doesn't do things like common subexpression elimination.
My favorite, at the moment, is [#f](http://code.google.com/p/false/). It *would* be interesting to see code quality size at the machine code level, but then it would have to rely on C compilers as well (since many main stream scheme systems use C as an IR). Still, it wouldn't be hard to compare; I'll pull some tests together (partially based off of this report) and see. *edit*: formatting 
A better version, no character problems: [An evaluation of Major Lisp Compilers, Seika Abe](http://cl-www.msi.co.jp/solutions/knowledge/lisp-world/tutorial/compiler-eval-dvipdfm.pdf)
why not? :) 2011?
&gt; How can we make Phosphorus less like Arc and more like VBA? I'm there!
Phosphorus-VBA will be the new 100-year language! (It already seems like VBA has been around for 100 years.)
I _suspect_, although I could be wrong, that it's a row-major vs. column-major array representation issue and that he's getting lots of cache misses when using implementation-provided 2D arrays. He should flip-flop array dimensions and take a look at how that performs.
[A follow-up](http://subvert-the-dominant-paradigm.net/blog/?p=38).
How does this solve fasl files generated in the same folders by different implementations? I have run into this problem before. (atleast clisp creates .fas files. they don't clash with others.)
Check out [asdf-binary-locations](http://common-lisp.net/project/cl-containers/asdf-binary-locations/).
First off, commenting and uncommenting "(setq inferior-lisp-program)" in .emacs is crazy. You need to be able to run several lisps simultaneously! Slime provides slime-lisp-implementations variable. To run a non-default lisp run M-x slime with a negative argument (M-- (that's Alt-minus) M-x slime). Example (with CLISP set as inferior-lisp-program): (setq slime-lisp-implementations (append slime-lisp-implementations '((sbcl ("d:/sbcl/1.0.29/sbcl")) (ccl ("e:/programs/clozurecl/wx86cl" "-K utf-8"))))) Also, the method of installing libraries could be improved. Instead of adding all subdirectories to asdf registry when the lisp starts (which would ignore all libraries installed since then - and usually you don't want to restart lisp all the time), the directories could be searched dynamically. The code basically goes like this (c) Peter Seibel: ;;; Method for finding ASD files that doesn't depend on symlinks. (defvar *top-level-directories* ()) (defun sysdef-crawl-directories (system) (let ((name (asdf::coerce-name system))) (block found (flet ((found-p (file) (when (and (equal (pathname-name file) name) (equal (pathname-type file) "asd")) (return-from found file)))) (dolist (dir *top-level-directories*) (walk-directory dir #'found-p)))))) (defun register-source-directory (dir) (push (pathname-as-directory dir) *top-level-directories*)) (setf *system-definition-search-functions* '(sysdef-crawl-directories)) (register-source-directory "c:/lisp/") (this depends on CL-FAD, so you might want to load and use-package it first) Yeah, it gets kinda slow when you have lots of libraries in there. 
Thank you very much for this how to, I will be setting up Slime for my Emacs real soon :)
Related point: deciding when to do cse is actually quite hard, since it can be a significant loss in many common cases. Laziness makes this still more complicated, but even then, its noteworthy that ghc implemented and then rejected full cse (while retaining a small "opportunistic" subset) for precisely this reason.
I didn't know that about GHC. Thanks for the information. I think the message I read about O'Caml said they had made an explicit choice not to do it as well.
&gt; * 2009-Jun-17: &gt; EOF Come on, don't leave us hanging, there!
Well, the port is unfinished. Would anyone be willing to pay to see Alastair finish the port?
One issue is that SBCL is pretty heavyweight compared to CLISP (byte-compiled) or Clozure Common Lisp. It might not be suitable for production use in embedded environments. I think the most likely chance for people with money to get CL compiled on ARM is to pay Clozure (who are set up to take money, although nyef would too, I am sure). That said, I am a big fan of nyef, and would be excited to see him do this.
ECL wouldn't be a candidate?
So...precise GC then ARM port? But yes, CCL is well-suited for this assuming someone is paid to do it. I bring up SBCL mostly because the port is started and nyef actually suggested I put a poll on reddit a while back when I asked him about the progress on it. :)
ECL already works fine on OpenBSD/ARM. CLISP at least had a port to linux/ARM for the Zaurus. ARM computers like [the PC-Z1](http://conics.net/catalog/product_info.php?products_id=572) and [the plugcomputer](http://plugcomputer.com/) are not too embedded for CL.
I don't know much about ECL, but I did think about it while writing the post. For fair comparison, my understanding is that you would also need a C compiler to get functionality beyond a byte-compiled interpreter. As opposed to SBCL/CCL/CLISP which are more self-supporting.
I thought SBCL already had a precise GC for non-x86. Or are you asking whether I would prefer nyef to work on a precise x86 GC for SBCL in preference to working on an ARM port?
I see nothing [here](http://sbcl-internals.cliki.net/Stop%20and%20Copy%20GC) about precise GC but you may be correct.
This is all Lisp-powered, of course... * Drakma for fetching Google Calendar XML and posting to twitter * CXML and CXML-STP for processing the Google Calendar feed * A little CL-WHO It was fun to make. 
How is CLISP different from ECL? CLISP does compile to byte code, as can ECL. ECL has the added option of compiling via a C compiler.
I'm currently contemplating a possibility of buying N900 (when it's available) so that I can run CL there and maybe hack together some useful stuff right on the phone by connecting there from SLIME. As far is I know, with no working ARM ports of SBCL and CCL, the only more or less full CL implementation that can currently run on Maemo is CLISP. [Here](http://github.com/Shmuma/ffcall/) is a working port of ffcall library to linux/armel that is needed for FFI. It's known to work on Maemo4. The problem is, I'm not 100% sure it'll work on Maemo5... I tried to download Maemo 5 SDK, but trying to build CLISP on ARMEL architecture using qemu gives SIGILL when starting CLISP for the first time (during make). I hope it's qemu thing, otherwise N900 would be rather worthless... 
Not to mention 'f instead of nil.
See the comments in this thread. ECL compiles fine on ARM. It works with SLIME and the developers have been **very** responsive to any problems I've had on the mailing lists.
Great idea.
3sat report in German about the Book: http://www.youtube.com/watch?v=ise6zOkWlVk
A lambda manga?
this is amazing - anyone keen to translate it?
Dear Amerikan. How do I write program. I have foundo a manga comikku with kawaii shoujo that said about writing program. Amerika pipuru rafu at me when I say "konsu". I do not understand.
Awesome, a lisp intro where the lisp code is the easiest part to read even for a newbie.
Ah, what memories. I used this book when I was learning to program my uni's 3600 back in 1987.
I second this request :)
All textbooks should look like this and be presented this way.
It would probably make targeting gcc with a CL compiler a lot easier.
How does one get listed here?
It says it's public, so click the "Edit" button, use the placemark tool (in the map area), and save it when you're done.
Has "lisp" always meant "common lisp", and should that still be the case today?
Yes, that's problematic practice. However, is anyone able to estimate how many people use Common Lisp as their main programming language today? 
It's certainly more common than Scheme or newLisp; the only Lisp family member that might be catching up is Clojure. Also, it depends on how many people are hacking out EmacsLisp &amp; AutoLisp. 
That was kind of RECURSIVE. Zing.
Upvoted for Lisp code in title.
Not that wacky once you know how letrec is implemented.
See the other reddit page http://www.reddit.com/r/programming/comments/a29qx/
I'd guess there are many more Scheme users than Clojure users. There are many maintained Scheme implementations, some are used in education and teaching. The educational Scheme texts are still used in schools and universities. Some tools have Scheme embedded.
&gt; should that still be the case today? whatever it takes to contain the newLisp damage, I'd say.
http://xach.livejournal.com/234320.html has some more explicit directions.
I could agree with that, only that Clojure is the only one I *could* see over taking Scheme (and possibly CL) at the moment, given the large base of Java developers. I don't think (for instance) that [Arc](http://arclanguage.org/) or [Nu](http://programming.nu) are positioned as well as Clojure is to overtake established Lisp languages. 
what "newLisp damage" do you refer to? I've never run into someone that, when I said "Lisp", retorted with anything that even mentioned newLisp in the slightest. Come to think of it, I've never seen it on LispNYC either. Don't get me wrong, I'm not really a fan of newLisp; however, I've never seen any "damage" caused by newLisp, other than people arguing about the strange номенклатура that surrounds it.
Imperatively -- which makes sense from an implementation standpoint, but from a programming standpoint I always treated `letrec` as being side-effect free. Obviously on the metal it's all imperative, but functional languages usually try to make side effects explicit in some way or another. As a relatively poor Scheme programmer myself, I would never have considered that `letrec` might behave this way. Anyway, I thought it was pretty neat. Scheme is a cool language.
bah, s/contain/prevent/ if you swing the less-paranoid way. &gt; номенклатура I've given up due to disgust way earlier, but I believe you!
Fair enough; I agree with your sentiment, I just haven't seen newLisp actually *produce* much other than reactions from other types of Lispers. To me, it's reminiscent of MacLisp (or other pre-Scheme/CL system), and was an interesting attempt, even if it is something I would *never* use for real work.
I'd say that Clojure has a long way to go, given the infrastructure of Scheme: 100+ implementations (using all kinds of implementation strategies), dozens of books, many courses, hundreds or even thousands of research papers, international standard, US standard, ... http://library.readscheme.org/index.html Scheme runs basically everywhere on all kinds of computers, processors, operating systems - not just on the JVM. That there are lots of Java programmers is no indication that those will switch to Clojure.
MacLisp had a good compiler.
Dunno; I use Scheme as my main language (one custom dialect, Scheme 48, Gauche &amp; STklos) and I could easily see Clojure overtaking my work. In my current office, I'm one of two people who have any background in Lisp, but quite a few people are using Clojure now for things they might have used Kawa or SISC a few years ago. There's buzz about Clojure, there's a PragPub book, and it's generally receiving praise for it's STM &amp; other features. Besides, I'm not sure that Scheme having 100+ implementations is necessarily a good thing; Clojure has one or two (if you include the .NET DLR version) implementations, meaning that Rich &amp;al are working on improving only **one** system. I think Scheme is attempting to catch up with R6RS &amp; things like [Nausicaa](http://wiki.github.com/marcomaggi/nausicaa), but there is a decent subset of the "Scheme community" that won't use R6RS in it's current form (or are holding out for R7RS small). **Also** I think that the JVM runs in enough places that most Clojure users don't really have to worry about "all kinds of computers, processors, operating systems". I didn't say that "lots of java programmers == Clojure domination"; I simply stated that it's in a *better* position, since you can use what you *already* know, as a Java Programmer. Ruby, Python, Groovy, and Scala are similarly poised. 
Why yes it did; I meant that newLisp reminds me of the older lisp systems, not any jibe against MacLisp.
With every language on the JVM you can reuse the knowledge of the Java libraries - just by calling them. Other than that I don't think one can reuse much knowledge from Java for Clojure. Both are sufficiently different programming languages. There are other languages that don't have that large conceptual gap (syntax, semantics, pragmatics) to Java and which also are running on the JVM. I think the conceptual difference between Java and Clojure is huge. With a bunch of Java programmers I would give them something simpler, but interactive and with less bloat than Java. I'm not sure I would use a language that is not object-oriented, has a completely different syntax and is mostly developed by one guy (if he stops developing it, it may stall). Java is used in enterprises and Clojure does not look very enterprise-minded. It is cool and intelligent people like it - but that will not result in a better position, since it lacks other 'appeals'. Just thinking about the possible damage 'average' Java programmers can do with an advanced Lisp dialect makes me shiver. That the JVM runs on 'enough' places does not mean I would want to use it. If I can get rid of an additional layer of cruft, I'll do it. 
Certainly; I don't see anything that is contrary to what I said. My point simply was that Clojure is in a better position; I think most of your arguments could be leveled against Scheme, and it wouldn't necessarily have the "features" that programmers might like in Clojure. &gt;That the JVM runs on 'enough' places does not mean I would want to &gt;use it. If I can get rid of an additional layer of cruft, I'll do it. You use a lisp machine, I use Scheme; I severely doubt that anyone "enterprise-minded" really cares about what we think. That said, which is in a better position: Scheme, with 100+ implementations; CL with excellent "enterprise-minded" implementations that may not necessarily and/or easily tie in to what you're already using (ACL &amp; LispWorks do, but the "easily" part is somewhat lost) ; or Clojure, which can be plunked down atop basically any JVM install. Some of these arguments work in favor of ABCL and Kawa (&amp;c.) as well, sans what I've already mentioned (that they might lack features people would be interested in; granted you can have STM in CL, but is it tested atop the JVM &amp; with ABCL, is it easily deployable? Does it use ASDF or XCVB? &amp;c.). 
I don't use STM and I don't care - it's not a feature I base any decisions on. As a Lisp user I don't use the JVM and I don't care about Java infrastructure. I use operating systems like Mac OS X, Windows, Linux, Solaris, and my Lisp Machine's. None of that requires me to use Java. I would not even write my own hobby software on top of the JVM. If I'd use Clojure, I'd lose a bunch of features I like. As a Lisp user I would use Clojure (and thus the JVM) if it would offer me something that I would be practically interested in. So far I haven't found much. I know people who are coming from the JVM/Java world, who found Clojure useful and I can understand why - but for me the JVM stuff is useless and gets in the way. Why should I give up the LispWorks IDE or wait for something comparable on Clojure? Why should I give up dumping images? Why should I dump my Common Lisp code? Why should I reduce the performance? Disclaimer: I have done Java projects as a project manager and consultant for several years.
I never stated that "Clojure will convert the uncleaned masses of Lisp users", only that it's in a position to overtake some other Lisp systems in terms of numbers of users. I use Scheme, and I too lose features I like when I use Clojure, but guess what? None of my colleagues care, since they want *specific* features that Clojure at the moment gives them. I'm *guessing* that in the future this might be true with more &amp; more Java programmers. So, you don't use Java, that doesn't mean that *no one* does. Also the "I don't use STM and I don't care" doesn't mean that *everyone* doesn't or won't care; in the future, on a future project, you too may care about it. Of course, being a CL user, you could just hack one together or use [CL-STM](http://common-lisp.net/project/cl-stm/). &gt;If I'd use Clojure, I'd lose a bunch of features I like. As a Lisp user I &gt;would use Clojure (and thus the JVM) if it would offer me something that &gt;I would be practically interested in. So far I haven't found much. I know &gt;people who are coming from the JVM/Java world, who found Clojure &gt;useful and I can understand why - but for me the JVM stuff is useless &gt;and gets in the way That's exactly what my point was; people who are *using* Java &amp; the JVM might find Clojure more "accessible", since they can plunk it down &amp; use it. I don't recall claiming that it will suddenly lead to a sacking of CL/Scheme programmers; my *thought* was that given a segment of the Java community may be interested in Clojure, and this number, over time, could over take the number of people using CL &amp; other Lisp system. &gt; Disclaimer: I have done Java projects as a project manager and consultant for several years. That's ancillary; I never said you didn't know what you're talking about or couldn't understand since you've never used Java, or anything similar. My **initial** point was that I could see Clojure build up steam due to interest from Java programmers, since there are significantly more of them than Scheme or CL programmers (at least professionally). Nothing more, nothing less.
&gt; That's exactly what my point was; people who are using Java &amp; the JVM might find Clojure more "accessible", since they can plunk it down &amp; use it. More accessible than what? Java? Ruby? Python? JavaScript? Groovy? Lisp? Scheme? Almost nobody cares. I doubt that many Java/JVM users are using Clojure because it is a more accessible Lisp or because it is a Lisp at all. Tim Bray [writes](http://www.tbray.org/ongoing/When/200x/2009/10/26/Messaging?1): 'If only Clojure weren’t a Lisp...' I guess people use Clojure, despite it is a Lisp, because Rich Hickey did develop an interesting programming language with a nice design.
More accessible by way of "drop and use"; as I **already** pointed out, Scala, Groovy, Ruby, Python &amp;c are similarly positioned. The argument is not about those languages, simply that Clojure **could be** the next "Lisp". &gt; Tim Bray writes: 'If only Clojure weren’t a Lisp...' He might think this but this: &gt;I guess people use Clojure, despite it is a Lisp, because Rich Hickey did &gt; develop an interesting programming language with a nice design. is most likely why he's spending [time discussing it](http://www.google.com/search?as_q=clojure&amp;hl=en&amp;ie=UTF-8&amp;btnG=Google%2BSearch&amp;as_qdr=all&amp;as_occt=any&amp;as_dt=i&amp;as_sitesearch=tbray.org) *Edit*: formatting.
letrec doesn't have any side-effects.
Whats so special about that? Creating a simple Lisp-Interpreter is easy - one strength of lisp.
For the record, I didn't downvote you, but you may want to read the link more carefully. The whole point is that in the presence of first class continuations, you can create a mutable cell with `letrec`.
Mhm. The continuation in the `letrec` form is just before the value is assigned, whereas in the `let` form it is to whatever follows the entire form. But just because it uses mutable state internally doesn't mean it has side-effects. That would mean running the form again would give a different result. It doesn't.
In this particular example, no -- but you can create an implementation of `set!` using `letrec` and `call/cc`, which is explained [in the original Usenet post](http://groups.google.com/group/comp.lang.scheme/tree/browse_frm/month/1989-03/367ac22c681623fd?rnum=1&amp;_done=%2Fgroup%2Fcomp.lang.scheme%2Fbrowse_frm%2Fmonth%2F1989-03%3F#doc_063a514aa6933180). `set!` is generally considered to be side-effect inducing, and informally one expects a composition of side-effect free functions to be side-effect free. EDIT: I realize that this is the result of the implementation of `letrec`, and I also realize that in Scheme this is not really a "problem" in the same way it would be in say, Haskell, where side-effects are meant to be explicitly encapsulated. Because the underlying hardware is not functional, every side-effect free function is fundamentally going to be implemented using stores and loads.
Toy Lisps seem to botch (&lt; x y z) pretty frequently.
this really looks cool!
Hmm. This is interesting. I wonder if I could combine it with my opengl based repl..
 It has an unholy number of dependencies... http://repo.or.cz/w/glrepl.git
As much lisp as possible was one of my design criteria. Working with foreign libraries equals maximum pain..
#2 could use another take. He said that factorials end in a lot of zeroes because every time you multiply by a power of ten, you get zeroes added to the end of the number. Actually that happens every time you multiply by a multiple of five, since there are plenty of twos around to give you a factor of ten. Otherwise, it's nice to see that someone is doing this. Lisp seems to need a lot more beginner-friendly introductions. I use Common Lisp, and I love it, but I think the statement that it has extremely simple syntax is stretching things, considering the various special forms, notations using punctuation marks such as single-quote and the sharp symbol and the dot, and the un-Lispy worlds of LOOP and FORMAT, not to mention conventions of using asterisks and plus signs to indicate dynamic variables and constants, colon notation in connection with packages, colons for keywords, and so on. To think of Lisp syntax as having nothing more than open and closed parens to worry about is to ignore a rat's nest of exceptions to that pattern. With macros especially, it seems all bets are off in terms of whether a symbol, a single-quoted symbol or a colon-prefixed keyword will be required in a given situation. I suppose it will make better sense to me after a few more years - or maybe in a few hours after people point out the technical errors I've probably made in this single paragraph.
yes, the s-expression syntax is relatively simple. But s-expressions are not all valid Lisp programs. Example: (cl:defun foo bar baz) Is not a valid Common Lisp program, because the arglist has to be a list. I've we say syntax determines the structure of valid programs, we can say that defun has a certain valid syntax - a syntax that is described on top of s-expressions. So telling the newbie that Lisp has a simple syntax is misleading - Common Lisp has lots of macros and special forms and one has take care to understand their 'syntax'. The Common Lisp standard provides this 'syntax' for every macro and special form.
That looks really nice. If only we could speed it up by an order of magnitude, we could use it for ray-traced games.
I really liked this I'm glad someone is making something to teach beginners I'd also like to mention if you just happen to have stumbled across these videos the practical common lisp book (great book!) is available for free online from http://www.gigamonkeys.com/book/
The cheneygc is precise, yes. 
I tried and succeeded made a **little** -only spheres so far- raytracer, based on distances, inspired on [this PDF](http://www.iquilezles.org/www/material/nvscene2008/rwwtt.pdf), but i just wrote directly to the SDL surface. Then i tried making any resulting distance affect all of the pixels for which the ray-traced distance is at that point within the sphere of the distance.(Doing more pixels at once.) Couldn't get it to work, though. Even if i forced it to do it for only a few pixels.. Haven't tried it much more, but i'd think i'd throw it in here just in case..
Wow, this was bad. I took a class on Scheme a few years ago and I'm a bit rusty, but I remember the general idea. I still couldn't keep up with these videos. He uses prefix notation before telling you that Lisp uses prefix notation. He uses macros without mentioning them. He doesn't mention that ! means that the text is overflowing into the next line, so you assume that he mistyped a "!" into his string of numbers. He makes a horrible mistake and asks you to find the bug in what is supposed to be the first example you've ever run across. The differences between things like let, define, defun, set, and setq are deep issues that he glances over in a few minutes with ambiguous examples. This is as bad as trying to learn Emacs and on the first page they assume you already know what "C-x M-c" means.
He drives the car through a few streets without telling you that there is an Anti-lock braking system, what it does and how it works...
This is a great! It fixes tail-call optimization problems I was having in 1.3, and hunchentoot now works for me in 64bit, though I admittedly didn't really spend any time trying to get it to work in 64bit under 1.3.
That's terribly hard to read.
Using srfi's as any kind of indicator of the usefulness of a scheme implementation is largely flawed too, as many don't require any specific changes to the implementation to support them. SRFI-1 for example can be entirely implemented with core r5rs functionality. SRFI-28's reference implementation will work on 100% of r5rs implementations that have SRFI-23 support, or can be modified to work easily if no support for SRFI-23 exists. Likewise, r6rs implementations have a natural advantage, since almost all of the SRFIs are now part of r6rs core (which is after all, pretty much the point of SRFIs), so r6rs implementations will 'appear' to be more conforming on a SRFI list, but may still be poor choices for an implementation for other reasons (especially if you're a r6rs-hater...) 9 and 6 are probably the key SRFIs that are absolute must-haves, and they're up there at the top of the table for a reason - almost everyone supports them (altho srfi-9 includes a reference implementation that only really depends on define-syntax)
I had a pretty lengthy correspondence with the guy who wrote SRFI-1. He spent a *lot* of braincells optimizing it for speed and flexibility. It's a major chunk of his life's output, so I doubt rolling your own from r5rs functions is going to go down very well. I agree with everything else you've said, though, from experience.
Except SRFI-1's reference implementation IS rolled from r5rs, you can just use it as-is in 99% of the scheme implementations. Any optimisations Olin performed are done in standard r5rs function usage - I'm not saying it's not optimised, I can believe it is, and the comments in the reference implementation he wrote certainly do bear out that he spent time and effort on optimising it, but the fact remains, it doesn't require any 'special support' by implementations.
cache: http://web.archive.org/web/20080429234811/http://lists.warhead.org.uk/pipermail/iwe/2005-July/000130.html
Playthrough: http://www.youtube.com/watch?v=oFgBI32r7Qo
Does anyone knows which CL implementation is used?
SBCL, but it might also work with CCL
Nice. Especially nice that it is implemented in real lisp syntax rather than in some reader macro with new syntax.
Yeah. I also like that the real lisp syntax he chose is lightweight and generally quite tasteful.
Great, now you made me miss Lisp. Thanks a lot!
It seems rather complicated for what it does. My version (defmacro collect-let (variables test value) (let ((accumulator (gensym))) `(let (,accumulator) ,(reduce (lambda(name&amp;list code) `(dolist ,name&amp;list ,code)) variables :initial-value `(when ,test (push ,value ,accumulator)) :from-end t) ,accumulator))) (collect-let ((x '(0 1 2)) (y '(0 1 2)) (z '(0 1 2))) (= (+ x y z) 3) (list x y z)) =&gt; ((2 1 0) (2 0 1) (1 2 0) (1 1 1) (1 0 2) (0 2 1) (0 1 2))
People do that for other reasons than the heck of it? (!)
I've made a series based version, available from [its Mercurial repository](http://bitbucket.org/roerd/series-comprehension/). This is the simpler of the two macros in the package (this one return lists, the other series): (defmacro comprehend (form pairs &amp;optional (guard t)) (let ((g (gensym))) (labels ((nest-iterations (pairs) (destructuring-bind (pair . rest) pairs `(iterate (,pair) ,(if (endp rest) `(if ,guard (next-out ,g ,form)) (nest-iterations rest)))))) `(gathering ((,g collect)) ,(nest-iterations pairs))))) SERIES-COMPREHENSION&gt; (comprehend (cons x y) ((x (scan '(0 1 2))) (y (scan '(0 1 2)))) (= (+ x y) 2)) ((0 . 2) (1 . 1) (2 . 0)) 
That's funny, I learned lisp over a weekend.
Really? Thith only took me a few minuteth.
When I first saw Lisp, after I realized how it worked, I was amazed at its simplicity. Take the list, evaluate all the elements except the first, then pass those elements to the function given by the first argument. And that's (almost) all there is to it.
It took me ten years to learn Lisp.
The basic concept of Lisp (in the generic "lisp" sense) can be learned in half an hour. The whole Common Lisp requires years, especially if accounting "doing it the lisp way" instead of being a human cross-compiler.
Oh you.
I can't believe I was downvoted for that. Okay, maybe I can. You win thome, you lothe thome.
Reddit workth in mythtetiouth wayth.
[See for theory](http://www.usingcsp.com/cspbook.pdf) and for a different but similar project, [chanl](http://www.cliki.net/chanl).
The syntax and the paradigms of lisp programming are not very complicated. But learning to use the possibilities of the language to write elegant and effective code is a matter of many years.
One one spreadsheet, gambit supports 11 SRFIs, on the other summary of systems it supports 40?
Oh good, i'm halfway there! :)
becauth it ith tho thtutpid!
But it was funny the first 827 times I heard it.
Thou doth lispeth sedition.
Didn't Calvin say something about novelty Christmas songs being funny *every* time? I think we can all agree that lisping jokes share this quality.
On the Internet, it's hard to tell if someone is being ironically stupid or genuinely stupid.
"I don't see how something can be funny 300 times but not 301 times." -- Dilbert
 (defun lisp (sentence) (coerce (loop for c across sentence if (char= c #\s) collect #\t and collect #\h else collect c) 'string))
Don't worry, I wrote a macro sat fixes it.
What a strange accent.
Really? Did you mean, &gt;But it wath funny the firtht 829 timeth I heard it.
(ppcre:regex-replace "th" sentence "s") ; take that
Clbuttic.
But that's why I named it LISP!
http://www.youtube.com/watch?v=5Pm5-TKmPYQ - in action :)
A Lisp that executes at compile time via C++ template expansion? Hmm. Does this mean I can use the equivalent of (defmacro ..) to generate C++ code at compile time?
It's unfinished! This library was looking extremely cool (especially with the Blast Tactics demo) -- any ideas when it'll get fleshed out?
This seems to be particularly true in Lisp-related forums, have you noticed? I wonder what it is about Lisp forums that attracts so many people whose only purpose in life seems to be to decrease the signal to noise ratio. They certainly don't have any interest in Lisp.
[Here's a much shorter version](http://matt.might.net/articles/c++-template-meta-programming-with-lambda-calculus/) using an SICP-style eval/apply interpreter.
Maybe if we encourage them to make 'perl necklace' jokes, they'll go off and bother the perl people instead?
Hi, I'm working more on games than on the documentation right now, but I'll keep moving along and get some more docs written... join irc.freenode.net#lispgames if you want to chat!
No, that won't be anywhere close to defmacro.
I'm getting a 502 on that page
me too, probably takes some time until is back... 
Any hint to what it was?
MCL + IDE MCLIDE is Macintosh Common Lisp combined with SWANK (from SLIME), so that MCL can be used as IDE for remote Lisps (like MCL, Clozure CL, LispWorks, ...). The tour page has screenshots how it looks like. We'll have to see when the page is back. The thing is brand new announced, though.
Ah sounds promising, I'll keep an eye on the link.
Link works now, looks very promising. 
I should mention that this can be seen without SilverLight. There is a 'Media Download' menu on the page. For example here is the iPod/MP4 version: http://ecn.channel9.msdn.com/o9/ch9/8/4/0/2/9/4/E2EBeckmanHickeyClojure_ch9.mp4
Its good to hear that ABCL is evolving.
not to sound ungrateful, but is there any way to provide non-source downloads? My ARM-dev board doesn't gracefully handle javac :S
English Version: http://blog.codeartist.org/2009/12/lisp-for-jvm.html
Its pretty neat given that its been put together in 48 hours. Any ideas on where is the code?
Hi, The compo rules allow pre-existing libraries to be used for the entry, so long as all game logic and design and assets are new. So, the 48 hours doesn't count my Lisp game engine :) but you can see everything at http://github.com/dto/rlx 
I wrote a small breakout implementation (no bonuses or levels yet) using SDL in Haskell, in a few hours (I think it added up to 5 or 6). I didn't write it very functionally, its a pretty heavily imperative program. http://github.com/peaker/breakout
 I've been working on Postabon for the last few months (full time for approximately the last 2). We've been beta testing in NYC for the last few weeks - and feel we have enough content there to launch now. Any feedback (especially criticism) you have would be greatly appreciated. The basic idea is that we want to help you find and share discounts near you. The video (click 'Watch a Video' on the left) will help explain the concept/history if you're interested. Our iPhone app's release is pending Apple approval (hopefully just a few more days ...). I'll write up some architecture posts if anyone is interested, but the short version is a nginx reverse proxy into hunchentoot. I'm also using Elephant/BDB for persistence, and html-template for templates.
Are you hiring? :D
Well, it's a great way to crash Firefox repeatedly 3.5.5 on the Mac. :| (more of a jab against Firefox, but you may want to look into that).
I'll be sure to do my part and spread the good word!
Here's one more data point in your market research: 1. If you can tell me where I can find the cheapest DDR3 DIMMs I would be eternally grateful. And I don't care what city they are in; USPS will deliver to my door. 2. Please don't pop up a dialog box and make a sound if you cannot find any deals in my city. That is so 20th century. Instead, immediately take me to the /nearest/ city that has some deals, not NY. Instead of a dialog box you could have simply displayed a message at the top of the page (and without making any sounds). 3. I don't see guys wanting to use a site like this. It seems more like it would appeal to women since it tends to be centered on shopping. The site could use more of a woman's touch since the subject matter is so shopping-centric. 4. I don't know what "bons" are. Maybe I should have watched the video. It's a little disconcerting that I don't understand the site's language. 5. Not sure how you would monetize this site. 6. If you want more people to use your site you may want to stop making them register before they can post. Bring down the barriers. What you could do is use cookies to track their usage. If the user continues to use your site then maybe after the 100th time they've posted you could ask them to register. Let the user try before they buy, so to speak. It makes the coding a little harder, and the spam problem more difficult, but you will get more people actually using the site. Thanks for listening and have a great day.
The homepage tells me nothing about what the site is for. This is a common problem with startups: you get so heads-down in the idea that you forget that nobody else knows what a bon is, or why they should care.
Not yet, unfortunately. We need more devs - but we aren't funded yet. Thanks for the interest though.
Thanks vanekl - that's some really useful feedback. 1) We aren't really focused on cataloging particular items (or non-physical purchases). Slickdeals/fatwallet/pricewatch might be a better solution for this use case. For 2, you're right. I'm fixing it now. For 3 - absolutely. We're not funded yet - but as soon as we are we'll buy some time with a good designer. 4 - Fixed (a new introductory sentence up top). 5 - Possibly charge retailers for priority placement of (clearly marked) ads. 6 - I'm of two minds here ... I'll consider it (or at least making registration less onerous), but I think I need registered users to get funded and make a stronger case to VCs and advertisers.
Hmm, you may be right. I was hoping the video would help - but I've added a sentence up top explaining the concept.
Sorry about that - I'm unable to reproduce on my macbook. I'll try on some other machines later today ... Some browsers don't like a lot of map overlays, but FF has usually been good in my experience. I'll keep digging though.
Thanks for the support!
What video? I didn't see one on my iPhone.
&gt;For 3 - absolutely. We're not funded yet - but as soon as we are we'll buy some time with a good designer. Change this now -- I opened your website in a new tab and kept browsing reddit. Your box grabbed focus from my browsing, which is really not cool.
&gt; 6 - I'm of two minds here ... I'll consider it (or at least making registration less onerous), but I think I need registered users to get funded and make a stronger case to VCs and advertisers. With your site the most important thing is the number of eyeballs and clicks you are able to draw. You can easily weed out the bots by simply counting the clicks on the map flags. Anything you can do that maximizes clicks is to your favor. Requiring people to logon will hurt clicks unless you have some way of rewarding people who logon. (Special deals only displayed for those who bother to logon perhaps? Or show only the most recent deals posted within the last 12 hours to those who are registered.) But I digress. I just don't see any advantage to making people register when you can track usage by clicks and cookies. Just something to think about. You may be right.
Yeah - the alert box was vanekl's point #2. I've disabled the alert - and I'm in the process of developing some sort of less disruptive error/warning message.
Well, best of luck; A lisp job in NYC would be great...
I like the site and the concept :) but i don't understand why you want to introduce a new word? And then go to the trouble of having to educate us. Would be great to have an alert feature where i can put up a few things im interested in looking for deals, and get alerts when "bons" get posted in my specified geographical area[s]. Great work though. Wish you all the best in securing funding. 
"Watch a video", at 90 degrees to the rest of the text, doesn't really scream "here's the explanation". (Also, my usual response to "watch a video" is "no". I don't want to watch; I want to read.)
Your site stole my browser focus by throwing a pop up and interrupting whatever I was reading in a different tab. Don't do that. Never greet your users with a pop up. If you hadn't done, that I would have been reading the content on your site instead of posting this comment. Anyways, 1+ for the lisp startup. Which lisp are you using? Care to share the insights and experiences?
Forget the video: Make your copy at the top short and sweet, like: "Postabon — Find and Share the Best Deals Near You!"
upvoted for the title
And down... anyone have a mirror?
will be interesting to read if the page loads. Guess his server got bombarded by redditers :)
All 8 of them that actually voted ;)
[From proggit](http://74.125.95.132/search?q=cache:WoG6gVMYIGAJ:arantaday.com/blog/+arantaday&amp;cd=2&amp;hl=en&amp;ct=clnk&amp;gl=us).
Thanks!
I wonder if his "rant" server is running lisp?
Thanks Xach. I don't know if it's possible - but could you change the link over to http://postabon.posterous.com/why-i-chose-common-lisp-over-python-ruby-and
Can't really change it after it's posted, sorry. I changed it on Planet Lisp, though.
Thanks - I just set up a redirect to the new site so the old link should still work anyways.
Thanks!
sykopomp, u are a poop-y programmer
Yep: ABCL started [releasing binaries as of abcl-0.17](http://common-lisp.net/project/armedbear/releases/abcl-bin-0.17.0.tar.gz), although it seems this is currently not noted on the [ABCL home page](http://common-lisp.net/project/armedbear), although you can find this listed on the [unofficial Mercurial-based copy of the source](http://code.google.com/p/abcl-dynamic-install/downloads/list). We will endeavor to make this more apparent.
aww come on ... I just updated to 1.0.32
update near the beginning of the month. :D The SBCL devs try to get a new release tagged near the end of each month...if not a rule, it's been the trend.
And [9.12.2](http://ecls.cvs.sourceforge.net/viewvc/ecls/ecl/src/CHANGELOG?revision=1.677&amp;view=markup) is out, with fixes for a particularly impressive [heisenbug](https://sourceforge.net/mailarchive/forum.php?thread_name=1F0BAA75-A83A-4D59-937C-FC3055EB59DD%40p-cos.net&amp;forum_name=ecls-list) (in which RANDOM randomly crashed).
I'm not really complaining ... really I'm not ... I'm very happy that SBCL is in active vigorous development, I wish I could even help but I'm certainly not at that level right now, just trying to learn Lisp and keep my dev environment current. 
clbuild early, clbuild often.
The language does not change at all, so sticking to some working version for some time is not a problem at all. Upgrading just for sake of upgrading is not obligatory.
http://dto.github.com/notebook/xe2-reference.html#sec-1 
Oh, I understand that, I'm just having fun with it right now. 
thanks!
I just read the paper linked in the article ([PDF](http://p-cos.net/documents/filtered-dispatch.pdf)) and it looks very promising. Having a **well-defined** form of predicate dispatch for CLOS is pretty awesome. 
Now that *Coders At Work* is published, it would be time for *More Practical Common Lisp*!
Practicaller Common Lisp :)
Now these are *two* books: **(more (practical common-lisp))**, and **((more practical) common-lisp)**. I'd even buy *Useless Common Lisp*. It doesn't matter. Just write another one, Peter! 
In the graphic design world, the question of legibility of typefaces has more or less been settled: it seems that people find more legible what they are accustomed to. (ever tried fraktur in recent times?). Being forced to switch emacs versions several times, I had a similar experience with aliased vs antialiased fonts: when your eye is tuned to one version, the other looks unreadable. Same for lisp vs non-lisp syntax, imho.
I couldn't load it, some server problem, but [google has a cached copy](http://docs.google.com/viewer?a=v&amp;q=cache:LXbvJvEbx88J:liw.iki.fi/liw/misc/hh-blurb.pdf+hh-blurb&amp;hl=en&amp;gl=ca&amp;pid=bl&amp;srcid=ADGEESjUS5t2C8GuySNyjkFe1ia6X3ZBL6ek9Pa_Gd9EH5tCR9EdER0azWCdM2-hKrGrrqQHpqX6WG9kw3esIfPsKC9UiN528kjYtvYkLcor1r59Q1Zb0VeC1H6-7PvTAvz_XmCxtBu8&amp;sig=AHIEtbSe3skzZQe9cX0PrwoMn5-J_A6R0Q)
I skimmed the image processing chapter, and while I can see potential, the current code (say for spiralize) is atrocious, e.g.: * Naming and order: the variable names for X and Y coordinates should have X and Y in their names, not I and J. I would name the images SOURCE, TARGET, and INTERMEDIATE, and source X/Y would be SX/SY, center X/Y would be CX/CY, maximum X/Y would be MX/MY, target X/Y would be TX/TY, etc. This makes the code so much easier to follow. Also, always use X/Y parameters order. If you want to be stupidly consistent and follow the peculiar order used in CH-IMAGE, substitute ROW for Y and COL for X throughout the code. * Factoring: the code is not well-factored. The last exercise mentions this, but why leave it as an exercise? A better design would be to have a TRANSPOSE-PIXELS operation, a REPEATEDLY-TRANSPOSE-PIXELS operation, and a SPIRALIZE operation using the latter with a SPIRAL-TRANSPOSER for source coordinates and IDENTITY-TRANSPOSER for target coordinates. I would then inline ROTATE and SOURCE-COORDINATES into the SPIRAL-TRANSPOSER, and COPY-PIXEL into TRANSPOSE-PIXELS. Exempli gratia (untested): moved to the end of the post. * Performance: The first exercise asks the reader a question, but this question should be asked of the author. I don't see why a "fresh copy", as defined, needs to be made for each iteration. COPY-IMAGE should have an optional target image so that it would be possible to copy the pixels without allocating a new image. Sigh, reddit is buggy w/ bullets and code. (defun make-spiral-transposer (width height) (let ((cx (+ (round width 4) (random (round width 2)))) (cy (+ (round height 4) (random (round height 2)))) (strength (* (+ 50.0 (random 100.0)) (if (random-boolean) +1 -1)))) (lambda (x y) (let ((d^2 (square-distance x y cx cy))) (if (zerop d^2) (values x y) (let ((dx (- x cx)) (dy (- y cy))) (theta (/ strength (sqrt d^2)))) (values (clamp 0 (+ cx (- (* dx (cos theta)) (* dy (sin theta)))) (- width 2)) (clamp 0 (+ cy (+ (* dy (cos theta)) (* dx (sin theta)))) (- height 2)))))))))
Ah, good old hunchentoot. I moved on to greener pastures though. Switched to compojure web framework (clojure). 
Thank you for the link. Even though I don't understand Russian, I found the links (e.g. To Ola bini's post, to Pascal Costanza's comparison of metaprogramming in Java and Lisp) to be very informative.
you can use Google Translate ( http://translate.google.com/ ) to translate the text from Russian to English. It's good enough to get an idea what the slide texts are about.
This was the first book I read on Lisp. It did a good job convincing me that CL is actually a good choice for many practical programming tasks. I especially liked the practicals on [creating your test framework](http://www.gigamonkeys.com/book/practical-building-a-unit-test-framework.html) and [parsing binary files](http://www.gigamonkeys.com/book/practical-parsing-binary-files.html). I tried the exercises using [clisp](http://clisp.org/). I would suggest anyone new to CL to read this first. 
A rather long discussion of the anti- and pro- lisp arguments in the comments. 
urgh, just posted it, then saw here it's already been posted.
Good tutorial, but I think the API for [Hunchentoot](http://www.weitz.de/hunchentoot/#start) has since changed slightly. Instead of doing: (start-server :port 8080) you'd do something like: (hunchentoot:start (make-instance 'hunchentoot:acceptor :port 4242))
Except that, at least in Common Lisp, there is in fact very little syntax, and no issues such as operator precedence, making it much easier to learn all there is to know about the language's syntax, and minimizing the effort necessary to read even the most syntax-heavy code. Compare to C derivatives with special keywords and operators and reserved characters for every little thing.
But one could also say that the uniformity of lisp syntax detracts from legibility (in the perceptive sense, not for semantics), the same way as descenders make lowercase lettering easier to recognize (or more difficult, for a different school of tought). You can build how many theories you want on theses matters, but the only empirically proven fact is that legibility mostly comes from habit. I also have experienced this. I happen to program long stretches of time (months) in either perl OR lisp. Every time I switch, I think it was easier on the eyes the one I come from. Note that in a conceptual sense I also like Common Lisp more. I was just talking about perception issues.
I don't think you can get around the fact that, at the very least, issues such as operator precedence require unreasonable cognitive overhead--and that uniform syntax is much easier to learn.
Wait, that would fit Rich Hickey? In October 2009 Clojure had its second birthday.
* Variable names: I agree about X and Y. I don't about agree with you abbreviations like SX for SOURCE-X * My concern has been not to make this inaccessible to newbies. When I get to the end of the book I hope to go back and review the whole thing for evenness, difficulty, etc. * I agree that COPY-IMAGE would be more useful if it took an optional target image. Unfortunately the ch-image library doesn't provide this. (And in terms of performance, I have trouble believing that this makes a lot of difference.)
Sorry - he's underqualified.
I guess he started committing to the Clojure archive three years ago - does that count?
OK - let's just take the time to read the ad and realise that it's a bit of trolling....downmodded
 (defn hiring-decission [applicant language expierence] (if (&gt; expierence (+ (age-of-language x) 1)) (send applicant :your-hired) (send applicant :not-qualified))) 
Hi all, that's an ad for Velocitude, and I'm the CTO. I can say it's real because we handed it to Comsys recently. We had a chuckle when we saw this reddit post because, well, obviously it's the sort of thing we laugh about ourselves, and it's kind of amusing when you know you caused the mischief. :-) Anyone who has worked with recruiters will tell you that they take what you give them and run with it, and I suspect they hit a database field where they simply had to enter a number. That's what happened here - our original job text obviously does not include a requirement for 3 years of Clojure experience. We're big fans of Lisp and Functional Programming, and one of the Clojure contrib library programmers works here. We have our first Clojure code in use now, and are planning to migrate to Clojure as our major platform in the next 6 months. And for those who are interested please read over the original job ad text. If you're interested and you think your resume might be a good fit, please reach us directly by emailing careers@velocitude.com. Clojure Developer (job id 0020) Velocitude, a provider in mobile web development and social media solutions, is looking for a Clojure Developer to assist in further developing the Velocitude Mobile Platform for mobile web services, for clients representing major US brands and other companies. Responsibilities * Develop and roll out highly dynamic web sites and web applications * Participate on a team of developers working on larger projects * Produce robust, readable, organized, maintainable, quality code * Stay current with mobile and social technologies * Meet with clients to establish client requirements for Velocitude services Minimum Qualifications * Strong programming skills in general * Knowledge of Clojure, strong skills in Lisp and/or Java * Knowledge of JVM and Java interop * Strong skills with Linux, Apache, MySQL * Strong skills with SQL and MySQL in particular * Strong knowledge of XHTML, CSS, and Javascript * Understanding of web protocols such as HTTP "on the wire" * Familiarity with Perl to work with parts of codebase in Perl * Familiarity with Amazon EC2, high volume web sites, network security * Working knowledge of Git for version control * Working knowledge of Bugzilla for issue tracking * Ability to write code that conforms to company coding conventions * Experience with Linux server administration and troubleshooting * Good communication and organizational skills Other Notes The successful candidate will: * Demonstrate knowledge of a wide range of programming paradigms * Understand several programming languages * Read academic works on programming * Show past hobby projects and/or be a participant of the open source community * Show real world experience working on major projects Possible pluses: * Experience with PCI DSS a plus * Background in technical consulting a plus 
Lame. I read this as three years of experience, not three years of Clojure experience - I've seen much worse.
Thanks for the additional detail. I posted here because Comsys cold-emailed me about posting it to Planet Lisp, even though someone wrote about it there already.
You have a bug. It should be (age-of-language language). But still: funny!
If Rich applies, he'll have a good shot!
Everyone gets a medal except for poor John McCarthy.
Probably he gave them the medals, since he was the boss?
He's probably the only one who realizes there isn't reason for optimism hence the dour look
CL does not define whether tail calls must be optimized. That is up to the individual implementation. 
Offtopic: You can pry anti-aliased fonts form my cold dead hands. 
Is it sad that I get all fanboy when I look at this photo?
It's completely up to the implementation (and its interpretation of your particular optimisation settings). In practice, SBCL will do TCO when speed ≥ debug. Which means you might not be able to debug effectively your tail-calling code in some situations.
It kind of reminds me of 'Space Cowboys': http://www.cineclub.de/images/2000/space_cowboys_1.jpg
Friends don't let friends use newlisp.
Why? I've used it and thought it was great. I finished what I needed to finish very quickly (a GUI 2d geometry editor), with only a passing knowledge of gui app programming. I'm actually surprised it's not more popular.
Oh god, it's like he copy/pasted C++.
Kenny Tilton?
All the design choices of newlisp were made so that it would be easy to implement rather than easy to use. This leaves you with a pathologically bad language that is slower than ruby, less supporting of state encapsulation than c, and uglier than common lisp. I can believe that it was ok for a small project, but their design choices mean that it will get much worse to use with a large project or large amounts of data. Try writing your own head function, it will either be O(n) instead of O(1) or manipulate global state. Disclaimer: I use and like common lisp and c, and I don't know enough about Ruby to cuss it properly.
There's a lot of hyperbole in the "Bloodied but Unbowed" slides. FFIing to another language's GUI package *does* work. In fact, at least for Unix and Windows, CL-GTK2 works fine.
Ruby faster than newLISP? Do you have a link/benchmark for that claim?
Don't need one. newLisp copies every argument passed to a function. In situations where this is unavoidable functions may have the wrong order of complexity. This means that if I have a sublinear function written in ruby and newlisp I can just keep passing it larger and larger structures until ruby wins. The work arounds involve not using functions or unsafe manipulation of global state, and defeat the purpose of writing in lisp anyway.
&gt; Don't need one. Yes, I'm afraid you do. With a benchmark we can evaluate whether you're actually saying anything meaningful or not. I can, in 2 seconds, come up with a benchmark that "shows" that newLISP is "faster" than C or any other language. You just have to make a stupid/inaccurate benchmark. &gt; This means that if I have a sublinear function written in ruby and newlisp I can just keep passing it larger and larger structures until ruby wins. The work arounds involve not using functions or unsafe manipulation of global state, and defeat the purpose of writing in lisp anyway. Ah, you didn't read the article, your misunderstanding of newLISP makes sense now. If you wanted to have an accurate benchmark, you'd pass the same datastructure (by-value) to the Ruby function. But that would be stupid. In newLISP you do not pass large datastructures by value. Using the techniques demonstrated in the article, you could easily create a wrapper: (my-user-func (MyDataWrapper my-giant-data))
&gt; If you wanted to have an accurate benchmark, you'd pass the same datastructure (by-value) to the Ruby function. But that would be stupid. In newLISP you do not pass large datastructures by value. Using the techniques demonstrated in the article, you could easily create a wrapper: (my-user-func (MyDataWrapper my-giant-data)) Doesn't this fail with recursion? So in common lisp (defun how-many-0s(list) "Returns the list append with the number of initial zeros" (if (equal 0 (first list)) (cons (1+ (first (how-many-0s (rest list)))) list) (cons 0 list))) Is O(n) worst case complexity. Naive new lisp is O(n^2). Using your method list is globally rather than dynamically or lexically scoped, and corrupts. If you've added lexical or dynamic scope to newLisp, well done but I really didn't get that from the article. Edit: Ok, I've reread the article. You've created a heap for each individual object class that must be managed by hand? This is does allow you to by-pass some of the issues that newLisp faces, but I still wouldn't want to use this. Can you show me the newLisp version of this code? 
&gt; If you've added lexical or dynamic scope to newLisp, well done but I really didn't get that from the article. newLISP is dynamically scoped always (but there are ways of simulating lexical scope, i.e. the 'letex'/'expand' functions). I'm guessing this is because dynamic scope is faster when you're dealing with a purely interpreted language. &gt; Doesn't this fail with recursion? So, using the data wrapper (an ObjNL object) you're passing a pointer to a context around O(1). There's no way of getting around the list copying through with the call to (rest list:data). So, for a 5 element list you end up doing 4+3+2+1 copies (I take it this doesn't happen in CL?). I don't think that's quite the same as O(n^2) but it's more than O(n). Typically such things have a minimal performance impact in real newLISP code because you're never copying huge lists, and newLISP is not intended as a general-purpose language to be used in data-heavy performance critical situations. It's just a very nice lightweight scripting language. Feel free to use compiled Common LISP for situations that need it, but I personally find newLISP much easier to work with when doing scripting tasks.
&gt; Ok, I've reread the article. You've created a heap for each individual object class that must be managed by hand? Sorry, I'm not sure what you mean by "managed by hand"? &gt; Can you show me the newLisp version of this code? Sure, just as you wouldn't write a tail-call recursive algorithm in CL because CL doesn't have it and you don't need it (just iterate instead, same performance), you wouldn't write that function that way in newLISP, but you'd do it the newLISP way: (define (how-many-0s lst , (num-zeros 0) break) (dolist (item lst break) (if (zero? item) (inc num-zeros) (setf break true))) (push num-zeros lst)) (how-many-0s '(0 0 0 1 2 5 3)) ; =&gt; (3 0 0 0 1 2 5 3) That has the same complexity as your CL code (ignoring the first copy to initialize the list &amp; pass it in, CL needs to O(n) copy that list somewhere to initialize it too), and it's also easier to understand. newLISP is fast for an interpreted language, and you can do a lot very quickly with it. You'll simply be depriving yourself of learning some of the neat things it has to offer if you allows yourself to believe that it's somehow flawed due to its use of dynamic scope and/or memory management model. In practice it's almost never an issue. Give newLISP a real shot first for your scripting needs, and then you'll have a better understanding of what it is good for, and when you should use something else. I use it every day and I love it!
&gt;newLISP is dynamically scoped always (but there are ways of simulating lexical scope, i.e. the 'letex'/'expand' functions). I'm guessing this is because dynamic scope is faster when you're dealing with a purely interpreted language. It's because lexical scoping requires a garbage collector. But the FOOP of newLisp doesn't have dynamic scope as each object is defined as a new global context. &gt;So, using the data wrapper (an ObjNL object) you're passing a pointer to a context around O(1). There's no way of getting around the list copying through with the call to (rest list:data). So, for a 5 element list you end up doing 4+3+2+1 copies (I take it this doesn't happen in CL?). I don't think that's quite the same as O(n^2) but it's more than O(n). This is O(n(n+1)/2)=O(n^2) complexity. &gt;(I take it this doesn't happen in CL?) No it doesn't happen in almost any language. A linked list implementation should not do this. You should be to write a correct implementation of this code, using your objects as you have control over a persistent heap. But you'd have to create lists from cons cells and ignore the built in language definitions.
&gt; FFIing to another language's GUI package does work. Not for much longer. The only language that allows this is C (or anything that can export stuff to look like C which for this point is equivalent). C libraries and calling conventions work fine if all you want is a level barely above assembly, no type safety, no thread safety (this last one is very important in the near future because we get more and more cores). Modern GUI programs are incredibly complex. What we need to use them properly are GUI frameworks on the abstraction level of a modern language, not on barely above assembly level.
&gt; It's because lexical scoping requires a garbage collector. Sure, but the point is newLISP would be slower if it were lexically scoped. &gt; But the FOOP of newLisp doesn't have dynamic scope as each object is defined as a new global context. Not true. Each FOOP object is just a plain old list. &gt; This is O(n(n+1)/2)=O(n^2) complexity. I show a very fast newLISP version that is the same complexity as your algorithm in my other reply to you. newLISP is a nice language, and benchmarks on much older versions showed it was as fast or faster than other scripting languages. I'd love to see the updated benchmarks as newLISP has since improved in speed considerably due to reference passing in built-in functions. But the bigger point is not about benchmarks but about elegance, and newLISP code, IMO, is far more elegant than CL code. To each his own as they say. I'm not forcing you to switch. :-)
&gt;Sorry, I'm not sure what you mean by "managed by hand"? You have to use equivalent functions to new and free and potentially prevent the heap from fragmenting. &gt;Sure, just as you wouldn't write a tail-call recursive algorithm in CL because CL doesn't have it and you don't need it (just iterate instead, same performance), you wouldn't write that function that way in newLISP, but you'd do it the newLISP way. This is more or less what I said. You either remove functions (or more precisely remove function calls) or you use global state. I deliberately gave a simple example but there are scenarios, such as traversal over a tree, where recursion is an easier solution and it sucks that you can't use it freely.
Exactly. NL lists are time inefficient for first-rest recursive dispatch. But, hey, CL lists are space-inefficient for that same dispatch. Optimal solution is iteration, not first-rest dispatch. Dispatch on tree-like structure is more important, and I think both NL and CL are efficient for that. Dispatch on first-half and second-half would be important as well, but neither CL nor NL are efficient. NL and CL built in lists are different and each has its advantages; for example, pushing on the right side, and length are O(1) in NL, and O(n) in CL. Again, one can solve it by developing his own structures. Finally, if Lisp is continuously marketed as programmable programming language, then one shouldn't be afraid of really programming that programming language. That's exactly what author of the Objective Newlisp tried. 
&gt; You have to use equivalent functions to new and free and potentially prevent the heap from fragmenting. Which heap are we referring to here? You said I created one for "each individual object class", I do not recall doing so, or I'm misunderstanding what you're saying. &gt; such as traversal over a tree, where recursion is an easier solution and it sucks that you can't use it freely. For what it's worth, if we were dealing with a tree then you could use ObjNL for that purpose with no problem as everything is passed by reference. So, it seems you really have to come up with convoluted examples where NL is really inefficient (you still haven't shown a significant one, but I'll just take your word for it). If there are problems that NL isn't very good at solving, either don't use it, or if you do, you can always write your stuff in C and then call it from NL. I personally have far fewer issues with NL than I do with CL, so I use NL over CL.
I wonder if it would be sensible to structure a GUI as a something of a stand-alone program that parses and runs an intrinsically type-safe command language, and communicates over local sockets. Like X, but with a protocol more at the level of QT.
I think that wouldn't be such a bad idea, You would need a very fast serialization and deserialization framework though to make it work (maybe something like Google Protocolbuffers). The main problem would be with programs doing very elaborate (re)drawing operations very often that are already at the limit of what our current computers can do without noticable delays.
Sorry for cross posting from proggit, but I am not sure if the two communities overlap enough. Proggit link [here](http://www.reddit.com/r/programming/comments/acxz8/ask_proggit_what_more_is_needed_in_ecmascript_5/).
I'm probably living in the past but how much more complex than 3D Max, Photoshop, etc. are you talking about? And, more importantly, why are modern GUI programs so complex and do they really need to be? Google Wave perhaps? (I have no experience with it.)
I liked "Bloodied but Unbowed." You can almost smell (through the terrible sound of the telecast) how badly Goldman wants Garnet to be usable. I felt his pain.
Someone mentioned gtkserver on our mailing list after this discussion. It is to GTK what you are describing here... except it communicates over standard-input and standard-output, I think.... actually, it may have facilities to talk over ports, too.
Eh... I don't know how fast your serialization really needs to be. Most GUIs aren't doing anything right now. They are waiting for something to happen... then they might focus or defocus something or disable a button.
You forget about * text windows (you would be surprised how time-sensitive cursor and linebreak operations can be, especially when you are dealing with text flowing around some larger elements) * list, table and tree views * animations 
Modern GUI programs are so complex because a lot of software today does a lot more than it used to do. Any particular view might only have two or three buttons but the interaction between them is what creates complexity. In particular the threading issue will soon begin to become a major issue because none of the GUI frameworks I am aware of today can be used from more than one thread which means if your app uses more than one you need to roll your own system to transfer a request to display or change some GUI element from that other thread to the main thread, somehow handle it there (normal thread primitives don't work because you can't just block the main thread), then you need to transfer the result of e.g. your dialog back to your thread and resume execution (if you can afford the luxury of pausing the whole thread while the GUI is displayed). All this is completely unnecessary complexity for something that should be a simple operation. It is also something that should not be a concern in another language at all because those other languages might not even tell the user what is executed in which OS thread (and what is just a green thread).
Isn't this essentially what LTK does via Wish?
It seems both SBCL and Allegro can handle it properly even in generic functions. (defgeneric foo (x)) (defgeneric bar (x)) (defmethod foo ((x integer)) (if (&lt;= x 0) 0 (bar (1- x)))) (defmethod bar ((y integer)) (if (&lt;= y 0) 0 (foo (1- y)))) (foo 100000000) Both terminated. 
()?
&gt; 1. A proper list structure instead of arrays. You don't need proper list structure (cons cells) to become Lisp. If I remember correctly, CL people debated during standardization about changing lists to arrays. The main issue is to have simple list/vector/sequence data structure that can represent code and data homoiconically. I think Emacscript 5 could be acceptable lisp if it had this homoiconic property that could be represented with s-expressions (current syntax might be used as alternate). Having lots of functions that work with this simple list structure is also important for Lisp "feel" Emacsript objects are already lot like symbols with property lists. You need only standardize symbol-name slot and function slot. Special-variables, numeric tower and macros would add more and more Lispiness. IMHO: Continuations and tail call optimizations would add more "Schemeness" into the language, not Lispiness. I would support tail calls tough. 
&gt; newLISP code, IMO, is far more elegant than CL code. The selection of newLISP is prima facie evidence that your conception of "elegant" is defective.
An upcasing reader, a kindof broken eval-when, loss of lexical context for eval, machines that used to run it "on the metal", fewer users, more bearded users. ;)
Javascript's dynamic scoping is a major pain in the ass, and it will never be homoiconic. In other words, it will never be a modern Lisp.
the condition system, CLOS, defmacro, sexps, APPLY, READ, COMPILE, symbol macros... shrimp gumbo, shrimp soup, shrimp sandwiches....
So there is Matlisp, lisp-matrix (http://github.com/blindglobe/lisp-matrix), LLA, cl-blapack ... possibly missed some. I only know Matlisp. Any recommendations, opinions? What's obsolete, abandoned, etc. 
Oh, and there is also spartns for sparse tensor junkies.
Nothing. It should be morphed into lisp dialect to become mainstream lisp. If it is not homoiconic, doesn't have macros it can't be lisp.
Speaking of dynamic scoping, do you refer to the with statement? It has been removed from Ecmascript 5, I think. If not removed then at least deprecated.
&gt; You don't need proper list structure (cons cells) to become Lisp. If I remember correctly, CL people debated during standardization about changing lists to arrays. Arrays have different performance characteristics than lists. And in a recursion heavy language, lists work out better. So the performance considerations can lead to different paradigms in implementations. An example is the implementation of map function in standard Ocaml core and in Janestreet's core. &gt; I think Emacscript 5 could be acceptable lisp if it had this homoiconic property that could be represented with s-expressions (current syntax might be used as alternate). Agreed. 
&gt; doesn't have macros it can't be lisp. I wonder if having lazy and strict annotations in the callees argument list is a good enough alternate to having macros. Though it is just an ugly workaround because of the syntax.
&gt;And in a recursion heavy language, lists work out better. I'm guessing that you are either Scheme programmer or non-lisp programmer who knows some Lisp? Do you know that traditional Lisps and it's successor Common Lisp are not recursion heavy (recursion is not used extensively) and it's not considered good style to use lists too much. There is functional programming style and Lisp gives some support for it and then there is Lisp programming style. 
I get what you are saying. I have noticed that even when I program in scheme, I use it as a strict functional language, making use of very little mutable state. Even my javascript style is matching that now. I would probably be using OCaml if it were not for the strange syntax and strict typing. Thanks for making me go back and examine my assumptions about javascript.
No, I'm referring to how "this" changes all the time.
I think this is a nomenclature problem; when many people hear 'lisp', they think 'lisp-family', i.e. lisp1.5 &amp; beyond (which would include all modern variants: cl, scheme, clojure, newlisp, picolisp, &amp;c). When CL people hear lisp, they think 'cl'. That said, I think you're correct in assuming that the OP hasn't had much exposure to cl style code, but this might work out better, since you wouldn't want to use much recursion in JavaScript either. ParenScript might be a decent starting point...
There are several languages that are Lisp-like, but do not use CONS-cells as their basic data structure. [Klone](http://openports.se/lang/klone) which is fairly CL-ish, but uses vectors underneath and [MISC](http://william.thimbleby.net/misc/) which is Lispy (in the generic sense) and uses maps underneath. Also, you can always look to Douglas Crockford to find something fairly Schemey in JS; his [Top Down Operator Precedence Parsing](http://javascript.crockford.com/tdop/tdop.html) paper is interesting, as one example.
JS has null, which would fit the bill CL style: cons(1,cons(2,cons(3,null))); 
Call-by-name might work as well... but that would be awful. :D 
or quote + decently hygienic macro system (for example quasiquote can be a series of syntax-rules for quasi-quote, unquote, unquote-splicing, &amp;c.). 
Using cl-gtk2 has been pie-easy for me. C(++) gtk itself might be a little more complex because it being a simpler(edit: well C++ not necessarily simpler, less effective) language. The library doesn't seem complex to me at all, actually fairly straightforward. It would seem to me that if someone made a complex GUI program with it, that'd be his own fault. Edit: tip for using cl-gtk2 is to just download it and link the .asd in ~/.sbcl/systems or by (pushnew directory-with-gtk2-asd-files asdf:*central-registry*), when using it, i just use the [C documentation](http://library.gnome.org/devel/references), cl-gtk2 is nearly entirely analogous. Actually, i have a bunch of notes i should be sending to the author suggesting he just make it fully analogous, (stuff with 'set' in the name setf functions.) and make parts that CL can do significanly better in a separate package. Btw, admittedly it doesn't all work, but you can work around not having lists by just composing objects.
Sounds just overcomplicating things to me. Why not wrap C ffi with nice cushy defmethods.. Have this project i call General Interface Library/Language(GIL) with ideas: * Typesetting and gui are overlapping/continuous spectrum. * Code is data, more specifically code as just calling functions is data. * It is constructed with methods, where the first argument is the output 'language'. Currently have :txt and :html, which admittedly doesn't really contain any GUI yet. Wrapper functions set the first argument with a special variable gil:*lang*.
Yes, you can; Pascal Constanza demonstrated this in a [paper](http://p-cos.net/documents/hygiene.pdf) recently (PDF warning). However, his paper was not much cleaner than what you describe. Syntax-rules are simple to implement, and achieve hygiene without relying on code executing (series of term rewrites, basically). This has benefits and drawbacks, demonstrated by the various syntactic systems available for modern scheme (er macros, syntactic closures, quasi-syntax, &amp;c.), as well as plain old CL macros. Basically, there are draw backs to either way of doing it, and in either case, quasi-quote is still semi-complicated (to implement correctly). 
Of course; I wish all discourse on reddit would be this civil &amp; reasoned. 
when will it appear in the iStore????
Emitter Coupled Logical?
Embeddable Common Lisp
Thanks. Maybe this'll help me finish it. Third time's a charm!
I'm working on designing a lisp for numerical computation (not sure whether it's a lisp 1 or lisp 2 yet ... see http://spencertipping.com#section=blog&amp;post=in-defense-of-the-lisp-2-paradigm for some thoughts about why). Ideally it will have a JIT compiler bootstrapped on a minimal interpreted Lisp. What I would like to do is have the executable store the image when it shuts down, rewriting itself so that its state is preserved. Naturally, I expect a lot of study of x86 assembly before any of this happens :)
I would be interested to know how x86 code generation goes. I'm looking at implementing a JIT compiler in Lisp for Lisp and I'm open to any advice you have.
Awesome! Anything that you've got online?
There may be an interface from the Perl decompiler (B, I think?) that you can leverage for the porting. It would be nice to have an automated conversion process.
It can be helpful to learn an existing Lisp before writing your own. I recommend Scheme or Common Lisp.
Quite true. Having learned both, I would like to write a very odd Lisp -- one implemented as an interpreter in Perl that then runs a JIT compiler written in interpreted Lisp. (You can JIT things in pure Perl code using DynaLoader, I believe.) Then, it would ideally be able to save its image back into its own source file, resulting in a stateful and platform-independent native-speed Lisp system.
If this sounds crazy, I'm sure it is. But I think it would be awesome :)
Write a program in your new language and see if it helps to write that program. Sometimes it could interesting to come up with new ideas how a language might work without looking at ways to apply that, but generally it is nothing I would do. Programming languages are there so that programs can be written and communicated. Developing new languages usually should have a goal. What you present are a few code snippets - this does not really give an idea what these features are for. In the higher-level Lisp world one usually has a domain problem (like describing and visualizing a turbine and its parts) - then one looks for a language that helps to write software for that domain. You seem to look for a solution first and then the problem later. What is the problem you want to solve, what does the language need, that helps solving that problem and what are examples that show the capabilities of that language in the domain?
It's not clear you know Common Lisp from the code shown in your blog post.
[Yes!](http://piepe.lv/abop/)
I see what you mean. Sorry about that. I'll fix it to make it clear that this is imaginary code and won't actually compile.
I was thinking more about the naive use of APPLY.
I'm not sure I follow you. It's an unconventional form because you generally don't cons an argument list directly, but you might see this sort of thing generated by a macro or some such.
Look up spreadable argument list designators in the glossary for more information.
That's very interesting. Thanks for the pointer; I didn't know about this.
See also: [Calispel](http://www.thoughtcrime.us/software/calispel/). (I wrote this.) It supports more efficient ALTing (no busy-waiting), and I'm finishing up a release that adds channel poisoning, for cleanly terminating networks of threads.
How would it compare to http://www.ii.uib.no/~knute/lsystems/llisp.html ?
plus: l-system definitions looks more like in abop book; import modeled polygon geometry for leaves, fruits, etc; generation of branching UV coordinates for texturing; minus: interaction with environment; spline based geometry;
You have either reached a page that is unavailable for viewing or you have reached your viewing limit for this book.
Aw bummer. Was working for me earlier today.
HTML?
You could have put at least a little explanation of what the link was before everybody had to click it.
It's not clear to me that Hefner's is going to be small! Also, I was really pleased with how easy it was to run Towers on my Linux box, and the code is short &amp; sweet. Ripe for hacking!
If you're too busy to click links in a niche subreddit to check them out, maybe you shouldn't waste time on reddit at all.
I do a fair amount of coding for the AppEngine platform in Java (so far my JRuby experiences have been mixed). The AppEngine platform is constrained and there is about zero chance that natively compiled Lisp will ever be supported. JVM based Schemes and Armed Bear CL should be possible.
If you're too busy to type a decent sentence worth of information about your links on a niche subreddit, maybe you shouldn't waste time posting links on reddit at all.
+1
take sat?
I imagine Google would have to do a fair amount of hacking to make CL generally available; from my understanding, Java &amp; Python development, are quite restricted (the Wikipedia entry mentions there is a [subset of the standard class path](http://en.wikipedia.org/wiki/GAE#Restrictions) for Java available). Plus, which web framework would they choose? Probably something custom, and similar to [CL-WHO](http://weitz.de/cl-who/) or [ParenScript](http://common-lisp.net/project/parenscript/); I'd be pretty interested to see what they puzzle out...
I agree. I downvoted myself.
ABCL might be possible... in theory. Clojure is already possible, but of course with no multi-threading.
Umm, they've already made ABCL working, according to mailing list: http://article.gmane.org/gmane.editors.j.devel/3025 So I guess issue can be closed.
hello world != working
Well, I didn't go so far as to downvote you. I was just making a little suggestion. :) &lt;3
Why do you think so? I worked with ABCL for some time, and from my experience the hardest thing is getting it to boot, as it needs to load its files in pretty unorthodox ways. Once it is loaded, all CL functionality should work and Java integration is not a problem, so it can do pretty much everything it should do. Also there can be a problem with getting compiler to work, as it works in quite weird way from JVM's point of view, but I don't think it impossible to implement. 
Material is online: http://sbcl10.sbcl.org/
You can get the code here: http://lisp.pingabuse.com/code/midori.zip . Keep in mind that it's not much and I'm just a beginner so the code might not be idiomatic or the best choice. It's also not that complex as you'll see ;). Hope it helps though.
And this too: http://lisp.pingabuse.com/code/gcl.zip . It's basically the same code, but different context.
This is very much not finished, and any comments to improve it would be very welcome. EDIT. This is getting closer. Added an example of the negative effect of oldspace writeprotection.
I don't think the two-column layout works very well for web-pages.
Actually, it depends on the size of your browser window relative to the font. I have seen it with one column and up to three columns. I agree that it doesn't work for long posts. Guess I should tidy things up anyway, and I've split the thing into multiple posts (will show up in a minute or so).
You lost me a bit on the first line, "optimization is about making something working go faster." That's only optimization of speed, and there are many other different axes of optimization. I like Erik Naggum's [summary](http://naggum.no/erik/optimization.html) better: "the purposeful act of improving something under a set of circumstances." I like his entire essay, in fact. &gt; People occasionally asking me vague questions about how to optimise their projects. Typo on asking? &gt; The famous saying that "micro-optimisation is the root of all evil" That's not the famous saying with which I'm familiar. &gt; a great deal of nonsense is written about it This seems like more on the pile.
It's dead. Repo.or.cz apparently isn't a paragon or reliability, it's not the first time they're down.
WFM.
I have corrected the quote and made explicit the remit of the series. Thanks for bringing it up. I guess your point is that this is contrary to the spirit of the people who kept with Lisp through its darkest days.
Who cares about spirits? I would love to see a good resource about optimization for SBCL. I hope your draft evolves into that.
Odd. It consistently refuses to work here, yet I haven't seen anything else have any issues.
It (the site is visible) worked for me (I am from Ukraine).
The font you're using for text seems unduly large, but I'm stuck on IE 6 at the moment. It may well look more reasonable on a more reasonable browser.
Nope.
My (Polish) ISP decided to block it for some reason ("possibility of botnets") :/
I find myself using web services a lot from CL with Drakma, CXML, and Ironclad. CFFI is great infrastructure for supporting such things. Oh, and cl-ppcre too. I do most of my scripting with CL because these libraries are well-documented and easy to use.
[cl-gtk2](http://www.cliki.net/cl-gtk2) is pretty good, although imo it would be nicer to have C very effective to-c conversion, and a layer in a separate package ontop of that.(cl-gtk2 doesn't go much beyond it atm, btw.) I added some 'hooks'(Functions you can input to alter things, macrohooks being an instance) on [ah2cl](http://www.cliki.net/ah2cl), to allow working with names. Unfortunately i can't find the code. (Omg) These should be usable to automatically make setf-functions when the word set is found. ah2cl works fine, but seems pretty badly coded by the way. Edit: the reason i think is is important, is that besides saving time in converting things manually, a good auto-cffi library would allow people to think about the *next* thing, like how to connect the libraries better to the programmer. CLOS is excellent, and i have been thinking/working on a method-based general GUI/markup library/language. [Ltk](http://www.cliki.net/Ltk) is also good, and unlike cl-gtk2 everything worked, but i found it more restrictive. [Lispbuilder (SDL, but it is a whole set)](http://www.cliki.net/lispbuilder-sdl) is pretty good too. Same note to it as cl-gtk2. The CFFI ones are damned important btw, they allow us to use *anything* in C. (At *least*.)
I've reduced the size of the text. At least on IE6 you don't have to contend with the strange column behaviour forcing to scroll up and down unnecessarily. Does anybody actually like the columns or shall I ditch them?
Please ditch them.
The original with an explanation of the code is http://grok-code.com/12/how-to-write-original-jokes-or-have-a-computer-do-it-for-you/ Here is a slightly modified version to run on other Lisps, like SBCL http://paste.lisp.org/display/92459
 (define-macro (quasiquote tmplt) (if (pair? tmplt) (fold (lambda (cell acc) (if (pair? cell) (if (eq? (car cell) 'unquote) (list 'cons (cadr cell) acc) (if (eq? (car cell) 'unquote-splicing) (list 'append (cadr cell) acc) (list 'cons (list 'quasiquote cell) acc))) (list 'cons (list 'quote cell) acc))) ''() (reverse tmplt)) (list 'quote tmplt))) Have I done something wrong? Or is this semi-complicated? EDIT: note that this is based on the assumption that only `quote`, `if`, `lambda`, `set!` and function application are available as syntactic forms.
That sounds about right, I'm in Poland right now.
The problem of hunting down libraries and evaluating their quality and completeness (which probably is a significant problem for people new to Lisp) will be solved for a large part when one or more Lisp implementations decide to agree upon and ship a common set of currently used libraries to at least match up the functionalities offered by other language's platforms. Such a "batteries included" distribution would de facto standardize those libraries and strengthen the "Lisp platform". I'm glad to see that at least the SBCL developers consider going this way. The non-existance of libraries for common tasks in the shipped libraries surely did hurt Lisp in the past years. I dont want to even think about how many people found about Lisp, thought it was great, but gave up because they thought it tiresome to first go hunting down and evaluating libraries in the wild and then to base their work on them, not knowing how well they will be developed and maintained in the future, etc. 
http://downforeveryoneorjustme.com/http://repo.or.cz
I'm pretty new to lisp and to be honest getting things done that are outside the ANSI standard is not pretty. Having a Batteries include distro will help provided it comes sufficiently documented. Haskell seems to have started giving batteries included distro known as Platform Haskell. Maybe we should do the same for CL as well.
CL has had a couple attempts at something like Cabal in the past, notably, [MK-defsystem](http://www.cliki.net/mk-defsystem) and [ASDF](http://www.cliki.net/asdf). It's been a while since I've strayed from Debian into the manual package management world, but iirc, ASDF is the most current system in use.
I think a better example of what shortsightedsid is talking about is something like [libcl](http://libcl.com/) or [lispbox](http://www.gigamonkeys.com/lispbox/). Sadly, lispbox is out of date and libcl doesn't include an implementation. Nevertheless, they are complementary projects and the SBCL developers discussion of including libraries in an "SBCL distribution" is interesting. There's a long [thread on the devel list](http://thread.gmane.org/gmane.lisp.steel-bank.devel/14269) about that actually...
What things are giving you trouble? Maybe I can help.
I didn't know there was a CL-LLVM binding, let alone this! Thanks for the posting, xach!
OSX only? That's a shame.
Just to compare, the ruby installation comes with a number of libraries such as for networking, xml, win32 ole, io etc.. Platform Haskell has a similar structure and it all seems to be packaged together. Even PLT Scheme comes with a number of libraries that are intertwined and documented. Having such a system for CL with the documentation really helps newbies come on board faster. redline6561's pointers [below](http://www.reddit.com/r/lisp/comments/ah645/favorite_cl_libraries/c0hlmh9) are something to think about.
So...which part is giving you trouble? Can I help you with something specific?
I think the problem I'm facing is more of a change of perspective rather than anything specific. Coming from a background where I have coded C and a variety of scripting languages for over a decade, CL is just a little different. What makes it interesting to me *is* that I'm learning something new each day. Beginner tutorials that exist are good but we need to have more tutorials that show how to use CL to solve small but real problems. Even if they are implementation specific, that should be ok, provided they are shipped with the implementation itself. Edit: What would you recommend as an CL to use for a newbie? I have tried CLISP and SBCL on Windows XP. Perhaps a different CL has some of things that I pointed out and is still easy for some one like me to pick up and get productive. Obviously cost is a factor when you are trying things out!
I don't use Windows, sorry. If I did, I think I would probably buy LispWorks. The LispWorks group is very supportive and there are a number of successful commercial Windows products that use LispWorks behind the scenes. I prefer Emacs, but people who use LispWorks (like Edi Weitz) swear by its editor. I personally use Linux and SBCL and SLIME for Lisp hacking. I do one-off Lisp projects for work (like file processing, templating, reports, etc) and for fun I work on http://wigflip.com/ which is all powered by Lisp.
what is the advantage of this over asdf?
I think it's more comparable to asdf-install.
As far as I can tell, this uses asdf internally. What it adds is a system for downloading libraries and resolving dependencies automatically, similarly to how a normal packaging system works in Linux with apt or rpm. 
What is the advantage of apt over make?
A better question is what's the advantage of this asdf-install. The only one I can think of is not depending on cliki.
It worth also looking at [libcl](http://libcl.com/) and [cl librarian](http://common-lisp.net/project/cl-librarian/).
lispy is apt, asdf is deb.
actually that is what I meant, should have formulated it better :)
&gt; "Patterns of Software: Tales from the Software Community" This is essentially a biography of RPG, it has maybe two lines or so of CL code. Are you sure it is a book on Common Lisp? 
It is not really a book 'on' Common Lisp, but relevant for a part of the Common Lisp community - those who are interested in some historical background. RPG was the head of Lucid Inc, an early Common Lisp vendor and describes in detail the business side and how they failed. He has a chapter dedicated to this. The book captures a lot of knowledge acquired while steering a Lisp vendor for a decade (1984 - 1994). It has some philosophical insight also. There is not much technical content and very little actual Lisp source, but I still included it - fearing that somebody will add it, if I leave it out and fearing that somebody will ask why it is in the list. ;-) 
There is a recently added [comparison](http://common-lisp.net/project/lispy/versus.html) of other library management systems.
Currently the best 'batteries included' Common Lisp implementations are commercial: Allegro CL and LispWorks. Both can be expensive, but they include everything from networking to cross platform graphics. Included is lots of documentation. LispWorks starts at 1200 Euro / $1500 for a normal (non-academic) user - excluding tax. The Enterprise Edition is even more expensive - there is also a very nice 64bit version though. For free / open source on the Mac: there is/was [Ready Lisp](http://www.newartisans.com/projects/ready-lisp.html): Aquamacs, Slime, SBCL and a small number of libraries.
Try running your JVM with the -server argument. Then run the Clojure version in a loop for a while so the Hotspot compiler has a chance. Afterwards, take a measurement for one of the later loops. If it's still not acceptably fast, Clojure users will probably try (set! *warn-on-reflection* true) and then add type hints or coercions to Java primitive types. 
Common Lisp: numbers are compared for equality with = or EQL. Not EQ. characters are compared for equality with char= or EQL. Case insensitive comparison with char-equal. Don't use EQ to compare numbers and characters. Common Lisp implementations are allowed to have more than one object for a number or character. EQ tests basically for pointer equality: is it the same object. Numbers and characters need to be compared by value.
This is the big deal. The Clojure version was probably not even compiled with a runtime of 0.5s. The JIT in JVM makes code fast once you have spent several seconds running it, and after that you have to spend a couple of dozen seconds amortizing the compile until you start to be comparable with native code. Why? Because unless your code takes that long to run, the time it takes is not very important. 
Good point, thanks !
(format stream "~a" string) is simply (format stream string) or more primitive (write-string string stream) If you build the test string, you can also allocate the result string directly and copy the source strings into it. (let* ((string "abcd") (l (length string)) (n 1000) (rl (* n l)) (result (make-string rl))) (loop repeat n for i from 0 by l do (setf (subseq result i) string)) result) 
Jesse Johnson? [This guy](http://www.jessejohnson.com/) codes?! Awesome. What's that? Not the same guy? Crap!
http://media.photobucket.com/image/do%20want%20squirrel/cutullus/do-want-dowantdowantdowant.jpg
(format stream string) is not a good idea since *string* might contain format directives.
good point, just use WRITE-STRING
Done
Lisper here. I almost never count (). I like that my editor can reindent my code for me, when I move it or restructure it, and can pick up large chunks of it easily. Historically, in the Lisp world, changes like yours do badly (i.e. see little to no adoption), and those that propose them either a) drop Lisp entirely, or b) use it more and cease to be bothered by the `))))` (any more than C (et al) programmers are bothered by } } } ), and occasionally publicly repent. As Kenny Tilton famously remarked, "When people ask me if all the parentheses in Lisp bother me, I ask them if all the spaces between the words in English bother them?" (Paraphrased from memory). In short, I wouldn't use your patch in Common Lisp, and I almost certainly wouldn't use it in Clojure (were I a Clojure programmer). Sorry to be negative, but you did ask.
I don't like it. It does not increase readability for me, it just breaks indentation. Anyway, my editor can show me matching parentheses, the correct indentation is showing matching parentheses too. Only experiment I liked in this area was block coloring: http://lemonodor.com/archives/001207.html
Fair enough. I use a fairly dumb editor. A smart editor is the trick that makes this work for people then? I'm mostly a Python user, but looking for something a bit more powerful (some people *are* bothered by all the spaces in Python!). Have dallied with Scheme in the past.
&gt; I use a fairly dumb editor. A smart editor is the trick that makes this work for people then? Vim or Emacs at very least, yeah. Clojure types may have their own brand, I don't know. See [here](http://www.reddit.com/r/programming/comments/afl23/where_can_i_learn_professional_programming/c0hdcnv) for a brief rant of mine on using a powerful editor.
last I saw of a survey, the healthy number of clojure programmers were using emacs w/slime for their primary environment. The rest seem to either be VIM/vimclojure or various Java IDEs with plugins (IntelliJ, Eclipse, Netbeans, etc)
The indentation is different, but self-consistent. It's like syntactic tail-call optimization. There's a passing similarity to the do syntax in Haskell, which flattens a series of nested function definitions. I guess my example doesn't really show this too well, here's another, adapted from http://rosettacode.org/wiki/Mandelbrot_set#Clojure (ns mandelbrot (:refer-clojure :exclude [+ * &lt;]) (:use (clojure.contrib complex-numbers) (clojure.contrib.generic [arithmetic :only [+ *]] [comparison :only [&lt;]] [math-functions :only [abs]]))) (defn mandelbrot? [c]] (loop [ iters 1 z c ]] (if (&lt; 20] iters true] (if (&lt; 2] (abs] z false] (recur (inc] iters] (+ c] (* z] z (defn mandelbrot []] (apply str] (interpose \newline] (for [y (range 1 -1 -0.05)]] (apply str] (for [x (range -2 0.5 0.0315)]] (if (mandelbrot?] (complex x y) "#"] " " (println] (mandelbrot) Compare the use of "for" in the mandelbrot function with a do statement using the list monad.
Paper dated March 1978, very Interlisp
Actually, I thought this was yet another stupidity of some new lisper, but I like that idea. It doesnt blow up the syntax too much and its not much harder to parse.
I'm programming using Common Lisp for more than 4 years now in my job. I use emacs, SLIME and paredit to edit Lisp code. I **never** type a single '(' or ')' character. I always edit code using structured editing commands, most of them are bound to simple key bindings without modifier keys to speed up typing. For example, the '(' character is bound to a key without modifier and will insert '()' into the buffer. The cursor will be positioned between the parenthesis. Other commands to edit s-expressions include: kill, copy, paste, move up, wrap, transpose, splice in, etc. When I read code I use the built in highlighter to color the background of the smallest s-expression which contains the cursor. I **never** count parenthesis. Actually I hardly see them, I rather focus on the words and the structure. What I wanted to say is that I **really do not care about** the trailing parenthesis. That's not for the programmer to read, but for the computer. So, for me this is a useless idea. Sorry about that.
finals )))))s are not bad. And getting rid of and keeping the starting (s will have sad effect on editors auto-indenting and paaren-matching.
&gt; similar to LibCL, Lispbox, Lisp in a Box and STARTER-PACK Genuine question, if there are already so many other 'similar' packages, why a new one? I have only dabbled a little in Lisp in a Box (and have never used the others), what does this have that the others don't? 
See [Lispy versus...](http://common-lisp.net/project/lispy/versus.html)
It is directly modelled after Linux distribution style package and dependency management. LibCL, LispBox and Lisp in a box just throw everything together in one big messy package, and since its only one maintainer, theyre progressing rather slowly, if at all. Its kinda like a prebuilt Linux from Scratch. Starter-Pack is the same, but additionally limited to Windows and the closed-source LispWorks. This style of packaging is nice for beginners, but nothing you would like to have for the whole community in the long term. asdf-install was a first step, but it's dependance on cliki, lack of proper package version control and naming and getting files directly from upstream sources from all over the web is a quick ugly hack, again nothing you want to have for the Lisp community in the long term. clbuild "works" right now but its a) not itself written in lisp, b) requires half a dozen different revision control systems to be installed, and c) has problems with version dependance management. Lispy (apart from having a "nice" name and not a butt-ugly acronym like "gfhgsffghs" or "asdf") simply recreates for the Common Lisp ecosystem what the author already did as Gentoo maintainer. It creates a proper package manager and a (hopefully) well-kept and community maintained central repository independent of the upstream sources. 
That's the way to explain the lambda calculus? :)
http://www.xach.com/misc/lambda.html was my choice of new logo, but it got viciously downvoted.
:) - at least to support hypnosis on die-hard Java-developers... :) 
Her twins shall remain nameless!
I hope you understand now what was wrong with your design and why this is much more popular.
Unfortunately she has a duckface :(
But thats a problem of the editors - which can easily be changed.
I thought lambda stood for lesbian...
Yeah, LibCL's had a slow start. But in this time, it has fixed portability issues in many of the bundled libraries; I'm trying to shape LibCL into a central clearinghouse for portability and maintenance. The single bundle also has other benefits to users (e.g. a single revision number). But even if LibCL were "perfect", there would still be a need for projects like Lispy which optimize a different set of criteria.
but ... what´s on her right protuberance?
Didn't know SEXP was a predicate ...
worked fine for me today.
Nice report from to of the core authors of R (which it is about). Though I wonder when they will really move the entire R project to CL. 
Andy Freeman wrote this on comp.lang.lisp in 1988: &gt;&amp;AUX is convenient if you'd like to write a destructuring function &gt;defining macro and don't want to figure out how to parse declarations. 
[Dan Weinreb chimes in](http://groups.google.com/group/comp.lang.lisp/msg/c872bea66b0f1943) on the same 1988 thread. &gt; At that time (1976), LET had not been codified as part of the &gt; language; many people at MIT had their own LET-like macros, all &gt; slightly different and incompatible. Soon thereafter, someone &gt; (probably Dave Moon) picked the current LET syntax and installed it as &gt; part of the basic Lisp system, implemented (originally) as a macro &gt; that expanded into a lambda-combination. This was one of the first &gt; times a macro had been installed as part of the Lisp system itself. 
I just retried it. It works if I remove the reddit frame, which apparently conflates my viewing with every redditor's.
Perhaps not the reason for its existence, but `&amp;aux` can be used in [BOA constructor](http://www.lispworks.com/documentation/HyperSpec/Body/03_df.htm) initialization: (defstruct (foo (:constructor make-foo (n &amp;aux (storage (make-sequence 'vector n))))) storage) Allows you to write `(make-foo 10)` and get a vector allocated.
You do realize you submitted this same link a couple years ago as well, right?
Sure, but not to lisp.reddit.com.
OT: why is it not standard practice to put the date on white papers? I know there is a review process sometimes before it becomes "published" but .... sigh.
This is very cool, although the writing style and format seems designed to make it as unpleasant to read as possible. One of the things that turned me off of REPL-style development is this exact ad-hoc testing thing. Coming from a compiled-code unit testing background, it always felt to fly-by-the-seat-of-my-pants for me. It does mischaracterize jUnit and NUnit as single-entrypoint though. At least with NUnit, it's simple to run a single test in isolation.
[December 2009](http://www.cs.aau.dk/~normark/laml/)
I have the tests in a buffer. Recompiling the buffer generates warnings or errors. The IDE lets me browse the warnings. With the compilation conditions browser, I'm locating the problematic forms. I 'm recompiling the tests until there are no more warnings.
SMP. Buzzword of the decade!
looks interesting, but at $5100 per user for the setup that I would want ... it's a little rich for me.
I didn't find the examples justified the advice very strongly.
There is also a bug in INLINE-ASSOC. Let the implementation do the optimizing for you, *then* go back and fix up hotspots.
From the intro, &gt;It is about SBCL, which is the highest performance Common Lisp implementation today, [...] Is this true? I've tried to find information on comparing the performance of the various implementations, but came up empty. I had also sort-of assumed that the proprietary ones had the best performance, though I don't plan on using any of them. 
&gt; Is this true? Probably. SBCL has very good compiler. &gt; I've tried to find information on comparing the performance of the various implementations, but came up empty. Have you tried Google? Googling for `common lisp benchmarks` has http://www.cliki.net/Benchmarks as a third link, and there you can find various benchmarks. Most are probably outdated, but the show general picture. &gt; I had also sort-of assumed that the proprietary ones had the best performance Proprietary ones might have particular aspects optimized better than SBCL. 
Heh, guess I didn't look very hard. Good to know that a Free one is the highest performing one! 
Next you'll say her knees are too sharp :P
None of the noise, or the expertise, of comp.lang.lisp!
A nice alternative to the existing ones.
Hi, I'm a college senior with 5 years of undergrad research experience in software development for biologists and metaheuristics such as evolutionary computation and simulated annealing. (Started in high school.) I'll be heading to grad school in the fall. Your job posting on Comsys mentioned work involving algorithms and AI. I would love to visit your company and see what sort of algorithms and AI work is being done in the real-world. (I live in the Ft Lauderdale area.) Do you think that this could be arranged? I can send a copy of my resume and code samples to verify my background, if you would like. Thank you.
The SLIK manual is interesting - a GUI system for a real-world app, built on CLX. 
&gt; One of the things that turned me off of REPL-style development is this exact ad-hoc testing thing. Because dynamic development naturally excludes unit tests?
Any better examples would be very welcome, I have tried to make them as real world as possible, but probably ended up muddying the waters :)
That was the point of inline-assoc, as assoc was a hotspot in a real program (tpd2). Excellent work spotting the bug!
Yes, I am more concerned with making tpd2 fast than documenting it. It also lacks features compared to most webservers. I have also rejected patches that don't meet my coding style so you could put the lack of contributers down to personal crankiness. That said, patches to add functionality are welcomed :) I make tpd2 for fun and there is a lot of stuff to finish before it gets to the state where someone can drop it into their project without having to understand and modify it.
In my experience, SBCL is much, much better than Lispworks, ClozureCL or Allegro at generating decent code. If you care about memory usage, maybe Lispworks or ClozureCL.
In theory, no. But, in practice, from what I've read, people who do REPL-style incremental development don't tend to leave a suite of unit tests in their wake.
Nice. Since there are a lot of possibilities of running Common Lisp Code as a Web-App, I wonder if it was a good idea to create some portable library which makes it easier to write simple applications for multiple server-types, such that the same code can be run in a hunchentoot-, aserve-, (f)cgi-, AppEngine-, etc.- environment.
FYI, I designed repo-install so that experienced lisp developers could easily contribute library changes upstream. That is why repo-install uses whatever distributed version control system the upstream package uses. Make a change, and push the result using the native git, bazaar, or mercurial process.
[UnCommon Web](http://common-lisp.net/project/ucw/) has a HTTP server abstraction which lets you deploy your UnCommon Web application in multiple environments without change. There's nothing like a standard web application container (like Java Servlet container) in Common Lisp land yet, though.
What I've seen in the Lisp community contradicts that.
How about manardb? That has plenty of docstrings.
Two things: it wasn't especially obvious that assoc was an actual hotspot. It might have been obvious to you, since you were hip-deep in your application's code, but it doesn't come out very well in your post. It looks like you're just micro-optimizing the implementation of ASSOC so you can make a micro-micro-benchmark better. Additionally, your example doesn't make it clear whether the reduced time is from the reduced consing or eliminating the function call overhead from ASSOC and the passed :TEST function, or perhaps a little of both. (Please also note that SBCL optimizes calls to ASSOC so they don't have to go through the full generality of keyword argument checking, function designator coercion, and the like.) Inserting a judcious FLET and DYNAMIC-EXTENT declarations would have helped in making this distinction. Showing that as one step along the way would have shown off the range of options you have to make your code efficient in Common Lisp, too.
Would buy if they offered a black t-shirt with white letters.
(eq your-wish my-command) http://www.zazzle.com/cproteus
I don't get it! Can you explain?
Thanks. Erik's words are a precious legacy, even when one does not agree with them (which happened quite often :-)). Even if not considering their undoubtful technical merits, in their absolute refusal of any compromise there is some kind of greatness. Also, I am glad that an archive of CLL exists. The thought that our memory depends on a corporate entity (albeit currently "not evil") is somewhat worrying.
The reason assoc was a hotspot was because of the overhead of the profile instrumentation in the test function passed to assoc. It's a long and complicated story. I hope to go into it, but it didn't seem the right time to do so. You are correct that I didn't talk about the reasons for which the assoc is slower than the simple loop despite SBCL's transforms on assoc. I haven't examined them. Your hypothesis about the consing and the full-call overhead being the most important things sounds sensible. I guess which one is most important will depend on the pressure on the gc from the rest of the program. I don't want to descend into saying the old stuff about declaring things dynamic-extent, inlining functions and declaring fixnums, etc., as plenty of people know about those.
 if (!love(books)) { pound(rocks); }
 (unless (love 'books) (pound 'rocks)) There, much more readable.
&gt; in their absolute refusal of any compromise there is some kind of greatness If Erik would have used his intellectual powers to actually further the cause of the great language that is Lisp, I would agree. However, his outright agression towards the uninitiated really only drove people away from Lisp. 
I suspect that in this world [of Assiah?], everything is a compromise somehow, Lisp included (albeit, in this case, a better compromise than other alternatives). Sometimes I felt that Erik was not really made for this world (and after all that's also why we remember him; reasonable discourse is rarely memorable). But, fleeing from Lisp (or SGML) because of someone's harsh words sounds exactly like the kind of fallacy that he loved to pinpoint. That said, I probably like the man because I've always admired him from a safe distance :-)
I don't think that's the _only_ impact his articles had. He was helpful, humorous, informative, aggressive, thought-provoking, and much more. I learned a lot about Lisp from Erik's articles, and I don't think I'm the only one.
He [did](http://naggum.no/lugm-time.html). And I'm not sure he had aggression so much against newbies as he did trolls and the "arrogant ignorant". That is, if you come in saying "Lisp sucks! Why can't it do x?" you would probably get a worse response than if you said "In the language I used before we did x for task y. What is the right way in Lisp?"
I understand what the code does, I don't get the pun!
I don't think I'd agree with "absolute refusal of any compromise". What did you have in mind by that?
It's just the impression that I got by reading some of his articles (recently, not when they were written): that Erik liked to follow lines of thought to their extremes. Which not rarely resulted in attacking people e.g. for not being absolutely consistent. It is also true, however, that I found the articles by following links, so it is possible that there was some selection bias. 
He pulled me towards CLL because of his posts always ending up at the top of a search results list. So consider this a counter point to your argument.
Having the message IDs be links to the posts in the Google Groups archives is a nice touch. 
Thanks. I'll probably try to convert the links to the "view in thread" links, but that will require some manual crawling. For the moment there's too much clicking involved to get the thread context.
Browsing at random I came across an article that I think is at odds with some notion of "outright agression towards the uninitiated." [Maciej Borecki asks how to compile Lisp to an executable](http://www.xach.com/naggum/articles/3284276275271451KL2065E@naggum.no.html), a FAQ and source of annoyance to many. A real bonehead would attack the very notion of generating executables, but that's not how Erik responds; I'd sum it up as "That's not a bad thing to want, but here's some CL context that might change what you want." He even talks about Emacs as one of many possible environments, not the exclusive tool of the super Lisp nerd.
There is no pun. The statement means exactly what it appears to mean. The fact that it's in Lisp syntax is what makes it amusing. Sort of like `honk() if $you-&gt;love(perl)`
&gt; I don't think that's the only impact his articles had. OK, I'll concede that. Regarding the question of whether he attracted or repelled people from Lisp: that can prolly never be answered. What is clear to me, however, is that without Eriks pointless pontificating, many more people might have been attracted. And it's not just the uninitiated; try and read op on the acrimonious debates with Erann Gatt (who, incidentally, put Lisp in outer space). At some point, Erann stopped contributing to comp.lang.lisp, and my impression is that quite a few other bright minds got fed up with Erik's mouth-foaming diatribes and just left. 
&gt; Regarding the question of whether he attracted or repelled people from Lisp: that can prolly never be answered. I think it's fairly obvious that he attracted some people and repelled others. &gt; What is clear to me, however, is that without Eriks pointless pontificating, many more people might have been attracted. I don't find that especially clear. If you miss Erann Gat's online wisdom, you can always follow him [here on reddit](http://www.reddit.com/user/lisper). He mostly debates Christians here, though.
DAE read (pound 'racks) instead of (pound 'rocks) the first few times?
I'm a lisp newbie, so I hadn't heard of him until the archive got posted. I got to reading some of it and it was interesting to say the least. Looks like he hated Perl and XML with a passion! Having said that he seems to have loved CL with greater passion as well. There are some interesting nuggets that I found including [very simple stuff](http://www.xach.com/naggum/articles/3005937741.475635@naggum.no.html) that I immediately tried out. It looks like the later posts got more and more abrasive and so I'm reading the earlier bits first :-)
It looks like they could use someone with HTML experience.
But he is possibly slightly insane - from his homepage: ' especially Ancient Lisp Systems (Harper has assembled a collection of still working 25 year old Lisp Machines (an enormous Symbolics 3650 and several 3620's) and components (e.g., about a hundred Symbolics triple-high VME boards) from the primordial age of symbolic processing); ' I can't really believe that he has 'a hundred Symbolics triple-high VME boards' - that's insane. 
&gt; \*everything\* from hash tables to string-operators to memory management is automatically included - there is **nothing that is not included** (emphasis mine) Seriously?? &gt; Excellent programming environments - e.g., parentheses-savvy editor. Pretty much every programming language has environments that can parse its syntax (Grammar savvy, similarly to parenthesis savvy). &gt; Excellent compiler, especially with declarations, enables very fast code. While it may compete favorably with Python or Ruby, it probably won't compete favorably with Haskell, OCaml, C, C++, C#, Java and many others. &gt; Excellent system stability with no random crashes at all I don't generally get "random crashes" from the languages' environments I use. I used a lot of Python and Haskell, for example, and they didn't have that. I did encounter some random crashes (at exit) when using SDL and incorrectly using GLUT, but somehow I really doubt Lisp bindings to those libraries are going to prevent that. &gt; Macros and all that. Ah, finally a real advantage.
Most editors and IDEs for non-Lisp languages simply aren't as good as Emacs' Lisp mode, or the Lisp mode of the Emacsalike included in LispWorks. They'll do coloring and brace-balancing, but what they won't do is **structure-based** editing, where you can (for example) select two Lisp expressions, hit C-M-t, and have their order swapped.
&gt;&gt; *everything* from hash tables to string-operators to memory management is automatically included - there is nothing that is not included &gt; Seriously?? Yes, it comes as an image. You start it and the stuff is there (or lazily loaded). ... &gt;&gt; Excellent compiler, especially with declarations, enables very fast code. &gt; While it may compete favorably with Python or Ruby, it probably won't compete favorably with Haskell, OCaml, C, C++, C#, Java and many others. It is one of the languages which are dynamic and can be compiled to fast code where necessary. In many cases compiled Lisp code is a hundred times faster than Ruby or Python, but as fast as OCaml, Haskell and Java - and slightly slower than C. 
How can you claim that **everything** is included? My friend has just published a new Union Find Delete structure. I bet its not there yet! I don't think there's any evidence CL (EDIT: compiler optimization-wise) competes with OCaml, Haskell and Java.. 
Unlikely. Apple seems reluctant to approve applications that interpret or compile code.
Everything he needed to write his application. Evidence: http://shootout.alioth.debian.org/u64/benchmark.php?test=all&amp;lang=all&amp;lang2=sbcl 
How recent of Visual Studio and Eclipse did you check out? I am not a fan, but their features are more impressive than Lisp mode in Emacs...
That's not what he said
Or even better: http://www.emacswiki.org/emacs/ParEdit
Here is his home page http://www.frobenius.com/enter.htm
&gt;&gt; Excellent compiler, especially with declarations, enables very fast code. &gt; While it may compete favorably with Python or Ruby, it probably won't compete favorably with Haskell, OCaml, C, C++, C#, Java and many others. You _probably_ won't compete favorably with a mediocre programmer. You know, because where I went to school and worked they taught programmers to learn/research then type and share their _findings_. Opinions are reserved for pubs.
When did you last use Emacs? Vague allusions about how "the other guy" sucks abound in this comments section! &gt; I am not a fan, but their features are more impressive than Lisp mode in Emacs... What features? You could be right but with references to some unknown thing it's kind of hard to compare.
&gt; I don't think ... WE KNOW YOU DON'T. Look for definitive results. This is very quantitative. We don't need you to express how you _think_ something measurable measures. Do most projects on the planet incur more in basic implementation costs or in later optimization costs? You don't even have an argument. You just want to be right about disregarding Lisp at some point in your life.
His web design is obsolete and slightly insane... just like his collection of Symbolics boards. (It's so **blue**!)
Hi, Lisp lover here. I appreciate that some of you are replying to Peaker's comment with specific points, but I'm disappointed that it's rated at -3 right now. I think that reflects poorly on the community of this subreddit, that we can't have a dissenting or contrary opinion. I don't think there's anything inflammatory or factually incorrect about the comment--in fact, I agree that the "nothing not included" remark of the article isn't quite .. sound. Like it or not, most people outside the choir would consider regular expression support to be essential to application development, but that's certainly not included. Nor or threads, or sockets--probably more relevant to your average Lisp hacker than REs. Now, there are great libraries for these things and more, and I'm not arguing that they belong in the ANSI language specification. But while Common Lisp does come with a great blend of data structures, I just about always find myself using third-party libraries or writing my own in order to write non-trivial programs. So that point stands. Most people on the lisp subreddit will probably agree that Lisp is a very enjoyable language. But don't downmod Peaker for making the perfectly valid point that the points *listed in the article* aren't particularly earth-shattering.
Visual Studio has a structure editor? Now that would be interesting... can you point to a source? 
Paredit is bliss.
I see your point but I think too many people rush to Lisp and start crying because it doesn't do what they expect it to. Lisp is and always has been more about an environment, a context rather than a strict adherence to some standard way to do things. For the record, I don't think Lispers are geniuses or that it is a magical language made out of rainbows, candy canes and happiness. For all intents and purposes, threading, regular expressions and sockets are solved problems in the Lisp ecosystem. If you want to use regular expressions, you and I both know that you're going to grab cl-ppcre. Once you've included that in your default image, you never have to think about it again. As for the "contrary opinion," the following is just stupid. It isn't misguided or ignorant. It is stupid: &gt;&gt; Excellent compiler, especially with declarations, enables very fast code. &gt; While it may compete favorably with Python or Ruby, it probably won't compete favorably with Haskell, OCaml, C, C++, C#, Java and many others. This statement in and of itself tells us all we need to know about Peaker and his desire to thoroughly debate (Common) Lisp and its place in the Programming Language landscape. People always talk about the grumpy Lispers, but I don't frequently see people walking into other language boards with people so unilaterally informing the inhabitants that their language is irreparably deficient. Better yet, try that at work with any topic whatsoever that is in a quantitative field. It's nonsense and as such it should be called out at the first sight. If you don't like parentheses, Emacs, or John McCarthy's haircut, shut up and play in your own sandbox. &gt; While it may compete favorably with Python or Ruby He thinks it is (well, "may" be) faster than Python and Ruby. Wow, that's some impressive sleuthing. &gt; it probably won't _Probably_? You see, one of two things took place here. A) He did some really interesting, never-before-seen statistical analysis on the space of computer programs and found that in the majority of cases, "it won't." (We'll get to what it won't do momentarily.) B) Before even waking up this morning and reading this posting, he made up his mind about Lisp by imitating the attitude of a dim-witted professor from five years ago or maybe the cool engineer at work who wears Hawaiian shirts and throws scalding hot coffee in managers' faces. Which do you think is more likely? &gt; Haskell, OCaml, C, C++, C#, Java He's impressed by these languages. His peers told him that they were neat. (We know that he is incapable of forming a logical preference on his own in any given context because he hasn't figured out how to measure things other than "A is always faster than B".) &gt; and many others. Lisp is very slooooooooow. Like, reeeeallllly slow. Probably somewhere around VBA slow. Oh, lest I forget "compete." What does that even mean? Are we going to line up Ruby, Python, Java, C, C++, Haskell, OCaml, Prolog, C#, VB, etc. on a big hill and hand them all massive logs to see how far each can throw theirs? Maybe we should time the point at which they are handed the log to that at which the log hits the ground. What's the competition? I guess it is "going fast" whatever that means. Do you think he uses -funroll-all-loops? I guess (which passes as fact in this comments section) for all values of compete, Lisp loses against the "big boys." You see, there is no discussion here. It is yet another person who just knows that Lisp is so braindead that they need to help the world by, uh, thinking that maybe it could be sort of slower than this or that if measured in some invisible way and then letting everyone know about it. Well, I guess that's better than coming here with a language shoot-out which, even though it shows CL and Some Language as being neck and neck for some non-representative algorithm (in that 1) the person so ignorant wouldn't have achieved those same tuned results in C and 2) when they do come across that type of code in production they're sorting a massive set of 200 items), they insist that last 5-10% is truly critical, even if they don't know where it is in their code, how to find it or how to measure that they reduced it.
lw cl = [LispWorks](http://www.lispworks.com/). fwiw...
Is support the only reason to pick a commercial CL over something free like SBCL? There must be other reasons and not just that. There are plenty of commercial products written in other languages that use free compilers/interpreters. E.g websites that use Apache, Ruby on Rails, PHP etc or even code written on linux compiled using GCC. Plus there are [examples](http://postabon.com) of commercial products built on free CL implementations and libraries. I guess the question is, what is support? Is it being able to pick up a phone and ask - I'm not able to install xyz or is it being able to get help on libraries/environment that is outside ANSI scope. For that matter there are plenty of people who buy Visual Studio on Windows and then search online for help. I guess someone with a commercial CL would do exactly the same thing as well. So, why pick a commercial CL?
I think the language features are moot when weighed next to the fact that he has nearly forty years of experience with the language. Going with what you know seldom puts you at a disadvantage when starting a company. 
I like that you added a [link to a random article](http://www.xach.com/naggum/articles/random). You should have that on the front page as well.
&gt;While it may compete favorably with Python or Ruby, it probably won't compete favorably with Haskell, OCaml, C, C++, C#, Java and many others. This may be what you think, but you're wrong. Go look at [this](http://john.freml.in/teepeedee2-c10k). So far there has only recently been a single C implementation able to compete with this. The majority of C implementations can touch these numbers.
It is not black and white. But even for free software you have to pay the people to put in the advanced stuff. Say, you are on an HP/UX box and you want the garbage collector to be improved for some engineering application. You can either maintain the Lisp yourself (there are companies doing this), use a 'free' Lisp (and find a knowledgeable person and pay him/her to do the work) or contact the support of your vendor ( [LispWorks support and Maintenance](http://www.lispworks.com/support/description.html) ) and pay for the enhancements. Some Lisp users are doing obscure stuff or are using obscure platforms and the chances that someone puts in the changes for free, when you need those, may not very large - especially when the number of people capable enhancing an implementation are not that numerous. Then it can help that some guys have a constant revenue stream and don't walk away. If you look at Clozure CL, it is free, but mostly driven by the developers of Clozure Associates. You can buy support from them. If you look at SBCL, lots of improvements have been added over the years - but SBCL now is already ten years old and started with an existing code base (from CMUCL). Some companies have paid for SBCL enhancements. This long term investment of a community in a platform pays back. One plus is that SBCL has attracted a group of hackers - not just one guy. One of the advantages of commercial Lisps like Allegro CL or LispWorks is, that they tend to work well on commercial/proprietary platforms like Microsoft Windows - including the whole development environment. SBCL is not very strong on Windows and CCL has been ported to it and they are working to make its IDE work there, too (paid for by a user). But the Windows IDE of CCL is based on a port of Apple's Cocoa library - which is alien on Windows and not something one would really want too much. Generally it is not that surprising, when working with 'free' software, why use Windows at all? If customers/users demand that, sure. But it seems there is a problem getting this thing going. There are few people on Windows demanding Lisp, Lisp is not supported by Microsoft (they have their own suite of supported development tools), there are few implementors in the free software Lisp world working on Windows, ... How to get out of that? Or is it really worth it? 
Ok, I am **sure** his data structure isn't there yet. That was only figure of speech. Its a new data structure - that was only discovered recently, and barely published in CS journals. Its silly to claim all data structures are included.
http://shootout.alioth.debian.org/u32q/lisp.php http://shootout.alioth.debian.org/u32q/benchmark.php?test=all&amp;lang=sbcl&amp;lang2=ghc http://shootout.alioth.debian.org/u32q/benchmark.php?test=all&amp;lang=sbcl&amp;lang2=gcc http://shootout.alioth.debian.org/u32q/benchmark.php?test=all&amp;lang=sbcl&amp;lang2=ocaml
&gt; When did you last use Emacs? Every day. I am an emacs fan far more than VS/Eclipse fan, but people at work constantly shove to my face the capabilities of Eclipse/VS, and in the structural realm they do beat emacs. &gt; What features? You could be right but with references to some unknown thing it's kind of hard to compare. I am not a user of Eclipse/VS/etc, so I've only been shown these features myself, and haven't used them. Personally, I find the editors themselves so horrible that I prefer emacs... Basically, they have structural editing capabilities which they call "refactoring" features, even display the code as flow charts, etc. Also, code browsing is pretty advanced, generating caller/callee graphs at any site on the fly.
&gt; Wow, that's some impressive sleuthing. You're really taking offense with what is just figure of speech. Saying A may be this, but not that -- does not imply that it may not be this. Yes, CL compilers generate faster code than Python or Ruby compilers do and faster than interpreters execute code. &gt; He's impressed by these languages. His peers told him that they were neat. (We know that he is incapable of forming a logical preference on his own in any given context because he hasn't figured out how to measure things other than "A is always faster than B".) Actually, I am not impressed at all with C++, C#, Java. OCaml I know little of, so its hard for me to be impressed of. I am **very** impressed with Haskell, and am a huge Haskell fan myself. The information I'm basing my rough "speed" of implementations of common languages estimates are based on the shootout. With all of the incompleteness and misleading disclaimers of benchmarks, its the best way I know of to estimate the performance capabilities of differing language implementations as of yet. &gt; You see, there is no discussion here. It is yet another person who just knows that Lisp is so braindead Actually, no, I don't think Lisp is braindead. I think Lisp is a very enlightened language - and the idea of code-as-data with macros to implement new language features is brilliant. I myself dislike Lisp-2 and other CL features and prefer Scheme. I love Scheme as a pedagogical language, and I love the idea of macros. I do prefer the more typed approach Haskell takes to tackle *most* of the same problems that Macros do differently. But I appreciate that macros are **more comprehensive and complete than any other approach**. &gt; the person so ignorant wouldn't have achieved those same tuned results in C You're assuming a **whole** lot based on very little text. My daily job **is** in C, and involves a lot of performance tuning. &gt; they insist that last 5-10% is truly critical, even if they don't know where it is in their code, how to find it or how to measure that they reduced it. Basically, your entire set of replies to me in this whole thread sum up to a huge straw-man attack. EDIT: Minor corrections
Examples here: http://trac.clozure.com/ccl/browser/trunk/source/contrib/krueger/InterfaceProjects 
Helpful. But as a Ph.D., I have to say that anyone who feels the need to append ", Ph.D." to his name is always a jerk desperate for attention.
Whatever you say, Dr. TheSummarizer.
That's Dr. TheSummarizer, Ph.D. to you.
I don't disagree. He seems nuts. I was responding to: &gt; I don't think there's any evidence CL (EDIT: compiler optimization-wise) competes with OCaml, Haskell and Java.. I'm not saying you're an idiot or that you aren't smarter than I am. For any language or technology, that is a dangerous statement that you clearly made no effort to back up. It's dangerous because you're presenting yourself as a domain expert and then making things up to suit your preference.
&gt; You're really taking offense with what is just figure of speech. Saying A may be this, but not that -- does not imply that it may not be this. Yes, CL compilers generate faster code than Python or Ruby compilers do and faster than interpreters execute code. No, it wasn't a figure of speech. You took the author's statement and then twisted it to fit your world. He made no claims about it other than to say it was fast. It's not unclear that he means fast enough for all projects he has applied it to. _You_ decided that this called for a "speed" comparison for some unclear reason. Ok, so the original author said this: &gt; Excellent compiler, especially with declarations, enables very fast code. To which you responded with this: &gt; While it may compete favorably with Python or Ruby, it probably won't compete favorably with Haskell, OCaml, C, C++, C#, Java and many others. How is that even relevant? Define compete. How does that relate to the author's "very fast"? We're talking numbers here, remember? Are you getting it yet? These shoot-outs provide a poorly-understood metric to be abused by those who cannot come up with something better to back up whatever decision they have already made. Now define a non-trivial program and demonstrate how knowing that language X has speed 2 and language Y has speed 2.3 during a merge sort helps you to establish one's superiority over in the other during the selection process. It's just a cop out because the obvious implication is that you have to learn a language in order to adequately assess it's strengths and weaknesses, most of which have nothing to do with start-up time, memory use or cycles spent in sorting an arbitrary list.
&gt; Basically, they have structural editing capabilities which they call "refactoring" features, even display the code as flow charts, etc. I'm familiar with this functionality. I think it is more necessary in the languages it is applied to than it is in Lisp. I wouldn't rush to call superior to Emacs offerings. &gt; Also, code browsing is pretty advanced, generating caller/callee graphs at any site on the fly. Last I knew, ACL did this.
But you see, you already made a bunch of guesses and treated them as fact. Do you understand the issue? Right or wrong, it wasn't until you encountered resistance that you even bothered to research the opinions you presented as truths. Unless "probably" was part of the "turn of phrase" that you later called it. I've seen those links dozens of times. Can you demonstrate how it isn't "competing favorably" in those graphs? Like, in an actual real-world scenario? Make sure to bring up an embedded machine where we don't have 1MB of RAM to spare. Because that is totally relevant.
Why do you say that? It is a title that someone spent years earning. Why shouldn't they add this?
It's not an honorific. It's a professional statement. In my experience, no PhD adds the title to their name, or tacks on "Dr.", unless they're (1) required to demonstrate their title in a professional context (say, business cards with "Dr. Bravo, DDS" or "Prof. Johnson"), or (2) desperate to attract attention to this fact. He's in the second category. Generally speaking, PhDs find what he's done a bit... icky. People spend four to six years getting their undergraduate diploma. This doesn't mean you go around saying "Mr. John Johnson, DIPLOMA-WINNER". It looks desperate. Except in your resume.
So does SLIME with SBCL, and presumably other CL implementations. You can track relationships like function-calling, macro-expansion and method-specialization. The UI is slightly clunky in that inimitable Emacs way, but the functionality is there. All of this is in addition to the special sexp editing features provided by Emacsen everywhere and which is just not present in any of the other language environments I've used.
I meant the more UI-friendly sort, but your points are important ones.
I don't see the harm in putting PhD on an instructional paper someone is putting out. That is exactly the sort of environment where I'd expect it. He's not sending you an email. And you don't get a diploma. You'd get a BA or Bsc in your example. I think that is something I'd point out as desperate.
Get a grip. You're drawing wild conclusions and putting words into people's mouths. It's ridiculous. CL implementations generally produce slower code than programs compiled with GCC, for "equivalent" code (as equivalent as can be between languages), and the shootout also shows generally the same for GHC and Java. These comparisons are indeed quantifiable. Now, would a 1:3 performance ratio between SBCL and GCC make Lisp uncompetitive in performance compared to C? I don't think so, but that is a wide performance margin, and who cares? "Competitive" is a damn subjective word. &gt; Lisp had not been good at numerical computations for their exotic design. This situation is however said to have been changed recently, because by giving appropriate declarations, **modern Lisp compilers can generate good code for numerical computation competitive with traditional compilers of Fortran and C. Nevertheless, there is still a significant difference between those generated codes in the sense of execution efficiency.** In this report, we investigate what is the sources of the significant difference for the three major Common Lisp implementations, ACL (Allegro Common Lisp 8.1), SBCL (Steel Bank Common Lisp 1.0.23), and LispWorks (6.0). -- [Seika Abe, An evaluation of Major Lisp Compilers, Knowledge Engineering Division, MSI, 2009-10-08](http://www.reddit.com/tb/9zfwl) So, guess what? Lisp compilers aren't perfect. And so what? That doesn't mean Lisp sucks, only that its implementations could use some work, in this area, compared to other language implementations. That Peaker points this fact out--an apparently quite inconvenient fact to you--doesn't make him/her a witch. &gt; CROWD: A witch! A witch! A witch! We've got a witch! A witch! &gt; &gt; GREML1N: We have found a witch, might we burn her? &gt; &gt; CROWD: Burn her! Burn! &gt; &gt; BEDEMIR: How do you know she is a witch? &gt; &gt; VILLAGER #2: She looks like one. &gt; &gt; BEDEMIR: Bring her forward. &gt; &gt; PEAKER: I'm not a witch. I'm not a witch! &gt; &gt; BEDEMIR: But you are dressed as one. &gt; &gt; WITCH: They dressed me up like this. &gt; &gt; CROWD: No, we didn't... no. &gt; &gt; WITCH: And this isn't my nose, it's a false one. &gt; &gt; BEDEMIR: Well? &gt; &gt; GREML1N: Well, we did do the nose. &gt; &gt; BEDEMIR: The nose? &gt; &gt; GREML1N: And the hat -- but she is a witch! &gt; &gt; CROWD: Burn her! Witch! Witch! Burn her! &gt; &gt; BEDEMIR: Did you dress her up like this? &gt; &gt; CROWD: No, no... no ... yes. Yes, yes, a bit, a bit. &gt; &gt; GREML1N: She has got a wart. &gt; &gt; BEDEMIR: What makes you think she is a witch? &gt; &gt; VILLAGER #3: Well, she turned me into a newt. &gt; &gt; BEDEMIR: A newt? -- Monty Python and the Holy Grail 
&gt; Get a grip. You're drawing wild conclusions and putting words into people's mouths. It's ridiculous. Given the original postings mention of "fast" how was a making a comparison to other languages at all relevant and not "ridiculous?" If some guy mentions in your office that he used Java because it was fast do you find it rational for someone else to run into the room shouting that C is faster? No, you don't because it doesn't make any sense. It's totally irrelevant. Do you have discussions like this at work? Is that productive? Does anything come from it? &gt; putting words into people's mouths That's what you're doing right now with this earth-shattering paper. Where did I say that Lisp is "faster" than C? I didn't. My point is that this "quantifiable" "evidence" is extrapolated to large systems incorrectly. This is further demonstrated by the constant need to chime in about Lisp's speed relative to C even though the Lisp application was already shipped successfully. But you could have saved X megs of RAM/Y cycles! The guy said Lisp is fast. Do you think he was claiming that it was _the fastest_? No. Why did another language have to be brought into the discussion? Think about it.
Personally, I find it helpful to know that something is coming from a person who has a PhD in his or her field. I respect what it takes to get a PhD. While it's not a guarantee of quality, it's also not a guarantee that the person is a "jerk desperate for attention."
&gt; But you see, you already made a bunch of guesses and treated them as fact. Do you understand the issue? Right or wrong, it wasn't until you encountered resistance that you even bothered to research the opinions you presented as truths. You assume, assume, assume. I have taken interest in the shootout benchmark of various language implementations long ago. Its actually a popular game in #haskell. &gt; Unless "probably" was part of the "turn of phrase" that you later called it. "probably" can be used as figure of speech, to avoid making absolutist statements. &gt; I've seen those links dozens of times. Can you demonstrate how it isn't "competing favorably" in those graphs? Like, in an actual real-world scenario? Make sure to bring up an embedded machine where we don't have 1MB of RAM to spare. Because that is totally relevant. You're asking if I have a better benchmark than the shootout? No, I don't. I agree benchmarks are problematic, but they're the best we have here (unless you have better?). Please stop arguing with some strawman that's only in your head. 
The real question is - do you have a better benchmark than the shootout? Of course the time it takes to merge sort in a particular merge-sort implementation in a particular CL compiler with a particular set of optimization flags, VS. the same with GHC -- is a **very** problematic comparison. It is somewhat better due to the fact that there are many little comparisons, and yes, I agree that on the overall, the comparison isn't worth a whole lot. **But its the best we have** (unless you have a better source). If there are large slants in favor of one implementation or another, it is likely they will show up in the differences over various examples. And they do seem to show a (non-huge) slant, when compared in the shootout. 
&gt; It's dangerous because you're presenting yourself as a domain expert Actually, my "figure of speech" (using words like "probably" rather than definite ones, etc) is an attempt to **avoid** presenting myself as such. &gt; and then making things up to suit your preference. I wasn't making it up - I was using my knowledge of the shootout entries (**and yes, I knew the shootout well before I cited it for you**).
What strawman? Please consider the following. The author said: &gt; Excellent compiler, especially with declarations, enables very fast code. In what way is the following relevant? &gt; While it may compete favorably with Python or Ruby, it probably won't compete favorably with Haskell, OCaml, C, C++, C#, Java and many others. What did that do to add to the discussion or disprove his statements? What was your motivation in saying it? How does pulling up statistics on tiny programs demonstrate your point? What is your point with respect to the original statement?
&gt; The real question is - do you have a better benchmark than the shootout? No, the real question is, what was your point with regards to the remark you were responding to? &gt; Jack Harper: I have a car with handling, comfort and speed all well within the requirements I have put forth. &gt; Peaker: Yeah, your car is more comfortable and faster than a Smart Car but there is no way it could compete with a Maserati Quattroporte. Do you see how it neither reinforces, acknowledges nor discredits the original statement?
No need to assume what he is like; you can watch a video of Paul talking about what he did here: http://vimeo.com/7933728 (his part starts about 18 minutes in) I was at the talk, and I don't think "a jerk desperate for attention" is anywhere on my list of ways to describe him.
&gt; What did that do to add to the discussion or disprove his statements? Saying "very fast" code out in thin air is meaningless. "fast" is relative. &gt; What was your motivation in saying it? To show that his list of reasons is mostly gibberish (Not that I think there are no good reasons [e.g: Macros]) &gt; How does pulling up statistics on tiny programs demonstrate your point? What is your point with respect to the original statement? Showing that the statement "CL has compilers that can generate very fast code" is moot.
&gt;&gt; What did that do to add to the discussion or disprove his statements? &gt; Saying "very fast" code out in thin air is meaningless. "fast" is relative. So are you saying that it (Common Lisp) is fast, or that it is not with your statistics? &gt;&gt; What was your motivation in saying it? &gt; To show that his list of reasons is mostly gibberish (Not that I think there are no good reasons [e.g: Macros]) I don't entirely disagree. But did you demonstrate that saying CL is fast is gibberish? Why is it ok to say that Haskell is fast? Or C? Can't they all be fast? What is the cutoff? &gt; Showing that the statement "CL has compilers that can generate very fast code" is moot. How is it moot? Because fast is meaningless? Stats comparing C to Lisp don't demonstrate that. Because CL compilers don't generate fast code? Because it isn't the _fastest_? How does bringing up Python and C and OCaml show that it is moot? He just said it was fast. Why do you even need to prove that moot? If you show me some C code and I compile it with some other vendor's which gives a 50% speed up, is yours no longer fast? Given his business/(non-trivial) application (which they are talking about), Lisp is fast _enough_. That isn't a moot point.
The Shootout is indeed a game, but it does **correlate** somewhat to actual general variations of performance in various language implementations. Compare, for example, Python and other languages. The slant is big enough to be noticeable even in this "game". The shootout is actually the most comprehensive set of benchmark-vs-language matrix I've seen yet.
&gt; So are you saying that it (Common Lisp) is fast, or that it is not with your statistics? Saying whether its "fast" is meaningless. Placing it above one language and below another at least gives some meaningful range for the expected performance. I placed SBCL somewhere between Python or Ruby and Haskell. &gt; I don't entirely disagree. But did you demonstrate that saying CL is fast is gibberish? Why is it ok to say that Haskell is fast? Or C? Can't they all be fast? What is the cutoff? Did I say Haskell was fast? I think it is more meaningful to compare implementations' performance than to say one is "fast" or "slow". It is relative. &gt; How is it moot? Because fast is meaningless? Stats comparing C to Lisp don't demonstrate that. Because CL compilers don't generate fast code? Because it isn't the fastest? It is moot because the word "fast" is relative, and would be more informative when compared against other implementations, instead.
&gt; It is moot because the word "fast" is relative, and would be more informative when compared against other implementations, instead. He is writing in the context of his business/application. In what way is that not clear? I guess it would be more informative if you ran off and started a competing business in another language and came back to us with the advantages afforded you by your faster language. Or, you know, you could interpret the statement in a rational way and see that what matters is that it is fast _enough_, and that OCaml being a little faster is totally irrelevant. It isn't moot. You clearly just have some emotional connection to reminding everyone which rung Lisp occupies on the speed ladder. He was letting everyone know that he didn't encounter any major language-related performance issues and fast implies that there was room to breathe. One cannot take away any more from the statement than that. He wasn't talking about it for all possible contexts. He wasn't comparing it to how other languages would perform in the same contexts. It is _absolutely_ irrelevant to his claims that OCaml would have produced a lighter, faster executable. Is that so difficult to understand?
Forth is the unabomber.. That means.. what.. it's powerful but has no rules? (edit: spelling)
web 'developers'
I love forth. I don't get it either haha.
Smalltalk being Bill Nye was the funniest IMO
Perhaps because he was a Luddite, (well, not sure if any particular group.) and i did hear some Forth people say lisp was too complicated, less too the point. Imo a valid point for Common Lisp, probably, but hardly for lisps in general. 
Developers! Developers! Developers! Developers...! I LOVE THIS COMPANY!!!!
Yeah, I can see that.. Bare metal, hates the affordances of modern languages..
Is it just me, or is the PHP one just wrong?
It's not just you. Wrong, and unoriginal too. Shame on the author.
A link from an old Reddit thread: includes [Lisp as seen by various programming language users](http://i.imgur.com/1gF1j.jpg).
That made me laugh out loud. Then again, it's late here, and I get a little goofy.
Fuck. I wish I didn't get these jokes.
I thought it was hilarious.
Actually, I didn't get most of it. I could understand the "corporate views" of Java and C#, but PHP? Also, why is CL (and cousins) in Star Trek? Is Clojure the Borg? And what's with Factor as a Jedi? Is that good or bad? Where's [joke-explainer](http://www.reddit.com/user/joke-explainer/) when you need him?
The picture from PHP is famous due to a motivational poster involving the words Special, Olympics, and retarded. CL programmers love three things. themselves, CL and Star Trek. No idea about Clojure or Factor.
[I'm sorry, I can't hear you over the sound of how awesome I am.](http://www.ackanime.com/random/1172403632074.jpg)
Factor is a Jedi if CL is Kirk because it's from another universe entirely, but is still very powerful and mysterious. Clojure is Locutus because he's a Star Trek character (lisp family) that has been "assimilated" by the JVM, which is probably considered evil due to its association with the Java language. C++ as C3P0 is pretty hilarious considering how useless he is compared to R2.
Clojure is a terrifying meld of a beloved character and an unreasoning alien onslaught.
 See me ride out of the sunset On your colored TV screen Out for all that I can get If you know what I mean Women to the left of me Women to the right Ain't got no gun got no knife Don't you start no fight (Chorus) Cos I'm P.H.P. I'm Dynamite P.H.P. And I'll win the fight P.H.P. I'm a power-load P.H.P. Watch me Explode I'm dirty, mean and mighty unclean I'm a Wanted man Public Enemy Number One Understand So lock up your daughter And lock up your wife Lock up your back door And run for your life The man is back in town So don't you mess around (Chorus) (Guitar Solo) P.H.P. oi oi oi P.H.P. oi oi oi P.H.P. oi oi oi P.H.P. oi oi oi P.H.P. I'm Dynamite (oi oi oi) P.H.P. And I'll win the fight (oi oi oi) P.H.P. I'm a power-load (oi oi oi) P.H.P. Watch me explode 
ITYM a [paedophile](http://en.wikipedia.org/wiki/Gary_Glitter) rock'n'roll star.
*Paradigms of Artificial Intelligence Programming* (frequently referred to as "PAIP") by Norvig is frequently recommended as a good text for learning Lisp, "even though it's about AI." Strangely, I can't recall specific comments regarding its utility in learning AI. (Though that's probably because I'm interested in Lisp, but not AI.) I still haven't gotten around to becoming proficient in Emacs, but people always recommend the built-in tutorial. [EmacsWiki](http://www.emacswiki.org/) also has a wealth of information. (I've always visited it via a link or a search, so I can't comment on its fitness for casual browsing.)
This was the first book I thought of. &gt; Strangely, I can't recall specific comments regarding its utility in learning AI. We're still trying to decide what AI is and is not. =p The O'Reilly text on Emacs is good for those who like to handle paper. Paul Graham's ANSI Common Lisp is another good one. For "AI," Norvig and Russell's Artificial Intelligence: A Modern Approach is a standard introductory text. It may be worth informing us what AI topic you're particularly interested in.
Steve Tanimoto wrote Elements of Artificial Intelligence Using Common Lisp: http://www.amazon.com/Elements-Artificial-Intelligence-Using-Common/dp/0716782693/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1263854423&amp;sr=8-1 I was pleased with it, but can't compare it to the PAIP. 
I have both. I think PAIP is a more solid package in terms of topics, quality of code, rate at which code is developed and the exploration of ideas (both in the current application as well as how to work in Lisp itself). That said, this book was of good quality and one wouldn't be unsatisfied at having both on their desk.
I suggest looking at Clojure (runs on JVM), especially if you have Java experience. Common Lisp (I use SBCL, which is easy to install and maintain (install packages etc.) on any UNIX box using clbuild http://common-lisp.net/project/clbuild/) "Practical Common Lisp" by Peter Seibel is an excellent general introduction to Common Lisp, while "Programming Clojure" by Stuart Sierra is a good introduction to Clojure.
Thanks for the help I downloaded a giant torrent as well containing within all the books ever written on AI, lisp I practially creamed my pants that is as the torrent poped up saying completed. I have a company to launch so I'll be setting this knowledge Aside until the weekend when I shall proscribe a overdose of lisp to combat my fear of going outside. 
why is haskell doc from bttf?
They probably used a picture of the unabomber because the inventor of Forth lives in a Cabin and blogs about that and the work he's doing on new processors. I'm split on whether it's clever or a bit mean... or both. :-)
Because they're both awesome mind-benders?
We've followed up with a [bugfix release in abcl-0.18.1](http://common-lisp.net/project/armedbear/)
I wouldn't describe this as a quote archive. It's a mostly-mechanical extraction of Erik's comp.lang.lisp Usenet signatures. If I were making a quote archive, it would be a _lot_ bigger...
That sea squirt quote is from Daniel Dennett, not Erik Naggum.
Duh. I was like "The fourth one is Michael Bolton from Office Space"
Rushed that title... Either way it saved me the same task, so thanks!
Yes, I mislabeled it as quotes when it should be signatures.
&gt;Someone in the #haskell IRC channel mentioned the “reverse state monad” explaining that it **used the state from the next computation and passed it to the previous one.** [src](http://lukepalmer.wordpress.com/2008/08/10/mindfuck-the-reverse-state-monad/)
Thanks, o supreme naggumologist. Reading these signatures makes me sad. They are so brilliant.
Why is Java the Indian guy from Office Space? Is it to do with big companies making heavy use of Java and being keen on offshoring?
Erlang LOL.
I'm still looking for a good lisp shirt.
Of course, employing before and around methods on UI components is a nice place to retrieve/modify data that the UI component needs to have, too.
 I will definitely read this all. But quick question: is this bound to Clozure CL or could SBCL be used with some hackery?
DAMNIT MAN! WHAT IS THE FIRST RULE OF USENET??
This is funny except I suspect many (maybe most?) Lispers would take issue with the implicit thumbs up for Star Trek. It's kind of the "blub" of science fiction.
Don't kid yourself, ASP/.NET is not nearly that exciting.
Laughed aloud at several. I dream of being well-thought-of enough that people comb through my emails and whatnot looking for gems ... and finding them freaking everywhere. :)
Loved the PHP one.
I've never heard of Horde3D before, thanks!
LUCKY BASTARD.
Oh, my, the interface doesn't give me claustrophobia fits on OS X any more.
Æh, please don't use "frameworks" to mean libraries. They're not the same thing.
That is just awesome. Now we need a port to the Android and iPhone and we're set!
I wonder if anyone has ported CLisp to Symbian and if there is Qt-bindings to CLisp. Nokia will have Qt in all its Symbian and Maemo devices in future. That would be huge market. 
Aye, whenever I hear someone mentioning the word framework, my hopes of seeing actual working code are devastated.
A stable and generic ARM port would be awesome. If this is a step in that direction, thats great!
Anything that runs a scrip or compiles code is strictly banned on the iPhone. Just one of apple's draconian terms that alone is enough of a reason to steer clear from the platform.
For Android, your best bet is probably some kind of debian chroot environment like [this](http://www.saurik.com/id/10) where you can build clisp and then make it run without the rest of the debian system somehow. Patches I made for Maemo will help there. As for iPhone, I think you will need something like [iphone-gcc](http://code.google.com/p/iphone-gcc/) and a lot of commitment to make CLISP work. Probably you're better off using ECL there, see [this blog post](http://lambdajive.wordpress.com/2009/03/27/common-lisp-on-iphone-ecl-comes-through-at-last/).
It would be nice, but it will take a LOT of work. After all, Maemo is just another Linux distribution, and iPhone at least runs a flavor Unix, while Symbian is something completely alien.
&gt; If this is a step in that direction, thats great! I hope so...
[P.I.P.S. Is POSIX on Symbian](http://en.wikipedia.org/wiki/P.I.P.S._Is_POSIX_on_Symbian). I wonder if CLisp uses signals because they are not available. 
It does trap SIGSEGV at the very least in libsigsegv. Without this, CLISP is rather handicapped.
Just because you can make it work doesn't mean you'll be able to use it.
http://common-lisp.net/project/commonqt/ Porting clisp to symbian should not be impossible, but would be quite a bit of work methinks.
clisp runs fine on all ARM systems; ISTR the only issue being that the FFI doesn't work because of broken ARM support in ffcall (something about the generated assembly not being correct for modern ARM with cache), but that appears to have been fixed now if cl-gtk2 was working.
http://en.wikipedia.org/wiki/Jailbreak_(iPhone_OS) &gt; Jailbreaking is a process that allows iPhone and iPod Touch users to run any code on their devices, as opposed to only that code authorised by Apple. Once jailbroken, iPhone users are able to download many applications previously unavailable through the App Store via unofficial installers such as Cydia; Rock App; Icy; and Installer, as well as illegal pirated apps. 
Not too fine. See [my post to clisp-devel](http://thread.gmane.org/gmane.lisp.clisp.devel/21214). Among other things, assembly code in ariarm.d which is used by default employs outdated APCS-26 calling convention, which may cause accidental data endianness switch on ARMv6+.
Yes. But I'd rather develop apps I can sell. Also, I would just be deeply offended if a device *I bought* was locked out so I couldn't do whatever the fuck I wanted with it. I guess that's why I'm in the n900 reddit.
Why use SINGLE-FLOATs instead of DOUBLE-FLOATs? Just because they're immediate types on a 64 bit SBCL?
A couple points: * You forgot to mention what platform you did these experiments on. It makes a difference (your example will cons more on x86 than on x86-64, for instance). * Use DEFCONSTANT. It'll make the final multiplication in DISTANCE go faster. * As a matter of style, using DECLARE is preferred to using THE. Especially when you use THE in unnecessary places (the compiler already knows that the difference of two SINGLE-FLOATs is a SINGLE-FLOAT, for instance). * You should explicitly make your floats in TEST to be SINGLE-FLOATs by suffixing them with f0; otherwise, compiling your example will run into problems if \*READ-DEFAULT-FLOAT-FORMAT* is set differently than you expect.
I should have mentioned I'm running x86-64. Good point about defconstant - I guess I just wasn't thinking. I wasn't aware of the last 2 points, but I'll be sure to keep them in mind for the future, so thanks!
Interesting article, but is great circle distance even really needed for something like this? It seems like, for small distances, just treating longitude/latitude as points on a flat Cartesian space would give a decent approximation for the distance. Do people really go halfway around the world for a deal?
Also...please don't use (SAFETY 0). Your example doesn't really need safety turned entirely off. The only places where it matters are in the call to SQRT--the compiler won't inline SQRT unless the argument range is suitably restricted, and that can be solved with a more expressive (THE (SINGLE-FLOAT 0.0f0 *) ...)--and ASIN, which suffers from a similar problem. Fortunately, that's solvable too with the same sort of solution. Oh, and making DEGREE-TO-RADIAN inline would probably help a bit, too.
I've driven to Delaware to avoid sales tax. Does that count?