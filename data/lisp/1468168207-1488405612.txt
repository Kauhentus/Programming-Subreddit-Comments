For sure, it all depend what we mean by "functional". I was taking it in the general sense of it. Now, we can always redefine what it means. Anyway, beyond the names we put on concepts, the programming style encouraged by Lisp is different than the one encouraged by Perl. However, as they are both general purpose languages, you could program in Perl like in Lisp and in Lisp like in Perl. This is painfull, but possible. You can take a car, put wings on it and call it "space shuttle". For sure, you can. 
&gt; Straw man. Where exactly does it mention SET, SETQ? LISP I manual, which describes the implementation. 1960. Page 51. http://history.siam.org/sup/Fox_1960_LISP.pdf &gt; A steady hand and a magnetised needle make all bits mutable. Not a great way to ignore my arguments. &gt; To ignore Scheme, Clojure, and McCarthy's original lisp. You might want to read the Scheme R7RS, the parts where Clojure uses Java's object system, the actual LISP I implementation. &gt; CL is amazingly practical, and I've programmed in it for over a decade, but it's not very good. That surprises me, since you don't seem to be familiar with actual Lisp programming practices. &gt; That lisps that came after CL have not followed CLOS's example is evidence that the lisp-programming community views it as a mistake. Many Lisp's after CL actually implemented CLOS. Racket has a CLOS implementation, for example. There are some Scheme implementations which make heavy use of CLOS. The Dylan, Eulisp, Emacs Lisp, various Schemes, and various other languages have CLOS implementations. &gt; Only for very small values of "heavily". Not true. Implementing '+' for vectors in standard Lisp would be a design mistake. &gt; you have a few big objects, and that means much less work for the memory manager. Yeah sure. 
| Lisp can be used for any problem. Well, any problem that can be modelled can be programmed using an application programming language that has suitable libraries. Millions of different problems can be solved using Java or Blub. Sometimes it would be great to have Lisp but I have not been wishing for it yet.
Where do you think libraries come from?
Source-code-in-database is used for years in APL, see Dyalog APL workspaces or GNU APL workspaces.
I used VisualAge for Java, both in beta and released form, as well as VisualAge for Smalltalk before that. I am pretty sure that VisualAge for Java was written *in* VisualAge for Smalltalk, and I think I remember having reason to believe that it even compiled the Java to Smalltalk to execute (my hazy memory is that this belief was formed from seeing certain content in stack-frames when debugging IDE crashes). Other than being able to speed up startup times by just loading a saved image after a reboot (rather than having to reload &amp; thus recompile a sizeable system), I can't think of anything in particular that having an image file *saved* really enhanced productivity, unless you want to count being able to save the image containing a live instance of an elusive bug, in order to be able to reproduce it at will. Having the ability to write specialized snippets of code that could find and examine all instances of a class in the image in combination with some digging into the structure of their classes and perhaps also interacting with the version control system to look at previous versions of the definitions of methods or classes, all whilst you have a bug waiting in a debugger, was really helpful. That isn't specifically a feature of it being image-based though (I think). I will say that with IBM VisualAge Java and Smalltalk, the version control system they used (ENVY) was the best I've ever used. It handled *each* method on *each* class in *each* package separately - none of this business of having class-level files containing the class and all methods, then having to look at diffs of that file that are affected by rearranging the methods. You could see *every* version of a method you'd made locally, and easily switch between them.
https://github.com/quicklisp/quicklisp-projects/tree/master/projects each directory contains files that point to repositories. Many are good, and many help (though whether do depends on the needs of the viewer) As a side note many of your questions here are very broad and could benefit from a bit more research before posting. Maybe you could refine your question into something that is more answerable.
From the user point of view it is the following: you run the interpreter, create variables, add functions. You can call an editor to create a function or you can type it in REPL. Later you can call an editor to edit the function again. If I remember correctly you can do it with the **)ed** command: )ed myfunc In Dyalog APL you can just double-click on any function or variable in the interpreter/editor and get its value or source code, do modifications, close the window and the changes will be applied instantly. Later you can save workspace with the **)save** command, exit the interpreter, run it again and load with the **)load** command. You can import functions or variables from different workspaces to your current workspace, either as modifiable or as read-only. You can also define a function which will be called when you load the workspace, to set the initial data or just dump the information about workspace contents to the REPL. Disadvantages are obivious: hard to support versioning. Advantages are in contrast to REPL in modern CL systems you can access the source code of all functions regardless if they are defined in the editor or in REPL, and the source code will still have all your comments etc since it is fully stored in the workspace. You can also query for the list of functions or variables in the current workspace. Dyalog APL supports serialization of workspaces to simple source files (SALT), but I haven't tried it. More on workspaces you can read here http://dyalog.com/uploads/documents/MasteringDyalogAPL.pdf Dyalog APL is free for the personal use from this July actually, so you can download and play with it.
If you want to work on some projects written in Common Lisp I'd suggest improving the portability of some wide-spread dependencies (for instance ACL-compat). cl-test-grid has nice reports regarding the dependency structure of the libraries. Also there is ongoing work to bring up to shape the McCLIM (native GUI toolkit for Common Lisp applications), more people would be very good thing. There are many other projects worth joining of course. If you want to work on the implementations, I'll leave a plug here – join the ECL crew :-)
The ecl developer is doing work to get ecl to compile on android, they already have working demos but it's still in early development by my understanding. C knowledge might be useful there. You can get more info in irc #lisp @ freenode cl-autowrap generates bindings to c libraries. It uses c2ffi tool which generates sexp or json from c headers. I made small program that generated inlined C++ for ecl from the c2ffi json output. It's not really useful because in the json there is no info if class field is public or private so it wouldn't compile because the program would generate getters and setters to private fields. Not sure if it would be useful to anyone but cl-autowrap could be extended to produce cl bindings by inlined C for ecl. You could try to think what people want to program and why they will choose language other than lisp for it. You might get some ideas by looking at what people are doing with the newer languages like Go and Clojure. 
ah, the pragmatic and the idealistic, the two facets of every programmer
I'm a big fan of iterate, but I won't start a war about it. New things bring the opportunity for better things. I will mention something that, as far as I know, neither `loop` or `iterate` can do, even with the extension facilities available. Perhaps the author of `for` can make it possible with it. For example, one can do (loop for i in '(1 2 3) collect i) ;;=&gt; (1 2 3) to iterate over a list, but there isn't a way to loop over a list *and then* another one. One can only loop over them simultaneously. What I would like to be able to do is (loop for i in '(1 2 3) then '(4 5 6) collect i) ;;=&gt; (1 2 3 4 5 6) or something equivalent without having to modify either of the original lists (or vectors etc.) or create a new one.
An interesting suggestion. I'll have to think about a way to incorporate that without having to sacrifice too much speed or generality for it.
There are quite a few things one can do. JSCL has page listing [projects](https://github.com/davazp/jscl/wiki/Medium-size-Projects). Ditto for [SBCL](http://www.sbcl.org/gsoc2014/ideas/). The CL webkit project wants to generate the [bindings from the GIR files.](https://github.com/joachifm/cl-webkit/issues/33) What is your area of interest? 
That's possible with a nested ITERATE.
No, you can collect from an inner ITERATE into an outer ITERATE. That's a feature LOOP doesn't have.
 FOO 4 &gt; (iterate outer (for i first '(1 2 3) then '(4 5 6)) (repeat 2) (iterate (for j in i) (in outer (collect j)))) (1 2 3 4 5 6) More generally I would write: FOO 12 &gt; (iterate outer (for list in (list '(1 2 3) '(4 5 6) '(7 8 9))) (iterate (for e in list) (in outer (collect e)))) (1 2 3 4 5 6 7 8 9) LOOP can't do that. 
[Bill](https://s-media-cache-ak0.pinimg.com/236x/e7/a9/24/e7a92409397308b249b74f55da002d07.jpg), is it you?
Perhaps I am totally missing the point here, and I don't really use iterate, but isn't what you want very similar to this loop: (loop for l in '((1 2 3) (4 5 6)) append (loop for e in l collect (* e e))) in this case I am squaring each number just to do something different with it than just plain collect. as I said I might be completely missing the point but it was the first thing I thought when I saw this. Edig: Fixing the format.
Yes, it is similar. One difference: it uses APPEND in the outer LOOP. The sub-loops create lists. All but the last list will be copied again by the outer LOOP. Usually that's not much a problem, but large lists and/or repeated execution may create a lot of garbage. 
That's something Series can do, isn't it? EDIT: Yes, that's what the CATENATE function does. (iterate ((i (catenate #Z(B C) #Z() #Z(D)))) (print i))
but isn't the loop itself creating a new list? kinda non-sense to me...
So his reply was very similar to mine, I did not notice it before, I do not know if he posted before me, I think something like: (loop with result = nil for list in '((1 2 3) (4 5 6)) do (loop for e in list do (setf result (cons e result))) finally (return (reverse result))) would create less intermediate lists, but is very ugly.
The ITERATE version I posted does not do extra consing.
If it helps anyhow, it *is* possible to clone the image without killing it - it utilizes making a fork syscall, calling SAVE-LISP-AND-DIE on the fork to produce a hard drive image, somehow upgrading that and only then changing the firewall rules. But this has a lot of problems of its own, including the fact that Lisp programs should not use image dumping as any actual persistence solution. You could just as well boot up a brand new Lisp image from the new/updated version, load up your data and make the switch at that time.
The wisdom so far in the other answers is sound - you can patch many things outside the fundamental implementation but the further you go in patching, the higher the risk of unexpected behaviour creeping in. The application I work on once had difficulties on a customer's site, but it had had many patches applied, rather than upgrade to a newer stable version. The problems could not be reproduced to be debugged and in the end we lost that customer. Though I say "we", it was before my time. The real answer if a service can't tolerate downtime, is to make it distributed so individual nodes can be brought down and upgraded. Keep in mind that accidentally distributed systems are the worst, so its something that requires solid design.
Since the herald is right there, I left clicked EMB-HOST, then middle clicked that output, then edit the INTERNET field. But programmatically is probably more important for patching?
Thank you, this is very useful.
Thank you, this makes a lot of sense, one wonders at the flexibility that Lisp affords.
&gt; APPEND Which is why you use nconc instead of append [edit] Misread original example. Here's how I'd do it: (loop for list in (list '(1 2 3) '(4 5 6)) nconc (loop for item in list collect item))
The code still traverses all lists returned by the inner LOOP to find the last cons. The inner LOOP builds them up and the outer LOOP has again to traverse them (all but the last list). NCONC avoids the consing, but still needs to traverse. This can be avoided.
Why is it written in python?
"A subreddit for the Lisp family of programming languages"
Because I'm crap at lisp, hence the need for a linter. And because I wanted to write it in python :D
That page is *very* helpful. I hope eudoxia.me will soon make an update, for 2016! PS: The original link is not valid anymore. It is at http://eudoxia.me/article/common-lisp-sotu-2015
The only thing I would (very slightly) disagree with is in GUI: the focus should be more on `cl-cffi-gtk` than on CommonQt/Qtools (very fine tools by themselves, thanks to Shinmera). And the reason is stated there: dependence on Smoke and, as a result, very limited set of Qt-widgets is available.
Well it's definitely not about macros, given that macros suck and fexprs are much more expressive. (flame-shield-up)
I disagree honestly. A lot of it is backwards incompatibility. I would much rather that mutating functions ended with `!` than started with `n`, for example. Predicates should end with `?`, not `p`. Simple consistency would go a long way.
Shinmera, are you watching this thread? I have couple of projects that depends on a fixed version of the dependent C libraries, can you do that also for Qtools? Making ASDF operation download and build the binary locally.
His code example is written in such an odd style that it's hard to read. I feel compelled to rewrite it. Using Common Lisp because I have no idea what Outlet Lisp is: (defun transform-source (filename) "Reads Scheme code from FILENAME, transforming a DEFINE form into a LAMBDA form." (with-open-file (in filename) (let* ((whole-form (read in)) (without-define (cdr whole-form)) (name+args (car without-define)) (body (cdr without-define))) (assert (eq (car whole-form) 'define)) `(lambda ,(cdr name+args) ,@body)))) 
I expressed myself incorrectly. It is not that weird functions names are needed for cohesion, but that there is cohesion in their weirdness. That is why most of the libraries keep up with the customs. Another custom I would prefer is to use -&gt; instead of - for conversion functions (char-int, char-code, code-char, etc) 
Last time I checked GTK didn't run so hot on platforms other than Linux which is a major reason for not wanting to use it. I also don't quite understand how the entirety of the Qt system is a "very limited set of widgets". That's understating the size of Qt by quite a bit.
Thank you for that. Could one use `fdefinition`, at least for his own code?
I might be wrong (if so, please point me to the right direction), but Smoke creates the layer to use standard set of Qt-widgets, so the "third-party" widgets like Qwt (http://qwt.sourceforge.net/class_qwt_plot.html) are not available directly. The benefit of GTK is that it is C-only, CFFI interface is much simpler. (But yes, GTK doesn't have Qwt either...)
~~Yes, Smoke by default only includes Qt itself.~~ I was more trying to say that what Qt offers is already a huge set of widgets. I could look into writing a guide to use Smoke for additional libraries, but with a CommonQt rewrite without Smoke lurking somewhere close by I'm not sure if I want to exert the effort to do that. Edit: According to the [Smoke homepage](https://techbase.kde.org/Languages/Smoke) QWT and other such things are actually supported and wrappers for them will be built if possible on your local system. Edit2: The standard qt-libs does not ship the Qwt bindings in its precompiled packages, which I will rectify. It does however include bindings for QtUiTools, QtWebkit, Qtscript, Qscintilla, and Phonon.
Interpreters suck.
Thanks! If QWT is supported from CommonQT/qt-libs this will cover like 90% of all GUI needs for me.
Wouldn't it be like.. 10000x easier to write a parser for scheme in scheme? 
I was thinking the other day that just baking this into the Lisp syntax might be the right way to go. Normally I'd not want to do that, but this seemed like a nice thing to have. e.g. (define! x [[(- b) + (+/- (sqrt [[b * b] + [4 * [a * c]]]))] / [2 * a]]) Then I realised that was ugly compared to (defun! qsolve (a b c) (div (+ (- b) (+/- (sqrt (+ (* b b) (* 4 a c))))) (* 2 a))) Of course, it's all ugly compared to this: (define! sqrt-discr (a b c) (sqrt (+ (* b b) (* 4 a c)))) (define! qsolve (a b c) (div (- (+/- (sqrt-discr a b c)) b) (* 2 a))) The actual solution, of course, is to compose the final equation from parts. Maybe even: (define! qsolve (a b c) (let ((discr (+ (* b b) (* 4 a c))) (sqrts (+/- (sqrt discr))) (numer (- sqrts b)) (denom (* 2 a))) (/ numer denom)))
&gt; interpreters are not interesting at all Gee, I find them very interesting.
Through the #. reader macro, *read* can call *eval*. See [\*reader-eval\*](http://www.lispworks.com/documentation/HyperSpec/Body/v_rd_eva.htm) to disable. *read* is also susceptible to memory attacks as #A can create arrays, #( creates vectors and *read* automatically interns symbols. (read-from-string "#99999999(1)") will exhaust the heap. edit: as for you second question. Read cannot define anything (except through eval). Even #S structure reader macro requires that the structure already is defined.
&gt;I don't see how it'd be any easier, it's all just text? Because it's not just text. It's structured text. With Lisp you can just use `read`, you don't have to parse all the s-expression syntax yourself. 
Everything is interpreted. Computers interpret microcode. Symbolics machines for example had hardware-based lisp-interpreter. - Eventually we compile directly into new hardware. This is what human-DNA-code compiler does.
&gt; (read-from-string "#99999999(1)") Thanks, interesting. When I tried that snippet in sbcl, I got: Heap exhausted during garbage collection: 32 bytes available, 48 requested. Gen StaPg UbSta LaSta LUbSt Boxed Unboxed LB LUB !move Alloc Waste Trig WP GCs Mem-age 0: 29497 0 0 0 3285 0 0 0 2 107538000 104880 64541226 0 1 0.0000 1: 32767 0 0 0 3492 41 24415 0 24425 915454752 345312 819050682 209 1 1.7660 2: 0 0 0 0 0 0 0 0 0 0 0 2000000 0 0 0.0000 3: 0 0 0 0 0 0 0 0 0 0 0 2000000 0 0 0.0000 4: 0 0 0 0 0 0 0 0 0 0 0 2000000 0 0 0.0000 5: 0 0 0 0 0 0 0 0 0 0 0 2000000 0 0 0.0000 6: 0 0 0 0 1306 229 0 0 0 50298880 0 2000000 1225 0 0.0000 Total bytes allocated = 1073291632 Dynamic-space-size bytes = 1073741824 GC control variables: *GC-INHIBIT* = true *GC-PENDING* = true *STOP-FOR-GC-PENDING* = false fatal error encountered in SBCL pid 5098(tid 140735112872704): Heap exhausted, game over. Welcome to LDB, a low-level debugger for the Lisp runtime environment. ldb&gt; If I try on `ccl64` (Clozure), it just runs on and on. I wonder why?
It's true. More I use lisp, more I find the prefix notation "natural" as compared to the infix notation. One argument I've heard in favor of infix notation is that it's easier to directly write formulas into your code from pen &amp; paper. Also, a lot of people haven't gotten used to it yet because they come from other languages or pen + paper + math class
Interesting, I'll hold onto that knowledge just in case, thanks for the tip!
It wasn't but it is now under Useful Lisp Resources.
We no longer have Lisp Machines, but we do have JavaScript machines. :-/
Interesting that you got so many downvotes while another comment saying "interpreters are not interesting at all" didn't.
CCL overcommits memory: http://ccl.clozure.com/docs/ccl.html#heap-growth
The only possible advantage to compilers is performance, while everything else compilers offer is inferior to what interpreters can do.
I just read your interesting article. About thes Lisp/Scheme implementation I guess that you are aware of some JS implementations following the Peter Norvig's [lispy](http://norvig.com/lispy.html). This is my own implementation in JS: [lambdalisp](http://epsilonwiki.free.fr/lambdaway/index.php?view=lambdalisp). I wrote too an "iconoclastic" Lisp/Scheme dialect built exclusively on regexps which is extremely small and works fine in a wiki context: [lambdaway](http://epsilonwiki.free.fr/lambdaway/). I wonder what you could think of such an approach and if regexps are efficiently implemented in a Microcontroller. Best regards Alain Marty
Thank you, I missed that whole-in-one CCL manual, very useful. It seems CCL has some features that make it more fitting than SBCL, at least for some use. I love the diversity of Common Lisp ecosytem.
You're incompetent. Compilers are simple and easy to verify. Compilers can be split into any number of isolated steps. Interpreters are always twisted and convoluted. They should not exist.
`some-script.lisp`: (defun foo (a b) ...) (defparameter bar ...) In the REPL: CL-USER&gt; (load "some-script.lisp") Or from the command line (this is for SBCL, Clozure CL will be similar): $ sbcl --load some-script.lisp
Thank you sooo much. This program has been killing me and I'm so stressed out. I really appreciate this. By the way do you have any recommendations on a good book to learn LISP?
In fact, you can not only store the source code for your functions, but also store the program, or more correctly, program image itself (see `SAVE-LISP-AND-DIE` or similar). And then you can restart the program from the point where you left it.
To be anally precise, that cute clojure trick is not really analogous to defining functions on keywords in CL. It's a hardcoded behavior of clojure keyword objects when used as functions by themselves; no function-binding lookup involved.
I'm going to have to guess how you have defined your class as you didnt say: (defclass book () ((title :initarg :title :initform "no-name") (author :initarg :author :initform "no-name"))) And now we tell lisp how to print the object (defmethod print-object ((obj book) stream) (with-slots (title author) obj (format stream "#&lt;BOOK ~a by ~a&gt;" title author))) You can think of `print-object` as somthing akin to `toString` One very important thing to grasp is that in CL methods don't live inside classes. Instead we define generic functions that specialize on the classes. This means that you can always add new functionality to existing types, without the need for mechanisms like `C#`'s `Extension Methods` Classes have slots (similar to fields) with you can access with `(slot-value myBook 'title)` or using `with-slots` like I showed above. You could also define the `book` class as: (defclass book () ((title :initarg :title :initform "no-name" :accessor title) (author :initarg :author :initform "no-name" :accessor author))) Which will automatically make generic functions for getting and setting the slots. &gt; (defparameter *someBook* (make-instance 'book :title "jim's quest" :author "jim")) *SOMEBOOK* &gt; (print *somebook*) #&lt;BOOK jim's quest by jim&gt; #&lt;BOOK jim's quest by jim&gt; &gt; (title *somebook*) "jim's quest" &gt; (setf (title *somebook*) "jim's epic") "jim's epic" &gt; CL-USER&gt; (title *somebook*) "jim's epic" Hope this helps you get started
Kudos to you for making a new Lisp idea work! Also, it's wonderful to read such a thorough and practical writeup. You could probably eliminate all tail calls by reusing the current stack frame when making a call where .tail would be true in the calling frame. This could be done with throw-catch like now, or by explicit cooperation of eval and function call machinery.
What are the most important purposes (unrelated to performances) that could be satisfied by compiler and not interpreter?
Simplicity, modularity, verifiabilty, maintainability. 
I had not seen that article, and I normally read everything you post since a while back. Do you continue to use these types of utilities?, I had not thought about doing this but seems like a good place to set up some of those "I whish i could ____ from the repl".
``` (defmacro :3 (name) `(eval-when (:compile-toplevel :load-toplevel :execute) (ql:quickload ,name) (in-package ,name))) ``` This is the only case where I use a keyword as a function. It's in my Lisp's RC file. It has the advantage of being available in every package, since it's a keyword.
If you're new to programming, Common Lisp - A Gentle Introduction To Symbollic Computation by D. Touretzky. If you're not-so-new to programming, Practical Common Lisp by P. Seibel.
Mayhaps - but for the limited uses of mine, it works.
Thanks for the comment! Good note on eliminating all tail calls, I'll definitely implement that.
A class just contains data you can access and doesn't encode any computations, unlike a function. Following SICP and other books, you can use lexical closures to mimic objects and their constructors, but it's not so useful in practice, and generally encourages a message-passing paradigm (which you can hide by way of additional named functions).
A function is basically a transformation - something that takes zero or more arguments, does something with them, optionally does some side effects and returns zero or more values. A class is a data structure.
&gt; [Edit]: I figured out that I'm supposed to call it as (get-genre "Fantasy") but now it's printing our nonstop and I have no clue on how to fix that :/ [`(loop)`](http://www.lispworks.com/documentation/lw51/CLHS/Body/m_loop.htm) loops.
&gt; wouldn't start as interpreters Python started as a bytecode compiler straight away. Same with Lua. And Javascript was designed to be awful anyway. Modularity is a gigantic advantage that you cannot dismiss. It means that complexity is controlled - each module is as simple as you want to keep it. And back to simplicity, it is a result of modularity. Compilers are so simple exactly because of their modular pipeline nature. Interpreters cannot ever achieve the same level of simplicity.
It's left unspecified. [According to the Hyperspec](http://www.lispworks.com/documentation/HyperSpec/Body/t_symbol.htm) &gt; The name of a symbol is a string used to identify the symbol. Every symbol has a name, and the consequences are undefined if that name is altered. 
Good point! 
https://www.reddit.com/r/lisp/comments/4lxi3c/gavinostyle_trolls_and_your_reaction_to_them/
Would be good to add to the README, too.
Hyperspec wins again!! You can tell that people really understood the spec and cared about getting it right.
Related, a cucumber clone, [clucumber](https://github.com/antifuchs/clucumber). Although the [example](https://github.com/antifuchs/cl-beanstalk/blob/master/features/job_injection.feature) is not as lispy as lspec
This looks great! I currently use fukamachis prove for testing and I'd love to have this syntax instead of plan/finalize and subtest from that!
Neato. Never seen a ruby test framework being used for lisp. I respect cucumber as a tool and think it can be beneficial to get non technical stake holders involved but as a lone developer I find it adds yet another layer of indirection and more code to maintain. And now rspec does scenarios I really do have no need for it.
*Here's the Urban Dictionary definition of* [***lolcow***](http://www.urbandictionary.com/define.php?term=lolcow) : --- &gt;(From ED) A lol-cow is a victim of a Flame War who can't help but be milked for lulz time and time again. They have a compulsive need to give up as many laughs as possible at their own expense despite themselves. --- _George W Bush is such a lolcow._ --- [^(about)](http://www.reddit.com/r/autourbanbot/wiki/index) ^| [^(flag for glitch)](http://www.reddit.com/message/compose?to=/r/autourbanbot&amp;subject=bot%20glitch&amp;message=%0Acontext:https://www.reddit.com/r/lisp/comments/4tpm38/difference_between_a_class_and_function/d5k2e5f) ^| ^(**Summon**: urbanbot, what is something?)
/u/muuh-gnu - let me answer your comment that I post below. Since I've already written an answer, I don't want it to go to waste. You wrote: ~~-----------------------------------~~ &gt; Perhaps it will help someone else in the future. Perhaps your feeding of the trolls will make other users go away, so any real new user that tries to connect to the community will only encounter trolls and sad lolcows, like they do when they first time read c.l.l. Everybody knows what feeding the trolls did to c.l.l., why is everybody so eager to repeat that sad part of history? &gt; please read xyz as well. The fact that you dont recognize something, does not mean that it isnt there. You just have to look harder, or be willing to look at all. &gt; I don't care whether it's a troll or not a troll or half a troll or anything. If the trolling rate is not once per month, but once per day, then youre drowning the sub in noise, and any rational person will go away, shaking their head. The more you feed them, the more they troll, like compounding interest, it gets out of hand exponentially. You absolutely should care if your feeding of the trolls contributes to increasing the amount of trolling. And it does. And no matter how honest your answers, honest well-intentioned noise ist still noise, and youre helping them drowning the sub in it. ~~-----------------------------------~~ &gt; Everybody knows what feeding the trolls did to c.l.l. The difference here is that CLL is a newsgroup. It's not moderated by any means and therefore bound to end up being a cesspool once someone decides to flood it with nonsense. &gt; The fact that you dont recognize something, does not mean that it isnt there. You just have to look harder, or be willing to look at all. Yes, I'm looking - and I see newbie questions and not trolling attempts. It's one of the parts that make Lisp community actually fun, as I see on #lisp when people occasionally compare that IRC channel to some of the other channels that actually give the vibe of elitism, RTFM and absolute non-friendliness to newbies. I say a different thing. I'm here to answers questions that are posted to the best of my extent. Since there's a moderator around here, if they think things are getting out of hand, they can be kind enough to move such a topic over to /r/learnlisp or, if they don't have the possibility to do such, delete the topic and ask the author to post the same question on the other subreddit. And if you think that things are getting out of hand, then you can, anonymously if you'd like, contact them and state your concerns. &gt; If the trolling rate is not once per month, but once per day, then youre drowning the sub in noise, and any rational person will go away, shaking their head. With the amount of traffic this sub is getting, I honestly don't know whether /r/learnlisp is really justified. And with the amount of traffic this sub is getting, I'd rather answer any questions that are asked than kick the asking person out. And about your point, honestly, I wish the main page of /r/lisp had a new post once per day. After considering your statement, I don't think that I'm not helping "them", whoever "they" are, drown the sub in trolling. And I will continue doing this for the reasons stated above while remaining open to discussion.
It is back again. It seems that github decided, that davazp isn't a real user and blocked his account. According to twitter he plans to move somewhere else than GitHub.
When I began using lisp-likes I would have agreed about the ! and ? suffixes (I started with Racket), but in CL -p is preferable to me because I can pronounce it. I'm not so sure about the n prefix though.
this binding for *libui* seem interesting https://github.com/jinwoo/cl-ui
I would second gitlab as a good choice. I've been in the process of slowly migrating. The added bonus is that it's all open sourced.
? But you can't solve the Halting Problem for Pascal in Pascal.
Writing a compiler is not equivalent to solving a halting problem. 
&gt; no macros use NLAMBDA concept instead I'm guessing nlambda means destructive lambda, which could mean a lambda that is able to modify its own source, and/or accepts arguments unevaluated - so a fexpr. If so I've not seen them referred to by that name before.
It also has the benefit of being easy to contribute to. The cl-cookbook has some examples that are out of date or terser than they could be. 
Just saw this little snippet from /r/common_lisp [Craig Lanning starts working on a fork of Franz Inc.'s CLIM 2 implementation, to support Clozure CL](https://www.reddit.com/r/Common_Lisp/comments/4ukhvw/craig_lanning_starts_working_on_a_fork_of_franz/)
This does sound like something AutoCAD specific! /r/autocad might be able to help better. I absolutely don't know AutoLISP and AutoCAD-specific commands and might not be able to help. I only managed to restructure the code layout a little bit, http://paste.lisp.org/display/321584 - I hope it helps someone else who has more knowledge about AutoLISP-specific features.
I haven't really looked at Mac at all, need to investigate the dependencies and all. Will do this :-) 
Awesome, thanks! 
I suspect no good guide will be gentler. It's like with C++ templates (which bear a strong resemblance to hash-consed Lisp macros). You have to be necessary doing something hard before it makes sense. 
Good work, this looks really cool.
When the Racket docs had me ready to run for the hills this article gave me hope. 
Thanks man, yeah I'll be more careful with that in future
Can you ELI5 how explicit regions work?
I'm sure this is a loaded question... how do you know if a value is truly "intermediate"? 
Immutability! A value can't escape to some place else via destructive operations.
Its there on the second page. And yes, completely agree on it being an amazing book.
Thanks for the suggestion. I couldn't agree more that we need a way to display the most relevant results to any given user - one measure of which is the intended audience for a resource. This either requires domain knowledge or some form of machine learning to figure out a user's preference for some difficulty level based on, say, the browsing pattern. We are working on it :)
is bone agnostic towards multithreading or will it take a specific approach (threads, csp, actor)?
Sorry about that. I had jquery blocked so there was no indication of a second page.
closures don't muck that up? for example when you return a closure from a function that had a region allocated for it, you would want some of the values that were allocated in the region to remain, in addition to the closure itself. maybe you copy over the values that have been closed over somewhere else before clearing the region?
Yes, return values have to be copied back from the inner to the outer region. This works for closures as well.
If you want to see the source code: * Here's the [copy_back()](https://github.com/wolfgangj/bone-lisp/blob/master/bone.c#L246) function. * And here is [how we copy a closure](https://github.com/wolfgangj/bone-lisp/blob/master/bone.c#L781).
Thank you for the help, I will certainly try, I hope you will be able to post some examples somewhere, perhaps even as a gist?
&gt; How do you GC the root region as it will presumably not be exited until the end of the application? I don't. I just have to avoid generating too many objects in the root region. &gt; If you run out of memory (say 4 regions deep) do you just panic and kill the application or do you rollback to a previous region or is there a fallback GC? I segfault and fix my code to use new regions at better places.
I don't think browsing patterns or ML will help all that much. The list would Need to be curated Not too hard, but time consuming.
What's the good logo alternative these days?
Still $10 for the ebook is well worth it. 
I already own the ebook, but would handed loved to get the paperback on sale. :\
It has a couple of nifty features like a reader macro for regexps. Also the implementation doesn't appear to be [accidentally quadratic](http://accidentallyquadratic.tumblr.com/post/147713851567/regular-expression-backtracking-on-stackoverflow). Test case (let* ((len 1000000) (test (make-string len :initial-element #\Space))) (setf (char test (1- len)) #\k) (re:match-re #r/%s+$/ test))
Super bummed I missed it :/
Thanks, it looks really impressive. Any other resources for LispWorks-specific stuff?
The lisp-hug mailing list is a great resource and that's how I heard about Jeffrey's software.
&gt;you probably want PDF (which is what this is) Once bought, you can download PDF, MOBI, or ePub versions of the book.
I don't know, sorry. I hope the gmane outage is temporary.
Unfortunately it seems not temporary: https://lars.ingebrigtsen.no/2016/07/28/the-end-of-gmane/ 
Thank you, nice reminder. I enjoyed reading it.
I just find those Scheme conventions ridiculous.
Agreed.
I find not using them ridiculous. They're a meagre approximation of a type system, which is quite nice. There's a difference between `list` and `list?`. 
I was wondering who thought this post would go down well in this subreddit, clicked on `tvganesh` to see the profile but got 'page not found', looked at gigadom 'who am i' and saw &gt; Tinniam V Ganesh Oh.. :)
@lispm, @dashkb, @mobius-eng,@Baggers. Thanks a lot for your detailed comments. I now realize that binary trees in Lisp are extremely trivial. However at the time I wrote this, I found it extremely difficult. More so because I come from the traditional procedural-based background of C. I am getting better at functional programming of late, and hope to write some decent sized lisp program in future, at which time I will clean up this code, fix the naming and also properly indent. Thanks Tinniam V Ganesh
SICP explains trees. Worth a look
That was already your response a year (or more?) ago. Why not just fix your code, now?
The article is written in 2012. fin.
For what it's worth, I tried to read the entire article and code thinking it was a prefix to "this is how it should be done in lisp!", for it is hard to see why someone would make such an effort. Here is my version of B-trees in Common Lisp. https://github.com/drewc/planks/blob/master/src/btree.lisp Mine were mean to be functional, so CoW not mutation, but the main difference lies here. (defclass btree-node () ((index :initarg :index :initform (vector) :accessor btree-node-index :documentation "A vector of key/value pairs. The keys are sorted by KEY&lt;. No two keys can be the same. For leaf nodes of btrees with non-unique-keys, the value part is actually a list of values. For intermediate nodes, the value is a child node. All keys in the child node will be KEY&lt; the child node's key in the parent node.") (leaf-p :initarg :leaf-p :initform nil :accessor btree-node-leaf-p))) Looking at it, there is only one use of LIST and that is optional. So a node is an instance of a class containing a vector of conses, not a list of lists. 
i like how an intro to the galaxy's most advanced graphics toolkit has pictures of nothing but text. :|
if you like it, why do you have a sad face in the end? ;)
If you are legitimately asking, why do you have the winky face in the-Oh! =-O
agree :)) definitely lol. demonstration of the "galaxys most advanced graphics toolkit" with the picture of listener ? are you kidding me? Show examples how it could beat CAPI, Gtk, Qt, WxWidgets, MFC/WTL, FLTK to name a few
I thought it was a very nice way of seeing McCLIM being used, it was also cool to follow along (though I wish the listener had copy paste!) and just see it work. More please. Ps, I had to update McCLIM to make the png example work, and I noticed that font rendering is a lot nicer in the newest iteration!
Yeah, it's a pipe face, it means his comments output is directed into the next comments input.
&gt; CLIM is the global minimum in graphics toolkits what does that mean?
I think you must ask Gabriel, but my best guess is that it's a joke in lines of: "CLIM is better than other toolkits, and since it's a global minimum, other toolkits lack so much to be acceptable". But it's only a guess.
Note that CLIM includes a graphics layer.
Interesting -- in my current toy language project, I thought I would implement lists. I realized that since I had implemented vectors, I had enough already. A `cons` is a vector of length two. I was really satisfied with how it came out.
That's a very good idea, I had a few questions about that. I'll make such thing on McCLIM website on Monday. In shortcut short term goals: - improving stability and portability - swapping some bugs - bring closer-mop instead of keeping MOP code for each implementation in McCLIM - create more learning materials, tutorials, improve documentation Longer term goals (not set in stone): - document how to write backends - write framebuffer backend (easier to glue with any system) in par with material design principles (if possible) as a reference backend
I donated to this because the state of free GUI libraries in Lisp is sad. I really only personally consider LispWorks' CAPI to be the only reasonable choice. If there is going to be a GUI library for Lisp, might as well be the Lispiest sort of one, offering something unique compared to other libraries in other languages. I'm not bullish on the whole command-based interaction and I don't think it should be pushed hard, but making/extending CLIM to be a useful tool to build native GUIs in Lisp is most welcome.
Bill Rozas did quantum experiment descriptions in Scheme in 1987 but I didn't see his work cited in the paper. http://oai.dtic.mil/oai/oai?verb=getRecord&amp;metadataPrefix=html&amp;identifier=ADA181768
Hey :) could you elaborate on this? There were some discussions how to evolve McCLIM to support things covered in https://github.com/robert-strandh/CLIMatis, but we have no conclusive stand on this matter.
@sammymammy2 Idk what jackdaniel or robert strandh have in mind. My roadmap: 1) Quash the final showstopping error: The X server will drop the connection to CLIM and one is forced to restart the whole lisp process, which defeats the whole purpose of having incremental compilation, disassemblers, a condition system etc in the first place. Details: https://github.com/robert-strandh/McCLIM/issues/55 The ~$1k collected so far should be enough to solve this bug if our time is spent wisely. Unlike the remainder of the issues in the project, it is unclear how much effort must be spent to fix this. The problem is not in CL, thus our debuggers are invalid etc. 2) Flesh out the CLX backend and demonstrate what it means to be a reference implementation. There are 38 CLIM forms that are not yet implemented. You can view this with: (let* ((f #P"/root/quicklisp/local-projects/McCLIM/Tools/unimplemented.lisp")) (load (compile-file f)) (CLIM-USER::PRINT-UNIMPLEMENTED)) There are 10s of small bugs/irritants such as - pattern don't rotate in a `with-rotation' block - autocompletion needs to be re-worked, sometimes it leaves visual artifacts hanging about - reader macros are expanded at the listener, and this makes it a PITA to use libraries like illogical-pathnames - goatee &amp; all related code can be removed as it serves no purpose All of this is straightforwards to fix. 3) New logs for #clim that use the same code as http://btcbase.org/log/. The current implementation is acceptable for the handful of devs we currently have, but not for the many thousands of users we can expect in the future. Search functionality + speed is essential. I will be working with phf on this when he returns from burning man. 4) Non-goals: any backend apart from CLX. The previously generation of CLIM programmers wasted a lot of time and effort implementing / thinking about other backends. It amounted to ~ nothing ~. Had they instead spent their time finishing the CLX backend, we'd have a reference implementation one could use to generalize from. Completion time for the CLX backend will be measured in weeks/months. Completion time for any other backend is going to be measured in years. Put another way: "If there is going to be a GUI library for Lisp, might as well be the Lispiest sort of one, offering something unique compared to other libraries in other languages." If you want to make money with McCLIM: THE CLX IMPLEMENTATION MUST BE COMPLETED. -- Consider a future in which all of our medical &amp; other mission critical programs continue to run windows[0] and similarly opaque computing sludge. Then do yourself a favor &amp; contribute to McCLIM, a saner future for you &amp; your people. Footnotes ---------------------------------------- [0] https://www.rt.com/usa/342124-operation-hospital-virus-computer/ http://www.edn.com/design/automotive/4423428/Toyota-s-killer-firmware--Bad-design-and-its-consequences http://xahlee.info/UnixResource_dir/_/buffer_overflow.html http://www.theverge.com/2016/6/30/12072408/tesla-autopilot-car-crash-death-autonomous-model-s http://www.zerohedge.com/news/2016-04-27/german-nuclear-power-plant-confirms-it-was-infected-computer-viruses http://www.thedailybeast.com/articles/2016/03/17/military-admits-billion-dollar-war-toy-f-35-is-f-ked.html
McCLIM is doomed to obscurity even in the small CL community, as long as it's tied to XWindows. The terrible decisions regarding platform support, made years ago, have now come home to roost. If McCLIM had a fully-working OpenGL backend (cross-platform by nature) things would be a lot better now. But whoever was in charge ~10 years ago (hello beach) obviously didn't get the point. OpenGL is everywhere now, even web browsers expose it. What has McCLIM accomplished in the meantime? 
This is a terrible idea (see my other post in the other thread). CLX is *what killed McCLIM if it ever was alive* and you insist that more time is wasted on it? The applications that operated on top of proven, **cross-platform** technologies (QT, SDL, OpenGL) have flourished. The toolkits that were tied to obsolete, archaic and rotten architectures (X11) are dead. It boggles the mind that some people can be so oblivious and cutoff from consensus reality.
&gt; Is there a road map for things to come? Hey, here it is: https://common-lisp.net/project/mcclim/involve I'll create a separate reddit thread to ask for comments
Lead Applications. IMHO an UIMS needs applications which drive the thing forward and helps testing the usability of it. One should be a more traditional GUI application with menus/dialogs/windows/gadgets. One or more of: * IDE, see for example: https://github.com/heshrobe/josh-dist/tree/master/clim-env * Text Editor ( Climacs ) * simple Graphics Editor: ( I have an old commercial one for the Lisp Machine called Illustrate, but not in CLIM) * simple Presentation Editor (like Powerpoint, Keynote) Should give an idea: * how to create and ship applications * what is an application? * good looking fonts * good looking drawing * good looking dialogs, windows, menus, gadgets, scrollbars * good looking color schemes * working drag&amp;drop * usabilty (doesn't crash, doesn't lock up, doesn't stall, doesn't waste cycles on laptops, good response times, ...) Extend it to an application framework with a simple 'NULL' application. Such an application has all the basic structure with default implementations/methods/subclasses, but does nothing real. It can be started, though. * start / stop an application * default menus / toplevel * cut/copy/paste/clipboard * preference dialog * open/save/close menus + dialogs * about / help CLIM 2 also had a test suite application: https://github.com/franzinc/clim2/tree/master/test . I can't remember if McCLIM has one. 
Certainly sounds interesting (graph-db), can you recommend any good papers/videos on the subject? I absolutely agree that reactive elements do have some place in whatever the solution is, and making sure it doesn't force the architecture of the games it is used with will be a good challenge. Same for the querying, hooking into the existing datastructure rather than forcing one less optimal datastore will be interesting. Thanks for the post, looking forward to reading more.
For graph databases I like the materials in the learn section of [neo4j](https://neo4j.com/) which is a db written in java (I ignored the code and learned what it is and how to use it), they even have a [downloadable book](http://graphdatabases.com/?_ga=1.147247927.1658902202.1471303316), which I think is quite good, they of course use Neo4j but try to be general on graph databases. I know for lisp the most advanced is [AllegroGraph](http://franz.com/agraph/allegrograph/), but I think is close source and only usable on Allegro CL, they have some documentation available on their site but I have not read it. I also referenced some wiki articles in my abandoned [proto-graph](https://github.com/maufdez/ProtoGraph) project's readme.
Having searchable, citeable IRC logs is key in ensuring we do not have to constantly re-hash discussions. At least 20x now I've found myself 'click searching' the #clim logs, hating the interface and wishing it was indexed. Should have noted this in my original message.
Most likely misleading, but an snippet from the [IRC logs](http://irclog.tymoon.eu/freenode/%23clim?around=2016-06-22T09:20:16&amp;types=tonam#1466587216), since the devel mailing list appears dead: &gt;09:20:16 jackdaniel how complete is CLX-core? (in scale from not complete at all to almost working?) &gt; &gt;09:20:28 beach I have no idea. &gt; &gt;09:20:37 jackdaniel OK &gt; &gt;09:20:43 beach The organization of the CLX backend is somewhat mysterious to me. &gt; &gt;09:21:06 beach And I am saying that despite having fixed the input keycode/keysym problem recently. &gt; &gt;09:21:22 jackdaniel clx-core is a single-mirror backend written by you &gt; &gt;09:21:37 beach I never could figure out why some code was in a particular file and some other code in a different one. &gt; &gt;09:21:38 jackdaniel (according to the copyrights in the system definition) &gt; &gt;09:21:50 beach Oh. Let me have a look then. &gt; &gt;09:22:46 beach I don't think it is in a useful state. It was an attempt to re-structure the code, but I had to give up. &gt; &gt;09:23:17 jackdaniel OK, so in my scale it's the leftmost :) &gt; &gt;09:23:23 beach Yep.
Can you spell out in more detail what you mean by "happily over-engineered"?
That snippet of the logs is discussing CLX-CORE (iirc holds some implementation details for the CLX backend), rather than the backend as a whole.
What on earth...
I saw a nested array iterate driver go by on lisp paste a few days back - I guess that was you. http://paste.lisp.org/display/323053 I'm not an iterate user but this sort of thing would be yet more temptation to take it up. Are you happy with the driver?
Not having good color support in CL-CHARMS is my fault. Maybe in a couple weekends. :) I'd be happy to chat about improvements and next steps to make it more useful. 
Caveat - I'm not very familiar with CLIM, and McCLIM, but would a libui backend be of value ? https://github.com/andlabs/libui
Post mortems are always very insightful, would be nice if more devs would make time for them and other docs.
Yeah that was me. After the jam ended I went back to another project and *immediately* needed a nested iterate driver for the millionth time, so I just went down the rabbit hole and wrote it. The end result is [here](https://github.com/sjl/cl-losh/blob/master/losh.lisp#L645-L819). Basically I finally ended up with three new iterate drivers. The `for ... :cycling` driver is like normal `for` but loops around when it hits the end, e.g.: (iterate (repeat 5) (for x :cycling (print 'beep) :from 1 :downto 0 :by 0.5) (print x)) =&gt; 1 0.5 0.0 BEEP 1 0.5 That one made it easier to write the actual `for-nested` driver that I really needed: (iterate (for-nested ((x :from 0 :to 3) (y :from 0 :below 1 :by 0.4))) (print (list x y))) =&gt; (0 0) (0 0.4) (0 0.8) (1 0) (1 0.4) (1 0.8) (2 0) (2 0.4) (2 0.8) (3 0) (3 0.4) (3 0.8) I also made a `for ... in-array` driver which is the one you linked. That one comes in handy when you've already got a multidimensional array and need to iterate over its contents AND indices: (iterate (for (height x y) :in-array some-2d-heightmap-array) (draw-terrain x y height)) I'm pretty happy with them overall. It definitely cleans up some of those ugly nested loops, like the square step in the Diamond Square terrain gen: ;; before (defun ds-squares (heightmap radius spread) (iterate (for x :from radius :below +world-size+ :by (* 2 radius)) (iterate (for y :from radius :below +world-size+ :by (* 2 radius)) (ds-square heightmap x y radius spread)))) ;; after (defun ds-squares (heightmap radius spread) (iterate (for-nested ((for x :from radius :below +world-size+ :by (* 2 radius)) (for y :from radius :below +world-size+ :by (* 2 radius)))) (ds-square heightmap x y radius spread))) I'm not 100% confident my implementations are completely correct though. I basically had to reimplement the numeric looping functionality for `cycling` and I'm sure there's an edge case or two that I missed. I'd like to do more testing of them before using them for anything important.
No worries. I've used ncurses from C a little bit before so it wasn't a big deal to fall back to the raw ncurses calls. And yeah, we should chat a bit, cl-charms is pretty nice and I can see myself using it more in the future. I'm sjl on freenode, usually in #lisp and #lispgames when I'm online.
Guess who implemented a quantum compiler using SBCL that is used for all their interactions with the Quantum Computer? www.dwavesys.com/
D-Wave solves a very different problem than gate-based quantum computation. They do something called "quantum annealing", which is more or less setting up an energy landscape which is slowly "solved" to find a minimum/maximum. Hence it's typically used to solve optimization problems. It would not be a compiler in the traditional sense of the word: Converting some (generally but not always universal) program representation to another, lower level one, for execution on a machine. As I understand, they use Lisp more for the control of their machine. Maybe they have a compiler though to describe different problem instances as annealing processes. But you're right, it's true, [they use SBCL](https://dwave.wordpress.com/2011/05/20/learning-to-program-the-d-wave-one-software-you-should-install-a-book-you-should-buy/#comment-21948)!
The author is /u/cracauer.
I bought this book last sale, it's simply fantastic!
Cool. Thank you for answering the question. Can you guess - or confirm - is that a reason or even possibly *the* main reason the JVM is so memory hungry relative to its performance? Java/JVM fans like to point out that efficient Java is well within an order of magnitude of efficient C++ for speed, but the difference in memory usage is often actually an order of magnitude or worse.
Thanks! Also Practical Common Lisp is on sale too :)
LiSP has a nice part about evaluation order in the chapter about denotational semantics.
Vulkan. Go for Vulkan. Or alternatively, also for HTML5. That one would be really interesting.
&gt;I've figured out that the "genera" binary (author does not link to the source) judging by the output of tree ([here](http://pastebin.com/TjxnAe8g)) on the untarred opegenera2.tar.bz2 (under http://www.loomcom.com/genera/) that might have been used to create the genera binary, at least at first glance.
Remember to read loper-os.org in full kids!
Thank you all for support, we'll do our best to improve McCLIM and make it a viable solution for GUI in Common Lisp
Thanks again for answering my questions and comments. I hadn't thought of the JIT. Substantial memory overhead from that makes sense. I knew about the boxing of built in types, but of course at worst that gives you a 100% memory overhead, right? Your 8, 16, 32, or 64 bit types are in one 64 bit register anyway, and you have one 64 bit register for indirect. It does make sense that Java's immutable strings carry a memory cost. There are advantages to immutability, of course - I spend a lot of my time typing "final" on my Java variable declarations, because in my experience more or less a third of your Java objects that are mutable bite you by their mutability later - but you never know which third until after you have the teeth marks, so it's best to work defensively. I also wonder how much is a general design approach. In Clojure, at least, the idiomatic approach to solving problems is data structures of sets, maps (hashes in Lisp, I think), and lists, nested if necessary. You pass the data around and manipulate it. Idiomatic Java uses custom types and structures for everything, with translation between them in different portions of your code and with third party libraries. That carries potentially a lot of overhead, a Java code path might convert a Foo to a Bar to a Baz and then all of the way back while the same Lisp path might add two keys and values to a map and change two others. But that's a guess. 
what exactly does that have to do with X11 vs OpenGL? unless you're saying that OpenGL etc is built on bad abstractions. if so, how come that doesn't apply to X11 either?
I've been dabbling on a similar ncurses binding for Lisp called [croatoan](https://github.com/McParen/croatoan) for quite a while now. It is sbcl-only, but the color and attribute handling routines should be quite portable to other Lisps, although I havent checked any other implementation yet. Out of all available GUI toolkits out there, ncurses should be the easiest to get fully supported in Lisp.
do you mean that CLIM as a standard is overcomplicated, or McCLIM is too messy as for now? /sidenote: I'll wait till CAPI is portable and opensource before using it :) – but I've heard many good things about CAPI/
The reader is mostly concerned with s-expression syntax. Lisp syntax is implemented on top of s-expressions. Macros are often used to implement syntax and they have nothing to do with the reader.
The NLAMBDA is like LAMBDA only that it quotes it's arguments. Interlisp had this, but it was ugly because you had to eval and then your local parameter names could shadow yours. Instead of implementing macros, that potentially lead to large code-expansions, which are undesirable on platforms with little memory, esp-lisp implements NLAMBDA. The NLAMBDA gets a first argument which is the local environment where it's evaluated. This caputures the variable bindings outside the function. Then you just call (eval x env). lisp&gt; (define my-if (nlambda (env x th el) (if (eval x env) (eval th env) (eval el env)))) #my-if lisp&gt; (my-if 1 2 3) 2 lisp&gt; (my-if nil 2 3) 3 lisp&gt; (my-if 1 (print 2) (print 3)) 2 2 lisp&gt; (my-if nil (print 2) (print 3)) 3 3 The same mechanism is used for C FFI functions in C that implement many "special" forms. Here is a simple example that captures the lexical environment. lisp&gt; (define e (nlambda (e) e)) #e lisp&gt; (let ((x 11)(y 12)) (e)) ((y . 12) (x . 11) (nil)) 
The way callf accepts a function and arguments to apply to a place is reminiscent of the way I've seen functors, applicatives and monads described (while not being exactly any of them). 
Is there a reason you were unable to contribute to CL-CHARMS? If so, that's nominally a problem. In the spirit of the Lisp library unification effort, it would be nice to have one canonical complete library, and not 5 incomplete ones. 
Perhaps it is clearer to describe macros as performing a syntax transformation at the level of lisp forms. If syntax describes what is a valid form in the language, the crux of the matter boils down to at what level we apply the notion of validity. (1 2 3) is a valid s-expression but not a valid lisp form, because 1 does not denote a function or macro, I can't write a macro to transform it. Thus macros cannot be said to add syntax at the source/s-expression level - reader macros do that. Lisp macros add syntax at the level of lisp forms.
I played around with Mezzano when the project was discussed on Hacker News a year or two ago. Very cool and reminds me, a little, of my Lisp Machine in the 1980s. I would like to see both Mezzano development to continue to the point where SSH shells and a simple web browser would make it possible to live in the environment for longer periods of time. I have the same desire for something similar built with Pharo Smalltalk.
This is an absolute steal if you're looking to throw some great introductory books at friends and colleagues. Land of Lisp is well worth the price of entry alone, and I've also enjoyed Learn You a Haskell. Clojure for the Brave and True has some great introductory chapters - probably one of the best beginner resources for getting up and running with lisp editing in emacs (most if it is not clojure-specific) - but it rather lost me after that. Most likely still useful. I've picked it up and might prod through Realm of Racket, as I've never really played with it beyond basic scheming. Might give some of the others a browse, too!
No. It's also not the most mathematically language either (not by a long shot). It's a programming language. One with some cool tricks up it's sleeves and a syntax that you may find unfamiliar at first, but it's still a 'regular' programming language. Dive in, the parens are lovely this time of year :p [datapoint] I have no maths background at all and the only maths I do in lisp is games related so is the same as if I were doing it in c/c#/java/etc
The full quote is: "This is what I do for fun, because it is the exact opposite of the kind of thing people will pay for: an obscure implementation of a programming language everybody hates." [[source](https://github.com/JeffBezanson/femtolisp)] **EDIT**: The entire README is worth reading in full.
No. It's simpler than basic algebra.
What's so bad about Scheme?
&gt;It's also not the most mathematically language either I nominate APL
I liked "Practical Common Lisp". The chapters on macros specifically. I finally "got" why lisp syntax was so great (it makes writing powerful macros easy). Also, the book is free and available online.
Yup got that one too, I only read chapter 1 of "Land of Lisp". It's really confusing so far cause it seems like he expects me to already understand a little of what he's saying.
I like your reply better than mine is more precise and short.
Close. The large code base in question was Cedar/[Mesa](https://en.wikipedia.org/wiki/Mesa_%28programming_language%29), one of the implementation languages for Xerox D machines (the [Xerox Star](https://en.wikipedia.org/wiki/Xerox_Star) is probably the best known). The opinion was based on their experience at PARC using Mesa to implement the underpinnings for Xerox Smalltalk, Interlisp-D, and Xerox's GlobalView desktop environment. The people in question were very smart and very experienced, but their experiences were mostly in the OS implementation area, which has a very different outlook than more typical application programming. I tend to think of Stroustrup's book above as The Design *Rationalization* and Evolution *by Random Mutation* of C++.
I disagree with your analysis. Top must know that middle throws, not that middle uses low. It so happens that middle throws because low does and middle doesn't catch it, but that's an implementation detail of middle that top doesn't have to know. In fact in a language with checked exceptions this is exactly what happens, middle has to be annotated as throwing what low throws because it doesn't catch, and then top must in turn either catch the same exceptions or also have an annotation. In either case though top is only looking at the functions it directly calls.
It seems to be in fashion now to be of the opinion that even *exceptions* are to be avoided, in favor of C-style return codes. All that non-local jumping is apparently too confusing for some programmers, and it has even been likened to `COMEFROM`. This opinion is not confined to the C++ community. I've seen it coming from Clojure programmers. 
From my (albeit naive) point of view, Emacs could be A component of a Lisp machine, but still not the same (see zmacs and so on). Mezzano is trying to replicate the idea of having a unified Lisp experience, all the way down which could have some nice effect, like hacking on the kernel live, reveal the bit of code that mystify us. Love the idea. But I'm not sure that, after careful consideration, it's still realistic to start this kind of project, even with huge backing. Between the fact that our current common computer arch are not as ready for this kind of project (even though they have their own advantage), and that on the other side we would need to recreate everything from scratch, which is the very annoying part. And that's even without talking about drivers for the hardware, which is as I see it still too often an open question for such a popular project as Linux. So, no, Emacs is not enough. But maybe turtles all the way down is not the answer we're waiting/hoping for. 
Whereas Common Lisp has throw for non-local jumps and conditions for signalling errors, C++ users seem to have been debating for decades whether exceptions should be either the former or the latter or both. It seems to alienate the usage of exceptions.
The heuristics for reading the game state from the screen are very clever and the most interesting part. Thanks for sharing
I would like to see how well it really plays (some statistics), there are some corner cases, like cacti coming close together or birds close to cacti, or if you jump something low (bird or cactus) you might hit a high bird. That kind of stuff. But I agree this is very clever and the post very interesting.
Note that this user is not me, but somebody who chose a very similar name... changed my flair to make it visible.
"Realm of Racket" was my first introduction to Racket (a scheme dialect) and functional programming in general. I think you'll find that functional programming is more idiomatic in the schemes but not so much in common lisp. The jump from static to dynamic typing can be odd. You may eventually be interested in Typed Racket, a variant that supports type inference and checking.
Clozure CL has an advice facility. http://ccl.clozure.com/docs/ccl.html#advising 
Thank you. I wish there would be a portable library, so SBCL could also take advantage of defadvice. Otherwise, any code one writes on ccl (or lw or allegro) will be locked in. I love ccl, but often sbcl is really quite faster.
What do you want to use advice for?
This is more of an exercise in studying Common Lisp, but also I find it somehow picking my interest: I would like to store the definition of a function *as is* when it is defined, so that it can be recalled at any time. I know I can get a definition, but it is not in the way it was inputted. I would like it exactly as it was defined. A use case: given a remote long-living image, and not having access to the source files, I would like to be able to recall the source of a given defun *as it was defined in the original file*. I went as far as finding this: http://stackoverflow.com/questions/21477336/how-to-get-a-function-macro-definition-from-cl-repl Rainer Joswig gives (as usual) quite stimulating remarks. I thought I could use his notes, and try to defadvice `defun` so that it could add its own definition as part of its definition. My main work (right now is study) is on SBCL. I do like ccl a lot, but SBCL is really quite faster sometimes, and I would like to be able to use defadvice on SBCL too.
I wish SBCL had defadvice, but in its absence, you can also just redefine CL:DEFUN to do what you like. It's not a very robust option, but it's not against the law to mess with internals to get what you want. I used to hack up the system to recognize ~ in pathnames in the unix style before SBCL supported it, for example.
Just a side note: see also this discussion: https://www.reddit.com/r/lisp/comments/4saada/curious_about_lisp_storing_code_and_state_in_image/
Thanks! I really wanted the Erlang book, and this got me so many more. Bought 'em all :)
Realm of Racket is really good, but you have to work your way through it from start to end. As in, picking it up in the middle makes it look like it doesn't explain things well enough (though it does a wonderful job if you're following from the beginning) and if you only read the first few chapters you end up with some misconceptions (i.e. there are better ways to program and the book explains them as you go through). Basically, think of it more like a set of connected lessons rather than a reference book.
Note that Rainer's `defadvice` is storing a form that has already been `read` (lisp objects like cons cells and symbols instead of a string). I think it would be pretty easy to do approximately the same thing in a portable way using `*maxroexpand-hook*`; that might be a fun exercise for you. When I looked into portably implementing `defadvice` I got stuck on trying to handle re-definitions sanely, and I think advising things in the `cl` package would have mostly been undefined or implementation defined behavior. Maybe there is a nice way to deal with redefinitions that I didn't find. Pascal Bourguignon's [IBCL](http://www.informatimago.com/develop/lisp/com/informatimago/small-cl-pgms/ibcl/) implements source storing/retrieving in a different way, and even allows editing the retrieved source. 
I suppose this is more than a tutorial, but: * Start with one of [ANSI Common Lisp](http://www.paulgraham.com/acl.html) or [Practical Common Lisp](http://www.gigamonkeys.com/book/) * Supplemented by [Common Lisp Recipes](http://weitz.de/cl-recipes/) ...if you then find yourself wanting more: * [On Lisp](http://www.paulgraham.com/onlisp.html) * [Common Lisp the Language, 2nd Edition](https://www.cs.cmu.edu/Groups/AI/html/cltl/cltl2.html)
ack, thanks
I just started learning Racket with [How to Design Programs 2](http://www.ccs.neu.edu/home/matthias/HtDP2e/) , I just started programming and find it really fun and interesting, but it may be a little to simple for someone with a lot of haskell experience. I still think its a good book for learning though :)
Lisp is very nearly the exact opposite of Haskell. That being said, [PCL](http://gigamonkeys.com/book/) is written for anyone with a moderate amount of programming experience in other languages, and is a very good introduction to Common Lisp for programmers. I don't use scheme, so can't recommend a book on that.
Thank you, that is vey helpful.
Ha! I was going to suggest J.
Thanks, just what I was missing in my workflow, never wrote unit tests in CL before, now will try to follow the flow shown. EDIT: the reason why I was never written unit tests for my CL projects was simple: too many projects to choose from and how to integrate to ASDF? As an example as C++ developer I know the mainstream (gtest/gmock) and know how to embed it into the workflow. For occasional java project there are not a lot of options since the major one - junit - is good enough. For C# the same, nunit get you covered. But for CL it was a problem for me - so tiny community is too spread with own solutions instead of working on some industry standard like junit :(
What do you mean? AFAICT there is complete consensus in the C++ community that if you are using exceptions you should be using them for error handling, not control flow.
Yes, I completely agree with you about size of the community and lacks of "de facto" unit-testing framework out there. Also "cl-project" tool generates testing skeleton for #'asdf:test-system. * SEE: https://github.com/ageldama/hello-adder-cl-asdf/blob/master/hello-adder.asd * SEE: https://github.com/ageldama/hello-adder-cl-asdf/blob/master/hello-adder-test.asd ..with that ASDF defsystems, I could run my tests with "(asdf:test-system :hello-adder)". (..or by just compile my testcase lisp source) It seems ASDF can be used with any testing frameworks. (by "customize" "test-op"-sections in defsystems.) http://www.cliki.net/test%20framework Yeah, it surely tons of test frameworks for commonlisp and I don't have any idea how to choose right one. But my "example" written with "prove" framework. (because it authored by same author of "cl-project" https://github.com/fukamachi?tab=repositories )
I prefer übergeek, but I'll take it ;-)
Did you ask her or does she knows you that well?
It was a wedding anniversary gift from her to me. 
Check http://eudoxia.me/article/common-lisp-sotu-2015#testing
Actually, with virtualization basically democratized at this point, this is the perfect time to be building OSs from scratch. It's pretty easy to target the handful of virtual devices that the VM platforms provide, which basically solves the myriad hardware driver problem. As for having to build everything from scratch -- it's got to happen sometime, otherwise we end up with nothing new or interesting ever again. The foundational assumptions can only be adequate questioned and new innovation can only be had by starting at the bottom sometimes. My thought was that if you could get it to the point where it could function as a swank server, then you have a good interface to work with it as it grows.
Makes me want a "May contain traces of Lisp" tee shirt.
Properly optimizing Lisp code is extremely tough. It's more than just adding types (because now you have to be concerned for code safety), cranking up SPEED to 11, and throwing out 3/4ths of the language. My biggest piece of advice is: profile. Optimization should *always* be guided by profiling. I might go as far as to say: *A priori* optimization is the root of all evil. It's a shame that many Lisp implementations have, in my opinion, nothing close to world-class profiling support. Some implementations (*cough* CCL) have absolutely abysmal support. It's laughable. Here, I'll list some examples where I thought I was being smart but it turned out I got negligibly better, and sometimes *worse*, performance. In these situations I didn't measure. 1. Attempting to remove inner-loop allocations by a single outer-loop allocation. No brainer, right? Wrong. Made the code uglier and didn't improve performance significantly. 2. Attempted to use pinned/static vectors. No brainer, right? Big vectors won't be scanned or moved. Wrong. Didn't help. 3. Attempt to memory pool small objects. No need to re-allocate them. Just recycle them. No brainer, right? Wrong. Made things complicated, made correctness more difficult, and didn't speed things up. 4. Attempted to optimize by using (UNSIGNED-BYTE 8) and avoid having to encode and decode endianness of larger word widths. Got rid of this extra nonsense so the code should be faster, right? Wrong. Working with more bits at a time was just cache friendlier and the extra encode/decode ops were not taking significant time. 5. Replace MAP-\* style macro with DO-\* style macro because loops are faster, no closure creation, no overhead. No brainer, right? Didn't make a measurable difference. In one particular application, I did numerous of these "optimizations" with some lazy TIME-based measurement, and it made the code brittle and hard to extend. I finally reached my senses and used SBCL's meager profilers to find out I was sinking most time into something I didn't think of at all: some DPB/LDB code that looked efficient but was behaving terribly, taking some 20+% of time.
Well. .it was our 6th anniversary, and I was married to someone else before. Think I found "the one" now ;-)
Excellent read, thank you.
&gt; Proudly NOT powered by WordPress. this is another funny bit I found.
Note that the code needs some improvements. Notably the use of EQ to compare characters and numbers is wrong. Also there are uses of LOOP which are not standard conform. For example (LOOP for ... while ... for ...) and (LOOP until ... for ...) is not allowed.
&gt;No fancy argument list for critical functions. &gt;I used &amp;key arguments in a few hot functions, and changing them to mandatory (or &amp;optional) improved speed a lot. Imagine you call a function that has named foo and bar arguments like this: &gt; (setq args (list :foo 1 :bar 2)) &gt; (apply some-function args) &gt;I'm no expert in compilers, but I think there is no way for a compiler to optimize that -- it has to produce code that digs the argument values from a list. That can't beat register arguments. So, for functions that are gonna get called like crazy, avoid &amp;key and &amp;rest (avoid &amp;optional too if you can, although it doesn't seem as bad). You don't have to throw out &amp;key arguments. Just do the &amp;key part in a macro. At the bottom of this comment is a small library that can be used for this purpose. It defines the `defkwfun` macro, which you use just like `defun`, except it creates a function that takes a flat argument list and a macro that accepts your "fancy" argument list and flattens it out at compile time. Why don't compilers already flatten `&amp;key` argument lists like this when their contents are known at compile time? EDIT: Fixed the formatting problems (caused by real tabs): (defpackage :fast-kw (:use :common-lisp) (:export :defkwfun)) (in-package :fast-kw) (defun symbol-append (&amp;rest symbols) (intern (apply #'concatenate (cons 'string (mapcar #'symbol-name symbols))) (symbol-package (car symbols)))) (defun lambda-keyword-p (symbol) (and (symbolp symbol) (char= (aref (symbol-name symbol) 0) #\&amp;))) (defun split-lambda-list (lambda-list) (let ((result '(&amp;positional)) (current-group nil)) (loop for symbol in lambda-list do (cond ((lambda-keyword-p symbol) (push (reverse current-group) result) (push symbol result) (setf current-group nil)) (t (push symbol current-group)))) (push (reverse current-group) result) (reverse result))) (defun make-kw-macro-body (real-name flat-lambda-list) `(,real-name ,@flat-lambda-list)) (defmacro defkwfun (name lambda-list &amp;body body) (let* ((parsed-lambda-list (split-lambda-list lambda-list)) (static-lambda-list (getf parsed-lambda-list '&amp;positional)) (sections (remove '&amp;positional (remove-if-not #'symbolp parsed-lambda-list))) (real-function-name (symbol-append name '- 'flat-arglist))) (setf static-lambda-list (append static-lambda-list (loop for section in sections append (loop for arg in (getf parsed-lambda-list section) if (symbolp arg) collect arg else if (and (listp arg) (= (length arg) 3)) collect (first arg) and collect (third arg) else if (listp arg) collect (first arg))))) `(progn (defun ,real-function-name ,static-lambda-list ,@body) (defmacro ,name ,lambda-list (make-kw-macro-body ',real-function-name (list ,@static-lambda-list)))))) 
The author has a nice write up of the software they use to host the site, sytes
It seems to me that fast code is a concern but it is more important to first have a good model of the problem to be solved. "Go" is said to be a harder problem than Chess and Google has a good model for besting champion Go players. There is an overview here https://en.wikipedia.org/wiki/AlphaGo, not Lispy, but relevant.
You're using `*` as a variable in the last three expressions. It means "previous value in the REPL". [More info](http://www.lispworks.com/documentation/HyperSpec/Body/v__stst_.htm)
thx! each expression in Lisp have to include a pair of parentheses, right?
What is a tree shaker?
Just a quick question -- what's the "best" way to run the examples? Some have a function defined to kick them off; some I can't quite put the pieces together. The ones that I can't get to run are good for syntax reference, but it would be nice to play with them interactively. Thanks for any guidance!
AFAIK, none of the implementations encrypt the images. I'm pretty sure none even checksum them. So, if you are concerned that if you save an image containing your password, someone could find it or if you are concerned that someone could tamper with the image provided, you're probably correct. Or, did you have something else in mind by "security".
I am very happy about SBCL being improved and bugs being fixed, for example, but I do wish there was some effort to improve it as a programming/delivery environment. This includes profilers, debuggers, introspection, binary delivery, corner case behavior (e.g., error handling for failed allocation), ... . Ideally these things could be taken to "production stage", not just a handful of proof-of-concepts. I too would contribute to such efforts, financially or otherwise. 
&gt;each expression in Lisp have to include a pair of parentheses, right? I'd call something like 5 an expression too, so no :) (it's an expression that evaluates to the number 5). But function calls and stuff (stuff being special operators and macros, you don't need to care about what those are right now though) needs to have the parens when you call them, yes. (Im-a-function Im-a-variable) The first f here is the function f (because it's first in the list) and the second f is the variable f, even though they're named the same! (f f) If you want to refer to the function f as a value (not calling it) you'd write (function f) Or for short #'f
I'm not sure what you expect from this? Could you qualify what you mean by security? Do you mean code "security" where the code is verified by a checksum or something, or do you want to know if it is possible for the image to be decompiled? Or do you mean something else entirely?
So you could include stripped versions of libraries? That could be pretty useful.
I've had good luck with: (ql:quickload :clim-examples) (clim-demo:demodemo) Edit: After loading that, assuming you are using sly/slime, you can open the demo files in the McClim repo and C-x C-e any modifications you have and it works like you'd expect.
&gt; profilers, debuggers, introspection I was pretty happy with the profiler though I haven't done anything big with it. Debuggers and introspection I always use sly so I can't say much about that. What do you feel is missing there? (I'm not an sbcl contributor (yet) so just curious)
demodemo... why didn't I think of that?! Thank you sir, have an upvote.
Basically the general idea is to remove anything that isn't used. How granular it gets (function level, package/module level, etc.) depends on the particular implementation from what I understand (I am definitely not an expert on it).
I love these posts. I am not into game development, but I can see how Common Lisp can be a huge help. I remember Carmack working on Oculus with Racket: https://youtu.be/ydyztGZnbNs?t=15m
It's worth mentioning that this behaviour is only possible in a Lisp-2 such as Common Lisp, where the value of * can be different from the function value. 
The only major language that has tried to implement the security you speak of is Java. Jar files have a manifest, optional signing, etc. By my memory, the classloader also has some hooks. Pretty much every other language is in the same boat as CL. The compiler will generate the best code it can. If someone edits the saved images (object files, etc.) or directly writes the memory, then all bets are off. This is where code signing, trusted computing, DRM, etc. come in to play. Disk storage, and to a lesser extent the object loader, fall outside the scope of a language. On the plus side, CL's dynamic tagging and GC do avoid and detect some common classes of runtime errors. If you haven't seen it, this article is a fun read. http://www.gamasutra.com/view/feature/131439/keeping_the_pirates_at_bay.php
Follow-up: I don't consider DLL signing, "app store signing", etc. to be language features per se. The .NET runtime has Java-style features built in. A CL environment could choose to do similar cryptographic integrity checks, but I am not aware of any implementations that do.
And through Java, Clojure would have the same features, right? It's probably the only Lisp that does.
Calling it a lisp... Never mind, I have problems with it due to its insistence on immutability. That's not the lisp way, lisp gets out of the way. Whatever. That's not really the point. You could easily write a preloader that would define the crypto necessary for encryption and verification of images, just use an off the shelf library, so you don't have the chance to screw it up. It would be no less vulnerable to manipulation than an infected jvm. Of course, that's work to do that. 
There's an outsdanding pull-request for lz4hc compression which also reduces size of images without hurting startup time as much as the existing zlib compression.
Attack surface for memory bugs (i.e. stack, heap overflow) is much reduced if the safety level is set to non-zero. You are then basically limited to bugs in foreign code and in the lisp runtime itself. It's not possible to write a stack overflow in portable lisp code. READ by default is unsafe to use on untrusted inputs. Any time I tried out a new web framework I searched for uses of that and reported them when I found them. Other than READ, the interface with foreign code is where the majority of exploitable bugs can be found. This is because the interface is basically the C ABI. Note that none of the languages you mention solve the problem of this. Assume that if there is multithreaded code that is trying to manually manage shared resources, there will be bugs. I can't imagine of a way to exploit those bugs for anything beyond a DoS, but that doesn't mean it's not possible. Note again that this is true for most languages, though the purity of Haskell helps, and Rust is making a concerted effort at making these bugs harder. Lisp in particular has it bad because bordeaux-threads silently pretends to succeed any time you make an unimplemented request (example, using a recursive lock on sbcl without the with- macro).
Congrats for finishing and the write up. When starting on Ubuntu 16 it complains about libcommonqt. I saw that you shipped a bunch of Qt libraries with the binary, but this one not.
Hi, thanks a lot for the post! I completely share your pain about lack of documentation. Sometimes it's really disappointing to go over libraries in quickdocs because some of them even don't have a readme attached and others have a tutorial written years ago with home page not active anymore. Since I'm new to common lisp it's even harder for me because I spend a lot of time understanding how things work. What do you think about ways to improve this? From my side I would be really happy to see a project similar to clojuredocs.org for common lisp world and approach to documentation and using projects like commondoc to be a requirement for libraries to be recommended for use. In addition to that I was thinking about taking cl-cookbook source from sourceforge and reshaping it into something more modern looking
No worries! Thanks for the new upload.
This feels like I have amnesia. Fixed again, this time for sure. Hopefully. 
What about ABCL?
The last version you uploaded works now, at least for me on Ubuntu 16. Thanks!
yeah, pretty demented
It removes unused code from your project. The thing is, SBCL does not have one at all, so if you make your hello-world function into an executable, it is 50MB. That's the kind of crap that other languages make fun of Lisp for, behind its back.
Not sure if the imacs counts - https://github.com/yesco/imacs It's tiny, only 364 lines (non-comments), but of course very limited ;-) It's designed for the esp8266, vt100 only, and can be used together with esp-lisp https://github.com/yesco/esp-lisp Have to look more at the FemtoLisp implementation ;-)
Fabulous documentation! And, thank you so much for implementing input from streams or strings instead of just strings! I can't wait to use it.
Interestingly you now deleted the old Github repository and created a new one under a slightly different name. Then you added the same old bullshit code you wrote before with all the problems: no formatting, doesn't work, ... I wonder what the reason is. All those problems are not that difficult to fix, but you did not. Is it a social experiment? A scam?Ar you just too lazy? What is it?
I'm interested in how picolisp users find it easier not to have floating point. I understand the goal of simplicity, but I dont think simplicity is having less of something, for example https://en.wikipedia.org/wiki/One_instruction_set_computer. The one instruction set computer has less instructions, but is it simpler to have to construct all things in terms of that instruction than it is to have `n` more specialized operations? The currency example feels like a miss-step too as one should not be using floating point numbers for financial things anyway. I would love to hear some stories in this area.
That's an interesting approach to fixed-point. You set the environment to track precision. I could see this being useful as a calculator, or in small applications. I wouldn't want to try making this work in a more complex application since the precision is tied to the environment instead of a data type or instance. I created this common-lisp library for fixed-point math based on Ada, https://github.com/npatrick04/fixed. It's not perfect, I want to make the reader macro more powerful, and it's based on CLOS, so not the most efficient. One nice thing this has that I don't see in the picolisp implementation is the ability to define fixed point types that are powers-of-2 based. I like decimal types for human readability, but hardware interfaces and other use cases will define fixed point types as a simple bit-shift. 
I gotta say it. This is insane. Unintuitive, error prone, context-dependent. I'd love to see an implementation of something really fundamental like a fixed-point tangent function. This approach isn't a reflection of KISS. At the end, there's complaining about supposed inexactness of floating point arithmetic. Any finite quantized domain will be inexact: fixed, floats, whatever. Only very rarely can you do exact computations (e.g., rational arithmetic). But it's so rare that choosing a number system that has far reach in magnitude but high practicality for "human-sized" numbers is the most sensible choice. One such number system is exactly the floating point number system. 
Hi, very interesting read! Very nice to see a game in lisp :) I'll have a few questions: * Is Beast gonna be on quicklisp? * Where do i need to put my curse header for cl-charms to find? Thanks for the great article and inspiration
Apologies if this falls under the rubric of un-allowed self promotion. (Or is otherwise a low quality post!)
The readme says it's an "Old, but suprisingly complete toolkit with no dependancies on other non-lisp libraries." but a toolkit for what? I guessed GUI given Aidenn0's comment. If so that is interesting, but it would be cool to see a little more up front info. We can of course compile the docs and see what they say but it leaves out those browsing on their phones. That aside, what OS does this run on? Do you have any example code or info on the usage patterns? What does it use for rendering? Also is this project now 'alive' again or was the goal just to get it asdf loadable and then let it lie (hoping it's the former :) )
No saving, sadly. It was on the list of possibilities but I didn't get around to it. I think it would be mainly just serializing the heightmap and entities, which should be fairly simple.
Thanks a bunch for the answers, i'll look into it.
Hey, I had made a simple port of jscl and put it on npm: https://www.npmjs.com/package/jscl https://www.npmjs.com/package/jscl-repl David actually reached out to me and stated he liked the idea and planned on making some improvements so I transferred the package to him. He's also on Bitbucket now https://bitbucket.org/davazp/profile/repositories
Long long time ago, I did something similar on an 8051 for a heated scalpel and needed to adjust the controls every 10ms. Using the same technique (scaling by shifting bits), I was able to get the calculations under 5ms, leaving 5ms for all the other stuff (controlling the display, user input, etc.). 
Agree. I still don't fully comprehend it. Its central idea is the 'interactor', which makes for slightly different approach, though it's still essentially MVC. What's interesting is that in some ways it's reminiscent of modern day Webpage apps like Angularjs, i.e. you 'markup' graphical elements to make them 'interactable'. Potentially any graphic element can become a widget by giving it certain attributes.
For background see [the CLiki page](http://www.cliki.net/garnet)
Fixed those, it now works in other implementations too. Tested AllegroCL and CCL, but SBCL is fastest by a long shot: https://gist.github.com/mishoo/503d4bf67da4e18fbab6c5e26c498df7 — wish I could improve this, but I don't know how; suggestions welcome.
This is great. Esrap is the first and only Lisp parser combinator library and wrote and what I reach for whenever I need a grammar. While it's very easy to get a parser up and running, the restriction of parsing exclusively on strings rather than streams and the performance were always a source of concern for me. I look forward to trying this. Also I appreciate the charts and the discussion of the impact of micro-optimization.
Very cool!
Very nice, I am looking forward to see it develop into an even fuller Common Lisp. From ulisp page: The language is generally a subset of Common Lisp, and uLisp programs should also run under Common Lisp. That helps preparing code on a SLIME environment first.
The CL heritage is not surprising, considering that the author has previous experience with Macintosh Common Lisp, LispWorks, and CL-HTTP.
This is cool, but there are a couple of things that need solving. 1. ISR handling. AFAIK, ULisp doesn't have any way of defining an ISR. If that is possible, then it's a big win in my book. Of course, one needs to ensure that the ISR doesn't cons or even if it does, how does one handle it. 2. Register Mapping. This is where C is ugly and everyone gets around it by convention. I wonder if there can be a macro makes memory mapped register access intuitive. I'm sure these are things solved in the original Lisp Machine, and would love to see how it was done then. These are more questions from me rather than a comment on the project. Any ideas?
Forth has infix?? Nope postfix. See http://c2.com/cgi/wiki?ForthVsLisp
SBCL core compression easily creates smaller binaries than say LW for most example code.
That neat. You should cross post that to /r/emacs 
Seems pretty thorough. I wish that the performance issues noted about a-cl-logger were not its primary feedback. A-cl-logger is fast enough for all of my purposes, is fairly easy to use, and provides (in my mind) features that are important and not available in other logging libraries (can log arbitrary data formatted as json to LogStash). It also heavily uses the condition system to make it really easy to extend log messages from the dynamic context. In the billing application I wrote for our company, we log lexical context information as well as real-time timing information about important functions in the application.
I was contacted by the author of this article a while back and was provided with very useful feedback that helped improve Verbose. Thank you again for that! I'm always glad to get feedback, especially when it leads to some good improvements. Some minor amendments though: * You can also log conditions, which will result in an SLDB-like printout of the condition along with a stack trace taken from the point of logging. That's very handy for offline debug info recording. * Some very [recent developments](https://github.com/Shinmera/verbose/issues/2) lead to the introduction of an explicit synchronization command with `(v:sync)` that allows you to make sure messages have been processed, as well as a `v:*process-locally*` variable that allows you to dictate that messages should be handled straight from the thread they were issued from. * You can define arbitrary filters by adding new pipe segments to the pipeline. This is a bit more cumbersome to do than I'd like it to be, but it is something that is "intended to be possible". * You can achieve multiple loggers by either creating separate pipeline sequences, or creating new `controller` instances and binding the appropriate one to `v:*global-controller*` around the logging calls. * Instead of `(setf (v:shared-instance '*standard-output*) *standard-output*)` for cases where you're connecting through multiple SLIME instances, you can use the shortcut of `(v:output-here)` that does the exact same. I'd like to add JSON output, that sounds really useful. I'll have to think on how to incorporate that into the system Verbose has in place with custom messages and all that though. As for performance-- that has never actually been much of a concern for me, but I can see the validity of it. I'd like to improve that as well if possible, but it might require some more serious restructuring. Edit: generally I'd also like to improve the documentation a bit to make it more extensive. As it is now there isn't much beyond a short introductory tutorial and the docstrings, which isn't great.
I looked through the source file. Really cool stuff.
Thank you for the suggested amendments. I have tried to take those into account and edited the article. Please let me know if there are any further corrections that should be made.
Remember that Emacs is a self-documenting editor. Just type `C-h f -&gt;&gt;` and voila: -&gt;&gt; is a Lisp macro in `dash.el'. (-&gt;&gt; X &amp;optional FORM &amp;rest MORE) Thread the expr through the forms. Insert X as the last item in the first form, making a list of it if it is not a list already. If there are more forms, insert the first form as the last item in second form, etc. You can even click on `dash.el` and Emacs will take you to the source!
-&gt; and -&gt;&gt; implementation on PicoLisp starting from line 91 and below https://bitbucket.org/mihailp/tankfeeder/src/b6b554771c1d998e8bb12df0a98b0940eb8a77a8/picolisp.l?at=default&amp;fileviewer=file-view-default
I think these macros first turned up in Clojure, this article should help: http://clojure.org/guides/threading_macros
used for solving all 4clojure tasks: https://bitbucket.org/mihailp/tankfeeder/src/b6b554771c1d998e8bb12df0a98b0940eb8a77a8/4clojure/?at=default
Oh no problem! I appreciate the hard work it took to compile this article :). It's definitely a nontrivial task to figure out that many logging libraries and document them as well as you did. Much thanks for doing it and for accepting feedback on it!
SBCL is not firendly to windows. I don't like cygwin etc. I wish a native tool chain
SBCL runs natively on windows. It is fully supported, including native threads support. There is a .msi installer [here](http://www.sbcl.org/platform-table.html) for both x86 and ARM64.
 sbcl --load my-program.lisp --load uiop --eval '(uiop/image:dump-image "my-program.exe" :executable t)' or similar work? Most lisps are VMs, when you dump an executable you're really dumping the VM (along with your data). This is actually how Emacs is packaged -- a proto-emacs (bare-bones elisp interpreter) loads all the elisp files that make up Emacs' actual systems, then dumps its memory in a format that can be executed.
so, that is not what I want
Have never used it, but heard that ECL is supposed to compile to C.
ecl and clicc don't use images. clicc is unmaintained.
Yes, it sounds like ECL might be what the OP is looking for, [as per the ECL manual](https://common-lisp.net/project/ecl/static/manual/ch34.html#Internals-What-can-ECL-do-).
Yep, I recently used ECL to deliver a win32 executable for work and it's actually really nice to work with! Dead impressed with how it's coming along. 
Thanks, I get it. It is a good choice for commercial use
&gt;WARNING: the Windows port is fragile, particularly for multithreaded code. Unfortunately, the development team currently lacks the time and resources this platform demands.
That warning has long ceased to be accurate, at least in terms of threading and fragility. SBCL works just fine on Windows and I've deployed a few applications on it without any issues.
Most CL implementations compile to local binary on the fly -- and you make a binary program by getting a running instance configured how you want and having it dump/save itself. It's probably different than what you're used to. If you want a more familiar process, use ECL. ECL compiles to C and then invokes the system compiler to generate the final product. If neither of those approaches is acceptable, you want a different language. hth
I have used ghc. I have used a dozen compilers on dos/windows going back to Turbo Pascal 3. What is it that you can't do now that you want to do? I'll tell you how.
Thanks
That works for this case (and I'd actually forgotten about BUTLAST, so thanks!) but it does not address the general case of setting the last cons of a list. It just seems so out of character for Common Lisp. We have a function that returns the last cons of a list and a wonderful mechanism for modifying places identified by similar functions, but they won't play together. This is where the extensibility of SETF would normally come to save you, but (SETF LAST) is reserved so you can't guarantee you're not breaking anything! I do love the war-stories of the CL standard process, so I guess I wondered if there was some historical reason for this or if it's just an omission due to "so much spec, so little remaining DARPA money".
It could very well also just have been an oversight. The standard writers were pretty good at trying to estimate all possible use-cases, but by far not perfect. There's quite a few parts of the spec that, in hindsight, could have been done much better in a different way.
Similarly `nthcdr` is not `setf`able in CL, which I also find irksome.
Also keep an eye on the _read_ function together with reader macros [#.](http://www.lispworks.com/documentation/HyperSpec/Body/02_dhf.htm) (it's enabled by default), cycles [#=](http://www.lispworks.com/documentation/HyperSpec/Body/02_dho.htm) with [##](http://www.lispworks.com/documentation/HyperSpec/Body/02_dhp.htm) and I'm not sure about [#+](http://www.lispworks.com/documentation/HyperSpec/Body/02_dhq.htm) and [#-](http://www.lispworks.com/documentation/HyperSpec/Body/02_dhr.htm).
Is it perhaps [nconc](http://www.lispworks.com/documentation/HyperSpec/Body/f_nconc.htm#nconc) that you actually want? LAST hands you the final cons. So SETF LAST must change the cdr of the penultimate cons. Which requires the list to have at least two elements. I bet that is going to lead to a nasty surprise one day when you try to setf the last of a list that is only one long.
Are you Marc?
It does not work because (mod n 1) will always be zero, (= d 0) should be (= d 1). Also you do not have to check all the divisors starting from number minus one is not necessary, you can start at square root of number You can further optimize it is by starting divisors from 2 and work upwards. Half of all the integers are divisible by it and the function will only have to make one check.
The first would give you NIL (for a list x of one element, (last x) is x), the second would be an error. This is consistent with the rest of CL, e.g: (cdr nil) is valid, but (setf (cdr nil) x) is not.
(last x) is not a ***consistent*** well-defined place. by consistent I mean: ;; the following should leave x and its value unchanged. (let ((y (setf-able x))) (setf (setf-able x) some-value) (setf (setf-able x) y)) for example, (setf x (list 'a 'b)) x -&gt; (a . (b . nil)) ;; save (last x) (setf y (last x)) y -&gt; (b . nil) (setf (last x) (list 'c)) x -&gt; (a . (c . nil)) y -&gt; (b . nil) ;; revert back (setf (last x) y) x -&gt; (a . (b . nil)) ;; ok this works. (setf (last x) (list 'd 'e)) x -&gt; (a . (d . (e . nil))) ;; now revert back (setf (last x) y) x -&gt; (a . (d . (b . nil))) ;; oops, did not revert back. edit: added explanation of consistent
here is your function, reformatted to a standard lisp style. (defun is-prime (n &amp;optional (d (- n 1))) (if (= d 0) t (if (= (mod n d) 0) nil (is-prime n (- d 1))))) also is-prime would probably be called primep (p for predicate) or prime? 
In addition to the more relevant comments, may I suggest (when (zerop i) ...) 'when' is more appropriate than 'if' since there is no 'else', and zerop telegraphs your intention to test for 0.... the second half of arvid's example could be written as (unless (zerop (mod n d)) (is-prime n (1- d))) 
As you may have seen in the other solutions, there's no need to RETURN-FROM here, and the reason is central to a big difference between Lisp expressions and Java statements. A statement does something. To get a value, you need to execute an explicit return operation. An expression is a form that has a value. Lisp has expressions. (+ 1 2) has no return, it just evaluates to 3. (if (= (mod 7 2) 1) 'odd 'even) has no return, it just evaluates to odd. Nothing changes when recursion is added.
And here is the same function using cond rather than nested ifs. My experience is that cond is more common than nested ifs, but I've seen both. (defun is-prime (n &amp;optional (d (- n 1))) (cond ((= d 1) t) ((= (mod n d) 0) nil) (t (is-prime n (- d 1))))) 
I'm on mobile (and reading your code is kinda hard) but I believe you need to assign the return value of your function. Something like: (defun test (l) (let (a (add l))) (format t "~A" a))) My code might be screwed up since I haven't written any CL in a while.
You have a global variable called A and you are passing it to a function, where it will be bound to the name A, but your mistake is assuming that you can rebind A within the function and have it reflect globally. (Sometimes you can mutate an object inside a function, and there are rules to that; but not NIL, and not by creating a new CONS cell.) One simple solution is to have ADD simply build the new list and do the SETQ assignment at the function call site: (setq a (add a)) What you're doing could be accomplished with a macro, but you're doing something non-idiomatically so better to learn the idiom.
try the following: CL-USER 1 &gt; (defvar *a* nil) *A* CL-USER 2 &gt; (setq *a* (append *a* (list 1))) (1) CL-USER 3 &gt;(nconc *a* (list 23)) (1 23) CL-USER 4 &gt; *a* (1 23) issues with your code: wrong use of append and nconc Misunderstanding in how parameters are treated outside the function
Functions return the return value of the last evaluated expression. So just make sure the return value of the last expression in your function returns the modified list.
/r/learnlisp may be a better place to go. &gt; (defun ADD(a) (setq a (CONS a (read)) )) Will result in a period rather than comma in the list ex. (1 . 2) *cons* are ordered pairs. (cons 1 2) results in (1 . 2) The *car* of the list is 1 while the *cdr* is 2. A list in the sense of what you are looking for can be created by *cons* as such: (cons 1 (cons 2 nil)) which results in (1 2) The *car* is 1 while the *cdr* is (2). Though you can also achieve a list by using *list*. (list 1 2) results in (1 2) Similarly, the *first* of the list is 1 while the *last* is (2). ---- (setf a '(1 2)) (setf b '(3 4)) (append a b) results in (1 2 3 4) however, append is non-destructive so a : (1 2) b : (3 4) now (nconc a b) results in (1 2 3 4) but it is destructive a : (1 2 3 4) b : (3 4) ---- Now let's try something. (setf a (list 1 2 3 4)) (setf b (list 5 6 7 8)) (defun add (a b) (append a b)) The result returned is (1 2 3 4 5 6 7 8) but *a* and *b* remain unchanged. (defun add (a b) (nconc a b)) The result (1 2 3 4 5 6 7 8) and *a* is changed while *b* remains unchanged. ---- So that should give you at least some idea as to how those three functions work. That should be enough information to help you get what you want. Though as was mentioned by someone else, you will have to take into account that if *a* is nil when you pass it in then it won't change like you want.
No. This was decided by CLtL1, pre-ansi. I found no discussion of this. So I am just speculating of a possible reason. I did find someone who requested for nthcdr to be setf-able but got no reply. Regard to the function *last* the only discussion that I found was what should last of nil be and last of an atom. In some lisps, (last 'a) returned nil, in others an error. similarly for last of nil (nil is both a list and atom).
Simpler: (defun is-prime (n &amp;optional (d (- n 1))) (or (= 1 d) (and (plusp (mod n d)) (is-prime n (1- d))))
Hello all, this has been a small side project of mine over the last couple weeks. This isn't directly lisp related, but the effect of mutating the python syntax during runtime of the program felt pretty lispy. Please share your thoughts
Depends on where you download it doesn't it. In other news your local library may have something or be able to borrow something to lend to you. 
See the sidebar. Has a list of the available free books. The hyperspec is basically a web book and you can download that too.
The new syntax is valid only inside decorated functions. Why? I suspect that it is because the same expression is syntactic valid outside a decorated function. In that case, wouldn't it be better to use a syntactically invalid expression for the new lambda? Python really needed this more powerful anonymous function expression.
The decorator is the mechanism which invokes the ast transformations in the decorated function. Unfortunately a valid python syntax must be used. The AST transformations happen after the python code has already been compiled, and having invalid syntax will cause the python compiler to complain. 
That is indeed my favourite site! ;-)
I've yet to find a book on Lisp that wasn't worth reading - PCL, SICP and On Lisp in particular
[https://www.reddit.com/r/lisp/comments/4fb066/inlined_static_dispatch_for_clos_empirical/](https://www.reddit.com/r/lisp/comments/4fb066/inlined_static_dispatch_for_clos_empirical/) I think he is refering to the "News" section that mentions an alternative branch with static type checking. See [https://github.com/guicho271828/inlined-generic-function/blob/invalid-branch/invalid-branch.org](https://github.com/guicho271828/inlined-generic-function/blob/invalid-branch/invalid-branch.org)
but Lisp programmers know the cost of nothing :/
I was rather surprised to read this sentence on the second page: &gt; Scheme is an elegant and compact subset of Common Lisp that supports a minimalistic core language and an excellent suite of language extensions tools. I think any Schemer would be surprised to hear it called a "subset of Common Lisp", given Lisp-1 vs Lisp-2, hygienic vs non-hygienic macros, and all the rest. edit: some other unconvincing pieces. They tout that Common Lisp was designed for "large, complex, and long-running applications" and supports hot-swapping, but scientific code typically runs for the duration of one simulation or computation. They tout CL's condition system, but a CL-inspired condition system is present in R and *literally nobody ever uses it* because *nobody bothers to handle errors* -- errors just mean your code is wrong, so they bail out and let the programmer fix it. Touting the ability to build DSLs in Lisp via macro magic also doesn't convince me, because most scientists are scientists, not programmers, and do not invest the time and effort to learn the software tools they already have. So as much as I'd like Scheme or Lisp to take over the scientific world, I don't think this is the argument for it.
&gt; We are convinced that Lisp grants programmers unprecedented power to build increasingly sophisticated artificial intelligence systems that may ultimately transform [...] AI research [...]. I thought that's what they said in the seventies, preceding the AI winter.
&gt; I think any Schemer would be surprised to hear it called a "subset of Common Lisp", given Lisp-1 vs Lisp-2, hygienic vs non-hygienic macros, and all the rest. Agreed. &gt; most scientists are scientists, not programmers Except computational biologists... But your reference to R is relevant because R's predecessor was Lisp-STAT. Luke Tierney mentioned that he thought the language syntax was off-putting to scientists. Back then, they didn't have teams of computational biologists like they do now, but Lisp never could catch on with the rest of the community. R, being Scheme-inspired by with more agreeable syntax, won out. Whether for good or bad, who knows, but this is what we have now.
Moore's law kind of invalidates that criticism...computers are getting closer to the processing equivalent of a human brain every day. We're not there yet, but we're exponentially closer than we were in the 70s.
Why have you put `&amp;lt;`'s throughout your post?
Count me in! :D
i use it ie. for scripting and websites. picolisp can be easily used as glue code to connect native libs. and for the web its a very light and useful alternative to wordpress+mysql. pil itself is only ~200kb with full nosql. me likes it and i am very happy that i found it.
&gt; Can we declare this a bigger emergency than it is commonly being treated as? I think it'll always be too easy for management to corral the less experienced programmers into short term thinking. Rails has a 1hz feedback loop until you hack stack for three years, and maintenance becomes a four letter word and a political issue at that point, when feature work is slower than ever and just as critical as always. How do we convince the business that any of this matters, when they refuse to empathize?
Nice work. I like your repo as well.
There isn't even an implementation of R7RS large, only the "small" variant, which is supposed to continue the tradition of Scheme being useless except for the academic study of fundamental computer science concepts. So that means if you want to write a real program in Scheme, you have to pick either Guile or Racket (which are mutually incompatible), both of which are just sucky versions of CL, each for different reasons. 
Thank you for this, it is quite inspiring.
thanks, tard
I haven't figured out exactly what I want out of a Lisp for statistical computing (I should dig up XLISP-STAT sometime), but I'll keep Clasp in mind. It'd be great to be able to fall back to R. Thanks for the ideas! Would it also be easy to fall back to Julia, since it's also LLVM-backed?
It would be nice if it behaved like rspec in that you could just put the specs into a `spec` subdirectory and it would find them without you having to load them explicitly. You could even have an `lspec.lisp` that works like the `rspec` command: (ql:quickload :lspec :silent t) (loop for file in (directory "spec/*-spec.lisp") do (load file)) (lspec:run-all)
What's the confusion? Perhaps you can format your question better?
&gt; in the first case. you entered (read-line) followed by the enter key. sbcl should then read in all characters up to the next enter key and return two values: the string of characters you typed and nil. it appears you typed no characters and an enter key. This is the problem. I typed `(read-line)`, pressed enter, and it acted as if I pressed enter a second time. I didn't. It didn't even give me a chance to enter any data. I'm using SBCL 1.3.9 on Windows 10. `*standard-input*` shows up as `#&lt;SYNONYM-STREAM :SYMBOL SB-SYS:*STDIN* {100017FF43}&gt;` on my REPL.
Hmmm, very strange indeed! Yes, I think that's the best thing to do! 
...what? Of course you can load files in SBCL. Terra:~ jfischer$ cat yes-this-works.lisp (defun hi () (format nil "Hello.")) Terra:~ jfischer$ sbcl This is SBCL 1.3.9, an implementation of ANSI Common Lisp. More information about SBCL is available at &lt;http://www.sbcl.org/&gt;. SBCL is free software, provided as is, with absolutely no warranty. It is mostly in the public domain; some portions are provided under BSD-style licenses. See the CREDITS and COPYING files in the distribution for more information. * (load "yes-this-works.lisp") T * (hi) "Hello." * 
Hi winter_mutant, good to have you here. It looks like you may be using the repl directly rather than via something like slime. Slime is library that connects your editor (emacs/vi/atom) to your lisp (sbcl in this case) and helps the development experience. Of course you are free to work however you like but using the REPL bare is not recommended by the SBCL manual: &gt; Though SBCL can be used running “bare”, the recommended mode of development is with an editor connected to SBCL, supporting not only basic lisp editing (paren-matching, etc), but providing among other features an integrated debugger, interactive compilation, and automated documentation lookup. &gt; Currently SLIME [..] together with Emacs is recommended for use with SBCL, [..] I would highly recommend using emacs with slime/sly or vim with slim. Atom support is being built but last time I checked it was too easy to break (at least with my projects). If you need a simple guide to getting an editor set up with sbcl you may want to try this video: https://www.youtube.com/watch?v=VnWVu8VVDbI Good luck and I hope you have fun
Just realize that sbcl itself should probably be considered a sort of back-end, and you'll pretty much never interface it directly like this. I.e. try to find an IDE that suits you.
Several Common Lisp implementation provide concurrent native threads. That means several threads run at the same time and they are scheduled by the OS. For most implementations all threads have to stop when a Garbage Collection occurs.
&gt; Dead project Oh, right. Um. But how do you use SBCL, then? Yesterday, I even tried passing a script as a command line argument and it didn't work either. The interpreter started, but I couldn't refer to any of the definitions in it. I've only managed to get any use out of it within SLIME.
Did you use the `--load` command line option, or something else?
`(load "file.lisp")` I was using it on Windows, any known problems with that? I just tried it, first time using SBCL since I switched to Ubuntu, and it worked fine. I think I'll be deleting my original comment now :$
OP is asking about whether there is anything similar to the GIL in Common Lisp, not which library supports multithreading. 
[ABCL](http://abcl.org) uses the JVM's garbage collector, which can be run asynchronously, and usually is by default in OpenJDK 8.
There is no standard way in Common Lisp to recover the s-expression for the body of a DEFUN once it is compiled. You could implement a macro DEFUN-AND-SAVE that saves the body and does the DEFUN and then recover the body when you want to calculate the symbolic derivative.
Why is it a macro and not a function?
If you aren't aware the book [Paradigms of AI Programming: Case Studies in Common Lisp](https://en.wikipedia.org/wiki/Paradigms_of_AI_Programming:_Case_Studies_in_Common_Lisp) covers the topic of symbolic differentiation, among others. There is also [Maxima](https://en.wikipedia.org/wiki/Maxima_(software\)) which is written in CL and available under the GPL. It is a fully functional computer algebra system which is of course capable of symbolic differentiation. Might be useful if you are interested in seeing a working implementation.
Actually, my interest was not in the symbolic differentiation in itself but in the lisp meta programing capabilities. The idea was to input a program and manipulate it to output a new program, which can be easily done by giving a quoted program such as this `(diff '(+ x x) 'x)`. Anyway, it does not seem possible in common lisp to inspect compiled user function. 
I bought it a while ago (emacs 24 time frame) and was offered the latest version with updated material for emacs 25.
Don't confuse parallel operation with concurrent operation. *parallel* basically means that work is split up and runs at the same time. *Concurrent* means that threads run independent from each other in whatever order. For example two different computations might run at the same time. When one says the GC is a parallel GC, then it basically means that the GC runs in more than one thread - which should help to make it faster. But it is not necessarily, that the application is running. The Allegro CL documentation mentions that in an SMP version of Allegro CL the GC runs both parallel and concurrent to the application threads. But there are no details given. If you look at the concurrent mark&amp;sweep GC for Java, it is partially concurrent. There are GC operations where the GC stops the application threads. https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/cms.html &gt; During each major collection cycle, the CMS collector pauses all the application threads for a brief period at the beginning of the collection and again toward the middle of the collection. &gt; However, if the CMS collector is unable to finish reclaiming the unreachable objects before the tenured generation fills up, or if an allocation cannot be satisfied with the available free space blocks in the tenured generation, then the application is paused and the collection is completed with all the application threads stopped. 
&gt; Quicklisp makes this harder since you can't lock down individual dependencies, though you are able to stick with a specific dist. Qlot allows you to lock down any library to any version you want. You can even use libraries from different Quicklisp dists.
Use FUNCTION-LAMBDA-EXPRESSION with INLINE declaration. However the result varies from implementation to implementation. FUNCTION-LAMBDA-EXPRESSION http://clhs.lisp.se/Body/f_fn_lam.htm (declaim (inline sqr)) (defun sqr (x) (* x x)) (print (function-lambda-expression sqr)) ; &gt;&gt; (EXT:LAMBDA-BLOCK SQR (X) (DECLARE (SI::C-GLOBAL)) (* X X)) ;; ECL (SB-INT:NAMED-LAMBDA SQR (X) (BLOCK SQR (* X X))) ;; SBCL My advice is don't try to recover definition from the compiled function, which is ideally just a binary blob. Save the definition before the compilation. 
Great talk. Lovely insights into how Shen works. "Hey kids, how'd you like it if someone snuck prolog into your type system?"
I don't understand the question. Since code = data, why do you need to think about code at all? Just find a database that allows OLTP for *just* data.
I was wondering if codebases and databases could converge instead of being separate as they commonly are. If that premise is possible, then does OLTP/OLAP make any sense? * Could we find utility in data mining for algorithms * Would self-testing code+data containers work * Am I just describing older object databases with behaviors along with data? Perhaps its just a naive idea.
Yeah, something like MUMPS or Mnesia, I'm wondering too
Some info about it you can find here: [https://www.pvk.ca/Blog/2013/04/13/starting-to-hack-on-sbcl/] (https://www.pvk.ca/Blog/2013/04/13/starting-to-hack-on-sbcl/) [https://github.com/sbcl/sbcl/blob/master/HACKING] (https://github.com/sbcl/sbcl/blob/master/HACKING) I've only submittet some bug reports. And for me that is what a beginner can offer in a simple way. For contributing I expect a steep learning curve, because many parts of the sbcl code is highly optimized and thus complex. 
Does [Datomic](http://www.datomic.com) meet your needs?
If I understand correctly, Datomic datoms are represented in EDN -- so you're storing data literals. Not sure that's an ideal format for dealing with sexprs, since you lose the ability for the reader to directly ingest them. You'd kind of have to turn the EDN into a data structure, then pull the sexpr out as a string and feed it to the reader. In my mind it'd be somewhat akin to wrapping JSON in XML or something (seen it done). At that point, why not just put the sexpr in any database that's capable of storing text data? If I get what /u/mycall is asking, he's looking for a database that DIRECTLY stores sexprs? Are you looking for the database to actually understand what it's storing?
You might like looking at Oleg Kiselyov's [Typeful symbolic differentiation of compiled functions](https://mail.haskell.org/pipermail/haskell/2004-November/014939.html). And here's my interpretation of pretty much the same thing in [common lisp](https://web.archive.org/web/20080216182353/http://sleepingsquirrel.org/lisp/sym_diff.lisp).
Is the 2016 version of the "State of the Common Lisp Ecosystem" available somewhere?
No.
Like [deleted], I am intrigued. Where/how could I learn more?
Correct, understanding to some degree, as an AST or similar, along with normal database functionality (atomic, transactions, CRUD, etc).
OK -- so that I haven't seen. Might be fun to hack on, though. Couple thoughts: * The CD database is PCL might be a starting point for something like what you're describing: http://www.gigamonkeys.com/book/practical-a-simple-database.html * In terms of the persistence aspect of a database, being able to just save your running image kind of gets you there (?) * There are several Prolog implementations in CL, which have the concept of a "database" of facts and such that can be queried I'm trying to imagine what I'd do with actual Lisp function sexprs if I were sticking them in a database -- and I keep imagining kind of a rules engine sort of thing. I can't think of any (forward-chaining, backward-chaining, rete-based, etc) rules engines written in CL, but I'm *sure* there are some out there. Edit: duh, quick Googling: http://lisa.sourceforge.net/ -- maybe something along those lines is kind of what you're thinking of?
I don't think its naive, its a natural idea that lisp is specially suited for, but I'm not aware of an implementation. A graph database would be a natural fit for loading code into. I'd like to see lisp support for https://srclib.org/
Y'know, considering what Multics was meant to be I wonder if there mightn't be an awful lot we might learn from it …
37% off 39.99? or is 39.99 the sale price?
doh ah well
Sure. That was the idea of Object Databases originally, storing the code and data of objects and classes. Fully ability to retrieve to a working form any object along with all associated code. Persistent pluggable objects if you will. I wouldn't recommend Smalltalk much myself these days. Just an example of having done this for at least a language that made it straight forward in terms of code level read/write and sufficiently deep reflection. CL has both and arguably at a deeper level with MOP. 
There is no such thing as 'lisp dialect'. And scheme, clojure, ... are not lisp.
"there is no such thing as lisp dialect" lisp is a family of programming languages using s-expressions common lisp is the lisp you're thinking of, which is commonly generalized to just "lisp", yet it is not the only "lisp" scheme and clojure aren't lisp, they're lisp dialects, yet common lisp is also a lisp dialect
&gt; lisp is a family of programming languages using s-expressions Instead of citing "common knowledge" which is literally bullshit I would suggest to go and try CL yourself and figure out yourself what is truth and what is not. If you are programmer at heart, you'll grok it and will see things clearly. GL.
You can build it from the source of the latest version using the sbcl you have installed. See instructions [here](http://articulate-lisp.com/implementations/sbcl-setup.html). You can also use [homebrew](http://brewformulas.org/Sbcl) to install. The version is usually fairly recent. I have only installed SBCL once on a mac and I found homebrew the easiest. The following was my emacs org notes: * Install gnu command line tools (c compiler, make, etc) ** Goto website https://developer.apple.com/download/more/ ** login with your appleid ** search for command line tools ** find the lastest version for your osx version and xcode (if you have xcode) ** download and install * Install HomeBrew (a package manager for osx) ** see http://brew.sh/ ** or in the terminal run the command: *** /usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" ** if you have a problem, run the command: *** brew doctor ** I had a problem with git and had to install it manually but my osx version is old: Lion 10.7.5 * Install curl (a tool to download files from the internet) ** brew install curl ** test installation: curl --version * Install Clozure-Cl (A common lisp implementation) ** brew install clozure-cl ** test installation: ccl64 --version ** do not use ccl as it is the 32 bit version * Install SBCL (A common lisp implementation) ** brew install sbcl ** test installation: sbcl --version 
Unfortunately the app store version will always throw up a GUI listener, but its an OK way to get a CL installed for beginners. http://stackoverflow.com/questions/9611771/clozure-cl-on-mac-os-x-get-rid-of-the-gui
Thank you. I originally tried homebrew but it got stuck on a make script. I just updated my version of homebrew and it works now.
I think you can still get Clozure Common Lisp and its whole IDE on the Mac App Store: http://itunes.apple.com/us/app/clozure-cl/id489900618?mt=12 
Is chicken good for going through SICP?
I remember this book vaguely. Unfortunately I cannot remember the dialect it used, but in case it *was* MACLISP, that's available on ITS, which is downloadable from [The Incompatible Timesharing System wiki](http://its.victor.se/wiki/). I did find [LISP: An introduction and some great programs (1979)](http://paperity.org/p/19031552/lisp-an-introduction-and-some-great-programs) by the same author as Let's Talk Lisp, which should be of interest to many of you here. 
That's awesome! thanks for the example as well!
I run ccl from trunk. Its not all that hard. post questions here.
Sounds mostly appropriate to me.
I think it's pretty neat. 
That is really cool.
Cool! I did something similar here: https://github.com/eugeneia/erlangen/blob/master/distribution/protocol/buffers.lisp#L1 Edit: I am posting this since its only 140 lines of code, and only implements a minimal set of primitive types. Hence, it might be useful for research purposes. :-)
May I ask what you use to generate documentation for your lisp packages? It looks neat. I know it's pdflatex at the sink, but more details re: mk2 -&gt; ?? -&gt; tex would be more than welcome.
There's nothing in /u/understanding23's comment except opinion. He starts of with "It looks terribly overengineered." Since he doesn't explain why he thinks the code is "terribly overengineered" (in fact he doesn't even go as far as to say it *is* overengineered, it merely "looks" that way), all I can do about the complaint is to disagree that it's overengineered in any way. Then he complains that the code is "not easy to read". I find it as easy to read as any other project I've downloaded from Quicklisp, so all I can do there is disagree again. If he has any factual issues with the project as opposed to opinion-based ones, he is of course welcome to file an issue on GitHub. And now, on to your comment: &gt;Announcing it to the world means you think it is ready, and with your name on it, future clients and/or employers will look at it. I can't think of even one open-source project that wasn't released until it was 100% ready for prime time, except if it had funding behind it, such as all those university-funded Lisp and Scheme implementations. Even Linux itself was initially released as a work-in-progress in far-from-ready-to-use condition. It is unreasonable to expect anything more from a one-person project. &gt;If you only care about what you are paid for It isn't that I don't care about this project because I'm not paid for it. The fact that I'm not paid for it means that there are always economic pressures pulling me away from it. It is unreasonable to expect a completely unfunded project to have a full-time developer working on it. I am unable to dedicate the amount of time I'd be able to put into it if I didn't have to stop and go do something else for money. 
Looks nice; I noticed https://github.com/motersen/pits as well - how do the two versions compare and did you find the Scheme version easier to work with or why the switch?
Btw. I'm maintaining and accepting PRs at https://github.com/Ferada/binary-types, if there's something to fix. Now, the one thing I've missed so far is C-compatible bitfields, i.e. with specific widths and the exact same padding (as GCC/... produces); it's more important for CFFI (e.g. GTK has a nasty habbit of using this for some structs), but would of course also be nice for these kind of libraries.
Be more gentle next time, please? I often got (still get) frustrated by the tone of the Lisp community. Its really not in my spirit to be used as an argument for this tone.
Note that my HTTP server is a practical joke, maybe a work of art if you are being generous: its HTTP 1.0 only, and emulates ed(1) error messages. Its main design goal is to be practically usable with telnet. I never expected anybody to run it, and I don’t think anybody does (well, except me of course). It surely has lots of bugs, still. If you look at serious HTTP servers you will see serious code, which usually can not afford this kind of simplicity. If I don’t like the code for a feature, I just drop it. Heck, I just dropped support for implementations except CCL, because I didn’t like the portable code.
Not only have I taken the time to go through your code and evaluate it, but I also offered what I thought was good, honest advice from the pov of someone who might have used your project: + Reduce the code footprint and simplify + Document and then document some more When I look at potential github projects that I can use in my job or in my personal consulting business, on average I spend less time evaluating them than I did for LISP-BINARY. **First impressions** count, more often than not, a quick glance at the code will tell me everything I need to know in order to either discard that project on the spot as rubbish or devote more time to look at it in depth. I shared my findings with you, which is a **luxury** these days, and you should be grateful for receiving that much yet you remain stand-offish and dismissive. I will thus fully agree with drewc (author of smug and a wise person in general) and put this thing to rest. 
Well, it works reasonably well for me non the less. ;-) I will try to give some general advice, since you seem genuinely interested, even though I did not look at the code (take with salt). First off, don’t take the criticism in this thread too personal/dearly. Words are cheap. Imo the primary quality of a program are its features (usefulness to the user). If the program does 100% of what you want it to do then there is no real need to ever touch it again, eh? Chances are though, that there will always be bugs (e.g. ~90% feature complete approaching, but never quite reaching, 100%). So in order to make the work leading from 90-99% pleasant we want code to be “maintainable”. Note that this might not only affect yourself, since someone else might fork the project etc. They will be happy too! :) I usually write a version that works first, which is usually not very readable, and of course contains bugs. When I have a “working” version (e.g. passes the—incomplete—tests) I commit it to be able to go back to the original functionality. This is important for me because otherwise I will loose track of what the functionality of the original “ugly” version was, and risk loosing some of that functionality during the refactor. Then I try to: - make the program as obvious as possible (there is code so simple that it obviously contains no bugs, and code that is so complex that there are no obvious bugs, we want the former) - reduce the number of components needed to be understood to understand any given component (isolate complexity, e.g. if there is a complex generic algorithm in a specific function it might make sense to factor out the generic algorithm and call it from the specific function, so to say “this specific function uses this generic algorithm. If you understand the API of the algorithm, you don’t need to understand its implementation to understand the function) - maximize communication of intent, e.g. make it clear to the reader what I am trying to do (a prominent example is CAR vs FIRST, they are equal but CAR communicates that you intend to operate on a CONS, while FIRST communicates that you intend to operate on a LIST, e.g. no improper lists are expected, if I call FIRST on an improper list that usually means I have a bug, that is in my code where I try to use CAR/FIRST as described) - subjective aesthetics (e.g. I personally prefer all my symbols to have long specific descriptive names, other schools of thought exist. sometimes a short mnemonic is better than a long descriptive names... I also obsess about maximum line length and formatting, but I believe I am compulsory in that regard) The most powerful strategy I know to write nice code is “bottom-up design”. In this strategy you *imagine* how your program would look in a perfect world, and then you create that world from the “bottom up”, so your beautiful imagination actually becomes reality. Example: imagine MAPCAR did not exist, and you were writing a lot of FOR IN loops that processes a list and returns the results as a list, you might imagine “hey my world would be better if I could simply write (MAPCAR &lt;operation&gt; &lt;list&gt;), the code would be simpler because I would save the mental overhead of parsing all the LOOPS” and write MAPCAR so you can separate the &lt;operations&gt; from the algorithm (MAPCAR). Basically, identify the tools you need make the solution look easy (I usually write the imaginary code first), and then create these tools and solve the problem using them. Instead of figuring out how to write nice code given what you have, you figure out what you need to write nice code. Finally, its important to note that you can also get lost refactoring the code, loosing sight of what you actually want to solve. Its important to know when to stop wasting time on superficial details, and focus on the problem. I surely wasted a lot of time rewriting functions, sometimes I even made them worse, or at least spent more time than justifiable on style.
[For those wondering what TXR even is.](http://www.nongnu.org/txr/) 
This is just an arbitrary omission. For instance nthcdr is also not a place. In TXR Lisp, I made it a place. I didn't make last a place. Oops! It's on the TODO list now for the next release. The last function is just a way to get at a particular cdr field; there is no inherent reason why it cannot be an accessor which denotes that field as a place. If it doesn't exist it's because it not existing isn't causing a problem for anyone. Now, let's briefly examine how nthcdr works as a place: 1&gt; (sys:expand '(set (nthcdr 42 blah) t)) ;; no setf or setq in this dialect, just set (let* ((#:g0146 (cons () blah)) (#:g0147 (nthcdr 42 #:g0146))) (sys:rplacd #:g0147 t) (sys:setq blah (cdr #:g0146))) A subterfuge is pulled here to cons up an extra item to the front of the list, and then work with the cdr of the nthcdr i-th cell. Finally, the list place itself is replaced by the cdr of this list! What this means is that if we do; (set (nthcdr 0 var) new) it is equivalent to (set var new) The zeroth cdr is the object itself. 
Let's look at write-bytes: (defmethod write-bytes (buffer (stream bit-stream) &amp;optional bytes) (setf bytes (or bytes (length buffer))) (if (and (integerp bytes) (byte-aligned-p stream)) ... What is the arglist? Why is the class for buffer not specified? What is bytes? Is it a sequence of bytes? One byte, many bytes? Is it the number of bytes in buffer? Is it a byte number specifier (number or something else)? It seems that integers are allowed. What else? What purpose have the optimize statements in the code? The whole code has debug=0? Why?But some code has debug = 3? Why? In read-bytes What is the intent of this code? Why isn't it abstracted? (and (listp element-type) (= (length element-type) 2) (numberp (second element-type))) In open-binary: the argument NIL for if-exists or if-does-not-exist is differently interpreted from CL:OPEN In get-enum-value and following: code duplication to find an enum definition. In decode-ip-addr: (defun decode-ip-addr (raw-msb) (declare (type (simple-array (unsigned-byte 8) (4)) raw-msb)) (with-output-to-string (*standard-output*) (format t "~{~a~^.~}" (loop for byte across raw-msb collect byte)))) Why output to a string, rebinding standard-output? FORMAT NIL creates a string. If you would want to use a string stream, provide some new name as the stream name, don't rebind standard-output. You also use two loops to create the output, one LOOP and another one inside FORMAT. array-pop: does not check an empty array. expand-defbinary-type-field looks a bit too large. ;-) and so on...
By the way, that behavior of my nthcdr place is sensitive on whether the original is a place. If the list doesn't come from a place, the implementation is different, and assigning to the zeroth cdr is unsupported: Not a place: 2&gt; (sys:expand '(set (nthcdr 42 (some-func arg)) t)) (let ((#:g0173 42) (#:g0174 (some-func arg))) (let ((#:g0176 (nthcdr (pred #:g0173) #:g0174))) (sys:rplacd #:g0176 t))) Place: 3&gt; (sys:expand '(set (nthcdr 42 (car arg)) t)) (let ((#:g0179 42) (#:g0180 (car arg))) (let* ((#:g0181 (cons () #:g0180)) (#:g0182 (nthcdr #:g0179 #:g0181))) (sys:rplacd #:g0182 t) (sys:rplaca arg (cdr #:g0181)))) In the not-a-place case, we take the predecessor of the index to determine the parent cell, so we can rewrite its cdr. A negative value blows up inside nthcdr. Why sys:rplaca and sys:rplacd? These versions return the stored value, not the cons, so they help produce the correct result for the place-manipulating form with less code.
Had no idea this was still alive..
Not a good idea to give up after just 35 years. 
The only implementation recently dead is CLISP. Everything else is getting updates. Some less frequently than others. Corman recently came back from the dead, too.
In my experience, this kind of work is not transferrable. People work on CMUCL because they know of both CMUCL and SBCL and still prefer CMUCL. If they did not work on CMUCL, they would work on something entirely different - it would not turn into hours worked on SBCL at all.
It is not.
Wasn't there a game they made before Jak &amp; Daxter that was available for Linux? I remember playing it, and hearing that it was written in some Lisp dialect, but now I can't find anything that mentions it which makes me think I might be going crazy.
Crash Bandicoot (which was on PS1) was written in GOOL (Game Oriented Object Lisp), the predecessor to GOAL. Perhaps you played an emulation of that, or are confusing it with a similar game? 
Some aspects of this sort of stuff are along the same theme as Henry Baker's COMFY-6502: http://josephoswald.nfshost.com/comfy/summary.html There are other "assembly in Lisp" languages out there. 
Not sure if you're thinking of Abuse, a late 90s platformer released on multiple platforms by Crack dot Com. It was partially programmed in lisp - a custom dialect I think. https://en.m.wikipedia.org/wiki/Abuse_(video_game)
Sorry for my late reply. I'm glad you ask. Getting an impression of picolisp was nice and I liked the native database integration because it helped putting something usable together really quickly but I never really understood it, especially the database procedures–I never knew which ones to use in which order and what they actually did, the documentation was really unclear about that–and I found the syntax really counter-intuitive. For example you are supposed to use capital letters for variables but `T` is reserved for `#t`/`t`. I also didn't like the literal minimalism that manifests in the reduction of `defun`/`define` to `de` and the absence of the `lambda` keyword which results in expressions like this one: '((F) (untag-file F @)) It might appeal on first sight but it actually obscures the source code by making it very hard to spot different expressions like procedures. With the basic background in Prolog that I acquired in the meantime I might finally be able to make sense of one of the filters that picolisp offers but I really don't feel like looking into it again. Anyway, the filter functionality was the reason to switch. But the switch to scheme brought many more advantages. I always liked its clean syntax, the community is obviously bigger and Gambit offers a lot of functionality, is really well documented (as is scheme itself) and fast. Plus, I can switch implementations to choose the one that is best suited for a particular project. Oh, and i also always wanted to prove to myself that I could write a working, practical program in scheme.
I think that's what I was thinking of! I'm not sure why I thought it was by the Naughty Dog guys.
Here is a CLISP task that could result in a new release: how about converting all those .d files to C99 syntax? CLISP's .d files are written in a dialect of C that allows mixed declarations and statements. A utility called "varbrace" processes these to .c files which conform to C90 and don't mix declarations and statements. ISO C 99 standardized mixed declarations and statements 17 years ago. Before that, it was an extension already available in some mainstream compilers (including GCC) and not to mention the C++ dialect. It would be nice for CLISP do ditch the varbrace hack. Or, heck, keep it there for portability to old compilers, but at least rename the darn files from .c to .d, and don't actually use varbrace when the compiler supports C99. Perhaps the .d files are highly compatible with C99 already so there isn't much conversion to do? 
I think it actually raises an interesting question: How different do the semantics of a language have to be to not count as a kind of lisp, even if it uses Sexps for syntax?
http://wiki.c2.com/?LispSchemeDifferences From what little I admittedly know about GOAL, it sounds to me to be more like (Common) Lisp than Scheme, unless GOAL is a Lisp-1 &lt;http://stackoverflow.com/questions/4578574/what-is-the-difference-between-lisp-1-and-lisp-2&gt; and that is what is meant by GOAL being syntactically similar to Scheme as opposed to the more general term, Lisp. 
Somewhat interesting: there was a bug in the Lisp code of Abuse which would crash if fired up on ARM Linux. Someone fixed it and ported it over to the [GP2X!](GP2X: http://dl.openhandhelds.org/cgi-bin/gp2x.cgi?......%20%3C/td%3E%3C/tr%3E%3Ctr%3E%3Ctd%3E%C2%A0%3C/td%3E%3C/tr%3E%3Ctr%3E%3Ctd%3E%3Cb%3EDate%20d,0,0,0,46,2688)
Andy Gavin, the creator, has bits and pieces on his web site. * http://all-things-andy-gavin.com/2011/03/12/making-crash-bandicoot-gool-part-9/ * http://all-things-andy-gavin.com/goal-test/
Only a list (setf *foo*) and a symbol *foo* are allowed as a function names in standard Common Lisp. In ZetaLisp I have seen other special list names, too. 
It's easy to use lists to represent names: ;; Here we use EQUAL for comparing lists; see CLHS. (defparameter *mapping* (make-hash-table :test 'equal)) (defun value (name) (gethash name *mapping*)) (defun (setf value) (new-value name) (setf (gethash name *mapping*) new-value) (setf (value '(a 5)) 42) (value '(a 5)) ;; ==&gt; 42 The concept of naming things is quite useful in programming and because there many reasonable representations for names, the term "name" is highly ambiguous. You seem to have conflated the poster's general remark about the possibility of representing a name as a list with the specific example he gave, where a name may be a certain kind of list.
That's more or less what I was getting at when I said the answer must have been meant in a more abstract sense, and I take your point that something like your hash table implementation has no less claim to the title "name" (and so is no more "abstract") than something used in `defun` or `set`. Thanks for nudging my perspective in that direction.
Not only that, it's also very ugly and hard to read. Not elegant at all.
Of course nobody, but only for the useless use of defun. (loop for n from 1 to 25 for f = (mod n 3) for b = (mod n 5) collect (format nil "~[fizz~]~[buzz~]~[~:;~d~]" f b (* f b) n)) Ah, work of art! :)
Is this supposed to be a joke?
If I asked someone to write FizzBuzz during an interview and they produced that, I wouldn't be hiring them. Solutions like that are nothing more than mental masturbation, and I don't need that jizz in my source tree.
I thought about that, I like it, but for me my fizzbuzz function is the real workhorse, the rest is just to apply it toa series of numbers. I guess is more philosophical. ;) 
Translate the comments from german, too?
(The CL-style) `if` is imperative because it controls evaluation, which implies an unconditional control transfer around some computation to be skipped. If can be used functionally, when we care only about the resulting value, and the behavior is the same regardless of the evaluation of the constituent forms. In TXR Lisp, I made `if` have a function binding, so it can be applied; in that situation it doesn't control evaluation but is a pure function. We can map over `if`: 1&gt; [mapcar if '(t nil t) '(0 1 2) '(a b c)] (0 b 2) `and` and `or` are similar. User code, too, can define both a macro binding and a function binding for the same symbol to do the same kind of thing. Furthermore, that neatly provides the functionality of `define-compiler-macro` without having to invent a new, separate kind of macro with its own defining operator. 1&gt; (defun square (x) (* x x))) square 2&gt; (defmacro square (arg :form f) (if (constantp arg) (eval ^(* ,arg ,arg)) f)) square 3&gt; (square 3) 9 4&gt; (let ((x 3)) (square x)) 9 5&gt; (macroexpand '(square x)) (square x) 6&gt; (macroexpand '(square 3)) 9 We can remove the macro binding while retaining the function or vice versa: 7&gt; (mmakunbound 'square) ;; not in CL square 8&gt; (macroexpand '(square 3)) (square 3) 9&gt; (defmacro square (arg :form f) (if (constantp arg) (eval ^(* ,arg ,arg)) f)) square 10&gt; (fmakunbound 'square) square 11&gt; (macroexpand '(square 3)) 9 12&gt; (let ((x 3)) (square x)) ** (expr-12:1) square does not name a function or operator If you're using macros-over-functions in this way of course you ensure that the expansion has the same semantics as the function call. But you're free to deviate from that, as exemplified by the built-in `if` and `and`, whose arguments are all evaluated when they are applied indirectly. 
That's some geeky use of format strings there! This is probably closer to the example: (require :series) (in-package :series) (defun cat (a b) (concatenate 'string a b)) (defun choose-str (a b) (if (and (stringp a) (string= a "")) (if (numberp b) (format nil "~D" b) b) (if (numberp a) (format nil "~D" a) a))) (defun fizzbuzz-n (n) (let* ((fizzes (series "" "" "Fizz")) (buzzes (series "" "" "" "" "Buzz")) (words (map-fn 'string 'cat fizzes buzzes)) (numbers (scan-range :from 1))) (collect 'list (subseries (map-fn 'string 'choose-str words numbers) 0 n)))) 
I like TXR from what I've seen in the documentation, I like the pattern matching capabilities, and having a lisp is always a plus.
&gt; (The CL-style) if is imperative because it controls evaluation, That's not what imperative means. Imagine that you had an `if-function` that simply returns the second or the third argument depending on if the first argument was truthy. I can't implement such a function without something that probably uses `if` underneath, but assume that we have such a function. Then, a CL-style `if` could be implemented by the following macro: (defmacro if (condition true-clause &amp;optional false-clause) `(funcall (if-function ,condition (lambda () ,true-clause) (lambda () ,false-clause)))) So that makes a CL-style `if` indistinguishable from a purely-functional `if`. It's only a matter of syntax and not semantics. 
&gt;If this version of the function breaks the program, it means that the program has additional requirements on the function's implementation. Your version of `if-function` has additional type requirements on its arguments. My if-macro will `funcall` whatever gets returned as `th` or `el`, so if `if-function` calls those functions and returns their *result* instead, then my if-macro would fail if the *result* ended up being something other than a function. &gt;Those requirements exist in support of impure behavior: the sequencing of visible effects and such. Sequencing of computation is not impure behavior. I think you are confusing lazy evaluation with purity. 
A stack language does offer a way to get by without lambda, and that does simplify implementation, while allowing a huge amount of flexibility with arguments and return values. I also appreciate having variables as a separate feature, having struggled with too much obscure stack manipulation in badly-written PostScript. I was wondering why a stack language would not have more stack primitives, though. At least PostScript's index (get nth item from top) and roll (rotate top n items by k steps). But considering the difficulty of reading such code, maybe it is for the best that the programmer would need to assign the two top values to variables to access the value beneath (converting the whole stack to a list and using list manipulation seems unlikely to be efficient).
Whether or not impure in itself, sequencing exists *in support of* impure behavior. There is no reason to use a construct which imposes sequencing, if there is no impure behavior. For example, in "pure Lisp" coding, we don't use `progn`, whether explicit or implicit. The only reason to write `(progn a b)` is that `a` produces some necessary effect. Either externally visible, or necessary to the correct evaluation of `b`. Sure `(progn 1 form)` might not be considered impure, but it's a useless verbiage that can be replaced by just `form`. Of course, we can use `cond` and its derivative `if` in "pure Lisp", but not in a way that demands sequencing. We use them in such a way that if all clauses of the constructs were to be evaluated, the result would still be the same. Lazy evaluation refers to a situation in which values are determined as late as possible. Programs that depend on lazy evaluation do so for the reason that it allows certain computations to be expressed, like the construction of infinite structures. If eager evaluation is substituted for lazy evaluation, it doesn't change what is computed in all cases in which the resulting program still terminates. However, it may introduce non-termination, due to cycles in the evaluation graph, which are forced. In purely functional languages, lazy behavior is also (ab-)used to sequence side effects such as I/O; that is neither here nor there. Obviously, when that happens, the program is no longer pure. 
&gt; There is no reason to use a construct which imposes sequencing, if there is no impure behavior. Yes there is: In an eagerly-evaluated language, you can't write code that generates an infinite list and then expect that to be okay because you only use the first few elements of that list. In a strict language, the whole list is generated *first*, and only *then* can elements be drawn from it, and this fact must be accounted for when writing the code. There are other cases where the memory and time requirements of a program are determined by the order in which expressions are evaluated, even if the final value returned would be the same either way. Consider some tree-walking algorithm. Maybe it contains a section that looks like this: (cond (some-condition (call-self-recursively foo)) (some-other-condition (call-self-recursively bar)) (a-third-condition (call-self-recursively baz)) (t nil)) If `if` is a regular function, in a strict language that means that all three calls to `call-self-recursively` are evaluated for every node in the tree. If this is a large tree and each of those cases follows a different branch, and each recursive call will in turn call itself three times until the leaf nodes are reached, the function would consume all available memory if `cond` is a regular function, but not if `cond` is a special form with what you're characterizing as "impure behavior". The only case when you can completely ignore the difference between a function and a special form is if the language is lazily evaluated. Then it's okay for `if` to be just a function, since the non-matching cases won't be evaluated because their values will never be needed. 
&gt; In an eagerly-evaluated language, you can't write code that generates an infinite list and then expect that to be okay because you only use the first few elements of that list. [... etc] This is covered where I wrote: *"Programs that depend on lazy evaluation do so for the reason that it allows certain computations to be expressed, like the construction of infinite structures."*
Although lists are not as versatile as lambdas because you can't have closures, I don't see the point in closures in a language like this. 1. 9 times out of 10 you could probably just add your value to the top of the list with "pair" (similar to cons in lisp) and it will act as the closure-type lambda you want. But also 2. There are no local variables or local stacks. The way you simulate local variables is by popping the variable off the variable stack when you're done using it. I don't see how, without over complicating things, you could give each lambda its own environment with its own argument stack, variable stack and function stack. The point of stack languages is there's one stack (or one set of stacks) that's used with every operation.
no, that's a separate patch. great article though!
It's a nice little language! Reminds me of the Joy language. I played with it a bit, writing my own variant in Common Lisp. (defun compute (dict data code) (labels ((push-code (quot) (setf code (append quot code)))) (loop (when (null code) (return `(running ,dict ,data))) (let ((expr (pop code))) (cond ((stringp expr) (push (intern (string-upcase expr)) data)) ((null expr) (push expr data)) ((not (symbolp expr)) (push expr data)) (t (case expr (def (let ((name (pop data)) (proc (pop data))) (setf dict (remove-if (lambda (binder) (eq (first binder) name)) dict)) (push (cons name proc) dict))) (undef (let ((name (pop data))) (setf dict (remove-if (lambda (binder) (eq (first binder) name)) dict)))) (dict (push dict data)) (clear (setf data '())) (dup (push (first data) data)) (pop (pop data)) (swap (let ((b (pop data)) (a (pop data))) (push b data) (push a data))) ((+ - *) (let ((b (pop data)) (a (pop data))) (push (funcall expr a b) data))) (if-cons (let ((then (pop data)) (else (pop data))) (push-code (if (consp (first data)) then else)))) (if-equal (let ((then (pop data)) (else (pop data)) (b (pop data)) (a (pop data))) (push-code (if (equal a b) then else)))) (shift-left (let ((right (pop data)) (left (pop data))) (push (cons (first right) left) data) (push (rest right) data))) (shift-right (let ((right (pop data)) (left (pop data))) (push (rest left) data) (push (cons (first left) right) data))) (cons (let ((first (pop data)) (rest (pop data))) (push (cons first rest) data))) (uncons (let ((list (pop data))) (push (rest list) data) (push (first list) data))) (! (push-code (pop data))) (print (format t "~{~(~:s~) ~}~%" (reverse data))) (halt (return `(halted () ,data))) (t (let ((binder (assoc expr dict))) (when binder (push-code (rest binder)))))))))))) (defun read-compute-loop () (let* ((dict '((first uncons swap pop) (rest uncons pop) (shift-left* (pop) (shift-left shift-left*) if-cons) (shift-right* swap shift-left*) (reverse () shift-right*) (append swap reverse shift-left*) (premap (cons) append (swap) swap append append (uncons swap) swap append) (map dup (map) swap cons swap premap () swap if-cons) (factorial dup 0 (dup 1 - factorial *) (pop 1) if-equal) )) (state `(running ,dict ()))) (loop (destructuring-bind (mode dict data) state (case mode (running (setf state (compute dict data (list (read))))) (halted (return 'halted)))))))
Depends on your distribution. For example, sbcl-1.3.10 is available on debian sid.
Why not Parenscript?
There are plenty of reasons, but the main one being that I didn't make the decision with regards to the client technology used. I only wrote some of that code, but another person wrote most of it. I am responsible for the server code, which is why I spend most of the talk discussing that part, and only very briefly touch on the Clojurescript part.
Ah, I thought there would be technical reasons you'd share with us. Thank you for the talk itself though. :)
ClojureScript is very *very* good clientside because of something called "Figwheel", which allows you to build and edit things in your project without ever having to reload the browser. And because of Clojure's philosophy for making everything immutable, reloading things as they change brings very few issues with it. Also, ClojureScript's source maps (Which allow for debugging Clojure in web inspectors directly) and compilation (Which produces surprisingly fast JavaScript) is ridiculously good. [Here](https://www.youtube.com/watch?v=j-kj2qwJa_E) is a pretty good talk on some of the things that make it really nice. (There is a spike of "oh wow" at around the 8 minute mark)
That stuff is indeed pretty cool, and with OM you can make changes to global state from the REPL and have the GUI immediately refresh.
optimization: better GC performance in the presence of many threads. (patch by Ilya Perminov, #1339924) https://bugs.launchpad.net/sbcl/+bug/1339924 I just noticed that this patch was from D-Wave!
Bash is used for file management. Imagine having to escape every URI/path with `#p` and quotes - I would hate it. There are also parentheses and having to type `(ls)` instead of `ls` all the time is annoying as well. This goes on for almost all features of bash (imagine e.g. `(pipe x y)` instead of `x | y`). So yeah, bash is messy for scripts, but it is very practical for "regular" use. Regarding the immutable file database: Why would one want this? The files need to be written to disk anyway and immutability (for me) implies having to rewrite the entire filesystem after a `touch foo`, and having to keep the entire FS in RAM. Maybe I misunderstood your idea, but it does not seem to be a good one...
Structural sharing could help with the immutability bit.
You might want to try Urbit (/r/urbit) - it offers much more and is an ancient Martian technology ported to Unix. ;-)
Another downside: windows. 
I can tell you why I clicked the down arrow. This is a post in /r/lisp with a question about using a lisp implementation as a shell in POSIX. Urbit is not Unix, not POSIX, not a command shell, not bash, and first and foremost (though placed last in this sentence for dramatic effect), not even related to lisp. I am not sure how this random post benefits you, but offtopic it is, nonlisp it is, and down votable, in my opinion, 'tis as well. Make sense to you?
esh http://web.mit.edu/jhawk/mnt/ss.b/esh-0.5/doc/esh.html probably another esh: https://3e8.org/pub/scheme/doc/lisp-pointers/v5i1/p247-rose.pdf
If someone wrote a shell-specific Lisp REPL, they could have the shell REPL make top-level parentheses optional. The reader for the shell REPL could translate `pipe x y` into `(pipe x y)` automatically or `ls "foo"` into `(ls "foo")`, which would help with brevity. It would be pretty simple rule, too. If the first character is `(` it wouldn't insert parentheses and if the first character is anything else (except maybe `;`) it would. This would only be done at the REPL level, not when used as a scripting language. The main flaw is that it would be harder to see the value of variables in the REPL, but having to type `print *x*` instead of `*x*` is probably worth the convenience of almost having sh-like syntax at the REPL. If the shell did this, then the main remaining annoyances would be having to quote strings/paths and the lack of some infix syntactic sugar like `|` and `&gt;`.
Shell compatibility could be solved by writing two shells. One would be a faithful `sh` interpreter written in Lisp and the other would be a Lisp with some slight reader changes and some automatically loaded packages to be used as a very different shell language. That way you can support legacy shell scripts and have an interactive Unix `sh` shell that could be configurable in Lisp, but you could also use Lisp as an incompatible interactive shell without having to borrow too many ugly features from `sh`. A few attempts at a Lisp shell try to do both and that results in a really ugly hybrid language. The problem with trying to replace `systemd` is if there are [applications that assume that `systemd` is going to be there](https://en.wikipedia.org/wiki/Systemd#Integration_with_other_software).
I think the most successful Lisp-shell hybrid so far might be Emacs's [eshell](https://www.gnu.org/software/emacs/manual/eshell.html). You are limited to redirecting text, but you can redirect directly into Emacs buffers or other virtual devices, such as the clipboard.
Thank you very much for the response. I'm was very impressed with the talk and the project and the way the REST interface seems to work!
Of course it makes sense, thanks.
These sessions are not recorded by any chance, are they?
Do we still want/need the ILC 2014 link there?
For that matter, the shell could auto-insert `()` on the command line and position the cursor between them. Want to evaluate a variable, just delete them.
There are two different kinds of AI: symbolic AI and neural networks. To do symbolic AI, you really need a language which supports symbols (which stand for words, concepts, etc. - anything you can give a name to) as a fundamental data type, and performs logical inferences, so your languages of choice are Lisp and Prolog. In neural networks, you're manipulating vectors and matrices of floating point numbers. For that, C/C++ are perfectly adequate, with Lisp's syntax for arithmetic operations being somewhat clunky in comparison (though it can be changed by writing the appropriate macros). Prolog's unsuitable for this. Until relatively recently, neural networks weren't capable of very much, while symbolic approaches had a modest amount of success, so AI was done in Lisp (or domain-specific languages built in Lisp) and Prolog. What changed that was the AI winter, which killed off most of the symbolic AI research and the Lisp Machines, and (more recently) the collection of humongous amounts of data and the use of graphics chips for fast processing of vectors and matrices, which made neural networks with many layers feasible. I expect symbolic AI will make a comeback when the deep learning hype dies down and it's realized that neural networks aren't suitable for everything. Maybe then Lisp will be in demand again. 
[Image](http://imgs.xkcd.com/comics/lisp.jpg) [Mobile](https://m.xkcd.com/224/) **Title:** Lisp **Title-text:** We lost the documentation on quantum mechanics\. You'll have to decode the regexes yourself\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/224#Explanation) **Stats:** This comic has been referenced 120 times, representing 0.0891% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_d9t7lg3)
Tom Van Vleck helped me download the source code for Multics Emacs. I'm not going to try building it, but it's good to know it's still there.
I look forwards to hybrid AI approaches with deep learning and symbolic techniques. I bet that already exists. 
&gt; Lots of software is hardwired to assume a shell that's at least vaguely Bourne-compatible. This is a presumption held by many, but no - it's not true. Any pre-existing shell script which is executed as a script, with a `#!&lt;some-shell&gt;` will still work **exactly** the same as before. Software which passes around snippets of posix-shell code, and blindly executes it against what is assumes is a posix shell? Very little of that exists. Very little. And for any which do, its an obvious bug which is easily fixed (`bash -c '...'` vs `'...'`). Those of us who have used non-posix shells, like rc (or fish), etc have found this out for ourselves. I've used rc, jimtcl and gauche scheme (the latter two with simple "front-end" libs of my own) as a main shell for periods of time. It works. Its a bogus argument that I've never understood. If you're making a replacement for a posix shell, it doesn't have to be posix-compatible itself. Feel free to experiment with whatever syntax you think works. bash, sh, dash, mksh or ksh are still installed in your filesystem, and scripts which need them will still use them, regardless of what command shell you're using it from.
It's not a bogus argument when I've seen problems first-hand after setting my shell to something like a programming-language-specific REPL (most recently with Julia). Window managers and other programs that launch other programs tend to assume that `$SHELL` will always accept a `-c` argument, which very rarely has the expected behavior outside of a traditional `sh` or `csh` compatible shell (unless for some reason the language designer anticipated this potential use-case and provided a `-c` that does behave expectedly, but this is exceedingly rare). If it works for you out-of-the-box, then great. That doesn't always happen, though, so some fiddling often needs to happen (usually by manually setting `$SHELL` to `/bin/sh` in the problematic program's environment).
So you're using a bunch of programs which blindly fork's and exec's: &lt;current process environment's value for 'SHELL'&gt; -c 'some posix sh code' Which programs are those? Genuine question. If any exists, its a horrendous bug, which is easily fixed upstream. 99(+ .999) % of the time, they'll just fork and exec `sh -c '....'`. Or if they have bash'isms mixed into their posix, then `bash -c '...'`. None of which are affected in the least by your choice of command shell. The only programs I've seen which are stuck to a particular shell is stuff like midnight commander, which spawns a bash subshell and pipes input to it (so it can keep the pwd of the sub shell in sync with mc's current directory).
&gt; Which programs are those? It's been awhile. Whatever window manager I was using at the time in that setup (I think it was Openbox, or maybe XMonad).
"Should" is the keyword there, though. Just saying. It's a potential gotcha that's worth anticipating when trying to transform a typical Unix into a hacked-together Lisp machine.
Honestly, no. Its not even worthy of the label "potential gotcha". It's using the point, on the top of a small pin, in a giant haystack, to somehow argue against, I dunno, not sitting on the haystick (even with a padded cushion).
I think some sort of hybrid approach, with neural networks being used for perception - vision, speech recognition, etc., and symbolic AI approaches for higher level cognition - natural language understanding, reasoning, common sense - is the way forward. This is not a popular viewpoint though. 
&gt; Neural networks are closely related to statistical approaches, and both stand apart from symbolic AI. That is arguable, but even then that doesn't mean that all statistical approaches are neural networks, only that neural networks have a statistical interpretation. &gt; Both neural networks and statistical learning rely on "big data", and statistical learning is usually similarly opaque w.r.t. how it arrives at its output. That also isn't true. Some statistical approaches are designed to deal with very small amounts of data ([this blog post](http://www.sumsar.net/blog/2014/10/tiny-data-and-the-socks-of-karl-broman/) is a good introduction to one of them), and a lot of statistical models are designed to be interpretable (although it becomes harder the bigger your model is). There is also a lot of research going on in one-shot learning (being able to learn something with only one example) for deep neural networks. &gt; I haven't worked on non-symbolic AI but I assume that while Lisp could be used for it, it generally isn't. Others here might confirm that, or correct me if I'm wrong. Yeah that I agree with completely. There are some ML libraries for Clojure (mainly due to the fact it's on the JVM) but besides that I haven't seen anything, there is just no advantage in using Lisp for numerical computations afaik.
&gt; Yeah that I agree with completely. There are some ML libraries for Clojure (mainly due to the fact it's on the JVM) but besides that I haven't seen anything, there is just no advantage in using Lisp for numerical computations afaik. Apart from Common Lisp having bignums, rationals and complex numbers, and seamless conversion between different numeric types. Some implementations have bigfloats (arbitrary precision) as well. 
TL;DR?
There are couple of books if you are interested in the doings in AI of those era, "The Brain Makers" by Nyquist and "Strategic Computing : DARPA and the Quest for Machine Intelligence, 1983-1993" by Roland and Shiman. Highly recommend both.
I think that the "weird scoping side-effects" part mostly comes from interactions between fexprs and dynamic scoping, which was the norm at the time fexprs and macros were in active competition. If you revisit fexprs in a modern language with mostly statically-scoped variables, they turn out much nicer. There have been [good discussions of John Shutt's work](http://lambda-the-ultimate.org/node/4093) on lambda-the-ultimate, where he himself is an active user.
Is Arcadia, the Clojure for Unity3D, permitted?
My understanding of the `$vau` calculus is still pretty limited and I'm still trying to wrap my mind around and understand what programs that it makes easier to express. In a traditional "vanilla lisp" / lambda calculus setting you have two functions `eval` and `apply`. `eval` takes a single S-expression as an argument and `apply` takes two, the function and its arguments as a list. We can imagine adding special forms `$eval/2` (taking a sexp and an environment) and `$apply/3` (taking a function, argument list, and an environment) that do not automatically evaluate their arguments, but do take an additional final parameter representing the bindings that constitute the environment when the evaluation / application takes place. `$eval/2` and `$apply/3` do not appear anywhere in the paper, I'm just trying to get a handle on the concept... I think `$vau` in this case is the "inverse" (I don't know what the actual name for this concept is) of `$apply/3`, the same way that `apply` is the "inverse" of `lambda`. `lambda` introduces an abstraction (not sure what term is for `(λ x . E)`) and `apply` eliminates it. I'm still trying to figure out what exactly explicit evaluation of arguments and passing your environment around really buy you. It superficially reminds me of continuation passing style. We're adding an explicit parameter to function calls to capture something (like control flow) that's normally implicit.
&gt; Unity is proprietary software and thus not recommended. is that for political reasons, practical reasons, or part of the jam rules?
for clojure, there's the [quil](http://quil.info) library.
X-Post referenced from [/r/haskell](http://np.reddit.com/r/haskell) by /u/__buckie__ [Pact: a Safe Smart Contract Language](http://np.reddit.com/r/haskell/comments/5cqpva/pact_a_safe_smart_contract_language/) ***** ^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
Is Arcadia even usable?
"The Brain Makers" by ~~Nyquist~~ Newquist ?
it just works in emacs apparently, though I haven't tried it out. u/spopejoy?
That's not coming yet, but watch out for the next year's "Planning and Learning" track http://icaps17.icaps-conference.org/cfp
`expand-right` was out-golfed by `ginterate`: 1&gt; (take 7 (expand-right (opip `@1*` [dup cons]) "")) ("*" "**" "***" "****" "*****" "******" "*******") Which tied against `mapcar` with `mkstring`: 3&gt; (take 7 [ginterate true (ret `@1*`) "*"]) ("*" "**" "***" "****" "*****" "******" "*******") 4&gt; (mapcar (op mkstring @1 #\*) (range 1 7)) ("*" "**" "***" "****" "*****" "******" "*******") :) Forehead-slap; I'm an idiot: 6&gt; (reverse (conses "*******")) ("*" "**" "***" "****" "*****" "******" "*******") 
Would you have some links? I'd be curious to see how that looks!
Awesome, thank you!
https://github.com/kadena-io/pact-mode hot off the press. 
Thanks. I haven't used processing. I will take a look at this as an alternative to using Arcadia or play-clj.
Why do people say that JavaScript was developed for the web?
I also gave up a while ago after a few tries.
You're not supposed to literally evaluate that. It's an anecdotal/joke-like question. Are you a spammer? No, so the result is NIL. Then invert that by NOT and you get the answer it expects. Hell, it even says explicitly on the page: &gt;Not "unbound variable you" or "undefined function spammer-p"; work with me here.
Lisp was huge at research back then. After the AI winter (when it became apparent that symbolic computation would not lead to true AI anytime soon) Lisp expertise, programmers and tools tried to sell it as the ultimate IDE at a time when programmers were still using an ad-hoc mix of command-line tools and text editors. It competed with Smalltalk, but both eventually lost to Visual Basic and java later... 
So, 2 months time to learn russian.
Hahaha. I'm pretty sure those comments are tongue-in-cheek! :D
It's still an experiment of C# code generation. And not yet macros. Although, it can compile the source into 'working' .net assembly right now ( that you can use with UNITY already ). All of them are primitives &amp; special forms that I made to see how will they fit .NET platform ( attributes, policy, types ). I'm planning to add more high-level functions, and macros (quote, unquote, backquote) after then. And certainly, (first '(new Dictionary&lt;string,string&gt;)) =&gt; new (as a symbol). Because 'new' is currently a primitives to generate equally 'new' keyword of C#.
Is there a MOOC on Russian starting this month?
wow that's really cool. thanks!
Oh, sorry I forgot to explain Dictionary&lt;string,string&gt; is a generic type of CSharp data, where string is key and also value of Dictionary class. I just keep the csharp syntax format to make .net programmer feel familiar. Maybe, it's a bit strange to lispers, I will remember that.
No examples on the project landing page :-(
Linking to https://gitlab.com/eql/EQL5/tree/master/examples from the landing page will halve your bounce rate, I feel. The clock source looks nice. It hints at the pseudo-declarative possibilities from the melding of these two technologies. Specifically the 12 hours marks - (dotimes (n 12). In my opinion examples are better broken out to separate repos, with a README each specifically to show ease of build/launch, which allows complete noobs more easily to say 'this is cool, imma gona write an app in this'. 
I added two links (examples, screenshot) to the Wiki page: [gitlab EQL5 Wiki](https://gitlab.com/eql/EQL5/wikis/home)
I did it. It's almost ready. I'm very sorry it's taking so long.
anyone know shipping costs to europe? not going throught the registration process if it's too high.
Thanks! I could not pass up that sweet sale on the Weitz book.
For some moments, I would call it an Flow-improvement over C# in format, also, I want to make Macros feature available to C# (because it's already good language and easy to use). It give me advantage of quick-sketching the ideas into the sample source code. So I can compile the sample into something executable without worrying about compiling errors and equal typing of C#/.NET system. Certainly, when the sample language is stable and good enough to be used widely, I will replace them with IL code or CodeDom (if it's enough). Plus, doing this transformation let people already feel familiar with C# and Lisp can involve the project, if they like the idea. For now, CSharp will be my low-level foundation, instead of ILAsm.
Rather than a "pure" REPL, you'd be better off building command-oriented interaction around something like the Dynamic Lisp Listener in Symbolics Genera. If you haven't seen it, watch Kalman Reti's demo of the Genera environment on YouTube, and realize that everything shown can be done with CLIM since it implements the concepts of command tables and output records.
Without knowing more, I was under the impression that I could call all of the relevant JavaFX code directly from ABCL, but I'm unclear about the difficulty of using and extending JavaFX classes. This is what the ABCL manual refers to as "Lisp to Java." What you're describing sounds like the other alternative of embedding ABCL/Lisp, which the ABCL manual refers to as "Java to Lisp."
I don't know if you can extend java class in abcl. I know you can do that in kawa. Even if you couldn't extend class in abcl depending on your needs you might not even need to. The widgets and using them should be easy. I think the hardest part will be the parts where in java you would use lambda expression () -&gt; {}. For example when giving buttons the function they do when pressed. When I wrote the app in kawa I think I wrote one small utility class with java just because it was easier mix in some java than trying to write everything in scheme.
As a side note, "Operation completed succesfully" uninformative message is one of Windows quirks, not ECL's. That means that some error has occured, but Windows can't report what's wrong.
This was it! I just had forgotten that I had the 32-bit version of ECL installed; and when I went to update it I didn't even notice. Thanks!
In particular, I just tried SDL2_ttf.dll in both ECL and CCL, and neither were able to load it in, although SBCL could. All could load SDL2.dll and SDL2_mixer.dll just fine. Is there some formatting mischief in SDL2_ttf that makes it difficult to read? Even [lispbuilder-sdl-ttf doesn't support ECL or CCL](http://lispbuilder.sourceforge.net/lispbuilder-sdl-ttf.html#compatibility). NOTE: My plan is to create bitmaps of fonts beforehand, to reduce lib dependencies, so I'm not anxious to have it fixed.
Obviously I've not looked at the relevant code, but that sounds to me like someone is calling FormatMessage with and error code of 0. That can happen when you don't call GetLastError immediately after the API call that has failed. Might be a simple bug to fix rather than blaming it on Windows. You'd get the same behaviour if you called strerror() with errno=0 on posix too. Might be worth looking into anyway. 
I have tried and it loads successfully. Did you place all four DLLs^1 in the same folder (or in the search path)? Since SDL2_ttf.dll depend on SDL2.dll. &gt; SDL2.dll, SDL2_ttf.dll, zlib1.dll, libfreetype-6.dll
This project looks really interesting! OP, do you have any idea how feasible it would be to write Ubuntu applications using this toolkit? Would one be able to just import the SDK and use FFI to use it or would wrappers need to be created for each module?
ps: Is just a trial phase, i have a lot to do, a lot add, and maybe a lot do remake. 
I can get behind the idea of this, especially if macros are usuable.
I did not need any macro until now, is pretty simple, we read a Lisp object (a list), and then just manipulate it following a struct (a parser for keywords) and print it to a file with "format stream"
If anybody has any questions on the implementation, I'm here to answer them.
I never liked the term 'homoiconic'. Code is or can be data is something I would find more interesting. Some code might be executed: CL-USER 36 &gt; (let ((a 20) (b 22)) (+ a b)) 42 If we quote this code, it is data which consists of primitive elements: lists, symbols, numbers. CL-USER 37 &gt; '(let ((a 20) (b 22)) (+ a b)) (LET ((A 20) (B 22)) (+ A B)) We could also put string quotes around it and it would be data - just one string. It's more difficult to use. For manipulating the code, we would need more complicated string operations. CL-USER 38 &gt; "(let ((a 20) (b 22)) (+ a b))" "(let ((a 20) (b 22)) (+ a b))" The execution function EVAL expects Lisp data for code and not a string: CL-USER 39 &gt; (eval '(let ((a 20) (b 22)) (+ a b))) 42 In this case Lisp uses so-called symbolic expressions (a data format with an external representation) to describe data and code as data. 
You would have to keep adding, because there are plenty of primitive types that are little better than strings. For instance, we might want to exclude nested lists whose elements are either other lists (possibly empty) or character strings (no symbols, numbers, or other things).
Whitespace is explicitly ignored though so at least for me that argument isn't sound. Same with comments.
`(+ 1 1)` and `(+ 0 2)` are different expressions that produce different ASTs (modulo optimization of constant expressions).
If we're ignoring comments and whitespace, then Ruby source code is isomorphic to its AST as well, no?
Great article. 
Appreciate your devotion to CL, man. You're doing great job at keeping CL alive these crazy times. So, donation from Russia and may force be with all of us. Happy coming holidays!
Matching until the 31st of December. From wording I'd assume donations can continue afterward, just without the matching?
Matching is for the first $6000, doubling it to $12,000. To my surprise and delight, donors have already blown past that initial $6000, so further donations are not matched, but they are still very much appreciated.
Can elaborate a little on the anticipated difficulties porting this forward?
Have you given Patreon a thought as well?
The paypal donations are very much appreciated, but do not have high volume. Most recently I bought a new build server that is 40% faster than my old one. I also use it to pay my AWS, domain, and other hosting costs.
I would certainly give a small contribution if it were an option! all my hobby projects depend on quicklisp
At least in US, it should be tax deductible I believe. At least, the email I got said: &gt; For donations Payment Processing in the United States, the CLF works together with the Association of Lisp Users, which is a registered 501(c)(3) corporation. This means your donation may be tax-deductible. The ALU's Federal ID number is: 54-1605867. &gt; For EU citizens, the Foundation is working on our tax-exempt status, which we hope to receive at some point. Stay tuned. 
Hi! you may want to give [live-support](https://github.com/cbaggers/livesupport) a go. There is a macro called 'continuable' which I wrap around code in my main loop so I can continue from an error and also 'update-repl-link' which you call inside you main loop to keep the repl active. You can both being used in [this example](https://github.com/cbaggers/cepl.examples/blob/master/examples/moving-triangles.lisp). Even though the example is for CEPL, CEPL is not required for **live-support** to work. **live-support** should work with both **slime** &amp; **sly**. Please file an issue if you run into any issues with those. [edit] Reading your question again, I'm wondering how you're starting your game/demo. Maybe try something like: (defvar *initialized* nil) (defun init () (unless *initialized* (print "initializing") ..init code here..)) (defvar *running* nil) (defun step-game () (update-repl-link) ..) (defun run-loop () (unless *running*) (init) (unwind-protect (progn (print "starting") (setf *running* t) (loop while *running* do (continuable (step-game)))) (print "finished") (setf *running* nil))) (defun stop-game () (setf *running* nil)) It's pretty basic but this way, even if the your game errors, you can fix the error and call run-game again to continue where you left off (as you didnt deinitialize). Also because of the **continuable** you can often just fix the error whilst the debugger is open, recompile the problem function and choose continue. Lastly you can have an optional argument in **run-game** for the number of frames to run the game for, this can be really handy when you are working on an effect as you can run 1 frame at a time. 
You can fix the mistake, hit "C-c C-c" again, then switch to the debugger, select any frame below the one where fixed function was called, and hit "r" to restart execution from this point in time. 
I like it. Sexprs have the most regular syntax imaginable. But that doesn't mean it's the simplest nor the most readable. They are closely aligned concepts but not identical. It's an historical accident that we ended up representing Lisp data and programs as parenthesized sequences just as much as it's an historical accident that the pair member access functions are called car and cdr. I don't think either one is objectively optimal.
...and much more accessible through vim-sexp or paredit.
In the earliest days of Lisp, S-expressions weren't going to be used for programs, only data. M-expressions were going to be for program logic. S-expressions were implemented first and turned out to be "good enough", and in many ways beneficial to the evolution of Lisp since they later enabled the macro system, but they weren't envisioned as the final syntax of Lisp. 
&gt; I don't think either one is objectively optimal. I disagree. If it isn't optimal, then people would've stop using it a long time ago. Recall that initially Lisp programs was going to be written in M-expressions (a more "traditional" syntax), but was later abandon due to the fact that people prefer using s-expressions directly. Or, as John McCarthy himself said in [History of Lisp](http://www-formal.stanford.edu/jmc/history/lisp.html): &gt;The project of defining M-expressions precisely and compiling them or at least translating them into S-expressions was neither finalized nor explicitly abandoned. It just receded into the indefinite future, and a new generation of programmers appeared *who preferred internal notation (i.e., s-expressions) to any FORTRAN-like or ALGOL-like notation that could be devised*. And it isn't hard to see why people prefer s-expressions after you sit down and really learn to read and use it. In short, this [picture](http://imgur.com/a/qz4im) sums it up quite nicely (and we haven't even talk about macros). As for the car and cdr, while their origin is quite archaic, they are still around because their composition functions can be given pronounceable names that match their semantic (see [here](https://en.wikipedia.org/wiki/CAR_and_CDR#Continued_acceptance) for some examples).
Wow, I did not know about this but this is incredible. Got a lot of great advice in this thread but this was the easiest to try so naturally I did it first. Really cool!!
&gt; If it isn't optimal, then people would've stop using it a long time ago. I kind of don't like this reasoning. Anthropological stuff like this can be explained using many other factors too. Like being backwards compatible with large code bases or that the pain in using them has reached a local minimum or being too lazy to use something else or that the existing tools work too well with existing syntax, that changing the syntax would mean using non-optimal tools. It's also not really obvious what "optimal" would mean. I argue, that sexps are not optimally readable by them self. Formatting and consistent coding style takes a huge role, but thats true for other languages too (Java, C/C++, JavaScript). It can be beneficial for having symbols to make the meaning of expressions more clear. For instance: It's hard to know how a sexprs is exactly evaluated without exactly knowing the meaning of the first word. If forms would optically be different from function applications/calls things would be easier to read: [let ((x 10) (y 20)) [if (&lt; x y) (display "Yay!") (display "Boo")]] We could go a step further, and make data visually different too: [let ({x 10} {y 20}) [if (&lt; x y) (display '{1 2 3 4}) (display "Boo")]] For me this would make code more readable. But ultimately this may come down to preference. You don't get far in any language without knowing the meaning/semantics behind a word. 
Interesting response from the community. Just to make clear, this is more of an alternate thought experiment by David Wheeler. While one may not entirely agree with an idea, one shouldn't oppose trying it out.
I would guess some of the response is that this topic that has been well hashed out at this point. From the days of m-expressions this question has been there and nothing has yet appeared that has convinced any large number of people to take it up. More than that, this work has in particular been discussed at length both here and on [comp.lang.lisp](https://groups.google.com/forum/#!searchin/comp.lang.lisp/readable%7Csort:relevance/comp.lang.lisp/bA5CGOZooTw/owyHMS8fpV4J) back when it came out. At this stage a more interesting line of inquiry may be to look at languages like [Dylan](https://en.wikipedia.org/wiki/Dylan_(programming_language) &amp; [Julia](http://julialang.org/) (both of which have macros and a more algol'y syntax) and identify what they do well that is missing from current attempts to make lisp 'more readable'. I would venture to say that good syntax supports you as you try and undertake a task. S-Expressions seem to make macros/meaprogramming very natural, so the first question is 'how does this alternate syntax make the situation better?' Or if not that, 'what task is this syntax aiming to make better?'
&gt; so let's appreciate the fact that Lisp is flexible and extensible enough to let us have it both ways, shall we? :) I'm absolutely on your side. And since I got an editor which colors the parentheses according to their nesting depth reading s-exprs got a lot easier.
I didn't look very closely, but I suspect that if `mismatch` is used instead of `string&lt;` in the `lcp` function, then you don't need the suffixes in lexicographic order. 
hehe, not the direction I meant but you got a good chuckle out of me anyway.
Fair points, I expected in it (like in many failures) there are things they did right. Of course I may be wrong, it may have been an end to end disaster. I've seen it occasionally mentioned here with some affection though, so I assumed it was interesting enough to be brought up.
Thanks for the comment! I think `mismatch` might be what I need for sequence comparison.
CamelCase makes little sense in Common Lisp. Symbols are internally case sensitive, but the reader upcases symbols by default. CL-USER 2 &gt; 'MyCamelCaseSymbol MYCAMELCASESYMBOL OOPS. Typical are hyphenated symbols: CL-USER 3 &gt; 'my-hyphenated-symbol MY-HYPHENATED-SYMBOL Possible are also symbols with up and downcase, white space and other characters: CL-USER 4 &gt; '|My Escaped Symbol| |My Escaped Symbol| or even: CL-USER 5 &gt; '|Habe nun, ach! Philosophie, Juristerei and Medizin, Und leider auch Theologie Durchaus studiert, mit heißem Bemühn. Da steh' ich nun, ich armer Tor, Und bin so klug als wie zuvor!| |Habe nun, ach! Philosophie, Juristerei and Medizin, Und leider auch Theologie Durchaus studiert, mit heißem Bemühn. Da steh' ich nun, ich armer Tor, Und bin so klug als wie zuvor!| 
However, the *Paul Graham Cult of Lisp* is pretty much dead. (Anybody got a good rant on Arc?) 
If you're using Scheme, you're out of luck. You can kinda fake it using continuations (but not in Racket because "continuation barriers" will stop you), but if you or your library uses `dynamic-wind` anywhere, the exit thunks have already executed by the time your error handling code runs, so there's no going back to the execution environment in which the error occurred. Faking it would look something like this: (define *resume-continuation* #f) (condition-case (let loop () (call/cc (lambda (cc) (set! *resume-continuation* cc) ;; Each individual form that might fail needs its own call/cc (some-code-that-might-fail))) (loop)) ((exn) (*resume-continuation*))) SRFI-12 allows a Scheme implementation to implement "continuable" exceptions (which can be resumed from like Common Lisp conditions), but I don't know any Scheme implementations that actually support them (Chicken certainly doesn't). SRFI-12 allows for the nightmare scenario where some exceptions are continuable but others aren't. Then, if your library or the implementation itself throws a non-continuable exception, you have no way to resume from it. The best solution, IMO, is to use Common Lisp whenever you're thinking of using Scheme.
It only works for frames that appear in green, and if you're using an aggressively optimizing compiler like SBCL, that won't be many. For those who are finding that their stack traces are entirely white, try turning off optimization by putting this at the top of your source file (and also entering it at the REPL for good measure): (declaim (optimize (debug 3) (speed 0))) 
Thank you very much for you elaborate answer and explanation. I think I understand the difference now a bit better. I always find myself torn between CL and Scheme. I love the maturity of CL while I totally dig the ability of Chicken to produce executables, as one example. I think at one point I will have to decide which one to ditch for the other ....
**or** evaluates each form, one at a time, from left to right. The evaluation of all forms terminates when a form evaluates to true (i.e., something other than nil). If the evaluation of any form other than the last returns a primary value that is true, **or** immediately returns that value (but no additional values) without evaluating the remaining forms. If every form but the last returns false as its primary value, **or** returns all values returned by the last form. If no forms are supplied, **or** returns **nil***.
You think right, I think :-) My point was that I'd have thought starting the sentence with *however* was sufficient acknowledgment of that point. [however](https://en.wiktionary.org/wiki/however): Nevertheless; yet, still; in spite of (that). 
"The infinite monkey theorem states that a monkey hitting keys at random on a typewriter keyboard for an infinite amount of time will almost surely type a given text, such as the complete works of William Shakespeare." or maybe even a good program.
I got your point, and understood your use of "however". so that would be, based on your assertion that Paul's cult is already (pretty much) dead, make the second proposition false, but the first would likely still be truth. However, I think defmacro-jam just went around your comment, without taking a stance regarding whether your assertion is truth. I think you are right.
I'm still a big fan of Paul Graham. On Lisp was one of the most formative books in my nerd development. I still have a soft spot for many of his articles. I was never a fan of arc, though. 
"The infinite javascript monkey theorem states that a monkey programming javascript for an infinite amount of time will never type even a good program."
As does caustic and idiotic tribalism.
The pre-Javascript idea of "embed Scheme in a browser" would've been a significantly better decision.
Good article. Thought perhaps dynamic-extent on strings can work, but anyway they solved the problem theirselves.
Lisp usage at an all-time low, languages like Julia picking up Lisp's slack for getting real work done... Fuck the Paul Graham heritage. 
&gt; Anybody got a good rant on Arc? I dunno about a rant, but I actually really enjoy Arc. The way I describe it is that it doesn't make a decision for every choice you want it to make, but of the decisions it does make, many of them result in nice features. For example, Arc unifies `if` and `cond`. This is pretty nice, and gets rid of a lot of useless parentheses, while keeping simple `if` calls *exactly* the same as "traditional" lisp `if`. An example: (if test-1 'result-1 (test 2) (result "two") (and (test 3) test-3.5) (string "the third" " result")) Arc actually goes the other way on variable binding -- to bind only one variable, use `let`: arc&gt; (let price 40 (prn "You bought something for $" price)) You bought something for $40 But to bind multiple variables, use `with`: arc&gt; (with (price 40 thing-name "a boat") (prn "You bought " thing-name " for $" price)) You bought a boat for $40 Also, `destructuring-bind` works for normal assignments, without having to do anything special: arc&gt; (let (a b (c d) . e) '(1 2 (3 4) 5 6) (prn a) (prn b) (prn c) (prn d) (prn e)) 1 2 3 4 (5 6) Memoization is also built into the language: arc&gt; (defmemo yell-and-return (val) (prn "I evaluated my body once!") val) #&lt;procedure: memo&gt; arc&gt; (yell-and-return "repeat?") I evaluated my body once! "repeat?" arc&gt; (yell-and-return "repeat?") "repeat?" So it's things like this that make me like the language. I would like more things in it (a module system, more libraries, language updates), but for what it does, it does some things really well.
SBCL"s gc is a "conservative" one, which is imprecise - it doesn't always know that particular object is not referenced and can be collected. I've seen SBCL failing with out-of-memory with 1GB heap where CCL successfully works with 100MB heap (it was compilation of f2cl).
Do you have numbers or sources to support that claim? I thought Lisp got a small boost due to Clojure ( https://clojure.org/ ) being popular. It was quite the rage 1-2 years ago. Especially with offspring like ClojureScript ( https://clojurescript.org/ ) it seems quite relevant these days. And there have been projects like "Make a Lisp" ( https://github.com/kanaka/mal ) that were/are quite active and interesting and taught even the basics of Lisp to some developers. 
I think CLASP is mostly SICL.
SICL is not complete yet, but CLASP uses part of it – Cleavir, which is a compiler-writing framework.
I linked to the discussion actually.
There is a discussion going on on the original site. You linked to a discussion on a site linking to the original site containing a discussion. I found that inconvenient, but I might be stupid as well.
I see the 1996 edition can be found online if you're not a landlubber. EDIT: I just pointed out a potential option for poor people and/or those without access to dead tree vendors and those who just want to check out the contents before buying.
Thanks, found the bug.
[Link](https://www.reddit.com/r/lisp/comments/5iohad/the_idea_of_lisp/db9v1z8/) ^(I &lt;3 tail recursion)
&gt; So HN in production is running that code? Or have they a much modified internal version that is not open sourced? They're running a modified internal version that has not been released. This is very unfortunate. &gt;&gt; YC has very very good hackers working on it. So if they run into problems, they can fix them. &gt; That is definitely true, but if I can't get the code I can't profit from their fixes. Yes. I actually meant "YC has very good hackers working on it. I only have me (and I'm not so good)." &gt; I expect that Lisp derivatives should be more secure than PHP brain damage, and also attract talent that tends to write more secure software out of the box. Yeah. It helps that HN is pretty limited, in terms of a feature set.
Thanks. I think I will give it a spin sometime nevertheless. My needs are very modest.
It's a fun language for what it does. Feel free to message me with any questions, or post [on the forum](http://arclanguage.org/forum) with trip reports or whatever. By the by, I'm going to be releasing 1.0 of my [Arc unit test library](https://bitbucket.org/zck/unit-test.arc) soon, so if you want to do that, ping me and I'll help you onto the latest version.
Embedding *any* preexisting sandboxable scripting language would be better than trying to design one yourself under very limited time constraints because one person can't possible think of every design issue, especially not in a very short amount of time, and once you put it on the web it has to be backwards compatible forever. Even if you had to write an *implementation* of it yourself, just having a language specification that (hopefully) thinks through most of the issues would be a major improvement over designing *and* implementing a language. The issue was purely about the syntax. It had to be close to Java. There are ways around this other than coming up with a completely new programming language. Schemes and Lisps have had alternate syntax layers before. They're just not that popular. [The SRFI list has several](http://srfi.schemers.org/final-srfis.html), such as [this one](http://srfi.schemers.org/srfi-110/srfi-110.html). It probably would have been possible to uglify Scheme to make it look like Java. JavaScript is not that language, though.
Yes, similar. But I think mine is more thorough, at least the test suite seems to be.
Another one: https://github.com/kiselgra/c-mera
Similar: https://bitbucket.org/ktg/l
Looks quite interesting, will you release it under a free software licence? (GPL, LGPL, MIT, BSD...)
Your question is too vague to answer without some detective work. What JSON library are you using, how are you calling it, where is assoc-default defined etc. That said, if you are in fact getting an array, you want aref instead of car/cdr and friends. 
Unfortunately, the syntax is structured in a way that, though it resembles C, so that it is quickly readable if you know C, seems to be hard to analyze for rudimentary structure in a way that follows semantics. For instance, we can't recognize a function definition just by peeking at the first symbol of a top-level expression: you have cases like `(int ...` `(void ...` and so on. If we consider two symbols into the form,`(int foo`, is that `int foo;` the variable? Or `int foo(...)` the function? More parsing is required. And that's just with a single declaration specifier: what if we have a `static unsigned int`. 
Okay sorry about that new to eLisp, I'm using request.el and json.el I believe within emacs. 
RSA on PicoLisp https://bitbucket.org/mihailp/picolisp/src/b0d59b0e01acfc35ffbf04f89d19e36f09cd8674/lib/rsa.l?at=default&amp;fileviewer=file-view-default some crypto on PicoLisp https://bitbucket.org/mihailp/tankfeeder/src/4dc5c9928cc2406720e7da655e02bbacea1c6adf/crypto/?at=default
Taskell is my favorite (and probably the most complete attempt at this) that i've seen so far. http://super.para.media.kyoto-u.ac.jp/~tasuku/sc/index.html The implementation is very interesting as well, it uses an apparently prolog style.
Yes, I will be in the future updating the licensing.
I wrote the syntax as I went along going through the examples and problems of K&amp;R. The syntax is more like C as this is more of a tool that is meant to bring C programmers into the Lisp world rather than pulling Lisp programmers into the C world. Hence, I tried to follow the conventions and structures of C with the syntax to make it more familiar to that broader audience.
Would also suggest looking at: https://github.com/vseloved/cl-nlp https://github.com/kraison/nlp https://github.com/kraison/langutils All seem to be somewhat active.
There are Japanese ones, but never heard of equivalents in English.
**Portacle is still not really officially released.** The current versions still suffer from platform incompatibility problems and some things don't quite work because getting them to be portable is a huge bag of issues. I haven't had much time to tend to it as of late, as I've grown very busy with other projects. I do intend on continuing the work soon, though. The core functionality should work at least on Linux and Windows. OS X I have not had much time to test yet. What I do know to be troublesome on all three platforms for sure is Git. Getting it to cooperate has been very frustrating. Either way, if you still end up giving it a shot and encounter issues, I'd appreciate it a lot if you could open up a ticket on the [issue tracker](https://github.com/Shinmera/portacle/issues) and let me know about what's up. 
Ok, thanks for the explanations. Hope I didn't bother you. Since it works on Linux (and Windows) I thought it's really worth sharing. You also have a collection of very interesting Common Lisp projects (I'm already incorporating Plump, Lquery, trying Ratify, keeping on eye on Radiance). That's impressive, congrats and keep up :)
Seeing Portacle on here is a bit to my chagrin, but more because I know I should've already spent more time on it to fix it. So it's fine, don't worry. Gives me more pressure to work on it. Thanks, I try my best.
Just checked it out on windows. Portacle looks and feels awesome and I replaced my custom environment with it.
## 2009-2010 - [LISP365](https://atnd.org/events/2526) ## 2011 - [LispギャグAdvent Calendar](https://atnd.org/events/22826) ## 2012 - [Lisp Advent Calendar 2012](http://qiita.com/advent-calendar/2012/lisp) - [Lisp Reader Macro Advent Calendar 2012](http://qiita.com/advent-calendar/2012/lisp-reader-macro) - [Common Lisp Libraries Advent Calendar 2012](http://qiita.com/advent-calendar/2012/clladvent) - [Lispギャグ Advent Calendar 2012](http://qiita.com/advent-calendar/2012/lispgag) ## 2013 - [Lisp Advent Calendar 2013](http://qiita.com/advent-calendar/2013/lisp) - [Clojure Advent Calendar 2013](http://qiita.com/advent-calendar/2013/clojure) - [Metaobject Protocol(MOP) Advent Calendar 2013](http://qiita.com/advent-calendar/2013/mop) ## 2014 - [Lisp Advent Calendar 2014](http://qiita.com/advent-calendar/2014/lisp) - [Clojure Advent Calendar 2014](http://qiita.com/advent-calendar/2014/clojure) - [LISP Library 365](https://atnd.org/events/46706) - [LISP Implementation Advent Calendar](https://atnd.org/events/58967) - [ADVENTAR: Lisp Advent Calendar 2014](http://www.adventar.org/calendars/554) ## 2015 - [Lisp Advent Calendar 2015](http://qiita.com/advent-calendar/2015/lisp) - [Clojure Advent Calendar 2015](http://qiita.com/advent-calendar/2015/clojure) - [ADVENTAR: Lisp Advent Calendar 2015](http://www.adventar.org/calendars/930) ## 2016 - [Lisp Advent Calendar 2016](http://qiita.com/advent-calendar/2016/lisp) - [Clojure Advent Calendar 2016](http://qiita.com/advent-calendar/2016/clojure) - [Retro Lisp Advent Calendar 2016](http://qiita.com/advent-calendar/2016/retro-lisp)
Nice, I must really start learning Japanese.
[buildapp](http://xach.com/lisp/buildapp) takes this approach. I made buildapp because I couldn't figure out how to use cl-launch.
thanks for sharing, I'm also beginner and it's nice to see examples. Do you have this on a repository, gitlab/github/… ?
You might have more luck getting a proper review on https://codereview.stackexchange.com.
How do you compress the core?
i've used roswell on several projects. It's rather nice. https://github.com/roswell/roswell It does several things, being a replacement for buildapp being one of them.
What's wrong with buildapp?
buildapp works best on SBCL, passably on CCL, and not at all anywhere else. If I had time and there was demand, I'd clean it up.
Nothing is wrong with build-app. My previous comment wasn't phrased very well (Sorry Xach, you are truely awesome!). I use both buildapp and roswell. Roswell does several things, creating an image being just one of them. It is the roswell feature I use the most. Here's an example of a ros script that I use to create a new stumpwm. From the command line, you would execute like: 'ros -Q build FILENAME.ros'.' #!/bin/sh #|-*- mode:lisp -*-|# #| &lt;Put a one-line description here&gt; exec ros -Q -- $0 "$@" |# (defpackage :ros.script.stumpwm.3676632732 (:use :cl)) (in-package :ros.script.stumpwm.3676632732) (ql:quickload "clx") (ql:quickload "cl-ppcre") (ql:quickload "stumpwm") (ql:quickload "swank") (defun main (&amp;rest argv) (declare (ignorable argv)) (swank-loader::setup) (swank:create-server :dont-close t) (stumpwm:stumpwm) ) ;;; vim: set ft=lisp lisp: 
I'm not up to speed on the latest ASDF, but I believe it doesn't do core compression automatically or through some neat option. However, you can still get it by adding something like this to your ASD file: #+sb-core-compression (defmethod asdf:perform ((o asdf:image-op) (c asdf:system)) (uiop:dump-image (asdf:output-file o c) :executable T :compression T))
Half the presentation is taken up by useless focus on performance, whilst not a single slide is devoted to security!! Talk about getting your priorities wrong. The following should be completely unacceptable these days: CL-USER&gt; (loop :for url :in '("https://expired.badssl.com" "https://wrong.host.badssl.com" "https://untrusted-root.badssl.com" "https://revoked.badssl.com") :collect (second (multiple-value-list (dexador:get url)))) (200 200 200 200) One big problem in CL-land, is the superficial focus which leads to lots of libraries that are scratching personal itches and, under specific circumstances or points of view may improve slightly on certain aspects, but when examined objectively completely fall apart in that they are not built on solid foundations and compromise too much on the things that should really matter. Now, normally, you wouldn't see me writing flames addressing this fact. But when people do *presentations* to show off their latest and greatest, they are positioning it on the pedestal of re-usability and asking the rest of us to take notice. Yes, drakma is a pile of shit. Unfortunately, dexador is an even bigger pile of shit. 
I think the only thing missing in the benchmark is the fact that Drakma can also re-use connections, it is not as straight forward as in Dexador (apparently), but it is possible ad it improves performance. I'm not deffending Drakma, just saying that might change some comparisons.
In my experience, shaming is not a strong motivator for open-source progress. Thanks for the example sites that should fail. *edit* It looks like the internal, undocumented variable `cl+ssl::*ssl-check-verify-p*` affects some, but not all, of the connections to the badssl.com sites. In particular, expired and untrusted-root fail, but wrong.host and revoked succeed.
Hey OP for NLP you need to go for either Python or Java. Both have Lisps you can write in: Clojure for Java and Hy for Python.
[Trending Common Lisp repositories](https://github.com/trending/common-lisp) on GitHub. Seems like some are still using lisp. Then there's the [trending repos for Clojure](https://github.com/trending/clojure). That aside, I found that learning lisp has given me a better understanding of things. Many features that have been appearing in hip new languages were pioneered in lisp. Such features are "normal" for lisp and have been around a long time. In other languages they are new features, with a lot of people struggling with understanding the best way to use them. Even for old languages like C, sometimes I'll realize a lispy solution informs my implementation. "Oh, I can't do this like I would in lisp, but I can use function pointers to do thus and so." The shape of the C solution will be guided by knowledge of how I would do it if I had the flexibility and power of lisp. Sometimes. ;-) I don't use lisp in my day job. I use various languages for my hobby projects. But I am glad that I bothered to learn lisp and will continue with it to some degree.
I would say that you should avoid lisp programming, the lisp community, and lisp in general. This is for your sake... if you want to be a mainstream commercial programmer who gets a day job with a salary, you should probably not go for Common Lisp or Scheme. You never get a second chance. At the same time, you might want to open your eyes and look out, as "nobody" is a strong, false term that tends to exhibit a poor first impression to us lispniks. 
Lisp is more capable than Python, but you should probably stick with Python first and come back to Lisp in 10 years, after you've passed from novice to intermediate programmer. Lisp is wonderful and will be waiting for you.
No I haven't don't know how to do this. Might have to look it up! Thanks :)
My projects don't really benefit of using ASDF or any build tool, so I just use `(sb-ext:save-lisp-and-die "myprog" :toplevel #'main :executable t :compression 9)` from the command-line.
I don't remember all of the details, but IIRC there's a keyword for save-lisp-and-die which was :compress that would let you compress the whole thing. I remember that patching stumpwm to use that would bring the executable down from 97 mb to 17 mb. Also, if you try to strip the executable you get and run the binary again, you end up with a simple repl. EDIT: http://www.sbcl.org/manual/#Function-sb_002dext_003asave_002dlisp_002dand_002ddie it was ":compression n" or ":compression t". If t is supplied, it uses the default compression level, -1. Otherwise, it uses a compression level the very same way zlib would. I got the best results with ":compression 9"
Bought a book, looks great. Thanks to the author for putting this up, its a fun and useful way to learn Lisp + web programming.
Thanks! That will be my next step but I just bought one for this purpose alone. I'm afraid of asking the girlfriend if I can get another one (even though it's my money).
What?
Here's the MCL manual: http://ccl.clozure.com/ftp/pub/mcl-reference.pdf I would do a search on *.fasl and look for the ones that are named the same names as those in the alice folder.
One reason to learn Scheme if you haven't programmed before is if you're using the beginner's academic textbook [How to Design Programs](http://htdp.org/), or MIT's [The Structure and Interpretation of Computer Programs](https://mitpress.mit.edu/sicp/full-text/book/book-Z-H-4.html#%_toc_start), which is the famous textbook that was used for MIT's 6.001 course from 1985 until 2008. The skill of programming carries easily across languages. Once you know how to do it, learning any other language is a matter of reading a one-page tutorial to learn the syntax, and using the language's API reference to see how to use the language's standard library. One of the advantages of learning Lisp is that it is based on just a few simple constructs, and everything else in the language follows logically from that. In other programming languages, there are obscure exceptions to every rule in the language, so sometimes your code *looks* right but isn't, which is frustrating even to a professional programmer, let alone a beginner. 
Qlot = Warning: This software is still ALPHA quality. The APIs will be likely to change. Portacle = Portacle is still not really officially released.
Hi, I'm the author. Thank you for pointing out. I added a code for verifying SSL certificates and the code is available at the master branch. Will you use it? :)
As others have mentioned, use `*earmuffs*` on special variables. Also it is preferred to use `if` when dealing with 2 branches, and `when` or `unless` when dealing with 1 such as you have in a few cases. In addition, you can use `cond` or the `case` variants, depending on use-case, for multiple branches.
Same. I purchased back when it was 10% done. It's now up to 25%
&gt; am learning scheme right now, but sometime i wonder why even bother? Scheme never was even created to be a language for real, practical use. It was designed for teaching. &gt; it seems like nobody uses it anymore. If your only goal in life is learning something everybody else already knows, you will have no competitive advantage in selling your skill, and the money you can milk per hour of work will be low. Is your life goal to become a replaceable code drone?
Thanks for the warning. Portacle [is reported to work everywhere except in the latest mac](https://www.reddit.com/r/lisp/comments/5j2fek/portacle_a_portable_common_lisp_development/), and it's sooo useful IMO, specially for newcommers, that we should talk about it. I don't know Qlot's state, but knowing that it's like a virtual env of Python makes me think it's a much welcome tool. The warnings don't discourage the use, it's just an open possibility for the authors to change something.
So it seems that this type of system is quite popular to implement. I didn’t start in the dark and had found others that had been made but they never felt quite correct (and I didn’t feel like RTFM’ing them) so I rolled my own. But I have a question. Has anybody ever actaully used one of these systems to their full advantage besides some initial tests? I know when writing the tests that I was mostly thinking in C. I couldn’t come up with many macro examples, but I think that the usage of this tool is ripe for someone to write an ‘On C’ similar to ‘On Lisp’, after sufficient practice, and such a book could be really low hanging fruit. Thoughts?
Did you try RMCL (latest open source MCL) https://code.google.com/archive/p/mcl/ Open source version of the Macintosh Common Lisp development environment. Works on Intel and PPC computers with MacOSX 10.4 and up, including MacOSX 10.6 "Snow Leopard". If you have the sources of ALICE, should be easy to recompile
On the topic of lisp to C, I sort of did that back in 1985/1986; I wrote a Pascal to C translator. The way that I did this was: (1) parse the Pascal input using YACC; (2) implement my own version of lisp and place the Pascal input / YACC output into lisp structures; (3) using my lisp environment, perform transformations of the lisp structures; (4) pretty print the transformed lisp structures out as C.
This is a great blog, and understanding fexprs really changes how you see what lisp could be. 
Thanks for the pointer to Hy. Didn't know about that. Perhaps that is an ideal solution.
Is there a javascript implementation of mccarthy lisp?
fexprs only change what you see Lisp could be if your idea of Lisp is that it's a finished work which someone hands you in binary without source code, such that you cannot add new special forms. If you see Lisp as something malleable and envision yourself having an implementation in which you can tweak and extend anything, including adding new special forms into an interpreter or compiler (or both, as necessary), then fexprs don't change your view of what Lisp could be. 
I could use this or something like this that is "field proven". Alas, two problems here: It seems to be not documented! There are only stub sections on CiSE in the Gauche doc. It is mis-licensed. The implementation uses the silly old 3-Clause BSD license which carries the counterproductive requirement to have copyright notices in binary forms. This second problem means I have to do a clean-room implementation if I want to use this in a 2-Clause BSD licensed program. Because of the first problem, I have to do it without any documentation. I have to write up my own spec from scratch based on studying the original source code and a corpus of Gauche code which uses it, and then implement it from the spec. 
Yes I did but I wasn't sure how to recompile as I am a newbie. Will try and fumble my way through it. Thanks so much for your help :)
PCL gives a good explanation of the differences between the equality predicates [here](http://www.gigamonkeys.com/book/syntax-and-semantics.html#truth-falsehood-and-equality). EQUAL actually does work for some types of arrays (try strings). I think I read about macros being the reason for separate namespaces in Let over Lambda. Common Lisp chose separate namespaces, scheme chose hygienic macros, and Haskell doesn't really have macros.
About the separate function namespace: http://www.dreamsongs.com/Separation.html
The different equality predicates don't so much "not work" on certain types as they use different definitions of equality. There are just so many ways you might want to compare objects. Unfortunately it's awfully hard to remember the rules for each one.
I haven't programmed in Lisp, but I have programmed in Scheme. I read about Lisp because I've come to a conclusion. Scheme alone doesn't have good community support for newcomers. But Lisp (or rather lisps as a whole, including schemes and clojure) provide better insight when put together, if you're willing to do the work. In my case, I code in Racket, but I read up on what's been ported onto quicklisp. One quick reference to a cheatsheet (hyperglot?) is all I need to extract the knowledge I'm looking for. I'm essentially re-emulating my learning curve from java, where I could either go through their ridiculously thorough documentation which assumed you read prior books or chapters XYZ, or google for some guys shortcut tutorial. I see Racket's own docs as the former, and the wider lisp community as the latter.
Editing code while it runs is kind of a staple feature of any Lisp environment, so I'm not sure how that's the part about Genera that makes you marvel. Just run Common Lisp on a usual PC and be done with it. Theoretically anything is possible, but practically, the chance that Genera, Mezzano, or anything of the LispOS/M nature is going to be updated to be even comparable to any of the modern OS environments is practically nil, simply because the amount of effort required to get there is way too big, and the amount of support these kinds of projects can garner is way too slim.
Not trying to offend you or anything but, what's the advantage of using a really outdated, practically useless OS if you don't program? Why would you even want to have the feature of editing while it runs if you'll never actually edit it? Anyways, besides that, there are a some modern Lisp Operating Systems out there: https://github.com/froggey/Mezzano https://github.com/whily/yalo https://github.com/mntmn/interim You probably won't use them as they're pretty much just REPLs and not much else.
Erm, I like the REPL. Teco is nothing but a programming language for editing text by REPL. What I don't like is "actual programming", you know, writing a whole new application, or even trying to compile an old application in a new compiler, where some statement or other is tripping the computer up,
Something tells me you're fishing for certain information here. Everything you said regarding your background makes 0 sense. 
The only information I'm fishing for is more on LispM operating systems for the modern age. That really is IT. Whether it's neoGenera, Mezzano, or something totally different. Personally, I like Genera. It has an e-Mail client (that needs updating for POP3 and IMAP), a LaTeX-lookalike, it prints to PostScript, it has an Emacs (WHICH HAS NO vile mode AAARRRRGGGGHHHH!). It needs a quick and dirty Web browser and I can live in Genera just like I sometimes live in Emacs.
Personally, I could have landed on Venice Beach, naked, with a pair of white angel wings on my back---I don't see your point regarding my bacground. The legal mumbo jumbo is ONLY a footnote---notice the lack of a question mark.
Nobody knows what you mean by "not using it right". OP said he or she got that code from a book as an example of memoization. The book's author is not present in this thread to defend their understanding of memoization. The code isn't working as intended; that the intent isn't an example of true memoization is tangential. Indeed, it is only a caching wrapper around a function. Unlike true memoization, if we apply it to a naive recursive Fibonacci (exponential time) it will not (or might not) reduce its complexity to linear time. That's because when the wrapped function recurses, it will call itself, and not the wrapper. When a Lisp function calls itself, a Lisp compiler is permitted to treat that efficiently, without going through its symbol's global function binding. Under true memoization, recursive calls must go to the memoized interface. Memoization speeds up recursion in which overlapping subcases occur. This issue can be fixed by declaring the function `notinline`: From **CLHS 3.2.2.3 Semantic Constraints:** &gt; *Within a function named F, the compiler may (but is not required to) assume that an apparent recursive call to a function named F refers to the same definition of F, unless that function has been declared notinline. The consequences of redefining such a recursively defined function F while it is executing are undefined.* 
That's essentially what I've got going on my Mac. I have Emacs as the usual shell and userland application, Firefox for browsing, and SciTECO as an editor. My desktop is DragonflyBSD (with an ITS-like auto-backup file system) with an Emacs shell.
&gt; I'm going to say that again: YOU CAN EDIT CODE WHILE IT RUNS. You can repeat that as many times as you want; it's simply not true. You can replace function definitions in Common Lisp while the image is running. This is not a self-modifying code hack. If this is done while a thread is executing the old function, nothing special happens. The thread keeps running the old function. If that function recurses, it also calls its old self (unless it was declared notinline). New calls through the function binding go to the new definition. Function objects that are not referenced by any binding, value slot or running code become garbage that is reclaimed. Lots of languages and environments can redefine functional units without leaving the image. You can replace functions in Bash without exiting from the shell. You can unload and re-load drivers into Linux, and shared-lib plugins into various user space applications. You can replace an executable in Unix so that the next time the command is invoked, it goes to the new executable. The only contemporary tool I know of that lets you edit the actual code while it is running is Microsoft's Visual Studio plus their compiler. Namely, the "program edit and continue" feature. That actually replaces machine code in-place and lets the program continue, in the same damn function! I used it a couple of times, many years ago; it's quite an impressive self-modifying code hack. I don't suspect it's bullet-proof enough to be used for anything other than debuggng; certainly not reliable in-service upgrades of running code.
I think that's splitting hairs. We all know what is meant, and very few other language communities make any sort of real effort at live coding in an image. I use Pry in Ruby all the time to manipulate programs during execution, but it's still nothing like doing so in common lisp or smalltalk. Maybe it's like art-- you can't define it precisely, but you know it when you see it. 
CAR: Content of Address Register CDR: Content of Decrement Register, but what about Decrement Register?
[removed]
I understand the difference now, but I don't understand how it would cause `old-neighbors` to be bound to the new `neighbors`. Wouldn't `old-neighbors` just be assigned the global `neighbors` (i.e. the one I got with `symbol-function`) since the new definition doesn't exist at that point? I would understand this behavior if I'd been using `symbol-macrolet` instead of `let`, but, well... I'm not.
I think you are missing the mark pretty broadly here. The development environment is where the strength lies, mostly because you can do things like activate the debugger on whatever code is responsible for some object you spot on the screen, you have generally reliable access to the source of whatever code you are looking at, and the debugger knows all about your object system and its internals. The operating system part of Genera is not so stellar. First, it is closely coupled to the hardware architecture. GPLing it would not provide a reasonable route to porting it to anything other than an emulator, the tricky bits of which are not represented in the Genera source but in arcane hardware knowledge. Second, it is, as you said, frozen in a primitive Internet era, full of cruft (not sleek at all in the code), lacks any concept of security or encryption, pervasively assumes a single processor and single memory space, and lacks support for any RFC above 1038. IPv6, for example, is completely missing. It has very important ideas but is long past its sell-by date. No, it probably cannot be made modern. We're going to be lucky if the emulated environment will be runnable in a reasonable way a decade from now. Debugging and development environments for live, supported, Common Lisp implementations could be made much better, but few people are working on it. Even less effort is available to work on Genera. 
[removed]
Does it so hard to open Quickdocs, enter "mock" in a search input and to hit Enter? http://quickdocs.org/search?q=Mock
I did google searches with no luck and the SO answers did not suggest any libraries so figured there wasn't one. Ah well, didn't spend a lot of time on this so no worries.
[removed]
[removed]
Fare has done some preliminary work on making Bazel a build system for Common Lisp.
Wow, this looks intense--nice! Although I imagine you'd read it after learning some basic CL, right?
&gt; GPU computing section could be added &gt; Can you give me some pointers in this area? ugh, didnt come up with anything other than cl-cuda (recently added to quicklisp) and mgl. Recently oclcl/cl-oclapi got in quicklisp repo. Lots of future work...
The new book, Common Lisp Recipes is great if you like learning by example.
No FP-centric recommendations but for those familiar with programing, (that aren't listed in the sidebar, or elsewhere in this thread so far): * [The Scheme Programming Language](http://www.scheme.com/tspl4/) * [ANSI Common Lisp](http://www.paulgraham.com/acl.html) 
I think I never finished it, but deservedly loved.
Here is a crazy idea: if you already know how to program, read reference manuals and standards rather than books.
and also the shinmera [portacle IDE ](https://shinmera.github.io/portacle/) ? 
I would also add [Object-oriented Programming in Common LISP: A Programmer's Guide to CLOS](https://www.amazon.co.uk/d/cka/Object-oriented-Programming-Common-LISP-Programmers-Guide-CLOS/0201175894/ref=sr_1_fkmr0_1?ie=UTF8&amp;qid=1483519869&amp;sr=8-1-fkmr0&amp;keywords=Common+lisp+object+system).
I don't think it will work: otherwise you will always program in the style of the first language you've learned. Even if they are in so to speak 'same' paradigm (FP) they could be quite different: the ML/Haskell style of programming and doing things is not applicable to CL. Books are good since they do not only show **how** to do things, but explain **why** the things are done is this way.
There are books with more extensive source code examples. My classic recommendation is PAIP: http://norvig.com/paip.html It may be that the examples topic (symbolic AI mostly) is not for everyone, but the code and the explanation is just great.
That part I can agree with. What I don't like are the never ending octal permissions that I have to deal with, chmod 777 etc when I download a file from a trusted source. Then there's aix which doesn't have sudo, and the program that double for it sucks.
[removed]
What is `assoc-value`? Just a shim that calls `cdr` on the `assoc` result? CL has no such function; Elisp has an `assoc-get`. Why the extra nesting? The value in `(:a (foo bar))` isn't `(foo bar)` but rather `((foo bar))`. We can make this more explicit by using the dotted pair notation to express the pair: `(:a . ((foo bar)))`. If your intent is that the value is `(foo bar)`, then wrapping it in an extra cons is a slight source of inefficiency.
I think assoc-value is from the [alexandria](http://quickdocs.org/alexandria/api) library. And yes, it calls cdr on the assoc result, but it is also setf-able. 
Roswell + Qlot
I vote version 1 because, if debugging is necessary, it's easier to (trace do-something-to-entry-value1) and see what's going on. As a general rule, if I have a function that accesses some larger object and then performs a calculation on the fetched value, I strongly consider splitting it into two functions. Easier to test and debug.
Ok I think you convinced me. Good point on not decomposing and computing in one function. I will use version1 from now. thanks for the input! 
Indeed. Roswell provides a normal, in some sense "unix-friendly", enviroment as python/ruby/co. does. We can see this in its focus on the shell command line interface, bootstrapping core written in C requiring minimal libraries and standard build-essentials, not assuming emacs (making it friendly to vim+slimv setup). It is thus good for hard server-based use cases including non-root cloud or network-isolated corporate clusters (Yes I did it myself). Portacle seemed to have a different emphasis. Its first use case advertised is "install from USB stick" which would be good for educational purpose. It does seem to target advanced users, but I don't know how far it extends. It looks more like Mac OS App and reminds me of lispbox/lisp-in-a-box that was recommended in PCL (jp version, perhaps an old translation or translation-only material).
I wonder if in the seven years since this paper was written these compilers have implemented more of the classic optimizations the paper shows they weren't doing back then. (Probably the answer, is that yes, they do more optimizations now.)
I vote for version 1, because in version 2 you repeat both `:a` and `*some-list*` unnecessarily. If you decide later that you need `:b` instead, or you need it from somewhere other than `*some-list*`, then version 2 must be changed in both places. Version 2 is also harder to convert into using a hash table or a struct instead of an alist, if other code in the project depends on `retrieve-value` remaining an alist operator. 
Is there a lisp compiler in javascript?
I wish he'd just called it "how to implement frp, actor model and pattern matching in Common Lisp" and let that stand on its own merits rather than try to shoehorn some misplaced Clojure straw man bashing into it as well. 
&gt; What does ACL have going for it? All the extras you get with it are pretty good (like the graph system and the prolog setup), and like u/xach said you can pay another company for support which is great. I used to use LispWorks quite a bit, because it had decent compiler support on Windows, which SBCL didn't always have.
I mean, until SWI Prolog caught up, it was pretty hard to find a commercial-grade Prolog system that was not only still updated, but worked on multiple platforms. I mean, I don't disagree with you, I think SBCL is close to best in class as you can get, but I can see why people choose other platforms too. *ninja edit* oh! I just thought of something: I've only seen a handful of places that used ACL, but one of them was one that had a bunch of stuff that had been originally written in Franz Lisp, so that makes sense obviously.
No, I wasn't joking or being sarcastic, so long as it had some way to integrate the prolog with lisp it sounds useful. 
Oh yeah, [ACL's Prolog system](http://franz.com/products/prolog/index.lhtml) is actually kinda neat. You can compile Prolog programs to CL functions, and integrate it directly into CL. If you combine it with the Graph stuff that Franz offers, it can be a pretty neat setup (depending on what you need, of course).
Maybe if someone would just create a repo on github. Everyone could contribute. And when it is considered "Done". Then we just add a tag on it. EDIT: @eudoxee That's one good way to get ideas and be pestered obssesively :P
[removed]
thx. Do you know if they expose a standalone javascript eval-lisp function? https://github.com/jscl-project/jscl/issues/265
I hear, picolisp also a good choice for little scripts. 
You might take a look at this article: http://picolisp.com/wiki/?tutscript
I don't know why I expected TCO.
"ERROR: Function 'READ' undefined"... huh. That wasn't mentioned on the project page. Still, good effort chaps!
http://www.clisp.org
on the machine all three implementations start/quit in around 40ms +\- 6ms with CLISP not being slower than CCL.
I really didn't expect a 2016 publication date here. Funny.
http://www.newlisp.org
http://zeniv.linux.org.uk/~ober/report.html and http://zeniv.linux.org.uk/~ober/clb/ show performance is not as much as an issue. The fact that one can spawn a ton of threads and not run into the "ldb&gt;" easily is a big win.
Mind sharing why you recommend cl and/or scheme for this over others?
This looks nice. Would you mind sharing what makes you recommend clisp over other options?
Mind elaborating a bit?
Appreciate the pointers.
[CLASH: CLisp as Shell](http://www.clisp.org/clash.html) "Do NOT modify your /etc/passwd yet!" ;-)
This started me off on a bit of a binge into the picolisp docs. Do you have direct experience scripting with picolisp?
TBH, I am really not recommending one thing over another. I just knew about these links. I have never really used picolisp, newlisp, arc etc.. I have never used roswell but if you are going to mix bash and CL it could be very useful. I have only played with the scheme shell. I really like scheme but except for some forays into scheme I have been programming (off and on) in common lisp or its precursor maclisp for 34 years. I almost always have a lisp image running, usually emacs+slime+sbcl, even if I am programming in something else or not programming at all. My scripting needs are not great and seem different than yours. There are two ways I do scripting: 1. My "terminal" is the SBCL repl, emacs+slime is my scripting ide. And everything is written in common lisp except an occasional call to an external program through uiop:run-program. ASDF3's UIOP library is great for these tasks. 2. I write a 100% bash script with no lisp. The more complex the programming aspect of the script, the more likely I will use 1. I use 2 when the script has more interaction with the CLI and less programming (or I snarfed someone else's script and want to alter it). The reason why I do this is that for programming CL has almost everything I need and the developmental cycle is real quick and pleasant with an interactive repl, slime and emacs. Programming in Bash is like programming in Basic, it just gives me a headache but then again it is easier to google and snarf another's solution. The only script I have that mixes the two starts my web servers in which part of the initialization is done by bash and part of it is done by lisp. But the web server is written in lisp, so that makes sense.
Scheme shell was one of the first mentioned: https://www.reddit.com/r/lisp/comments/5mxixb/some_recommendations_for_a_lisp_useful_for_system/dc74rjh/
That's really cool to hear! Then I guess I have underestimated CL. What distribution of CL are you using?
No, this doesn't say that Haskell is not Racket. 
Intel(R) Core(TM) i7-2600 CPU @ 3.40GHz SBCL 1.3.12 ccl 1.11 clisp 2.49 sbcl starts in ~7ms ccl starts in ~8ms clisp starts in ~21ms An image with drakma loaded (a couple .so, more code): sbcl starts in ~10ms ccl starts in ~8ms clisp starts in ~30ms
Thank you for the detailed response! On my "need to check out" list now are: - scsh - guile - gauche - newlisp - picolisp In answer to your question, besides the obvious bourne/posix shell, awk and sed do sort of make it on the list. I've not really ventured out a lot, but Haskell also can be surprisingly nice apart from its initialization times (~500ms on my system). Finally, I guess python is also here, though I've not really touched the language for about a decade. Anyway, cheers!
[removed]
@xelxebar The reply above yours is from the author of PicoLisp ;) I write all my "shell" scripts in PicoLisp, and I've also contributed a JSON and unit testing library for PicoLisp which you can find [here](https://aw.github.io/picolisp) You might also be interested in some PicoLisp "shell" scripting stuff I started recently [here](https://github.com/Jidoteki/tinycore-scripts). Sorry for the sparse documentation, it's still a very early work in progress - but I do use that current code in production along with other PicoLisp scripts I've written (which aren't open sourced yet).
I use PicoLisp for shell scripting because it provides the following advantages: * super lightweight/fast interpreter with no start-up penalty. * very low memory consumption, which makes it perfect to run as a daemon. * the compiled binary is less than 200 KB, so I've been able to run it in lots of places without any dependencies or issues, including my Raspberry Pi 2. * with my tiny [unit testing](https://github.com/aw/picolisp-unit) library, I can write tests for all my shell scripts, in PicoLisp of course. * my web apps are also written in PicoLisp, which means I can share libraries, helpers, and modules between my web app and shell scripts. * the interpreter is not riddled with bugs, unlike other *popular* languages which I won't name here. That means your PicoLisp code written in 2014 will still work perfectly in 2017, and you don't *need* to constantly update your version of PicoLisp. * the author clearly loves his language, and happily supports people who are interested in it (even noobs). * most importantly, writing in PicoLisp is **actually fun**! Some downsides: * there are multiple ways to call external commands, they don't all return the same thing, and it's not always obvious how to obtain the exit code or stderr of commands. You'll need to experiment to find what you want. It's all there though ;) * piping commands using *|* is a bit painful, and required a bit of playing around to figure out. PicoLisp has built-in pipes and handles stdin/stdout gracefully, you just need to learn how to use them correctly. It's much easier to just parse in PicoLisp instead of using *cut | tr | awk | sed | grep*. * nobody will contribute to your code because it's obscure haha. People will read it and learn from it though. * you get a lot of rope, which makes it easy to do ugly things. I consider that a good thing, but it may be bad for someone starting out. As you know, bash is not always *bash* (sometimes it's dash, sometimes it's BusyBox bash, sometimes who knows?). Overall, I'm just happy to write shell scripts which can have simple unit tests, and which run identically no matter what system they're deployed on.
 (tree-union `((1) (2)) `((3))) =&gt; ((1 3) (2)) or =&gt; ((1) (2 3)) ?
 (tree-union `(1 (2) 3) `(4 5 (6))) =&gt; (1 4 5 (2) 3 (6)) or =&gt; (1 4 (2) 5 3 (6))) or =&gt; (1 3 4 5 (2 6))) or =&gt; (1 4 5 (2 6) 3 )) or =&gt; Cannot do, different tree structure or =&gt; ... ? 
(1 3 4 5 (2 6)) or (1 4 5 (2 6) 3) From the questions I've been asked, this is looking to be a union between levels. Ordering per level is irrelevant in this use case I have for this function.
That's absolutely incredible. Fantastic read. 
[removed]
The readme of this project is great. Especially the bit on using `cltl2:variable-information`
I am personally currently in the process of reading through a dozen books on Lisp. I intend to write a complete book report for those books as well as a few other books I've read over the years when i'm done along with a suggested reading order depending on your own personal goals. I will publish this to my blog when it's done and post it here. In the meantime I recommend that you learn Lisp as well as you can after all it is the original "AI Language" and a lot of the history of AI is wrapped up in it. You are correct that there is something special about Lisp. It's the only truly programmable programming language that i'm aware of. The fact that you can easily modify, reader, compiler and write forms using macro's allows for extending the language using new paradigms, things no one has ever thought of. If you don't find that immediately useful for AI then you're asleep. Anyway some books I can recommend are: Lisp itself and by extension "AI" * ANSI Common Lisp * On Lisp * Let Over Lambda * Art of MetaObject Protocol * Common Lisp the Language Second Edition Artificial Intelligence related: * Artificial Intelligence with Common Lisp: Fundamentals of Symbolic and Numeric Computation * Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp * Artificial Intelligence a Modern Approach Third Edition Other: * The Art of Prolog * Purely Functional Data Structures 
[removed]
one reason is that lisp binaries can be really big, since they are batteries included. SBCL binaries can be ~30 MB for a single image, so if you have a bunch of what are supposed to be small scripts, that adds up really fast.
Thank you very much arvid!
I don't know. You will have to investigate the documentation of those projects.
I don't recommend using the mysql interface directly, nor any library specific to particular database implementation. Instead, use a wrapper around those libraries with which you can switch the backend database. The combination of http://quickdocs.org/cl-dbi/ and http://quickdocs.org/sxql/
you can list your times in comment
Without sample chapters or any kind of meaningful preview I wouldn't touch this.
Wimpie's point about where CL programs are usually run was clear to me. The value of the book is to learn how to get serious about deploying CL applications, rather than playing around in a REPL. In that sense, I think this book is doing a favor to the CL community.
I appreciate the value of the book and what the author is trying to do. The point of my feedback is that most people expect technical books to be, at the very least, technically rigorous. Getting (basic) terminology right is an important part of that. If the author can't even get the terminology right, then who knows what else he or she might got wrong. For example, would you buy a book on C programming language where the author gives a wrong definition of a pointer or confuses pointer with something else unrelated? I wouldn't, and I wouldn't trust anything else in the book either. I'm sure Mr. Wimpie meant well, which is why I hope he double check the correctness of his terminology (and maybe rewrite some parts that unnecessary confuse people). If this is a good technical book, then it would be a shame for people to skip or ignore it because of simple (but crucial) mistakes, wouldn't you agree? I (and I'm sure many other as well) would love more Common Lisp books, but I personally would rather have no books at all than ones that contain wrong information (because those kind of books does more harm than good).
I'm not sure what's 'usual' for a Lisp program. A Roomba cleaning robot does not have a Lisp interpreter or a REPL, still it runs a CL application when you turn it on.
Author here. The table of contents is available at the link posted above. The sample chapter will also be available soon. I just haven't had time to update the page yet.
Author again. As others pointed out, "interpreter" is the wrong word choice for the sentence. Understandably it detracts from the point I tried to make, which is that most human lisp users run lisp programs from source code most of the time - whether from the REPL or the command line. Many people do so because they don't know that lisp programs can be turned into standalone executables. I will update the page to be more accurate.
Love the first paragraph prose: &gt; Above all the wonders of Lisp's pantheon stand its metalinguistic tools; by their grace have Lisp's acolytes been liberated from the rigid asceticism of lesser faiths. Thanks to Macro and kin, the jolly, complacent Lisp hacker can gaze through a fragrant cloud of setfs and defstructs at the emaciated unfortunates below, scraping out their meager code in inflexible notation, and sneer superciliously. It's a good feeling.
Congrats on the release!
what-the-hell, there is not a single explanation line nor on gitlab or common-lisp.net. &gt; ManKai Common Lisp (MKCL) aims to be a full implementation of the Common Lisp language in compliance with the ANSI X3J13 Common Lisp standard
I'm not a big fan of Iterate, I don't get its syntax. Why do we put parens around certain forms, why don't they nest like I'd expect them to? (iterate (for el in num-list) (when (&gt; el 3) (collect el))) This code I'd probably imagine to look like this (iterate (for el num-list (when (&gt; el 3) (collect el)))) In loop there's a pretty clear distinction between loop forms and lisp forms, and nesting is obvious, you just don't do it! Don't get me wrong, I don't think Iterate is bad, in fact I think it looks like a familiar way to iterate and its extension capabilities are nice. I just don't think the syntax conveys how it works, it feels more like magic than loop does. Is anyone here more enlightened and willing to explain? ps. Now if someone can explain how the heck you're supposed to learn SERIES in a reasonable manner then I'll be very impressed.
I've been writing CL on and off for many years and I've never found a use for iterate. It's not that I find it terrible, it's just not a big enough improvement over (built-in) loop to be worth the extra effort to me. By the way, the loop-is-hard-to-parse argument is nullified by using keyword symbols, which I find aesthetically more pleasing than iterate parens. The inconsistent indentation arguments are nullified by a properly configured Emacs. Finally, loop may be more verbose for certain tasks but, in general, I find it less dense and easier to mentally parse than the equivalent (condensed) iterate code. Sometimes, less code does not equal better code. 
Use slime-indentation contrib and set lisp-indent-function to common-lisp-indent-function. Look in slime-cl-indent.el for more details.
Well, you're on /r/lisp so it should be fairly obvious what a common lisp is. Also most lisp-ers are probably aware that ECL forked a while back when it was going through development difficulties, and that MKCL is the result.
The changes themselves are pretty easy to make. I should know; I recently updated [this largeish codebase](https://github.com/Kodiologist/Rogue-TV) for changes in Hy. Here's what you gotta do: - In each `require` form, change each module name `foo` to `[foo [*]]`. (`require` now works like `import` instead of just importing every macro unconditionally.) - Remove the extra pair of square brackets in `let`, `with`, and `defclass`. You don't need these anymore. (Tip: don't use `let` at all. Its days are numbered. Python's scoping rules don't provide any way to make it work like you'd expect it to work from other Lisps.) - Rename `slice` to `cut`. - If you used any of `throw`, `catch`, `progn`, `defun`, `lisp-if`, `lisp-if-not`, `filterfalse`, `true`, `false`, `nil`, or `nil?`, those synonyms are gone now, so use the remaining name, which is Python's in the case of things that already existed in Python (`raise` for `throw`, `True` for `true`, etc.). Hy is still unstable, which on the downside means we have growing pains like these, but on the upside, there's still the opportunity to help make the language what you want it to be. We could really use some more active maintainers right now. Hint, hint.
I don't know what you were trying to do at the time, but the lightbulb moment for me was when I realized you can write a lot of `scan-foo` functions just by using `map-fn` on another series, or `scan-fn`.
It hasn't hit 1.0 yet, so breaking changes should be expected.
thanks
Good point.
I am happy a book like this is being written, and I think the author's writing style is direct and straightforward, but it's my opinion that it needs more work. I'm extremely delighted to support Lisp projects in general, but some 35 USD is a bit much for some 70 pages of tips. At least based on the sample, the chapters need more depth and breadth. Lisp in production is fun but challenging and I think there's a book's worth of content about the idea. It just needs to come out in full form. 
[removed]
&gt; should ANSI X3J13 be obvious too ? Sorta. It's mentioned a lot in common lisp related literature (at least in cltl2 and clhs), so you are practically guaranteed to learn what it is, sooner or later.
Apparently it looks batteries included.
[removed]
How could one get the SERIES now? (ql:quickload "series") ? It looks there are folio2-series exists as well. What is the difference? Any modern supported fork around? 
yes, that's how you load it. series was almost a part of the language, so I'm assuming it's pretty much feature complete. it looks like folio2 is something else completely, but it depends on series. 
Thanks. One more question - how it compares to RxJava? For example how to wrap series with async and multithreading code, like to process in one thread and collect result in another?
It depends on a stack you are using. 
How does this compare to LFE?
So what's the proper definition ? a lisp dialect ?
Ignore this guy; Scheme, Joxa, Clojure, and others like them are all lisp dialects by any reasonable definition, but there's a minority that clings to a "No True Scotsman" definition where only Common Lisp implementations are allowed to be called lisp. The fact that he dismisses Scheme, which *predates* Common Lisp, is a pretty good indication that he's in that camp. 
I'm not sure what he thinks but being too hung up on what is and what is not lisp is losing game. So many things happened from early mccarthy era to dialects, to scheme, to common lisp, to eulisp/le lisp .. to ml and smalltalk who knows what else. Thanks for your comment though.
LFE is actively developed. Joxa is not. LFE is a Lisp-2+. Joxa is a Lisp-1. LFE attempts to be a transparent Lisp frontend to Erlang. Joxa attempts to be clean. LFE doesn't have gensym since atoms on the BEAM VM are not garbage collected making it a bad idea to produce them dynamically. Joxa somehow added gensym.
Could you define clean vs transparent?
My lack of knowledge about OOP shows with all the warning I get about my methods implicitly creating generic functions ( I used methods like I would use functions with the only difference I could use with accessor to save typing ( wich seems easy to imitate in noraml functions with macros anyway so even at the time I knew there was a problem but at the same it seems obvious that writing this layes correctly wil lnot afect the other ones later.. I just have to get to it )) 
I don't know an awful lot about Joxa, but it looks like their choices are more in the direction of "this needs to be nice or fluid to use with whatever changes that entails" whereas LFE is basically Erlang, written as s-expressions.
Well, I do - https://github.com/gwathlobal/CotD Though I do not use CLOS to its full extent and did not use macros.
:) It's a small world.
Looking a bit at the code ( I think the one I downladed was already compiled). I already notice things I maybe should be using.
Is putting everything I do except the key down and up events inside the :idle a correct way to do it ?
If it is a real time game - I think, it is. Though I have no experience with real-time games.
Hi, you might want to try out CL-SDL2 instead. Of course if Lispbuilder-sdl is satisfying your needs then no need to switch, but you might want to look into it.
&gt;Softwares 
[removed]
[removed]
You can actually do something similar to your C workflow if you want to. See http://www.xach.com/lisp/quickproject/ for a template but basically instead of a makefile you make an .asd file and you (asdf:load-system) or (ql:quickload) instead of running an executable. You can also build executables if you want to but they are big by C standards in SBCL (many MB) because they include the entire lisp implementation so that you can live program. My personal style is that I usually create a project like above and then live program with a repl but often write the code in the actual file and do C-x C-e with sly (fork of Slime) instead of writing directly in the repl. Then I test things in the repl and keep working.
If you want to redistribute your code to other platforms you will definitely want to hold onto your source code. I generally write my source code into a file, and then use SLIME to compile it into a running instance of Lisp. That way, I can keep my source code all together in a file, but still have the interactivity of a REPL. In theory, you could write a Lisp program that holds onto all of the source code in a database that it knows about, but this typically isn't done in Common Lisp. For quicklisp, if you want to distribute your program, it might be a good idea to distribute your dependencies with the program, in case versions change or your user doesn't have internet connection. you can use [(quicklisp:bundle-systems)](https://www.quicklisp.org/beta/bundles.html) to bundle systems together for redistribution. In any case, yes it is a good idea to call quicklisp from your code, but keep your quicklisp calls separated within your code so you can easily shift to providing already bundled libraries if/when you need to. &gt;I'm very used to the C style "write a file with a main function, and write a makefile to compile it with" The shift in thinking is that now every function that is at the top level is now a "main" function that you can interact with. So you write functions at the top level that do pieces of the program until you have one or two functions that do everything you need them to do. If you want to create an application that you can run from the command line for SBCL you can use [buildapp](http://www.xach.com/lisp/buildapp/). Fair warning these executables can be a bit large, so they probably shouldn't be used for a multitude of one-off scripts. I personally write my LISP files to compile themselves, but if you are designing a library, you should probably use ASDF - which is more or less the Lisp equivalent of Make. If I'm writing an application, I have a single Lisp file that does the all of the dependency building and loading for me (like a Makefile might). If I'm building a library, then I use [(quickproject:make-project)](http://www.xach.com/lisp/quickproject/). With [quickproject](http://xach.livejournal.com/278047.html), you get the added benefit of being able to load your library with quicklisp with no additional configuration. Choosing to compile applications using Lisp instead of ASDF is personal preference, and ASDF is fine to use for applications, too. HTH
No, of course nobody(well, that I know of) really keeps their programs as lisp images. General workflow that I've seen is editing source files, then recompiling relevant files/definitions (C-c C-c for definitions, C-c C-k for whole files) in slime. After that lisp will use new definitions(including functions), even for things that are already running. Calling quickload from a lisp program is perfectly fine, but you really should make proper lisp projects, especially if you are going to share that code.
PS: I get a lot of good comments and critics from the first version. Many of those has helped me make it better. I would love more opinions. Feel free to say whatever you need.
Sure, but you don't -have- to jump right into it. You can start in a more comfortable place and integrate the interactive development more as you go.
Quicklisp is built on top of ASDF. ASDF is sort of like make files, but it can include dependencies. You can create your own ASDF files and you can depend on systems in quicklisp and when you load your system it will load all the dependencies (recompiling any files that need it). Explicitly specifying the dependencies is far superior to calling quicklisp directly in a lisp file as ASDF manages the compile-time/load-time differences for you. There are 3 ways to have lisp find your ASDF file: * [Put it somewhere that ASDF can find it](https://common-lisp.net/project/asdf/asdf/Configuring-ASDF-to-find-your-systems.html#Configuring-ASDF-to-find-your-systems) * put it in a subdirectory of ~/quicklisp/local-projects/ (this obviously only works if you have quicklisp installed) * Manually load the .asd file with `asdf:load-asd` (new enough versions of slime are smart enough to use this function when you C-c C-k a file with a .asd extension) quickproject (which is in quicklisp) can generate a skeleton ASDF project directory for you. There are several other tools that will do the same. Saved images are primarily used for binary distribution; they are closest to a linked-executable by analogy with C. They are also useful when startup time matters (If you're going to write a program that will be called in a loop from a shell script, you want to save an image).
My personal style is that I use Emacs/SLIME. I write a function into a source file in Emacs and C-x C-e to load it into Lisp... Then, I test it in the REPL. If the test takes a good deal of setup, then I put the expression into my source file and just C-x C-j to run that in the REPL for me. If I have to make any tweaks to the function that I wrote, I C-x C-e them again when I've modified the source buffer. The trickiest part is that sometimes output that I'm expecting to go to my SLIME repl instead goes to the inferior-lisp buffer. But, with this approach, my source buffer always contains the thing that I last compiled. You can see me doing this... though without a whole lot of feedback about what Emacs keys I am pressing... here: * https://vimeo.com/21221157 * https://vimeo.com/72382085 Every time a section of my buffer flashes, that's a C-x C-e.
It's a lot like editing your .emacs actually. You make your changes in the source file then load them with a hotkey (in Emacs). Only real difference is where the code goes (to a running Common Lisp instead of to Emacs).
I also know C (and C++), and recently got started with Lisp. My idea is to learn the "ECL" way and do something like this: make a C project, handle the OS/low-level stuff there, and embed a Lisp interpreter in it, writing the higher level / main meat of the project in lisp. If this sounds as something you would do, this link may help: https://common-lisp.net/project/ecl/posts/ECL-Quarterly-Volume-V.html EDIT: Also this post (and generally the whole blog): https://chriskohlhepp.wordpress.com/advanced-c-lisp/embedding-lisp-in-cplusplus-a-recipe/
Thanks, this is what I intend to do. But I have a side question (sorry for opening this bracket). [how is the asdf path treated in msys2 "environment" on Windows ?] Detail: I am running sbcl (or ccl) in slime+emacs from a msys2 terminal, hoping for a working cl-ffi-gtk on Windows. The sbcl has been compiled in msys2 environment but I failed to find the location of the asdf default. 
I did a talk recently about this very topic. You might be interested to watch it. Please let me know if you have any questions about the video. https://engineers.sg/video/web-development-in-emacs-common-lisp-and-clojurescript-emacs-sg--1245
[removed]
You may be interested in reading "Creating a Common Lisp project – Part I" in ECL Quarterly: https://common-lisp.net/project/ecl/tag/quarterly.html#orgheadline24 It is a first part of three-part tutorial (from creating the project, through creating a gui to the deployment process) I'm writing. It's not ECL specific.
Well, I can not say for something that requires higher load, but for my needs Lisp is perfect. Closures are really a boon, you can pass information from one part of your program to another without much effort. Lambdas and first-class functions let me reuse code much more efficiently. The whole dynamic nature of Lisp lets me change parts of my system gradually. E.g., I recently decided to rewrite the code that handles turns into a simultaneous manner. With a statically typed compiled language I think I would have needed to complete the whole rewrite before I could start to test it. With Lisp I can do it incrementally rewriting only a part and testing it right on the spot, without touching the rest of the (now invalid) code. And REPL is a great help too when you can basically pause the game on some screen and, for example, adjust the relative positions of its elements to each other by changing and recompiling the functions that outputs that screen.
Because I wanted to link to the discussion, and not to the project page.
I'm a C programmer by day and Lisp programmer by night, so any questions, feel free to ask.
With true macros.
&gt; *do i just dump images and never keep my software in source form?* I hope you only included this silly remark for completeness. I came into Lisp from a varied background (heavy on C in the decade before that) in 2000. Basically, I just wrote code the same way as before: put it in a file, load it. I used the REPL for testing code, but anything important in a file first, and of course version control. Initially I did some "cute" things; I had Lisp projects built with a GNU Makefile, with dependencies like `foo.fas: foo.lisp macros.lisp` to rebuild `foo.fas` if `foo.lisp` is newer, or the macros have changed. Fifteen years ago I wrote an open source version control system in Common Lisp on top of CVS called Meta-CVS. It was released in January 2002. The code for this is self-contained; it has no external dependencies other than the CLISP implementation of Lisp and (of course) a run-time dependency on CVS. Inside the tarball (find it from here https://common-lisp.net/project/meta-cvs/) you can see a kind of funny hybrid approach. There is a Makefile (very small and simple) which controls the master build steps. The Lisp compiling is done with ASDF. A very old version of ASDF is packaged in the program, and its package is renamed to ZXCV (the keys on the QWERTY keyboard below ASDF) so that it won't clash with an existing installation of ASDF that might be present in CLISP. This project shows you how to make a stand-alone program with CLISP, which has custom bindings to the C library also, and also has a kind of "going from C to Lisp" point of view that could be helpful. If you have some serious application that you'd like to write in Lisp (particularly something non-OSS), I would strongly recommend disconnecting from any sort of ecosystem for package management. Include everything you need in the version control repo for that application, including a copy of the system building utility like ASDF. The following program is written in Common Lisp: http://www.kylheku.com/tankan/ The user sees a professional installer for Windows, and only executables. In the version control tree, I have everything: all the libs it uses, and a copy of ASDF to build and load them all. It's completely standalone. A small `build.lisp` file serves as a script: it loads `asdf`, gets it to compile and load everything and then dumps an executable image. The approach isn't so different from Meta-CVS, except that there is no pointless Makefile (the build steps are scripted in Lisp) and there are quite a few third-party libraries in it (more stuff for ASDF to build). Even though I haven't touched this program for several years, I can go back and work on it at any time. Almost everything from which it is built is frozen in the repository; it won't be breaking because of the latest version of this or that being incompatible with the code or some other thing. Moreover, I can do that on a newly minted development machine that has absolutely no Lisp setup, other than just an installation of CCL. The thing can be built from the CMD.EXE prompt on Windows. The application is paired with a web service for licensing (which I hacked from scratch). It's built from the same code tree. That uses CLISP and runs on Linux; a build script loads the code and dumps an executable which serves as a CGI program, and doubles as a command line utility for license administration, in the same program. Basically, it's not rocket science. Just the same old programming: identify the pieces that are required and bring them together in a way that you control with your level of comfort. 
Haha I've tried the makefile thing and quickly realized that it's sub-optimal. And the image-dump comment was a bit of a dry joke, thanks for noticing :)
I may be wrong here but I recall reading that invoking lisp callbacks from foreign threads is something you're not allowed to do - I don't think SBCL supports it. try emailing the dev list 
Ok that's useful to know, I definitely read some years ago that it wasn't allowed but maybe that was a different implementation 
So what semantic mess of what language has Joxa cleaned?
I just pushed chapter Conditions to git. It'll take up to an hour for my hosting to pull the fresh version - but, the fourth chapter is done.
This is a really awesome idea and great effort
+1
what about nginx + lisp?
I want to add that I would appreciate if the formatting of the excellent [standard](http://mr.gy/ansi-common-lisp/satisfies.html#satisfies) was retained. I format my library documentation the same way for uniformity. Also see [Notational Conventions](http://mr.gy/ansi-common-lisp/Notational-Conventions.html#Notational-Conventions), or more generally the chapter on [Definitions](http://mr.gy/ansi-common-lisp/Definitions.html#Definitions).
If you go through the trouble of collecting that kind of data you should use it to create a plot, to get a quick overview and comparison of the results.
I see "this channel is offline". And it has very very old comments. Why?
[removed]
This is pretty awesome.
At least the mapcar+lambda thing could be optimized by the bytecode compiler. It's just that nobody has taken the time to do so.
I think the article you linked is arguing in favor of efficient system design over micro-optimizations. From the article: "What Hoare and Knuth are really saying is that software engineers should worry about other issues (such as good algorithm design and good implementations of those algorithms) before they worry about micro-optimizations such as how many CPU cycles a particular statement consumes." All of the optimizations listed in the article have that cycle-county nature to it. These are exactly the types of things that are easy to change late in the software development cycle. Choosing things like not using lambdas for higher-order functions and unrolling loops don't seem like a good idea to "be applied at all times as a matter of style".
Thanks! Though I do [keep an eye on it from Emacs](https://github.com/skeeto/.emacs.d/blob/694b79e206ceb5c6758a70609adefcd24cadab12/etc/feed-setup.el#L240). There's a lot more feedback on reddit and Hacker News than in my measly blog comments.
[removed]
[removed]
&gt; The phrase premature optimization comes from a time That may be its origins but that's not its general meaning and usefulness today. I've been around for a while, and it's almost universal that developers are tempted to waste time worrying about making low level code cleverly efficient, at the expense of being more obscure and fragile, having little effect on overall performance. Efficiency issues usually boil down to high level algorithms, and data structures used. Low level tips like here usually are only important when they're in a tight loop - most importantly an *unavoidable* tight loop.
If all goes according to plan Overlord should be out next week.
[removed]
I will check this out. Thank you!
[removed]
Emacs
On the Mac you can use the Clozure Common Lisp IDE as an editor, it works quite well.
If you're using the clojure dialect, [Light Table](http://lighttable.com/) is another option (although I like emacs best).
A "few decades" is stretching it. I switched to Emacs exactly 12 years ago, and I have an understanding of it that far exceeds "learning it in detail". Learning it in detail, to me, is possible after 1 year of continuous use. That will bring someone to the level where basic Emacs usage (that includes most useful/important packages and libraries) is second nature, and most importantly where one can customize Emacs at runtime through Emacs Lisp, at will, in order to accomplish pretty much anything one desires (within the constraints that Emacs imposes). 
In Clojure, there's also [Cursive](https://cursive-ide.com/).
GNU Emacs + SLIME for Common Lisp. GNU Emacs + Cider for Clojure. 
This is pretty meta haha 
DrRacket is nice if you're not using anything better — it's a great way to get good IDE + language integration with no effort, which makes it excellent for newbies especially — but I think emacs is still a better long-term option even for a Scheme. 
I agree with both parts of this. I started with Light Table for Clojure then eventually moved to emacs because of problems caused by the community handover they did around the 0.8 version. LT does a lot of nice things out of the box, almost feels like a "modern emacs", but ultimately you can do pretty much anything LT does in emacs anyway and it's less prone to abrupt change. Honourable mention also goes to [Nightcode](https://sekao.net/nightcode/) (and its cousins, [Nightlight](https://github.com/oakes/Nightlight) and [Nightcoders.net](http://nightcoders.net/). That guy is apparently addicted to making Clojure editors...). It and its derivatives attempt to give Clojure and Clojurescript a vaguely DrRacket-like easy-to-start experience.
GNU Emacs + Geiser for Scheme.
Is there good integration with Slime for Atom?
emacs
fully switched to emacs from vim in a couple of weeks
Thank you. That's excellent news.
Lovely :-&gt; Edit: Lisp smiley
Very cool. Looks like it has code for playing notes as well. I'm curious, it doesn't have Lisp macros. Is that because the Lisp would have to be written in Lisp first?
I am not sure. Perhaps the easiest would be to ask directly the author, on Twitter.
Here's a quick demo video: https://www.youtube.com/watch?v=4tDGtt2T-wI&amp;feature=youtu.be
PCL has some extensive "practical" parts that describe the process of writing simple applications. Do you follow these and actually *write* the same code, as in typing it on the keyboard, and not just read it? Do you toy with the results and/or the code that was written? Do you see how the results change according to your modifications? Additionally, you could support yourself with Lisp Koans and writing your own solutions to 99 Lisp Problems. In general - don't worry. I ended up coming back to PCL over and over multiple times over the span of months as I was learning Lisp, and I most likely will come back to it again multiple times.
You can't use a package in a form, when the package does not exist yet. Use something like (funcall (find-symbol "INSTALL" "QUICKLISP-QUICKSTART") ...)
Hi, CL beginner here. I myself enjoy the resources of [lisp-lang.org](http://lisp-lang.org/wiki/article/recommended-libraries) or [awesome-cl](https://github.com/CodyReichert/awesome-cl). I pick up some libraries and try to do real stuff (web scraping,…).
I also would recommend Emacs + SLIME + show-paren-mode and maybe ac-slime for autocompletion if you want that.
Try porting your old projects or writing small projects/utilities. For example, when I first started learning, I ported a small compact genetic algorithm program that I wrote in Python to Common Lisp. Also, you might want to learn how to use Quickproject's make-project to create a proper ASDF project and also learn how to manage dependency (and all that jazz).
Hope Edit: I didn't intent to post the comment above. I am sorry if it was interpreted in a way that seemed callous towards the bad news. I did intend to post something along the lines of "Hope Gary Byers gets better. He has always been helpful on #ccl" But closed the tab because I didn't remember it gbyers or rme that answered some questions I had during the last 'office hours' on #ccl. I must accidentally pressed enter before closing the tab.
Why? 
+1 for Quickproject, and don't worry about them being at the end. Just start reading them, and the moment there's something you don't understand, find that part of the book or ask on #lisp or #clnoobs on Freenode.
My advice is to finish reading PCL, then work through the Common Lisp exercism track: http://exercism.io/languages/lisp/about Each exercise doesn't take very long to finish and you get great feedback.
I guess PPop meant "hope Gary gets better"
I highly doubt PuercoPop meant anything rude. *Especially* coming from PuercoPop. 
[removed]
Probably because the "add macros" task hasn't yet bubbled to the top of the maker's prioritized TODO list. 
Although at agree that the readme is not concise currently I chalked to still being a project in flux. As I understand, it is similar to the racket module system in that you you specify a reader for the module (which is delimited as file in this case). For example, cl-yesql which with some additional annotations reads an SQL file and creates the corresponding functions in CL. Also it is similar to redo in that it re-compiles target files when dependencies have changed. Ideally the latter behaviour would be implemented at a function level by the compiler to make it easier to work with in-lining.
Answered in [/r/learnlisp](https://www.reddit.com/r/learnlisp/comments/5t1ims/slimesbcl_why_does_this_fail_in_slime/).
&gt; The important difference is that Overlord uses **two scripts per target: one for building the target, and another for computing its dependencies**. This (mostly) replaces the need to maintain a database of dependencies. Could you expand on this? As a redo user who even dabbled in an implementation I'm intrigued how this would work. Each run, I assume the first time a target is requested, the dependecy computing script is run, and then the result is cached for that run? That seems like it could be slower than the database approach because you have to run code for every target that needs to be checked even if you don't end up building it... but I guess those scripts are usually pretty trivial? How does this work for things like header dependencies where you don't know them until *after* you build? I considered the handling of that one of redo's strengths. Also, does overlord handle rebuilding in response to changes in the dependency computing and the actual building script? Does it only rebuild things that actually were built using those scripts when they change and not everything (e.g. Makefiles are typically setup to force a full rebuild if they change)? If so how? Do the scripts always live in separate files that you hash as a whole like redo does, or do you somehow detect the common lisp function has changed, or ...? This is something I struggled with in my python implementation.
There are separate dependency and init scripts, but the execution is interleaved, so things like header dependencies would work the same way they do in Redo. Scripts live in CL files. The trick is that when a target is defined, a hidden target is defined with its (quoted) script as its value, and the target being defined is made to depend on that hidden target. So, ignoring for a moment the question of separate scripts, something like (file-target build-my-file "my-file.txt" script....) Expands into something like (define-script build-my-file.do 'script...) (%file-target build-my-file "my-file.txt" script... (:depends-on 'build-my-file.do))
You're right. It just compares the old and new definitions literally (at the s-exp level). It would be nice to catch function redefinitions, of course. But then even redo has no way of knowing if you have, say, upgraded to a new and incompatible version of some command-line program in the system path.
Exciting! Will check it out.
I haven't used Emacs in a long time, and i never used it extensively, but I intend to pick up `mg`, a "microemacs" with compatible keystrokes. 
If CCL works best for you, there is no reason to change at all. 
Thanks!
Had no plans for that, but I can look into it if you would like
please do!
[removed]
[removed]
Is it safe to assume that you are planning on taking part in the 7-day rogue like contest coming up on March 4th?
Scsh has the following features: - a pretty complete wrapper for the POSIX API (`fork`, `dup`, etc.) - "process notation" for redirects, piping, backgrounding processes, etc. E.g., `(run (| (ls) (grep "something")))` (another example [here](https://scsh.net/about/what.html) - It's Scheme 48, so you get a real module system and good abstractions - Easy to mix Scheme and sh commands, e.g., `(let ((x "foo")) (run (cat ,x)))` - `rx` regular expression package, which uses an s-expression notation (allowing for macros, etc.) - an `awk` macro useful for processing records and fields in files The best place to get started reading about it is the [original design paper](https://scsh.net/docu/dessous.html). You can read more about it in [the documentation](https://scsh.net/docu/html/man-Z-H-1.html). Feel free to PM me if you have any questions, etc. I'm not an "expert" but I've used it off and on for a while.
This one implemented for exercism.io task: https://bitbucket.org/mihailp/tankfeeder/src/fe014c4554fc9bdde3c6315f2a67c2ccdd2ffb5c/forth.l?at=default&amp;fileviewer=file-view-default 
[removed]
I was always in "Emacs camp", but recently tried out [Spacemacs](http://spacemacs.org) managed configuration for it, with Evil mode, lazy loading and all that. And after about 6 months, I'm just so used to it, plus don't have to go through all the manual configuration pain, now I run it across OS X, Linux and Windows between home and work. Emacs with Vim style editing is great, kind of combines 2 greatest ever created editor methodologies in one. May not be everyone's cup of tea, but I highly recommend to try it. There are couple of absolutely "must do" things with it to be more useful, like setting: (setq-default evil-escape-key-sequence "jj") ; "jj" when in qwerty, "hh" when in dvorak (setq-default evil-escape-delay 0.2) inside of ~/.spacemacs configuration file, inside of: (defun dotspacemacs/user-init () ...) Hope it's helpful to somebody. Cheers!
I admit I don't know much about Haskell, so I can't comment on it. Lists are important to LISP because LISP represents it code internally as lists. This means that any operation that you can perform on a list, you can use to manipulate your source code as well. This may not seem like a big or important thing, but it is at the core of why is LISPs has survived. **You write programs that write your programs by manipulating lists.** The higher order functions are a useful part of the toolbox for doing this, but the low level ones like car and cdr also see a lot of usage. The best way that I have seen it summarized is: When you are writing LISP code, you are directly creating the Abstract Syntax Tree that the compiler will operate and you can use the full power of the language to automatically generate large chunks of your programs for you.
Lisp stands for list processing. It's a programming language based on the logic model of recursive functions. So recursion is very important. I'm not an expert but McCarthy was probably thinking more about recursive functions than functional programming per se. It just so happens that using recursive functions usually results in functional programs.
&gt; Hassle lol
Lisp is still #1 for key algorithmic techniques such as recursion and condescension.
Lists are great because you can support so many data structures with them. - Lists - Stacks - Queues - Arrays - Trees - Sets - Pairs - Structures - Etc. You could also use arrays to represent these things, but Lists have the advantage of being useful in a functional context, since *you can add to the front of existing lists without needing to copy the data*, and lists have a *recursive definition* which makes them easier for functions to dissect. The implementation of lists in Lisp is similar to Haskell, although *Haskell is lazy*, while *Lisp uses eager evaluation*. Higher order functions are not essential to programming in Lisp, but I find them more practical to use vs. loops. 
&gt; A striking difference between Lisp lists and Hassle lists is that Hassle lists are constrained into containing elements of all the same type. I would say that this is actually a rather banal, if intentional, difference. Cons cells more closely correspond to Haskell's `data` statement than the `[]` type in that they are used for constructing arbitrary product types. They are essentially Haskell's `tuple` data type, but constructing lists out of tuples would be quite restrictive in Haskell's type system. The more interesting difference (between cons lists to Haskell's list type) is due to the different evaluation strategies of the two languages. In strictly evaluated languages (functional or not) lists are data structures, and inefficient ones at that on modern hardware. You put things in them, slice and dice, and get out a new list. This is a not-uncommon use of lists in Haskell as well, though more compact data structures are typically preferred for non-trivial amounts of data. The more common use of lists in Haskell is not as data structures, but as control-flow structures. What I mean by this is that Haskell programs are often built as list processing pipelines where cons cells move intermediate results down stream. Lazy evaluation allows this to be a reasonably efficient way to structure programs, since the intermediate lists are not forced into memory at each stage of the pipeline. Most lists in Haskell never exist in memory in their entirety at once, and in many cases the compiler eliminates them entirely. Viewed like this, Haskell's lists function more like iterators, allowing loops to be composed as sequences of list operations. 
Homoiconicity is the key point. Note that lists aren't a "real" data structure in Lisp, instead the "real" data structure is the cons, which is a simple structure with two pointers; conses are nodes for a binary tree. Binary trees are extremely important data types by themselves, but they are especially important in Lisp because programs are represented as binary trees. In other languages like C, the parser parses the source code into a binary tree representation before the final compilation steps. In Lisp, the source code IS the binary tree representation, and this is the defining characteristic of Lisp. Lisp is different in this respect in that macros are so much easier to use than Template Haskell, because Lisp source code (the binary tree representation of code) is a first class data type, or rather, Lisp code is an ordinary data type in Lisp, therefore Lisp can manipulate Lisp code ordinarily, like one might add two numbers together in non-Lisp languages.
Condescension is the attitude some Lisp programmers have towards people who don't know Lisp very well.
In general you are right, but sometimes it *is* a good idea to manipulate lists and pass them to `eval`. For instance doing [genetic programming](https://en.wikipedia.org/wiki/Genetic_programming) in lisp is much easier than most other languages *because* you can do that.
object-oriented elisp... someone flush me down please
Please don't post links that require registration.
Here's the blog post content without the pretty pictures. (/u/JuanitoJons tell me if you want this removed): Common lisp sockets I want to use sockets under common lisp, so I am going to create a two simple functions the first one serve-socket and the second client-socket, I am going to use usocket library. - Load the library: (ql:quickload "usocket") - Change to usocket library (in-package :usocket) - Create the functions: (defun server-socket (port) "Listening on a port for a message, and print the received message." (usocket:with-socket-listener (socket "127.0.0.1" port) (loop (usocket:with-connected-socket (connection (usocket:socket-accept socket)) (format t "~a~%" (read-line (usocket:socket-stream connection))))))) (defun client-socket (port message) "Connect to a server and send a message." (usocket:with-client-socket (socket stream "127.0.0.1" port) (format stream message) (force-output stream))) - Test Call the function USOCKET&gt; (server-socket 9090) with netstat -tap linux command we see: tcp 0 0 localhost:9090 0.0.0.0:* LISTEN 4103/sbcl The server is ready! With other sbcl instance we need to run client socket then: Load the library: (ql:quickload "usocket") Change to usocket library (in-package :usocket) call the function USOCKET&gt; (client-socket 9090 "Hello world !") The server has : USOCKET&gt; (server-socket 9090) Hello world !
[removed]
[Portacle](https://shinmera.github.io/portacle/) is also awesome.
[removed]
Thank you for that and the other tidbits. I find them useful at least from an explorative point of view. 
1) There are the shell commands for doing several tasks in that post, including how to change directory. 2) Locating .emacs can be difficult for a first timer. 3) It lacks saving instructions and restarting emacs (or if there is a combination to reload the configuration file) yes, they should be added. Thing is that a tutorial should be all the time at the same level, so if there are instructions about changing a directory there should be instructions about opening a file. Also, in an introductory tutorial there should be no assumption about one knows. Take as an example -a bad one- how the [org mode tutorial](http://orgmode.org/worg/org-tutorials/orgtutorial_dto.html) by David O'Toole starts. You reach the section **The basics**: &gt; This section illustrates basic org-mode usage by showing how I used org-mode to create this document Great!, I want to learn. I follow a bit more and... &gt; First I entered a **headline** called "Tasks" to keep tasks under. Headline? How the fuck do I do a headline? No link, no explanation. Despair... *(I have a cheat sheet and I found how to do it)*
Gotta love how simple and powerful Forth is :-)
good advise!, thanks
[removed]
This could use some exposition about what all these things do. Sure you know what they do, and I know what they do, and most people on this subreddit knows what they do, but this needs some explanation. Btw, that's actually a nice diagram.
it makes no sense to pretend that sublime is a good editor for Lisp, since its integration in and its support for Lisp is so weak. Just tell it how it is: primitive. Wanting to 'lint' Lisp code additionally hints at a wrong approach to use Lisp.
Like I don't disagree with you, that it is a weak tool for writing Lisp. primitive is accurate. my point was that they said it was the "wrong" tool. It's hard to see why they would say that it is the wrong tool when it can be used and works. For someone who might be completely new to Lisp, they might think that they actually *need* a special tool in order to edit lisp code. But really you can just use notepad and be fine. I prefer Emacs, but notepad works. I also agree that wanting to lint is odd and probably comes from a misunderstanding.
Sure is. It was made by guicho271828 for the Japanese Wikipedia entry on CLOS (which I reused in the Spanish entry https://commons.m.wikimedia.org/wiki/File:Method-combination.png#mw-jump-to-license
Thanks, I saw this diagram before, but didn't knew it was guicho271828 who made it. That said, it would be nice if the original poster/blogger bother to attribute the diagram to guicho271828 in the "article" itself.
Yes, please do try it out! This is the first announcement for Vlime, I would be grateful for any feedback.
There are still features and bugs to work on, so I will focus on Vim for now.
What is wrong with linting? I would love to see additional information from compiler/linter with suggestions for style or potential missuses of APIs. I can't see any difference with CL to any other language concerning linting.
Thank you.
[removed]
&gt; where loading or reloading the definition would want to pick up a new value of the variable that's what I meant by "programmer intervention". also what I meant by "can be easily changed by the programmer during development" defconstant is used for actual constants: things that won't change in the real world like the value of pi or e or the number of bytes in a megabyte. because of the way defconstant works (using eq to compare for redefinitions) it can be really impractical to use, so I almost always prefer defparameter. operationally you are correct. practically the name "defvar" implies that you are declaring a variable; something that the system expects to change. the name "defparameter" indicates you are declaring a parameter of the system. parameters change the system and are set by the programmer. variables are changed by the system.
[removed]
I like sharing lisp stuff :) , so my account is not a spam, have a nice day!
&gt; I like sharing lisp stuff Not as much as your love of using huuii.com, right? Or you and your friends love of small(-ish) subreddits because of their lack of spam prevention. **EDIT:** &gt;my account is not a spam Sure. Stealth marketing, social network engineering, etc., whatever, it's all the same.
The problem is that I am using huuii.com? But I write a little code and sharing , I think that it is not bad or yes?
Thanks for the feedback! I hesitated while making this decision too. But I'm not sure what you mean by "periodically prints to output". If it's (format t ...), the read-only REPL buffer should be able to capture all the output, whether they are periodical or not. And there is actually another reason for this decision. I wanted to support swank-presentation in the REPL buffer, but couldn't find a good way to associate the presentation IDs with mutable text. A read-only buffer made everything easier. All those said, the decision to make the REPL buffer read-only is not final. It's more like a compromise. I may try other solutions. P.S. Sorry for the delayed reply. I live in a UTC+8 timezone.
hmm. I think I got the interpretation from Paradigms of Artificial Intelligence Programming (I can't remember). You might be right (I don't know) that it was originally meaningless, but I still like my interpretation and think it's a useful way of looking at them.
&gt; that's what I meant by "programmer intervention". also what I meant by "can be easily changed by the programmer during development" It's also later when the user uses (!) the code. Let's say you are using a Lisp Machine and there are two variables: \*console\* and \*max-serial-speed\*. The \*console*\ points to a data structure which represents your current console interaction (a local console, an X11 console, a console on the Mac, ...). Now, I'm loading a new version of the software or patches to it. Define \*console\* with defvar, then it wouldn't try to create a new console object when loading the software (locking me out) and I would hope that \*max-serial-speed\* picks up the faster speed with the new update. Thus define it with defparameter. Thus it makes a difference, when the user use it and loads it. Not just during development. 
Overall looks very cool and promising! Please don't stop working on it)
Ah, I mapped &lt;CR&gt; in normal mode so that it won't interfere with multi-line editing in insert mode. The change in window sizes is an issue I'm aware of but not yet been able to deal with. I'll add that to the list of known bugs.
Thank you very much for your quick feedbacks.
1. (map 'list 'list '(1 2 3)) or (mapcar 'list '(1 2 3)) 2. (map 'string 'digit-char (list 0 1 2 3 4)) 4. (map 'vector 'identity (list 1 2 3)) 5. use identity 6. use mapcar and cadr instead of (car (cdr ..)) (and maybe first and second instead of car and cdr)
Nope. `defparameter` is for a variable that must change to the value specified in the `defparameter` form when that form is evaluated. `defparameter` doesn't define a new kind of variable that is distinct from the kind defined by `defvar`. Lisp has only one kind of dynamic variable. Whether such a variable is expected to change or not has nothing to do with whether it was introduced by a `defvar` or `defparameter`. I don't see anything in ANSI CL about any expectation that `defparameter`-defined variables are expected not to change, whereas `defvar`-defined parameters are. That's just some cargo cult thing. 
The construct doesn't support your interpretation, so it is a convention only. If you work in a team, that will cause problems; others will not understand or abide by the fiction that you're imposing on the constructs. There is a much better case for using `first` and `rest` in certain situations and `car` and `cdr` in others. But those are straight synonyms. If `defvar` and `defparameter` were exact synonyms like `car` and `first`, then their only rational use would be to express some convention. They are not synonms; they do something differently. Analogy: you could use `(psetf x y)` in some places in your code to carry some annotating convention which has nothing to do with the parallel semantics (that doesn't even apply when there is only one place being set). If you want to annotate dynamic variables for certain purposes, it's better to write your own macro that expands to `defvar` or `defparameter`: `define-my-kind-of-var`. Don't hijack existing vocabulary. 
It is a convention. That's why I used the words "practically", "implies", and "indicates". It's not exactly a fiction when I'm using the definition of the words "parameter" and "variable" to derive the meaning the macros "defvar" and "defparameter". I'm also not saying they are synonyms. I am saying that they have practical meanings in reality. You said that the difference is meaningless, implying that they are basically synonyms. I gave benefit of the doubt to the language designers for choosing names that were meaningful and good, but it is of course possible that they accidentally chose these names and they are ultimately meaningless. Of the two cases it seems more likely that the designers of the language thought it through. I'm not hijacking existing vocabulary when I am using the definition of the words to derive meaning and convention. That's actually just called "interpreting". You could say I am "interpreting existing vocabulary". From Google Dictionary: parameter: "a numerical or other measurable factor forming one of a set that defines a system or sets the conditions of its operation." variable: "an element, feature, or factor that is liable to vary or change."
&gt; That's just some cargo cult thing. It's about communicating your intention. A parameter is a value that doesn't (or shouldn't) change. And a variable, or var, is *expected* to change. &gt; Nope. defparameter is for a variable that must change to the value specified in the defparameter form when that form is evaluated. If you really want to pick nits, it **establishes a binding** to the `initial-value` without having changed anything. &gt; I don't see anything in ANSI CL about any expectation that defparameter-defined variables are expected not to change, whereas defvar-defined parameters are. It's the first paragraph on page 87 of Common Lisp the Language, 2nd Edition: &gt;&gt; **`defparameter` is similar to `defvar`, but `defparameter` requires an `initial-value` form, always evaluates the form, and assigns the result to the variable. The semantic distinction is that `defvar` is intended to declare a variable changed by the program, whereas `defparameter` is intended to declare a variable that is normally constant but can be changed (possibly at run time), where such a change is considered a change to the program. `defparameter` therefore does not indicate that the quantity never changes; in particular, it does not license the compiler to build assumptions about the value into programs being compiled.** 
Ok cargo cult is an interesting choice of words here. Because cargo culting is all about copying practices of others without understanding or recognizing the _original intent_. To say that the difference between the names parameter and variable is meaningless implies that there was _no original intent_. By looking at the definitions of the words parameter and variable; and looking at their use, you can either choose to see them as "meaningless" or as being well chosen words that specify intent. Do understand that analyzing the meaning of words that were clearly carefully chosen by the language designers is the _exact opposite_ of cargo culting. It comes from an understanding of the nature of language design and an appreciation for the level of thought that went into designing Common Lisp. Choosing to believe that the origin of the words is meaningless is actually _very similar_ to cargo culting.
[removed]
Emacs, and live in Emacs. Elisp fulfills all your requirements
[removed]
&gt; You would introduce a global variable with DEFPARAMETER. It can get an initial value and a documentation string. DEFPARAMETER requires an initial value. 
Last time I checked you can supply extra rules to normal lint as well. So you are talking about technical limitations of potential not-existing lint for CL. But it is not what lispm meant I assume. For example now when I write in CL I compile my code with different compilers to see different compiler warnings/notes. I absolutely see the lint helping me with all that - carefully analyzing the stuff I've written, where I could add exceptions or additional rules etc.
OK, you may have a point there. Although I wonder what form the linting definitions would take. Something similar to macro or compiler macro definitions in the source code? 
[removed]
Sorry, just messing around at that moment it time. Should be up again.
Cool to see another person working on lisp-based music, especially the experimental variety. Do you plan to upload the source anywhere? I've been working on [my own lisp library for sequencing](https://github.com/defaultxr/cl-patterns) and so far I've mostly been messing around with cl-collider (lisp interface to supercollider) and incudine as synthesis backends for it. Have you looked into either of those projects (or any of the other lisp music libraries) and if so, how does yours differ? The sound samples are interesting and cool btw, keep it up.
[removed]
From bits of books I remember while searching for the relationship between LISP and ML. ML programmers wanted to escape the List everywhere and have a way to keep some of the benefits of LISP (recursive/inductive reasoning I guess); so they formalized the notions of sum and product types as a more general data structure creation concept; which could re-encode LISP cons lists: List of a = Cons a (List of a) OR Nil And anything else you'd like to express (I guess having explicit Tree types instead of treating sexps as trees invisibly). I believe Haskell inherited this.
[removed]
Super interesting! I read it some time ago and found this approach certainly powerful. Paul Graham is a functional programming hero
If your code above is in a file called test.lisp, then in a freshly launched SBCL: (setf sb-ext:evaluator-mode :interpret) (load "test") works just like the other Lisp implementations. http://www.lispworks.com/documentation/HyperSpec/Body/03_bbc.htm notes that, &gt; All conforming programs must obey the following constraints, which &gt; are designed to minimize the observable differences between compiled &gt; and interpreted programs: &gt; [...] &gt; A call within a file to a named function that is defined in the &gt; same file refers to that function, unless that function has been &gt; declared notinline. The consequences are unspecified if functions &gt; are redefined individually at run time or multiply defined in the &gt; same file. Because test.lisp defines #'next twice, it isn't a conforming lisp program. So I tried moving the first three lines into a separate file, loaded first. Now the program is conforming. However, the problem remains. So it does look like a bug in the SBCL compiler that inlines old-next from line 7 into lines 9, 12, 13. That would explain the stack overflow on calling (next 0), and also your printouts: T, NIL, that make it seem like old-next's value is mysteriously changing without being told to.
One of the reasons I find his work not especially exemplary when it comes to Common Lisp.
Could you elaborate?
Paul Graham's books about Common Lisp leave out a lot of the good stuff about Common Lisp that he doesn't like because they aren't his kind of Lisp.
A reminder that /u/JuanitoJons is a spam account that was created to promote/push huuii.com by astroturfing. **Backgrounds:** You can see that the domain huuii.com started to appear on Reddit 6 days ago, on February 21, 2017: * https://www.reddit.com/domain/huuii.com/ All of the links to huuii.com were posted by 3 accounts; all of which were also created on February 21, 2017 as well: * https://www.reddit.com/user/Yarentzy * https://www.reddit.com/user/jesmcg * https://www.reddit.com/user/JuanitoJons For about 6 days since creation, these 3 accounts did nothing else other than posting links to blog spam posts on huuii.com. Note how the links were appropriately downvoted/moderated on all other subreddits (despite the fact that the posters attempt to make huuii links "fit" into the theme of each subreddit). The only subreddit that this astroturfing had any success (so far) was, unfortunately, /r/lisp.
You are mixing (and confusing) read time with run time. In your second example, `#1#` isn't the result of `(list nil)`, but the literal list `(list nil)` (a list with two symbols). At run time it is evaluated twice, so you get different lists. Anyway, you should never modify at run time data created at read time. It's in the CLHS somewhere, and if it isn't, it should be, because it almost never works.
[removed]
*constant*: n. 1. a constant form. 2. a constant variable. 3. a constant object. 4. a self-evaluating object. [ANSI CL] *constant variable*: n. a variable, the value of which can never change; that is, a *keyword* or a named constant. "The symbols `t`, `nil`, `:direction`, and `most-positive-fixnum` are constant variables.'" [ANSI CL] Oops: blatant oxymoron! Also, "parameter" is most often used in computing (including Lisp) as short for "formal parameter": the local variable which receives a function argument. In mathematics, formal parameters are just called arguments. The word parameter refers to some understood additional arguments which we don't have to spell out (essentially, curried arguments). The written convention is that these are separated with a semicolon: f(x, y; z) = x + y + z. Here, f and y are arguments, and z is a parameter. It has some contextually understood value, so elsewhere we write the invocations of f just with two arguments: f(s, t) or whatever. Speaking of the ANSI CL glossary, it also defines *parameter* for us: *parameter*: n. 1. (of a function) a variable in the definition of a function which takes on the value of a corresponding argument (or of a list of corresponding arguments) to that function when it is called, or which in some cases is given a default value because there is no corresponding argument. 2. (of a format directive) an object received as data flow by a format directive due to a prefix notation within the format string at the format directive's point of use. See Section 22.3 (Formatted Output). "In "~3,'0D", the number 3 and the character #\0 are parameters to the ~D format directive." Nothing here whatsoever about *defparameter*, oops!
Sharpsign-sharpsign is a special *read notation* which allows us to express objects which are not just tree structures, but more general graphs: objects with shared substructure and even cycles. Well, interned symbols already let us express a shared substructure. When we write `(a a a)`, all three occurrences of `a` are turned into the same symbol value which is essentially a pointer to the symbol object. What you are doing in your example is expressing shared substructure in the syntax. The syntax you have written is an object similar to: (list '(nil) (setf (cdr '(nil)) 'new) '(nil)) except that the three occurrences of the `'(nil)` syntax are actually the same object. This is perfectly fine, and irrelevant to the real issue. The problem here is that when this expression is evaluated, it modifies a literal, which is a form of self-modifying code and undefined behavior according to ANSI CL. Whether or not we have the shared substructure there via the sharpsign-equal notation or not, this is questionable code. Note that a Lisp compiler **is allowed to do this substitution anyway**. That is to say, not only is your syntax fine, but a Lisp implementation can take the ordinary expression: (list '(nil) (setf (cdr '(nil)) 'new) '(nil)) and collapse the multiple occurrences of the `'(nil)` literal to a single object. That is one of the reasons why modifying a literal is not allowed. Or, other way around: not defining the consequences of literals being modified allows optimizations such as shared substructure between separate literals.
&gt; Oops: blatant oxymoron! I'm not sure what point you are making about constant variables. I simply said I prefer not to use them because of their _practical_ behavior when it comes to redefining already defined constants. Clearly defparameter is defining a dynamic variable which is not the same thing as a formal parameter. I believe that maybe it means the other definition for parameter: the one I suggested. Interestingly, in English, words can have several meanings. I understand the confusion this brings about, but one has to accept the meaning that makes the most contextual sense. /u/defmacro-jam already pointed out the meaning of defparameter in one of his replies, so at this point I think I'm done with this argument. Feel free to have the last word.
Yes - at bottom, on the right side. **touched: 2015-10-09**
yep
I find this one pretty impressive: &gt; CMUCL compilation notes can detect more subtle type problems than those detected by OCaml (e.g., argument falling outside an integer range). do you have an opinion to share ?
This seems nice, and it is the sign of a laudable engineering effort on the CMUCL compiler. However, it sounds like the claim could be a bit overstated. Several languages (for example Ada, and Racket using the contract system) let you define integer ranges as types, but it often turns out to be much less usable than you could expect. Either the compiler ignores the specification (what do other Common Lisp implementation do?), or they have a very restrictive static check that in practice makes those subtle types very hard to use (they don't know how to do the (complex) reasoning to check that a variable remains in range after a non-trivial computation), or they insert dynamic checks in a way that may affect performance and you have to be careful about. In contrast, types in a ML-family language come with a baggage of things that we know work fairly well (type inference, modularity of type checking) and we come to expect levels of usability that are hard to preserve with arbitrary "subtle types". I think that this is a compromise, or a matter of understanding what problem domains will benefit from the feature and at which usability cost. I have no experience with Common Lisp type annotations and their support in existing implementation (I guess SBCL would be the reference these days), but I suspect that they remain sensibly less usable in common practice than OCaml's type system -- they are, after all, more geared towards specialization/optimization than static verification.
Shen is one: www.shenlanguage.org/ There's a reddit: http://www.reddit.com/r/shenlanguage/ It's type system is Turing complete, but unfortunately not written using s-expressions.
I believe it has a tiny core and everything else is written in that making it easy to implement by implementing the core in whatever. 
Could you expand on that?
typed racket
Yes, I've seen this touched date, but was more interested in the information /u/gasche has provided - i.e. which of this points are still relevant. It was very interesting to read.
You are confusing code and data. try this: (let ((lambda-body (loop for i in '(0 2) collect (list 'nth i 'x)))) (print lambda-body) (print ((lambda (x) lambda-body) '(1 2 3 4 5 6))) (map 'list (lambda (x) lambda-body) my-list))
You probably need something like this: (flet ((lambda-body (x) (loop for i in '(0 2) collect (nth i x)))) (map 'list #'lambda-body my-list))
I've implement blake2b: + cool and fast + optional keying + pass on original test vectors FILES: + blake2.l + test-blake2.l 
Either that CXML is junk, or it's being used wrong. What you want is something like: (some-html-macro stream `(div (class foo) "this is static text" ,this-is-interpolated ;; backquote does this for us (span (style "color:blue") "blue") ... )) Ten years ago, I used something like this already without having to write it myself; let's not regress to the stone age. Here is Cliki's portal to HTML generators: http://www.cliki.net/HTML%20generator 
The Racket Guide itself is a solid tutorial and reference. Creating your own languages would, I think, be the best way to really "get" Racket as much as it has to offer. Unfortunately, there aren't many other books or references worth noting (unless you're looking for something very basic in which case "How to Design Programs" and PLAI might be useful). I would recommend jumping right into the Racket Guide itself.
I second this. The way you think about code in C is so different from the way you think about it in Java that the only thing they really have in common is curly braces. I think the others mentioned are pretty good examples of their field though. Smalltalk is a distilled OO language, Haskell is where you want to be to explore static typing, and lisp is the ultimate dynamic language. But if you ask me to say what is meant by 'C-style', I'd say a systems language - and Java doesn't fit the bill.
Unfortunately I don't know of any Racket resources, but if you want to see lisp in its most powerful form then the book [Let Over Lambda](http://www.letoverlambda.com/) is what you want. It is however written for Common Lisp, and you will need to already be very familiar with CL in order to really appreciate LOL.
Looks like the open source kernel is lacking behind Shen Professional: &gt; Shen Professional (SP) is a graphical cloud based implementation of Shen, based on the OS Shen kernel running under SBCL. Though the OS Shen is a good program, there is no guaranteed support for it and some parts are rather old. The OS SBCL is many versions behind the latest release. Likewise the OS library exists but is not maintained. This does not stop you learning using the OS version of Shen which still remains a very powerful and solid tool. It is still an excellent way to learn Shen before moving to SP. &gt; In contrast, SP is fully up to date and runs under the latest SBCL but with multiple improvements to the kernel. any experience / explanations with that ?